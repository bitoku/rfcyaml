- title: __initial_text__
  contents:
  - '      Network File System (NFS) Version 4 Minor Version 1 Protocol

    '
- title: Abstract
  contents:
  - "Abstract\n   This document describes the Network File System (NFS) version 4\
    \ minor\n   version 1, including features retained from the base protocol (NFS\n\
    \   version 4 minor version 0, which is specified in RFC 7530) and\n   protocol\
    \ extensions made subsequently.  The later minor version has\n   no dependencies\
    \ on NFS version 4 minor version 0, and is considered a\n   separate protocol.\n\
    \   This document obsoletes RFC 5661.  It substantially revises the\n   treatment\
    \ of features relating to multi-server namespace, superseding\n   the description\
    \ of those features appearing in RFC 5661.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This is an Internet Standards Track document.\n   This\
    \ document is a product of the Internet Engineering Task Force\n   (IETF).  It\
    \ represents the consensus of the IETF community.  It has\n   received public\
    \ review and has been approved for publication by the\n   Internet Engineering\
    \ Steering Group (IESG).  Further information on\n   Internet Standards is available\
    \ in Section 2 of RFC 7841.\n   Information about the current status of this document,\
    \ any errata,\n   and how to provide feedback on it may be obtained at\n   https://www.rfc-editor.org/info/rfc8881.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2020 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (https://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n   This document\
    \ may contain material from IETF Documents or IETF\n   Contributions published\
    \ or made publicly available before November\n   10, 2008.  The person(s) controlling\
    \ the copyright in some of this\n   material may not have granted the IETF Trust\
    \ the right to allow\n   modifications of such material outside the IETF Standards\
    \ Process.\n   Without obtaining an adequate license from the person(s) controlling\n\
    \   the copyright in such materials, this document may not be modified\n   outside\
    \ the IETF Standards Process, and derivative works of it may\n   not be created\
    \ outside the IETF Standards Process, except to format\n   it for publication\
    \ as an RFC or to translate it into languages other\n   than English.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction\n     1.1.  Introduction to This Update\n\
    \     1.2.  The NFS Version 4 Minor Version 1 Protocol\n     1.3.  Requirements\
    \ Language\n     1.4.  Scope of This Document\n     1.5.  NFSv4 Goals\n     1.6.\
    \  NFSv4.1 Goals\n     1.7.  General Definitions\n     1.8.  Overview of NFSv4.1\
    \ Features\n     1.9.  Differences from NFSv4.0\n   2.  Core Infrastructure\n\
    \     2.1.  Introduction\n     2.2.  RPC and XDR\n     2.3.  COMPOUND and CB_COMPOUND\n\
    \     2.4.  Client Identifiers and Client Owners\n     2.5.  Server Owners\n \
    \    2.6.  Security Service Negotiation\n     2.7.  Minor Versioning\n     2.8.\
    \  Non-RPC-Based Security Services\n     2.9.  Transport Layers\n     2.10. Session\n\
    \   3.  Protocol Constants and Data Types\n     3.1.  Basic Constants\n     3.2.\
    \  Basic Data Types\n     3.3.  Structured Data Types\n   4.  Filehandles\n  \
    \   4.1.  Obtaining the First Filehandle\n     4.2.  Filehandle Types\n     4.3.\
    \  One Method of Constructing a Volatile Filehandle\n     4.4.  Client Recovery\
    \ from Filehandle Expiration\n   5.  File Attributes\n     5.1.  REQUIRED Attributes\n\
    \     5.2.  RECOMMENDED Attributes\n     5.3.  Named Attributes\n     5.4.  Classification\
    \ of Attributes\n     5.5.  Set-Only and Get-Only Attributes\n     5.6.  REQUIRED\
    \ Attributes - List and Definition References\n     5.7.  RECOMMENDED Attributes\
    \ - List and Definition References\n     5.8.  Attribute Definitions\n     5.9.\
    \  Interpreting owner and owner_group\n     5.10. Character Case Attributes\n\
    \     5.11. Directory Notification Attributes\n     5.12. pNFS Attribute Definitions\n\
    \     5.13. Retention Attributes\n   6.  Access Control Attributes\n     6.1.\
    \  Goals\n     6.2.  File Attributes Discussion\n     6.3.  Common Methods\n \
    \    6.4.  Requirements\n   7.  Single-Server Namespace\n     7.1.  Server Exports\n\
    \     7.2.  Browsing Exports\n     7.3.  Server Pseudo File System\n     7.4.\
    \  Multiple Roots\n     7.5.  Filehandle Volatility\n     7.6.  Exported Root\n\
    \     7.7.  Mount Point Crossing\n     7.8.  Security Policy and Namespace Presentation\n\
    \   8.  State Management\n     8.1.  Client and Session ID\n     8.2.  Stateid\
    \ Definition\n     8.3.  Lease Renewal\n     8.4.  Crash Recovery\n     8.5. \
    \ Server Revocation of Locks\n     8.6.  Short and Long Leases\n     8.7.  Clocks,\
    \ Propagation Delay, and Calculating Lease Expiration\n     8.8.  Obsolete Locking\
    \ Infrastructure from NFSv4.0\n   9.  File Locking and Share Reservations\n  \
    \   9.1.  Opens and Byte-Range Locks\n     9.2.  Lock Ranges\n     9.3.  Upgrading\
    \ and Downgrading Locks\n     9.4.  Stateid Seqid Values and Byte-Range Locks\n\
    \     9.5.  Issues with Multiple Open-Owners\n     9.6.  Blocking Locks\n    \
    \ 9.7.  Share Reservations\n     9.8.  OPEN/CLOSE Operations\n     9.9.  Open\
    \ Upgrade and Downgrade\n     9.10. Parallel OPENs\n     9.11. Reclaim of Open\
    \ and Byte-Range Locks\n   10. Client-Side Caching\n     10.1.  Performance Challenges\
    \ for Client-Side Caching\n     10.2.  Delegation and Callbacks\n     10.3.  Data\
    \ Caching\n     10.4.  Open Delegation\n     10.5.  Data Caching and Revocation\n\
    \     10.6.  Attribute Caching\n     10.7.  Data and Metadata Caching and Memory\
    \ Mapped Files\n     10.8.  Name and Directory Caching without Directory Delegations\n\
    \     10.9.  Directory Delegations\n   11. Multi-Server Namespace\n     11.1.\
    \  Terminology\n     11.2.  File System Location Attributes\n     11.3.  File\
    \ System Presence or Absence\n     11.4.  Getting Attributes for an Absent File\
    \ System\n     11.5.  Uses of File System Location Information\n     11.6.  Trunking\
    \ without File System Location Information\n     11.7.  Users and Groups in a\
    \ Multi-Server Namespace\n     11.8.  Additional Client-Side Considerations\n\
    \     11.9.  Overview of File Access Transitions\n     11.10. Effecting Network\
    \ Endpoint Transitions\n     11.11. Effecting File System Transitions\n     11.12.\
    \ Transferring State upon Migration\n     11.13. Client Responsibilities When\
    \ Access Is Transitioned\n     11.14. Server Responsibilities Upon Migration\n\
    \     11.15. Effecting File System Referrals\n     11.16. The Attribute fs_locations\n\
    \     11.17. The Attribute fs_locations_info\n     11.18. The Attribute fs_status\n\
    \   12. Parallel NFS (pNFS)\n     12.1.  Introduction\n     12.2.  pNFS Definitions\n\
    \     12.3.  pNFS Operations\n     12.4.  pNFS Attributes\n     12.5.  Layout\
    \ Semantics\n     12.6.  pNFS Mechanics\n     12.7.  Recovery\n     12.8.  Metadata\
    \ and Storage Device Roles\n     12.9.  Security Considerations for pNFS\n   13.\
    \ NFSv4.1 as a Storage Protocol in pNFS: the File Layout Type\n     13.1.  Client\
    \ ID and Session Considerations\n     13.2.  File Layout Definitions\n     13.3.\
    \  File Layout Data Types\n     13.4.  Interpreting the File Layout\n     13.5.\
    \  Data Server Multipathing\n     13.6.  Operations Sent to NFSv4.1 Data Servers\n\
    \     13.7.  COMMIT through Metadata Server\n     13.8.  The Layout Iomode\n \
    \    13.9.  Metadata and Data Server State Coordination\n     13.10. Data Server\
    \ Component File Size\n     13.11. Layout Revocation and Fencing\n     13.12.\
    \ Security Considerations for the File Layout Type\n   14. Internationalization\n\
    \     14.1.  Stringprep Profile for the utf8str_cs Type\n     14.2.  Stringprep\
    \ Profile for the utf8str_cis Type\n     14.3.  Stringprep Profile for the utf8str_mixed\
    \ Type\n     14.4.  UTF-8 Capabilities\n     14.5.  UTF-8 Related Errors\n   15.\
    \ Error Values\n     15.1.  Error Definitions\n     15.2.  Operations and Their\
    \ Valid Errors\n     15.3.  Callback Operations and Their Valid Errors\n     15.4.\
    \  Errors and the Operations That Use Them\n   16. NFSv4.1 Procedures\n     16.1.\
    \  Procedure 0: NULL - No Operation\n     16.2.  Procedure 1: COMPOUND - Compound\
    \ Operations\n   17. Operations: REQUIRED, RECOMMENDED, or OPTIONAL\n   18. NFSv4.1\
    \ Operations\n     18.1.  Operation 3: ACCESS - Check Access Rights\n     18.2.\
    \  Operation 4: CLOSE - Close File\n     18.3.  Operation 5: COMMIT - Commit Cached\
    \ Data\n     18.4.  Operation 6: CREATE - Create a Non-Regular File Object\n \
    \    18.5.  Operation 7: DELEGPURGE - Purge Delegations Awaiting\n           \
    \  Recovery\n     18.6.  Operation 8: DELEGRETURN - Return Delegation\n     18.7.\
    \  Operation 9: GETATTR - Get Attributes\n     18.8.  Operation 10: GETFH - Get\
    \ Current Filehandle\n     18.9.  Operation 11: LINK - Create Link to a File\n\
    \     18.10. Operation 12: LOCK - Create Lock\n     18.11. Operation 13: LOCKT\
    \ - Test for Lock\n     18.12. Operation 14: LOCKU - Unlock File\n     18.13.\
    \ Operation 15: LOOKUP - Lookup Filename\n     18.14. Operation 16: LOOKUPP -\
    \ Lookup Parent Directory\n     18.15. Operation 17: NVERIFY - Verify Difference\
    \ in Attributes\n     18.16. Operation 18: OPEN - Open a Regular File\n     18.17.\
    \ Operation 19: OPENATTR - Open Named Attribute Directory\n     18.18. Operation\
    \ 21: OPEN_DOWNGRADE - Reduce Open File Access\n     18.19. Operation 22: PUTFH\
    \ - Set Current Filehandle\n     18.20. Operation 23: PUTPUBFH - Set Public Filehandle\n\
    \     18.21. Operation 24: PUTROOTFH - Set Root Filehandle\n     18.22. Operation\
    \ 25: READ - Read from File\n     18.23. Operation 26: READDIR - Read Directory\n\
    \     18.24. Operation 27: READLINK - Read Symbolic Link\n     18.25. Operation\
    \ 28: REMOVE - Remove File System Object\n     18.26. Operation 29: RENAME - Rename\
    \ Directory Entry\n     18.27. Operation 31: RESTOREFH - Restore Saved Filehandle\n\
    \     18.28. Operation 32: SAVEFH - Save Current Filehandle\n     18.29. Operation\
    \ 33: SECINFO - Obtain Available Security\n     18.30. Operation 34: SETATTR -\
    \ Set Attributes\n     18.31. Operation 37: VERIFY - Verify Same Attributes\n\
    \     18.32. Operation 38: WRITE - Write to File\n     18.33. Operation 40: BACKCHANNEL_CTL\
    \ - Backchannel Control\n     18.34. Operation 41: BIND_CONN_TO_SESSION - Associate\
    \ Connection\n             with Session\n     18.35. Operation 42: EXCHANGE_ID\
    \ - Instantiate Client ID\n     18.36. Operation 43: CREATE_SESSION - Create New\
    \ Session and\n             Confirm Client ID\n     18.37. Operation 44: DESTROY_SESSION\
    \ - Destroy a Session\n     18.38. Operation 45: FREE_STATEID - Free Stateid with\
    \ No Locks\n     18.39. Operation 46: GET_DIR_DELEGATION - Get a Directory\n \
    \            Delegation\n     18.40. Operation 47: GETDEVICEINFO - Get Device\
    \ Information\n     18.41. Operation 48: GETDEVICELIST - Get All Device Mappings\
    \ for\n             a File System\n     18.42. Operation 49: LAYOUTCOMMIT - Commit\
    \ Writes Made Using a\n             Layout\n     18.43. Operation 50: LAYOUTGET\
    \ - Get Layout Information\n     18.44. Operation 51: LAYOUTRETURN - Release Layout\
    \ Information\n     18.45. Operation 52: SECINFO_NO_NAME - Get Security on Unnamed\n\
    \             Object\n     18.46. Operation 53: SEQUENCE - Supply Per-Procedure\
    \ Sequencing\n             and Control\n     18.47. Operation 54: SET_SSV - Update\
    \ SSV for a Client ID\n     18.48. Operation 55: TEST_STATEID - Test Stateids\
    \ for Validity\n     18.49. Operation 56: WANT_DELEGATION - Request Delegation\n\
    \     18.50. Operation 57: DESTROY_CLIENTID - Destroy a Client ID\n     18.51.\
    \ Operation 58: RECLAIM_COMPLETE - Indicates Reclaims\n             Finished\n\
    \     18.52. Operation 10044: ILLEGAL - Illegal Operation\n   19. NFSv4.1 Callback\
    \ Procedures\n     19.1.  Procedure 0: CB_NULL - No Operation\n     19.2.  Procedure\
    \ 1: CB_COMPOUND - Compound Operations\n   20. NFSv4.1 Callback Operations\n \
    \    20.1.  Operation 3: CB_GETATTR - Get Attributes\n     20.2.  Operation 4:\
    \ CB_RECALL - Recall a Delegation\n     20.3.  Operation 5: CB_LAYOUTRECALL -\
    \ Recall Layout from Client\n     20.4.  Operation 6: CB_NOTIFY - Notify Client\
    \ of Directory\n             Changes\n     20.5.  Operation 7: CB_PUSH_DELEG -\
    \ Offer Previously Requested\n             Delegation to Client\n     20.6.  Operation\
    \ 8: CB_RECALL_ANY - Keep Any N Recallable Objects\n     20.7.  Operation 9: CB_RECALLABLE_OBJ_AVAIL\
    \ - Signal Resources\n             for Recallable Objects\n     20.8.  Operation\
    \ 10: CB_RECALL_SLOT - Change Flow Control Limits\n     20.9.  Operation 11: CB_SEQUENCE\
    \ - Supply Backchannel Sequencing\n             and Control\n     20.10. Operation\
    \ 12: CB_WANTS_CANCELLED - Cancel Pending\n             Delegation Wants\n   \
    \  20.11. Operation 13: CB_NOTIFY_LOCK - Notify Client of Possible\n         \
    \    Lock Availability\n     20.12. Operation 14: CB_NOTIFY_DEVICEID - Notify\
    \ Client of Device\n             ID Changes\n     20.13. Operation 10044: CB_ILLEGAL\
    \ - Illegal Callback Operation\n   21. Security Considerations\n   22. IANA Considerations\n\
    \     22.1.  IANA Actions\n     22.2.  Named Attribute Definitions\n     22.3.\
    \  Device ID Notifications\n     22.4.  Object Recall Types\n     22.5.  Layout\
    \ Types\n     22.6.  Path Variable Definitions\n   23. References\n     23.1.\
    \  Normative References\n     23.2.  Informative References\n   Appendix A.  The\
    \ Need for This Update\n   Appendix B.  Changes in This Update\n     B.1.  Revisions\
    \ Made to Section 11 of RFC 5661\n     B.2.  Revisions Made to Operations in RFC\
    \ 5661\n     B.3.  Revisions Made to Error Definitions in RFC 5661\n     B.4.\
    \  Other Revisions Made to RFC 5661\n   Appendix C.  Security Issues That Need\
    \ to Be Addressed\n   Acknowledgments\n   Authors' Addresses\n"
- title: 1.  Introduction
  contents:
  - '1.  Introduction

    '
- title: 1.1.  Introduction to This Update
  contents:
  - "1.1.  Introduction to This Update\n   Two important features previously defined\
    \ in minor version 0 but\n   never fully addressed in minor version 1 are trunking,\
    \ which is the\n   simultaneous use of multiple connections between a client and\
    \ server,\n   potentially to different network addresses, and Transparent State\n\
    \   Migration, which allows a file system to be transferred between\n   servers\
    \ in a way that provides to the client the ability to maintain\n   its existing\
    \ locking state across the transfer.\n   The revised description of the NFS version\
    \ 4 minor version 1\n   (NFSv4.1) protocol presented in this update is necessary\
    \ to enable\n   full use of these features together with other multi-server namespace\n\
    \   features.  This document is in the form of an updated description of\n   the\
    \ NFSv4.1 protocol previously defined in RFC 5661 [66].  RFC 5661\n   is obsoleted\
    \ by this document.  However, the update has a limited\n   scope and is focused\
    \ on enabling full use of trunking and Transparent\n   State Migration.  The need\
    \ for these changes is discussed in\n   Appendix A.  Appendix B describes the\
    \ specific changes made to arrive\n   at the current text.\n   This limited-scope\
    \ update replaces the current NFSv4.1 RFC with the\n   intention of providing\
    \ an authoritative and complete specification,\n   the motivation for which is\
    \ discussed in [36], addressing the issues\n   within the scope of the update.\
    \  However, it will not address issues\n   that are known but outside of this\
    \ limited scope as could be expected\n   by a full update of the protocol.  Below\
    \ are some areas that are\n   known to need addressing in a future update of the\
    \ protocol:\n   *  Work needs to be done with regard to RFC 8178 [67], which\n\
    \      establishes NFSv4-wide versioning rules.  As RFC 5661 is currently\n  \
    \    inconsistent with that document, changes are needed in order to\n      arrive\
    \ at a situation in which there would be no need for RFC 8178\n      to update\
    \ the NFSv4.1 specification.\n   *  Work needs to be done with regard to RFC 8434\
    \ [70], which\n      establishes the requirements for parallel NFS (pNFS) layout\
    \ types,\n      which are not clearly defined in RFC 5661.  When that work is\
    \ done\n      and the resulting documents approved, the new NFSv4.1\n      specification\
    \ document will provide a clear set of requirements\n      for layout types and\
    \ a description of the file layout type that\n      conforms to those requirements.\
    \  Other layout types will have\n      their own specification documents that\
    \ conform to those\n      requirements as well.\n   *  Work needs to be done to\
    \ address many errata reports relevant to\n      RFC 5661, other than errata report\
    \ 2006 [64], which is addressed\n      in this document.  Addressing that report\
    \ was not deferrable\n      because of the interaction of the changes suggested\
    \ there and the\n      newly described handling of state and session migration.\n\
    \      The errata reports that have been deferred and that will need to\n    \
    \  be addressed in a later document include reports currently\n      assigned\
    \ a range of statuses in the errata reporting system,\n      including reports\
    \ marked Accepted and those marked Hold For\n      Document Update because the\
    \ change was too minor to address\n      immediately.\n      In addition, there\
    \ is a set of other reports, including at least\n      one in state Rejected,\
    \ that will need to be addressed in a later\n      document.  This will involve\
    \ making changes to consensus decisions\n      reflected in RFC 5661, in situations\
    \ in which the working group\n      has decided that the treatment in RFC 5661\
    \ is incorrect and needs\n      to be revised to reflect the working group's new\
    \ consensus and to\n      ensure compatibility with existing implementations that\
    \ do not\n      follow the handling described in RFC 5661.\n      Note that it\
    \ is expected that all such errata reports will remain\n      relevant to implementors\
    \ and the authors of an eventual\n      rfc5661bis, despite the fact that this\
    \ document obsoletes RFC 5661\n      [66].\n   *  There is a need for a new approach\
    \ to the description of\n      internationalization since the current internationalization\n\
    \      section (Section 14) has never been implemented and does not meet\n   \
    \   the needs of the NFSv4 protocol.  Possible solutions are to create\n     \
    \ a new internationalization section modeled on that in [68] or to\n      create\
    \ a new document describing internationalization for all\n      NFSv4 minor versions\
    \ and reference that document in the RFCs\n      defining both NFSv4.0 and NFSv4.1.\n\
    \   *  There is a need for a revised treatment of security in NFSv4.1.\n     \
    \ The issues with the existing treatment are discussed in\n      Appendix C.\n\
    \   Until the above work is done, there will not be a consistent set of\n   documents\
    \ that provides a description of the NFSv4.1 protocol, and\n   any full description\
    \ would involve documents updating other documents\n   within the specification.\
    \  The updates applied by RFC 8434 [70] and\n   RFC 8178 [67] to RFC 5661 also\
    \ apply to this specification, and will\n   apply to any subsequent v4.1 specification\
    \ until that work is done.\n"
- title: 1.2.  The NFS Version 4 Minor Version 1 Protocol
  contents:
  - "1.2.  The NFS Version 4 Minor Version 1 Protocol\n   The NFS version 4 minor\
    \ version 1 (NFSv4.1) protocol is the second\n   minor version of the NFS version\
    \ 4 (NFSv4) protocol.  The first minor\n   version, NFSv4.0, is now described\
    \ in RFC 7530 [68].  It generally\n   follows the guidelines for minor versioning\
    \ that are listed in\n   Section 10 of RFC 3530 [37].  However, it diverges from\
    \ guidelines 11\n   (\"a client and server that support minor version X must support\
    \ minor\n   versions 0 through X-1\") and 12 (\"no new features may be introduced\n\
    \   as mandatory in a minor version\").  These divergences are due to the\n  \
    \ introduction of the sessions model for managing non-idempotent\n   operations\
    \ and the RECLAIM_COMPLETE operation.  These two new\n   features are infrastructural\
    \ in nature and simplify implementation of\n   existing and other new features.\
    \  Making them anything but REQUIRED\n   would add undue complexity to protocol\
    \ definition and implementation.\n   NFSv4.1 accordingly updates the minor versioning\
    \ guidelines\n   (Section 2.7).\n   As a minor version, NFSv4.1 is consistent\
    \ with the overall goals for\n   NFSv4, but extends the protocol so as to better\
    \ meet those goals,\n   based on experiences with NFSv4.0.  In addition, NFSv4.1\
    \ has adopted\n   some additional goals, which motivate some of the major extensions\
    \ in\n   NFSv4.1.\n"
- title: 1.3.  Requirements Language
  contents:
  - "1.3.  Requirements Language\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\"\
    , \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"\
    MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in RFC 2119 [1].\n"
- title: 1.4.  Scope of This Document
  contents:
  - "1.4.  Scope of This Document\n   This document describes the NFSv4.1 protocol.\
    \  With respect to\n   NFSv4.0, this document does not:\n   *  describe the NFSv4.0\
    \ protocol, except where needed to contrast\n      with NFSv4.1.\n   *  modify\
    \ the specification of the NFSv4.0 protocol.\n   *  clarify the NFSv4.0 protocol.\n"
- title: 1.5.  NFSv4 Goals
  contents:
  - "1.5.  NFSv4 Goals\n   The NFSv4 protocol is a further revision of the NFS protocol\
    \ defined\n   already by NFSv3 [38].  It retains the essential characteristics\
    \ of\n   previous versions: easy recovery; independence of transport\n   protocols,\
    \ operating systems, and file systems; simplicity; and good\n   performance. \
    \ NFSv4 has the following goals:\n   *  Improved access and good performance on\
    \ the Internet\n      The protocol is designed to transit firewalls easily, perform\
    \ well\n      where latency is high and bandwidth is low, and scale to very\n\
    \      large numbers of clients per server.\n   *  Strong security with negotiation\
    \ built into the protocol\n      The protocol builds on the work of the ONCRPC\
    \ working group in\n      supporting the RPCSEC_GSS protocol.  Additionally, the\
    \ NFSv4.1\n      protocol provides a mechanism to allow clients and servers the\n\
    \      ability to negotiate security and require clients and servers to\n    \
    \  support a minimal set of security schemes.\n   *  Good cross-platform interoperability\n\
    \      The protocol features a file system model that provides a useful,\n   \
    \   common set of features that does not unduly favor one file system\n      or\
    \ operating system over another.\n   *  Designed for protocol extensions\n   \
    \   The protocol is designed to accept standard extensions within a\n      framework\
    \ that enables and encourages backward compatibility.\n"
- title: 1.6.  NFSv4.1 Goals
  contents:
  - "1.6.  NFSv4.1 Goals\n   NFSv4.1 has the following goals, within the framework\
    \ established by\n   the overall NFSv4 goals.\n   *  To correct significant structural\
    \ weaknesses and oversights\n      discovered in the base protocol.\n   *  To\
    \ add clarity and specificity to areas left unaddressed or not\n      addressed\
    \ in sufficient detail in the base protocol.  However, as\n      stated in Section\
    \ 1.4, it is not a goal to clarify the NFSv4.0\n      protocol in the NFSv4.1\
    \ specification.\n   *  To add specific features based on experience with the\
    \ existing\n      protocol and recent industry developments.\n   *  To provide\
    \ protocol support to take advantage of clustered server\n      deployments including\
    \ the ability to provide scalable parallel\n      access to files distributed\
    \ among multiple servers.\n"
- title: 1.7.  General Definitions
  contents:
  - "1.7.  General Definitions\n   The following definitions provide an appropriate\
    \ context for the\n   reader.\n   Byte:  In this document, a byte is an octet,\
    \ i.e., a datum exactly 8\n      bits in length.\n   Client:  The client is the\
    \ entity that accesses the NFS server's\n      resources.  The client may be an\
    \ application that contains the\n      logic to access the NFS server directly.\
    \  The client may also be\n      the traditional operating system client that\
    \ provides remote file\n      system services for a set of applications.\n   \
    \   A client is uniquely identified by a client owner.\n      With reference to\
    \ byte-range locking, the client is also the\n      entity that maintains a set\
    \ of locks on behalf of one or more\n      applications.  This client is responsible\
    \ for crash or failure\n      recovery for those locks it manages.\n      Note\
    \ that multiple clients may share the same transport and\n      connection and\
    \ multiple clients may exist on the same network\n      node.\n   Client ID: \
    \ The client ID is a 64-bit quantity used as a unique,\n      short-hand reference\
    \ to a client-supplied verifier and client\n      owner.  The server is responsible\
    \ for supplying the client ID.\n   Client Owner:  The client owner is a unique\
    \ string, opaque to the\n      server, that identifies a client.  Multiple network\
    \ connections\n      and source network addresses originating from those connections\n\
    \      may share a client owner.  The server is expected to treat\n      requests\
    \ from connections with the same client owner as coming\n      from the same client.\n\
    \   File System:  The file system is the collection of objects on a\n      server\
    \ (as identified by the major identifier of a server owner,\n      which is defined\
    \ later in this section) that share the same fsid\n      attribute (see Section\
    \ 5.8.1.9).\n   Lease:  A lease is an interval of time defined by the server for\n\
    \      which the client is irrevocably granted locks.  At the end of a\n     \
    \ lease period, locks may be revoked if the lease has not been\n      extended.\
    \  A lock must be revoked if a conflicting lock has been\n      granted after\
    \ the lease interval.\n      A server grants a client a single lease for all state.\n\
    \   Lock:  The term \"lock\" is used to refer to byte-range (in UNIX\n      environments,\
    \ also known as record) locks, share reservations,\n      delegations, or layouts\
    \ unless specifically stated otherwise.\n   Secret State Verifier (SSV):  The\
    \ SSV is a unique secret key shared\n      between a client and server.  The SSV\
    \ serves as the secret key for\n      an internal (that is, internal to NFSv4.1)\
    \ Generic Security\n      Services (GSS) mechanism (the SSV GSS mechanism; see\n\
    \      Section 2.10.9).  The SSV GSS mechanism uses the SSV to compute\n     \
    \ message integrity code (MIC) and Wrap tokens.  See\n      Section 2.10.8.3 for\
    \ more details on how NFSv4.1 uses the SSV and\n      the SSV GSS mechanism.\n\
    \   Server:  The Server is the entity responsible for coordinating client\n  \
    \    access to a set of file systems and is identified by a server\n      owner.\
    \  A server can span multiple network addresses.\n   Server Owner:  The server\
    \ owner identifies the server to the client.\n      The server owner consists\
    \ of a major identifier and a minor\n      identifier.  When the client has two\
    \ connections each to a peer\n      with the same major identifier, the client\
    \ assumes that both peers\n      are the same server (the server namespace is\
    \ the same via each\n      connection) and that lock state is shareable across\
    \ both\n      connections.  When each peer has both the same major and minor\n\
    \      identifiers, the client assumes that each connection might be\n      associable\
    \ with the same session.\n   Stable Storage:  Stable storage is storage from which\
    \ data stored by\n      an NFSv4.1 server can be recovered without data loss from\
    \ multiple\n      power failures (including cascading power failures, that is,\n\
    \      several power failures in quick succession), operating system\n      failures,\
    \ and/or hardware failure of components other than the\n      storage medium itself\
    \ (such as disk, nonvolatile RAM, flash\n      memory, etc.).\n      Some examples\
    \ of stable storage that are allowable for an NFS\n      server include:\n   \
    \   1.  Media commit of data; that is, the modified data has been\n          successfully\
    \ written to the disk media, for example, the disk\n          platter.\n     \
    \ 2.  An immediate reply disk drive with battery-backed, on-drive\n          intermediate\
    \ storage or uninterruptible power system (UPS).\n      3.  Server commit of data\
    \ with battery-backed intermediate storage\n          and recovery software.\n\
    \      4.  Cache commit with uninterruptible power system (UPS) and\n        \
    \  recovery software.\n   Stateid:  A stateid is a 128-bit quantity returned by\
    \ a server that\n      uniquely defines the open and locking states provided by\
    \ the\n      server for a specific open-owner or lock-owner/open-owner pair for\n\
    \      a specific file and type of lock.\n   Verifier:  A verifier is a 64-bit\
    \ quantity generated by the client\n      that the server can use to determine\
    \ if the client has restarted\n      and lost all previous lock state.\n"
- title: 1.8.  Overview of NFSv4.1 Features
  contents:
  - "1.8.  Overview of NFSv4.1 Features\n   The major features of the NFSv4.1 protocol\
    \ will be reviewed in brief.\n   This will be done to provide an appropriate context\
    \ for both the\n   reader who is familiar with the previous versions of the NFS\
    \ protocol\n   and the reader who is new to the NFS protocols.  For the reader\
    \ new\n   to the NFS protocols, there is still a set of fundamental knowledge\n\
    \   that is expected.  The reader should be familiar with the External\n   Data\
    \ Representation (XDR) and Remote Procedure Call (RPC) protocols\n   as described\
    \ in [2] and [3].  A basic knowledge of file systems and\n   distributed file\
    \ systems is expected as well.\n   In general, this specification of NFSv4.1 will\
    \ not distinguish those\n   features added in minor version 1 from those present\
    \ in the base\n   protocol but will treat NFSv4.1 as a unified whole.  See Section\
    \ 1.9\n   for a summary of the differences between NFSv4.0 and NFSv4.1.\n"
- title: 1.8.1.  RPC and Security
  contents:
  - "1.8.1.  RPC and Security\n   As with previous versions of NFS, the External Data\
    \ Representation\n   (XDR) and Remote Procedure Call (RPC) mechanisms used for\
    \ the NFSv4.1\n   protocol are those defined in [2] and [3].  To meet end-to-end\n\
    \   security requirements, the RPCSEC_GSS framework [4] is used to extend\n  \
    \ the basic RPC security.  With the use of RPCSEC_GSS, various\n   mechanisms\
    \ can be provided to offer authentication, integrity, and\n   privacy to the NFSv4\
    \ protocol.  Kerberos V5 is used as described in\n   [5] to provide one security\
    \ framework.  With the use of RPCSEC_GSS,\n   other mechanisms may also be specified\
    \ and used for NFSv4.1 security.\n   To enable in-band security negotiation, the\
    \ NFSv4.1 protocol has\n   operations that provide the client a method of querying\
    \ the server\n   about its policies regarding which security mechanisms must be\
    \ used\n   for access to the server's file system resources.  With this, the\n\
    \   client can securely match the security mechanism that meets the\n   policies\
    \ specified at both the client and server.\n   NFSv4.1 introduces parallel access\
    \ (see Section 1.8.2.2), which is\n   called pNFS.  The security framework described\
    \ in this section is\n   significantly modified by the introduction of pNFS (see\n\
    \   Section 12.9), because data access is sometimes not over RPC.  The\n   level\
    \ of significance varies with the storage protocol (see\n   Section 12.2.5) and\
    \ can be as low as zero impact (see Section 13.12).\n"
- title: 1.8.2.  Protocol Structure
  contents:
  - '1.8.2.  Protocol Structure

    '
- title: 1.8.2.1.  Core Protocol
  contents:
  - "1.8.2.1.  Core Protocol\n   Unlike NFSv3, which used a series of ancillary protocols\
    \ (e.g., NLM,\n   NSM (Network Status Monitor), MOUNT), within all minor versions\
    \ of\n   NFSv4 a single RPC protocol is used to make requests to the server.\n\
    \   Facilities that had been separate protocols, such as locking, are now\n  \
    \ integrated within a single unified protocol.\n"
- title: 1.8.2.2.  Parallel Access
  contents:
  - "1.8.2.2.  Parallel Access\n   Minor version 1 supports high-performance data\
    \ access to a clustered\n   server implementation by enabling a separation of\
    \ metadata access and\n   data access, with the latter done to multiple servers\
    \ in parallel.\n   Such parallel data access is controlled by recallable objects\
    \ known\n   as \"layouts\", which are integrated into the protocol locking model.\n\
    \   Clients direct requests for data access to a set of data servers\n   specified\
    \ by the layout via a data storage protocol which may be\n   NFSv4.1 or may be\
    \ another protocol.\n   Because the protocols used for parallel data access are\
    \ not\n   necessarily RPC-based, the RPC-based security model (Section 1.8.1)\n\
    \   is obviously impacted (see Section 12.9).  The degree of impact\n   varies\
    \ with the storage protocol (see Section 12.2.5) used for data\n   access, and\
    \ can be as low as zero (see Section 13.12).\n"
- title: 1.8.3.  File System Model
  contents:
  - "1.8.3.  File System Model\n   The general file system model used for the NFSv4.1\
    \ protocol is the\n   same as previous versions.  The server file system is hierarchical\n\
    \   with the regular files contained within being treated as opaque byte\n   streams.\
    \  In a slight departure, file and directory names are encoded\n   with UTF-8\
    \ to deal with the basics of internationalization.\n   The NFSv4.1 protocol does\
    \ not require a separate protocol to provide\n   for the initial mapping between\
    \ path name and filehandle.  All file\n   systems exported by a server are presented\
    \ as a tree so that all file\n   systems are reachable from a special per-server\
    \ global root\n   filehandle.  This allows LOOKUP operations to be used to perform\n\
    \   functions previously provided by the MOUNT protocol.  The server\n   provides\
    \ any necessary pseudo file systems to bridge any gaps that\n   arise due to unexported\
    \ gaps between exported file systems.\n"
- title: 1.8.3.1.  Filehandles
  contents:
  - "1.8.3.1.  Filehandles\n   As in previous versions of the NFS protocol, opaque\
    \ filehandles are\n   used to identify individual files and directories.  Lookup-type\
    \ and\n   create operations translate file and directory names to filehandles,\n\
    \   which are then used to identify objects in subsequent operations.\n   The\
    \ NFSv4.1 protocol provides support for persistent filehandles,\n   guaranteed\
    \ to be valid for the lifetime of the file system object\n   designated.  In addition,\
    \ it provides support to servers to provide\n   filehandles with more limited\
    \ validity guarantees, called volatile\n   filehandles.\n"
- title: 1.8.3.2.  File Attributes
  contents:
  - "1.8.3.2.  File Attributes\n   The NFSv4.1 protocol has a rich and extensible\
    \ file object attribute\n   structure, which is divided into REQUIRED, RECOMMENDED,\
    \ and named\n   attributes (see Section 5).\n   Several (but not all) of the REQUIRED\
    \ attributes are derived from the\n   attributes of NFSv3 (see the definition\
    \ of the fattr3 data type in\n   [38]).  An example of a REQUIRED attribute is\
    \ the file object's type\n   (Section 5.8.1.2) so that regular files can be distinguished\
    \ from\n   directories (also known as folders in some operating environments)\n\
    \   and other types of objects.  REQUIRED attributes are discussed in\n   Section\
    \ 5.1.\n   An example of three RECOMMENDED attributes are acl, sacl, and dacl.\n\
    \   These attributes define an Access Control List (ACL) on a file object\n  \
    \ (Section 6).  An ACL provides directory and file access control\n   beyond the\
    \ model used in NFSv3.  The ACL definition allows for\n   specification of specific\
    \ sets of permissions for individual users\n   and groups.  In addition, ACL inheritance\
    \ allows propagation of\n   access permissions and restrictions down a directory\
    \ tree as file\n   system objects are created.  RECOMMENDED attributes are discussed\
    \ in\n   Section 5.2.\n   A named attribute is an opaque byte stream that is associated\
    \ with a\n   directory or file and referred to by a string name.  Named attributes\n\
    \   are meant to be used by client applications as a method to associate\n   application-specific\
    \ data with a regular file or directory.  NFSv4.1\n   modifies named attributes\
    \ relative to NFSv4.0 by tightening the\n   allowed operations in order to prevent\
    \ the development of non-\n   interoperable implementations.  Named attributes\
    \ are discussed in\n   Section 5.3.\n"
- title: 1.8.3.3.  Multi-Server Namespace
  contents:
  - "1.8.3.3.  Multi-Server Namespace\n   NFSv4.1 contains a number of features to\
    \ allow implementation of\n   namespaces that cross server boundaries and that\
    \ allow and facilitate\n   a nondisruptive transfer of support for individual\
    \ file systems\n   between servers.  They are all based upon attributes that allow\
    \ one\n   file system to specify alternate, additional, and new location\n   information\
    \ that specifies how the client may access that file\n   system.\n   These attributes\
    \ can be used to provide for individual active file\n   systems:\n   *  Alternate\
    \ network addresses to access the current file system\n      instance.\n   * \
    \ The locations of alternate file system instances or replicas to be\n      used\
    \ in the event that the current file system instance becomes\n      unavailable.\n\
    \   These file system location attributes may be used together with the\n   concept\
    \ of absent file systems, in which a position in the server\n   namespace is associated\
    \ with locations on other servers without there\n   being any corresponding file\
    \ system instance on the current server.\n   For example,\n   *  These attributes\
    \ may be used with absent file systems to implement\n      referrals whereby one\
    \ server may direct the client to a file\n      system provided by another server.\
    \  This allows extensive multi-\n      server namespaces to be constructed.\n\
    \   *  These attributes may be provided when a previously present file\n     \
    \ system becomes absent.  This allows nondisruptive migration of\n      file systems\
    \ to alternate servers.\n"
- title: 1.8.4.  Locking Facilities
  contents:
  - "1.8.4.  Locking Facilities\n   As mentioned previously, NFSv4.1 is a single protocol\
    \ that includes\n   locking facilities.  These locking facilities include support\
    \ for\n   many types of locks including a number of sorts of recallable locks.\n\
    \   Recallable locks such as delegations allow the client to be assured\n   that\
    \ certain events will not occur so long as that lock is held.\n   When circumstances\
    \ change, the lock is recalled via a callback\n   request.  The assurances provided\
    \ by delegations allow more extensive\n   caching to be done safely when circumstances\
    \ allow it.\n   The types of locks are:\n   *  Share reservations as established\
    \ by OPEN operations.\n   *  Byte-range locks.\n   *  File delegations, which\
    \ are recallable locks that assure the\n      holder that inconsistent opens and\
    \ file changes cannot occur so\n      long as the delegation is held.\n   *  Directory\
    \ delegations, which are recallable locks that assure the\n      holder that inconsistent\
    \ directory modifications cannot occur so\n      long as the delegation is held.\n\
    \   *  Layouts, which are recallable objects that assure the holder that\n   \
    \   direct access to the file data may be performed directly by the\n      client\
    \ and that no change to the data's location that is\n      inconsistent with that\
    \ access may be made so long as the layout is\n      held.\n   All locks for a\
    \ given client are tied together under a single client-\n   wide lease.  All requests\
    \ made on sessions associated with the client\n   renew that lease.  When the\
    \ client's lease is not promptly renewed,\n   the client's locks are subject to\
    \ revocation.  In the event of server\n   restart, clients have the opportunity\
    \ to safely reclaim their locks\n   within a special grace period.\n"
- title: 1.9.  Differences from NFSv4.0
  contents:
  - "1.9.  Differences from NFSv4.0\n   The following summarizes the major differences\
    \ between minor version\n   1 and the base protocol:\n   *  Implementation of\
    \ the sessions model (Section 2.10).\n   *  Parallel access to data (Section 12).\n\
    \   *  Addition of the RECLAIM_COMPLETE operation to better structure the\n  \
    \    lock reclamation process (Section 18.51).\n   *  Enhanced delegation support\
    \ as follows.\n      -  Delegations on directories and other file types in addition\
    \ to\n         regular files (Section 18.39, Section 18.49).\n      -  Operations\
    \ to optimize acquisition of recalled or denied\n         delegations (Section\
    \ 18.49, Section 20.5, Section 20.7).\n      -  Notifications of changes to files\
    \ and directories\n         (Section 18.39, Section 20.4).\n      -  A method\
    \ to allow a server to indicate that it is recalling one\n         or more delegations\
    \ for resource management reasons, and thus a\n         method to allow the client\
    \ to pick which delegations to return\n         (Section 20.6).\n   *  Attributes\
    \ can be set atomically during exclusive file create via\n      the OPEN operation\
    \ (see the new EXCLUSIVE4_1 creation method in\n      Section 18.16).\n   *  Open\
    \ files can be preserved if removed and the hard link count\n      (\"hard link\"\
    \ is defined in an Open Group [6] standard) goes to\n      zero, thus obviating\
    \ the need for clients to rename deleted files\n      to partially hidden names\
    \ -- colloquially called \"silly rename\"\n      (see the new OPEN4_RESULT_PRESERVE_UNLINKED\
    \ reply flag in\n      Section 18.16).\n   *  Improved compatibility with Microsoft\
    \ Windows for Access Control\n      Lists (Section 6.2.3, Section 6.2.2, Section\
    \ 6.4.3.2).\n   *  Data retention (Section 5.13).\n   *  Identification of the\
    \ implementation of the NFS client and server\n      (Section 18.35).\n   *  Support\
    \ for notification of the availability of byte-range locks\n      (see the new\
    \ OPEN4_RESULT_MAY_NOTIFY_LOCK reply flag in\n      Section 18.16 and see Section\
    \ 20.11).\n   *  In NFSv4.1, LIPKEY and SPKM-3 are not required security mechanisms\n\
    \      [39].\n"
- title: 2.  Core Infrastructure
  contents:
  - '2.  Core Infrastructure

    '
- title: 2.1.  Introduction
  contents:
  - "2.1.  Introduction\n   NFSv4.1 relies on core infrastructure common to nearly\
    \ every\n   operation.  This core infrastructure is described in the remainder\
    \ of\n   this section.\n"
- title: 2.2.  RPC and XDR
  contents:
  - "2.2.  RPC and XDR\n   The NFSv4.1 protocol is a Remote Procedure Call (RPC) application\n\
    \   that uses RPC version 2 and the corresponding eXternal Data\n   Representation\
    \ (XDR) as defined in [3] and [2].\n"
- title: 2.2.1.  RPC-Based Security
  contents:
  - "2.2.1.  RPC-Based Security\n   Previous NFS versions have been thought of as\
    \ having a host-based\n   authentication model, where the NFS server authenticates\
    \ the NFS\n   client, and trusts the client to authenticate all users.  Actually,\n\
    \   NFS has always depended on RPC for authentication.  One of the first\n   forms\
    \ of RPC authentication, AUTH_SYS, had no strong authentication\n   and required\
    \ a host-based authentication approach.  NFSv4.1 also\n   depends on RPC for basic\
    \ security services and mandates RPC support\n   for a user-based authentication\
    \ model.  The user-based authentication\n   model has user principals authenticated\
    \ by a server, and in turn the\n   server authenticated by user principals.  RPC\
    \ provides some basic\n   security services that are used by NFSv4.1.\n"
- title: 2.2.1.1.  RPC Security Flavors
  contents:
  - "2.2.1.1.  RPC Security Flavors\n   As described in \"Authentication\", Section\
    \ 7 of [3], RPC security is\n   encapsulated in the RPC header, via a security\
    \ or authentication\n   flavor, and information specific to the specified security\
    \ flavor.\n   Every RPC header conveys information used to identify and\n   authenticate\
    \ a client and server.  As discussed in Section 2.2.1.1.1,\n   some security flavors\
    \ provide additional security services.\n   NFSv4.1 clients and servers MUST implement\
    \ RPCSEC_GSS.  (This\n   requirement to implement is not a requirement to use.)\
    \  Other\n   flavors, such as AUTH_NONE and AUTH_SYS, MAY be implemented as well.\n"
- title: 2.2.1.1.1.  RPCSEC_GSS and Security Services
  contents:
  - "2.2.1.1.1.  RPCSEC_GSS and Security Services\n   RPCSEC_GSS [4] uses the functionality\
    \ of GSS-API [7].  This allows\n   for the use of various security mechanisms\
    \ by the RPC layer without\n   the additional implementation overhead of adding\
    \ RPC security\n   flavors.\n"
- title: 2.2.1.1.1.1.  Identification, Authentication, Integrity, Privacy
  contents:
  - "2.2.1.1.1.1.  Identification, Authentication, Integrity, Privacy\n   Via the\
    \ GSS-API, RPCSEC_GSS can be used to identify and authenticate\n   users on clients\
    \ to servers, and servers to users.  It can also\n   perform integrity checking\
    \ on the entire RPC message, including the\n   RPC header, and on the arguments\
    \ or results.  Finally, privacy,\n   usually via encryption, is a service available\
    \ with RPCSEC_GSS.\n   Privacy is performed on the arguments and results.  Note\
    \ that if\n   privacy is selected, integrity, authentication, and identification\n\
    \   are enabled.  If privacy is not selected, but integrity is selected,\n   authentication\
    \ and identification are enabled.  If integrity and\n   privacy are not selected,\
    \ but authentication is enabled,\n   identification is enabled.  RPCSEC_GSS does\
    \ not provide\n   identification as a separate service.\n   Although GSS-API has\
    \ an authentication service distinct from its\n   privacy and integrity services,\
    \ GSS-API's authentication service is\n   not used for RPCSEC_GSS's authentication\
    \ service.  Instead, each RPC\n   request and response header is integrity protected\
    \ with the GSS-API\n   integrity service, and this allows RPCSEC_GSS to offer\
    \ per-RPC\n   authentication and identity.  See [4] for more information.\n  \
    \ NFSv4.1 client and servers MUST support RPCSEC_GSS's integrity and\n   authentication\
    \ service.  NFSv4.1 servers MUST support RPCSEC_GSS's\n   privacy service.  NFSv4.1\
    \ clients SHOULD support RPCSEC_GSS's privacy\n   service.\n"
- title: 2.2.1.1.1.2.  Security Mechanisms for NFSv4.1
  contents:
  - "2.2.1.1.1.2.  Security Mechanisms for NFSv4.1\n   RPCSEC_GSS, via GSS-API, normalizes\
    \ access to mechanisms that provide\n   security services.  Therefore, NFSv4.1\
    \ clients and servers MUST\n   support the Kerberos V5 security mechanism.\n \
    \  The use of RPCSEC_GSS requires selection of mechanism, quality of\n   protection\
    \ (QOP), and service (authentication, integrity, privacy).\n   For the mandated\
    \ security mechanisms, NFSv4.1 specifies that a QOP of\n   zero is used, leaving\
    \ it up to the mechanism or the mechanism's\n   configuration to map QOP zero\
    \ to an appropriate level of protection.\n   Each mandated mechanism specifies\
    \ a minimum set of cryptographic\n   algorithms for implementing integrity and\
    \ privacy.  NFSv4.1 clients\n   and servers MUST be implemented on operating environments\
    \ that comply\n   with the REQUIRED cryptographic algorithms of each REQUIRED\n\
    \   mechanism.\n"
- title: 2.2.1.1.1.2.1.  Kerberos V5
  contents:
  - "2.2.1.1.1.2.1.  Kerberos V5\n   The Kerberos V5 GSS-API mechanism as described\
    \ in [5] MUST be\n   implemented with the RPCSEC_GSS services as specified in\
    \ the\n   following table:\n      column descriptions:\n      1 == number of pseudo\
    \ flavor\n      2 == name of pseudo flavor\n      3 == mechanism's OID\n     \
    \ 4 == RPCSEC_GSS service\n      5 == NFSv4.1 clients MUST support\n      6 ==\
    \ NFSv4.1 servers MUST support\n      1      2        3                    4 \
    \                    5   6\n      390003 krb5     1.2.840.113554.1.2.2 rpc_gss_svc_none\
    \      yes yes\n      390004 krb5i    1.2.840.113554.1.2.2 rpc_gss_svc_integrity\
    \ yes yes\n      390005 krb5p    1.2.840.113554.1.2.2 rpc_gss_svc_privacy    no\
    \ yes\n   Note that the number and name of the pseudo flavor are presented here\n\
    \   as a mapping aid to the implementor.  Because the NFSv4.1 protocol\n   includes\
    \ a method to negotiate security and it understands the GSS-\n   API mechanism,\
    \ the pseudo flavor is not needed.  The pseudo flavor is\n   needed for the NFSv3\
    \ since the security negotiation is done via the\n   MOUNT protocol as described\
    \ in [40].\n   At the time NFSv4.1 was specified, the Advanced Encryption Standard\n\
    \   (AES) with HMAC-SHA1 was a REQUIRED algorithm set for Kerberos V5.\n   In\
    \ contrast, when NFSv4.0 was specified, weaker algorithm sets were\n   REQUIRED\
    \ for Kerberos V5, and were REQUIRED in the NFSv4.0\n   specification, because\
    \ the Kerberos V5 specification at the time did\n   not specify stronger algorithms.\
    \  The NFSv4.1 specification does not\n   specify REQUIRED algorithms for Kerberos\
    \ V5, and instead, the\n   implementor is expected to track the evolution of the\
    \ Kerberos V5\n   standard if and when stronger algorithms are specified.\n"
- title: 2.2.1.1.1.2.1.1.  Security Considerations for Cryptographic Algorithms
  contents:
  - "2.2.1.1.1.2.1.1.  Security Considerations for Cryptographic Algorithms\n    \
    \              in Kerberos V5\n   When deploying NFSv4.1, the strength of the\
    \ security achieved depends\n   on the existing Kerberos V5 infrastructure.  The\
    \ algorithms of\n   Kerberos V5 are not directly exposed to or selectable by the\
    \ client\n   or server, so there is some due diligence required by the user of\n\
    \   NFSv4.1 to ensure that security is acceptable where needed.\n"
- title: 2.2.1.1.1.3.  GSS Server Principal
  contents:
  - "2.2.1.1.1.3.  GSS Server Principal\n   Regardless of what security mechanism\
    \ under RPCSEC_GSS is being used,\n   the NFS server MUST identify itself in GSS-API\
    \ via a\n   GSS_C_NT_HOSTBASED_SERVICE name type.  GSS_C_NT_HOSTBASED_SERVICE\n\
    \   names are of the form:\n        service@hostname\n   For NFS, the \"service\"\
    \ element is\n        nfs\n   Implementations of security mechanisms will convert\
    \ nfs@hostname to\n   various different forms.  For Kerberos V5, the following\
    \ form is\n   RECOMMENDED:\n        nfs/hostname\n"
- title: 2.3.  COMPOUND and CB_COMPOUND
  contents:
  - "2.3.  COMPOUND and CB_COMPOUND\n   A significant departure from the versions\
    \ of the NFS protocol before\n   NFSv4 is the introduction of the COMPOUND procedure.\
    \  For the NFSv4\n   protocol, in all minor versions, there are exactly two RPC\n\
    \   procedures, NULL and COMPOUND.  The COMPOUND procedure is defined as\n   a\
    \ series of individual operations and these operations perform the\n   sorts of\
    \ functions performed by traditional NFS procedures.\n   The operations combined\
    \ within a COMPOUND request are evaluated in\n   order by the server, without\
    \ any atomicity guarantees.  A limited set\n   of facilities exist to pass results\
    \ from one operation to another.\n   Once an operation returns a failing result,\
    \ the evaluation ends and\n   the results of all evaluated operations are returned\
    \ to the client.\n   With the use of the COMPOUND procedure, the client is able\
    \ to build\n   simple or complex requests.  These COMPOUND requests allow for\
    \ a\n   reduction in the number of RPCs needed for logical file system\n   operations.\
    \  For example, multi-component look up requests can be\n   constructed by combining\
    \ multiple LOOKUP operations.  Those can be\n   further combined with operations\
    \ such as GETATTR, READDIR, or OPEN\n   plus READ to do more complicated sets\
    \ of operation without incurring\n   additional latency.\n   NFSv4.1 also contains\
    \ a considerable set of callback operations in\n   which the server makes an RPC\
    \ directed at the client.  Callback RPCs\n   have a similar structure to that\
    \ of the normal server requests.  In\n   all minor versions of the NFSv4 protocol,\
    \ there are two callback RPC\n   procedures: CB_NULL and CB_COMPOUND.  The CB_COMPOUND\
    \ procedure is\n   defined in an analogous fashion to that of COMPOUND with its\
    \ own set\n   of callback operations.\n   The addition of new server and callback\
    \ operations within the\n   COMPOUND and CB_COMPOUND request framework provides\
    \ a means of\n   extending the protocol in subsequent minor versions.\n   Except\
    \ for a small number of operations needed for session creation,\n   server requests\
    \ and callback requests are performed within the\n   context of a session.  Sessions\
    \ provide a client context for every\n   request and support robust replay protection\
    \ for non-idempotent\n   requests.\n"
- title: 2.4.  Client Identifiers and Client Owners
  contents:
  - "2.4.  Client Identifiers and Client Owners\n   For each operation that obtains\
    \ or depends on locking state, the\n   specific client needs to be identifiable\
    \ by the server.\n   Each distinct client instance is represented by a client\
    \ ID.  A\n   client ID is a 64-bit identifier representing a specific client at\
    \ a\n   given time.  The client ID is changed whenever the client re-\n   initializes,\
    \ and may change when the server re-initializes.  Client\n   IDs are used to support\
    \ lock identification and crash recovery.\n   During steady state operation, the\
    \ client ID associated with each\n   operation is derived from the session (see\
    \ Section 2.10) on which the\n   operation is sent.  A session is associated with\
    \ a client ID when the\n   session is created.\n   Unlike NFSv4.0, the only NFSv4.1\
    \ operations possible before a client\n   ID is established are those needed to\
    \ establish the client ID.\n   A sequence of an EXCHANGE_ID operation followed\
    \ by a CREATE_SESSION\n   operation using that client ID (eir_clientid as returned\
    \ from\n   EXCHANGE_ID) is required to establish and confirm the client ID on\n\
    \   the server.  Establishment of identification by a new incarnation of\n   the\
    \ client also has the effect of immediately releasing any locking\n   state that\
    \ a previous incarnation of that same client might have had\n   on the server.\
    \  Such released state would include all byte-range\n   lock, share reservation,\
    \ layout state, and -- where the server\n   supports neither the CLAIM_DELEGATE_PREV\
    \ nor CLAIM_DELEG_CUR_FH claim\n   types -- all delegation state associated with\
    \ the same client with\n   the same identity.  For discussion of delegation state\
    \ recovery, see\n   Section 10.2.1.  For discussion of layout state recovery,\
    \ see\n   Section 12.7.1.\n   Releasing such state requires that the server be\
    \ able to determine\n   that one client instance is the successor of another.\
    \  Where this\n   cannot be done, for any of a number of reasons, the locking\
    \ state\n   will remain for a time subject to lease expiration (see Section 8.3)\n\
    \   and the new client will need to wait for such state to be removed, if\n  \
    \ it makes conflicting lock requests.\n   Client identification is encapsulated\
    \ in the following client owner\n   data type:\n   struct client_owner4 {\n  \
    \         verifier4       co_verifier;\n           opaque          co_ownerid<NFS4_OPAQUE_LIMIT>;\n\
    \   };\n   The first field, co_verifier, is a client incarnation verifier,\n \
    \  allowing the server to distinguish successive incarnations (e.g.,\n   reboots)\
    \ of the same client.  The server will start the process of\n   canceling the\
    \ client's leased state if co_verifier is different than\n   what the server has\
    \ previously recorded for the identified client (as\n   specified in the co_ownerid\
    \ field).\n   The second field, co_ownerid, is a variable length string that\n\
    \   uniquely defines the client so that subsequent instances of the same\n   client\
    \ bear the same co_ownerid with a different verifier.\n   There are several considerations\
    \ for how the client generates the\n   co_ownerid string:\n   *  The string should\
    \ be unique so that multiple clients do not\n      present the same string.  The\
    \ consequences of two clients\n      presenting the same string range from one\
    \ client getting an error\n      to one client having its leased state abruptly\
    \ and unexpectedly\n      cancelled.\n   *  The string should be selected so that\
    \ subsequent incarnations\n      (e.g., restarts) of the same client cause the\
    \ client to present\n      the same string.  The implementor is cautioned from\
    \ an approach\n      that requires the string to be recorded in a local file because\n\
    \      this precludes the use of the implementation in an environment\n      where\
    \ there is no local disk and all file access is from an\n      NFSv4.1 server.\n\
    \   *  The string should be the same for each server network address that\n  \
    \    the client accesses.  This way, if a server has multiple\n      interfaces,\
    \ the client can trunk traffic over multiple network\n      paths as described\
    \ in Section 2.10.5.  (Note: the precise opposite\n      was advised in the NFSv4.0\
    \ specification [37].)\n   *  The algorithm for generating the string should not\
    \ assume that the\n      client's network address will not change, unless the\
    \ client\n      implementation knows it is using statically assigned network\n\
    \      addresses.  This includes changes between client incarnations and\n   \
    \   even changes while the client is still running in its current\n      incarnation.\
    \  Thus, with dynamic address assignment, if the client\n      includes just the\
    \ client's network address in the co_ownerid\n      string, there is a real risk\
    \ that after the client gives up the\n      network address, another client, using\
    \ a similar algorithm for\n      generating the co_ownerid string, would generate\
    \ a conflicting\n      co_ownerid string.\n   Given the above considerations,\
    \ an example of a well-generated\n   co_ownerid string is one that includes:\n\
    \   *  If applicable, the client's statically assigned network address.\n   *\
    \  Additional information that tends to be unique, such as one or\n      more\
    \ of:\n      -  The client machine's serial number (for privacy reasons, it is\n\
    \         best to perform some one-way function on the serial number).\n     \
    \ -  A Media Access Control (MAC) address (again, a one-way function\n       \
    \  should be performed).\n      -  The timestamp of when the NFSv4.1 software\
    \ was first installed\n         on the client (though this is subject to the previously\n\
    \         mentioned caution about using information that is stored in a\n    \
    \     file, because the file might only be accessible over NFSv4.1).\n      -\
    \  A true random number.  However, since this number ought to be\n         the\
    \ same between client incarnations, this shares the same\n         problem as\
    \ that of using the timestamp of the software\n         installation.\n   *  For\
    \ a user-level NFSv4.1 client, it should contain additional\n      information\
    \ to distinguish the client from other user-level\n      clients running on the\
    \ same host, such as a process identifier or\n      other unique sequence.\n \
    \  The client ID is assigned by the server (the eir_clientid result from\n   EXCHANGE_ID)\
    \ and should be chosen so that it will not conflict with a\n   client ID previously\
    \ assigned by the server.  This applies across\n   server restarts.\n   In the\
    \ event of a server restart, a client may find out that its\n   current client\
    \ ID is no longer valid when it receives an\n   NFS4ERR_STALE_CLIENTID error.\
    \  The precise circumstances depend on\n   the characteristics of the sessions\
    \ involved, specifically whether\n   the session is persistent (see Section 2.10.6.5),\
    \ but in each case\n   the client will receive this error when it attempts to\
    \ establish a\n   new session with the existing client ID and receives the error\n\
    \   NFS4ERR_STALE_CLIENTID, indicating that a new client ID needs to be\n   obtained\
    \ via EXCHANGE_ID and the new session established with that\n   client ID.\n \
    \  When a session is not persistent, the client will find out that it\n   needs\
    \ to create a new session as a result of getting an\n   NFS4ERR_BADSESSION, since\
    \ the session in question was lost as part of\n   a server restart.  When the\
    \ existing client ID is presented to a\n   server as part of creating a session\
    \ and that client ID is not\n   recognized, as would happen after a server restart,\
    \ the server will\n   reject the request with the error NFS4ERR_STALE_CLIENTID.\n\
    \   In the case of the session being persistent, the client will re-\n   establish\
    \ communication using the existing session after the restart.\n   This session\
    \ will be associated with the existing client ID but may\n   only be used to retransmit\
    \ operations that the client previously\n   transmitted and did not see replies\
    \ to.  Replies to operations that\n   the server previously performed will come\
    \ from the reply cache;\n   otherwise, NFS4ERR_DEADSESSION will be returned. \
    \ Hence, such a\n   session is referred to as \"dead\".  In this situation, in\
    \ order to\n   perform new operations, the client needs to establish a new session.\n\
    \   If an attempt is made to establish this new session with the existing\n  \
    \ client ID, the server will reject the request with\n   NFS4ERR_STALE_CLIENTID.\n\
    \   When NFS4ERR_STALE_CLIENTID is received in either of these\n   situations,\
    \ the client needs to obtain a new client ID by use of the\n   EXCHANGE_ID operation,\
    \ then use that client ID as the basis of a new\n   session, and then proceed\
    \ to any other necessary recovery for the\n   server restart case (see Section\
    \ 8.4.2).\n   See the descriptions of EXCHANGE_ID (Section 18.35) and\n   CREATE_SESSION\
    \ (Section 18.36) for a complete specification of these\n   operations.\n"
- title: 2.4.1.  Upgrade from NFSv4.0 to NFSv4.1
  contents:
  - "2.4.1.  Upgrade from NFSv4.0 to NFSv4.1\n   To facilitate upgrade from NFSv4.0\
    \ to NFSv4.1, a server may compare a\n   value of data type client_owner4 in an\
    \ EXCHANGE_ID with a value of\n   data type nfs_client_id4 that was established\
    \ using the SETCLIENTID\n   operation of NFSv4.0.  A server that does so will\
    \ allow an upgraded\n   client to avoid waiting until the lease (i.e., the lease\
    \ established\n   by the NFSv4.0 instance client) expires.  This requires that\
    \ the\n   value of data type client_owner4 be constructed the same way as the\n\
    \   value of data type nfs_client_id4.  If the latter's contents included\n  \
    \ the server's network address (per the recommendations of the NFSv4.0\n   specification\
    \ [37]), and the NFSv4.1 client does not wish to use a\n   client ID that prevents\
    \ trunking, it should send two EXCHANGE_ID\n   operations.  The first EXCHANGE_ID\
    \ will have a client_owner4 equal to\n   the nfs_client_id4.  This will clear\
    \ the state created by the NFSv4.0\n   client.  The second EXCHANGE_ID will not\
    \ have the server's network\n   address.  The state created for the second EXCHANGE_ID\
    \ will not have\n   to wait for lease expiration, because there will be no state\
    \ to\n   expire.\n"
- title: 2.4.2.  Server Release of Client ID
  contents:
  - "2.4.2.  Server Release of Client ID\n   NFSv4.1 introduces a new operation called\
    \ DESTROY_CLIENTID\n   (Section 18.50), which the client SHOULD use to destroy\
    \ a client ID\n   it no longer needs.  This permits graceful, bilateral release\
    \ of a\n   client ID.  The operation cannot be used if there are sessions\n  \
    \ associated with the client ID, or state with an unexpired lease.\n   If the\
    \ server determines that the client holds no associated state\n   for its client\
    \ ID (associated state includes unrevoked sessions,\n   opens, locks, delegations,\
    \ layouts, and wants), the server MAY choose\n   to unilaterally release the client\
    \ ID in order to conserve resources.\n   If the client contacts the server after\
    \ this release, the server MUST\n   ensure that the client receives the appropriate\
    \ error so that it will\n   use the EXCHANGE_ID/CREATE_SESSION sequence to establish\
    \ a new client\n   ID.  The server ought to be very hesitant to release a client\
    \ ID\n   since the resulting work on the client to recover from such an event\n\
    \   will be the same burden as if the server had failed and restarted.\n   Typically,\
    \ a server would not release a client ID unless there had\n   been no activity\
    \ from that client for many minutes.  As long as there\n   are sessions, opens,\
    \ locks, delegations, layouts, or wants, the\n   server MUST NOT release the client\
    \ ID.  See Section 2.10.13.1.4 for\n   discussion on releasing inactive sessions.\n"
- title: 2.4.3.  Resolving Client Owner Conflicts
  contents:
  - "2.4.3.  Resolving Client Owner Conflicts\n   When the server gets an EXCHANGE_ID\
    \ for a client owner that currently\n   has no state, or that has state but the\
    \ lease has expired, the server\n   MUST allow the EXCHANGE_ID and confirm the\
    \ new client ID if followed\n   by the appropriate CREATE_SESSION.\n   When the\
    \ server gets an EXCHANGE_ID for a new incarnation of a client\n   owner that\
    \ currently has an old incarnation with state and an\n   unexpired lease, the\
    \ server is allowed to dispose of the state of the\n   previous incarnation of\
    \ the client owner if one of the following is\n   true:\n   *  The principal that\
    \ created the client ID for the client owner is\n      the same as the principal\
    \ that is sending the EXCHANGE_ID\n      operation.  Note that if the client ID\
    \ was created with\n      SP4_MACH_CRED state protection (Section 18.35), the\
    \ principal MUST\n      be based on RPCSEC_GSS authentication, the RPCSEC_GSS\
    \ service used\n      MUST be integrity or privacy, and the same GSS mechanism\
    \ and\n      principal MUST be used as that used when the client ID was\n    \
    \  created.\n   *  The client ID was established with SP4_SSV protection\n   \
    \   (Section 18.35, Section 2.10.8.3) and the client sends the\n      EXCHANGE_ID\
    \ with the security flavor set to RPCSEC_GSS using the\n      GSS SSV mechanism\
    \ (Section 2.10.9).\n   *  The client ID was established with SP4_SSV protection,\
    \ and under\n      the conditions described herein, the EXCHANGE_ID was sent with\n\
    \      SP4_MACH_CRED state protection.  Because the SSV might not persist\n  \
    \    across client and server restart, and because the first time a\n      client\
    \ sends EXCHANGE_ID to a server it does not have an SSV, the\n      client MAY\
    \ send the subsequent EXCHANGE_ID without an SSV\n      RPCSEC_GSS handle.  Instead,\
    \ as with SP4_MACH_CRED protection, the\n      principal MUST be based on RPCSEC_GSS\
    \ authentication, the\n      RPCSEC_GSS service used MUST be integrity or privacy,\
    \ and the same\n      GSS mechanism and principal MUST be used as that used when\
    \ the\n      client ID was created.\n   If none of the above situations apply,\
    \ the server MUST return\n   NFS4ERR_CLID_INUSE.\n   If the server accepts the\
    \ principal and co_ownerid as matching that\n   which created the client ID, and\
    \ the co_verifier in the EXCHANGE_ID\n   differs from the co_verifier used when\
    \ the client ID was created,\n   then after the server receives a CREATE_SESSION\
    \ that confirms the\n   client ID, the server deletes state.  If the co_verifier\
    \ values are\n   the same (e.g., the client either is updating properties of the\n\
    \   client ID (Section 18.35) or is attempting trunking (Section 2.10.5),\n  \
    \ the server MUST NOT delete state.\n"
- title: 2.5.  Server Owners
  contents:
  - "2.5.  Server Owners\n   The server owner is similar to a client owner (Section\
    \ 2.4), but\n   unlike the client owner, there is no shorthand server ID.  The\
    \ server\n   owner is defined in the following data type:\n   struct server_owner4\
    \ {\n    uint64_t       so_minor_id;\n    opaque         so_major_id<NFS4_OPAQUE_LIMIT>;\n\
    \   };\n   The server owner is returned from EXCHANGE_ID.  When the so_major_id\n\
    \   fields are the same in two EXCHANGE_ID results, the connections that\n   each\
    \ EXCHANGE_ID were sent over can be assumed to address the same\n   server (as\
    \ defined in Section 1.7).  If the so_minor_id fields are\n   also the same, then\
    \ not only do both connections connect to the same\n   server, but the session\
    \ can be shared across both connections.  The\n   reader is cautioned that multiple\
    \ servers may deliberately or\n   accidentally claim to have the same so_major_id\
    \ or so_major_id/\n   so_minor_id; the reader should examine Sections 2.10.5 and\
    \ 18.35 in\n   order to avoid acting on falsely matching server owner values.\n\
    \   The considerations for generating an so_major_id are similar to that\n   for\
    \ generating a co_ownerid string (see Section 2.4).  The\n   consequences of two\
    \ servers generating conflicting so_major_id values\n   are less dire than they\
    \ are for co_ownerid conflicts because the\n   client can use RPCSEC_GSS to compare\
    \ the authenticity of each server\n   (see Section 2.10.5).\n"
- title: 2.6.  Security Service Negotiation
  contents:
  - "2.6.  Security Service Negotiation\n   With the NFSv4.1 server potentially offering\
    \ multiple security\n   mechanisms, the client needs a method to determine or\
    \ negotiate which\n   mechanism is to be used for its communication with the server.\
    \  The\n   NFS server may have multiple points within its file system namespace\n\
    \   that are available for use by NFS clients.  These points can be\n   considered\
    \ security policy boundaries, and, in some NFS\n   implementations, are tied to\
    \ NFS export points.  In turn, the NFS\n   server may be configured such that\
    \ each of these security policy\n   boundaries may have different or multiple\
    \ security mechanisms in use.\n   The security negotiation between client and\
    \ server SHOULD be done\n   with a secure channel to eliminate the possibility\
    \ of a third party\n   intercepting the negotiation sequence and forcing the client\
    \ and\n   server to choose a lower level of security than required or desired.\n\
    \   See Section 21 for further discussion.\n"
- title: 2.6.1.  NFSv4.1 Security Tuples
  contents:
  - "2.6.1.  NFSv4.1 Security Tuples\n   An NFS server can assign one or more \"security\
    \ tuples\" to each\n   security policy boundary in its namespace.  Each security\
    \ tuple\n   consists of a security flavor (see Section 2.2.1.1) and, if the\n\
    \   flavor is RPCSEC_GSS, a GSS-API mechanism Object Identifier (OID), a\n   GSS-API\
    \ quality of protection, and an RPCSEC_GSS service.\n"
- title: 2.6.2.  SECINFO and SECINFO_NO_NAME
  contents:
  - "2.6.2.  SECINFO and SECINFO_NO_NAME\n   The SECINFO and SECINFO_NO_NAME operations\
    \ allow the client to\n   determine, on a per-filehandle basis, what security\
    \ tuple is to be\n   used for server access.  In general, the client will not\
    \ have to use\n   either operation except during initial communication with the\
    \ server\n   or when the client crosses security policy boundaries at the server.\n\
    \   However, the server's policies may also change at any time and force\n   the\
    \ client to negotiate a new security tuple.\n   Where the use of different security\
    \ tuples would affect the type of\n   access that would be allowed if a request\
    \ was sent over the same\n   connection used for the SECINFO or SECINFO_NO_NAME\
    \ operation (e.g.,\n   read-only vs. read-write) access, security tuples that\
    \ allow greater\n   access should be presented first.  Where the general level\
    \ of access\n   is the same and different security flavors limit the range of\n\
    \   principals whose privileges are recognized (e.g., allowing or\n   disallowing\
    \ root access), flavors supporting the greatest range of\n   principals should\
    \ be listed first.\n"
- title: 2.6.3.  Security Error
  contents:
  - "2.6.3.  Security Error\n   Based on the assumption that each NFSv4.1 client and\
    \ server MUST\n   support a minimum set of security (i.e., Kerberos V5 under\n\
    \   RPCSEC_GSS), the NFS client will initiate file access to the server\n   with\
    \ one of the minimal security tuples.  During communication with\n   the server,\
    \ the client may receive an NFS error of NFS4ERR_WRONGSEC.\n   This error allows\
    \ the server to notify the client that the security\n   tuple currently being\
    \ used contravenes the server's security policy.\n   The client is then responsible\
    \ for determining (see Section 2.6.3.1)\n   what security tuples are available\
    \ at the server and choosing one\n   that is appropriate for the client.\n"
- title: 2.6.3.1.  Using NFS4ERR_WRONGSEC, SECINFO, and SECINFO_NO_NAME
  contents:
  - "2.6.3.1.  Using NFS4ERR_WRONGSEC, SECINFO, and SECINFO_NO_NAME\n   This section\
    \ explains the mechanics of NFSv4.1 security negotiation.\n"
- title: 2.6.3.1.1.  Put Filehandle Operations
  contents:
  - "2.6.3.1.1.  Put Filehandle Operations\n   The term \"put filehandle operation\"\
    \ refers to PUTROOTFH, PUTPUBFH,\n   PUTFH, and RESTOREFH.  Each of the subsections\
    \ herein describes how\n   the server handles a subseries of operations that starts\
    \ with a put\n   filehandle operation.\n"
- title: 2.6.3.1.1.1.  Put Filehandle Operation + SAVEFH
  contents:
  - "2.6.3.1.1.1.  Put Filehandle Operation + SAVEFH\n   The client is saving a filehandle\
    \ for a future RESTOREFH, LINK, or\n   RENAME.  SAVEFH MUST NOT return NFS4ERR_WRONGSEC.\
    \  To determine\n   whether or not the put filehandle operation returns NFS4ERR_WRONGSEC,\n\
    \   the server implementation pretends SAVEFH is not in the series of\n   operations\
    \ and examines which of the situations described in the\n   other subsections\
    \ of Section 2.6.3.1.1 apply.\n"
- title: 2.6.3.1.1.2.  Two or More Put Filehandle Operations
  contents:
  - "2.6.3.1.1.2.  Two or More Put Filehandle Operations\n   For a series of N put\
    \ filehandle operations, the server MUST NOT\n   return NFS4ERR_WRONGSEC to the\
    \ first N-1 put filehandle operations.\n   The Nth put filehandle operation is\
    \ handled as if it is the first in\n   a subseries of operations.  For example,\
    \ if the server received a\n   COMPOUND request with this series of operations\
    \ -- PUTFH, PUTROOTFH,\n   LOOKUP -- then the PUTFH operation is ignored for NFS4ERR_WRONGSEC\n\
    \   purposes, and the PUTROOTFH, LOOKUP subseries is processed as\n   according\
    \ to Section 2.6.3.1.1.3.\n"
- title: 2.6.3.1.1.3.  Put Filehandle Operation + LOOKUP (or OPEN of an Existing
  contents:
  - "2.6.3.1.1.3.  Put Filehandle Operation + LOOKUP (or OPEN of an Existing\n   \
    \           Name)\n   This situation also applies to a put filehandle operation\
    \ followed by\n   a LOOKUP or an OPEN operation that specifies an existing component\n\
    \   name.\n   In this situation, the client is potentially crossing a security\n\
    \   policy boundary, and the set of security tuples the parent directory\n   supports\
    \ may differ from those of the child.  The server\n   implementation may decide\
    \ whether to impose any restrictions on\n   security policy administration.  There\
    \ are at least three approaches\n   (sec_policy_child is the tuple set of the\
    \ child export,\n   sec_policy_parent is that of the parent).\n   (a)  sec_policy_child\
    \ <= sec_policy_parent (<= for subset).  This\n        means that the set of security\
    \ tuples specified on the security\n        policy of a child directory is always\
    \ a subset of its parent\n        directory.\n   (b)  sec_policy_child ^ sec_policy_parent\
    \ != {} (^ for intersection,\n        {} for the empty set).  This means that\
    \ the set of security\n        tuples specified on the security policy of a child\
    \ directory\n        always has a non-empty intersection with that of the parent.\n\
    \   (c)  sec_policy_child ^ sec_policy_parent == {}.  This means that the\n  \
    \      set of security tuples specified on the security policy of a\n        child\
    \ directory may not intersect with that of the parent.  In\n        other words,\
    \ there are no restrictions on how the system\n        administrator may set up\
    \ these tuples.\n   In order for a server to support approaches (b) (for the case\
    \ when a\n   client chooses a flavor that is not a member of sec_policy_parent)\n\
    \   and (c), the put filehandle operation cannot return NFS4ERR_WRONGSEC\n   when\
    \ there is a security tuple mismatch.  Instead, it should be\n   returned from\
    \ the LOOKUP (or OPEN by existing component name) that\n   follows.\n   Since\
    \ the above guideline does not contradict approach (a), it should\n   be followed\
    \ in general.  Even if approach (a) is implemented, it is\n   possible for the\
    \ security tuple used to be acceptable for the target\n   of LOOKUP but not for\
    \ the filehandles used in the put filehandle\n   operation.  The put filehandle\
    \ operation could be a PUTROOTFH or\n   PUTPUBFH, where the client cannot know\
    \ the security tuples for the\n   root or public filehandle.  Or the security\
    \ policy for the filehandle\n   used by the put filehandle operation could have\
    \ changed since the\n   time the filehandle was obtained.\n   Therefore, an NFSv4.1\
    \ server MUST NOT return NFS4ERR_WRONGSEC in\n   response to the put filehandle\
    \ operation if the operation is\n   immediately followed by a LOOKUP or an OPEN\
    \ by component name.\n"
- title: 2.6.3.1.1.4.  Put Filehandle Operation + LOOKUPP
  contents:
  - "2.6.3.1.1.4.  Put Filehandle Operation + LOOKUPP\n   Since SECINFO only works\
    \ its way down, there is no way LOOKUPP can\n   return NFS4ERR_WRONGSEC without\
    \ SECINFO_NO_NAME.  SECINFO_NO_NAME\n   solves this issue via style SECINFO_STYLE4_PARENT,\
    \ which works in the\n   opposite direction as SECINFO.  As with Section 2.6.3.1.1.3,\
    \ a put\n   filehandle operation that is followed by a LOOKUPP MUST NOT return\n\
    \   NFS4ERR_WRONGSEC.  If the server does not support SECINFO_NO_NAME,\n   the\
    \ client's only recourse is to send the put filehandle operation,\n   LOOKUPP,\
    \ GETFH sequence of operations with every security tuple it\n   supports.\n  \
    \ Regardless of whether SECINFO_NO_NAME is supported, an NFSv4.1 server\n   MUST\
    \ NOT return NFS4ERR_WRONGSEC in response to a put filehandle\n   operation if\
    \ the operation is immediately followed by a LOOKUPP.\n"
- title: 2.6.3.1.1.5.  Put Filehandle Operation + SECINFO/SECINFO_NO_NAME
  contents:
  - "2.6.3.1.1.5.  Put Filehandle Operation + SECINFO/SECINFO_NO_NAME\n   A security-sensitive\
    \ client is allowed to choose a strong security\n   tuple when querying a server\
    \ to determine a file object's permitted\n   security tuples.  The security tuple\
    \ chosen by the client does not\n   have to be included in the tuple list of the\
    \ security policy of\n   either the parent directory indicated in the put filehandle\
    \ operation\n   or the child file object indicated in SECINFO (or any parent\n\
    \   directory indicated in SECINFO_NO_NAME).  Of course, the server has\n   to\
    \ be configured for whatever security tuple the client selects;\n   otherwise,\
    \ the request will fail at the RPC layer with an appropriate\n   authentication\
    \ error.\n   In theory, there is no connection between the security flavor used\
    \ by\n   SECINFO or SECINFO_NO_NAME and those supported by the security\n   policy.\
    \  But in practice, the client may start looking for strong\n   flavors from those\
    \ supported by the security policy, followed by\n   those in the REQUIRED set.\n\
    \   The NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC to a put\n   filehandle\
    \ operation that is immediately followed by SECINFO or\n   SECINFO_NO_NAME.  The\
    \ NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC\n   from SECINFO or SECINFO_NO_NAME.\n"
- title: 2.6.3.1.1.6.  Put Filehandle Operation + Nothing
  contents:
  - "2.6.3.1.1.6.  Put Filehandle Operation + Nothing\n   The NFSv4.1 server MUST\
    \ NOT return NFS4ERR_WRONGSEC.\n"
- title: 2.6.3.1.1.7.  Put Filehandle Operation + Anything Else
  contents:
  - "2.6.3.1.1.7.  Put Filehandle Operation + Anything Else\n   \"Anything Else\"\
    \ includes OPEN by filehandle.\n   The security policy enforcement applies to\
    \ the filehandle specified\n   in the put filehandle operation.  Therefore, the\
    \ put filehandle\n   operation MUST return NFS4ERR_WRONGSEC when there is a security\
    \ tuple\n   mismatch.  This avoids the complexity of adding NFS4ERR_WRONGSEC as\n\
    \   an allowable error to every other operation.\n   A COMPOUND containing the\
    \ series put filehandle operation +\n   SECINFO_NO_NAME (style SECINFO_STYLE4_CURRENT_FH)\
    \ is an efficient way\n   for the client to recover from NFS4ERR_WRONGSEC.\n \
    \  The NFSv4.1 server MUST NOT return NFS4ERR_WRONGSEC to any operation\n   other\
    \ than a put filehandle operation, LOOKUP, LOOKUPP, and OPEN (by\n   component\
    \ name).\n"
- title: 2.6.3.1.1.8.  Operations after SECINFO and SECINFO_NO_NAME
  contents:
  - "2.6.3.1.1.8.  Operations after SECINFO and SECINFO_NO_NAME\n   Suppose a client\
    \ sends a COMPOUND procedure containing the series\n   SEQUENCE, PUTFH, SECINFO_NONAME,\
    \ READ, and suppose the security tuple\n   used does not match that required for\
    \ the target file.  By rule (see\n   Section 2.6.3.1.1.5), neither PUTFH nor SECINFO_NO_NAME\
    \ can return\n   NFS4ERR_WRONGSEC.  By rule (see Section 2.6.3.1.1.7), READ cannot\n\
    \   return NFS4ERR_WRONGSEC.  The issue is resolved by the fact that\n   SECINFO\
    \ and SECINFO_NO_NAME consume the current filehandle (note that\n   this is a\
    \ change from NFSv4.0).  This leaves no current filehandle\n   for READ to use,\
    \ and READ returns NFS4ERR_NOFILEHANDLE.\n"
- title: 2.6.3.1.2.  LINK and RENAME
  contents:
  - "2.6.3.1.2.  LINK and RENAME\n   The LINK and RENAME operations use both the current\
    \ and saved\n   filehandles.  Technically, the server MAY return NFS4ERR_WRONGSEC\n\
    \   from LINK or RENAME if the security policy of the saved filehandle\n   rejects\
    \ the security flavor used in the COMPOUND request's\n   credentials.  If the\
    \ server does so, then if there is no intersection\n   between the security policies\
    \ of saved and current filehandles, this\n   means that it will be impossible\
    \ for the client to perform the\n   intended LINK or RENAME operation.\n   For\
    \ example, suppose the client sends this COMPOUND request:\n   SEQUENCE, PUTFH\
    \ bFH, SAVEFH, PUTFH aFH, RENAME \"c\" \"d\", where\n   filehandles bFH and aFH\
    \ refer to different directories.  Suppose no\n   common security tuple exists\
    \ between the security policies of aFH and\n   bFH.  If the client sends the request\
    \ using credentials acceptable to\n   bFH's security policy but not aFH's policy,\
    \ then the PUTFH aFH\n   operation will fail with NFS4ERR_WRONGSEC.  After a SECINFO_NO_NAME\n\
    \   request, the client sends SEQUENCE, PUTFH bFH, SAVEFH, PUTFH aFH,\n   RENAME\
    \ \"c\" \"d\", using credentials acceptable to aFH's security policy\n   but not\
    \ bFH's policy.  The server returns NFS4ERR_WRONGSEC on the\n   RENAME operation.\n\
    \   To prevent a client from an endless sequence of a request containing\n   LINK\
    \ or RENAME, followed by a request containing SECINFO_NO_NAME or\n   SECINFO,\
    \ the server MUST detect when the security policies of the\n   current and saved\
    \ filehandles have no mutually acceptable security\n   tuple, and MUST NOT return\
    \ NFS4ERR_WRONGSEC from LINK or RENAME in\n   that situation.  Instead the server\
    \ MUST do one of two things:\n   *  The server can return NFS4ERR_XDEV.\n   *\
    \  The server can allow the security policy of the current filehandle\n      to\
    \ override that of the saved filehandle, and so return NFS4_OK.\n"
- title: 2.7.  Minor Versioning
  contents:
  - "2.7.  Minor Versioning\n   To address the requirement of an NFS protocol that\
    \ can evolve as the\n   need arises, the NFSv4.1 protocol contains the rules and\
    \ framework to\n   allow for future minor changes or versioning.\n   The base\
    \ assumption with respect to minor versioning is that any\n   future accepted\
    \ minor version will be documented in one or more\n   Standards Track RFCs.  Minor\
    \ version 0 of the NFSv4 protocol is\n   represented by [37], and minor version\
    \ 1 is represented by this RFC.\n   The COMPOUND and CB_COMPOUND procedures support\
    \ the encoding of the\n   minor version being requested by the client.\n   The\
    \ following items represent the basic rules for the development of\n   minor versions.\
    \  Note that a future minor version may modify or add\n   to the following rules\
    \ as part of the minor version definition.\n   1.   Procedures are not added or\
    \ deleted.\n        To maintain the general RPC model, NFSv4 minor versions will\
    \ not\n        add to or delete procedures from the NFS program.\n   2.   Minor\
    \ versions may add operations to the COMPOUND and\n        CB_COMPOUND procedures.\n\
    \        The addition of operations to the COMPOUND and CB_COMPOUND\n        procedures\
    \ does not affect the RPC model.\n        *  Minor versions may append attributes\
    \ to the bitmap4 that\n           represents sets of attributes and to the fattr4\
    \ that\n           represents sets of attribute values.\n           This allows\
    \ for the expansion of the attribute model to allow\n           for future growth\
    \ or adaptation.\n        *  Minor version X must append any new attributes after\
    \ the last\n           documented attribute.\n           Since attribute results\
    \ are specified as an opaque array of\n           per-attribute, XDR-encoded results,\
    \ the complexity of adding\n           new attributes in the midst of the current\
    \ definitions would\n           be too burdensome.\n   3.   Minor versions must\
    \ not modify the structure of an existing\n        operation's arguments or results.\n\
    \        Again, the complexity of handling multiple structure definitions\n  \
    \      for a single operation is too burdensome.  New operations should\n    \
    \    be added instead of modifying existing structures for a minor\n        version.\n\
    \        This rule does not preclude the following adaptations in a minor\n  \
    \      version:\n        *  adding bits to flag fields, such as new attributes\
    \ to\n           GETATTR's bitmap4 data type, and providing corresponding\n  \
    \         variants of opaque arrays, such as a notify4 used together\n       \
    \    with such bitmaps\n        *  adding bits to existing attributes like ACLs\
    \ that have flag\n           words\n        *  extending enumerated types (including\
    \ NFS4ERR_*) with new\n           values\n        *  adding cases to a switched\
    \ union\n   4.   Minor versions must not modify the structure of existing\n  \
    \      attributes.\n   5.   Minor versions must not delete operations.\n     \
    \   This prevents the potential reuse of a particular operation\n        \"slot\"\
    \ in a future minor version.\n   6.   Minor versions must not delete attributes.\n\
    \   7.   Minor versions must not delete flag bits or enumeration values.\n   8.\
    \   Minor versions may declare an operation MUST NOT be implemented.\n       \
    \ Specifying that an operation MUST NOT be implemented is\n        equivalent\
    \ to obsoleting an operation.  For the client, it means\n        that the operation\
    \ MUST NOT be sent to the server.  For the\n        server, an NFS error can be\
    \ returned as opposed to \"dropping\"\n        the request as an XDR decode error.\
    \  This approach allows for\n        the obsolescence of an operation while maintaining\
    \ its structure\n        so that a future minor version can reintroduce the operation.\n\
    \        1.  Minor versions may declare that an attribute MUST NOT be\n      \
    \      implemented.\n        2.  Minor versions may declare that a flag bit or\
    \ enumeration\n            value MUST NOT be implemented.\n   9.   Minor versions\
    \ may downgrade features from REQUIRED to\n        RECOMMENDED, or RECOMMENDED\
    \ to OPTIONAL.\n   10.  Minor versions may upgrade features from OPTIONAL to\n\
    \        RECOMMENDED, or RECOMMENDED to REQUIRED.\n   11.  A client and server\
    \ that support minor version X SHOULD support\n        minor versions zero through\
    \ X-1 as well.\n   12.  Except for infrastructural changes, a minor version must\
    \ not\n        introduce REQUIRED new features.\n        This rule allows for\
    \ the introduction of new functionality and\n        forces the use of implementation\
    \ experience before designating a\n        feature as REQUIRED.  On the other\
    \ hand, some classes of\n        features are infrastructural and have broad effects.\
    \  Allowing\n        infrastructural features to be RECOMMENDED or OPTIONAL\n\
    \        complicates implementation of the minor version.\n   13.  A client MUST\
    \ NOT attempt to use a stateid, filehandle, or\n        similar returned object\
    \ from the COMPOUND procedure with minor\n        version X for another COMPOUND\
    \ procedure with minor version Y,\n        where X != Y.\n"
- title: 2.8.  Non-RPC-Based Security Services
  contents:
  - "2.8.  Non-RPC-Based Security Services\n   As described in Section 2.2.1.1.1.1,\
    \ NFSv4.1 relies on RPC for\n   identification, authentication, integrity, and\
    \ privacy.  NFSv4.1\n   itself provides or enables additional security services\
    \ as described\n   in the next several subsections.\n"
- title: 2.8.1.  Authorization
  contents:
  - "2.8.1.  Authorization\n   Authorization to access a file object via an NFSv4.1\
    \ operation is\n   ultimately determined by the NFSv4.1 server.  A client can\n\
    \   predetermine its access to a file object via the OPEN (Section 18.16)\n  \
    \ and the ACCESS (Section 18.1) operations.\n   Principals with appropriate access\
    \ rights can modify the\n   authorization on a file object via the SETATTR (Section\
    \ 18.30)\n   operation.  Attributes that affect access rights include mode, owner,\n\
    \   owner_group, acl, dacl, and sacl.  See Section 5.\n"
- title: 2.8.2.  Auditing
  contents:
  - "2.8.2.  Auditing\n   NFSv4.1 provides auditing on a per-file object basis, via\
    \ the acl and\n   sacl attributes as described in Section 6.  It is outside the\
    \ scope\n   of this specification to specify audit log formats or management\n\
    \   policies.\n"
- title: 2.8.3.  Intrusion Detection
  contents:
  - "2.8.3.  Intrusion Detection\n   NFSv4.1 provides alarm control on a per-file\
    \ object basis, via the\n   acl and sacl attributes as described in Section 6.\
    \  Alarms may serve\n   as the basis for intrusion detection.  It is outside the\
    \ scope of\n   this specification to specify heuristics for detecting intrusion\
    \ via\n   alarms.\n"
- title: 2.9.  Transport Layers
  contents:
  - '2.9.  Transport Layers

    '
- title: 2.9.1.  REQUIRED and RECOMMENDED Properties of Transports
  contents:
  - "2.9.1.  REQUIRED and RECOMMENDED Properties of Transports\n   NFSv4.1 works over\
    \ Remote Direct Memory Access (RDMA) and non-RDMA-\n   based transports with the\
    \ following attributes:\n   *  The transport supports reliable delivery of data,\
    \ which NFSv4.1\n      requires but neither NFSv4.1 nor RPC has facilities for\
    \ ensuring\n      [41].\n   *  The transport delivers data in the order it was\
    \ sent.  Ordered\n      delivery simplifies detection of transmit errors, and\
    \ simplifies\n      the sending of arbitrary sized requests and responses via\
    \ the\n      record marking protocol [3].\n   Where an NFSv4.1 implementation\
    \ supports operation over the IP\n   network protocol, any transport used between\
    \ NFS and IP MUST be among\n   the IETF-approved congestion control transport\
    \ protocols.  At the\n   time this document was written, the only two transports\
    \ that had the\n   above attributes were TCP and the Stream Control Transmission\n\
    \   Protocol (SCTP).  To enhance the possibilities for interoperability,\n   an\
    \ NFSv4.1 implementation MUST support operation over the TCP\n   transport protocol.\n\
    \   Even if NFSv4.1 is used over a non-IP network protocol, it is\n   RECOMMENDED\
    \ that the transport support congestion control.\n   It is permissible for a connectionless\
    \ transport to be used under\n   NFSv4.1; however, reliable and in-order delivery\
    \ of data combined\n   with congestion control by the connectionless transport\
    \ is REQUIRED.\n   As a consequence, UDP by itself MUST NOT be used as an NFSv4.1\n\
    \   transport.  NFSv4.1 assumes that a client transport address and\n   server\
    \ transport address used to send data over a transport together\n   constitute\
    \ a connection, even if the underlying transport eschews the\n   concept of a\
    \ connection.\n"
- title: 2.9.2.  Client and Server Transport Behavior
  contents:
  - "2.9.2.  Client and Server Transport Behavior\n   If a connection-oriented transport\
    \ (e.g., TCP) is used, the client\n   and server SHOULD use long-lived connections\
    \ for at least three\n   reasons:\n   1.  This will prevent the weakening of the\
    \ transport's congestion\n       control mechanisms via short-lived connections.\n\
    \   2.  This will improve performance for the WAN environment by\n       eliminating\
    \ the need for connection setup handshakes.\n   3.  The NFSv4.1 callback model\
    \ differs from NFSv4.0, and requires the\n       client and server to maintain\
    \ a client-created backchannel (see\n       Section 2.10.3.1) for the server to\
    \ use.\n   In order to reduce congestion, if a connection-oriented transport is\n\
    \   used, and the request is not the NULL procedure:\n   *  A requester MUST NOT\
    \ retry a request unless the connection the\n      request was sent over was lost\
    \ before the reply was received.\n   *  A replier MUST NOT silently drop a request,\
    \ even if the request is\n      a retry.  (The silent drop behavior of RPCSEC_GSS\
    \ [4] does not\n      apply because this behavior happens at the RPCSEC_GSS layer,\
    \ a\n      lower layer in the request processing.)  Instead, the replier\n   \
    \   SHOULD return an appropriate error (see Section 2.10.6.1), or it\n      MAY\
    \ disconnect the connection.\n   When sending a reply, the replier MUST send the\
    \ reply to the same\n   full network address (e.g., if using an IP-based transport,\
    \ the\n   source port of the requester is part of the full network address)\n\
    \   from which the requester sent the request.  If using a connection-\n   oriented\
    \ transport, replies MUST be sent on the same connection from\n   which the request\
    \ was received.\n   If a connection is dropped after the replier receives the\
    \ request but\n   before the replier sends the reply, the replier might have a\
    \ pending\n   reply.  If a connection is established with the same source and\n\
    \   destination full network address as the dropped connection, then the\n   replier\
    \ MUST NOT send the reply until the requester retries the\n   request.  The reason\
    \ for this prohibition is that the requester MAY\n   retry a request over a different\
    \ connection (provided that connection\n   is associated with the original request's\
    \ session).\n   When using RDMA transports, there are other reasons for not\n\
    \   tolerating retries over the same connection:\n   *  RDMA transports use \"\
    credits\" to enforce flow control, where a\n      credit is a right to a peer\
    \ to transmit a message.  If one peer\n      were to retransmit a request (or\
    \ reply), it would consume an\n      additional credit.  If the replier retransmitted\
    \ a reply, it would\n      certainly result in an RDMA connection loss, since\
    \ the requester\n      would typically only post a single receive buffer for each\n\
    \      request.  If the requester retransmitted a request, the additional\n  \
    \    credit consumed on the server might lead to RDMA connection\n      failure\
    \ unless the client accounted for it and decreased its\n      available credit,\
    \ leading to wasted resources.\n   *  RDMA credits present a new issue to the\
    \ reply cache in NFSv4.1.\n      The reply cache may be used when a connection\
    \ within a session is\n      lost, such as after the client reconnects.  Credit\
    \ information is\n      a dynamic property of the RDMA connection, and stale values\
    \ must\n      not be replayed from the cache.  This implies that the reply cache\n\
    \      contents must not be blindly used when replies are sent from it,\n    \
    \  and credit information appropriate to the channel must be\n      refreshed\
    \ by the RPC layer.\n   In addition, as described in Section 2.10.6.2, while a\
    \ session is\n   active, the NFSv4.1 requester MUST NOT stop waiting for a reply.\n"
- title: 2.9.3.  Ports
  contents:
  - "2.9.3.  Ports\n   Historically, NFSv3 servers have listened over TCP port 2049.\
    \  The\n   registered port 2049 [42] for the NFS protocol should be the default\n\
    \   configuration.  NFSv4.1 clients SHOULD NOT use the RPC binding\n   protocols\
    \ as described in [43].\n"
- title: 2.10.  Session
  contents:
  - "2.10.  Session\n   NFSv4.1 clients and servers MUST support and MUST use the\
    \ session\n   feature as described in this section.\n"
- title: 2.10.1.  Motivation and Overview
  contents:
  - "2.10.1.  Motivation and Overview\n   Previous versions and minor versions of\
    \ NFS have suffered from the\n   following:\n   *  Lack of support for Exactly\
    \ Once Semantics (EOS).  This includes\n      lack of support for EOS through\
    \ server failure and recovery.\n   *  Limited callback support, including no support\
    \ for sending\n      callbacks through firewalls, and races between replies to\
    \ normal\n      requests and callbacks.\n   *  Limited trunking over multiple\
    \ network paths.\n   *  Requiring machine credentials for fully secure operation.\n\
    \   Through the introduction of a session, NFSv4.1 addresses the above\n   shortfalls\
    \ with practical solutions:\n   *  EOS is enabled by a reply cache with a bounded\
    \ size, making it\n      feasible to keep the cache in persistent storage and\
    \ enable EOS\n      through server failure and recovery.  One reason that previous\n\
    \      revisions of NFS did not support EOS was because some EOS\n      approaches\
    \ often limited parallelism.  As will be explained in\n      Section 2.10.6, NFSv4.1\
    \ supports both EOS and unlimited\n      parallelism.\n   *  The NFSv4.1 client\
    \ (defined in Section 1.7) creates transport\n      connections and provides them\
    \ to the server to use for sending\n      callback requests, thus solving the\
    \ firewall issue\n      (Section 18.34).  Races between responses from client\
    \ requests and\n      callbacks caused by the requests are detected via the session's\n\
    \      sequencing properties that are a consequence of EOS\n      (Section 2.10.6.3).\n\
    \   *  The NFSv4.1 client can associate an arbitrary number of\n      connections\
    \ with the session, and thus provide trunking\n      (Section 2.10.5).\n   * \
    \ The NFSv4.1 client and server produce a session key independent of\n      client\
    \ and server machine credentials which can be used to compute\n      a digest\
    \ for protecting critical session management operations\n      (Section 2.10.8.3).\n\
    \   *  The NFSv4.1 client can also create secure RPCSEC_GSS contexts for\n   \
    \   use by the session's backchannel that do not require the server to\n     \
    \ authenticate to a client machine principal (Section 2.10.8.2).\n   A session\
    \ is a dynamically created, long-lived server object created\n   by a client and\
    \ used over time from one or more transport\n   connections.  Its function is\
    \ to maintain the server's state relative\n   to the connection(s) belonging to\
    \ a client instance.  This state is\n   entirely independent of the connection\
    \ itself, and indeed the state\n   exists whether or not the connection exists.\
    \  A client may have one\n   or more sessions associated with it so that client-associated\
    \ state\n   may be accessed using any of the sessions associated with that\n \
    \  client's client ID, when connections are associated with those\n   sessions.\
    \  When no connections are associated with any of a client\n   ID's sessions for\
    \ an extended time, such objects as locks, opens,\n   delegations, layouts, etc.\
    \ are subject to expiration.  The session\n   serves as an object representing\
    \ a means of access by a client to the\n   associated client state on the server,\
    \ independent of the physical\n   means of access to that state.\n   A single\
    \ client may create multiple sessions.  A single session MUST\n   NOT serve multiple\
    \ clients.\n"
- title: 2.10.2.  NFSv4 Integration
  contents:
  - "2.10.2.  NFSv4 Integration\n   Sessions are part of NFSv4.1 and not NFSv4.0.\
    \  Normally, a major\n   infrastructure change such as sessions would require\
    \ a new major\n   version number to an Open Network Computing (ONC) RPC program\
    \ like\n   NFS.  However, because NFSv4 encapsulates its functionality in a\n\
    \   single procedure, COMPOUND, and because COMPOUND can support an\n   arbitrary\
    \ number of operations, sessions have been added to NFSv4.1\n   with little difficulty.\
    \  COMPOUND includes a minor version number\n   field, and for NFSv4.1 this minor\
    \ version is set to 1.  When the\n   NFSv4 server processes a COMPOUND with the\
    \ minor version set to 1, it\n   expects a different set of operations than it\
    \ does for NFSv4.0.\n   NFSv4.1 defines the SEQUENCE operation, which is required\
    \ for every\n   COMPOUND that operates over an established session, with the\n\
    \   exception of some session administration operations, such as\n   DESTROY_SESSION\
    \ (Section 18.37).\n"
- title: 2.10.2.1.  SEQUENCE and CB_SEQUENCE
  contents:
  - "2.10.2.1.  SEQUENCE and CB_SEQUENCE\n   In NFSv4.1, when the SEQUENCE operation\
    \ is present, it MUST be the\n   first operation in the COMPOUND procedure.  The\
    \ primary purpose of\n   SEQUENCE is to carry the session identifier.  The session\
    \ identifier\n   associates all other operations in the COMPOUND procedure with\
    \ a\n   particular session.  SEQUENCE also contains required information for\n\
    \   maintaining EOS (see Section 2.10.6).  Session-enabled NFSv4.1\n   COMPOUND\
    \ requests thus have the form:\n       | tag | minorversion | numops    |SEQUENCE\
    \ op | op + args | ...\n       |     |   (== 1)     | (limited) |  + args    |\
    \           |\n   and the replies have the form:\n       |last status | tag |\
    \ numres |status + SEQUENCE op + results |  //\n               // status + op\
    \ + results | ...\n   A CB_COMPOUND procedure request and reply has a similar\
    \ form to\n   COMPOUND, but instead of a SEQUENCE operation, there is a CB_SEQUENCE\n\
    \   operation.  CB_COMPOUND also has an additional field called\n   \"callback_ident\"\
    , which is superfluous in NFSv4.1 and MUST be ignored\n   by the client.  CB_SEQUENCE\
    \ has the same information as SEQUENCE, and\n   also includes other information\
    \ needed to resolve callback races\n   (Section 2.10.6.3).\n"
- title: 2.10.2.2.  Client ID and Session Association
  contents:
  - "2.10.2.2.  Client ID and Session Association\n   Each client ID (Section 2.4)\
    \ can have zero or more active sessions.\n   A client ID and associated session\
    \ are required to perform file\n   access in NFSv4.1.  Each time a session is\
    \ used (whether by a client\n   sending a request to the server or the client\
    \ replying to a callback\n   request from the server), the state leased to its\
    \ associated client\n   ID is automatically renewed.\n   State (which can consist\
    \ of share reservations, locks, delegations,\n   and layouts (Section 1.8.4))\
    \ is tied to the client ID.  Client state\n   is not tied to any individual session.\
    \  Successive state changing\n   operations from a given state owner MAY go over\
    \ different sessions,\n   provided the session is associated with the same client\
    \ ID.  A\n   callback MAY arrive over a different session than that of the request\n\
    \   that originally acquired the state pertaining to the callback.  For\n   example,\
    \ if session A is used to acquire a delegation, a request to\n   recall the delegation\
    \ MAY arrive over session B if both sessions are\n   associated with the same\
    \ client ID.  Sections 2.10.8.1 and 2.10.8.2\n   discuss the security considerations\
    \ around callbacks.\n"
- title: 2.10.3.  Channels
  contents:
  - "2.10.3.  Channels\n   A channel is not a connection.  A channel represents the\
    \ direction\n   ONC RPC requests are sent.\n   Each session has one or two channels:\
    \ the fore channel and the\n   backchannel.  Because there are at most two channels\
    \ per session, and\n   because each channel has a distinct purpose, channels are\
    \ not\n   assigned identifiers.\n   The fore channel is used for ordinary requests\
    \ from the client to the\n   server, and carries COMPOUND requests and responses.\
    \  A session\n   always has a fore channel.\n   The backchannel is used for callback\
    \ requests from server to client,\n   and carries CB_COMPOUND requests and responses.\
    \  Whether or not there\n   is a backchannel is decided by the client; however,\
    \ many features of\n   NFSv4.1 require a backchannel.  NFSv4.1 servers MUST support\n\
    \   backchannels.\n   Each session has resources for each channel, including separate\
    \ reply\n   caches (see Section 2.10.6.1).  Note that even the backchannel\n \
    \  requires a reply cache (or, at least, a slot table in order to detect\n   retries)\
    \ because some callback operations are non-idempotent.\n"
- title: 2.10.3.1.  Association of Connections, Channels, and Sessions
  contents:
  - "2.10.3.1.  Association of Connections, Channels, and Sessions\n   Each channel\
    \ is associated with zero or more transport connections\n   (whether of the same\
    \ transport protocol or different transport\n   protocols).  A connection can\
    \ be associated with one channel or both\n   channels of a session; the client\
    \ and server negotiate whether a\n   connection will carry traffic for one channel\
    \ or both channels via\n   the CREATE_SESSION (Section 18.36) and the BIND_CONN_TO_SESSION\n\
    \   (Section 18.34) operations.  When a session is created via\n   CREATE_SESSION,\
    \ the connection that transported the CREATE_SESSION\n   request is automatically\
    \ associated with the fore channel, and\n   optionally the backchannel.  If the\
    \ client specifies no state\n   protection (Section 18.35) when the session is\
    \ created, then when\n   SEQUENCE is transmitted on a different connection, the\
    \ connection is\n   automatically associated with the fore channel of the session\n\
    \   specified in the SEQUENCE operation.\n   A connection's association with a\
    \ session is not exclusive.  A\n   connection associated with the channel(s) of\
    \ one session may be\n   simultaneously associated with the channel(s) of other\
    \ sessions\n   including sessions associated with other client IDs.\n   It is\
    \ permissible for connections of multiple transport types to be\n   associated\
    \ with the same channel.  For example, both TCP and RDMA\n   connections can be\
    \ associated with the fore channel.  In the event an\n   RDMA and non-RDMA connection\
    \ are associated with the same channel,\n   the maximum number of slots SHOULD\
    \ be at least one more than the\n   total number of RDMA credits (Section 2.10.6.1).\
    \  This way, if all\n   RDMA credits are used, the non-RDMA connection can have\
    \ at least one\n   outstanding request.  If a server supports multiple transport\
    \ types,\n   it MUST allow a client to associate connections from each transport\n\
    \   to a channel.\n   It is permissible for a connection of one type of transport\
    \ to be\n   associated with the fore channel, and a connection of a different\n\
    \   type to be associated with the backchannel.\n"
- title: 2.10.4.  Server Scope
  contents:
  - "2.10.4.  Server Scope\n   Servers each specify a server scope value in the form\
    \ of an opaque\n   string eir_server_scope returned as part of the results of\
    \ an\n   EXCHANGE_ID operation.  The purpose of the server scope is to allow a\n\
    \   group of servers to indicate to clients that a set of servers sharing\n  \
    \ the same server scope value has arranged to use distinct values of\n   opaque\
    \ identifiers so that the two servers never assign the same\n   value to two distinct\
    \ objects.  Thus, the identifiers generated by\n   two servers within that set\
    \ can be assumed compatible so that, in\n   certain important cases, identifiers\
    \ generated by one server in that\n   set may be presented to another server of\
    \ the same scope.\n   The use of such compatible values does not imply that a\
    \ value\n   generated by one server will always be accepted by another.  In most\n\
    \   cases, it will not.  However, a server will not inadvertently accept\n   a\
    \ value generated by another server.  When it does accept it, it will\n   be because\
    \ it is recognized as valid and carrying the same meaning as\n   on another server\
    \ of the same scope.\n   When servers are of the same server scope, this compatibility\
    \ of\n   values applies to the following identifiers:\n   *  Filehandle values.\
    \  A filehandle value accepted by two servers of\n      the same server scope\
    \ denotes the same object.  A WRITE operation\n      sent to one server is reflected\
    \ immediately in a READ sent to the\n      other.\n   *  Server owner values.\
    \  When the server scope values are the same,\n      server owner value may be\
    \ validly compared.  In cases where the\n      server scope values are different,\
    \ server owner values are treated\n      as different even if they contain identical\
    \ strings of bytes.\n   The coordination among servers required to provide such\
    \ compatibility\n   can be quite minimal, and limited to a simple partition of\
    \ the ID\n   space.  The recognition of common values requires additional\n  \
    \ implementation, but this can be tailored to the specific situations\n   in which\
    \ that recognition is desired.\n   Clients will have occasion to compare the server\
    \ scope values of\n   multiple servers under a number of circumstances, each of\
    \ which will\n   be discussed under the appropriate functional section:\n   *\
    \  When server owner values received in response to EXCHANGE_ID\n      operations\
    \ sent to multiple network addresses are compared for the\n      purpose of determining\
    \ the validity of various forms of trunking,\n      as described in Section 11.5.2.\n\
    \   *  When network or server reconfiguration causes the same network\n      address\
    \ to possibly be directed to different servers, with the\n      necessity for\
    \ the client to determine when lock reclaim should be\n      attempted, as described\
    \ in Section 8.4.2.1.\n   When two replies from EXCHANGE_ID, each from two different\
    \ server\n   network addresses, have the same server scope, there are a number\
    \ of\n   ways a client can validate that the common server scope is due to two\n\
    \   servers cooperating in a group.\n   *  If both EXCHANGE_ID requests were sent\
    \ with RPCSEC_GSS ([4], [9],\n      [27]) authentication and the server principal\
    \ is the same for both\n      targets, the equality of server scope is validated.\
    \  It is\n      RECOMMENDED that two servers intending to share the same server\n\
    \      scope and server_owner major_id also share the same principal\n      name.\
    \  In some cases, this simplifies the client's task of\n      validating server\
    \ scope.\n   *  The client may accept the appearance of the second server in the\n\
    \      fs_locations or fs_locations_info attribute for a relevant file\n     \
    \ system.  For example, if there is a migration event for a\n      particular\
    \ file system or there are locks to be reclaimed on a\n      particular file system,\
    \ the attributes for that particular file\n      system may be used.  The client\
    \ sends the GETATTR request to the\n      first server for the fs_locations or\
    \ fs_locations_info attribute\n      with RPCSEC_GSS authentication.  It may need\
    \ to do this in advance\n      of the need to verify the common server scope.\
    \  If the client\n      successfully authenticates the reply to GETATTR, and the\
    \ GETATTR\n      request and reply containing the fs_locations or fs_locations_info\n\
    \      attribute refers to the second server, then the equality of server\n  \
    \    scope is supported.  A client may choose to limit the use of this\n     \
    \ form of support to information relevant to the specific file\n      system involved\
    \ (e.g. a file system being migrated).\n"
- title: 2.10.5.  Trunking
  contents:
  - "2.10.5.  Trunking\n   Trunking is the use of multiple connections between a client\
    \ and\n   server in order to increase the speed of data transfer.  NFSv4.1\n \
    \  supports two types of trunking: session trunking and client ID\n   trunking.\n\
    \   In the context of a single server network address, it can be assumed\n   that\
    \ all connections are accessing the same server, and NFSv4.1\n   servers MUST\
    \ support both forms of trunking.  When multiple\n   connections use a set of\
    \ network addresses to access the same server,\n   the server MUST support both\
    \ forms of trunking.  NFSv4.1 servers in a\n   clustered configuration MAY allow\
    \ network addresses for different\n   servers to use client ID trunking.\n   Clients\
    \ may use either form of trunking as long as they do not, when\n   trunking between\
    \ different server network addresses, violate the\n   servers' mandates as to\
    \ the kinds of trunking to be allowed (see\n   below).  With regard to callback\
    \ channels, the client MUST allow the\n   server to choose among all callback\
    \ channels valid for a given client\n   ID and MUST support trunking when the\
    \ connections supporting the\n   backchannel allow session or client ID trunking\
    \ to be used for\n   callbacks.\n   Session trunking is essentially the association\
    \ of multiple\n   connections, each with potentially different target and/or source\n\
    \   network addresses, to the same session.  When the target network\n   addresses\
    \ (server addresses) of the two connections are the same, the\n   server MUST\
    \ support such session trunking.  When the target network\n   addresses are different,\
    \ the server MAY indicate such support using\n   the data returned by the EXCHANGE_ID\
    \ operation (see below).\n   Client ID trunking is the association of multiple\
    \ sessions to the\n   same client ID.  Servers MUST support client ID trunking\
    \ for two\n   target network addresses whenever they allow session trunking for\n\
    \   those same two network addresses.  In addition, a server MAY, by\n   presenting\
    \ the same major server owner ID (Section 2.5) and server\n   scope (Section 2.10.4),\
    \ allow an additional case of client ID\n   trunking.  When two servers return\
    \ the same major server owner and\n   server scope, it means that the two servers\
    \ are cooperating on\n   locking state management, which is a prerequisite for\
    \ client ID\n   trunking.\n   Distinguishing when the client is allowed to use\
    \ session and client\n   ID trunking requires understanding how the results of\
    \ the EXCHANGE_ID\n   (Section 18.35) operation identify a server.  Suppose a\
    \ client sends\n   EXCHANGE_IDs over two different connections, each with a possibly\n\
    \   different target network address, but each EXCHANGE_ID operation has\n   the\
    \ same value in the eia_clientowner field.  If the same NFSv4.1\n   server is\
    \ listening over each connection, then each EXCHANGE_ID\n   result MUST return\
    \ the same values of eir_clientid,\n   eir_server_owner.so_major_id, and eir_server_scope.\
    \  The client can\n   then treat each connection as referring to the same server\
    \ (subject\n   to verification; see Section 2.10.5.1 below), and it can use each\n\
    \   connection to trunk requests and replies.  The client's choice is\n   whether\
    \ session trunking or client ID trunking applies.\n   Session Trunking.  If the\
    \ eia_clientowner argument is the same in two\n      different EXCHANGE_ID requests,\
    \ and the eir_clientid,\n      eir_server_owner.so_major_id, eir_server_owner.so_minor_id,\
    \ and\n      eir_server_scope results match in both EXCHANGE_ID results, then\n\
    \      the client is permitted to perform session trunking.  If the\n      client\
    \ has no session mapping to the tuple of eir_clientid,\n      eir_server_owner.so_major_id,\
    \ eir_server_scope, and\n      eir_server_owner.so_minor_id, then it creates the\
    \ session via a\n      CREATE_SESSION operation over one of the connections, which\n\
    \      associates the connection to the session.  If there is a session\n    \
    \  for the tuple, the client can send BIND_CONN_TO_SESSION to\n      associate\
    \ the connection to the session.\n      Of course, if the client does not desire\
    \ to use session trunking,\n      it is not required to do so.  It can invoke\
    \ CREATE_SESSION on the\n      connection.  This will result in client ID trunking\
    \ as described\n      below.  It can also decide to drop the connection if it\
    \ does not\n      choose to use trunking.\n   Client ID Trunking.  If the eia_clientowner\
    \ argument is the same in\n      two different EXCHANGE_ID requests, and the eir_clientid,\n\
    \      eir_server_owner.so_major_id, and eir_server_scope results match\n    \
    \  in both EXCHANGE_ID results, then the client is permitted to\n      perform\
    \ client ID trunking (regardless of whether the\n      eir_server_owner.so_minor_id\
    \ results match).  The client can\n      associate each connection with different\
    \ sessions, where each\n      session is associated with the same server.\n  \
    \    The client completes the act of client ID trunking by invoking\n      CREATE_SESSION\
    \ on each connection, using the same client ID that\n      was returned in eir_clientid.\
    \  These invocations create two\n      sessions and also associate each connection\
    \ with its respective\n      session.  The client is free to decline to use client\
    \ ID trunking\n      by simply dropping the connection at this point.\n      When\
    \ doing client ID trunking, locking state is shared across\n      sessions associated\
    \ with that same client ID.  This requires the\n      server to coordinate state\
    \ across sessions and the client to be\n      able to associate the same locking\
    \ state with multiple sessions.\n   It is always possible that, as a result of\
    \ various sorts of\n   reconfiguration events, eir_server_scope and eir_server_owner\
    \ values\n   may be different on subsequent EXCHANGE_ID requests made to the same\n\
    \   network address.\n   In most cases, such reconfiguration events will be disruptive\
    \ and\n   indicate that an IP address formerly connected to one server is now\n\
    \   connected to an entirely different one.\n   Some guidelines on client handling\
    \ of such situations follow:\n   *  When eir_server_scope changes, the client\
    \ has no assurance that\n      any IDs that it obtained previously (e.g., filehandles)\
    \ can be\n      validly used on the new server, and, even if the new server\n\
    \      accepts them, there is no assurance that this is not due to\n      accident.\
    \  Thus, it is best to treat all such state as lost or\n      stale, although\
    \ a client may assume that the probability of\n      inadvertent acceptance is\
    \ low and treat this situation as within\n      the next case.\n   *  When eir_server_scope\
    \ remains the same and\n      eir_server_owner.so_major_id changes, the client\
    \ can use the\n      filehandles it has, consider its locking state lost, and\
    \ attempt\n      to reclaim or otherwise re-obtain its locks.  It might find that\n\
    \      its filehandle is now stale.  However, if NFS4ERR_STALE is not\n      returned,\
    \ it can proceed to reclaim or otherwise re-obtain its\n      open locking state.\n\
    \   *  When eir_server_scope and eir_server_owner.so_major_id remain the\n   \
    \   same, the client has to use the now-current values of\n      eir_server_owner.so_minor_id\
    \ in deciding on appropriate forms of\n      trunking.  This may result in connections\
    \ being dropped or new\n      sessions being created.\n"
- title: 2.10.5.1.  Verifying Claims of Matching Server Identity
  contents:
  - "2.10.5.1.  Verifying Claims of Matching Server Identity\n   When the server responds\
    \ using two different connections that claim\n   matching or partially matching\
    \ eir_server_owner, eir_server_scope,\n   and eir_clientid values, the client\
    \ does not have to trust the\n   servers' claims.  The client may verify these\
    \ claims before trunking\n   traffic in the following ways:\n   *  For session\
    \ trunking, clients SHOULD reliably verify if\n      connections between different\
    \ network paths are in fact associated\n      with the same NFSv4.1 server and\
    \ usable on the same session, and\n      servers MUST allow clients to perform\
    \ reliable verification.  When\n      a client ID is created, the client SHOULD\
    \ specify that\n      BIND_CONN_TO_SESSION is to be verified according to the\
    \ SP4_SSV or\n      SP4_MACH_CRED (Section 18.35) state protection options.  For\n\
    \      SP4_SSV, reliable verification depends on a shared secret (the\n      SSV)\
    \ that is established via the SET_SSV (see Section 18.47)\n      operation.\n\
    \      When a new connection is associated with the session (via the\n      BIND_CONN_TO_SESSION\
    \ operation, see Section 18.34), if the client\n      specified SP4_SSV state\
    \ protection for the BIND_CONN_TO_SESSION\n      operation, the client MUST send\
    \ the BIND_CONN_TO_SESSION with\n      RPCSEC_GSS protection, using integrity\
    \ or privacy, and an\n      RPCSEC_GSS handle created with the GSS SSV mechanism\
    \ (see\n      Section 2.10.9).\n      If the client mistakenly tries to associate\
    \ a connection to a\n      session of a wrong server, the server will either reject\
    \ the\n      attempt because it is not aware of the session identifier of the\n\
    \      BIND_CONN_TO_SESSION arguments, or it will reject the attempt\n      because\
    \ the RPCSEC_GSS authentication fails.  Even if the server\n      mistakenly or\
    \ maliciously accepts the connection association\n      attempt, the RPCSEC_GSS\
    \ verifier it computes in the response will\n      not be verified by the client,\
    \ so the client will know it cannot\n      use the connection for trunking the\
    \ specified session.\n      If the client specified SP4_MACH_CRED state protection,\
    \ the\n      BIND_CONN_TO_SESSION operation will use RPCSEC_GSS integrity or\n\
    \      privacy, using the same credential that was used when the client\n    \
    \  ID was created.  Mutual authentication via RPCSEC_GSS assures the\n      client\
    \ that the connection is associated with the correct session\n      of the correct\
    \ server.\n   *  For client ID trunking, the client has at least two options for\n\
    \      verifying that the same client ID obtained from two different\n      EXCHANGE_ID\
    \ operations came from the same server.  The first\n      option is to use RPCSEC_GSS\
    \ authentication when sending each\n      EXCHANGE_ID operation.  Each time an\
    \ EXCHANGE_ID is sent with\n      RPCSEC_GSS authentication, the client notes\
    \ the principal name of\n      the GSS target.  If the EXCHANGE_ID results indicate\
    \ that client\n      ID trunking is possible, and the GSS targets' principal names\
    \ are\n      the same, the servers are the same and client ID trunking is\n  \
    \    allowed.\n      The second option for verification is to use SP4_SSV protection.\n\
    \      When the client sends EXCHANGE_ID, it specifies SP4_SSV\n      protection.\
    \  The first EXCHANGE_ID the client sends always has to\n      be confirmed by\
    \ a CREATE_SESSION call.  The client then sends\n      SET_SSV.  Later, the client\
    \ sends EXCHANGE_ID to a second\n      destination network address different from\
    \ the one the first\n      EXCHANGE_ID was sent to.  The client checks that each\
    \ EXCHANGE_ID\n      reply has the same eir_clientid, eir_server_owner.so_major_id,\
    \ and\n      eir_server_scope.  If so, the client verifies the claim by sending\n\
    \      a CREATE_SESSION operation to the second destination address,\n      protected\
    \ with RPCSEC_GSS integrity using an RPCSEC_GSS handle\n      returned by the\
    \ second EXCHANGE_ID.  If the server accepts the\n      CREATE_SESSION request,\
    \ and if the client verifies the RPCSEC_GSS\n      verifier and integrity codes,\
    \ then the client has proof the second\n      server knows the SSV, and thus the\
    \ two servers are cooperating for\n      the purposes of specifying server scope\
    \ and client ID trunking.\n"
- title: 2.10.6.  Exactly Once Semantics
  contents:
  - "2.10.6.  Exactly Once Semantics\n   Via the session, NFSv4.1 offers exactly once\
    \ semantics (EOS) for\n   requests sent over a channel.  EOS is supported on both\
    \ the fore\n   channel and backchannel.\n   Each COMPOUND or CB_COMPOUND request\
    \ that is sent with a leading\n   SEQUENCE or CB_SEQUENCE operation MUST be executed\
    \ by the receiver\n   exactly once.  This requirement holds regardless of whether\
    \ the\n   request is sent with reply caching specified (see\n   Section 2.10.6.1.3).\
    \  The requirement holds even if the requester is\n   sending the request over\
    \ a session created between a pNFS data client\n   and pNFS data server.  To understand\
    \ the rationale for this\n   requirement, divide the requests into three classifications:\n\
    \   *  Non-idempotent requests.\n   *  Idempotent modifying requests.\n   *  Idempotent\
    \ non-modifying requests.\n   An example of a non-idempotent request is RENAME.\
    \  Obviously, if a\n   replier executes the same RENAME request twice, and the\
    \ first\n   execution succeeds, the re-execution will fail.  If the replier\n\
    \   returns the result from the re-execution, this result is incorrect.\n   Therefore,\
    \ EOS is required for non-idempotent requests.\n   An example of an idempotent\
    \ modifying request is a COMPOUND request\n   containing a WRITE operation.  Repeated\
    \ execution of the same WRITE\n   has the same effect as execution of that WRITE\
    \ a single time.\n   Nevertheless, enforcing EOS for WRITEs and other idempotent\
    \ modifying\n   requests is necessary to avoid data corruption.\n   Suppose a\
    \ client sends WRITE A to a noncompliant server that does not\n   enforce EOS,\
    \ and receives no response, perhaps due to a network\n   partition.  The client\
    \ reconnects to the server and re-sends WRITE A.\n   Now, the server has outstanding\
    \ two instances of A.  The server can\n   be in a situation in which it executes\
    \ and replies to the retry of A,\n   while the first A is still waiting in the\
    \ server's internal I/O\n   system for some resource.  Upon receiving the reply\
    \ to the second\n   attempt of WRITE A, the client believes its WRITE is done\
    \ so it is\n   free to send WRITE B, which overlaps the byte-range of A.  When\
    \ the\n   original A is dispatched from the server's I/O system and executed\n\
    \   (thus the second time A will have been written), then what has been\n   written\
    \ by B can be overwritten and thus corrupted.\n   An example of an idempotent\
    \ non-modifying request is a COMPOUND\n   containing SEQUENCE, PUTFH, READLINK,\
    \ and nothing else.  The re-\n   execution of such a request will not cause data\
    \ corruption or produce\n   an incorrect result.  Nonetheless, to keep the implementation\
    \ simple,\n   the replier MUST enforce EOS for all requests, whether or not\n\
    \   idempotent and non-modifying.\n   Note that true and complete EOS is not possible\
    \ unless the server\n   persists the reply cache in stable storage, and unless\
    \ the server is\n   somehow implemented to never require a restart (indeed, if\
    \ such a\n   server exists, the distinction between a reply cache kept in stable\n\
    \   storage versus one that is not is one without meaning).  See\n   Section 2.10.6.5\
    \ for a discussion of persistence in the reply cache.\n   Regardless, even if\
    \ the server does not persist the reply cache, EOS\n   improves robustness and\
    \ correctness over previous versions of NFS\n   because the legacy duplicate request/reply\
    \ caches were based on the\n   ONC RPC transaction identifier (XID).  Section\
    \ 2.10.6.1 explains the\n   shortcomings of the XID as a basis for a reply cache\
    \ and describes\n   how NFSv4.1 sessions improve upon the XID.\n"
- title: 2.10.6.1.  Slot Identifiers and Reply Cache
  contents:
  - "2.10.6.1.  Slot Identifiers and Reply Cache\n   The RPC layer provides a transaction\
    \ ID (XID), which, while required\n   to be unique, is not convenient for tracking\
    \ requests for two\n   reasons.  First, the XID is only meaningful to the requester;\
    \ it\n   cannot be interpreted by the replier except to test for equality with\n\
    \   previously sent requests.  When consulting an RPC-based duplicate\n   request\
    \ cache, the opaqueness of the XID requires a computationally\n   expensive look\
    \ up (often via a hash that includes XID and source\n   address).  NFSv4.1 requests\
    \ use a non-opaque slot ID, which is an\n   index into a slot table, which is\
    \ far more efficient.  Second,\n   because RPC requests can be executed by the\
    \ replier in any order,\n   there is no bound on the number of requests that may\
    \ be outstanding\n   at any time.  To achieve perfect EOS, using ONC RPC would\
    \ require\n   storing all replies in the reply cache.  XIDs are 32 bits; storing\n\
    \   over four billion (2^(32)) replies in the reply cache is not\n   practical.\
    \  In practice, previous versions of NFS have chosen to\n   store a fixed number\
    \ of replies in the cache, and to use a least\n   recently used (LRU) approach\
    \ to replacing cache entries with new\n   entries when the cache is full.  In\
    \ NFSv4.1, the number of\n   outstanding requests is bounded by the size of the\
    \ slot table, and a\n   sequence ID per slot is used to tell the replier when\
    \ it is safe to\n   delete a cached reply.\n   In the NFSv4.1 reply cache, when\
    \ the requester sends a new request,\n   it selects a slot ID in the range 0..N,\
    \ where N is the replier's\n   current maximum slot ID granted to the requester\
    \ on the session over\n   which the request is to be sent.  The value of N starts\
    \ out as equal\n   to ca_maxrequests - 1 (Section 18.36), but can be adjusted\
    \ by the\n   response to SEQUENCE or CB_SEQUENCE as described later in this\n\
    \   section.  The slot ID must be unused by any of the requests that the\n   requester\
    \ has already active on the session.  \"Unused\" here means the\n   requester\
    \ has no outstanding request for that slot ID.\n   A slot contains a sequence\
    \ ID and the cached reply corresponding to\n   the request sent with that sequence\
    \ ID.  The sequence ID is a 32-bit\n   unsigned value, and is therefore in the\
    \ range 0..0xFFFFFFFF (2^(32) -\n   1).  The first time a slot is used, the requester\
    \ MUST specify a\n   sequence ID of one (Section 18.36).  Each time a slot is\
    \ reused, the\n   request MUST specify a sequence ID that is one greater than\
    \ that of\n   the previous request on the slot.  If the previous sequence ID was\n\
    \   0xFFFFFFFF, then the next request for the slot MUST have the sequence\n  \
    \ ID set to zero (i.e., (2^(32) - 1) + 1 mod 2^(32)).\n   The sequence ID accompanies\
    \ the slot ID in each request.  It is for\n   the critical check at the replier:\
    \ it used to efficiently determine\n   whether a request using a certain slot\
    \ ID is a retransmit or a new,\n   never-before-seen request.  It is not feasible\
    \ for the requester to\n   assert that it is retransmitting to implement this,\
    \ because for any\n   given request the requester cannot know whether the replier\
    \ has seen\n   it unless the replier actually replies.  Of course, if the requester\n\
    \   has seen the reply, the requester would not retransmit.\n   The replier compares\
    \ each received request's sequence ID with the\n   last one previously received\
    \ for that slot ID, to see if the new\n   request is:\n   *  A new request, in\
    \ which the sequence ID is one greater than that\n      previously seen in the\
    \ slot (accounting for sequence wraparound).\n      The replier proceeds to execute\
    \ the new request, and the replier\n      MUST increase the slot's sequence ID\
    \ by one.\n   *  A retransmitted request, in which the sequence ID is equal to\
    \ that\n      currently recorded in the slot.  If the original request has\n \
    \     executed to completion, the replier returns the cached reply.  See\n   \
    \   Section 2.10.6.2 for direction on how the replier deals with\n      retries\
    \ of requests that are still in progress.\n   *  A misordered retry, in which\
    \ the sequence ID is less than\n      (accounting for sequence wraparound) that\
    \ previously seen in the\n      slot.  The replier MUST return NFS4ERR_SEQ_MISORDERED\
    \ (as the\n      result from SEQUENCE or CB_SEQUENCE).\n   *  A misordered new\
    \ request, in which the sequence ID is two or more\n      than (accounting for\
    \ sequence wraparound) that previously seen in\n      the slot.  Note that because\
    \ the sequence ID MUST wrap around to\n      zero once it reaches 0xFFFFFFFF,\
    \ a misordered new request and a\n      misordered retry cannot be distinguished.\
    \  Thus, the replier MUST\n      return NFS4ERR_SEQ_MISORDERED (as the result\
    \ from SEQUENCE or\n      CB_SEQUENCE).\n   Unlike the XID, the slot ID is always\
    \ within a specific range; this\n   has two implications.  The first implication\
    \ is that for a given\n   session, the replier need only cache the results of\
    \ a limited number\n   of COMPOUND requests.  The second implication derives from\
    \ the first,\n   which is that unlike XID-indexed reply caches (also known as\n\
    \   duplicate request caches - DRCs), the slot ID-based reply cache\n   cannot\
    \ be overflowed.  Through use of the sequence ID to identify\n   retransmitted\
    \ requests, the replier does not need to actually cache\n   the request itself,\
    \ reducing the storage requirements of the reply\n   cache further.  These facilities\
    \ make it practical to maintain all\n   the required entries for an effective\
    \ reply cache.\n   The slot ID, sequence ID, and session ID therefore take over\
    \ the\n   traditional role of the XID and source network address in the\n   replier's\
    \ reply cache implementation.  This approach is considerably\n   more portable\
    \ and completely robust -- it is not subject to the\n   reassignment of ports\
    \ as clients reconnect over IP networks.  In\n   addition, the RPC XID is not\
    \ used in the reply cache, enhancing\n   robustness of the cache in the face of\
    \ any rapid reuse of XIDs by the\n   requester.  While the replier does not care\
    \ about the XID for the\n   purposes of reply cache management (but the replier\
    \ MUST return the\n   same XID that was in the request), nonetheless there are\n\
    \   considerations for the XID in NFSv4.1 that are the same as all other\n   previous\
    \ versions of NFS.  The RPC XID remains in each message and\n   needs to be formulated\
    \ in NFSv4.1 requests as in any other ONC RPC\n   request.  The reasons include:\n\
    \   *  The RPC layer retains its existing semantics and implementation.\n   *\
    \  The requester and replier must be able to interoperate at the RPC\n      layer,\
    \ prior to the NFSv4.1 decoding of the SEQUENCE or\n      CB_SEQUENCE operation.\n\
    \   *  If an operation is being used that does not start with SEQUENCE or\n  \
    \    CB_SEQUENCE (e.g., BIND_CONN_TO_SESSION), then the RPC XID is\n      needed\
    \ for correct operation to match the reply to the request.\n   *  The SEQUENCE\
    \ or CB_SEQUENCE operation may generate an error.  If\n      so, the embedded\
    \ slot ID, sequence ID, and session ID (if present)\n      in the request will\
    \ not be in the reply, and the requester has\n      only the XID to match the\
    \ reply to the request.\n   Given that well-formulated XIDs continue to be required,\
    \ this raises\n   the question: why do SEQUENCE and CB_SEQUENCE replies have a\
    \ session\n   ID, slot ID, and sequence ID?  Having the session ID in the reply\n\
    \   means that the requester does not have to use the XID to look up the\n   session\
    \ ID, which would be necessary if the connection were\n   associated with multiple\
    \ sessions.  Having the slot ID and sequence\n   ID in the reply means that the\
    \ requester does not have to use the XID\n   to look up the slot ID and sequence\
    \ ID.  Furthermore, since the XID\n   is only 32 bits, it is too small to guarantee\
    \ the re-association of a\n   reply with its request [44]; having session ID,\
    \ slot ID, and sequence\n   ID in the reply allows the client to validate that\
    \ the reply in fact\n   belongs to the matched request.\n   The SEQUENCE (and\
    \ CB_SEQUENCE) operation also carries a\n   \"highest_slotid\" value, which carries\
    \ additional requester slot usage\n   information.  The requester MUST always\
    \ indicate the slot ID\n   representing the outstanding request with the highest-numbered\
    \ slot\n   value.  The requester should in all cases provide the most\n   conservative\
    \ value possible, although it can be increased somewhat\n   above the actual instantaneous\
    \ usage to maintain some minimum or\n   optimal level.  This provides a way for\
    \ the requester to yield unused\n   request slots back to the replier, which in\
    \ turn can use the\n   information to reallocate resources.\n   The replier responds\
    \ with both a new target highest_slotid and an\n   enforced highest_slotid, described\
    \ as follows:\n   *  The target highest_slotid is an indication to the requester\
    \ of the\n      highest_slotid the replier wishes the requester to be using. \
    \ This\n      permits the replier to withdraw (or add) resources from a\n    \
    \  requester that has been found to not be using them, in order to\n      more\
    \ fairly share resources among a varying level of demand from\n      other requesters.\
    \  The requester must always comply with the\n      replier's value updates, since\
    \ they indicate newly established\n      hard limits on the requester's access\
    \ to session resources.\n      However, because of request pipelining, the requester\
    \ may have\n      active requests in flight reflecting prior values; therefore,\
    \ the\n      replier must not immediately require the requester to comply.\n \
    \  *  The enforced highest_slotid indicates the highest slot ID the\n      requester\
    \ is permitted to use on a subsequent SEQUENCE or\n      CB_SEQUENCE operation.\
    \  The replier's enforced highest_slotid\n      SHOULD be no less than the highest_slotid\
    \ the requester indicated\n      in the SEQUENCE or CB_SEQUENCE arguments.\n \
    \     A requester can be intransigent with respect to lowering its\n      highest_slotid\
    \ argument to a Sequence operation, i.e. the\n      requester continues to ignore\
    \ the target highest_slotid in the\n      response to a Sequence operation, and\
    \ continues to set its\n      highest_slotid argument to be higher than the target\n\
    \      highest_slotid.  This can be considered particularly egregious\n      behavior\
    \ when the replier knows there are no outstanding requests\n      with slot IDs\
    \ higher than its target highest_slotid.  When faced\n      with such intransigence,\
    \ the replier is free to take more forceful\n      action, and MAY reply with\
    \ a new enforced highest_slotid that is\n      less than its previous enforced\
    \ highest_slotid.  Thereafter, if\n      the requester continues to send requests\
    \ with a highest_slotid\n      that is greater than the replier's new enforced\
    \ highest_slotid,\n      the server MAY return NFS4ERR_BAD_HIGH_SLOT, unless the\
    \ slot ID in\n      the request is greater than the new enforced highest_slotid\
    \ and\n      the request is a retry.\n      The replier SHOULD retain the slots\
    \ it wants to retire until the\n      requester sends a request with a highest_slotid\
    \ less than or equal\n      to the replier's new enforced highest_slotid.\n  \
    \    The requester can also be intransigent with respect to sending\n      non-retry\
    \ requests that have a slot ID that exceeds the replier's\n      highest_slotid.\
    \  Once the replier has forcibly lowered the\n      enforced highest_slotid, the\
    \ requester is only allowed to send\n      retries on slots that exceed the replier's\
    \ highest_slotid.  If a\n      request is received with a slot ID that is higher\
    \ than the new\n      enforced highest_slotid, and the sequence ID is one higher\
    \ than\n      what is in the slot's reply cache, then the server can both retire\n\
    \      the slot and return NFS4ERR_BADSLOT (however, the server MUST NOT\n   \
    \   do one and not the other).  The reason it is safe to retire the\n      slot\
    \ is because by using the next sequence ID, the requester is\n      indicating\
    \ it has received the previous reply for the slot.\n   *  The requester SHOULD\
    \ use the lowest available slot when sending a\n      new request.  This way,\
    \ the replier may be able to retire slot\n      entries faster.  However, where\
    \ the replier is actively adjusting\n      its granted highest_slotid, it will\
    \ not be able to use only the\n      receipt of the slot ID and highest_slotid\
    \ in the request.  Neither\n      the slot ID nor the highest_slotid used in a\
    \ request may reflect\n      the replier's current idea of the requester's session\
    \ limit,\n      because the request may have been sent from the requester before\n\
    \      the update was received.  Therefore, in the downward adjustment\n     \
    \ case, the replier may have to retain a number of reply cache\n      entries\
    \ at least as large as the old value of maximum requests\n      outstanding, until\
    \ it can infer that the requester has seen a\n      reply containing the new granted\
    \ highest_slotid.  The replier can\n      infer that the requester has seen such\
    \ a reply when it receives a\n      new request with the same slot ID as the request\
    \ replied to and\n      the next higher sequence ID.\n"
- title: 2.10.6.1.1.  Caching of SEQUENCE and CB_SEQUENCE Replies
  contents:
  - "2.10.6.1.1.  Caching of SEQUENCE and CB_SEQUENCE Replies\n   When a SEQUENCE\
    \ or CB_SEQUENCE operation is successfully executed,\n   its reply MUST always\
    \ be cached.  Specifically, session ID, sequence\n   ID, and slot ID MUST be cached\
    \ in the reply cache.  The reply from\n   SEQUENCE also includes the highest slot\
    \ ID, target highest slot ID,\n   and status flags.  Instead of caching these\
    \ values, the server MAY\n   re-compute the values from the current state of the\
    \ fore channel,\n   session, and/or client ID as appropriate.  Similarly, the\
    \ reply from\n   CB_SEQUENCE includes a highest slot ID and target highest slot\
    \ ID.\n   The client MAY re-compute the values from the current state of the\n\
    \   session as appropriate.\n   Regardless of whether or not a replier is re-computing\
    \ highest slot\n   ID, target slot ID, and status on replies to retries, the requester\n\
    \   MUST NOT assume that the values are being re-computed whenever it\n   receives\
    \ a reply after a retry is sent, since it has no way of\n   knowing whether the\
    \ reply it has received was sent by the replier in\n   response to the retry or\
    \ is a delayed response to the original\n   request.  Therefore, it may be the\
    \ case that highest slot ID, target\n   slot ID, or status bits may reflect the\
    \ state of affairs when the\n   request was first executed.  Although acting based\
    \ on such delayed\n   information is valid, it may cause the receiver of the reply\
    \ to do\n   unneeded work.  Requesters MAY choose to send additional requests\
    \ to\n   get the current state of affairs or use the state of affairs reported\n\
    \   by subsequent requests, in preference to acting immediately on data\n   that\
    \ might be out of date.\n"
- title: 2.10.6.1.2.  Errors from SEQUENCE and CB_SEQUENCE
  contents:
  - "2.10.6.1.2.  Errors from SEQUENCE and CB_SEQUENCE\n   Any time SEQUENCE or CB_SEQUENCE\
    \ returns an error, the sequence ID of\n   the slot MUST NOT change.  The replier\
    \ MUST NOT modify the reply\n   cache entry for the slot whenever an error is\
    \ returned from SEQUENCE\n   or CB_SEQUENCE.\n"
- title: 2.10.6.1.3.  Optional Reply Caching
  contents:
  - "2.10.6.1.3.  Optional Reply Caching\n   On a per-request basis, the requester\
    \ can choose to direct the\n   replier to cache the reply to all operations after\
    \ the first\n   operation (SEQUENCE or CB_SEQUENCE) via the sa_cachethis or\n\
    \   csa_cachethis fields of the arguments to SEQUENCE or CB_SEQUENCE.\n   The\
    \ reason it would not direct the replier to cache the entire reply\n   is that\
    \ the request is composed of all idempotent operations [41].\n   Caching the reply\
    \ may offer little benefit.  If the reply is too\n   large (see Section 2.10.6.4),\
    \ it may not be cacheable anyway.  Even\n   if the reply to idempotent request\
    \ is small enough to cache,\n   unnecessarily caching the reply slows down the\
    \ server and increases\n   RPC latency.\n   Whether or not the requester requests\
    \ the reply to be cached has no\n   effect on the slot processing.  If the result\
    \ of SEQUENCE or\n   CB_SEQUENCE is NFS4_OK, then the slot's sequence ID MUST\
    \ be\n   incremented by one.  If a requester does not direct the replier to\n\
    \   cache the reply, the replier MUST do one of following:\n   *  The replier\
    \ can cache the entire original reply.  Even though\n      sa_cachethis or csa_cachethis\
    \ is FALSE, the replier is always free\n      to cache.  It may choose this approach\
    \ in order to simplify\n      implementation.\n   *  The replier enters into its\
    \ reply cache a reply consisting of the\n      original results to the SEQUENCE\
    \ or CB_SEQUENCE operation, and\n      with the next operation in COMPOUND or\
    \ CB_COMPOUND having the\n      error NFS4ERR_RETRY_UNCACHED_REP.  Thus, if the\
    \ requester later\n      retries the request, it will get NFS4ERR_RETRY_UNCACHED_REP.\
    \  If a\n      replier receives a retried Sequence operation where the reply to\n\
    \      the COMPOUND or CB_COMPOUND was not cached, then the replier,\n      -\
    \  MAY return NFS4ERR_RETRY_UNCACHED_REP in reply to a Sequence\n         operation\
    \ if the Sequence operation is not the first operation\n         (granted, a requester\
    \ that does so is in violation of the\n         NFSv4.1 protocol).\n      -  MUST\
    \ NOT return NFS4ERR_RETRY_UNCACHED_REP in reply to a\n         Sequence operation\
    \ if the Sequence operation is the first\n         operation.\n   *  If the second\
    \ operation is an illegal operation, or an operation\n      that was legal in\
    \ a previous minor version of NFSv4 and MUST NOT\n      be supported in the current\
    \ minor version (e.g., SETCLIENTID), the\n      replier MUST NOT ever return NFS4ERR_RETRY_UNCACHED_REP.\
    \  Instead\n      the replier MUST return NFS4ERR_OP_ILLEGAL or NFS4ERR_BADXDR\
    \ or\n      NFS4ERR_NOTSUPP as appropriate.\n   *  If the second operation can\
    \ result in another error status, the\n      replier MAY return a status other\
    \ than NFS4ERR_RETRY_UNCACHED_REP,\n      provided the operation is not executed\
    \ in such a way that the\n      state of the replier is changed.  Examples of\
    \ such an error status\n      include: NFS4ERR_NOTSUPP returned for an operation\
    \ that is legal\n      but not REQUIRED in the current minor versions, and thus\
    \ not\n      supported by the replier; NFS4ERR_SEQUENCE_POS; and\n      NFS4ERR_REQ_TOO_BIG.\n\
    \   The discussion above assumes that the retried request matches the\n   original\
    \ one.  Section 2.10.6.1.3.1 discusses what the replier might\n   do, and MUST\
    \ do when original and retried requests do not match.\n   Since the replier may\
    \ only cache a small amount of the information\n   that would be required to determine\
    \ whether this is a case of a false\n   retry, the replier may send to the client\
    \ any of the following\n   responses:\n   *  The cached reply to the original\
    \ request (if the replier has\n      cached it in its entirety and the users of\
    \ the original request\n      and retry match).\n   *  A reply that consists only\
    \ of the Sequence operation with the\n      error NFS4ERR_SEQ_FALSE_RETRY.\n \
    \  *  A reply consisting of the response to Sequence with the status\n      NFS4_OK,\
    \ together with the second operation as it appeared in the\n      retried request\
    \ with an error of NFS4ERR_RETRY_UNCACHED_REP or\n      other error as described\
    \ above.\n   *  A reply that consists of the response to Sequence with the status\n\
    \      NFS4_OK, together with the second operation as it appeared in the\n   \
    \   original request with an error of NFS4ERR_RETRY_UNCACHED_REP or\n      other\
    \ error as described above.\n"
- title: 2.10.6.1.3.1.  False Retry
  contents:
  - "2.10.6.1.3.1.  False Retry\n   If a requester sent a Sequence operation with\
    \ a slot ID and sequence\n   ID that are in the reply cache but the replier detected\
    \ that the\n   retried request is not the same as the original request, including\
    \ a\n   retry that has different operations or different arguments in the\n  \
    \ operations from the original and a retry that uses a different\n   principal\
    \ in the RPC request's credential field that translates to a\n   different user,\
    \ then this is a false retry.  When the replier detects\n   a false retry, it\
    \ is permitted (but not always obligated) to return\n   NFS4ERR_SEQ_FALSE_RETRY\
    \ in response to the Sequence operation when it\n   detects a false retry.\n \
    \  Translations of particularly privileged user values to other users\n   due\
    \ to the lack of appropriately secure credentials, as configured on\n   the replier,\
    \ should be applied before determining whether the users\n   are the same or different.\
    \  If the replier determines the users are\n   different between the original\
    \ request and a retry, then the replier\n   MUST return NFS4ERR_SEQ_FALSE_RETRY.\n\
    \   If an operation of the retry is an illegal operation, or an operation\n  \
    \ that was legal in a previous minor version of NFSv4 and MUST NOT be\n   supported\
    \ in the current minor version (e.g., SETCLIENTID), the\n   replier MAY return\
    \ NFS4ERR_SEQ_FALSE_RETRY (and MUST do so if the\n   users of the original request\
    \ and retry differ).  Otherwise, the\n   replier MAY return NFS4ERR_OP_ILLEGAL\
    \ or NFS4ERR_BADXDR or\n   NFS4ERR_NOTSUPP as appropriate.  Note that the handling\
    \ is in\n   contrast for how the replier deals with retries requests with no\n\
    \   cached reply.  The difference is due to NFS4ERR_SEQ_FALSE_RETRY being\n  \
    \ a valid error for only Sequence operations, whereas\n   NFS4ERR_RETRY_UNCACHED_REP\
    \ is a valid error for all operations except\n   illegal operations and operations\
    \ that MUST NOT be supported in the\n   current minor version of NFSv4.\n"
- title: 2.10.6.2.  Retry and Replay of Reply
  contents:
  - "2.10.6.2.  Retry and Replay of Reply\n   A requester MUST NOT retry a request,\
    \ unless the connection it used\n   to send the request disconnects.  The requester\
    \ can then reconnect\n   and re-send the request, or it can re-send the request\
    \ over a\n   different connection that is associated with the same session.\n\
    \   If the requester is a server wanting to re-send a callback operation\n   over\
    \ the backchannel of a session, the requester of course cannot\n   reconnect because\
    \ only the client can associate connections with the\n   backchannel.  The server\
    \ can re-send the request over another\n   connection that is bound to the same\
    \ session's backchannel.  If there\n   is no such connection, the server MUST\
    \ indicate that the session has\n   no backchannel by setting the SEQ4_STATUS_CB_PATH_DOWN_SESSION\
    \ flag\n   bit in the response to the next SEQUENCE operation from the client.\n\
    \   The client MUST then associate a connection with the session (or\n   destroy\
    \ the session).\n   Note that it is not fatal for a requester to retry without\
    \ a\n   disconnect between the request and retry.  However, the retry does\n \
    \  consume resources, especially with RDMA, where each request, retry or\n   not,\
    \ consumes a credit.  Retries for no reason, especially retries\n   sent shortly\
    \ after the previous attempt, are a poor use of network\n   bandwidth and defeat\
    \ the purpose of a transport's inherent congestion\n   control system.\n   A requester\
    \ MUST wait for a reply to a request before using the slot\n   for another request.\
    \  If it does not wait for a reply, then the\n   requester does not know what\
    \ sequence ID to use for the slot on its\n   next request.  For example, suppose\
    \ a requester sends a request with\n   sequence ID 1, and does not wait for the\
    \ response.  The next time it\n   uses the slot, it sends the new request with\
    \ sequence ID 2.  If the\n   replier has not seen the request with sequence ID\
    \ 1, then the replier\n   is not expecting sequence ID 2, and rejects the requester's\
    \ new\n   request with NFS4ERR_SEQ_MISORDERED (as the result from SEQUENCE or\n\
    \   CB_SEQUENCE).\n   RDMA fabrics do not guarantee that the memory handles (Steering\
    \ Tags)\n   within each RPC/RDMA \"chunk\" [32] are valid on a scope outside that\n\
    \   of a single connection.  Therefore, handles used by the direct\n   operations\
    \ become invalid after connection loss.  The server must\n   ensure that any RDMA\
    \ operations that must be replayed from the reply\n   cache use the newly provided\
    \ handle(s) from the most recent request.\n   A retry might be sent while the\
    \ original request is still in progress\n   on the replier.  The replier SHOULD\
    \ deal with the issue by returning\n   NFS4ERR_DELAY as the reply to SEQUENCE\
    \ or CB_SEQUENCE operation, but\n   implementations MAY return NFS4ERR_MISORDERED.\
    \  Since errors from\n   SEQUENCE and CB_SEQUENCE are never recorded in the reply\
    \ cache, this\n   approach allows the results of the execution of the original\
    \ request\n   to be properly recorded in the reply cache (assuming that the\n\
    \   requester specified the reply to be cached).\n"
- title: 2.10.6.3.  Resolving Server Callback Races
  contents:
  - "2.10.6.3.  Resolving Server Callback Races\n   It is possible for server callbacks\
    \ to arrive at the client before\n   the reply from related fore channel operations.\
    \  For example, a\n   client may have been granted a delegation to a file it has\
    \ opened,\n   but the reply to the OPEN (informing the client of the granting\
    \ of\n   the delegation) may be delayed in the network.  If a conflicting\n  \
    \ operation arrives at the server, it will recall the delegation using\n   the\
    \ backchannel, which may be on a different transport connection,\n   perhaps even\
    \ a different network, or even a different session\n   associated with the same\
    \ client ID.\n   The presence of a session between the client and server alleviates\n\
    \   this issue.  When a session is in place, each client request is\n   uniquely\
    \ identified by its { session ID, slot ID, sequence ID }\n   triple.  By the rules\
    \ under which slot entries (reply cache entries)\n   are retired, the server has\
    \ knowledge whether the client has \"seen\"\n   each of the server's replies.\
    \  The server can therefore provide\n   sufficient information to the client to\
    \ allow it to disambiguate\n   between an erroneous or conflicting callback race\
    \ condition.\n   For each client operation that might result in some sort of server\n\
    \   callback, the server SHOULD \"remember\" the { session ID, slot ID,\n   sequence\
    \ ID } triple of the client request until the slot ID\n   retirement rules allow\
    \ the server to determine that the client has,\n   in fact, seen the server's\
    \ reply.  Until the time the { session ID,\n   slot ID, sequence ID } request\
    \ triple can be retired, any recalls of\n   the associated object MUST carry an\
    \ array of these referring\n   identifiers (in the CB_SEQUENCE operation's arguments),\
    \ for the\n   benefit of the client.  After this time, it is not necessary for\
    \ the\n   server to provide this information in related callbacks, since it is\n\
    \   certain that a race condition can no longer occur.\n   The CB_SEQUENCE operation\
    \ that begins each server callback carries a\n   list of \"referring\" { session\
    \ ID, slot ID, sequence ID } triples.  If\n   the client finds the request corresponding\
    \ to the referring session\n   ID, slot ID, and sequence ID to be currently outstanding\
    \ (i.e., the\n   server's reply has not been seen by the client), it can determine\n\
    \   that the callback has raced the reply, and act accordingly.  If the\n   client\
    \ does not find the request corresponding to the referring\n   triple to be outstanding\
    \ (including the case of a session ID\n   referring to a destroyed session), then\
    \ there is no race with respect\n   to this triple.  The server SHOULD limit the\
    \ referring triples to\n   requests that refer to just those that apply to the\
    \ objects referred\n   to in the CB_COMPOUND procedure.\n   The client must not\
    \ simply wait forever for the expected server reply\n   to arrive before responding\
    \ to the CB_COMPOUND that won the race,\n   because it is possible that it will\
    \ be delayed indefinitely.  The\n   client should assume the likely case that\
    \ the reply will arrive\n   within the average round-trip time for COMPOUND requests\
    \ to the\n   server, and wait that period of time.  If that period of time\n \
    \  expires, it can respond to the CB_COMPOUND with NFS4ERR_DELAY.  There\n   are\
    \ other scenarios under which callbacks may race replies.  Among\n   them are\
    \ pNFS layout recalls as described in Section 12.5.5.2.\n"
- title: 2.10.6.4.  COMPOUND and CB_COMPOUND Construction Issues
  contents:
  - "2.10.6.4.  COMPOUND and CB_COMPOUND Construction Issues\n   Very large requests\
    \ and replies may pose both buffer management\n   issues (especially with RDMA)\
    \ and reply cache issues.  When the\n   session is created (Section 18.36), for\
    \ each channel (fore and back),\n   the client and server negotiate the maximum-sized\
    \ request they will\n   send or process (ca_maxrequestsize), the maximum-sized\
    \ reply they\n   will return or process (ca_maxresponsesize), and the maximum-sized\n\
    \   reply they will store in the reply cache (ca_maxresponsesize_cached).\n  \
    \ If a request exceeds ca_maxrequestsize, the reply will have the\n   status NFS4ERR_REQ_TOO_BIG.\
    \  A replier MAY return NFS4ERR_REQ_TOO_BIG\n   as the status for the first operation\
    \ (SEQUENCE or CB_SEQUENCE) in\n   the request (which means that no operations\
    \ in the request executed\n   and that the state of the slot in the reply cache\
    \ is unchanged), or\n   it MAY opt to return it on a subsequent operation in the\
    \ same\n   COMPOUND or CB_COMPOUND request (which means that at least one\n  \
    \ operation did execute and that the state of the slot in the reply\n   cache\
    \ does change).  The replier SHOULD set NFS4ERR_REQ_TOO_BIG on\n   the operation\
    \ that exceeds ca_maxrequestsize.\n   If a reply exceeds ca_maxresponsesize, the\
    \ reply will have the status\n   NFS4ERR_REP_TOO_BIG.  A replier MAY return NFS4ERR_REP_TOO_BIG\
    \ as the\n   status for the first operation (SEQUENCE or CB_SEQUENCE) in the\n\
    \   request, or it MAY opt to return it on a subsequent operation (in the\n  \
    \ same COMPOUND or CB_COMPOUND reply).  A replier MAY return\n   NFS4ERR_REP_TOO_BIG\
    \ in the reply to SEQUENCE or CB_SEQUENCE, even if\n   the response would still\
    \ exceed ca_maxresponsesize.\n   If sa_cachethis or csa_cachethis is TRUE, then\
    \ the replier MUST cache\n   a reply except if an error is returned by the SEQUENCE\
    \ or CB_SEQUENCE\n   operation (see Section 2.10.6.1.2).  If the reply exceeds\n\
    \   ca_maxresponsesize_cached (and sa_cachethis or csa_cachethis is\n   TRUE),\
    \ then the server MUST return NFS4ERR_REP_TOO_BIG_TO_CACHE.\n   Even if NFS4ERR_REP_TOO_BIG_TO_CACHE\
    \ (or any other error for that\n   matter) is returned on an operation other than\
    \ the first operation\n   (SEQUENCE or CB_SEQUENCE), then the reply MUST be cached\
    \ if\n   sa_cachethis or csa_cachethis is TRUE.  For example, if a COMPOUND\n\
    \   has eleven operations, including SEQUENCE, the fifth operation is a\n   RENAME,\
    \ and the tenth operation is a READ for one million bytes, the\n   server may\
    \ return NFS4ERR_REP_TOO_BIG_TO_CACHE on the tenth\n   operation.  Since the server\
    \ executed several operations, especially\n   the non-idempotent RENAME, the client's\
    \ request to cache the reply\n   needs to be honored in order for the correct\
    \ operation of exactly\n   once semantics.  If the client retries the request,\
    \ the server will\n   have cached a reply that contains results for ten of the\
    \ eleven\n   requested operations, with the tenth operation having a status of\n\
    \   NFS4ERR_REP_TOO_BIG_TO_CACHE.\n   A client needs to take care that, when sending\
    \ operations that change\n   the current filehandle (except for PUTFH, PUTPUBFH,\
    \ PUTROOTFH, and\n   RESTOREFH), it does not exceed the maximum reply buffer before\
    \ the\n   GETFH operation.  Otherwise, the client will have to retry the\n   operation\
    \ that changed the current filehandle, in order to obtain the\n   desired filehandle.\
    \  For the OPEN operation (see Section 18.16),\n   retry is not always available\
    \ as an option.  The following guidelines\n   for the handling of filehandle-changing\
    \ operations are advised:\n   *  Within the same COMPOUND procedure, a client\
    \ SHOULD send GETFH\n      immediately after a current filehandle-changing operation.\
    \  A\n      client MUST send GETFH after a current filehandle-changing\n     \
    \ operation that is also non-idempotent (e.g., the OPEN operation),\n      unless\
    \ the operation is RESTOREFH.  RESTOREFH is an exception,\n      because even\
    \ though it is non-idempotent, the filehandle RESTOREFH\n      produced originated\
    \ from an operation that is either idempotent\n      (e.g., PUTFH, LOOKUP), or\
    \ non-idempotent (e.g., OPEN, CREATE).  If\n      the origin is non-idempotent,\
    \ then because the client MUST send\n      GETFH after the origin operation, the\
    \ client can recover if\n      RESTOREFH returns an error.\n   *  A server MAY\
    \ return NFS4ERR_REP_TOO_BIG or\n      NFS4ERR_REP_TOO_BIG_TO_CACHE (if sa_cachethis\
    \ is TRUE) on a\n      filehandle-changing operation if the reply would be too\
    \ large on\n      the next operation.\n   *  A server SHOULD return NFS4ERR_REP_TOO_BIG\
    \ or\n      NFS4ERR_REP_TOO_BIG_TO_CACHE (if sa_cachethis is TRUE) on a\n    \
    \  filehandle-changing, non-idempotent operation if the reply would\n      be\
    \ too large on the next operation, especially if the operation is\n      OPEN.\n\
    \   *  A server MAY return NFS4ERR_UNSAFE_COMPOUND to a non-idempotent\n     \
    \ current filehandle-changing operation, if it looks at the next\n      operation\
    \ (in the same COMPOUND procedure) and finds it is not\n      GETFH.  The server\
    \ SHOULD do this if it is unable to determine in\n      advance whether the total\
    \ response size would exceed\n      ca_maxresponsesize_cached or ca_maxresponsesize.\n"
- title: 2.10.6.5.  Persistence
  contents:
  - "2.10.6.5.  Persistence\n   Since the reply cache is bounded, it is practical\
    \ for the reply cache\n   to persist across server restarts.  The replier MUST\
    \ persist the\n   following information if it agreed to persist the session (when\
    \ the\n   session was created; see Section 18.36):\n   *  The session ID.\n  \
    \ *  The slot table including the sequence ID and cached reply for each\n    \
    \  slot.\n   The above are sufficient for a replier to provide EOS semantics for\n\
    \   any requests that were sent and executed before the server restarted.\n  \
    \ If the replier is a client, then there is no need for it to persist\n   any\
    \ more information, unless the client will be persisting all other\n   state across\
    \ client restart, in which case, the server will never see\n   any NFSv4.1-level\
    \ protocol manifestation of a client restart.  If the\n   replier is a server,\
    \ with just the slot table and session ID\n   persisting, any requests the client\
    \ retries after the server restart\n   will return the results that are cached\
    \ in the reply cache, and any\n   new requests (i.e., the sequence ID is one greater\
    \ than the slot's\n   sequence ID) MUST be rejected with NFS4ERR_DEADSESSION (returned\
    \ by\n   SEQUENCE).  Such a session is considered dead.  A server MAY re-\n  \
    \ animate a session after a server restart so that the session will\n   accept\
    \ new requests as well as retries.  To re-animate a session, the\n   server needs\
    \ to persist additional information through server\n   restart:\n   *  The client\
    \ ID.  This is a prerequisite to let the client create\n      more sessions associated\
    \ with the same client ID as the re-\n      animated session.\n   *  The client\
    \ ID's sequence ID that is used for creating sessions\n      (see Sections 18.35\
    \ and 18.36).  This is a prerequisite to let the\n      client create more sessions.\n\
    \   *  The principal that created the client ID.  This allows the server\n   \
    \   to authenticate the client when it sends EXCHANGE_ID.\n   *  The SSV, if SP4_SSV\
    \ state protection was specified when the client\n      ID was created (see Section\
    \ 18.35).  This lets the client create\n      new sessions, and associate connections\
    \ with the new and existing\n      sessions.\n   *  The properties of the client\
    \ ID as defined in Section 18.35.\n   A persistent reply cache places certain\
    \ demands on the server.  The\n   execution of the sequence of operations (starting\
    \ with SEQUENCE) and\n   placement of its results in the persistent cache MUST\
    \ be atomic.  If\n   a client retries a sequence of operations that was previously\n\
    \   executed on the server, the only acceptable outcomes are either the\n   original\
    \ cached reply or an indication that the client ID or session\n   has been lost\
    \ (indicating a catastrophic loss of the reply cache or a\n   session that has\
    \ been deleted because the client failed to use the\n   session for an extended\
    \ period of time).\n   A server could fail and restart in the middle of a COMPOUND\
    \ procedure\n   that contains one or more non-idempotent or idempotent-but-modifying\n\
    \   operations.  This creates an even higher challenge for atomic\n   execution\
    \ and placement of results in the reply cache.  One way to\n   view the problem\
    \ is as a single transaction consisting of each\n   operation in the COMPOUND\
    \ followed by storing the result in\n   persistent storage, then finally a transaction\
    \ commit.  If there is a\n   failure before the transaction is committed, then\
    \ the server rolls\n   back the transaction.  If the server itself fails, then\
    \ when it\n   restarts, its recovery logic could roll back the transaction before\n\
    \   starting the NFSv4.1 server.\n   While the description of the implementation\
    \ for atomic execution of\n   the request and caching of the reply is beyond the\
    \ scope of this\n   document, an example implementation for NFSv2 [45] is described\
    \ in\n   [46].\n"
- title: 2.10.7.  RDMA Considerations
  contents:
  - "2.10.7.  RDMA Considerations\n   A complete discussion of the operation of RPC-based\
    \ protocols over\n   RDMA transports is in [32].  A discussion of the operation\
    \ of NFSv4,\n   including NFSv4.1, over RDMA is in [33].  Where RDMA is considered,\n\
    \   this specification assumes the use of such a layering; it addresses\n   only\
    \ the upper-layer issues relevant to making best use of RPC/RDMA.\n"
- title: 2.10.7.1.  RDMA Connection Resources
  contents:
  - "2.10.7.1.  RDMA Connection Resources\n   RDMA requires its consumers to register\
    \ memory and post buffers of a\n   specific size and number for receive operations.\n\
    \   Registration of memory can be a relatively high-overhead operation,\n   since\
    \ it requires pinning of buffers, assignment of attributes (e.g.,\n   readable/writable),\
    \ and initialization of hardware translation.\n   Preregistration is desirable\
    \ to reduce overhead.  These registrations\n   are specific to hardware interfaces\
    \ and even to RDMA connection\n   endpoints; therefore, negotiation of their limits\
    \ is desirable to\n   manage resources effectively.\n   Following basic registration,\
    \ these buffers must be posted by the RPC\n   layer to handle receives.  These\
    \ buffers remain in use by the RPC/\n   NFSv4.1 implementation; the size and number\
    \ of them must be known to\n   the remote peer in order to avoid RDMA errors that\
    \ would cause a\n   fatal error on the RDMA connection.\n   NFSv4.1 manages slots\
    \ as resources on a per-session basis (see\n   Section 2.10), while RDMA connections\
    \ manage credits on a per-\n   connection basis.  This means that in order for\
    \ a peer to send data\n   over RDMA to a remote buffer, it has to have both an\
    \ NFSv4.1 slot and\n   an RDMA credit.  If multiple RDMA connections are associated\
    \ with a\n   session, then if the total number of credits across all RDMA\n  \
    \ connections associated with the session is X, and the number of slots\n   in\
    \ the session is Y, then the maximum number of outstanding requests\n   is the\
    \ lesser of X and Y.\n"
- title: 2.10.7.2.  Flow Control
  contents:
  - "2.10.7.2.  Flow Control\n   Previous versions of NFS do not provide flow control;\
    \ instead, they\n   rely on the windowing provided by transports like TCP to throttle\n\
    \   requests.  This does not work with RDMA, which provides no operation\n   flow\
    \ control and will terminate a connection in error when limits are\n   exceeded.\
    \  Limits such as maximum number of requests outstanding are\n   therefore negotiated\
    \ when a session is created (see the\n   ca_maxrequests field in Section 18.36).\
    \  These limits then provide\n   the maxima within which each connection associated\
    \ with the session's\n   channel(s) must remain.  RDMA connections are managed\
    \ within these\n   limits as described in Section 3.3 of [32]; if there are multiple\n\
    \   RDMA connections, then the maximum number of requests for a channel\n   will\
    \ be divided among the RDMA connections.  Put a different way, the\n   onus is\
    \ on the replier to ensure that the total number of RDMA\n   credits across all\
    \ connections associated with the replier's channel\n   does exceed the channel's\
    \ maximum number of outstanding requests.\n   The limits may also be modified\
    \ dynamically at the replier's choosing\n   by manipulating certain parameters\
    \ present in each NFSv4.1 reply.  In\n   addition, the CB_RECALL_SLOT callback\
    \ operation (see Section 20.8)\n   can be sent by a server to a client to return\
    \ RDMA credits to the\n   server, thereby lowering the maximum number of requests\
    \ a client can\n   have outstanding to the server.\n"
- title: 2.10.7.3.  Padding
  contents:
  - "2.10.7.3.  Padding\n   Header padding is requested by each peer at session initiation\
    \ (see\n   the ca_headerpadsize argument to CREATE_SESSION in Section 18.36),\n\
    \   and subsequently used by the RPC RDMA layer, as described in [32].\n   Zero\
    \ padding is permitted.\n   Padding leverages the useful property that RDMA preserve\
    \ alignment of\n   data, even when they are placed into anonymous (untagged) buffers.\n\
    \   If requested, client inline writes will insert appropriate pad bytes\n   within\
    \ the request header to align the data payload on the specified\n   boundary.\
    \  The client is encouraged to add sufficient padding (up to\n   the negotiated\
    \ size) so that the \"data\" field of the WRITE operation\n   is aligned.  Most\
    \ servers can make good use of such padding, which\n   allows them to chain receive\
    \ buffers in such a way that any data\n   carried by client requests will be placed\
    \ into appropriate buffers at\n   the server, ready for file system processing.\
    \  The receiver's RPC\n   layer encounters no overhead from skipping over pad\
    \ bytes, and the\n   RDMA layer's high performance makes the insertion and transmission\
    \ of\n   padding on the sender a significant optimization.  In this way, the\n\
    \   need for servers to perform RDMA Read to satisfy all but the largest\n   client\
    \ writes is obviated.  An added benefit is the reduction of\n   message round\
    \ trips on the network -- a potentially good trade, where\n   latency is present.\n\
    \   The value to choose for padding is subject to a number of criteria.\n   A\
    \ primary source of variable-length data in the RPC header is the\n   authentication\
    \ information, the form of which is client-determined,\n   possibly in response\
    \ to server specification.  The contents of\n   COMPOUNDs, sizes of strings such\
    \ as those passed to RENAME, etc. all\n   go into the determination of a maximal\
    \ NFSv4.1 request size and\n   therefore minimal buffer size.  The client must\
    \ select its offered\n   value carefully, so as to avoid overburdening the server,\
    \ and vice\n   versa.  The benefit of an appropriate padding value is higher\n\
    \   performance.\n                    Sender gather:\n        |RPC Request|Pad\
    \  bytes|Length| -> |User data...|\n                 \\    Receiver scatter: \
    \       \\-----------+- ...\n            |RPC Request|Pad|Length|   ->  |FS buffer|->|FS\
    \ buffer|->...\n   In the above case, the server may recycle unused buffers to\
    \ the next\n   posted receive if unused by the actual received request, or may\
    \ pass\n   the now-complete buffers by reference for normal write processing.\n\
    \   For a server that can make use of it, this removes any need for data\n   copies\
    \ of incoming data, without resorting to complicated end-to-end\n   buffer advertisement\
    \ and management.  This includes most kernel-based\n   and integrated server designs,\
    \ among many others.  The client may\n   perform similar optimizations, if desired.\n"
- title: 2.10.7.4.  Dual RDMA and Non-RDMA Transports
  contents:
  - "2.10.7.4.  Dual RDMA and Non-RDMA Transports\n   Some RDMA transports (e.g.,\
    \ RFC 5040 [8]) permit a \"streaming\" (non-\n   RDMA) phase, where ordinary traffic\
    \ might flow before \"stepping up\"\n   to RDMA mode, commencing RDMA traffic.\
    \  Some RDMA transports start\n   connections always in RDMA mode.  NFSv4.1 allows,\
    \ but does not\n   assume, a streaming phase before RDMA mode.  When a connection\
    \ is\n   associated with a session, the client and server negotiate whether\n\
    \   the connection is used in RDMA or non-RDMA mode (see Sections 18.36\n   and\
    \ 18.34).\n"
- title: 2.10.8.  Session Security
  contents:
  - '2.10.8.  Session Security

    '
- title: 2.10.8.1.  Session Callback Security
  contents:
  - "2.10.8.1.  Session Callback Security\n   Via session/connection association,\
    \ NFSv4.1 improves security over\n   that provided by NFSv4.0 for the backchannel.\
    \  The connection is\n   client-initiated (see Section 18.34) and subject to the\
    \ same firewall\n   and routing checks as the fore channel.  At the client's option\
    \ (see\n   Section 18.35), connection association is fully authenticated before\n\
    \   being activated (see Section 18.34).  Traffic from the server over\n   the\
    \ backchannel is authenticated exactly as the client specifies (see\n   Section\
    \ 2.10.8.2).\n"
- title: 2.10.8.2.  Backchannel RPC Security
  contents:
  - "2.10.8.2.  Backchannel RPC Security\n   When the NFSv4.1 client establishes the\
    \ backchannel, it informs the\n   server of the security flavors and principals\
    \ to use when sending\n   requests.  If the security flavor is RPCSEC_GSS, the\
    \ client expresses\n   the principal in the form of an established RPCSEC_GSS\
    \ context.  The\n   server is free to use any of the flavor/principal combinations\
    \ the\n   client offers, but it MUST NOT use unoffered combinations.  This way,\n\
    \   the client need not provide a target GSS principal for the\n   backchannel\
    \ as it did with NFSv4.0, nor does the server have to\n   implement an RPCSEC_GSS\
    \ initiator as it did with NFSv4.0 [37].\n   The CREATE_SESSION (Section 18.36)\
    \ and BACKCHANNEL_CTL\n   (Section 18.33) operations allow the client to specify\
    \ flavor/\n   principal combinations.\n   Also note that the SP4_SSV state protection\
    \ mode (see Sections 18.35\n   and 2.10.8.3) has the side benefit of providing\
    \ SSV-derived\n   RPCSEC_GSS contexts (Section 2.10.9).\n"
- title: 2.10.8.3.  Protection from Unauthorized State Changes
  contents:
  - "2.10.8.3.  Protection from Unauthorized State Changes\n   As described to this\
    \ point in the specification, the state model of\n   NFSv4.1 is vulnerable to\
    \ an attacker that sends a SEQUENCE operation\n   with a forged session ID and\
    \ with a slot ID that it expects the\n   legitimate client to use next.  When\
    \ the legitimate client uses the\n   slot ID with the same sequence number, the\
    \ server returns the\n   attacker's result from the reply cache, which disrupts\
    \ the legitimate\n   client and thus denies service to it.  Similarly, an attacker\
    \ could\n   send a CREATE_SESSION with a forged client ID to create a new session\n\
    \   associated with the client ID.  The attacker could send requests\n   using\
    \ the new session that change locking state, such as LOCKU\n   operations to release\
    \ locks the legitimate client has acquired.\n   Setting a security policy on the\
    \ file that requires RPCSEC_GSS\n   credentials when manipulating the file's state\
    \ is one potential work\n   around, but has the disadvantage of preventing a legitimate\
    \ client\n   from releasing state when RPCSEC_GSS is required to do so, but a\
    \ GSS\n   context cannot be obtained (possibly because the user has logged off\n\
    \   the client).\n   NFSv4.1 provides three options to a client for state protection,\n\
    \   which are specified when a client creates a client ID via EXCHANGE_ID\n  \
    \ (Section 18.35).\n   The first (SP4_NONE) is to simply waive state protection.\n\
    \   The other two options (SP4_MACH_CRED and SP4_SSV) share several\n   traits:\n\
    \   *  An RPCSEC_GSS-based credential is used to authenticate client ID\n    \
    \  and session maintenance operations, including creating and\n      destroying\
    \ a session, associating a connection with the session,\n      and destroying\
    \ the client ID.\n   *  Because RPCSEC_GSS is used to authenticate client ID and\
    \ session\n      maintenance, the attacker cannot associate a rogue connection\
    \ with\n      a legitimate session, or associate a rogue session with a\n    \
    \  legitimate client ID in order to maliciously alter the client ID's\n      lock\
    \ state via CLOSE, LOCKU, DELEGRETURN, LAYOUTRETURN, etc.\n   *  In cases where\
    \ the server's security policies on a portion of its\n      namespace require\
    \ RPCSEC_GSS authentication, a client may have to\n      use an RPCSEC_GSS credential\
    \ to remove per-file state (e.g.,\n      LOCKU, CLOSE, etc.).  The server may\
    \ require that the principal\n      that removes the state match certain criteria\
    \ (e.g., the principal\n      might have to be the same as the one that acquired\
    \ the state).\n      However, the client might not have an RPCSEC_GSS context\
    \ for such\n      a principal, and might not be able to create such a context\n\
    \      (perhaps because the user has logged off).  When the client\n      establishes\
    \ SP4_MACH_CRED or SP4_SSV protection, it can specify a\n      list of operations\
    \ that the server MUST allow using the machine\n      credential (if SP4_MACH_CRED\
    \ is used) or the SSV credential (if\n      SP4_SSV is used).\n   The SP4_MACH_CRED\
    \ state protection option uses a machine credential\n   where the principal that\
    \ creates the client ID MUST also be the\n   principal that performs client ID\
    \ and session maintenance operations.\n   The security of the machine credential\
    \ state protection approach\n   depends entirely on safeguarding the per-machine\
    \ credential.\n   Assuming a proper safeguard using the per-machine credential\
    \ for\n   operations like CREATE_SESSION, BIND_CONN_TO_SESSION,\n   DESTROY_SESSION,\
    \ and DESTROY_CLIENTID will prevent an attacker from\n   associating a rogue connection\
    \ with a session, or associating a rogue\n   session with a client ID.\n   There\
    \ are at least three scenarios for the SP4_MACH_CRED option:\n   1.  The system\
    \ administrator configures a unique, permanent per-\n       machine credential\
    \ for one of the mandated GSS mechanisms (e.g.,\n       if Kerberos V5 is used,\
    \ a \"keytab\" containing a principal derived\n       from a client host name\
    \ could be used).\n   2.  The client is used by a single user, and so the client\
    \ ID and its\n       sessions are used by just that user.  If the user's credential\n\
    \       expires, then session and client ID maintenance cannot occur, but\n  \
    \     since the client has a single user, only that user is\n       inconvenienced.\n\
    \   3.  The physical client has multiple users, but the client\n       implementation\
    \ has a unique client ID for each user.  This is\n       effectively the same\
    \ as the second scenario, but a disadvantage\n       is that each user needs to\
    \ be allocated at least one session\n       each, so the approach suffers from\
    \ lack of economy.\n   The SP4_SSV protection option uses the SSV (Section 1.7),\
    \ via\n   RPCSEC_GSS and the SSV GSS mechanism (Section 2.10.9), to protect\n\
    \   state from attack.  The SP4_SSV protection option is intended for the\n  \
    \ situation comprised of a client that has multiple active users and a\n   system\
    \ administrator who wants to avoid the burden of installing a\n   permanent machine\
    \ credential on each client.  The SSV is established\n   and updated on the server\
    \ via SET_SSV (see Section 18.47).  To\n   prevent eavesdropping, a client SHOULD\
    \ send SET_SSV via RPCSEC_GSS\n   with the privacy service.  Several aspects of\
    \ the SSV make it\n   intractable for an attacker to guess the SSV, and thus associate\n\
    \   rogue connections with a session, and rogue sessions with a client\n   ID:\n\
    \   *  The arguments to and results of SET_SSV include digests of the old\n  \
    \    and new SSV, respectively.\n   *  Because the initial value of the SSV is\
    \ zero, therefore known, the\n      client that opts for SP4_SSV protection and\
    \ opts to apply SP4_SSV\n      protection to BIND_CONN_TO_SESSION and CREATE_SESSION\
    \ MUST send at\n      least one SET_SSV operation before the first BIND_CONN_TO_SESSION\n\
    \      operation or before the second CREATE_SESSION operation on a\n      client\
    \ ID.  If it does not, the SSV mechanism will not generate\n      tokens (Section\
    \ 2.10.9).  A client SHOULD send SET_SSV as soon as\n      a session is created.\n\
    \   *  A SET_SSV request does not replace the SSV with the argument to\n     \
    \ SET_SSV.  Instead, the current SSV on the server is logically\n      exclusive\
    \ ORed (XORed) with the argument to SET_SSV.  Each time a\n      new principal\
    \ uses a client ID for the first time, the client\n      SHOULD send a SET_SSV\
    \ with that principal's RPCSEC_GSS\n      credentials, with RPCSEC_GSS service\
    \ set to RPC_GSS_SVC_PRIVACY.\n   Here are the types of attacks that can be attempted\
    \ by an attacker\n   named Eve on a victim named Bob, and how SP4_SSV protection\
    \ foils\n   each attack:\n   *  Suppose Eve is the first user to log into a legitimate\
    \ client.\n      Eve's use of an NFSv4.1 file system will cause the legitimate\n\
    \      client to create a client ID with SP4_SSV protection, specifying\n    \
    \  that the BIND_CONN_TO_SESSION operation MUST use the SSV\n      credential.\
    \  Eve's use of the file system also causes an SSV to be\n      created.  The\
    \ SET_SSV operation that creates the SSV will be\n      protected by the RPCSEC_GSS\
    \ context created by the legitimate\n      client, which uses Eve's GSS principal\
    \ and credentials.  Eve can\n      eavesdrop on the network while her RPCSEC_GSS\
    \ context is created\n      and the SET_SSV using her context is sent.  Even if\
    \ the legitimate\n      client sends the SET_SSV with RPC_GSS_SVC_PRIVACY, because\
    \ Eve\n      knows her own credentials, she can decrypt the SSV.  Eve can\n  \
    \    compute an RPCSEC_GSS credential that BIND_CONN_TO_SESSION will\n      accept,\
    \ and so associate a new connection with the legitimate\n      session.  Eve can\
    \ change the slot ID and sequence state of a\n      legitimate session, and/or\
    \ the SSV state, in such a way that when\n      Bob accesses the server via the\
    \ same legitimate client, the\n      legitimate client will be unable to use the\
    \ session.\n      The client's only recourse is to create a new client ID for\
    \ Bob to\n      use, and establish a new SSV for the client ID.  The client will\n\
    \      be unable to delete the old client ID, and will let the lease on\n    \
    \  the old client ID expire.\n      Once the legitimate client establishes an\
    \ SSV over the new session\n      using Bob's RPCSEC_GSS context, Eve can use\
    \ the new session via\n      the legitimate client, but she cannot disrupt Bob.\
    \  Moreover,\n      because the client SHOULD have modified the SSV due to Eve\
    \ using\n      the new session, Bob cannot get revenge on Eve by associating a\n\
    \      rogue connection with the session.\n      The question is how did the legitimate\
    \ client detect that Eve has\n      hijacked the old session?  When the client\
    \ detects that a new\n      principal, Bob, wants to use the session, it SHOULD\
    \ have sent a\n      SET_SSV, which leads to the following sub-scenarios:\n  \
    \    -  Let us suppose that from the rogue connection, Eve sent a\n         SET_SSV\
    \ with the same slot ID and sequence ID that the\n         legitimate client later\
    \ uses.  The server will assume the\n         SET_SSV sent with Bob's credentials\
    \ is a retry, and return to\n         the legitimate client the reply it sent\
    \ Eve.  However, unless\n         Eve can correctly guess the SSV the legitimate\
    \ client will use,\n         the digest verification checks in the SET_SSV response\
    \ will\n         fail.  That is an indication to the client that the session has\n\
    \         apparently been hijacked.\n      -  Alternatively, Eve sent a SET_SSV\
    \ with a different slot ID than\n         the legitimate client uses for its SET_SSV.\
    \  Then the digest\n         verification of the SET_SSV sent with Bob's credentials\
    \ fails\n         on the server, and the error returned to the client makes it\n\
    \         apparent that the session has been hijacked.\n      -  Alternatively,\
    \ Eve sent an operation other than SET_SSV, but\n         with the same slot ID\
    \ and sequence that the legitimate client\n         uses for its SET_SSV.  The\
    \ server returns to the legitimate\n         client the response it sent Eve.\
    \  The client sees that the\n         response is not at all what it expects.\
    \  The client assumes\n         either session hijacking or a server bug, and\
    \ either way\n         destroys the old session.\n   *  Eve associates a rogue\
    \ connection with the session as above, and\n      then destroys the session.\
    \  Again, Bob goes to use the server from\n      the legitimate client, which\
    \ sends a SET_SSV using Bob's\n      credentials.  The client receives an error\
    \ that indicates that the\n      session does not exist.  When the client tries\
    \ to create a new\n      session, this will fail because the SSV it has does not\
    \ match that\n      which the server has, and now the client knows the session\
    \ was\n      hijacked.  The legitimate client establishes a new client ID.\n \
    \  *  If Eve creates a connection before the legitimate client\n      establishes\
    \ an SSV, because the initial value of the SSV is zero\n      and therefore known,\
    \ Eve can send a SET_SSV that will pass the\n      digest verification check.\
    \  However, because the new connection\n      has not been associated with the\
    \ session, the SET_SSV is rejected\n      for that reason.\n   In summary, an\
    \ attacker's disruption of state when SP4_SSV protection\n   is in use is limited\
    \ to the formative period of a client ID, its\n   first session, and the establishment\
    \ of the SSV.  Once a non-\n   malicious user uses the client ID, the client quickly\
    \ detects any\n   hijack and rectifies the situation.  Once a non-malicious user\n\
    \   successfully modifies the SSV, the attacker cannot use NFSv4.1\n   operations\
    \ to disrupt the non-malicious user.\n   Note that neither the SP4_MACH_CRED nor\
    \ SP4_SSV protection approaches\n   prevent hijacking of a transport connection\
    \ that has previously been\n   associated with a session.  If the goal of a counter-threat\
    \ strategy\n   is to prevent connection hijacking, the use of IPsec is RECOMMENDED.\n\
    \   If a connection hijack occurs, the hijacker could in theory change\n   locking\
    \ state and negatively impact the service to legitimate\n   clients.  However,\
    \ if the server is configured to require the use of\n   RPCSEC_GSS with integrity\
    \ or privacy on the affected file objects,\n   and if EXCHGID4_FLAG_BIND_PRINC_STATEID\
    \ capability (Section 18.35) is\n   in force, this will thwart unauthorized attempts\
    \ to change locking\n   state.\n"
- title: 2.10.9.  The Secret State Verifier (SSV) GSS Mechanism
  contents:
  - "2.10.9.  The Secret State Verifier (SSV) GSS Mechanism\n   The SSV provides the\
    \ secret key for a GSS mechanism internal to\n   NFSv4.1 that NFSv4.1 uses for\
    \ state protection.  Contexts for this\n   mechanism are not established via the\
    \ RPCSEC_GSS protocol.  Instead,\n   the contexts are automatically created when\
    \ EXCHANGE_ID specifies\n   SP4_SSV protection.  The only tokens defined are the\
    \ PerMsgToken\n   (emitted by GSS_GetMIC) and the SealedMessage token (emitted\
    \ by\n   GSS_Wrap).\n   The mechanism OID for the SSV mechanism is\n   iso.org.dod.internet.private.enterprise.Michael\
    \ Eisler.nfs.ssv_mech\n   (1.3.6.1.4.1.28882.1.1).  While the SSV mechanism does\
    \ not define any\n   initial context tokens, the OID can be used to let servers\
    \ indicate\n   that the SSV mechanism is acceptable whenever the client sends\
    \ a\n   SECINFO or SECINFO_NO_NAME operation (see Section 2.6).\n   The SSV mechanism\
    \ defines four subkeys derived from the SSV value.\n   Each time SET_SSV is invoked,\
    \ the subkeys are recalculated by the\n   client and server.  The calculation\
    \ of each of the four subkeys\n   depends on each of the four respective ssv_subkey4\
    \ enumerated values.\n   The calculation uses the HMAC [52] algorithm, using the\
    \ current SSV\n   as the key, the one-way hash algorithm as negotiated by EXCHANGE_ID,\n\
    \   and the input text as represented by the XDR encoded enumeration\n   value\
    \ for that subkey of data type ssv_subkey4.  If the length of the\n   output of\
    \ the HMAC algorithm exceeds the length of key of the\n   encryption algorithm\
    \ (which is also negotiated by EXCHANGE_ID), then\n   the subkey MUST be truncated\
    \ from the HMAC output, i.e., if the\n   subkey is of N bytes long, then the first\
    \ N bytes of the HMAC output\n   MUST be used for the subkey.  The specification\
    \ of EXCHANGE_ID states\n   that the length of the output of the HMAC algorithm\
    \ MUST NOT be less\n   than the length of subkey needed for the encryption algorithm\
    \ (see\n   Section 18.35).\n   /* Input for computing subkeys */\n   enum ssv_subkey4\
    \ {\n           SSV4_SUBKEY_MIC_I2T     = 1,\n           SSV4_SUBKEY_MIC_T2I \
    \    = 2,\n           SSV4_SUBKEY_SEAL_I2T    = 3,\n           SSV4_SUBKEY_SEAL_T2I\
    \    = 4\n   };\n   The subkey derived from SSV4_SUBKEY_MIC_I2T is used for calculating\n\
    \   message integrity codes (MICs) that originate from the NFSv4.1\n   client,\
    \ whether as part of a request over the fore channel or a\n   response over the\
    \ backchannel.  The subkey derived from\n   SSV4_SUBKEY_MIC_T2I is used for MICs\
    \ originating from the NFSv4.1\n   server.  The subkey derived from SSV4_SUBKEY_SEAL_I2T\
    \ is used for\n   encryption text originating from the NFSv4.1 client, and the\
    \ subkey\n   derived from SSV4_SUBKEY_SEAL_T2I is used for encryption text\n \
    \  originating from the NFSv4.1 server.\n   The PerMsgToken description is based\
    \ on an XDR definition:\n   /* Input for computing smt_hmac */\n   struct ssv_mic_plain_tkn4\
    \ {\n     uint32_t        smpt_ssv_seq;\n     opaque          smpt_orig_plain<>;\n\
    \   };\n   /* SSV GSS PerMsgToken token */\n   struct ssv_mic_tkn4 {\n     uint32_t\
    \        smt_ssv_seq;\n     opaque          smt_hmac<>;\n   };\n   The field smt_hmac\
    \ is an HMAC calculated by using the subkey derived\n   from SSV4_SUBKEY_MIC_I2T\
    \ or SSV4_SUBKEY_MIC_T2I as the key, the one-\n   way hash algorithm as negotiated\
    \ by EXCHANGE_ID, and the input text\n   as represented by data of type ssv_mic_plain_tkn4.\
    \  The field\n   smpt_ssv_seq is the same as smt_ssv_seq.  The field smpt_orig_plain\n\
    \   is the \"message\" input passed to GSS_GetMIC() (see Section 2.3.1 of\n  \
    \ [7]).  The caller of GSS_GetMIC() provides a pointer to a buffer\n   containing\
    \ the plain text.  The SSV mechanism's entry point for\n   GSS_GetMIC() encodes\
    \ this into an opaque array, and the encoding will\n   include an initial four-byte\
    \ length, plus any necessary padding.\n   Prepended to this will be the XDR encoded\
    \ value of smpt_ssv_seq, thus\n   making up an XDR encoding of a value of data\
    \ type ssv_mic_plain_tkn4,\n   which in turn is the input into the HMAC.\n   The\
    \ token emitted by GSS_GetMIC() is XDR encoded and of XDR data type\n   ssv_mic_tkn4.\
    \  The field smt_ssv_seq comes from the SSV sequence\n   number, which is equal\
    \ to one after SET_SSV (Section 18.47) is called\n   the first time on a client\
    \ ID.  Thereafter, the SSV sequence number\n   is incremented on each SET_SSV.\
    \  Thus, smt_ssv_seq represents the\n   version of the SSV at the time GSS_GetMIC()\
    \ was called.  As noted in\n   Section 18.35, the client and server can maintain\
    \ multiple concurrent\n   versions of the SSV.  This allows the SSV to be changed\
    \ without\n   serializing all RPC calls that use the SSV mechanism with SET_SSV\n\
    \   operations.  Once the HMAC is calculated, it is XDR encoded into\n   smt_hmac,\
    \ which will include an initial four-byte length, and any\n   necessary padding.\
    \  Prepended to this will be the XDR encoded value\n   of smt_ssv_seq.\n   The\
    \ SealedMessage description is based on an XDR definition:\n   /* Input for computing\
    \ ssct_encr_data and ssct_hmac */\n   struct ssv_seal_plain_tkn4 {\n     opaque\
    \          sspt_confounder<>;\n     uint32_t        sspt_ssv_seq;\n     opaque\
    \          sspt_orig_plain<>;\n     opaque          sspt_pad<>;\n   };\n   /*\
    \ SSV GSS SealedMessage token */\n   struct ssv_seal_cipher_tkn4 {\n     uint32_t\
    \      ssct_ssv_seq;\n     opaque        ssct_iv<>;\n     opaque        ssct_encr_data<>;\n\
    \     opaque        ssct_hmac<>;\n   };\n   The token emitted by GSS_Wrap() is\
    \ XDR encoded and of XDR data type\n   ssv_seal_cipher_tkn4.\n   The ssct_ssv_seq\
    \ field has the same meaning as smt_ssv_seq.\n   The ssct_encr_data field is the\
    \ result of encrypting a value of the\n   XDR encoded data type ssv_seal_plain_tkn4.\
    \  The encryption key is the\n   subkey derived from SSV4_SUBKEY_SEAL_I2T or SSV4_SUBKEY_SEAL_T2I,\
    \ and\n   the encryption algorithm is that negotiated by EXCHANGE_ID.\n   The\
    \ ssct_iv field is the initialization vector (IV) for the\n   encryption algorithm\
    \ (if applicable) and is sent in clear text.  The\n   content and size of the\
    \ IV MUST comply with the specification of the\n   encryption algorithm.  For\
    \ example, the id-aes256-CBC algorithm MUST\n   use a 16-byte initialization vector\
    \ (IV), which MUST be unpredictable\n   for each instance of a value of data type\
    \ ssv_seal_plain_tkn4 that is\n   encrypted with a particular SSV key.\n   The\
    \ ssct_hmac field is the result of computing an HMAC using the\n   value of the\
    \ XDR encoded data type ssv_seal_plain_tkn4 as the input\n   text.  The key is\
    \ the subkey derived from SSV4_SUBKEY_MIC_I2T or\n   SSV4_SUBKEY_MIC_T2I, and\
    \ the one-way hash algorithm is that\n   negotiated by EXCHANGE_ID.\n   The sspt_confounder\
    \ field is a random value.\n   The sspt_ssv_seq field is the same as ssvt_ssv_seq.\n\
    \   The field sspt_orig_plain field is the original plaintext and is the\n   \"\
    input_message\" input passed to GSS_Wrap() (see Section 2.3.3 of\n   [7]).  As\
    \ with the handling of the plaintext by the SSV mechanism's\n   GSS_GetMIC() entry\
    \ point, the entry point for GSS_Wrap() expects a\n   pointer to the plaintext,\
    \ and will XDR encode an opaque array into\n   sspt_orig_plain representing the\
    \ plain text, along with the other\n   fields of an instance of data type ssv_seal_plain_tkn4.\n\
    \   The sspt_pad field is present to support encryption algorithms that\n   require\
    \ inputs to be in fixed-sized blocks.  The content of sspt_pad\n   is zero filled\
    \ except for the length.  Beware that the XDR encoding\n   of ssv_seal_plain_tkn4\
    \ contains three variable-length arrays, and so\n   each array consumes four bytes\
    \ for an array length, and each array\n   that follows the length is always padded\
    \ to a multiple of four bytes\n   per the XDR standard.\n   For example, suppose\
    \ the encryption algorithm uses 16-byte blocks,\n   and the sspt_confounder is\
    \ three bytes long, and the sspt_orig_plain\n   field is 15 bytes long.  The XDR\
    \ encoding of sspt_confounder uses\n   eight bytes (4 + 3 + 1-byte pad), the XDR\
    \ encoding of sspt_ssv_seq\n   uses four bytes, the XDR encoding of sspt_orig_plain\
    \ uses 20 bytes (4\n   + 15 + 1-byte pad), and the smallest XDR encoding of the\
    \ sspt_pad\n   field is four bytes.  This totals 36 bytes.  The next multiple\
    \ of 16\n   is 48; thus, the length field of sspt_pad needs to be set to 12\n\
    \   bytes, or a total encoding of 16 bytes.  The total number of XDR\n   encoded\
    \ bytes is thus 8 + 4 + 20 + 16 = 48.\n   GSS_Wrap() emits a token that is an\
    \ XDR encoding of a value of data\n   type ssv_seal_cipher_tkn4.  Note that regardless\
    \ of whether or not\n   the caller of GSS_Wrap() requests confidentiality, the\
    \ token always\n   has confidentiality.  This is because the SSV mechanism is\
    \ for\n   RPCSEC_GSS, and RPCSEC_GSS never produces GSS_wrap() tokens without\n\
    \   confidentiality.\n   There is one SSV per client ID.  There is a single GSS\
    \ context for a\n   client ID / SSV pair.  All SSV mechanism RPCSEC_GSS handles\
    \ of a\n   client ID / SSV pair share the same GSS context.  SSV GSS contexts\
    \ do\n   not expire except when the SSV is destroyed (causes would include the\n\
    \   client ID being destroyed or a server restart).  Since one purpose of\n  \
    \ context expiration is to replace keys that have been in use for \"too\n   long\"\
    , hence vulnerable to compromise by brute force or accident, the\n   client can\
    \ replace the SSV key by sending periodic SET_SSV\n   operations, which is done\
    \ by cycling through different users'\n   RPCSEC_GSS credentials.  This way, the\
    \ SSV is replaced without\n   destroying the SSV's GSS contexts.\n   SSV RPCSEC_GSS\
    \ handles can be expired or deleted by the server at any\n   time, and the EXCHANGE_ID\
    \ operation can be used to create more SSV\n   RPCSEC_GSS handles.  Expiration\
    \ of SSV RPCSEC_GSS handles does not\n   imply that the SSV or its GSS context\
    \ has expired.\n   The client MUST establish an SSV via SET_SSV before the SSV\
    \ GSS\n   context can be used to emit tokens from GSS_Wrap() and GSS_GetMIC().\n\
    \   If SET_SSV has not been successfully called, attempts to emit tokens\n   MUST\
    \ fail.\n   The SSV mechanism does not support replay detection and sequencing\
    \ in\n   its tokens because RPCSEC_GSS does not use those features (see\n   \"\
    Context Creation Requests\", Section 5.2.2 of [4]).  However,\n   Section 2.10.10\
    \ discusses special considerations for the SSV\n   mechanism when used with RPCSEC_GSS.\n"
- title: 2.10.10.  Security Considerations for RPCSEC_GSS When Using the SSV
  contents:
  - "2.10.10.  Security Considerations for RPCSEC_GSS When Using the SSV\n       \
    \   Mechanism\n   When a client ID is created with SP4_SSV state protection (see\n\
    \   Section 18.35), the client is permitted to associate multiple\n   RPCSEC_GSS\
    \ handles with the single SSV GSS context (see\n   Section 2.10.9).  Because of\
    \ the way RPCSEC_GSS (both version 1 and\n   version 2, see [4] and [9]) calculate\
    \ the verifier of the reply,\n   special care must be taken by the implementation\
    \ of the NFSv4.1\n   client to prevent attacks by a man-in-the-middle.  The verifier\
    \ of an\n   RPCSEC_GSS reply is the output of GSS_GetMIC() applied to the input\n\
    \   value of the seq_num field of the RPCSEC_GSS credential (data type\n   rpc_gss_cred_ver_1_t)\
    \ (see Section 5.3.3.2 of [4]).  If multiple\n   RPCSEC_GSS handles share the\
    \ same GSS context, then if one handle is\n   used to send a request with the\
    \ same seq_num value as another handle,\n   an attacker could block the reply,\
    \ and replace it with the verifier\n   used for the other handle.\n   There are\
    \ multiple ways to prevent the attack on the SSV RPCSEC_GSS\n   verifier in the\
    \ reply.  The simplest is believed to be as follows.\n   *  Each time one or more\
    \ new SSV RPCSEC_GSS handles are created via\n      EXCHANGE_ID, the client SHOULD\
    \ send a SET_SSV operation to modify\n      the SSV.  By changing the SSV, the\
    \ new handles will not result in\n      the re-use of an SSV RPCSEC_GSS verifier\
    \ in a reply.\n   *  When a requester decides to use N SSV RPCSEC_GSS handles,\
    \ it\n      SHOULD assign a unique and non-overlapping range of seq_nums to\n\
    \      each SSV RPCSEC_GSS handle.  The size of each range SHOULD be\n      equal\
    \ to MAXSEQ / N (see Section 5 of [4] for the definition of\n      MAXSEQ).  When\
    \ an SSV RPCSEC_GSS handle reaches its maximum, it\n      SHOULD force the replier\
    \ to destroy the handle by sending a NULL\n      RPC request with seq_num set\
    \ to MAXSEQ + 1 (see Section 5.3.3.3 of\n      [4]).\n   *  When the requester\
    \ wants to increase or decrease N, it SHOULD\n      force the replier to destroy\
    \ all N handles by sending a NULL RPC\n      request on each handle with seq_num\
    \ set to MAXSEQ + 1.  If the\n      requester is the client, it SHOULD send a\
    \ SET_SSV operation before\n      using new handles.  If the requester is the\
    \ server, then the\n      client SHOULD send a SET_SSV operation when it detects\
    \ that the\n      server has forced it to destroy a backchannel's SSV RPCSEC_GSS\n\
    \      handle.  By sending a SET_SSV operation, the SSV will change, and\n   \
    \   so the attacker will be unavailable to successfully replay a\n      previous\
    \ verifier in a reply to the requester.\n   Note that if the replier carefully\
    \ creates the SSV RPCSEC_GSS\n   handles, the related risk of a man-in-the-middle\
    \ splicing a forged\n   SSV RPCSEC_GSS credential with a verifier for another\
    \ handle does not\n   exist.  This is because the verifier in an RPCSEC_GSS request\
    \ is\n   computed from input that includes both the RPCSEC_GSS handle and\n  \
    \ seq_num (see Section 5.3.1 of [4]).  Provided the replier takes care\n   to\
    \ avoid re-using the value of an RPCSEC_GSS handle that it creates,\n   such as\
    \ by including a generation number in the handle, the man-in-\n   the-middle will\
    \ not be able to successfully replay a previous\n   verifier in the request to\
    \ a replier.\n"
- title: 2.10.11.  Session Mechanics - Steady State
  contents:
  - '2.10.11.  Session Mechanics - Steady State

    '
- title: 2.10.11.1.  Obligations of the Server
  contents:
  - "2.10.11.1.  Obligations of the Server\n   The server has the primary obligation\
    \ to monitor the state of\n   backchannel resources that the client has created\
    \ for the server\n   (RPCSEC_GSS contexts and backchannel connections).  If these\n\
    \   resources vanish, the server takes action as specified in\n   Section 2.10.13.2.\n"
- title: 2.10.11.2.  Obligations of the Client
  contents:
  - "2.10.11.2.  Obligations of the Client\n   The client SHOULD honor the following\
    \ obligations in order to utilize\n   the session:\n   *  Keep a necessary session\
    \ from going idle on the server.  A client\n      that requires a session but\
    \ nonetheless is not sending operations\n      risks having the session be destroyed\
    \ by the server.  This is\n      because sessions consume resources, and resource\
    \ limitations may\n      force the server to cull an inactive session.  A server\
    \ MAY\n      consider a session to be inactive if the client has not used the\n\
    \      session before the session inactivity timer (Section 2.10.12) has\n   \
    \   expired.\n   *  Destroy the session when not needed.  If a client has multiple\n\
    \      sessions, one of which has no requests waiting for replies, and\n     \
    \ has been idle for some period of time, it SHOULD destroy the\n      session.\n\
    \   *  Maintain GSS contexts and RPCSEC_GSS handles for the backchannel.\n   \
    \   If the client requires the server to use the RPCSEC_GSS security\n      flavor\
    \ for callbacks, then it needs to be sure the RPCSEC_GSS\n      handles and/or\
    \ their GSS contexts that are handed to the server\n      via BACKCHANNEL_CTL\
    \ or CREATE_SESSION are unexpired.\n   *  Preserve a connection for a backchannel.\
    \  The server requires a\n      backchannel in order to gracefully recall recallable\
    \ state or\n      notify the client of certain events.  Note that if the connection\n\
    \      is not being used for the fore channel, there is no way for the\n     \
    \ client to tell if the connection is still alive (e.g., the server\n      restarted\
    \ without sending a disconnect).  The onus is on the\n      server, not the client,\
    \ to determine if the backchannel's\n      connection is alive, and to indicate\
    \ in the response to a SEQUENCE\n      operation when the last connection associated\
    \ with a session's\n      backchannel has disconnected.\n"
- title: 2.10.11.3.  Steps the Client Takes to Establish a Session
  contents:
  - "2.10.11.3.  Steps the Client Takes to Establish a Session\n   If the client does\
    \ not have a client ID, the client sends EXCHANGE_ID\n   to establish a client\
    \ ID.  If it opts for SP4_MACH_CRED or SP4_SSV\n   protection, in the spo_must_enforce\
    \ list of operations, it SHOULD at\n   minimum specify CREATE_SESSION, DESTROY_SESSION,\n\
    \   BIND_CONN_TO_SESSION, BACKCHANNEL_CTL, and DESTROY_CLIENTID.  If it\n   opts\
    \ for SP4_SSV protection, the client needs to ask for SSV-based\n   RPCSEC_GSS\
    \ handles.\n   The client uses the client ID to send a CREATE_SESSION on a\n \
    \  connection to the server.  The results of CREATE_SESSION indicate\n   whether\
    \ or not the server will persist the session reply cache\n   through a server\
    \ that has restarted, and the client notes this for\n   future reference.\n  \
    \ If the client specified SP4_SSV state protection when the client ID\n   was\
    \ created, then it SHOULD send SET_SSV in the first COMPOUND after\n   the session\
    \ is created.  Each time a new principal goes to use the\n   client ID, it SHOULD\
    \ send a SET_SSV again.\n   If the client wants to use delegations, layouts, directory\n\
    \   notifications, or any other state that requires a backchannel, then\n   it\
    \ needs to add a connection to the backchannel if CREATE_SESSION did\n   not already\
    \ do so.  The client creates a connection, and calls\n   BIND_CONN_TO_SESSION\
    \ to associate the connection with the session and\n   the session's backchannel.\
    \  If CREATE_SESSION did not already do so,\n   the client MUST tell the server\
    \ what security is required in order\n   for the client to accept callbacks. \
    \ The client does this via\n   BACKCHANNEL_CTL.  If the client selected SP4_MACH_CRED\
    \ or SP4_SSV\n   protection when it called EXCHANGE_ID, then the client SHOULD\
    \ specify\n   that the backchannel use RPCSEC_GSS contexts for security.\n   If\
    \ the client wants to use additional connections for the\n   backchannel, then\
    \ it needs to call BIND_CONN_TO_SESSION on each\n   connection it wants to use\
    \ with the session.  If the client wants to\n   use additional connections for\
    \ the fore channel, then it needs to\n   call BIND_CONN_TO_SESSION if it specified\
    \ SP4_SSV or SP4_MACH_CRED\n   state protection when the client ID was created.\n\
    \   At this point, the session has reached steady state.\n"
- title: 2.10.12.  Session Inactivity Timer
  contents:
  - "2.10.12.  Session Inactivity Timer\n   The server MAY maintain a session inactivity\
    \ timer for each session.\n   If the session inactivity timer expires, then the\
    \ server MAY destroy\n   the session.  To avoid losing a session due to inactivity,\
    \ the client\n   MUST renew the session inactivity timer.  The length of session\n\
    \   inactivity timer MUST NOT be less than the lease_time attribute\n   (Section\
    \ 5.8.1.11).  As with lease renewal (Section 8.3), when the\n   server receives\
    \ a SEQUENCE operation, it resets the session\n   inactivity timer, and MUST NOT\
    \ allow the timer to expire while the\n   rest of the operations in the COMPOUND\
    \ procedure's request are still\n   executing.  Once the last operation has finished,\
    \ the server MUST set\n   the session inactivity timer to expire no sooner than\
    \ the sum of the\n   current time and the value of the lease_time attribute.\n"
- title: 2.10.13.  Session Mechanics - Recovery
  contents:
  - '2.10.13.  Session Mechanics - Recovery

    '
- title: 2.10.13.1.  Events Requiring Client Action
  contents:
  - "2.10.13.1.  Events Requiring Client Action\n   The following events require client\
    \ action to recover.\n"
- title: 2.10.13.1.1.  RPCSEC_GSS Context Loss by Callback Path
  contents:
  - "2.10.13.1.1.  RPCSEC_GSS Context Loss by Callback Path\n   If all RPCSEC_GSS\
    \ handles granted by the client to the server for\n   callback use have expired,\
    \ the client MUST establish a new handle via\n   BACKCHANNEL_CTL.  The sr_status_flags\
    \ field of the SEQUENCE results\n   indicates when callback handles are nearly\
    \ expired, or fully expired\n   (see Section 18.46.3).\n"
- title: 2.10.13.1.2.  Connection Loss
  contents:
  - "2.10.13.1.2.  Connection Loss\n   If the client loses the last connection of\
    \ the session and wants to\n   retain the session, then it needs to create a new\
    \ connection, and if,\n   when the client ID was created, BIND_CONN_TO_SESSION\
    \ was specified in\n   the spo_must_enforce list, the client MUST use BIND_CONN_TO_SESSION\n\
    \   to associate the connection with the session.\n   If there was a request outstanding\
    \ at the time of connection loss,\n   then if the client wants to continue to\
    \ use the session, it MUST\n   retry the request, as described in Section 2.10.6.2.\
    \  Note that it is\n   not necessary to retry requests over a connection with\
    \ the same\n   source network address or the same destination network address\
    \ as the\n   lost connection.  As long as the session ID, slot ID, and sequence\
    \ ID\n   in the retry match that of the original request, the server will\n  \
    \ recognize the request as a retry if it executed the request prior to\n   disconnect.\n\
    \   If the connection that was lost was the last one associated with the\n   backchannel,\
    \ and the client wants to retain the backchannel and/or\n   prevent revocation\
    \ of recallable state, the client needs to\n   reconnect, and if it does, it MUST\
    \ associate the connection to the\n   session and backchannel via BIND_CONN_TO_SESSION.\
    \  The server SHOULD\n   indicate when it has no callback connection via the sr_status_flags\n\
    \   result from SEQUENCE.\n"
- title: 2.10.13.1.3.  Backchannel GSS Context Loss
  contents:
  - "2.10.13.1.3.  Backchannel GSS Context Loss\n   Via the sr_status_flags result\
    \ of the SEQUENCE operation or other\n   means, the client will learn if some\
    \ or all of the RPCSEC_GSS\n   contexts it assigned to the backchannel have been\
    \ lost.  If the\n   client wants to retain the backchannel and/or not put recallable\n\
    \   state subject to revocation, the client needs to use BACKCHANNEL_CTL\n   to\
    \ assign new contexts.\n"
- title: 2.10.13.1.4.  Loss of Session
  contents:
  - "2.10.13.1.4.  Loss of Session\n   The replier might lose a record of the session.\
    \  Causes include:\n   *  Replier failure and restart.\n   *  A catastrophe that\
    \ causes the reply cache to be corrupted or lost\n      on the media on which\
    \ it was stored.  This applies even if the\n      replier indicated in the CREATE_SESSION\
    \ results that it would\n      persist the cache.\n   *  The server purges the\
    \ session of a client that has been inactive\n      for a very extended period\
    \ of time.\n   *  As a result of configuration changes among a set of clustered\n\
    \      servers, a network address previously connected to one server\n      becomes\
    \ connected to a different server that has no knowledge of\n      the session\
    \ in question.  Such a configuration change will\n      generally only happen\
    \ when the original server ceases to function\n      for a time.\n   Loss of reply\
    \ cache is equivalent to loss of session.  The replier\n   indicates loss of session\
    \ to the requester by returning\n   NFS4ERR_BADSESSION on the next operation that\
    \ uses the session ID\n   that refers to the lost session.\n   After an event\
    \ like a server restart, the client may have lost its\n   connections.  The client\
    \ assumes for the moment that the session has\n   not been lost.  It reconnects,\
    \ and if it specified connection\n   association enforcement when the session\
    \ was created, it invokes\n   BIND_CONN_TO_SESSION using the session ID.  Otherwise,\
    \ it invokes\n   SEQUENCE.  If BIND_CONN_TO_SESSION or SEQUENCE returns\n   NFS4ERR_BADSESSION,\
    \ the client knows the session is not available to\n   it when communicating with\
    \ that network address.  If the connection\n   survives session loss, then the\
    \ next SEQUENCE operation the client\n   sends over the connection will get back\
    \ NFS4ERR_BADSESSION.  The\n   client again knows the session was lost.\n   Here\
    \ is one suggested algorithm for the client when it gets\n   NFS4ERR_BADSESSION.\
    \  It is not obligatory in that, if a client does\n   not want to take advantage\
    \ of such features as trunking, it may omit\n   parts of it.  However, it is a\
    \ useful example that draws attention to\n   various possible recovery issues:\n\
    \   1.  If the client has other connections to other server network\n       addresses\
    \ associated with the same session, attempt a COMPOUND\n       with a single operation,\
    \ SEQUENCE, on each of the other\n       connections.\n   2.  If the attempts\
    \ succeed, the session is still alive, and this is\n       a strong indicator\
    \ that the server's network address has moved.\n       The client might send an\
    \ EXCHANGE_ID on the connection that\n       returned NFS4ERR_BADSESSION to see\
    \ if there are opportunities for\n       client ID trunking (i.e., the same client\
    \ ID and so_major_id\n       value are returned).  The client might use DNS to\
    \ see if the\n       moved network address was replaced with another, so that\
    \ the\n       performance and availability benefits of session trunking can\n\
    \       continue.\n   3.  If the SEQUENCE requests fail with NFS4ERR_BADSESSION,\
    \ then the\n       session no longer exists on any of the server network addresses\n\
    \       for which the client has connections associated with that session\n  \
    \     ID.  It is possible the session is still alive and available on\n      \
    \ other network addresses.  The client sends an EXCHANGE_ID on all\n       the\
    \ connections to see if the server owner is still listening on\n       those network\
    \ addresses.  If the same server owner is returned\n       but a new client ID\
    \ is returned, this is a strong indicator of a\n       server restart.  If both\
    \ the same server owner and same client ID\n       are returned, then this is\
    \ a strong indication that the server\n       did delete the session, and the\
    \ client will need to send a\n       CREATE_SESSION if it has no other sessions\
    \ for that client ID.\n       If a different server owner is returned, the client\
    \ can use DNS\n       to find other network addresses.  If it does not, or if\
    \ DNS does\n       not find any other addresses for the server, then the client\
    \ will\n       be unable to provide NFSv4.1 service, and fatal errors should be\n\
    \       returned to processes that were using the server.  If the client\n   \
    \    is using a \"mount\" paradigm, unmounting the server is advised.\n   4. \
    \ If the client knows of no other connections associated with the\n       session\
    \ ID and server network addresses that are, or have been,\n       associated with\
    \ the session ID, then the client can use DNS to\n       find other network addresses.\
    \  If it does not, or if DNS does not\n       find any other addresses for the\
    \ server, then the client will be\n       unable to provide NFSv4.1 service, and\
    \ fatal errors should be\n       returned to processes that were using the server.\
    \  If the client\n       is using a \"mount\" paradigm, unmounting the server\
    \ is advised.\n   If there is a reconfiguration event that results in the same\
    \ network\n   address being assigned to servers where the eir_server_scope value\
    \ is\n   different, it cannot be guaranteed that a session ID generated by the\n\
    \   first will be recognized as invalid by the first.  Therefore, in\n   managing\
    \ server reconfigurations among servers with different server\n   scope values,\
    \ it is necessary to make sure that all clients have\n   disconnected from the\
    \ first server before effecting the\n   reconfiguration.  Nonetheless, clients\
    \ should not assume that servers\n   will always adhere to this requirement; clients\
    \ MUST be prepared to\n   deal with unexpected effects of server reconfigurations.\
    \  Even where\n   a session ID is inappropriately recognized as valid, it is likely\n\
    \   either that the connection will not be recognized as valid or that a\n   sequence\
    \ value for a slot will not be correct.  Therefore, when a\n   client receives\
    \ results indicating such unexpected errors, the use of\n   EXCHANGE_ID to determine\
    \ the current server configuration is\n   RECOMMENDED.\n   A variation on the\
    \ above is that after a server's network address\n   moves, there is no NFSv4.1\
    \ server listening, e.g., no listener on\n   port 2049.  In this example, one\
    \ of the following occur: the NFSv4\n   server returns NFS4ERR_MINOR_VERS_MISMATCH,\
    \ the NFS server returns a\n   PROG_MISMATCH error, the RPC listener on 2049 returns\
    \ PROG_UNVAIL, or\n   attempts to reconnect to the network address timeout.  These\
    \ SHOULD\n   be treated as equivalent to SEQUENCE returning NFS4ERR_BADSESSION\
    \ for\n   these purposes.\n   When the client detects session loss, it needs to\
    \ call CREATE_SESSION\n   to recover.  Any non-idempotent operations that were\
    \ in progress\n   might have been performed on the server at the time of session\
    \ loss.\n   The client has no general way to recover from this.\n   Note that\
    \ loss of session does not imply loss of byte-range lock,\n   open, delegation,\
    \ or layout state because locks, opens, delegations,\n   and layouts are tied\
    \ to the client ID and depend on the client ID,\n   not the session.  Nor does\
    \ loss of byte-range lock, open, delegation,\n   or layout state imply loss of\
    \ session state, because the session\n   depends on the client ID; loss of client\
    \ ID however does imply loss\n   of session, byte-range lock, open, delegation,\
    \ and layout state.  See\n   Section 8.4.2.  A session can survive a server restart,\
    \ but lock\n   recovery may still be needed.\n   It is possible that CREATE_SESSION\
    \ will fail with\n   NFS4ERR_STALE_CLIENTID (e.g., the server restarts and does\
    \ not\n   preserve client ID state).  If so, the client needs to call\n   EXCHANGE_ID,\
    \ followed by CREATE_SESSION.\n"
- title: 2.10.13.2.  Events Requiring Server Action
  contents:
  - "2.10.13.2.  Events Requiring Server Action\n   The following events require server\
    \ action to recover.\n"
- title: 2.10.13.2.1.  Client Crash and Restart
  contents:
  - "2.10.13.2.1.  Client Crash and Restart\n   As described in Section 18.35, a restarted\
    \ client sends EXCHANGE_ID\n   in such a way that it causes the server to delete\
    \ any sessions it\n   had.\n"
- title: 2.10.13.2.2.  Client Crash with No Restart
  contents:
  - "2.10.13.2.2.  Client Crash with No Restart\n   If a client crashes and never\
    \ comes back, it will never send\n   EXCHANGE_ID with its old client owner.  Thus,\
    \ the server has session\n   state that will never be used again.  After an extended\
    \ period of\n   time, and if the server has resource constraints, it MAY destroy\
    \ the\n   old session as well as locking state.\n"
- title: 2.10.13.2.3.  Extended Network Partition
  contents:
  - "2.10.13.2.3.  Extended Network Partition\n   To the server, the extended network\
    \ partition may be no different\n   from a client crash with no restart (see Section\
    \ 2.10.13.2.2).\n   Unless the server can discern that there is a network partition,\
    \ it\n   is free to treat the situation as if the client has crashed\n   permanently.\n"
- title: 2.10.13.2.4.  Backchannel Connection Loss
  contents:
  - "2.10.13.2.4.  Backchannel Connection Loss\n   If there were callback requests\
    \ outstanding at the time of a\n   connection loss, then the server MUST retry\
    \ the requests, as\n   described in Section 2.10.6.2.  Note that it is not necessary\
    \ to\n   retry requests over a connection with the same source network address\n\
    \   or the same destination network address as the lost connection.  As\n   long\
    \ as the session ID, slot ID, and sequence ID in the retry match\n   that of the\
    \ original request, the callback target will recognize the\n   request as a retry\
    \ even if it did see the request prior to\n   disconnect.\n   If the connection\
    \ lost is the last one associated with the\n   backchannel, then the server MUST\
    \ indicate that in the\n   sr_status_flags field of every SEQUENCE reply until\
    \ the backchannel\n   is re-established.  There are two situations, each of which\
    \ uses\n   different status flags: no connectivity for the session's backchannel\n\
    \   and no connectivity for any session backchannel of the client.  See\n   Section\
    \ 18.46 for a description of the appropriate flags in\n   sr_status_flags.\n"
- title: 2.10.13.2.5.  GSS Context Loss
  contents:
  - "2.10.13.2.5.  GSS Context Loss\n   The server SHOULD monitor when the number\
    \ of RPCSEC_GSS handles\n   assigned to the backchannel reaches one, and when\
    \ that one handle is\n   near expiry (i.e., between one and two periods of lease\
    \ time), and\n   indicate so in the sr_status_flags field of all SEQUENCE replies.\n\
    \   The server MUST indicate when all of the backchannel's assigned\n   RPCSEC_GSS\
    \ handles have expired via the sr_status_flags field of all\n   SEQUENCE replies.\n"
- title: 2.10.14.  Parallel NFS and Sessions
  contents:
  - "2.10.14.  Parallel NFS and Sessions\n   A client and server can potentially be\
    \ a non-pNFS implementation, a\n   metadata server implementation, a data server\
    \ implementation, or two\n   or three types of implementations.  The EXCHGID4_FLAG_USE_NON_PNFS,\n\
    \   EXCHGID4_FLAG_USE_PNFS_MDS, and EXCHGID4_FLAG_USE_PNFS_DS flags (not\n   mutually\
    \ exclusive) are passed in the EXCHANGE_ID arguments and\n   results to allow\
    \ the client to indicate how it wants to use sessions\n   created under the client\
    \ ID, and to allow the server to indicate how\n   it will allow the sessions to\
    \ be used.  See Section 13.1 for pNFS\n   sessions considerations.\n"
- title: 3.  Protocol Constants and Data Types
  contents:
  - "3.  Protocol Constants and Data Types\n   The syntax and semantics to describe\
    \ the data types of the NFSv4.1\n   protocol are defined in the XDR (RFC 4506\
    \ [2]) and RPC (RFC 5531 [3])\n   documents.  The next sections build upon the\
    \ XDR data types to define\n   constants, types, and structures specific to this\
    \ protocol.  The full\n   list of XDR data types is in [10].\n"
- title: 3.1.  Basic Constants
  contents:
  - "3.1.  Basic Constants\n   const NFS4_FHSIZE               = 128;\n   const NFS4_VERIFIER_SIZE\
    \        = 8;\n   const NFS4_OPAQUE_LIMIT         = 1024;\n   const NFS4_SESSIONID_SIZE\
    \       = 16;\n   const NFS4_INT64_MAX            = 0x7fffffffffffffff;\n   const\
    \ NFS4_UINT64_MAX           = 0xffffffffffffffff;\n   const NFS4_INT32_MAX   \
    \         = 0x7fffffff;\n   const NFS4_UINT32_MAX           = 0xffffffff;\n  \
    \ const NFS4_MAXFILELEN           = 0xffffffffffffffff;\n   const NFS4_MAXFILEOFF\
    \           = 0xfffffffffffffffe;\n   Except where noted, all these constants\
    \ are defined in bytes.\n   *  NFS4_FHSIZE is the maximum size of a filehandle.\n\
    \   *  NFS4_VERIFIER_SIZE is the fixed size of a verifier.\n   *  NFS4_OPAQUE_LIMIT\
    \ is the maximum size of certain opaque\n      information.\n   *  NFS4_SESSIONID_SIZE\
    \ is the fixed size of a session identifier.\n   *  NFS4_INT64_MAX is the maximum\
    \ value of a signed 64-bit integer.\n   *  NFS4_UINT64_MAX is the maximum value\
    \ of an unsigned 64-bit\n      integer.\n   *  NFS4_INT32_MAX is the maximum value\
    \ of a signed 32-bit integer.\n   *  NFS4_UINT32_MAX is the maximum value of an\
    \ unsigned 32-bit\n      integer.\n   *  NFS4_MAXFILELEN is the maximum length\
    \ of a regular file.\n   *  NFS4_MAXFILEOFF is the maximum offset into a regular\
    \ file.\n"
- title: 3.2.  Basic Data Types
  contents:
  - "3.2.  Basic Data Types\n   These are the base NFSv4.1 data types.\n     | Data\
    \ Type     | Definition                                   |\n     | int32_t  \
    \     | typedef int int32_t;                         |\n     | uint32_t      |\
    \ typedef unsigned int uint32_t;               |\n     | int64_t       | typedef\
    \ hyper int64_t;                       |\n     | uint64_t      | typedef unsigned\
    \ hyper uint64_t;             |\n     | attrlist4     | typedef opaque attrlist4<>;\
    \                  |\n     |               | Used for file/directory attributes.\
    \          |\n     | bitmap4       | typedef uint32_t bitmap4<>;             \
    \     |\n     |               | Used in attribute array encoding.            |\n\
    \     | changeid4     | typedef uint64_t changeid4;                  |\n     |\
    \               | Used in the definition of change_info4.      |\n     | clientid4\
    \     | typedef uint64_t clientid4;                  |\n     |               |\
    \ Shorthand reference to client                |\n     |               | identification.\
    \                              |\n     | count4        | typedef uint32_t count4;\
    \                     |\n     |               | Various count parameters (READ,\
    \ WRITE,       |\n     |               | COMMIT).                            \
    \         |\n     | length4       | typedef uint64_t length4;                \
    \    |\n     |               | The length of a byte-range within a file.    |\n\
    \     | mode4         | typedef uint32_t mode4;                      |\n     |\
    \               | Mode attribute data type.                    |\n     | nfs_cookie4\
    \   | typedef uint64_t nfs_cookie4;                |\n     |               | Opaque\
    \ cookie value for READDIR.             |\n     | nfs_fh4       | typedef opaque\
    \ nfs_fh4<NFS4_FHSIZE>;         |\n     |               | Filehandle definition.\
    \                       |\n     | nfs_ftype4    | enum nfs_ftype4;           \
    \                  |\n     |               | Various defined file types.     \
    \             |\n     | nfsstat4      | enum nfsstat4;                       \
    \        |\n     |               | Return value for operations.              \
    \   |\n     | offset4       | typedef uint64_t offset4;                    |\n\
    \     |               | Various offset designations (READ, WRITE,    |\n     |\
    \               | LOCK, COMMIT).                               |\n     | qop4\
    \          | typedef uint32_t qop4;                       |\n     |          \
    \     | Quality of protection designation in         |\n     |               |\
    \ SECINFO.                                     |\n     | sec_oid4      | typedef\
    \ opaque sec_oid4<>;                   |\n     |               | Security Object\
    \ Identifier.  The sec_oid4    |\n     |               | data type is not really\
    \ opaque.  Instead, it |\n     |               | contains an ASN.1 OBJECT IDENTIFIER\
    \ as used  |\n     |               | by GSS-API in the mech_type argument to \
    \     |\n     |               | GSS_Init_sec_context.  See [7] for details.  |\n\
    \     | sequenceid4   | typedef uint32_t sequenceid4;                |\n     |\
    \               | Sequence number used for various session     |\n     |     \
    \          | operations (EXCHANGE_ID, CREATE_SESSION,     |\n     |          \
    \     | SEQUENCE, CB_SEQUENCE).                      |\n     | seqid4        |\
    \ typedef uint32_t seqid4;                     |\n     |               | Sequence\
    \ identifier used for locking.        |\n     | sessionid4    | typedef opaque\
    \                               |\n     |               | sessionid4[NFS4_SESSIONID_SIZE];\
    \             |\n     |               | Session identifier.                  \
    \        |\n     | slotid4       | typedef uint32_t slotid4;                 \
    \   |\n     |               | Sequencing artifact for various session      |\n\
    \     |               | operations (SEQUENCE, CB_SEQUENCE).          |\n     |\
    \ utf8string    | typedef opaque utf8string<>;                 |\n     |     \
    \          | UTF-8 encoding for strings.                  |\n     | utf8str_cis\
    \   | typedef utf8string utf8str_cis;              |\n     |               | Case-insensitive\
    \ UTF-8 string.               |\n     | utf8str_cs    | typedef utf8string utf8str_cs;\
    \               |\n     |               | Case-sensitive UTF-8 string.       \
    \          |\n     | utf8str_mixed | typedef utf8string utf8str_mixed;       \
    \     |\n     |               | UTF-8 strings with a case-sensitive prefix   |\n\
    \     |               | and a case-insensitive suffix.               |\n     |\
    \ component4    | typedef utf8str_cs component4;               |\n     |     \
    \          | Represents pathname components.              |\n     | linktext4\
    \     | typedef utf8str_cs linktext4;                |\n     |               |\
    \ Symbolic link contents (\"symbolic link\" is   |\n     |               | defined\
    \ in an Open Group [11] standard).     |\n     | pathname4     | typedef component4\
    \ pathname4<>;              |\n     |               | Represents pathname for\
    \ fs_locations.        |\n     | verifier4     | typedef opaque              \
    \                 |\n     |               | verifier4[NFS4_VERIFIER_SIZE];   \
    \            |\n     |               | Verifier used for various operations  \
    \       |\n     |               | (COMMIT, CREATE, EXCHANGE_ID, OPEN, READDIR,\
    \ |\n     |               | WRITE) NFS4_VERIFIER_SIZE is defined as 8.   |\n \
    \  End of Base Data Types\n"
- title: 3.3.  Structured Data Types
  contents:
  - '3.3.  Structured Data Types

    '
- title: 3.3.1.  nfstime4
  contents:
  - "3.3.1.  nfstime4\n   struct nfstime4 {\n           int64_t         seconds;\n\
    \           uint32_t        nseconds;\n   };\n   The nfstime4 data type gives\
    \ the number of seconds and nanoseconds\n   since midnight or zero hour January\
    \ 1, 1970 Coordinated Universal\n   Time (UTC).  Values greater than zero for\
    \ the seconds field denote\n   dates after the zero hour January 1, 1970.  Values\
    \ less than zero for\n   the seconds field denote dates before the zero hour January\
    \ 1, 1970.\n   In both cases, the nseconds field is to be added to the seconds\
    \ field\n   for the final time representation.  For example, if the time to be\n\
    \   represented is one-half second before zero hour January 1, 1970, the\n   seconds\
    \ field would have a value of negative one (-1) and the\n   nseconds field would\
    \ have a value of one-half second (500000000).\n   Values greater than 999,999,999\
    \ for nseconds are invalid.\n   This data type is used to pass time and date information.\
    \  A server\n   converts to and from its local representation of time when processing\n\
    \   time values, preserving as much accuracy as possible.  If the\n   precision\
    \ of timestamps stored for a file system object is less than\n   defined, loss\
    \ of precision can occur.  An adjunct time maintenance\n   protocol is RECOMMENDED\
    \ to reduce client and server time skew.\n"
- title: 3.3.2.  time_how4
  contents:
  - "3.3.2.  time_how4\n   enum time_how4 {\n           SET_TO_SERVER_TIME4 = 0,\n\
    \           SET_TO_CLIENT_TIME4 = 1\n   };\n"
- title: 3.3.3.  settime4
  contents:
  - "3.3.3.  settime4\n   union settime4 switch (time_how4 set_it) {\n    case SET_TO_CLIENT_TIME4:\n\
    \            nfstime4       time;\n    default:\n            void;\n   };\n  \
    \ The time_how4 and settime4 data types are used for setting timestamps\n   in\
    \ file object attributes.  If set_it is SET_TO_SERVER_TIME4, then\n   the server\
    \ uses its local representation of time for the time value.\n"
- title: 3.3.4.  specdata4
  contents:
  - "3.3.4.  specdata4\n   struct specdata4 {\n    uint32_t specdata1; /* major device\
    \ number */\n    uint32_t specdata2; /* minor device number */\n   };\n   This\
    \ data type represents the device numbers for the device file\n   types NF4CHR\
    \ and NF4BLK.\n"
- title: 3.3.5.  fsid4
  contents:
  - "3.3.5.  fsid4\n   struct fsid4 {\n           uint64_t        major;\n       \
    \    uint64_t        minor;\n   };\n"
- title: 3.3.6.  change_policy4
  contents:
  - "3.3.6.  change_policy4\n   struct change_policy4 {\n           uint64_t     \
    \   cp_major;\n           uint64_t        cp_minor;\n   };\n   The change_policy4\
    \ data type is used for the change_policy\n   RECOMMENDED attribute.  It provides\
    \ change sequencing indication\n   analogous to the change attribute.  To enable\
    \ the server to present a\n   value valid across server re-initialization without\
    \ requiring\n   persistent storage, two 64-bit quantities are used, allowing one\
    \ to\n   be a server instance ID and the second to be incremented non-\n   persistently,\
    \ within a given server instance.\n"
- title: 3.3.7.  fattr4
  contents:
  - "3.3.7.  fattr4\n   struct fattr4 {\n           bitmap4         attrmask;\n  \
    \         attrlist4       attr_vals;\n   };\n   The fattr4 data type is used to\
    \ represent file and directory\n   attributes.\n   The bitmap is a counted array\
    \ of 32-bit integers used to contain bit\n   values.  The position of the integer\
    \ in the array that contains bit n\n   can be computed from the expression (n\
    \ / 32), and its bit within that\n   integer is (n mod 32).\n                \
    \     0            1\n   |  count    | 31  ..  0 | 63  .. 32 |\n"
- title: 3.3.8.  change_info4
  contents:
  - "3.3.8.  change_info4\n   struct change_info4 {\n           bool            atomic;\n\
    \           changeid4       before;\n           changeid4       after;\n   };\n\
    \   This data type is used with the CREATE, LINK, OPEN, REMOVE, and\n   RENAME\
    \ operations to let the client know the value of the change\n   attribute for\
    \ the directory in which the target file system object\n   resides.\n"
- title: 3.3.9.  netaddr4
  contents:
  - "3.3.9.  netaddr4\n   struct netaddr4 {\n           /* see struct rpcb in RFC\
    \ 1833 */\n           string na_r_netid<>; /* network id */\n           string\
    \ na_r_addr<>;  /* universal address */\n   };\n   The netaddr4 data type is used\
    \ to identify network transport\n   endpoints.  The na_r_netid and na_r_addr fields\
    \ respectively contain\n   a netid and uaddr.  The netid and uaddr concepts are\
    \ defined in [12].\n   The netid and uaddr formats for TCP over IPv4 and TCP over\
    \ IPv6 are\n   defined in [12], specifically Tables 2 and 3 and in Sections 5.2.3.3\n\
    \   and 5.2.3.4.\n"
- title: 3.3.10.  state_owner4
  contents:
  - "3.3.10.  state_owner4\n   struct state_owner4 {\n           clientid4       clientid;\n\
    \           opaque          owner<NFS4_OPAQUE_LIMIT>;\n   };\n   typedef state_owner4\
    \ open_owner4;\n   typedef state_owner4 lock_owner4;\n   The state_owner4 data\
    \ type is the base type for the open_owner4\n   (Section 3.3.10.1) and lock_owner4\
    \ (Section 3.3.10.2).\n"
- title: 3.3.10.1.  open_owner4
  contents:
  - "3.3.10.1.  open_owner4\n   This data type is used to identify the owner of OPEN\
    \ state.\n"
- title: 3.3.10.2.  lock_owner4
  contents:
  - "3.3.10.2.  lock_owner4\n   This structure is used to identify the owner of byte-range\
    \ locking\n   state.\n"
- title: 3.3.11.  open_to_lock_owner4
  contents:
  - "3.3.11.  open_to_lock_owner4\n   struct open_to_lock_owner4 {\n           seqid4\
    \          open_seqid;\n           stateid4        open_stateid;\n           seqid4\
    \          lock_seqid;\n           lock_owner4     lock_owner;\n   };\n   This\
    \ data type is used for the first LOCK operation done for an\n   open_owner4.\
    \  It provides both the open_stateid and lock_owner, such\n   that the transition\
    \ is made from a valid open_stateid sequence to\n   that of the new lock_stateid\
    \ sequence.  Using this mechanism avoids\n   the confirmation of the lock_owner/lock_seqid\
    \ pair since it is tied\n   to established state in the form of the open_stateid/open_seqid.\n"
- title: 3.3.12.  stateid4
  contents:
  - "3.3.12.  stateid4\n   struct stateid4 {\n           uint32_t        seqid;\n\
    \           opaque          other[12];\n   };\n   This data type is used for the\
    \ various state sharing mechanisms\n   between the client and server.  The client\
    \ never modifies a value of\n   data type stateid.  The starting value of the\
    \ \"seqid\" field is\n   undefined.  The server is required to increment the \"\
    seqid\" field by\n   one at each transition of the stateid.  This is important\
    \ since the\n   client will inspect the seqid in OPEN stateids to determine the\
    \ order\n   of OPEN processing done by the server.\n"
- title: 3.3.13.  layouttype4
  contents:
  - "3.3.13.  layouttype4\n   enum layouttype4 {\n           LAYOUT4_NFSV4_1_FILES\
    \   = 0x1,\n           LAYOUT4_OSD2_OBJECTS    = 0x2,\n           LAYOUT4_BLOCK_VOLUME\
    \    = 0x3\n   };\n   This data type indicates what type of layout is being used.\
    \  The file\n   server advertises the layout types it supports through the\n \
    \  fs_layout_type file system attribute (Section 5.12.1).  A client asks\n   for\
    \ layouts of a particular type in LAYOUTGET, and processes those\n   layouts in\
    \ its layout-type-specific logic.\n   The layouttype4 data type is 32 bits in\
    \ length.  The range\n   represented by the layout type is split into three parts.\
    \  Type 0x0\n   is reserved.  Types within the range 0x00000001-0x7FFFFFFF are\n\
    \   globally unique and are assigned according to the description in\n   Section\
    \ 22.5; they are maintained by IANA.  Types within the range\n   0x80000000-0xFFFFFFFF\
    \ are site specific and for private use only.\n   The LAYOUT4_NFSV4_1_FILES enumeration\
    \ specifies that the NFSv4.1 file\n   layout type, as defined in Section 13, is\
    \ to be used.  The\n   LAYOUT4_OSD2_OBJECTS enumeration specifies that the object\
    \ layout, as\n   defined in [47], is to be used.  Similarly, the LAYOUT4_BLOCK_VOLUME\n\
    \   enumeration specifies that the block/volume layout, as defined in\n   [48],\
    \ is to be used.\n"
- title: 3.3.14.  deviceid4
  contents:
  - "3.3.14.  deviceid4\n   const NFS4_DEVICEID4_SIZE = 16;\n   typedef opaque  deviceid4[NFS4_DEVICEID4_SIZE];\n\
    \   Layout information includes device IDs that specify a storage device\n   through\
    \ a compact handle.  Addressing and type information is\n   obtained with the\
    \ GETDEVICEINFO operation.  Device IDs are not\n   guaranteed to be valid across\
    \ metadata server restarts.  A device ID\n   is unique per client ID and layout\
    \ type.  See Section 12.2.10 for\n   more details.\n"
- title: 3.3.15.  device_addr4
  contents:
  - "3.3.15.  device_addr4\n   struct device_addr4 {\n           layouttype4     \
    \        da_layout_type;\n           opaque                  da_addr_body<>;\n\
    \   };\n   The device address is used to set up a communication channel with the\n\
    \   storage device.  Different layout types will require different data\n   types\
    \ to define how they communicate with storage devices.  The\n   opaque da_addr_body\
    \ field is interpreted based on the specified\n   da_layout_type field.\n   This\
    \ document defines the device address for the NFSv4.1 file layout\n   (see Section\
    \ 13.3), which identifies a storage device by network IP\n   address and port\
    \ number.  This is sufficient for the clients to\n   communicate with the NFSv4.1\
    \ storage devices, and may be sufficient\n   for other layout types as well. \
    \ Device types for object-based\n   storage devices and block storage devices\
    \ (e.g., Small Computer\n   System Interface (SCSI) volume labels) are defined\
    \ by their\n   respective layout specifications.\n"
- title: 3.3.16.  layout_content4
  contents:
  - "3.3.16.  layout_content4\n   struct layout_content4 {\n           layouttype4\
    \ loc_type;\n           opaque      loc_body<>;\n   };\n   The loc_body field\
    \ is interpreted based on the layout type\n   (loc_type).  This document defines\
    \ the loc_body for the NFSv4.1 file\n   layout type; see Section 13.3 for its\
    \ definition.\n"
- title: 3.3.17.  layout4
  contents:
  - "3.3.17.  layout4\n   struct layout4 {\n           offset4                 lo_offset;\n\
    \           length4                 lo_length;\n           layoutiomode4     \
    \      lo_iomode;\n           layout_content4         lo_content;\n   };\n   The\
    \ layout4 data type defines a layout for a file.  The layout type\n   specific\
    \ data is opaque within lo_content.  Since layouts are sub-\n   dividable, the\
    \ offset and length together with the file's filehandle,\n   the client ID, iomode,\
    \ and layout type identify the layout.\n"
- title: 3.3.18.  layoutupdate4
  contents:
  - "3.3.18.  layoutupdate4\n   struct layoutupdate4 {\n           layouttype4   \
    \          lou_type;\n           opaque                  lou_body<>;\n   };\n\
    \   The layoutupdate4 data type is used by the client to return updated\n   layout\
    \ information to the metadata server via the LAYOUTCOMMIT\n   (Section 18.42)\
    \ operation.  This data type provides a channel to pass\n   layout type specific\
    \ information (in field lou_body) back to the\n   metadata server.  For example,\
    \ for the block/volume layout type, this\n   could include the list of reserved\
    \ blocks that were written.  The\n   contents of the opaque lou_body argument\
    \ are determined by the layout\n   type.  The NFSv4.1 file-based layout does not\
    \ use this data type; if\n   lou_type is LAYOUT4_NFSV4_1_FILES, the lou_body field\
    \ MUST have a\n   zero length.\n"
- title: 3.3.19.  layouthint4
  contents:
  - "3.3.19.  layouthint4\n   struct layouthint4 {\n           layouttype4       \
    \      loh_type;\n           opaque                  loh_body<>;\n   };\n   The\
    \ layouthint4 data type is used by the client to pass in a hint\n   about the\
    \ type of layout it would like created for a particular file.\n   It is the data\
    \ type specified by the layout_hint attribute described\n   in Section 5.12.4.\
    \  The metadata server may ignore the hint or may\n   selectively ignore fields\
    \ within the hint.  This hint should be\n   provided at create time as part of\
    \ the initial attributes within\n   OPEN.  The loh_body field is specific to the\
    \ type of layout\n   (loh_type).  The NFSv4.1 file-based layout uses the\n   nfsv4_1_file_layouthint4\
    \ data type as defined in Section 13.3.\n"
- title: 3.3.20.  layoutiomode4
  contents:
  - "3.3.20.  layoutiomode4\n   enum layoutiomode4 {\n           LAYOUTIOMODE4_READ\
    \      = 1,\n           LAYOUTIOMODE4_RW        = 2,\n           LAYOUTIOMODE4_ANY\
    \       = 3\n   };\n   The iomode specifies whether the client intends to just\
    \ read or both\n   read and write the data represented by the layout.  While the\n\
    \   LAYOUTIOMODE4_ANY iomode MUST NOT be used in the arguments to the\n   LAYOUTGET\
    \ operation, it MAY be used in the arguments to the\n   LAYOUTRETURN and CB_LAYOUTRECALL\
    \ operations.  The LAYOUTIOMODE4_ANY\n   iomode specifies that layouts pertaining\
    \ to both LAYOUTIOMODE4_READ\n   and LAYOUTIOMODE4_RW iomodes are being returned\
    \ or recalled,\n   respectively.  The metadata server's use of the iomode may\
    \ depend on\n   the layout type being used.  The storage devices MAY validate\
    \ I/O\n   accesses against the iomode and reject invalid accesses.\n"
- title: 3.3.21.  nfs_impl_id4
  contents:
  - "3.3.21.  nfs_impl_id4\n   struct nfs_impl_id4 {\n           utf8str_cis   nii_domain;\n\
    \           utf8str_cs    nii_name;\n           nfstime4      nii_date;\n   };\n\
    \   This data type is used to identify client and server implementation\n   details.\
    \  The nii_domain field is the DNS domain name with which the\n   implementor\
    \ is associated.  The nii_name field is the product name of\n   the implementation\
    \ and is completely free form.  It is RECOMMENDED\n   that the nii_name be used\
    \ to distinguish machine architecture,\n   machine platforms, revisions, versions,\
    \ and patch levels.  The\n   nii_date field is the timestamp of when the software\
    \ instance was\n   published or built.\n"
- title: 3.3.22.  threshold_item4
  contents:
  - "3.3.22.  threshold_item4\n   struct threshold_item4 {\n           layouttype4\
    \     thi_layout_type;\n           bitmap4         thi_hintset;\n           opaque\
    \          thi_hintlist<>;\n   };\n   This data type contains a list of hints\
    \ specific to a layout type for\n   helping the client determine when it should\
    \ send I/O directly through\n   the metadata server versus the storage devices.\
    \  The data type\n   consists of the layout type (thi_layout_type), a bitmap (thi_hintset)\n\
    \   describing the set of hints supported by the server (they may differ\n   based\
    \ on the layout type), and a list of hints (thi_hintlist) whose\n   content is\
    \ determined by the hintset bitmap.  See the mdsthreshold\n   attribute for more\
    \ details.\n   The thi_hintset field is a bitmap of the following values:\n  \
    \ | name                    | # | Data    | Description               |\n   |\
    \ threshold4_read_size    | 0 | length4 | If a file's length is     |\n   | threshold4_write_size\
    \   | 1 | length4 | If a file's length is     |\n   | threshold4_read_iosize \
    \ | 2 | length4 | For read I/O sizes        |\n   | threshold4_write_iosize |\
    \ 3 | length4 | For write I/O sizes       |\n"
- title: 3.3.23.  mdsthreshold4
  contents:
  - "3.3.23.  mdsthreshold4\n   struct mdsthreshold4 {\n           threshold_item4\
    \ mth_hints<>;\n   };\n   This data type holds an array of elements of data type\n\
    \   threshold_item4, each of which is valid for a particular layout type.\n  \
    \ An array is necessary because a server can support multiple layout\n   types\
    \ for a single file.\n"
- title: 4.  Filehandles
  contents:
  - "4.  Filehandles\n   The filehandle in the NFS protocol is a per-server unique\
    \ identifier\n   for a file system object.  The contents of the filehandle are\
    \ opaque\n   to the client.  Therefore, the server is responsible for translating\n\
    \   the filehandle to an internal representation of the file system\n   object.\n"
- title: 4.1.  Obtaining the First Filehandle
  contents:
  - "4.1.  Obtaining the First Filehandle\n   The operations of the NFS protocol are\
    \ defined in terms of one or\n   more filehandles.  Therefore, the client needs\
    \ a filehandle to\n   initiate communication with the server.  With the NFSv3\
    \ protocol (RFC\n   1813 [38]), there exists an ancillary protocol to obtain this\
    \ first\n   filehandle.  The MOUNT protocol, RPC program number 100005, provides\n\
    \   the mechanism of translating a string-based file system pathname to a\n  \
    \ filehandle, which can then be used by the NFS protocols.\n   The MOUNT protocol\
    \ has deficiencies in the area of security and use\n   via firewalls.  This is\
    \ one reason that the use of the public\n   filehandle was introduced in RFC 2054\
    \ [49] and RFC 2055 [50].  With\n   the use of the public filehandle in combination\
    \ with the LOOKUP\n   operation in the NFSv3 protocol, it has been demonstrated\
    \ that the\n   MOUNT protocol is unnecessary for viable interaction between NFS\n\
    \   client and server.\n   Therefore, the NFSv4.1 protocol will not use an ancillary\
    \ protocol\n   for translation from string-based pathnames to a filehandle.  Two\n\
    \   special filehandles will be used as starting points for the NFS\n   client.\n"
- title: 4.1.1.  Root Filehandle
  contents:
  - "4.1.1.  Root Filehandle\n   The first of the special filehandles is the ROOT\
    \ filehandle.  The\n   ROOT filehandle is the \"conceptual\" root of the file\
    \ system namespace\n   at the NFS server.  The client uses or starts with the\
    \ ROOT\n   filehandle by employing the PUTROOTFH operation.  The PUTROOTFH\n \
    \  operation instructs the server to set the \"current\" filehandle to the\n \
    \  ROOT of the server's file tree.  Once this PUTROOTFH operation is\n   used,\
    \ the client can then traverse the entirety of the server's file\n   tree with\
    \ the LOOKUP operation.  A complete discussion of the server\n   namespace is\
    \ in Section 7.\n"
- title: 4.1.2.  Public Filehandle
  contents:
  - "4.1.2.  Public Filehandle\n   The second special filehandle is the PUBLIC filehandle.\
    \  Unlike the\n   ROOT filehandle, the PUBLIC filehandle may be bound or represent\
    \ an\n   arbitrary file system object at the server.  The server is\n   responsible\
    \ for this binding.  It may be that the PUBLIC filehandle\n   and the ROOT filehandle\
    \ refer to the same file system object.\n   However, it is up to the administrative\
    \ software at the server and\n   the policies of the server administrator to define\
    \ the binding of the\n   PUBLIC filehandle and server file system object.  The\
    \ client may not\n   make any assumptions about this binding.  The client uses\
    \ the PUBLIC\n   filehandle via the PUTPUBFH operation.\n"
- title: 4.2.  Filehandle Types
  contents:
  - "4.2.  Filehandle Types\n   In the NFSv3 protocol, there was one type of filehandle\
    \ with a single\n   set of semantics.  This type of filehandle is termed \"persistent\"\
    \ in\n   NFSv4.1.  The semantics of a persistent filehandle remain the same as\n\
    \   before.  A new type of filehandle introduced in NFSv4.1 is the\n   \"volatile\"\
    \ filehandle, which attempts to accommodate certain server\n   environments.\n\
    \   The volatile filehandle type was introduced to address server\n   functionality\
    \ or implementation issues that make correct\n   implementation of a persistent\
    \ filehandle infeasible.  Some server\n   environments do not provide a file-system-level\
    \ invariant that can be\n   used to construct a persistent filehandle.  The underlying\
    \ server\n   file system may not provide the invariant or the server's file system\n\
    \   programming interfaces may not provide access to the needed\n   invariant.\
    \  Volatile filehandles may ease the implementation of\n   server functionality\
    \ such as hierarchical storage management or file\n   system reorganization or\
    \ migration.  However, the volatile filehandle\n   increases the implementation\
    \ burden for the client.\n   Since the client will need to handle persistent and\
    \ volatile\n   filehandles differently, a file attribute is defined that may be\
    \ used\n   by the client to determine the filehandle types being returned by the\n\
    \   server.\n"
- title: 4.2.1.  General Properties of a Filehandle
  contents:
  - "4.2.1.  General Properties of a Filehandle\n   The filehandle contains all the\
    \ information the server needs to\n   distinguish an individual file.  To the\
    \ client, the filehandle is\n   opaque.  The client stores filehandles for use\
    \ in a later request and\n   can compare two filehandles from the same server\
    \ for equality by\n   doing a byte-by-byte comparison.  However, the client MUST\
    \ NOT\n   otherwise interpret the contents of filehandles.  If two filehandles\n\
    \   from the same server are equal, they MUST refer to the same file.\n   Servers\
    \ SHOULD try to maintain a one-to-one correspondence between\n   filehandles and\
    \ files, but this is not required.  Clients MUST use\n   filehandle comparisons\
    \ only to improve performance, not for correct\n   behavior.  All clients need\
    \ to be prepared for situations in which it\n   cannot be determined whether two\
    \ filehandles denote the same object\n   and in such cases, avoid making invalid\
    \ assumptions that might cause\n   incorrect behavior.  Further discussion of\
    \ filehandle and attribute\n   comparison in the context of data caching is presented\
    \ in\n   Section 10.3.4.\n   As an example, in the case that two different pathnames\
    \ when\n   traversed at the server terminate at the same file system object, the\n\
    \   server SHOULD return the same filehandle for each path.  This can\n   occur\
    \ if a hard link (see [6]) is used to create two file names that\n   refer to\
    \ the same underlying file object and associated data.  For\n   example, if paths\
    \ /a/b/c and /a/d/c refer to the same file, the\n   server SHOULD return the same\
    \ filehandle for both pathnames'\n   traversals.\n"
- title: 4.2.2.  Persistent Filehandle
  contents:
  - "4.2.2.  Persistent Filehandle\n   A persistent filehandle is defined as having\
    \ a fixed value for the\n   lifetime of the file system object to which it refers.\
    \  Once the\n   server creates the filehandle for a file system object, the server\n\
    \   MUST accept the same filehandle for the object for the lifetime of\n   the\
    \ object.  If the server restarts, the NFS server MUST honor the\n   same filehandle\
    \ value as it did in the server's previous\n   instantiation.  Similarly, if the\
    \ file system is migrated, the new\n   NFS server MUST honor the same filehandle\
    \ as the old NFS server.\n   The persistent filehandle will be become stale or\
    \ invalid when the\n   file system object is removed.  When the server is presented\
    \ with a\n   persistent filehandle that refers to a deleted object, it MUST return\n\
    \   an error of NFS4ERR_STALE.  A filehandle may become stale when the\n   file\
    \ system containing the object is no longer available.  The file\n   system may\
    \ become unavailable if it exists on removable media and the\n   media is no longer\
    \ available at the server or the file system in\n   whole has been destroyed or\
    \ the file system has simply been removed\n   from the server's namespace (i.e.,\
    \ unmounted in a UNIX environment).\n"
- title: 4.2.3.  Volatile Filehandle
  contents:
  - "4.2.3.  Volatile Filehandle\n   A volatile filehandle does not share the same\
    \ longevity\n   characteristics of a persistent filehandle.  The server may determine\n\
    \   that a volatile filehandle is no longer valid at many different\n   points\
    \ in time.  If the server can definitively determine that a\n   volatile filehandle\
    \ refers to an object that has been removed, the\n   server should return NFS4ERR_STALE\
    \ to the client (as is the case for\n   persistent filehandles).  In all other\
    \ cases where the server\n   determines that a volatile filehandle can no longer\
    \ be used, it\n   should return an error of NFS4ERR_FHEXPIRED.\n   The REQUIRED\
    \ attribute \"fh_expire_type\" is used by the client to\n   determine what type\
    \ of filehandle the server is providing for a\n   particular file system.  This\
    \ attribute is a bitmask with the\n   following values:\n   FH4_PERSISTENT  The\
    \ value of FH4_PERSISTENT is used to indicate a\n      persistent filehandle,\
    \ which is valid until the object is removed\n      from the file system.  The\
    \ server will not return\n      NFS4ERR_FHEXPIRED for this filehandle.  FH4_PERSISTENT\
    \ is defined\n      as a value in which none of the bits specified below are set.\n\
    \   FH4_VOLATILE_ANY  The filehandle may expire at any time, except as\n     \
    \ specifically excluded (i.e., FH4_NO_EXPIRE_WITH_OPEN).\n   FH4_NOEXPIRE_WITH_OPEN\
    \  May only be set when FH4_VOLATILE_ANY is set.\n      If this bit is set, then\
    \ the meaning of FH4_VOLATILE_ANY is\n      qualified to exclude any expiration\
    \ of the filehandle when it is\n      open.\n   FH4_VOL_MIGRATION  The filehandle\
    \ will expire as a result of a file\n      system transition (migration or replication),\
    \ in those cases in\n      which the continuity of filehandle use is not specified\
    \ by handle\n      class information within the fs_locations_info attribute. \
    \ When\n      this bit is set, clients without access to fs_locations_info\n \
    \     information should assume that filehandles will expire on file\n      system\
    \ transitions.\n   FH4_VOL_RENAME  The filehandle will expire during rename. \
    \ This\n      includes a rename by the requesting client or a rename by any\n\
    \      other client.  If FH4_VOL_ANY is set, FH4_VOL_RENAME is redundant.\n  \
    \ Servers that provide volatile filehandles that can expire while open\n   require\
    \ special care as regards handling of RENAMEs and REMOVEs.\n   This situation\
    \ can arise if FH4_VOL_MIGRATION or FH4_VOL_RENAME is\n   set, if FH4_VOLATILE_ANY\
    \ is set and FH4_NOEXPIRE_WITH_OPEN is not\n   set, or if a non-read-only file\
    \ system has a transition target in a\n   different handle class.  In these cases,\
    \ the server should deny a\n   RENAME or REMOVE that would affect an OPEN file\
    \ of any of the\n   components leading to the OPEN file.  In addition, the server\
    \ should\n   deny all RENAME or REMOVE requests during the grace period, in order\n\
    \   to make sure that reclaims of files where filehandles may have\n   expired\
    \ do not do a reclaim for the wrong file.\n   Volatile filehandles are especially\
    \ suitable for implementation of\n   the pseudo file systems used to bridge exports.\
    \  See Section 7.5 for\n   a discussion of this.\n"
- title: 4.3.  One Method of Constructing a Volatile Filehandle
  contents:
  - "4.3.  One Method of Constructing a Volatile Filehandle\n   A volatile filehandle,\
    \ while opaque to the client, could contain:\n   [volatile bit = 1 | server boot\
    \ time | slot | generation number]\n   *  slot is an index in the server volatile\
    \ filehandle table\n   *  generation number is the generation number for the table\
    \ entry/\n      slot\n   When the client presents a volatile filehandle, the server\
    \ makes the\n   following checks, which assume that the check for the volatile\
    \ bit\n   has passed.  If the server boot time is less than the current server\n\
    \   boot time, return NFS4ERR_FHEXPIRED.  If slot is out of range, return\n  \
    \ NFS4ERR_BADHANDLE.  If the generation number does not match, return\n   NFS4ERR_FHEXPIRED.\n\
    \   When the server restarts, the table is gone (it is volatile).\n   If the volatile\
    \ bit is 0, then it is a persistent filehandle with a\n   different structure\
    \ following it.\n"
- title: 4.4.  Client Recovery from Filehandle Expiration
  contents:
  - "4.4.  Client Recovery from Filehandle Expiration\n   If possible, the client\
    \ SHOULD recover from the receipt of an\n   NFS4ERR_FHEXPIRED error.  The client\
    \ must take on additional\n   responsibility so that it may prepare itself to\
    \ recover from the\n   expiration of a volatile filehandle.  If the server returns\n\
    \   persistent filehandles, the client does not need these additional\n   steps.\n\
    \   For volatile filehandles, most commonly the client will need to store\n  \
    \ the component names leading up to and including the file system\n   object in\
    \ question.  With these names, the client should be able to\n   recover by finding\
    \ a filehandle in the namespace that is still\n   available or by starting at\
    \ the root of the server's file system\n   namespace.\n   If the expired filehandle\
    \ refers to an object that has been removed\n   from the file system, obviously\
    \ the client will not be able to\n   recover from the expired filehandle.\n  \
    \ It is also possible that the expired filehandle refers to a file that\n   has\
    \ been renamed.  If the file was renamed by another client, again\n   it is possible\
    \ that the original client will not be able to recover.\n   However, in the case\
    \ that the client itself is renaming the file and\n   the file is open, it is\
    \ possible that the client may be able to\n   recover.  The client can determine\
    \ the new pathname based on the\n   processing of the rename request.  The client\
    \ can then regenerate the\n   new filehandle based on the new pathname.  The client\
    \ could also use\n   the COMPOUND procedure to construct a series of operations\
    \ like:\n             RENAME A B\n             LOOKUP B\n             GETFH\n\
    \   Note that the COMPOUND procedure does not provide atomicity.  This\n   example\
    \ only reduces the overhead of recovering from an expired\n   filehandle.\n"
- title: 5.  File Attributes
  contents:
  - "5.  File Attributes\n   To meet the requirements of extensibility and increased\n\
    \   interoperability with non-UNIX platforms, attributes need to be\n   handled\
    \ in a flexible manner.  The NFSv3 fattr3 structure contains a\n   fixed list\
    \ of attributes that not all clients and servers are able to\n   support or care\
    \ about.  The fattr3 structure cannot be extended as\n   new needs arise and it\
    \ provides no way to indicate non-support.  With\n   the NFSv4.1 protocol, the\
    \ client is able to query what attributes the\n   server supports and construct\
    \ requests with only those supported\n   attributes (or a subset thereof).\n \
    \  To this end, attributes are divided into three groups: REQUIRED,\n   RECOMMENDED,\
    \ and named.  Both REQUIRED and RECOMMENDED attributes are\n   supported in the\
    \ NFSv4.1 protocol by a specific and well-defined\n   encoding and are identified\
    \ by number.  They are requested by setting\n   a bit in the bit vector sent in\
    \ the GETATTR request; the server\n   response includes a bit vector to list what\
    \ attributes were returned\n   in the response.  New REQUIRED or RECOMMENDED attributes\
    \ may be added\n   to the NFSv4 protocol as part of a new minor version by publishing\
    \ a\n   Standards Track RFC that allocates a new attribute number value and\n\
    \   defines the encoding for the attribute.  See Section 2.7 for further\n   discussion.\n\
    \   Named attributes are accessed by the new OPENATTR operation, which\n   accesses\
    \ a hidden directory of attributes associated with a file\n   system object. \
    \ OPENATTR takes a filehandle for the object and\n   returns the filehandle for\
    \ the attribute hierarchy.  The filehandle\n   for the named attributes is a directory\
    \ object accessible by LOOKUP\n   or READDIR and contains files whose names represent\
    \ the named\n   attributes and whose data bytes are the value of the attribute.\
    \  For\n   example:\n        | LOOKUP   | \"foo\"     | ; look up file       \
    \           |\n        | GETATTR  | attrbits  |                              \
    \   |\n        | OPENATTR |           | ; access foo's named attributes |\n  \
    \      | LOOKUP   | \"x11icon\" | ; look up specific attribute    |\n        |\
    \ READ     | 0,4096    | ; read stream of bytes          |\n   Named attributes\
    \ are intended for data needed by applications rather\n   than by an NFS client\
    \ implementation.  NFS implementors are strongly\n   encouraged to define their\
    \ new attributes as RECOMMENDED attributes\n   by bringing them to the IETF Standards\
    \ Track process.\n   The set of attributes that are classified as REQUIRED is\
    \ deliberately\n   small since servers need to do whatever it takes to support\
    \ them.  A\n   server should support as many of the RECOMMENDED attributes as\n\
    \   possible but, by their definition, the server is not required to\n   support\
    \ all of them.  Attributes are deemed REQUIRED if the data is\n   both needed\
    \ by a large number of clients and is not otherwise\n   reasonably computable\
    \ by the client when support is not provided on\n   the server.\n   Note that\
    \ the hidden directory returned by OPENATTR is a convenience\n   for protocol\
    \ processing.  The client should not make any assumptions\n   about the server's\
    \ implementation of named attributes and whether or\n   not the underlying file\
    \ system at the server has a named attribute\n   directory.  Therefore, operations\
    \ such as SETATTR and GETATTR on the\n   named attribute directory are undefined.\n"
- title: 5.1.  REQUIRED Attributes
  contents:
  - "5.1.  REQUIRED Attributes\n   These MUST be supported by every NFSv4.1 client\
    \ and server in order\n   to ensure a minimum level of interoperability.  The\
    \ server MUST store\n   and return these attributes, and the client MUST be able\
    \ to function\n   with an attribute set limited to these attributes.  With just\
    \ the\n   REQUIRED attributes some client functionality may be impaired or\n \
    \  limited in some ways.  A client may ask for any of these attributes\n   to\
    \ be returned by setting a bit in the GETATTR request, and the\n   server MUST\
    \ return their value.\n"
- title: 5.2.  RECOMMENDED Attributes
  contents:
  - "5.2.  RECOMMENDED Attributes\n   These attributes are understood well enough\
    \ to warrant support in the\n   NFSv4.1 protocol.  However, they may not be supported\
    \ on all clients\n   and servers.  A client may ask for any of these attributes\
    \ to be\n   returned by setting a bit in the GETATTR request but must handle the\n\
    \   case where the server does not return them.  A client MAY ask for the\n  \
    \ set of attributes the server supports and SHOULD NOT request\n   attributes\
    \ the server does not support.  A server should be tolerant\n   of requests for\
    \ unsupported attributes and simply not return them\n   rather than considering\
    \ the request an error.  It is expected that\n   servers will support all attributes\
    \ they comfortably can and only\n   fail to support attributes that are difficult\
    \ to support in their\n   operating environments.  A server should provide attributes\
    \ whenever\n   they don't have to \"tell lies\" to the client.  For example, a\
    \ file\n   modification time should be either an accurate time or should not be\n\
    \   supported by the server.  At times this will be difficult for\n   clients,\
    \ but a client is better positioned to decide whether and how\n   to fabricate\
    \ or construct an attribute or whether to do without the\n   attribute.\n"
- title: 5.3.  Named Attributes
  contents:
  - "5.3.  Named Attributes\n   These attributes are not supported by direct encoding\
    \ in the NFSv4\n   protocol but are accessed by string names rather than numbers\
    \ and\n   correspond to an uninterpreted stream of bytes that are stored with\n\
    \   the file system object.  The namespace for these attributes may be\n   accessed\
    \ by using the OPENATTR operation.  The OPENATTR operation\n   returns a filehandle\
    \ for a virtual \"named attribute directory\", and\n   further perusal and modification\
    \ of the namespace may be done using\n   operations that work on more typical\
    \ directories.  In particular,\n   READDIR may be used to get a list of such named\
    \ attributes, and\n   LOOKUP and OPEN may select a particular attribute.  Creation\
    \ of a new\n   named attribute may be the result of an OPEN specifying file\n\
    \   creation.\n   Once an OPEN is done, named attributes may be examined and changed\
    \ by\n   normal READ and WRITE operations using the filehandles and stateids\n\
    \   returned by OPEN.\n   Named attributes and the named attribute directory may\
    \ have their own\n   (non-named) attributes.  Each of these objects MUST have\
    \ all of the\n   REQUIRED attributes and may have additional RECOMMENDED attributes.\n\
    \   However, the set of attributes for named attributes and the named\n   attribute\
    \ directory need not be, and typically will not be, as large\n   as that for other\
    \ objects in that file system.\n   Named attributes and the named attribute directory\
    \ might be the\n   target of delegations (in the case of the named attribute directory,\n\
    \   these will be directory delegations).  However, since granting of\n   delegations\
    \ is at the server's discretion, a server need not support\n   delegations on\
    \ named attributes or the named attribute directory.\n   It is RECOMMENDED that\
    \ servers support arbitrary named attributes.  A\n   client should not depend\
    \ on the ability to store any named attributes\n   in the server's file system.\
    \  If a server does support named\n   attributes, a client that is also able to\
    \ handle them should be able\n   to copy a file's data and metadata with complete\
    \ transparency from\n   one location to another; this would imply that names allowed\
    \ for\n   regular directory entries are valid for named attribute names as\n \
    \  well.\n   In NFSv4.1, the structure of named attribute directories is\n   restricted\
    \ in a number of ways, in order to prevent the development\n   of non-interoperable\
    \ implementations in which some servers support a\n   fully general hierarchical\
    \ directory structure for named attributes\n   while others support a limited\
    \ but adequate structure for named\n   attributes.  In such an environment, clients\
    \ or applications might\n   come to depend on non-portable extensions.  The restrictions\
    \ are:\n   *  CREATE is not allowed in a named attribute directory.  Thus, such\n\
    \      objects as symbolic links and special files are not allowed to be\n   \
    \   named attributes.  Further, directories may not be created in a\n      named\
    \ attribute directory, so no hierarchical structure of named\n      attributes\
    \ for a single object is allowed.\n   *  If OPENATTR is done on a named attribute\
    \ directory or on a named\n      attribute, the server MUST return NFS4ERR_WRONG_TYPE.\n\
    \   *  Doing a RENAME of a named attribute to a different named attribute\n  \
    \    directory or to an ordinary (i.e., non-named-attribute) directory\n     \
    \ is not allowed.\n   *  Creating hard links between named attribute directories\
    \ or between\n      named attribute directories and ordinary directories is not\n\
    \      allowed.\n   Names of attributes will not be controlled by this document\
    \ or other\n   IETF Standards Track documents.  See Section 22.2 for further\n\
    \   discussion.\n"
- title: 5.4.  Classification of Attributes
  contents:
  - "5.4.  Classification of Attributes\n   Each of the REQUIRED and RECOMMENDED attributes\
    \ can be classified in\n   one of three categories: per server (i.e., the value\
    \ of the attribute\n   will be the same for all file objects that share the same\
    \ server\n   owner; see Section 2.5 for a definition of server owner), per file\n\
    \   system (i.e., the value of the attribute will be the same for some or\n  \
    \ all file objects that share the same fsid attribute (Section 5.8.1.9)\n   and\
    \ server owner), or per file system object.  Note that it is\n   possible that\
    \ some per file system attributes may vary within the\n   file system, depending\
    \ on the value of the \"homogeneous\"\n   (Section 5.8.2.16) attribute.  Note\
    \ that the attributes\n   time_access_set and time_modify_set are not listed in\
    \ this section\n   because they are write-only attributes corresponding to time_access\n\
    \   and time_modify, and are used in a special instance of SETATTR.\n   *  The\
    \ per-server attribute is:\n         lease_time\n   *  The per-file system attributes\
    \ are:\n         supported_attrs, suppattr_exclcreat, fh_expire_type,\n      \
    \   link_support, symlink_support, unique_handles, aclsupport,\n         cansettime,\
    \ case_insensitive, case_preserving,\n         chown_restricted, files_avail,\
    \ files_free, files_total,\n         fs_locations, homogeneous, maxfilesize, maxname,\
    \ maxread,\n         maxwrite, no_trunc, space_avail, space_free, space_total,\n\
    \         time_delta, change_policy, fs_status, fs_layout_type,\n         fs_locations_info,\
    \ fs_charset_cap\n   *  The per-file system object attributes are:\n         type,\
    \ change, size, named_attr, fsid, rdattr_error, filehandle,\n         acl, archive,\
    \ fileid, hidden, maxlink, mimetype, mode,\n         numlinks, owner, owner_group,\
    \ rawdev, space_used, system,\n         time_access, time_backup, time_create,\
    \ time_metadata,\n         time_modify, mounted_on_fileid, dir_notif_delay,\n\
    \         dirent_notif_delay, dacl, sacl, layout_type, layout_hint,\n        \
    \ layout_blksize, layout_alignment, mdsthreshold, retention_get,\n         retention_set,\
    \ retentevt_get, retentevt_set, retention_hold,\n         mode_set_masked\n  \
    \ For quota_avail_hard, quota_avail_soft, and quota_used, see their\n   definitions\
    \ below for the appropriate classification.\n"
- title: 5.5.  Set-Only and Get-Only Attributes
  contents:
  - "5.5.  Set-Only and Get-Only Attributes\n   Some REQUIRED and RECOMMENDED attributes\
    \ are set-only; i.e., they can\n   be set via SETATTR but not retrieved via GETATTR.\
    \  Similarly, some\n   REQUIRED and RECOMMENDED attributes are get-only; i.e.,\
    \ they can be\n   retrieved via GETATTR but not set via SETATTR.  If a client\
    \ attempts\n   to set a get-only attribute or get a set-only attributes, the server\n\
    \   MUST return NFS4ERR_INVAL.\n"
- title: 5.6.  REQUIRED Attributes - List and Definition References
  contents:
  - "5.6.  REQUIRED Attributes - List and Definition References\n   The list of REQUIRED\
    \ attributes appears in Table 4.  The meaning of\n   the columns of the table\
    \ are:\n   Name:  The name of the attribute.\n   Id:  The number assigned to the\
    \ attribute.  In the event of conflicts\n      between the assigned number and\
    \ [10], the latter is likely\n      authoritative, but should be resolved with\
    \ Errata to this document\n      and/or [10].  See [51] for the Errata process.\n\
    \   Data Type:  The XDR data type of the attribute.\n   Acc:  Access allowed to\
    \ the attribute.  R means read-only (GETATTR\n      may retrieve, SETATTR may\
    \ not set).  W means write-only (SETATTR\n      may set, GETATTR may not retrieve).\
    \  R W means read/write (GETATTR\n      may retrieve, SETATTR may set).\n   Defined\
    \ in:  The section of this specification that describes the\n      attribute.\n\
    \     | Name               | Id | Data Type  | Acc | Defined in:      |\n    \
    \ | supported_attrs    | 0  | bitmap4    | R   | Section 5.8.1.1  |\n     | type\
    \               | 1  | nfs_ftype4 | R   | Section 5.8.1.2  |\n     | fh_expire_type\
    \     | 2  | uint32_t   | R   | Section 5.8.1.3  |\n     | change            \
    \ | 3  | uint64_t   | R   | Section 5.8.1.4  |\n     | size               | 4\
    \  | uint64_t   | R W | Section 5.8.1.5  |\n     | link_support       | 5  | bool\
    \       | R   | Section 5.8.1.6  |\n     | symlink_support    | 6  | bool    \
    \   | R   | Section 5.8.1.7  |\n     | named_attr         | 7  | bool       |\
    \ R   | Section 5.8.1.8  |\n     | fsid               | 8  | fsid4      | R  \
    \ | Section 5.8.1.9  |\n     | unique_handles     | 9  | bool       | R   | Section\
    \ 5.8.1.10 |\n     | lease_time         | 10 | nfs_lease4 | R   | Section 5.8.1.11\
    \ |\n     | rdattr_error       | 11 | enum       | R   | Section 5.8.1.12 |\n\
    \     | filehandle         | 19 | nfs_fh4    | R   | Section 5.8.1.13 |\n    \
    \ | suppattr_exclcreat | 75 | bitmap4    | R   | Section 5.8.1.14 |\n"
- title: 5.7.  RECOMMENDED Attributes - List and Definition References
  contents:
  - "5.7.  RECOMMENDED Attributes - List and Definition References\n   The RECOMMENDED\
    \ attributes are defined in Table 5.  The meanings of\n   the column headers are\
    \ the same as Table 4; see Section 5.6 for the\n   meanings.\n   | Name      \
    \         | Id | Data Type          | Acc | Defined in: |\n   | acl          \
    \      | 12 | nfsace4<>          | R W | Section     |\n   | aclsupport      \
    \   | 13 | uint32_t           | R   | Section     |\n   | archive            |\
    \ 14 | bool               | R W | Section     |\n   | cansettime         | 15\
    \ | bool               | R   | Section     |\n   | case_insensitive   | 16 | bool\
    \               | R   | Section     |\n   | case_preserving    | 17 | bool   \
    \            | R   | Section     |\n   | change_policy      | 60 | chg_policy4\
    \        | R   | Section     |\n   | chown_restricted   | 18 | bool          \
    \     | R   | Section     |\n   | dacl               | 58 | nfsacl41         \
    \  | R W | Section     |\n   | dir_notif_delay    | 56 | nfstime4           |\
    \ R   | Section     |\n   | dirent_notif_delay | 57 | nfstime4           | R \
    \  | Section     |\n   | fileid             | 20 | uint64_t           | R   |\
    \ Section     |\n   | files_avail        | 21 | uint64_t           | R   | Section\
    \     |\n   | files_free         | 22 | uint64_t           | R   | Section   \
    \  |\n   | files_total        | 23 | uint64_t           | R   | Section     |\n\
    \   | fs_charset_cap     | 76 | uint32_t           | R   | Section     |\n   |\
    \ fs_layout_type     | 62 | layouttype4<>      | R   | Section     |\n   | fs_locations\
    \       | 24 | fs_locations       | R   | Section     |\n   | fs_locations_info\
    \  | 67 | fs_locations_info4 | R   | Section     |\n   | fs_status          |\
    \ 61 | fs4_status         | R   | Section     |\n   | hidden             | 25\
    \ | bool               | R W | Section     |\n   | homogeneous        | 26 | bool\
    \               | R   | Section     |\n   | layout_alignment   | 66 | uint32_t\
    \           | R   | Section     |\n   | layout_blksize     | 65 | uint32_t   \
    \        | R   | Section     |\n   | layout_hint        | 63 | layouthint4   \
    \     |   W | Section     |\n   | layout_type        | 64 | layouttype4<>    \
    \  | R   | Section     |\n   | maxfilesize        | 27 | uint64_t           |\
    \ R   | Section     |\n   | maxlink            | 28 | uint32_t           | R \
    \  | Section     |\n   | maxname            | 29 | uint32_t           | R   |\
    \ Section     |\n   | maxread            | 30 | uint64_t           | R   | Section\
    \     |\n   | maxwrite           | 31 | uint64_t           | R   | Section   \
    \  |\n   | mdsthreshold       | 68 | mdsthreshold4      | R   | Section     |\n\
    \   | mimetype           | 32 | utf8str_cs         | R W | Section     |\n   |\
    \ mode               | 33 | mode4              | R W | Section     |\n   | mode_set_masked\
    \    | 74 | mode_masked4       |   W | Section     |\n   | mounted_on_fileid \
    \ | 55 | uint64_t           | R   | Section     |\n   | no_trunc           | 34\
    \ | bool               | R   | Section     |\n   | numlinks           | 35 | uint32_t\
    \           | R   | Section     |\n   | owner              | 36 | utf8str_mixed\
    \      | R W | Section     |\n   | owner_group        | 37 | utf8str_mixed   \
    \   | R W | Section     |\n   | quota_avail_hard   | 38 | uint64_t           |\
    \ R   | Section     |\n   | quota_avail_soft   | 39 | uint64_t           | R \
    \  | Section     |\n   | quota_used         | 40 | uint64_t           | R   |\
    \ Section     |\n   | rawdev             | 41 | specdata4          | R   | Section\
    \     |\n   | retentevt_get      | 71 | retention_get4     | R   | Section   \
    \  |\n   | retentevt_set      | 72 | retention_set4     |   W | Section     |\n\
    \   | retention_get      | 69 | retention_get4     | R   | Section     |\n   |\
    \ retention_hold     | 73 | uint64_t           | R W | Section     |\n   | retention_set\
    \      | 70 | retention_set4     |   W | Section     |\n   | sacl            \
    \   | 59 | nfsacl41           | R W | Section     |\n   | space_avail        |\
    \ 42 | uint64_t           | R   | Section     |\n   | space_free         | 43\
    \ | uint64_t           | R   | Section     |\n   | space_total        | 44 | uint64_t\
    \           | R   | Section     |\n   | space_used         | 45 | uint64_t   \
    \        | R   | Section     |\n   | system             | 46 | bool          \
    \     | R W | Section     |\n   | time_access        | 47 | nfstime4         \
    \  | R   | Section     |\n   | time_access_set    | 48 | settime4           |\
    \   W | Section     |\n   | time_backup        | 49 | nfstime4           | R W\
    \ | Section     |\n   | time_create        | 50 | nfstime4           | R W | Section\
    \     |\n   | time_delta         | 51 | nfstime4           | R   | Section   \
    \  |\n   | time_metadata      | 52 | nfstime4           | R   | Section     |\n\
    \   | time_modify        | 53 | nfstime4           | R   | Section     |\n   |\
    \ time_modify_set    | 54 | settime4           |   W | Section     |\n"
- title: 5.8.  Attribute Definitions
  contents:
  - '5.8.  Attribute Definitions

    '
- title: 5.8.1.  Definitions of REQUIRED Attributes
  contents:
  - '5.8.1.  Definitions of REQUIRED Attributes

    '
- title: '5.8.1.1.  Attribute 0: supported_attrs'
  contents:
  - "5.8.1.1.  Attribute 0: supported_attrs\n   The bit vector that would retrieve\
    \ all REQUIRED and RECOMMENDED\n   attributes that are supported for this object.\
    \  The scope of this\n   attribute applies to all objects with a matching fsid.\n"
- title: '5.8.1.2.  Attribute 1: type'
  contents:
  - "5.8.1.2.  Attribute 1: type\n   Designates the type of an object in terms of\
    \ one of a number of\n   special constants:\n   *  NF4REG designates a regular\
    \ file.\n   *  NF4DIR designates a directory.\n   *  NF4BLK designates a block\
    \ device special file.\n   *  NF4CHR designates a character device special file.\n\
    \   *  NF4LNK designates a symbolic link.\n   *  NF4SOCK designates a named socket\
    \ special file.\n   *  NF4FIFO designates a fifo special file.\n   *  NF4ATTRDIR\
    \ designates a named attribute directory.\n   *  NF4NAMEDATTR designates a named\
    \ attribute.\n   Within the explanatory text and operation descriptions, the following\n\
    \   phrases will be used with the meanings given below:\n   *  The phrase \"is\
    \ a directory\" means that the object's type attribute\n      is NF4DIR or NF4ATTRDIR.\n\
    \   *  The phrase \"is a special file\" means that the object's type\n      attribute\
    \ is NF4BLK, NF4CHR, NF4SOCK, or NF4FIFO.\n   *  The phrases \"is an ordinary\
    \ file\" and \"is a regular file\" mean\n      that the object's type attribute\
    \ is NF4REG or NF4NAMEDATTR.\n"
- title: '5.8.1.3.  Attribute 2: fh_expire_type'
  contents:
  - "5.8.1.3.  Attribute 2: fh_expire_type\n   Server uses this to specify filehandle\
    \ expiration behavior to the\n   client.  See Section 4 for additional description.\n"
- title: '5.8.1.4.  Attribute 3: change'
  contents:
  - "5.8.1.4.  Attribute 3: change\n   A value created by the server that the client\
    \ can use to determine if\n   file data, directory contents, or attributes of\
    \ the object have been\n   modified.  The server may return the object's time_metadata\
    \ attribute\n   for this attribute's value, but only if the file system object\
    \ cannot\n   be updated more frequently than the resolution of time_metadata.\n"
- title: '5.8.1.5.  Attribute 4: size'
  contents:
  - "5.8.1.5.  Attribute 4: size\n   The size of the object in bytes.\n"
- title: '5.8.1.6.  Attribute 5: link_support'
  contents:
  - "5.8.1.6.  Attribute 5: link_support\n   TRUE, if the object's file system supports\
    \ hard links.\n"
- title: '5.8.1.7.  Attribute 6: symlink_support'
  contents:
  - "5.8.1.7.  Attribute 6: symlink_support\n   TRUE, if the object's file system\
    \ supports symbolic links.\n"
- title: '5.8.1.8.  Attribute 7: named_attr'
  contents:
  - "5.8.1.8.  Attribute 7: named_attr\n   TRUE, if this object has named attributes.\
    \  In other words, object\n   has a non-empty named attribute directory.\n"
- title: '5.8.1.9.  Attribute 8: fsid'
  contents:
  - "5.8.1.9.  Attribute 8: fsid\n   Unique file system identifier for the file system\
    \ holding this\n   object.  The fsid attribute has major and minor components,\
    \ each of\n   which are of data type uint64_t.\n"
- title: '5.8.1.10.  Attribute 9: unique_handles'
  contents:
  - "5.8.1.10.  Attribute 9: unique_handles\n   TRUE, if two distinct filehandles\
    \ are guaranteed to refer to two\n   different file system objects.\n"
- title: '5.8.1.11.  Attribute 10: lease_time'
  contents:
  - "5.8.1.11.  Attribute 10: lease_time\n   Duration of the lease at server in seconds.\n"
- title: '5.8.1.12.  Attribute 11: rdattr_error'
  contents:
  - "5.8.1.12.  Attribute 11: rdattr_error\n   Error returned from an attempt to retrieve\
    \ attributes during a\n   READDIR operation.\n"
- title: '5.8.1.13.  Attribute 19: filehandle'
  contents:
  - "5.8.1.13.  Attribute 19: filehandle\n   The filehandle of this object (primarily\
    \ for READDIR requests).\n"
- title: '5.8.1.14.  Attribute 75: suppattr_exclcreat'
  contents:
  - "5.8.1.14.  Attribute 75: suppattr_exclcreat\n   The bit vector that would set\
    \ all REQUIRED and RECOMMENDED attributes\n   that are supported by the EXCLUSIVE4_1\
    \ method of file creation via\n   the OPEN operation.  The scope of this attribute\
    \ applies to all\n   objects with a matching fsid.\n"
- title: 5.8.2.  Definitions of Uncategorized RECOMMENDED Attributes
  contents:
  - "5.8.2.  Definitions of Uncategorized RECOMMENDED Attributes\n   The definitions\
    \ of most of the RECOMMENDED attributes follow.\n   Collections that share a common\
    \ category are defined in other\n   sections.\n"
- title: '5.8.2.1.  Attribute 14: archive'
  contents:
  - "5.8.2.1.  Attribute 14: archive\n   TRUE, if this file has been archived since\
    \ the time of last\n   modification (deprecated in favor of time_backup).\n"
- title: '5.8.2.2.  Attribute 15: cansettime'
  contents:
  - "5.8.2.2.  Attribute 15: cansettime\n   TRUE, if the server is able to change\
    \ the times for a file system\n   object as specified in a SETATTR operation.\n"
- title: '5.8.2.3.  Attribute 16: case_insensitive'
  contents:
  - "5.8.2.3.  Attribute 16: case_insensitive\n   TRUE, if file name comparisons on\
    \ this file system are case\n   insensitive.\n"
- title: '5.8.2.4.  Attribute 17: case_preserving'
  contents:
  - "5.8.2.4.  Attribute 17: case_preserving\n   TRUE, if file name case on this file\
    \ system is preserved.\n"
- title: '5.8.2.5.  Attribute 60: change_policy'
  contents:
  - "5.8.2.5.  Attribute 60: change_policy\n   A value created by the server that\
    \ the client can use to determine if\n   some server policy related to the current\
    \ file system has been\n   subject to change.  If the value remains the same,\
    \ then the client\n   can be sure that the values of the attributes related to\
    \ fs location\n   and the fss_type field of the fs_status attribute have not changed.\n\
    \   On the other hand, a change in this value does necessarily imply a\n   change\
    \ in policy.  It is up to the client to interrogate the server\n   to determine\
    \ if some policy relevant to it has changed.  See\n   Section 3.3.6 for details.\n\
    \   This attribute MUST change when the value returned by the\n   fs_locations\
    \ or fs_locations_info attribute changes, when a file\n   system goes from read-only\
    \ to writable or vice versa, or when the\n   allowable set of security flavors\
    \ for the file system or any part\n   thereof is changed.\n"
- title: '5.8.2.6.  Attribute 18: chown_restricted'
  contents:
  - "5.8.2.6.  Attribute 18: chown_restricted\n   If TRUE, the server will reject\
    \ any request to change either the\n   owner or the group associated with a file\
    \ if the caller is not a\n   privileged user (for example, \"root\" in UNIX operating\
    \ environments\n   or, in Windows 2000, the \"Take Ownership\" privilege).\n"
- title: '5.8.2.7.  Attribute 20: fileid'
  contents:
  - "5.8.2.7.  Attribute 20: fileid\n   A number uniquely identifying the file within\
    \ the file system.\n"
- title: '5.8.2.8.  Attribute 21: files_avail'
  contents:
  - "5.8.2.8.  Attribute 21: files_avail\n   File slots available to this user on\
    \ the file system containing this\n   object -- this should be the smallest relevant\
    \ limit.\n"
- title: '5.8.2.9.  Attribute 22: files_free'
  contents:
  - "5.8.2.9.  Attribute 22: files_free\n   Free file slots on the file system containing\
    \ this object -- this\n   should be the smallest relevant limit.\n"
- title: '5.8.2.10.  Attribute 23: files_total'
  contents:
  - "5.8.2.10.  Attribute 23: files_total\n   Total file slots on the file system\
    \ containing this object.\n"
- title: '5.8.2.11.  Attribute 76: fs_charset_cap'
  contents:
  - "5.8.2.11.  Attribute 76: fs_charset_cap\n   Character set capabilities for this\
    \ file system.  See Section 14.4.\n"
- title: '5.8.2.12.  Attribute 24: fs_locations'
  contents:
  - "5.8.2.12.  Attribute 24: fs_locations\n   Locations where this file system may\
    \ be found.  If the server returns\n   NFS4ERR_MOVED as an error, this attribute\
    \ MUST be supported.  See\n   Section 11.16 for more details.\n"
- title: '5.8.2.13.  Attribute 67: fs_locations_info'
  contents:
  - "5.8.2.13.  Attribute 67: fs_locations_info\n   Full function file system location.\
    \  See Section 11.17.2 for more\n   details.\n"
- title: '5.8.2.14.  Attribute 61: fs_status'
  contents:
  - "5.8.2.14.  Attribute 61: fs_status\n   Generic file system type information.\
    \  See Section 11.18 for more\n   details.\n"
- title: '5.8.2.15.  Attribute 25: hidden'
  contents:
  - "5.8.2.15.  Attribute 25: hidden\n   TRUE, if the file is considered hidden with\
    \ respect to the Windows\n   API.\n"
- title: '5.8.2.16.  Attribute 26: homogeneous'
  contents:
  - "5.8.2.16.  Attribute 26: homogeneous\n   TRUE, if this object's file system is\
    \ homogeneous; i.e., all objects\n   in the file system (all objects on the server\
    \ with the same fsid)\n   have common values for all per-file-system attributes.\n"
- title: '5.8.2.17.  Attribute 27: maxfilesize'
  contents:
  - "5.8.2.17.  Attribute 27: maxfilesize\n   Maximum supported file size for the\
    \ file system of this object.\n"
- title: '5.8.2.18.  Attribute 28: maxlink'
  contents:
  - "5.8.2.18.  Attribute 28: maxlink\n   Maximum number of links for this object.\n"
- title: '5.8.2.19.  Attribute 29: maxname'
  contents:
  - "5.8.2.19.  Attribute 29: maxname\n   Maximum file name size supported for this\
    \ object.\n"
- title: '5.8.2.20.  Attribute 30: maxread'
  contents:
  - "5.8.2.20.  Attribute 30: maxread\n   Maximum amount of data the READ operation\
    \ will return for this\n   object.\n"
- title: '5.8.2.21.  Attribute 31: maxwrite'
  contents:
  - "5.8.2.21.  Attribute 31: maxwrite\n   Maximum amount of data the WRITE operation\
    \ will accept for this\n   object.  This attribute SHOULD be supported if the\
    \ file is writable.\n   Lack of this attribute can lead to the client either wasting\n\
    \   bandwidth or not receiving the best performance.\n"
- title: '5.8.2.22.  Attribute 32: mimetype'
  contents:
  - "5.8.2.22.  Attribute 32: mimetype\n   MIME body type/subtype of this object.\n"
- title: '5.8.2.23.  Attribute 55: mounted_on_fileid'
  contents:
  - "5.8.2.23.  Attribute 55: mounted_on_fileid\n   Like fileid, but if the target\
    \ filehandle is the root of a file\n   system, this attribute represents the fileid\
    \ of the underlying\n   directory.\n   UNIX-based operating environments connect\
    \ a file system into the\n   namespace by connecting (mounting) the file system\
    \ onto the existing\n   file object (the mount point, usually a directory) of\
    \ an existing\n   file system.  When the mount point's parent directory is read\
    \ via an\n   API like readdir(), the return results are directory entries, each\n\
    \   with a component name and a fileid.  The fileid of the mount point's\n   directory\
    \ entry will be different from the fileid that the stat()\n   system call returns.\
    \  The stat() system call is returning the fileid\n   of the root of the mounted\
    \ file system, whereas readdir() is\n   returning the fileid that stat() would\
    \ have returned before any file\n   systems were mounted on the mount point.\n\
    \   Unlike NFSv3, NFSv4.1 allows a client's LOOKUP request to cross other\n  \
    \ file systems.  The client detects the file system crossing whenever\n   the\
    \ filehandle argument of LOOKUP has an fsid attribute different\n   from that\
    \ of the filehandle returned by LOOKUP.  A UNIX-based client\n   will consider\
    \ this a \"mount point crossing\".  UNIX has a legacy\n   scheme for allowing\
    \ a process to determine its current working\n   directory.  This relies on readdir()\
    \ of a mount point's parent and\n   stat() of the mount point returning fileids\
    \ as previously described.\n   The mounted_on_fileid attribute corresponds to\
    \ the fileid that\n   readdir() would have returned as described previously.\n\
    \   While the NFSv4.1 client could simply fabricate a fileid\n   corresponding\
    \ to what mounted_on_fileid provides (and if the server\n   does not support mounted_on_fileid,\
    \ the client has no choice), there\n   is a risk that the client will generate\
    \ a fileid that conflicts with\n   one that is already assigned to another object\
    \ in the file system.\n   Instead, if the server can provide the mounted_on_fileid,\
    \ the\n   potential for client operational problems in this area is eliminated.\n\
    \   If the server detects that there is no mounted point at the target\n   file\
    \ object, then the value for mounted_on_fileid that it returns is\n   the same\
    \ as that of the fileid attribute.\n   The mounted_on_fileid attribute is RECOMMENDED,\
    \ so the server SHOULD\n   provide it if possible, and for a UNIX-based server,\
    \ this is\n   straightforward.  Usually, mounted_on_fileid will be requested during\n\
    \   a READDIR operation, in which case it is trivial (at least for UNIX-\n   based\
    \ servers) to return mounted_on_fileid since it is equal to the\n   fileid of\
    \ a directory entry returned by readdir().  If\n   mounted_on_fileid is requested\
    \ in a GETATTR operation, the server\n   should obey an invariant that has it\
    \ returning a value that is equal\n   to the file object's entry in the object's\
    \ parent directory, i.e.,\n   what readdir() would have returned.  Some operating\
    \ environments\n   allow a series of two or more file systems to be mounted onto\
    \ a\n   single mount point.  In this case, for the server to obey the\n   aforementioned\
    \ invariant, it will need to find the base mount point,\n   and not the intermediate\
    \ mount points.\n"
- title: '5.8.2.24.  Attribute 34: no_trunc'
  contents:
  - "5.8.2.24.  Attribute 34: no_trunc\n   If this attribute is TRUE, then if the\
    \ client uses a file name longer\n   than name_max, an error will be returned\
    \ instead of the name being\n   truncated.\n"
- title: '5.8.2.25.  Attribute 35: numlinks'
  contents:
  - "5.8.2.25.  Attribute 35: numlinks\n   Number of hard links to this object.\n"
- title: '5.8.2.26.  Attribute 36: owner'
  contents:
  - "5.8.2.26.  Attribute 36: owner\n   The string name of the owner of this object.\n"
- title: '5.8.2.27.  Attribute 37: owner_group'
  contents:
  - "5.8.2.27.  Attribute 37: owner_group\n   The string name of the group ownership\
    \ of this object.\n"
- title: '5.8.2.28.  Attribute 38: quota_avail_hard'
  contents:
  - "5.8.2.28.  Attribute 38: quota_avail_hard\n   The value in bytes that represents\
    \ the amount of additional disk\n   space beyond the current allocation that can\
    \ be allocated to this\n   file or directory before further allocations will be\
    \ refused.  It is\n   understood that this space may be consumed by allocations\
    \ to other\n   files or directories.\n"
- title: '5.8.2.29.  Attribute 39: quota_avail_soft'
  contents:
  - "5.8.2.29.  Attribute 39: quota_avail_soft\n   The value in bytes that represents\
    \ the amount of additional disk\n   space that can be allocated to this file or\
    \ directory before the user\n   may reasonably be warned.  It is understood that\
    \ this space may be\n   consumed by allocations to other files or directories\
    \ though there is\n   a rule as to which other files or directories.\n"
- title: '5.8.2.30.  Attribute 40: quota_used'
  contents:
  - "5.8.2.30.  Attribute 40: quota_used\n   The value in bytes that represents the\
    \ amount of disk space used by\n   this file or directory and possibly a number\
    \ of other similar files\n   or directories, where the set of \"similar\" meets\
    \ at least the\n   criterion that allocating space to any file or directory in\
    \ the set\n   will reduce the \"quota_avail_hard\" of every other file or directory\n\
    \   in the set.\n   Note that there may be a number of distinct but overlapping\
    \ sets of\n   files or directories for which a quota_used value is maintained,\n\
    \   e.g., \"all files with a given owner\", \"all files with a given group\n \
    \  owner\", etc.  The server is at liberty to choose any of those sets\n   when\
    \ providing the content of the quota_used attribute, but should do\n   so in a\
    \ repeatable way.  The rule may be configured per file system\n   or may be \"\
    choose the set with the smallest quota\".\n"
- title: '5.8.2.31.  Attribute 41: rawdev'
  contents:
  - "5.8.2.31.  Attribute 41: rawdev\n   Raw device number of file of type NF4BLK\
    \ or NF4CHR.  The device\n   number is split into major and minor numbers.  If\
    \ the file's type\n   attribute is not NF4BLK or NF4CHR, the value returned SHOULD\
    \ NOT be\n   considered useful.\n"
- title: '5.8.2.32.  Attribute 42: space_avail'
  contents:
  - "5.8.2.32.  Attribute 42: space_avail\n   Disk space in bytes available to this\
    \ user on the file system\n   containing this object -- this should be the smallest\
    \ relevant limit.\n"
- title: '5.8.2.33.  Attribute 43: space_free'
  contents:
  - "5.8.2.33.  Attribute 43: space_free\n   Free disk space in bytes on the file\
    \ system containing this object --\n   this should be the smallest relevant limit.\n"
- title: '5.8.2.34.  Attribute 44: space_total'
  contents:
  - "5.8.2.34.  Attribute 44: space_total\n   Total disk space in bytes on the file\
    \ system containing this object.\n"
- title: '5.8.2.35.  Attribute 45: space_used'
  contents:
  - "5.8.2.35.  Attribute 45: space_used\n   Number of file system bytes allocated\
    \ to this object.\n"
- title: '5.8.2.36.  Attribute 46: system'
  contents:
  - "5.8.2.36.  Attribute 46: system\n   This attribute is TRUE if this file is a\
    \ \"system\" file with respect\n   to the Windows operating environment.\n"
- title: '5.8.2.37.  Attribute 47: time_access'
  contents:
  - "5.8.2.37.  Attribute 47: time_access\n   The time_access attribute represents\
    \ the time of last access to the\n   object by a READ operation sent to the server.\
    \  The notion of what is\n   an \"access\" depends on the server's operating environment\
    \ and/or the\n   server's file system semantics.  For example, for servers obeying\n\
    \   Portable Operating System Interface (POSIX) semantics, time_access\n   would\
    \ be updated only by the READ and READDIR operations and not any\n   of the operations\
    \ that modify the content of the object [13], [14],\n   [15].  Of course, setting\
    \ the corresponding time_access_set attribute\n   is another way to modify the\
    \ time_access attribute.\n   Whenever the file object resides on a writable file\
    \ system, the\n   server should make its best efforts to record time_access into\
    \ stable\n   storage.  However, to mitigate the performance effects of doing so,\n\
    \   and most especially whenever the server is satisfying the read of the\n  \
    \ object's content from its cache, the server MAY cache access time\n   updates\
    \ and lazily write them to stable storage.  It is also\n   acceptable to give\
    \ administrators of the server the option to disable\n   time_access updates.\n"
- title: '5.8.2.38.  Attribute 48: time_access_set'
  contents:
  - "5.8.2.38.  Attribute 48: time_access_set\n   Sets the time of last access to\
    \ the object.  SETATTR use only.\n"
- title: '5.8.2.39.  Attribute 49: time_backup'
  contents:
  - "5.8.2.39.  Attribute 49: time_backup\n   The time of last backup of the object.\n"
- title: '5.8.2.40.  Attribute 50: time_create'
  contents:
  - "5.8.2.40.  Attribute 50: time_create\n   The time of creation of the object.\
    \  This attribute does not have any\n   relation to the traditional UNIX file\
    \ attribute \"ctime\" or \"change\n   time\".\n"
- title: '5.8.2.41.  Attribute 51: time_delta'
  contents:
  - "5.8.2.41.  Attribute 51: time_delta\n   Smallest useful server time granularity.\n"
- title: '5.8.2.42.  Attribute 52: time_metadata'
  contents:
  - "5.8.2.42.  Attribute 52: time_metadata\n   The time of last metadata modification\
    \ of the object.\n"
- title: '5.8.2.43.  Attribute 53: time_modify'
  contents:
  - "5.8.2.43.  Attribute 53: time_modify\n   The time of last modification to the\
    \ object.\n"
- title: '5.8.2.44.  Attribute 54: time_modify_set'
  contents:
  - "5.8.2.44.  Attribute 54: time_modify_set\n   Sets the time of last modification\
    \ to the object.  SETATTR use only.\n"
- title: 5.9.  Interpreting owner and owner_group
  contents:
  - "5.9.  Interpreting owner and owner_group\n   The RECOMMENDED attributes \"owner\"\
    \ and \"owner_group\" (and also users\n   and groups within the \"acl\" attribute)\
    \ are represented in terms of a\n   UTF-8 string.  To avoid a representation that\
    \ is tied to a particular\n   underlying implementation at the client or server,\
    \ the use of the\n   UTF-8 string has been chosen.  Note that Section 6.1 of RFC\
    \ 2624 [53]\n   provides additional rationale.  It is expected that the client\
    \ and\n   server will have their own local representation of owner and\n   owner_group\
    \ that is used for local storage or presentation to the end\n   user.  Therefore,\
    \ it is expected that when these attributes are\n   transferred between the client\
    \ and server, the local representation\n   is translated to a syntax of the form\
    \ \"user@dns_domain\".  This will\n   allow for a client and server that do not\
    \ use the same local\n   representation the ability to translate to a common syntax\
    \ that can\n   be interpreted by both.\n   Similarly, security principals may\
    \ be represented in different ways\n   by different security mechanisms.  Servers\
    \ normally translate these\n   representations into a common format, generally\
    \ that used by local\n   storage, to serve as a means of identifying the users\
    \ corresponding\n   to these security principals.  When these local identifiers\
    \ are\n   translated to the form of the owner attribute, associated with files\n\
    \   created by such principals, they identify, in a common format, the\n   users\
    \ associated with each corresponding set of security principals.\n   The translation\
    \ used to interpret owner and group strings is not\n   specified as part of the\
    \ protocol.  This allows various solutions to\n   be employed.  For example, a\
    \ local translation table may be consulted\n   that maps a numeric identifier\
    \ to the user@dns_domain syntax.  A name\n   service may also be used to accomplish\
    \ the translation.  A server may\n   provide a more general service, not limited\
    \ by any particular\n   translation (which would only translate a limited set\
    \ of possible\n   strings) by storing the owner and owner_group attributes in\
    \ local\n   storage without any translation or it may augment a translation\n\
    \   method by storing the entire string for attributes for which no\n   translation\
    \ is available while using the local representation for\n   those cases in which\
    \ a translation is available.\n   Servers that do not provide support for all\
    \ possible values of the\n   owner and owner_group attributes SHOULD return an\
    \ error\n   (NFS4ERR_BADOWNER) when a string is presented that has no\n   translation,\
    \ as the value to be set for a SETATTR of the owner,\n   owner_group, or acl attributes.\
    \  When a server does accept an owner\n   or owner_group value as valid on a SETATTR\
    \ (and similarly for the\n   owner and group strings in an acl), it is promising\
    \ to return that\n   same string when a corresponding GETATTR is done.  Configuration\n\
    \   changes (including changes from the mapping of the string to the\n   local\
    \ representation) and ill-constructed name translations (those\n   that contain\
    \ aliasing) may make that promise impossible to honor.\n   Servers should make\
    \ appropriate efforts to avoid a situation in which\n   these attributes have\
    \ their values changed when no real change to\n   ownership has occurred.\n  \
    \ The \"dns_domain\" portion of the owner string is meant to be a DNS\n   domain\
    \ name, for example, user@example.org.  Servers should accept as\n   valid a set\
    \ of users for at least one domain.  A server may treat\n   other domains as having\
    \ no valid translations.  A more general\n   service is provided when a server\
    \ is capable of accepting users for\n   multiple domains, or for all domains,\
    \ subject to security\n   constraints.\n   In the case where there is no translation\
    \ available to the client or\n   server, the attribute value will be constructed\
    \ without the \"@\".\n   Therefore, the absence of the @ from the owner or owner_group\n\
    \   attribute signifies that no translation was available at the sender\n   and\
    \ that the receiver of the attribute should not use that string as\n   a basis\
    \ for translation into its own internal format.  Even though\n   the attribute\
    \ value cannot be translated, it may still be useful.  In\n   the case of a client,\
    \ the attribute string may be used for local\n   display of ownership.\n   To\
    \ provide a greater degree of compatibility with NFSv3, which\n   identified users\
    \ and groups by 32-bit unsigned user identifiers and\n   group identifiers, owner\
    \ and group strings that consist of decimal\n   numeric values with no leading\
    \ zeros can be given a special\n   interpretation by clients and servers that\
    \ choose to provide such\n   support.  The receiver may treat such a user or group\
    \ string as\n   representing the same user as would be represented by an NFSv3\
    \ uid or\n   gid having the corresponding numeric value.  A server is not\n  \
    \ obligated to accept such a string, but may return an NFS4ERR_BADOWNER\n   instead.\
    \  To avoid this mechanism being used to subvert user and\n   group translation,\
    \ so that a client might pass all of the owners and\n   groups in numeric form,\
    \ a server SHOULD return an NFS4ERR_BADOWNER\n   error when there is a valid translation\
    \ for the user or owner\n   designated in this way.  In that case, the client\
    \ must use the\n   appropriate name@domain string and not the special form for\n\
    \   compatibility.\n   The owner string \"nobody\" may be used to designate an\
    \ anonymous user,\n   which will be associated with a file created by a security\
    \ principal\n   that cannot be mapped through normal means to the owner attribute.\n\
    \   Users and implementations of NFSv4.1 SHOULD NOT use \"nobody\" to\n   designate\
    \ a real user whose access is not anonymous.\n"
- title: 5.10.  Character Case Attributes
  contents:
  - "5.10.  Character Case Attributes\n   With respect to the case_insensitive and\
    \ case_preserving attributes,\n   each UCS-4 character (which UTF-8 encodes) can\
    \ be mapped according to\n   Appendix B.2 of RFC 3454 [16].  For general character\
    \ handling and\n   internationalization issues, see Section 14.\n"
- title: 5.11.  Directory Notification Attributes
  contents:
  - "5.11.  Directory Notification Attributes\n   As described in Section 18.39, the\
    \ client can request a minimum delay\n   for notifications of changes to attributes,\
    \ but the server is free to\n   ignore what the client requests.  The client can\
    \ determine in advance\n   what notification delays the server will accept by\
    \ sending a GETATTR\n   operation for either or both of two directory notification\n\
    \   attributes.  When the client calls the GET_DIR_DELEGATION operation\n   and\
    \ asks for attribute change notifications, it should request\n   notification\
    \ delays that are no less than the values in the server-\n   provided attributes.\n"
- title: '5.11.1.  Attribute 56: dir_notif_delay'
  contents:
  - "5.11.1.  Attribute 56: dir_notif_delay\n   The dir_notif_delay attribute is the\
    \ minimum number of seconds the\n   server will delay before notifying the client\
    \ of a change to the\n   directory's attributes.\n"
- title: '5.11.2.  Attribute 57: dirent_notif_delay'
  contents:
  - "5.11.2.  Attribute 57: dirent_notif_delay\n   The dirent_notif_delay attribute\
    \ is the minimum number of seconds the\n   server will delay before notifying\
    \ the client of a change to a file\n   object that has an entry in the directory.\n"
- title: 5.12.  pNFS Attribute Definitions
  contents:
  - '5.12.  pNFS Attribute Definitions

    '
- title: '5.12.1.  Attribute 62: fs_layout_type'
  contents:
  - "5.12.1.  Attribute 62: fs_layout_type\n   The fs_layout_type attribute (see Section\
    \ 3.3.13) applies to a file\n   system and indicates what layout types are supported\
    \ by the file\n   system.  When the client encounters a new fsid, the client SHOULD\n\
    \   obtain the value for the fs_layout_type attribute associated with the\n  \
    \ new file system.  This attribute is used by the client to determine\n   if the\
    \ layout types supported by the server match any of the client's\n   supported\
    \ layout types.\n"
- title: '5.12.2.  Attribute 66: layout_alignment'
  contents:
  - "5.12.2.  Attribute 66: layout_alignment\n   When a client holds layouts on files\
    \ of a file system, the\n   layout_alignment attribute indicates the preferred\
    \ alignment for I/O\n   to files on that file system.  Where possible, the client\
    \ should send\n   READ and WRITE operations with offsets that are whole multiples\
    \ of\n   the layout_alignment attribute.\n"
- title: '5.12.3.  Attribute 65: layout_blksize'
  contents:
  - "5.12.3.  Attribute 65: layout_blksize\n   When a client holds layouts on files\
    \ of a file system, the\n   layout_blksize attribute indicates the preferred block\
    \ size for I/O\n   to files on that file system.  Where possible, the client should\
    \ send\n   READ operations with a count argument that is a whole multiple of\n\
    \   layout_blksize, and WRITE operations with a data argument of size\n   that\
    \ is a whole multiple of layout_blksize.\n"
- title: '5.12.4.  Attribute 63: layout_hint'
  contents:
  - "5.12.4.  Attribute 63: layout_hint\n   The layout_hint attribute (see Section\
    \ 3.3.19) may be set on newly\n   created files to influence the metadata server's\
    \ choice for the\n   file's layout.  If possible, this attribute is one of those\
    \ set in\n   the initial attributes within the OPEN operation.  The metadata\n\
    \   server may choose to ignore this attribute.  The layout_hint\n   attribute\
    \ is a subset of the layout structure returned by LAYOUTGET.\n   For example,\
    \ instead of specifying particular devices, this would be\n   used to suggest\
    \ the stripe width of a file.  The server\n   implementation determines which\
    \ fields within the layout will be\n   used.\n"
- title: '5.12.5.  Attribute 64: layout_type'
  contents:
  - "5.12.5.  Attribute 64: layout_type\n   This attribute lists the layout type(s)\
    \ available for a file.  The\n   value returned by the server is for informational\
    \ purposes only.  The\n   client will use the LAYOUTGET operation to obtain the\
    \ information\n   needed in order to perform I/O, for example, the specific device\n\
    \   information for the file and its layout.\n"
- title: '5.12.6.  Attribute 68: mdsthreshold'
  contents:
  - "5.12.6.  Attribute 68: mdsthreshold\n   This attribute is a server-provided hint\
    \ used to communicate to the\n   client when it is more efficient to send READ\
    \ and WRITE operations to\n   the metadata server or the data server.  The two\
    \ types of thresholds\n   described are file size thresholds and I/O size thresholds.\
    \  If a\n   file's size is smaller than the file size threshold, data accesses\n\
    \   SHOULD be sent to the metadata server.  If an I/O request has a\n   length\
    \ that is below the I/O size threshold, the I/O SHOULD be sent\n   to the metadata\
    \ server.  Each threshold type is specified separately\n   for read and write.\n\
    \   The server MAY provide both types of thresholds for a file.  If both\n   file\
    \ size and I/O size are provided, the client SHOULD reach or\n   exceed both thresholds\
    \ before sending its read or write requests to\n   the data server.  Alternatively,\
    \ if only one of the specified\n   thresholds is reached or exceeded, the I/O\
    \ requests are sent to the\n   metadata server.\n   For each threshold type, a\
    \ value of zero indicates no READ or WRITE\n   should be sent to the metadata\
    \ server, while a value of all ones\n   indicates that all READs or WRITEs should\
    \ be sent to the metadata\n   server.\n   The attribute is available on a per-filehandle\
    \ basis.  If the current\n   filehandle refers to a non-pNFS file or directory,\
    \ the metadata\n   server should return an attribute that is representative of\
    \ the\n   filehandle's file system.  It is suggested that this attribute is\n\
    \   queried as part of the OPEN operation.  Due to dynamic system\n   changes,\
    \ the client should not assume that the attribute will remain\n   constant for\
    \ any specific time period; thus, it should be\n   periodically refreshed.\n"
- title: 5.13.  Retention Attributes
  contents:
  - "5.13.  Retention Attributes\n   Retention is a concept whereby a file object\
    \ can be placed in an\n   immutable, undeletable, unrenamable state for a fixed\
    \ or infinite\n   duration of time.  Once in this \"retained\" state, the file\
    \ cannot be\n   moved out of the state until the duration of retention has been\n\
    \   reached.\n   When retention is enabled, retention MUST extend to the data\
    \ of the\n   file, and the name of file.  The server MAY extend retention to any\n\
    \   other property of the file, including any subset of REQUIRED,\n   RECOMMENDED,\
    \ and named attributes, with the exceptions noted in this\n   section.\n   Servers\
    \ MAY support or not support retention on any file object type.\n   The five retention\
    \ attributes are explained in the next subsections.\n"
- title: '5.13.1.  Attribute 69: retention_get'
  contents:
  - "5.13.1.  Attribute 69: retention_get\n   If retention is enabled for the associated\
    \ file, this attribute's\n   value represents the retention begin time of the\
    \ file object.  This\n   attribute's value is only readable with the GETATTR operation\
    \ and\n   MUST NOT be modified by the SETATTR operation (Section 5.5).  The\n\
    \   value of the attribute consists of:\n   const RET4_DURATION_INFINITE    =\
    \ 0xffffffffffffffff;\n   struct retention_get4 {\n           uint64_t       \
    \ rg_duration;\n           nfstime4        rg_begin_time<1>;\n   };\n   The field\
    \ rg_duration is the duration in seconds indicating how long\n   the file will\
    \ be retained once retention is enabled.  The field\n   rg_begin_time is an array\
    \ of up to one absolute time value.  If the\n   array is zero length, no beginning\
    \ retention time has been\n   established, and retention is not enabled.  If rg_duration\
    \ is equal\n   to RET4_DURATION_INFINITE, the file, once retention is enabled,\
    \ will\n   be retained for an infinite duration.\n   If (as soon as) rg_duration\
    \ is zero, then rg_begin_time will be of\n   zero length, and again, retention\
    \ is not (no longer) enabled.\n"
- title: '5.13.2.  Attribute 70: retention_set'
  contents:
  - "5.13.2.  Attribute 70: retention_set\n   This attribute is used to set the retention\
    \ duration and optionally\n   enable retention for the associated file object.\
    \  This attribute is\n   only modifiable via the SETATTR operation and MUST NOT\
    \ be retrieved\n   by the GETATTR operation (Section 5.5).  This attribute corresponds\n\
    \   to retention_get.  The value of the attribute consists of:\n   struct retention_set4\
    \ {\n           bool            rs_enable;\n           uint64_t        rs_duration<1>;\n\
    \   };\n   If the client sets rs_enable to TRUE, then it is enabling retention\n\
    \   on the file object with the begin time of retention starting from the\n  \
    \ server's current time and date.  The duration of the retention can\n   also\
    \ be provided if the rs_duration array is of length one.  The\n   duration is\
    \ the time in seconds from the begin time of retention, and\n   if set to RET4_DURATION_INFINITE,\
    \ the file is to be retained forever.\n   If retention is enabled, with no duration\
    \ specified in either this\n   SETATTR or a previous SETATTR, the duration defaults\
    \ to zero seconds.\n   The server MAY restrict the enabling of retention or the\
    \ duration of\n   retention on the basis of the ACE4_WRITE_RETENTION ACL permission.\n\
    \   The enabling of retention MUST NOT prevent the enabling of event-\n   based\
    \ retention or the modification of the retention_hold attribute.\n   The following\
    \ rules apply to both the retention_set and retentevt_set\n   attributes.\n  \
    \ *  As long as retention is not enabled, the client is permitted to\n      decrease\
    \ the duration.\n   *  The duration can always be set to an equal or higher value,\
    \ even\n      if retention is enabled.  Note that once retention is enabled, the\n\
    \      actual duration (as returned by the retention_get or retentevt_get\n  \
    \    attributes; see Section 5.13.1 or Section 5.13.3) is constantly\n      counting\
    \ down to zero (one unit per second), unless the duration\n      was set to RET4_DURATION_INFINITE.\
    \  Thus, it will not be possible\n      for the client to precisely extend the\
    \ duration on a file that has\n      retention enabled.\n   *  While retention\
    \ is enabled, attempts to disable retention or\n      decrease the retention's\
    \ duration MUST fail with the error\n      NFS4ERR_INVAL.\n   *  If the principal\
    \ attempting to change retention_set or\n      retentevt_set does not have ACE4_WRITE_RETENTION\
    \ permissions, the\n      attempt MUST fail with NFS4ERR_ACCESS.\n"
- title: '5.13.3.  Attribute 71: retentevt_get'
  contents:
  - "5.13.3.  Attribute 71: retentevt_get\n   Gets the event-based retention duration,\
    \ and if enabled, the event-\n   based retention begin time of the file object.\
    \  This attribute is\n   like retention_get, but refers to event-based retention.\
    \  The event\n   that triggers event-based retention is not defined by the NFSv4.1\n\
    \   specification.\n"
- title: '5.13.4.  Attribute 72: retentevt_set'
  contents:
  - "5.13.4.  Attribute 72: retentevt_set\n   Sets the event-based retention duration,\
    \ and optionally enables\n   event-based retention on the file object.  This attribute\
    \ corresponds\n   to retentevt_get and is like retention_set, but refers to event-based\n\
    \   retention.  When event-based retention is set, the file MUST be\n   retained\
    \ even if non-event-based retention has been set, and the\n   duration of non-event-based\
    \ retention has been reached.  Conversely,\n   when non-event-based retention\
    \ has been set, the file MUST be\n   retained even if event-based retention has\
    \ been set, and the duration\n   of event-based retention has been reached.  The\
    \ server MAY restrict\n   the enabling of event-based retention or the duration\
    \ of event-based\n   retention on the basis of the ACE4_WRITE_RETENTION ACL permission.\n\
    \   The enabling of event-based retention MUST NOT prevent the enabling\n   of\
    \ non-event-based retention or the modification of the\n   retention_hold attribute.\n"
- title: '5.13.5.  Attribute 73: retention_hold'
  contents:
  - "5.13.5.  Attribute 73: retention_hold\n   Gets or sets administrative retention\
    \ holds, one hold per bit\n   position.\n   This attribute allows one to 64 administrative\
    \ holds, one hold per\n   bit on the attribute.  If retention_hold is not zero,\
    \ then the file\n   MUST NOT be deleted, renamed, or modified, even if the duration\
    \ on\n   enabled event or non-event-based retention has been reached.  The\n \
    \  server MAY restrict the modification of retention_hold on the basis\n   of\
    \ the ACE4_WRITE_RETENTION_HOLD ACL permission.  The enabling of\n   administration\
    \ retention holds does not prevent the enabling of\n   event-based or non-event-based\
    \ retention.\n   If the principal attempting to change retention_hold does not\
    \ have\n   ACE4_WRITE_RETENTION_HOLD permissions, the attempt MUST fail with\n\
    \   NFS4ERR_ACCESS.\n"
- title: 6.  Access Control Attributes
  contents:
  - "6.  Access Control Attributes\n   Access Control Lists (ACLs) are file attributes\
    \ that specify fine-\n   grained access control.  This section covers the \"acl\"\
    , \"dacl\",\n   \"sacl\", \"aclsupport\", \"mode\", and \"mode_set_masked\" file\
    \ attributes\n   and their interactions.  Note that file attributes may apply\
    \ to any\n   file system object.\n"
- title: 6.1.  Goals
  contents:
  - "6.1.  Goals\n   ACLs and modes represent two well-established models for specifying\n\
    \   permissions.  This section specifies requirements that attempt to\n   meet\
    \ the following goals:\n   *  If a server supports the mode attribute, it should\
    \ provide\n      reasonable semantics to clients that only set and retrieve the\n\
    \      mode attribute.\n   *  If a server supports ACL attributes, it should provide\
    \ reasonable\n      semantics to clients that only set and retrieve those attributes.\n\
    \   *  On servers that support the mode attribute, if ACL attributes have\n  \
    \    never been set on an object, via inheritance or explicitly, the\n      behavior\
    \ should be traditional UNIX-like behavior.\n   *  On servers that support the\
    \ mode attribute, if the ACL attributes\n      have been previously set on an\
    \ object, either explicitly or via\n      inheritance:\n      -  Setting only\
    \ the mode attribute should effectively control the\n         traditional UNIX-like\
    \ permissions of read, write, and execute\n         on owner, owner_group, and\
    \ other.\n      -  Setting only the mode attribute should provide reasonable\n\
    \         security.  For example, setting a mode of 000 should be enough\n   \
    \      to ensure that future OPEN operations for\n         OPEN4_SHARE_ACCESS_READ\
    \ or OPEN4_SHARE_ACCESS_WRITE by any\n         principal fail, regardless of a\
    \ previously existing or\n         inherited ACL.\n   *  NFSv4.1 may introduce\
    \ different semantics relating to the mode and\n      ACL attributes, but it does\
    \ not render invalid any previously\n      existing implementations.  Additionally,\
    \ this section provides\n      clarifications based on previous implementations\
    \ and discussions\n      around them.\n   *  On servers that support both the\
    \ mode and the acl or dacl\n      attributes, the server must keep the two consistent\
    \ with each\n      other.  The value of the mode attribute (with the exception\
    \ of the\n      three high-order bits described in Section 6.2.4) must be\n  \
    \    determined entirely by the value of the ACL, so that use of the\n      mode\
    \ is never required for anything other than setting the three\n      high-order\
    \ bits.  See Section 6.4.1 for exact requirements.\n   *  When a mode attribute\
    \ is set on an object, the ACL attributes may\n      need to be modified in order\
    \ to not conflict with the new mode.\n      In such cases, it is desirable that\
    \ the ACL keep as much\n      information as possible.  This includes information\
    \ about\n      inheritance, AUDIT and ALARM ACEs, and permissions granted and\n\
    \      denied that do not conflict with the new mode.\n"
- title: 6.2.  File Attributes Discussion
  contents:
  - '6.2.  File Attributes Discussion

    '
- title: '6.2.1.  Attribute 12: acl'
  contents:
  - "6.2.1.  Attribute 12: acl\n   The NFSv4.1 ACL attribute contains an array of\
    \ Access Control Entries\n   (ACEs) that are associated with the file system object.\
    \  Although the\n   client can set and get the acl attribute, the server is responsible\n\
    \   for using the ACL to perform access control.  The client can use the\n   OPEN\
    \ or ACCESS operations to check access without modifying or\n   reading data or\
    \ metadata.\n   The NFS ACE structure is defined as follows:\n   typedef uint32_t\
    \        acetype4;\n   typedef uint32_t aceflag4;\n   typedef uint32_t       \
    \ acemask4;\n   struct nfsace4 {\n           acetype4        type;\n         \
    \  aceflag4        flag;\n           acemask4        access_mask;\n          \
    \ utf8str_mixed   who;\n   };\n   To determine if a request succeeds, the server\
    \ processes each nfsace4\n   entry in order.  Only ACEs that have a \"who\" that\
    \ matches the\n   requester are considered.  Each ACE is processed until all of\
    \ the\n   bits of the requester's access have been ALLOWED.  Once a bit (see\n\
    \   below) has been ALLOWED by an ACCESS_ALLOWED_ACE, it is no longer\n   considered\
    \ in the processing of later ACEs.  If an ACCESS_DENIED_ACE\n   is encountered\
    \ where the requester's access still has unALLOWED bits\n   in common with the\
    \ \"access_mask\" of the ACE, the request is denied.\n   When the ACL is fully\
    \ processed, if there are bits in the requester's\n   mask that have not been\
    \ ALLOWED or DENIED, access is denied.\n   Unlike the ALLOW and DENY ACE types,\
    \ the ALARM and AUDIT ACE types do\n   not affect a requester's access, and instead\
    \ are for triggering\n   events as a result of a requester's access attempt. \
    \ Therefore, AUDIT\n   and ALARM ACEs are processed only after processing ALLOW\
    \ and DENY\n   ACEs.\n   The NFSv4.1 ACL model is quite rich.  Some server platforms\
    \ may\n   provide access-control functionality that goes beyond the UNIX-style\n\
    \   mode attribute, but that is not as rich as the NFS ACL model.  So\n   that\
    \ users can take advantage of this more limited functionality, the\n   server\
    \ may support the acl attributes by mapping between its ACL\n   model and the\
    \ NFSv4.1 ACL model.  Servers must ensure that the ACL\n   they actually store\
    \ or enforce is at least as strict as the NFSv4 ACL\n   that was set.  It is tempting\
    \ to accomplish this by rejecting any ACL\n   that falls outside the small set\
    \ that can be represented accurately.\n   However, such an approach can render\
    \ ACLs unusable without special\n   client-side knowledge of the server's mapping,\
    \ which defeats the\n   purpose of having a common NFSv4 ACL protocol.  Therefore,\
    \ servers\n   should accept every ACL that they can without compromising security.\n\
    \   To help accomplish this, servers may make a special exception, in the\n  \
    \ case of unsupported permission bits, to the rule that bits not\n   ALLOWED or\
    \ DENIED by an ACL must be denied.  For example, a UNIX-\n   style server might\
    \ choose to silently allow read attribute\n   permissions even though an ACL does\
    \ not explicitly allow those\n   permissions.  (An ACL that explicitly denies\
    \ permission to read\n   attributes should still be rejected.)\n   The situation\
    \ is complicated by the fact that a server may have\n   multiple modules that\
    \ enforce ACLs.  For example, the enforcement for\n   NFSv4.1 access may be different\
    \ from, but not weaker than, the\n   enforcement for local access, and both may\
    \ be different from the\n   enforcement for access through other protocols such\
    \ as SMB (Server\n   Message Block).  So it may be useful for a server to accept\
    \ an ACL\n   even if not all of its modules are able to support it.\n   The guiding\
    \ principle with regard to NFSv4 access is that the server\n   must not accept\
    \ ACLs that appear to make access to the file more\n   restrictive than it really\
    \ is.\n"
- title: 6.2.1.1.  ACE Type
  contents:
  - "6.2.1.1.  ACE Type\n   The constants used for the type field (acetype4) are as\
    \ follows:\n   const ACE4_ACCESS_ALLOWED_ACE_TYPE      = 0x00000000;\n   const\
    \ ACE4_ACCESS_DENIED_ACE_TYPE       = 0x00000001;\n   const ACE4_SYSTEM_AUDIT_ACE_TYPE\
    \        = 0x00000002;\n   const ACE4_SYSTEM_ALARM_ACE_TYPE        = 0x00000003;\n\
    \   Only the ALLOWED and DENIED bits may be used in the dacl attribute,\n   and\
    \ only the AUDIT and ALARM bits may be used in the sacl attribute.\n   All four\
    \ are permitted in the acl attribute.\n   | Value                        | Abbreviation\
    \ | Description         |\n   | ACE4_ACCESS_ALLOWED_ACE_TYPE | ALLOW        |\
    \ Explicitly grants   |\n   | ACE4_ACCESS_DENIED_ACE_TYPE  | DENY         | Explicitly\
    \ denies   |\n   | ACE4_SYSTEM_AUDIT_ACE_TYPE   | AUDIT        | Log (in a system-\
    \   |\n   | ACE4_SYSTEM_ALARM_ACE_TYPE   | ALARM        | Generate an alarm  \
    \ |\n   The \"Abbreviation\" column denotes how the types will be referred to\n\
    \   throughout the rest of this section.\n"
- title: '6.2.1.2.  Attribute 13: aclsupport'
  contents:
  - "6.2.1.2.  Attribute 13: aclsupport\n   A server need not support all of the above\
    \ ACE types.  This attribute\n   indicates which ACE types are supported for the\
    \ current file system.\n   The bitmask constants used to represent the above definitions\
    \ within\n   the aclsupport attribute are as follows:\n   const ACL4_SUPPORT_ALLOW_ACL\
    \    = 0x00000001;\n   const ACL4_SUPPORT_DENY_ACL     = 0x00000002;\n   const\
    \ ACL4_SUPPORT_AUDIT_ACL    = 0x00000004;\n   const ACL4_SUPPORT_ALARM_ACL   \
    \ = 0x00000008;\n   Servers that support either the ALLOW or DENY ACE type SHOULD\
    \ support\n   both ALLOW and DENY ACE types.\n   Clients should not attempt to\
    \ set an ACE unless the server claims\n   support for that ACE type.  If the server\
    \ receives a request to set\n   an ACE that it cannot store, it MUST reject the\
    \ request with\n   NFS4ERR_ATTRNOTSUPP.  If the server receives a request to set\
    \ an ACE\n   that it can store but cannot enforce, the server SHOULD reject the\n\
    \   request with NFS4ERR_ATTRNOTSUPP.\n   Support for any of the ACL attributes\
    \ is optional (albeit\n   RECOMMENDED).  However, a server that supports either\
    \ of the new ACL\n   attributes (dacl or sacl) MUST allow use of the new ACL attributes\
    \ to\n   access all of the ACE types that it supports.  In other words, if\n \
    \  such a server supports ALLOW or DENY ACEs, then it MUST support the\n   dacl\
    \ attribute, and if it supports AUDIT or ALARM ACEs, then it MUST\n   support\
    \ the sacl attribute.\n"
- title: 6.2.1.3.  ACE Access Mask
  contents:
  - "6.2.1.3.  ACE Access Mask\n   The bitmask constants used for the access mask\
    \ field are as follows:\n   const ACE4_READ_DATA            = 0x00000001;\n  \
    \ const ACE4_LIST_DIRECTORY       = 0x00000001;\n   const ACE4_WRITE_DATA    \
    \       = 0x00000002;\n   const ACE4_ADD_FILE             = 0x00000002;\n   const\
    \ ACE4_APPEND_DATA          = 0x00000004;\n   const ACE4_ADD_SUBDIRECTORY    \
    \ = 0x00000004;\n   const ACE4_READ_NAMED_ATTRS     = 0x00000008;\n   const ACE4_WRITE_NAMED_ATTRS\
    \    = 0x00000010;\n   const ACE4_EXECUTE              = 0x00000020;\n   const\
    \ ACE4_DELETE_CHILD         = 0x00000040;\n   const ACE4_READ_ATTRIBUTES     \
    \ = 0x00000080;\n   const ACE4_WRITE_ATTRIBUTES     = 0x00000100;\n   const ACE4_WRITE_RETENTION\
    \      = 0x00000200;\n   const ACE4_WRITE_RETENTION_HOLD = 0x00000400;\n   const\
    \ ACE4_DELETE               = 0x00010000;\n   const ACE4_READ_ACL            \
    \ = 0x00020000;\n   const ACE4_WRITE_ACL            = 0x00040000;\n   const ACE4_WRITE_OWNER\
    \          = 0x00080000;\n   const ACE4_SYNCHRONIZE          = 0x00100000;\n \
    \  Note that some masks have coincident values, for example,\n   ACE4_READ_DATA\
    \ and ACE4_LIST_DIRECTORY.  The mask entries\n   ACE4_LIST_DIRECTORY, ACE4_ADD_FILE,\
    \ and ACE4_ADD_SUBDIRECTORY are\n   intended to be used with directory objects,\
    \ while ACE4_READ_DATA,\n   ACE4_WRITE_DATA, and ACE4_APPEND_DATA are intended\
    \ to be used with\n   non-directory objects.\n"
- title: 6.2.1.3.1.  Discussion of Mask Attributes
  contents:
  - "6.2.1.3.1.  Discussion of Mask Attributes\n   ACE4_READ_DATA\n      Operation(s)\
    \ affected:\n         READ\n         OPEN\n      Discussion:\n         Permission\
    \ to read the data of the file.\n         Servers SHOULD allow a user the ability\
    \ to read the data of the\n         file when only the ACE4_EXECUTE access mask\
    \ bit is allowed.\n   ACE4_LIST_DIRECTORY\n      Operation(s) affected:\n    \
    \     READDIR\n      Discussion:\n         Permission to list the contents of\
    \ a directory.\n   ACE4_WRITE_DATA\n      Operation(s) affected:\n         WRITE\n\
    \         OPEN\n         SETATTR of size\n      Discussion:\n         Permission\
    \ to modify a file's data.\n   ACE4_ADD_FILE\n      Operation(s) affected:\n \
    \        CREATE\n         LINK\n         OPEN\n         RENAME\n      Discussion:\n\
    \         Permission to add a new file in a directory.  The CREATE\n         operation\
    \ is affected when nfs_ftype4 is NF4LNK, NF4BLK,\n         NF4CHR, NF4SOCK, or\
    \ NF4FIFO.  (NF4DIR is not listed because it\n         is covered by ACE4_ADD_SUBDIRECTORY.)\
    \  OPEN is affected when\n         used to create a regular file.  LINK and RENAME\
    \ are always\n         affected.\n   ACE4_APPEND_DATA\n      Operation(s) affected:\n\
    \         WRITE\n         OPEN\n         SETATTR of size\n      Discussion:\n\
    \         The ability to modify a file's data, but only starting at EOF.\n   \
    \      This allows for the notion of append-only files, by allowing\n        \
    \ ACE4_APPEND_DATA and denying ACE4_WRITE_DATA to the same user\n         or group.\
    \  If a file has an ACL such as the one described above\n         and a WRITE\
    \ request is made for somewhere other than EOF, the\n         server SHOULD return\
    \ NFS4ERR_ACCESS.\n   ACE4_ADD_SUBDIRECTORY\n      Operation(s) affected:\n  \
    \       CREATE\n         RENAME\n      Discussion:\n         Permission to create\
    \ a subdirectory in a directory.  The CREATE\n         operation is affected when\
    \ nfs_ftype4 is NF4DIR.  The RENAME\n         operation is always affected.\n\
    \   ACE4_READ_NAMED_ATTRS\n      Operation(s) affected:\n         OPENATTR\n \
    \     Discussion:\n         Permission to read the named attributes of a file\
    \ or to look up\n         the named attribute directory.  OPENATTR is affected\
    \ when it is\n         not used to create a named attribute directory.  This is\
    \ when\n         1) createdir is TRUE, but a named attribute directory already\n\
    \         exists, or 2) createdir is FALSE.\n   ACE4_WRITE_NAMED_ATTRS\n     \
    \ Operation(s) affected:\n         OPENATTR\n      Discussion:\n         Permission\
    \ to write the named attributes of a file or to create\n         a named attribute\
    \ directory.  OPENATTR is affected when it is\n         used to create a named\
    \ attribute directory.  This is when\n         createdir is TRUE and no named\
    \ attribute directory exists.  The\n         ability to check whether or not a\
    \ named attribute directory\n         exists depends on the ability to look it\
    \ up; therefore, users\n         also need the ACE4_READ_NAMED_ATTRS permission\
    \ in order to\n         create a named attribute directory.\n   ACE4_EXECUTE\n\
    \      Operation(s) affected:\n         READ\n         OPEN\n         REMOVE\n\
    \         RENAME\n         LINK\n         CREATE\n      Discussion:\n        \
    \ Permission to execute a file.\n         Servers SHOULD allow a user the ability\
    \ to read the data of the\n         file when only the ACE4_EXECUTE access mask\
    \ bit is allowed.\n         This is because there is no way to execute a file\
    \ without\n         reading the contents.  Though a server may treat ACE4_EXECUTE\n\
    \         and ACE4_READ_DATA bits identically when deciding to permit a\n    \
    \     READ operation, it SHOULD still allow the two bits to be set\n         independently\
    \ in ACLs, and MUST distinguish between them when\n         replying to ACCESS\
    \ operations.  In particular, servers SHOULD\n         NOT silently turn on one\
    \ of the two bits when the other is set,\n         as that would make it impossible\
    \ for the client to correctly\n         enforce the distinction between read and\
    \ execute permissions.\n         As an example, following a SETATTR of the following\
    \ ACL:\n            nfsuser:ACE4_EXECUTE:ALLOW\n         A subsequent GETATTR\
    \ of ACL for that file SHOULD return:\n            nfsuser:ACE4_EXECUTE:ALLOW\n\
    \         Rather than:\n            nfsuser:ACE4_EXECUTE/ACE4_READ_DATA:ALLOW\n\
    \   ACE4_EXECUTE\n      Operation(s) affected:\n         LOOKUP\n      Discussion:\n\
    \         Permission to traverse/search a directory.\n   ACE4_DELETE_CHILD\n \
    \     Operation(s) affected:\n         REMOVE\n         RENAME\n      Discussion:\n\
    \         Permission to delete a file or directory within a directory.\n     \
    \    See Section 6.2.1.3.2 for information on ACE4_DELETE and\n         ACE4_DELETE_CHILD\
    \ interact.\n   ACE4_READ_ATTRIBUTES\n      Operation(s) affected:\n         GETATTR\
    \ of file system object attributes\n         VERIFY\n         NVERIFY\n      \
    \   READDIR\n      Discussion:\n         The ability to read basic attributes\
    \ (non-ACLs) of a file.  On\n         a UNIX system, basic attributes can be thought\
    \ of as the stat-\n         level attributes.  Allowing this access mask bit would\
    \ mean\n         that the entity can execute \"ls -l\" and stat.  If a READDIR\n\
    \         operation requests attributes, this mask must be allowed for\n     \
    \    the READDIR to succeed.\n   ACE4_WRITE_ATTRIBUTES\n      Operation(s) affected:\n\
    \         SETATTR of time_access_set, time_backup,\n         time_create, time_modify_set,\
    \ mimetype, hidden, system\n      Discussion:\n         Permission to change the\
    \ times associated with a file or\n         directory to an arbitrary value. \
    \ Also permission to change the\n         mimetype, hidden, and system attributes.\
    \  A user having\n         ACE4_WRITE_DATA or ACE4_WRITE_ATTRIBUTES will be allowed\
    \ to set\n         the times associated with a file to the current server time.\n\
    \   ACE4_WRITE_RETENTION\n      Operation(s) affected:\n         SETATTR of retention_set,\
    \ retentevt_set.\n      Discussion:\n         Permission to modify the durations\
    \ of event and non-event-based\n         retention.  Also permission to enable\
    \ event and non-event-based\n         retention.  A server MAY behave such that\
    \ setting\n         ACE4_WRITE_ATTRIBUTES allows ACE4_WRITE_RETENTION.\n   ACE4_WRITE_RETENTION_HOLD\n\
    \      Operation(s) affected:\n         SETATTR of retention_hold.\n      Discussion:\n\
    \         Permission to modify the administration retention holds.  A\n      \
    \   server MAY map ACE4_WRITE_ATTRIBUTES to\n         ACE_WRITE_RETENTION_HOLD.\n\
    \   ACE4_DELETE\n      Operation(s) affected:\n         REMOVE\n      Discussion:\n\
    \         Permission to delete the file or directory.  See\n         Section 6.2.1.3.2\
    \ for information on ACE4_DELETE and\n         ACE4_DELETE_CHILD interact.\n \
    \  ACE4_READ_ACL\n      Operation(s) affected:\n         GETATTR of acl, dacl,\
    \ or sacl\n         NVERIFY\n         VERIFY\n      Discussion:\n         Permission\
    \ to read the ACL.\n   ACE4_WRITE_ACL\n      Operation(s) affected:\n        \
    \ SETATTR of acl and mode\n      Discussion:\n         Permission to write the\
    \ acl and mode attributes.\n   ACE4_WRITE_OWNER\n      Operation(s) affected:\n\
    \         SETATTR of owner and owner_group\n      Discussion:\n         Permission\
    \ to write the owner and owner_group attributes.  On\n         UNIX systems, this\
    \ is the ability to execute chown() and\n         chgrp().\n   ACE4_SYNCHRONIZE\n\
    \      Operation(s) affected:\n         NONE\n      Discussion:\n         Permission\
    \ to use the file object as a synchronization\n         primitive for interprocess\
    \ communication.  This permission is\n         not enforced or interpreted by\
    \ the NFSv4.1 server on behalf of\n         the client.\n         Typically, the\
    \ ACE4_SYNCHRONIZE permission is only meaningful\n         on local file systems,\
    \ i.e., file systems not accessed via\n         NFSv4.1.  The reason that the\
    \ permission bit exists is that\n         some operating environments, such as\
    \ Windows, use\n         ACE4_SYNCHRONIZE.\n         For example, if a client\
    \ copies a file that has\n         ACE4_SYNCHRONIZE set from a local file system\
    \ to an NFSv4.1\n         server, and then later copies the file from the NFSv4.1\
    \ server\n         to a local file system, it is likely that if ACE4_SYNCHRONIZE\n\
    \         was set in the original file, the client will want it set in\n     \
    \    the second copy.  The first copy will not have the permission\n         set\
    \ unless the NFSv4.1 server has the means to set the\n         ACE4_SYNCHRONIZE\
    \ bit.  The second copy will not have the\n         permission set unless the\
    \ NFSv4.1 server has the means to\n         retrieve the ACE4_SYNCHRONIZE bit.\n\
    \   Server implementations need not provide the granularity of control\n   that\
    \ is implied by this list of masks.  For example, POSIX-based\n   systems might\
    \ not distinguish ACE4_APPEND_DATA (the ability to append\n   to a file) from\
    \ ACE4_WRITE_DATA (the ability to modify existing\n   contents); both masks would\
    \ be tied to a single \"write\" permission\n   [17].  When such a server returns\
    \ attributes to the client, it would\n   show both ACE4_APPEND_DATA and ACE4_WRITE_DATA\
    \ if and only if the\n   write permission is enabled.\n   If a server receives\
    \ a SETATTR request that it cannot accurately\n   implement, it should err in\
    \ the direction of more restricted access,\n   except in the previously discussed\
    \ cases of execute and read.  For\n   example, suppose a server cannot distinguish\
    \ overwriting data from\n   appending new data, as described in the previous paragraph.\
    \  If a\n   client submits an ALLOW ACE where ACE4_APPEND_DATA is set but\n  \
    \ ACE4_WRITE_DATA is not (or vice versa), the server should either turn\n   off\
    \ ACE4_APPEND_DATA or reject the request with NFS4ERR_ATTRNOTSUPP.\n"
- title: 6.2.1.3.2.  ACE4_DELETE vs. ACE4_DELETE_CHILD
  contents:
  - "6.2.1.3.2.  ACE4_DELETE vs. ACE4_DELETE_CHILD\n   Two access mask bits govern\
    \ the ability to delete a directory entry:\n   ACE4_DELETE on the object itself\
    \ (the \"target\") and ACE4_DELETE_CHILD\n   on the containing directory (the\
    \ \"parent\").\n   Many systems also take the \"sticky bit\" (MODE4_SVTX) on a\
    \ directory\n   to allow unlink only to a user that owns either the target or\
    \ the\n   parent; on some such systems the decision also depends on whether the\n\
    \   target is writable.\n   Servers SHOULD allow unlink if either ACE4_DELETE\
    \ is permitted on the\n   target, or ACE4_DELETE_CHILD is permitted on the parent.\
    \  (Note that\n   this is true even if the parent or target explicitly denies\
    \ one of\n   these permissions.)\n   If the ACLs in question neither explicitly\
    \ ALLOW nor DENY either of\n   the above, and if MODE4_SVTX is not set on the\
    \ parent, then the\n   server SHOULD allow the removal if and only if ACE4_ADD_FILE\
    \ is\n   permitted.  In the case where MODE4_SVTX is set, the server may also\n\
    \   require the remover to own either the parent or the target, or may\n   require\
    \ the target to be writable.\n   This allows servers to support something close\
    \ to traditional UNIX-\n   like semantics, with ACE4_ADD_FILE taking the place\
    \ of the write bit.\n"
- title: 6.2.1.4.  ACE flag
  contents:
  - "6.2.1.4.  ACE flag\n   The bitmask constants used for the flag field are as follows:\n\
    \   const ACE4_FILE_INHERIT_ACE             = 0x00000001;\n   const ACE4_DIRECTORY_INHERIT_ACE\
    \        = 0x00000002;\n   const ACE4_NO_PROPAGATE_INHERIT_ACE     = 0x00000004;\n\
    \   const ACE4_INHERIT_ONLY_ACE             = 0x00000008;\n   const ACE4_SUCCESSFUL_ACCESS_ACE_FLAG\
    \   = 0x00000010;\n   const ACE4_FAILED_ACCESS_ACE_FLAG       = 0x00000020;\n\
    \   const ACE4_IDENTIFIER_GROUP             = 0x00000040;\n   const ACE4_INHERITED_ACE\
    \                = 0x00000080;\n   A server need not support any of these flags.\
    \  If the server supports\n   flags that are similar to, but not exactly the same\
    \ as, these flags,\n   the implementation may define a mapping between the protocol-defined\n\
    \   flags and the implementation-defined flags.\n   For example, suppose a client\
    \ tries to set an ACE with\n   ACE4_FILE_INHERIT_ACE set but not ACE4_DIRECTORY_INHERIT_ACE.\
    \  If the\n   server does not support any form of ACL inheritance, the server\n\
    \   should reject the request with NFS4ERR_ATTRNOTSUPP.  If the server\n   supports\
    \ a single \"inherit ACE\" flag that applies to both files and\n   directories,\
    \ the server may reject the request (i.e., requiring the\n   client to set both\
    \ the file and directory inheritance flags).  The\n   server may also accept the\
    \ request and silently turn on the\n   ACE4_DIRECTORY_INHERIT_ACE flag.\n"
- title: 6.2.1.4.1.  Discussion of Flag Bits
  contents:
  - "6.2.1.4.1.  Discussion of Flag Bits\n   ACE4_FILE_INHERIT_ACE\n      Any non-directory\
    \ file in any sub-directory will get this ACE\n      inherited.\n   ACE4_DIRECTORY_INHERIT_ACE\n\
    \      Can be placed on a directory and indicates that this ACE should be\n  \
    \    added to each new directory created.\n      If this flag is set in an ACE\
    \ in an ACL attribute to be set on a\n      non-directory file system object,\
    \ the operation attempting to set\n      the ACL SHOULD fail with NFS4ERR_ATTRNOTSUPP.\n\
    \   ACE4_NO_PROPAGATE_INHERIT_ACE\n      Can be placed on a directory.  This flag\
    \ tells the server that\n      inheritance of this ACE should stop at newly created\
    \ child\n      directories.\n   ACE4_INHERIT_ONLY_ACE\n      Can be placed on\
    \ a directory but does not apply to the directory;\n      ALLOW and DENY ACEs\
    \ with this bit set do not affect access to the\n      directory, and AUDIT and\
    \ ALARM ACEs with this bit set do not\n      trigger log or alarm events.  Such\
    \ ACEs only take effect once they\n      are applied (with this bit cleared) to\
    \ newly created files and\n      directories as specified by the ACE4_FILE_INHERIT_ACE\
    \ and\n      ACE4_DIRECTORY_INHERIT_ACE flags.\n      If this flag is present\
    \ on an ACE, but neither\n      ACE4_DIRECTORY_INHERIT_ACE nor ACE4_FILE_INHERIT_ACE\
    \ is present,\n      then an operation attempting to set such an attribute SHOULD\
    \ fail\n      with NFS4ERR_ATTRNOTSUPP.\n   ACE4_SUCCESSFUL_ACCESS_ACE_FLAG and\
    \ ACE4_FAILED_ACCESS_ACE_FLAG\n      The ACE4_SUCCESSFUL_ACCESS_ACE_FLAG (SUCCESS)\
    \ and\n      ACE4_FAILED_ACCESS_ACE_FLAG (FAILED) flag bits may be set only on\n\
    \      ACE4_SYSTEM_AUDIT_ACE_TYPE (AUDIT) and ACE4_SYSTEM_ALARM_ACE_TYPE\n   \
    \   (ALARM) ACE types.  If during the processing of the file's ACL,\n      the\
    \ server encounters an AUDIT or ALARM ACE that matches the\n      principal attempting\
    \ the OPEN, the server notes that fact, and the\n      presence, if any, of the\
    \ SUCCESS and FAILED flags encountered in\n      the AUDIT or ALARM ACE.  Once\
    \ the server completes the ACL\n      processing, it then notes if the operation\
    \ succeeded or failed.\n      If the operation succeeded, and if the SUCCESS flag\
    \ was set for a\n      matching AUDIT or ALARM ACE, then the appropriate AUDIT\
    \ or ALARM\n      event occurs.  If the operation failed, and if the FAILED flag\
    \ was\n      set for the matching AUDIT or ALARM ACE, then the appropriate\n \
    \     AUDIT or ALARM event occurs.  Either or both of the SUCCESS or\n      FAILED\
    \ can be set, but if neither is set, the AUDIT or ALARM ACE\n      is not useful.\n\
    \      The previously described processing applies to ACCESS operations\n    \
    \  even when they return NFS4_OK.  For the purposes of AUDIT and\n      ALARM,\
    \ we consider an ACCESS operation to be a \"failure\" if it\n      fails to return\
    \ a bit that was requested and supported.\n   ACE4_IDENTIFIER_GROUP\n      Indicates\
    \ that the \"who\" refers to a GROUP as defined under UNIX\n      or a GROUP ACCOUNT\
    \ as defined under Windows.  Clients and servers\n      MUST ignore the ACE4_IDENTIFIER_GROUP\
    \ flag on ACEs with a who\n      value equal to one of the special identifiers\
    \ outlined in\n      Section 6.2.1.5.\n   ACE4_INHERITED_ACE\n      Indicates\
    \ that this ACE is inherited from a parent directory.  A\n      server that supports\
    \ automatic inheritance will place this flag on\n      any ACEs inherited from\
    \ the parent directory when creating a new\n      object.  Client applications\
    \ will use this to perform automatic\n      inheritance.  Clients and servers\
    \ MUST clear this bit in the acl\n      attribute; it may only be used in the\
    \ dacl and sacl attributes.\n"
- title: 6.2.1.5.  ACE Who
  contents:
  - "6.2.1.5.  ACE Who\n   The \"who\" field of an ACE is an identifier that specifies\
    \ the\n   principal or principals to whom the ACE applies.  It may refer to a\n\
    \   user or a group, with the flag bit ACE4_IDENTIFIER_GROUP specifying\n   which.\n\
    \   There are several special identifiers that need to be understood\n   universally,\
    \ rather than in the context of a particular DNS domain.\n   Some of these identifiers\
    \ cannot be understood when an NFS client\n   accesses the server, but have meaning\
    \ when a local process accesses\n   the file.  The ability to display and modify\
    \ these permissions is\n   permitted over NFS, even if none of the access methods\
    \ on the server\n   understands the identifiers.\n   | Who           | Description\
    \                                      |\n   | OWNER         | The owner of the\
    \ file.                           |\n   | GROUP         | The group associated\
    \ with the file.              |\n   | EVERYONE      | The world, including the\
    \ owner and owning group. |\n   | INTERACTIVE   | Accessed from an interactive\
    \ terminal.           |\n   | NETWORK       | Accessed via the network.      \
    \                  |\n   | DIALUP        | Accessed as a dialup user to the server.\
    \         |\n   | BATCH         | Accessed from a batch job.                 \
    \      |\n   | ANONYMOUS     | Accessed without any authentication.          \
    \   |\n   | AUTHENTICATED | Any authenticated user (opposite of ANONYMOUS).  |\n\
    \   | SERVICE       | Access from a system service.                    |\n   To\
    \ avoid conflict, these special identifiers are distinguished by an\n   appended\
    \ \"@\" and should appear in the form \"xxxx@\" (with no domain\n   name after\
    \ the \"@\"), for example, ANONYMOUS@.\n   The ACE4_IDENTIFIER_GROUP flag MUST\
    \ be ignored on entries with these\n   special identifiers.  When encoding entries\
    \ with these special\n   identifiers, the ACE4_IDENTIFIER_GROUP flag SHOULD be\
    \ set to zero.\n"
- title: 6.2.1.5.1.  Discussion of EVERYONE@
  contents:
  - "6.2.1.5.1.  Discussion of EVERYONE@\n   It is important to note that \"EVERYONE@\"\
    \ is not equivalent to the\n   UNIX \"other\" entity.  This is because, by definition,\
    \ UNIX \"other\"\n   does not include the owner or owning group of a file.  \"\
    EVERYONE@\"\n   means literally everyone, including the owner or owning group.\n"
- title: '6.2.2.  Attribute 58: dacl'
  contents:
  - "6.2.2.  Attribute 58: dacl\n   The dacl attribute is like the acl attribute,\
    \ but dacl allows just\n   ALLOW and DENY ACEs.  The dacl attribute supports automatic\n\
    \   inheritance (see Section 6.4.3.2).\n"
- title: '6.2.3.  Attribute 59: sacl'
  contents:
  - "6.2.3.  Attribute 59: sacl\n   The sacl attribute is like the acl attribute,\
    \ but sacl allows just\n   AUDIT and ALARM ACEs.  The sacl attribute supports\
    \ automatic\n   inheritance (see Section 6.4.3.2).\n"
- title: '6.2.4.  Attribute 33: mode'
  contents:
  - "6.2.4.  Attribute 33: mode\n   The NFSv4.1 mode attribute is based on the UNIX\
    \ mode bits.  The\n   following bits are defined:\n   const MODE4_SUID = 0x800;\
    \  /* set user id on execution */\n   const MODE4_SGID = 0x400;  /* set group\
    \ id on execution */\n   const MODE4_SVTX = 0x200;  /* save text even after use\
    \ */\n   const MODE4_RUSR = 0x100;  /* read permission: owner */\n   const MODE4_WUSR\
    \ = 0x080;  /* write permission: owner */\n   const MODE4_XUSR = 0x040;  /* execute\
    \ permission: owner */\n   const MODE4_RGRP = 0x020;  /* read permission: group\
    \ */\n   const MODE4_WGRP = 0x010;  /* write permission: group */\n   const MODE4_XGRP\
    \ = 0x008;  /* execute permission: group */\n   const MODE4_ROTH = 0x004;  /*\
    \ read permission: other */\n   const MODE4_WOTH = 0x002;  /* write permission:\
    \ other */\n   const MODE4_XOTH = 0x001;  /* execute permission: other */\n  \
    \ Bits MODE4_RUSR, MODE4_WUSR, and MODE4_XUSR apply to the principal\n   identified\
    \ in the owner attribute.  Bits MODE4_RGRP, MODE4_WGRP, and\n   MODE4_XGRP apply\
    \ to principals identified in the owner_group\n   attribute but who are not identified\
    \ in the owner attribute.  Bits\n   MODE4_ROTH, MODE4_WOTH, and MODE4_XOTH apply\
    \ to any principal that\n   does not match that in the owner attribute and does\
    \ not have a group\n   matching that of the owner_group attribute.\n   Bits within\
    \ a mode other than those specified above are not defined\n   by this protocol.\
    \  A server MUST NOT return bits other than those\n   defined above in a GETATTR\
    \ or READDIR operation, and it MUST return\n   NFS4ERR_INVAL if bits other than\
    \ those defined above are set in a\n   SETATTR, CREATE, OPEN, VERIFY, or NVERIFY\
    \ operation.\n"
- title: '6.2.5.  Attribute 74: mode_set_masked'
  contents:
  - "6.2.5.  Attribute 74: mode_set_masked\n   The mode_set_masked attribute is a\
    \ write-only attribute that allows\n   individual bits in the mode attribute to\
    \ be set or reset, without\n   changing others.  It allows, for example, the bits\
    \ MODE4_SUID,\n   MODE4_SGID, and MODE4_SVTX to be modified while leaving unmodified\n\
    \   any of the nine low-order mode bits devoted to permissions.\n   In such instances\
    \ that the nine low-order bits are left unmodified,\n   then neither the acl nor\
    \ the dacl attribute should be automatically\n   modified as discussed in Section\
    \ 6.4.1.\n   The mode_set_masked attribute consists of two words, each in the\
    \ form\n   of a mode4.  The first consists of the value to be applied to the\n\
    \   current mode value and the second is a mask.  Only bits set to one in\n  \
    \ the mask word are changed (set or reset) in the file's mode.  All\n   other\
    \ bits in the mode remain unchanged.  Bits in the first word that\n   correspond\
    \ to bits that are zero in the mask are ignored, except that\n   undefined bits\
    \ are checked for validity and can result in\n   NFS4ERR_INVAL as described below.\n\
    \   The mode_set_masked attribute is only valid in a SETATTR operation.\n   If\
    \ it is used in a CREATE or OPEN operation, the server MUST return\n   NFS4ERR_INVAL.\n\
    \   Bits not defined as valid in the mode attribute are not valid in\n   either\
    \ word of the mode_set_masked attribute.  The server MUST return\n   NFS4ERR_INVAL\
    \ if any such bits are set to one in a SETATTR.  If the\n   mode and mode_set_masked\
    \ attributes are both specified in the same\n   SETATTR, the server MUST also\
    \ return NFS4ERR_INVAL.\n"
- title: 6.3.  Common Methods
  contents:
  - "6.3.  Common Methods\n   The requirements in this section will be referred to\
    \ in future\n   sections, especially Section 6.4.\n"
- title: 6.3.1.  Interpreting an ACL
  contents:
  - '6.3.1.  Interpreting an ACL

    '
- title: 6.3.1.1.  Server Considerations
  contents:
  - "6.3.1.1.  Server Considerations\n   The server uses the algorithm described in\
    \ Section 6.2.1 to determine\n   whether an ACL allows access to an object.  However,\
    \ the ACL might\n   not be the sole determiner of access.  For example:\n   *\
    \  In the case of a file system exported as read-only, the server may\n      deny\
    \ write access even though an object's ACL grants it.\n   *  Server implementations\
    \ MAY grant ACE4_WRITE_ACL and ACE4_READ_ACL\n      permissions to prevent a situation\
    \ from arising in which there is\n      no valid way to ever modify the ACL.\n\
    \   *  All servers will allow a user the ability to read the data of the\n   \
    \   file when only the execute permission is granted (i.e., if the ACL\n     \
    \ denies the user the ACE4_READ_DATA access and allows the user\n      ACE4_EXECUTE,\
    \ the server will allow the user to read the data of\n      the file).\n   * \
    \ Many servers have the notion of owner-override in which the owner\n      of\
    \ the object is allowed to override accesses that are denied by\n      the ACL.\
    \  This may be helpful, for example, to allow users\n      continued access to\
    \ open files on which the permissions have\n      changed.\n   *  Many servers\
    \ have the notion of a \"superuser\" that has privileges\n      beyond an ordinary\
    \ user.  The superuser may be able to read or\n      write data or metadata in\
    \ ways that would not be permitted by the\n      ACL.\n   *  A retention attribute\
    \ might also block access otherwise allowed by\n      ACLs (see Section 5.13).\n"
- title: 6.3.1.2.  Client Considerations
  contents:
  - "6.3.1.2.  Client Considerations\n   Clients SHOULD NOT do their own access checks\
    \ based on their\n   interpretation of the ACL, but rather use the OPEN and ACCESS\n\
    \   operations to do access checks.  This allows the client to act on the\n  \
    \ results of having the server determine whether or not access should\n   be granted\
    \ based on its interpretation of the ACL.\n   Clients must be aware of situations\
    \ in which an object's ACL will\n   define a certain access even though the server\
    \ will not enforce it.\n   In general, but especially in these situations, the\
    \ client needs to\n   do its part in the enforcement of access as defined by the\
    \ ACL.  To\n   do this, the client MAY send the appropriate ACCESS operation prior\n\
    \   to servicing the request of the user or application in order to\n   determine\
    \ whether the user or application should be granted the\n   access requested.\
    \  For examples in which the ACL may define accesses\n   that the server doesn't\
    \ enforce, see Section 6.3.1.1.\n"
- title: 6.3.2.  Computing a Mode Attribute from an ACL
  contents:
  - "6.3.2.  Computing a Mode Attribute from an ACL\n   The following method can be\
    \ used to calculate the MODE4_R*, MODE4_W*,\n   and MODE4_X* bits of a mode attribute,\
    \ based upon an ACL.\n   First, for each of the special identifiers OWNER@, GROUP@,\
    \ and\n   EVERYONE@, evaluate the ACL in order, considering only ALLOW and DENY\n\
    \   ACEs for the identifier EVERYONE@ and for the identifier under\n   consideration.\
    \  The result of the evaluation will be an NFSv4 ACL\n   mask showing exactly\
    \ which bits are permitted to that identifier.\n   Then translate the calculated\
    \ mask for OWNER@, GROUP@, and EVERYONE@\n   into mode bits for, respectively,\
    \ the user, group, and other, as\n   follows:\n   1.  Set the read bit (MODE4_RUSR,\
    \ MODE4_RGRP, or MODE4_ROTH) if and\n       only if ACE4_READ_DATA is set in the\
    \ corresponding mask.\n   2.  Set the write bit (MODE4_WUSR, MODE4_WGRP, or MODE4_WOTH)\
    \ if and\n       only if ACE4_WRITE_DATA and ACE4_APPEND_DATA are both set in\
    \ the\n       corresponding mask.\n   3.  Set the execute bit (MODE4_XUSR, MODE4_XGRP,\
    \ or MODE4_XOTH), if\n       and only if ACE4_EXECUTE is set in the corresponding\
    \ mask.\n"
- title: 6.3.2.1.  Discussion
  contents:
  - "6.3.2.1.  Discussion\n   Some server implementations also add bits permitted\
    \ to named users\n   and groups to the group bits (MODE4_RGRP, MODE4_WGRP, and\n\
    \   MODE4_XGRP).\n   Implementations are discouraged from doing this, because\
    \ it has been\n   found to cause confusion for users who see members of a file's\
    \ group\n   denied access that the mode bits appear to allow.  (The presence of\n\
    \   DENY ACEs may also lead to such behavior, but DENY ACEs are expected\n   to\
    \ be more rarely used.)\n   The same user confusion seen when fetching the mode\
    \ also results if\n   setting the mode does not effectively control permissions\
    \ for the\n   owner, group, and other users; this motivates some of the\n   requirements\
    \ that follow.\n"
- title: 6.4.  Requirements
  contents:
  - "6.4.  Requirements\n   The server that supports both mode and ACL must take care\
    \ to\n   synchronize the MODE4_*USR, MODE4_*GRP, and MODE4_*OTH bits with the\n\
    \   ACEs that have respective who fields of \"OWNER@\", \"GROUP@\", and\n   \"\
    EVERYONE@\".  This way, the client can see if semantically equivalent\n   access\
    \ permissions exist whether the client asks for the owner,\n   owner_group, and\
    \ mode attributes or for just the ACL.\n   In this section, much is made of the\
    \ methods in Section 6.3.2.  Many\n   requirements refer to this section.  But\
    \ note that the methods have\n   behaviors specified with \"SHOULD\".  This is\
    \ intentional, to avoid\n   invalidating existing implementations that compute\
    \ the mode according\n   to the withdrawn POSIX ACL draft (1003.1e draft 17),\
    \ rather than by\n   actual permissions on owner, group, and other.\n"
- title: 6.4.1.  Setting the Mode and/or ACL Attributes
  contents:
  - "6.4.1.  Setting the Mode and/or ACL Attributes\n   In the case where a server\
    \ supports the sacl or dacl attribute, in\n   addition to the acl attribute, the\
    \ server MUST fail a request to set\n   the acl attribute simultaneously with\
    \ a dacl or sacl attribute.  The\n   error to be given is NFS4ERR_ATTRNOTSUPP.\n"
- title: 6.4.1.1.  Setting Mode and not ACL
  contents:
  - "6.4.1.1.  Setting Mode and not ACL\n   When any of the nine low-order mode bits\
    \ are subject to change,\n   either because the mode attribute was set or because\
    \ the\n   mode_set_masked attribute was set and the mask included one or more\n\
    \   bits from the nine low-order mode bits, and no ACL attribute is\n   explicitly\
    \ set, the acl and dacl attributes must be modified in\n   accordance with the\
    \ updated value of those bits.  This must happen\n   even if the value of the\
    \ low-order bits is the same after the mode is\n   set as before.\n   Note that\
    \ any AUDIT or ALARM ACEs (hence any ACEs in the sacl\n   attribute) are unaffected\
    \ by changes to the mode.\n   In cases in which the permissions bits are subject\
    \ to change, the acl\n   and dacl attributes MUST be modified such that the mode\
    \ computed via\n   the method in Section 6.3.2 yields the low-order nine bits\
    \ (MODE4_R*,\n   MODE4_W*, MODE4_X*) of the mode attribute as modified by the\n\
    \   attribute change.  The ACL attributes SHOULD also be modified such\n   that:\n\
    \   1.  If MODE4_RGRP is not set, entities explicitly listed in the ACL\n    \
    \   other than OWNER@ and EVERYONE@ SHOULD NOT be granted\n       ACE4_READ_DATA.\n\
    \   2.  If MODE4_WGRP is not set, entities explicitly listed in the ACL\n    \
    \   other than OWNER@ and EVERYONE@ SHOULD NOT be granted\n       ACE4_WRITE_DATA\
    \ or ACE4_APPEND_DATA.\n   3.  If MODE4_XGRP is not set, entities explicitly listed\
    \ in the ACL\n       other than OWNER@ and EVERYONE@ SHOULD NOT be granted\n \
    \      ACE4_EXECUTE.\n   Access mask bits other than those listed above, appearing\
    \ in ALLOW\n   ACEs, MAY also be disabled.\n   Note that ACEs with the flag ACE4_INHERIT_ONLY_ACE\
    \ set do not affect\n   the permissions of the ACL itself, nor do ACEs of the\
    \ type AUDIT and\n   ALARM.  As such, it is desirable to leave these ACEs unmodified\
    \ when\n   modifying the ACL attributes.\n   Also note that the requirement may\
    \ be met by discarding the acl and\n   dacl, in favor of an ACL that represents\
    \ the mode and only the mode.\n   This is permitted, but it is preferable for\
    \ a server to preserve as\n   much of the ACL as possible without violating the\
    \ above requirements.\n   Discarding the ACL makes it effectively impossible for\
    \ a file created\n   with a mode attribute to inherit an ACL (see Section 6.4.3).\n"
- title: 6.4.1.2.  Setting ACL and Not Mode
  contents:
  - "6.4.1.2.  Setting ACL and Not Mode\n   When setting the acl or dacl and not setting\
    \ the mode or\n   mode_set_masked attributes, the permission bits of the mode\
    \ need to\n   be derived from the ACL.  In this case, the ACL attribute SHOULD\
    \ be\n   set as given.  The nine low-order bits of the mode attribute\n   (MODE4_R*,\
    \ MODE4_W*, MODE4_X*) MUST be modified to match the result\n   of the method in\
    \ Section 6.3.2.  The three high-order bits of the\n   mode (MODE4_SUID, MODE4_SGID,\
    \ MODE4_SVTX) SHOULD remain unchanged.\n"
- title: 6.4.1.3.  Setting Both ACL and Mode
  contents:
  - "6.4.1.3.  Setting Both ACL and Mode\n   When setting both the mode (includes\
    \ use of either the mode attribute\n   or the mode_set_masked attribute) and the\
    \ acl or dacl attributes in\n   the same operation, the attributes MUST be applied\
    \ in this order:\n   mode (or mode_set_masked), then ACL.  The mode-related attribute\
    \ is\n   set as given, then the ACL attribute is set as given, possibly\n   changing\
    \ the final mode, as described above in Section 6.4.1.2.\n"
- title: 6.4.2.  Retrieving the Mode and/or ACL Attributes
  contents:
  - "6.4.2.  Retrieving the Mode and/or ACL Attributes\n   This section applies only\
    \ to servers that support both the mode and\n   ACL attributes.\n   Some server\
    \ implementations may have a concept of \"objects without\n   ACLs\", meaning\
    \ that all permissions are granted and denied according\n   to the mode attribute\
    \ and that no ACL attribute is stored for that\n   object.  If an ACL attribute\
    \ is requested of such a server, the\n   server SHOULD return an ACL that does\
    \ not conflict with the mode;\n   that is to say, the ACL returned SHOULD represent\
    \ the nine low-order\n   bits of the mode attribute (MODE4_R*, MODE4_W*, MODE4_X*)\
    \ as\n   described in Section 6.3.2.\n   For other server implementations, the\
    \ ACL attribute is always present\n   for every object.  Such servers SHOULD store\
    \ at least the three high-\n   order bits of the mode attribute (MODE4_SUID, MODE4_SGID,\n\
    \   MODE4_SVTX).  The server SHOULD return a mode attribute if one is\n   requested,\
    \ and the low-order nine bits of the mode (MODE4_R*,\n   MODE4_W*, MODE4_X*) MUST\
    \ match the result of applying the method in\n   Section 6.3.2 to the ACL attribute.\n"
- title: 6.4.3.  Creating New Objects
  contents:
  - "6.4.3.  Creating New Objects\n   If a server supports any ACL attributes, it\
    \ may use the ACL\n   attributes on the parent directory to compute an initial\
    \ ACL\n   attribute for a newly created object.  This will be referred to as\n\
    \   the inherited ACL within this section.  The act of adding one or more\n  \
    \ ACEs to the inherited ACL that are based upon ACEs in the parent\n   directory's\
    \ ACL will be referred to as inheriting an ACE within this\n   section.\n   Implementors\
    \ should standardize what the behavior of CREATE and OPEN\n   must be depending\
    \ on the presence or absence of the mode and ACL\n   attributes.\n   1.  If just\
    \ the mode is given in the call:\n       In this case, inheritance SHOULD take\
    \ place, but the mode MUST be\n       applied to the inherited ACL as described\
    \ in Section 6.4.1.1,\n       thereby modifying the ACL.\n   2.  If just the ACL\
    \ is given in the call:\n       In this case, inheritance SHOULD NOT take place,\
    \ and the ACL as\n       defined in the CREATE or OPEN will be set without modification,\n\
    \       and the mode modified as in Section 6.4.1.2.\n   3.  If both mode and\
    \ ACL are given in the call:\n       In this case, inheritance SHOULD NOT take\
    \ place, and both\n       attributes will be set as described in Section 6.4.1.3.\n\
    \   4.  If neither mode nor ACL is given in the call:\n       In the case where\
    \ an object is being created without any initial\n       attributes at all, e.g.,\
    \ an OPEN operation with an opentype4 of\n       OPEN4_CREATE and a createmode4\
    \ of EXCLUSIVE4, inheritance SHOULD\n       NOT take place (note that EXCLUSIVE4_1\
    \ is a better choice of\n       createmode4, since it does permit initial attributes).\
    \  Instead,\n       the server SHOULD set permissions to deny all access to the\
    \ newly\n       created object.  It is expected that the appropriate client will\n\
    \       set the desired attributes in a subsequent SETATTR operation, and\n  \
    \     the server SHOULD allow that operation to succeed, regardless of\n     \
    \  what permissions the object is created with.  For example, an\n       empty\
    \ ACL denies all permissions, but the server should allow the\n       owner's\
    \ SETATTR to succeed even though WRITE_ACL is implicitly\n       denied.\n   \
    \    In other cases, inheritance SHOULD take place, and no\n       modifications\
    \ to the ACL will happen.  The mode attribute, if\n       supported, MUST be as\
    \ computed in Section 6.3.2, with the\n       MODE4_SUID, MODE4_SGID, and MODE4_SVTX\
    \ bits clear.  If no\n       inheritable ACEs exist on the parent directory, the\
    \ rules for\n       creating acl, dacl, or sacl attributes are implementation\n\
    \       defined.  If either the dacl or sacl attribute is supported, then\n  \
    \     the ACL4_DEFAULTED flag SHOULD be set on the newly created\n       attributes.\n"
- title: 6.4.3.1.  The Inherited ACL
  contents:
  - "6.4.3.1.  The Inherited ACL\n   If the object being created is not a directory,\
    \ the inherited ACL\n   SHOULD NOT inherit ACEs from the parent directory ACL\
    \ unless the\n   ACE4_FILE_INHERIT_FLAG is set.\n   If the object being created\
    \ is a directory, the inherited ACL should\n   inherit all inheritable ACEs from\
    \ the parent directory, that is,\n   those that have the ACE4_FILE_INHERIT_ACE\
    \ or\n   ACE4_DIRECTORY_INHERIT_ACE flag set.  If the inheritable ACE has\n  \
    \ ACE4_FILE_INHERIT_ACE set but ACE4_DIRECTORY_INHERIT_ACE is clear,\n   the inherited\
    \ ACE on the newly created directory MUST have the\n   ACE4_INHERIT_ONLY_ACE flag\
    \ set to prevent the directory from being\n   affected by ACEs meant for non-directories.\n\
    \   When a new directory is created, the server MAY split any inherited\n   ACE\
    \ that is both inheritable and effective (in other words, that has\n   neither\
    \ ACE4_INHERIT_ONLY_ACE nor ACE4_NO_PROPAGATE_INHERIT_ACE set),\n   into two ACEs,\
    \ one with no inheritance flags and one with\n   ACE4_INHERIT_ONLY_ACE set.  (In\
    \ the case of a dacl or sacl attribute,\n   both of those ACEs SHOULD also have\
    \ the ACE4_INHERITED_ACE flag set.)\n   This makes it simpler to modify the effective\
    \ permissions on the\n   directory without modifying the ACE that is to be inherited\
    \ to the\n   new directory's children.\n"
- title: 6.4.3.2.  Automatic Inheritance
  contents:
  - "6.4.3.2.  Automatic Inheritance\n   The acl attribute consists only of an array\
    \ of ACEs, but the sacl\n   (Section 6.2.3) and dacl (Section 6.2.2) attributes\
    \ also include an\n   additional flag field.\n   struct nfsacl41 {\n         \
    \  aclflag4        na41_flag;\n           nfsace4         na41_aces<>;\n   };\n\
    \   The flag field applies to the entire sacl or dacl; three flag values\n   are\
    \ defined:\n   const ACL4_AUTO_INHERIT         = 0x00000001;\n   const ACL4_PROTECTED\
    \            = 0x00000002;\n   const ACL4_DEFAULTED            = 0x00000004;\n\
    \   and all other bits must be cleared.  The ACE4_INHERITED_ACE flag may\n   be\
    \ set in the ACEs of the sacl or dacl (whereas it must always be\n   cleared in\
    \ the acl).\n   Together these features allow a server to support automatic\n\
    \   inheritance, which we now explain in more detail.\n   Inheritable ACEs are\
    \ normally inherited by child objects only at the\n   time that the child objects\
    \ are created; later modifications to\n   inheritable ACEs do not result in modifications\
    \ to inherited ACEs on\n   descendants.\n   However, the dacl and sacl provide\
    \ an OPTIONAL mechanism that allows\n   a client application to propagate changes\
    \ to inheritable ACEs to an\n   entire directory hierarchy.\n   A server that\
    \ supports this performs inheritance at object creation\n   time in the normal\
    \ way, and SHOULD set the ACE4_INHERITED_ACE flag on\n   any inherited ACEs as\
    \ they are added to the new object.\n   A client application such as an ACL editor\
    \ may then propagate changes\n   to inheritable ACEs on a directory by recursively\
    \ traversing that\n   directory's descendants and modifying each ACL encountered\
    \ to remove\n   any ACEs with the ACE4_INHERITED_ACE flag and to replace them\
    \ by the\n   new inheritable ACEs (also with the ACE4_INHERITED_ACE flag set).\
    \  It\n   uses the existing ACE inheritance flags in the obvious way to decide\n\
    \   which ACEs to propagate.  (Note that it may encounter further\n   inheritable\
    \ ACEs when descending the directory hierarchy and that\n   those will also need\
    \ to be taken into account when propagating\n   inheritable ACEs to further descendants.)\n\
    \   The reach of this propagation may be limited in two ways: first,\n   automatic\
    \ inheritance is not performed from any directory ACL that\n   has the ACL4_AUTO_INHERIT\
    \ flag cleared; and second, automatic\n   inheritance stops wherever an ACL with\
    \ the ACL4_PROTECTED flag is\n   set, preventing modification of that ACL and\
    \ also (if the ACL is set\n   on a directory) of the ACL on any of the object's\
    \ descendants.\n   This propagation is performed independently for the sacl and\
    \ the dacl\n   attributes; thus, the ACL4_AUTO_INHERIT and ACL4_PROTECTED flags\
    \ may\n   be independently set for the sacl and the dacl, and propagation of\n\
    \   one type of acl may continue down a hierarchy even where propagation\n   of\
    \ the other acl has stopped.\n   New objects should be created with a dacl and\
    \ a sacl that both have\n   the ACL4_PROTECTED flag cleared and the ACL4_AUTO_INHERIT\
    \ flag set to\n   the same value as that on, respectively, the sacl or dacl of\
    \ the\n   parent object.\n   Both the dacl and sacl attributes are RECOMMENDED,\
    \ and a server may\n   support one without supporting the other.\n   A server\
    \ that supports both the old acl attribute and one or both of\n   the new dacl\
    \ or sacl attributes must do so in such a way as to keep\n   all three attributes\
    \ consistent with each other.  Thus, the ACEs\n   reported in the acl attribute\
    \ should be the union of the ACEs\n   reported in the dacl and sacl attributes,\
    \ except that the\n   ACE4_INHERITED_ACE flag must be cleared from the ACEs in\
    \ the acl.\n   And of course a client that queries only the acl will be unable\
    \ to\n   determine the values of the sacl or dacl flag fields.\n   When a client\
    \ performs a SETATTR for the acl attribute, the server\n   SHOULD set the ACL4_PROTECTED\
    \ flag to true on both the sacl and the\n   dacl.  By using the acl attribute,\
    \ as opposed to the dacl or sacl\n   attributes, the client signals that it may\
    \ not understand automatic\n   inheritance, and thus cannot be trusted to set\
    \ an ACL for which\n   automatic inheritance would make sense.\n   When a client\
    \ application queries an ACL, modifies it, and sets it\n   again, it should leave\
    \ any ACEs marked with ACE4_INHERITED_ACE\n   unchanged, in their original order,\
    \ at the end of the ACL.  If the\n   application is unable to do this, it should\
    \ set the ACL4_PROTECTED\n   flag.  This behavior is not enforced by servers,\
    \ but violations of\n   this rule may lead to unexpected results when applications\
    \ perform\n   automatic inheritance.\n   If a server also supports the mode attribute,\
    \ it SHOULD set the mode\n   in such a way that leaves inherited ACEs unchanged,\
    \ in their original\n   order, at the end of the ACL.  If it is unable to do so,\
    \ it SHOULD\n   set the ACL4_PROTECTED flag on the file's dacl.\n   Finally, in\
    \ the case where the request that creates a new file or\n   directory does not\
    \ also set permissions for that file or directory,\n   and there are also no ACEs\
    \ to inherit from the parent's directory,\n   then the server's choice of ACL\
    \ for the new object is implementation-\n   dependent.  In this case, the server\
    \ SHOULD set the ACL4_DEFAULTED\n   flag on the ACL it chooses for the new object.\
    \  An application\n   performing automatic inheritance takes the ACL4_DEFAULTED\
    \ flag as a\n   sign that the ACL should be completely replaced by one generated\n\
    \   using the automatic inheritance rules.\n"
- title: 7.  Single-Server Namespace
  contents:
  - "7.  Single-Server Namespace\n   This section describes the NFSv4 single-server\
    \ namespace.  Single-\n   server namespaces may be presented directly to clients,\
    \ or they may\n   be used as a basis to form larger multi-server namespaces (e.g.,\n\
    \   site-wide or organization-wide) to be presented to clients, as\n   described\
    \ in Section 11.\n"
- title: 7.1.  Server Exports
  contents:
  - "7.1.  Server Exports\n   On a UNIX server, the namespace describes all the files\
    \ reachable by\n   pathnames under the root directory or \"/\".  On a Windows\
    \ server, the\n   namespace constitutes all the files on disks named by mapped\
    \ disk\n   letters.  NFS server administrators rarely make the entire server's\n\
    \   file system namespace available to NFS clients.  More often, portions\n  \
    \ of the namespace are made available via an \"export\" feature.  In\n   previous\
    \ versions of the NFS protocol, the root filehandle for each\n   export is obtained\
    \ through the MOUNT protocol; the client sent a\n   string that identified the\
    \ export name within the namespace and the\n   server returned the root filehandle\
    \ for that export.  The MOUNT\n   protocol also provided an EXPORTS procedure\
    \ that enumerated the\n   server's exports.\n"
- title: 7.2.  Browsing Exports
  contents:
  - "7.2.  Browsing Exports\n   The NFSv4.1 protocol provides a root filehandle that\
    \ clients can use\n   to obtain filehandles for the exports of a particular server,\
    \ via a\n   series of LOOKUP operations within a COMPOUND, to traverse a path.\
    \  A\n   common user experience is to use a graphical user interface (perhaps\n\
    \   a file \"Open\" dialog window) to find a file via progressive browsing\n \
    \  through a directory tree.  The client must be able to move from one\n   export\
    \ to another export via single-component, progressive LOOKUP\n   operations.\n\
    \   This style of browsing is not well supported by the NFSv3 protocol.\n   In\
    \ NFSv3, the client expects all LOOKUP operations to remain within a\n   single\
    \ server file system.  For example, the device attribute will\n   not change.\
    \  This prevents a client from taking namespace paths that\n   span exports.\n\
    \   In the case of NFSv3, an automounter on the client can obtain a\n   snapshot\
    \ of the server's namespace using the EXPORTS procedure of the\n   MOUNT protocol.\
    \  If it understands the server's pathname syntax, it\n   can create an image\
    \ of the server's namespace on the client.  The\n   parts of the namespace that\
    \ are not exported by the server are filled\n   in with directories that might\
    \ be constructed similarly to an NFSv4.1\n   \"pseudo file system\" (see Section\
    \ 7.3) that allows the user to browse\n   from one mounted file system to another.\
    \  There is a drawback to this\n   representation of the server's namespace on\
    \ the client: it is static.\n   If the server administrator adds a new export,\
    \ the client will be\n   unaware of it.\n"
- title: 7.3.  Server Pseudo File System
  contents:
  - "7.3.  Server Pseudo File System\n   NFSv4.1 servers avoid this namespace inconsistency\
    \ by presenting all\n   the exports for a given server within the framework of\
    \ a single\n   namespace for that server.  An NFSv4.1 client uses LOOKUP and READDIR\n\
    \   operations to browse seamlessly from one export to another.\n   Where there\
    \ are portions of the server namespace that are not\n   exported, clients require\
    \ some way of traversing those portions to\n   reach actual exported file systems.\
    \  A technique that servers may use\n   to provide for this is to bridge the unexported\
    \ portion of the\n   namespace via a \"pseudo file system\" that provides a view\
    \ of exported\n   directories only.  A pseudo file system has a unique fsid and\
    \ behaves\n   like a normal, read-only file system.\n   Based on the construction\
    \ of the server's namespace, it is possible\n   that multiple pseudo file systems\
    \ may exist.  For example,\n           /a              pseudo file system\n  \
    \         /a/b            real file system\n           /a/b/c          pseudo\
    \ file system\n           /a/b/c/d        real file system\n   Each of the pseudo\
    \ file systems is considered a separate entity and\n   therefore MUST have its\
    \ own fsid, unique among all the fsids for that\n   server.\n"
- title: 7.4.  Multiple Roots
  contents:
  - "7.4.  Multiple Roots\n   Certain operating environments are sometimes described\
    \ as having\n   \"multiple roots\".  In such environments, individual file systems\
    \ are\n   commonly represented by disk or volume names.  NFSv4 servers for\n \
    \  these platforms can construct a pseudo file system above these root\n   names\
    \ so that disk letters or volume names are simply directory names\n   in the pseudo\
    \ root.\n"
- title: 7.5.  Filehandle Volatility
  contents:
  - "7.5.  Filehandle Volatility\n   The nature of the server's pseudo file system\
    \ is that it is a logical\n   representation of file system(s) available from\
    \ the server.\n   Therefore, the pseudo file system is most likely constructed\n\
    \   dynamically when the server is first instantiated.  It is expected\n   that\
    \ the pseudo file system may not have an on-disk counterpart from\n   which persistent\
    \ filehandles could be constructed.  Even though it is\n   preferable that the\
    \ server provide persistent filehandles for the\n   pseudo file system, the NFS\
    \ client should expect that pseudo file\n   system filehandles are volatile. \
    \ This can be confirmed by checking\n   the associated \"fh_expire_type\" attribute\
    \ for those filehandles in\n   question.  If the filehandles are volatile, the\
    \ NFS client must be\n   prepared to recover a filehandle value (e.g., with a\
    \ series of LOOKUP\n   operations) when receiving an error of NFS4ERR_FHEXPIRED.\n\
    \   Because it is quite likely that servers will implement pseudo file\n   systems\
    \ using volatile filehandles, clients need to be prepared for\n   them, rather\
    \ than assuming that all filehandles will be persistent.\n"
- title: 7.6.  Exported Root
  contents:
  - "7.6.  Exported Root\n   If the server's root file system is exported, one might\
    \ conclude that\n   a pseudo file system is unneeded.  This is not necessarily\
    \ so.\n   Assume the following file systems on a server:\n           /       fs1\
    \  (exported)\n           /a      fs2  (not exported)\n           /a/b    fs3\
    \  (exported)\n   Because fs2 is not exported, fs3 cannot be reached with simple\n\
    \   LOOKUPs.  The server must bridge the gap with a pseudo file system.\n"
- title: 7.7.  Mount Point Crossing
  contents:
  - "7.7.  Mount Point Crossing\n   The server file system environment may be constructed\
    \ in such a way\n   that one file system contains a directory that is 'covered'\
    \ or\n   mounted upon by a second file system.  For example:\n           /a/b\
    \            (file system 1)\n           /a/b/c/d        (file system 2)\n   The\
    \ pseudo file system for this server may be constructed to look\n   like:\n  \
    \         /               (place holder/not exported)\n           /a/b       \
    \     (file system 1)\n           /a/b/c/d        (file system 2)\n   It is the\
    \ server's responsibility to present the pseudo file system\n   that is complete\
    \ to the client.  If the client sends a LOOKUP request\n   for the path /a/b/c/d,\
    \ the server's response is the filehandle of the\n   root of the file system /a/b/c/d.\
    \  In previous versions of the NFS\n   protocol, the server would respond with\
    \ the filehandle of directory\n   /a/b/c/d within the file system /a/b.\n   The\
    \ NFS client will be able to determine if it crosses a server mount\n   point\
    \ by a change in the value of the \"fsid\" attribute.\n"
- title: 7.8.  Security Policy and Namespace Presentation
  contents:
  - "7.8.  Security Policy and Namespace Presentation\n   Because NFSv4 clients possess\
    \ the ability to change the security\n   mechanisms used, after determining what\
    \ is allowed, by using SECINFO\n   and SECINFO_NONAME, the server SHOULD NOT present\
    \ a different view of\n   the namespace based on the security mechanism being\
    \ used by a client.\n   Instead, it should present a consistent view and return\n\
    \   NFS4ERR_WRONGSEC if an attempt is made to access data with an\n   inappropriate\
    \ security mechanism.\n   If security considerations make it necessary to hide\
    \ the existence of\n   a particular file system, as opposed to all of the data\
    \ within it,\n   the server can apply the security policy of a shared resource\
    \ in the\n   server's namespace to components of the resource's ancestors.  For\n\
    \   example:\n           /a/b                        (file system 1)\n       \
    \    /a/b/MySecretProject        (file system 2)\n   The /a/b/MySecretProject\
    \ directory is a real file system and is the\n   shared resource.  Suppose the\
    \ security policy for /a/b/\n   MySecretProject is Kerberos with integrity and\
    \ it is desired to limit\n   knowledge of the existence of this file system. \
    \ In this case, the\n   server should apply the same security policy to /a/b.\
    \  This allows\n   for knowledge of the existence of a file system to be secured\
    \ when\n   desirable.\n   For the case of the use of multiple, disjoint security\
    \ mechanisms in\n   the server's resources, applying that sort of policy would\
    \ result in\n   the higher-level file system not being accessible using any security\n\
    \   flavor.  Therefore, that sort of configuration is not compatible with\n  \
    \ hiding the existence (as opposed to the contents) from clients using\n   multiple\
    \ disjoint sets of security flavors.\n   In other circumstances, a desirable policy\
    \ is for the security of a\n   particular object in the server's namespace to\
    \ include the union of\n   all security mechanisms of all direct descendants.\
    \  A common and\n   convenient practice, unless strong security requirements dictate\n\
    \   otherwise, is to make the entire the pseudo file system accessible by\n  \
    \ all of the valid security mechanisms.\n   Where there is concern about the security\
    \ of data on the network,\n   clients should use strong security mechanisms to\
    \ access the pseudo\n   file system in order to prevent man-in-the-middle attacks.\n"
- title: 8.  State Management
  contents:
  - "8.  State Management\n   Integrating locking into the NFS protocol necessarily\
    \ causes it to be\n   stateful.  With the inclusion of such features as share\
    \ reservations,\n   file and directory delegations, recallable layouts, and support\
    \ for\n   mandatory byte-range locking, the protocol becomes substantially more\n\
    \   dependent on proper management of state than the traditional\n   combination\
    \ of NFS and NLM (Network Lock Manager) [54].  These\n   features include expanded\
    \ locking facilities, which provide some\n   measure of inter-client exclusion,\
    \ but the state also offers features\n   not readily providable using a stateless\
    \ model.  There are three\n   components to making this state manageable:\n  \
    \ *  clear division between client and server\n   *  ability to reliably detect\
    \ inconsistency in state between client\n      and server\n   *  simple and robust\
    \ recovery mechanisms\n   In this model, the server owns the state information.\
    \  The client\n   requests changes in locks and the server responds with the changes\n\
    \   made.  Non-client-initiated changes in locking state are infrequent.\n   The\
    \ client receives prompt notification of such changes and can\n   adjust its view\
    \ of the locking state to reflect the server's changes.\n   Individual pieces\
    \ of state created by the server and passed to the\n   client at its request are\
    \ represented by 128-bit stateids.  These\n   stateids may represent a particular\
    \ open file, a set of byte-range\n   locks held by a particular owner, or a recallable\
    \ delegation of\n   privileges to access a file in particular ways or at a particular\n\
    \   location.\n   In all cases, there is a transition from the most general information\n\
    \   that represents a client as a whole to the eventual lightweight\n   stateid\
    \ used for most client and server locking interactions.  The\n   details of this\
    \ transition will vary with the type of object but it\n   always starts with a\
    \ client ID.\n"
- title: 8.1.  Client and Session ID
  contents:
  - "8.1.  Client and Session ID\n   A client must establish a client ID (see Section\
    \ 2.4) and then one or\n   more sessionids (see Section 2.10) before performing\
    \ any operations\n   to open, byte-range lock, delegate, or obtain a layout for\
    \ a file\n   object.  Each session ID is associated with a specific client ID,\
    \ and\n   thus serves as a shorthand reference to an NFSv4.1 client.\n   For some\
    \ types of locking interactions, the client will represent\n   some number of\
    \ internal locking entities called \"owners\", which\n   normally correspond to\
    \ processes internal to the client.  For other\n   types of locking-related objects,\
    \ such as delegations and layouts, no\n   such intermediate entities are provided\
    \ for, and the locking-related\n   objects are considered to be transferred directly\
    \ between the server\n   and a unitary client.\n"
- title: 8.2.  Stateid Definition
  contents:
  - "8.2.  Stateid Definition\n   When the server grants a lock of any type (including\
    \ opens, byte-\n   range locks, delegations, and layouts), it responds with a\
    \ unique\n   stateid that represents a set of locks (often a single lock) for\
    \ the\n   same file, of the same type, and sharing the same ownership\n   characteristics.\
    \  Thus, opens of the same file by different open-\n   owners each have an identifying\
    \ stateid.  Similarly, each set of\n   byte-range locks on a file owned by a specific\
    \ lock-owner has its own\n   identifying stateid.  Delegations and layouts also\
    \ have associated\n   stateids by which they may be referenced.  The stateid is\
    \ used as a\n   shorthand reference to a lock or set of locks, and given a stateid,\n\
    \   the server can determine the associated state-owner or state-owners\n   (in\
    \ the case of an open-owner/lock-owner pair) and the associated\n   filehandle.\
    \  When stateids are used, the current filehandle must be\n   the one associated\
    \ with that stateid.\n   All stateids associated with a given client ID are associated\
    \ with a\n   common lease that represents the claim of those stateids and the\n\
    \   objects they represent to be maintained by the server.  See\n   Section 8.3\
    \ for a discussion of the lease.\n   The server may assign stateids independently\
    \ for different clients.\n   A stateid with the same bit pattern for one client\
    \ may designate an\n   entirely different set of locks for a different client.\
    \  The stateid\n   is always interpreted with respect to the client ID associated\
    \ with\n   the current session.  Stateids apply to all sessions associated with\n\
    \   the given client ID, and the client may use a stateid obtained from\n   one\
    \ session on another session associated with the same client ID.\n"
- title: 8.2.1.  Stateid Types
  contents:
  - "8.2.1.  Stateid Types\n   With the exception of special stateids (see Section\
    \ 8.2.3), each\n   stateid represents locking objects of one of a set of types\
    \ defined\n   by the NFSv4.1 protocol.  Note that in all these cases, where we\n\
    \   speak of guarantee, it is understood there are situations such as a\n   client\
    \ restart, or lock revocation, that allow the guarantee to be\n   voided.\n  \
    \ *  Stateids may represent opens of files.\n      Each stateid in this case represents\
    \ the OPEN state for a given\n      client ID/open-owner/filehandle triple.  Such\
    \ stateids are subject\n      to change (with consequent incrementing of the stateid's\
    \ seqid) in\n      response to OPENs that result in upgrade and OPEN_DOWNGRADE\n\
    \      operations.\n   *  Stateids may represent sets of byte-range locks.\n \
    \     All locks held on a particular file by a particular owner and\n      gotten\
    \ under the aegis of a particular open file are associated\n      with a single\
    \ stateid with the seqid being incremented whenever\n      LOCK and LOCKU operations\
    \ affect that set of locks.\n   *  Stateids may represent file delegations, which\
    \ are recallable\n      guarantees by the server to the client that other clients\
    \ will not\n      reference or modify a particular file, until the delegation\
    \ is\n      returned.  In NFSv4.1, file delegations may be obtained on both\n\
    \      regular and non-regular files.\n      A stateid represents a single delegation\
    \ held by a client for a\n      particular filehandle.\n   *  Stateids may represent\
    \ directory delegations, which are recallable\n      guarantees by the server\
    \ to the client that other clients will not\n      modify the directory, until\
    \ the delegation is returned.\n      A stateid represents a single delegation\
    \ held by a client for a\n      particular directory filehandle.\n   *  Stateids\
    \ may represent layouts, which are recallable guarantees by\n      the server\
    \ to the client that particular files may be accessed via\n      an alternate\
    \ data access protocol at specific locations.  Such\n      access is limited to\
    \ particular sets of byte-ranges and may\n      proceed until those byte-ranges\
    \ are reduced or the layout is\n      returned.\n      A stateid represents the\
    \ set of all layouts held by a particular\n      client for a particular filehandle\
    \ with a given layout type.  The\n      seqid is updated as the layouts of that\
    \ set of byte-ranges change,\n      via layout stateid changing operations such\
    \ as LAYOUTGET and\n      LAYOUTRETURN.\n"
- title: 8.2.2.  Stateid Structure
  contents:
  - "8.2.2.  Stateid Structure\n   Stateids are divided into two fields, a 96-bit\
    \ \"other\" field\n   identifying the specific set of locks and a 32-bit \"seqid\"\
    \ sequence\n   value.  Except in the case of special stateids (see Section 8.2.3),\
    \ a\n   particular value of the \"other\" field denotes a set of locks of the\n\
    \   same type (for example, byte-range locks, opens, delegations, or\n   layouts),\
    \ for a specific file or directory, and sharing the same\n   ownership characteristics.\
    \  The seqid designates a specific instance\n   of such a set of locks, and is\
    \ incremented to indicate changes in\n   such a set of locks, either by the addition\
    \ or deletion of locks from\n   the set, a change in the byte-range they apply\
    \ to, or an upgrade or\n   downgrade in the type of one or more locks.\n   When\
    \ such a set of locks is first created, the server returns a\n   stateid with\
    \ seqid value of one.  On subsequent operations that\n   modify the set of locks,\
    \ the server is required to increment the\n   \"seqid\" field by one whenever\
    \ it returns a stateid for the same\n   state-owner/file/type combination and\
    \ there is some change in the set\n   of locks actually designated.  In this case,\
    \ the server will return a\n   stateid with an \"other\" field the same as previously\
    \ used for that\n   state-owner/file/type combination, with an incremented \"\
    seqid\" field.\n   This pattern continues until the seqid is incremented past\n\
    \   NFS4_UINT32_MAX, and one (not zero) is the next seqid value.\n   The purpose\
    \ of the incrementing of the seqid is to allow the server\n   to communicate to\
    \ the client the order in which operations that\n   modified locking state associated\
    \ with a stateid have been processed\n   and to make it possible for the client\
    \ to send requests that are\n   conditional on the set of locks not having changed\
    \ since the stateid\n   in question was returned.\n   Except for layout stateids\
    \ (Section 12.5.3), when a client sends a\n   stateid to the server, it has two\
    \ choices with regard to the seqid\n   sent.  It may set the seqid to zero to\
    \ indicate to the server that it\n   wishes the most up-to-date seqid for that\
    \ stateid's \"other\" field to\n   be used.  This would be the common choice in\
    \ the case of a stateid\n   sent with a READ or WRITE operation.  It also may\
    \ set a non-zero\n   value, in which case the server checks if that seqid is the\
    \ correct\n   one.  In that case, the server is required to return\n   NFS4ERR_OLD_STATEID\
    \ if the seqid is lower than the most current value\n   and NFS4ERR_BAD_STATEID\
    \ if the seqid is greater than the most current\n   value.  This would be the\
    \ common choice in the case of stateids sent\n   with a CLOSE or OPEN_DOWNGRADE.\
    \  Because OPENs may be sent in\n   parallel for the same owner, a client might\
    \ close a file without\n   knowing that an OPEN upgrade had been done by the server,\
    \ changing\n   the lock in question.  If CLOSE were sent with a zero seqid, the\
    \ OPEN\n   upgrade would be cancelled before the client even received an\n   indication\
    \ that an upgrade had happened.\n   When a stateid is sent by the server to the\
    \ client as part of a\n   callback operation, it is not subject to checking for\
    \ a current seqid\n   and returning NFS4ERR_OLD_STATEID.  This is because the\
    \ client is not\n   in a position to know the most up-to-date seqid and thus cannot\n\
    \   verify it.  Unless specially noted, the seqid value for a stateid\n   sent\
    \ by the server to the client as part of a callback is required to\n   be zero\
    \ with NFS4ERR_BAD_STATEID returned if it is not.\n   In making comparisons between\
    \ seqids, both by the client in\n   determining the order of operations and by\
    \ the server in determining\n   whether the NFS4ERR_OLD_STATEID is to be returned,\
    \ the possibility of\n   the seqid being swapped around past the NFS4_UINT32_MAX\
    \ value needs\n   to be taken into account.  When two seqid values are being compared,\n\
    \   the total count of slots for all sessions associated with the current\n  \
    \ client is used to do this.  When one seqid value is less than this\n   total\
    \ slot count and another seqid value is greater than\n   NFS4_UINT32_MAX minus\
    \ the total slot count, the former is to be\n   treated as lower than the latter,\
    \ despite the fact that it is\n   numerically greater.\n"
- title: 8.2.3.  Special Stateids
  contents:
  - "8.2.3.  Special Stateids\n   Stateid values whose \"other\" field is either all\
    \ zeros or all ones\n   are reserved.  They may not be assigned by the server\
    \ but have\n   special meanings defined by the protocol.  The particular meaning\n\
    \   depends on whether the \"other\" field is all zeros or all ones and the\n\
    \   specific value of the \"seqid\" field.\n   The following combinations of \"\
    other\" and \"seqid\" are defined in\n   NFSv4.1:\n   *  When \"other\" and \"\
    seqid\" are both zero, the stateid is treated as\n      a special anonymous stateid,\
    \ which can be used in READ, WRITE, and\n      SETATTR requests to indicate the\
    \ absence of any OPEN state\n      associated with the request.  When an anonymous\
    \ stateid value is\n      used and an existing open denies the form of access\
    \ requested,\n      then access will be denied to the request.  This stateid MUST\
    \ NOT\n      be used on operations to data servers (Section 13.6).\n   *  When\
    \ \"other\" and \"seqid\" are both all ones, the stateid is a\n      special READ\
    \ bypass stateid.  When this value is used in WRITE or\n      SETATTR, it is treated\
    \ like the anonymous value.  When used in\n      READ, the server MAY grant access,\
    \ even if access would normally\n      be denied to READ operations.  This stateid\
    \ MUST NOT be used on\n      operations to data servers.\n   *  When \"other\"\
    \ is zero and \"seqid\" is one, the stateid represents\n      the current stateid,\
    \ which is whatever value is the last stateid\n      returned by an operation\
    \ within the COMPOUND.  In the case of an\n      OPEN, the stateid returned for\
    \ the open file and not the\n      delegation is used.  The stateid passed to\
    \ the operation in place\n      of the special value has its \"seqid\" value set\
    \ to zero, except\n      when the current stateid is used by the operation CLOSE\
    \ or\n      OPEN_DOWNGRADE.  If there is no operation in the COMPOUND that has\n\
    \      returned a stateid value, the server MUST return the error\n      NFS4ERR_BAD_STATEID.\
    \  As illustrated in Figure 6, if the value of\n      a current stateid is a special\
    \ stateid and the stateid of an\n      operation's arguments has \"other\" set\
    \ to zero and \"seqid\" set to\n      one, then the server MUST return the error\
    \ NFS4ERR_BAD_STATEID.\n   *  When \"other\" is zero and \"seqid\" is NFS4_UINT32_MAX,\
    \ the stateid\n      represents a reserved stateid value defined to be invalid.\
    \  When\n      this stateid is used, the server MUST return the error\n      NFS4ERR_BAD_STATEID.\n\
    \   If a stateid value is used that has all zeros or all ones in the\n   \"other\"\
    \ field but does not match one of the cases above, the server\n   MUST return\
    \ the error NFS4ERR_BAD_STATEID.\n   Special stateids, unlike other stateids,\
    \ are not associated with\n   individual client IDs or filehandles and can be\
    \ used with all valid\n   client IDs and filehandles.  In the case of a special\
    \ stateid\n   designating the current stateid, the current stateid value\n   substituted\
    \ for the special stateid is associated with a particular\n   client ID and filehandle,\
    \ and so, if it is used where the current\n   filehandle does not match that associated\
    \ with the current stateid,\n   the operation to which the stateid is passed will\
    \ return\n   NFS4ERR_BAD_STATEID.\n"
- title: 8.2.4.  Stateid Lifetime and Validation
  contents:
  - "8.2.4.  Stateid Lifetime and Validation\n   Stateids must remain valid until\
    \ either a client restart or a server\n   restart or until the client returns\
    \ all of the locks associated with\n   the stateid by means of an operation such\
    \ as CLOSE or DELEGRETURN.\n   If the locks are lost due to revocation, as long\
    \ as the client ID is\n   valid, the stateid remains a valid designation of that\
    \ revoked state\n   until the client frees it by using FREE_STATEID.  Stateids\
    \ associated\n   with byte-range locks are an exception.  They remain valid even\
    \ if a\n   LOCKU frees all remaining locks, so long as the open file with which\n\
    \   they are associated remains open, unless the client frees the\n   stateids\
    \ via the FREE_STATEID operation.\n   It should be noted that there are situations\
    \ in which the client's\n   locks become invalid, without the client requesting\
    \ they be returned.\n   These include lease expiration and a number of forms of\
    \ lock\n   revocation within the lease period.  It is important to note that in\n\
    \   these situations, the stateid remains valid and the client can use it\n  \
    \ to determine the disposition of the associated lost locks.\n   An \"other\"\
    \ value must never be reused for a different purpose (i.e.,\n   different filehandle,\
    \ owner, or type of locks) within the context of\n   a single client ID.  A server\
    \ may retain the \"other\" value for the\n   same purpose beyond the point where\
    \ it may otherwise be freed, but if\n   it does so, it must maintain \"seqid\"\
    \ continuity with previous values.\n   One mechanism that may be used to satisfy\
    \ the requirement that the\n   server recognize invalid and out-of-date stateids\
    \ is for the server\n   to divide the \"other\" field of the stateid into two\
    \ fields.\n   *  an index into a table of locking-state structures.\n   *  a generation\
    \ number that is incremented on each allocation of a\n      table entry for a\
    \ particular use.\n   And then store in each table entry,\n   *  the client ID\
    \ with which the stateid is associated.\n   *  the current generation number for\
    \ the (at most one) valid stateid\n      sharing this index value.\n   *  the\
    \ filehandle of the file on which the locks are taken.\n   *  an indication of\
    \ the type of stateid (open, byte-range lock, file\n      delegation, directory\
    \ delegation, layout).\n   *  the last \"seqid\" value returned corresponding\
    \ to the current\n      \"other\" value.\n   *  an indication of the current status\
    \ of the locks associated with\n      this stateid, in particular, whether these\
    \ have been revoked and\n      if so, for what reason.\n   With this information,\
    \ an incoming stateid can be validated and the\n   appropriate error returned\
    \ when necessary.  Special and non-special\n   stateids are handled separately.\
    \  (See Section 8.2.3 for a discussion\n   of special stateids.)\n   Note that\
    \ stateids are implicitly qualified by the current client ID,\n   as derived from\
    \ the client ID associated with the current session.\n   Note, however, that the\
    \ semantics of the session will prevent\n   stateids associated with a previous\
    \ client or server instance from\n   being analyzed by this procedure.\n   If\
    \ server restart has resulted in an invalid client ID or a session\n   ID that\
    \ is invalid, SEQUENCE will return an error and the operation\n   that takes a\
    \ stateid as an argument will never be processed.\n   If there has been a server\
    \ restart where there is a persistent\n   session and all leased state has been\
    \ lost, then the session in\n   question will, although valid, be marked as dead,\
    \ and any operation\n   not satisfied by means of the reply cache will receive\
    \ the error\n   NFS4ERR_DEADSESSION, and thus not be processed as indicated below.\n\
    \   When a stateid is being tested and the \"other\" field is all zeros or\n \
    \  all ones, a check that the \"other\" and \"seqid\" fields match a defined\n\
    \   combination for a special stateid is done and the results determined\n   as\
    \ follows:\n   *  If the \"other\" and \"seqid\" fields do not match a defined\n\
    \      combination associated with a special stateid, the error\n      NFS4ERR_BAD_STATEID\
    \ is returned.\n   *  If the special stateid is one designating the current stateid\
    \ and\n      there is a current stateid, then the current stateid is\n      substituted\
    \ for the special stateid and the checks appropriate to\n      non-special stateids\
    \ are performed.\n   *  If the combination is valid in general but is not appropriate\
    \ to\n      the context in which the stateid is used (e.g., an all-zero\n    \
    \  stateid is used when an OPEN stateid is required in a LOCK\n      operation),\
    \ the error NFS4ERR_BAD_STATEID is also returned.\n   *  Otherwise, the check\
    \ is completed and the special stateid is\n      accepted as valid.\n   When a\
    \ stateid is being tested, and the \"other\" field is neither all\n   zeros nor\
    \ all ones, the following procedure could be used to validate\n   an incoming\
    \ stateid and return an appropriate error, when necessary,\n   assuming that the\
    \ \"other\" field would be divided into a table index\n   and an entry generation.\n\
    \   *  If the table index field is outside the range of the associated\n     \
    \ table, return NFS4ERR_BAD_STATEID.\n   *  If the selected table entry is of\
    \ a different generation than that\n      specified in the incoming stateid, return\
    \ NFS4ERR_BAD_STATEID.\n   *  If the selected table entry does not match the current\
    \ filehandle,\n      return NFS4ERR_BAD_STATEID.\n   *  If the client ID in the\
    \ table entry does not match the client ID\n      associated with the current\
    \ session, return NFS4ERR_BAD_STATEID.\n   *  If the stateid represents revoked\
    \ state, then return\n      NFS4ERR_EXPIRED, NFS4ERR_ADMIN_REVOKED, or NFS4ERR_DELEG_REVOKED,\n\
    \      as appropriate.\n   *  If the stateid type is not valid for the context\
    \ in which the\n      stateid appears, return NFS4ERR_BAD_STATEID.  Note that\
    \ a stateid\n      may be valid in general, as would be reported by the TEST_STATEID\n\
    \      operation, but be invalid for a particular operation, as, for\n      example,\
    \ when a stateid that doesn't represent byte-range locks is\n      passed to the\
    \ non-from_open case of LOCK or to LOCKU, or when a\n      stateid that does not\
    \ represent an open is passed to CLOSE or\n      OPEN_DOWNGRADE.  In such cases,\
    \ the server MUST return\n      NFS4ERR_BAD_STATEID.\n   *  If the \"seqid\" field\
    \ is not zero and it is greater than the\n      current sequence value corresponding\
    \ to the current \"other\" field,\n      return NFS4ERR_BAD_STATEID.\n   *  If\
    \ the \"seqid\" field is not zero and it is less than the current\n      sequence\
    \ value corresponding to the current \"other\" field, return\n      NFS4ERR_OLD_STATEID.\n\
    \   *  Otherwise, the stateid is valid and the table entry should contain\n  \
    \    any additional information about the type of stateid and\n      information\
    \ associated with that particular type of stateid, such\n      as the associated\
    \ set of locks, e.g., open-owner and lock-owner\n      information, as well as\
    \ information on the specific locks, e.g.,\n      open modes and byte-ranges.\n"
- title: 8.2.5.  Stateid Use for I/O Operations
  contents:
  - "8.2.5.  Stateid Use for I/O Operations\n   Clients performing I/O operations\
    \ need to select an appropriate\n   stateid based on the locks (including opens\
    \ and delegations) held by\n   the client and the various types of state-owners\
    \ sending the I/O\n   requests.  SETATTR operations that change the file size\
    \ are treated\n   like I/O operations in this regard.\n   The following rules,\
    \ applied in order of decreasing priority, govern\n   the selection of the appropriate\
    \ stateid.  In following these rules,\n   the client will only consider locks\
    \ of which it has actually received\n   notification by an appropriate operation\
    \ response or callback.  Note\n   that the rules are slightly different in the\
    \ case of I/O to data\n   servers when file layouts are being used (see Section\
    \ 13.9.1).\n   *  If the client holds a delegation for the file in question, the\n\
    \      delegation stateid SHOULD be used.\n   *  Otherwise, if the entity corresponding\
    \ to the lock-owner (e.g., a\n      process) sending the I/O has a byte-range\
    \ lock stateid for the\n      associated open file, then the byte-range lock stateid\
    \ for that\n      lock-owner and open file SHOULD be used.\n   *  If there is\
    \ no byte-range lock stateid, then the OPEN stateid for\n      the open file in\
    \ question SHOULD be used.\n   *  Finally, if none of the above apply, then a\
    \ special stateid SHOULD\n      be used.\n   Ignoring these rules may result in\
    \ situations in which the server\n   does not have information necessary to properly\
    \ process the request.\n   For example, when mandatory byte-range locks are in\
    \ effect, if the\n   stateid does not indicate the proper lock-owner, via a lock\
    \ stateid,\n   a request might be avoidably rejected.\n   The server however should\
    \ not try to enforce these ordering rules and\n   should use whatever information\
    \ is available to properly process I/O\n   requests.  In particular, when a client\
    \ has a delegation for a given\n   file, it SHOULD take note of this fact in processing\
    \ a request, even\n   if it is sent with a special stateid.\n"
- title: 8.2.6.  Stateid Use for SETATTR Operations
  contents:
  - "8.2.6.  Stateid Use for SETATTR Operations\n   Because each operation is associated\
    \ with a session ID and from that\n   the clientid can be determined, operations\
    \ do not need to include a\n   stateid for the server to be able to determine\
    \ whether they should\n   cause a delegation to be recalled or are to be treated\
    \ as done within\n   the scope of the delegation.\n   In the case of SETATTR operations,\
    \ a stateid is present.  In cases\n   other than those that set the file size,\
    \ the client may send either a\n   special stateid or, when a delegation is held\
    \ for the file in\n   question, a delegation stateid.  While the server SHOULD\
    \ validate the\n   stateid and may use the stateid to optimize the determination\
    \ as to\n   whether a delegation is held, it SHOULD note the presence of a\n \
    \  delegation even when a special stateid is sent, and MUST accept a\n   valid\
    \ delegation stateid when sent.\n"
- title: 8.3.  Lease Renewal
  contents:
  - "8.3.  Lease Renewal\n   Each client/server pair, as represented by a client ID,\
    \ has a single\n   lease.  The purpose of the lease is to allow the client to\
    \ indicate\n   to the server, in a low-overhead way, that it is active, and thus\n\
    \   that the server is to retain the client's locks.  This arrangement\n   allows\
    \ the server to remove stale locking-related objects that are\n   held by a client\
    \ that has crashed or is otherwise unreachable, once\n   the relevant lease expires.\
    \  This in turn allows other clients to\n   obtain conflicting locks without being\
    \ delayed indefinitely by\n   inactive or unreachable clients.  It is not a mechanism\
    \ for cache\n   consistency and lease renewals may not be denied if the lease\n\
    \   interval has not expired.\n   Since each session is associated with a specific\
    \ client (identified\n   by the client's client ID), any operation sent on that\
    \ session is an\n   indication that the associated client is reachable.  When\
    \ a request\n   is sent for a given session, successful execution of a SEQUENCE\n\
    \   operation (or successful retrieval of the result of SEQUENCE from the\n  \
    \ reply cache) on an unexpired lease will result in the lease being\n   implicitly\
    \ renewed, for the standard renewal period (equal to the\n   lease_time attribute).\n\
    \   If the client ID's lease has not expired when the server receives a\n   SEQUENCE\
    \ operation, then the server MUST renew the lease.  If the\n   client ID's lease\
    \ has expired when the server receives a SEQUENCE\n   operation, the server MAY\
    \ renew the lease; this depends on whether\n   any state was revoked as a result\
    \ of the client's failure to renew\n   the lease before expiration.\n   Absent\
    \ other activity that would renew the lease, a COMPOUND\n   consisting of a single\
    \ SEQUENCE operation will suffice.  The client\n   should also take communication-related\
    \ delays into account and take\n   steps to ensure that the renewal messages actually\
    \ reach the server\n   in good time.  For example:\n   *  When trunking is in\
    \ effect, the client should consider sending\n      multiple requests on different\
    \ connections, in order to ensure\n      that renewal occurs, even in the event\
    \ of blockage in the path\n      used for one of those connections.\n   *  Transport\
    \ retransmission delays might become so large as to\n      approach or exceed\
    \ the length of the lease period.  This may be\n      particularly likely when\
    \ the server is unresponsive due to a\n      restart; see Section 8.4.2.1.  If\
    \ the client implementation is not\n      careful, transport retransmission delays\
    \ can result in the client\n      failing to detect a server restart before the\
    \ grace period ends.\n      The scenario is that the client is using a transport\
    \ with\n      exponential backoff, such that the maximum retransmission timeout\n\
    \      exceeds both the grace period and the lease_time attribute.  A\n      network\
    \ partition causes the client's connection's retransmission\n      interval to\
    \ back off, and even after the partition heals, the next\n      transport-level\
    \ retransmission is sent after the server has\n      restarted and its grace period\
    \ ends.\n      The client MUST either recover from the ensuing NFS4ERR_NO_GRACE\n\
    \      errors or it MUST ensure that, despite transport-level\n      retransmission\
    \ intervals that exceed the lease_time, a SEQUENCE\n      operation is sent that\
    \ renews the lease before expiration.  The\n      client can achieve this by associating\
    \ a new connection with the\n      session, and sending a SEQUENCE operation on\
    \ it.  However, if the\n      attempt to establish a new connection is delayed\
    \ for some reason\n      (e.g., exponential backoff of the connection establishment\n\
    \      packets), the client will have to abort the connection\n      establishment\
    \ attempt before the lease expires, and attempt to\n      reconnect.\n   If the\
    \ server renews the lease upon receiving a SEQUENCE operation,\n   the server\
    \ MUST NOT allow the lease to expire while the rest of the\n   operations in the\
    \ COMPOUND procedure's request are still executing.\n   Once the last operation\
    \ has finished, and the response to COMPOUND\n   has been sent, the server MUST\
    \ set the lease to expire no sooner than\n   the sum of current time and the value\
    \ of the lease_time attribute.\n   A client ID's lease can expire when it has\
    \ been at least the lease\n   interval (lease_time) since the last lease-renewing\
    \ SEQUENCE\n   operation was sent on any of the client ID's sessions and there\
    \ are\n   no active COMPOUND operations on any such sessions.\n   Because the\
    \ SEQUENCE operation is the basic mechanism to renew a\n   lease, and because\
    \ it must be done at least once for each lease\n   period, it is the natural mechanism\
    \ whereby the server will inform\n   the client of changes in the lease status\
    \ that the client needs to be\n   informed of.  The client should inspect the\
    \ status flags\n   (sr_status_flags) returned by sequence and take the appropriate\n\
    \   action (see Section 18.46.3 for details).\n   *  The status bits SEQ4_STATUS_CB_PATH_DOWN\
    \ and\n      SEQ4_STATUS_CB_PATH_DOWN_SESSION indicate problems with the\n   \
    \   backchannel that the client may need to address in order to\n      receive\
    \ callback requests.\n   *  The status bits SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRING\
    \ and\n      SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED indicate problems with GSS\n\
    \      contexts or RPCSEC_GSS handles for the backchannel that the client\n  \
    \    might have to address in order to allow callback requests to be\n      sent.\n\
    \   *  The status bits SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED,\n      SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED,\n\
    \      SEQ4_STATUS_ADMIN_STATE_REVOKED, and\n      SEQ4_STATUS_RECALLABLE_STATE_REVOKED\
    \ notify the client of lock\n      revocation events.  When these bits are set,\
    \ the client should use\n      TEST_STATEID to find what stateids have been revoked\
    \ and use\n      FREE_STATEID to acknowledge loss of the associated state.\n \
    \  *  The status bit SEQ4_STATUS_LEASE_MOVE indicates that\n      responsibility\
    \ for lease renewal has been transferred to one or\n      more new servers.\n\
    \   *  The status bit SEQ4_STATUS_RESTART_RECLAIM_NEEDED indicates that\n    \
    \  due to server restart the client must reclaim locking state.\n   *  The status\
    \ bit SEQ4_STATUS_BACKCHANNEL_FAULT indicates that the\n      server has encountered\
    \ an unrecoverable fault with the backchannel\n      (e.g., it has lost track\
    \ of a sequence ID for a slot in the\n      backchannel).\n"
- title: 8.4.  Crash Recovery
  contents:
  - "8.4.  Crash Recovery\n   A critical requirement in crash recovery is that both\
    \ the client and\n   the server know when the other has failed.  Additionally,\
    \ it is\n   required that a client sees a consistent view of data across server\n\
    \   restarts.  All READ and WRITE operations that may have been queued\n   within\
    \ the client or network buffers must wait until the client has\n   successfully\
    \ recovered the locks protecting the READ and WRITE\n   operations.  Any that\
    \ reach the server before the server can safely\n   determine that the client\
    \ has recovered enough locking state to be\n   sure that such operations can be\
    \ safely processed must be rejected.\n   This will happen because either:\n  \
    \ *  The state presented is no longer valid since it is associated with\n    \
    \  a now invalid client ID.  In this case, the client will receive\n      either\
    \ an NFS4ERR_BADSESSION or NFS4ERR_DEADSESSION error, and any\n      attempt to\
    \ attach a new session to that invalid client ID will\n      result in an NFS4ERR_STALE_CLIENTID\
    \ error.\n   *  Subsequent recovery of locks may make execution of the operation\n\
    \      inappropriate (NFS4ERR_GRACE).\n"
- title: 8.4.1.  Client Failure and Recovery
  contents:
  - "8.4.1.  Client Failure and Recovery\n   In the event that a client fails, the\
    \ server may release the client's\n   locks when the associated lease has expired.\
    \  Conflicting locks from\n   another client may only be granted after this lease\
    \ expiration.  As\n   discussed in Section 8.3, when a client has not failed and\
    \ re-\n   establishes its lease before expiration occurs, requests for\n   conflicting\
    \ locks will not be granted.\n   To minimize client delay upon restart, lock requests\
    \ are associated\n   with an instance of the client by a client-supplied verifier.\
    \  This\n   verifier is part of the client_owner4 sent in the initial EXCHANGE_ID\n\
    \   call made by the client.  The server returns a client ID as a result\n   of\
    \ the EXCHANGE_ID operation.  The client then confirms the use of\n   the client\
    \ ID by establishing a session associated with that client\n   ID (see Section\
    \ 18.36.3 for a description of how this is done).  All\n   locks, including opens,\
    \ byte-range locks, delegations, and layouts\n   obtained by sessions using that\
    \ client ID, are associated with that\n   client ID.\n   Since the verifier will\
    \ be changed by the client upon each\n   initialization, the server can compare\
    \ a new verifier to the verifier\n   associated with currently held locks and\
    \ determine that they do not\n   match.  This signifies the client's new instantiation\
    \ and subsequent\n   loss (upon confirmation of the new client ID) of locking\
    \ state.  As a\n   result, the server is free to release all locks held that are\n\
    \   associated with the old client ID that was derived from the old\n   verifier.\
    \  At this point, conflicting locks from other clients, kept\n   waiting while\
    \ the lease had not yet expired, can be granted.  In\n   addition, all stateids\
    \ associated with the old client ID can also be\n   freed, as they are no longer\
    \ reference-able.\n   Note that the verifier must have the same uniqueness properties\
    \ as\n   the verifier for the COMMIT operation.\n"
- title: 8.4.2.  Server Failure and Recovery
  contents:
  - "8.4.2.  Server Failure and Recovery\n   If the server loses locking state (usually\
    \ as a result of a restart),\n   it must allow clients time to discover this fact\
    \ and re-establish the\n   lost locking state.  The client must be able to re-establish\
    \ the\n   locking state without having the server deny valid requests because\n\
    \   the server has granted conflicting access to another client.\n   Likewise,\
    \ if there is a possibility that clients have not yet re-\n   established their\
    \ locking state for a file and that such locking\n   state might make it invalid\
    \ to perform READ or WRITE operations.  For\n   example, if mandatory locks are\
    \ a possibility, the server must\n   disallow READ and WRITE operations for that\
    \ file.\n   A client can determine that loss of locking state has occurred via\n\
    \   several methods.\n   1.  When a SEQUENCE (most common) or other operation\
    \ returns\n       NFS4ERR_BADSESSION, this may mean that the session has been\n\
    \       destroyed but the client ID is still valid.  The client sends a\n    \
    \   CREATE_SESSION request with the client ID to re-establish the\n       session.\
    \  If CREATE_SESSION fails with NFS4ERR_STALE_CLIENTID,\n       the client must\
    \ establish a new client ID (see Section 8.1) and\n       re-establish its lock\
    \ state with the new client ID, after the\n       CREATE_SESSION operation succeeds\
    \ (see Section 8.4.2.1).\n   2.  When a SEQUENCE (most common) or other operation\
    \ on a persistent\n       session returns NFS4ERR_DEADSESSION, this indicates\
    \ that a\n       session is no longer usable for new, i.e., not satisfied from\
    \ the\n       reply cache, operations.  Once all pending operations are\n    \
    \   determined to be either performed before the retry or not\n       performed,\
    \ the client sends a CREATE_SESSION request with the\n       client ID to re-establish\
    \ the session.  If CREATE_SESSION fails\n       with NFS4ERR_STALE_CLIENTID, the\
    \ client must establish a new\n       client ID (see Section 8.1) and re-establish\
    \ its lock state after\n       the CREATE_SESSION, with the new client ID, succeeds\n\
    \       (Section 8.4.2.1).\n   3.  When an operation, neither SEQUENCE nor preceded\
    \ by SEQUENCE (for\n       example, CREATE_SESSION, DESTROY_SESSION), returns\n\
    \       NFS4ERR_STALE_CLIENTID, the client MUST establish a new client ID\n  \
    \     (Section 8.1) and re-establish its lock state (Section 8.4.2.1).\n"
- title: 8.4.2.1.  State Reclaim
  contents:
  - "8.4.2.1.  State Reclaim\n   When state information and the associated locks are\
    \ lost as a result\n   of a server restart, the protocol must provide a way to\
    \ cause that\n   state to be re-established.  The approach used is to define,\
    \ for most\n   types of locking state (layouts are an exception), a request whose\n\
    \   function is to allow the client to re-establish on the server a lock\n   first\
    \ obtained from a previous instance.  Generally, these requests\n   are variants\
    \ of the requests normally used to create locks of that\n   type and are referred\
    \ to as \"reclaim-type\" requests, and the process\n   of re-establishing such\
    \ locks is referred to as \"reclaiming\" them.\n   Because each client must have\
    \ an opportunity to reclaim all of the\n   locks that it has without the possibility\
    \ that some other client will\n   be granted a conflicting lock, a \"grace period\"\
    \ is devoted to the\n   reclaim process.  During this period, requests creating\
    \ client IDs\n   and sessions are handled normally, but locking requests are subject\n\
    \   to special restrictions.  Only reclaim-type locking requests are\n   allowed,\
    \ unless the server can reliably determine (through state\n   persistently maintained\
    \ across restart instances) that granting any\n   such lock cannot possibly conflict\
    \ with a subsequent reclaim.  When a\n   request is made to obtain a new lock\
    \ (i.e., not a reclaim-type\n   request) during the grace period and such a determination\
    \ cannot be\n   made, the server must return the error NFS4ERR_GRACE.\n   Once\
    \ a session is established using the new client ID, the client\n   will use reclaim-type\
    \ locking requests (e.g., LOCK operations with\n   reclaim set to TRUE and OPEN\
    \ operations with a claim type of\n   CLAIM_PREVIOUS; see Section 9.11) to re-establish\
    \ its locking state.\n   Once this is done, or if there is no such locking state\
    \ to reclaim,\n   the client sends a global RECLAIM_COMPLETE operation, i.e.,\
    \ one with\n   the rca_one_fs argument set to FALSE, to indicate that it has\n\
    \   reclaimed all of the locking state that it will reclaim.  Once a\n   client\
    \ sends such a RECLAIM_COMPLETE operation, it may attempt non-\n   reclaim locking\
    \ operations, although it might get an NFS4ERR_GRACE\n   status result from each\
    \ such operation until the period of special\n   handling is over.  See Section\
    \ 11.11.9 for a discussion of the\n   analogous handling lock reclamation in the\
    \ case of file systems\n   transitioning from server to server.\n   During the\
    \ grace period, the server must reject READ and WRITE\n   operations and non-reclaim\
    \ locking requests (i.e., other LOCK and\n   OPEN operations) with an error of\
    \ NFS4ERR_GRACE, unless it can\n   guarantee that these may be done safely, as\
    \ described below.\n   The grace period may last until all clients that are known\
    \ to\n   possibly have had locks have done a global RECLAIM_COMPLETE\n   operation,\
    \ indicating that they have finished reclaiming the locks\n   they held before\
    \ the server restart.  This means that a client that\n   has done a RECLAIM_COMPLETE\
    \ must be prepared to receive an\n   NFS4ERR_GRACE when attempting to acquire\
    \ new locks.  In order for the\n   server to know that all clients with possible\
    \ prior lock state have\n   done a RECLAIM_COMPLETE, the server must maintain\
    \ in stable storage a\n   list clients that may have such locks.  The server may\
    \ also terminate\n   the grace period before all clients have done a global\n\
    \   RECLAIM_COMPLETE.  The server SHOULD NOT terminate the grace period\n   before\
    \ a time equal to the lease period in order to give clients an\n   opportunity\
    \ to find out about the server restart, as a result of\n   sending requests on\
    \ associated sessions with a frequency governed by\n   the lease time.  Note that\
    \ when a client does not send such requests\n   (or they are sent by the client\
    \ but not received by the server), it\n   is possible for the grace period to\
    \ expire before the client finds\n   out that the server restart has occurred.\n\
    \   Some additional time in order to allow a client to establish a new\n   client\
    \ ID and session and to effect lock reclaims may be added to the\n   lease time.\
    \  Note that analogous rules apply to file system-specific\n   grace periods discussed\
    \ in Section 11.11.9.\n   If the server can reliably determine that granting a\
    \ non-reclaim\n   request will not conflict with reclamation of locks by other\
    \ clients,\n   the NFS4ERR_GRACE error does not have to be returned even within\
    \ the\n   grace period, although NFS4ERR_GRACE must always be returned to\n  \
    \ clients attempting a non-reclaim lock request before doing their own\n   global\
    \ RECLAIM_COMPLETE.  For the server to be able to service READ\n   and WRITE operations\
    \ during the grace period, it must again be able\n   to guarantee that no possible\
    \ conflict could arise between a\n   potential reclaim locking request and the\
    \ READ or WRITE operation.\n   If the server is unable to offer that guarantee,\
    \ the NFS4ERR_GRACE\n   error must be returned to the client.\n   For a server\
    \ to provide simple, valid handling during the grace\n   period, the easiest method\
    \ is to simply reject all non-reclaim\n   locking requests and READ and WRITE\
    \ operations by returning the\n   NFS4ERR_GRACE error.  However, a server may\
    \ keep information about\n   granted locks in stable storage.  With this information,\
    \ the server\n   could determine if a locking, READ or WRITE operation can be\
    \ safely\n   processed.\n   For example, if the server maintained on stable storage\
    \ summary\n   information on whether mandatory locks exist, either mandatory byte-\n\
    \   range locks, or share reservations specifying deny modes, many\n   requests\
    \ could be allowed during the grace period.  If it is known\n   that no such share\
    \ reservations exist, OPEN request that do not\n   specify deny modes may be safely\
    \ granted.  If, in addition, it is\n   known that no mandatory byte-range locks\
    \ exist, either through\n   information stored on stable storage or simply because\
    \ the server\n   does not support such locks, READ and WRITE operations may be\
    \ safely\n   processed during the grace period.  Another important case is where\n\
    \   it is known that no mandatory byte-range locks exist, either because\n   the\
    \ server does not provide support for them or because their absence\n   is known\
    \ from persistently recorded data.  In this case, READ and\n   WRITE operations\
    \ specifying stateids derived from reclaim-type\n   operations may be validly\
    \ processed during the grace period because\n   of the fact that the valid reclaim\
    \ ensures that no lock subsequently\n   granted can prevent the I/O.\n   To reiterate,\
    \ for a server that allows non-reclaim lock and I/O\n   requests to be processed\
    \ during the grace period, it MUST determine\n   that no lock subsequently reclaimed\
    \ will be rejected and that no lock\n   subsequently reclaimed would have prevented\
    \ any I/O operation\n   processed during the grace period.\n   Clients should\
    \ be prepared for the return of NFS4ERR_GRACE errors for\n   non-reclaim lock\
    \ and I/O requests.  In this case, the client should\n   employ a retry mechanism\
    \ for the request.  A delay (on the order of\n   several seconds) between retries\
    \ should be used to avoid overwhelming\n   the server.  Further discussion of\
    \ the general issue is included in\n   [55].  The client must account for the\
    \ server that can perform I/O\n   and non-reclaim locking requests within the\
    \ grace period as well as\n   those that cannot do so.\n   A reclaim-type locking\
    \ request outside the server's grace period can\n   only succeed if the server\
    \ can guarantee that no conflicting lock or\n   I/O request has been granted since\
    \ restart.\n   A server may, upon restart, establish a new value for the lease\n\
    \   period.  Therefore, clients should, once a new client ID is\n   established,\
    \ refetch the lease_time attribute and use it as the basis\n   for lease renewal\
    \ for the lease associated with that server.\n   However, the server must establish,\
    \ for this restart event, a grace\n   period at least as long as the lease period\
    \ for the previous server\n   instantiation.  This allows the client state obtained\
    \ during the\n   previous server instance to be reliably re-established.\n   The\
    \ possibility exists that, because of server configuration events,\n   the client\
    \ will be communicating with a server different than the one\n   on which the\
    \ locks were obtained, as shown by the combination of\n   eir_server_scope and\
    \ eir_server_owner.  This leads to the issue of if\n   and when the client should\
    \ attempt to reclaim locks previously\n   obtained on what is being reported as\
    \ a different server.  The rules\n   to resolve this question are as follows:\n\
    \   *  If the server scope is different, the client should not attempt to\n  \
    \    reclaim locks.  In this situation, no lock reclaim is possible.\n      Any\
    \ attempt to re-obtain the locks with non-reclaim operations is\n      problematic\
    \ since there is no guarantee that the existing\n      filehandles will be recognized\
    \ by the new server, or that if\n      recognized, they denote the same objects.\
    \  It is best to treat the\n      locks as having been revoked by the reconfiguration\
    \ event.\n   *  If the server scope is the same, the client should attempt to\n\
    \      reclaim locks, even if the eir_server_owner value is different.\n     \
    \ In this situation, it is the responsibility of the server to\n      return NFS4ERR_NO_GRACE\
    \ if it cannot provide correct support for\n      lock reclaim operations, including\
    \ the prevention of edge\n      conditions.\n   The eir_server_owner field is\
    \ not used in making this determination.\n   Its function is to specify trunking\
    \ possibilities for the client (see\n   Section 2.10.5) and not to control lock\
    \ reclaim.\n"
- title: 8.4.2.1.1.  Security Considerations for State Reclaim
  contents:
  - "8.4.2.1.1.  Security Considerations for State Reclaim\n   During the grace period,\
    \ a client can reclaim state that it believes\n   or asserts it had before the\
    \ server restarted.  Unless the server\n   maintained a complete record of all\
    \ the state the client had, the\n   server has little choice but to trust the\
    \ client.  (Of course, if the\n   server maintained a complete record, then it\
    \ would not have to force\n   the client to reclaim state after server restart.)\
    \  While the server\n   has to trust the client to tell the truth, the negative\
    \ consequences\n   for security are limited to enabling denial-of-service attacks\
    \ in\n   situations in which AUTH_SYS is supported.  The fundamental rule for\n\
    \   the server when processing reclaim requests is that it MUST NOT grant\n  \
    \ the reclaim if an equivalent non-reclaim request would not be granted\n   during\
    \ steady state due to access control or access conflict issues.\n   For example,\
    \ an OPEN request during a reclaim will be refused with\n   NFS4ERR_ACCESS if\
    \ the principal making the request does not have\n   access to open the file according\
    \ to the discretionary ACL\n   (Section 6.2.2) on the file.\n   Nonetheless, it\
    \ is possible that a client operating in error or\n   maliciously could, during\
    \ reclaim, prevent another client from\n   reclaiming access to state.  For example,\
    \ an attacker could send an\n   OPEN reclaim operation with a deny mode that prevents\
    \ another client\n   from reclaiming the OPEN state it had before the server restarted.\n\
    \   The attacker could perform the same denial of service during steady\n   state\
    \ prior to server restart, as long as the attacker had\n   permissions.  Given\
    \ that the attack vectors are equivalent, the grace\n   period does not offer\
    \ any additional opportunity for denial of\n   service, and any concerns about\
    \ this attack vector, whether during\n   grace or steady state, are addressed\
    \ the same way: use RPCSEC_GSS for\n   authentication and limit access to the\
    \ file only to principals that\n   the owner of the file trusts.\n   Note that\
    \ if prior to restart the server had client IDs with the\n   EXCHGID4_FLAG_BIND_PRINC_STATEID\
    \ (Section 18.35) capability set, then\n   the server SHOULD record in stable\
    \ storage the client owner and the\n   principal that established the client ID\
    \ via EXCHANGE_ID.  If the\n   server does not, then there is a risk a client\
    \ will be unable to\n   reclaim state if it does not have a credential for a principal\
    \ that\n   was originally authorized to establish the state.\n"
- title: 8.4.3.  Network Partitions and Recovery
  contents:
  - "8.4.3.  Network Partitions and Recovery\n   If the duration of a network partition\
    \ is greater than the lease\n   period provided by the server, the server will\
    \ not have received a\n   lease renewal from the client.  If this occurs, the\
    \ server may free\n   all locks held for the client or it may allow the lock state\
    \ to\n   remain for a considerable period, subject to the constraint that if a\n\
    \   request for a conflicting lock is made, locks associated with an\n   expired\
    \ lease do not prevent such a conflicting lock from being\n   granted but MUST\
    \ be revoked as necessary so as to avoid interfering\n   with such conflicting\
    \ requests.\n   If the server chooses to delay freeing of lock state until there\
    \ is a\n   conflict, it may either free all of the client's locks once there is\n\
    \   a conflict or it may only revoke the minimum set of locks necessary\n   to\
    \ allow conflicting requests.  When it adopts the finer-grained\n   approach,\
    \ it must revoke all locks associated with a given stateid,\n   even if the conflict\
    \ is with only a subset of locks.\n   When the server chooses to free all of a\
    \ client's lock state, either\n   immediately upon lease expiration or as a result\
    \ of the first attempt\n   to obtain a conflicting a lock, the server may report\
    \ the loss of\n   lock state in a number of ways.\n   The server may choose to\
    \ invalidate the session and the associated\n   client ID.  In this case, once\
    \ the client can communicate with the\n   server, it will receive an NFS4ERR_BADSESSION\
    \ error.  Upon attempting\n   to create a new session, it would get an NFS4ERR_STALE_CLIENTID.\n\
    \   Upon creating the new client ID and new session, the client will\n   attempt\
    \ to reclaim locks.  Normally, the server will not allow the\n   client to reclaim\
    \ locks, because the server will not be in its\n   recovery grace period.\n  \
    \ Another possibility is for the server to maintain the session and\n   client\
    \ ID but for all stateids held by the client to become invalid\n   or stale. \
    \ Once the client can reach the server after such a network\n   partition, the\
    \ status returned by the SEQUENCE operation will\n   indicate a loss of locking\
    \ state; i.e., the flag\n   SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED will be set\
    \ in sr_status_flags.\n   In addition, all I/O submitted by the client with the\
    \ now invalid\n   stateids will fail with the server returning the error\n   NFS4ERR_EXPIRED.\
    \  Once the client learns of the loss of locking\n   state, it will suitably notify\
    \ the applications that held the\n   invalidated locks.  The client should then\
    \ take action to free\n   invalidated stateids, either by establishing a new client\
    \ ID using a\n   new verifier or by doing a FREE_STATEID operation to release\
    \ each of\n   the invalidated stateids.\n   When the server adopts a finer-grained\
    \ approach to revocation of\n   locks when a client's lease has expired, only\
    \ a subset of stateids\n   will normally become invalid during a network partition.\
    \  When the\n   client can communicate with the server after such a network partition\n\
    \   heals, the status returned by the SEQUENCE operation will indicate a\n   partial\
    \ loss of locking state\n   (SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED).  In addition,\
    \ operations,\n   including I/O submitted by the client, with the now invalid\
    \ stateids\n   will fail with the server returning the error NFS4ERR_EXPIRED.\
    \  Once\n   the client learns of the loss of locking state, it will use the\n\
    \   TEST_STATEID operation on all of its stateids to determine which\n   locks\
    \ have been lost and then suitably notify the applications that\n   held the invalidated\
    \ locks.  The client can then release the\n   invalidated locking state and acknowledge\
    \ the revocation of the\n   associated locks by doing a FREE_STATEID operation\
    \ on each of the\n   invalidated stateids.\n   When a network partition is combined\
    \ with a server restart, there are\n   edge conditions that place requirements\
    \ on the server in order to\n   avoid silent data corruption following the server\
    \ restart.  Two of\n   these edge conditions are known, and are discussed below.\n\
    \   The first edge condition arises as a result of the scenarios such as\n   the\
    \ following:\n   1.  Client A acquires a lock.\n   2.  Client A and server experience\
    \ mutual network partition, such\n       that client A is unable to renew its\
    \ lease.\n   3.  Client A's lease expires, and the server releases the lock.\n\
    \   4.  Client B acquires a lock that would have conflicted with that of\n   \
    \    client A.\n   5.  Client B releases its lock.\n   6.  Server restarts.\n\
    \   7.  Network partition between client A and server heals.\n   8.  Client A\
    \ connects to a new server instance and finds out about\n       server restart.\n\
    \   9.  Client A reclaims its lock within the server's grace period.\n   Thus,\
    \ at the final step, the server has erroneously granted client\n   A's lock reclaim.\
    \  If client B modified the object the lock was\n   protecting, client A will\
    \ experience object corruption.\n   The second known edge condition arises in\
    \ situations such as the\n   following:\n   1.   Client A acquires one or more\
    \ locks.\n   2.   Server restarts.\n   3.   Client A and server experience mutual\
    \ network partition, such\n        that client A is unable to reclaim all of its\
    \ locks within the\n        grace period.\n   4.   Server's reclaim grace period\
    \ ends.  Client A has either no\n        locks or an incomplete set of locks known\
    \ to the server.\n   5.   Client B acquires a lock that would have conflicted\
    \ with a lock\n        of client A that was not reclaimed.\n   6.   Client B releases\
    \ the lock.\n   7.   Server restarts a second time.\n   8.   Network partition\
    \ between client A and server heals.\n   9.   Client A connects to new server\
    \ instance and finds out about\n        server restart.\n   10.  Client A reclaims\
    \ its lock within the server's grace period.\n   As with the first edge condition,\
    \ the final step of the scenario of\n   the second edge condition has the server\
    \ erroneously granting client\n   A's lock reclaim.\n   Solving the first and\
    \ second edge conditions requires either that the\n   server always assumes after\
    \ it restarts that some edge condition\n   occurs, and thus returns NFS4ERR_NO_GRACE\
    \ for all reclaim attempts,\n   or that the server record some information in\
    \ stable storage.  The\n   amount of information the server records in stable\
    \ storage is in\n   inverse proportion to how harsh the server intends to be whenever\n\
    \   edge conditions arise.  The server that is completely tolerant of all\n  \
    \ edge conditions will record in stable storage every lock that is\n   acquired,\
    \ removing the lock record from stable storage only when the\n   lock is released.\
    \  For the two edge conditions discussed above, the\n   harshest a server can\
    \ be, and still support a grace period for\n   reclaims, requires that the server\
    \ record in stable storage some\n   minimal information.  For example, a server\
    \ implementation could, for\n   each client, save in stable storage a record containing:\n\
    \   *  the co_ownerid field from the client_owner4 presented in the\n      EXCHANGE_ID\
    \ operation.\n   *  a boolean that indicates if the client's lease expired or\
    \ if there\n      was administrative intervention (see Section 8.5) to revoke\
    \ a\n      byte-range lock, share reservation, or delegation and there has\n \
    \     been no acknowledgment, via FREE_STATEID, of such revocation.\n   *  a boolean\
    \ that indicates whether the client may have locks that it\n      believes to\
    \ be reclaimable in situations in which the grace period\n      was terminated,\
    \ making the server's view of lock reclaimability\n      suspect.  The server\
    \ will set this for any client record in stable\n      storage where the client\
    \ has not done a suitable RECLAIM_COMPLETE\n      (global or file system-specific\
    \ depending on the target of the\n      lock request) before it grants any new\
    \ (i.e., not reclaimed) lock\n      to any client.\n   Assuming the above record\
    \ keeping, for the first edge condition,\n   after the server restarts, the record\
    \ that client A's lease expired\n   means that another client could have acquired\
    \ a conflicting byte-\n   range lock, share reservation, or delegation.  Hence,\
    \ the server must\n   reject a reclaim from client A with the error NFS4ERR_NO_GRACE.\n\
    \   For the second edge condition, after the server restarts for a second\n  \
    \ time, the indication that the client had not completed its reclaims\n   at the\
    \ time at which the grace period ended means that the server\n   must reject a\
    \ reclaim from client A with the error NFS4ERR_NO_GRACE.\n   When either edge\
    \ condition occurs, the client's attempt to reclaim\n   locks will result in the\
    \ error NFS4ERR_NO_GRACE.  When this is\n   received, or after the client restarts\
    \ with no lock state, the client\n   will send a global RECLAIM_COMPLETE.  When\
    \ the RECLAIM_COMPLETE is\n   received, the server and client are again in agreement\
    \ regarding\n   reclaimable locks and both booleans in persistent storage can\
    \ be\n   reset, to be set again only when there is a subsequent event that\n \
    \  causes lock reclaim operations to be questionable.\n   Regardless of the level\
    \ and approach to record keeping, the server\n   MUST implement one of the following\
    \ strategies (which apply to\n   reclaims of share reservations, byte-range locks,\
    \ and delegations):\n   1.  Reject all reclaims with NFS4ERR_NO_GRACE.  This is\
    \ extremely\n       unforgiving, but necessary if the server does not record lock\n\
    \       state in stable storage.\n   2.  Record sufficient state in stable storage\
    \ such that all known\n       edge conditions involving server restart, including\
    \ the two noted\n       in this section, are detected.  It is acceptable to erroneously\n\
    \       recognize an edge condition and not allow a reclaim, when, with\n    \
    \   sufficient knowledge, it would be allowed.  The error the server\n       would\
    \ return in this case is NFS4ERR_NO_GRACE.  Note that it is\n       not known\
    \ if there are other edge conditions.\n       In the event that, after a server\
    \ restart, the server determines\n       there is unrecoverable damage or corruption\
    \ to the information in\n       stable storage, then for all clients and/or locks\
    \ that may be\n       affected, the server MUST return NFS4ERR_NO_GRACE.\n   A\
    \ mandate for the client's handling of the NFS4ERR_NO_GRACE error is\n   outside\
    \ the scope of this specification, since the strategies for\n   such handling\
    \ are very dependent on the client's operating\n   environment.  However, one\
    \ potential approach is described below.\n   When the client receives NFS4ERR_NO_GRACE,\
    \ it could examine the\n   change attribute of the objects for which the client\
    \ is trying to\n   reclaim state, and use that to determine whether to re-establish\
    \ the\n   state via normal OPEN or LOCK operations.  This is acceptable\n   provided\
    \ that the client's operating environment allows it.  In other\n   words, the\
    \ client implementor is advised to document for his users\n   the behavior.  The\
    \ client could also inform the application that its\n   byte-range lock or share\
    \ reservations (whether or not they were\n   delegated) have been lost, such as\
    \ via a UNIX signal, a Graphical\n   User Interface (GUI) pop-up window, etc.\
    \  See Section 10.5 for a\n   discussion of what the client should do for dealing\
    \ with unreclaimed\n   delegations on client state.\n   For further discussion\
    \ of revocation of locks, see Section 8.5.\n"
- title: 8.5.  Server Revocation of Locks
  contents:
  - "8.5.  Server Revocation of Locks\n   At any point, the server can revoke locks\
    \ held by a client, and the\n   client must be prepared for this event.  When\
    \ the client detects that\n   its locks have been or may have been revoked, the\
    \ client is\n   responsible for validating the state information between itself\
    \ and\n   the server.  Validating locking state for the client means that it\n\
    \   must verify or reclaim state for each lock currently held.\n   The first occasion\
    \ of lock revocation is upon server restart.  Note\n   that this includes situations\
    \ in which sessions are persistent and\n   locking state is lost.  In this class\
    \ of instances, the client will\n   receive an error (NFS4ERR_STALE_CLIENTID)\
    \ on an operation that takes\n   client ID, usually as part of recovery in response\
    \ to a problem with\n   the current session), and the client will proceed with\
    \ normal crash\n   recovery as described in the Section 8.4.2.1.\n   The second\
    \ occasion of lock revocation is the inability to renew the\n   lease before expiration,\
    \ as discussed in Section 8.4.3.  While this\n   is considered a rare or unusual\
    \ event, the client must be prepared to\n   recover.  The server is responsible\
    \ for determining the precise\n   consequences of the lease expiration, informing\
    \ the client of the\n   scope of the lock revocation decided upon.  The client\
    \ then uses the\n   status information provided by the server in the SEQUENCE\
    \ results\n   (field sr_status_flags, see Section 18.46.3) to synchronize its\n\
    \   locking state with that of the server, in order to recover.\n   The third\
    \ occasion of lock revocation can occur as a result of\n   revocation of locks\
    \ within the lease period, either because of\n   administrative intervention or\
    \ because a recallable lock (a\n   delegation or layout) was not returned within\
    \ the lease period after\n   having been recalled.  While these are considered\
    \ rare events, they\n   are possible, and the client must be prepared to deal\
    \ with them.\n   When either of these events occurs, the client finds out about\
    \ the\n   situation through the status returned by the SEQUENCE operation.  Any\n\
    \   use of stateids associated with locks revoked during the lease period\n  \
    \ will receive the error NFS4ERR_ADMIN_REVOKED or\n   NFS4ERR_DELEG_REVOKED, as\
    \ appropriate.\n   In all situations in which a subset of locking state may have\
    \ been\n   revoked, which include all cases in which locking state is revoked\n\
    \   within the lease period, it is up to the client to determine which\n   locks\
    \ have been revoked and which have not.  It does this by using\n   the TEST_STATEID\
    \ operation on the appropriate set of stateids.  Once\n   the set of revoked locks\
    \ has been determined, the applications can be\n   notified, and the invalidated\
    \ stateids can be freed and lock\n   revocation acknowledged by using FREE_STATEID.\n"
- title: 8.6.  Short and Long Leases
  contents:
  - "8.6.  Short and Long Leases\n   When determining the time period for the server\
    \ lease, the usual\n   lease trade-offs apply.  A short lease is good for fast\
    \ server\n   recovery at a cost of increased operations to effect lease renewal\n\
    \   (when there are no other operations during the period to effect lease\n  \
    \ renewal as a side effect).  A long lease is certainly kinder and\n   gentler\
    \ to servers trying to handle very large numbers of clients.\n   The number of\
    \ extra requests to effect lock renewal drops in inverse\n   proportion to the\
    \ lease time.  The disadvantages of a long lease\n   include the possibility of\
    \ slower recovery after certain failures.\n   After server failure, a longer grace\
    \ period may be required when some\n   clients do not promptly reclaim their locks\
    \ and do a global\n   RECLAIM_COMPLETE.  In the event of client failure, the longer\
    \ period\n   for a lease to expire will force conflicting requests to wait longer.\n\
    \   A long lease is practical if the server can store lease state in\n   stable\
    \ storage.  Upon recovery, the server can reconstruct the lease\n   state from\
    \ its stable storage and continue operation with its\n   clients.\n"
- title: 8.7.  Clocks, Propagation Delay, and Calculating Lease Expiration
  contents:
  - "8.7.  Clocks, Propagation Delay, and Calculating Lease Expiration\n   To avoid\
    \ the need for synchronized clocks, lease times are granted by\n   the server\
    \ as a time delta.  However, there is a requirement that the\n   client and server\
    \ clocks do not drift excessively over the duration\n   of the lease.  There is\
    \ also the issue of propagation delay across\n   the network, which could easily\
    \ be several hundred milliseconds, as\n   well as the possibility that requests\
    \ will be lost and need to be\n   retransmitted.\n   To take propagation delay\
    \ into account, the client should subtract it\n   from lease times (e.g., if the\
    \ client estimates the one-way\n   propagation delay as 200 milliseconds, then\
    \ it can assume that the\n   lease is already 200 milliseconds old when it gets\
    \ it).  In addition,\n   it will take another 200 milliseconds to get a response\
    \ back to the\n   server.  So the client must send a lease renewal or write data\
    \ back\n   to the server at least 400 milliseconds before the lease would\n  \
    \ expire.  If the propagation delay varies over the life of the lease\n   (e.g.,\
    \ the client is on a mobile host), the client will need to\n   continuously subtract\
    \ the increase in propagation delay from the\n   lease times.\n   The server's\
    \ lease period configuration should take into account the\n   network distance\
    \ of the clients that will be accessing the server's\n   resources.  It is expected\
    \ that the lease period will take into\n   account the network propagation delays\
    \ and other network delay\n   factors for the client population.  Since the protocol\
    \ does not allow\n   for an automatic method to determine an appropriate lease\
    \ period, the\n   server's administrator may have to tune the lease period.\n"
- title: 8.8.  Obsolete Locking Infrastructure from NFSv4.0
  contents:
  - "8.8.  Obsolete Locking Infrastructure from NFSv4.0\n   There are a number of\
    \ operations and fields within existing\n   operations that no longer have a function\
    \ in NFSv4.1.  In one way or\n   another, these changes are all due to the implementation\
    \ of sessions\n   that provide client context and exactly once semantics as a\
    \ base\n   feature of the protocol, separate from locking itself.\n   The following\
    \ NFSv4.0 operations MUST NOT be implemented in NFSv4.1.\n   The server MUST return\
    \ NFS4ERR_NOTSUPP if these operations are found\n   in an NFSv4.1 COMPOUND.\n\
    \   *  SETCLIENTID since its function has been replaced by EXCHANGE_ID.\n   *\
    \  SETCLIENTID_CONFIRM since client ID confirmation now happens by\n      means\
    \ of CREATE_SESSION.\n   *  OPEN_CONFIRM because state-owner-based seqids have\
    \ been replaced\n      by the sequence ID in the SEQUENCE operation.\n   *  RELEASE_LOCKOWNER\
    \ because lock-owners with no associated locks do\n      not have any sequence-related\
    \ state and so can be deleted by the\n      server at will.\n   *  RENEW because\
    \ every SEQUENCE operation for a session causes lease\n      renewal, making a\
    \ separate operation superfluous.\n   Also, there are a number of fields, present\
    \ in existing operations,\n   related to locking that have no use in minor version\
    \ 1.  They were\n   used in minor version 0 to perform functions now provided\
    \ in a\n   different fashion.\n   *  Sequence ids used to sequence requests for\
    \ a given state-owner and\n      to provide retry protection, now provided via\
    \ sessions.\n   *  Client IDs used to identify the client associated with a given\n\
    \      request.  Client identification is now available using the client\n   \
    \   ID associated with the current session, without needing an\n      explicit\
    \ client ID field.\n   Such vestigial fields in existing operations have no function\
    \ in\n   NFSv4.1 and are ignored by the server.  Note that client IDs in\n   operations\
    \ new to NFSv4.1 (such as CREATE_SESSION and\n   DESTROY_CLIENTID) are not ignored.\n"
- title: 9.  File Locking and Share Reservations
  contents:
  - "9.  File Locking and Share Reservations\n   To support Win32 share reservations,\
    \ it is necessary to provide\n   operations that atomically open or create files.\
    \  Having a separate\n   share/unshare operation would not allow correct implementation\
    \ of the\n   Win32 OpenFile API.  In order to correctly implement share semantics,\n\
    \   the previous NFS protocol mechanisms used when a file is opened or\n   created\
    \ (LOOKUP, CREATE, ACCESS) need to be replaced.  The NFSv4.1\n   protocol defines\
    \ an OPEN operation that is capable of atomically\n   looking up, creating, and\
    \ locking a file on the server.\n"
- title: 9.1.  Opens and Byte-Range Locks
  contents:
  - "9.1.  Opens and Byte-Range Locks\n   It is assumed that manipulating a byte-range\
    \ lock is rare when\n   compared to READ and WRITE operations.  It is also assumed\
    \ that\n   server restarts and network partitions are relatively rare.\n   Therefore,\
    \ it is important that the READ and WRITE operations have a\n   lightweight mechanism\
    \ to indicate if they possess a held lock.  A\n   LOCK operation contains the\
    \ heavyweight information required to\n   establish a byte-range lock and uniquely\
    \ define the owner of the\n   lock.\n"
- title: 9.1.1.  State-Owner Definition
  contents:
  - "9.1.1.  State-Owner Definition\n   When opening a file or requesting a byte-range\
    \ lock, the client must\n   specify an identifier that represents the owner of\
    \ the requested\n   lock.  This identifier is in the form of a state-owner, represented\n\
    \   in the protocol by a state_owner4, a variable-length opaque array\n   that,\
    \ when concatenated with the current client ID, uniquely defines\n   the owner\
    \ of a lock managed by the client.  This may be a thread ID,\n   process ID, or\
    \ other unique value.\n   Owners of opens and owners of byte-range locks are separate\
    \ entities\n   and remain separate even if the same opaque arrays are used to\n\
    \   designate owners of each.  The protocol distinguishes between open-\n   owners\
    \ (represented by open_owner4 structures) and lock-owners\n   (represented by\
    \ lock_owner4 structures).\n   Each open is associated with a specific open-owner\
    \ while each byte-\n   range lock is associated with a lock-owner and an open-owner,\
    \ the\n   latter being the open-owner associated with the open file under which\n\
    \   the LOCK operation was done.  Delegations and layouts, on the other\n   hand,\
    \ are not associated with a specific owner but are associated\n   with the client\
    \ as a whole (identified by a client ID).\n"
- title: 9.1.2.  Use of the Stateid and Locking
  contents:
  - "9.1.2.  Use of the Stateid and Locking\n   All READ, WRITE, and SETATTR operations\
    \ contain a stateid.  For the\n   purposes of this section, SETATTR operations\
    \ that change the size\n   attribute of a file are treated as if they are writing\
    \ the area\n   between the old and new sizes (i.e., the byte-range truncated or\n\
    \   added to the file by means of the SETATTR), even where SETATTR is not\n  \
    \ explicitly mentioned in the text.  The stateid passed to one of these\n   operations\
    \ must be one that represents an open, a set of byte-range\n   locks, or a delegation,\
    \ or it may be a special stateid representing\n   anonymous access or the special\
    \ bypass stateid.\n   If the state-owner performs a READ or WRITE operation in\
    \ a situation\n   in which it has established a byte-range lock or share reservation\
    \ on\n   the server (any OPEN constitutes a share reservation), the stateid\n\
    \   (previously returned by the server) must be used to indicate what\n   locks,\
    \ including both byte-range locks and share reservations, are\n   held by the\
    \ state-owner.  If no state is established by the client,\n   either a byte-range\
    \ lock or a share reservation, a special stateid\n   for anonymous state (zero\
    \ as the value for \"other\" and \"seqid\") is\n   used.  (See Section 8.2.3 for\
    \ a description of 'special' stateids in\n   general.)  Regardless of whether\
    \ a stateid for anonymous state or a\n   stateid returned by the server is used,\
    \ if there is a conflicting\n   share reservation or mandatory byte-range lock\
    \ held on the file, the\n   server MUST refuse to service the READ or WRITE operation.\n\
    \   Share reservations are established by OPEN operations and by their\n   nature\
    \ are mandatory in that when the OPEN denies READ or WRITE\n   operations, that\
    \ denial results in such operations being rejected\n   with error NFS4ERR_LOCKED.\
    \  Byte-range locks may be implemented by\n   the server as either mandatory or\
    \ advisory, or the choice of\n   mandatory or advisory behavior may be determined\
    \ by the server on the\n   basis of the file being accessed (for example, some\
    \ UNIX-based\n   servers support a \"mandatory lock bit\" on the mode attribute\
    \ such\n   that if set, byte-range locks are required on the file before I/O is\n\
    \   possible).  When byte-range locks are advisory, they only prevent the\n  \
    \ granting of conflicting lock requests and have no effect on READs or\n   WRITEs.\
    \  Mandatory byte-range locks, however, prevent conflicting I/O\n   operations.\
    \  When they are attempted, they are rejected with\n   NFS4ERR_LOCKED.  When the\
    \ client gets NFS4ERR_LOCKED on a file for\n   which it knows it has the proper\
    \ share reservation, it will need to\n   send a LOCK operation on the byte-range\
    \ of the file that includes the\n   byte-range the I/O was to be performed on,\
    \ with an appropriate\n   locktype field of the LOCK operation's arguments (i.e.,\
    \ READ*_LT for\n   a READ operation, WRITE*_LT for a WRITE operation).\n   Note\
    \ that for UNIX environments that support mandatory byte-range\n   locking, the\
    \ distinction between advisory and mandatory locking is\n   subtle.  In fact,\
    \ advisory and mandatory byte-range locks are exactly\n   the same as far as the\
    \ APIs and requirements on implementation.  If\n   the mandatory lock attribute\
    \ is set on the file, the server checks to\n   see if the lock-owner has an appropriate\
    \ shared (READ_LT) or\n   exclusive (WRITE_LT) byte-range lock on the byte-range\
    \ it wishes to\n   READ from or WRITE to.  If there is no appropriate lock, the\
    \ server\n   checks if there is a conflicting lock (which can be done by\n   attempting\
    \ to acquire the conflicting lock on behalf of the lock-\n   owner, and if successful,\
    \ release the lock after the READ or WRITE\n   operation is done), and if there\
    \ is, the server returns\n   NFS4ERR_LOCKED.\n   For Windows environments, byte-range\
    \ locks are always mandatory, so\n   the server always checks for byte-range locks\
    \ during I/O requests.\n   Thus, the LOCK operation does not need to distinguish\
    \ between\n   advisory and mandatory byte-range locks.  It is the server's\n \
    \  processing of the READ and WRITE operations that introduces the\n   distinction.\n\
    \   Every stateid that is validly passed to READ, WRITE, or SETATTR, with\n  \
    \ the exception of special stateid values, defines an access mode for\n   the\
    \ file (i.e., OPEN4_SHARE_ACCESS_READ, OPEN4_SHARE_ACCESS_WRITE, or\n   OPEN4_SHARE_ACCESS_BOTH).\n\
    \   *  For stateids associated with opens, this is the mode defined by\n     \
    \ the original OPEN that caused the allocation of the OPEN stateid\n      and\
    \ as modified by subsequent OPENs and OPEN_DOWNGRADEs for the\n      same open-owner/file\
    \ pair.\n   *  For stateids returned by byte-range LOCK operations, the\n    \
    \  appropriate mode is the access mode for the OPEN stateid\n      associated\
    \ with the lock set represented by the stateid.\n   *  For delegation stateids,\
    \ the access mode is based on the type of\n      delegation.\n   When a READ,\
    \ WRITE, or SETATTR (that specifies the size attribute)\n   operation is done,\
    \ the operation is subject to checking against the\n   access mode to verify that\
    \ the operation is appropriate given the\n   stateid with which the operation\
    \ is associated.\n   In the case of WRITE-type operations (i.e., WRITEs and SETATTRs\
    \ that\n   set size), the server MUST verify that the access mode allows writing\n\
    \   and MUST return an NFS4ERR_OPENMODE error if it does not.  In the\n   case\
    \ of READ, the server may perform the corresponding check on the\n   access mode,\
    \ or it may choose to allow READ on OPENs for\n   OPEN4_SHARE_ACCESS_WRITE, to\
    \ accommodate clients whose WRITE\n   implementation may unavoidably do reads\
    \ (e.g., due to buffer cache\n   constraints).  However, even if READs are allowed\
    \ in these\n   circumstances, the server MUST still check for locks that conflict\n\
    \   with the READ (e.g., another OPEN specified OPEN4_SHARE_DENY_READ or\n   OPEN4_SHARE_DENY_BOTH).\
    \  Note that a server that does enforce the\n   access mode check on READs need\
    \ not explicitly check for conflicting\n   share reservations since the existence\
    \ of OPEN for\n   OPEN4_SHARE_ACCESS_READ guarantees that no conflicting share\n\
    \   reservation can exist.\n   The READ bypass special stateid (all bits of \"\
    other\" and \"seqid\" set\n   to one) indicates a desire to bypass locking checks.\
    \  The server MAY\n   allow READ operations to bypass locking checks at the server,\
    \ when\n   this special stateid is used.  However, WRITE operations with this\n\
    \   special stateid value MUST NOT bypass locking checks and are treated\n   exactly\
    \ the same as if a special stateid for anonymous state were\n   used.\n   A lock\
    \ may not be granted while a READ or WRITE operation using one\n   of the special\
    \ stateids is being performed and the scope of the lock\n   to be granted would\
    \ conflict with the READ or WRITE operation.  This\n   can occur when:\n   * \
    \ A mandatory byte-range lock is requested with a byte-range that\n      conflicts\
    \ with the byte-range of the READ or WRITE operation.  For\n      the purposes\
    \ of this paragraph, a conflict occurs when a shared\n      lock is requested\
    \ and a WRITE operation is being performed, or an\n      exclusive lock is requested\
    \ and either a READ or a WRITE operation\n      is being performed.\n   *  A share\
    \ reservation is requested that denies reading and/or\n      writing and the corresponding\
    \ operation is being performed.\n   *  A delegation is to be granted and the delegation\
    \ type would\n      prevent the I/O operation, i.e., READ and WRITE conflict with\
    \ an\n      OPEN_DELEGATE_WRITE delegation and WRITE conflicts with an\n     \
    \ OPEN_DELEGATE_READ delegation.\n   When a client holds a delegation, it needs\
    \ to ensure that the stateid\n   sent conveys the association of operation with\
    \ the delegation, to\n   avoid the delegation from being avoidably recalled. \
    \ When the\n   delegation stateid, a stateid open associated with that delegation,\n\
    \   or a stateid representing byte-range locks derived from such an open\n   is\
    \ used, the server knows that the READ, WRITE, or SETATTR does not\n   conflict\
    \ with the delegation but is sent under the aegis of the\n   delegation.  Even\
    \ though it is possible for the server to determine\n   from the client ID (via\
    \ the session ID) that the client does in fact\n   have a delegation, the server\
    \ is not obliged to check this, so using\n   a special stateid can result in avoidable\
    \ recall of the delegation.\n"
- title: 9.2.  Lock Ranges
  contents:
  - "9.2.  Lock Ranges\n   The protocol allows a lock-owner to request a lock with\
    \ a byte-range\n   and then either upgrade, downgrade, or unlock a sub-range of\
    \ the\n   initial lock, or a byte-range that overlaps -- fully or partially --\n\
    \   either with that initial lock or a combination of a set of existing\n   locks\
    \ for the same lock-owner.  It is expected that this will be an\n   uncommon type\
    \ of request.  In any case, servers or server file\n   systems may not be able\
    \ to support sub-range lock semantics.  In the\n   event that a server receives\
    \ a locking request that represents a sub-\n   range of current locking state\
    \ for the lock-owner, the server is\n   allowed to return the error NFS4ERR_LOCK_RANGE\
    \ to signify that it\n   does not support sub-range lock operations.  Therefore,\
    \ the client\n   should be prepared to receive this error and, if appropriate,\
    \ report\n   the error to the requesting application.\n   The client is discouraged\
    \ from combining multiple independent locking\n   ranges that happen to be adjacent\
    \ into a single request since the\n   server may not support sub-range requests\
    \ for reasons related to the\n   recovery of byte-range locking state in the event\
    \ of server failure.\n   As discussed in Section 8.4.2, the server may employ\
    \ certain\n   optimizations during recovery that work effectively only when the\n\
    \   client's behavior during lock recovery is similar to the client's\n   locking\
    \ behavior prior to server failure.\n"
- title: 9.3.  Upgrading and Downgrading Locks
  contents:
  - "9.3.  Upgrading and Downgrading Locks\n   If a client has a WRITE_LT lock on\
    \ a byte-range, it can request an\n   atomic downgrade of the lock to a READ_LT\
    \ lock via the LOCK\n   operation, by setting the type to READ_LT.  If the server\
    \ supports\n   atomic downgrade, the request will succeed.  If not, it will return\n\
    \   NFS4ERR_LOCK_NOTSUPP.  The client should be prepared to receive this\n   error\
    \ and, if appropriate, report the error to the requesting\n   application.\n \
    \  If a client has a READ_LT lock on a byte-range, it can request an\n   atomic\
    \ upgrade of the lock to a WRITE_LT lock via the LOCK operation\n   by setting\
    \ the type to WRITE_LT or WRITEW_LT.  If the server does not\n   support atomic\
    \ upgrade, it will return NFS4ERR_LOCK_NOTSUPP.  If the\n   upgrade can be achieved\
    \ without an existing conflict, the request\n   will succeed.  Otherwise, the\
    \ server will return either\n   NFS4ERR_DENIED or NFS4ERR_DEADLOCK.  The error\
    \ NFS4ERR_DEADLOCK is\n   returned if the client sent the LOCK operation with\
    \ the type set to\n   WRITEW_LT and the server has detected a deadlock.  The client\
    \ should\n   be prepared to receive such errors and, if appropriate, report the\n\
    \   error to the requesting application.\n"
- title: 9.4.  Stateid Seqid Values and Byte-Range Locks
  contents:
  - "9.4.  Stateid Seqid Values and Byte-Range Locks\n   When a LOCK or LOCKU operation\
    \ is performed, the stateid returned has\n   the same \"other\" value as the argument's\
    \ stateid, and a \"seqid\" value\n   that is incremented (relative to the argument's\
    \ stateid) to reflect\n   the occurrence of the LOCK or LOCKU operation.  The\
    \ server MUST\n   increment the value of the \"seqid\" field whenever there is\
    \ any change\n   to the locking status of any byte offset as described by any\
    \ of the\n   locks covered by the stateid.  A change in locking status includes\
    \ a\n   change from locked to unlocked or the reverse or a change from being\n\
    \   locked for READ_LT to being locked for WRITE_LT or the reverse.\n   When there\
    \ is no such change, as, for example, when a range already\n   locked for WRITE_LT\
    \ is locked again for WRITE_LT, the server MAY\n   increment the \"seqid\" value.\n"
- title: 9.5.  Issues with Multiple Open-Owners
  contents:
  - "9.5.  Issues with Multiple Open-Owners\n   When the same file is opened by multiple\
    \ open-owners, a client will\n   have multiple OPEN stateids for that file, each\
    \ associated with a\n   different open-owner.  In that case, there can be multiple\
    \ LOCK and\n   LOCKU requests for the same lock-owner sent using the different\
    \ OPEN\n   stateids, and so a situation may arise in which there are multiple\n\
    \   stateids, each representing byte-range locks on the same file and\n   held\
    \ by the same lock-owner but each associated with a different\n   open-owner.\n\
    \   In such a situation, the locking status of each byte (i.e., whether\n   it\
    \ is locked, the READ_LT or WRITE_LT type of the lock, and the lock-\n   owner\
    \ holding the lock) MUST reflect the last LOCK or LOCKU operation\n   done for\
    \ the lock-owner in question, independent of the stateid\n   through which the\
    \ request was sent.\n   When a byte is locked by the lock-owner in question, the\
    \ open-owner\n   to which that byte-range lock is assigned SHOULD be that of the\
    \ open-\n   owner associated with the stateid through which the last LOCK of that\n\
    \   byte was done.  When there is a change in the open-owner associated\n   with\
    \ locks for the stateid through which a LOCK or LOCKU was done,\n   the \"seqid\"\
    \ field of the stateid MUST be incremented, even if the\n   locking, in terms\
    \ of lock-owners has not changed.  When there is a\n   change to the set of locked\
    \ bytes associated with a different stateid\n   for the same lock-owner, i.e.,\
    \ associated with a different open-\n   owner, the \"seqid\" value for that stateid\
    \ MUST NOT be incremented.\n"
- title: 9.6.  Blocking Locks
  contents:
  - "9.6.  Blocking Locks\n   Some clients require the support of blocking locks.\
    \  While NFSv4.1\n   provides a callback when a previously unavailable lock becomes\n\
    \   available, this is an OPTIONAL feature and clients cannot depend on\n   its\
    \ presence.  Clients need to be prepared to continually poll for\n   the lock.\
    \  This presents a fairness problem.  Two of the lock types,\n   READW_LT and\
    \ WRITEW_LT, are used to indicate to the server that the\n   client is requesting\
    \ a blocking lock.  When the callback is not used,\n   the server should maintain\
    \ an ordered list of pending blocking locks.\n   When the conflicting lock is\
    \ released, the server may wait for the\n   period of time equal to lease_time\
    \ for the first waiting client to\n   re-request the lock.  After the lease period\
    \ expires, the next\n   waiting client request is allowed the lock.  Clients are\
    \ required to\n   poll at an interval sufficiently small that it is likely to\
    \ acquire\n   the lock in a timely manner.  The server is not required to maintain\n\
    \   a list of pending blocked locks as it is used to increase fairness\n   and\
    \ not correct operation.  Because of the unordered nature of crash\n   recovery,\
    \ storing of lock state to stable storage would be required\n   to guarantee ordered\
    \ granting of blocking locks.\n   Servers may also note the lock types and delay\
    \ returning denial of\n   the request to allow extra time for a conflicting lock\
    \ to be\n   released, allowing a successful return.  In this way, clients can\n\
    \   avoid the burden of needless frequent polling for blocking locks.\n   The\
    \ server should take care in the length of delay in the event the\n   client retransmits\
    \ the request.\n   If a server receives a blocking LOCK operation, denies it,\
    \ and then\n   later receives a nonblocking request for the same lock, which is\
    \ also\n   denied, then it should remove the lock in question from its list of\n\
    \   pending blocking locks.  Clients should use such a nonblocking\n   request\
    \ to indicate to the server that this is the last time they\n   intend to poll\
    \ for the lock, as may happen when the process\n   requesting the lock is interrupted.\
    \  This is a courtesy to the\n   server, to prevent it from unnecessarily waiting\
    \ a lease period\n   before granting other LOCK operations.  However, clients\
    \ are not\n   required to perform this courtesy, and servers must not depend on\n\
    \   them doing so.  Also, clients must be prepared for the possibility\n   that\
    \ this final locking request will be accepted.\n   When a server indicates, via\
    \ the flag OPEN4_RESULT_MAY_NOTIFY_LOCK,\n   that CB_NOTIFY_LOCK callbacks might\
    \ be done for the current open\n   file, the client should take notice of this,\
    \ but, since this is a\n   hint, cannot rely on a CB_NOTIFY_LOCK always being\
    \ done.  A client\n   may reasonably reduce the frequency with which it polls\
    \ for a denied\n   lock, since the greater latency that might occur is likely\
    \ to be\n   eliminated given a prompt callback, but it still needs to poll.  When\n\
    \   it receives a CB_NOTIFY_LOCK, it should promptly try to obtain the\n   lock,\
    \ but it should be aware that other clients may be polling and\n   that the server\
    \ is under no obligation to reserve the lock for that\n   particular client.\n"
- title: 9.7.  Share Reservations
  contents:
  - "9.7.  Share Reservations\n   A share reservation is a mechanism to control access\
    \ to a file.  It\n   is a separate and independent mechanism from byte-range locking.\n\
    \   When a client opens a file, it sends an OPEN operation to the server\n   specifying\
    \ the type of access required (READ, WRITE, or BOTH) and the\n   type of access\
    \ to deny others (OPEN4_SHARE_DENY_NONE,\n   OPEN4_SHARE_DENY_READ, OPEN4_SHARE_DENY_WRITE,\
    \ or\n   OPEN4_SHARE_DENY_BOTH).  If the OPEN fails, the client will fail the\n\
    \   application's open request.\n   Pseudo-code definition of the semantics:\n\
    \           if (request.access == 0) {\n             return (NFS4ERR_INVAL)\n\
    \           } else {\n             if ((request.access & file_state.deny)) ||\n\
    \                (request.deny & file_state.access)) {\n               return\
    \ (NFS4ERR_SHARE_DENIED)\n           }\n           return (NFS4ERR_OK);\n   When\
    \ doing this checking of share reservations on OPEN, the current\n   file_state\
    \ used in the algorithm includes bits that reflect all\n   current opens, including\
    \ those for the open-owner making the new OPEN\n   request.\n   The constants\
    \ used for the OPEN and OPEN_DOWNGRADE operations for the\n   access and deny\
    \ fields are as follows:\n   const OPEN4_SHARE_ACCESS_READ   = 0x00000001;\n \
    \  const OPEN4_SHARE_ACCESS_WRITE  = 0x00000002;\n   const OPEN4_SHARE_ACCESS_BOTH\
    \   = 0x00000003;\n   const OPEN4_SHARE_DENY_NONE     = 0x00000000;\n   const\
    \ OPEN4_SHARE_DENY_READ     = 0x00000001;\n   const OPEN4_SHARE_DENY_WRITE   \
    \ = 0x00000002;\n   const OPEN4_SHARE_DENY_BOTH     = 0x00000003;\n"
- title: 9.8.  OPEN/CLOSE Operations
  contents:
  - "9.8.  OPEN/CLOSE Operations\n   To provide correct share semantics, a client\
    \ MUST use the OPEN\n   operation to obtain the initial filehandle and indicate\
    \ the desired\n   access and what access, if any, to deny.  Even if the client\
    \ intends\n   to use a special stateid for anonymous state or READ bypass, it\
    \ must\n   still obtain the filehandle for the regular file with the OPEN\n  \
    \ operation so the appropriate share semantics can be applied.  Clients\n   that\
    \ do not have a deny mode built into their programming interfaces\n   for opening\
    \ a file should request a deny mode of\n   OPEN4_SHARE_DENY_NONE.\n   The OPEN\
    \ operation with the CREATE flag also subsumes the CREATE\n   operation for regular\
    \ files as used in previous versions of the NFS\n   protocol.  This allows a create\
    \ with a share to be done atomically.\n   The CLOSE operation removes all share\
    \ reservations held by the open-\n   owner on that file.  If byte-range locks\
    \ are held, the client SHOULD\n   release all locks before sending a CLOSE operation.\
    \  The server MAY\n   free all outstanding locks on CLOSE, but some servers may\
    \ not support\n   the CLOSE of a file that still has byte-range locks held.  The\
    \ server\n   MUST return failure, NFS4ERR_LOCKS_HELD, if any locks would exist\n\
    \   after the CLOSE.\n   The LOOKUP operation will return a filehandle without\
    \ establishing\n   any lock state on the server.  Without a valid stateid, the\
    \ server\n   will assume that the client has the least access.  For example, if\n\
    \   one client opened a file with OPEN4_SHARE_DENY_BOTH and another\n   client\
    \ accesses the file via a filehandle obtained through LOOKUP,\n   the second client\
    \ could only read the file using the special read\n   bypass stateid.  The second\
    \ client could not WRITE the file at all\n   because it would not have a valid\
    \ stateid from OPEN and the special\n   anonymous stateid would not be allowed\
    \ access.\n"
- title: 9.9.  Open Upgrade and Downgrade
  contents:
  - "9.9.  Open Upgrade and Downgrade\n   When an OPEN is done for a file and the\
    \ open-owner for which the OPEN\n   is being done already has the file open, the\
    \ result is to upgrade the\n   open file status maintained on the server to include\
    \ the access and\n   deny bits specified by the new OPEN as well as those for\
    \ the existing\n   OPEN.  The result is that there is one open file, as far as\
    \ the\n   protocol is concerned, and it includes the union of the access and\n\
    \   deny bits for all of the OPEN requests completed.  The OPEN is\n   represented\
    \ by a single stateid whose \"other\" value matches that of\n   the original open,\
    \ and whose \"seqid\" value is incremented to reflect\n   the occurrence of the\
    \ upgrade.  The increment is required in cases in\n   which the \"upgrade\" results\
    \ in no change to the open mode (e.g., an\n   OPEN is done for read when the existing\
    \ open file is opened for\n   OPEN4_SHARE_ACCESS_BOTH).  Only a single CLOSE will\
    \ be done to reset\n   the effects of both OPENs.  The client may use the stateid\
    \ returned\n   by the OPEN effecting the upgrade or with a stateid sharing the\
    \ same\n   \"other\" field and a seqid of zero, although care needs to be taken\
    \ as\n   far as upgrades that happen while the CLOSE is pending.  Note that\n\
    \   the client, when sending the OPEN, may not know that the same file is\n  \
    \ in fact being opened.  The above only applies if both OPENs result in\n   the\
    \ OPENed object being designated by the same filehandle.\n   When the server chooses\
    \ to export multiple filehandles corresponding\n   to the same file object and\
    \ returns different filehandles on two\n   different OPENs of the same file object,\
    \ the server MUST NOT \"OR\"\n   together the access and deny bits and coalesce\
    \ the two open files.\n   Instead, the server must maintain separate OPENs with\
    \ separate\n   stateids and will require separate CLOSEs to free them.\n   When\
    \ multiple open files on the client are merged into a single OPEN\n   file object\
    \ on the server, the close of one of the open files (on the\n   client) may necessitate\
    \ change of the access and deny status of the\n   open file on the server.  This\
    \ is because the union of the access and\n   deny bits for the remaining opens\
    \ may be smaller (i.e., a proper\n   subset) than previously.  The OPEN_DOWNGRADE\
    \ operation is used to\n   make the necessary change and the client should use\
    \ it to update the\n   server so that share reservation requests by other clients\
    \ are\n   handled properly.  The stateid returned has the same \"other\" field\
    \ as\n   that passed to the server.  The \"seqid\" value in the returned stateid\n\
    \   MUST be incremented, even in situations in which there is no change\n   to\
    \ the access and deny bits for the file.\n"
- title: 9.10.  Parallel OPENs
  contents:
  - "9.10.  Parallel OPENs\n   Unlike the case of NFSv4.0, in which OPEN operations\
    \ for the same\n   open-owner are inherently serialized because of the owner-based\n\
    \   seqid, multiple OPENs for the same open-owner may be done in\n   parallel.\
    \  When clients do this, they may encounter situations in\n   which, because of\
    \ the existence of hard links, two OPEN operations\n   may turn out to open the\
    \ same file, with a later OPEN performed being\n   an upgrade of the first, with\
    \ this fact only visible to the client\n   once the operations complete.\n   In\
    \ this situation, clients may determine the order in which the OPENs\n   were\
    \ performed by examining the stateids returned by the OPENs.\n   Stateids that\
    \ share a common value of the \"other\" field can be\n   recognized as having\
    \ opened the same file, with the order of the\n   operations determinable from\
    \ the order of the \"seqid\" fields, mod any\n   possible wraparound of the 32-bit\
    \ field.\n   When the possibility exists that the client will send multiple OPENs\n\
    \   for the same open-owner in parallel, it may be the case that an open\n   upgrade\
    \ may happen without the client knowing beforehand that this\n   could happen.\
    \  Because of this possibility, CLOSEs and\n   OPEN_DOWNGRADEs should generally\
    \ be sent with a non-zero seqid in the\n   stateid, to avoid the possibility that\
    \ the status change associated\n   with an open upgrade is not inadvertently lost.\n"
- title: 9.11.  Reclaim of Open and Byte-Range Locks
  contents:
  - "9.11.  Reclaim of Open and Byte-Range Locks\n   Special forms of the LOCK and\
    \ OPEN operations are provided when it is\n   necessary to re-establish byte-range\
    \ locks or opens after a server\n   failure.\n   *  To reclaim existing opens,\
    \ an OPEN operation is performed using a\n      CLAIM_PREVIOUS.  Because the client,\
    \ in this type of situation,\n      will have already opened the file and have\
    \ the filehandle of the\n      target file, this operation requires that the current\
    \ filehandle\n      be the target file, rather than a directory, and no file name\
    \ is\n      specified.\n   *  To reclaim byte-range locks, a LOCK operation with\
    \ the reclaim\n      parameter set to true is used.\n   Reclaims of opens associated\
    \ with delegations are discussed in\n   Section 10.2.1.\n"
- title: 10.  Client-Side Caching
  contents:
  - "10.  Client-Side Caching\n   Client-side caching of data, of file attributes,\
    \ and of file names is\n   essential to providing good performance with the NFS\
    \ protocol.\n   Providing distributed cache coherence is a difficult problem,\
    \ and\n   previous versions of the NFS protocol have not attempted it.\n   Instead,\
    \ several NFS client implementation techniques have been used\n   to reduce the\
    \ problems that a lack of coherence poses for users.\n   These techniques have\
    \ not been clearly defined by earlier protocol\n   specifications, and it is often\
    \ unclear what is valid or invalid\n   client behavior.\n   The NFSv4.1 protocol\
    \ uses many techniques similar to those that have\n   been used in previous protocol\
    \ versions.  The NFSv4.1 protocol does\n   not provide distributed cache coherence.\
    \  However, it defines a more\n   limited set of caching guarantees to allow locks\
    \ and share\n   reservations to be used without destructive interference from\
    \ client-\n   side caching.\n   In addition, the NFSv4.1 protocol introduces a\
    \ delegation mechanism,\n   which allows many decisions normally made by the server\
    \ to be made\n   locally by clients.  This mechanism provides efficient support\
    \ of the\n   common cases where sharing is infrequent or where sharing is read-\n\
    \   only.\n"
- title: 10.1.  Performance Challenges for Client-Side Caching
  contents:
  - "10.1.  Performance Challenges for Client-Side Caching\n   Caching techniques\
    \ used in previous versions of the NFS protocol have\n   been successful in providing\
    \ good performance.  However, several\n   scalability challenges can arise when\
    \ those techniques are used with\n   very large numbers of clients.  This is particularly\
    \ true when\n   clients are geographically distributed, which classically increases\n\
    \   the latency for cache revalidation requests.\n   The previous versions of\
    \ the NFS protocol repeat their file data\n   cache validation requests at the\
    \ time the file is opened.  This\n   behavior can have serious performance drawbacks.\
    \  A common case is\n   one in which a file is only accessed by a single client.\
    \  Therefore,\n   sharing is infrequent.\n   In this case, repeated references\
    \ to the server to find that no\n   conflicts exist are expensive.  A better option\
    \ with regards to\n   performance is to allow a client that repeatedly opens a\
    \ file to do\n   so without reference to the server.  This is done until potentially\n\
    \   conflicting operations from another client actually occur.\n   A similar situation\
    \ arises in connection with byte-range locking.\n   Sending LOCK and LOCKU operations\
    \ as well as the READ and WRITE\n   operations necessary to make data caching\
    \ consistent with the locking\n   semantics (see Section 10.3.2) can severely\
    \ limit performance.  When\n   locking is used to provide protection against infrequent\
    \ conflicts, a\n   large penalty is incurred.  This penalty may discourage the\
    \ use of\n   byte-range locking by applications.\n   The NFSv4.1 protocol provides\
    \ more aggressive caching strategies with\n   the following design goals:\n  \
    \ *  Compatibility with a large range of server semantics.\n   *  Providing the\
    \ same caching benefits as previous versions of the\n      NFS protocol when unable\
    \ to support the more aggressive model.\n   *  Requirements for aggressive caching\
    \ are organized so that a large\n      portion of the benefit can be obtained\
    \ even when not all of the\n      requirements can be met.\n   The appropriate\
    \ requirements for the server are discussed in later\n   sections in which specific\
    \ forms of caching are covered (see\n   Section 10.4).\n"
- title: 10.2.  Delegation and Callbacks
  contents:
  - "10.2.  Delegation and Callbacks\n   Recallable delegation of server responsibilities\
    \ for a file to a\n   client improves performance by avoiding repeated requests\
    \ to the\n   server in the absence of inter-client conflict.  With the use of\
    \ a\n   \"callback\" RPC from server to client, a server recalls delegated\n \
    \  responsibilities when another client engages in sharing of a\n   delegated\
    \ file.\n   A delegation is passed from the server to the client, specifying the\n\
    \   object of the delegation and the type of delegation.  There are\n   different\
    \ types of delegations, but each type contains a stateid to\n   be used to represent\
    \ the delegation when performing operations that\n   depend on the delegation.\
    \  This stateid is similar to those\n   associated with locks and share reservations\
    \ but differs in that the\n   stateid for a delegation is associated with a client\
    \ ID and may be\n   used on behalf of all the open-owners for the given client.\
    \  A\n   delegation is made to the client as a whole and not to any specific\n\
    \   process or thread of control within it.\n   The backchannel is established\
    \ by CREATE_SESSION and\n   BIND_CONN_TO_SESSION, and the client is required to\
    \ maintain it.\n   Because the backchannel may be down, even temporarily, correct\n\
    \   protocol operation does not depend on them.  Preliminary testing of\n   backchannel\
    \ functionality by means of a CB_COMPOUND procedure with a\n   single operation,\
    \ CB_SEQUENCE, can be used to check the continuity of\n   the backchannel.  A\
    \ server avoids delegating responsibilities until\n   it has determined that the\
    \ backchannel exists.  Because the granting\n   of a delegation is always conditional\
    \ upon the absence of conflicting\n   access, clients MUST NOT assume that a delegation\
    \ will be granted and\n   they MUST always be prepared for OPENs, WANT_DELEGATIONs,\
    \ and\n   GET_DIR_DELEGATIONs to be processed without any delegations being\n\
    \   granted.\n   Unlike locks, an operation by a second client to a delegated\
    \ file\n   will cause the server to recall a delegation through a callback.  For\n\
    \   individual operations, we will describe, under IMPLEMENTATION, when\n   such\
    \ operations are required to effect a recall.  A number of points\n   should be\
    \ noted, however.\n   *  The server is free to recall a delegation whenever it\
    \ feels it is\n      desirable and may do so even if no operations requiring recall\
    \ are\n      being done.\n   *  Operations done outside the NFSv4.1 protocol,\
    \ due to, for example,\n      access by other protocols, or by local access, also\
    \ need to result\n      in delegation recall when they make analogous changes\
    \ to file\n      system data.  What is crucial is if the change would invalidate\n\
    \      the guarantees provided by the delegation.  When this is possible,\n  \
    \    the delegation needs to be recalled and MUST be returned or\n      revoked\
    \ before allowing the operation to proceed.\n   *  The semantics of the file system\
    \ are crucial in defining when\n      delegation recall is required.  If a particular\
    \ change within a\n      specific implementation causes change to a file attribute,\
    \ then\n      delegation recall is required, whether that operation has been\n\
    \      specifically listed as requiring delegation recall.  Again, what\n    \
    \  is critical is whether the guarantees provided by the delegation\n      are\
    \ being invalidated.\n   Despite those caveats, the implementation sections for\
    \ a number of\n   operations describe situations in which delegation recall would\
    \ be\n   required under some common circumstances:\n   *  For GETATTR, see Section\
    \ 18.7.4.\n   *  For OPEN, see Section 18.16.4.\n   *  For READ, see Section 18.22.4.\n\
    \   *  For REMOVE, see Section 18.25.4.\n   *  For RENAME, see Section 18.26.4.\n\
    \   *  For SETATTR, see Section 18.30.4.\n   *  For WRITE, see Section 18.32.4.\n\
    \   On recall, the client holding the delegation needs to flush modified\n   state\
    \ (such as modified data) to the server and return the\n   delegation.  The conflicting\
    \ request will not be acted on until the\n   recall is complete.  The recall is\
    \ considered complete when the\n   client returns the delegation or the server\
    \ times its wait for the\n   delegation to be returned and revokes the delegation\
    \ as a result of\n   the timeout.  In the interim, the server will either delay\
    \ responding\n   to conflicting requests or respond to them with NFS4ERR_DELAY.\n\
    \   Following the resolution of the recall, the server has the\n   information\
    \ necessary to grant or deny the second client's request.\n   At the time the\
    \ client receives a delegation recall, it may have\n   substantial state that\
    \ needs to be flushed to the server.  Therefore,\n   the server should allow sufficient\
    \ time for the delegation to be\n   returned since it may involve numerous RPCs\
    \ to the server.  If the\n   server is able to determine that the client is diligently\
    \ flushing\n   state to the server as a result of the recall, the server may extend\n\
    \   the usual time allowed for a recall.  However, the time allowed for\n   recall\
    \ completion should not be unbounded.\n   An example of this is when responsibility\
    \ to mediate opens on a given\n   file is delegated to a client (see Section 10.4).\
    \  The server will\n   not know what opens are in effect on the client.  Without\
    \ this\n   knowledge, the server will be unable to determine if the access and\n\
    \   deny states for the file allow any particular open until the\n   delegation\
    \ for the file has been returned.\n   A client failure or a network partition\
    \ can result in failure to\n   respond to a recall callback.  In this case, the\
    \ server will revoke\n   the delegation, which in turn will render useless any\
    \ modified state\n   still on the client.\n"
- title: 10.2.1.  Delegation Recovery
  contents:
  - "10.2.1.  Delegation Recovery\n   There are three situations that delegation recovery\
    \ needs to deal\n   with:\n   *  client restart\n   *  server restart\n   *  network\
    \ partition (full or backchannel-only)\n   In the event the client restarts, the\
    \ failure to renew the lease will\n   result in the revocation of byte-range locks\
    \ and share reservations.\n   Delegations, however, may be treated a bit differently.\n\
    \   There will be situations in which delegations will need to be re-\n   established\
    \ after a client restarts.  The reason for this is that the\n   client may have\
    \ file data stored locally and this data was associated\n   with the previously\
    \ held delegations.  The client will need to re-\n   establish the appropriate\
    \ file state on the server.\n   To allow for this type of client recovery, the\
    \ server MAY extend the\n   period for delegation recovery beyond the typical\
    \ lease expiration\n   period.  This implies that requests from other clients\
    \ that conflict\n   with these delegations will need to wait.  Because the normal\
    \ recall\n   process may require significant time for the client to flush changed\n\
    \   state to the server, other clients need be prepared for delays that\n   occur\
    \ because of a conflicting delegation.  This longer interval\n   would increase\
    \ the window for clients to restart and consult stable\n   storage so that the\
    \ delegations can be reclaimed.  For OPEN\n   delegations, such delegations are\
    \ reclaimed using OPEN with a claim\n   type of CLAIM_DELEGATE_PREV or CLAIM_DELEG_PREV_FH\
    \ (see Sections 10.5\n   and 18.16 for discussion of OPEN delegation and the details\
    \ of OPEN,\n   respectively).\n   A server MAY support claim types of CLAIM_DELEGATE_PREV\
    \ and\n   CLAIM_DELEG_PREV_FH, and if it does, it MUST NOT remove delegations\n\
    \   upon a CREATE_SESSION that confirm a client ID created by\n   EXCHANGE_ID.\
    \  Instead, the server MUST, for a period of time no less\n   than that of the\
    \ value of the lease_time attribute, maintain the\n   client's delegations to\
    \ allow time for the client to send\n   CLAIM_DELEGATE_PREV and/or CLAIM_DELEG_PREV_FH\
    \ requests.  The server\n   that supports CLAIM_DELEGATE_PREV and/or CLAIM_DELEG_PREV_FH\
    \ MUST\n   support the DELEGPURGE operation.\n   When the server restarts, delegations\
    \ are reclaimed (using the OPEN\n   operation with CLAIM_PREVIOUS) in a similar\
    \ fashion to byte-range\n   locks and share reservations.  However, there is a\
    \ slight semantic\n   difference.  In the normal case, if the server decides that\
    \ a\n   delegation should not be granted, it performs the requested action\n \
    \  (e.g., OPEN) without granting any delegation.  For reclaim, the\n   server\
    \ grants the delegation but a special designation is applied so\n   that the client\
    \ treats the delegation as having been granted but\n   recalled by the server.\
    \  Because of this, the client has the duty to\n   write all modified state to\
    \ the server and then return the\n   delegation.  This process of handling delegation\
    \ reclaim reconciles\n   three principles of the NFSv4.1 protocol:\n   *  Upon\
    \ reclaim, a client reporting resources assigned to it by an\n      earlier server\
    \ instance must be granted those resources.\n   *  The server has unquestionable\
    \ authority to determine whether\n      delegations are to be granted and, once\
    \ granted, whether they are\n      to be continued.\n   *  The use of callbacks\
    \ should not be depended upon until the client\n      has proven its ability to\
    \ receive them.\n   When a client needs to reclaim a delegation and there is no\n\
    \   associated open, the client may use the CLAIM_PREVIOUS variant of the\n  \
    \ WANT_DELEGATION operation.  However, since the server is not required\n   to\
    \ support this operation, an alternative is to reclaim via a dummy\n   OPEN together\
    \ with the delegation using an OPEN of type\n   CLAIM_PREVIOUS.  The dummy open\
    \ file can be released using a CLOSE to\n   re-establish the original state to\
    \ be reclaimed, a delegation without\n   an associated open.\n   When a client\
    \ has more than a single open associated with a\n   delegation, state for those\
    \ additional opens can be established using\n   OPEN operations of type CLAIM_DELEGATE_CUR.\
    \  When these are used to\n   establish opens associated with reclaimed delegations,\
    \ the server\n   MUST allow them when made within the grace period.\n   When a\
    \ network partition occurs, delegations are subject to freeing\n   by the server\
    \ when the lease renewal period expires.  This is similar\n   to the behavior\
    \ for locks and share reservations.  For delegations,\n   however, the server\
    \ may extend the period in which conflicting\n   requests are held off.  Eventually,\
    \ the occurrence of a conflicting\n   request from another client will cause revocation\
    \ of the delegation.\n   A loss of the backchannel (e.g., by later network configuration\n\
    \   change) will have the same effect.  A recall request will fail and\n   revocation\
    \ of the delegation will result.\n   A client normally finds out about revocation\
    \ of a delegation when it\n   uses a stateid associated with a delegation and\
    \ receives one of the\n   errors NFS4ERR_EXPIRED, NFS4ERR_ADMIN_REVOKED, or\n\
    \   NFS4ERR_DELEG_REVOKED.  It also may find out about delegation\n   revocation\
    \ after a client restart when it attempts to reclaim a\n   delegation and receives\
    \ that same error.  Note that in the case of a\n   revoked OPEN_DELEGATE_WRITE\
    \ delegation, there are issues because data\n   may have been modified by the\
    \ client whose delegation is revoked and\n   separately by other clients.  See\
    \ Section 10.5.1 for a discussion of\n   such issues.  Note also that when delegations\
    \ are revoked,\n   information about the revoked delegation will be written by\
    \ the\n   server to stable storage (as described in Section 8.4.3).  This is\n\
    \   done to deal with the case in which a server restarts after revoking\n   a\
    \ delegation but before the client holding the revoked delegation is\n   notified\
    \ about the revocation.\n"
- title: 10.3.  Data Caching
  contents:
  - "10.3.  Data Caching\n   When applications share access to a set of files, they\
    \ need to be\n   implemented so as to take account of the possibility of conflicting\n\
    \   access by another application.  This is true whether the applications\n  \
    \ in question execute on different clients or reside on the same\n   client.\n\
    \   Share reservations and byte-range locks are the facilities the\n   NFSv4.1\
    \ protocol provides to allow applications to coordinate access\n   by using mutual\
    \ exclusion facilities.  The NFSv4.1 protocol's data\n   caching must be implemented\
    \ such that it does not invalidate the\n   assumptions on which those using these\
    \ facilities depend.\n"
- title: 10.3.1.  Data Caching and OPENs
  contents:
  - "10.3.1.  Data Caching and OPENs\n   In order to avoid invalidating the sharing\
    \ assumptions on which\n   applications rely, NFSv4.1 clients should not provide\
    \ cached data to\n   applications or modify it on behalf of an application when\
    \ it would\n   not be valid to obtain or modify that same data via a READ or WRITE\n\
    \   operation.\n   Furthermore, in the absence of an OPEN delegation (see Section\
    \ 10.4),\n   two additional rules apply.  Note that these rules are obeyed in\n\
    \   practice by many NFSv3 clients.\n   *  First, cached data present on a client\
    \ must be revalidated after\n      doing an OPEN.  Revalidating means that the\
    \ client fetches the\n      change attribute from the server, compares it with\
    \ the cached\n      change attribute, and if different, declares the cached data\
    \ (as\n      well as the cached attributes) as invalid.  This is to ensure that\n\
    \      the data for the OPENed file is still correctly reflected in the\n    \
    \  client's cache.  This validation must be done at least when the\n      client's\
    \ OPEN operation includes a deny of OPEN4_SHARE_DENY_WRITE\n      or OPEN4_SHARE_DENY_BOTH,\
    \ thus terminating a period in which other\n      clients may have had the opportunity\
    \ to open the file with\n      OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH\
    \ access.  Clients\n      may choose to do the revalidation more often (i.e.,\
    \ at OPENs\n      specifying a deny mode of OPEN4_SHARE_DENY_NONE) to parallel\
    \ the\n      NFSv3 protocol's practice for the benefit of users assuming this\n\
    \      degree of cache revalidation.\n      Since the change attribute is updated\
    \ for data and metadata\n      modifications, some client implementors may be\
    \ tempted to use the\n      time_modify attribute and not the change attribute\
    \ to validate\n      cached data, so that metadata changes do not spuriously invalidate\n\
    \      clean data.  The implementor is cautioned in this approach.  The\n    \
    \  change attribute is guaranteed to change for each update to the\n      file,\
    \ whereas time_modify is guaranteed to change only at the\n      granularity of\
    \ the time_delta attribute.  Use by the client's data\n      cache validation\
    \ logic of time_modify and not change runs the risk\n      of the client incorrectly\
    \ marking stale data as valid.  Thus, any\n      cache validation approach by\
    \ the client MUST include the use of\n      the change attribute.\n   *  Second,\
    \ modified data must be flushed to the server before closing\n      a file OPENed\
    \ for OPEN4_SHARE_ACCESS_WRITE.  This is complementary\n      to the first rule.\
    \  If the data is not flushed at CLOSE, the\n      revalidation done after the\
    \ client OPENs a file is unable to\n      achieve its purpose.  The other aspect\
    \ to flushing the data before\n      close is that the data must be committed\
    \ to stable storage, at the\n      server, before the CLOSE operation is requested\
    \ by the client.  In\n      the case of a server restart and a CLOSEd file, it\
    \ may not be\n      possible to retransmit the data to be written to the file,\
    \ hence,\n      this requirement.\n"
- title: 10.3.2.  Data Caching and File Locking
  contents:
  - "10.3.2.  Data Caching and File Locking\n   For those applications that choose\
    \ to use byte-range locking instead\n   of share reservations to exclude inconsistent\
    \ file access, there is\n   an analogous set of constraints that apply to client-side\
    \ data\n   caching.  These rules are effective only if the byte-range locking\
    \ is\n   used in a way that matches in an equivalent way the actual READ and\n\
    \   WRITE operations executed.  This is as opposed to byte-range locking\n   that\
    \ is based on pure convention.  For example, it is possible to\n   manipulate\
    \ a two-megabyte file by dividing the file into two one-\n   megabyte ranges and\
    \ protecting access to the two byte-ranges by byte-\n   range locks on bytes zero\
    \ and one.  A WRITE_LT lock on byte zero of\n   the file would represent the right\
    \ to perform READ and WRITE\n   operations on the first byte-range.  A WRITE_LT\
    \ lock on byte one of\n   the file would represent the right to perform READ and\
    \ WRITE\n   operations on the second byte-range.  As long as all applications\n\
    \   manipulating the file obey this convention, they will work on a local\n  \
    \ file system.  However, they may not work with the NFSv4.1 protocol\n   unless\
    \ clients refrain from data caching.\n   The rules for data caching in the byte-range\
    \ locking environment are:\n   *  First, when a client obtains a byte-range lock\
    \ for a particular\n      byte-range, the data cache corresponding to that byte-range\
    \ (if\n      any cache data exists) must be revalidated.  If the change\n    \
    \  attribute indicates that the file may have been updated since the\n      cached\
    \ data was obtained, the client must flush or invalidate the\n      cached data\
    \ for the newly locked byte-range.  A client might\n      choose to invalidate\
    \ all of the non-modified cached data that it\n      has for the file, but the\
    \ only requirement for correct operation\n      is to invalidate all of the data\
    \ in the newly locked byte-range.\n   *  Second, before releasing a WRITE_LT lock\
    \ for a byte-range, all\n      modified data for that byte-range must be flushed\
    \ to the server.\n      The modified data must also be written to stable storage.\n\
    \   Note that flushing data to the server and the invalidation of cached\n   data\
    \ must reflect the actual byte-ranges locked or unlocked.\n   Rounding these up\
    \ or down to reflect client cache block boundaries\n   will cause problems if\
    \ not carefully done.  For example, writing a\n   modified block when only half\
    \ of that block is within an area being\n   unlocked may cause invalid modification\
    \ to the byte-range outside the\n   unlocked area.  This, in turn, may be part\
    \ of a byte-range locked by\n   another client.  Clients can avoid this situation\
    \ by synchronously\n   performing portions of WRITE operations that overlap that\
    \ portion\n   (initial or final) that is not a full block.  Similarly, invalidating\n\
    \   a locked area that is not an integral number of full buffer blocks\n   would\
    \ require the client to read one or two partial blocks from the\n   server if\
    \ the revalidation procedure shows that the data that the\n   client possesses\
    \ may not be valid.\n   The data that is written to the server as a prerequisite\
    \ to the\n   unlocking of a byte-range must be written, at the server, to stable\n\
    \   storage.  The client may accomplish this either with synchronous\n   writes\
    \ or by following asynchronous writes with a COMMIT operation.\n   This is required\
    \ because retransmission of the modified data after a\n   server restart might\
    \ conflict with a lock held by another client.\n   A client implementation may\
    \ choose to accommodate applications that\n   use byte-range locking in non-standard\
    \ ways (e.g., using a byte-range\n   lock as a global semaphore) by flushing to\
    \ the server more data upon\n   a LOCKU than is covered by the locked range. \
    \ This may include\n   modified data within files other than the one for which\
    \ the unlocks\n   are being done.  In such cases, the client must not interfere\
    \ with\n   applications whose READs and WRITEs are being done only within the\n\
    \   bounds of byte-range locks that the application holds.  For example,\n   an\
    \ application locks a single byte of a file and proceeds to write\n   that single\
    \ byte.  A client that chose to handle a LOCKU by flushing\n   all modified data\
    \ to the server could validly write that single byte\n   in response to an unrelated\
    \ LOCKU operation.  However, it would not\n   be valid to write the entire block\
    \ in which that single written byte\n   was located since it includes an area\
    \ that is not locked and might be\n   locked by another client.  Client implementations\
    \ can avoid this\n   problem by dividing files with modified data into those for\
    \ which all\n   modifications are done to areas covered by an appropriate byte-range\n\
    \   lock and those for which there are modifications not covered by a\n   byte-range\
    \ lock.  Any writes done for the former class of files must\n   not include areas\
    \ not locked and thus not modified on the client.\n"
- title: 10.3.3.  Data Caching and Mandatory File Locking
  contents:
  - "10.3.3.  Data Caching and Mandatory File Locking\n   Client-side data caching\
    \ needs to respect mandatory byte-range\n   locking when it is in effect.  The\
    \ presence of mandatory byte-range\n   locking for a given file is indicated when\
    \ the client gets back\n   NFS4ERR_LOCKED from a READ or WRITE operation on a\
    \ file for which it\n   has an appropriate share reservation.  When mandatory\
    \ locking is in\n   effect for a file, the client must check for an appropriate\
    \ byte-\n   range lock for data being read or written.  If a byte-range lock\n\
    \   exists for the range being read or written, the client may satisfy\n   the\
    \ request using the client's validated cache.  If an appropriate\n   byte-range\
    \ lock is not held for the range of the read or write, the\n   read or write request\
    \ must not be satisfied by the client's cache and\n   the request must be sent\
    \ to the server for processing.  When a read\n   or write request partially overlaps\
    \ a locked byte-range, the request\n   should be subdivided into multiple pieces\
    \ with each byte-range\n   (locked or not) treated appropriately.\n"
- title: 10.3.4.  Data Caching and File Identity
  contents:
  - "10.3.4.  Data Caching and File Identity\n   When clients cache data, the file\
    \ data needs to be organized\n   according to the file system object to which\
    \ the data belongs.  For\n   NFSv3 clients, the typical practice has been to assume\
    \ for the\n   purpose of caching that distinct filehandles represent distinct\
    \ file\n   system objects.  The client then has the choice to organize and\n \
    \  maintain the data cache on this basis.\n   In the NFSv4.1 protocol, there is\
    \ now the possibility to have\n   significant deviations from a \"one filehandle\
    \ per object\" model\n   because a filehandle may be constructed on the basis\
    \ of the object's\n   pathname.  Therefore, clients need a reliable method to\
    \ determine if\n   two filehandles designate the same file system object.  If\
    \ clients\n   were simply to assume that all distinct filehandles denote distinct\n\
    \   objects and proceed to do data caching on this basis, caching\n   inconsistencies\
    \ would arise between the distinct client-side objects\n   that mapped to the\
    \ same server-side object.\n   By providing a method to differentiate filehandles,\
    \ the NFSv4.1\n   protocol alleviates a potential functional regression in comparison\n\
    \   with the NFSv3 protocol.  Without this method, caching\n   inconsistencies\
    \ within the same client could occur, and this has not\n   been present in previous\
    \ versions of the NFS protocol.  Note that it\n   is possible to have such inconsistencies\
    \ with applications executing\n   on multiple clients, but that is not the issue\
    \ being addressed here.\n   For the purposes of data caching, the following steps\
    \ allow an\n   NFSv4.1 client to determine whether two distinct filehandles denote\n\
    \   the same server-side object:\n   *  If GETATTR directed to two filehandles\
    \ returns different values of\n      the fsid attribute, then the filehandles\
    \ represent distinct\n      objects.\n   *  If GETATTR for any file with an fsid\
    \ that matches the fsid of the\n      two filehandles in question returns a unique_handles\
    \ attribute\n      with a value of TRUE, then the two objects are distinct.\n\
    \   *  If GETATTR directed to the two filehandles does not return the\n      fileid\
    \ attribute for both of the handles, then it cannot be\n      determined whether\
    \ the two objects are the same.  Therefore,\n      operations that depend on that\
    \ knowledge (e.g., client-side data\n      caching) cannot be done reliably. \
    \ Note that if GETATTR does not\n      return the fileid attribute for both filehandles,\
    \ it will return\n      it for neither of the filehandles, since the fsid for\
    \ both\n      filehandles is the same.\n   *  If GETATTR directed to the two filehandles\
    \ returns different\n      values for the fileid attribute, then they are distinct\
    \ objects.\n   *  Otherwise, they are the same object.\n"
- title: 10.4.  Open Delegation
  contents:
  - "10.4.  Open Delegation\n   When a file is being OPENed, the server may delegate\
    \ further handling\n   of opens and closes for that file to the opening client.\
    \  Any such\n   delegation is recallable since the circumstances that allowed\
    \ for the\n   delegation are subject to change.  In particular, if the server\n\
    \   receives a conflicting OPEN from another client, the server must\n   recall\
    \ the delegation before deciding whether the OPEN from the other\n   client may\
    \ be granted.  Making a delegation is up to the server, and\n   clients should\
    \ not assume that any particular OPEN either will or\n   will not result in an\
    \ OPEN delegation.  The following is a typical\n   set of conditions that servers\
    \ might use in deciding whether an OPEN\n   should be delegated:\n   *  The client\
    \ must be able to respond to the server's callback\n      requests.  If a backchannel\
    \ has been established, the server will\n      send a CB_COMPOUND request, containing\
    \ a single operation,\n      CB_SEQUENCE, for a test of backchannel availability.\n\
    \   *  The client must have responded properly to previous recalls.\n   *  There\
    \ must be no current OPEN conflicting with the requested\n      delegation.\n\
    \   *  There should be no current delegation that conflicts with the\n      delegation\
    \ being requested.\n   *  The probability of future conflicting open requests\
    \ should be low\n      based on the recent history of the file.\n   *  The existence\
    \ of any server-specific semantics of OPEN/CLOSE that\n      would make the required\
    \ handling incompatible with the prescribed\n      handling that the delegated\
    \ client would apply (see below).\n   There are two types of OPEN delegations:\
    \ OPEN_DELEGATE_READ and\n   OPEN_DELEGATE_WRITE.  An OPEN_DELEGATE_READ delegation\
    \ allows a\n   client to handle, on its own, requests to open a file for reading\n\
    \   that do not deny OPEN4_SHARE_ACCESS_READ access to others.  Multiple\n   OPEN_DELEGATE_READ\
    \ delegations may be outstanding simultaneously and\n   do not conflict.  An OPEN_DELEGATE_WRITE\
    \ delegation allows the client\n   to handle, on its own, all opens.  Only one\
    \ OPEN_DELEGATE_WRITE\n   delegation may exist for a given file at a given time,\
    \ and it is\n   inconsistent with any OPEN_DELEGATE_READ delegations.\n   When\
    \ a client has an OPEN_DELEGATE_READ delegation, it is assured\n   that neither\
    \ the contents, the attributes (with the exception of\n   time_access), nor the\
    \ names of any links to the file will change\n   without its knowledge, so long\
    \ as the delegation is held.  When a\n   client has an OPEN_DELEGATE_WRITE delegation,\
    \ it may modify the file\n   data locally since no other client will be accessing\
    \ the file's data.\n   The client holding an OPEN_DELEGATE_WRITE delegation may\
    \ only locally\n   affect file attributes that are intimately connected with the\
    \ file\n   data: size, change, time_access, time_metadata, and time_modify.  All\n\
    \   other attributes must be reflected on the server.\n   When a client has an\
    \ OPEN delegation, it does not need to send OPENs\n   or CLOSEs to the server.\
    \  Instead, the client may update the\n   appropriate status internally.  For\
    \ an OPEN_DELEGATE_READ delegation,\n   opens that cannot be handled locally (opens\
    \ that are for\n   OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH or that deny\n\
    \   OPEN4_SHARE_ACCESS_READ access) must be sent to the server.\n   When an OPEN\
    \ delegation is made, the reply to the OPEN contains an\n   OPEN delegation structure\
    \ that specifies the following:\n   *  the type of delegation (OPEN_DELEGATE_READ\
    \ or\n      OPEN_DELEGATE_WRITE).\n   *  space limitation information to control\
    \ flushing of data on close\n      (OPEN_DELEGATE_WRITE delegation only; see Section\
    \ 10.4.1)\n   *  an nfsace4 specifying read and write permissions\n   *  a stateid\
    \ to represent the delegation\n   The delegation stateid is separate and distinct\
    \ from the stateid for\n   the OPEN proper.  The standard stateid, unlike the\
    \ delegation\n   stateid, is associated with a particular lock-owner and will\
    \ continue\n   to be valid after the delegation is recalled and the file remains\n\
    \   open.\n   When a request internal to the client is made to open a file and\
    \ an\n   OPEN delegation is in effect, it will be accepted or rejected solely\n\
    \   on the basis of the following conditions.  Any requirement for other\n   checks\
    \ to be made by the delegate should result in the OPEN\n   delegation being denied\
    \ so that the checks can be made by the server\n   itself.\n   *  The access and\
    \ deny bits for the request and the file as described\n      in Section 9.7.\n\
    \   *  The read and write permissions as determined below.\n   The nfsace4 passed\
    \ with delegation can be used to avoid frequent\n   ACCESS calls.  The permission\
    \ check should be as follows:\n   *  If the nfsace4 indicates that the open may\
    \ be done, then it should\n      be granted without reference to the server.\n\
    \   *  If the nfsace4 indicates that the open may not be done, then an\n     \
    \ ACCESS request must be sent to the server to obtain the definitive\n      answer.\n\
    \   The server may return an nfsace4 that is more restrictive than the\n   actual\
    \ ACL of the file.  This includes an nfsace4 that specifies\n   denial of all\
    \ access.  Note that some common practices such as\n   mapping the traditional\
    \ user \"root\" to the user \"nobody\" (see\n   Section 5.9) may make it incorrect\
    \ to return the actual ACL of the\n   file in the delegation response.\n   The\
    \ use of a delegation together with various other forms of caching\n   creates\
    \ the possibility that no server authentication and\n   authorization will ever\
    \ be performed for a given user since all of\n   the user's requests might be\
    \ satisfied locally.  Where the client is\n   depending on the server for authentication\
    \ and authorization, the\n   client should be sure authentication and authorization\
    \ occurs for\n   each user by use of the ACCESS operation.  This should be the\
    \ case\n   even if an ACCESS operation would not be required otherwise.  As\n\
    \   mentioned before, the server may enforce frequent authentication by\n   returning\
    \ an nfsace4 denying all access with every OPEN delegation.\n"
- title: 10.4.1.  Open Delegation and Data Caching
  contents:
  - "10.4.1.  Open Delegation and Data Caching\n   An OPEN delegation allows much\
    \ of the message overhead associated\n   with the opening and closing files to\
    \ be eliminated.  An open when an\n   OPEN delegation is in effect does not require\
    \ that a validation\n   message be sent to the server.  The continued endurance\
    \ of the\n   \"OPEN_DELEGATE_READ delegation\" provides a guarantee that no OPEN\
    \ for\n   OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH, and thus no write,\n\
    \   has occurred.  Similarly, when closing a file opened for\n   OPEN4_SHARE_ACCESS_WRITE/OPEN4_SHARE_ACCESS_BOTH\
    \ and if an\n   OPEN_DELEGATE_WRITE delegation is in effect, the data written\
    \ does\n   not have to be written to the server until the OPEN delegation is\n\
    \   recalled.  The continued endurance of the OPEN delegation provides a\n   guarantee\
    \ that no open, and thus no READ or WRITE, has been done by\n   another client.\n\
    \   For the purposes of OPEN delegation, READs and WRITEs done without an\n  \
    \ OPEN are treated as the functional equivalents of a corresponding\n   type of\
    \ OPEN.  Although a client SHOULD NOT use special stateids when\n   an open exists,\
    \ delegation handling on the server can use the client\n   ID associated with\
    \ the current session to determine if the operation\n   has been done by the holder\
    \ of the delegation (in which case, no\n   recall is necessary) or by another\
    \ client (in which case, the\n   delegation must be recalled and I/O not proceed\
    \ until the delegation\n   is returned or revoked).\n   With delegations, a client\
    \ is able to avoid writing data to the\n   server when the CLOSE of a file is\
    \ serviced.  The file close system\n   call is the usual point at which the client\
    \ is notified of a lack of\n   stable storage for the modified file data generated\
    \ by the\n   application.  At the close, file data is written to the server and,\n\
    \   through normal accounting, the server is able to determine if the\n   available\
    \ file system space for the data has been exceeded (i.e., the\n   server returns\
    \ NFS4ERR_NOSPC or NFS4ERR_DQUOT).  This accounting\n   includes quotas.  The\
    \ introduction of delegations requires that an\n   alternative method be in place\
    \ for the same type of communication to\n   occur between client and server.\n\
    \   In the delegation response, the server provides either the limit of\n   the\
    \ size of the file or the number of modified blocks and associated\n   block size.\
    \  The server must ensure that the client will be able to\n   write modified data\
    \ to the server of a size equal to that provided in\n   the original delegation.\
    \  The server must make this assurance for all\n   outstanding delegations.  Therefore,\
    \ the server must be careful in\n   its management of available space for new\
    \ or modified data, taking\n   into account available file system space and any\
    \ applicable quotas.\n   The server can recall delegations as a result of managing\
    \ the\n   available file system space.  The client should abide by the server's\n\
    \   state space limits for delegations.  If the client exceeds the stated\n  \
    \ limits for the delegation, the server's behavior is undefined.\n   Based on\
    \ server conditions, quotas, or available file system space,\n   the server may\
    \ grant OPEN_DELEGATE_WRITE delegations with very\n   restrictive space limitations.\
    \  The limitations may be defined in a\n   way that will always force modified\
    \ data to be flushed to the server\n   on close.\n   With respect to authentication,\
    \ flushing modified data to the server\n   after a CLOSE has occurred may be problematic.\
    \  For example, the user\n   of the application may have logged off the client,\
    \ and unexpired\n   authentication credentials may not be present.  In this case,\
    \ the\n   client may need to take special care to ensure that local unexpired\n\
    \   credentials will in fact be available.  This may be accomplished by\n   tracking\
    \ the expiration time of credentials and flushing data well in\n   advance of\
    \ their expiration or by making private copies of\n   credentials to assure their\
    \ availability when needed.\n"
- title: 10.4.2.  Open Delegation and File Locks
  contents:
  - "10.4.2.  Open Delegation and File Locks\n   When a client holds an OPEN_DELEGATE_WRITE\
    \ delegation, lock\n   operations are performed locally.  This includes those\
    \ required for\n   mandatory byte-range locking.  This can be done since the delegation\n\
    \   implies that there can be no conflicting locks.  Similarly, all of\n   the\
    \ revalidations that would normally be associated with obtaining\n   locks and\
    \ the flushing of data associated with the releasing of locks\n   need not be\
    \ done.\n   When a client holds an OPEN_DELEGATE_READ delegation, lock operations\n\
    \   are not performed locally.  All lock operations, including those\n   requesting\
    \ non-exclusive locks, are sent to the server for\n   resolution.\n"
- title: 10.4.3.  Handling of CB_GETATTR
  contents:
  - "10.4.3.  Handling of CB_GETATTR\n   The server needs to employ special handling\
    \ for a GETATTR where the\n   target is a file that has an OPEN_DELEGATE_WRITE\
    \ delegation in\n   effect.  The reason for this is that the client holding the\n\
    \   OPEN_DELEGATE_WRITE delegation may have modified the data, and the\n   server\
    \ needs to reflect this change to the second client that\n   submitted the GETATTR.\
    \  Therefore, the client holding the\n   OPEN_DELEGATE_WRITE delegation needs\
    \ to be interrogated.  The server\n   will use the CB_GETATTR operation.  The\
    \ only attributes that the\n   server can reliably query via CB_GETATTR are size\
    \ and change.\n   Since CB_GETATTR is being used to satisfy another client's GETATTR\n\
    \   request, the server only needs to know if the client holding the\n   delegation\
    \ has a modified version of the file.  If the client's copy\n   of the delegated\
    \ file is not modified (data or size), the server can\n   satisfy the second client's\
    \ GETATTR request from the attributes\n   stored locally at the server.  If the\
    \ file is modified, the server\n   only needs to know about this modified state.\
    \  If the server\n   determines that the file is currently modified, it will respond\
    \ to\n   the second client's GETATTR as if the file had been modified locally\n\
    \   at the server.\n   Since the form of the change attribute is determined by\
    \ the server\n   and is opaque to the client, the client and server need to agree\
    \ on a\n   method of communicating the modified state of the file.  For the size\n\
    \   attribute, the client will report its current view of the file size.\n   For\
    \ the change attribute, the handling is more involved.\n   For the client, the\
    \ following steps will be taken when receiving an\n   OPEN_DELEGATE_WRITE delegation:\n\
    \   *  The value of the change attribute will be obtained from the server\n  \
    \    and cached.  Let this value be represented by c.\n   *  The client will create\
    \ a value greater than c that will be used\n      for communicating that modified\
    \ data is held at the client.  Let\n      this value be represented by d.\n  \
    \ *  When the client is queried via CB_GETATTR for the change\n      attribute,\
    \ it checks to see if it holds modified data.  If the\n      file is modified,\
    \ the value d is returned for the change attribute\n      value.  If this file\
    \ is not currently modified, the client returns\n      the value c for the change\
    \ attribute.\n   For simplicity of implementation, the client MAY for each CB_GETATTR\n\
    \   return the same value d.  This is true even if, between successive\n   CB_GETATTR\
    \ operations, the client again modifies the file's data or\n   metadata in its\
    \ cache.  The client can return the same value because\n   the only requirement\
    \ is that the client be able to indicate to the\n   server that the client holds\
    \ modified data.  Therefore, the value of\n   d may always be c + 1.\n   While\
    \ the change attribute is opaque to the client in the sense that\n   it has no\
    \ idea what units of time, if any, the server is counting\n   change with, it\
    \ is not opaque in that the client has to treat it as\n   an unsigned integer,\
    \ and the server has to be able to see the results\n   of the client's changes\
    \ to that integer.  Therefore, the server MUST\n   encode the change attribute\
    \ in network order when sending it to the\n   client.  The client MUST decode\
    \ it from network order to its native\n   order when receiving it, and the client\
    \ MUST encode it in network\n   order when sending it to the server.  For this\
    \ reason, change is\n   defined as an unsigned integer rather than an opaque array\
    \ of bytes.\n   For the server, the following steps will be taken when providing\
    \ an\n   OPEN_DELEGATE_WRITE delegation:\n   *  Upon providing an OPEN_DELEGATE_WRITE\
    \ delegation, the server will\n      cache a copy of the change attribute in the\
    \ data structure it uses\n      to record the delegation.  Let this value be represented\
    \ by sc.\n   *  When a second client sends a GETATTR operation on the same file\
    \ to\n      the server, the server obtains the change attribute from the first\n\
    \      client.  Let this value be cc.\n   *  If the value cc is equal to sc, the\
    \ file is not modified and the\n      server returns the current values for change,\
    \ time_metadata, and\n      time_modify (for example) to the second client.\n\
    \   *  If the value cc is NOT equal to sc, the file is currently modified\n  \
    \    at the first client and most likely will be modified at the server\n    \
    \  at a future time.  The server then uses its current time to\n      construct\
    \ attribute values for time_metadata and time_modify.  A\n      new value of sc,\
    \ which we will call nsc, is computed by the\n      server, such that nsc >= sc\
    \ + 1.  The server then returns the\n      constructed time_metadata, time_modify,\
    \ and nsc values to the\n      requester.  The server replaces sc in the delegation\
    \ record with\n      nsc.  To prevent the possibility of time_modify, time_metadata,\n\
    \      and change from appearing to go backward (which would happen if\n     \
    \ the client holding the delegation fails to write its modified data\n      to\
    \ the server before the delegation is revoked or returned), the\n      server\
    \ SHOULD update the file's metadata record with the\n      constructed attribute\
    \ values.  For reasons of reasonable\n      performance, committing the constructed\
    \ attribute values to stable\n      storage is OPTIONAL.\n   As discussed earlier\
    \ in this section, the client MAY return the same\n   cc value on subsequent CB_GETATTR\
    \ calls, even if the file was\n   modified in the client's cache yet again between\
    \ successive\n   CB_GETATTR calls.  Therefore, the server must assume that the\
    \ file\n   has been modified yet again, and MUST take care to ensure that the\n\
    \   new nsc it constructs and returns is greater than the previous nsc it\n  \
    \ returned.  An example implementation's delegation record would\n   satisfy this\
    \ mandate by including a boolean field (let us call it\n   \"modified\") that\
    \ is set to FALSE when the delegation is granted, and\n   an sc value set at the\
    \ time of grant to the change attribute value.\n   The modified field would be\
    \ set to TRUE the first time cc != sc, and\n   would stay TRUE until the delegation\
    \ is returned or revoked.  The\n   processing for constructing nsc, time_modify,\
    \ and time_metadata would\n   use this pseudo code:\n       if (!modified) {\n\
    \           do CB_GETATTR for change and size;\n           if (cc != sc)\n   \
    \            modified = TRUE;\n       } else {\n           do CB_GETATTR for size;\n\
    \       }\n       if (modified) {\n           sc = sc + 1;\n           time_modify\
    \ = time_metadata = current_time;\n           update sc, time_modify, time_metadata\
    \ into file's metadata;\n       }\n   This would return to the client (that sent\
    \ GETATTR) the attributes it\n   requested, but make sure size comes from what\
    \ CB_GETATTR returned.\n   The server would not update the file's metadata with\
    \ the client's\n   modified size.\n   In the case that the file attribute size\
    \ is different than the\n   server's current value, the server treats this as\
    \ a modification\n   regardless of the value of the change attribute retrieved\
    \ via\n   CB_GETATTR and responds to the second client as in the last step.\n\
    \   This methodology resolves issues of clock differences between client\n   and\
    \ server and other scenarios where the use of CB_GETATTR break\n   down.\n   It\
    \ should be noted that the server is under no obligation to use\n   CB_GETATTR,\
    \ and therefore the server MAY simply recall the delegation\n   to avoid its use.\n"
- title: 10.4.4.  Recall of Open Delegation
  contents:
  - "10.4.4.  Recall of Open Delegation\n   The following events necessitate recall\
    \ of an OPEN delegation:\n   *  potentially conflicting OPEN request (or a READ\
    \ or WRITE operation\n      done with a special stateid)\n   *  SETATTR sent by\
    \ another client\n   *  REMOVE request for the file\n   *  RENAME request for\
    \ the file as either the source or target of the\n      RENAME\n   Whether a RENAME\
    \ of a directory in the path leading to the file\n   results in recall of an OPEN\
    \ delegation depends on the semantics of\n   the server's file system.  If that\
    \ file system denies such RENAMEs\n   when a file is open, the recall must be\
    \ performed to determine\n   whether the file in question is, in fact, open.\n\
    \   In addition to the situations above, the server may choose to recall\n   OPEN\
    \ delegations at any time if resource constraints make it\n   advisable to do\
    \ so.  Clients should always be prepared for the\n   possibility of recall.\n\
    \   When a client receives a recall for an OPEN delegation, it needs to\n   update\
    \ state on the server before returning the delegation.  These\n   same updates\
    \ must be done whenever a client chooses to return a\n   delegation voluntarily.\
    \  The following items of state need to be\n   dealt with:\n   *  If the file\
    \ associated with the delegation is no longer open and\n      no previous CLOSE\
    \ operation has been sent to the server, a CLOSE\n      operation must be sent\
    \ to the server.\n   *  If a file has other open references at the client, then\
    \ OPEN\n      operations must be sent to the server.  The appropriate stateids\n\
    \      will be provided by the server for subsequent use by the client\n     \
    \ since the delegation stateid will no longer be valid.  These OPEN\n      requests\
    \ are done with the claim type of CLAIM_DELEGATE_CUR.  This\n      will allow\
    \ the presentation of the delegation stateid so that the\n      client can establish\
    \ the appropriate rights to perform the OPEN.\n      (See Section 18.16, which\
    \ describes the OPEN operation, for\n      details.)\n   *  If there are granted\
    \ byte-range locks, the corresponding LOCK\n      operations need to be performed.\
    \  This applies to the\n      OPEN_DELEGATE_WRITE delegation case only.\n   *\
    \  For an OPEN_DELEGATE_WRITE delegation, if at the time of recall\n      the\
    \ file is not open for OPEN4_SHARE_ACCESS_WRITE/\n      OPEN4_SHARE_ACCESS_BOTH,\
    \ all modified data for the file must be\n      flushed to the server.  If the\
    \ delegation had not existed, the\n      client would have done this data flush\
    \ before the CLOSE operation.\n   *  For an OPEN_DELEGATE_WRITE delegation when\
    \ a file is still open at\n      the time of recall, any modified data for the\
    \ file needs to be\n      flushed to the server.\n   *  With the OPEN_DELEGATE_WRITE\
    \ delegation in place, it is possible\n      that the file was truncated during\
    \ the duration of the delegation.\n      For example, the truncation could have\
    \ occurred as a result of an\n      OPEN UNCHECKED with a size attribute value\
    \ of zero.  Therefore, if\n      a truncation of the file has occurred and this\
    \ operation has not\n      been propagated to the server, the truncation must\
    \ occur before\n      any modified data is written to the server.\n   In the case\
    \ of OPEN_DELEGATE_WRITE delegation, byte-range locking\n   imposes some additional\
    \ requirements.  To precisely maintain the\n   associated invariant, it is required\
    \ to flush any modified data in\n   any byte-range for which a WRITE_LT lock was\
    \ released while the\n   OPEN_DELEGATE_WRITE delegation was in effect.  However,\
    \ because the\n   OPEN_DELEGATE_WRITE delegation implies no other locking by other\n\
    \   clients, a simpler implementation is to flush all modified data for\n   the\
    \ file (as described just above) if any WRITE_LT lock has been\n   released while\
    \ the OPEN_DELEGATE_WRITE delegation was in effect.\n   An implementation need\
    \ not wait until delegation recall (or the\n   decision to voluntarily return\
    \ a delegation) to perform any of the\n   above actions, if implementation considerations\
    \ (e.g., resource\n   availability constraints) make that desirable.  Generally,\
    \ however,\n   the fact that the actual OPEN state of the file may continue to\n\
    \   change makes it not worthwhile to send information about opens and\n   closes\
    \ to the server, except as part of delegation return.  An\n   exception is when\
    \ the client has no more internal opens of the file.\n   In this case, sending\
    \ a CLOSE is useful because it reduces resource\n   utilization on the client\
    \ and server.  Regardless of the client's\n   choices on scheduling these actions,\
    \ all must be performed before the\n   delegation is returned, including (when\
    \ applicable) the close that\n   corresponds to the OPEN that resulted in the\
    \ delegation.  These\n   actions can be performed either in previous requests\
    \ or in previous\n   operations in the same COMPOUND request.\n"
- title: 10.4.5.  Clients That Fail to Honor Delegation Recalls
  contents:
  - "10.4.5.  Clients That Fail to Honor Delegation Recalls\n   A client may fail\
    \ to respond to a recall for various reasons, such as\n   a failure of the backchannel\
    \ from server to the client.  The client\n   may be unaware of a failure in the\
    \ backchannel.  This lack of\n   awareness could result in the client finding\
    \ out long after the\n   failure that its delegation has been revoked, and another\
    \ client has\n   modified the data for which the client had a delegation.  This\
    \ is\n   especially a problem for the client that held an OPEN_DELEGATE_WRITE\n\
    \   delegation.\n   Status bits returned by SEQUENCE operations help to provide\
    \ an\n   alternate way of informing the client of issues regarding the status\n\
    \   of the backchannel and of recalled delegations.  When the backchannel\n  \
    \ is not available, the server returns the status bit\n   SEQ4_STATUS_CB_PATH_DOWN\
    \ on SEQUENCE operations.  The client can\n   react by attempting to re-establish\
    \ the backchannel and by returning\n   recallable objects if a backchannel cannot\
    \ be successfully re-\n   established.\n   Whether the backchannel is functioning\
    \ or not, it may be that the\n   recalled delegation is not returned.  Note that\
    \ the client's lease\n   might still be renewed, even though the recalled delegation\
    \ is not\n   returned.  In this situation, servers SHOULD revoke delegations that\n\
    \   are not returned in a period of time equal to the lease period.  This\n  \
    \ period of time should allow the client time to note the backchannel-\n   down\
    \ status and re-establish the backchannel.\n   When delegations are revoked, the\
    \ server will return with the\n   SEQ4_STATUS_RECALLABLE_STATE_REVOKED status\
    \ bit set on subsequent\n   SEQUENCE operations.  The client should note this\
    \ and then use\n   TEST_STATEID to find which delegations have been revoked.\n"
- title: 10.4.6.  Delegation Revocation
  contents:
  - "10.4.6.  Delegation Revocation\n   At the point a delegation is revoked, if there\
    \ are associated opens\n   on the client, these opens may or may not be revoked.\
    \  If no byte-\n   range lock or open is granted that is inconsistent with the\
    \ existing\n   open, the stateid for the open may remain valid and be disconnected\n\
    \   from the revoked delegation, just as would be the case if the\n   delegation\
    \ were returned.\n   For example, if an OPEN for OPEN4_SHARE_ACCESS_BOTH with\
    \ a deny of\n   OPEN4_SHARE_DENY_NONE is associated with the delegation, granting\
    \ of\n   another such OPEN to a different client will revoke the delegation\n\
    \   but need not revoke the OPEN, since the two OPENs are consistent with\n  \
    \ each other.  On the other hand, if an OPEN denying write access is\n   granted,\
    \ then the existing OPEN must be revoked.\n   When opens and/or locks are revoked,\
    \ the applications holding these\n   opens or locks need to be notified.  This\
    \ notification usually occurs\n   by returning errors for READ/WRITE operations\
    \ or when a close is\n   attempted for the open file.\n   If no opens exist for\
    \ the file at the point the delegation is\n   revoked, then notification of the\
    \ revocation is unnecessary.\n   However, if there is modified data present at\
    \ the client for the\n   file, the user of the application should be notified.\
    \  Unfortunately,\n   it may not be possible to notify the user since active applications\n\
    \   may not be present at the client.  See Section 10.5.1 for additional\n   details.\n"
- title: 10.4.7.  Delegations via WANT_DELEGATION
  contents:
  - "10.4.7.  Delegations via WANT_DELEGATION\n   In addition to providing delegations\
    \ as part of the reply to OPEN\n   operations, servers MAY provide delegations\
    \ separate from open, via\n   the OPTIONAL WANT_DELEGATION operation.  This allows\
    \ delegations to\n   be obtained in advance of an OPEN that might benefit from\
    \ them, for\n   objects that are not a valid target of OPEN, or to deal with cases\
    \ in\n   which a delegation has been recalled and the client wants to make an\n\
    \   attempt to re-establish it if the absence of use by other clients\n   allows\
    \ that.\n   The WANT_DELEGATION operation may be performed on any type of file\n\
    \   object other than a directory.\n   When a delegation is obtained using WANT_DELEGATION,\
    \ any open files\n   for the same filehandle held by that client are to be treated\
    \ as\n   subordinate to the delegation, just as if they had been created using\n\
    \   an OPEN of type CLAIM_DELEGATE_CUR.  They are otherwise unchanged as\n   to\
    \ seqid, access and deny modes, and the relationship with byte-range\n   locks.\
    \  Similarly, because existing byte-range locks are subordinate\n   to an open,\
    \ those byte-range locks also become indirectly subordinate\n   to that new delegation.\n\
    \   The WANT_DELEGATION operation provides for delivery of delegations\n   via\
    \ callbacks, when the delegations are not immediately available.\n   When a requested\
    \ delegation is available, it is delivered to the\n   client via a CB_PUSH_DELEG\
    \ operation.  When this happens, open files\n   for the same filehandle become\
    \ subordinate to the new delegation at\n   the point at which the delegation is\
    \ delivered, just as if they had\n   been created using an OPEN of type CLAIM_DELEGATE_CUR.\
    \  Similarly,\n   this occurs for existing byte-range locks subordinate to an\
    \ open.\n"
- title: 10.5.  Data Caching and Revocation
  contents:
  - "10.5.  Data Caching and Revocation\n   When locks and delegations are revoked,\
    \ the assumptions upon which\n   successful caching depends are no longer guaranteed.\
    \  For any locks\n   or share reservations that have been revoked, the corresponding\n\
    \   state-owner needs to be notified.  This notification includes\n   applications\
    \ with a file open that has a corresponding delegation\n   that has been revoked.\
    \  Cached data associated with the revocation\n   must be removed from the client.\
    \  In the case of modified data\n   existing in the client's cache, that data\
    \ must be removed from the\n   client without being written to the server.  As\
    \ mentioned, the\n   assumptions made by the client are no longer valid at the\
    \ point when\n   a lock or delegation has been revoked.  For example, another\
    \ client\n   may have been granted a conflicting byte-range lock after the\n \
    \  revocation of the byte-range lock at the first client.  Therefore,\n   the\
    \ data within the lock range may have been modified by the other\n   client. \
    \ Obviously, the first client is unable to guarantee to the\n   application what\
    \ has occurred to the file in the case of revocation.\n   Notification to a state-owner\
    \ will in many cases consist of simply\n   returning an error on the next and\
    \ all subsequent READs/WRITEs to the\n   open file or on the close.  Where the\
    \ methods available to a client\n   make such notification impossible because\
    \ errors for certain\n   operations may not be returned, more drastic action such\
    \ as signals\n   or process termination may be appropriate.  The justification\
    \ here is\n   that an invariant on which an application depends may be violated.\n\
    \   Depending on how errors are typically treated for the client-\n   operating\
    \ environment, further levels of notification including\n   logging, console messages,\
    \ and GUI pop-ups may be appropriate.\n"
- title: 10.5.1.  Revocation Recovery for Write Open Delegation
  contents:
  - "10.5.1.  Revocation Recovery for Write Open Delegation\n   Revocation recovery\
    \ for an OPEN_DELEGATE_WRITE delegation poses the\n   special issue of modified\
    \ data in the client cache while the file is\n   not open.  In this situation,\
    \ any client that does not flush modified\n   data to the server on each close\
    \ must ensure that the user receives\n   appropriate notification of the failure\
    \ as a result of the\n   revocation.  Since such situations may require human\
    \ action to\n   correct problems, notification schemes in which the appropriate\
    \ user\n   or administrator is notified may be necessary.  Logging and console\n\
    \   messages are typical examples.\n   If there is modified data on the client,\
    \ it must not be flushed\n   normally to the server.  A client may attempt to\
    \ provide a copy of\n   the file data as modified during the delegation under\
    \ a different\n   name in the file system namespace to ease recovery.  Note that\
    \ when\n   the client can determine that the file has not been modified by any\n\
    \   other client, or when the client has a complete cached copy of the\n   file\
    \ in question, such a saved copy of the client's view of the file\n   may be of\
    \ particular value for recovery.  In another case, recovery\n   using a copy of\
    \ the file based partially on the client's cached data\n   and partially on the\
    \ server's copy as modified by other clients will\n   be anything but straightforward,\
    \ so clients may avoid saving file\n   contents in these situations or specially\
    \ mark the results to warn\n   users of possible problems.\n   Saving of such\
    \ modified data in delegation revocation situations may\n   be limited to files\
    \ of a certain size or might be used only when\n   sufficient disk space is available\
    \ within the target file system.\n   Such saving may also be restricted to situations\
    \ when the client has\n   sufficient buffering resources to keep the cached copy\
    \ available\n   until it is properly stored to the target file system.\n"
- title: 10.6.  Attribute Caching
  contents:
  - "10.6.  Attribute Caching\n   This section pertains to the caching of a file's\
    \ attributes on a\n   client when that client does not hold a delegation on the\
    \ file.\n   The attributes discussed in this section do not include named\n  \
    \ attributes.  Individual named attributes are analogous to files, and\n   caching\
    \ of the data for these needs to be handled just as data\n   caching is for ordinary\
    \ files.  Similarly, LOOKUP results from an\n   OPENATTR directory (as well as\
    \ the directory's contents) are to be\n   cached on the same basis as any other\
    \ pathnames.\n   Clients may cache file attributes obtained from the server and\
    \ use\n   them to avoid subsequent GETATTR requests.  Such caching is write\n\
    \   through in that modification to file attributes is always done by\n   means\
    \ of requests to the server and should not be done locally and\n   should not\
    \ be cached.  The exception to this are modifications to\n   attributes that are\
    \ intimately connected with data caching.\n   Therefore, extending a file by writing\
    \ data to the local data cache\n   is reflected immediately in the size as seen\
    \ on the client without\n   this change being immediately reflected on the server.\
    \  Normally,\n   such changes are not propagated directly to the server, but when\
    \ the\n   modified data is flushed to the server, analogous attribute changes\n\
    \   are made on the server.  When OPEN delegation is in effect, the\n   modified\
    \ attributes may be returned to the server in reaction to a\n   CB_RECALL call.\n\
    \   The result of local caching of attributes is that the attribute\n   caches\
    \ maintained on individual clients will not be coherent.\n   Changes made in one\
    \ order on the server may be seen in a different\n   order on one client and in\
    \ a third order on another client.\n   The typical file system application programming\
    \ interfaces do not\n   provide means to atomically modify or interrogate attributes\
    \ for\n   multiple files at the same time.  The following rules provide an\n \
    \  environment where the potential incoherencies mentioned above can be\n   reasonably\
    \ managed.  These rules are derived from the practice of\n   previous NFS protocols.\n\
    \   *  All attributes for a given file (per-fsid attributes excepted) are\n  \
    \    cached as a unit at the client so that no non-serializability can\n     \
    \ arise within the context of a single file.\n   *  An upper time boundary is\
    \ maintained on how long a client cache\n      entry can be kept without being\
    \ refreshed from the server.\n   *  When operations are performed that change\
    \ attributes at the\n      server, the updated attribute set is requested as part\
    \ of the\n      containing RPC.  This includes directory operations that update\n\
    \      attributes indirectly.  This is accomplished by following the\n      modifying\
    \ operation with a GETATTR operation and then using the\n      results of the\
    \ GETATTR to update the client's cached attributes.\n   Note that if the full\
    \ set of attributes to be cached is requested by\n   READDIR, the results can\
    \ be cached by the client on the same basis as\n   attributes obtained via GETATTR.\n\
    \   A client may validate its cached version of attributes for a file by\n   fetching\
    \ both the change and time_access attributes and assuming that\n   if the change\
    \ attribute has the same value as it did when the\n   attributes were cached,\
    \ then no attributes other than time_access\n   have changed.  The reason why\
    \ time_access is also fetched is because\n   many servers operate in environments\
    \ where the operation that updates\n   change does not update time_access.  For\
    \ example, POSIX file\n   semantics do not update access time when a file is modified\
    \ by the\n   write system call [15].  Therefore, the client that wants a current\n\
    \   time_access value should fetch it with change during the attribute\n   cache\
    \ validation processing and update its cached time_access.\n   The client may\
    \ maintain a cache of modified attributes for those\n   attributes intimately\
    \ connected with data of modified regular files\n   (size, time_modify, and change).\
    \  Other than those three attributes,\n   the client MUST NOT maintain a cache\
    \ of modified attributes.\n   Instead, attribute changes are immediately sent\
    \ to the server.\n   In some operating environments, the equivalent to time_access\
    \ is\n   expected to be implicitly updated by each read of the content of the\n\
    \   file object.  If an NFS client is caching the content of a file\n   object,\
    \ whether it is a regular file, directory, or symbolic link,\n   the client SHOULD\
    \ NOT update the time_access attribute (via SETATTR\n   or a small READ or READDIR\
    \ request) on the server with each read that\n   is satisfied from cache.  The\
    \ reason is that this can defeat the\n   performance benefits of caching content,\
    \ especially since an explicit\n   SETATTR of time_access may alter the change\
    \ attribute on the server.\n   If the change attribute changes, clients that are\
    \ caching the content\n   will think the content has changed, and will re-read\
    \ unmodified data\n   from the server.  Nor is the client encouraged to maintain\
    \ a modified\n   version of time_access in its cache, since the client either\
    \ would\n   eventually have to write the access time to the server with bad\n\
    \   performance effects or never update the server's time_access, thereby\n  \
    \ resulting in a situation where an application that caches access time\n   between\
    \ a close and open of the same file observes the access time\n   oscillating between\
    \ the past and present.  The time_access attribute\n   always means the time of\
    \ last access to a file by a read that was\n   satisfied by the server.  This\
    \ way clients will tend to see only\n   time_access changes that go forward in\
    \ time.\n"
- title: 10.7.  Data and Metadata Caching and Memory Mapped Files
  contents:
  - "10.7.  Data and Metadata Caching and Memory Mapped Files\n   Some operating environments\
    \ include the capability for an application\n   to map a file's content into the\
    \ application's address space.  Each\n   time the application accesses a memory\
    \ location that corresponds to a\n   block that has not been loaded into the address\
    \ space, a page fault\n   occurs and the file is read (or if the block does not\
    \ exist in the\n   file, the block is allocated and then instantiated in the\n\
    \   application's address space).\n   As long as each memory-mapped access to\
    \ the file requires a page\n   fault, the relevant attributes of the file that\
    \ are used to detect\n   access and modification (time_access, time_metadata,\
    \ time_modify, and\n   change) will be updated.  However, in many operating environments,\n\
    \   when page faults are not required, these attributes will not be\n   updated\
    \ on reads or updates to the file via memory access (regardless\n   of whether\
    \ the file is local or is accessed remotely).  A client or\n   server MAY fail\
    \ to update attributes of a file that is being accessed\n   via memory-mapped\
    \ I/O.  This has several implications:\n   *  If there is an application on the\
    \ server that has memory mapped a\n      file that a client is also accessing,\
    \ the client may not be able\n      to get a consistent value of the change attribute\
    \ to determine\n      whether or not its cache is stale.  A server that knows\
    \ that the\n      file is memory-mapped could always pessimistically return updated\n\
    \      values for change so as to force the application to always get the\n  \
    \    most up-to-date data and metadata for the file.  However, due to\n      the\
    \ negative performance implications of this, such behavior is\n      OPTIONAL.\n\
    \   *  If the memory-mapped file is not being modified on the server, and\n  \
    \    instead is just being read by an application via the memory-mapped\n    \
    \  interface, the client will not see an updated time_access\n      attribute.\
    \  However, in many operating environments, neither will\n      any process running\
    \ on the server.  Thus, NFS clients are at no\n      disadvantage with respect\
    \ to local processes.\n   *  If there is another client that is memory mapping\
    \ the file, and if\n      that client is holding an OPEN_DELEGATE_WRITE delegation,\
    \ the same\n      set of issues as discussed in the previous two bullet points\n\
    \      apply.  So, when a server does a CB_GETATTR to a file that the\n      client\
    \ has modified in its cache, the reply from CB_GETATTR will\n      not necessarily\
    \ be accurate.  As discussed earlier, the client's\n      obligation is to report\
    \ that the file has been modified since the\n      delegation was granted, not\
    \ whether it has been modified again\n      between successive CB_GETATTR calls,\
    \ and the server MUST assume\n      that any file the client has modified in cache\
    \ has been modified\n      again between successive CB_GETATTR calls.  Depending\
    \ on the\n      nature of the client's memory management system, this weak\n \
    \     obligation may not be possible.  A client MAY return stale\n      information\
    \ in CB_GETATTR whenever the file is memory-mapped.\n   *  The mixture of memory\
    \ mapping and byte-range locking on the same\n      file is problematic.  Consider\
    \ the following scenario, where a\n      page size on each client is 8192 bytes.\n\
    \      -  Client A memory maps the first page (8192 bytes) of file X.\n      -\
    \  Client B memory maps the first page (8192 bytes) of file X.\n      -  Client\
    \ A WRITE_LT locks the first 4096 bytes.\n      -  Client B WRITE_LT locks the\
    \ second 4096 bytes.\n      -  Client A, via a STORE instruction, modifies part\
    \ of its locked\n         byte-range.\n      -  Simultaneous to client A, client\
    \ B executes a STORE on part of\n         its locked byte-range.\n   Here the\
    \ challenge is for each client to resynchronize to get a\n   correct view of the\
    \ first page.  In many operating environments, the\n   virtual memory management\
    \ systems on each client only know a page is\n   modified, not that a subset of\
    \ the page corresponding to the\n   respective lock byte-ranges has been modified.\
    \  So it is not possible\n   for each client to do the right thing, which is to\
    \ write to the\n   server only that portion of the page that is locked.  For example,\
    \ if\n   client A simply writes out the page, and then client B writes out the\n\
    \   page, client A's data is lost.\n   Moreover, if mandatory locking is enabled\
    \ on the file, then we have a\n   different problem.  When clients A and B execute\
    \ the STORE\n   instructions, the resulting page faults require a byte-range lock\
    \ on\n   the entire page.  Each client then tries to extend their locked range\n\
    \   to the entire page, which results in a deadlock.  Communicating the\n   NFS4ERR_DEADLOCK\
    \ error to a STORE instruction is difficult at best.\n   If a client is locking\
    \ the entire memory-mapped file, there is no\n   problem with advisory or mandatory\
    \ byte-range locking, at least until\n   the client unlocks a byte-range in the\
    \ middle of the file.\n   Given the above issues, the following are permitted:\n\
    \   *  Clients and servers MAY deny memory mapping a file for which they\n   \
    \   know there are byte-range locks.\n   *  Clients and servers MAY deny a byte-range\
    \ lock on a file they know\n      is memory-mapped.\n   *  A client MAY deny memory\
    \ mapping a file that it knows requires\n      mandatory locking for I/O.  If\
    \ mandatory locking is enabled after\n      the file is opened and mapped, the\
    \ client MAY deny the application\n      further access to its mapped file.\n"
- title: 10.8.  Name and Directory Caching without Directory Delegations
  contents:
  - "10.8.  Name and Directory Caching without Directory Delegations\n   The NFSv4.1\
    \ directory delegation facility (described in Section 10.9\n   below) is OPTIONAL\
    \ for servers to implement.  Even where it is\n   implemented, it may not always\
    \ be functional because of resource\n   availability issues or other constraints.\
    \  Thus, it is important to\n   understand how name and directory caching are\
    \ done in the absence of\n   directory delegations.  These topics are discussed\
    \ in the next two\n   subsections.\n"
- title: 10.8.1.  Name Caching
  contents:
  - "10.8.1.  Name Caching\n   The results of LOOKUP and READDIR operations may be\
    \ cached to avoid\n   the cost of subsequent LOOKUP operations.  Just as in the\
    \ case of\n   attribute caching, inconsistencies may arise among the various client\n\
    \   caches.  To mitigate the effects of these inconsistencies and given\n   the\
    \ context of typical file system APIs, an upper time boundary is\n   maintained\
    \ for how long a client name cache entry can be kept without\n   verifying that\
    \ the entry has not been made invalid by a directory\n   change operation performed\
    \ by another client.\n   When a client is not making changes to a directory for\
    \ which there\n   exist name cache entries, the client needs to periodically fetch\n\
    \   attributes for that directory to ensure that it is not being\n   modified.\
    \  After determining that no modification has occurred, the\n   expiration time\
    \ for the associated name cache entries may be updated\n   to be the current time\
    \ plus the name cache staleness bound.\n   When a client is making changes to\
    \ a given directory, it needs to\n   determine whether there have been changes\
    \ made to the directory by\n   other clients.  It does this by using the change\
    \ attribute as\n   reported before and after the directory operation in the associated\n\
    \   change_info4 value returned for the operation.  The server is able to\n  \
    \ communicate to the client whether the change_info4 data is provided\n   atomically\
    \ with respect to the directory operation.  If the change\n   values are provided\
    \ atomically, the client has a basis for\n   determining, given proper care, whether\
    \ other clients are modifying\n   the directory in question.\n   The simplest\
    \ way to enable the client to make this determination is\n   for the client to\
    \ serialize all changes made to a specific directory.\n   When this is done, and\
    \ the server provides before and after values of\n   the change attribute atomically,\
    \ the client can simply compare the\n   after value of the change attribute from\
    \ one operation on a directory\n   with the before value on the subsequent operation\
    \ modifying that\n   directory.  When these are equal, the client is assured that\
    \ no other\n   client is modifying the directory in question.\n   When such serialization\
    \ is not used, and there may be multiple\n   simultaneous outstanding operations\
    \ modifying a single directory sent\n   from a single client, making this sort\
    \ of determination can be more\n   complicated.  If two such operations complete\
    \ in a different order\n   than they were actually performed, that might give\
    \ an appearance\n   consistent with modification being made by another client.\
    \  Where\n   this appears to happen, the client needs to await the completion\
    \ of\n   all such modifications that were started previously, to see if the\n\
    \   outstanding before and after change numbers can be sorted into a\n   chain\
    \ such that the before value of one change number matches the\n   after value\
    \ of a previous one, in a chain consistent with this client\n   being the only\
    \ one modifying the directory.\n   In either of these cases, the client is able\
    \ to determine whether the\n   directory is being modified by another client.\
    \  If the comparison\n   indicates that the directory was updated by another client,\
    \ the name\n   cache associated with the modified directory is purged from the\n\
    \   client.  If the comparison indicates no modification, the name cache\n   can\
    \ be updated on the client to reflect the directory operation and\n   the associated\
    \ timeout can be extended.  The post-operation change\n   value needs to be saved\
    \ as the basis for future change_info4\n   comparisons.\n   As demonstrated by\
    \ the scenario above, name caching requires that the\n   client revalidate name\
    \ cache data by inspecting the change attribute\n   of a directory at the point\
    \ when the name cache item was cached.\n   This requires that the server update\
    \ the change attribute for\n   directories when the contents of the corresponding\
    \ directory is\n   modified.  For a client to use the change_info4 information\n\
    \   appropriately and correctly, the server must report the pre- and\n   post-operation\
    \ change attribute values atomically.  When the server\n   is unable to report\
    \ the before and after values atomically with\n   respect to the directory operation,\
    \ the server must indicate that\n   fact in the change_info4 return value.  When\
    \ the information is not\n   atomically reported, the client should not assume\
    \ that other clients\n   have not changed the directory.\n"
- title: 10.8.2.  Directory Caching
  contents:
  - "10.8.2.  Directory Caching\n   The results of READDIR operations may be used\
    \ to avoid subsequent\n   READDIR operations.  Just as in the cases of attribute\
    \ and name\n   caching, inconsistencies may arise among the various client caches.\n\
    \   To mitigate the effects of these inconsistencies, and given the\n   context\
    \ of typical file system APIs, the following rules should be\n   followed:\n \
    \  *  Cached READDIR information for a directory that is not obtained in\n   \
    \   a single READDIR operation must always be a consistent snapshot of\n     \
    \ directory contents.  This is determined by using a GETATTR before\n      the\
    \ first READDIR and after the last READDIR that contributes to\n      the cache.\n\
    \   *  An upper time boundary is maintained to indicate the length of\n      time\
    \ a directory cache entry is considered valid before the client\n      must revalidate\
    \ the cached information.\n   The revalidation technique parallels that discussed\
    \ in the case of\n   name caching.  When the client is not changing the directory\
    \ in\n   question, checking the change attribute of the directory with GETATTR\n\
    \   is adequate.  The lifetime of the cache entry can be extended at\n   these\
    \ checkpoints.  When a client is modifying the directory, the\n   client needs\
    \ to use the change_info4 data to determine whether there\n   are other clients\
    \ modifying the directory.  If it is determined that\n   no other client modifications\
    \ are occurring, the client may update\n   its directory cache to reflect its\
    \ own changes.\n   As demonstrated previously, directory caching requires that\
    \ the\n   client revalidate directory cache data by inspecting the change\n  \
    \ attribute of a directory at the point when the directory was cached.\n   This\
    \ requires that the server update the change attribute for\n   directories when\
    \ the contents of the corresponding directory is\n   modified.  For a client to\
    \ use the change_info4 information\n   appropriately and correctly, the server\
    \ must report the pre- and\n   post-operation change attribute values atomically.\
    \  When the server\n   is unable to report the before and after values atomically\
    \ with\n   respect to the directory operation, the server must indicate that\n\
    \   fact in the change_info4 return value.  When the information is not\n   atomically\
    \ reported, the client should not assume that other clients\n   have not changed\
    \ the directory.\n"
- title: 10.9.  Directory Delegations
  contents:
  - '10.9.  Directory Delegations

    '
- title: 10.9.1.  Introduction to Directory Delegations
  contents:
  - "10.9.1.  Introduction to Directory Delegations\n   Directory caching for the\
    \ NFSv4.1 protocol, as previously described,\n   is similar to file caching in\
    \ previous versions.  Clients typically\n   cache directory information for a\
    \ duration determined by the client.\n   At the end of a predefined timeout, the\
    \ client will query the server\n   to see if the directory has been updated. \
    \ By caching attributes,\n   clients reduce the number of GETATTR calls made to\
    \ the server to\n   validate attributes.  Furthermore, frequently accessed files\
    \ and\n   directories, such as the current working directory, have their\n   attributes\
    \ cached on the client so that some NFS operations can be\n   performed without\
    \ having to make an RPC call.  By caching name and\n   inode information about\
    \ most recently looked up entries in a\n   Directory Name Lookup Cache (DNLC),\
    \ clients do not need to send\n   LOOKUP calls to the server every time these\
    \ files are accessed.\n   This caching approach works reasonably well at reducing\
    \ network\n   traffic in many environments.  However, it does not address\n  \
    \ environments where there are numerous queries for files that do not\n   exist.\
    \  In these cases of \"misses\", the client sends requests to the\n   server in\
    \ order to provide reasonable application semantics and\n   promptly detect the\
    \ creation of new directory entries.  Examples of\n   high miss activity are compilation\
    \ in software development\n   environments.  The current behavior of NFS limits\
    \ its potential\n   scalability and wide-area sharing effectiveness in these types\
    \ of\n   environments.  Other distributed stateful file system architectures\n\
    \   such as AFS and DFS have proven that adding state around directory\n   contents\
    \ can greatly reduce network traffic in high-miss\n   environments.\n   Delegation\
    \ of directory contents is an OPTIONAL feature of NFSv4.1.\n   Directory delegations\
    \ provide similar traffic reduction benefits as\n   with file delegations.  By\
    \ allowing clients to cache directory\n   contents (in a read-only fashion) while\
    \ being notified of changes,\n   the client can avoid making frequent requests\
    \ to interrogate the\n   contents of slowly-changing directories, reducing network\
    \ traffic and\n   improving client performance.  It can also simplify the task\
    \ of\n   determining whether other clients are making changes to the directory\n\
    \   when the client itself is making many changes to the directory and\n   changes\
    \ are not serialized.\n   Directory delegations allow improved namespace cache\
    \ consistency to\n   be achieved through delegations and synchronous recalls,\
    \ in the\n   absence of notifications.  In addition, if time-based consistency\
    \ is\n   sufficient, asynchronous notifications can provide performance\n   benefits\
    \ for the client, and possibly the server, under some common\n   operating conditions\
    \ such as slowly-changing and/or very large\n   directories.\n"
- title: 10.9.2.  Directory Delegation Design
  contents:
  - "10.9.2.  Directory Delegation Design\n   NFSv4.1 introduces the GET_DIR_DELEGATION\
    \ (Section 18.39) operation\n   to allow the client to ask for a directory delegation.\
    \  The\n   delegation covers directory attributes and all entries in the\n   directory.\
    \  If either of these change, the delegation will be\n   recalled synchronously.\
    \  The operation causing the recall will have\n   to wait before the recall is\
    \ complete.  Any changes to directory\n   entry attributes will not cause the\
    \ delegation to be recalled.\n   In addition to asking for delegations, a client\
    \ can also ask for\n   notifications for certain events.  These events include\
    \ changes to\n   the directory's attributes and/or its contents.  If a client\
    \ asks for\n   notification for a certain event, the server will notify the client\n\
    \   when that event occurs.  This will not result in the delegation being\n  \
    \ recalled for that client.  The notifications are asynchronous and\n   provide\
    \ a way of avoiding recalls in situations where a directory is\n   changing enough\
    \ that the pure recall model may not be effective while\n   trying to allow the\
    \ client to get substantial benefit.  In the\n   absence of notifications, once\
    \ the delegation is recalled the client\n   has to refresh its directory cache;\
    \ this might not be very efficient\n   for very large directories.\n   The delegation\
    \ is read-only and the client may not make changes to\n   the directory other\
    \ than by performing NFSv4.1 operations that modify\n   the directory or the associated\
    \ file attributes so that the server\n   has knowledge of these changes.  In order\
    \ to keep the client's\n   namespace synchronized with that of the server, the\
    \ server will\n   notify the delegation-holding client (assuming it has requested\n\
    \   notifications) of the changes made as a result of that client's\n   directory-modifying\
    \ operations.  This is to avoid any need for that\n   client to send subsequent\
    \ GETATTR or READDIR operations to the\n   server.  If a single client is holding\
    \ the delegation and that client\n   makes any changes to the directory (i.e.,\
    \ the changes are made via\n   operations sent on a session associated with the\
    \ client ID holding\n   the delegation), the delegation will not be recalled.\
    \  Multiple\n   clients may hold a delegation on the same directory, but if any\
    \ such\n   client modifies the directory, the server MUST recall the delegation\n\
    \   from the other clients, unless those clients have made provisions to\n   be\
    \ notified of that sort of modification.\n   Delegations can be recalled by the\
    \ server at any time.  Normally, the\n   server will recall the delegation when\
    \ the directory changes in a way\n   that is not covered by the notification,\
    \ or when the directory\n   changes and notifications have not been requested.\
    \  If another client\n   removes the directory for which a delegation has been\
    \ granted, the\n   server will recall the delegation.\n"
- title: 10.9.3.  Attributes in Support of Directory Notifications
  contents:
  - "10.9.3.  Attributes in Support of Directory Notifications\n   See Section 5.11\
    \ for a description of the attributes associated with\n   directory notifications.\n"
- title: 10.9.4.  Directory Delegation Recall
  contents:
  - "10.9.4.  Directory Delegation Recall\n   The server will recall the directory\
    \ delegation by sending a callback\n   to the client.  It will use the same callback\
    \ procedure as used for\n   recalling file delegations.  The server will recall\
    \ the delegation\n   when the directory changes in a way that is not covered by\
    \ the\n   notification.  However, the server need not recall the delegation if\n\
    \   attributes of an entry within the directory change.\n   If the server notices\
    \ that handing out a delegation for a directory\n   is causing too many notifications\
    \ to be sent out, it may decide to\n   not hand out delegations for that directory\
    \ and/or recall those\n   already granted.  If a client tries to remove the directory\
    \ for which\n   a delegation has been granted, the server will recall all associated\n\
    \   delegations.\n   The implementation sections for a number of operations describe\n\
    \   situations in which notification or delegation recall would be\n   required\
    \ under some common circumstances.  In this regard, a similar\n   set of caveats\
    \ to those listed in Section 10.2 apply.\n   *  For CREATE, see Section 18.4.4.\n\
    \   *  For LINK, see Section 18.9.4.\n   *  For OPEN, see Section 18.16.4.\n \
    \  *  For REMOVE, see Section 18.25.4.\n   *  For RENAME, see Section 18.26.4.\n\
    \   *  For SETATTR, see Section 18.30.4.\n"
- title: 10.9.5.  Directory Delegation Recovery
  contents:
  - "10.9.5.  Directory Delegation Recovery\n   Recovery from client or server restart\
    \ for state on regular files has\n   two main goals: avoiding the necessity of\
    \ breaking application\n   guarantees with respect to locked files and delivery\
    \ of updates\n   cached at the client.  Neither of these goals applies to directories\n\
    \   protected by OPEN_DELEGATE_READ delegations and notifications.  Thus,\n  \
    \ no provision is made for reclaiming directory delegations in the\n   event of\
    \ client or server restart.  The client can simply establish a\n   directory delegation\
    \ in the same fashion as was done initially.\n"
- title: 11.  Multi-Server Namespace
  contents:
  - "11.  Multi-Server Namespace\n   NFSv4.1 supports attributes that allow a namespace\
    \ to extend beyond\n   the boundaries of a single server.  It is desirable that\
    \ clients and\n   servers support construction of such multi-server namespaces.\
    \  Use of\n   such multi-server namespaces is OPTIONAL; however, and for many\n\
    \   purposes, single-server namespaces are perfectly acceptable.  The use\n  \
    \ of multi-server namespaces can provide many advantages by separating\n   a file\
    \ system's logical position in a namespace from the (possibly\n   changing) logistical\
    \ and administrative considerations that cause a\n   particular file system to\
    \ be located on a particular server via a\n   single network access path that\
    \ has to be known in advance or\n   determined using DNS.\n"
- title: 11.1.  Terminology
  contents:
  - "11.1.  Terminology\n   In this section as a whole (i.e., within all of Section\
    \ 11), the\n   phrase \"client ID\" always refers to the 64-bit shorthand identifier\n\
    \   assigned by the server (a clientid4) and never to the structure that\n   the\
    \ client uses to identify itself to the server (called an\n   nfs_client_id4 or\
    \ client_owner in NFSv4.0 and NFSv4.1, respectively).\n   The opaque identifier\
    \ within those structures is referred to as a\n   \"client id string\".\n"
- title: 11.1.1.  Terminology Related to Trunking
  contents:
  - "11.1.1.  Terminology Related to Trunking\n   It is particularly important to\
    \ clarify the distinction between\n   trunking detection and trunking discovery.\
    \  The definitions we\n   present are applicable to all minor versions of NFSv4,\
    \ but we will\n   focus on how these terms apply to NFS version 4.1.\n   *  Trunking\
    \ detection refers to ways of deciding whether two specific\n      network addresses\
    \ are connected to the same NFSv4 server.  The\n      means available to make\
    \ this determination depends on the protocol\n      version, and, in some cases,\
    \ on the client implementation.\n      In the case of NFS version 4.1 and later\
    \ minor versions, the means\n      of trunking detection are as described in this\
    \ document and are\n      available to every client.  Two network addresses connected\
    \ to the\n      same server can always be used together to access a particular\n\
    \      server but cannot necessarily be used together to access a single\n   \
    \   session.  See below for definitions of the terms \"server-\n      trunkable\"\
    \ and \"session-trunkable\".\n   *  Trunking discovery is a process by which a\
    \ client using one\n      network address can obtain other addresses that are\
    \ connected to\n      the same server.  Typically, it builds on a trunking detection\n\
    \      facility by providing one or more methods by which candidate\n      addresses\
    \ are made available to the client, who can then use\n      trunking detection\
    \ to appropriately filter them.\n      Despite the support for trunking detection,\
    \ there was no\n      description of trunking discovery provided in RFC 5661 [66],\n\
    \      making it necessary to provide those means in this document.\n   The combination\
    \ of a server network address and a particular\n   connection type to be used\
    \ by a connection is referred to as a\n   \"server endpoint\".  Although using\
    \ different connection types may\n   result in different ports being used, the\
    \ use of different ports by\n   multiple connections to the same network address\
    \ in such cases is not\n   the essence of the distinction between the two endpoints\
    \ used.  This\n   is in contrast to the case of port-specific endpoints, in which\
    \ the\n   explicit specification of port numbers within network addresses is\n\
    \   used to allow a single server node to support multiple NFS servers.\n   Two\
    \ network addresses connected to the same server are said to be\n   server-trunkable.\
    \  Two such addresses support the use of client ID\n   trunking, as described\
    \ in Section 2.10.5.\n   Two network addresses connected to the same server such\
    \ that those\n   addresses can be used to support a single common session are\
    \ referred\n   to as session-trunkable.  Note that two addresses may be server-\n\
    \   trunkable without being session-trunkable, and that, when two\n   connections\
    \ of different connection types are made to the same\n   network address and are\
    \ based on a single file system location entry,\n   they are always session-trunkable,\
    \ independent of the connection\n   type, as specified by Section 2.10.5, since\
    \ their derivation from the\n   same file system location entry, together with\
    \ the identity of their\n   network addresses, assures that both connections are\
    \ to the same\n   server and will return server-owner information, allowing session\n\
    \   trunking to be used.\n"
- title: 11.1.2.  Terminology Related to File System Location
  contents:
  - "11.1.2.  Terminology Related to File System Location\n   Regarding the terminology\
    \ that relates to the construction of multi-\n   server namespaces out of a set\
    \ of local per-server namespaces:\n   *  Each server has a set of exported file\
    \ systems that may be\n      accessed by NFSv4 clients.  Typically, this is done\
    \ by assigning\n      each file system a name within the pseudo-fs associated\
    \ with the\n      server, although the pseudo-fs may be dispensed with if there\
    \ is\n      only a single exported file system.  Each such file system is part\n\
    \      of the server's local namespace, and can be considered as a file\n    \
    \  system instance within a larger multi-server namespace.\n   *  The set of all\
    \ exported file systems for a given server\n      constitutes that server's local\
    \ namespace.\n   *  In some cases, a server will have a namespace more extensive\
    \ than\n      its local namespace by using features associated with attributes\n\
    \      that provide file system location information.  These features,\n     \
    \ which allow construction of a multi-server namespace, are all\n      described\
    \ in individual sections below and include referrals\n      (Section 11.5.6),\
    \ migration (Section 11.5.5), and replication\n      (Section 11.5.4).\n   * \
    \ A file system present in a server's pseudo-fs may have multiple\n      file\
    \ system instances on different servers associated with it.\n      All such instances\
    \ are considered replicas of one another.\n      Whether such replicas can be\
    \ used simultaneously is discussed in\n      Section 11.11.1, while the level\
    \ of coordination between them\n      (important when switching between them)\
    \ is discussed in Sections\n      11.11.2 through 11.11.8 below.\n   *  When a\
    \ file system is present in a server's pseudo-fs, but there\n      is no corresponding\
    \ local file system, it is said to be \"absent\".\n      In such cases, all associated\
    \ instances will be accessed on other\n      servers.\n   Regarding the terminology\
    \ that relates to attributes used in trunking\n   discovery and other multi-server\
    \ namespace features:\n   *  File system location attributes include the fs_locations\
    \ and\n      fs_locations_info attributes.\n   *  File system location entries\
    \ provide the individual file system\n      locations within the file system location\
    \ attributes.  Each such\n      entry specifies a server, in the form of a hostname\
    \ or an address,\n      and an fs name, which designates the location of the file\
    \ system\n      within the server's local namespace.  A file system location entry\n\
    \      designates a set of server endpoints to which the client may\n      establish\
    \ connections.  There may be multiple endpoints because a\n      hostname may\
    \ map to multiple network addresses and because\n      multiple connection types\
    \ may be used to communicate with a single\n      network address.  However, except\
    \ where explicit port numbers are\n      used to designate a set of servers within\
    \ a single server node,\n      all such endpoints MUST designate a way of connecting\
    \ to a single\n      server.  The exact form of the location entry varies with\
    \ the\n      particular file system location attribute used, as described in\n\
    \      Section 11.2.\n      The network addresses used in file system location\
    \ entries\n      typically appear without port number indications and are used\
    \ to\n      designate a server at one of the standard ports for NFS access,\n\
    \      e.g., 2049 for TCP or 20049 for use with RPC-over-RDMA.  Port\n      numbers\
    \ may be used in file system location entries to designate\n      servers (typically\
    \ user-level ones) accessed using other port\n      numbers.  In the case where\
    \ network addresses indicate trunking\n      relationships, the use of an explicit\
    \ port number is inappropriate\n      since trunking is a relationship between\
    \ network addresses.  See\n      Section 11.5.2 for details.\n   *  File system\
    \ location elements are derived from location entries,\n      and each describes\
    \ a particular network access path consisting of\n      a network address and\
    \ a location within the server's local\n      namespace.  Such location elements\
    \ need not appear within a file\n      system location attribute, but the existence\
    \ of each location\n      element derives from a corresponding location entry.\
    \  When a\n      location entry specifies an IP address, there is only a single\n\
    \      corresponding location element.  File system location entries that\n  \
    \    contain a hostname are resolved using DNS, and may result in one\n      or\
    \ more location elements.  All location elements consist of a\n      location\
    \ address that includes the IP address of an interface to a\n      server and\
    \ an fs name, which is the location of the file system\n      within the server's\
    \ local namespace.  The fs name can be empty if\n      the server has no pseudo-fs\
    \ and only a single exported file system\n      at the root filehandle.\n   *\
    \  Two file system location elements are said to be server-trunkable\n      if\
    \ they specify the same fs name and the location addresses are\n      such that\
    \ the location addresses are server-trunkable.  When the\n      corresponding\
    \ network paths are used, the client will always be\n      able to use client\
    \ ID trunking, but will only be able to use\n      session trunking if the paths\
    \ are also session-trunkable.\n   *  Two file system location elements are said\
    \ to be session-trunkable\n      if they specify the same fs name and the location\
    \ addresses are\n      such that the location addresses are session-trunkable.\
    \  When the\n      corresponding network paths are used, the client will be able\
    \ to\n      able to use either client ID trunking or session trunking.\n   Discussion\
    \ of the term \"replica\" is complicated by the fact that the\n   term was used\
    \ in RFC 5661 [66] with a meaning different from that\n   used in this document.\
    \  In short, in [66] each replica is identified\n   by a single network access\
    \ path, while in the current document, a set\n   of network access paths that\
    \ have server-trunkable network addresses\n   and the same root-relative file\
    \ system pathname is considered to be a\n   single replica with multiple network\
    \ access paths.\n   Each set of server-trunkable location elements defines a set\
    \ of\n   available network access paths to a particular file system.  When\n \
    \  there are multiple such file systems, each of which containing the\n   same\
    \ data, these file systems are considered replicas of one another.\n   Logically,\
    \ such replication is symmetric, since the fs currently in\n   use and an alternate\
    \ fs are replicas of each other.  Often, in other\n   documents, the term \"replica\"\
    \ is not applied to the fs currently in\n   use, despite the fact that the replication\
    \ relation is inherently\n   symmetric.\n"
- title: 11.2.  File System Location Attributes
  contents:
  - "11.2.  File System Location Attributes\n   NFSv4.1 contains attributes that provide\
    \ information about how a\n   given file system may be accessed (i.e., at what\
    \ network address and\n   namespace position).  As a result, file systems in the\
    \ namespace of\n   one server can be associated with one or more instances of\
    \ that file\n   system on other servers.  These attributes contain file system\n\
    \   location entries specifying a server address target (either as a DNS\n   name\
    \ representing one or more IP addresses or as a specific IP\n   address) together\
    \ with the pathname of that file system within the\n   associated single-server\
    \ namespace.\n   The fs_locations_info RECOMMENDED attribute allows specification\
    \ of\n   one or more file system instance locations where the data\n   corresponding\
    \ to a given file system may be found.  In addition to\n   the specification of\
    \ file system instance locations, this attribute\n   provides helpful information\
    \ to do the following:\n   *  Guide choices among the various file system instances\
    \ provided\n      (e.g., priority for use, writability, currency, etc.).\n   *\
    \  Help the client efficiently effect as seamless a transition as\n      possible\
    \ among multiple file system instances, when and if that\n      should be necessary.\n\
    \   *  Guide the selection of the appropriate connection type to be used\n   \
    \   when establishing a connection.\n   Within the fs_locations_info attribute,\
    \ each fs_locations_server4\n   entry corresponds to a file system location entry:\
    \ the fls_server\n   field designates the server, and the fl_rootpath field of\
    \ the\n   encompassing fs_locations_item4 gives the location pathname within\n\
    \   the server's pseudo-fs.\n   The fs_locations attribute defined in NFSv4.0\
    \ is also a part of\n   NFSv4.1.  This attribute only allows specification of\
    \ the file system\n   locations where the data corresponding to a given file system\
    \ may be\n   found.  Servers SHOULD make this attribute available whenever\n \
    \  fs_locations_info is supported, but client use of fs_locations_info\n   is\
    \ preferable because it provides more information.\n   Within the fs_locations\
    \ attribute, each fs_location4 contains a file\n   system location entry with\
    \ the server field designating the server\n   and the rootpath field giving the\
    \ location pathname within the\n   server's pseudo-fs.\n"
- title: 11.3.  File System Presence or Absence
  contents:
  - "11.3.  File System Presence or Absence\n   A given location in an NFSv4.1 namespace\
    \ (typically but not\n   necessarily a multi-server namespace) can have a number\
    \ of file\n   system instance locations associated with it (via the fs_locations\
    \ or\n   fs_locations_info attribute).  There may also be an actual current\n\
    \   file system at that location, accessible via normal namespace\n   operations\
    \ (e.g., LOOKUP).  In this case, the file system is said to\n   be \"present\"\
    \ at that position in the namespace, and clients will\n   typically use it, reserving\
    \ use of additional locations specified via\n   the location-related attributes\
    \ to situations in which the principal\n   location is no longer available.\n\
    \   When there is no actual file system at the namespace location in\n   question,\
    \ the file system is said to be \"absent\".  An absent file\n   system contains\
    \ no files or directories other than the root.  Any\n   reference to it, except\
    \ to access a small set of attributes useful in\n   determining alternate locations,\
    \ will result in an error,\n   NFS4ERR_MOVED.  Note that if the server ever returns\
    \ the error\n   NFS4ERR_MOVED, it MUST support the fs_locations attribute and\
    \ SHOULD\n   support the fs_locations_info and fs_status attributes.\n   While\
    \ the error name suggests that we have a case of a file system\n   that once was\
    \ present, and has only become absent later, this is only\n   one possibility.\
    \  A position in the namespace may be permanently\n   absent with the set of file\
    \ system(s) designated by the location\n   attributes being the only realization.\
    \  The name NFS4ERR_MOVED\n   reflects an earlier, more limited conception of\
    \ its function, but\n   this error will be returned whenever the referenced file\
    \ system is\n   absent, whether it has moved or not.\n   Except in the case of\
    \ GETATTR-type operations (to be discussed\n   later), when the current filehandle\
    \ at the start of an operation is\n   within an absent file system, that operation\
    \ is not performed and the\n   error NFS4ERR_MOVED is returned, to indicate that\
    \ the file system is\n   absent on the current server.\n   Because a GETFH cannot\
    \ succeed if the current filehandle is within an\n   absent file system, filehandles\
    \ within an absent file system cannot\n   be transferred to the client.  When\
    \ a client does have filehandles\n   within an absent file system, it is the result\
    \ of obtaining them when\n   the file system was present, and having the file\
    \ system become absent\n   subsequently.\n   It should be noted that because the\
    \ check for the current filehandle\n   being within an absent file system happens\
    \ at the start of every\n   operation, operations that change the current filehandle\
    \ so that it\n   is within an absent file system will not result in an error.\
    \  This\n   allows such combinations as PUTFH-GETATTR and LOOKUP-GETATTR to be\n\
    \   used to get attribute information, particularly location attribute\n   information,\
    \ as discussed below.\n   The RECOMMENDED file system attribute fs_status can\
    \ be used to\n   interrogate the present/absent status of a given file system.\n"
- title: 11.4.  Getting Attributes for an Absent File System
  contents:
  - "11.4.  Getting Attributes for an Absent File System\n   When a file system is\
    \ absent, most attributes are not available, but\n   it is necessary to allow\
    \ the client access to the small set of\n   attributes that are available, and\
    \ most particularly those that give\n   information about the correct current\
    \ locations for this file system:\n   fs_locations and fs_locations_info.\n"
- title: 11.4.1.  GETATTR within an Absent File System
  contents:
  - "11.4.1.  GETATTR within an Absent File System\n   As mentioned above, an exception\
    \ is made for GETATTR in that\n   attributes may be obtained for a filehandle\
    \ within an absent file\n   system.  This exception only applies if the attribute\
    \ mask contains\n   at least one attribute bit that indicates the client is interested\
    \ in\n   a result regarding an absent file system: fs_locations,\n   fs_locations_info,\
    \ or fs_status.  If none of these attributes is\n   requested, GETATTR will result\
    \ in an NFS4ERR_MOVED error.\n   When a GETATTR is done on an absent file system,\
    \ the set of supported\n   attributes is very limited.  Many attributes, including\
    \ those that\n   are normally REQUIRED, will not be available on an absent file\n\
    \   system.  In addition to the attributes mentioned above (fs_locations,\n  \
    \ fs_locations_info, fs_status), the following attributes SHOULD be\n   available\
    \ on absent file systems.  In the case of RECOMMENDED\n   attributes, they should\
    \ be available at least to the same degree that\n   they are available on present\
    \ file systems.\n   change_policy:  This attribute is useful for absent file systems\
    \ and\n      can be helpful in summarizing to the client when any of the\n   \
    \   location-related attributes change.\n   fsid:  This attribute should be provided\
    \ so that the client can\n      determine file system boundaries, including, in\
    \ particular, the\n      boundary between present and absent file systems.  This\
    \ value must\n      be different from any other fsid on the current server and\
    \ need\n      have no particular relationship to fsids on any particular\n   \
    \   destination to which the client might be directed.\n   mounted_on_fileid:\
    \  For objects at the top of an absent file system,\n      this attribute needs\
    \ to be available.  Since the fileid is within\n      the present parent file\
    \ system, there should be no need to\n      reference the absent file system to\
    \ provide this information.\n   Other attributes SHOULD NOT be made available\
    \ for absent file\n   systems, even when it is possible to provide them.  The\
    \ server should\n   not assume that more information is always better and should\
    \ avoid\n   gratuitously providing additional information.\n   When a GETATTR\
    \ operation includes a bit mask for one of the\n   attributes fs_locations, fs_locations_info,\
    \ or fs_status, but where\n   the bit mask includes attributes that are not supported,\
    \ GETATTR will\n   not return an error, but will return the mask of the actual\n\
    \   attributes supported with the results.\n   Handling of VERIFY/NVERIFY is similar\
    \ to GETATTR in that if the\n   attribute mask does not include fs_locations,\
    \ fs_locations_info, or\n   fs_status, the error NFS4ERR_MOVED will result.  It\
    \ differs in that\n   any appearance in the attribute mask of an attribute not\
    \ supported\n   for an absent file system (and note that this will include some\n\
    \   normally REQUIRED attributes) will also cause an NFS4ERR_MOVED\n   result.\n"
- title: 11.4.2.  READDIR and Absent File Systems
  contents:
  - "11.4.2.  READDIR and Absent File Systems\n   A READDIR performed when the current\
    \ filehandle is within an absent\n   file system will result in an NFS4ERR_MOVED\
    \ error, since, unlike the\n   case of GETATTR, no such exception is made for\
    \ READDIR.\n   Attributes for an absent file system may be fetched via a READDIR\
    \ for\n   a directory in a present file system, when that directory contains\n\
    \   the root directories of one or more absent file systems.  In this\n   case,\
    \ the handling is as follows:\n   *  If the attribute set requested includes one\
    \ of the attributes\n      fs_locations, fs_locations_info, or fs_status, then\
    \ fetching of\n      attributes proceeds normally and no NFS4ERR_MOVED indication\
    \ is\n      returned, even when the rdattr_error attribute is requested.\n   *\
    \  If the attribute set requested does not include one of the\n      attributes\
    \ fs_locations, fs_locations_info, or fs_status, then if\n      the rdattr_error\
    \ attribute is requested, each directory entry for\n      the root of an absent\
    \ file system will report NFS4ERR_MOVED as the\n      value of the rdattr_error\
    \ attribute.\n   *  If the attribute set requested does not include any of the\n\
    \      attributes fs_locations, fs_locations_info, fs_status, or\n      rdattr_error,\
    \ then the occurrence of the root of an absent file\n      system within the directory\
    \ will result in the READDIR failing\n      with an NFS4ERR_MOVED error.\n   *\
    \  The unavailability of an attribute because of a file system's\n      absence,\
    \ even one that is ordinarily REQUIRED, does not result in\n      any error indication.\
    \  The set of attributes returned for the root\n      directory of the absent\
    \ file system in that case is simply\n      restricted to those actually available.\n"
- title: 11.5.  Uses of File System Location Information
  contents:
  - "11.5.  Uses of File System Location Information\n   The file system location\
    \ attributes (i.e., fs_locations and\n   fs_locations_info), together with the\
    \ possibility of absent file\n   systems, provide a number of important facilities\
    \ for reliable,\n   manageable, and scalable data access.\n   When a file system\
    \ is present, these attributes can provide the\n   following:\n   *  The locations\
    \ of alternative replicas to be used to access the\n      same data in the event\
    \ of server failures, communications\n      problems, or other difficulties that\
    \ make continued access to the\n      current replica impossible or otherwise\
    \ impractical.  Provisioning\n      and use of such alternate replicas is referred\
    \ to as \"replication\"\n      and is discussed in Section 11.5.4 below.\n   *\
    \  The network address(es) to be used to access the current file\n      system\
    \ instance or replicas of it.  Client use of this information\n      is discussed\
    \ in Section 11.5.2 below.\n   Under some circumstances, multiple replicas may\
    \ be used\n   simultaneously to provide higher-performance access to the file\n\
    \   system in question, although the lack of state sharing between\n   servers\
    \ may be an impediment to such use.\n   When a file system is present but becomes\
    \ absent, clients can be\n   given the opportunity to have continued access to\
    \ their data using a\n   different replica.  In this case, a continued attempt\
    \ to use the data\n   in the now-absent file system will result in an NFS4ERR_MOVED\
    \ error,\n   and then the successor replica or set of possible replica choices\
    \ can\n   be fetched and used to continue access.  Transfer of access to the\n\
    \   new replica location is referred to as \"migration\" and is discussed\n  \
    \ in Section 11.5.4 below.\n   When a file system is currently absent, specification\
    \ of file system\n   location provides a means by which file systems located on\
    \ one server\n   can be associated with a namespace defined by another server,\
    \ thus\n   allowing a general multi-server namespace facility.  A designation\
    \ of\n   such a remote instance, in place of a file system not previously\n  \
    \ present, is called a \"pure referral\" and is discussed in\n   Section 11.5.6\
    \ below.\n   Because client support for attributes related to file system location\n\
    \   is OPTIONAL, a server may choose to take action to hide migration and\n  \
    \ referral events from such clients, by acting as a proxy, for example.\n   The\
    \ server can determine the presence of client support from the\n   arguments of\
    \ the EXCHANGE_ID operation (see Section 18.35.3).\n"
- title: 11.5.1.  Combining Multiple Uses in a Single Attribute
  contents:
  - "11.5.1.  Combining Multiple Uses in a Single Attribute\n   A file system location\
    \ attribute will sometimes contain information\n   relating to the location of\
    \ multiple replicas, which may be used in\n   different ways:\n   *  File system\
    \ location entries that relate to the file system\n      instance currently in\
    \ use provide trunking information, allowing\n      the client to find additional\
    \ network addresses by which the\n      instance may be accessed.\n   *  File\
    \ system location entries that provide information about\n      replicas to which\
    \ access is to be transferred.\n   *  Other file system location entries that\
    \ relate to replicas that\n      are available to use in the event that access\
    \ to the current\n      replica becomes unsatisfactory.\n   In order to simplify\
    \ client handling and to allow the best choice of\n   replicas to access, the\
    \ server should adhere to the following\n   guidelines:\n   *  All file system\
    \ location entries that relate to a single file\n      system instance should\
    \ be adjacent.\n   *  File system location entries that relate to the instance\
    \ currently\n      in use should appear first.\n   *  File system location entries\
    \ that relate to replica(s) to which\n      migration is occurring should appear\
    \ before replicas that are\n      available for later use if the current replica\
    \ should become\n      inaccessible.\n"
- title: 11.5.2.  File System Location Attributes and Trunking
  contents:
  - "11.5.2.  File System Location Attributes and Trunking\n   Trunking is the use\
    \ of multiple connections between a client and\n   server in order to increase\
    \ the speed of data transfer.  A client may\n   determine the set of network addresses\
    \ to use to access a given file\n   system in a number of ways:\n   *  When the\
    \ name of the server is known to the client, it may use DNS\n      to obtain a\
    \ set of network addresses to use in accessing the\n      server.\n   *  The client\
    \ may fetch the file system location attribute for the\n      file system.  This\
    \ will provide either the name of the server\n      (which can be turned into\
    \ a set of network addresses using DNS) or\n      a set of server-trunkable location\
    \ entries.  Using the latter\n      alternative, the server can provide addresses\
    \ it regards as\n      desirable to use to access the file system in question.\
    \  Although\n      these entries can contain port numbers, these port numbers\
    \ are not\n      used in determining trunking relationships.  Once the candidate\n\
    \      addresses have been determined and EXCHANGE_ID done to the proper\n   \
    \   server, only the value of the so_major_id field returned by the\n      servers\
    \ in question determines whether a trunking relationship\n      actually exists.\n\
    \   When the client fetches a location attribute for a file system, it\n   should\
    \ be noted that the client may encounter multiple entries for a\n   number of\
    \ reasons, such that when it determines trunking information,\n   it may need\
    \ to bypass addresses not trunkable with one already known.\n   The server can\
    \ provide location entries that include either names or\n   network addresses.\
    \  It might use the latter form because of DNS-\n   related security concerns\
    \ or because the set of addresses to be used\n   might require active management\
    \ by the server.\n   Location entries used to discover candidate addresses for\
    \ use in\n   trunking are subject to change, as discussed in Section 11.5.7 below.\n\
    \   The client may respond to such changes by using additional addresses\n   once\
    \ they are verified or by ceasing to use existing ones.  The\n   server can force\
    \ the client to cease using an address by returning\n   NFS4ERR_MOVED when that\
    \ address is used to access a file system.\n   This allows a transfer of client\
    \ access that is similar to migration,\n   although the same file system instance\
    \ is accessed throughout.\n"
- title: 11.5.3.  File System Location Attributes and Connection Type Selection
  contents:
  - "11.5.3.  File System Location Attributes and Connection Type Selection\n   Because\
    \ of the need to support multiple types of connections, clients\n   face the issue\
    \ of determining the proper connection type to use when\n   establishing a connection\
    \ to a given server network address.  In some\n   cases, this issue can be addressed\
    \ through the use of the connection\n   \"step-up\" facility described in Section\
    \ 18.36.  However, because\n   there are cases in which that facility is not available,\
    \ the client\n   may have to choose a connection type with no possibility of changing\n\
    \   it within the scope of a single connection.\n   The two file system location\
    \ attributes differ as to the information\n   made available in this regard. \
    \ The fs_locations attribute provides\n   no information to support connection\
    \ type selection.  As a result,\n   clients supporting multiple connection types\
    \ would need to attempt to\n   establish connections using multiple connection\
    \ types until the one\n   preferred by the client is successfully established.\n\
    \   The fs_locations_info attribute includes the FSLI4TF_RDMA flag, which\n  \
    \ is convenient for a client wishing to use RDMA.  When this flag is\n   set,\
    \ it indicates that RPC-over-RDMA support is available using the\n   specified\
    \ location entry.  A client can establish a TCP connection\n   and then convert\
    \ that connection to use RDMA by using the step-up\n   facility.\n   Irrespective\
    \ of the particular attribute used, when there is no\n   indication that a step-up\
    \ operation can be performed, a client\n   supporting RDMA operation can establish\
    \ a new RDMA connection, and it\n   can be bound to the session already established\
    \ by the TCP\n   connection, allowing the TCP connection to be dropped and the\
    \ session\n   converted to further use in RDMA mode, if the server supports that.\n"
- title: 11.5.4.  File System Replication
  contents:
  - "11.5.4.  File System Replication\n   The fs_locations and fs_locations_info attributes\
    \ provide alternative\n   file system locations, to be used to access data in\
    \ place of or in\n   addition to the current file system instance.  On first access\
    \ to a\n   file system, the client should obtain the set of alternate locations\n\
    \   by interrogating the fs_locations or fs_locations_info attribute,\n   with\
    \ the latter being preferred.\n   In the event that the occurrence of server failures,\
    \ communications\n   problems, or other difficulties make continued access to\
    \ the current\n   file system impossible or otherwise impractical, the client\
    \ can use\n   the alternate locations as a way to get continued access to its\
    \ data.\n   The alternate locations may be physical replicas of the (typically\n\
    \   read-only) file system data supplemented by possible asynchronous\n   propagation\
    \ of updates.  Alternatively, they may provide for the use\n   of various forms\
    \ of server clustering in which multiple servers\n   provide alternate ways of\
    \ accessing the same physical file system.\n   How the difference between replicas\
    \ affects file system transitions\n   can be represented within the fs_locations\
    \ and fs_locations_info\n   attributes, and how the client deals with file system\
    \ transition\n   issues will be discussed in detail in later sections.\n   Although\
    \ the location attributes provide some information about the\n   nature of the\
    \ inter-replica transition, many aspects of the semantics\n   of possible asynchronous\
    \ updates are not currently described by the\n   protocol, which makes it necessary\
    \ for clients using replication to\n   switch among replicas undergoing change\
    \ to familiarize themselves\n   with the semantics of the update approach used.\
    \  Due to this lack of\n   specificity, many applications may find the use of\
    \ migration more\n   appropriate because a server can propagate all updates made\
    \ before an\n   established point in time to the new replica as part of the migration\n\
    \   event.\n"
- title: 11.5.4.1.  File System Trunking Presented as Replication
  contents:
  - "11.5.4.1.  File System Trunking Presented as Replication\n   In some situations,\
    \ a file system location entry may indicate a file\n   system access path to be\
    \ used as an alternate location, where\n   trunking, rather than replication,\
    \ is to be used.  The situations in\n   which this is appropriate are limited\
    \ to those in which both of the\n   following are true:\n   *  The two file system\
    \ locations (i.e., the one on which the location\n      attribute is obtained\
    \ and the one specified in the file system\n      location entry) designate the\
    \ same locations within their\n      respective single-server namespaces.\n  \
    \ *  The two server network addresses (i.e., the one being used to\n      obtain\
    \ the location attribute and the one specified in the file\n      system location\
    \ entry) designate the same server (as indicated by\n      the same value of the\
    \ so_major_id field of the eir_server_owner\n      field returned in response\
    \ to EXCHANGE_ID).\n   When these conditions hold, operations using both access\
    \ paths are\n   generally trunked, although trunking may be disallowed when the\n\
    \   attribute fs_locations_info is used:\n   *  When the fs_locations_info attribute\
    \ shows the two entries as not\n      having the same simultaneous-use class,\
    \ trunking is inhibited, and\n      the two access paths cannot be used together.\n\
    \      In this case, the two paths can be used serially with no\n      transition\
    \ activity required on the part of the client, and any\n      transition between\
    \ access paths is transparent.  In transferring\n      access from one to the\
    \ other, the client acts as if communication\n      were interrupted, establishing\
    \ a new connection and possibly a new\n      session to continue access to the\
    \ same file system.\n   *  Note that for two such location entries, any information\
    \ within\n      the fs_locations_info attribute that indicates the need for\n\
    \      special transition activity, i.e., the appearance of the two file\n   \
    \   system location entries with different handle, fileid, write-\n      verifier,\
    \ change, and readdir classes, indicates a serious\n      problem.  The client,\
    \ if it allows transition to the file system\n      instance at all, must not\
    \ treat any transition as a transparent\n      one.  The server SHOULD NOT indicate\
    \ that these two entries (for\n      the same file system on the same server)\
    \ belong to different\n      handle, fileid, write-verifier, change, and readdir\
    \ classes,\n      whether or not the two entries are shown belonging to the same\n\
    \      simultaneous-use class.\n   These situations were recognized by [66], even\
    \ though that document\n   made no explicit mention of trunking:\n   *  It treated\
    \ the situation that we describe as trunking as one of\n      simultaneous use\
    \ of two distinct file system instances, even\n      though, in the explanatory\
    \ framework now used to describe the\n      situation, the case is one in which\
    \ a single file system is\n      accessed by two different trunked addresses.\n\
    \   *  It treated the situation in which two paths are to be used\n      serially\
    \ as a special sort of \"transparent transition\".  However,\n      in the descriptive\
    \ framework now used to categorize transition\n      situations, this is considered\
    \ a case of a \"network endpoint\n      transition\" (see Section 11.9).\n"
- title: 11.5.5.  File System Migration
  contents:
  - "11.5.5.  File System Migration\n   When a file system is present and becomes\
    \ inaccessible using the\n   current access path, the NFSv4.1 protocol provides\
    \ a means by which\n   clients can be given the opportunity to have continued\
    \ access to\n   their data.  This may involve using a different access path to\
    \ the\n   existing replica or providing a path to a different replica.  The new\n\
    \   access path or the location of the new replica is specified by a file\n  \
    \ system location attribute.  The ensuing migration of access includes\n   the\
    \ ability to retain locks across the transition.  Depending on\n   circumstances,\
    \ this can involve:\n   *  The continued use of the existing clientid when accessing\
    \ the\n      current replica using a new access path.\n   *  Use of lock reclaim,\
    \ taking advantage of a per-fs grace period.\n   *  Use of Transparent State Migration.\n\
    \   Typically, a client will be accessing the file system in question,\n   get\
    \ an NFS4ERR_MOVED error, and then use a file system location\n   attribute to\
    \ determine the new access path for the data.  When\n   fs_locations_info is used,\
    \ additional information will be available\n   that will define the nature of\
    \ the client's handling of the\n   transition to a new server.\n   In most instances,\
    \ servers will choose to migrate all clients using a\n   particular file system\
    \ to a successor replica at the same time to\n   avoid cases in which different\
    \ clients are updating different\n   replicas.  However, migration of an individual\
    \ client can be helpful\n   in providing load balancing, as long as the replicas\
    \ in question are\n   such that they represent the same data as described in\n\
    \   Section 11.11.8.\n   *  In the case in which there is no transition between\
    \ replicas\n      (i.e., only a change in access path), there are no special\n\
    \      difficulties in using of this mechanism to effect load balancing.\n   *\
    \  In the case in which the two replicas are sufficiently coordinated\n      as\
    \ to allow a single client coherent, simultaneous access to both,\n      there\
    \ is, in general, no obstacle to the use of migration of\n      particular clients\
    \ to effect load balancing.  Generally, such\n      simultaneous use involves\
    \ cooperation between servers to ensure\n      that locks granted on two coordinated\
    \ replicas cannot conflict and\n      can remain effective when transferred to\
    \ a common replica.\n   *  In the case in which a large set of clients is accessing\
    \ a file\n      system in a read-only fashion, it can be helpful to migrate all\n\
    \      clients with writable access simultaneously, while using load\n      balancing\
    \ on the set of read-only copies, as long as the rules in\n      Section 11.11.8,\
    \ which are designed to prevent data reversion, are\n      followed.\n   In other\
    \ cases, the client might not have sufficient guarantees of\n   data similarity\
    \ or coherence to function properly (e.g., the data in\n   the two replicas is\
    \ similar but not identical), and the possibility\n   that different clients are\
    \ updating different replicas can exacerbate\n   the difficulties, making the\
    \ use of load balancing in such situations\n   a perilous enterprise.\n   The\
    \ protocol does not specify how the file system will be moved\n   between servers\
    \ or how updates to multiple replicas will be\n   coordinated.  It is anticipated\
    \ that a number of different server-to-\n   server coordination mechanisms might\
    \ be used, with the choice left to\n   the server implementer.  The NFSv4.1 protocol\
    \ specifies the method\n   used to communicate the migration event between client\
    \ and server.\n   In the case of various forms of server clustering, the new location\n\
    \   may be another server providing access to the same physical file\n   system.\
    \  The client's responsibilities in dealing with this\n   transition will depend\
    \ on whether a switch between replicas has\n   occurred and the means the server\
    \ has chosen to provide continuity of\n   locking state.  These issues will be\
    \ discussed in detail below.\n   Although a single successor location is typical,\
    \ multiple locations\n   may be provided.  When multiple locations are provided,\
    \ the client\n   will typically use the first one provided.  If that is inaccessible\n\
    \   for some reason, later ones can be used.  In such cases, the client\n   might\
    \ consider the transition to the new replica to be a migration\n   event, even\
    \ though some of the servers involved might not be aware of\n   the use of the\
    \ server that was inaccessible.  In such a case, a\n   client might lose access\
    \ to locking state as a result of the access\n   transfer.\n   When an alternate\
    \ location is designated as the target for migration,\n   it must designate the\
    \ same data (with metadata being the same to the\n   degree indicated by the fs_locations_info\
    \ attribute).  Where file\n   systems are writable, a change made on the original\
    \ file system must\n   be visible on all migration targets.  Where a file system\
    \ is not\n   writable but represents a read-only copy (possibly periodically\n\
    \   updated) of a writable file system, similar requirements apply to the\n  \
    \ propagation of updates.  Any change visible in the original file\n   system\
    \ must already be effected on all migration targets, to avoid\n   any possibility\
    \ that a client, in effecting a transition to the\n   migration target, will see\
    \ any reversion in file system state.\n"
- title: 11.5.6.  Referrals
  contents:
  - "11.5.6.  Referrals\n   Referrals allow the server to associate a file system\
    \ namespace entry\n   located on one server with a file system located on another\
    \ server.\n   When this includes the use of pure referrals, servers are provided\
    \ a\n   way of placing a file system in a location within the namespace\n   essentially\
    \ without respect to its physical location on a particular\n   server.  This allows\
    \ a single server or a set of servers to present a\n   multi-server namespace\
    \ that encompasses file systems located on a\n   wider range of servers.  Some\
    \ likely uses of this facility include\n   establishment of site-wide or organization-wide\
    \ namespaces, with the\n   eventual possibility of combining such together into\
    \ a truly global\n   namespace, such as the one provided by AFS (the Andrew File\
    \ System)\n   [65].\n   Referrals occur when a client determines, upon first referencing\
    \ a\n   position in the current namespace, that it is part of a new file\n   system\
    \ and that the file system is absent.  When this occurs,\n   typically upon receiving\
    \ the error NFS4ERR_MOVED, the actual location\n   or locations of the file system\
    \ can be determined by fetching a\n   locations attribute.\n   The file system\
    \ location attribute may designate a single file system\n   location or multiple\
    \ file system locations, to be selected based on\n   the needs of the client.\
    \  The server, in the fs_locations_info\n   attribute, may specify priorities\
    \ to be associated with various file\n   system location choices.  The server\
    \ may assign different priorities\n   to different locations as reported to individual\
    \ clients, in order to\n   adapt to client physical location or to effect load\
    \ balancing.  When\n   both read-only and read-write file systems are present,\
    \ some of the\n   read-only locations might not be absolutely up-to-date (as they\
    \ would\n   have to be in the case of replication and migration).  Servers may\n\
    \   also specify file system locations that include client-substituted\n   variables\
    \ so that different clients are referred to different file\n   systems (with different\
    \ data contents) based on client attributes\n   such as CPU architecture.\n  \
    \ If the fs_locations_info attribute lists multiple possible targets,\n   the\
    \ relationships among them may be important to the client in\n   selecting which\
    \ one to use.  The same rules specified in\n   Section 11.5.5 below regarding\
    \ multiple migration targets apply to\n   these multiple replicas as well.  For\
    \ example, the client might\n   prefer a writable target on a server that has\
    \ additional writable\n   replicas to which it subsequently might switch.  Note\
    \ that, as\n   distinguished from the case of replication, there is no need to\
    \ deal\n   with the case of propagation of updates made by the current client,\n\
    \   since the current client has not accessed the file system in\n   question.\n\
    \   Use of multi-server namespaces is enabled by NFSv4.1 but is not\n   required.\
    \  The use of multi-server namespaces and their scope will\n   depend on the applications\
    \ used and system administration\n   preferences.\n   Multi-server namespaces\
    \ can be established by a single server\n   providing a large set of pure referrals\
    \ to all of the included file\n   systems.  Alternatively, a single multi-server\
    \ namespace may be\n   administratively segmented with separate referral file\
    \ systems (on\n   separate servers) for each separately administered portion of\
    \ the\n   namespace.  The top-level referral file system or any segment may use\n\
    \   replicated referral file systems for higher availability.\n   Generally, multi-server\
    \ namespaces are for the most part uniform, in\n   that the same data made available\
    \ to one client at a given location\n   in the namespace is made available to\
    \ all clients at that namespace\n   location.  However, there are facilities provided\
    \ that allow\n   different clients to be directed to different sets of data, for\n\
    \   reasons such as enabling adaptation to such client characteristics as\n  \
    \ CPU architecture.  These facilities are described in Section 11.17.3.\n   Note\
    \ that it is possible, when providing a uniform namespace, to\n   provide different\
    \ location entries to different clients in order to\n   provide each client with\
    \ a copy of the data physically closest to it\n   or otherwise optimize access\
    \ (e.g., provide load balancing).\n"
- title: 11.5.7.  Changes in a File System Location Attribute
  contents:
  - "11.5.7.  Changes in a File System Location Attribute\n   Although clients will\
    \ typically fetch a file system location\n   attribute when first accessing a\
    \ file system and when NFS4ERR_MOVED\n   is returned, a client can choose to fetch\
    \ the attribute periodically,\n   in which case, the value fetched may change\
    \ over time.\n   For clients not prepared to access multiple replicas simultaneously\n\
    \   (see Section 11.11.1), the handling of the various cases of location\n   change\
    \ are as follows:\n   *  Changes in the list of replicas or in the network addresses\n\
    \      associated with replicas do not require immediate action.  The\n      client\
    \ will typically update its list of replicas to reflect the\n      new information.\n\
    \   *  Additions to the list of network addresses for the current file\n     \
    \ system instance need not be acted on promptly.  However, to\n      prepare for\
    \ a subsequent migration event, the client can choose to\n      take note of the\
    \ new address and then use it whenever it needs to\n      switch access to a new\
    \ replica.\n   *  Deletions from the list of network addresses for the current\
    \ file\n      system instance do not require the client to immediately cease use\n\
    \      of existing access paths, although new connections are not to be\n    \
    \  established on addresses that have been deleted.  However, clients\n      can\
    \ choose to act on such deletions by preparing for an eventual\n      shift in\
    \ access, which becomes unavoidable as soon as the server\n      returns NFS4ERR_MOVED\
    \ to indicate that a particular network access\n      path is not usable to access\
    \ the current file system.\n   For clients that are prepared to access several\
    \ replicas\n   simultaneously, the following additional cases need to be addressed.\n\
    \   As in the cases discussed above, changes in the set of replicas need\n   not\
    \ be acted upon promptly, although the client has the option of\n   adjusting\
    \ its access even in the absence of difficulties that would\n   lead to the selection\
    \ of a new replica.\n   *  When a new replica is added, which may be accessed\
    \ simultaneously\n      with one currently in use, the client is free to use the\
    \ new\n      replica immediately.\n   *  When a replica currently in use is deleted\
    \ from the list, the\n      client need not cease using it immediately.  However,\
    \ since the\n      server may subsequently force such use to cease (by returning\n\
    \      NFS4ERR_MOVED), clients might decide to limit the need for later\n    \
    \  state transfer.  For example, new opens might be done on other\n      replicas,\
    \ rather than on one not present in the list.\n"
- title: 11.6.  Trunking without File System Location Information
  contents:
  - "11.6.  Trunking without File System Location Information\n   In situations in\
    \ which a file system is accessed using two server-\n   trunkable addresses (as\
    \ indicated by the same value of the\n   so_major_id field of the eir_server_owner\
    \ field returned in response\n   to EXCHANGE_ID), trunked access is allowed even\
    \ though there might\n   not be any location entries specifically indicating the\
    \ use of\n   trunking for that file system.\n   This situation was recognized\
    \ by [66], although that document made no\n   explicit mention of trunking and\
    \ treated the situation as one of\n   simultaneous use of two distinct file system\
    \ instances.  In the\n   explanatory framework now used to describe the situation,\
    \ the case is\n   one in which a single file system is accessed by two different\n\
    \   trunked addresses.\n"
- title: 11.7.  Users and Groups in a Multi-Server Namespace
  contents:
  - "11.7.  Users and Groups in a Multi-Server Namespace\n   As in the case of a single-server\
    \ environment (see Section 5.9), when\n   an owner or group name of the form \"\
    id@domain\" is assigned to a file,\n   there is an implicit promise to return\
    \ that same string when the\n   corresponding attribute is interrogated subsequently.\
    \  In the case of\n   a multi-server namespace, that same promise applies even\
    \ if server\n   boundaries have been crossed.  Similarly, when the owner attribute\
    \ of\n   a file is derived from the security principal that created the file,\n\
    \   that attribute should have the same value even if the interrogation\n   occurs\
    \ on a different server from the file creation.\n   Similarly, the set of security\
    \ principals recognized by all the\n   participating servers needs to be the same,\
    \ with each such principal\n   having the same credentials, regardless of the\
    \ particular server\n   being accessed.\n   In order to meet these requirements,\
    \ those setting up multi-server\n   namespaces will need to limit the servers\
    \ included so that:\n   *  In all cases in which more than a single domain is\
    \ supported, the\n      requirements stated in RFC 8000 [31] are to be respected.\n\
    \   *  All servers support a common set of domains that includes all of\n    \
    \  the domains clients use and expect to see returned as the domain\n      portion\
    \ of an owner or group in the form \"id@domain\".  Note that,\n      although\
    \ this set most often consists of a single domain, it is\n      possible for multiple\
    \ domains to be supported.\n   *  All servers, for each domain that they support,\
    \ accept the same\n      set of user and group ids as valid.\n   *  All servers\
    \ recognize the same set of security principals.  For\n      each principal, the\
    \ same credential is required, independent of\n      the server being accessed.\
    \  In addition, the group membership for\n      each such principal is to be the\
    \ same, independent of the server\n      accessed.\n   Note that there is no requirement\
    \ in general that the users\n   corresponding to particular security principals\
    \ have the same local\n   representation on each server, even though it is most\
    \ often the case\n   that this is so.\n   When AUTH_SYS is used, the following\
    \ additional requirements must be\n   met:\n   *  Only a single NFSv4 domain can\
    \ be supported through the use of\n      AUTH_SYS.\n   *  The \"local\" representation\
    \ of all owners and groups must be the\n      same on all servers.  The word \"\
    local\" is used here since that is\n      the way that numeric user and group\
    \ ids are described in\n      Section 5.9.  However, when AUTH_SYS or stringified\
    \ numeric owners\n      or groups are used, these identifiers are not truly local,\
    \ since\n      they are known to the clients as well as to the server.\n   Similarly,\
    \ when stringified numeric user and group ids are used, the\n   \"local\" representation\
    \ of all owners and groups must be the same on\n   all servers, even when AUTH_SYS\
    \ is not used.\n"
- title: 11.8.  Additional Client-Side Considerations
  contents:
  - "11.8.  Additional Client-Side Considerations\n   When clients make use of servers\
    \ that implement referrals,\n   replication, and migration, care should be taken\
    \ that a user who\n   mounts a given file system that includes a referral or a\
    \ relocated\n   file system continues to see a coherent picture of that user-side\n\
    \   file system despite the fact that it contains a number of server-side\n  \
    \ file systems that may be on different servers.\n   One important issue is upward\
    \ navigation from the root of a server-\n   side file system to its parent (specified\
    \ as \"..\" in UNIX), in the\n   case in which it transitions to that file system\
    \ as a result of\n   referral, migration, or a transition as a result of replication.\n\
    \   When the client is at such a point, and it needs to ascend to the\n   parent,\
    \ it must go back to the parent as seen within the multi-server\n   namespace\
    \ rather than sending a LOOKUPP operation to the server,\n   which would result\
    \ in the parent within that server's single-server\n   namespace.  In order to\
    \ do this, the client needs to remember the\n   filehandles that represent such\
    \ file system roots and use these\n   instead of sending a LOOKUPP operation to\
    \ the current server.  This\n   will allow the client to present to applications\
    \ a consistent\n   namespace, where upward navigation and downward navigation\
    \ are\n   consistent.\n   Another issue concerns refresh of referral locations.\
    \  When referrals\n   are used extensively, they may change as server configurations\n\
    \   change.  It is expected that clients will cache information related\n   to\
    \ traversing referrals so that future client-side requests are\n   resolved locally\
    \ without server communication.  This is usually\n   rooted in client-side name\
    \ look up caching.  Clients should\n   periodically purge this data for referral\
    \ points in order to detect\n   changes in location information.  When the change_policy\
    \ attribute\n   changes for directories that hold referral entries or for the\n\
    \   referral entries themselves, clients should consider any associated\n   cached\
    \ referral information to be out of date.\n"
- title: 11.9.  Overview of File Access Transitions
  contents:
  - "11.9.  Overview of File Access Transitions\n   File access transitions are of\
    \ two types:\n   *  Those that involve a transition from accessing the current\
    \ replica\n      to another one in connection with either replication or migration.\n\
    \      How these are dealt with is discussed in Section 11.11.\n   *  Those in\
    \ which access to the current file system instance is\n      retained, while the\
    \ network path used to access that instance is\n      changed.  This case is discussed\
    \ in Section 11.10.\n"
- title: 11.10.  Effecting Network Endpoint Transitions
  contents:
  - "11.10.  Effecting Network Endpoint Transitions\n   The endpoints used to access\
    \ a particular file system instance may\n   change in a number of ways, as listed\
    \ below.  In each of these cases,\n   the same fsid, client IDs, filehandles,\
    \ and stateids are used to\n   continue access, with a continuity of lock state.\
    \  In many cases, the\n   same sessions can also be used.\n   The appropriate\
    \ action depends on the set of replacement addresses\n   that are available for\
    \ use (i.e., server endpoints that are server-\n   trunkable with one previously\
    \ being used).\n   *  When use of a particular address is to cease, and there\
    \ is also\n      another address currently in use that is server-trunkable with\
    \ it,\n      requests that would have been issued on the address whose use is\n\
    \      to be discontinued can be issued on the remaining address(es).\n      When\
    \ an address is server-trunkable but not session-trunkable with\n      the address\
    \ whose use is to be discontinued, the request might\n      need to be modified\
    \ to reflect the fact that a different session\n      will be used.\n   *  When\
    \ use of a particular connection is to cease, as indicated by\n      receiving\
    \ NFS4ERR_MOVED when using that connection, but that\n      address is still indicated\
    \ as accessible according to the\n      appropriate file system location entries,\
    \ it is likely that\n      requests can be issued on a new connection of a different\n\
    \      connection type once that connection is established.  Since any\n     \
    \ two non-port-specific server endpoints that share a network\n      address are\
    \ inherently session-trunkable, the client can use\n      BIND_CONN_TO_SESSION\
    \ to access the existing session with the new\n      connection.\n   *  When there\
    \ are no potential replacement addresses in use, but\n      there are valid addresses\
    \ session-trunkable with the one whose use\n      is to be discontinued, the client\
    \ can use BIND_CONN_TO_SESSION to\n      access the existing session using the\
    \ new address.  Although the\n      target session will generally be accessible,\
    \ there may be rare\n      situations in which that session is no longer accessible\
    \ when an\n      attempt is made to bind the new connection to it.  In this case,\n\
    \      the client can create a new session to enable continued access to\n   \
    \   the existing instance using the new connection, providing for the\n      use\
    \ of existing filehandles, stateids, and client ids while\n      supplying continuity\
    \ of locking state.\n   *  When there is no potential replacement address in use,\
    \ and there\n      are no valid addresses session-trunkable with the one whose\
    \ use is\n      to be discontinued, other server-trunkable addresses may be used\n\
    \      to provide continued access.  Although the use of CREATE_SESSION\n    \
    \  is available to provide continued access to the existing instance,\n      servers\
    \ have the option of providing continued access to the\n      existing session\
    \ through the new network access path in a fashion\n      similar to that provided\
    \ by session migration (see Section 11.12).\n      To take advantage of this possibility,\
    \ clients can perform an\n      initial BIND_CONN_TO_SESSION, as in the previous\
    \ case, and use\n      CREATE_SESSION only if that fails.\n"
- title: 11.11.  Effecting File System Transitions
  contents:
  - "11.11.  Effecting File System Transitions\n   There are a range of situations\
    \ in which there is a change to be\n   effected in the set of replicas used to\
    \ access a particular file\n   system.  Some of these may involve an expansion\
    \ or contraction of the\n   set of replicas used as discussed in Section 11.11.1\
    \ below.\n   For reasons explained in that section, most transitions will involve\n\
    \   a transition from a single replica to a corresponding replacement\n   replica.\
    \  When effecting replica transition, some types of sharing\n   between the replicas\
    \ may affect handling of the transition as\n   described in Sections 11.11.2 through\
    \ 11.11.8 below.  The attribute\n   fs_locations_info provides helpful information\
    \ to allow the client to\n   determine the degree of inter-replica sharing.\n\
    \   With regard to some types of state, the degree of continuity across\n   the\
    \ transition depends on the occasion prompting the transition, with\n   transitions\
    \ initiated by the servers (i.e., migration) offering much\n   more scope for\
    \ a nondisruptive transition than cases in which the\n   client on its own shifts\
    \ its access to another replica (i.e.,\n   replication).  This issue potentially\
    \ applies to locking state and to\n   session state, which are dealt with below\
    \ as follows:\n   *  An introduction to the possible means of providing continuity\
    \ in\n      these areas appears in Section 11.11.9 below.\n   *  Transparent State\
    \ Migration is introduced in Section 11.12.  The\n      possible transfer of session\
    \ state is addressed there as well.\n   *  The client handling of transitions,\
    \ including determining how to\n      deal with the various means that the server\
    \ might take to supply\n      effective continuity of locking state, is discussed\
    \ in\n      Section 11.13.\n   *  The source and destination servers' responsibilities\
    \ in effecting\n      Transparent State Migration of locking and session state\
    \ are\n      discussed in Section 11.14.\n"
- title: 11.11.1.  File System Transitions and Simultaneous Access
  contents:
  - "11.11.1.  File System Transitions and Simultaneous Access\n   The fs_locations_info\
    \ attribute (described in Section 11.17) may\n   indicate that two replicas may\
    \ be used simultaneously, although some\n   situations in which such simultaneous\
    \ access is permitted are more\n   appropriately described as instances of trunking\
    \ (see\n   Section 11.5.4.1).  Although situations in which multiple replicas\n\
    \   may be accessed simultaneously are somewhat similar to those in which\n  \
    \ a single replica is accessed by multiple network addresses, there are\n   important\
    \ differences since locking state is not shared among\n   multiple replicas.\n\
    \   Because of this difference in state handling, many clients will not\n   have\
    \ the ability to take advantage of the fact that such replicas\n   represent the\
    \ same data.  Such clients will not be prepared to use\n   multiple replicas simultaneously\
    \ but will access each file system\n   using only a single replica, although the\
    \ replica selected might make\n   multiple server-trunkable addresses available.\n\
    \   Clients who are prepared to use multiple replicas simultaneously can\n   divide\
    \ opens among replicas however they choose.  Once that choice is\n   made, any\
    \ subsequent transitions will treat the set of locking state\n   associated with\
    \ each replica as a single entity.\n   For example, if one of the replicas become\
    \ unavailable, access will\n   be transferred to a different replica, which is\
    \ also capable of\n   simultaneous access with the one still in use.\n   When\
    \ there is no such replica, the transition may be to the replica\n   already in\
    \ use.  At this point, the client has a choice between\n   merging the locking\
    \ state for the two replicas under the aegis of the\n   sole replica in use or\
    \ treating these separately until another\n   replica capable of simultaneous\
    \ access presents itself.\n"
- title: 11.11.2.  Filehandles and File System Transitions
  contents:
  - "11.11.2.  Filehandles and File System Transitions\n   There are a number of ways\
    \ in which filehandles can be handled across\n   a file system transition.  These\
    \ can be divided into two broad\n   classes depending upon whether the two file\
    \ systems across which the\n   transition happens share sufficient state to effect\
    \ some sort of\n   continuity of file system handling.\n   When there is no such\
    \ cooperation in filehandle assignment, the two\n   file systems are reported\
    \ as being in different handle classes.  In\n   this case, all filehandles are\
    \ assumed to expire as part of the file\n   system transition.  Note that this\
    \ behavior does not depend on the\n   fh_expire_type attribute and supersedes\
    \ the specification of the\n   FH4_VOL_MIGRATION bit, which only affects behavior\
    \ when\n   fs_locations_info is not available.\n   When there is cooperation in\
    \ filehandle assignment, the two file\n   systems are reported as being in the\
    \ same handle classes.  In this\n   case, persistent filehandles remain valid\
    \ after the file system\n   transition, while volatile filehandles (excluding\
    \ those that are only\n   volatile due to the FH4_VOL_MIGRATION bit) are subject\
    \ to expiration\n   on the target server.\n"
- title: 11.11.3.  Fileids and File System Transitions
  contents:
  - "11.11.3.  Fileids and File System Transitions\n   In NFSv4.0, the issue of continuity\
    \ of fileids in the event of a file\n   system transition was not addressed. \
    \ The general expectation had\n   been that in situations in which the two file\
    \ system instances are\n   created by a single vendor using some sort of file\
    \ system image copy,\n   fileids would be consistent across the transition, while\
    \ in the\n   analogous multi-vendor transitions they would not.  This poses\n\
    \   difficulties, especially for the client without special knowledge of\n   the\
    \ transition mechanisms adopted by the server.  Note that although\n   fileid\
    \ is not a REQUIRED attribute, many servers support fileids and\n   many clients\
    \ provide APIs that depend on fileids.\n   It is important to note that while\
    \ clients themselves may have no\n   trouble with a fileid changing as a result\
    \ of a file system\n   transition event, applications do typically have access\
    \ to the fileid\n   (e.g., via stat).  The result is that an application may work\n\
    \   perfectly well if there is no file system instance transition or if\n   any\
    \ such transition is among instances created by a single vendor,\n   yet be unable\
    \ to deal with the situation in which a multi-vendor\n   transition occurs at\
    \ the wrong time.\n   Providing the same fileids in a multi-vendor (multiple server\n\
    \   vendors) environment has generally been held to be quite difficult.\n   While\
    \ there is work to be done, it needs to be pointed out that this\n   difficulty\
    \ is partly self-imposed.  Servers have typically identified\n   fileid with inode\
    \ number, i.e. with a quantity used to find the file\n   in question.  This identification\
    \ poses special difficulties for\n   migration of a file system between vendors\
    \ where assigning the same\n   index to a given file may not be possible.  Note\
    \ here that a fileid\n   is not required to be useful to find the file in question,\
    \ only that\n   it is unique within the given file system.  Servers prepared to\n\
    \   accept a fileid as a single piece of metadata and store it apart from\n  \
    \ the value used to index the file information can relatively easily\n   maintain\
    \ a fileid value across a migration event, allowing a truly\n   transparent migration\
    \ event.\n   In any case, where servers can provide continuity of fileids, they\n\
    \   should, and the client should be able to find out that such\n   continuity\
    \ is available and take appropriate action.  Information\n   about the continuity\
    \ (or lack thereof) of fileids across a file\n   system transition is represented\
    \ by specifying whether the file\n   systems in question are of the same fileid\
    \ class.\n   Note that when consistent fileids do not exist across a transition\n\
    \   (either because there is no continuity of fileids or because fileid\n   is\
    \ not a supported attribute on one of instances involved), and there\n   are no\
    \ reliable filehandles across a transition event (either because\n   there is\
    \ no filehandle continuity or because the filehandles are\n   volatile), the client\
    \ is in a position where it cannot verify that\n   files it was accessing before\
    \ the transition are the same objects.\n   It is forced to assume that no object\
    \ has been renamed, and, unless\n   there are guarantees that provide this (e.g.,\
    \ the file system is\n   read-only), problems for applications may occur.  Therefore,\
    \ use of\n   such configurations should be limited to situations where the\n \
    \  problems that this may cause can be tolerated.\n"
- title: 11.11.4.  Fsids and File System Transitions
  contents:
  - "11.11.4.  Fsids and File System Transitions\n   Since fsids are generally only\
    \ unique on a per-server basis, it is\n   likely that they will change during\
    \ a file system transition.\n   Clients should not make the fsids received from\
    \ the server visible to\n   applications since they may not be globally unique,\
    \ and because they\n   may change during a file system transition event.  Applications\
    \ are\n   best served if they are isolated from such transitions to the extent\n\
    \   possible.\n   Although normally a single source file system will transition\
    \ to a\n   single target file system, there is a provision for splitting a\n \
    \  single source file system into multiple target file systems, by\n   specifying\
    \ the FSLI4F_MULTI_FS flag.\n"
- title: 11.11.4.1.  File System Splitting
  contents:
  - "11.11.4.1.  File System Splitting\n   When a file system transition is made and\
    \ the fs_locations_info\n   indicates that the file system in question might be\
    \ split into\n   multiple file systems (via the FSLI4F_MULTI_FS flag), the client\n\
    \   SHOULD do GETATTRs to determine the fsid attribute on all known\n   objects\
    \ within the file system undergoing transition to determine the\n   new file system\
    \ boundaries.\n   Clients might choose to maintain the fsids passed to existing\n\
    \   applications by mapping all of the fsids for the descendant file\n   systems\
    \ to the common fsid used for the original file system.\n   Splitting a file system\
    \ can be done on a transition between file\n   systems of the same fileid class,\
    \ since the fact that fileids are\n   unique within the source file system ensure\
    \ they will be unique in\n   each of the target file systems.\n"
- title: 11.11.5.  The Change Attribute and File System Transitions
  contents:
  - "11.11.5.  The Change Attribute and File System Transitions\n   Since the change\
    \ attribute is defined as a server-specific one,\n   change attributes fetched\
    \ from one server are normally presumed to be\n   invalid on another server. \
    \ Such a presumption is troublesome since\n   it would invalidate all cached change\
    \ attributes, requiring\n   refetching.  Even more disruptive, the absence of\
    \ any assured\n   continuity for the change attribute means that even if the same\
    \ value\n   is retrieved on refetch, no conclusions can be drawn as to whether\n\
    \   the object in question has changed.  The identical change attribute\n   could\
    \ be merely an artifact of a modified file with a different\n   change attribute\
    \ construction algorithm, with that new algorithm just\n   happening to result\
    \ in an identical change value.\n   When the two file systems have consistent\
    \ change attribute formats,\n   and this fact is communicated to the client by\
    \ reporting in the same\n   change class, the client may assume a continuity of\
    \ change attribute\n   construction and handle this situation just as it would\
    \ be handled\n   without any file system transition.\n"
- title: 11.11.6.  Write Verifiers and File System Transitions
  contents:
  - "11.11.6.  Write Verifiers and File System Transitions\n   In a file system transition,\
    \ the two file systems might be\n   cooperating in the handling of unstably written\
    \ data.  Clients can\n   determine if this is the case by seeing if the two file\
    \ systems\n   belong to the same write-verifier class.  When this is the case,\n\
    \   write verifiers returned from one system may be compared to those\n   returned\
    \ by the other and superfluous writes can be avoided.\n   When two file systems\
    \ belong to different write-verifier classes, any\n   verifier generated by one\
    \ must not be compared to one provided by the\n   other.  Instead, the two verifiers\
    \ should be treated as not equal\n   even when the values are identical.\n"
- title: 11.11.7.  READDIR Cookies and Verifiers and File System Transitions
  contents:
  - "11.11.7.  READDIR Cookies and Verifiers and File System Transitions\n   In a\
    \ file system transition, the two file systems might be consistent\n   in their\
    \ handling of READDIR cookies and verifiers.  Clients can\n   determine if this\
    \ is the case by seeing if the two file systems\n   belong to the same readdir\
    \ class.  When this is the case, readdir\n   class, READDIR cookies, and verifiers\
    \ from one system will be\n   recognized by the other, and READDIR operations\
    \ started on one server\n   can be validly continued on the other simply by presenting\
    \ the cookie\n   and verifier returned by a READDIR operation done on the first\
    \ file\n   system to the second.\n   When two file systems belong to different\
    \ readdir classes, any\n   READDIR cookie and verifier generated by one is not\
    \ valid on the\n   second and must not be presented to that server by the client.\
    \  The\n   client should act as if the verifier were rejected.\n"
- title: 11.11.8.  File System Data and File System Transitions
  contents:
  - "11.11.8.  File System Data and File System Transitions\n   When multiple replicas\
    \ exist and are used simultaneously or in\n   succession by a client, applications\
    \ using them will normally expect\n   that they contain either the same data or\
    \ data that is consistent\n   with the normal sorts of changes that are made by\
    \ other clients\n   updating the data of the file system (with metadata being\
    \ the same to\n   the degree indicated by the fs_locations_info attribute).  However,\n\
    \   when multiple file systems are presented as replicas of one another,\n   the\
    \ precise relationship between the data of one and the data of\n   another is\
    \ not, as a general matter, specified by the NFSv4.1\n   protocol.  It is quite\
    \ possible to present as replicas file systems\n   where the data of those file\
    \ systems is sufficiently different that\n   some applications have problems dealing\
    \ with the transition between\n   replicas.  The namespace will typically be constructed\
    \ so that\n   applications can choose an appropriate level of support, so that\
    \ in\n   one position in the namespace, a varied set of replicas might be\n  \
    \ listed, while in another, only those that are up-to-date would be\n   considered\
    \ replicas.  The protocol does define three special cases of\n   the relationship\
    \ among replicas to be specified by the server and\n   relied upon by clients:\n\
    \   *  When multiple replicas exist and are used simultaneously by a\n      client\
    \ (see the FSLIB4_CLSIMUL definition within\n      fs_locations_info), they must\
    \ designate the same data.  Where file\n      systems are writable, a change made\
    \ on one instance must be\n      visible on all instances at the same time, regardless\
    \ of whether\n      the interrogated instance is the one on which the modification\
    \ was\n      done.  This allows a client to use these replicas simultaneously\n\
    \      without any special adaptation to the fact that there are multiple\n  \
    \    replicas, beyond adapting to the fact that locks obtained on one\n      replica\
    \ are maintained separately (i.e., under a different client\n      ID).  In this\
    \ case, locks (whether share reservations or byte-\n      range locks) and delegations\
    \ obtained on one replica are\n      immediately reflected on all replicas, in\
    \ the sense that access\n      from all other servers is prevented regardless\
    \ of the replica\n      used.  However, because the servers are not required to\
    \ treat two\n      associated client IDs as representing the same client, it is\
    \ best\n      to access each file using only a single client ID.\n   *  When one\
    \ replica is designated as the successor instance to\n      another existing instance\
    \ after the return of NFS4ERR_MOVED (i.e.,\n      the case of migration), the\
    \ client may depend on the fact that all\n      changes written to stable storage\
    \ on the original instance are\n      written to stable storage of the successor\
    \ (uncommitted writes are\n      dealt with in Section 11.11.6 above).\n   * \
    \ Where a file system is not writable but represents a read-only\n      copy (possibly\
    \ periodically updated) of a writable file system,\n      clients have similar\
    \ requirements with regard to the propagation\n      of updates.  They may need\
    \ a guarantee that any change visible on\n      the original file system instance\
    \ must be immediately visible on\n      any replica before the client transitions\
    \ access to that replica,\n      in order to avoid any possibility that a client,\
    \ in effecting a\n      transition to a replica, will see any reversion in file\
    \ system\n      state.  The specific means of this guarantee varies based on the\n\
    \      value of the fss_type field that is reported as part of the\n      fs_status\
    \ attribute (see Section 11.18).  Since these file systems\n      are presumed\
    \ to be unsuitable for simultaneous use, there is no\n      specification of how\
    \ locking is handled; in general, locks\n      obtained on one file system will\
    \ be separate from those on others.\n      Since these are expected to be read-only\
    \ file systems, this is not\n      likely to pose an issue for clients or applications.\n\
    \   When none of these special situations applies, there is no basis\n   within\
    \ the protocol for the client to make assumptions about the\n   contents of a\
    \ replica file system or its relationship to previous\n   file system instances.\
    \  Thus, switching between nominally identical\n   read-write file systems would\
    \ not be possible because either the\n   client does not use the fs_locations_info\
    \ attribute, or the server\n   does not support it.\n"
- title: 11.11.9.  Lock State and File System Transitions
  contents:
  - "11.11.9.  Lock State and File System Transitions\n   While accessing a file system,\
    \ clients obtain locks enforced by the\n   server, which may prevent actions by\
    \ other clients that are\n   inconsistent with those locks.\n   When access is\
    \ transferred between replicas, clients need to be\n   assured that the actions\
    \ disallowed by holding these locks cannot\n   have occurred during the transition.\
    \  This can be ensured by the\n   methods below.  Unless at least one of these\
    \ is implemented, clients\n   will not be assured of continuity of lock possession\
    \ across a\n   migration event:\n   *  Providing the client an opportunity to\
    \ re-obtain his locks via a\n      per-fs grace period on the destination server,\
    \ denying all clients\n      using the destination file system the opportunity\
    \ to obtain new\n      locks that conflict with those held by the transferred\
    \ client as\n      long as that client has not completed its per-fs grace period.\n\
    \      Because the lock reclaim mechanism was originally defined to\n      support\
    \ server reboot, it implicitly assumes that filehandles\n      will, upon reclaim,\
    \ be the same as those at open.  In the case of\n      migration, this requires\
    \ that source and destination servers use\n      the same filehandles, as evidenced\
    \ by using the same server scope\n      (see Section 2.10.4) or by showing this\
    \ agreement using\n      fs_locations_info (see Section 11.11.2 above).\n    \
    \  Note that such a grace period can be implemented without\n      interfering\
    \ with the ability of non-transferred clients to obtain\n      new locks while\
    \ it is going on.  As long as the destination server\n      is aware of the transferred\
    \ locks, it can distinguish requests to\n      obtain new locks that contrast\
    \ with existing locks from those that\n      do not, allowing it to treat such\
    \ client requests without\n      reference to the ongoing grace period.\n   *\
    \  Locking state can be transferred as part of the transition by\n      providing\
    \ Transparent State Migration as described in\n      Section 11.12.\n   Of these,\
    \ Transparent State Migration provides the smoother\n   experience for clients\
    \ in that there is no need to go through a\n   reclaim process before new locks\
    \ can be obtained; however, it\n   requires a greater degree of inter-server coordination.\
    \  In general,\n   the servers taking part in migration are free to provide either\n\
    \   facility.  However, when the filehandles can differ across the\n   migration\
    \ event, Transparent State Migration is the only available\n   means of providing\
    \ the needed functionality.\n   It should be noted that these two methods are\
    \ not mutually exclusive\n   and that a server might well provide both.  In particular,\
    \ if there\n   is some circumstance preventing a specific lock from being\n  \
    \ transferred transparently, the destination server can allow it to be\n   reclaimed\
    \ by implementing a per-fs grace period for the migrated file\n   system.\n"
- title: 11.11.9.1.  Security Consideration Related to Reclaiming Lock State
  contents:
  - "11.11.9.1.  Security Consideration Related to Reclaiming Lock State\n       \
    \     after File System Transitions\n   Although it is possible for a client reclaiming\
    \ state to misrepresent\n   its state in the same fashion as described in Section\
    \ 8.4.2.1.1, most\n   implementations providing for such reclamation in the case\
    \ of file\n   system transitions will have the ability to detect such\n   misrepresentations.\
    \  This limits the ability of unauthenticated\n   clients to execute denial-of-service\
    \ attacks in these circumstances.\n   Nevertheless, the rules stated in Section\
    \ 8.4.2.1.1 regarding\n   principal verification for reclaim requests apply in\
    \ this situation\n   as well.\n   Typically, implementations that support file\
    \ system transitions will\n   have extensive information about the locks to be\
    \ transferred.  This\n   is because of the following:\n   *  Since failure is\
    \ not involved, there is no need to store locking\n      information in persistent\
    \ storage.\n   *  There is no need, as there is in the failure case, to update\n\
    \      multiple repositories containing locking state to keep them in\n      sync.\
    \  Instead, there is a one-time communication of locking state\n      from the\
    \ source to the destination server.\n   *  Providing this information avoids potential\
    \ interference with\n      existing clients using the destination file system\
    \ by denying them\n      the ability to obtain new locks during the grace period.\n\
    \   When such detailed locking information, not necessarily including the\n  \
    \ associated stateids, is available:\n   *  It is possible to detect reclaim requests\
    \ that attempt to reclaim\n      locks that did not exist before the transfer,\
    \ rejecting them with\n      NFS4ERR_RECLAIM_BAD (Section 15.1.9.4).\n   *  It\
    \ is possible when dealing with non-reclaim requests, to\n      determine whether\
    \ they conflict with existing locks, eliminating\n      the need to return NFS4ERR_GRACE\
    \ (Section 15.1.9.2) on non-reclaim\n      requests.\n   It is possible for implementations\
    \ of grace periods in connection\n   with file system transitions not to have\
    \ detailed locking information\n   available at the destination server, in which\
    \ case, the security\n   situation is exactly as described in Section 8.4.2.1.1.\n"
- title: 11.11.9.2.  Leases and File System Transitions
  contents:
  - "11.11.9.2.  Leases and File System Transitions\n   In the case of lease renewal,\
    \ the client may not be submitting\n   requests for a file system that has been\
    \ transferred to another\n   server.  This can occur because of the lease renewal\
    \ mechanism.  The\n   client renews the lease associated with all file systems\
    \ when\n   submitting a request on an associated session, regardless of the\n\
    \   specific file system being referenced.\n   In order for the client to schedule\
    \ renewal of its lease where there\n   is locking state that may have been relocated\
    \ to the new server, the\n   client must find out about lease relocation before\
    \ that lease expire.\n   To accomplish this, the SEQUENCE operation will return\
    \ the status bit\n   SEQ4_STATUS_LEASE_MOVED if responsibility for any of the\
    \ renewed\n   locking state has been transferred to a new server.  This will\n\
    \   continue until the client receives an NFS4ERR_MOVED error for each of\n  \
    \ the file systems for which there has been locking state relocation.\n   When\
    \ a client receives an SEQ4_STATUS_LEASE_MOVED indication from a\n   server, for\
    \ each file system of the server for which the client has\n   locking state, the\
    \ client should perform an operation.  For\n   simplicity, the client may choose\
    \ to reference all file systems, but\n   what is important is that it must reference\
    \ all file systems for\n   which there was locking state where that state has\
    \ moved.  Once the\n   client receives an NFS4ERR_MOVED error for each such file\
    \ system, the\n   server will clear the SEQ4_STATUS_LEASE_MOVED indication.  The\
    \ client\n   can terminate the process of checking file systems once this\n  \
    \ indication is cleared (but only if the client has received a reply\n   for all\
    \ outstanding SEQUENCE requests on all sessions it has with the\n   server), since\
    \ there are no others for which locking state has moved.\n   A client may use\
    \ GETATTR of the fs_status (or fs_locations_info)\n   attribute on all of the\
    \ file systems to get absence indications in a\n   single (or a few) request(s),\
    \ since absent file systems will not\n   cause an error in this context.  However,\
    \ it still must do an\n   operation that receives NFS4ERR_MOVED on each file system,\
    \ in order\n   to clear the SEQ4_STATUS_LEASE_MOVED indication.\n   Once the set\
    \ of file systems with transferred locking state has been\n   determined, the\
    \ client can follow the normal process to obtain the\n   new server information\
    \ (through the fs_locations and\n   fs_locations_info attributes) and perform\
    \ renewal of that lease on\n   the new server, unless information in the fs_locations_info\
    \ attribute\n   shows that no state could have been transferred.  If the server\
    \ has\n   not had state transferred to it transparently, the client will\n   receive\
    \ NFS4ERR_STALE_CLIENTID from the new server, as described\n   above, and the\
    \ client can then reclaim locks as is done in the event\n   of server failure.\n"
- title: 11.11.9.3.  Transitions and the Lease_time Attribute
  contents:
  - "11.11.9.3.  Transitions and the Lease_time Attribute\n   In order that the client\
    \ may appropriately manage its lease in the\n   case of a file system transition,\
    \ the destination server must\n   establish proper values for the lease_time attribute.\n\
    \   When state is transferred transparently, that state should include\n   the\
    \ correct value of the lease_time attribute.  The lease_time\n   attribute on\
    \ the destination server must never be less than that on\n   the source, since\
    \ this would result in premature expiration of a\n   lease granted by the source\
    \ server.  Upon transitions in which state\n   is transferred transparently, the\
    \ client is under no obligation to\n   refetch the lease_time attribute and may\
    \ continue to use the value\n   previously fetched (on the source server).\n \
    \  If state has not been transferred transparently, either because the\n   associated\
    \ servers are shown as having different eir_server_scope\n   strings or because\
    \ the client ID is rejected when presented to the\n   new server, the client should\
    \ fetch the value of lease_time on the\n   new (i.e., destination) server, and\
    \ use it for subsequent locking\n   requests.  However, the server must respect\
    \ a grace period of at\n   least as long as the lease_time on the source server,\
    \ in order to\n   ensure that clients have ample time to reclaim their lock before\n\
    \   potentially conflicting non-reclaimed locks are granted.\n"
- title: 11.12.  Transferring State upon Migration
  contents:
  - "11.12.  Transferring State upon Migration\n   When the transition is a result\
    \ of a server-initiated decision to\n   transition access, and the source and\
    \ destination servers have\n   implemented appropriate cooperation, it is possible\
    \ to do the\n   following:\n   *  Transfer locking state from the source to the\
    \ destination server\n      in a fashion similar to that provided by Transparent\
    \ State\n      Migration in NFSv4.0, as described in [69].  Server\n      responsibilities\
    \ are described in Section 11.14.2.\n   *  Transfer session state from the source\
    \ to the destination server.\n      Server responsibilities in effecting such\
    \ a transfer are described\n      in Section 11.14.3.\n   The means by which the\
    \ client determines which of these transfer\n   events has occurred are described\
    \ in Section 11.13.\n"
- title: 11.12.1.  Transparent State Migration and pNFS
  contents:
  - "11.12.1.  Transparent State Migration and pNFS\n   When pNFS is involved, the\
    \ protocol is capable of supporting:\n   *  Migration of the Metadata Server (MDS),\
    \ leaving the Data Servers\n      (DSs) in place.\n   *  Migration of the file\
    \ system as a whole, including the MDS and\n      associated DSs.\n   *  Replacement\
    \ of one DS by another.\n   *  Migration of a pNFS file system to one in which\
    \ pNFS is not used.\n   *  Migration of a file system not using pNFS to one in\
    \ which layouts\n      are available.\n   Note that migration, per se, is only\
    \ involved in the transfer of the\n   MDS function.  Although the servicing of\
    \ a layout may be transferred\n   from one data server to another, this not done\
    \ using the file system\n   location attributes.  The MDS can effect such transfers\
    \ by recalling\n   or revoking existing layouts and granting new ones on a different\n\
    \   data server.\n   Migration of the MDS function is directly supported by Transparent\n\
    \   State Migration.  Layout state will normally be transparently\n   transferred,\
    \ just as other state is.  As a result, Transparent State\n   Migration provides\
    \ a framework in which, given appropriate inter-MDS\n   data transfer, one MDS\
    \ can be substituted for another.\n   Migration of the file system function as\
    \ a whole can be accomplished\n   by recalling all layouts as part of the initial\
    \ phase of the\n   migration process.  As a result, I/O will be done through the\
    \ MDS\n   during the migration process, and new layouts can be granted once the\n\
    \   client is interacting with the new MDS.  An MDS can also effect this\n   sort\
    \ of transition by revoking all layouts as part of Transparent\n   State Migration,\
    \ as long as the client is notified about the loss of\n   locking state.\n   In\
    \ order to allow migration to a file system on which pNFS is not\n   supported,\
    \ clients need to be prepared for a situation in which\n   layouts are not available\
    \ or supported on the destination file system\n   and so direct I/O requests to\
    \ the destination server, rather than\n   depending on layouts being available.\n\
    \   Replacement of one DS by another is not addressed by migration as\n   such\
    \ but can be effected by an MDS recalling layouts for the DS to be\n   replaced\
    \ and issuing new ones to be served by the successor DS.\n   Migration may transfer\
    \ a file system from a server that does not\n   support pNFS to one that does.\
    \  In order to properly adapt to this\n   situation, clients that support pNFS,\
    \ but function adequately in its\n   absence, should check for pNFS support when\
    \ a file system is migrated\n   and be prepared to use pNFS when support is available\
    \ on the\n   destination.\n"
- title: 11.13.  Client Responsibilities When Access Is Transitioned
  contents:
  - "11.13.  Client Responsibilities When Access Is Transitioned\n   For a client\
    \ to respond to an access transition, it must become aware\n   of it.  The ways\
    \ in which this can happen are discussed in\n   Section 11.13.1, which discusses\
    \ indications that a specific file\n   system access path has transitioned as\
    \ well as situations in which\n   additional activity is necessary to determine\
    \ the set of file systems\n   that have been migrated.  Section 11.13.2 goes on\
    \ to complete the\n   discussion of how the set of migrated file systems might\
    \ be\n   determined.  Sections 11.13.3 through 11.13.5 discuss how the client\n\
    \   should deal with each transition it becomes aware of, either directly\n  \
    \ or as a result of migration discovery.\n   The following terms are used to describe\
    \ client activities:\n   *  \"Transition recovery\" refers to the process of restoring\
    \ access to\n      a file system on which NFS4ERR_MOVED was received.\n   *  \"\
    Migration recovery\" refers to that subset of transition recovery\n      that\
    \ applies when the file system has migrated to a different\n      replica.\n \
    \  *  \"Migration discovery\" refers to the process of determining which\n   \
    \   file system(s) have been migrated.  It is necessary to avoid a\n      situation\
    \ in which leases could expire when a file system is not\n      accessed for a\
    \ long period of time, since a client unaware of the\n      migration might be\
    \ referencing an unmigrated file system and not\n      renewing the lease associated\
    \ with the migrated file system.\n"
- title: 11.13.1.  Client Transition Notifications
  contents:
  - "11.13.1.  Client Transition Notifications\n   When there is a change in the network\
    \ access path that a client is to\n   use to access a file system, there are a\
    \ number of related status\n   indications with which clients need to deal:\n\
    \   *  If an attempt is made to use or return a filehandle within a file\n   \
    \   system that is no longer accessible at the address previously used\n     \
    \ to access it, the error NFS4ERR_MOVED is returned.\n      Exceptions are made\
    \ to allow such filehandles to be used when\n      interrogating a file system\
    \ location attribute.  This enables a\n      client to determine a new replica's\
    \ location or a new network\n      access path.\n      This condition continues\
    \ on subsequent attempts to access the file\n      system in question.  The only\
    \ way the client can avoid the error\n      is to cease accessing the file system\
    \ in question at its old\n      server location and access it instead using a\
    \ different address at\n      which it is now available.\n   *  Whenever a client\
    \ sends a SEQUENCE operation to a server that\n      generated state held on that\
    \ client and associated with a file\n      system no longer accessible on that\
    \ server, the response will\n      contain the status bit SEQ4_STATUS_LEASE_MOVED,\
    \ indicating that\n      there has been a lease migration.\n      This condition\
    \ continues until the client acknowledges the\n      notification by fetching\
    \ a file system location attribute for the\n      file system whose network access\
    \ path is being changed.  When\n      there are multiple such file systems, a\
    \ location attribute for\n      each such file system needs to be fetched.  The\
    \ location attribute\n      for all migrated file systems needs to be fetched\
    \ in order to\n      clear the condition.  Even after the condition is cleared,\
    \ the\n      client needs to respond by using the location information to\n  \
    \    access the file system at its new location to ensure that leases\n      are\
    \ not needlessly expired.\n   Unlike NFSv4.0, in which the corresponding conditions\
    \ are both errors\n   and thus mutually exclusive, in NFSv4.1 the client can,\
    \ and often\n   will, receive both indications on the same request.  As a result,\n\
    \   implementations need to address the question of how to coordinate the\n  \
    \ necessary recovery actions when both indications arrive in the\n   response\
    \ to the same request.  It should be noted that when\n   processing an NFSv4 COMPOUND,\
    \ the server will normally decide whether\n   SEQ4_STATUS_LEASE_MOVED is to be\
    \ set before it determines which file\n   system will be referenced or whether\
    \ NFS4ERR_MOVED is to be returned.\n   Since these indications are not mutually\
    \ exclusive in NFSv4.1, the\n   following combinations are possible results when\
    \ a COMPOUND is\n   issued:\n   *  The COMPOUND status is NFS4ERR_MOVED, and SEQ4_STATUS_LEASE_MOVED\n\
    \      is asserted.\n      In this case, transition recovery is required.  While\
    \ it is\n      possible that migration discovery is needed in addition, it is\n\
    \      likely that only the accessed file system has transitioned.  In\n     \
    \ any case, because addressing NFS4ERR_MOVED is necessary to allow\n      the\
    \ rejected requests to be processed on the target, dealing with\n      it will\
    \ typically have priority over migration discovery.\n   *  The COMPOUND status\
    \ is NFS4ERR_MOVED, and SEQ4_STATUS_LEASE_MOVED\n      is clear.\n      In this\
    \ case, transition recovery is also required.  It is clear\n      that migration\
    \ discovery is not needed to find file systems that\n      have been migrated\
    \ other than the one returning NFS4ERR_MOVED.\n      Cases in which this result\
    \ can arise include a referral or a\n      migration for which there is no associated\
    \ locking state.  This\n      can also arise in cases in which an access path\
    \ transition other\n      than migration occurs within the same server.  In such\
    \ a case,\n      there is no need to set SEQ4_STATUS_LEASE_MOVED, since the lease\n\
    \      remains associated with the current server even though the access\n   \
    \   path has changed.\n   *  The COMPOUND status is not NFS4ERR_MOVED, and\n \
    \     SEQ4_STATUS_LEASE_MOVED is asserted.\n      In this case, no transition\
    \ recovery activity is required on the\n      file system(s) accessed by the request.\
    \  However, to prevent\n      avoidable lease expiration, migration discovery\
    \ needs to be done.\n   *  The COMPOUND status is not NFS4ERR_MOVED, and\n   \
    \   SEQ4_STATUS_LEASE_MOVED is clear.\n      In this case, neither transition-related\
    \ activity nor migration\n      discovery is required.\n   Note that the specified\
    \ actions only need to be taken if they are not\n   already going on.  For example,\
    \ when NFS4ERR_MOVED is received while\n   accessing a file system for which transition\
    \ recovery is already\n   occurring, the client merely waits for that recovery\
    \ to be completed,\n   while the receipt of the SEQ4_STATUS_LEASE_MOVED indication\
    \ only\n   needs to initiate migration discovery for a server if such discovery\n\
    \   is not already underway for that server.\n   The fact that a lease-migrated\
    \ condition does not result in an error\n   in NFSv4.1 has a number of important\
    \ consequences.  In addition to\n   the fact that the two indications are not\
    \ mutually exclusive, as\n   discussed above, there are number of issues that\
    \ are important in\n   considering implementation of migration discovery, as discussed\
    \ in\n   Section 11.13.2.\n   Because SEQ4_STATUS_LEASE_MOVED is not an error\
    \ condition, it is\n   possible for file systems whose access paths have not changed\
    \ to be\n   successfully accessed on a given server even though recovery is\n\
    \   necessary for other file systems on the same server.  As a result,\n   access\
    \ can take place while:\n   *  The migration discovery process is happening for\
    \ that server.\n   *  The transition recovery process is happening for other file\n\
    \      systems connected to that server.\n"
- title: 11.13.2.  Performing Migration Discovery
  contents:
  - "11.13.2.  Performing Migration Discovery\n   Migration discovery can be performed\
    \ in the same context as\n   transition recovery, allowing recovery for each migrated\
    \ file system\n   to be invoked as it is discovered.  Alternatively, it may be\
    \ done in\n   a separate migration discovery thread, allowing migration discovery\n\
    \   to be done in parallel with one or more instances of transition\n   recovery.\n\
    \   In either case, because the lease-migrated indication does not result\n  \
    \ in an error, other access to file systems on the server can proceed\n   normally,\
    \ with the possibility that further such indications will be\n   received, raising\
    \ the issue of how such indications are to be dealt\n   with.  In general:\n \
    \  *  No action needs to be taken for such indications received by any\n     \
    \ threads performing migration discovery, since continuation of that\n      work\
    \ will address the issue.\n   *  In other cases in which migration discovery is\
    \ currently being\n      performed, nothing further needs to be done to respond\
    \ to such\n      lease migration indications, as long as one can be certain that\n\
    \      the migration discovery process would deal with those indications.\n  \
    \    See below for details.\n   *  For such indications received in all other\
    \ contexts, the\n      appropriate response is to initiate or otherwise provide\
    \ for the\n      execution of migration discovery for file systems associated\
    \ with\n      the server IP address returning the indication.\n   This leaves\
    \ a potential difficulty in situations in which the\n   migration discovery process\
    \ is near to completion but is still\n   operating.  One should not ignore a SEQ4_STATUS_LEASE_MOVED\n\
    \   indication if the migration discovery process is not able to respond\n   to\
    \ the discovery of additional migrating file systems without\n   additional aid.\
    \  A further complexity relevant in addressing such\n   situations is that a lease-migrated\
    \ indication may reflect the\n   server's state at the time the SEQUENCE operation\
    \ was processed,\n   which may be different from that in effect at the time the\
    \ response\n   is received.  Because new migration events may occur at any time,\
    \ and\n   because a SEQ4_STATUS_LEASE_MOVED indication may reflect the\n   situation\
    \ in effect a considerable time before the indication is\n   received, special\
    \ care needs to be taken to ensure that\n   SEQ4_STATUS_LEASE_MOVED indications\
    \ are not inappropriately ignored.\n   A useful approach to this issue involves\
    \ the use of separate\n   externally-visible migration discovery states for each\
    \ server.\n   Separate values could represent the various possible states for\
    \ the\n   migration discovery process for a server:\n   *  Non-operation, in which\
    \ migration discovery is not being\n      performed.\n   *  Normal operation,\
    \ in which there is an ongoing scan for migrated\n      file systems.\n   *  Completion/verification\
    \ of migration discovery processing, in\n      which the possible completion of\
    \ migration discovery processing\n      needs to be verified.\n   Given that framework,\
    \ migration discovery processing would proceed as\n   follows:\n   *  While in\
    \ the normal-operation state, the thread performing\n      discovery would fetch,\
    \ for successive file systems known to the\n      client on the server being worked\
    \ on, a file system location\n      attribute plus the fs_status attribute.\n\
    \   *  If the fs_status attribute indicates that the file system is a\n      migrated\
    \ one (i.e., fss_absent is true, and fss_type !=\n      STATUS4_REFERRAL), then\
    \ a migrated file system has been found.  In\n      this situation, it is likely\
    \ that the fetch of the file system\n      location attribute has cleared one\
    \ of the file systems\n      contributing to the lease-migrated indication.\n\
    \   *  In cases in which that happened, the thread cannot know whether\n     \
    \ the lease-migrated indication has been cleared, and so it enters\n      the\
    \ completion/verification state and proceeds to issue a COMPOUND\n      to see\
    \ if the SEQ4_STATUS_LEASE_MOVED indication has been cleared.\n   *  When the\
    \ discovery process is in the completion/verification\n      state, if other requests\
    \ get a lease-migrated indication, they\n      note that it was received.  Later,\
    \ the existence of such\n      indications is used when the request completes,\
    \ as described\n      below.\n   When the request used in the completion/verification\
    \ state completes:\n   *  If a lease-migrated indication is returned, the discovery\n\
    \      continues normally.  Note that this is so even if all file systems\n  \
    \    have been traversed, since new migrations could have occurred\n      while\
    \ the process was going on.\n   *  Otherwise, if there is any record that other\
    \ requests saw a lease-\n      migrated indication while the request was occurring,\
    \ that record\n      is cleared, and the verification request is retried.  The\n\
    \      discovery process remains in the completion/verification state.\n   * \
    \ If there have been no lease-migrated indications, the work of\n      migration\
    \ discovery is considered completed, and it enters the\n      non-operating state.\
    \  Once it enters this state, subsequent lease-\n      migrated indications will\
    \ trigger a new migration discovery\n      process.\n   It should be noted that\
    \ the process described above is not guaranteed\n   to terminate, as a long series\
    \ of new migration events might\n   continually delay the clearing of the SEQ4_STATUS_LEASE_MOVED\n\
    \   indication.  To prevent unnecessary lease expiration, it is\n   appropriate\
    \ for clients to use the discovery of migrations to effect\n   lease renewal immediately,\
    \ rather than waiting for the clearing of\n   the SEQ4_STATUS_LEASE_MOVED indication\
    \ when the complete set of\n   migrations is available.\n   Lease discovery needs\
    \ to be provided as described above.  This\n   ensures that the client discovers\
    \ file system migrations soon enough\n   to renew its leases on each destination\
    \ server before they expire.\n   Non-renewal of leases can lead to loss of locking\
    \ state.  While the\n   consequences of such loss can be ameliorated through implementations\n\
    \   of courtesy locks, servers are under no obligation to do so, and a\n   conflicting\
    \ lock request may mean that a lock is revoked\n   unexpectedly.  Clients should\
    \ be aware of this possibility.\n"
- title: 11.13.3.  Overview of Client Response to NFS4ERR_MOVED
  contents:
  - "11.13.3.  Overview of Client Response to NFS4ERR_MOVED\n   This section outlines\
    \ a way in which a client that receives\n   NFS4ERR_MOVED can effect transition\
    \ recovery by using a new server or\n   server endpoint if one is available. \
    \ As part of that process, it\n   will determine:\n   *  Whether the NFS4ERR_MOVED\
    \ indicates migration has occurred, or\n      whether it indicates another sort\
    \ of file system access transition\n      as discussed in Section 11.10 above.\n\
    \   *  In the case of migration, whether Transparent State Migration has\n   \
    \   occurred.\n   *  Whether any state has been lost during the process of Transparent\n\
    \      State Migration.\n   *  Whether sessions have been transferred as part\
    \ of Transparent\n      State Migration.\n   During the first phase of this process,\
    \ the client proceeds to\n   examine file system location entries to find the\
    \ initial network\n   address it will use to continue access to the file system\
    \ or its\n   replacement.  For each location entry that the client examines, the\n\
    \   process consists of five steps:\n   1.  Performing an EXCHANGE_ID directed\
    \ at the location address.  This\n       operation is used to register the client\
    \ owner (in the form of a\n       client_owner4) with the server, to obtain a\
    \ client ID to be used\n       subsequently to communicate with it, to obtain\
    \ that client ID's\n       confirmation status, and to determine server_owner4\
    \ and scope for\n       the purpose of determining if the entry is trunkable with\
    \ the\n       address previously being used to access the file system (i.e.,\n\
    \       that it represents another network access path to the same file\n    \
    \   system and can share locking state with it).\n   2.  Making an initial determination\
    \ of whether migration has\n       occurred.  The initial determination will be\
    \ based on whether the\n       EXCHANGE_ID results indicate that the current location\
    \ element is\n       server-trunkable with that used to access the file system\
    \ when\n       access was terminated by receiving NFS4ERR_MOVED.  If it is, then\n\
    \       migration has not occurred.  In that case, the transition is\n       dealt\
    \ with, at least initially, as one involving continued access\n       to the same\
    \ file system on the same server through a new network\n       address.\n   3.\
    \  Obtaining access to existing session state or creating new\n       sessions.\
    \  How this is done depends on the initial determination\n       of whether migration\
    \ has occurred and can be done as described in\n       Section 11.13.4 below in\
    \ the case of migration or as described in\n       Section 11.13.5 below in the\
    \ case of a network address transfer\n       without migration.\n   4.  Verifying\
    \ the trunking relationship assumed in step 2 as\n       discussed in Section\
    \ 2.10.5.1.  Although this step will generally\n       confirm the initial determination,\
    \ it is possible for\n       verification to invalidate the initial determination\
    \ of network\n       address shift (without migration) and instead determine that\n\
    \       migration had occurred.  There is no need to redo step 3 above,\n    \
    \   since it will be possible to continue use of the session\n       established\
    \ already.\n   5.  Obtaining access to existing locking state and/or re-obtaining\n\
    \       it.  How this is done depends on the final determination of\n       whether\
    \ migration has occurred and can be done as described below\n       in Section\
    \ 11.13.4 in the case of migration or as described in\n       Section 11.13.5\
    \ in the case of a network address transfer without\n       migration.\n   Once\
    \ the initial address has been determined, clients are free to\n   apply an abbreviated\
    \ process to find additional addresses trunkable\n   with it (clients may seek\
    \ session-trunkable or server-trunkable\n   addresses depending on whether they\
    \ support client ID trunking).\n   During this later phase of the process, further\
    \ location entries are\n   examined using the abbreviated procedure specified\
    \ below:\n   A:  Before the EXCHANGE_ID, the fs name of the location entry is\n\
    \       examined, and if it does not match that currently being used, the\n  \
    \     entry is ignored.  Otherwise, one proceeds as specified by step 1\n    \
    \   above.\n   B:  In the case that the network address is session-trunkable with\n\
    \       one used previously, a BIND_CONN_TO_SESSION is used to access\n      \
    \ that session using the new network address.  Otherwise, or if the\n       bind\
    \ operation fails, a CREATE_SESSION is done.\n   C:  The verification procedure\
    \ referred to in step 4 above is used.\n       However, if it fails, the entry\
    \ is ignored and the next available\n       entry is used.\n"
- title: 11.13.4.  Obtaining Access to Sessions and State after Migration
  contents:
  - "11.13.4.  Obtaining Access to Sessions and State after Migration\n   In the event\
    \ that migration has occurred, migration recovery will\n   involve determining\
    \ whether Transparent State Migration has occurred.\n   This decision is made\
    \ based on the client ID returned by the\n   EXCHANGE_ID and the reported confirmation\
    \ status.\n   *  If the client ID is an unconfirmed client ID not previously known\n\
    \      to the client, then Transparent State Migration has not occurred.\n   *\
    \  If the client ID is a confirmed client ID previously known to the\n      client,\
    \ then any transferred state would have been merged with an\n      existing client\
    \ ID representing the client to the destination\n      server.  In this state\
    \ merger case, Transparent State Migration\n      might or might not have occurred,\
    \ and a determination as to\n      whether it has occurred is deferred until sessions\
    \ are established\n      and the client is ready to begin state recovery.\n  \
    \ *  If the client ID is a confirmed client ID not previously known to\n     \
    \ the client, then the client can conclude that the client ID was\n      transferred\
    \ as part of Transparent State Migration.  In this\n      transferred client ID\
    \ case, Transparent State Migration has\n      occurred, although some state might\
    \ have been lost.\n   Once the client ID has been obtained, it is necessary to\
    \ obtain\n   access to sessions to continue communication with the new server.\
    \  In\n   any of the cases in which Transparent State Migration has occurred,\n\
    \   it is possible that a session was transferred as well.  To deal with\n   that\
    \ possibility, clients can, after doing the EXCHANGE_ID, issue a\n   BIND_CONN_TO_SESSION\
    \ to connect the transferred session to a\n   connection to the new server.  If\
    \ that fails, it is an indication\n   that the session was not transferred and\
    \ that a new session needs to\n   be created to take its place.\n   In some situations,\
    \ it is possible for a BIND_CONN_TO_SESSION to\n   succeed without session migration\
    \ having occurred.  If state merger\n   has taken place, then the associated client\
    \ ID may have already had a\n   set of existing sessions, with it being possible\
    \ that the session ID\n   of a given session is the same as one that might have\
    \ been migrated.\n   In that event, a BIND_CONN_TO_SESSION might succeed, even\
    \ though\n   there could have been no migration of the session with that session\n\
    \   ID.  In such cases, the client will receive sequence errors when the\n   slot\
    \ sequence values used are not appropriate on the new session.\n   When this occurs,\
    \ the client can create a new a session and cease\n   using the existing one.\n\
    \   Once the client has determined the initial migration status, and\n   determined\
    \ that there was a shift to a new server, it needs to re-\n   establish its locking\
    \ state, if possible.  To enable this to happen\n   without loss of the guarantees\
    \ normally provided by locking, the\n   destination server needs to implement\
    \ a per-fs grace period in all\n   cases in which lock state was lost, including\
    \ those in which\n   Transparent State Migration was not implemented.  Each client\
    \ for\n   which there was a transfer of locking state to the new server will\n\
    \   have the duration of the grace period to reclaim its locks, from the\n   time\
    \ its locks were transferred.\n   Clients need to deal with the following cases:\n\
    \   *  In the state merger case, it is possible that the server has not\n    \
    \  attempted Transparent State Migration, in which case state may\n      have\
    \ been lost without it being reflected in the SEQ4_STATUS bits.\n      To determine\
    \ whether this has happened, the client can use\n      TEST_STATEID to check whether\
    \ the stateids created on the source\n      server are still accessible on the\
    \ destination server.  Once a\n      single stateid is found to have been successfully\
    \ transferred, the\n      client can conclude that Transparent State Migration\
    \ was begun,\n      and any failure to transport all of the stateids will be reflected\n\
    \      in the SEQ4_STATUS bits.  Otherwise, Transparent State Migration\n    \
    \  has not occurred.\n   *  In a case in which Transparent State Migration has\
    \ not occurred,\n      the client can use the per-fs grace period provided by\
    \ the\n      destination server to reclaim locks that were held on the source\n\
    \      server.\n   *  In a case in which Transparent State Migration has occurred,\
    \ and\n      no lock state was lost (as shown by SEQ4_STATUS flags), no lock\n\
    \      reclaim is necessary.\n   *  In a case in which Transparent State Migration\
    \ has occurred, and\n      some lock state was lost (as shown by SEQ4_STATUS flags),\
    \ existing\n      stateids need to be checked for validity using TEST_STATEID,\
    \ and\n      reclaim used to re-establish any that were not transferred.\n   For\
    \ all of the cases above, RECLAIM_COMPLETE with an rca_one_fs value\n   of TRUE\
    \ needs to be done before normal use of the file system,\n   including obtaining\
    \ new locks for the file system.  This applies even\n   if no locks were lost\
    \ and there was no need for any to be reclaimed.\n"
- title: 11.13.5.  Obtaining Access to Sessions and State after Network Address
  contents:
  - "11.13.5.  Obtaining Access to Sessions and State after Network Address\n    \
    \      Transfer\n   The case in which there is a transfer to a new network address\n\
    \   without migration is similar to that described in Section 11.13.4\n   above\
    \ in that there is a need to obtain access to needed sessions and\n   locking\
    \ state.  However, the details are simpler and will vary\n   depending on the\
    \ type of trunking between the address receiving\n   NFS4ERR_MOVED and that to\
    \ which the transfer is to be made.\n   To make a session available for use, a\
    \ BIND_CONN_TO_SESSION should be\n   used to obtain access to the session previously\
    \ in use.  Only if this\n   fails, should a CREATE_SESSION be done.  While this\
    \ procedure mirrors\n   that in Section 11.13.4 above, there is an important difference\
    \ in\n   that preservation of the session is not purely optional but depends\n\
    \   on the type of trunking.\n   Access to appropriate locking state will generally\
    \ need no actions\n   beyond access to the session.  However, the SEQ4_STATUS\
    \ bits need to\n   be checked for lost locking state, including the need to reclaim\n\
    \   locks after a server reboot, since there is always a possibility of\n   locking\
    \ state being lost.\n"
- title: 11.14.  Server Responsibilities Upon Migration
  contents:
  - "11.14.  Server Responsibilities Upon Migration\n   In the event of file system\
    \ migration, when the client connects to\n   the destination server, that server\
    \ needs to be able to provide the\n   client continued access to the files it\
    \ had open on the source\n   server.  There are two ways to provide this:\n  \
    \ *  By provision of an fs-specific grace period, allowing the client\n      the\
    \ ability to reclaim its locks, in a fashion similar to what\n      would have\
    \ been done in the case of recovery from a server\n      restart.  See Section\
    \ 11.14.1 for a more complete discussion.\n   *  By implementing Transparent State\
    \ Migration possibly in connection\n      with session migration, the server can\
    \ provide the client\n      immediate access to the state built up on the source\
    \ server on the\n      destination server.\n      These features are discussed\
    \ separately in Sections 11.14.2 and\n      11.14.3, which discuss Transparent\
    \ State Migration and session\n      migration, respectively.\n   All the features\
    \ described above can involve transfer of lock-related\n   information between\
    \ source and destination servers.  In some cases,\n   this transfer is a necessary\
    \ part of the implementation, while in\n   other cases, it is a helpful implementation\
    \ aid, which servers might\n   or might not use.  The subsections below discuss\
    \ the information that\n   would be transferred but do not define the specifics\
    \ of the transfer\n   protocol.  This is left as an implementation choice, although\n\
    \   standards in this area could be developed at a later time.\n"
- title: 11.14.1.  Server Responsibilities in Effecting State Reclaim after
  contents:
  - "11.14.1.  Server Responsibilities in Effecting State Reclaim after\n        \
    \  Migration\n   In this case, the destination server needs no knowledge of the\
    \ locks\n   held on the source server.  It relies on the clients to accurately\n\
    \   report (via reclaim operations) the locks previously held, and does\n   not\
    \ allow new locks to be granted on migrated file systems until the\n   grace period\
    \ expires.  Disallowing of new locks applies to all\n   clients accessing these\
    \ file systems, while grace period expiration\n   occurs for each migrated client\
    \ independently.\n   During this grace period, clients have the opportunity to\
    \ use reclaim\n   operations to obtain locks for file system objects within the\n\
    \   migrated file system, in the same way that they do when recovering\n   from\
    \ server restart, and the servers typically rely on clients to\n   accurately\
    \ report their locks, although they have the option of\n   subjecting these requests\
    \ to verification.  If the clients only\n   reclaim locks held on the source server,\
    \ no conflict can arise.  Once\n   the client has reclaimed its locks, it indicates\
    \ the completion of\n   lock reclamation by performing a RECLAIM_COMPLETE specifying\n\
    \   rca_one_fs as TRUE.\n   While it is not necessary for source and destination\
    \ servers to\n   cooperate to transfer information about locks, implementations\
    \ are\n   well advised to consider transferring the following useful\n   information:\n\
    \   *  If information about the set of clients that have locking state\n     \
    \ for the transferred file system is made available, the destination\n      server\
    \ will be able to terminate the grace period once all such\n      clients have\
    \ reclaimed their locks, allowing normal locking\n      activity to resume earlier\
    \ than it would have otherwise.\n   *  Locking summary information for individual\
    \ clients (at various\n      possible levels of detail) can detect some instances\
    \ in which\n      clients do not accurately represent the locks held on the source\n\
    \      server.\n"
- title: 11.14.2.  Server Responsibilities in Effecting Transparent State
  contents:
  - "11.14.2.  Server Responsibilities in Effecting Transparent State\n          Migration\n\
    \   The basic responsibility of the source server in effecting\n   Transparent\
    \ State Migration is to make available to the destination\n   server a description\
    \ of each piece of locking state associated with\n   the file system being migrated.\
    \  In addition to client id string and\n   verifier, the source server needs to\
    \ provide for each stateid:\n   *  The stateid including the current sequence\
    \ value.\n   *  The associated client ID.\n   *  The handle of the associated\
    \ file.\n   *  The type of the lock, such as open, byte-range lock, delegation,\n\
    \      or layout.\n   *  For locks such as opens and byte-range locks, there will\
    \ be\n      information about the owner(s) of the lock.\n   *  For recallable/revocable\
    \ lock types, the current recall status\n      needs to be included.\n   *  For\
    \ each lock type, there will be associated type-specific\n      information. \
    \ For opens, this will include share and deny mode\n      while for byte-range\
    \ locks and layouts, there will be a type and a\n      byte-range.\n   Such information\
    \ will most probably be organized by client id string\n   on the destination server\
    \ so that it can be used to provide\n   appropriate context to each client when\
    \ it makes itself known to the\n   client.  Issues connected with a client impersonating\
    \ another by\n   presenting another client's client id string can be addressed\
    \ using\n   NFSv4.1 state protection features, as described in Section 21.\n \
    \  A further server responsibility concerns locks that are revoked or\n   otherwise\
    \ lost during the process of file system migration.  Because\n   locks that appear\
    \ to be lost during the process of migration will be\n   reclaimed by the client,\
    \ the servers have to take steps to ensure\n   that locks revoked soon before\
    \ or soon after migration are not\n   inadvertently allowed to be reclaimed in\
    \ situations in which the\n   continuity of lock possession cannot be assured.\n\
    \   *  For locks lost on the source but whose loss has not yet been\n      acknowledged\
    \ by the client (by using FREE_STATEID), the\n      destination must be aware\
    \ of this loss so that it can deny a\n      request to reclaim them.\n   *  For\
    \ locks lost on the destination after the state transfer but\n      before the\
    \ client's RECLAIM_COMPLETE is done, the destination\n      server should note\
    \ these and not allow them to be reclaimed.\n   An additional responsibility of\
    \ the cooperating servers concerns\n   situations in which a stateid cannot be\
    \ transferred transparently\n   because it conflicts with an existing stateid\
    \ held by the client and\n   associated with a different file system.  In this\
    \ case, there are two\n   valid choices:\n   *  Treat the transfer, as in NFSv4.0,\
    \ as one without Transparent\n      State Migration.  In this case, conflicting\
    \ locks cannot be\n      granted until the client does a RECLAIM_COMPLETE, after\
    \ reclaiming\n      the locks it had, with the exception of reclaims denied because\n\
    \      they were attempts to reclaim locks that had been lost.\n   *  Implement\
    \ Transparent State Migration, except for the lock with\n      the conflicting\
    \ stateid.  In this case, the client will be aware\n      of a lost lock (through\
    \ the SEQ4_STATUS flags) and be allowed to\n      reclaim it.\n   When transferring\
    \ state between the source and destination, the\n   issues discussed in Section\
    \ 7.2 of [69] must still be attended to.\n   In this case, the use of NFS4ERR_DELAY\
    \ may still be necessary in\n   NFSv4.1, as it was in NFSv4.0, to prevent locking\
    \ state changing\n   while it is being transferred.  See Section 15.1.1.3 for\
    \ information\n   about appropriate client retry approaches in the event that\n\
    \   NFS4ERR_DELAY is returned.\n   There are a number of important differences\
    \ in the NFS4.1 context:\n   *  The absence of RELEASE_LOCKOWNER means that the\
    \ one case in which\n      an operation could not be deferred by use of NFS4ERR_DELAY\
    \ no\n      longer exists.\n   *  Sequencing of operations is no longer done using\
    \ owner-based\n      operation sequences numbers.  Instead, sequencing is session-\n\
    \      based.\n   As a result, when sessions are not transferred, the techniques\n\
    \   discussed in Section 7.2 of [69] are adequate and will not be further\n  \
    \ discussed.\n"
- title: 11.14.3.  Server Responsibilities in Effecting Session Transfer
  contents:
  - "11.14.3.  Server Responsibilities in Effecting Session Transfer\n   The basic\
    \ responsibility of the source server in effecting session\n   transfer is to\
    \ make available to the destination server a description\n   of the current state\
    \ of each slot with the session, including the\n   following:\n   *  The last\
    \ sequence value received for that slot.\n   *  Whether there is cached reply\
    \ data for the last request executed\n      and, if so, the cached reply.\n  \
    \ When sessions are transferred, there are a number of issues that pose\n   challenges\
    \ in terms of making the transferred state unmodifiable\n   during the period\
    \ it is gathered up and transferred to the\n   destination server:\n   *  A single\
    \ session may be used to access multiple file systems, not\n      all of which\
    \ are being transferred.\n   *  Requests made on a session may, even if rejected,\
    \ affect the state\n      of the session by advancing the sequence number associated\
    \ with\n      the slot used.\n   As a result, when the file system state might\
    \ otherwise be considered\n   unmodifiable, the client might have any number of\
    \ in-flight requests,\n   each of which is capable of changing session state,\
    \ which may be of a\n   number of types:\n   1.  Those requests that were processed\
    \ on the migrating file system\n       before migration began.\n   2.  Those requests\
    \ that received the error NFS4ERR_DELAY because the\n       file system being\
    \ accessed was in the process of being migrated.\n   3.  Those requests that received\
    \ the error NFS4ERR_MOVED because the\n       file system being accessed had been\
    \ migrated.\n   4.  Those requests that accessed the migrating file system in\
    \ order\n       to obtain location or status information.\n   5.  Those requests\
    \ that did not reference the migrating file system.\n   It should be noted that\
    \ the history of any particular slot is likely\n   to include a number of these\
    \ request classes.  In the case in which a\n   session that is migrated is used\
    \ by file systems other than the one\n   migrated, requests of class 5 may be\
    \ common and may be the last\n   request processed for many slots.\n   Since session\
    \ state can change even after the locking state has been\n   fixed as part of\
    \ the migration process, the session state known to\n   the client could be different\
    \ from that on the destination server,\n   which necessarily reflects the session\
    \ state on the source server at\n   an earlier time.  In deciding how to deal\
    \ with this situation, it is\n   helpful to distinguish between two sorts of behavioral\
    \ consequences\n   of the choice of initial sequence ID values:\n   *  The error\
    \ NFS4ERR_SEQ_MISORDERED is returned when the sequence ID\n      in a request\
    \ is neither equal to the last one seen for the current\n      slot nor the next\
    \ greater one.\n      In view of the difficulty of arriving at a mutually acceptable\n\
    \      value for the correct last sequence value at the point of\n      migration,\
    \ it may be necessary for the server to show some degree\n      of forbearance\
    \ when the sequence ID is one that would be\n      considered unacceptable if\
    \ session migration were not involved.\n   *  Returning the cached reply for a\
    \ previously executed request when\n      the sequence ID in the request matches\
    \ the last value recorded for\n      the slot.\n      In the cases in which an\
    \ error is returned and there is no\n      possibility of any non-idempotent operation\
    \ having been executed,\n      it may not be necessary to adhere to this as strictly\
    \ as might be\n      proper if session migration were not involved.  For example,\
    \ the\n      fact that the error NFS4ERR_DELAY was returned may not assist the\n\
    \      client in any material way, while the fact that NFS4ERR_MOVED was\n   \
    \   returned by the source server may not be relevant when the request\n     \
    \ was reissued and directed to the destination server.\n   An important issue\
    \ is that the specification needs to take note of\n   all potential COMPOUNDs,\
    \ even if they might be unlikely in practice.\n   For example, a COMPOUND is allowed\
    \ to access multiple file systems\n   and might perform non-idempotent operations\
    \ in some of them before\n   accessing a file system being migrated.  Also, a\
    \ COMPOUND may return\n   considerable data in the response before being rejected\
    \ with\n   NFS4ERR_DELAY or NFS4ERR_MOVED, and may in addition be marked as\n\
    \   sa_cachethis.  However, note that if the client and server adhere to\n   rules\
    \ in Section 15.1.1.3, there is no possibility of non-idempotent\n   operations\
    \ being spuriously reissued after receiving NFS4ERR_DELAY\n   response.\n   To\
    \ address these issues, a destination server MAY do any of the\n   following when\
    \ implementing session transfer:\n   *  Avoid enforcing any sequencing semantics\
    \ for a particular slot\n      until the client has established the starting sequence\
    \ for that\n      slot on the destination server.\n   *  For each slot, avoid\
    \ returning a cached reply returning\n      NFS4ERR_DELAY or NFS4ERR_MOVED until\
    \ the client has established\n      the starting sequence for that slot on the\
    \ destination server.\n   *  Until the client has established the starting sequence\
    \ for a\n      particular slot on the destination server, avoid reporting\n  \
    \    NFS4ERR_SEQ_MISORDERED or returning a cached reply that contains\n      either\
    \ NFS4ERR_DELAY or NFS4ERR_MOVED and consists solely of a\n      series of operations\
    \ where the response is NFS4_OK until the final\n      error.\n   Because of the\
    \ considerations mentioned above, including the rules\n   for the handling of\
    \ NFS4ERR_DELAY included in Section 15.1.1.3, the\n   destination server can respond\
    \ appropriately to SEQUENCE operations\n   received from the client by adopting\
    \ the three policies listed below:\n   *  Not responding with NFS4ERR_SEQ_MISORDERED\
    \ for the initial request\n      on a slot within a transferred session because\
    \ the destination\n      server cannot be aware of requests made by the client\
    \ after the\n      server handoff but before the client became aware of the shift.\n\
    \      In cases in which NFS4ERR_SEQ_MISORDERED would normally have been\n   \
    \   reported, the request is to be processed normally as a new\n      request.\n\
    \   *  Replying as it would for a retry whenever the sequence matches\n      that\
    \ transferred by the source server, even though this would not\n      provide\
    \ retry handling for requests issued after the server\n      handoff, under the\
    \ assumption that, when such requests are issued,\n      they will never be responded\
    \ to in a state-changing fashion,\n      making retry support for them unnecessary.\n\
    \   *  Once a non-retry SEQUENCE is received for a given slot, using that\n  \
    \    as the basis for further sequence checking, with no further\n      reference\
    \ to the sequence value transferred by the source server.\n"
- title: 11.15.  Effecting File System Referrals
  contents:
  - "11.15.  Effecting File System Referrals\n   Referrals are effected when an absent\
    \ file system is encountered and\n   one or more alternate locations are made\
    \ available by the\n   fs_locations or fs_locations_info attributes.  The client\
    \ will\n   typically get an NFS4ERR_MOVED error, fetch the appropriate location\n\
    \   information, and proceed to access the file system on a different\n   server,\
    \ even though it retains its logical position within the\n   original namespace.\
    \  Referrals differ from migration events in that\n   they happen only when the\
    \ client has not previously referenced the\n   file system in question (so there\
    \ is nothing to transition).\n   Referrals can only come into effect when an absent\
    \ file system is\n   encountered at its root.\n   The examples given in the sections\
    \ below are somewhat artificial in\n   that an actual client will not typically\
    \ do a multi-component look\n   up, but will have cached information regarding\
    \ the upper levels of\n   the name hierarchy.  However, these examples are chosen\
    \ to make the\n   required behavior clear and easy to put within the scope of\
    \ a small\n   number of requests, without getting into a discussion of the details\n\
    \   of how specific clients might choose to cache things.\n"
- title: 11.15.1.  Referral Example (LOOKUP)
  contents:
  - "11.15.1.  Referral Example (LOOKUP)\n   Let us suppose that the following COMPOUND\
    \ is sent in an environment\n   in which /this/is/the/path is absent from the\
    \ target server.  This\n   may be for a number of reasons.  It may be that the\
    \ file system has\n   moved, or it may be that the target server is functioning\
    \ mainly, or\n   solely, to refer clients to the servers on which various file\
    \ systems\n   are located.\n   *  PUTROOTFH\n   *  LOOKUP \"this\"\n   *  LOOKUP\
    \ \"is\"\n   *  LOOKUP \"the\"\n   *  LOOKUP \"path\"\n   *  GETFH\n   *  GETATTR\
    \ (fsid, fileid, size, time_modify)\n   Under the given circumstances, the following\
    \ will be the result.\n   *  PUTROOTFH --> NFS_OK.  The current fh is now the\
    \ root of the\n      pseudo-fs.\n   *  LOOKUP \"this\" --> NFS_OK.  The current\
    \ fh is for /this and is\n      within the pseudo-fs.\n   *  LOOKUP \"is\" -->\
    \ NFS_OK.  The current fh is for /this/is and is\n      within the pseudo-fs.\n\
    \   *  LOOKUP \"the\" --> NFS_OK.  The current fh is for /this/is/the and\n  \
    \    is within the pseudo-fs.\n   *  LOOKUP \"path\" --> NFS_OK.  The current\
    \ fh is for /this/is/the/path\n      and is within a new, absent file system,\
    \ but ...  the client will\n      never see the value of that fh.\n   *  GETFH\
    \ --> NFS4ERR_MOVED.  Fails because current fh is in an absent\n      file system\
    \ at the start of the operation, and the specification\n      makes no exception\
    \ for GETFH.\n   *  GETATTR (fsid, fileid, size, time_modify).  Not executed because\n\
    \      the failure of the GETFH stops processing of the COMPOUND.\n   Given the\
    \ failure of the GETFH, the client has the job of determining\n   the root of\
    \ the absent file system and where to find that file\n   system, i.e., the server\
    \ and path relative to that server's root fh.\n   Note that in this example, the\
    \ client did not obtain filehandles and\n   attribute information (e.g., fsid)\
    \ for the intermediate directories,\n   so that it would not be sure where the\
    \ absent file system starts.  It\n   could be the case, for example, that /this/is/the\
    \ is the root of the\n   moved file system and that the reason that the look up\
    \ of \"path\"\n   succeeded is that the file system was not absent on that operation\n\
    \   but was moved between the last LOOKUP and the GETFH (since COMPOUND\n   is\
    \ not atomic).  Even if we had the fsids for all of the intermediate\n   directories,\
    \ we could have no way of knowing that /this/is/the/path\n   was the root of a\
    \ new file system, since we don't yet have its fsid.\n   In order to get the necessary\
    \ information, let us re-send the chain\n   of LOOKUPs with GETFHs and GETATTRs\
    \ to at least get the fsids so we\n   can be sure where the appropriate file system\
    \ boundaries are.  The\n   client could choose to get fs_locations_info at the\
    \ same time but in\n   most cases the client will have a good guess as to where\
    \ file system\n   boundaries are (because of where NFS4ERR_MOVED was, and was\
    \ not,\n   received) making fetching of fs_locations_info unnecessary.\n   OP01:\
    \  PUTROOTFH --> NFS_OK\n      *  Current fh is root of pseudo-fs.\n   OP02: \
    \ GETATTR(fsid) --> NFS_OK\n      *  Just for completeness.  Normally, clients\
    \ will know the fsid of\n         the pseudo-fs as soon as they establish communication\
    \ with a\n         server.\n   OP03:  LOOKUP \"this\" --> NFS_OK\n   OP04:  GETATTR(fsid)\
    \ --> NFS_OK\n      *  Get current fsid to see where file system boundaries are.\
    \  The\n         fsid will be that for the pseudo-fs in this example, so no\n\
    \         boundary.\n   OP05:  GETFH --> NFS_OK\n      *  Current fh is for /this\
    \ and is within pseudo-fs.\n   OP06:  LOOKUP \"is\" --> NFS_OK\n      *  Current\
    \ fh is for /this/is and is within pseudo-fs.\n   OP07:  GETATTR(fsid) --> NFS_OK\n\
    \      *  Get current fsid to see where file system boundaries are.  The\n   \
    \      fsid will be that for the pseudo-fs in this example, so no\n         boundary.\n\
    \   OP08:  GETFH --> NFS_OK\n      *  Current fh is for /this/is and is within\
    \ pseudo-fs.\n   OP09:  LOOKUP \"the\" --> NFS_OK\n      *  Current fh is for\
    \ /this/is/the and is within pseudo-fs.\n   OP10:  GETATTR(fsid) --> NFS_OK\n\
    \      *  Get current fsid to see where file system boundaries are.  The\n   \
    \      fsid will be that for the pseudo-fs in this example, so no\n         boundary.\n\
    \   OP11:  GETFH --> NFS_OK\n      *  Current fh is for /this/is/the and is within\
    \ pseudo-fs.\n   OP12:  LOOKUP \"path\" --> NFS_OK\n      *  Current fh is for\
    \ /this/is/the/path and is within a new, absent\n         file system, but ...\n\
    \      *  The client will never see the value of that fh.\n   OP13:  GETATTR(fsid,\
    \ fs_locations_info) --> NFS_OK\n      *  We are getting the fsid to know where\
    \ the file system\n         boundaries are.  In this operation, the fsid will\
    \ be different\n         than that of the parent directory (which in turn was\
    \ retrieved\n         in OP10).  Note that the fsid we are given will not necessarily\n\
    \         be preserved at the new location.  That fsid might be\n         different,\
    \ and in fact the fsid we have for this file system\n         might be a valid\
    \ fsid of a different file system on that new\n         server.\n      *  In this\
    \ particular case, we are pretty sure anyway that what\n         has moved is\
    \ /this/is/the/path rather than /this/is/the since\n         we have the fsid\
    \ of the latter and it is that of the pseudo-fs,\n         which presumably cannot\
    \ move.  However, in other examples, we\n         might not have this kind of\
    \ information to rely on (e.g.,\n         /this/is/the might be a non-pseudo file\
    \ system separate from\n         /this/is/the/path), so we need to have other\
    \ reliable source\n         information on the boundary of the file system that\
    \ is moved.\n         If, for example, the file system /this/is had moved, we\
    \ would\n         have a case of migration rather than referral, and once the\n\
    \         boundaries of the migrated file system was clear we could fetch\n  \
    \       fs_locations_info.\n      *  We are fetching fs_locations_info because\
    \ the fact that we got\n         an NFS4ERR_MOVED at this point means that it\
    \ is most likely\n         that this is a referral and we need the destination.\
    \  Even if\n         it is the case that /this/is/the is a file system that has\n\
    \         migrated, we will still need the location information for that\n   \
    \      file system.\n   OP14:  GETFH --> NFS4ERR_MOVED\n      *  Fails because\
    \ current fh is in an absent file system at the\n         start of the operation,\
    \ and the specification makes no\n         exception for GETFH.  Note that this\
    \ means the server will\n         never send the client a filehandle from within\
    \ an absent file\n         system.\n   Given the above, the client knows where\
    \ the root of the absent file\n   system is (/this/is/the/path) by noting where\
    \ the change of fsid\n   occurred (between \"the\" and \"path\").  The fs_locations_info\
    \ attribute\n   also gives the client the actual location of the absent file system,\n\
    \   so that the referral can proceed.  The server gives the client the\n   bare\
    \ minimum of information about the absent file system so that\n   there will be\
    \ very little scope for problems of conflict between\n   information sent by the\
    \ referring server and information of the file\n   system's home.  No filehandles\
    \ and very few attributes are present on\n   the referring server, and the client\
    \ can treat those it receives as\n   transient information with the function of\
    \ enabling the referral.\n"
- title: 11.15.2.  Referral Example (READDIR)
  contents:
  - "11.15.2.  Referral Example (READDIR)\n   Another context in which a client may\
    \ encounter referrals is when it\n   does a READDIR on a directory in which some\
    \ of the sub-directories\n   are the roots of absent file systems.\n   Suppose\
    \ such a directory is read as follows:\n   *  PUTROOTFH\n   *  LOOKUP \"this\"\
    \n   *  LOOKUP \"is\"\n   *  LOOKUP \"the\"\n   *  READDIR (fsid, size, time_modify,\
    \ mounted_on_fileid)\n   In this case, because rdattr_error is not requested,\n\
    \   fs_locations_info is not requested, and some of the attributes cannot\n  \
    \ be provided, the result will be an NFS4ERR_MOVED error on the\n   READDIR, with\
    \ the detailed results as follows:\n   *  PUTROOTFH --> NFS_OK.  The current fh\
    \ is at the root of the\n      pseudo-fs.\n   *  LOOKUP \"this\" --> NFS_OK. \
    \ The current fh is for /this and is\n      within the pseudo-fs.\n   *  LOOKUP\
    \ \"is\" --> NFS_OK.  The current fh is for /this/is and is\n      within the\
    \ pseudo-fs.\n   *  LOOKUP \"the\" --> NFS_OK.  The current fh is for /this/is/the\
    \ and\n      is within the pseudo-fs.\n   *  READDIR (fsid, size, time_modify,\
    \ mounted_on_fileid) -->\n      NFS4ERR_MOVED.  Note that the same error would\
    \ have been returned\n      if /this/is/the had migrated, but it is returned because\
    \ the\n      directory contains the root of an absent file system.\n   So now\
    \ suppose that we re-send with rdattr_error:\n   *  PUTROOTFH\n   *  LOOKUP \"\
    this\"\n   *  LOOKUP \"is\"\n   *  LOOKUP \"the\"\n   *  READDIR (rdattr_error,\
    \ fsid, size, time_modify, mounted_on_fileid)\n   The results will be:\n   * \
    \ PUTROOTFH --> NFS_OK.  The current fh is at the root of the\n      pseudo-fs.\n\
    \   *  LOOKUP \"this\" --> NFS_OK.  The current fh is for /this and is\n     \
    \ within the pseudo-fs.\n   *  LOOKUP \"is\" --> NFS_OK.  The current fh is for\
    \ /this/is and is\n      within the pseudo-fs.\n   *  LOOKUP \"the\" --> NFS_OK.\
    \  The current fh is for /this/is/the and\n      is within the pseudo-fs.\n  \
    \ *  READDIR (rdattr_error, fsid, size, time_modify, mounted_on_fileid)\n    \
    \  --> NFS_OK.  The attributes for directory entry with the component\n      named\
    \ \"path\" will only contain rdattr_error with the value\n      NFS4ERR_MOVED,\
    \ together with an fsid value and a value for\n      mounted_on_fileid.\n   Suppose\
    \ we do another READDIR to get fs_locations_info (although we\n   could have used\
    \ a GETATTR directly, as in Section 11.15.1).\n   *  PUTROOTFH\n   *  LOOKUP \"\
    this\"\n   *  LOOKUP \"is\"\n   *  LOOKUP \"the\"\n   *  READDIR (rdattr_error,\
    \ fs_locations_info, mounted_on_fileid, fsid,\n      size, time_modify)\n   The\
    \ results would be:\n   *  PUTROOTFH --> NFS_OK.  The current fh is at the root\
    \ of the\n      pseudo-fs.\n   *  LOOKUP \"this\" --> NFS_OK.  The current fh\
    \ is for /this and is\n      within the pseudo-fs.\n   *  LOOKUP \"is\" --> NFS_OK.\
    \  The current fh is for /this/is and is\n      within the pseudo-fs.\n   *  LOOKUP\
    \ \"the\" --> NFS_OK.  The current fh is for /this/is/the and\n      is within\
    \ the pseudo-fs.\n   *  READDIR (rdattr_error, fs_locations_info, mounted_on_fileid,\
    \ fsid,\n      size, time_modify) --> NFS_OK.  The attributes will be as shown\n\
    \      below.\n   The attributes for the directory entry with the component named\n\
    \   \"path\" will only contain:\n   *  rdattr_error (value: NFS_OK)\n   *  fs_locations_info\n\
    \   *  mounted_on_fileid (value: unique fileid within referring file\n      system)\n\
    \   *  fsid (value: unique value within referring server)\n   The attributes for\
    \ entry \"path\" will not contain size or time_modify\n   because these attributes\
    \ are not available within an absent file\n   system.\n"
- title: 11.16.  The Attribute fs_locations
  contents:
  - "11.16.  The Attribute fs_locations\n   The fs_locations attribute is structured\
    \ in the following way:\n   struct fs_location4 {\n           utf8str_cis    \
    \ server<>;\n           pathname4       rootpath;\n   };\n   struct fs_locations4\
    \ {\n           pathname4       fs_root;\n           fs_location4    locations<>;\n\
    \   };\n   The fs_location4 data type is used to represent the location of a\n\
    \   file system by providing a server name and the path to the root of\n   the\
    \ file system within that server's namespace.  When a set of\n   servers have\
    \ corresponding file systems at the same path within their\n   namespaces, an\
    \ array of server names may be provided.  An entry in\n   the server array is\
    \ a UTF-8 string and represents one of a\n   traditional DNS host name, IPv4 address,\
    \ IPv6 address, or a zero-\n   length string.  An IPv4 or IPv6 address is represented\
    \ as a universal\n   address (see Section 3.3.9 and [12]), minus the netid, and\
    \ either\n   with or without the trailing \".p1.p2\" suffix that represents the\
    \ port\n   number.  If the suffix is omitted, then the default port, 2049,\n \
    \  SHOULD be assumed.  A zero-length string SHOULD be used to indicate\n   the\
    \ current address being used for the RPC call.  It is not a\n   requirement that\
    \ all servers that share the same rootpath be listed\n   in one fs_location4 instance.\
    \  The array of server names is provided\n   for convenience.  Servers that share\
    \ the same rootpath may also be\n   listed in separate fs_location4 entries in\
    \ the fs_locations\n   attribute.\n   The fs_locations4 data type and the fs_locations\
    \ attribute each\n   contain an array of such locations.  Since the namespace\
    \ of each\n   server may be constructed differently, the \"fs_root\" field is\n\
    \   provided.  The path represented by fs_root represents the location of\n  \
    \ the file system in the current server's namespace, i.e., that of the\n   server\
    \ from which the fs_locations attribute was obtained.  The\n   fs_root path is\
    \ meant to aid the client by clearly referencing the\n   root of the file system\
    \ whose locations are being reported, no matter\n   what object within the current\
    \ file system the current filehandle\n   designates.  The fs_root is simply the\
    \ pathname the client used to\n   reach the object on the current server (i.e.,\
    \ the object to which the\n   fs_locations attribute applies).\n   When the fs_locations\
    \ attribute is interrogated and there are no\n   alternate file system locations,\
    \ the server SHOULD return a zero-\n   length array of fs_location4 structures,\
    \ together with a valid\n   fs_root.\n   As an example, suppose there is a replicated\
    \ file system located at\n   two servers (servA and servB).  At servA, the file\
    \ system is located\n   at path /a/b/c.  At, servB the file system is located\
    \ at path /x/y/z.\n   If the client were to obtain the fs_locations value for\
    \ the directory\n   at /a/b/c/d, it might not necessarily know that the file system's\n\
    \   root is located in servA's namespace at /a/b/c.  When the client\n   switches\
    \ to servB, it will need to determine that the directory it\n   first referenced\
    \ at servA is now represented by the path /x/y/z/d on\n   servB.  To facilitate\
    \ this, the fs_locations attribute provided by\n   servA would have an fs_root\
    \ value of /a/b/c and two entries in\n   fs_locations.  One entry in fs_locations\
    \ will be for itself (servA)\n   and the other will be for servB with a path of\
    \ /x/y/z.  With this\n   information, the client is able to substitute /x/y/z\
    \ for the /a/b/c\n   at the beginning of its access path and construct /x/y/z/d\
    \ to use for\n   the new server.\n   Note that there is no requirement that the\
    \ number of components in\n   each rootpath be the same; there is no relation\
    \ between the number of\n   components in rootpath or fs_root, and none of the\
    \ components in a\n   rootpath and fs_root have to be the same.  In the above\
    \ example, we\n   could have had a third element in the locations array, with\
    \ server\n   equal to \"servC\" and rootpath equal to \"/I/II\", and a fourth\
    \ element\n   in locations with server equal to \"servD\" and rootpath equal to\n\
    \   \"/aleph/beth/gimel/daleth/he\".\n   The relationship between fs_root to a\
    \ rootpath is that the client\n   replaces the pathname indicated in fs_root for\
    \ the current server for\n   the substitute indicated in rootpath for the new\
    \ server.\n   For an example of a referred or migrated file system, suppose there\n\
    \   is a file system located at serv1.  At serv1, the file system is\n   located\
    \ at /az/buky/vedi/glagoli.  The client finds that object at\n   glagoli has migrated\
    \ (or is a referral).  The client gets the\n   fs_locations attribute, which contains\
    \ an fs_root of /az/buky/vedi/\n   glagoli, and one element in the locations array,\
    \ with server equal to\n   serv2, and rootpath equal to /izhitsa/fita.  The client\
    \ replaces\n   /az/buky/vedi/glagoli with /izhitsa/fita, and uses the latter\n\
    \   pathname on serv2.\n   Thus, the server MUST return an fs_root that is equal\
    \ to the path the\n   client used to reach the object to which the fs_locations\
    \ attribute\n   applies.  Otherwise, the client cannot determine the new path\
    \ to use\n   on the new server.\n   Since the fs_locations attribute lacks information\
    \ defining various\n   attributes of the various file system choices presented,\
    \ it SHOULD\n   only be interrogated and used when fs_locations_info is not\n\
    \   available.  When fs_locations is used, information about the specific\n  \
    \ locations should be assumed based on the following rules.\n   The following\
    \ rules are general and apply irrespective of the\n   context.\n   *  All listed\
    \ file system instances should be considered as of the\n      same handle class,\
    \ if and only if, the current fh_expire_type\n      attribute does not include\
    \ the FH4_VOL_MIGRATION bit.  Note that\n      in the case of referral, filehandle\
    \ issues do not apply since\n      there can be no filehandles known within the\
    \ current file system,\n      nor is there any access to the fh_expire_type attribute\
    \ on the\n      referring (absent) file system.\n   *  All listed file system\
    \ instances should be considered as of the\n      same fileid class if and only\
    \ if the fh_expire_type attribute\n      indicates persistent filehandles and\
    \ does not include the\n      FH4_VOL_MIGRATION bit.  Note that in the case of\
    \ referral, fileid\n      issues do not apply since there can be no fileids known\
    \ within the\n      referring (absent) file system, nor is there any access to\
    \ the\n      fh_expire_type attribute.\n   *  All file system instances servers\
    \ should be considered as of\n      different change classes.\n   For other class\
    \ assignments, handling of file system transitions\n   depends on the reasons\
    \ for the transition:\n   *  When the transition is due to migration, that is,\
    \ the client was\n      directed to a new file system after receiving an NFS4ERR_MOVED\n\
    \      error, the target should be treated as being of the same write-\n     \
    \ verifier class as the source.\n   *  When the transition is due to failover\
    \ to another replica, that\n      is, the client selected another replica without\
    \ receiving an\n      NFS4ERR_MOVED error, the target should be treated as being\
    \ of a\n      different write-verifier class from the source.\n   The specific\
    \ choices reflect typical implementation patterns for\n   failover and controlled\
    \ migration, respectively.  Since other choices\n   are possible and useful, this\
    \ information is better obtained by using\n   fs_locations_info.  When a server\
    \ implementation needs to communicate\n   other choices, it MUST support the fs_locations_info\
    \ attribute.\n   See Section 21 for a discussion on the recommendations for the\n\
    \   security flavor to be used by any GETATTR operation that requests the\n  \
    \ fs_locations attribute.\n"
- title: 11.17.  The Attribute fs_locations_info
  contents:
  - "11.17.  The Attribute fs_locations_info\n   The fs_locations_info attribute is\
    \ intended as a more functional\n   replacement for the fs_locations attribute,\
    \ which will continue to\n   exist and be supported.  Clients can use it to get\
    \ a more complete\n   set of data about alternative file system locations, including\n\
    \   additional network paths to access replicas in use and additional\n   replicas.\
    \  When the server does not support fs_locations_info,\n   fs_locations can be\
    \ used to get a subset of the data.  A server that\n   supports fs_locations_info\
    \ MUST support fs_locations as well.\n   There is additional data present in fs_locations_info\
    \ that is not\n   available in fs_locations:\n   *  Attribute continuity information.\
    \  This information will allow a\n      client to select a replica that meets\
    \ the transparency\n      requirements of the applications accessing the data\
    \ and to\n      leverage optimizations due to the server guarantees of attribute\n\
    \      continuity (e.g., if the change attribute of a file of the file\n     \
    \ system is continuous between multiple replicas, the client does\n      not have\
    \ to invalidate the file's cache when switching to a\n      different replica).\n\
    \   *  File system identity information that indicates when multiple\n      replicas,\
    \ from the client's point of view, correspond to the same\n      target file system,\
    \ allowing them to be used interchangeably,\n      without disruption, as distinct\
    \ synchronized replicas of the same\n      file data.\n      Note that having\
    \ two replicas with common identity information is\n      distinct from the case\
    \ of two (trunked) paths to the same replica.\n   *  Information that will bear\
    \ on the suitability of various replicas,\n      depending on the use that the\
    \ client intends.  For example, many\n      applications need an absolutely up-to-date\
    \ copy (e.g., those that\n      write), while others may only need access to the\
    \ most up-to-date\n      copy reasonably available.\n   *  Server-derived preference\
    \ information for replicas, which can be\n      used to implement load-balancing\
    \ while giving the client the\n      entire file system list to be used in case\
    \ the primary fails.\n   The fs_locations_info attribute is structured similarly\
    \ to the\n   fs_locations attribute.  A top-level structure (fs_locations_info4)\n\
    \   contains the entire attribute including the root pathname of the file\n  \
    \ system and an array of lower-level structures that define replicas\n   that\
    \ share a common rootpath on their respective servers.  The lower-\n   level structure\
    \ in turn (fs_locations_item4) contains a specific\n   pathname and information\
    \ on one or more individual network access\n   paths.  For that last, lowest level,\
    \ fs_locations_info has an\n   fs_locations_server4 structure that contains per-server-replica\n\
    \   information in addition to the file system location entry.  This per-\n  \
    \ server-replica information includes a nominally opaque array,\n   fls_info,\
    \ within which specific pieces of information are located at\n   the specific\
    \ indices listed below.\n   Two fs_location_server4 entries that are within different\n\
    \   fs_location_item4 structures are never trunkable, while two entries\n   within\
    \ in the same fs_location_item4 structure might or might not be\n   trunkable.\
    \  Two entries that are trunkable will have identical\n   identity information,\
    \ although, as noted above, the converse is not\n   the case.\n   The attribute\
    \ will always contain at least a single\n   fs_locations_server entry.  Typically,\
    \ there will be an entry with\n   the FS4LIGF_CUR_REQ flag set, although in the\
    \ case of a referral\n   there will be no entry with that flag set.\n   It should\
    \ be noted that fs_locations_info attributes returned by\n   servers for various\
    \ replicas may differ for various reasons.  One\n   server may know about a set\
    \ of replicas that are not known to other\n   servers.  Further, compatibility\
    \ attributes may differ.  Filehandles\n   might be of the same class going from\
    \ replica A to replica B but not\n   going in the reverse direction.  This might\
    \ happen because the\n   filehandles are the same, but replica B's server implementation\
    \ might\n   not have provision to note and report that equivalence.\n   The fs_locations_info\
    \ attribute consists of a root pathname\n   (fli_fs_root, just like fs_root in\
    \ the fs_locations attribute),\n   together with an array of fs_location_item4\
    \ structures.  The\n   fs_location_item4 structures in turn consist of a root\
    \ pathname\n   (fli_rootpath) together with an array (fli_entries) of elements\
    \ of\n   data type fs_locations_server4, all defined as follows.\n   /*\n    *\
    \ Defines an individual server access path\n    */\n   struct  fs_locations_server4\
    \ {\n           int32_t         fls_currency;\n           opaque          fls_info<>;\n\
    \           utf8str_cis     fls_server;\n   };\n   /*\n    * Byte indices of items\
    \ within\n    * fls_info: flag fields, class numbers,\n    * bytes indicating\
    \ ranks and orders.\n    */\n   const FSLI4BX_GFLAGS            = 0;\n   const\
    \ FSLI4BX_TFLAGS            = 1;\n   const FSLI4BX_CLSIMUL           = 2;\n  \
    \ const FSLI4BX_CLHANDLE          = 3;\n   const FSLI4BX_CLFILEID          = 4;\n\
    \   const FSLI4BX_CLWRITEVER        = 5;\n   const FSLI4BX_CLCHANGE          =\
    \ 6;\n   const FSLI4BX_CLREADDIR         = 7;\n   const FSLI4BX_READRANK     \
    \     = 8;\n   const FSLI4BX_WRITERANK         = 9;\n   const FSLI4BX_READORDER\
    \         = 10;\n   const FSLI4BX_WRITEORDER        = 11;\n   /*\n    * Bits defined\
    \ within the general flag byte.\n    */\n   const FSLI4GF_WRITABLE          =\
    \ 0x01;\n   const FSLI4GF_CUR_REQ           = 0x02;\n   const FSLI4GF_ABSENT \
    \           = 0x04;\n   const FSLI4GF_GOING             = 0x08;\n   const FSLI4GF_SPLIT\
    \             = 0x10;\n   /*\n    * Bits defined within the transport flag byte.\n\
    \    */\n   const FSLI4TF_RDMA              = 0x01;\n   /*\n    * Defines a set\
    \ of replicas sharing\n    * a common value of the rootpath\n    * within the\
    \ corresponding\n    * single-server namespaces.\n    */\n   struct  fs_locations_item4\
    \ {\n           fs_locations_server4    fli_entries<>;\n           pathname4 \
    \              fli_rootpath;\n   };\n   /*\n    * Defines the overall structure\
    \ of\n    * the fs_locations_info attribute.\n    */\n   struct  fs_locations_info4\
    \ {\n           uint32_t                fli_flags;\n           int32_t       \
    \          fli_valid_for;\n           pathname4               fli_fs_root;\n \
    \          fs_locations_item4      fli_items<>;\n   };\n   /*\n    * Flag bits\
    \ in fli_flags.\n    */\n   const FSLI4IF_VAR_SUB           = 0x00000001;\n  \
    \ typedef fs_locations_info4 fattr4_fs_locations_info;\n   As noted above, the\
    \ fs_locations_info attribute, when supported, may\n   be requested of absent\
    \ file systems without causing NFS4ERR_MOVED to\n   be returned.  It is generally\
    \ expected that it will be available for\n   both present and absent file systems\
    \ even if only a single\n   fs_locations_server4 entry is present, designating\
    \ the current\n   (present) file system, or two fs_locations_server4 entries\n\
    \   designating the previous location of an absent file system (the one\n   just\
    \ referenced) and its successor location.  Servers are strongly\n   urged to support\
    \ this attribute on all file systems if they support\n   it on any file system.\n\
    \   The data presented in the fs_locations_info attribute may be obtained\n  \
    \ by the server in any number of ways, including specification by the\n   administrator\
    \ or by current protocols for transferring data among\n   replicas and protocols\
    \ not yet developed.  NFSv4.1 only defines how\n   this information is presented\
    \ by the server to the client.\n"
- title: 11.17.1.  The fs_locations_server4 Structure
  contents:
  - "11.17.1.  The fs_locations_server4 Structure\n   The fs_locations_server4 structure\
    \ consists of the following items in\n   addition to the fls_server field, which\
    \ specifies a network address\n   or set of addresses to be used to access the\
    \ specified file system.\n   Note that both of these items (i.e., fls_currency\
    \ and fls_info)\n   specify attributes of the file system replica and should not\
    \ be\n   different when there are multiple fs_locations_server4 structures,\n\
    \   each specifying a network path to the chosen replica, for the same\n   replica.\n\
    \   When these values are different in two fs_locations_server4\n   structures,\
    \ a client has no basis for choosing one over the other and\n   is best off simply\
    \ ignoring both entries, whether these entries apply\n   to migration replication\
    \ or referral.  When there are more than two\n   such entries, majority voting\
    \ can be used to exclude a single\n   erroneous entry from consideration.  In\
    \ the case in which trunking\n   information is provided for a replica currently\
    \ being accessed, the\n   additional trunked addresses can be ignored while access\
    \ continues on\n   the address currently being used, even if the entry corresponding\
    \ to\n   that path might be considered invalid.\n   *  An indication of how up-to-date\
    \ the file system is (fls_currency)\n      in seconds.  This value is relative\
    \ to the master copy.  A\n      negative value indicates that the server is unable\
    \ to give any\n      reasonably useful value here.  A value of zero indicates\
    \ that the\n      file system is the actual writable data or a reliably coherent\
    \ and\n      fully up-to-date copy.  Positive values indicate how out-of-date\n\
    \      this copy can normally be before it is considered for update.\n      Such\
    \ a value is not a guarantee that such updates will always be\n      performed\
    \ on the required schedule but instead serves as a hint\n      about how far the\
    \ copy of the data would be expected to be behind\n      the most up-to-date copy.\n\
    \   *  A counted array of one-byte values (fls_info) containing\n      information\
    \ about the particular file system instance.  This data\n      includes general\
    \ flags, transport capability flags, file system\n      equivalence class information,\
    \ and selection priority information.\n      The encoding will be discussed below.\n\
    \   *  The server string (fls_server).  For the case of the replica\n      currently\
    \ being accessed (via GETATTR), a zero-length string MAY\n      be used to indicate\
    \ the current address being used for the RPC\n      call.  The fls_server field\
    \ can also be an IPv4 or IPv6 address,\n      formatted the same way as an IPv4\
    \ or IPv6 address in the \"server\"\n      field of the fs_location4 data type\
    \ (see Section 11.16).\n   With the exception of the transport-flag field (at\
    \ offset\n   FSLI4BX_TFLAGS with the fls_info array), all of this data defined\
    \ in\n   this specification applies to the replica specified by the entry,\n \
    \  rather than the specific network path used to access it.  The\n   classification\
    \ of data in extensions to this data is discussed below.\n   Data within the fls_info\
    \ array is in the form of 8-bit data items\n   with constants giving the offsets\
    \ within the array of various values\n   describing this particular file system\
    \ instance.  This style of\n   definition was chosen, in preference to explicit\
    \ XDR structure\n   definitions for these values, for a number of reasons.\n \
    \  *  The kinds of data in the fls_info array, representing flags, file\n    \
    \  system classes, and priorities among sets of file systems\n      representing\
    \ the same data, are such that 8 bits provide a quite\n      acceptable range\
    \ of values.  Even where there might be more than\n      256 such file system\
    \ instances, having more than 256 distinct\n      classes or priorities is unlikely.\n\
    \   *  Explicit definition of the various specific data items within XDR\n   \
    \   would limit expandability in that any extension within would\n      require\
    \ yet another attribute, leading to specification and\n      implementation clumsiness.\
    \  In the context of the NFSv4 extension\n      model in effect at the time fs_locations_info\
    \ was designed (i.e.,\n      that which is described in RFC 5661 [66]), this would\
    \ necessitate\n      a new minor version to effect any Standards Track extension\
    \ to the\n      data in fls_info.\n   The set of fls_info data is subject to expansion\
    \ in a future minor\n   version or in a Standards Track RFC within the context\
    \ of a single\n   minor version.  The server SHOULD NOT send and the client MUST\
    \ NOT\n   use indices within the fls_info array or flag bits that are not\n  \
    \ defined in Standards Track RFCs.\n   In light of the new extension model defined\
    \ in RFC 8178 [67] and the\n   fact that the individual items within fls_info\
    \ are not explicitly\n   referenced in the XDR, the following practices should\
    \ be followed\n   when extending or otherwise changing the structure of the data\n\
    \   returned in fls_info within the scope of a single minor version:\n   *  All\
    \ extensions need to be described by Standards Track documents.\n      There is\
    \ no need for such documents to be marked as updating RFC\n      5661 [66] or\
    \ this document.\n   *  It needs to be made clear whether the information in any\
    \ added\n      data items applies to the replica specified by the entry or to\
    \ the\n      specific network paths specified in the entry.\n   *  There needs\
    \ to be a reliable way defined to determine whether the\n      server is aware\
    \ of the extension.  This may be based on the length\n      field of the fls_info\
    \ array, but it is more flexible to provide\n      fs-scope or server-scope attributes\
    \ to indicate what extensions\n      are provided.\n   This encoding scheme can\
    \ be adapted to the specification of multi-\n   byte numeric values, even though\
    \ none are currently defined.  If\n   extensions are made via Standards Track\
    \ RFCs, multi-byte quantities\n   will be encoded as a range of bytes with a range\
    \ of indices, with the\n   byte interpreted in big-endian byte order.  Further,\
    \ any such index\n   assignments will be constrained by the need for the relevant\n\
    \   quantities not to cross XDR word boundaries.\n   The fls_info array currently\
    \ contains:\n   *  Two 8-bit flag fields, one devoted to general file-system\n\
    \      characteristics and a second reserved for transport-related\n      capabilities.\n\
    \   *  Six 8-bit class values that define various file system equivalence\n  \
    \    classes as explained below.\n   *  Four 8-bit priority values that govern\
    \ file system selection as\n      explained below.\n   The general file system\
    \ characteristics flag (at byte index\n   FSLI4BX_GFLAGS) has the following bits\
    \ defined within it:\n   *  FSLI4GF_WRITABLE indicates that this file system target\
    \ is\n      writable, allowing it to be selected by clients that may need to\n\
    \      write on this file system.  When the current file system instance\n   \
    \   is writable and is defined as of the same simultaneous use class\n      (as\
    \ specified by the value at index FSLI4BX_CLSIMUL) to which the\n      client\
    \ was previously writing, then it must incorporate within its\n      data any\
    \ committed write made on the source file system instance.\n      See Section\
    \ 11.11.6, which discusses the write-verifier class.\n      While there is no\
    \ harm in not setting this flag for a file system\n      that turns out to be\
    \ writable, turning the flag on for a read-only\n      file system can cause problems\
    \ for clients that select a migration\n      or replication target based on the\
    \ flag and then find themselves\n      unable to write.\n   *  FSLI4GF_CUR_REQ\
    \ indicates that this replica is the one on which\n      the request is being\
    \ made.  Only a single server entry may have\n      this flag set and, in the\
    \ case of a referral, no entry will have\n      it set.  Note that this flag might\
    \ be set even if the request was\n      made on a network access path different\
    \ from any of those\n      specified in the current entry.\n   *  FSLI4GF_ABSENT\
    \ indicates that this entry corresponds to an absent\n      file system replica.\
    \  It can only be set if FSLI4GF_CUR_REQ is\n      set.  When both such bits are\
    \ set, it indicates that a file system\n      instance is not usable but that\
    \ the information in the entry can\n      be used to determine the sorts of continuity\
    \ available when\n      switching from this replica to other possible replicas.\
    \  Since\n      this bit can only be true if FSLI4GF_CUR_REQ is true, the value\n\
    \      could be determined using the fs_status attribute, but the\n      information\
    \ is also made available here for the convenience of the\n      client.  An entry\
    \ with this bit, since it represents a true file\n      system (albeit absent),\
    \ does not appear in the event of a\n      referral, but only when a file system\
    \ has been accessed at this\n      location and has subsequently been migrated.\n\
    \   *  FSLI4GF_GOING indicates that a replica, while still available,\n      should\
    \ not be used further.  The client, if using it, should make\n      an orderly\
    \ transfer to another file system instance as\n      expeditiously as possible.\
    \  It is expected that file systems going\n      out of service will be announced\
    \ as FSLI4GF_GOING some time before\n      the actual loss of service.  It is\
    \ also expected that the\n      fli_valid_for value will be sufficiently small\
    \ to allow clients to\n      detect and act on scheduled events, while large enough\
    \ that the\n      cost of the requests to fetch the fs_locations_info values will\n\
    \      not be excessive.  Values on the order of ten minutes seem\n      reasonable.\n\
    \      When this flag is seen as part of a transition into a new file\n      system,\
    \ a client might choose to transfer immediately to another\n      replica, or\
    \ it may reference the current file system and only\n      transition when a migration\
    \ event occurs.  Similarly, when this\n      flag appears as a replica in the\
    \ referral, clients would likely\n      avoid being referred to this instance\
    \ whenever there is another\n      choice.\n      This flag, like the other items\
    \ within fls_info, applies to the\n      replica rather than to a particular path\
    \ to that replica.  When it\n      appears, a transition to a new replica, rather\
    \ than to a different\n      path to the same replica, is indicated.\n   *  FSLI4GF_SPLIT\
    \ indicates that when a transition occurs from the\n      current file system\
    \ instance to this one, the replacement may\n      consist of multiple file systems.\
    \  In this case, the client has to\n      be prepared for the possibility that\
    \ objects on the same file\n      system before migration will be on different\
    \ ones after.  Note\n      that FSLI4GF_SPLIT is not incompatible with the file\
    \ systems\n      belonging to the same fileid class since, if one has a set of\n\
    \      fileids that are unique within a file system, each subset assigned\n  \
    \    to a smaller file system after migration would not have any\n      conflicts\
    \ internal to that file system.\n      A client, in the case of a split file system,\
    \ will interrogate\n      existing files with which it has continuing connection\
    \ (it is free\n      to simply forget cached filehandles).  If the client remembers\
    \ the\n      directory filehandle associated with each open file, it may\n   \
    \   proceed upward using LOOKUPP to find the new file system\n      boundaries.\
    \  Note that in the event of a referral, there will not\n      be any such files\
    \ and so these actions will not be performed.\n      Instead, a reference to a\
    \ portion of the original file system now\n      split off into other file systems\
    \ will encounter an fsid change\n      and possibly a further referral.\n    \
    \  Once the client recognizes that one file system has been split\n      into\
    \ two, it can prevent the disruption of running applications by\n      presenting\
    \ the two file systems as a single one until a convenient\n      point to recognize\
    \ the transition, such as a restart.  This would\n      require a mapping from\
    \ the server's fsids to fsids as seen by the\n      client, but this is already\
    \ necessary for other reasons.  As noted\n      above, existing fileids within\
    \ the two descendant file systems\n      will not conflict.  Providing non-conflicting\
    \ fileids for newly\n      created files on the split file systems is the responsibility\
    \ of\n      the server (or servers working in concert).  The server can encode\n\
    \      filehandles such that filehandles generated before the split event\n  \
    \    can be discerned from those generated after the split, allowing\n      the\
    \ server to determine when the need for emulating two file\n      systems as one\
    \ is over.\n      Although it is possible for this flag to be present in the event\n\
    \      of referral, it would generally be of little interest to the\n      client,\
    \ since the client is not expected to have information\n      regarding the current\
    \ contents of the absent file system.\n   The transport-flag field (at byte index\
    \ FSLI4BX_TFLAGS) contains the\n   following bits related to the transport capabilities\
    \ of the specific\n   network path(s) specified by the entry:\n   *  FSLI4TF_RDMA\
    \ indicates that any specified network paths provide\n      NFSv4.1 clients access\
    \ using an RDMA-capable transport.\n   Attribute continuity and file system identity\
    \ information are\n   expressed by defining equivalence relations on the sets\
    \ of file\n   systems presented to the client.  Each such relation is expressed\
    \ as\n   a set of file system equivalence classes.  For each relation, a file\n\
    \   system has an 8-bit class number.  Two file systems belong to the\n   same\
    \ class if both have identical non-zero class numbers.  Zero is\n   treated as\
    \ non-matching.  Most often, the relevant question for the\n   client will be\
    \ whether a given replica is identical to / continuous\n   with the current one\
    \ in a given respect, but the information should\n   be available also as to whether\
    \ two other replicas match in that\n   respect as well.\n   The following fields\
    \ specify the file system's class numbers for the\n   equivalence relations used\
    \ in determining the nature of file system\n   transitions.  See Sections 11.9\
    \ through 11.14 and their various\n   subsections for details about how this information\
    \ is to be used.\n   Servers may assign these values as they wish, so long as\
    \ file system\n   instances that share the same value have the specified relationship\n\
    \   to one another; conversely, file systems that have the specified\n   relationship\
    \ to one another share a common class value.  As each\n   instance entry is added,\
    \ the relationships of this instance to\n   previously entered instances can be\
    \ consulted, and if one is found\n   that bears the specified relationship, that\
    \ entry's class value can\n   be copied to the new entry.  When no such previous\
    \ entry exists, a\n   new value for that byte index (not previously used) can\
    \ be selected,\n   most likely by incrementing the value of the last class value\n\
    \   assigned for that index.\n   *  The field with byte index FSLI4BX_CLSIMUL\
    \ defines the\n      simultaneous-use class for the file system.\n   *  The field\
    \ with byte index FSLI4BX_CLHANDLE defines the handle\n      class for the file\
    \ system.\n   *  The field with byte index FSLI4BX_CLFILEID defines the fileid\n\
    \      class for the file system.\n   *  The field with byte index FSLI4BX_CLWRITEVER\
    \ defines the write-\n      verifier class for the file system.\n   *  The field\
    \ with byte index FSLI4BX_CLCHANGE defines the change\n      class for the file\
    \ system.\n   *  The field with byte index FSLI4BX_CLREADDIR defines the readdir\n\
    \      class for the file system.\n   Server-specified preference information\
    \ is also provided via 8-bit\n   values within the fls_info array.  The values\
    \ provide a rank and an\n   order (see below) to be used with separate values\
    \ specifiable for the\n   cases of read-only and writable file systems.  These\
    \ values are\n   compared for different file systems to establish the server-specified\n\
    \   preference, with lower values indicating \"more preferred\".\n   Rank is used\
    \ to express a strict server-imposed ordering on clients,\n   with lower values\
    \ indicating \"more preferred\".  Clients should\n   attempt to use all replicas\
    \ with a given rank before they use one\n   with a higher rank.  Only if all of\
    \ those file systems are\n   unavailable should the client proceed to those of\
    \ a higher rank.\n   Because specifying a rank will override client preferences,\
    \ servers\n   should be conservative about using this mechanism, particularly\
    \ when\n   the environment is one in which client communication characteristics\n\
    \   are neither tightly controlled nor visible to the server.\n   Within a rank,\
    \ the order value is used to specify the server's\n   preference to guide the\
    \ client's selection when the client's own\n   preferences are not controlling,\
    \ with lower values of order\n   indicating \"more preferred\".  If replicas are\
    \ approximately equal in\n   all respects, clients should defer to the order specified\
    \ by the\n   server.  When clients look at server latency as part of their\n \
    \  selection, they are free to use this criterion, but it is suggested\n   that\
    \ when latency differences are not significant, the server-\n   specified order\
    \ should guide selection.\n   *  The field at byte index FSLI4BX_READRANK gives\
    \ the rank value to\n      be used for read-only access.\n   *  The field at byte\
    \ index FSLI4BX_READORDER gives the order value to\n      be used for read-only\
    \ access.\n   *  The field at byte index FSLI4BX_WRITERANK gives the rank value\
    \ to\n      be used for writable access.\n   *  The field at byte index FSLI4BX_WRITEORDER\
    \ gives the order value\n      to be used for writable access.\n   Depending on\
    \ the potential need for write access by a given client,\n   one of the pairs\
    \ of rank and order values is used.  The read rank and\n   order should only be\
    \ used if the client knows that only reading will\n   ever be done or if it is\
    \ prepared to switch to a different replica in\n   the event that any write access\
    \ capability is required in the future.\n"
- title: 11.17.2.  The fs_locations_info4 Structure
  contents:
  - "11.17.2.  The fs_locations_info4 Structure\n   The fs_locations_info4 structure,\
    \ encoding the fs_locations_info\n   attribute, contains the following:\n   *\
    \  The fli_flags field, which contains general flags that affect the\n      interpretation\
    \ of this fs_locations_info4 structure and all\n      fs_locations_item4 structures\
    \ within it.  The only flag currently\n      defined is FSLI4IF_VAR_SUB.  All\
    \ bits in the fli_flags field that\n      are not defined should always be returned\
    \ as zero.\n   *  The fli_fs_root field, which contains the pathname of the root\
    \ of\n      the current file system on the current server, just as it does in\n\
    \      the fs_locations4 structure.\n   *  An array called fli_items of fs_locations4_item\
    \ structures, which\n      contain information about replicas of the current file\
    \ system.\n      Where the current file system is actually present, or has been\n\
    \      present, i.e., this is not a referral situation, one of the\n      fs_locations_item4\
    \ structures will contain an fs_locations_server4\n      for the current server.\
    \  This structure will have FSLI4GF_ABSENT\n      set if the current file system\
    \ is absent, i.e., normal access to\n      it will return NFS4ERR_MOVED.\n   *\
    \  The fli_valid_for field specifies a time in seconds for which it\n      is\
    \ reasonable for a client to use the fs_locations_info attribute\n      without\
    \ refetch.  The fli_valid_for value does not provide a\n      guarantee of validity\
    \ since servers can unexpectedly go out of\n      service or become inaccessible\
    \ for any number of reasons.  Clients\n      are well-advised to refetch this\
    \ information for an actively\n      accessed file system at every fli_valid_for\
    \ seconds.  This is\n      particularly important when file system replicas may\
    \ go out of\n      service in a controlled way using the FSLI4GF_GOING flag to\n\
    \      communicate an ongoing change.  The server should set\n      fli_valid_for\
    \ to a value that allows well-behaved clients to\n      notice the FSLI4GF_GOING\
    \ flag and make an orderly switch before\n      the loss of service becomes effective.\
    \  If this value is zero,\n      then no refetch interval is appropriate and the\
    \ client need not\n      refetch this data on any particular schedule.  In the\
    \ event of a\n      transition to a new file system instance, a new value of the\n\
    \      fs_locations_info attribute will be fetched at the destination.\n     \
    \ It is to be expected that this may have a different fli_valid_for\n      value,\
    \ which the client should then use in the same fashion as the\n      previous\
    \ value.  Because a refetch of the attribute causes\n      information from all\
    \ component entries to be refetched, the server\n      will typically provide\
    \ a low value for this field if any of the\n      replicas are likely to go out\
    \ of service in a short time frame.\n      Note that, because of the ability of\
    \ the server to return\n      NFS4ERR_MOVED to trigger the use of different paths,\
    \ when\n      alternate trunked paths are available, there is generally no need\n\
    \      to use low values of fli_valid_for in connection with the\n      management\
    \ of alternate paths to the same replica.\n   The FSLI4IF_VAR_SUB flag within\
    \ fli_flags controls whether variable\n   substitution is to be enabled.  See\
    \ Section 11.17.3 for an\n   explanation of variable substitution.\n"
- title: 11.17.3.  The fs_locations_item4 Structure
  contents:
  - "11.17.3.  The fs_locations_item4 Structure\n   The fs_locations_item4 structure\
    \ contains a pathname (in the field\n   fli_rootpath) that encodes the path of\
    \ the target file system\n   replicas on the set of servers designated by the\
    \ included\n   fs_locations_server4 entries.  The precise manner in which this\n\
    \   target location is specified depends on the value of the\n   FSLI4IF_VAR_SUB\
    \ flag within the associated fs_locations_info4\n   structure.\n   If this flag\
    \ is not set, then fli_rootpath simply designates the\n   location of the target\
    \ file system within each server's single-server\n   namespace just as it does\
    \ for the rootpath within the fs_location4\n   structure.  When this bit is set,\
    \ however, component entries of a\n   certain form are subject to client-specific\
    \ variable substitution so\n   as to allow a degree of namespace non-uniformity\
    \ in order to\n   accommodate the selection of client-specific file system targets\
    \ to\n   adapt to different client architectures or other characteristics.\n \
    \  When such substitution is in effect, a variable beginning with the\n   string\
    \ \"${\" and ending with the string \"}\" and containing a colon is\n   to be\
    \ replaced by the client-specific value associated with that\n   variable.  The\
    \ string \"unknown\" should be used by the client when it\n   has no value for\
    \ such a variable.  The pathname resulting from such\n   substitutions is used\
    \ to designate the target file system, so that\n   different clients may have\
    \ different file systems, corresponding to\n   that location in the multi-server\
    \ namespace.\n   As mentioned above, such substituted pathname variables contain\
    \ a\n   colon.  The part before the colon is to be a DNS domain name, and the\n\
    \   part after is to be a case-insensitive alphanumeric string.\n   Where the\
    \ domain is \"ietf.org\", only variable names defined in this\n   document or\
    \ subsequent Standards Track RFCs are subject to such\n   substitution.  Organizations\
    \ are free to use their domain names to\n   create their own sets of client-specific\
    \ variables, to be subject to\n   such substitution.  In cases where such variables\
    \ are intended to be\n   used more broadly than a single organization, publication\
    \ of an\n   Informational RFC defining such variables is RECOMMENDED.\n   The\
    \ variable ${ietf.org:CPU_ARCH} is used to denote that the CPU\n   architecture\
    \ object files are compiled.  This specification does not\n   limit the acceptable\
    \ values (except that they must be valid UTF-8\n   strings), but such values as\
    \ \"x86\", \"x86_64\", and \"sparc\" would be\n   expected to be used in line\
    \ with industry practice.\n   The variable ${ietf.org:OS_TYPE} is used to denote\
    \ the operating\n   system, and thus the kernel and library APIs, for which code\
    \ might be\n   compiled.  This specification does not limit the acceptable values\n\
    \   (except that they must be valid UTF-8 strings), but such values as\n   \"\
    linux\" and \"freebsd\" would be expected to be used in line with\n   industry\
    \ practice.\n   The variable ${ietf.org:OS_VERSION} is used to denote the operating\n\
    \   system version, and thus the specific details of versioned\n   interfaces,\
    \ for which code might be compiled.  This specification\n   does not limit the\
    \ acceptable values (except that they must be valid\n   UTF-8 strings).  However,\
    \ combinations of numbers and letters with\n   interspersed dots would be expected\
    \ to be used in line with industry\n   practice, with the details of the version\
    \ format depending on the\n   specific value of the variable ${ietf.org:OS_TYPE}\
    \ with which it is\n   used.\n   Use of these variables could result in the direction\
    \ of different\n   clients to different file systems on the same server, as appropriate\n\
    \   to particular clients.  In cases in which the target file systems are\n  \
    \ located on different servers, a single server could serve as a\n   referral\
    \ point so that each valid combination of variable values\n   would designate\
    \ a referral hosted on a single server, with the\n   targets of those referrals\
    \ on a number of different servers.\n   Because namespace administration is affected\
    \ by the values selected\n   to substitute for various variables, clients should\
    \ provide\n   convenient means of determining what variable substitutions a client\n\
    \   will implement, as well as, where appropriate, providing means to\n   control\
    \ the substitutions to be used.  The exact means by which this\n   will be done\
    \ is outside the scope of this specification.\n   Although variable substitution\
    \ is most suitable for use in the\n   context of referrals, it may be used in\
    \ the context of replication\n   and migration.  If it is used in these contexts,\
    \ the server must\n   ensure that no matter what values the client presents for\
    \ the\n   substituted variables, the result is always a valid successor file\n\
    \   system instance to that from which a transition is occurring, i.e.,\n   that\
    \ the data is identical or represents a later image of a writable\n   file system.\n\
    \   Note that when fli_rootpath is a null pathname (that is, one with\n   zero\
    \ components), the file system designated is at the root of the\n   specified\
    \ server, whether or not the FSLI4IF_VAR_SUB flag within the\n   associated fs_locations_info4\
    \ structure is set.\n"
- title: 11.18.  The Attribute fs_status
  contents:
  - "11.18.  The Attribute fs_status\n   In an environment in which multiple copies\
    \ of the same basic set of\n   data are available, information regarding the particular\
    \ source of\n   such data and the relationships among different copies can be\
    \ very\n   helpful in providing consistent data to applications.\n   enum fs4_status_type\
    \ {\n           STATUS4_FIXED = 1,\n           STATUS4_UPDATED = 2,\n        \
    \   STATUS4_VERSIONED = 3,\n           STATUS4_WRITABLE = 4,\n           STATUS4_REFERRAL\
    \ = 5\n   };\n   struct fs4_status {\n           bool            fss_absent;\n\
    \           fs4_status_type fss_type;\n           utf8str_cs      fss_source;\n\
    \           utf8str_cs      fss_current;\n           int32_t         fss_age;\n\
    \           nfstime4        fss_version;\n   };\n   The boolean fss_absent indicates\
    \ whether the file system is currently\n   absent.  This value will be set if\
    \ the file system was previously\n   present and becomes absent, or if the file\
    \ system has never been\n   present and the type is STATUS4_REFERRAL.  When this\
    \ boolean is set\n   and the type is not STATUS4_REFERRAL, the remaining information\
    \ in\n   the fs4_status reflects that last valid when the file system was\n  \
    \ present.\n   The fss_type field indicates the kind of file system image\n  \
    \ represented.  This is of particular importance when using the version\n   values\
    \ to determine appropriate succession of file system images.\n   When fss_absent\
    \ is set, and the file system was previously present,\n   the value of fss_type\
    \ reflected is that when the file was last\n   present.  Five values are distinguished:\n\
    \   *  STATUS4_FIXED, which indicates a read-only image in the sense that\n  \
    \    it will never change.  The possibility is allowed that, as a\n      result\
    \ of migration or switch to a different image, changed data\n      can be accessed,\
    \ but within the confines of this instance, no\n      change is allowed.  The\
    \ client can use this fact to cache\n      aggressively.\n   *  STATUS4_VERSIONED,\
    \ which indicates that the image, like the\n      STATUS4_UPDATED case, is updated\
    \ externally, but it provides a\n      guarantee that the server will carefully\
    \ update an associated\n      version value so that the client can protect itself\
    \ from a\n      situation in which it reads data from one version of the file\n\
    \      system and then later reads data from an earlier version of the\n     \
    \ same file system.  See below for a discussion of how this can be\n      done.\n\
    \   *  STATUS4_UPDATED, which indicates an image that cannot be updated\n    \
    \  by the user writing to it but that may be changed externally,\n      typically\
    \ because it is a periodically updated copy of another\n      writable file system\
    \ somewhere else.  In this case, version\n      information is not provided, and\
    \ the client does not have the\n      responsibility of making sure that this\
    \ version only advances upon\n      a file system instance transition.  In this\
    \ case, it is the\n      responsibility of the server to make sure that the data\
    \ presented\n      after a file system instance transition is a proper successor\n\
    \      image and includes all changes seen by the client and any change\n    \
    \  made before all such changes.\n   *  STATUS4_WRITABLE, which indicates that\
    \ the file system is an\n      actual writable one.  The client need not, of course,\
    \ actually\n      write to the file system, but once it does, it should not accept\
    \ a\n      transition to anything other than a writable instance of that same\n\
    \      file system.\n   *  STATUS4_REFERRAL, which indicates that the file system\
    \ in question\n      is absent and has never been present on this server.\n  \
    \ Note that in the STATUS4_UPDATED and STATUS4_VERSIONED cases, the\n   server\
    \ is responsible for the appropriate handling of locks that are\n   inconsistent\
    \ with external changes to delegations.  If a server gives\n   out delegations,\
    \ they SHOULD be recalled before an inconsistent\n   change is made to the data,\
    \ and MUST be revoked if this is not\n   possible.  Similarly, if an OPEN is inconsistent\
    \ with data that is\n   changed (the OPEN has OPEN4_SHARE_DENY_WRITE/OPEN4_SHARE_DENY_BOTH\n\
    \   and the data is changed), that OPEN SHOULD be considered\n   administratively\
    \ revoked.\n   The opaque strings fss_source and fss_current provide a way of\n\
    \   presenting information about the source of the file system image\n   being\
    \ present.  It is not intended that the client do anything with\n   this information\
    \ other than make it available to administrative\n   tools.  It is intended that\
    \ this information be helpful when\n   researching possible problems with a file\
    \ system image that might\n   arise when it is unclear if the correct image is\
    \ being accessed and,\n   if not, how that image came to be made.  This kind of\
    \ diagnostic\n   information will be helpful, if, as seems likely, copies of file\n\
    \   systems are made in many different ways (e.g., simple user-level\n   copies,\
    \ file-system-level point-in-time copies, clones of the\n   underlying storage),\
    \ under a variety of administrative arrangements.\n   In such environments, determining\
    \ how a given set of data was\n   constructed can be very helpful in resolving\
    \ problems.\n   The opaque string fss_source is used to indicate the source of\
    \ a\n   given file system with the expectation that tools capable of creating\n\
    \   a file system image propagate this information, when possible.  It is\n  \
    \ understood that this may not always be possible since a user-level\n   copy\
    \ may be thought of as creating a new data set and the tools used\n   may have\
    \ no mechanism to propagate this data.  When a file system is\n   initially created,\
    \ it is desirable to associate with it data\n   regarding how the file system\
    \ was created, where it was created, who\n   created it, etc.  Making this information\
    \ available in this attribute\n   in a human-readable string will be helpful for\
    \ applications and\n   system administrators and will also serve to make it available\
    \ when\n   the original file system is used to make subsequent copies.\n   The\
    \ opaque string fss_current should provide whatever information is\n   available\
    \ about the source of the current copy.  Such information\n   includes the tool\
    \ creating it, any relevant parameters to that tool,\n   the time at which the\
    \ copy was done, the user making the change, the\n   server on which the change\
    \ was made, etc.  All information should be\n   in a human-readable string.\n\
    \   The field fss_age provides an indication of how out-of-date the file\n   system\
    \ currently is with respect to its ultimate data source (in case\n   of cascading\
    \ data updates).  This complements the fls_currency field\n   of fs_locations_server4\
    \ (see Section 11.17) in the following way: the\n   information in fls_currency\
    \ gives a bound for how out of date the\n   data in a file system might typically\
    \ get, while the value in fss_age\n   gives a bound on how out-of-date that data\
    \ actually is.  Negative\n   values imply that no information is available.  A\
    \ zero means that\n   this data is known to be current.  A positive value means\
    \ that this\n   data is known to be no older than that number of seconds with\
    \ respect\n   to the ultimate data source.  Using this value, the client may be\n\
    \   able to decide that a data copy is too old, so that it may search for\n  \
    \ a newer version to use.\n   The fss_version field provides a version identification,\
    \ in the form\n   of a time value, such that successive versions always have later\
    \ time\n   values.  When the fs_type is anything other than STATUS4_VERSIONED,\n\
    \   the server may provide such a value, but there is no guarantee as to\n   its\
    \ validity and clients will not use it except to provide additional\n   information\
    \ to add to fss_source and fss_current.\n   When fss_type is STATUS4_VERSIONED,\
    \ servers SHOULD provide a value of\n   fss_version that progresses monotonically\
    \ whenever any new version of\n   the data is established.  This allows the client,\
    \ if reliable image\n   progression is important to it, to fetch this attribute\
    \ as part of\n   each COMPOUND where data or metadata from the file system is\
    \ used.\n   When it is important to the client to make sure that only valid\n\
    \   successor images are accepted, it must make sure that it does not\n   read\
    \ data or metadata from the file system without updating its sense\n   of the\
    \ current state of the image.  This is to avoid the possibility\n   that the fs_status\
    \ that the client holds will be one for an earlier\n   image, which would cause\
    \ the client to accept a new file system\n   instance that is later than that\
    \ but still earlier than the updated\n   data read by the client.\n   In order\
    \ to accept valid images reliably, the client must do a\n   GETATTR of the fs_status\
    \ attribute that follows any interrogation of\n   data or metadata within the\
    \ file system in question.  Often this is\n   most conveniently done by appending\
    \ such a GETATTR after all other\n   operations that reference a given file system.\
    \  When errors occur\n   between reading file system data and performing such\
    \ a GETATTR, care\n   must be exercised to make sure that the data in question\
    \ is not used\n   before obtaining the proper fs_status value.  In this connection,\n\
    \   when an OPEN is done within such a versioned file system and the\n   associated\
    \ GETATTR of fs_status is not successfully completed, the\n   open file in question\
    \ must not be accessed until that fs_status is\n   fetched.\n   The procedure\
    \ above will ensure that before using any data from the\n   file system the client\
    \ has in hand a newly-fetched current version of\n   the file system image.  Multiple\
    \ values for multiple requests in\n   flight can be resolved by assembling them\
    \ into the required partial\n   order (and the elements should form a total order\
    \ within the partial\n   order) and using the last.  The client may then, when\
    \ switching among\n   file system instances, decline to use an instance that does\
    \ not have\n   an fss_type of STATUS4_VERSIONED or whose fss_version field is\n\
    \   earlier than the last one obtained from the predecessor file system\n   instance.\n"
- title: 12.  Parallel NFS (pNFS)
  contents:
  - '12.  Parallel NFS (pNFS)

    '
- title: 12.1.  Introduction
  contents:
  - "12.1.  Introduction\n   pNFS is an OPTIONAL feature within NFSv4.1; the pNFS\
    \ feature set\n   allows direct client access to the storage devices containing\
    \ file\n   data.  When file data for a single NFSv4 server is stored on multiple\n\
    \   and/or higher-throughput storage devices (by comparison to the\n   server's\
    \ throughput capability), the result can be significantly\n   better file access\
    \ performance.  The relationship among multiple\n   clients, a single server,\
    \ and multiple storage devices for pNFS\n   (server and clients have access to\
    \ all storage devices) is shown in\n   Figure 1.\n       +-----------+\n     \
    \  |||           |        NFSv4.1 + pNFS          |           |\n       +||  Clients\
    \  |<------------------------------>|   Server  |\n              ||| Storage \
    \       +-----------+              |\n              ||| Protocol       |+-----------+\
    \             |\n   In this model, the clients, server, and storage devices are\n\
    \   responsible for managing file access.  This is in contrast to NFSv4\n   without\
    \ pNFS, where it is primarily the server's responsibility; some\n   of this responsibility\
    \ may be delegated to the client under strictly\n   specified conditions.  See\
    \ Section 12.2.5 for a discussion of the\n   Storage Protocol.  See Section 12.2.6\
    \ for a discussion of the Control\n   Protocol.\n   pNFS takes the form of OPTIONAL\
    \ operations that manage protocol\n   objects called 'layouts' (Section 12.2.7)\
    \ that contain a byte-range\n   and storage location information.  The layout\
    \ is managed in a similar\n   fashion as NFSv4.1 data delegations.  For example,\
    \ the layout is\n   leased, recallable, and revocable.  However, layouts are distinct\n\
    \   abstractions and are manipulated with new operations.  When a client\n   holds\
    \ a layout, it is granted the ability to directly access the\n   byte-range at\
    \ the storage location specified in the layout.\n   There are interactions between\
    \ layouts and other NFSv4.1 abstractions\n   such as data delegations and byte-range\
    \ locking.  Delegation issues\n   are discussed in Section 12.5.5.  Byte-range\
    \ locking issues are\n   discussed in Sections 12.2.9 and 12.5.1.\n"
- title: 12.2.  pNFS Definitions
  contents:
  - "12.2.  pNFS Definitions\n   NFSv4.1's pNFS feature provides parallel data access\
    \ to a file system\n   that stripes its content across multiple storage servers.\
    \  The first\n   instantiation of pNFS, as part of NFSv4.1, separates the file\
    \ system\n   protocol processing into two parts: metadata processing and data\n\
    \   processing.  Data consist of the contents of regular files that are\n   striped\
    \ across storage servers.  Data striping occurs in at least two\n   ways: on a\
    \ file-by-file basis and, within sufficiently large files,\n   on a block-by-block\
    \ basis.  In contrast, striped access to metadata\n   by pNFS clients is not provided\
    \ in NFSv4.1, even though the file\n   system back end of a pNFS server might\
    \ stripe metadata.  Metadata\n   consist of everything else, including the contents\
    \ of non-regular\n   files (e.g., directories); see Section 12.2.1.  The metadata\n\
    \   functionality is implemented by an NFSv4.1 server that supports pNFS\n   and\
    \ the operations described in Section 18; such a server is called a\n   metadata\
    \ server (Section 12.2.2).\n   The data functionality is implemented by one or\
    \ more storage devices,\n   each of which are accessed by the client via a storage\
    \ protocol.  A\n   subset (defined in Section 13.6) of NFSv4.1 is one such storage\n\
    \   protocol.  New terms are introduced to the NFSv4.1 nomenclature and\n   existing\
    \ terms are clarified to allow for the description of the pNFS\n   feature.\n"
- title: 12.2.1.  Metadata
  contents:
  - "12.2.1.  Metadata\n   Information about a file system object, such as its name,\
    \ location\n   within the namespace, owner, ACL, and other attributes.  Metadata\
    \ may\n   also include storage location information, and this will vary based\n\
    \   on the underlying storage mechanism that is used.\n"
- title: 12.2.2.  Metadata Server
  contents:
  - "12.2.2.  Metadata Server\n   An NFSv4.1 server that supports the pNFS feature.\
    \  A variety of\n   architectural choices exist for the metadata server and its\
    \ use of\n   file system information held at the server.  Some servers may contain\n\
    \   metadata only for file objects residing at the metadata server, while\n  \
    \ the file data resides on associated storage devices.  Other metadata\n   servers\
    \ may hold both metadata and a varying degree of file data.\n"
- title: 12.2.3.  pNFS Client
  contents:
  - "12.2.3.  pNFS Client\n   An NFSv4.1 client that supports pNFS operations and\
    \ supports at least\n   one storage protocol for performing I/O to storage devices.\n"
- title: 12.2.4.  Storage Device
  contents:
  - "12.2.4.  Storage Device\n   A storage device stores a regular file's data, but\
    \ leaves metadata\n   management to the metadata server.  A storage device could\
    \ be another\n   NFSv4.1 server, an object-based storage device (OSD), a block\
    \ device\n   accessed over a System Area Network (SAN, e.g., either FiberChannel\n\
    \   or iSCSI SAN), or some other entity.\n"
- title: 12.2.5.  Storage Protocol
  contents:
  - "12.2.5.  Storage Protocol\n   As noted in Figure 1, the storage protocol is the\
    \ method used by the\n   client to store and retrieve data directly from the storage\
    \ devices.\n   The NFSv4.1 pNFS feature has been structured to allow for a variety\n\
    \   of storage protocols to be defined and used.  One example storage\n   protocol\
    \ is NFSv4.1 itself (as documented in Section 13).  Other\n   options for the\
    \ storage protocol are described elsewhere and include:\n   *  Block/volume protocols\
    \ such as Internet SCSI (iSCSI) [56] and FCP\n      [57].  The block/volume protocol\
    \ support can be independent of the\n      addressing structure of the block/volume\
    \ protocol used, allowing\n      more than one protocol to access the same file\
    \ data and enabling\n      extensibility to other block/volume protocols.  See\
    \ [48] for a\n      layout specification that allows pNFS to use block/volume\
    \ storage\n      protocols.\n   *  Object protocols such as OSD over iSCSI or\
    \ Fibre Channel [58].\n      See [47] for a layout specification that allows pNFS\
    \ to use object\n      storage protocols.\n   It is possible that various storage\
    \ protocols are available to both\n   client and server and it may be possible\
    \ that a client and server do\n   not have a matching storage protocol available\
    \ to them.  Because of\n   this, the pNFS server MUST support normal NFSv4.1 access\
    \ to any file\n   accessible by the pNFS feature; this will allow for continued\n\
    \   interoperability between an NFSv4.1 client and server.\n"
- title: 12.2.6.  Control Protocol
  contents:
  - "12.2.6.  Control Protocol\n   As noted in Figure 1, the control protocol is used\
    \ by the exported\n   file system between the metadata server and storage devices.\n\
    \   Specification of such protocols is outside the scope of the NFSv4.1\n   protocol.\
    \  Such control protocols would be used to control activities\n   such as the\
    \ allocation and deallocation of storage, the management of\n   state required\
    \ by the storage devices to perform client access\n   control, and, depending\
    \ on the storage protocol, the enforcement of\n   authentication and authorization\
    \ so that restrictions that would be\n   enforced by the metadata server are also\
    \ enforced by the storage\n   device.\n   A particular control protocol is not\
    \ REQUIRED by NFSv4.1 but\n   requirements are placed on the control protocol\
    \ for maintaining\n   attributes like modify time, the change attribute, and the\
    \ end-of-\n   file (EOF) position.  Note that if pNFS is layered over a clustered,\n\
    \   parallel file system (e.g., PVFS [59]), the mechanisms that enable\n   clustering\
    \ and parallelism in that file system can be considered the\n   control protocol.\n"
- title: 12.2.7.  Layout Types
  contents:
  - "12.2.7.  Layout Types\n   A layout describes the mapping of a file's data to\
    \ the storage\n   devices that hold the data.  A layout is said to belong to a\
    \ specific\n   layout type (data type layouttype4, see Section 3.3.13).  The layout\n\
    \   type allows for variants to handle different storage protocols, such\n   as\
    \ those associated with block/volume [48], object [47], and file\n   (Section\
    \ 13) layout types.  A metadata server, along with its control\n   protocol, MUST\
    \ support at least one layout type.  A private sub-range\n   of the layout type\
    \ namespace is also defined.  Values from the\n   private layout type range MAY\
    \ be used for internal testing or\n   experimentation (see Section 3.3.13).\n\
    \   As an example, the organization of the file layout type could be an\n   array\
    \ of tuples (e.g., device ID, filehandle), along with a\n   definition of how\
    \ the data is stored across the devices (e.g.,\n   striping).  A block/volume\
    \ layout might be an array of tuples that\n   store <device ID, block number,\
    \ block count> along with information\n   about block size and the associated\
    \ file offset of the block number.\n   An object layout might be an array of tuples\
    \ <device ID, object ID>\n   and an additional structure (i.e., the aggregation\
    \ map) that defines\n   how the logical byte sequence of the file data is serialized\
    \ into the\n   different objects.  Note that the actual layouts are typically\
    \ more\n   complex than these simple expository examples.\n   Requests for pNFS-related\
    \ operations will often specify a layout\n   type.  Examples of such operations\
    \ are GETDEVICEINFO and LAYOUTGET.\n   The response for these operations will\
    \ include structures such as a\n   device_addr4 or a layout4, each of which includes\
    \ a layout type\n   within it.  The layout type sent by the server MUST always\
    \ be the\n   same one requested by the client.  When a server sends a response\n\
    \   that includes a different layout type, the client SHOULD ignore the\n   response\
    \ and behave as if the server had returned an error response.\n"
- title: 12.2.8.  Layout
  contents:
  - "12.2.8.  Layout\n   A layout defines how a file's data is organized on one or\
    \ more\n   storage devices.  There are many potential layout types; each of the\n\
    \   layout types are differentiated by the storage protocol used to\n   access\
    \ data and by the aggregation scheme that lays out the file data\n   on the underlying\
    \ storage devices.  A layout is precisely identified\n   by the tuple <client\
    \ ID, filehandle, layout type, iomode, range>,\n   where filehandle refers to\
    \ the filehandle of the file on the metadata\n   server.\n   It is important to\
    \ define when layouts overlap and/or conflict with\n   each other.  For two layouts\
    \ with overlapping byte-ranges to actually\n   overlap each other, both layouts\
    \ must be of the same layout type,\n   correspond to the same filehandle, and\
    \ have the same iomode.  Layouts\n   conflict when they overlap and differ in\
    \ the content of the layout\n   (i.e., the storage device/file mapping parameters\
    \ differ).  Note that\n   differing iomodes do not lead to conflicting layouts.\
    \  It is\n   permissible for layouts with different iomodes, pertaining to the\n\
    \   same byte-range, to be held by the same client.  An example of this\n   would\
    \ be copy-on-write functionality for a block/volume layout type.\n"
- title: 12.2.9.  Layout Iomode
  contents:
  - "12.2.9.  Layout Iomode\n   The layout iomode (data type layoutiomode4, see Section\
    \ 3.3.20)\n   indicates to the metadata server the client's intent to perform\n\
    \   either just READ operations or a mixture containing READ and WRITE\n   operations.\
    \  For certain layout types, it is useful for a client to\n   specify this intent\
    \ at the time it sends LAYOUTGET (Section 18.43).\n   For example, for block/volume-based\
    \ protocols, block allocation could\n   occur when a LAYOUTIOMODE4_RW iomode is\
    \ specified.  A special\n   LAYOUTIOMODE4_ANY iomode is defined and can only be\
    \ used for\n   LAYOUTRETURN and CB_LAYOUTRECALL, not for LAYOUTGET.  It specifies\n\
    \   that layouts pertaining to both LAYOUTIOMODE4_READ and\n   LAYOUTIOMODE4_RW\
    \ iomodes are being returned or recalled,\n   respectively.\n   A storage device\
    \ may validate I/O with regard to the iomode; this is\n   dependent upon storage\
    \ device implementation and layout type.  Thus,\n   if the client's layout iomode\
    \ is inconsistent with the I/O being\n   performed, the storage device may reject\
    \ the client's I/O with an\n   error indicating that a new layout with the correct\
    \ iomode should be\n   obtained via LAYOUTGET.  For example, if a client gets\
    \ a layout with\n   a LAYOUTIOMODE4_READ iomode and performs a WRITE to a storage\
    \ device,\n   the storage device is allowed to reject that WRITE.\n   The use\
    \ of the layout iomode does not conflict with OPEN share modes\n   or byte-range\
    \ LOCK operations; open share mode and byte-range lock\n   conflicts are enforced\
    \ as they are without the use of pNFS and are\n   logically separate from the\
    \ pNFS layout level.  Open share modes and\n   byte-range locks are the preferred\
    \ method for restricting user access\n   to data files.  For example, an OPEN\
    \ of OPEN4_SHARE_ACCESS_WRITE does\n   not conflict with a LAYOUTGET containing\
    \ an iomode of\n   LAYOUTIOMODE4_RW performed by another client.  Applications\
    \ that\n   depend on writing into the same file concurrently may use byte-range\n\
    \   locking to serialize their accesses.\n"
- title: 12.2.10.  Device IDs
  contents:
  - "12.2.10.  Device IDs\n   The device ID (data type deviceid4, see Section 3.3.14)\
    \ identifies a\n   group of storage devices.  The scope of a device ID is the\
    \ pair\n   <client ID, layout type>.  In practice, a significant amount of\n \
    \  information may be required to fully address a storage device.\n   Rather than\
    \ embedding all such information in a layout, layouts embed\n   device IDs.  The\
    \ NFSv4.1 operation GETDEVICEINFO (Section 18.40) is\n   used to retrieve the\
    \ complete address information (including all\n   device addresses for the device\
    \ ID) regarding the storage device\n   according to its layout type and device\
    \ ID.  For example, the address\n   of an NFSv4.1 data server or of an object-based\
    \ storage device could\n   be an IP address and port.  The address of a block\
    \ storage device\n   could be a volume label.\n   Clients cannot expect the mapping\
    \ between a device ID and its storage\n   device address(es) to persist across\
    \ metadata server restart.  See\n   Section 12.7.4 for a description of how recovery\
    \ works in that\n   situation.\n   A device ID lives as long as there is a layout\
    \ referring to the\n   device ID.  If there are no layouts referring to the device\
    \ ID, the\n   server is free to delete the device ID any time.  Once a device\
    \ ID is\n   deleted by the server, the server MUST NOT reuse the device ID for\n\
    \   the same layout type and client ID again.  This requirement is\n   feasible\
    \ because the device ID is 16 bytes long, leaving sufficient\n   room to store\
    \ a generation number if the server's implementation\n   requires most of the\
    \ rest of the device ID's content to be reused.\n   This requirement is necessary\
    \ because otherwise the race conditions\n   between asynchronous notification\
    \ of device ID addition and deletion\n   would be too difficult to sort out.\n\
    \   Device ID to device address mappings are not leased, and can be\n   changed\
    \ at any time.  (Note that while device ID to device address\n   mappings are\
    \ likely to change after the metadata server restarts, the\n   server is not required\
    \ to change the mappings.)  A server has two\n   choices for changing mappings.\
    \  It can recall all layouts referring\n   to the device ID or it can use a notification\
    \ mechanism.\n   The NFSv4.1 protocol has no optimal way to recall all layouts\
    \ that\n   referred to a particular device ID (unless the server associates a\n\
    \   single device ID with a single fsid or a single client ID; in which\n   case,\
    \ CB_LAYOUTRECALL has options for recalling all layouts\n   associated with the\
    \ fsid, client ID pair, or just the client ID).\n   Via a notification mechanism\
    \ (see Section 20.12), device ID to device\n   address mappings can change over\
    \ the duration of server operation\n   without recalling or revoking the layouts\
    \ that refer to device ID.\n   The notification mechanism can also delete a device\
    \ ID, but only if\n   the client has no layouts referring to the device ID.  A\
    \ notification\n   of a change to a device ID to device address mapping will immediately\n\
    \   or eventually invalidate some or all of the device ID's mappings.\n   The\
    \ server MUST support notifications and the client must request\n   them before\
    \ they can be used.  For further information about the\n   notification types,\
    \ see Section 20.12.\n"
- title: 12.3.  pNFS Operations
  contents:
  - "12.3.  pNFS Operations\n   NFSv4.1 has several operations that are needed for\
    \ pNFS servers,\n   regardless of layout type or storage protocol.  These operations\
    \ are\n   all sent to a metadata server and summarized here.  While pNFS is an\n\
    \   OPTIONAL feature, if pNFS is implemented, some operations are\n   REQUIRED\
    \ in order to comply with pNFS.  See Section 17.\n   These are the fore channel\
    \ pNFS operations:\n   GETDEVICEINFO  (Section 18.40), as noted previously\n \
    \     (Section 12.2.10), returns the mapping of device ID to storage\n      device\
    \ address.\n   GETDEVICELIST  (Section 18.41) allows clients to fetch all device\
    \ IDs\n      for a specific file system.\n   LAYOUTGET  (Section 18.43) is used\
    \ by a client to get a layout for a\n      file.\n   LAYOUTCOMMIT  (Section 18.42)\
    \ is used to inform the metadata server\n      of the client's intent to commit\
    \ data that has been written to the\n      storage device (the storage device\
    \ as originally indicated in the\n      return value of LAYOUTGET).\n   LAYOUTRETURN\
    \  (Section 18.44) is used to return layouts for a file, a\n      file system\
    \ ID (FSID), or a client ID.\n   These are the backchannel pNFS operations:\n\
    \   CB_LAYOUTRECALL  (Section 20.3) recalls a layout, all layouts\n      belonging\
    \ to a file system, or all layouts belonging to a client\n      ID.\n   CB_RECALL_ANY\
    \  (Section 20.6) tells a client that it needs to return\n      some number of\
    \ recallable objects, including layouts, to the\n      metadata server.\n   CB_RECALLABLE_OBJ_AVAIL\
    \  (Section 20.7) tells a client that a\n      recallable object that it was denied\
    \ (in case of pNFS, a layout\n      denied by LAYOUTGET) due to resource exhaustion\
    \ is now available.\n   CB_NOTIFY_DEVICEID  (Section 20.12) notifies the client\
    \ of changes to\n      device IDs.\n"
- title: 12.4.  pNFS Attributes
  contents:
  - "12.4.  pNFS Attributes\n   A number of attributes specific to pNFS are listed\
    \ and described in\n   Section 5.12.\n"
- title: 12.5.  Layout Semantics
  contents:
  - '12.5.  Layout Semantics

    '
- title: 12.5.1.  Guarantees Provided by Layouts
  contents:
  - "12.5.1.  Guarantees Provided by Layouts\n   Layouts grant to the client the ability\
    \ to access data located at a\n   storage device with the appropriate storage\
    \ protocol.  The client is\n   guaranteed the layout will be recalled when one\
    \ of two things occur:\n   either a conflicting layout is requested or the state\
    \ encapsulated by\n   the layout becomes invalid (this can happen when an event\
    \ directly or\n   indirectly modifies the layout).  When a layout is recalled\
    \ and\n   returned by the client, the client continues with the ability to\n \
    \  access file data with normal NFSv4.1 operations through the metadata\n   server.\
    \  Only the ability to access the storage devices is affected.\n   The requirement\
    \ of NFSv4.1 that all user access rights MUST be\n   obtained through the appropriate\
    \ OPEN, LOCK, and ACCESS operations is\n   not modified with the existence of\
    \ layouts.  Layouts are provided to\n   NFSv4.1 clients, and user access still\
    \ follows the rules of the\n   protocol as if they did not exist.  It is a requirement\
    \ that for a\n   client to access a storage device, a layout must be held by the\n\
    \   client.  If a storage device receives an I/O request for a byte-range\n  \
    \ for which the client does not hold a layout, the storage device\n   SHOULD reject\
    \ that I/O request.  Note that the act of modifying a\n   file for which a layout\
    \ is held does not necessarily conflict with\n   the holding of the layout that\
    \ describes the file being modified.\n   Therefore, it is the requirement of the\
    \ storage protocol or layout\n   type that determines the necessary behavior.\
    \  For example, block/\n   volume layout types require that the layout's iomode\
    \ agree with the\n   type of I/O being performed.\n   Depending upon the layout\
    \ type and storage protocol in use, storage\n   device access permissions may\
    \ be granted by LAYOUTGET and may be\n   encoded within the type-specific layout.\
    \  For an example of storage\n   device access permissions, see an object-based\
    \ protocol such as [58].\n   If access permissions are encoded within the layout,\
    \ the metadata\n   server SHOULD recall the layout when those permissions become\
    \ invalid\n   for any reason -- for example, when a file becomes unwritable or\n\
    \   inaccessible to a client.  Note, clients are still required to\n   perform\
    \ the appropriate OPEN, LOCK, and ACCESS operations as\n   described above.  The\
    \ degree to which it is possible for the client\n   to circumvent these operations\
    \ and the consequences of doing so must\n   be clearly specified by the individual\
    \ layout type specifications.\n   In addition, these specifications must be clear\
    \ about the\n   requirements and non-requirements for the checking performed by\
    \ the\n   server.\n   In the presence of pNFS functionality, mandatory byte-range\
    \ locks\n   MUST behave as they would without pNFS.  Therefore, if mandatory file\n\
    \   locks and layouts are provided simultaneously, the storage device\n   MUST\
    \ be able to enforce the mandatory byte-range locks.  For example,\n   if one\
    \ client obtains a mandatory byte-range lock and a second client\n   accesses\
    \ the storage device, the storage device MUST appropriately\n   restrict I/O for\
    \ the range of the mandatory byte-range lock.  If the\n   storage device is incapable\
    \ of providing this check in the presence\n   of mandatory byte-range locks, then\
    \ the metadata server MUST NOT\n   grant layouts and mandatory byte-range locks\
    \ simultaneously.\n"
- title: 12.5.2.  Getting a Layout
  contents:
  - "12.5.2.  Getting a Layout\n   A client obtains a layout with the LAYOUTGET operation.\
    \  The metadata\n   server will grant layouts of a particular type (e.g., block/volume,\n\
    \   object, or file).  The client selects an appropriate layout type that\n  \
    \ the server supports and the client is prepared to use.  The layout\n   returned\
    \ to the client might not exactly match the requested byte-\n   range as described\
    \ in Section 18.43.3.  As needed a client may send\n   multiple LAYOUTGET operations;\
    \ these might result in multiple\n   overlapping, non-conflicting layouts (see\
    \ Section 12.2.8).\n   In order to get a layout, the client must first have opened\
    \ the file\n   via the OPEN operation.  When a client has no layout on a file,\
    \ it\n   MUST present an open stateid, a delegation stateid, or a byte-range\n\
    \   lock stateid in the loga_stateid argument.  A successful LAYOUTGET\n   result\
    \ includes a layout stateid.  The first successful LAYOUTGET\n   processed by\
    \ the server using a non-layout stateid as an argument\n   MUST have the \"seqid\"\
    \ field of the layout stateid in the response set\n   to one.  Thereafter, the\
    \ client MUST use a layout stateid (see\n   Section 12.5.3) on future invocations\
    \ of LAYOUTGET on the file, and\n   the \"seqid\" MUST NOT be set to zero.  Once\
    \ the layout has been\n   retrieved, it can be held across multiple OPEN and CLOSE\
    \ sequences.\n   Therefore, a client may hold a layout for a file that is not\n\
    \   currently open by any user on the client.  This allows for the\n   caching\
    \ of layouts beyond CLOSE.\n   The storage protocol used by the client to access\
    \ the data on the\n   storage device is determined by the layout's type.  The\
    \ client is\n   responsible for matching the layout type with an available method\
    \ to\n   interpret and use the layout.  The method for this layout type\n   selection\
    \ is outside the scope of the pNFS functionality.\n   Although the metadata server\
    \ is in control of the layout for a file,\n   the pNFS client can provide hints\
    \ to the server when a file is opened\n   or created about the preferred layout\
    \ type and aggregation schemes.\n   pNFS introduces a layout_hint attribute (Section\
    \ 5.12.4) that the\n   client can set at file creation time to provide a hint\
    \ to the server\n   for new files.  Setting this attribute separately, after the\
    \ file has\n   been created might make it difficult, or impossible, for the server\n\
    \   implementation to comply.\n   Because the EXCLUSIVE4 createmode4 does not\
    \ allow the setting of\n   attributes at file creation time, NFSv4.1 introduces\
    \ the EXCLUSIVE4_1\n   createmode4, which does allow attributes to be set at file\
    \ creation\n   time.  In addition, if the session is created with persistent reply\n\
    \   caches, EXCLUSIVE4_1 is neither necessary nor allowed.  Instead,\n   GUARDED4\
    \ both works better and is prescribed.  Table 18 in\n   Section 18.16.3 summarizes\
    \ how a client is allowed to send an\n   exclusive create.\n"
- title: 12.5.3.  Layout Stateid
  contents:
  - "12.5.3.  Layout Stateid\n   As with all other stateids, the layout stateid consists\
    \ of a \"seqid\"\n   and \"other\" field.  Once a layout stateid is established,\
    \ the \"other\"\n   field will stay constant unless the stateid is revoked or\
    \ the client\n   returns all layouts on the file and the server disposes of the\n\
    \   stateid.  The \"seqid\" field is initially set to one, and is never\n   zero\
    \ on any NFSv4.1 operation that uses layout stateids, whether it\n   is a fore\
    \ channel or backchannel operation.  After the layout stateid\n   is established,\
    \ the server increments by one the value of the \"seqid\"\n   in each subsequent\
    \ LAYOUTGET and LAYOUTRETURN response, and in each\n   CB_LAYOUTRECALL request.\n\
    \   Given the design goal of pNFS to provide parallelism, the layout\n   stateid\
    \ differs from other stateid types in that the client is\n   expected to send\
    \ LAYOUTGET and LAYOUTRETURN operations in parallel.\n   The \"seqid\" value is\
    \ used by the client to properly sort responses to\n   LAYOUTGET and LAYOUTRETURN.\
    \  The \"seqid\" is also used to prevent race\n   conditions between LAYOUTGET\
    \ and CB_LAYOUTRECALL.  Given that the\n   processing rules differ from layout\
    \ stateids and other stateid types,\n   only the pNFS sections of this document\
    \ should be considered to\n   determine proper layout stateid handling.\n   Once\
    \ the client receives a layout stateid, it MUST use the correct\n   \"seqid\"\
    \ for subsequent LAYOUTGET or LAYOUTRETURN operations.  The\n   correct \"seqid\"\
    \ is defined as the highest \"seqid\" value from\n   responses of fully processed\
    \ LAYOUTGET or LAYOUTRETURN operations or\n   arguments of a fully processed CB_LAYOUTRECALL\
    \ operation.  Since the\n   server is incrementing the \"seqid\" value on each\
    \ layout operation,\n   the client may determine the order of operation processing\
    \ by\n   inspecting the \"seqid\" value.  In the case of overlapping layout\n\
    \   ranges, the ordering information will provide the client the\n   knowledge\
    \ of which layout ranges are held.  Note that overlapping\n   layout ranges may\
    \ occur because of the client's specific requests or\n   because the server is\
    \ allowed to expand the range of a requested\n   layout and notify the client\
    \ in the LAYOUTRETURN results.  Additional\n   layout stateid sequencing requirements\
    \ are provided in\n   Section 12.5.5.2.\n   The client's receipt of a \"seqid\"\
    \ is not sufficient for subsequent\n   use.  The client must fully process the\
    \ operations before the \"seqid\"\n   can be used.  For LAYOUTGET results, if\
    \ the client is not using the\n   forgetful model (Section 12.5.5.1), it MUST\
    \ first update its record\n   of what ranges of the file's layout it has before\
    \ using the seqid.\n   For LAYOUTRETURN results, the client MUST delete the range\
    \ from its\n   record of what ranges of the file's layout it had before using\
    \ the\n   seqid.  For CB_LAYOUTRECALL arguments, the client MUST send a\n   response\
    \ to the recall before using the seqid.  The fundamental\n   requirement in client\
    \ processing is that the \"seqid\" is used to\n   provide the order of processing.\
    \  LAYOUTGET results may be processed\n   in parallel.  LAYOUTRETURN results may\
    \ be processed in parallel.\n   LAYOUTGET and LAYOUTRETURN responses may be processed\
    \ in parallel as\n   long as the ranges do not overlap.  CB_LAYOUTRECALL request\n\
    \   processing MUST be processed in \"seqid\" order at all times.\n   Once a client\
    \ has no more layouts on a file, the layout stateid is no\n   longer valid and\
    \ MUST NOT be used.  Any attempt to use such a layout\n   stateid will result\
    \ in NFS4ERR_BAD_STATEID.\n"
- title: 12.5.4.  Committing a Layout
  contents:
  - "12.5.4.  Committing a Layout\n   Allowing for varying storage protocol capabilities,\
    \ the pNFS protocol\n   does not require the metadata server and storage devices\
    \ to have a\n   consistent view of file attributes and data location mappings.\
    \  Data\n   location mapping refers to aspects such as which offsets store data\n\
    \   as opposed to storing holes (see Section 13.4.4 for a discussion).\n   Related\
    \ issues arise for storage protocols where a layout may hold\n   provisionally\
    \ allocated blocks where the allocation of those blocks\n   does not survive a\
    \ complete restart of both the client and server.\n   Because of this inconsistency,\
    \ it is necessary to resynchronize the\n   client with the metadata server and\
    \ its storage devices and make any\n   potential changes available to other clients.\
    \  This is accomplished\n   by use of the LAYOUTCOMMIT operation.\n   The LAYOUTCOMMIT\
    \ operation is responsible for committing a modified\n   layout to the metadata\
    \ server.  The data should be written and\n   committed to the appropriate storage\
    \ devices before the LAYOUTCOMMIT\n   occurs.  The scope of the LAYOUTCOMMIT operation\
    \ depends on the\n   storage protocol in use.  It is important to note that the\
    \ level of\n   synchronization is from the point of view of the client that sent\
    \ the\n   LAYOUTCOMMIT.  The updated state on the metadata server need only\n\
    \   reflect the state as of the client's last operation previous to the\n   LAYOUTCOMMIT.\
    \  The metadata server is not REQUIRED to maintain a\n   global view that accounts\
    \ for other clients' I/O that may have\n   occurred within the same time frame.\n\
    \   For block/volume-based layouts, LAYOUTCOMMIT may require updating the\n  \
    \ block list that comprises the file and committing this layout to\n   stable\
    \ storage.  For file-based layouts, synchronization of\n   attributes between\
    \ the metadata and storage devices, primarily the\n   size attribute, is required.\n\
    \   The control protocol is free to synchronize the attributes before it\n   receives\
    \ a LAYOUTCOMMIT; however, upon successful completion of a\n   LAYOUTCOMMIT, state\
    \ that exists on the metadata server that describes\n   the file MUST be synchronized\
    \ with the state that exists on the\n   storage devices that comprise that file\
    \ as of the client's last sent\n   operation.  Thus, a client that queries the\
    \ size of a file between a\n   WRITE to a storage device and the LAYOUTCOMMIT\
    \ might observe a size\n   that does not reflect the actual data written.\n  \
    \ The client MUST have a layout in order to send a LAYOUTCOMMIT\n   operation.\n"
- title: 12.5.4.1.  LAYOUTCOMMIT and change/time_modify
  contents:
  - "12.5.4.1.  LAYOUTCOMMIT and change/time_modify\n   The change and time_modify\
    \ attributes may be updated by the server\n   when the LAYOUTCOMMIT operation\
    \ is processed.  The reason for this is\n   that some layout types do not support\
    \ the update of these attributes\n   when the storage devices process I/O operations.\
    \  If a client has a\n   layout with the LAYOUTIOMODE4_RW iomode on the file,\
    \ the client MAY\n   provide a suggested value to the server for time_modify within\
    \ the\n   arguments to LAYOUTCOMMIT.  Based on the layout type, the provided\n\
    \   value may or may not be used.  The server should sanity-check the\n   client-provided\
    \ values before they are used.  For example, the server\n   should ensure that\
    \ time does not flow backwards.  The client always\n   has the option to set time_modify\
    \ through an explicit SETATTR\n   operation.\n   For some layout protocols, the\
    \ storage device is able to notify the\n   metadata server of the occurrence of\
    \ an I/O; as a result, the change\n   and time_modify attributes may be updated\
    \ at the metadata server.\n   For a metadata server that is capable of monitoring\
    \ updates to the\n   change and time_modify attributes, LAYOUTCOMMIT processing\
    \ is not\n   required to update the change attribute.  In this case, the metadata\n\
    \   server must ensure that no further update to the data has occurred\n   since\
    \ the last update of the attributes; file-based protocols may\n   have enough\
    \ information to make this determination or may update the\n   change attribute\
    \ upon each file modification.  This also applies for\n   the time_modify attribute.\
    \  If the server implementation is able to\n   determine that the file has not\
    \ been modified since the last\n   time_modify update, the server need not update\
    \ time_modify at\n   LAYOUTCOMMIT.  At LAYOUTCOMMIT completion, the updated attributes\n\
    \   should be visible if that file was modified since the latest previous\n  \
    \ LAYOUTCOMMIT or LAYOUTGET.\n"
- title: 12.5.4.2.  LAYOUTCOMMIT and size
  contents:
  - "12.5.4.2.  LAYOUTCOMMIT and size\n   The size of a file may be updated when the\
    \ LAYOUTCOMMIT operation is\n   used by the client.  One of the fields in the\
    \ argument to\n   LAYOUTCOMMIT is loca_last_write_offset; this field indicates\
    \ the\n   highest byte offset written but not yet committed with the\n   LAYOUTCOMMIT\
    \ operation.  The data type of loca_last_write_offset is\n   newoffset4 and is\
    \ switched on a boolean value, no_newoffset, that\n   indicates if a previous\
    \ write occurred or not.  If no_newoffset is\n   FALSE, an offset is not given.\
    \  If the client has a layout with\n   LAYOUTIOMODE4_RW iomode on the file, with\
    \ a byte-range (denoted by\n   the values of lo_offset and lo_length) that overlaps\n\
    \   loca_last_write_offset, then the client MAY set no_newoffset to TRUE\n   and\
    \ provide an offset that will update the file size.  Keep in mind\n   that offset\
    \ is not the same as length, though they are related.  For\n   example, a loca_last_write_offset\
    \ value of zero means that one byte\n   was written at offset zero, and so the\
    \ length of the file is at least\n   one byte.\n   The metadata server may do\
    \ one of the following:\n   1.  Update the file's size using the last write offset\
    \ provided by\n       the client as either the true file size or as a hint of\
    \ the file\n       size.  If the metadata server has a method available, any new\n\
    \       value for file size should be sanity-checked.  For example, the\n    \
    \   file must not be truncated if the client presents a last write\n       offset\
    \ less than the file's current size.\n   2.  Ignore the client-provided last write\
    \ offset; the metadata server\n       must have sufficient knowledge from other\
    \ sources to determine\n       the file's size.  For example, the metadata server\
    \ queries the\n       storage devices with the control protocol.\n   The method\
    \ chosen to update the file's size will depend on the\n   storage device's and/or\
    \ the control protocol's capabilities.  For\n   example, if the storage devices\
    \ are block devices with no knowledge\n   of file size, the metadata server must\
    \ rely on the client to set the\n   last write offset appropriately.\n   The results\
    \ of LAYOUTCOMMIT contain a new size value in the form of a\n   newsize4 union\
    \ data type.  If the file's size is set as a result of\n   LAYOUTCOMMIT, the metadata\
    \ server must reply with the new size;\n   otherwise, the new size is not provided.\
    \  If the file size is\n   updated, the metadata server SHOULD update the storage\
    \ devices such\n   that the new file size is reflected when LAYOUTCOMMIT processing\
    \ is\n   complete.  For example, the client should be able to read up to the\n\
    \   new file size.\n   The client can extend the length of a file or truncate\
    \ a file by\n   sending a SETATTR operation to the metadata server with the size\n\
    \   attribute specified.  If the size specified is larger than the\n   current\
    \ size of the file, the file is \"zero extended\", i.e., zeros\n   are implicitly\
    \ added between the file's previous EOF and the new EOF.\n   (In many implementations,\
    \ the zero-extended byte-range of the file\n   consists of unallocated holes in\
    \ the file.)  When the client writes\n   past EOF via WRITE, the SETATTR operation\
    \ does not need to be used.\n"
- title: 12.5.4.3.  LAYOUTCOMMIT and layoutupdate
  contents:
  - "12.5.4.3.  LAYOUTCOMMIT and layoutupdate\n   The LAYOUTCOMMIT argument contains\
    \ a loca_layoutupdate field\n   (Section 18.42.1) of data type layoutupdate4 (Section\
    \ 3.3.18).  This\n   argument is a layout-type-specific structure.  The structure\
    \ can be\n   used to pass arbitrary layout-type-specific information from the\n\
    \   client to the metadata server at LAYOUTCOMMIT time.  For example, if\n   using\
    \ a block/volume layout, the client can indicate to the metadata\n   server which\
    \ reserved or allocated blocks the client used or did not\n   use.  The content\
    \ of loca_layoutupdate (field lou_body) need not be\n   the same layout-type-specific\
    \ content returned by LAYOUTGET\n   (Section 18.43.2) in the loc_body field of\
    \ the lo_content field of\n   the logr_layout field.  The content of loca_layoutupdate\
    \ is defined\n   by the layout type specification and is opaque to LAYOUTCOMMIT.\n"
- title: 12.5.5.  Recalling a Layout
  contents:
  - "12.5.5.  Recalling a Layout\n   Since a layout protects a client's access to\
    \ a file via a direct\n   client-storage-device path, a layout need only be recalled\
    \ when it is\n   semantically unable to serve this function.  Typically, this\
    \ occurs\n   when the layout no longer encapsulates the true location of the file\n\
    \   over the byte-range it represents.  Any operation or action, such as\n   server-driven\
    \ restriping or load balancing, that changes the layout\n   will result in a recall\
    \ of the layout.  A layout is recalled by the\n   CB_LAYOUTRECALL callback operation\
    \ (see Section 20.3) and returned\n   with LAYOUTRETURN (see Section 18.44). \
    \ The CB_LAYOUTRECALL operation\n   may recall a layout identified by a byte-range,\
    \ all layouts\n   associated with a file system ID (FSID), or all layouts associated\n\
    \   with a client ID.  Section 12.5.5.2 discusses sequencing issues\n   surrounding\
    \ the getting, returning, and recalling of layouts.\n   An iomode is also specified\
    \ when recalling a layout.  Generally, the\n   iomode in the recall request must\
    \ match the layout being returned;\n   for example, a recall with an iomode of\
    \ LAYOUTIOMODE4_RW should cause\n   the client to only return LAYOUTIOMODE4_RW\
    \ layouts and not\n   LAYOUTIOMODE4_READ layouts.  However, a special LAYOUTIOMODE4_ANY\n\
    \   enumeration is defined to enable recalling a layout of any iomode; in\n  \
    \ other words, the client must return both LAYOUTIOMODE4_READ and\n   LAYOUTIOMODE4_RW\
    \ layouts.\n   A REMOVE operation SHOULD cause the metadata server to recall the\n\
    \   layout to prevent the client from accessing a non-existent file and\n   to\
    \ reclaim state stored on the client.  Since a REMOVE may be delayed\n   until\
    \ the last close of the file has occurred, the recall may also be\n   delayed\
    \ until this time.  After the last reference on the file has\n   been released\
    \ and the file has been removed, the client should no\n   longer be able to perform\
    \ I/O using the layout.  In the case of a\n   file-based layout, the data server\
    \ SHOULD return NFS4ERR_STALE in\n   response to any operation on the removed\
    \ file.\n   Once a layout has been returned, the client MUST NOT send I/Os to\
    \ the\n   storage devices for the file, byte-range, and iomode represented by\n\
    \   the returned layout.  If a client does send an I/O to a storage\n   device\
    \ for which it does not hold a layout, the storage device SHOULD\n   reject the\
    \ I/O.\n   Although pNFS does not alter the file data caching capabilities of\n\
    \   clients, or their semantics, it recognizes that some clients may\n   perform\
    \ more aggressive write-behind caching to optimize the benefits\n   provided by\
    \ pNFS.  However, write-behind caching may negatively\n   affect the latency in\
    \ returning a layout in response to a\n   CB_LAYOUTRECALL; this is similar to\
    \ file delegations and the impact\n   that file data caching has on DELEGRETURN.\
    \  Client implementations\n   SHOULD limit the amount of unwritten data they have\
    \ outstanding at\n   any one time in order to prevent excessively long responses\
    \ to\n   CB_LAYOUTRECALL.  Once a layout is recalled, a server MUST wait one\n\
    \   lease period before taking further action.  As soon as a lease period\n  \
    \ has passed, the server may choose to fence the client's access to the\n   storage\
    \ devices if the server perceives the client has taken too long\n   to return\
    \ a layout.  However, just as in the case of data delegation\n   and DELEGRETURN,\
    \ the server may choose to wait, given that the client\n   is showing forward\
    \ progress on its way to returning the layout.  This\n   forward progress can\
    \ take the form of successful interaction with the\n   storage devices or of sub-portions\
    \ of the layout being returned by\n   the client.  The server can also limit exposure\
    \ to these problems by\n   limiting the byte-ranges initially provided in the\
    \ layouts and thus\n   the amount of outstanding modified data.\n"
- title: 12.5.5.1.  Layout Recall Callback Robustness
  contents:
  - "12.5.5.1.  Layout Recall Callback Robustness\n   It has been assumed thus far\
    \ that pNFS client state (layout ranges\n   and iomode) for a file exactly matches\
    \ that of the pNFS server for\n   that file.  This assumption leads to the implication\
    \ that any\n   callback results in a LAYOUTRETURN or set of LAYOUTRETURNs that\n\
    \   exactly match the range in the callback, since both client and server\n  \
    \ agree about the state being maintained.  However, it can be useful if\n   this\
    \ assumption does not always hold.  For example:\n   *  If conflicts that require\
    \ callbacks are very rare, and a server\n      can use a multi-file callback to\
    \ recover per-client resources\n      (e.g., via an FSID recall or a multi-file\
    \ recall within a single\n      CB_COMPOUND), the result may be significantly\
    \ less client-server\n      pNFS traffic.\n   *  It may be useful for servers\
    \ to maintain information about what\n      ranges are held by a client on a coarse-grained\
    \ basis, leading to\n      the server's layout ranges being beyond those actually\
    \ held by the\n      client.  In the extreme, a server could manage conflicts\
    \ on a per-\n      file basis, only sending whole-file callbacks even though clients\n\
    \      may request and be granted sub-file ranges.\n   *  It may be useful for\
    \ clients to \"forget\" details about what\n      layouts and ranges the client\
    \ actually has, leading to the\n      server's layout ranges being beyond those\
    \ that the client \"thinks\"\n      it has.  As long as the client does not assume\
    \ it has layouts that\n      are beyond what the server has granted, this is a\
    \ safe practice.\n      When a client forgets what ranges and layouts it has,\
    \ and it\n      receives a CB_LAYOUTRECALL operation, the client MUST follow up\n\
    \      with a LAYOUTRETURN for what the server recalled, or alternatively\n  \
    \    return the NFS4ERR_NOMATCHING_LAYOUT error if it has no layout to\n     \
    \ return in the recalled range.\n   *  In order to avoid errors, it is vital that\
    \ a client not assign\n      itself layout permissions beyond what the server\
    \ has granted, and\n      that the server not forget layout permissions that have\
    \ been\n      granted.  On the other hand, if a server believes that a client\n\
    \      holds a layout that the client does not know about, it is useful\n    \
    \  for the client to cleanly indicate completion of the requested\n      recall\
    \ either by sending a LAYOUTRETURN operation for the entire\n      requested range\
    \ or by returning an NFS4ERR_NOMATCHING_LAYOUT error\n      to the CB_LAYOUTRECALL.\n\
    \   Thus, in light of the above, it is useful for a server to be able to\n   send\
    \ callbacks for layout ranges it has not granted to a client, and\n   for a client\
    \ to return ranges it does not hold.  A pNFS client MUST\n   always return layouts\
    \ that comprise the full range specified by the\n   recall.  Note, the full recalled\
    \ layout range need not be returned as\n   part of a single operation, but may\
    \ be returned in portions.  This\n   allows the client to stage the flushing of\
    \ dirty data and commits and\n   returns of layouts.  Also, it indicates to the\
    \ metadata server that\n   the client is making progress.\n   When a layout is\
    \ returned, the client MUST NOT have any outstanding\n   I/O requests to the storage\
    \ devices involved in the layout.\n   Rephrasing, the client MUST NOT return the\
    \ layout while it has\n   outstanding I/O requests to the storage device.\n  \
    \ Even with this requirement for the client, it is possible that I/O\n   requests\
    \ may be presented to a storage device no longer allowed to\n   perform them.\
    \  Since the server has no strict control as to when the\n   client will return\
    \ the layout, the server may later decide to\n   unilaterally revoke the client's\
    \ access to the storage devices as\n   provided by the layout.  In choosing to\
    \ revoke access, the server\n   must deal with the possibility of lingering I/O\
    \ requests, i.e., I/O\n   requests that are still in flight to storage devices\
    \ identified by\n   the revoked layout.  All layout type specifications MUST define\n\
    \   whether unilateral layout revocation by the metadata server is\n   supported;\
    \ if it is, the specification must also describe how\n   lingering writes are\
    \ processed.  For example, storage devices\n   identified by the revoked layout\
    \ could be fenced off from the client\n   that held the layout.\n   In order to\
    \ ensure client/server convergence with regard to layout\n   state, the final\
    \ LAYOUTRETURN operation in a sequence of LAYOUTRETURN\n   operations for a particular\
    \ recall MUST specify the entire range\n   being recalled, echoing the recalled\
    \ layout type, iomode, recall/\n   return type (FILE, FSID, or ALL), and byte-range,\
    \ even if layouts\n   pertaining to partial ranges were previously returned. \
    \ In addition,\n   if the client holds no layouts that overlap the range being\
    \ recalled,\n   the client should return the NFS4ERR_NOMATCHING_LAYOUT error code\
    \ to\n   CB_LAYOUTRECALL.  This allows the server to update its view of the\n\
    \   client's layout state.\n"
- title: 12.5.5.2.  Sequencing of Layout Operations
  contents:
  - "12.5.5.2.  Sequencing of Layout Operations\n   As with other stateful operations,\
    \ pNFS requires the correct\n   sequencing of layout operations. pNFS uses the\
    \ \"seqid\" in the layout\n   stateid to provide the correct sequencing between\
    \ regular operations\n   and callbacks.  It is the server's responsibility to\
    \ avoid\n   inconsistencies regarding the layouts provided and the client's\n\
    \   responsibility to properly serialize its layout requests and layout\n   returns.\n"
- title: 12.5.5.2.1.  Layout Recall and Return Sequencing
  contents:
  - "12.5.5.2.1.  Layout Recall and Return Sequencing\n   One critical issue with\
    \ regard to layout operations sequencing\n   concerns callbacks.  The protocol\
    \ must defend against races between\n   the reply to a LAYOUTGET or LAYOUTRETURN\
    \ operation and a subsequent\n   CB_LAYOUTRECALL.  A client MUST NOT process a\
    \ CB_LAYOUTRECALL that\n   implies one or more outstanding LAYOUTGET or LAYOUTRETURN\
    \ operations\n   to which the client has not yet received a reply.  The client\
    \ detects\n   such a CB_LAYOUTRECALL by examining the \"seqid\" field of the recall's\n\
    \   layout stateid.  If the \"seqid\" is not exactly one higher than what\n  \
    \ the client currently has recorded, and the client has at least one\n   LAYOUTGET\
    \ and/or LAYOUTRETURN operation outstanding, the client knows\n   the server sent\
    \ the CB_LAYOUTRECALL after sending a response to an\n   outstanding LAYOUTGET\
    \ or LAYOUTRETURN.  The client MUST wait before\n   processing such a CB_LAYOUTRECALL\
    \ until it processes all replies for\n   outstanding LAYOUTGET and LAYOUTRETURN\
    \ operations for the\n   corresponding file with seqid less than the seqid given\
    \ by\n   CB_LAYOUTRECALL (lor_stateid; see Section 20.3.)\n   In addition to the\
    \ seqid-based mechanism, Section 2.10.6.3 describes\n   the sessions mechanism\
    \ for allowing the client to detect callback\n   race conditions and delay processing\
    \ such a CB_LAYOUTRECALL.  The\n   server MAY reference conflicting operations\
    \ in the CB_SEQUENCE that\n   precedes the CB_LAYOUTRECALL.  Because the server\
    \ has already sent\n   replies for these operations before sending the callback,\
    \ the replies\n   may race with the CB_LAYOUTRECALL.  The client MUST wait for\
    \ all the\n   referenced calls to complete and update its view of the layout state\n\
    \   before processing the CB_LAYOUTRECALL.\n"
- title: 12.5.5.2.1.1.  Get/Return Sequencing
  contents:
  - "12.5.5.2.1.1.  Get/Return Sequencing\n   The protocol allows the client to send\
    \ concurrent LAYOUTGET and\n   LAYOUTRETURN operations to the server.  The protocol\
    \ does not provide\n   any means for the server to process the requests in the\
    \ same order in\n   which they were created.  However, through the use of the\
    \ \"seqid\"\n   field in the layout stateid, the client can determine the order\
    \ in\n   which parallel outstanding operations were processed by the server.\n\
    \   Thus, when a layout retrieved by an outstanding LAYOUTGET operation\n   intersects\
    \ with a layout returned by an outstanding LAYOUTRETURN on\n   the same file,\
    \ the order in which the two conflicting operations are\n   processed determines\
    \ the final state of the overlapping layout.  The\n   order is determined by the\
    \ \"seqid\" returned in each operation: the\n   operation with the higher seqid\
    \ was executed later.\n   It is permissible for the client to send multiple parallel\
    \ LAYOUTGET\n   operations for the same file or multiple parallel LAYOUTRETURN\n\
    \   operations for the same file or a mix of both.\n   It is permissible for the\
    \ client to use the current stateid (see\n   Section 16.2.3.1.2) for LAYOUTGET\
    \ operations, for example, when\n   compounding LAYOUTGETs or compounding OPEN\
    \ and LAYOUTGETs.  It is\n   also permissible to use the current stateid when\
    \ compounding\n   LAYOUTRETURNs.\n   It is permissible for the client to use the\
    \ current stateid when\n   combining LAYOUTRETURN and LAYOUTGET operations for\
    \ the same file in\n   the same COMPOUND request since the server MUST process\
    \ these in\n   order.  However, if a client does send such COMPOUND requests,\
    \ it\n   MUST NOT have more than one outstanding for the same file at the same\n\
    \   time, and it MUST NOT have other LAYOUTGET or LAYOUTRETURN operations\n  \
    \ outstanding at the same time for that same file.\n"
- title: 12.5.5.2.1.2.  Client Considerations
  contents:
  - "12.5.5.2.1.2.  Client Considerations\n   Consider a pNFS client that has sent\
    \ a LAYOUTGET, and before it\n   receives the reply to LAYOUTGET, it receives\
    \ a CB_LAYOUTRECALL for\n   the same file with an overlapping range.  There are\
    \ two\n   possibilities, which the client can distinguish via the layout\n   stateid\
    \ in the recall.\n   1.  The server processed the LAYOUTGET before sending the\
    \ recall, so\n       the LAYOUTGET must be waited for because it may be carrying\n\
    \       layout information that will need to be returned to deal with the\n  \
    \     CB_LAYOUTRECALL.\n   2.  The server sent the callback before receiving the\
    \ LAYOUTGET.  The\n       server will not respond to the LAYOUTGET until the\n\
    \       CB_LAYOUTRECALL is processed.\n   If these possibilities cannot be distinguished,\
    \ a deadlock could\n   result, as the client must wait for the LAYOUTGET response\
    \ before\n   processing the recall in the first case, but that response will not\n\
    \   arrive until after the recall is processed in the second case.  Note\n   that\
    \ in the first case, the \"seqid\" in the layout stateid of the\n   recall is\
    \ two greater than what the client has recorded; in the\n   second case, the \"\
    seqid\" is one greater than what the client has\n   recorded.  This allows the\
    \ client to disambiguate between the two\n   cases.  The client thus knows precisely\
    \ which possibility applies.\n   In case 1, the client knows it needs to wait\
    \ for the LAYOUTGET\n   response before processing the recall (or the client can\
    \ return\n   NFS4ERR_DELAY).\n   In case 2, the client will not wait for the LAYOUTGET\
    \ response before\n   processing the recall because waiting would cause deadlock.\n\
    \   Therefore, the action at the client will only require waiting in the\n   case\
    \ that the client has not yet seen the server's earlier responses\n   to the LAYOUTGET\
    \ operation(s).\n   The recall process can be considered completed when the final\n\
    \   LAYOUTRETURN operation for the recalled range is completed.  The\n   LAYOUTRETURN\
    \ uses the layout stateid (with seqid) specified in\n   CB_LAYOUTRECALL.  If the\
    \ client uses multiple LAYOUTRETURNs in\n   processing the recall, the first LAYOUTRETURN\
    \ will use the layout\n   stateid as specified in CB_LAYOUTRECALL.  Subsequent\
    \ LAYOUTRETURNs\n   will use the highest seqid as is the usual case.\n"
- title: 12.5.5.2.1.3.  Server Considerations
  contents:
  - "12.5.5.2.1.3.  Server Considerations\n   Consider a race from the metadata server's\
    \ point of view.  The\n   metadata server has sent a CB_LAYOUTRECALL and receives\
    \ an\n   overlapping LAYOUTGET for the same file before the LAYOUTRETURN(s)\n\
    \   that respond to the CB_LAYOUTRECALL.  There are three cases:\n   1.  The client\
    \ sent the LAYOUTGET before processing the\n       CB_LAYOUTRECALL.  The \"seqid\"\
    \ in the layout stateid of the\n       arguments of LAYOUTGET is one less than\
    \ the \"seqid\" in\n       CB_LAYOUTRECALL.  The server returns NFS4ERR_RECALLCONFLICT\
    \ to\n       the client, which indicates to the client that there is a pending\n\
    \       recall.\n   2.  The client sent the LAYOUTGET after processing the\n \
    \      CB_LAYOUTRECALL, but the LAYOUTGET arrived before the\n       LAYOUTRETURN\
    \ and the response to CB_LAYOUTRECALL that completed\n       that processing.\
    \  The \"seqid\" in the layout stateid of LAYOUTGET\n       is equal to or greater\
    \ than that of the \"seqid\" in\n       CB_LAYOUTRECALL.  The server has not received\
    \ a response to the\n       CB_LAYOUTRECALL, so it returns NFS4ERR_RECALLCONFLICT.\n\
    \   3.  The client sent the LAYOUTGET after processing the\n       CB_LAYOUTRECALL;\
    \ the server received the CB_LAYOUTRECALL\n       response, but the LAYOUTGET\
    \ arrived before the LAYOUTRETURN that\n       completed that processing.  The\
    \ \"seqid\" in the layout stateid of\n       LAYOUTGET is equal to that of the\
    \ \"seqid\" in CB_LAYOUTRECALL.\n       The server has received a response to\
    \ the CB_LAYOUTRECALL, so it\n       returns NFS4ERR_RETURNCONFLICT.\n"
- title: 12.5.5.2.1.4.  Wraparound and Validation of Seqid
  contents:
  - "12.5.5.2.1.4.  Wraparound and Validation of Seqid\n   The rules for layout stateid\
    \ processing differ from other stateids in\n   the protocol because the \"seqid\"\
    \ value cannot be zero and the\n   stateid's \"seqid\" value changes in a CB_LAYOUTRECALL\
    \ operation.  The\n   non-zero requirement combined with the inherent parallelism\
    \ of layout\n   operations means that a set of LAYOUTGET and LAYOUTRETURN operations\n\
    \   may contain the same value for \"seqid\".  The server uses a slightly\n  \
    \ modified version of the modulo arithmetic as described in\n   Section 2.10.6.1\
    \ when incrementing the layout stateid's \"seqid\".  The\n   difference is that\
    \ zero is not a valid value for \"seqid\"; when the\n   value of a \"seqid\" is\
    \ 0xFFFFFFFF, the next valid value will be\n   0x00000001.  The modulo arithmetic\
    \ is also used for the comparisons\n   of \"seqid\" values in the processing of\
    \ CB_LAYOUTRECALL events as\n   described above in Section 12.5.5.2.1.3.\n   Just\
    \ as the server validates the \"seqid\" in the event of\n   CB_LAYOUTRECALL usage,\
    \ as described in Section 12.5.5.2.1.3, the\n   server also validates the \"seqid\"\
    \ value to ensure that it is within\n   an appropriate range.  This range represents\
    \ the degree of\n   parallelism the server supports for layout stateids.  If the\
    \ client\n   is sending multiple layout operations to the server in parallel,\
    \ by\n   definition, the \"seqid\" value in the supplied stateid will not be the\n\
    \   current \"seqid\" as held by the server.  The range of parallelism\n   spans\
    \ from the highest or current \"seqid\" to a \"seqid\" value in the\n   past.\
    \  To assist in the discussion, the server's current \"seqid\"\n   value for a\
    \ layout stateid is defined as SERVER_CURRENT_SEQID.  The\n   lowest \"seqid\"\
    \ value that is acceptable to the server is represented\n   by PAST_SEQID.  And\
    \ the value for the range of valid \"seqid\"s or\n   range of parallelism is VALID_SEQID_RANGE.\
    \  Therefore, the following\n   holds: VALID_SEQID_RANGE = SERVER_CURRENT_SEQID\
    \ - PAST_SEQID.  In the\n   following, all arithmetic is the modulo arithmetic\
    \ as described\n   above.\n   The server MUST support a minimum VALID_SEQID_RANGE.\
    \  The minimum is\n   defined as: VALID_SEQID_RANGE = summation over 1..N of\n\
    \   (ca_maxoperations(i) - 1), where N is the number of session fore\n   channels\
    \ and ca_maxoperations(i) is the value of the ca_maxoperations\n   returned from\
    \ CREATE_SESSION of the i'th session.  The reason for \"-\n   1\" is to allow\
    \ for the required SEQUENCE operation.  The server MAY\n   support a VALID_SEQID_RANGE\
    \ value larger than the minimum.  The\n   maximum VALID_SEQID_RANGE is (2^(32)\
    \ - 2) (accounting for zero not\n   being a valid \"seqid\" value).\n   If the\
    \ server finds the \"seqid\" is zero, the NFS4ERR_BAD_STATEID\n   error is returned\
    \ to the client.  The server further validates the\n   \"seqid\" to ensure it\
    \ is within the range of parallelism,\n   VALID_SEQID_RANGE.  If the \"seqid\"\
    \ value is outside of that range,\n   the error NFS4ERR_OLD_STATEID is returned\
    \ to the client.  Upon\n   receipt of NFS4ERR_OLD_STATEID, the client updates\
    \ the stateid in the\n   layout request based on processing of other layout requests\
    \ and re-\n   sends the operation to the server.\n"
- title: 12.5.5.2.1.5.  Bulk Recall and Return
  contents:
  - "12.5.5.2.1.5.  Bulk Recall and Return\n   pNFS supports recalling and returning\
    \ all layouts that are for files\n   belonging to a particular fsid (LAYOUTRECALL4_FSID,\n\
    \   LAYOUTRETURN4_FSID) or client ID (LAYOUTRECALL4_ALL,\n   LAYOUTRETURN4_ALL).\
    \  There are no \"bulk\" stateids, so detection of\n   races via the seqid is\
    \ not possible.  The server MUST NOT initiate\n   bulk recall while another recall\
    \ is in progress, or the corresponding\n   LAYOUTRETURN is in progress or pending.\
    \  In the event the server\n   sends a bulk recall while the client has a pending\
    \ or in-progress\n   LAYOUTRETURN, CB_LAYOUTRECALL, or LAYOUTGET, the client returns\n\
    \   NFS4ERR_DELAY.  In the event the client sends a LAYOUTGET or\n   LAYOUTRETURN\
    \ while a bulk recall is in progress, the server returns\n   NFS4ERR_RECALLCONFLICT.\
    \  If the client sends a LAYOUTGET or\n   LAYOUTRETURN after the server receives\
    \ NFS4ERR_DELAY from a bulk\n   recall, then to ensure forward progress, the server\
    \ MAY return\n   NFS4ERR_RECALLCONFLICT.\n   Once a CB_LAYOUTRECALL of LAYOUTRECALL4_ALL\
    \ is sent, the server MUST\n   NOT allow the client to use any layout stateid\
    \ except for\n   LAYOUTCOMMIT operations.  Once the client receives a CB_LAYOUTRECALL\n\
    \   of LAYOUTRECALL4_ALL, it MUST NOT use any layout stateid except for\n   LAYOUTCOMMIT\
    \ operations.  Once a LAYOUTRETURN of LAYOUTRETURN4_ALL is\n   sent, all layout\
    \ stateids granted to the client ID are freed.  The\n   client MUST NOT use the\
    \ layout stateids again.  It MUST use LAYOUTGET\n   to obtain new layout stateids.\n\
    \   Once a CB_LAYOUTRECALL of LAYOUTRECALL4_FSID is sent, the server MUST\n  \
    \ NOT allow the client to use any layout stateid that refers to a file\n   with\
    \ the specified fsid except for LAYOUTCOMMIT operations.  Once the\n   client\
    \ receives a CB_LAYOUTRECALL of LAYOUTRECALL4_ALL, it MUST NOT\n   use any layout\
    \ stateid that refers to a file with the specified fsid\n   except for LAYOUTCOMMIT\
    \ operations.  Once a LAYOUTRETURN of\n   LAYOUTRETURN4_FSID is sent, all layout\
    \ stateids granted to the\n   referenced fsid are freed.  The client MUST NOT\
    \ use those freed\n   layout stateids for files with the referenced fsid again.\n\
    \   Subsequently, for any file with the referenced fsid, to use a layout,\n  \
    \ the client MUST first send a LAYOUTGET operation in order to obtain a\n   new\
    \ layout stateid for that file.\n   If the server has sent a bulk CB_LAYOUTRECALL\
    \ and receives a\n   LAYOUTGET, or a LAYOUTRETURN with a stateid, the server MUST\
    \ return\n   NFS4ERR_RECALLCONFLICT.  If the server has sent a bulk\n   CB_LAYOUTRECALL\
    \ and receives a LAYOUTRETURN with an lr_returntype\n   that is not equal to the\
    \ lor_recalltype of the CB_LAYOUTRECALL, the\n   server MUST return NFS4ERR_RECALLCONFLICT.\n"
- title: 12.5.6.  Revoking Layouts
  contents:
  - "12.5.6.  Revoking Layouts\n   Parallel NFS permits servers to revoke layouts\
    \ from clients that fail\n   to respond to recalls and/or fail to renew their\
    \ lease in time.\n   Depending on the layout type, the server might revoke the\
    \ layout and\n   might take certain actions with respect to the client's I/O to\
    \ data\n   servers.\n"
- title: 12.5.7.  Metadata Server Write Propagation
  contents:
  - "12.5.7.  Metadata Server Write Propagation\n   Asynchronous writes written through\
    \ the metadata server may be\n   propagated lazily to the storage devices.  For\
    \ data written\n   asynchronously through the metadata server, a client performing\
    \ a\n   read at the appropriate storage device is not guaranteed to see the\n\
    \   newly written data until a COMMIT occurs at the metadata server.\n   While\
    \ the write is pending, reads to the storage device may give out\n   either the\
    \ old data, the new data, or a mixture of new and old.  Upon\n   completion of\
    \ a synchronous WRITE or COMMIT (for asynchronously\n   written data), the metadata\
    \ server MUST ensure that storage devices\n   give out the new data and that the\
    \ data has been written to stable\n   storage.  If the server implements its storage\
    \ in any way such that\n   it cannot obey these constraints, then it MUST recall\
    \ the layouts to\n   prevent reads being done that cannot be handled correctly.\
    \  Note that\n   the layouts MUST be recalled prior to the server responding to\
    \ the\n   associated WRITE operations.\n"
- title: 12.6.  pNFS Mechanics
  contents:
  - "12.6.  pNFS Mechanics\n   This section describes the operations flow taken by\
    \ a pNFS client to\n   a metadata server and storage device.\n   When a pNFS client\
    \ encounters a new FSID, it sends a GETATTR to the\n   NFSv4.1 server for the\
    \ fs_layout_type (Section 5.12.1) attribute.  If\n   the attribute returns at\
    \ least one layout type, and the layout types\n   returned are among the set supported\
    \ by the client, the client knows\n   that pNFS is a possibility for the file\
    \ system.  If, from the server\n   that returned the new FSID, the client does\
    \ not have a client ID that\n   came from an EXCHANGE_ID result that returned\n\
    \   EXCHGID4_FLAG_USE_PNFS_MDS, it MUST send an EXCHANGE_ID to the server\n  \
    \ with the EXCHGID4_FLAG_USE_PNFS_MDS bit set.  If the server's\n   response does\
    \ not have EXCHGID4_FLAG_USE_PNFS_MDS, then contrary to\n   what the fs_layout_type\
    \ attribute said, the server does not support\n   pNFS, and the client will not\
    \ be able use pNFS to that server; in\n   this case, the server MUST return NFS4ERR_NOTSUPP\
    \ in response to any\n   pNFS operation.\n   The client then creates a session,\
    \ requesting a persistent session,\n   so that exclusive creates can be done with\
    \ single round trip via the\n   createmode4 of GUARDED4.  If the session ends\
    \ up not being\n   persistent, the client will use EXCLUSIVE4_1 for exclusive\
    \ creates.\n   If a file is to be created on a pNFS-enabled file system, the client\n\
    \   uses the OPEN operation.  With the normal set of attributes that may\n   be\
    \ provided upon OPEN used for creation, there is an OPTIONAL\n   layout_hint attribute.\
    \  The client's use of layout_hint allows the\n   client to express its preference\
    \ for a layout type and its associated\n   layout details.  The use of a createmode4\
    \ of UNCHECKED4, GUARDED4, or\n   EXCLUSIVE4_1 will allow the client to provide\
    \ the layout_hint\n   attribute at create time.  The client MUST NOT use EXCLUSIVE4\
    \ (see\n   Table 18).  The client is RECOMMENDED to combine a GETATTR operation\n\
    \   after the OPEN within the same COMPOUND.  The GETATTR may then\n   retrieve\
    \ the layout_type attribute for the newly created file.  The\n   client will then\
    \ know what layout type the server has chosen for the\n   file and therefore what\
    \ storage protocol the client must use.\n   If the client wants to open an existing\
    \ file, then it also includes a\n   GETATTR to determine what layout type the\
    \ file supports.\n   The GETATTR in either the file creation or plain file open\
    \ case can\n   also include the layout_blksize and layout_alignment attributes\
    \ so\n   that the client can determine optimal offsets and lengths for I/O on\n\
    \   the file.\n   Assuming the client supports the layout type returned by GETATTR\
    \ and\n   it chooses to use pNFS for data access, it then sends LAYOUTGET using\n\
    \   the filehandle and stateid returned by OPEN, specifying the range it\n   wants\
    \ to do I/O on.  The response is a layout, which may be a subset\n   of the range\
    \ for which the client asked.  It also includes device IDs\n   and a description\
    \ of how data is organized (or in the case of\n   writing, how data is to be organized)\
    \ across the devices.  The device\n   IDs and data description are encoded in\
    \ a format that is specific to\n   the layout type, but the client is expected\
    \ to understand.\n   When the client wants to send an I/O, it determines to which\
    \ device\n   ID it needs to send the I/O command by examining the data description\n\
    \   in the layout.  It then sends a GETDEVICEINFO to find the device\n   address(es)\
    \ of the device ID.  The client then sends the I/O request\n   to one of device\
    \ ID's device addresses, using the storage protocol\n   defined for the layout\
    \ type.  Note that if a client has multiple I/Os\n   to send, these I/O requests\
    \ may be done in parallel.\n   If the I/O was a WRITE, then at some point the\
    \ client may want to use\n   LAYOUTCOMMIT to commit the modification time and\
    \ the new size of the\n   file (if it believes it extended the file size) to the\
    \ metadata\n   server and the modified data to the file system.\n"
- title: 12.7.  Recovery
  contents:
  - "12.7.  Recovery\n   Recovery is complicated by the distributed nature of the\
    \ pNFS\n   protocol.  In general, crash recovery for layouts is similar to crash\n\
    \   recovery for delegations in the base NFSv4.1 protocol.  However, the\n   client's\
    \ ability to perform I/O without contacting the metadata\n   server introduces\
    \ subtleties that must be handled correctly if the\n   possibility of file system\
    \ corruption is to be avoided.\n"
- title: 12.7.1.  Recovery from Client Restart
  contents:
  - "12.7.1.  Recovery from Client Restart\n   Client recovery for layouts is similar\
    \ to client recovery for other\n   lock and delegation state.  When a pNFS client\
    \ restarts, it will lose\n   all information about the layouts that it previously\
    \ owned.  There\n   are two methods by which the server can reclaim these resources\
    \ and\n   allow otherwise conflicting layouts to be provided to other clients.\n\
    \   The first is through the expiry of the client's lease.  If the client\n  \
    \ recovery time is longer than the lease period, the client's lease\n   will expire\
    \ and the server will know that state may be released.  For\n   layouts, the server\
    \ may release the state immediately upon lease\n   expiry or it may allow the\
    \ layout to persist, awaiting possible lease\n   revival, as long as no other\
    \ layout conflicts.\n   The second is through the client restarting in less time\
    \ than it\n   takes for the lease period to expire.  In such a case, the client\n\
    \   will contact the server through the standard EXCHANGE_ID protocol.\n   The\
    \ server will find that the client's co_ownerid matches the\n   co_ownerid of\
    \ the previous client invocation, but that the verifier\n   is different.  The\
    \ server uses this as a signal to release all layout\n   state associated with\
    \ the client's previous invocation.  In this\n   scenario, the data written by\
    \ the client but not covered by a\n   successful LAYOUTCOMMIT is in an undefined\
    \ state; it may have been\n   written or it may now be lost.  This is acceptable\
    \ behavior and it is\n   the client's responsibility to use LAYOUTCOMMIT to achieve\
    \ the\n   desired level of stability.\n"
- title: 12.7.2.  Dealing with Lease Expiration on the Client
  contents:
  - "12.7.2.  Dealing with Lease Expiration on the Client\n   If a client believes\
    \ its lease has expired, it MUST NOT send I/O to\n   the storage device until\
    \ it has validated its lease.  The client can\n   send a SEQUENCE operation to\
    \ the metadata server.  If the SEQUENCE\n   operation is successful, but sr_status_flag\
    \ has\n   SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED,\n   SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED,\
    \ or\n   SEQ4_STATUS_ADMIN_STATE_REVOKED set, the client MUST NOT use\n   currently\
    \ held layouts.  The client has two choices to recover from\n   the lease expiration.\
    \  First, for all modified but uncommitted data,\n   the client writes it to the\
    \ metadata server using the FILE_SYNC4 flag\n   for the WRITEs, or WRITE and COMMIT.\
    \  Second, the client re-\n   establishes a client ID and session with the server\
    \ and obtains new\n   layouts and device-ID-to-device-address mappings for the\
    \ modified\n   data ranges and then writes the data to the storage devices with\
    \ the\n   newly obtained layouts.\n   If sr_status_flags from the metadata server\
    \ has\n   SEQ4_STATUS_RESTART_RECLAIM_NEEDED set (or SEQUENCE returns\n   NFS4ERR_BAD_SESSION\
    \ and CREATE_SESSION returns\n   NFS4ERR_STALE_CLIENTID), then the metadata server\
    \ has restarted, and\n   the client SHOULD recover using the methods described\
    \ in\n   Section 12.7.4.\n   If sr_status_flags from the metadata server has\n\
    \   SEQ4_STATUS_LEASE_MOVED set, then the client recovers by following\n   the\
    \ procedure described in Section 11.11.9.2.  After that, the client\n   may get\
    \ an indication that the layout state was not moved with the\n   file system.\
    \  The client recovers as in the other applicable\n   situations discussed in\
    \ the first two paragraphs of this section.\n   If sr_status_flags reports no\
    \ loss of state, then the lease for the\n   layouts that the client has are valid\
    \ and renewed, and the client can\n   once again send I/O requests to the storage\
    \ devices.\n   While clients SHOULD NOT send I/Os to storage devices that may\
    \ extend\n   past the lease expiration time period, this is not always possible,\n\
    \   for example, an extended network partition that starts after the I/O\n   is\
    \ sent and does not heal until the I/O request is received by the\n   storage\
    \ device.  Thus, the metadata server and/or storage devices are\n   responsible\
    \ for protecting themselves from I/Os that are both sent\n   before the lease\
    \ expires and arrive after the lease expires.  See\n   Section 12.7.3.\n"
- title: 12.7.3.  Dealing with Loss of Layout State on the Metadata Server
  contents:
  - "12.7.3.  Dealing with Loss of Layout State on the Metadata Server\n   This is\
    \ a description of the case where all of the following are\n   true:\n   *  the\
    \ metadata server has not restarted\n   *  a pNFS client's layouts have been discarded\
    \ (usually because the\n      client's lease expired) and are invalid\n   *  an\
    \ I/O from the pNFS client arrives at the storage device\n   The metadata server\
    \ and its storage devices MUST solve this by\n   fencing the client.  In other\
    \ words, they MUST solve this by\n   preventing the execution of I/O operations\
    \ from the client to the\n   storage devices after layout state loss.  The details\
    \ of how fencing\n   is done are specific to the layout type.  The solution for\
    \ NFSv4.1\n   file-based layouts is described in (Section 13.11), and solutions\
    \ for\n   other layout types are in their respective external specification\n\
    \   documents.\n"
- title: 12.7.4.  Recovery from Metadata Server Restart
  contents:
  - "12.7.4.  Recovery from Metadata Server Restart\n   The pNFS client will discover\
    \ that the metadata server has restarted\n   via the methods described in Section\
    \ 8.4.2 and discussed in a pNFS-\n   specific context in Section 12.7.2, Paragraph\
    \ 2.  The client MUST\n   stop using layouts and delete the device ID to device\
    \ address\n   mappings it previously received from the metadata server.  Having\n\
    \   done that, if the client wrote data to the storage device without\n   committing\
    \ the layouts via LAYOUTCOMMIT, then the client has\n   additional work to do\
    \ in order to have the client, metadata server,\n   and storage device(s) all\
    \ synchronized on the state of the data.\n   *  If the client has data still modified\
    \ and unwritten in the\n      client's memory, the client has only two choices.\n\
    \      1.  The client can obtain a layout via LAYOUTGET after the\n          server's\
    \ grace period and write the data to the storage\n          devices.\n      2.\
    \  The client can WRITE that data through the metadata server\n          using\
    \ the WRITE (Section 18.32) operation, and then obtain\n          layouts as desired.\n\
    \   *  If the client asynchronously wrote data to the storage device, but\n  \
    \    still has a copy of the data in its memory, then it has available\n     \
    \ to it the recovery options listed above in the previous bullet\n      point.\
    \  If the metadata server is also in its grace period, the\n      client has available\
    \ to it the options below in the next bullet\n      point.\n   *  The client does\
    \ not have a copy of the data in its memory and the\n      metadata server is\
    \ still in its grace period.  The client cannot\n      use LAYOUTGET (within or\
    \ outside the grace period) to reclaim a\n      layout because the contents of\
    \ the response from LAYOUTGET may not\n      match what it had previously.  The\
    \ range might be different or the\n      client might get the same range but the\
    \ content of the layout\n      might be different.  Even if the content of the\
    \ layout appears to\n      be the same, the device IDs may map to different device\
    \ addresses,\n      and even if the device addresses are the same, the device\n\
    \      addresses could have been assigned to a different storage device.\n   \
    \   The option of retrieving the data from the storage device and\n      writing\
    \ it to the metadata server per the recovery scenario\n      described above is\
    \ not available because, again, the mappings of\n      range to device ID, device\
    \ ID to device address, and device\n      address to physical device are stale,\
    \ and new mappings via new\n      LAYOUTGET do not solve the problem.\n      The\
    \ only recovery option for this scenario is to send a\n      LAYOUTCOMMIT in reclaim\
    \ mode, which the metadata server will\n      accept as long as it is in its grace\
    \ period.  The use of\n      LAYOUTCOMMIT in reclaim mode informs the metadata\
    \ server that the\n      layout has changed.  It is critical that the metadata\
    \ server\n      receive this information before its grace period ends, and thus\n\
    \      before it starts allowing updates to the file system.\n      To send LAYOUTCOMMIT\
    \ in reclaim mode, the client sets the\n      loca_reclaim field of the operation's\
    \ arguments (Section 18.42.1)\n      to TRUE.  During the metadata server's recovery\
    \ grace period (and\n      only during the recovery grace period) the metadata\
    \ server is\n      prepared to accept LAYOUTCOMMIT requests with the loca_reclaim\n\
    \      field set to TRUE.\n      When loca_reclaim is TRUE, the client is attempting\
    \ to commit\n      changes to the layout that occurred prior to the restart of\
    \ the\n      metadata server.  The metadata server applies some consistency\n\
    \      checks on the loca_layoutupdate field of the arguments to\n      determine\
    \ whether the client can commit the data written to the\n      storage device\
    \ to the file system.  The loca_layoutupdate field is\n      of data type layoutupdate4\
    \ and contains layout-type-specific\n      content (in the lou_body field of loca_layoutupdate).\
    \  The layout-\n      type-specific information that loca_layoutupdate might have\
    \ is\n      discussed in Section 12.5.4.3.  If the metadata server's\n      consistency\
    \ checks on loca_layoutupdate succeed, then the metadata\n      server MUST commit\
    \ the data (as described by the loca_offset,\n      loca_length, and loca_layoutupdate\
    \ fields of the arguments) that\n      was written to the storage device.  If\
    \ the metadata server's\n      consistency checks on loca_layoutupdate fail, the\
    \ metadata server\n      rejects the LAYOUTCOMMIT operation and makes no changes\
    \ to the\n      file system.  However, any time LAYOUTCOMMIT with loca_reclaim\n\
    \      TRUE fails, the pNFS client has lost all the data in the range\n      defined\
    \ by <loca_offset, loca_length>.  A client can defend\n      against this risk\
    \ by caching all data, whether written\n      synchronously or asynchronously\
    \ in its memory, and by not\n      releasing the cached data until a successful\
    \ LAYOUTCOMMIT.  This\n      condition does not hold true for all layout types;\
    \ for example,\n      file-based storage devices need not suffer from this limitation.\n\
    \   *  The client does not have a copy of the data in its memory and the\n   \
    \   metadata server is no longer in its grace period; i.e., the\n      metadata\
    \ server returns NFS4ERR_NO_GRACE.  As with the scenario in\n      the above bullet\
    \ point, the failure of LAYOUTCOMMIT means the data\n      in the range <loca_offset,\
    \ loca_length> lost.  The defense against\n      the risk is the same -- cache\
    \ all written data on the client until\n      a successful LAYOUTCOMMIT.\n"
- title: 12.7.5.  Operations during Metadata Server Grace Period
  contents:
  - "12.7.5.  Operations during Metadata Server Grace Period\n   Some of the recovery\
    \ scenarios thus far noted that some operations\n   (namely, WRITE and LAYOUTGET)\
    \ might be permitted during the metadata\n   server's grace period.  The metadata\
    \ server may allow these\n   operations during its grace period.  For LAYOUTGET,\
    \ the metadata\n   server must reliably determine that servicing such a request\
    \ will not\n   conflict with an impending LAYOUTCOMMIT reclaim request.  For WRITE,\n\
    \   the metadata server must reliably determine that servicing the\n   request\
    \ will not conflict with an impending OPEN or with a LOCK where\n   the file has\
    \ mandatory byte-range locking enabled.\n   As mentioned previously, for expediency,\
    \ the metadata server might\n   reject some operations (namely, WRITE and LAYOUTGET)\
    \ during its grace\n   period, because the simplest correct approach is to reject\
    \ all non-\n   reclaim pNFS requests and WRITE operations by returning the\n \
    \  NFS4ERR_GRACE error.  However, depending on the storage protocol\n   (which\
    \ is specific to the layout type) and metadata server\n   implementation, the\
    \ metadata server may be able to determine that a\n   particular request is safe.\
    \  For example, a metadata server may save\n   provisional allocation mappings\
    \ for each file to stable storage, as\n   well as information about potentially\
    \ conflicting OPEN share modes\n   and mandatory byte-range locks that might have\
    \ been in effect at the\n   time of restart, and the metadata server may use this\
    \ information\n   during the recovery grace period to determine that a WRITE request\
    \ is\n   safe.\n"
- title: 12.7.6.  Storage Device Recovery
  contents:
  - "12.7.6.  Storage Device Recovery\n   Recovery from storage device restart is\
    \ mostly dependent upon the\n   layout type in use.  However, there are a few\
    \ general techniques a\n   client can use if it discovers a storage device has\
    \ crashed while\n   holding modified, uncommitted data that was asynchronously\
    \ written.\n   First and foremost, it is important to realize that the client\
    \ is the\n   only one that has the information necessary to recover non-committed\n\
    \   data since it holds the modified data and probably nothing else does.\n  \
    \ Second, the best solution is for the client to err on the side of\n   caution\
    \ and attempt to rewrite the modified data through another\n   path.\n   The client\
    \ SHOULD immediately WRITE the data to the metadata server,\n   with the stable\
    \ field in the WRITE4args set to FILE_SYNC4.  Once it\n   does this, there is\
    \ no need to wait for the original storage device.\n"
- title: 12.8.  Metadata and Storage Device Roles
  contents:
  - "12.8.  Metadata and Storage Device Roles\n   If the same physical hardware is\
    \ used to implement both a metadata\n   server and storage device, then the same\
    \ hardware entity is to be\n   understood to be implementing two distinct roles\
    \ and it is important\n   that it be clearly understood on behalf of which role\
    \ the hardware is\n   executing at any given time.\n   Two sub-cases can be distinguished.\n\
    \   1.  The storage device uses NFSv4.1 as the storage protocol, i.e.,\n     \
    \  the same physical hardware is used to implement both a metadata\n       and\
    \ data server.  See Section 13.1 for a description of how\n       multiple roles\
    \ are handled.\n   2.  The storage device does not use NFSv4.1 as the storage\
    \ protocol,\n       and the same physical hardware is used to implement both a\n\
    \       metadata and storage device.  Whether distinct network addresses\n   \
    \    are used to access the metadata server and storage device is\n       immaterial.\
    \  This is because it is always clear to the pNFS\n       client and server, from\
    \ the upper-layer protocol being used\n       (NFSv4.1 or non-NFSv4.1), to which\
    \ role the request to the common\n       server network address is directed.\n"
- title: 12.9.  Security Considerations for pNFS
  contents:
  - "12.9.  Security Considerations for pNFS\n   pNFS separates file system metadata\
    \ and data and provides access to\n   both.  There are pNFS-specific operations\
    \ (listed in Section 12.3)\n   that provide access to the metadata; all existing\
    \ NFSv4.1\n   conventional (non-pNFS) security mechanisms and features apply to\n\
    \   accessing the metadata.  The combination of components in a pNFS\n   system\
    \ (see Figure 1) is required to preserve the security properties\n   of NFSv4.1\
    \ with respect to an entity that is accessing a storage\n   device from a client,\
    \ including security countermeasures to defend\n   against threats for which NFSv4.1\
    \ provides defenses in environments\n   where these threats are considered significant.\n\
    \   In some cases, the security countermeasures for connections to\n   storage\
    \ devices may take the form of physical isolation or a\n   recommendation to avoid\
    \ the use of pNFS in an environment.  For\n   example, it may be impractical to\
    \ provide confidentiality protection\n   for some storage protocols to protect\
    \ against eavesdropping.  In\n   environments where eavesdropping on such protocols\
    \ is of sufficient\n   concern to require countermeasures, physical isolation\
    \ of the\n   communication channel (e.g., via direct connection from client(s)\
    \ to\n   storage device(s)) and/or a decision to forgo use of pNFS (e.g., and\n\
    \   fall back to conventional NFSv4.1) may be appropriate courses of\n   action.\n\
    \   Where communication with storage devices is subject to the same\n   threats\
    \ as client-to-metadata server communication, the protocols\n   used for that\
    \ communication need to provide security mechanisms as\n   strong as or no weaker\
    \ than those available via RPCSEC_GSS for\n   NFSv4.1.  Except for the storage\
    \ protocol used for the\n   LAYOUT4_NFSV4_1_FILES layout (see Section 13), i.e.,\
    \ except for\n   NFSv4.1, it is beyond the scope of this document to specify the\n\
    \   security mechanisms for storage access protocols.\n   pNFS implementations\
    \ MUST NOT remove NFSv4.1's access controls.  The\n   combination of clients,\
    \ storage devices, and the metadata server are\n   responsible for ensuring that\
    \ all client-to-storage-device file data\n   access respects NFSv4.1's ACLs and\
    \ file open modes.  This entails\n   performing both of these checks on every\
    \ access in the client, the\n   storage device, or both (as applicable; when the\
    \ storage device is an\n   NFSv4.1 server, the storage device is ultimately responsible\
    \ for\n   controlling access as described in Section 13.9.2).  If a pNFS\n   configuration\
    \ performs these checks only in the client, the risk of a\n   misbehaving client\
    \ obtaining unauthorized access is an important\n   consideration in determining\
    \ when it is appropriate to use such a\n   pNFS configuration.  Such layout types\
    \ SHOULD NOT be used when\n   client-only access checks do not provide sufficient\
    \ assurance that\n   NFSv4.1 access control is being applied correctly.  (This\
    \ is not a\n   problem for the file layout type described in Section 13 because\
    \ the\n   storage access protocol for LAYOUT4_NFSV4_1_FILES is NFSv4.1, and\n\
    \   thus the security model for storage device access via\n   LAYOUT4_NFSv4_1_FILES\
    \ is the same as that of the metadata server.)\n   For handling of access control\
    \ specific to a layout, the reader\n   should examine the layout specification,\
    \ such as the NFSv4.1/\n   file-based layout (Section 13) of this document, the\
    \ blocks layout\n   [48], and objects layout [47].\n"
- title: '13.  NFSv4.1 as a Storage Protocol in pNFS: the File Layout Type'
  contents:
  - "13.  NFSv4.1 as a Storage Protocol in pNFS: the File Layout Type\n   This section\
    \ describes the semantics and format of NFSv4.1 file-based\n   layouts for pNFS.\
    \  NFSv4.1 file-based layouts use the\n   LAYOUT4_NFSV4_1_FILES layout type. \
    \ The LAYOUT4_NFSV4_1_FILES type\n   defines striping data across multiple NFSv4.1\
    \ data servers.\n"
- title: 13.1.  Client ID and Session Considerations
  contents:
  - "13.1.  Client ID and Session Considerations\n   Sessions are a REQUIRED feature\
    \ of NFSv4.1, and this extends to both\n   the metadata server and file-based\
    \ (NFSv4.1-based) data servers.\n   The role a server plays in pNFS is determined\
    \ by the result it\n   returns from EXCHANGE_ID.  The roles are:\n   *  Metadata\
    \ server (EXCHGID4_FLAG_USE_PNFS_MDS is set in the result\n      eir_flags).\n\
    \   *  Data server (EXCHGID4_FLAG_USE_PNFS_DS).\n   *  Non-metadata server (EXCHGID4_FLAG_USE_NON_PNFS).\
    \  This is an\n      NFSv4.1 server that does not support operations (e.g., LAYOUTGET)\n\
    \      or attributes that pertain to pNFS.\n   The client MAY request zero or\
    \ more of EXCHGID4_FLAG_USE_NON_PNFS,\n   EXCHGID4_FLAG_USE_PNFS_DS, or EXCHGID4_FLAG_USE_PNFS_MDS,\
    \ even though\n   some combinations (e.g., EXCHGID4_FLAG_USE_NON_PNFS |\n   EXCHGID4_FLAG_USE_PNFS_MDS)\
    \ are contradictory.  However, the server\n   MUST only return the following acceptable\
    \ combinations:\n        | Acceptable Results from EXCHANGE_ID               \
    \     |\n        | EXCHGID4_FLAG_USE_PNFS_MDS                             |\n\
    \        | EXCHGID4_FLAG_USE_PNFS_MDS | EXCHGID4_FLAG_USE_PNFS_DS |\n        |\
    \ EXCHGID4_FLAG_USE_PNFS_DS                              |\n        | EXCHGID4_FLAG_USE_NON_PNFS\
    \                             |\n        | EXCHGID4_FLAG_USE_PNFS_DS | EXCHGID4_FLAG_USE_NON_PNFS\
    \ |\n   As the above table implies, a server can have one or two roles.  A\n \
    \  server can be both a metadata server and a data server, or it can be\n   both\
    \ a data server and non-metadata server.  In addition to returning\n   two roles\
    \ in the EXCHANGE_ID's results, and thus serving both roles\n   via a common client\
    \ ID, a server can serve two roles by returning a\n   unique client ID and server\
    \ owner for each role in each of two\n   EXCHANGE_ID results, with each result\
    \ indicating each role.\n   In the case of a server with concurrent pNFS roles\
    \ that are served by\n   a common client ID, if the EXCHANGE_ID request from the\
    \ client has\n   zero or a combination of the bits set in eia_flags, the server\
    \ result\n   should set bits that represent the higher of the acceptable\n   combination\
    \ of the server roles, with a preference to match the roles\n   requested by the\
    \ client.  Thus, if a client request has\n   (EXCHGID4_FLAG_USE_NON_PNFS | EXCHGID4_FLAG_USE_PNFS_MDS\
    \ |\n   EXCHGID4_FLAG_USE_PNFS_DS) flags set, and the server is both a\n   metadata\
    \ server and a data server, serving both the roles by a common\n   client ID,\
    \ the server SHOULD return with\n   (EXCHGID4_FLAG_USE_PNFS_MDS | EXCHGID4_FLAG_USE_PNFS_DS)\
    \ set.\n   In the case of a server that has multiple concurrent pNFS roles, each\n\
    \   role served by a unique client ID, if the client specifies zero or a\n   combination\
    \ of roles in the request, the server results SHOULD return\n   only one of the\
    \ roles from the combination specified by the client\n   request.  If the role\
    \ specified by the server result does not match\n   the intended use by the client,\
    \ the client should send the\n   EXCHANGE_ID specifying just the interested pNFS\
    \ role.\n   If a pNFS metadata client gets a layout that refers it to an NFSv4.1\n\
    \   data server, it needs a client ID on that data server.  If it does\n   not\
    \ yet have a client ID from the server that had the\n   EXCHGID4_FLAG_USE_PNFS_DS\
    \ flag set in the EXCHANGE_ID results, then\n   the client needs to send an EXCHANGE_ID\
    \ to the data server, using the\n   same co_ownerid as it sent to the metadata\
    \ server, with the\n   EXCHGID4_FLAG_USE_PNFS_DS flag set in the arguments.  If\
    \ the server's\n   EXCHANGE_ID results have EXCHGID4_FLAG_USE_PNFS_DS set, then\
    \ the\n   client may use the client ID to create sessions that will exchange\n\
    \   pNFS data operations.  The client ID returned by the data server has\n   no\
    \ relationship with the client ID returned by a metadata server\n   unless the\
    \ client IDs are equal, and the server owners and server\n   scopes of the data\
    \ server and metadata server are equal.\n   In NFSv4.1, the session ID in the\
    \ SEQUENCE operation implies the\n   client ID, which in turn might be used by\
    \ the server to map the\n   stateid to the right client/server pair.  However,\
    \ when a data server\n   is presented with a READ or WRITE operation with a stateid,\
    \ because\n   the stateid is associated with a client ID on a metadata server,\
    \ and\n   because the session ID in the preceding SEQUENCE operation is tied to\n\
    \   the client ID of the data server, the data server has no obvious way\n   to\
    \ determine the metadata server from the COMPOUND procedure, and\n   thus has\
    \ no way to validate the stateid.  One RECOMMENDED approach is\n   for pNFS servers\
    \ to encode metadata server routing and/or identity\n   information in the data\
    \ server filehandles as returned in the layout.\n   If metadata server routing\
    \ and/or identity information is encoded in\n   data server filehandles, when\
    \ the metadata server identity or\n   location changes, the data server filehandles\
    \ it gave out will become\n   invalid (stale), and so the metadata server MUST\
    \ first recall the\n   layouts.  Invalidating a data server filehandle does not\
    \ render the\n   NFS client's data cache invalid.  The client's cache should map\
    \ a\n   data server filehandle to a metadata server filehandle, and a\n   metadata\
    \ server filehandle to cached data.\n   If a server is both a metadata server\
    \ and a data server, the server\n   might need to distinguish operations on files\
    \ that are directed to\n   the metadata server from those that are directed to\
    \ the data server.\n   It is RECOMMENDED that the values of the filehandles returned\
    \ by the\n   LAYOUTGET operation be different than the value of the filehandle\n\
    \   returned by the OPEN of the same file.\n   Another scenario is for the metadata\
    \ server and the storage device to\n   be distinct from one client's point of\
    \ view, and the roles reversed\n   from another client's point of view.  For example,\
    \ in the cluster\n   file system model, a metadata server to one client might\
    \ be a data\n   server to another client.  If NFSv4.1 is being used as the storage\n\
    \   protocol, then pNFS servers need to encode the values of filehandles\n   according\
    \ to their specific roles.\n"
- title: 13.1.1.  Sessions Considerations for Data Servers
  contents:
  - "13.1.1.  Sessions Considerations for Data Servers\n   Section 2.10.11.2 states\
    \ that a client has to keep its lease renewed\n   in order to prevent a session\
    \ from being deleted by the server.  If\n   the reply to EXCHANGE_ID has just\
    \ the EXCHGID4_FLAG_USE_PNFS_DS role\n   set, then (as noted in Section 13.6)\
    \ the client will not be able to\n   determine the data server's lease_time attribute\
    \ because GETATTR will\n   not be permitted.  Instead, the rule is that any time\
    \ a client\n   receives a layout referring it to a data server that returns just\
    \ the\n   EXCHGID4_FLAG_USE_PNFS_DS role, the client MAY assume that the\n   lease_time\
    \ attribute from the metadata server that returned the\n   layout applies to the\
    \ data server.  Thus, the data server MUST be\n   aware of the values of all lease_time\
    \ attributes of all metadata\n   servers for which it is providing I/O, and it\
    \ MUST use the maximum of\n   all such lease_time values as the lease interval\
    \ for all client IDs\n   and sessions established on it.\n   For example, if one\
    \ metadata server has a lease_time attribute of 20\n   seconds, and a second metadata\
    \ server has a lease_time attribute of\n   10 seconds, then if both servers return\
    \ layouts that refer to an\n   EXCHGID4_FLAG_USE_PNFS_DS-only data server, the\
    \ data server MUST\n   renew a client's lease if the interval between two SEQUENCE\n\
    \   operations on different COMPOUND requests is less than 20 seconds.\n"
- title: 13.2.  File Layout Definitions
  contents:
  - "13.2.  File Layout Definitions\n   The following definitions apply to the LAYOUT4_NFSV4_1_FILES\
    \ layout\n   type and may be applicable to other layout types.\n   Unit.  A unit\
    \ is a fixed-size quantity of data written to a data\n      server.\n   Pattern.\
    \  A pattern is a method of distributing one or more equal\n      sized units\
    \ across a set of data servers.  A pattern is iterated\n      one or more times.\n\
    \   Stripe.  A stripe is a set of data distributed across a set of data\n    \
    \  servers in a pattern before that pattern repeats.\n   Stripe Count.  A stripe\
    \ count is the number of units in a pattern.\n   Stripe Width.  A stripe width\
    \ is the size of a stripe in bytes.  The\n      stripe width = the stripe count\
    \ * the size of the stripe unit.\n   Hereafter, this document will refer to a\
    \ unit that is a written in a\n   pattern as a \"stripe unit\".\n   A pattern\
    \ may have more stripe units than data servers.  If so, some\n   data servers\
    \ will have more than one stripe unit per stripe.  A data\n   server that has\
    \ multiple stripe units per stripe MAY store each unit\n   in a different data\
    \ file (and depending on the implementation, will\n   possibly assign a unique\
    \ data filehandle to each data file).\n"
- title: 13.3.  File Layout Data Types
  contents:
  - "13.3.  File Layout Data Types\n   The high level NFSv4.1 layout types are nfsv4_1_file_layouthint4,\n\
    \   nfsv4_1_file_layout_ds_addr4, and nfsv4_1_file_layout4.\n   The SETATTR operation\
    \ supports a layout hint attribute\n   (Section 5.12.4).  When the client sets\
    \ a layout hint (data type\n   layouthint4) with a layout type of LAYOUT4_NFSV4_1_FILES\
    \ (the\n   loh_type field), the loh_body field contains a value of data type\n\
    \   nfsv4_1_file_layouthint4.\n   const NFL4_UFLG_MASK            = 0x0000003F;\n\
    \   const NFL4_UFLG_DENSE           = 0x00000001;\n   const NFL4_UFLG_COMMIT_THRU_MDS\
    \ = 0x00000002;\n   const NFL4_UFLG_STRIPE_UNIT_SIZE_MASK\n   typedef uint32_t\
    \ nfl_util4;\n   enum filelayout_hint_care4 {\n           NFLH4_CARE_DENSE   \
    \     = NFL4_UFLG_DENSE,\n           NFLH4_CARE_COMMIT_THRU_MDS\n           NFLH4_CARE_STRIPE_UNIT_SIZE\n\
    \           NFLH4_CARE_STRIPE_COUNT = 0x00000080\n   };\n   /* Encoded in the\
    \ loh_body field of data type layouthint4: */\n   struct nfsv4_1_file_layouthint4\
    \ {\n           uint32_t        nflh_care;\n           nfl_util4       nflh_util;\n\
    \           count4          nflh_stripe_count;\n   };\n   The generic layout hint\
    \ structure is described in Section 3.3.19.\n   The client uses the layout hint\
    \ in the layout_hint (Section 5.12.4)\n   attribute to indicate the preferred\
    \ type of layout to be used for a\n   newly created file.  The LAYOUT4_NFSV4_1_FILES\
    \ layout-type-specific\n   content for the layout hint is composed of three fields.\
    \  The first\n   field, nflh_care, is a set of flags indicating which values of\
    \ the\n   hint the client cares about.  If the NFLH4_CARE_DENSE flag is set,\n\
    \   then the client indicates in the second field, nflh_util, a\n   preference\
    \ for how the data file is packed (Section 13.4.4), which is\n   controlled by\
    \ the value of the expression nflh_util & NFL4_UFLG_DENSE\n   (\"&\" represents\
    \ the bitwise AND operator).  If the\n   NFLH4_CARE_COMMIT_THRU_MDS flag is set,\
    \ then the client indicates a\n   preference for whether the client should send\
    \ COMMIT operations to\n   the metadata server or data server (Section 13.7),\
    \ which is\n   controlled by the value of nflh_util & NFL4_UFLG_COMMIT_THRU_MDS.\
    \  If\n   the NFLH4_CARE_STRIPE_UNIT_SIZE flag is set, the client indicates its\n\
    \   preferred stripe unit size, which is indicated in nflh_util &\n   NFL4_UFLG_STRIPE_UNIT_SIZE_MASK\
    \ (thus, the stripe unit size MUST be a\n   multiple of 64 bytes).  The minimum\
    \ stripe unit size is 64 bytes.  If\n   the NFLH4_CARE_STRIPE_COUNT flag is set,\
    \ the client indicates in the\n   third field, nflh_stripe_count, the stripe count.\
    \  The stripe count\n   multiplied by the stripe unit size is the stripe width.\n\
    \   When LAYOUTGET returns a LAYOUT4_NFSV4_1_FILES layout (indicated in\n   the\
    \ loc_type field of the lo_content field), the loc_body field of\n   the lo_content\
    \ field contains a value of data type\n   nfsv4_1_file_layout4.  Among other content,\
    \ nfsv4_1_file_layout4 has\n   a storage device ID (field nfl_deviceid) of data\
    \ type deviceid4.  The\n   GETDEVICEINFO operation maps a device ID to a storage\
    \ device address\n   (type device_addr4).  When GETDEVICEINFO returns a device\
    \ address\n   with a layout type of LAYOUT4_NFSV4_1_FILES (the da_layout_type\n\
    \   field), the da_addr_body field contains a value of data type\n   nfsv4_1_file_layout_ds_addr4.\n\
    \   typedef netaddr4 multipath_list4<>;\n   /*\n    * Encoded in the da_addr_body\
    \ field of\n    * data type device_addr4:\n    */\n   struct nfsv4_1_file_layout_ds_addr4\
    \ {\n           uint32_t        nflda_stripe_indices<>;\n           multipath_list4\
    \ nflda_multipath_ds_list<>;\n   };\n   The nfsv4_1_file_layout_ds_addr4 data\
    \ type represents the device\n   address.  It is composed of two fields:\n   1.\
    \  nflda_multipath_ds_list: An array of lists of data servers, where\n       each\
    \ list can be one or more elements, and each element\n       represents a data\
    \ server address that may serve equally as the\n       target of I/O operations\
    \ (see Section 13.5).  The length of this\n       array might be different than\
    \ the stripe count.\n   2.  nflda_stripe_indices: An array of indices used to\
    \ index into\n       nflda_multipath_ds_list.  The value of each element of\n\
    \       nflda_stripe_indices MUST be less than the number of elements in\n   \
    \    nflda_multipath_ds_list.  Each element of nflda_multipath_ds_list\n     \
    \  SHOULD be referred to by one or more elements of\n       nflda_stripe_indices.\
    \  The number of elements in\n       nflda_stripe_indices is always equal to the\
    \ stripe count.\n   /*\n    * Encoded in the loc_body field of\n    * data type\
    \ layout_content4:\n    */\n   struct nfsv4_1_file_layout4 {\n            deviceid4\
    \      nfl_deviceid;\n            nfl_util4      nfl_util;\n            uint32_t\
    \       nfl_first_stripe_index;\n            offset4        nfl_pattern_offset;\n\
    \            nfs_fh4        nfl_fh_list<>;\n   };\n   The nfsv4_1_file_layout4\
    \ data type represents the layout.  It is\n   composed of the following fields:\n\
    \   1.  nfl_deviceid: The device ID that maps to a value of type\n       nfsv4_1_file_layout_ds_addr4.\n\
    \   2.  nfl_util: Like the nflh_util field of data type\n       nfsv4_1_file_layouthint4,\
    \ a compact representation of how the\n       data on a file on each data server\
    \ is packed, whether the client\n       should send COMMIT operations to the metadata\
    \ server or data\n       server, and the stripe unit size.  If a server returns\
    \ two or\n       more overlapping layouts, each stripe unit size in each\n   \
    \    overlapping layout MUST be the same.\n   3.  nfl_first_stripe_index: The\
    \ index into the first element of the\n       nflda_stripe_indices array to use.\n\
    \   4.  nfl_pattern_offset: This field is the logical offset into the\n      \
    \ file where the striping pattern starts.  It is required for\n       converting\
    \ the client's logical I/O offset (e.g., the current\n       offset in a POSIX\
    \ file descriptor before the read() or write()\n       system call is sent) into\
    \ the stripe unit number (see\n       Section 13.4.1).\n       If dense packing\
    \ is used, then nfl_pattern_offset is also needed\n       to convert the client's\
    \ logical I/O offset to an offset on the\n       file on the data server corresponding\
    \ to the stripe unit number\n       (see Section 13.4.4).\n       Note that nfl_pattern_offset\
    \ is not always the same as lo_offset.\n       For example, via the LAYOUTGET\
    \ operation, a client might request\n       a layout starting at offset 1000 of\
    \ a file that has its striping\n       pattern start at offset zero.\n   5.  nfl_fh_list:\
    \ An array of data server filehandles for each list of\n       data servers in\
    \ each element of the nflda_multipath_ds_list\n       array.  The number of elements\
    \ in nfl_fh_list depends on whether\n       sparse or dense packing is being used.\n\
    \       *  If sparse packing is being used, the number of elements in\n      \
    \    nfl_fh_list MUST be one of three values:\n          -  Zero.  This means\
    \ that filehandles used for each data\n             server are the same as the\
    \ filehandle returned by the OPEN\n             operation from the metadata server.\n\
    \          -  One.  This means that every data server uses the same\n        \
    \     filehandle: what is specified in nfl_fh_list[0].\n          -  The same\
    \ number of elements in nflda_multipath_ds_list.\n             Thus, in this case,\
    \ when sending an I/O operation to any\n             data server in nflda_multipath_ds_list[X],\
    \ the filehandle\n             in nfl_fh_list[X] MUST be used.\n          See\
    \ the discussion on sparse packing in Section 13.4.4.\n       *  If dense packing\
    \ is being used, the number of elements in\n          nfl_fh_list MUST be the\
    \ same as the number of elements in\n          nflda_stripe_indices.  Thus, when\
    \ sending an I/O operation to\n          any data server in\n          nflda_multipath_ds_list[nflda_stripe_indices[Y]],\
    \ the\n          filehandle in nfl_fh_list[Y] MUST be used.  In addition, any\n\
    \          time there exists i and j, (i != j), such that the\n          intersection\
    \ of\n          nflda_multipath_ds_list[nflda_stripe_indices[i]] and\n       \
    \   nflda_multipath_ds_list[nflda_stripe_indices[j]] is not empty,\n         \
    \ then nfl_fh_list[i] MUST NOT equal nfl_fh_list[j].  In other\n          words,\
    \ when dense packing is being used, if a data server\n          appears in two\
    \ or more units of a striping pattern, each\n          reference to the data server\
    \ MUST use a different filehandle.\n          Indeed, if there are multiple striping\
    \ patterns, as indicated\n          by the presence of multiple objects of data\
    \ type layout4\n          (either returned in one or multiple LAYOUTGET operations),\
    \ and\n          a data server is the target of a unit of one pattern and\n  \
    \        another unit of another pattern, then each reference to each\n      \
    \    data server MUST use a different filehandle.\n          See the discussion\
    \ on dense packing in Section 13.4.4.\n   The details on the interpretation of\
    \ the layout are in Section 13.4.\n"
- title: 13.4.  Interpreting the File Layout
  contents:
  - '13.4.  Interpreting the File Layout

    '
- title: 13.4.1.  Determining the Stripe Unit Number
  contents:
  - "13.4.1.  Determining the Stripe Unit Number\n   To find the stripe unit number\
    \ that corresponds to the client's\n   logical file offset, the pattern offset\
    \ will also be used.  The i'th\n   stripe unit (SUi) is:\n       relative_offset\
    \ = file_offset - nfl_pattern_offset;\n       SUi = floor(relative_offset / stripe_unit_size);\n"
- title: 13.4.2.  Interpreting the File Layout Using Sparse Packing
  contents:
  - "13.4.2.  Interpreting the File Layout Using Sparse Packing\n   When sparse packing\
    \ is used, the algorithm for determining the\n   filehandle and set of data-server\
    \ network addresses to write stripe\n   unit i (SUi) to is:\n      stripe_count\
    \ = number of elements in nflda_stripe_indices;\n      j = (SUi + nfl_first_stripe_index)\
    \ % stripe_count;\n      idx = nflda_stripe_indices[j];\n      fh_count = number\
    \ of elements in nfl_fh_list;\n      ds_count = number of elements in nflda_multipath_ds_list;\n\
    \      switch (fh_count) {\n        case ds_count:\n          fh = nfl_fh_list[idx];\n\
    \          break;\n        case 1:\n          fh = nfl_fh_list[0];\n         \
    \ break;\n        case 0:\n          fh = filehandle returned by OPEN;\n     \
    \     break;\n        default:\n          throw a fatal exception;\n         \
    \ break;\n      }\n      address_list = nflda_multipath_ds_list[idx];\n   The\
    \ client would then select a data server from address_list, and\n   send a READ\
    \ or WRITE operation using the filehandle specified in fh.\n   Consider the following\
    \ example:\n   Suppose we have a device address consisting of seven data servers,\n\
    \   arranged in three equivalence (Section 13.5) classes:\n      { A, B, C, D\
    \ }, { E }, { F, G }\n   where A through G are network addresses.\n   Then\n \
    \     nflda_multipath_ds_list<> = { A, B, C, D }, { E }, { F, G }\n   i.e.,\n\
    \      nflda_multipath_ds_list[0] = { A, B, C, D }\n      nflda_multipath_ds_list[1]\
    \ = { E }\n      nflda_multipath_ds_list[2] = { F, G }\n   Suppose the striping\
    \ index array is:\n      nflda_stripe_indices<> = { 2, 0, 1, 0 }\n   Now suppose\
    \ the client gets a layout that has a device ID that maps\n   to the above device\
    \ address.  The initial index contains\n      nfl_first_stripe_index = 2,\n  \
    \ and the filehandle list is\n      nfl_fh_list = { 0x36, 0x87, 0x67 }.\n   If\
    \ the client wants to write to SU0, the set of valid { network\n   address, filehandle\
    \ } combinations for SUi are determined by:\n      nfl_first_stripe_index = 2\n\
    \   So\n      idx = nflda_stripe_indices[(0 + 2) % 4]\n         = nflda_stripe_indices[2]\n\
    \         = 1\n   So\n      nflda_multipath_ds_list[1] = { E }\n   and\n     \
    \ nfl_fh_list[1] = { 0x87 }\n   The client can thus write SU0 to { 0x87, { E }\
    \ }.\n   The destinations of the first 13 storage units are:\n               \
    \     | SUi | filehandle | data servers |\n                    | 0   | 87    \
    \     | E            |\n                    | 1   | 36         | A,B,C,D     \
    \ |\n                    | 2   | 67         | F,G          |\n               \
    \     | 3   | 36         | A,B,C,D      |\n                    | 4   | 87    \
    \     | E            |\n                    | 5   | 36         | A,B,C,D     \
    \ |\n                    | 6   | 67         | F,G          |\n               \
    \     | 7   | 36         | A,B,C,D      |\n                    | 8   | 87    \
    \     | E            |\n                    | 9   | 36         | A,B,C,D     \
    \ |\n                    | 10  | 67         | F,G          |\n               \
    \     | 11  | 36         | A,B,C,D      |\n                    | 12  | 87    \
    \     | E            |\n"
- title: 13.4.3.  Interpreting the File Layout Using Dense Packing
  contents:
  - "13.4.3.  Interpreting the File Layout Using Dense Packing\n   When dense packing\
    \ is used, the algorithm for determining the\n   filehandle and set of data server\
    \ network addresses to write stripe\n   unit i (SUi) to is:\n      stripe_count\
    \ = number of elements in nflda_stripe_indices;\n      j = (SUi + nfl_first_stripe_index)\
    \ % stripe_count;\n      idx = nflda_stripe_indices[j];\n      fh_count = number\
    \ of elements in nfl_fh_list;\n      ds_count = number of elements in nflda_multipath_ds_list;\n\
    \      switch (fh_count) {\n        case stripe_count:\n          fh = nfl_fh_list[j];\n\
    \          break;\n        default:\n          throw a fatal exception;\n    \
    \      break;\n      }\n      address_list = nflda_multipath_ds_list[idx];\n \
    \  The client would then select a data server from address_list, and\n   send\
    \ a READ or WRITE operation using the filehandle specified in fh.\n   Consider\
    \ the following example (which is the same as the sparse\n   packing example,\
    \ except for the filehandle list):\n   Suppose we have a device address consisting\
    \ of seven data servers,\n   arranged in three equivalence (Section 13.5) classes:\n\
    \      { A, B, C, D }, { E }, { F, G }\n   where A through G are network addresses.\n\
    \   Then\n      nflda_multipath_ds_list<> = { A, B, C, D }, { E }, { F, G }\n\
    \   i.e.,\n      nflda_multipath_ds_list[0] = { A, B, C, D }\n      nflda_multipath_ds_list[1]\
    \ = { E }\n      nflda_multipath_ds_list[2] = { F, G }\n   Suppose the striping\
    \ index array is:\n      nflda_stripe_indices<> = { 2, 0, 1, 0 }\n   Now suppose\
    \ the client gets a layout that has a device ID that maps\n   to the above device\
    \ address.  The initial index contains\n      nfl_first_stripe_index = 2,\n  \
    \ and\n      nfl_fh_list = { 0x67, 0x37, 0x87, 0x36 }.\n   The interesting examples\
    \ for dense packing are SU1 and SU3 because\n   each stripe unit refers to the\
    \ same data server list, yet each stripe\n   unit MUST use a different filehandle.\
    \  If the client wants to write\n   to SU1, the set of valid { network address,\
    \ filehandle } combinations\n   for SUi are determined by:\n      nfl_first_stripe_index\
    \ = 2\n   So\n      j = (1 + 2) % 4 = 3\n         idx = nflda_stripe_indices[j]\n\
    \         = nflda_stripe_indices[3]\n         = 0\n   So\n      nflda_multipath_ds_list[0]\
    \ = { A, B, C, D }\n   and\n      nfl_fh_list[3] = { 0x36 }\n   The client can\
    \ thus write SU1 to { 0x36, { A, B, C, D } }.\n   For SU3, j = (3 + 2) % 4 = 1,\
    \ and nflda_stripe_indices[1] = 0.  Then\n   nflda_multipath_ds_list[0] = { A,\
    \ B, C, D }, and nfl_fh_list[1] =\n   0x37.  The client can thus write SU3 to\
    \ { 0x37, { A, B, C, D } }.\n   The destinations of the first 13 storage units\
    \ are:\n                    | SUi | filehandle | data servers |\n            \
    \        | 0   | 87         | E            |\n                    | 1   | 36 \
    \        | A,B,C,D      |\n                    | 2   | 67         | F,G      \
    \    |\n                    | 3   | 37         | A,B,C,D      |\n            \
    \        | 4   | 87         | E            |\n                    | 5   | 36 \
    \        | A,B,C,D      |\n                    | 6   | 67         | F,G      \
    \    |\n                    | 7   | 37         | A,B,C,D      |\n            \
    \        | 8   | 87         | E            |\n                    | 9   | 36 \
    \        | A,B,C,D      |\n                    | 10  | 67         | F,G      \
    \    |\n                    | 11  | 37         | A,B,C,D      |\n            \
    \        | 12  | 87         | E            |\n"
- title: 13.4.4.  Sparse and Dense Stripe Unit Packing
  contents:
  - "13.4.4.  Sparse and Dense Stripe Unit Packing\n   The flag NFL4_UFLG_DENSE of\
    \ the nfl_util4 data type (field nflh_util\n   of the data type nfsv4_1_file_layouthint4\
    \ and field nfl_util of data\n   type nfsv4_1_file_layout_ds_addr4) specifies\
    \ how the data is packed\n   within the data file on a data server.  It allows\
    \ for two different\n   data packings: sparse and dense.  The packing type determines\
    \ the\n   calculation that will be made to map the client-visible file offset\n\
    \   to the offset within the data file located on the data server.\n   If nfl_util\
    \ & NFL4_UFLG_DENSE is zero, this means that sparse packing\n   is being used.\
    \  Hence, the logical offsets of the file as viewed by a\n   client sending READs\
    \ and WRITEs directly to the metadata server are\n   the same offsets each data\
    \ server uses when storing a stripe unit.\n   The effect then, for striping patterns\
    \ consisting of at least two\n   stripe units, is for each data server file to\
    \ be sparse or \"holey\".\n   So for example, suppose there is a pattern with\
    \ three stripe units,\n   the stripe unit size is 4096 bytes, and there are three\
    \ data servers\n   in the pattern.  Then, the file in data server 1 will have\
    \ stripe\n   units 0, 3, 6, 9, ... filled; data server 2's file will have stripe\n\
    \   units 1, 4, 7, 10, ... filled; and data server 3's file will have\n   stripe\
    \ units 2, 5, 8, 11, ... filled.  The unfilled stripe units of\n   each file will\
    \ be holes; hence, the files in each data server are\n   sparse.\n   If sparse\
    \ packing is being used and a client attempts I/O to one of\n   the holes, then\
    \ an error MUST be returned by the data server.  Using\n   the above example,\
    \ if data server 3 received a READ or WRITE\n   operation for block 4, the data\
    \ server would return\n   NFS4ERR_PNFS_IO_HOLE.  Thus, data servers need to understand\
    \ the\n   striping pattern in order to support sparse packing.\n   If nfl_util\
    \ & NFL4_UFLG_DENSE is one, this means that dense packing\n   is being used, and\
    \ the data server files have no holes.  Dense\n   packing might be selected because\
    \ the data server does not\n   (efficiently) support holey files or because the\
    \ data server cannot\n   recognize read-ahead unless there are no holes.  If dense\
    \ packing is\n   indicated in the layout, the data files will be packed.  Using\
    \ the\n   same striping pattern and stripe unit size that were used for the\n\
    \   sparse packing example, the corresponding dense packing example would\n  \
    \ have all stripe units of all data files filled as follows:\n   *  Logical stripe\
    \ units 0, 3, 6, ... of the file would live on stripe\n      units 0, 1, 2, ...\
    \ of the file of data server 1.\n   *  Logical stripe units 1, 4, 7, ... of the\
    \ file would live on stripe\n      units 0, 1, 2, ... of the file of data server\
    \ 2.\n   *  Logical stripe units 2, 5, 8, ... of the file would live on stripe\n\
    \      units 0, 1, 2, ... of the file of data server 3.\n   Because dense packing\
    \ does not leave holes on the data servers, the\n   pNFS client is allowed to\
    \ write to any offset of any data file of any\n   data server in the stripe. \
    \ Thus, the data servers need not know the\n   file's striping pattern.\n   The\
    \ calculation to determine the byte offset within the data file for\n   dense\
    \ data server layouts is:\n      stripe_width = stripe_unit_size * N;\n      \
    \   where N = number of elements in nflda_stripe_indices.\n      relative_offset\
    \ = file_offset - nfl_pattern_offset;\n      data_file_offset = floor(relative_offset\
    \ / stripe_width)\n         * stripe_unit_size\n         + relative_offset % stripe_unit_size\n\
    \   If dense packing is being used, and a data server appears more than\n   once\
    \ in a striping pattern, then to distinguish one stripe unit from\n   another,\
    \ the data server MUST use a different filehandle.  Let's\n   suppose there are\
    \ two data servers.  Logical stripe units 0, 3, 6 are\n   served by data server\
    \ 1; logical stripe units 1, 4, 7 are served by\n   data server 2; and logical\
    \ stripe units 2, 5, 8 are also served by\n   data server 2.  Unless data server\
    \ 2 has two filehandles (each\n   referring to a different data file), then, for\
    \ example, a write to\n   logical stripe unit 1 overwrites the write to logical\
    \ stripe unit 2\n   because both logical stripe units are located in the same\
    \ stripe unit\n   (0) of data server 2.\n"
- title: 13.5.  Data Server Multipathing
  contents:
  - "13.5.  Data Server Multipathing\n   The NFSv4.1 file layout supports multipathing\
    \ to multiple data server\n   addresses.  Data-server-level multipathing is used\
    \ for bandwidth\n   scaling via trunking (Section 2.10.5) and for higher availability\
    \ of\n   use in the case of a data-server failure.  Multipathing allows the\n\
    \   client to switch to another data server address which may be that of\n   another\
    \ data server that is exporting the same data stripe unit,\n   without having\
    \ to contact the metadata server for a new layout.\n   To support data server\
    \ multipathing, each element of the\n   nflda_multipath_ds_list contains an array\
    \ of one more data server\n   network addresses.  This array (data type multipath_list4)\
    \ represents\n   a list of data servers (each identified by a network address),\
    \ with\n   the possibility that some data servers will appear in the list\n  \
    \ multiple times.\n   The client is free to use any of the network addresses as\
    \ a\n   destination to send data server requests.  If some network addresses\n\
    \   are less optimal paths to the data than others, then the MDS SHOULD\n   NOT\
    \ include those network addresses in an element of\n   nflda_multipath_ds_list.\
    \  If less optimal network addresses exist to\n   provide failover, the RECOMMENDED\
    \ method to offer the addresses is to\n   provide them in a replacement device-ID-to-device-address\
    \ mapping, or\n   a replacement device ID.  When a client finds that no data server\
    \ in\n   an element of nflda_multipath_ds_list responds, it SHOULD send a\n  \
    \ GETDEVICEINFO to attempt to replace the existing device-ID-to-device-\n   address\
    \ mappings.  If the MDS detects that all data servers\n   represented by an element\
    \ of nflda_multipath_ds_list are unavailable,\n   the MDS SHOULD send a CB_NOTIFY_DEVICEID\
    \ (if the client has indicated\n   it wants device ID notifications for changed\
    \ device IDs) to change\n   the device-ID-to-device-address mappings to the available\
    \ data\n   servers.  If the device ID itself will be replaced, the MDS SHOULD\n\
    \   recall all layouts with the device ID, and thus force the client to\n   get\
    \ new layouts and device ID mappings via LAYOUTGET and\n   GETDEVICEINFO.\n  \
    \ Generally, if two network addresses appear in an element of\n   nflda_multipath_ds_list,\
    \ they will designate the same data server,\n   and the two data server addresses\
    \ will support the implementation of\n   client ID or session trunking (the latter\
    \ is RECOMMENDED) as defined\n   in Section 2.10.5.  The two data server addresses\
    \ will share the same\n   server owner or major ID of the server owner.  It is\
    \ not always\n   necessary for the two data server addresses to designate the\
    \ same\n   server with trunking being used.  For example, the data could be\n\
    \   read-only, and the data consist of exact replicas.\n"
- title: 13.6.  Operations Sent to NFSv4.1 Data Servers
  contents:
  - "13.6.  Operations Sent to NFSv4.1 Data Servers\n   Clients accessing data on\
    \ an NFSv4.1 data server MUST send only the\n   NULL procedure and COMPOUND procedures\
    \ whose operations are taken\n   only from two restricted subsets of the operations\
    \ defined as valid\n   NFSv4.1 operations.  Clients MUST use the filehandle specified\
    \ by the\n   layout when accessing data on NFSv4.1 data servers.\n   The first\
    \ of these operation subsets consists of management\n   operations.  This subset\
    \ consists of the BACKCHANNEL_CTL,\n   BIND_CONN_TO_SESSION, CREATE_SESSION, DESTROY_CLIENTID,\n\
    \   DESTROY_SESSION, EXCHANGE_ID, SECINFO_NO_NAME, SET_SSV, and SEQUENCE\n   operations.\
    \  The client may use these operations in order to set up\n   and maintain the\
    \ appropriate client IDs, sessions, and security\n   contexts involved in communication\
    \ with the data server.  Henceforth,\n   these will be referred to as data-server\
    \ housekeeping operations.\n   The second subset consists of COMMIT, READ, WRITE,\
    \ and PUTFH.  These\n   operations MUST be used with a current filehandle specified\
    \ by the\n   layout.  In the case of PUTFH, the new current filehandle MUST be\
    \ one\n   taken from the layout.  Henceforth, these will be referred to as\n \
    \  data-server I/O operations.  As described in Section 12.5.1, a client\n   MUST\
    \ NOT send an I/O to a data server for which it does not hold a\n   valid layout;\
    \ the data server MUST reject such an I/O.\n   Unless the server has a concurrent\
    \ non-data-server personality --\n   i.e., EXCHANGE_ID results returned (EXCHGID4_FLAG_USE_PNFS_DS\
    \ |\n   EXCHGID4_FLAG_USE_PNFS_MDS) or (EXCHGID4_FLAG_USE_PNFS_DS |\n   EXCHGID4_FLAG_USE_NON_PNFS)\
    \ see Section 13.1 -- any attempted use of\n   operations against a data server\
    \ other than those specified in the\n   two subsets above MUST return NFS4ERR_NOTSUPP\
    \ to the client.\n   When the server has concurrent data-server and non-data-server\n\
    \   personalities, each COMPOUND sent by the client MUST be constructed\n   so\
    \ that it is appropriate to one of the two personalities, and it\n   MUST NOT\
    \ contain operations directed to a mix of those personalities.\n   The server\
    \ MUST enforce this.  To understand the constraints,\n   operations within a COMPOUND\
    \ are divided into the following three\n   classes:\n   1.  An operation that\
    \ is ambiguous regarding its personality\n       assignment.  This includes all\
    \ of the data-server housekeeping\n       operations.  Additionally, if the server\
    \ has assigned filehandles\n       so that the ones defined by the layout are\
    \ the same as those used\n       by the metadata server, all operations using\
    \ such filehandles are\n       within this class, with the following exception.\
    \  The exception\n       is that if the operation uses a stateid that is incompatible\
    \ with\n       a data-server personality (e.g., a special stateid or the stateid\n\
    \       has a non-zero \"seqid\" field, see Section 13.9.1), the operation\n \
    \      is in class 3, as described below.  A COMPOUND containing\n       multiple\
    \ class 1 operations (and operations of no other class)\n       MAY be sent to\
    \ a server with multiple concurrent data server and\n       non-data-server personalities.\n\
    \   2.  An operation that is unambiguously referable to the data-server\n    \
    \   personality.  This includes data-server I/O operations where the\n       filehandle\
    \ is one that can only be validly directed to the data-\n       server personality.\n\
    \   3.  An operation that is unambiguously referable to the non-data-\n      \
    \ server personality.  This includes all COMPOUND operations that\n       are\
    \ neither data-server housekeeping nor data-server I/O\n       operations, plus\
    \ data-server I/O operations where the current fh\n       (or the one to be made\
    \ the current fh in the case of PUTFH) is\n       only valid on the metadata server\
    \ or where a stateid is used that\n       is incompatible with the data server,\
    \ i.e., is a special stateid\n       or has a non-zero seqid value.\n   When a\
    \ COMPOUND first executes an operation from class 3 above, it\n   acts as a normal\
    \ COMPOUND on any other server, and the data-server\n   personality ceases to\
    \ be relevant.  There are no special restrictions\n   on the operations in the\
    \ COMPOUND to limit them to those for a data\n   server.  When a PUTFH is done,\
    \ filehandles derived from the layout\n   are not valid.  If their format is not\
    \ normally acceptable, then\n   NFS4ERR_BADHANDLE MUST result.  Similarly, current\
    \ filehandles for\n   other operations do not accept filehandles derived from\
    \ layouts and\n   are not normally usable on the metadata server.  Using these\
    \ will\n   result in NFS4ERR_STALE.\n   When a COMPOUND first executes an operation\
    \ from class 2, which would\n   be PUTFH where the filehandle is one from a layout,\
    \ the COMPOUND\n   henceforth is interpreted with respect to the data-server\n\
    \   personality.  Operations outside the two classes discussed above MUST\n  \
    \ result in NFS4ERR_NOTSUPP.  Filehandles are validated using the rules\n   of\
    \ the data server, resulting in NFS4ERR_BADHANDLE and/or\n   NFS4ERR_STALE even\
    \ when they would not normally do so when addressed\n   to the non-data-server\
    \ personality.  Stateids must obey the rules of\n   the data server in that any\
    \ use of special stateids or stateids with\n   non-zero seqid values must result\
    \ in NFS4ERR_BAD_STATEID.\n   Until the server first executes an operation from\
    \ class 2 or class 3,\n   the client MUST NOT depend on the operation being executed\
    \ by either\n   the data-server or the non-data-server personality.  The server\
    \ MUST\n   pick one personality consistently for a given COMPOUND, with the only\n\
    \   possible transition being a single one when the first operation from\n   class\
    \ 2 or class 3 is executed.\n   Because of the complexity induced by assigning\
    \ filehandles so they\n   can be used on both a data server and a metadata server,\
    \ it is\n   RECOMMENDED that where the same server can have both personalities,\n\
    \   the server assign separate unique filehandles to both personalities.\n   This\
    \ makes it unambiguous for which server a given request is\n   intended.\n   GETATTR\
    \ and SETATTR MUST be directed to the metadata server.  In the\n   case of a SETATTR\
    \ of the size attribute, the control protocol is\n   responsible for propagating\
    \ size updates/truncations to the data\n   servers.  In the case of extending\
    \ WRITEs to the data servers, the\n   new size must be visible on the metadata\
    \ server once a LAYOUTCOMMIT\n   has completed (see Section 12.5.4.2).  Section\
    \ 13.10 describes the\n   mechanism by which the client is to handle data-server\
    \ files that do\n   not reflect the metadata server's size.\n"
- title: 13.7.  COMMIT through Metadata Server
  contents:
  - "13.7.  COMMIT through Metadata Server\n   The file layout provides two alternate\
    \ means of providing for the\n   commit of data written through data servers.\
    \  The flag\n   NFL4_UFLG_COMMIT_THRU_MDS in the field nfl_util of the file layout\n\
    \   (data type nfsv4_1_file_layout4) is an indication from the metadata\n   server\
    \ to the client of the REQUIRED way of performing COMMIT, either\n   by sending\
    \ the COMMIT to the data server or the metadata server.\n   These two methods\
    \ of dealing with the issue correspond to broad\n   styles of implementation for\
    \ a pNFS server supporting the file layout\n   type.\n   *  When the flag is FALSE,\
    \ COMMIT operations MUST to be sent to the\n      data server to which the corresponding\
    \ WRITE operations were sent.\n      This approach is sometimes useful when file\
    \ striping is\n      implemented within the pNFS server (instead of the file system),\n\
    \      with the individual data servers each implementing their own file\n   \
    \   systems.\n   *  When the flag is TRUE, COMMIT operations MUST be sent to the\n\
    \      metadata server, rather than to the individual data servers.  This\n  \
    \    approach is sometimes useful when file striping is implemented\n      within\
    \ the clustered file system that is the backend to the pNFS\n      server.  In\
    \ such an implementation, each COMMIT to each data\n      server might result\
    \ in repeated writes of metadata blocks to the\n      detriment of write performance.\
    \  Sending a single COMMIT to the\n      metadata server can be more efficient\
    \ when there exists a\n      clustered file system capable of implementing such\
    \ a coordinated\n      COMMIT.\n      If nfl_util & NFL4_UFLG_COMMIT_THRU_MDS\
    \ is TRUE, then in order to\n      maintain the current NFSv4.1 commit and recovery\
    \ model, the data\n      servers MUST return a common writeverf verifier in all\
    \ WRITE\n      responses for a given file layout, and the metadata server's\n\
    \      COMMIT implementation must return the same writeverf.  The value\n    \
    \  of the writeverf verifier MUST be changed at the metadata server\n      or\
    \ any data server that is referenced in the layout, whenever\n      there is a\
    \ server event that can possibly lead to loss of\n      uncommitted data.  The\
    \ scope of the verifier can be for a file or\n      for the entire pNFS server.\
    \  It might be more difficult for the\n      server to maintain the verifier at\
    \ the file level, but the benefit\n      is that only events that impact a given\
    \ file will require recovery\n      action.\n   Note that if the layout specified\
    \ dense packing, then the offset used\n   to a COMMIT to the MDS may differ than\
    \ that of an offset used to a\n   COMMIT to the data server.\n   The single COMMIT\
    \ to the metadata server will return a verifier, and\n   the client should compare\
    \ it to all the verifiers from the WRITEs and\n   fail the COMMIT if there are\
    \ any mismatched verifiers.  If COMMIT to\n   the metadata server fails, the client\
    \ should re-send WRITEs for all\n   the modified data in the file.  The client\
    \ should treat modified data\n   with a mismatched verifier as a WRITE failure\
    \ and try to recover by\n   resending the WRITEs to the original data server or\
    \ using another\n   path to that data if the layout has not been recalled.\n \
    \  Alternatively, the client can obtain a new layout or it could rewrite\n   the\
    \ data directly to the metadata server.  If nfl_util &\n   NFL4_UFLG_COMMIT_THRU_MDS\
    \ is FALSE, sending a COMMIT to the metadata\n   server might have no effect.\
    \  If nfl_util & NFL4_UFLG_COMMIT_THRU_MDS\n   is FALSE, a COMMIT sent to the\
    \ metadata server should be used only to\n   commit data that was written to the\
    \ metadata server.  See\n   Section 12.7.6 for recovery options.\n"
- title: 13.8.  The Layout Iomode
  contents:
  - "13.8.  The Layout Iomode\n   The layout iomode need not be used by the metadata\
    \ server when\n   servicing NFSv4.1 file-based layouts, although in some circumstances\n\
    \   it may be useful.  For example, if the server implementation supports\n  \
    \ reading from read-only replicas or mirrors, it would be useful for\n   the server\
    \ to return a layout enabling the client to do so.  As such,\n   the client SHOULD\
    \ set the iomode based on its intent to read or write\n   the data.  The client\
    \ may default to an iomode of LAYOUTIOMODE4_RW.\n   The iomode need not be checked\
    \ by the data servers when clients\n   perform I/O.  However, the data servers\
    \ SHOULD still validate that\n   the client holds a valid layout and return an\
    \ error if the client\n   does not.\n"
- title: 13.9.  Metadata and Data Server State Coordination
  contents:
  - '13.9.  Metadata and Data Server State Coordination

    '
- title: 13.9.1.  Global Stateid Requirements
  contents:
  - "13.9.1.  Global Stateid Requirements\n   When the client sends I/O to a data\
    \ server, the stateid used MUST NOT\n   be a layout stateid as returned by LAYOUTGET\
    \ or sent by\n   CB_LAYOUTRECALL.  Permitted stateids are based on one of the\n\
    \   following: an OPEN stateid (the stateid field of data type OPEN4resok\n  \
    \ as returned by OPEN), a delegation stateid (the stateid field of data\n   types\
    \ open_read_delegation4 and open_write_delegation4 as returned by\n   OPEN or\
    \ WANT_DELEGATION, or as sent by CB_PUSH_DELEG), or a stateid\n   returned by\
    \ the LOCK or LOCKU operations.  The stateid sent to the\n   data server MUST\
    \ be sent with the seqid set to zero, indicating the\n   most current version\
    \ of that stateid, rather than indicating a\n   specific non-zero seqid value.\
    \  In no case is the use of special\n   stateid values allowed.\n   The stateid\
    \ used for I/O MUST have the same effect and be subject to\n   the same validation\
    \ on a data server as it would if the I/O was being\n   performed on the metadata\
    \ server itself in the absence of pNFS.  This\n   has the implication that stateids\
    \ are globally valid on both the\n   metadata and data servers.  This requires\
    \ the metadata server to\n   propagate changes in LOCK and OPEN state to the data\
    \ servers, so that\n   the data servers can validate I/O accesses.  This is discussed\n\
    \   further in Section 13.9.2.  Depending on when stateids are\n   propagated,\
    \ the existence of a valid stateid on the data server may\n   act as proof of\
    \ a valid layout.\n   Clients performing I/O operations need to select an appropriate\n\
    \   stateid based on the locks (including opens and delegations) held by\n   the\
    \ client and the various types of state-owners sending the I/O\n   requests. \
    \ The rules for doing so when referencing data servers are\n   somewhat different\
    \ from those discussed in Section 8.2.5, which apply\n   when accessing metadata\
    \ servers.\n   The following rules, applied in order of decreasing priority, govern\n\
    \   the selection of the appropriate stateid:\n   *  If the client holds a delegation\
    \ for the file in question, the\n      delegation stateid should be used.\n  \
    \ *  Otherwise, there must be an OPEN stateid for the current open-\n      owner,\
    \ and that OPEN stateid for the open file in question is\n      used, unless mandatory\
    \ locking prevents that.  See below.\n   *  If the data server had previously\
    \ responded with NFS4ERR_LOCKED to\n      use of the OPEN stateid, then the client\
    \ should use the byte-range\n      lock stateid whenever one exists for that open\
    \ file with the\n      current lock-owner.\n   *  Special stateids should never\
    \ be used.  If they are used, the data\n      server MUST reject the I/O with\
    \ an NFS4ERR_BAD_STATEID error.\n"
- title: 13.9.2.  Data Server State Propagation
  contents:
  - "13.9.2.  Data Server State Propagation\n   Since the metadata server, which handles\
    \ byte-range lock and open-\n   mode state changes as well as ACLs, might not\
    \ be co-located with the\n   data servers where I/O accesses are validated, the\
    \ server\n   implementation MUST take care of propagating changes of this state\
    \ to\n   the data servers.  Once the propagation to the data servers is\n   complete,\
    \ the full effect of those changes MUST be in effect at the\n   data servers.\
    \  However, some state changes need not be propagated\n   immediately, although\
    \ all changes SHOULD be propagated promptly.\n   These state propagations have\
    \ an impact on the design of the control\n   protocol, even though the control\
    \ protocol is outside of the scope of\n   this specification.  Immediate propagation\
    \ refers to the synchronous\n   propagation of state from the metadata server\
    \ to the data server(s);\n   the propagation must be complete before returning\
    \ to the client.\n"
- title: 13.9.2.1.  Lock State Propagation
  contents:
  - "13.9.2.1.  Lock State Propagation\n   If the pNFS server supports mandatory byte-range\
    \ locking, any\n   mandatory byte-range locks on a file MUST be made effective\
    \ at the\n   data servers before the request that establishes them returns to\
    \ the\n   caller.  The effect MUST be the same as if the mandatory byte-range\n\
    \   lock state were synchronously propagated to the data servers, even\n   though\
    \ the details of the control protocol may avoid actual transfer\n   of the state\
    \ under certain circumstances.\n   On the other hand, since advisory byte-range\
    \ lock state is not used\n   for checking I/O accesses at the data servers, there\
    \ is no semantic\n   reason for propagating advisory byte-range lock state to\
    \ the data\n   servers.  Since updates to advisory locks neither confer nor remove\n\
    \   privileges, these changes need not be propagated immediately, and may\n  \
    \ not need to be propagated promptly.  The updates to advisory locks\n   need\
    \ only be propagated when the data server needs to resolve a\n   question about\
    \ a stateid.  In fact, if byte-range locking is not\n   mandatory (i.e., is advisory)\
    \ the clients are advised to avoid using\n   the byte-range lock-based stateids\
    \ for I/O.  The stateids returned by\n   OPEN are sufficient and eliminate overhead\
    \ for this kind of state\n   propagation.\n   If a client gets back an NFS4ERR_LOCKED\
    \ error from a data server,\n   this is an indication that mandatory byte-range\
    \ locking is in force.\n   The client recovers from this by getting a byte-range\
    \ lock that\n   covers the affected range and re-sends the I/O with the stateid\
    \ of\n   the byte-range lock.\n"
- title: 13.9.2.2.  Open and Deny Mode Validation
  contents:
  - "13.9.2.2.  Open and Deny Mode Validation\n   Open and deny mode validation MUST\
    \ be performed against the open and\n   deny mode(s) held by the data servers.\
    \  When access is reduced or a\n   deny mode made more restrictive (because of\
    \ CLOSE or OPEN_DOWNGRADE),\n   the data server MUST prevent any I/Os that would\
    \ be denied if\n   performed on the metadata server.  When access is expanded,\
    \ the data\n   server MUST make sure that no requests are subsequently rejected\n\
    \   because of open or deny issues that no longer apply, given the\n   previous\
    \ relaxation.\n"
- title: 13.9.2.3.  File Attributes
  contents:
  - "13.9.2.3.  File Attributes\n   Since the SETATTR operation has the ability to\
    \ modify state that is\n   visible on both the metadata and data servers (e.g.,\
    \ the size), care\n   must be taken to ensure that the resultant state across\
    \ the set of\n   data servers is consistent, especially when truncating or growing\
    \ the\n   file.\n   As described earlier, the LAYOUTCOMMIT operation is used to\
    \ ensure\n   that the metadata is synchronized with changes made to the data\n\
    \   servers.  For the NFSv4.1-based data storage protocol, it is\n   necessary\
    \ to re-synchronize state such as the size attribute, and the\n   setting of mtime/change/atime.\
    \  See Section 12.5.4 for a full\n   description of the semantics regarding LAYOUTCOMMIT\
    \ and attribute\n   synchronization.  It should be noted that by using an NFSv4.1-based\n\
    \   layout type, it is possible to synchronize this state before\n   LAYOUTCOMMIT\
    \ occurs.  For example, the control protocol can be used\n   to query the attributes\
    \ present on the data servers.\n   Any changes to file attributes that control\
    \ authorization or access\n   as reflected by ACCESS calls or READs and WRITEs\
    \ on the metadata\n   server, MUST be propagated to the data servers for enforcement\
    \ on\n   READ and WRITE I/O calls.  If the changes made on the metadata server\n\
    \   result in more restrictive access permissions for any user, those\n   changes\
    \ MUST be propagated to the data servers synchronously.\n   The OPEN operation\
    \ (Section 18.16.4) does not impose any requirement\n   that I/O operations on\
    \ an open file have the same credentials as the\n   OPEN itself (unless EXCHGID4_FLAG_BIND_PRINC_STATEID\
    \ is set when\n   EXCHANGE_ID creates the client ID), and so it requires the server's\n\
    \   READ and WRITE operations to perform appropriate access checking.\n   Changes\
    \ to ACLs also require new access checking by READ and WRITE on\n   the server.\
    \  The propagation of access-right changes due to changes\n   in ACLs may be asynchronous\
    \ only if the server implementation is able\n   to determine that the updated\
    \ ACL is not more restrictive for any\n   user specified in the old ACL.  Due\
    \ to the relative infrequency of\n   ACL updates, it is suggested that all changes\
    \ be propagated\n   synchronously.\n"
- title: 13.10.  Data Server Component File Size
  contents:
  - "13.10.  Data Server Component File Size\n   A potential problem exists when a\
    \ component data file on a particular\n   data server has grown past EOF; the\
    \ problem exists for both dense and\n   sparse layouts.  Imagine the following\
    \ scenario: a client creates a\n   new file (size == 0) and writes to byte 131072;\
    \ the client then seeks\n   to the beginning of the file and reads byte 100. \
    \ The client should\n   receive zeroes back as a result of the READ.  However,\
    \ if the\n   striping pattern directs the client to send the READ to a data server\n\
    \   other than the one that received the client's original WRITE, the\n   data\
    \ server servicing the READ may believe that the file's size is\n   still 0 bytes.\
    \  In that event, the data server's READ response will\n   contain zero bytes\
    \ and an indication of EOF.  The data server can\n   only return zeroes if it\
    \ knows that the file's size has been\n   extended.  This would require the immediate\
    \ propagation of the file's\n   size to all data servers, which is potentially\
    \ very costly.\n   Therefore, the client that has initiated the extension of the\
    \ file's\n   size MUST be prepared to deal with these EOF conditions.  When the\n\
    \   offset in the arguments to READ is less than the client's view of the\n  \
    \ file size, if the READ response indicates EOF and/or contains fewer\n   bytes\
    \ than requested, the client will interpret such a response as a\n   hole in the\
    \ file, and the NFS client will substitute zeroes for the\n   data.\n   The NFSv4.1\
    \ protocol only provides close-to-open file data cache\n   semantics; meaning\
    \ that when the file is closed, all modified data is\n   written to the server.\
    \  When a subsequent OPEN of the file is done,\n   the change attribute is inspected\
    \ for a difference from a cached\n   value for the change attribute.  For the\
    \ case above, this means that\n   a LAYOUTCOMMIT will be done at close (along\
    \ with the data WRITEs) and\n   will update the file's size and change attribute.\
    \  Access from\n   another client after that point will result in the appropriate\
    \ size\n   being returned.\n"
- title: 13.11.  Layout Revocation and Fencing
  contents:
  - "13.11.  Layout Revocation and Fencing\n   As described in Section 12.7, the layout-type-specific\
    \ storage\n   protocol is responsible for handling the effects of I/Os that started\n\
    \   before lease expiration and extend through lease expiration.  The\n   LAYOUT4_NFSV4_1_FILES\
    \ layout type can prevent all I/Os to data\n   servers from being executed after\
    \ lease expiration (this prevention\n   is called \"fencing\"), without relying\
    \ on a precise client lease timer\n   and without requiring data servers to maintain\
    \ lease timers.  The\n   LAYOUT4_NFSV4_1_FILES pNFS server has the flexibility\
    \ to revoke\n   individual layouts, and thus fence I/O on a per-file basis.\n\
    \   In addition to lease expiration, the reasons a layout can be revoked\n   include:\
    \ client fails to respond to a CB_LAYOUTRECALL, the metadata\n   server restarts,\
    \ or administrative intervention.  Regardless of the\n   reason, once a client's\
    \ layout has been revoked, the pNFS server MUST\n   prevent the client from sending\
    \ I/O for the affected file from and to\n   all data servers; in other words,\
    \ it MUST fence the client from the\n   affected file on the data servers.\n \
    \  Fencing works as follows.  As described in Section 13.1, in COMPOUND\n   procedure\
    \ requests to the data server, the data filehandle provided\n   by the PUTFH operation\
    \ and the stateid in the READ or WRITE operation\n   are used to ensure that the\
    \ client has a valid layout for the I/O\n   being performed; if it does not, the\
    \ I/O is rejected with\n   NFS4ERR_PNFS_NO_LAYOUT.  The server can simply check\
    \ the stateid and,\n   additionally, make the data filehandle stale if the layout\
    \ specified\n   a data filehandle that is different from the metadata server's\n\
    \   filehandle for the file (see the nfl_fh_list description in\n   Section 13.3).\n\
    \   Before the metadata server takes any action to revoke layout state\n   given\
    \ out by a previous instance, it must make sure that all layout\n   state from\
    \ that previous instance are invalidated at the data\n   servers.  This has the\
    \ following implications.\n   *  The metadata server must not restripe a file\
    \ until it has\n      contacted all of the data servers to invalidate the layouts\
    \ from\n      the previous instance.\n   *  The metadata server must not give\
    \ out mandatory locks that\n      conflict with layouts from the previous instance\
    \ without either\n      doing a specific layout invalidation (as it would have\
    \ to do\n      anyway) or doing a global data server invalidation.\n"
- title: 13.12.  Security Considerations for the File Layout Type
  contents:
  - "13.12.  Security Considerations for the File Layout Type\n   The NFSv4.1 file\
    \ layout type MUST adhere to the security\n   considerations outlined in Section\
    \ 12.9.  NFSv4.1 data servers MUST\n   make all of the required access checks\
    \ on each READ or WRITE I/O as\n   determined by the NFSv4.1 protocol.  If the\
    \ metadata server would\n   deny a READ or WRITE operation on a file due to its\
    \ ACL, mode\n   attribute, open access mode, open deny mode, mandatory byte-range\n\
    \   lock state, or any other attributes and state, the data server MUST\n   also\
    \ deny the READ or WRITE operation.  This impacts the control\n   protocol and\
    \ the propagation of state from the metadata server to the\n   data servers; see\
    \ Section 13.9.2 for more details.\n   The methods for authentication, integrity,\
    \ and privacy for data\n   servers based on the LAYOUT4_NFSV4_1_FILES layout type\
    \ are the same\n   as those used by metadata servers.  Metadata and data servers\
    \ use ONC\n   RPC security flavors to authenticate, and SECINFO and SECINFO_NO_NAME\n\
    \   to negotiate the security mechanism and services to be used.  Thus,\n   when\
    \ using the LAYOUT4_NFSV4_1_FILES layout type, the impact on the\n   RPC-based\
    \ security model due to pNFS (as alluded to in Sections 1.8.1\n   and 1.8.2.2)\
    \ is zero.\n   For a given file object, a metadata server MAY require different\n\
    \   security parameters (secinfo4 value) than the data server.  For a\n   given\
    \ file object with multiple data servers, the secinfo4 value\n   SHOULD be the\
    \ same across all data servers.  If the secinfo4 values\n   across a metadata\
    \ server and its data servers differ for a specific\n   file, the mapping of the\
    \ principal to the server's internal user\n   identifier MUST be the same in order\
    \ for the access-control checks\n   based on ACL, mode, open and deny mode, and\
    \ mandatory locking to be\n   consistent across on the pNFS server.\n   If an\
    \ NFSv4.1 implementation supports pNFS and supports NFSv4.1 file\n   layouts,\
    \ then the implementation MUST support the SECINFO_NO_NAME\n   operation on both\
    \ the metadata and data servers.\n"
- title: 14.  Internationalization
  contents:
  - "14.  Internationalization\n   The primary issue in which NFSv4.1 needs to deal\
    \ with\n   internationalization, or I18N, is with respect to file names and\n\
    \   other strings as used within the protocol.  The choice of string\n   representation\
    \ must allow reasonable name/string access to clients\n   that use various languages.\
    \  The UTF-8 encoding of the UCS (Universal\n   Multiple-Octet Coded Character\
    \ Set) as defined by ISO10646 [18]\n   allows for this type of access and follows\
    \ the policy described in\n   \"IETF Policy on Character Sets and Languages\"\
    , RFC 2277 [19].\n   RFC 3454 [16], otherwise known as \"stringprep\", documents\
    \ a framework\n   for using Unicode/UTF-8 in networking protocols so as \"to increase\n\
    \   the likelihood that string input and string comparison work in ways\n   that\
    \ make sense for typical users throughout the world\".  A protocol\n   must define\
    \ a profile of stringprep \"in order to fully specify the\n   processing options\"\
    .  The remainder of this section defines the\n   NFSv4.1 stringprep profiles.\
    \  Much of the terminology used for the\n   remainder of this section comes from\
    \ stringprep.\n   There are three UTF-8 string types defined for NFSv4.1: utf8str_cs,\n\
    \   utf8str_cis, and utf8str_mixed.  Separate profiles are defined for\n   each.\
    \  Each profile defines the following, as required by stringprep:\n   *  The intended\
    \ applicability of the profile.\n   *  The character repertoire that is the input\
    \ and output to\n      stringprep (which is Unicode 3.2 for the referenced version\
    \ of\n      stringprep).  However, NFSv4.1 implementations are not limited to\n\
    \      3.2.\n   *  The mapping tables from stringprep used (as described in Section\
    \ 3\n      of stringprep).\n   *  Any additional mapping tables specific to the\
    \ profile.\n   *  The Unicode normalization used, if any (as described in Section\
    \ 4\n      of stringprep).\n   *  The tables from the stringprep listing of characters\
    \ that are\n      prohibited as output (as described in Section 5 of stringprep).\n\
    \   *  The bidirectional string testing used, if any (as described in\n      Section\
    \ 6 of stringprep).\n   *  Any additional characters that are prohibited as output\
    \ specific\n      to the profile.\n   Stringprep discusses Unicode characters,\
    \ whereas NFSv4.1 renders\n   UTF-8 characters.  Since there is a one-to-one mapping\
    \ from UTF-8 to\n   Unicode, when the remainder of this document refers to Unicode,\
    \ the\n   reader should assume UTF-8.\n   Much of the text for the profiles comes\
    \ from RFC 3491 [20].\n"
- title: 14.1.  Stringprep Profile for the utf8str_cs Type
  contents:
  - "14.1.  Stringprep Profile for the utf8str_cs Type\n   Every use of the utf8str_cs\
    \ type definition in the NFSv4 protocol\n   specification follows the profile\
    \ named nfs4_cs_prep.\n"
- title: 14.1.1.  Intended Applicability of the nfs4_cs_prep Profile
  contents:
  - "14.1.1.  Intended Applicability of the nfs4_cs_prep Profile\n   The utf8str_cs\
    \ type is a case-sensitive string of UTF-8 characters.\n   Its primary use in\
    \ NFSv4.1 is for naming components and pathnames.\n   Components and pathnames\
    \ are stored on the server's file system.  Two\n   valid distinct UTF-8 strings\
    \ might be the same after processing via\n   the utf8str_cs profile.  If the strings\
    \ are two names inside a\n   directory, the NFSv4.1 server will need to either:\n\
    \   *  disallow the creation of a second name if its post-processed form\n   \
    \   collides with that of an existing name, or\n   *  allow the creation of the\
    \ second name, but arrange so that after\n      post-processing, the second name\
    \ is different than the post-\n      processed form of the first name.\n"
- title: 14.1.2.  Character Repertoire of nfs4_cs_prep
  contents:
  - "14.1.2.  Character Repertoire of nfs4_cs_prep\n   The nfs4_cs_prep profile uses\
    \ Unicode 3.2, as defined in stringprep's\n   Appendix A.1.  However, NFSv4.1\
    \ implementations are not limited to\n   3.2.\n"
- title: 14.1.3.  Mapping Used by nfs4_cs_prep
  contents:
  - "14.1.3.  Mapping Used by nfs4_cs_prep\n   The nfs4_cs_prep profile specifies\
    \ mapping using the following tables\n   from stringprep:\n      Table B.1\n \
    \  Table B.2 is normally not part of the nfs4_cs_prep profile as it is\n   primarily\
    \ for dealing with case-insensitive comparisons.  However, if\n   the NFSv4.1\
    \ file server supports the case_insensitive file system\n   attribute, and if\
    \ case_insensitive is TRUE, the NFSv4.1 server MUST\n   use Table B.2 (in addition\
    \ to Table B1) when processing utf8str_cs\n   strings, and the NFSv4.1 client\
    \ MUST assume Table B.2 (in addition to\n   Table B.1) is being used.\n   If the\
    \ case_preserving attribute is present and set to FALSE, then\n   the NFSv4.1\
    \ server MUST use Table B.2 to map case when processing\n   utf8str_cs strings.\
    \  Whether the server maps from lower to upper case\n   or from upper to lower\
    \ case is an implementation dependency.\n"
- title: 14.1.4.  Normalization used by nfs4_cs_prep
  contents:
  - "14.1.4.  Normalization used by nfs4_cs_prep\n   The nfs4_cs_prep profile does\
    \ not specify a normalization form.  A\n   later revision of this specification\
    \ may specify a particular\n   normalization form.  Therefore, the server and\
    \ client can expect that\n   they may receive unnormalized characters within protocol\
    \ requests and\n   responses.  If the operating environment requires normalization,\
    \ then\n   the implementation must normalize utf8str_cs strings within the\n \
    \  protocol before presenting the information to an application (at the\n   client)\
    \ or local file system (at the server).\n"
- title: 14.1.5.  Prohibited Output for nfs4_cs_prep
  contents:
  - "14.1.5.  Prohibited Output for nfs4_cs_prep\n   The nfs4_cs_prep profile RECOMMENDS\
    \ prohibiting the use of the\n   following tables from stringprep:\n      Table\
    \ C.5\n      Table C.6\n"
- title: 14.1.6.  Bidirectional Output for nfs4_cs_prep
  contents:
  - "14.1.6.  Bidirectional Output for nfs4_cs_prep\n   The nfs4_cs_prep profile does\
    \ not specify any checking of\n   bidirectional strings.\n"
- title: 14.2.  Stringprep Profile for the utf8str_cis Type
  contents:
  - "14.2.  Stringprep Profile for the utf8str_cis Type\n   Every use of the utf8str_cis\
    \ type definition in the NFSv4.1 protocol\n   specification follows the profile\
    \ named nfs4_cis_prep.\n"
- title: 14.2.1.  Intended Applicability of the nfs4_cis_prep Profile
  contents:
  - "14.2.1.  Intended Applicability of the nfs4_cis_prep Profile\n   The utf8str_cis\
    \ type is a case-insensitive string of UTF-8\n   characters.  Its primary use\
    \ in NFSv4.1 is for naming NFS servers.\n"
- title: 14.2.2.  Character Repertoire of nfs4_cis_prep
  contents:
  - "14.2.2.  Character Repertoire of nfs4_cis_prep\n   The nfs4_cis_prep profile\
    \ uses Unicode 3.2, as defined in\n   stringprep's Appendix A.1.  However, NFSv4.1\
    \ implementations are not\n   limited to 3.2.\n"
- title: 14.2.3.  Mapping Used by nfs4_cis_prep
  contents:
  - "14.2.3.  Mapping Used by nfs4_cis_prep\n   The nfs4_cis_prep profile specifies\
    \ mapping using the following\n   tables from stringprep:\n      Table B.1\n \
    \     Table B.2\n"
- title: 14.2.4.  Normalization Used by nfs4_cis_prep
  contents:
  - "14.2.4.  Normalization Used by nfs4_cis_prep\n   The nfs4_cis_prep profile specifies\
    \ using Unicode normalization form\n   KC, as described in stringprep.\n"
- title: 14.2.5.  Prohibited Output for nfs4_cis_prep
  contents:
  - "14.2.5.  Prohibited Output for nfs4_cis_prep\n   The nfs4_cis_prep profile specifies\
    \ prohibiting using the following\n   tables from stringprep:\n      Table C.1.2\n\
    \      Table C.2.2\n      Table C.3\n      Table C.4\n      Table C.5\n      Table\
    \ C.6\n      Table C.7\n      Table C.8\n      Table C.9\n"
- title: 14.2.6.  Bidirectional Output for nfs4_cis_prep
  contents:
  - "14.2.6.  Bidirectional Output for nfs4_cis_prep\n   The nfs4_cis_prep profile\
    \ specifies checking bidirectional strings as\n   described in stringprep's Section\
    \ 6.\n"
- title: 14.3.  Stringprep Profile for the utf8str_mixed Type
  contents:
  - "14.3.  Stringprep Profile for the utf8str_mixed Type\n   Every use of the utf8str_mixed\
    \ type definition in the NFSv4.1\n   protocol specification follows the profile\
    \ named nfs4_mixed_prep.\n"
- title: 14.3.1.  Intended Applicability of the nfs4_mixed_prep Profile
  contents:
  - "14.3.1.  Intended Applicability of the nfs4_mixed_prep Profile\n   The utf8str_mixed\
    \ type is a string of UTF-8 characters, with a prefix\n   that is case sensitive,\
    \ a separator equal to '@', and a suffix that\n   is a fully qualified domain\
    \ name.  Its primary use in NFSv4.1 is for\n   naming principals identified in\
    \ an Access Control Entry.\n"
- title: 14.3.2.  Character Repertoire of nfs4_mixed_prep
  contents:
  - "14.3.2.  Character Repertoire of nfs4_mixed_prep\n   The nfs4_mixed_prep profile\
    \ uses Unicode 3.2, as defined in\n   stringprep's Appendix A.1.  However, NFSv4.1\
    \ implementations are not\n   limited to 3.2.\n"
- title: 14.3.3.  Mapping Used by nfs4_cis_prep
  contents:
  - "14.3.3.  Mapping Used by nfs4_cis_prep\n   For the prefix and the separator of\
    \ a utf8str_mixed string, the\n   nfs4_mixed_prep profile specifies mapping using\
    \ the following table\n   from stringprep:\n      Table B.1\n   For the suffix\
    \ of a utf8str_mixed string, the nfs4_mixed_prep profile\n   specifies mapping\
    \ using the following tables from stringprep:\n      Table B.1\n      Table B.2\n"
- title: 14.3.4.  Normalization Used by nfs4_mixed_prep
  contents:
  - "14.3.4.  Normalization Used by nfs4_mixed_prep\n   The nfs4_mixed_prep profile\
    \ specifies using Unicode normalization\n   form KC, as described in stringprep.\n"
- title: 14.3.5.  Prohibited Output for nfs4_mixed_prep
  contents:
  - "14.3.5.  Prohibited Output for nfs4_mixed_prep\n   The nfs4_mixed_prep profile\
    \ specifies prohibiting using the following\n   tables from stringprep:\n    \
    \  Table C.1.2\n      Table C.2.2\n      Table C.3\n      Table C.4\n      Table\
    \ C.5\n      Table C.6\n      Table C.7\n      Table C.8\n      Table C.9\n"
- title: 14.3.6.  Bidirectional Output for nfs4_mixed_prep
  contents:
  - "14.3.6.  Bidirectional Output for nfs4_mixed_prep\n   The nfs4_mixed_prep profile\
    \ specifies checking bidirectional strings\n   as described in stringprep's Section\
    \ 6.\n"
- title: 14.4.  UTF-8 Capabilities
  contents:
  - "14.4.  UTF-8 Capabilities\n   const FSCHARSET_CAP4_CONTAINS_NON_UTF8  = 0x1;\n\
    \   const FSCHARSET_CAP4_ALLOWS_ONLY_UTF8   = 0x2;\n   typedef uint32_t      \
    \  fs_charset_cap4;\n   Because some operating environments and file systems do\
    \ not enforce\n   character set encodings, NFSv4.1 supports the fs_charset_cap\n\
    \   attribute (Section 5.8.2.11) that indicates to the client a file\n   system's\
    \ UTF-8 capabilities.  The attribute is an integer containing\n   a pair of flags.\
    \  The first flag is FSCHARSET_CAP4_CONTAINS_NON_UTF8,\n   which, if set to one,\
    \ tells the client that the file system contains\n   non-UTF-8 characters, and\
    \ the server will not convert non-UTF\n   characters to UTF-8 if the client reads\
    \ a symbolic link or directory,\n   neither will operations with component names\
    \ or pathnames in the\n   arguments convert the strings to UTF-8.  The second\
    \ flag is\n   FSCHARSET_CAP4_ALLOWS_ONLY_UTF8, which, if set to one, indicates\
    \ that\n   the server will accept (and generate) only UTF-8 characters on the\n\
    \   file system.  If FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 is set to one,\n   FSCHARSET_CAP4_CONTAINS_NON_UTF8\
    \ MUST be set to zero.\n   FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 SHOULD always be set\
    \ to one.\n"
- title: 14.5.  UTF-8 Related Errors
  contents:
  - "14.5.  UTF-8 Related Errors\n   Where the client sends an invalid UTF-8 string,\
    \ the server should\n   return NFS4ERR_INVAL (see Table 11).  This includes cases\
    \ in which\n   inappropriate prefixes are detected and where the count includes\n\
    \   trailing bytes that do not constitute a full UCS character.\n   Where the\
    \ client-supplied string is valid UTF-8 but contains\n   characters that are not\
    \ supported by the server as a value for that\n   string (e.g., names containing\
    \ characters outside of Unicode plane 0\n   on file systems that fail to support\
    \ such characters despite their\n   presence in the Unicode standard), the server\
    \ should return\n   NFS4ERR_BADCHAR.\n   Where a UTF-8 string is used as a file\
    \ name, and the file system\n   (while supporting all of the characters within\
    \ the name) does not\n   allow that particular name to be used, the server should\
    \ return the\n   error NFS4ERR_BADNAME (Table 11).  This includes situations in\
    \ which\n   the server file system imposes a normalization constraint on name\n\
    \   strings, but will also include such situations as file system\n   prohibitions\
    \ of \".\" and \"..\" as file names for certain operations,\n   and other such\
    \ constraints.\n"
- title: 15.  Error Values
  contents:
  - "15.  Error Values\n   NFS error numbers are assigned to failed operations within\
    \ a Compound\n   (COMPOUND or CB_COMPOUND) request.  A Compound request contains\
    \ a\n   number of NFS operations that have their results encoded in sequence\n\
    \   in a Compound reply.  The results of successful operations will\n   consist\
    \ of an NFS4_OK status followed by the encoded results of the\n   operation. \
    \ If an NFS operation fails, an error status will be\n   entered in the reply\
    \ and the Compound request will be terminated.\n"
- title: 15.1.  Error Definitions
  contents:
  - "15.1.  Error Definitions\n    | Error                             | Number |\
    \ Description       |\n    | NFS4_OK                           | 0      | Section\
    \ 15.1.3.1  |\n    | NFS4ERR_ACCESS                    | 13     | Section 15.1.6.1\
    \  |\n    | NFS4ERR_ATTRNOTSUPP               | 10032  | Section 15.1.15.1 |\n\
    \    | NFS4ERR_ADMIN_REVOKED             | 10047  | Section 15.1.5.1  |\n    |\
    \ NFS4ERR_BACK_CHAN_BUSY            | 10057  | Section 15.1.12.1 |\n    | NFS4ERR_BADCHAR\
    \                   | 10040  | Section 15.1.7.1  |\n    | NFS4ERR_BADHANDLE  \
    \               | 10001  | Section 15.1.2.1  |\n    | NFS4ERR_BADIOMODE      \
    \           | 10049  | Section 15.1.10.1 |\n    | NFS4ERR_BADLAYOUT          \
    \       | 10050  | Section 15.1.10.2 |\n    | NFS4ERR_BADNAME                \
    \   | 10041  | Section 15.1.7.2  |\n    | NFS4ERR_BADOWNER                  |\
    \ 10039  | Section 15.1.15.2 |\n    | NFS4ERR_BADSESSION                | 10052\
    \  | Section 15.1.11.1 |\n    | NFS4ERR_BADSLOT                   | 10053  | Section\
    \ 15.1.11.2 |\n    | NFS4ERR_BADTYPE                   | 10007  | Section 15.1.4.1\
    \  |\n    | NFS4ERR_BADXDR                    | 10036  | Section 15.1.1.1  |\n\
    \    | NFS4ERR_BAD_COOKIE                | 10003  | Section 15.1.1.2  |\n    |\
    \ NFS4ERR_BAD_HIGH_SLOT             | 10077  | Section 15.1.11.3 |\n    | NFS4ERR_BAD_RANGE\
    \                 | 10042  | Section 15.1.8.1  |\n    | NFS4ERR_BAD_SEQID    \
    \             | 10026  | Section 15.1.16.1 |\n    | NFS4ERR_BAD_SESSION_DIGEST\
    \        | 10051  | Section 15.1.12.2 |\n    | NFS4ERR_BAD_STATEID           \
    \    | 10025  | Section 15.1.5.2  |\n    | NFS4ERR_CB_PATH_DOWN              |\
    \ 10048  | Section 15.1.11.4 |\n    | NFS4ERR_CLID_INUSE                | 10017\
    \  | Section 15.1.13.2 |\n    | NFS4ERR_CLIENTID_BUSY             | 10074  | Section\
    \ 15.1.13.1 |\n    | NFS4ERR_COMPLETE_ALREADY          | 10054  | Section 15.1.9.1\
    \  |\n    | NFS4ERR_CONN_NOT_BOUND_TO_SESSION | 10055  | Section 15.1.11.6 |\n\
    \    | NFS4ERR_DEADLOCK                  | 10045  | Section 15.1.8.2  |\n    |\
    \ NFS4ERR_DEADSESSION               | 10078  | Section 15.1.11.5 |\n    | NFS4ERR_DELAY\
    \                     | 10008  | Section 15.1.1.3  |\n    | NFS4ERR_DELEG_ALREADY_WANTED\
    \      | 10056  | Section 15.1.14.1 |\n    | NFS4ERR_DELEG_REVOKED           \
    \  | 10087  | Section 15.1.5.3  |\n    | NFS4ERR_DENIED                    | 10010\
    \  | Section 15.1.8.3  |\n    | NFS4ERR_DIRDELEG_UNAVAIL          | 10084  | Section\
    \ 15.1.14.2 |\n    | NFS4ERR_DQUOT                     | 69     | Section 15.1.4.2\
    \  |\n    | NFS4ERR_ENCR_ALG_UNSUPP           | 10079  | Section 15.1.13.3 |\n\
    \    | NFS4ERR_EXIST                     | 17     | Section 15.1.4.3  |\n    |\
    \ NFS4ERR_EXPIRED                   | 10011  | Section 15.1.5.4  |\n    | NFS4ERR_FBIG\
    \                      | 27     | Section 15.1.4.4  |\n    | NFS4ERR_FHEXPIRED\
    \                 | 10014  | Section 15.1.2.2  |\n    | NFS4ERR_FILE_OPEN    \
    \             | 10046  | Section 15.1.4.5  |\n    | NFS4ERR_GRACE            \
    \         | 10013  | Section 15.1.9.2  |\n    | NFS4ERR_HASH_ALG_UNSUPP      \
    \     | 10072  | Section 15.1.13.4 |\n    | NFS4ERR_INVAL                    \
    \ | 22     | Section 15.1.1.4  |\n    | NFS4ERR_IO                        | 5\
    \      | Section 15.1.4.6  |\n    | NFS4ERR_ISDIR                     | 21   \
    \  | Section 15.1.2.3  |\n    | NFS4ERR_LAYOUTTRYLATER            | 10058  | Section\
    \ 15.1.10.3 |\n    | NFS4ERR_LAYOUTUNAVAILABLE         | 10059  | Section 15.1.10.4\
    \ |\n    | NFS4ERR_LEASE_MOVED               | 10031  | Section 15.1.16.2 |\n\
    \    | NFS4ERR_LOCKED                    | 10012  | Section 15.1.8.4  |\n    |\
    \ NFS4ERR_LOCKS_HELD                | 10037  | Section 15.1.8.5  |\n    | NFS4ERR_LOCK_NOTSUPP\
    \              | 10043  | Section 15.1.8.6  |\n    | NFS4ERR_LOCK_RANGE      \
    \          | 10028  | Section 15.1.8.7  |\n    | NFS4ERR_MINOR_VERS_MISMATCH \
    \      | 10021  | Section 15.1.3.2  |\n    | NFS4ERR_MLINK                   \
    \  | 31     | Section 15.1.4.7  |\n    | NFS4ERR_MOVED                     | 10019\
    \  | Section 15.1.2.4  |\n    | NFS4ERR_NAMETOOLONG               | 63     | Section\
    \ 15.1.7.3  |\n    | NFS4ERR_NOENT                     | 2      | Section 15.1.4.8\
    \  |\n    | NFS4ERR_NOFILEHANDLE              | 10020  | Section 15.1.2.5  |\n\
    \    | NFS4ERR_NOMATCHING_LAYOUT         | 10060  | Section 15.1.10.5 |\n    |\
    \ NFS4ERR_NOSPC                     | 28     | Section 15.1.4.9  |\n    | NFS4ERR_NOTDIR\
    \                    | 20     | Section 15.1.2.6  |\n    | NFS4ERR_NOTEMPTY  \
    \                | 66     | Section 15.1.4.10 |\n    | NFS4ERR_NOTSUPP       \
    \            | 10004  | Section 15.1.1.5  |\n    | NFS4ERR_NOT_ONLY_OP       \
    \        | 10081  | Section 15.1.3.3  |\n    | NFS4ERR_NOT_SAME              \
    \    | 10027  | Section 15.1.15.3 |\n    | NFS4ERR_NO_GRACE                  |\
    \ 10033  | Section 15.1.9.3  |\n    | NFS4ERR_NXIO                      | 6  \
    \    | Section 15.1.16.3 |\n    | NFS4ERR_OLD_STATEID               | 10024  |\
    \ Section 15.1.5.5  |\n    | NFS4ERR_OPENMODE                  | 10038  | Section\
    \ 15.1.8.8  |\n    | NFS4ERR_OP_ILLEGAL                | 10044  | Section 15.1.3.4\
    \  |\n    | NFS4ERR_OP_NOT_IN_SESSION         | 10071  | Section 15.1.3.5  |\n\
    \    | NFS4ERR_PERM                      | 1      | Section 15.1.6.2  |\n    |\
    \ NFS4ERR_PNFS_IO_HOLE              | 10075  | Section 15.1.10.6 |\n    | NFS4ERR_PNFS_NO_LAYOUT\
    \            | 10080  | Section 15.1.10.7 |\n    | NFS4ERR_RECALLCONFLICT    \
    \        | 10061  | Section 15.1.14.3 |\n    | NFS4ERR_RECLAIM_BAD           \
    \    | 10034  | Section 15.1.9.4  |\n    | NFS4ERR_RECLAIM_CONFLICT          |\
    \ 10035  | Section 15.1.9.5  |\n    | NFS4ERR_REJECT_DELEG              | 10085\
    \  | Section 15.1.14.4 |\n    | NFS4ERR_REP_TOO_BIG               | 10066  | Section\
    \ 15.1.3.6  |\n    | NFS4ERR_REP_TOO_BIG_TO_CACHE      | 10067  | Section 15.1.3.7\
    \  |\n    | NFS4ERR_REQ_TOO_BIG               | 10065  | Section 15.1.3.8  |\n\
    \    | NFS4ERR_RESTOREFH                 | 10030  | Section 15.1.16.4 |\n    |\
    \ NFS4ERR_RETRY_UNCACHED_REP        | 10068  | Section 15.1.3.9  |\n    | NFS4ERR_RETURNCONFLICT\
    \            | 10086  | Section 15.1.10.8 |\n    | NFS4ERR_ROFS              \
    \        | 30     | Section 15.1.4.11 |\n    | NFS4ERR_SAME                  \
    \    | 10009  | Section 15.1.15.4 |\n    | NFS4ERR_SHARE_DENIED              |\
    \ 10015  | Section 15.1.8.9  |\n    | NFS4ERR_SEQUENCE_POS              | 10064\
    \  | Section 15.1.3.10 |\n    | NFS4ERR_SEQ_FALSE_RETRY           | 10076  | Section\
    \ 15.1.11.7 |\n    | NFS4ERR_SEQ_MISORDERED            | 10063  | Section 15.1.11.8\
    \ |\n    | NFS4ERR_SERVERFAULT               | 10006  | Section 15.1.1.6  |\n\
    \    | NFS4ERR_STALE                     | 70     | Section 15.1.2.7  |\n    |\
    \ NFS4ERR_STALE_CLIENTID            | 10022  | Section 15.1.13.5 |\n    | NFS4ERR_STALE_STATEID\
    \             | 10023  | Section 15.1.16.5 |\n    | NFS4ERR_SYMLINK          \
    \         | 10029  | Section 15.1.2.8  |\n    | NFS4ERR_TOOSMALL             \
    \     | 10005  | Section 15.1.1.7  |\n    | NFS4ERR_TOO_MANY_OPS             \
    \ | 10070  | Section 15.1.3.11 |\n    | NFS4ERR_UNKNOWN_LAYOUTTYPE        | 10062\
    \  | Section 15.1.10.9 |\n    | NFS4ERR_UNSAFE_COMPOUND           | 10069  | Section\
    \ 15.1.3.12 |\n    | NFS4ERR_WRONGSEC                  | 10016  | Section 15.1.6.3\
    \  |\n    | NFS4ERR_WRONG_CRED                | 10082  | Section 15.1.6.4  |\n\
    \    | NFS4ERR_WRONG_TYPE                | 10083  | Section 15.1.2.9  |\n    |\
    \ NFS4ERR_XDEV                      | 18     | Section 15.1.4.12 |\n         \
    \          Table 11: Protocol Error Definitions\n"
- title: 15.1.1.  General Errors
  contents:
  - "15.1.1.  General Errors\n   This section deals with errors that are applicable\
    \ to a broad set of\n   different purposes.\n"
- title: 15.1.1.1.  NFS4ERR_BADXDR (Error Code 10036)
  contents:
  - "15.1.1.1.  NFS4ERR_BADXDR (Error Code 10036)\n   The arguments for this operation\
    \ do not match those specified in the\n   XDR definition.  This includes situations\
    \ in which the request ends\n   before all the arguments have been seen.  Note\
    \ that this error\n   applies when fixed enumerations (these include booleans)\
    \ have a value\n   within the input stream that is not valid for the enum.  A\
    \ replier\n   may pre-parse all operations for a Compound procedure before doing\n\
    \   any operation execution and return RPC-level XDR errors in that case.\n"
- title: 15.1.1.2.  NFS4ERR_BAD_COOKIE (Error Code 10003)
  contents:
  - "15.1.1.2.  NFS4ERR_BAD_COOKIE (Error Code 10003)\n   Used for operations that\
    \ provide a set of information indexed by some\n   quantity provided by the client\
    \ or cookie sent by the server for an\n   earlier invocation.  Where the value\
    \ cannot be used for its intended\n   purpose, this error results.\n"
- title: 15.1.1.3.  NFS4ERR_DELAY (Error Code 10008)
  contents:
  - "15.1.1.3.  NFS4ERR_DELAY (Error Code 10008)\n   For any of a number of reasons,\
    \ the replier could not process this\n   operation in what was deemed a reasonable\
    \ time.  The client should\n   wait and then try the request with a new slot and\
    \ sequence value.\n   Some examples of scenarios that might lead to this situation:\n\
    \   *  A server that supports hierarchical storage receives a request to\n   \
    \   process a file that had been migrated.\n   *  An operation requires a delegation\
    \ recall to proceed, but the need\n      to wait for this delegation to be recalled\
    \ and returned makes\n      processing this request in a timely fashion impossible.\n\
    \   *  A request is being performed on a session being migrated from\n      another\
    \ server as described in Section 11.14.3, and the lack of\n      full information\
    \ about the state of the session on the source\n      makes it impossible to process\
    \ the request immediately.\n   In such cases, returning the error NFS4ERR_DELAY\
    \ allows necessary\n   preparatory operations to proceed without holding up requester\n\
    \   resources such as a session slot.  After delaying for period of time,\n  \
    \ the client can then re-send the operation in question, often as part\n   of\
    \ a nearly identical request.  Because of the need to avoid spurious\n   reissues\
    \ of non-idempotent operations and to avoid acting in response\n   to NFS4ERR_DELAY\
    \ errors returned on responses returned from the\n   replier's reply cache, integration\
    \ with the session-provided reply\n   cache is necessary.  There are a number\
    \ of cases to deal with, each\n   of which requires different sorts of handling\
    \ by the requester and\n   replier:\n   *  If NFS4ERR_DELAY is returned on a SEQUENCE\
    \ operation, the request\n      is retried in full with the SEQUENCE operation\
    \ containing the same\n      slot and sequence values.  In this case, the replier\
    \ MUST avoid\n      returning a response containing NFS4ERR_DELAY as the response\
    \ to\n      SEQUENCE solely because an earlier instance of the same request\n\
    \      returned that error and it was stored in the reply cache.  If the\n   \
    \   replier did this, the retries would not be effective as there\n      would\
    \ be no opportunity for the replier to see whether the\n      condition that generated\
    \ the NFS4ERR_DELAY had been rectified\n      during the interim between the original\
    \ request and the retry.\n   *  If NFS4ERR_DELAY is returned on an operation other\
    \ than SEQUENCE\n      that validly appears as the first operation of a request,\
    \ the\n      handling is similar.  The request can be retried in full without\n\
    \      modification.  In this case as well, the replier MUST avoid\n      returning\
    \ a response containing NFS4ERR_DELAY as the response to\n      an initial operation\
    \ of a request solely on the basis of its\n      presence in the reply cache.\
    \  If the replier did this, the retries\n      would not be effective as there\
    \ would be no opportunity for the\n      replier to see whether the condition\
    \ that generated the\n      NFS4ERR_DELAY had been rectified during the interim\
    \ between the\n      original request and the retry.\n   *  If NFS4ERR_DELAY is\
    \ returned on an operation other than the first\n      in the request, the request\
    \ when retried MUST contain a SEQUENCE\n      operation that is different than\
    \ the original one, with either the\n      slot ID or the sequence value different\
    \ from that in the original\n      request.  Because requesters do this, there\
    \ is no need for the\n      replier to take special care to avoid returning an\
    \ NFS4ERR_DELAY\n      error obtained from the reply cache.  When no non-idempotent\n\
    \      operations have been processed before the NFS4ERR_DELAY was\n      returned,\
    \ the requester should retry the request in full, with the\n      only difference\
    \ from the original request being the modification\n      to the slot ID or sequence\
    \ value in the reissued SEQUENCE\n      operation.\n   *  When NFS4ERR_DELAY is\
    \ returned on an operation other than the\n      first within a request and there\
    \ has been a non-idempotent\n      operation processed before the NFS4ERR_DELAY\
    \ was returned,\n      reissuing the request as is normally done would incorrectly\
    \ cause\n      the re-execution of the non-idempotent operation.\n      To avoid\
    \ this situation, the client should reissue the request\n      without the non-idempotent\
    \ operation.  The request still must use\n      a SEQUENCE operation with either\
    \ a different slot ID or sequence\n      value from the SEQUENCE in the original\
    \ request.  Because this is\n      done, there is no way the replier could avoid\
    \ spuriously re-\n      executing the non-idempotent operation since the different\n\
    \      SEQUENCE parameters prevent the requester from recognizing that\n     \
    \ the non-idempotent operation is being retried.\n   Note that without the ability\
    \ to return NFS4ERR_DELAY and the\n   requester's willingness to re-send when\
    \ receiving it, deadlock might\n   result.  For example, if a recall is done,\
    \ and if the delegation\n   return or operations preparatory to delegation return\
    \ are held up by\n   other operations that need the delegation to be returned,\
    \ session\n   slots might not be available.  The result could be deadlock.\n"
- title: 15.1.1.4.  NFS4ERR_INVAL (Error Code 22)
  contents:
  - "15.1.1.4.  NFS4ERR_INVAL (Error Code 22)\n   The arguments for this operation\
    \ are not valid for some reason, even\n   though they do match those specified\
    \ in the XDR definition for the\n   request.\n"
- title: 15.1.1.5.  NFS4ERR_NOTSUPP (Error Code 10004)
  contents:
  - "15.1.1.5.  NFS4ERR_NOTSUPP (Error Code 10004)\n   Operation not supported, either\
    \ because the operation is an OPTIONAL\n   one and is not supported by this server\
    \ or because the operation MUST\n   NOT be implemented in the current minor version.\n"
- title: 15.1.1.6.  NFS4ERR_SERVERFAULT (Error Code 10006)
  contents:
  - "15.1.1.6.  NFS4ERR_SERVERFAULT (Error Code 10006)\n   An error occurred on the\
    \ server that does not map to any of the\n   specific legal NFSv4.1 protocol error\
    \ values.  The client should\n   translate this into an appropriate error.  UNIX\
    \ clients may choose to\n   translate this to EIO.\n"
- title: 15.1.1.7.  NFS4ERR_TOOSMALL (Error Code 10005)
  contents:
  - "15.1.1.7.  NFS4ERR_TOOSMALL (Error Code 10005)\n   Used where an operation returns\
    \ a variable amount of data, with a\n   limit specified by the client.  Where\
    \ the data returned cannot be fit\n   within the limit specified by the client,\
    \ this error results.\n"
- title: 15.1.2.  Filehandle Errors
  contents:
  - "15.1.2.  Filehandle Errors\n   These errors deal with the situation in which\
    \ the current or saved\n   filehandle, or the filehandle passed to PUTFH intended\
    \ to become the\n   current filehandle, is invalid in some way.  This includes\
    \ situations\n   in which the filehandle is a valid filehandle in general but\
    \ is not\n   of the appropriate object type for the current operation.\n   Where\
    \ the error description indicates a problem with the current or\n   saved filehandle,\
    \ it is to be understood that filehandles are only\n   checked for the condition\
    \ if they are implicit arguments of the\n   operation in question.\n"
- title: 15.1.2.1.  NFS4ERR_BADHANDLE (Error Code 10001)
  contents:
  - "15.1.2.1.  NFS4ERR_BADHANDLE (Error Code 10001)\n   Illegal NFS filehandle for\
    \ the current server.  The current\n   filehandle failed internal consistency\
    \ checks.  Once accepted as\n   valid (by PUTFH), no subsequent status change\
    \ can cause the\n   filehandle to generate this error.\n"
- title: 15.1.2.2.  NFS4ERR_FHEXPIRED (Error Code 10014)
  contents:
  - "15.1.2.2.  NFS4ERR_FHEXPIRED (Error Code 10014)\n   A current or saved filehandle\
    \ that is an argument to the current\n   operation is volatile and has expired\
    \ at the server.\n"
- title: 15.1.2.3.  NFS4ERR_ISDIR (Error Code 21)
  contents:
  - "15.1.2.3.  NFS4ERR_ISDIR (Error Code 21)\n   The current or saved filehandle\
    \ designates a directory when the\n   current operation does not allow a directory\
    \ to be accepted as the\n   target of this operation.\n"
- title: 15.1.2.4.  NFS4ERR_MOVED (Error Code 10019)
  contents:
  - "15.1.2.4.  NFS4ERR_MOVED (Error Code 10019)\n   The file system that contains\
    \ the current filehandle object is not\n   present at the server or is not accessible\
    \ with the network address\n   used.  It may have been made accessible on a different\
    \ set of network\n   addresses, relocated or migrated to another server, or it\
    \ may have\n   never been present.  The client may obtain the new file system\n\
    \   location by obtaining the fs_locations or fs_locations_info attribute\n  \
    \ for the current filehandle.  For further discussion, refer to\n   Section 11.3.\n\
    \   As with the case of NFS4ERR_DELAY, it is possible that one or more\n   non-idempotent\
    \ operations may have been successfully executed within\n   a COMPOUND before\
    \ NFS4ERR_MOVED is returned.  Because of this, once\n   the new location is determined,\
    \ the original request that received\n   the NFS4ERR_MOVED should not be re-executed\
    \ in full.  Instead, the\n   client should send a new COMPOUND with any successfully\
    \ executed non-\n   idempotent operations removed.  When the client uses the same\
    \ session\n   for the new COMPOUND, its SEQUENCE operation should use a different\n\
    \   slot ID or sequence.\n"
- title: 15.1.2.5.  NFS4ERR_NOFILEHANDLE (Error Code 10020)
  contents:
  - "15.1.2.5.  NFS4ERR_NOFILEHANDLE (Error Code 10020)\n   The logical current or\
    \ saved filehandle value is required by the\n   current operation and is not set.\
    \  This may be a result of a\n   malformed COMPOUND operation (i.e., no PUTFH\
    \ or PUTROOTFH before an\n   operation that requires the current filehandle be\
    \ set).\n"
- title: 15.1.2.6.  NFS4ERR_NOTDIR (Error Code 20)
  contents:
  - "15.1.2.6.  NFS4ERR_NOTDIR (Error Code 20)\n   The current (or saved) filehandle\
    \ designates an object that is not a\n   directory for an operation in which a\
    \ directory is required.\n"
- title: 15.1.2.7.  NFS4ERR_STALE (Error Code 70)
  contents:
  - "15.1.2.7.  NFS4ERR_STALE (Error Code 70)\n   The current or saved filehandle\
    \ value designating an argument to the\n   current operation is invalid.  The\
    \ file referred to by that\n   filehandle no longer exists or access to it has\
    \ been revoked.\n"
- title: 15.1.2.8.  NFS4ERR_SYMLINK (Error Code 10029)
  contents:
  - "15.1.2.8.  NFS4ERR_SYMLINK (Error Code 10029)\n   The current filehandle designates\
    \ a symbolic link when the current\n   operation does not allow a symbolic link\
    \ as the target.\n"
- title: 15.1.2.9.  NFS4ERR_WRONG_TYPE (Error Code 10083)
  contents:
  - "15.1.2.9.  NFS4ERR_WRONG_TYPE (Error Code 10083)\n   The current (or saved) filehandle\
    \ designates an object that is of an\n   invalid type for the current operation,\
    \ and there is no more specific\n   error (such as NFS4ERR_ISDIR or NFS4ERR_SYMLINK)\
    \ that applies.  Note\n   that in NFSv4.0, such situations generally resulted\
    \ in the less-\n   specific error NFS4ERR_INVAL.\n"
- title: 15.1.3.  Compound Structure Errors
  contents:
  - "15.1.3.  Compound Structure Errors\n   This section deals with errors that relate\
    \ to the overall structure\n   of a Compound request (by which we mean to include\
    \ both COMPOUND and\n   CB_COMPOUND), rather than to particular operations.\n\
    \   There are a number of basic constraints on the operations that may\n   appear\
    \ in a Compound request.  Sessions add to these basic\n   constraints by requiring\
    \ a Sequence operation (either SEQUENCE or\n   CB_SEQUENCE) at the start of the\
    \ Compound.\n"
- title: 15.1.3.1.  NFS_OK (Error code 0)
  contents:
  - "15.1.3.1.  NFS_OK (Error code 0)\n   Indicates the operation completed successfully,\
    \ in that all of the\n   constituent operations completed without error.\n"
- title: 15.1.3.2.  NFS4ERR_MINOR_VERS_MISMATCH (Error code 10021)
  contents:
  - "15.1.3.2.  NFS4ERR_MINOR_VERS_MISMATCH (Error code 10021)\n   The minor version\
    \ specified is not one that the current listener\n   supports.  This value is\
    \ returned in the overall status for the\n   Compound but is not associated with\
    \ a specific operation since the\n   results will specify a result count of zero.\n"
- title: 15.1.3.3.  NFS4ERR_NOT_ONLY_OP (Error Code 10081)
  contents:
  - "15.1.3.3.  NFS4ERR_NOT_ONLY_OP (Error Code 10081)\n   Certain operations, which\
    \ are allowed to be executed outside of a\n   session, MUST be the only operation\
    \ within a Compound whenever the\n   Compound does not start with a Sequence operation.\
    \  This error\n   results when that constraint is not met.\n"
- title: 15.1.3.4.  NFS4ERR_OP_ILLEGAL (Error Code 10044)
  contents:
  - "15.1.3.4.  NFS4ERR_OP_ILLEGAL (Error Code 10044)\n   The operation code is not\
    \ a valid one for the current Compound\n   procedure.  The opcode in the result\
    \ stream matched with this error\n   is the ILLEGAL value, although the value\
    \ that appears in the request\n   stream may be different.  Where an illegal value\
    \ appears and the\n   replier pre-parses all operations for a Compound procedure\
    \ before\n   doing any operation execution, an RPC-level XDR error may be\n  \
    \ returned.\n"
- title: 15.1.3.5.  NFS4ERR_OP_NOT_IN_SESSION (Error Code 10071)
  contents:
  - "15.1.3.5.  NFS4ERR_OP_NOT_IN_SESSION (Error Code 10071)\n   Most forward operations\
    \ and all callback operations are only valid\n   within the context of a session,\
    \ so that the Compound request in\n   question MUST begin with a Sequence operation.\
    \  If an attempt is made\n   to execute these operations outside the context of\
    \ session, this\n   error results.\n"
- title: 15.1.3.6.  NFS4ERR_REP_TOO_BIG (Error Code 10066)
  contents:
  - "15.1.3.6.  NFS4ERR_REP_TOO_BIG (Error Code 10066)\n   The reply to a Compound\
    \ would exceed the channel's negotiated maximum\n   response size.\n"
- title: 15.1.3.7.  NFS4ERR_REP_TOO_BIG_TO_CACHE (Error Code 10067)
  contents:
  - "15.1.3.7.  NFS4ERR_REP_TOO_BIG_TO_CACHE (Error Code 10067)\n   The reply to a\
    \ Compound would exceed the channel's negotiated maximum\n   size for replies\
    \ cached in the reply cache when the Sequence for the\n   current request specifies\
    \ that this request is to be cached.\n"
- title: 15.1.3.8.  NFS4ERR_REQ_TOO_BIG (Error Code 10065)
  contents:
  - "15.1.3.8.  NFS4ERR_REQ_TOO_BIG (Error Code 10065)\n   The Compound request exceeds\
    \ the channel's negotiated maximum size\n   for requests.\n"
- title: 15.1.3.9.  NFS4ERR_RETRY_UNCACHED_REP (Error Code 10068)
  contents:
  - "15.1.3.9.  NFS4ERR_RETRY_UNCACHED_REP (Error Code 10068)\n   The requester has\
    \ attempted a retry of a Compound that it previously\n   requested not be placed\
    \ in the reply cache.\n"
- title: 15.1.3.10.  NFS4ERR_SEQUENCE_POS (Error Code 10064)
  contents:
  - "15.1.3.10.  NFS4ERR_SEQUENCE_POS (Error Code 10064)\n   A Sequence operation\
    \ appeared in a position other than the first\n   operation of a Compound request.\n"
- title: 15.1.3.11.  NFS4ERR_TOO_MANY_OPS (Error Code 10070)
  contents:
  - "15.1.3.11.  NFS4ERR_TOO_MANY_OPS (Error Code 10070)\n   The Compound request\
    \ has too many operations, exceeding the count\n   negotiated when the session\
    \ was created.\n"
- title: 15.1.3.12.  NFS4ERR_UNSAFE_COMPOUND (Error Code 10068)
  contents:
  - "15.1.3.12.  NFS4ERR_UNSAFE_COMPOUND (Error Code 10068)\n   The client has sent\
    \ a COMPOUND request with an unsafe mix of\n   operations -- specifically, with\
    \ a non-idempotent operation that\n   changes the current filehandle and that\
    \ is not followed by a GETFH.\n"
- title: 15.1.4.  File System Errors
  contents:
  - "15.1.4.  File System Errors\n   These errors describe situations that occurred\
    \ in the underlying file\n   system implementation rather than in the protocol\
    \ or any NFSv4.x\n   feature.\n"
- title: 15.1.4.1.  NFS4ERR_BADTYPE (Error Code 10007)
  contents:
  - "15.1.4.1.  NFS4ERR_BADTYPE (Error Code 10007)\n   An attempt was made to create\
    \ an object with an inappropriate type\n   specified to CREATE.  This may be because\
    \ the type is undefined,\n   because the type is not supported by the server,\
    \ or because the type\n   is not intended to be created by CREATE (such as a regular\
    \ file or\n   named attribute, for which OPEN is used to do the file creation).\n"
- title: 15.1.4.2.  NFS4ERR_DQUOT (Error Code 69)
  contents:
  - "15.1.4.2.  NFS4ERR_DQUOT (Error Code 69)\n   Resource (quota) hard limit exceeded.\
    \  The user's resource limit on\n   the server has been exceeded.\n"
- title: 15.1.4.3.  NFS4ERR_EXIST (Error Code 17)
  contents:
  - "15.1.4.3.  NFS4ERR_EXIST (Error Code 17)\n   A file of the specified target name\
    \ (when creating, renaming, or\n   linking) already exists.\n"
- title: 15.1.4.4.  NFS4ERR_FBIG (Error Code 27)
  contents:
  - "15.1.4.4.  NFS4ERR_FBIG (Error Code 27)\n   The file is too large.  The operation\
    \ would have caused the file to\n   grow beyond the server's limit.\n"
- title: 15.1.4.5.  NFS4ERR_FILE_OPEN (Error Code 10046)
  contents:
  - "15.1.4.5.  NFS4ERR_FILE_OPEN (Error Code 10046)\n   The operation is not allowed\
    \ because a file involved in the operation\n   is currently open.  Servers may,\
    \ but are not required to, disallow\n   linking-to, removing, or renaming open\
    \ files.\n"
- title: 15.1.4.6.  NFS4ERR_IO (Error Code 5)
  contents:
  - "15.1.4.6.  NFS4ERR_IO (Error Code 5)\n   Indicates that an I/O error occurred\
    \ for which the file system was\n   unable to provide recovery.\n"
- title: 15.1.4.7.  NFS4ERR_MLINK (Error Code 31)
  contents:
  - "15.1.4.7.  NFS4ERR_MLINK (Error Code 31)\n   The request would have caused the\
    \ server's limit for the number of\n   hard links a file may have to be exceeded.\n"
- title: 15.1.4.8.  NFS4ERR_NOENT (Error Code 2)
  contents:
  - "15.1.4.8.  NFS4ERR_NOENT (Error Code 2)\n   Indicates no such file or directory.\
    \  The file or directory name\n   specified does not exist.\n"
- title: 15.1.4.9.  NFS4ERR_NOSPC (Error Code 28)
  contents:
  - "15.1.4.9.  NFS4ERR_NOSPC (Error Code 28)\n   Indicates there is no space left\
    \ on the device.  The operation would\n   have caused the server's file system\
    \ to exceed its limit.\n"
- title: 15.1.4.10.  NFS4ERR_NOTEMPTY (Error Code 66)
  contents:
  - "15.1.4.10.  NFS4ERR_NOTEMPTY (Error Code 66)\n   An attempt was made to remove\
    \ a directory that was not empty.\n"
- title: 15.1.4.11.  NFS4ERR_ROFS (Error Code 30)
  contents:
  - "15.1.4.11.  NFS4ERR_ROFS (Error Code 30)\n   Indicates a read-only file system.\
    \  A modifying operation was\n   attempted on a read-only file system.\n"
- title: 15.1.4.12.  NFS4ERR_XDEV (Error Code 18)
  contents:
  - "15.1.4.12.  NFS4ERR_XDEV (Error Code 18)\n   Indicates an attempt to do an operation,\
    \ such as linking, that\n   inappropriately crosses a boundary.  This may be due\
    \ to such\n   boundaries as:\n   *  that between file systems (where the fsids\
    \ are different).\n   *  that between different named attribute directories or\
    \ between a\n      named attribute directory and an ordinary directory.\n   *\
    \  that between byte-ranges of a file system that the file system\n      implementation\
    \ treats as separate (for example, for space\n      accounting purposes), and\
    \ where cross-connection between the byte-\n      ranges are not allowed.\n"
- title: 15.1.5.  State Management Errors
  contents:
  - "15.1.5.  State Management Errors\n   These errors indicate problems with the\
    \ stateid (or one of the\n   stateids) passed to a given operation.  This includes\
    \ situations in\n   which the stateid is invalid as well as situations in which\
    \ the\n   stateid is valid but designates locking state that has been revoked.\n\
    \   Depending on the operation, the stateid when valid may designate\n   opens,\
    \ byte-range locks, file or directory delegations, layouts, or\n   device maps.\n"
- title: 15.1.5.1.  NFS4ERR_ADMIN_REVOKED (Error Code 10047)
  contents:
  - "15.1.5.1.  NFS4ERR_ADMIN_REVOKED (Error Code 10047)\n   A stateid designates\
    \ locking state of any type that has been revoked\n   due to administrative interaction,\
    \ possibly while the lease is valid.\n"
- title: 15.1.5.2.  NFS4ERR_BAD_STATEID (Error Code 10026)
  contents:
  - "15.1.5.2.  NFS4ERR_BAD_STATEID (Error Code 10026)\n   A stateid does not properly\
    \ designate any valid state.  See Sections\n   8.2.4 and 8.2.3 for a discussion\
    \ of how stateids are validated.\n"
- title: 15.1.5.3.  NFS4ERR_DELEG_REVOKED (Error Code 10087)
  contents:
  - "15.1.5.3.  NFS4ERR_DELEG_REVOKED (Error Code 10087)\n   A stateid designates\
    \ recallable locking state of any type (delegation\n   or layout) that has been\
    \ revoked due to the failure of the client to\n   return the lock when it was\
    \ recalled.\n"
- title: 15.1.5.4.  NFS4ERR_EXPIRED (Error Code 10011)
  contents:
  - "15.1.5.4.  NFS4ERR_EXPIRED (Error Code 10011)\n   A stateid designates locking\
    \ state of any type that has been revoked\n   due to expiration of the client's\
    \ lease, either immediately upon\n   lease expiration, or following a later request\
    \ for a conflicting\n   lock.\n"
- title: 15.1.5.5.  NFS4ERR_OLD_STATEID (Error Code 10024)
  contents:
  - "15.1.5.5.  NFS4ERR_OLD_STATEID (Error Code 10024)\n   A stateid with a non-zero\
    \ seqid value does match the current seqid\n   for the state designated by the\
    \ user.\n"
- title: 15.1.6.  Security Errors
  contents:
  - "15.1.6.  Security Errors\n   These are the various permission-related errors\
    \ in NFSv4.1.\n"
- title: 15.1.6.1.  NFS4ERR_ACCESS (Error Code 13)
  contents:
  - "15.1.6.1.  NFS4ERR_ACCESS (Error Code 13)\n   Indicates permission denied.  The\
    \ caller does not have the correct\n   permission to perform the requested operation.\
    \  Contrast this with\n   NFS4ERR_PERM (Section 15.1.6.2), which restricts itself\
    \ to owner or\n   privileged-user permission failures, and NFS4ERR_WRONG_CRED\n\
    \   (Section 15.1.6.4), which deals with appropriate permission to delete\n  \
    \ or modify transient objects based on the credentials of the user that\n   created\
    \ them.\n"
- title: 15.1.6.2.  NFS4ERR_PERM (Error Code 1)
  contents:
  - "15.1.6.2.  NFS4ERR_PERM (Error Code 1)\n   Indicates requester is not the owner.\
    \  The operation was not allowed\n   because the caller is neither a privileged\
    \ user (root) nor the owner\n   of the target of the operation.\n"
- title: 15.1.6.3.  NFS4ERR_WRONGSEC (Error Code 10016)
  contents:
  - "15.1.6.3.  NFS4ERR_WRONGSEC (Error Code 10016)\n   Indicates that the security\
    \ mechanism being used by the client for\n   the operation does not match the\
    \ server's security policy.  The\n   client should change the security mechanism\
    \ being used and re-send\n   the operation (but not with the same slot ID and\
    \ sequence ID; one or\n   both MUST be different on the re-send).  SECINFO and\
    \ SECINFO_NO_NAME\n   can be used to determine the appropriate mechanism.\n"
- title: 15.1.6.4.  NFS4ERR_WRONG_CRED (Error Code 10082)
  contents:
  - "15.1.6.4.  NFS4ERR_WRONG_CRED (Error Code 10082)\n   An operation that manipulates\
    \ state was attempted by a principal that\n   was not allowed to modify that piece\
    \ of state.\n"
- title: 15.1.7.  Name Errors
  contents:
  - "15.1.7.  Name Errors\n   Names in NFSv4 are UTF-8 strings.  When the strings\
    \ are not valid\n   UTF-8 or are of length zero, the error NFS4ERR_INVAL results.\n\
    \   Besides this, there are a number of other errors to indicate specific\n  \
    \ problems with names.\n"
- title: 15.1.7.1.  NFS4ERR_BADCHAR (Error Code 10040)
  contents:
  - "15.1.7.1.  NFS4ERR_BADCHAR (Error Code 10040)\n   A UTF-8 string contains a character\
    \ that is not supported by the\n   server in the context in which it being used.\n"
- title: 15.1.7.2.  NFS4ERR_BADNAME (Error Code 10041)
  contents:
  - "15.1.7.2.  NFS4ERR_BADNAME (Error Code 10041)\n   A name string in a request\
    \ consisted of valid UTF-8 characters\n   supported by the server, but the name\
    \ is not supported by the server\n   as a valid name for the current operation.\
    \  An example might be\n   creating a file or directory named \"..\" on a server\
    \ whose file system\n   uses that name for links to parent directories.\n"
- title: 15.1.7.3.  NFS4ERR_NAMETOOLONG (Error Code 63)
  contents:
  - "15.1.7.3.  NFS4ERR_NAMETOOLONG (Error Code 63)\n   Returned when the filename\
    \ in an operation exceeds the server's\n   implementation limit.\n"
- title: 15.1.8.  Locking Errors
  contents:
  - "15.1.8.  Locking Errors\n   This section deals with errors related to locking,\
    \ both as to share\n   reservations and byte-range locking.  It does not deal\
    \ with errors\n   specific to the process of reclaiming locks.  Those are dealt\
    \ with in\n   Section 15.1.9.\n"
- title: 15.1.8.1.  NFS4ERR_BAD_RANGE (Error Code 10042)
  contents:
  - "15.1.8.1.  NFS4ERR_BAD_RANGE (Error Code 10042)\n   The byte-range of a LOCK,\
    \ LOCKT, or LOCKU operation is not allowed by\n   the server.  For example, this\
    \ error results when a server that only\n   supports 32-bit ranges receives a\
    \ range that cannot be handled by\n   that server.  (See Section 18.10.3.)\n"
- title: 15.1.8.2.  NFS4ERR_DEADLOCK (Error Code 10045)
  contents:
  - "15.1.8.2.  NFS4ERR_DEADLOCK (Error Code 10045)\n   The server has been able to\
    \ determine a byte-range locking deadlock\n   condition for a READW_LT or WRITEW_LT\
    \ LOCK operation.\n"
- title: 15.1.8.3.  NFS4ERR_DENIED (Error Code 10010)
  contents:
  - "15.1.8.3.  NFS4ERR_DENIED (Error Code 10010)\n   An attempt to lock a file is\
    \ denied.  Since this may be a temporary\n   condition, the client is encouraged\
    \ to re-send the lock request (but\n   not with the same slot ID and sequence\
    \ ID; one or both MUST be\n   different on the re-send) until the lock is accepted.\
    \  See\n   Section 9.6 for a discussion of the re-send.\n"
- title: 15.1.8.4.  NFS4ERR_LOCKED (Error Code 10012)
  contents:
  - "15.1.8.4.  NFS4ERR_LOCKED (Error Code 10012)\n   A READ or WRITE operation was\
    \ attempted on a file where there was a\n   conflict between the I/O and an existing\
    \ lock:\n   *  There is a share reservation inconsistent with the I/O being done.\n\
    \   *  The range to be read or written intersects an existing mandatory\n    \
    \  byte-range lock.\n"
- title: 15.1.8.5.  NFS4ERR_LOCKS_HELD (Error Code 10037)
  contents:
  - "15.1.8.5.  NFS4ERR_LOCKS_HELD (Error Code 10037)\n   An operation was prevented\
    \ by the unexpected presence of locks.\n"
- title: 15.1.8.6.  NFS4ERR_LOCK_NOTSUPP (Error Code 10043)
  contents:
  - "15.1.8.6.  NFS4ERR_LOCK_NOTSUPP (Error Code 10043)\n   A LOCK operation was attempted\
    \ that would require the upgrade or\n   downgrade of a byte-range lock range already\
    \ held by the owner, and\n   the server does not support atomic upgrade or downgrade\
    \ of locks.\n"
- title: 15.1.8.7.  NFS4ERR_LOCK_RANGE (Error Code 10028)
  contents:
  - "15.1.8.7.  NFS4ERR_LOCK_RANGE (Error Code 10028)\n   A LOCK operation is operating\
    \ on a range that overlaps in part a\n   currently held byte-range lock for the\
    \ current lock-owner and does\n   not precisely match a single such byte-range\
    \ lock where the server\n   does not support this type of request, and thus does\
    \ not implement\n   POSIX locking semantics [21].  See Sections 18.10.4, 18.11.4,\
    \ and\n   18.12.4 for a discussion of how this applies to LOCK, LOCKT, and\n \
    \  LOCKU respectively.\n"
- title: 15.1.8.8.  NFS4ERR_OPENMODE (Error Code 10038)
  contents:
  - "15.1.8.8.  NFS4ERR_OPENMODE (Error Code 10038)\n   The client attempted a READ,\
    \ WRITE, LOCK, or other operation not\n   sanctioned by the stateid passed (e.g.,\
    \ writing to a file opened for\n   read-only access).\n"
- title: 15.1.8.9.  NFS4ERR_SHARE_DENIED (Error Code 10015)
  contents:
  - "15.1.8.9.  NFS4ERR_SHARE_DENIED (Error Code 10015)\n   An attempt to OPEN a file\
    \ with a share reservation has failed because\n   of a share conflict.\n"
- title: 15.1.9.  Reclaim Errors
  contents:
  - "15.1.9.  Reclaim Errors\n   These errors relate to the process of reclaiming\
    \ locks after a server\n   restart.\n"
- title: 15.1.9.1.  NFS4ERR_COMPLETE_ALREADY (Error Code 10054)
  contents:
  - "15.1.9.1.  NFS4ERR_COMPLETE_ALREADY (Error Code 10054)\n   The client previously\
    \ sent a successful RECLAIM_COMPLETE operation\n   specifying the same scope,\
    \ whether that scope is global or for the\n   same file system in the case of\
    \ a per-fs RECLAIM_COMPLETE.  An\n   additional RECLAIM_COMPLETE operation is\
    \ not necessary and results in\n   this error.\n"
- title: 15.1.9.2.  NFS4ERR_GRACE (Error Code 10013)
  contents:
  - "15.1.9.2.  NFS4ERR_GRACE (Error Code 10013)\n   This error is returned when the\
    \ server is in its grace period with\n   regard to the file system object for\
    \ which the lock was requested.\n   In this situation, a non-reclaim locking request\
    \ cannot be granted.\n   This can occur because either:\n   *  The server does\
    \ not have sufficient information about locks that\n      might be potentially\
    \ reclaimed to determine whether the lock could\n      be granted.\n   *  The\
    \ request is made by a client responsible for reclaiming its\n      locks that\
    \ has not yet done the appropriate RECLAIM_COMPLETE\n      operation, allowing\
    \ it to proceed to obtain new locks.\n   In the case of a per-fs grace period,\
    \ there may be clients (i.e.,\n   those currently using the destination file system)\
    \ who might be\n   unaware of the circumstances resulting in the initiation of\
    \ the grace\n   period.  Such clients need to periodically retry the request until\n\
    \   the grace period is over, just as other clients do.\n"
- title: 15.1.9.3.  NFS4ERR_NO_GRACE (Error Code 10033)
  contents:
  - "15.1.9.3.  NFS4ERR_NO_GRACE (Error Code 10033)\n   A reclaim of client state\
    \ was attempted in circumstances in which the\n   server cannot guarantee that\
    \ conflicting state has not been provided\n   to another client.  This occurs\
    \ in any of the following situations:\n   *  There is no active grace period applying\
    \ to the file system object\n      for which the request was made.\n   *  The\
    \ client making the request has no current role in reclaiming\n      locks.\n\
    \   *  Previous operations have created a situation in which the server\n    \
    \  is not able to determine that a reclaim-interfering edge condition\n      does\
    \ not exist.\n"
- title: 15.1.9.4.  NFS4ERR_RECLAIM_BAD (Error Code 10034)
  contents:
  - "15.1.9.4.  NFS4ERR_RECLAIM_BAD (Error Code 10034)\n   The server has determined\
    \ that a reclaim attempted by the client is\n   not valid, i.e., the lock specified\
    \ as being reclaimed could not\n   possibly have existed before the server restart\
    \ or file system\n   migration event.  A server is not obliged to make this determination\n\
    \   and will typically rely on the client to only reclaim locks that the\n   client\
    \ was granted prior to restart.  However, when a server does\n   have reliable\
    \ information to enable it to make this determination,\n   this error indicates\
    \ that the reclaim has been rejected as invalid.\n   This is as opposed to the\
    \ error NFS4ERR_RECLAIM_CONFLICT (see\n   Section 15.1.9.5) where the server can\
    \ only determine that there has\n   been an invalid reclaim, but cannot determine\
    \ which request is\n   invalid.\n"
- title: 15.1.9.5.  NFS4ERR_RECLAIM_CONFLICT (Error Code 10035)
  contents:
  - "15.1.9.5.  NFS4ERR_RECLAIM_CONFLICT (Error Code 10035)\n   The reclaim attempted\
    \ by the client has encountered a conflict and\n   cannot be satisfied.  This\
    \ potentially indicates a misbehaving\n   client, although not necessarily the\
    \ one receiving the error.  The\n   misbehavior might be on the part of the client\
    \ that established the\n   lock with which this client conflicted.  See also Section\
    \ 15.1.9.4\n   for the related error, NFS4ERR_RECLAIM_BAD.\n"
- title: 15.1.10.  pNFS Errors
  contents:
  - "15.1.10.  pNFS Errors\n   This section deals with pNFS-related errors including\
    \ those that are\n   associated with using NFSv4.1 to communicate with a data\
    \ server.\n"
- title: 15.1.10.1.  NFS4ERR_BADIOMODE (Error Code 10049)
  contents:
  - "15.1.10.1.  NFS4ERR_BADIOMODE (Error Code 10049)\n   An invalid or inappropriate\
    \ layout iomode was specified.  For example\n   an inappropriate layout iomode,\
    \ suppose a client's LAYOUTGET\n   operation specified an iomode of LAYOUTIOMODE4_RW,\
    \ and the server is\n   neither able nor willing to let the client send write\
    \ requests to\n   data servers; the server can reply with NFS4ERR_BADIOMODE. \
    \ The\n   client would then send another LAYOUTGET with an iomode of\n   LAYOUTIOMODE4_READ.\n"
- title: 15.1.10.2.  NFS4ERR_BADLAYOUT (Error Code 10050)
  contents:
  - "15.1.10.2.  NFS4ERR_BADLAYOUT (Error Code 10050)\n   The layout specified is\
    \ invalid in some way.  For LAYOUTCOMMIT, this\n   indicates that the specified\
    \ layout is not held by the client or is\n   not of mode LAYOUTIOMODE4_RW.  For\
    \ LAYOUTGET, it indicates that a\n   layout matching the client's specification\
    \ as to minimum length\n   cannot be granted.\n"
- title: 15.1.10.3.  NFS4ERR_LAYOUTTRYLATER (Error Code 10058)
  contents:
  - "15.1.10.3.  NFS4ERR_LAYOUTTRYLATER (Error Code 10058)\n   Layouts are temporarily\
    \ unavailable for the file.  The client should\n   re-send later (but not with\
    \ the same slot ID and sequence ID; one or\n   both MUST be different on the re-send).\n"
- title: 15.1.10.4.  NFS4ERR_LAYOUTUNAVAILABLE (Error Code 10059)
  contents:
  - "15.1.10.4.  NFS4ERR_LAYOUTUNAVAILABLE (Error Code 10059)\n   Returned when layouts\
    \ are not available for the current file system\n   or the particular specified\
    \ file.\n"
- title: 15.1.10.5.  NFS4ERR_NOMATCHING_LAYOUT (Error Code 10060)
  contents:
  - "15.1.10.5.  NFS4ERR_NOMATCHING_LAYOUT (Error Code 10060)\n   Returned when layouts\
    \ are recalled and the client has no layouts\n   matching the specification of\
    \ the layouts being recalled.\n"
- title: 15.1.10.6.  NFS4ERR_PNFS_IO_HOLE (Error Code 10075)
  contents:
  - "15.1.10.6.  NFS4ERR_PNFS_IO_HOLE (Error Code 10075)\n   The pNFS client has attempted\
    \ to read from or write to an illegal\n   hole of a file of a data server that\
    \ is using sparse packing.  See\n   Section 13.4.4.\n"
- title: 15.1.10.7.  NFS4ERR_PNFS_NO_LAYOUT (Error Code 10080)
  contents:
  - "15.1.10.7.  NFS4ERR_PNFS_NO_LAYOUT (Error Code 10080)\n   The pNFS client has\
    \ attempted to read from or write to a file (using\n   a request to a data server)\
    \ without holding a valid layout.  This\n   includes the case where the client\
    \ had a layout, but the iomode does\n   not allow a WRITE.\n"
- title: 15.1.10.8.  NFS4ERR_RETURNCONFLICT (Error Code 10086)
  contents:
  - "15.1.10.8.  NFS4ERR_RETURNCONFLICT (Error Code 10086)\n   A layout is unavailable\
    \ due to an attempt to perform the LAYOUTGET\n   before a pending LAYOUTRETURN\
    \ on the file has been received.  See\n   Section 12.5.5.2.1.3.\n"
- title: 15.1.10.9.  NFS4ERR_UNKNOWN_LAYOUTTYPE (Error Code 10062)
  contents:
  - "15.1.10.9.  NFS4ERR_UNKNOWN_LAYOUTTYPE (Error Code 10062)\n   The client has\
    \ specified a layout type that is not supported by the\n   server.\n"
- title: 15.1.11.  Session Use Errors
  contents:
  - "15.1.11.  Session Use Errors\n   This section deals with errors encountered when\
    \ using sessions, that\n   is, errors encountered when a request uses a Sequence\
    \ (i.e., either\n   SEQUENCE or CB_SEQUENCE) operation.\n"
- title: 15.1.11.1.  NFS4ERR_BADSESSION (Error Code 10052)
  contents:
  - "15.1.11.1.  NFS4ERR_BADSESSION (Error Code 10052)\n   The specified session ID\
    \ is unknown to the server to which the\n   operation is addressed.\n"
- title: 15.1.11.2.  NFS4ERR_BADSLOT (Error Code 10053)
  contents:
  - "15.1.11.2.  NFS4ERR_BADSLOT (Error Code 10053)\n   The requester sent a Sequence\
    \ operation that attempted to use a slot\n   the replier does not have in its\
    \ slot table.  It is possible the slot\n   may have been retired.\n"
- title: 15.1.11.3.  NFS4ERR_BAD_HIGH_SLOT (Error Code 10077)
  contents:
  - "15.1.11.3.  NFS4ERR_BAD_HIGH_SLOT (Error Code 10077)\n   The highest_slot argument\
    \ in a Sequence operation exceeds the\n   replier's enforced highest_slotid.\n"
- title: 15.1.11.4.  NFS4ERR_CB_PATH_DOWN (Error Code 10048)
  contents:
  - "15.1.11.4.  NFS4ERR_CB_PATH_DOWN (Error Code 10048)\n   There is a problem contacting\
    \ the client via the callback path.  The\n   function of this error has been mostly\
    \ superseded by the use of\n   status flags in the reply to the SEQUENCE operation\
    \ (see\n   Section 18.46).\n"
- title: 15.1.11.5.  NFS4ERR_DEADSESSION (Error Code 10078)
  contents:
  - "15.1.11.5.  NFS4ERR_DEADSESSION (Error Code 10078)\n   The specified session\
    \ is a persistent session that is dead and does\n   not accept new requests or\
    \ perform new operations on existing\n   requests (in the case in which a request\
    \ was partially executed\n   before server restart).\n"
- title: 15.1.11.6.  NFS4ERR_CONN_NOT_BOUND_TO_SESSION (Error Code 10055)
  contents:
  - "15.1.11.6.  NFS4ERR_CONN_NOT_BOUND_TO_SESSION (Error Code 10055)\n   A Sequence\
    \ operation was sent on a connection that has not been\n   associated with the\
    \ specified session, where the client specified\n   that connection association\
    \ was to be enforced with SP4_MACH_CRED or\n   SP4_SSV state protection.\n"
- title: 15.1.11.7.  NFS4ERR_SEQ_FALSE_RETRY (Error Code 10076)
  contents:
  - "15.1.11.7.  NFS4ERR_SEQ_FALSE_RETRY (Error Code 10076)\n   The requester sent\
    \ a Sequence operation with a slot ID and sequence\n   ID that are in the reply\
    \ cache, but the replier has detected that the\n   retried request is not the\
    \ same as the original request.  See\n   Section 2.10.6.1.3.1.\n"
- title: 15.1.11.8.  NFS4ERR_SEQ_MISORDERED (Error Code 10063)
  contents:
  - "15.1.11.8.  NFS4ERR_SEQ_MISORDERED (Error Code 10063)\n   The requester sent\
    \ a Sequence operation with an invalid sequence ID.\n"
- title: 15.1.12.  Session Management Errors
  contents:
  - "15.1.12.  Session Management Errors\n   This section deals with errors associated\
    \ with requests used in\n   session management.\n"
- title: 15.1.12.1.  NFS4ERR_BACK_CHAN_BUSY (Error Code 10057)
  contents:
  - "15.1.12.1.  NFS4ERR_BACK_CHAN_BUSY (Error Code 10057)\n   An attempt was made\
    \ to destroy a session when the session cannot be\n   destroyed because the server\
    \ has callback requests outstanding.\n"
- title: 15.1.12.2.  NFS4ERR_BAD_SESSION_DIGEST (Error Code 10051)
  contents:
  - "15.1.12.2.  NFS4ERR_BAD_SESSION_DIGEST (Error Code 10051)\n   The digest used\
    \ in a SET_SSV request is not valid.\n"
- title: 15.1.13.  Client Management Errors
  contents:
  - "15.1.13.  Client Management Errors\n   This section deals with errors associated\
    \ with requests used to\n   create and manage client IDs.\n"
- title: 15.1.13.1.  NFS4ERR_CLIENTID_BUSY (Error Code 10074)
  contents:
  - "15.1.13.1.  NFS4ERR_CLIENTID_BUSY (Error Code 10074)\n   The DESTROY_CLIENTID\
    \ operation has found there are sessions and/or\n   unexpired state associated\
    \ with the client ID to be destroyed.\n"
- title: 15.1.13.2.  NFS4ERR_CLID_INUSE (Error Code 10017)
  contents:
  - "15.1.13.2.  NFS4ERR_CLID_INUSE (Error Code 10017)\n   While processing an EXCHANGE_ID\
    \ operation, the server was presented\n   with a co_ownerid field that matches\
    \ an existing client with valid\n   leased state, but the principal sending the\
    \ EXCHANGE_ID operation\n   differs from the principal that established the existing\
    \ client.\n   This indicates a collision (most likely due to chance) between\n\
    \   clients.  The client should recover by changing the co_ownerid and\n   re-sending\
    \ EXCHANGE_ID (but not with the same slot ID and sequence\n   ID; one or both\
    \ MUST be different on the re-send).\n"
- title: 15.1.13.3.  NFS4ERR_ENCR_ALG_UNSUPP (Error Code 10079)
  contents:
  - "15.1.13.3.  NFS4ERR_ENCR_ALG_UNSUPP (Error Code 10079)\n   An EXCHANGE_ID was\
    \ sent that specified state protection via SSV, and\n   where the set of encryption\
    \ algorithms presented by the client did\n   not include any supported by the\
    \ server.\n"
- title: 15.1.13.4.  NFS4ERR_HASH_ALG_UNSUPP (Error Code 10072)
  contents:
  - "15.1.13.4.  NFS4ERR_HASH_ALG_UNSUPP (Error Code 10072)\n   An EXCHANGE_ID was\
    \ sent that specified state protection via SSV, and\n   where the set of hashing\
    \ algorithms presented by the client did not\n   include any supported by the\
    \ server.\n"
- title: 15.1.13.5.  NFS4ERR_STALE_CLIENTID (Error Code 10022)
  contents:
  - "15.1.13.5.  NFS4ERR_STALE_CLIENTID (Error Code 10022)\n   A client ID not recognized\
    \ by the server was passed to an operation.\n   Note that unlike the case of NFSv4.0,\
    \ client IDs are not passed\n   explicitly to the server in ordinary locking operations\
    \ and cannot\n   result in this error.  Instead, when there is a server restart,\
    \ it is\n   first manifested through an error on the associated session, and the\n\
    \   staleness of the client ID is detected when trying to associate a\n   client\
    \ ID with a new session.\n"
- title: 15.1.14.  Delegation Errors
  contents:
  - "15.1.14.  Delegation Errors\n   This section deals with errors associated with\
    \ requesting and\n   returning delegations.\n"
- title: 15.1.14.1.  NFS4ERR_DELEG_ALREADY_WANTED (Error Code 10056)
  contents:
  - "15.1.14.1.  NFS4ERR_DELEG_ALREADY_WANTED (Error Code 10056)\n   The client has\
    \ requested a delegation when it had already registered\n   that it wants that\
    \ same delegation.\n"
- title: 15.1.14.2.  NFS4ERR_DIRDELEG_UNAVAIL (Error Code 10084)
  contents:
  - "15.1.14.2.  NFS4ERR_DIRDELEG_UNAVAIL (Error Code 10084)\n   This error is returned\
    \ when the server is unable or unwilling to\n   provide a requested directory\
    \ delegation.\n"
- title: 15.1.14.3.  NFS4ERR_RECALLCONFLICT (Error Code 10061)
  contents:
  - "15.1.14.3.  NFS4ERR_RECALLCONFLICT (Error Code 10061)\n   A recallable object\
    \ (i.e., a layout or delegation) is unavailable due\n   to a conflicting recall\
    \ operation that is currently in progress for\n   that object.\n"
- title: 15.1.14.4.  NFS4ERR_REJECT_DELEG (Error Code 10085)
  contents:
  - "15.1.14.4.  NFS4ERR_REJECT_DELEG (Error Code 10085)\n   The callback operation\
    \ invoked to deal with a new delegation has\n   rejected it.\n"
- title: 15.1.15.  Attribute Handling Errors
  contents:
  - "15.1.15.  Attribute Handling Errors\n   This section deals with errors specific\
    \ to attribute handling within\n   NFSv4.\n"
- title: 15.1.15.1.  NFS4ERR_ATTRNOTSUPP (Error Code 10032)
  contents:
  - "15.1.15.1.  NFS4ERR_ATTRNOTSUPP (Error Code 10032)\n   An attribute specified\
    \ is not supported by the server.  This error\n   MUST NOT be returned by the\
    \ GETATTR operation.\n"
- title: 15.1.15.2.  NFS4ERR_BADOWNER (Error Code 10039)
  contents:
  - "15.1.15.2.  NFS4ERR_BADOWNER (Error Code 10039)\n   This error is returned when\
    \ an owner or owner_group attribute value\n   or the who field of an ACE within\
    \ an ACL attribute value cannot be\n   translated to a local representation.\n"
- title: 15.1.15.3.  NFS4ERR_NOT_SAME (Error Code 10027)
  contents:
  - "15.1.15.3.  NFS4ERR_NOT_SAME (Error Code 10027)\n   This error is returned by\
    \ the VERIFY operation to signify that the\n   attributes compared were not the\
    \ same as those provided in the\n   client's request.\n"
- title: 15.1.15.4.  NFS4ERR_SAME (Error Code 10009)
  contents:
  - "15.1.15.4.  NFS4ERR_SAME (Error Code 10009)\n   This error is returned by the\
    \ NVERIFY operation to signify that the\n   attributes compared were the same\
    \ as those provided in the client's\n   request.\n"
- title: 15.1.16.  Obsoleted Errors
  contents:
  - "15.1.16.  Obsoleted Errors\n   These errors MUST NOT be generated by any NFSv4.1\
    \ operation.  This\n   can be for a number of reasons.\n   *  The function provided\
    \ by the error has been superseded by one of\n      the status bits returned by\
    \ the SEQUENCE operation.\n   *  The new session structure and associated change\
    \ in locking have\n      made the error unnecessary.\n   *  There has been a restructuring\
    \ of some errors for NFSv4.1 that\n      resulted in the elimination of certain\
    \ errors.\n"
- title: 15.1.16.1.  NFS4ERR_BAD_SEQID (Error Code 10026)
  contents:
  - "15.1.16.1.  NFS4ERR_BAD_SEQID (Error Code 10026)\n   The sequence number (seqid)\
    \ in a locking request is neither the next\n   expected number or the last number\
    \ processed.  These seqids are\n   ignored in NFSv4.1.\n"
- title: 15.1.16.2.  NFS4ERR_LEASE_MOVED (Error Code 10031)
  contents:
  - "15.1.16.2.  NFS4ERR_LEASE_MOVED (Error Code 10031)\n   A lease being renewed\
    \ is associated with a file system that has been\n   migrated to a new server.\
    \  The error has been superseded by the\n   SEQ4_STATUS_LEASE_MOVED status bit\
    \ (see Section 18.46).\n"
- title: 15.1.16.3.  NFS4ERR_NXIO (Error Code 5)
  contents:
  - "15.1.16.3.  NFS4ERR_NXIO (Error Code 5)\n   I/O error.  No such device or address.\
    \  This error is for errors\n   involving block and character device access, but\
    \ because NFSv4.1 is\n   not a device-access protocol, this error is not applicable.\n"
- title: 15.1.16.4.  NFS4ERR_RESTOREFH (Error Code 10030)
  contents:
  - "15.1.16.4.  NFS4ERR_RESTOREFH (Error Code 10030)\n   The RESTOREFH operation\
    \ does not have a saved filehandle (identified\n   by SAVEFH) to operate upon.\
    \  In NFSv4.1, this error has been\n   superseded by NFS4ERR_NOFILEHANDLE.\n"
- title: 15.1.16.5.  NFS4ERR_STALE_STATEID (Error Code 10023)
  contents:
  - "15.1.16.5.  NFS4ERR_STALE_STATEID (Error Code 10023)\n   A stateid generated\
    \ by an earlier server instance was used.  This\n   error is moot in NFSv4.1 because\
    \ all operations that take a stateid\n   MUST be preceded by the SEQUENCE operation,\
    \ and the earlier server\n   instance is detected by the session infrastructure\
    \ that supports\n   SEQUENCE.\n"
- title: 15.2.  Operations and Their Valid Errors
  contents:
  - "15.2.  Operations and Their Valid Errors\n   This section contains a table that\
    \ gives the valid error returns for\n   each protocol operation.  The error code\
    \ NFS4_OK (indicating no\n   error) is not listed but should be understood to\
    \ be returnable by all\n   operations with two important exceptions:\n   *  The\
    \ operations that MUST NOT be implemented: OPEN_CONFIRM,\n      RELEASE_LOCKOWNER,\
    \ RENEW, SETCLIENTID, and SETCLIENTID_CONFIRM.\n   *  The invalid operation: ILLEGAL.\n\
    \     | Operation            | Errors                                 |\n    \
    \ | ACCESS               | NFS4ERR_ACCESS, NFS4ERR_BADXDR,        |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n     |          \
    \            | NFS4ERR_IO, NFS4ERR_MOVED,             |\n     |              \
    \        | NFS4ERR_NOFILEHANDLE,                  |\n     |                  \
    \    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG,                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS                   |\n    \
    \ | BACKCHANNEL_CTL      | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,   |\n     |  \
    \                    | NFS4ERR_DELAY, NFS4ERR_INVAL,          |\n     |      \
    \                | NFS4ERR_NOENT,                         |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_TOO_MANY_OPS           \
    \        |\n     | BIND_CONN_TO_SESSION | NFS4ERR_BADSESSION, NFS4ERR_BADXDR,\
    \    |\n     |                      | NFS4ERR_BAD_SESSION_DIGEST,            |\n\
    \     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n    \
    \ |                      | NFS4ERR_INVAL, NFS4ERR_NOT_ONLY_OP,    |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |          \
    \            | NFS4ERR_REQ_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                  \
    \    | NFS4ERR_SERVERFAULT,                   |\n     |                      |\
    \ NFS4ERR_TOO_MANY_OPS                   |\n     | CLOSE                | NFS4ERR_ADMIN_REVOKED,\
    \ NFS4ERR_BADXDR, |\n     |                      | NFS4ERR_BAD_STATEID,      \
    \             |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,\
    \    |\n     |                      | NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED,    |\n\
    \     |                      | NFS4ERR_LOCKS_HELD, NFS4ERR_MOVED,     |\n    \
    \ |                      | NFS4ERR_NOFILEHANDLE,                  |\n     |  \
    \                    | NFS4ERR_OLD_STATEID,                   |\n     |      \
    \                | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                  \
    \    | NFS4ERR_REQ_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      | NFS4ERR_SERVERFAULT,\
    \ NFS4ERR_STALE,    |\n     |                      | NFS4ERR_TOO_MANY_OPS,   \
    \               |\n     |                      | NFS4ERR_WRONG_CRED          \
    \           |\n     | COMMIT               | NFS4ERR_ACCESS, NFS4ERR_BADXDR, \
    \       |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY, \
    \   |\n     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_IO,         |\n\
    \     |                      | NFS4ERR_ISDIR, NFS4ERR_MOVED,          |\n    \
    \ |                      | NFS4ERR_NOFILEHANDLE,                  |\n     |  \
    \                    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |              \
    \        | NFS4ERR_REQ_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      |\
    \ NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n     |                      | NFS4ERR_SYMLINK,\
    \ NFS4ERR_TOO_MANY_OPS, |\n     |                      | NFS4ERR_WRONG_TYPE  \
    \                   |\n     | CREATE               | NFS4ERR_ACCESS, NFS4ERR_ATTRNOTSUPP,\
    \   |\n     |                      | NFS4ERR_BADCHAR, NFS4ERR_BADNAME,      |\n\
    \     |                      | NFS4ERR_BADOWNER, NFS4ERR_BADTYPE,     |\n    \
    \ |                      | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,   |\n     |  \
    \                    | NFS4ERR_DELAY, NFS4ERR_DQUOT,          |\n     |      \
    \                | NFS4ERR_EXIST, NFS4ERR_FHEXPIRED,      |\n     |          \
    \            | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |              \
    \        | NFS4ERR_MLINK, NFS4ERR_MOVED,          |\n     |                  \
    \    | NFS4ERR_NAMETOOLONG,                   |\n     |                      |\
    \ NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC,   |\n     |                      | NFS4ERR_NOTDIR,\
    \                        |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,\
    \             |\n     |                      | NFS4ERR_PERM, NFS4ERR_REP_TOO_BIG,\
    \     |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,         \
    \ |\n     |                      | NFS4ERR_REQ_TOO_BIG,                   |\n\
    \     |                      | NFS4ERR_RETRY_UNCACHED_REP,            |\n    \
    \ |                      | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,     |\n     |  \
    \                    | NFS4ERR_STALE, NFS4ERR_TOO_MANY_OPS,   |\n     |      \
    \                | NFS4ERR_UNSAFE_COMPOUND                |\n     | CREATE_SESSION\
    \       | NFS4ERR_BADXDR, NFS4ERR_CLID_INUSE,    |\n     |                   \
    \   | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                      |\
    \ NFS4ERR_INVAL, NFS4ERR_NOENT,          |\n     |                      | NFS4ERR_NOT_ONLY_OP,\
    \ NFS4ERR_NOSPC,    |\n     |                      | NFS4ERR_REP_TOO_BIG,    \
    \               |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SEQ_MISORDERED,                |\n\
    \     |                      | NFS4ERR_SERVERFAULT,                   |\n    \
    \ |                      | NFS4ERR_STALE_CLIENTID,                |\n     |  \
    \                    | NFS4ERR_TOOSMALL,                      |\n     |      \
    \                | NFS4ERR_TOO_MANY_OPS,                  |\n     |          \
    \            | NFS4ERR_WRONG_CRED                     |\n     | DELEGPURGE   \
    \        | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,   |\n     |                  \
    \    | NFS4ERR_DELAY, NFS4ERR_NOTSUPP,        |\n     |                      |\
    \ NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      | NFS4ERR_REP_TOO_BIG,\
    \                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT,                   |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n    \
    \ |                      | NFS4ERR_WRONG_CRED                     |\n     | DELEGRETURN\
    \          | NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, |\n     |                \
    \      | NFS4ERR_BAD_STATEID,                   |\n     |                    \
    \  | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_DELEG_REVOKED,\
    \                 |\n     |                      | NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED,\
    \    |\n     |                      | NFS4ERR_INVAL, NFS4ERR_MOVED,          |\n\
    \     |                      | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, |\n    \
    \ |                      | NFS4ERR_OLD_STATEID,                   |\n     |  \
    \                    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |              \
    \        | NFS4ERR_REQ_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      |\
    \ NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n     |                      | NFS4ERR_TOO_MANY_OPS,\
    \                  |\n     |                      | NFS4ERR_WRONG_CRED       \
    \              |\n     | DESTROY_CLIENTID     | NFS4ERR_BADXDR, NFS4ERR_CLIENTID_BUSY,\
    \ |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n\
    \     |                      | NFS4ERR_NOT_ONLY_OP,                   |\n    \
    \ |                      | NFS4ERR_REP_TOO_BIG,                   |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |      \
    \                | NFS4ERR_REQ_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |              \
    \        | NFS4ERR_SERVERFAULT,                   |\n     |                  \
    \    | NFS4ERR_STALE_CLIENTID,                |\n     |                      |\
    \ NFS4ERR_TOO_MANY_OPS,                  |\n     |                      | NFS4ERR_WRONG_CRED\
    \                     |\n     | DESTROY_SESSION      | NFS4ERR_BACK_CHAN_BUSY,\
    \                |\n     |                      | NFS4ERR_BADSESSION, NFS4ERR_BADXDR,\
    \    |\n     |                      | NFS4ERR_CB_PATH_DOWN,                  |\n\
    \     |                      | NFS4ERR_CONN_NOT_BOUND_TO_SESSION,     |\n    \
    \ |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |  \
    \                    | NFS4ERR_NOT_ONLY_OP,                   |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |              \
    \        | NFS4ERR_REQ_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      |\
    \ NFS4ERR_SERVERFAULT,                   |\n     |                      | NFS4ERR_STALE_CLIENTID,\
    \                |\n     |                      | NFS4ERR_TOO_MANY_OPS,      \
    \            |\n     |                      | NFS4ERR_WRONG_CRED             \
    \        |\n     | EXCHANGE_ID          | NFS4ERR_BADCHAR, NFS4ERR_BADXDR,   \
    \    |\n     |                      | NFS4ERR_CLID_INUSE,                    |\n\
    \     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n    \
    \ |                      | NFS4ERR_ENCR_ALG_UNSUPP,               |\n     |  \
    \                    | NFS4ERR_HASH_ALG_UNSUPP,               |\n     |      \
    \                | NFS4ERR_INVAL, NFS4ERR_NOENT,          |\n     |          \
    \            | NFS4ERR_NOT_ONLY_OP, NFS4ERR_NOT_SAME, |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT,           \
    \        |\n     |                      | NFS4ERR_TOO_MANY_OPS               \
    \    |\n     | FREE_STATEID         | NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID,   |\n\
    \     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n    \
    \ |                      | NFS4ERR_LOCKS_HELD,                    |\n     |  \
    \                    | NFS4ERR_OLD_STATEID,                   |\n     |      \
    \                | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                  \
    \    | NFS4ERR_REQ_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      | NFS4ERR_SERVERFAULT,\
    \                   |\n     |                      | NFS4ERR_TOO_MANY_OPS,   \
    \               |\n     |                      | NFS4ERR_WRONG_CRED          \
    \           |\n     | GET_DIR_DELEGATION   | NFS4ERR_ACCESS, NFS4ERR_BADXDR, \
    \       |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY, \
    \   |\n     |                      | NFS4ERR_DIRDELEG_UNAVAIL,              |\n\
    \     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n    \
    \ |                      | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |  \
    \                    | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |      \
    \                | NFS4ERR_NOTDIR, NFS4ERR_NOTSUPP,       |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,\
    \    |\n     |                      | NFS4ERR_TOO_MANY_OPS                   |\n\
    \     | GETATTR              | NFS4ERR_ACCESS, NFS4ERR_BADXDR,        |\n    \
    \ |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |  \
    \                    | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n     |      \
    \                | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |          \
    \            | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |              \
    \        | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      | NFS4ERR_REQ_TOO_BIG,\
    \                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,\
    \    |\n     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n\
    \     |                      | NFS4ERR_WRONG_TYPE                     |\n    \
    \ | GETDEVICEINFO        | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,   |\n     |  \
    \                    | NFS4ERR_DELAY, NFS4ERR_INVAL,          |\n     |      \
    \                | NFS4ERR_NOENT, NFS4ERR_NOTSUPP,        |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_TOOSMALL,\
    \ |\n     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n\
    \     |                      | NFS4ERR_UNKNOWN_LAYOUTTYPE             |\n    \
    \ | GETDEVICELIST        | NFS4ERR_BADXDR, NFS4ERR_BAD_COOKIE,    |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n     |          \
    \            | NFS4ERR_IO, NFS4ERR_NOFILEHANDLE,      |\n     |              \
    \        | NFS4ERR_NOTSUPP, NFS4ERR_NOT_SAME,     |\n     |                  \
    \    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG,                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT,                   |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n    \
    \ |                      | NFS4ERR_UNKNOWN_LAYOUTTYPE             |\n     | GETFH\
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_MOVED,      |\n     |          \
    \            | NFS4ERR_NOFILEHANDLE,                  |\n     |              \
    \        | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                  \
    \    | NFS4ERR_STALE                          |\n     | ILLEGAL              |\
    \ NFS4ERR_BADXDR, NFS4ERR_OP_ILLEGAL     |\n     | LAYOUTCOMMIT         | NFS4ERR_ACCESS,\
    \ NFS4ERR_ADMIN_REVOKED, |\n     |                      | NFS4ERR_ATTRNOTSUPP,\
    \                   |\n     |                      | NFS4ERR_BADIOMODE, NFS4ERR_BADLAYOUT,\
    \  |\n     |                      | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,   |\n\
    \     |                      | NFS4ERR_DELAY, NFS4ERR_DELEG_REVOKED,  |\n    \
    \ |                      | NFS4ERR_EXPIRED, NFS4ERR_FBIG,         |\n     |  \
    \                    | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n     |      \
    \                | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |          \
    \            | NFS4ERR_ISDIR NFS4ERR_MOVED,           |\n     |              \
    \        | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, |\n     |                  \
    \    | NFS4ERR_NO_GRACE,                      |\n     |                      |\
    \ NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      | NFS4ERR_RECLAIM_BAD,\
    \                   |\n     |                      | NFS4ERR_RECLAIM_CONFLICT,\
    \              |\n     |                      | NFS4ERR_REP_TOO_BIG,         \
    \          |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,    \
    \      |\n     |                      | NFS4ERR_REQ_TOO_BIG,                 \
    \  |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,            |\n\
    \     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n    \
    \ |                      | NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, |\n     |  \
    \                    | NFS4ERR_UNKNOWN_LAYOUTTYPE,            |\n     |      \
    \                | NFS4ERR_WRONG_CRED                     |\n     | LAYOUTGET\
    \            | NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, |\n     |              \
    \        | NFS4ERR_BADIOMODE, NFS4ERR_BADLAYOUT,  |\n     |                  \
    \    | NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID,   |\n     |                      |\
    \ NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_DELEG_REVOKED,\
    \ NFS4ERR_DQUOT,  |\n     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,\
    \      |\n     |                      | NFS4ERR_INVAL, NFS4ERR_IO,           \
    \  |\n     |                      | NFS4ERR_LAYOUTTRYLATER,                |\n\
    \     |                      | NFS4ERR_LAYOUTUNAVAILABLE,             |\n    \
    \ |                      | NFS4ERR_LOCKED, NFS4ERR_MOVED,         |\n     |  \
    \                    | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOSPC,   |\n     |      \
    \                | NFS4ERR_NOTSUPP, NFS4ERR_OLD_STATEID,  |\n     |          \
    \            | NFS4ERR_OPENMODE,                      |\n     |              \
    \        | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                  \
    \    | NFS4ERR_RECALLCONFLICT,                |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG,                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOOSMALL,                      |\n    \
    \ |                      | NFS4ERR_TOO_MANY_OPS,                  |\n     |  \
    \                    | NFS4ERR_UNKNOWN_LAYOUTTYPE,            |\n     |      \
    \                | NFS4ERR_WRONG_TYPE                     |\n     | LAYOUTRETURN\
    \         | NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, |\n     |                 \
    \     | NFS4ERR_BAD_STATEID,                   |\n     |                     \
    \ | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_DELEG_REVOKED,\
    \                 |\n     |                      | NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED,\
    \    |\n     |                      | NFS4ERR_GRACE, NFS4ERR_INVAL,          |\n\
    \     |                      | NFS4ERR_ISDIR, NFS4ERR_MOVED,          |\n    \
    \ |                      | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTSUPP, |\n     |  \
    \                    | NFS4ERR_NO_GRACE, NFS4ERR_OLD_STATEID, |\n     |      \
    \                | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                  \
    \    | NFS4ERR_REQ_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      | NFS4ERR_SERVERFAULT,\
    \ NFS4ERR_STALE,    |\n     |                      | NFS4ERR_TOO_MANY_OPS,   \
    \               |\n     |                      | NFS4ERR_UNKNOWN_LAYOUTTYPE, \
    \           |\n     |                      | NFS4ERR_WRONG_CRED, NFS4ERR_WRONG_TYPE\
    \ |\n     | LINK                 | NFS4ERR_ACCESS, NFS4ERR_BADCHAR,       |\n\
    \     |                      | NFS4ERR_BADNAME, NFS4ERR_BADXDR,       |\n    \
    \ |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |  \
    \                    | NFS4ERR_DQUOT, NFS4ERR_EXIST,          |\n     |      \
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_FILE_OPEN,  |\n     |          \
    \            | NFS4ERR_GRACE, NFS4ERR_INVAL,          |\n     |              \
    \        | NFS4ERR_ISDIR, NFS4ERR_IO,             |\n     |                  \
    \    | NFS4ERR_MLINK, NFS4ERR_MOVED,          |\n     |                      |\
    \ NFS4ERR_NAMETOOLONG,                   |\n     |                      | NFS4ERR_NOFILEHANDLE,\
    \ NFS4ERR_NOSPC,   |\n     |                      | NFS4ERR_NOTDIR, NFS4ERR_NOTSUPP,\
    \       |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,          \
    \   |\n     |                      | NFS4ERR_REP_TOO_BIG,                   |\n\
    \     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n    \
    \ |                      | NFS4ERR_REQ_TOO_BIG,                   |\n     |  \
    \                    | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |      \
    \                | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,     |\n     |          \
    \            | NFS4ERR_STALE, NFS4ERR_SYMLINK,        |\n     |              \
    \        | NFS4ERR_TOO_MANY_OPS,                  |\n     |                  \
    \    | NFS4ERR_WRONGSEC, NFS4ERR_WRONG_TYPE,  |\n     |                      |\
    \ NFS4ERR_XDEV                           |\n     | LOCK                 | NFS4ERR_ACCESS,\
    \ NFS4ERR_ADMIN_REVOKED, |\n     |                      | NFS4ERR_BADXDR, NFS4ERR_BAD_RANGE,\
    \     |\n     |                      | NFS4ERR_BAD_STATEID, NFS4ERR_DEADLOCK,\
    \ |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n\
    \     |                      | NFS4ERR_DENIED, NFS4ERR_EXPIRED,       |\n    \
    \ |                      | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n     |  \
    \                    | NFS4ERR_INVAL, NFS4ERR_ISDIR,          |\n     |      \
    \                | NFS4ERR_LOCK_NOTSUPP,                  |\n     |          \
    \            | NFS4ERR_LOCK_RANGE, NFS4ERR_MOVED,     |\n     |              \
    \        | NFS4ERR_NOFILEHANDLE,                  |\n     |                  \
    \    | NFS4ERR_NO_GRACE, NFS4ERR_OLD_STATEID, |\n     |                      |\
    \ NFS4ERR_OPENMODE,                      |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,\
    \             |\n     |                      | NFS4ERR_RECLAIM_BAD,          \
    \         |\n     |                      | NFS4ERR_RECLAIM_CONFLICT,         \
    \     |\n     |                      | NFS4ERR_REP_TOO_BIG,                  \
    \ |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n\
    \     |                      | NFS4ERR_REQ_TOO_BIG,                   |\n    \
    \ |                      | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |  \
    \                    | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,     |\n     |      \
    \                | NFS4ERR_STALE, NFS4ERR_SYMLINK,        |\n     |          \
    \            | NFS4ERR_TOO_MANY_OPS,                  |\n     |              \
    \        | NFS4ERR_WRONG_CRED, NFS4ERR_WRONG_TYPE |\n     | LOCKT            \
    \    | NFS4ERR_ACCESS, NFS4ERR_BADXDR,        |\n     |                      |\
    \ NFS4ERR_BAD_RANGE,                     |\n     |                      | NFS4ERR_DEADSESSION,\
    \ NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_DENIED, NFS4ERR_FHEXPIRED,\
    \     |\n     |                      | NFS4ERR_GRACE, NFS4ERR_INVAL,         \
    \ |\n     |                      | NFS4ERR_ISDIR, NFS4ERR_LOCK_RANGE,     |\n\
    \     |                      | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n    \
    \ |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |          \
    \            | NFS4ERR_REQ_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                  \
    \    | NFS4ERR_ROFS, NFS4ERR_STALE,           |\n     |                      |\
    \ NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, |\n     |                      | NFS4ERR_WRONG_CRED,\
    \ NFS4ERR_WRONG_TYPE |\n     | LOCKU                | NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED,\
    \ |\n     |                      | NFS4ERR_BADXDR, NFS4ERR_BAD_RANGE,     |\n\
    \     |                      | NFS4ERR_BAD_STATEID,                   |\n    \
    \ |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |  \
    \                    | NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED,    |\n     |      \
    \                | NFS4ERR_INVAL, NFS4ERR_LOCK_RANGE,     |\n     |          \
    \            | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |              \
    \        | NFS4ERR_OLD_STATEID,                   |\n     |                  \
    \    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG,                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n    \
    \ |                      | NFS4ERR_WRONG_CRED                     |\n     | LOOKUP\
    \               | NFS4ERR_ACCESS, NFS4ERR_BADCHAR,       |\n     |           \
    \           | NFS4ERR_BADNAME, NFS4ERR_BADXDR,       |\n     |               \
    \       | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                   \
    \   | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n     |                      |\
    \ NFS4ERR_IO, NFS4ERR_MOVED,             |\n     |                      | NFS4ERR_NAMETOOLONG,\
    \ NFS4ERR_NOENT,    |\n     |                      | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR,\
    \  |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n\
    \     |                      | NFS4ERR_REP_TOO_BIG,                   |\n    \
    \ |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |  \
    \                    | NFS4ERR_REQ_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |          \
    \            | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n     |              \
    \        | NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, |\n     |                  \
    \    | NFS4ERR_WRONGSEC                       |\n     | LOOKUPP              |\
    \ NFS4ERR_ACCESS, NFS4ERR_DEADSESSION,   |\n     |                      | NFS4ERR_DELAY,\
    \ NFS4ERR_FHEXPIRED,      |\n     |                      | NFS4ERR_IO, NFS4ERR_MOVED,\
    \             |\n     |                      | NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE,\
    \   |\n     |                      | NFS4ERR_NOTDIR,                        |\n\
    \     |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n    \
    \ |                      | NFS4ERR_REP_TOO_BIG,                   |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |      \
    \                | NFS4ERR_REQ_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |              \
    \        | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n     |                  \
    \    | NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, |\n     |                      |\
    \ NFS4ERR_WRONGSEC                       |\n     | NVERIFY              | NFS4ERR_ACCESS,\
    \ NFS4ERR_ATTRNOTSUPP,   |\n     |                      | NFS4ERR_BADCHAR, NFS4ERR_BADXDR,\
    \       |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY, \
    \   |\n     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n\
    \     |                      | NFS4ERR_INVAL, NFS4ERR_IO,             |\n    \
    \ |                      | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |  \
    \                    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |              \
    \        | NFS4ERR_REQ_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      |\
    \ NFS4ERR_SAME, NFS4ERR_SERVERFAULT,     |\n     |                      | NFS4ERR_STALE,\
    \ NFS4ERR_TOO_MANY_OPS,   |\n     |                      | NFS4ERR_UNKNOWN_LAYOUTTYPE,\
    \            |\n     |                      | NFS4ERR_WRONG_TYPE             \
    \        |\n     | OPEN                 | NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED,\
    \ |\n     |                      | NFS4ERR_ATTRNOTSUPP, NFS4ERR_BADCHAR,  |\n\
    \     |                      | NFS4ERR_BADNAME, NFS4ERR_BADOWNER,     |\n    \
    \ |                      | NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID,   |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_DELEG_ALREADY_WANTED,          |\n     |          \
    \            | NFS4ERR_DELEG_REVOKED, NFS4ERR_DQUOT,  |\n     |              \
    \        | NFS4ERR_EXIST, NFS4ERR_EXPIRED,        |\n     |                  \
    \    | NFS4ERR_FBIG, NFS4ERR_FHEXPIRED,       |\n     |                      |\
    \ NFS4ERR_GRACE, NFS4ERR_INVAL,          |\n     |                      | NFS4ERR_ISDIR,\
    \ NFS4ERR_IO,             |\n     |                      | NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG,\
    \    |\n     |                      | NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE,   |\n\
    \     |                      | NFS4ERR_NOSPC, NFS4ERR_NOTDIR,         |\n    \
    \ |                      | NFS4ERR_NO_GRACE, NFS4ERR_OLD_STATEID, |\n     |  \
    \                    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |      \
    \                | NFS4ERR_PERM, NFS4ERR_RECLAIM_BAD,     |\n     |          \
    \            | NFS4ERR_RECLAIM_CONFLICT,              |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,\
    \     |\n     |                      | NFS4ERR_SHARE_DENIED, NFS4ERR_STALE,  \
    \ |\n     |                      | NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, |\n\
    \     |                      | NFS4ERR_UNSAFE_COMPOUND,               |\n    \
    \ |                      | NFS4ERR_WRONGSEC, NFS4ERR_WRONG_TYPE   |\n     | OPEN_CONFIRM\
    \         | NFS4ERR_NOTSUPP                        |\n     | OPEN_DOWNGRADE  \
    \     | NFS4ERR_ADMIN_REVOKED, NFS4ERR_BADXDR, |\n     |                     \
    \ | NFS4ERR_BAD_STATEID,                   |\n     |                      | NFS4ERR_DEADSESSION,\
    \ NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED,\
    \    |\n     |                      | NFS4ERR_INVAL, NFS4ERR_MOVED,          |\n\
    \     |                      | NFS4ERR_NOFILEHANDLE,                  |\n    \
    \ |                      | NFS4ERR_OLD_STATEID,                   |\n     |  \
    \                    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |              \
    \        | NFS4ERR_REQ_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      |\
    \ NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,     |\n     |                      | NFS4ERR_STALE,\
    \ NFS4ERR_TOO_MANY_OPS,   |\n     |                      | NFS4ERR_WRONG_CRED\
    \                     |\n     | OPENATTR             | NFS4ERR_ACCESS, NFS4ERR_BADXDR,\
    \        |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,\
    \    |\n     |                      | NFS4ERR_DQUOT, NFS4ERR_FHEXPIRED,      |\n\
    \     |                      | NFS4ERR_IO, NFS4ERR_MOVED,             |\n    \
    \ |                      | NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE,   |\n     |  \
    \                    | NFS4ERR_NOSPC, NFS4ERR_NOTSUPP,        |\n     |      \
    \                | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                  \
    \    | NFS4ERR_REQ_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      | NFS4ERR_ROFS,\
    \ NFS4ERR_SERVERFAULT,     |\n     |                      | NFS4ERR_STALE, NFS4ERR_TOO_MANY_OPS,\
    \   |\n     |                      | NFS4ERR_UNSAFE_COMPOUND,               |\n\
    \     |                      | NFS4ERR_WRONG_TYPE                     |\n    \
    \ | PUTFH                | NFS4ERR_BADHANDLE, NFS4ERR_BADXDR,     |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_MOVED,                         |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,\
    \    |\n     |                      | NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC |\n\
    \     | PUTPUBFH             | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n    \
    \ |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |          \
    \            | NFS4ERR_REQ_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                  \
    \    | NFS4ERR_SERVERFAULT,                   |\n     |                      |\
    \ NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC |\n     | PUTROOTFH            | NFS4ERR_DEADSESSION,\
    \ NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,\
    \             |\n     |                      | NFS4ERR_REP_TOO_BIG,          \
    \         |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,     \
    \     |\n     |                      | NFS4ERR_REQ_TOO_BIG,                  \
    \ |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,            |\n\
    \     |                      | NFS4ERR_SERVERFAULT,                   |\n    \
    \ |                      | NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC |\n     | READ\
    \                 | NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, |\n     |         \
    \             | NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID,   |\n     |             \
    \         | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                 \
    \     | NFS4ERR_DELEG_REVOKED,                 |\n     |                     \
    \ | NFS4ERR_EXPIRED, NFS4ERR_FHEXPIRED,    |\n     |                      | NFS4ERR_GRACE,\
    \ NFS4ERR_INVAL,          |\n     |                      | NFS4ERR_ISDIR, NFS4ERR_IO,\
    \             |\n     |                      | NFS4ERR_LOCKED, NFS4ERR_MOVED,\
    \         |\n     |                      | NFS4ERR_NOFILEHANDLE,             \
    \     |\n     |                      | NFS4ERR_OLD_STATEID, NFS4ERR_OPENMODE,\
    \ |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n\
    \     |                      | NFS4ERR_PNFS_IO_HOLE,                  |\n    \
    \ |                      | NFS4ERR_PNFS_NO_LAYOUT,                |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |          \
    \            | NFS4ERR_REQ_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                  \
    \    | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n     |                      |\
    \ NFS4ERR_SYMLINK, NFS4ERR_TOO_MANY_OPS, |\n     |                      | NFS4ERR_WRONG_TYPE\
    \                     |\n     | READDIR              | NFS4ERR_ACCESS, NFS4ERR_BADXDR,\
    \        |\n     |                      | NFS4ERR_BAD_COOKIE,                \
    \    |\n     |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n\
    \     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n    \
    \ |                      | NFS4ERR_IO, NFS4ERR_MOVED,             |\n     |  \
    \                    | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR,  |\n     |      \
    \                | NFS4ERR_NOT_SAME,                      |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,\
    \    |\n     |                      | NFS4ERR_TOOSMALL, NFS4ERR_TOO_MANY_OPS |\n\
    \     | READLINK             | NFS4ERR_ACCESS, NFS4ERR_DEADSESSION,   |\n    \
    \ |                      | NFS4ERR_DELAY, NFS4ERR_FHEXPIRED,      |\n     |  \
    \                    | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |      \
    \                | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,\
    \    |\n     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n\
    \     |                      | NFS4ERR_WRONG_TYPE                     |\n    \
    \ | RECLAIM_COMPLETE     | NFS4ERR_BADXDR,                        |\n     |  \
    \                    | NFS4ERR_COMPLETE_ALREADY,              |\n     |      \
    \                | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |          \
    \            | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n     |              \
    \        | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |                  \
    \    | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG,                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS,                  |\n    \
    \ |                      | NFS4ERR_WRONG_CRED, NFS4ERR_WRONG_TYPE |\n     | RELEASE_LOCKOWNER\
    \    | NFS4ERR_NOTSUPP                        |\n     | REMOVE               |\
    \ NFS4ERR_ACCESS, NFS4ERR_BADCHAR,       |\n     |                      | NFS4ERR_BADNAME,\
    \ NFS4ERR_BADXDR,       |\n     |                      | NFS4ERR_DEADSESSION,\
    \ NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_FILE_OPEN,\
    \  |\n     |                      | NFS4ERR_GRACE, NFS4ERR_INVAL,          |\n\
    \     |                      | NFS4ERR_IO, NFS4ERR_MOVED,             |\n    \
    \ |                      | NFS4ERR_NAMETOOLONG, NFS4ERR_NOENT,    |\n     |  \
    \                    | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR,  |\n     |      \
    \                | NFS4ERR_NOTEMPTY,                      |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,\
    \     |\n     |                      | NFS4ERR_STALE, NFS4ERR_TOO_MANY_OPS   \
    \ |\n     | RENAME               | NFS4ERR_ACCESS, NFS4ERR_BADCHAR,       |\n\
    \     |                      | NFS4ERR_BADNAME, NFS4ERR_BADXDR,       |\n    \
    \ |                      | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |  \
    \                    | NFS4ERR_DQUOT, NFS4ERR_EXIST,          |\n     |      \
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_FILE_OPEN,  |\n     |          \
    \            | NFS4ERR_GRACE, NFS4ERR_INVAL,          |\n     |              \
    \        | NFS4ERR_IO, NFS4ERR_MLINK,             |\n     |                  \
    \    | NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG,    |\n     |                      |\
    \ NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE,   |\n     |                      | NFS4ERR_NOSPC,\
    \ NFS4ERR_NOTDIR,         |\n     |                      | NFS4ERR_NOTEMPTY, \
    \                     |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,\
    \             |\n     |                      | NFS4ERR_REP_TOO_BIG,          \
    \         |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,     \
    \     |\n     |                      | NFS4ERR_REQ_TOO_BIG,                  \
    \ |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,            |\n\
    \     |                      | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,     |\n    \
    \ |                      | NFS4ERR_STALE, NFS4ERR_TOO_MANY_OPS,   |\n     |  \
    \                    | NFS4ERR_WRONGSEC, NFS4ERR_XDEV         |\n     | RENEW\
    \                | NFS4ERR_NOTSUPP                        |\n     | RESTOREFH\
    \            | NFS4ERR_DEADSESSION,                   |\n     |              \
    \        | NFS4ERR_FHEXPIRED, NFS4ERR_MOVED,      |\n     |                  \
    \    | NFS4ERR_NOFILEHANDLE,                  |\n     |                      |\
    \ NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      | NFS4ERR_REP_TOO_BIG,\
    \                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS, NFS4ERR_WRONGSEC |\n    \
    \ | SAVEFH               | NFS4ERR_DEADSESSION,                   |\n     |  \
    \                    | NFS4ERR_FHEXPIRED, NFS4ERR_MOVED,      |\n     |      \
    \                | NFS4ERR_NOFILEHANDLE,                  |\n     |          \
    \            | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,\
    \    |\n     |                      | NFS4ERR_TOO_MANY_OPS                   |\n\
    \     | SECINFO              | NFS4ERR_ACCESS, NFS4ERR_BADCHAR,       |\n    \
    \ |                      | NFS4ERR_BADNAME, NFS4ERR_BADXDR,       |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n     |          \
    \            | NFS4ERR_MOVED, NFS4ERR_NAMETOOLONG,    |\n     |              \
    \        | NFS4ERR_NOENT, NFS4ERR_NOFILEHANDLE,   |\n     |                  \
    \    | NFS4ERR_NOTDIR,                        |\n     |                      |\
    \ NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      | NFS4ERR_REP_TOO_BIG,\
    \                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS                   |\n    \
    \ | SECINFO_NO_NAME      | NFS4ERR_ACCESS, NFS4ERR_BADXDR,        |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_FHEXPIRED, NFS4ERR_INVAL,      |\n     |          \
    \            | NFS4ERR_MOVED, NFS4ERR_NOENT,          |\n     |              \
    \        | NFS4ERR_NOFILEHANDLE, NFS4ERR_NOTDIR,  |\n     |                  \
    \    | NFS4ERR_NOTSUPP,                       |\n     |                      |\
    \ NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                      | NFS4ERR_REP_TOO_BIG,\
    \                   |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,\
    \          |\n     |                      | NFS4ERR_REQ_TOO_BIG,             \
    \      |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,          \
    \  |\n     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS                   |\n    \
    \ | SEQUENCE             | NFS4ERR_BADSESSION, NFS4ERR_BADSLOT,   |\n     |  \
    \                    | NFS4ERR_BADXDR, NFS4ERR_BAD_HIGH_SLOT, |\n     |      \
    \                | NFS4ERR_CONN_NOT_BOUND_TO_SESSION,     |\n     |          \
    \            | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG,                   |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      |\
    \ NFS4ERR_REQ_TOO_BIG,                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_SEQUENCE_POS,          \
    \        |\n     |                      | NFS4ERR_SEQ_FALSE_RETRY,           \
    \    |\n     |                      | NFS4ERR_SEQ_MISORDERED,                |\n\
    \     |                      | NFS4ERR_TOO_MANY_OPS                   |\n    \
    \ | SET_SSV              | NFS4ERR_BADXDR,                        |\n     |  \
    \                    | NFS4ERR_BAD_SESSION_DIGEST,            |\n     |      \
    \                | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |          \
    \            | NFS4ERR_INVAL,                         |\n     |              \
    \        | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                  \
    \    | NFS4ERR_REP_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                      | NFS4ERR_REQ_TOO_BIG,\
    \                   |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,\
    \            |\n     |                      | NFS4ERR_TOO_MANY_OPS           \
    \        |\n     | SETATTR              | NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED,\
    \ |\n     |                      | NFS4ERR_ATTRNOTSUPP, NFS4ERR_BADCHAR,  |\n\
    \     |                      | NFS4ERR_BADOWNER, NFS4ERR_BADXDR,      |\n    \
    \ |                      | NFS4ERR_BAD_STATEID,                   |\n     |  \
    \                    | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |      \
    \                | NFS4ERR_DELEG_REVOKED, NFS4ERR_DQUOT,  |\n     |          \
    \            | NFS4ERR_EXPIRED, NFS4ERR_FBIG,         |\n     |              \
    \        | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n     |                  \
    \    | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |                      |\
    \ NFS4ERR_LOCKED, NFS4ERR_MOVED,         |\n     |                      | NFS4ERR_NOFILEHANDLE,\
    \ NFS4ERR_NOSPC,   |\n     |                      | NFS4ERR_OLD_STATEID, NFS4ERR_OPENMODE,\
    \ |\n     |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n\
    \     |                      | NFS4ERR_PERM, NFS4ERR_REP_TOO_BIG,     |\n    \
    \ |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |  \
    \                    | NFS4ERR_REQ_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |          \
    \            | NFS4ERR_ROFS, NFS4ERR_SERVERFAULT,     |\n     |              \
    \        | NFS4ERR_STALE, NFS4ERR_TOO_MANY_OPS,   |\n     |                  \
    \    | NFS4ERR_UNKNOWN_LAYOUTTYPE,            |\n     |                      |\
    \ NFS4ERR_WRONG_TYPE                     |\n     | SETCLIENTID          | NFS4ERR_NOTSUPP\
    \                        |\n     | SETCLIENTID_CONFIRM  | NFS4ERR_NOTSUPP    \
    \                    |\n     | TEST_STATEID         | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,\
    \   |\n     |                      | NFS4ERR_DELAY,                         |\n\
    \     |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n    \
    \ |                      | NFS4ERR_REP_TOO_BIG,                   |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |      \
    \                | NFS4ERR_REQ_TOO_BIG,                   |\n     |          \
    \            | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |              \
    \        | NFS4ERR_SERVERFAULT,                   |\n     |                  \
    \    | NFS4ERR_TOO_MANY_OPS                   |\n     | VERIFY               |\
    \ NFS4ERR_ACCESS, NFS4ERR_ATTRNOTSUPP,   |\n     |                      | NFS4ERR_BADCHAR,\
    \ NFS4ERR_BADXDR,       |\n     |                      | NFS4ERR_DEADSESSION,\
    \ NFS4ERR_DELAY,    |\n     |                      | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,\
    \      |\n     |                      | NFS4ERR_INVAL, NFS4ERR_IO,           \
    \  |\n     |                      | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n\
    \     |                      | NFS4ERR_NOT_SAME,                      |\n    \
    \ |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |  \
    \                    | NFS4ERR_REP_TOO_BIG,                   |\n     |      \
    \                | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |          \
    \            | NFS4ERR_REQ_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                  \
    \    | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n     |                      |\
    \ NFS4ERR_TOO_MANY_OPS,                  |\n     |                      | NFS4ERR_UNKNOWN_LAYOUTTYPE,\
    \            |\n     |                      | NFS4ERR_WRONG_TYPE             \
    \        |\n     | WANT_DELEGATION      | NFS4ERR_BADXDR, NFS4ERR_DEADSESSION,\
    \   |\n     |                      | NFS4ERR_DELAY,                         |\n\
    \     |                      | NFS4ERR_DELEG_ALREADY_WANTED,          |\n    \
    \ |                      | NFS4ERR_FHEXPIRED, NFS4ERR_GRACE,      |\n     |  \
    \                    | NFS4ERR_INVAL, NFS4ERR_IO,             |\n     |      \
    \                | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,   |\n     |          \
    \            | NFS4ERR_NOTSUPP, NFS4ERR_NO_GRACE,     |\n     |              \
    \        | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |                  \
    \    | NFS4ERR_RECALLCONFLICT,                |\n     |                      |\
    \ NFS4ERR_RECLAIM_BAD,                   |\n     |                      | NFS4ERR_RECLAIM_CONFLICT,\
    \              |\n     |                      | NFS4ERR_REP_TOO_BIG,         \
    \          |\n     |                      | NFS4ERR_REP_TOO_BIG_TO_CACHE,    \
    \      |\n     |                      | NFS4ERR_REQ_TOO_BIG,                 \
    \  |\n     |                      | NFS4ERR_RETRY_UNCACHED_REP,            |\n\
    \     |                      | NFS4ERR_SERVERFAULT, NFS4ERR_STALE,    |\n    \
    \ |                      | NFS4ERR_TOO_MANY_OPS,                  |\n     |  \
    \                    | NFS4ERR_WRONG_TYPE                     |\n     | WRITE\
    \                | NFS4ERR_ACCESS, NFS4ERR_ADMIN_REVOKED, |\n     |          \
    \            | NFS4ERR_BADXDR, NFS4ERR_BAD_STATEID,   |\n     |              \
    \        | NFS4ERR_DEADSESSION, NFS4ERR_DELAY,    |\n     |                  \
    \    | NFS4ERR_DELEG_REVOKED, NFS4ERR_DQUOT,  |\n     |                      |\
    \ NFS4ERR_EXPIRED, NFS4ERR_FBIG,         |\n     |                      | NFS4ERR_FHEXPIRED,\
    \ NFS4ERR_GRACE,      |\n     |                      | NFS4ERR_INVAL, NFS4ERR_IO,\
    \             |\n     |                      | NFS4ERR_ISDIR, NFS4ERR_LOCKED,\
    \         |\n     |                      | NFS4ERR_MOVED, NFS4ERR_NOFILEHANDLE,\
    \   |\n     |                      | NFS4ERR_NOSPC, NFS4ERR_OLD_STATEID,    |\n\
    \     |                      | NFS4ERR_OPENMODE,                      |\n    \
    \ |                      | NFS4ERR_OP_NOT_IN_SESSION,             |\n     |  \
    \                    | NFS4ERR_PNFS_IO_HOLE,                  |\n     |      \
    \                | NFS4ERR_PNFS_NO_LAYOUT,                |\n     |          \
    \            | NFS4ERR_REP_TOO_BIG,                   |\n     |              \
    \        | NFS4ERR_REP_TOO_BIG_TO_CACHE,          |\n     |                  \
    \    | NFS4ERR_REQ_TOO_BIG,                   |\n     |                      |\
    \ NFS4ERR_RETRY_UNCACHED_REP,            |\n     |                      | NFS4ERR_ROFS,\
    \ NFS4ERR_SERVERFAULT,     |\n     |                      | NFS4ERR_STALE, NFS4ERR_SYMLINK,\
    \        |\n     |                      | NFS4ERR_TOO_MANY_OPS,              \
    \    |\n     |                      | NFS4ERR_WRONG_TYPE                     |\n\
    \         Table 12: Valid Error Returns for Each Protocol Operation\n"
- title: 15.3.  Callback Operations and Their Valid Errors
  contents:
  - "15.3.  Callback Operations and Their Valid Errors\n   This section contains a\
    \ table that gives the valid error returns for\n   each callback operation.  The\
    \ error code NFS4_OK (indicating no\n   error) is not listed but should be understood\
    \ to be returnable by all\n   callback operations with the exception of CB_ILLEGAL.\n\
    \    | Callback Operation      | Errors                                |\n   \
    \ | CB_GETATTR              | NFS4ERR_BADHANDLE, NFS4ERR_BADXDR,    |\n    | CB_ILLEGAL\
    \              | NFS4ERR_BADXDR, NFS4ERR_OP_ILLEGAL    |\n    | CB_LAYOUTRECALL\
    \         | NFS4ERR_BADHANDLE, NFS4ERR_BADIOMODE, |\n    | CB_NOTIFY         \
    \      | NFS4ERR_BADHANDLE, NFS4ERR_BADXDR,    |\n    | CB_NOTIFY_DEVICEID   \
    \   | NFS4ERR_BADXDR, NFS4ERR_DELAY,        |\n    | CB_NOTIFY_LOCK          |\
    \ NFS4ERR_BADHANDLE, NFS4ERR_BADXDR,    |\n    | CB_PUSH_DELEG           | NFS4ERR_BADHANDLE,\
    \ NFS4ERR_BADXDR,    |\n    | CB_RECALL               | NFS4ERR_BADHANDLE, NFS4ERR_BADXDR,\
    \    |\n    | CB_RECALL_ANY           | NFS4ERR_BADXDR, NFS4ERR_DELAY,       \
    \ |\n    | CB_RECALLABLE_OBJ_AVAIL | NFS4ERR_BADXDR, NFS4ERR_DELAY,        |\n\
    \    | CB_RECALL_SLOT          | NFS4ERR_BADXDR,                       |\n   \
    \ | CB_SEQUENCE             | NFS4ERR_BADSESSION, NFS4ERR_BADSLOT,  |\n    | CB_WANTS_CANCELLED\
    \      | NFS4ERR_BADXDR, NFS4ERR_DELAY,        |\n     Table 13: Valid Error Returns\
    \ for Each Protocol Callback Operation\n"
- title: 15.4.  Errors and the Operations That Use Them
  contents:
  - "15.4.  Errors and the Operations That Use Them\n   | Error                  \
    \           | Operations                    |\n   | NFS4ERR_ACCESS           \
    \         | ACCESS, COMMIT, CREATE,       |\n   | NFS4ERR_ADMIN_REVOKED      \
    \       | CLOSE, DELEGRETURN,           |\n   | NFS4ERR_ATTRNOTSUPP          \
    \     | CREATE, LAYOUTCOMMIT,         |\n   | NFS4ERR_BACK_CHAN_BUSY         \
    \   | DESTROY_SESSION               |\n   | NFS4ERR_BADCHAR                  \
    \ | CREATE, EXCHANGE_ID, LINK,    |\n   | NFS4ERR_BADHANDLE                 |\
    \ CB_GETATTR, CB_LAYOUTRECALL,  |\n   | NFS4ERR_BADIOMODE                 | CB_LAYOUTRECALL,\
    \              |\n   | NFS4ERR_BADLAYOUT                 | LAYOUTCOMMIT, LAYOUTGET\
    \       |\n   | NFS4ERR_BADNAME                   | CREATE, LINK, LOOKUP, OPEN,\
    \   |\n   | NFS4ERR_BADOWNER                  | CREATE, OPEN, SETATTR        \
    \ |\n   | NFS4ERR_BADSESSION                | BIND_CONN_TO_SESSION,         |\n\
    \   | NFS4ERR_BADSLOT                   | CB_SEQUENCE, SEQUENCE         |\n  \
    \ | NFS4ERR_BADTYPE                   | CREATE                        |\n   |\
    \ NFS4ERR_BADXDR                    | ACCESS, BACKCHANNEL_CTL,      |\n   | NFS4ERR_BAD_COOKIE\
    \                | GETDEVICELIST, READDIR        |\n   | NFS4ERR_BAD_HIGH_SLOT\
    \             | CB_RECALL_SLOT, CB_SEQUENCE,  |\n   | NFS4ERR_BAD_RANGE      \
    \           | LOCK, LOCKT, LOCKU            |\n   | NFS4ERR_BAD_SESSION_DIGEST\
    \        | BIND_CONN_TO_SESSION,         |\n   | NFS4ERR_BAD_STATEID         \
    \      | CB_LAYOUTRECALL, CB_NOTIFY,   |\n   | NFS4ERR_CB_PATH_DOWN          \
    \    | DESTROY_SESSION               |\n   | NFS4ERR_CLID_INUSE              \
    \  | CREATE_SESSION, EXCHANGE_ID   |\n   | NFS4ERR_CLIENTID_BUSY             |\
    \ DESTROY_CLIENTID              |\n   | NFS4ERR_COMPLETE_ALREADY          | RECLAIM_COMPLETE\
    \              |\n   | NFS4ERR_CONN_NOT_BOUND_TO_SESSION | CB_SEQUENCE,      \
    \            |\n   | NFS4ERR_DEADLOCK                  | LOCK                \
    \          |\n   | NFS4ERR_DEADSESSION               | ACCESS, BACKCHANNEL_CTL,\
    \      |\n   | NFS4ERR_DELAY                     | ACCESS, BACKCHANNEL_CTL,  \
    \    |\n   | NFS4ERR_DELEG_ALREADY_WANTED      | OPEN, WANT_DELEGATION       \
    \  |\n   | NFS4ERR_DELEG_REVOKED             | DELEGRETURN, LAYOUTCOMMIT,    |\n\
    \   | NFS4ERR_DENIED                    | LOCK, LOCKT                   |\n  \
    \ | NFS4ERR_DIRDELEG_UNAVAIL          | GET_DIR_DELEGATION            |\n   |\
    \ NFS4ERR_DQUOT                     | CREATE, LAYOUTGET, LINK,      |\n   | NFS4ERR_ENCR_ALG_UNSUPP\
    \           | EXCHANGE_ID                   |\n   | NFS4ERR_EXIST            \
    \         | CREATE, LINK, OPEN, RENAME    |\n   | NFS4ERR_EXPIRED            \
    \       | CLOSE, DELEGRETURN,           |\n   | NFS4ERR_FBIG                 \
    \     | LAYOUTCOMMIT, OPEN, SETATTR,  |\n   | NFS4ERR_FHEXPIRED              \
    \   | ACCESS, CLOSE, COMMIT,        |\n   | NFS4ERR_FILE_OPEN                \
    \ | LINK, REMOVE, RENAME          |\n   | NFS4ERR_GRACE                     |\
    \ GETATTR, GET_DIR_DELEGATION,  |\n   | NFS4ERR_HASH_ALG_UNSUPP           | EXCHANGE_ID\
    \                   |\n   | NFS4ERR_INVAL                     | ACCESS, BACKCHANNEL_CTL,\
    \      |\n   | NFS4ERR_IO                        | ACCESS, COMMIT, CREATE,   \
    \    |\n   | NFS4ERR_ISDIR                     | COMMIT, LAYOUTCOMMIT,       \
    \  |\n   | NFS4ERR_LAYOUTTRYLATER            | LAYOUTGET                     |\n\
    \   | NFS4ERR_LAYOUTUNAVAILABLE         | LAYOUTGET                     |\n  \
    \ | NFS4ERR_LOCKED                    | LAYOUTGET, READ, SETATTR,     |\n   |\
    \ NFS4ERR_LOCKS_HELD                | CLOSE, FREE_STATEID           |\n   | NFS4ERR_LOCK_NOTSUPP\
    \              | LOCK                          |\n   | NFS4ERR_LOCK_RANGE    \
    \            | LOCK, LOCKT, LOCKU            |\n   | NFS4ERR_MLINK           \
    \          | CREATE, LINK, RENAME          |\n   | NFS4ERR_MOVED             \
    \        | ACCESS, CLOSE, COMMIT,        |\n   | NFS4ERR_NAMETOOLONG         \
    \      | CREATE, LINK, LOOKUP, OPEN,   |\n   | NFS4ERR_NOENT                 \
    \    | BACKCHANNEL_CTL,              |\n   | NFS4ERR_NOFILEHANDLE            \
    \  | ACCESS, CLOSE, COMMIT,        |\n   | NFS4ERR_NOMATCHING_LAYOUT         |\
    \ CB_LAYOUTRECALL               |\n   | NFS4ERR_NOSPC                     | CREATE,\
    \ CREATE_SESSION,       |\n   | NFS4ERR_NOTDIR                    | CREATE, GET_DIR_DELEGATION,\
    \   |\n   | NFS4ERR_NOTEMPTY                  | REMOVE, RENAME               \
    \ |\n   | NFS4ERR_NOTSUPP                   | CB_LAYOUTRECALL, CB_NOTIFY,   |\n\
    \   | NFS4ERR_NOT_ONLY_OP               | BIND_CONN_TO_SESSION,         |\n  \
    \ | NFS4ERR_NOT_SAME                  | EXCHANGE_ID, GETDEVICELIST,   |\n   |\
    \ NFS4ERR_NO_GRACE                  | LAYOUTCOMMIT, LAYOUTRETURN,   |\n   | NFS4ERR_OLD_STATEID\
    \               | CLOSE, DELEGRETURN,           |\n   | NFS4ERR_OPENMODE     \
    \             | LAYOUTGET, LOCK, READ,        |\n   | NFS4ERR_OP_ILLEGAL     \
    \           | CB_ILLEGAL, ILLEGAL           |\n   | NFS4ERR_OP_NOT_IN_SESSION\
    \         | ACCESS, BACKCHANNEL_CTL,      |\n   | NFS4ERR_PERM               \
    \       | CREATE, OPEN, SETATTR         |\n   | NFS4ERR_PNFS_IO_HOLE         \
    \     | READ, WRITE                   |\n   | NFS4ERR_PNFS_NO_LAYOUT         \
    \   | READ, WRITE                   |\n   | NFS4ERR_RECALLCONFLICT           \
    \ | LAYOUTGET, WANT_DELEGATION    |\n   | NFS4ERR_RECLAIM_BAD               |\
    \ LAYOUTCOMMIT, LOCK, OPEN,     |\n   | NFS4ERR_RECLAIM_CONFLICT          | LAYOUTCOMMIT,\
    \ LOCK, OPEN,     |\n   | NFS4ERR_REJECT_DELEG              | CB_PUSH_DELEG  \
    \               |\n   | NFS4ERR_REP_TOO_BIG               | ACCESS, BACKCHANNEL_CTL,\
    \      |\n   | NFS4ERR_REP_TOO_BIG_TO_CACHE      | ACCESS, BACKCHANNEL_CTL,  \
    \    |\n   | NFS4ERR_REQ_TOO_BIG               | ACCESS, BACKCHANNEL_CTL,    \
    \  |\n   | NFS4ERR_RETRY_UNCACHED_REP        | ACCESS, BACKCHANNEL_CTL,      |\n\
    \   | NFS4ERR_ROFS                      | CREATE, LINK, LOCK, LOCKT,    |\n  \
    \ | NFS4ERR_SAME                      | NVERIFY                       |\n   |\
    \ NFS4ERR_SEQUENCE_POS              | CB_SEQUENCE, SEQUENCE         |\n   | NFS4ERR_SEQ_FALSE_RETRY\
    \           | CB_SEQUENCE, SEQUENCE         |\n   | NFS4ERR_SEQ_MISORDERED   \
    \         | CB_SEQUENCE, CREATE_SESSION,  |\n   | NFS4ERR_SERVERFAULT        \
    \       | ACCESS,                       |\n   | NFS4ERR_SHARE_DENIED         \
    \     | OPEN                          |\n   | NFS4ERR_STALE                  \
    \   | ACCESS, CLOSE, COMMIT,        |\n   | NFS4ERR_STALE_CLIENTID           \
    \ | CREATE_SESSION,               |\n   | NFS4ERR_SYMLINK                   |\
    \ COMMIT, LAYOUTCOMMIT, LINK,   |\n   | NFS4ERR_TOOSMALL                  | CREATE_SESSION,\
    \               |\n   | NFS4ERR_TOO_MANY_OPS              | ACCESS, BACKCHANNEL_CTL,\
    \      |\n   | NFS4ERR_UNKNOWN_LAYOUTTYPE        | CB_LAYOUTRECALL,          \
    \    |\n   | NFS4ERR_UNSAFE_COMPOUND           | CREATE, OPEN, OPENATTR      \
    \  |\n   | NFS4ERR_WRONGSEC                  | LINK, LOOKUP, LOOKUPP, OPEN,  |\n\
    \   | NFS4ERR_WRONG_CRED                | CLOSE, CREATE_SESSION,        |\n  \
    \ | NFS4ERR_WRONG_TYPE                | CB_LAYOUTRECALL,              |\n   |\
    \ NFS4ERR_XDEV                      | LINK, RENAME                  |\n      \
    \       Table 14: Errors and the Operations That Use Them\n"
- title: 16.  NFSv4.1 Procedures
  contents:
  - "16.  NFSv4.1 Procedures\n   Both procedures, NULL and COMPOUND, MUST be implemented.\n"
- title: '16.1.  Procedure 0: NULL - No Operation'
  contents:
  - '16.1.  Procedure 0: NULL - No Operation

    '
- title: 16.1.1.  ARGUMENTS
  contents:
  - "16.1.1.  ARGUMENTS\n   void;\n"
- title: 16.1.2.  RESULTS
  contents:
  - "16.1.2.  RESULTS\n   void;\n"
- title: 16.1.3.  DESCRIPTION
  contents:
  - "16.1.3.  DESCRIPTION\n   This is the standard NULL procedure with the standard\
    \ void argument\n   and void response.  This procedure has no functionality associated\n\
    \   with it.  Because of this, it is sometimes used to measure the\n   overhead\
    \ of processing a service request.  Therefore, the server\n   SHOULD ensure that\
    \ no unnecessary work is done in servicing this\n   procedure.\n"
- title: 16.1.4.  ERRORS
  contents:
  - "16.1.4.  ERRORS\n   None.\n"
- title: '16.2.  Procedure 1: COMPOUND - Compound Operations'
  contents:
  - '16.2.  Procedure 1: COMPOUND - Compound Operations

    '
- title: 16.2.1.  ARGUMENTS
  contents:
  - "16.2.1.  ARGUMENTS\n   enum nfs_opnum4 {\n    OP_ACCESS              = 3,\n \
    \   OP_CLOSE               = 4,\n    OP_COMMIT              = 5,\n    OP_CREATE\
    \              = 6,\n    OP_DELEGPURGE          = 7,\n    OP_DELEGRETURN     \
    \    = 8,\n    OP_GETATTR             = 9,\n    OP_GETFH               = 10,\n\
    \    OP_LINK                = 11,\n    OP_LOCK                = 12,\n    OP_LOCKT\
    \               = 13,\n    OP_LOCKU               = 14,\n    OP_LOOKUP       \
    \       = 15,\n    OP_LOOKUPP             = 16,\n    OP_NVERIFY             =\
    \ 17,\n    OP_OPEN                = 18,\n    OP_OPENATTR            = 19,\n  \
    \  OP_OPEN_CONFIRM        = 20, /* Mandatory not-to-implement */\n    OP_OPEN_DOWNGRADE\
    \      = 21,\n    OP_PUTFH               = 22,\n    OP_PUTPUBFH            = 23,\n\
    \    OP_PUTROOTFH           = 24,\n    OP_READ                = 25,\n    OP_READDIR\
    \             = 26,\n    OP_READLINK            = 27,\n    OP_REMOVE         \
    \     = 28,\n    OP_RENAME              = 29,\n    OP_RENEW               = 30,\
    \ /* Mandatory not-to-implement */\n    OP_RESTOREFH           = 31,\n    OP_SAVEFH\
    \              = 32,\n    OP_SECINFO             = 33,\n    OP_SETATTR       \
    \      = 34,\n    OP_SETCLIENTID         = 35, /* Mandatory not-to-implement */\n\
    \    OP_SETCLIENTID_CONFIRM = 36, /* Mandatory not-to-implement */\n    OP_VERIFY\
    \              = 37,\n    OP_WRITE               = 38,\n    OP_RELEASE_LOCKOWNER\
    \   = 39, /* Mandatory not-to-implement */\n   /* new operations for NFSv4.1 */\n\
    \    OP_BACKCHANNEL_CTL     = 40,\n    OP_BIND_CONN_TO_SESSION = 41,\n    OP_EXCHANGE_ID\
    \         = 42,\n    OP_CREATE_SESSION      = 43,\n    OP_DESTROY_SESSION    \
    \ = 44,\n    OP_FREE_STATEID        = 45,\n    OP_GET_DIR_DELEGATION  = 46,\n\
    \    OP_GETDEVICEINFO       = 47,\n    OP_GETDEVICELIST       = 48,\n    OP_LAYOUTCOMMIT\
    \        = 49,\n    OP_LAYOUTGET           = 50,\n    OP_LAYOUTRETURN        =\
    \ 51,\n    OP_SECINFO_NO_NAME     = 52,\n    OP_SEQUENCE            = 53,\n  \
    \  OP_SET_SSV             = 54,\n    OP_TEST_STATEID        = 55,\n    OP_WANT_DELEGATION\
    \     = 56,\n    OP_DESTROY_CLIENTID    = 57,\n    OP_RECLAIM_COMPLETE    = 58,\n\
    \    OP_ILLEGAL             = 10044\n   };\n   union nfs_argop4 switch (nfs_opnum4\
    \ argop) {\n    case OP_ACCESS:        ACCESS4args opaccess;\n    case OP_CLOSE:\
    \         CLOSE4args opclose;\n    case OP_COMMIT:        COMMIT4args opcommit;\n\
    \    case OP_CREATE:        CREATE4args opcreate;\n    case OP_DELEGPURGE:   \
    \ DELEGPURGE4args opdelegpurge;\n    case OP_DELEGRETURN:   DELEGRETURN4args opdelegreturn;\n\
    \    case OP_GETATTR:       GETATTR4args opgetattr;\n    case OP_GETFH:      \
    \   void;\n    case OP_LINK:          LINK4args oplink;\n    case OP_LOCK:   \
    \       LOCK4args oplock;\n    case OP_LOCKT:         LOCKT4args oplockt;\n  \
    \  case OP_LOCKU:         LOCKU4args oplocku;\n    case OP_LOOKUP:        LOOKUP4args\
    \ oplookup;\n    case OP_LOOKUPP:       void;\n    case OP_NVERIFY:       NVERIFY4args\
    \ opnverify;\n    case OP_OPEN:          OPEN4args opopen;\n    case OP_OPENATTR:\
    \      OPENATTR4args opopenattr;\n    /* Not for NFSv4.1 */\n    case OP_OPEN_CONFIRM:\
    \  OPEN_CONFIRM4args opopen_confirm;\n    case OP_OPEN_DOWNGRADE:\n          \
    \                 OPEN_DOWNGRADE4args opopen_downgrade;\n    case OP_PUTFH:  \
    \       PUTFH4args opputfh;\n    case OP_PUTPUBFH:      void;\n    case OP_PUTROOTFH:\
    \     void;\n    case OP_READ:          READ4args opread;\n    case OP_READDIR:\
    \       READDIR4args opreaddir;\n    case OP_READLINK:      void;\n    case OP_REMOVE:\
    \        REMOVE4args opremove;\n    case OP_RENAME:        RENAME4args oprename;\n\
    \    /* Not for NFSv4.1 */\n    case OP_RENEW:         RENEW4args oprenew;\n \
    \   case OP_RESTOREFH:     void;\n    case OP_SAVEFH:        void;\n    case OP_SECINFO:\
    \       SECINFO4args opsecinfo;\n    case OP_SETATTR:       SETATTR4args opsetattr;\n\
    \    /* Not for NFSv4.1 */\n    case OP_SETCLIENTID: SETCLIENTID4args opsetclientid;\n\
    \    /* Not for NFSv4.1 */\n    case OP_SETCLIENTID_CONFIRM: SETCLIENTID_CONFIRM4args\n\
    \    case OP_VERIFY:        VERIFY4args opverify;\n    case OP_WRITE:        \
    \ WRITE4args opwrite;\n    /* Not for NFSv4.1 */\n    case OP_RELEASE_LOCKOWNER:\n\
    \                           RELEASE_LOCKOWNER4args\n                         \
    \  oprelease_lockowner;\n    /* Operations new to NFSv4.1 */\n    case OP_BACKCHANNEL_CTL:\n\
    \                           BACKCHANNEL_CTL4args opbackchannel_ctl;\n    case\
    \ OP_BIND_CONN_TO_SESSION:\n                           BIND_CONN_TO_SESSION4args\n\
    \                           opbind_conn_to_session;\n    case OP_EXCHANGE_ID:\
    \   EXCHANGE_ID4args opexchange_id;\n    case OP_CREATE_SESSION:\n           \
    \                CREATE_SESSION4args opcreate_session;\n    case OP_DESTROY_SESSION:\n\
    \                           DESTROY_SESSION4args opdestroy_session;\n    case\
    \ OP_FREE_STATEID:  FREE_STATEID4args opfree_stateid;\n    case OP_GET_DIR_DELEGATION:\n\
    \                           GET_DIR_DELEGATION4args\n    case OP_GETDEVICEINFO:\
    \ GETDEVICEINFO4args opgetdeviceinfo;\n    case OP_GETDEVICELIST: GETDEVICELIST4args\
    \ opgetdevicelist;\n    case OP_LAYOUTCOMMIT:  LAYOUTCOMMIT4args oplayoutcommit;\n\
    \    case OP_LAYOUTGET:     LAYOUTGET4args oplayoutget;\n    case OP_LAYOUTRETURN:\
    \  LAYOUTRETURN4args oplayoutreturn;\n    case OP_SECINFO_NO_NAME:\n         \
    \                  SECINFO_NO_NAME4args opsecinfo_no_name;\n    case OP_SEQUENCE:\
    \      SEQUENCE4args opsequence;\n    case OP_SET_SSV:       SET_SSV4args opset_ssv;\n\
    \    case OP_TEST_STATEID:  TEST_STATEID4args optest_stateid;\n    case OP_WANT_DELEGATION:\n\
    \                           WANT_DELEGATION4args opwant_delegation;\n    case\
    \ OP_DESTROY_CLIENTID:\n                           DESTROY_CLIENTID4args\n   \
    \ case OP_RECLAIM_COMPLETE:\n                           RECLAIM_COMPLETE4args\n\
    \    /* Operations not new to NFSv4.1 */\n    case OP_ILLEGAL:       void;\n \
    \  };\n   struct COMPOUND4args {\n           utf8str_cs      tag;\n          \
    \ uint32_t        minorversion;\n           nfs_argop4      argarray<>;\n   };\n"
- title: 16.2.2.  RESULTS
  contents:
  - "16.2.2.  RESULTS\n   union nfs_resop4 switch (nfs_opnum4 resop) {\n    case OP_ACCESS:\
    \        ACCESS4res opaccess;\n    case OP_CLOSE:         CLOSE4res opclose;\n\
    \    case OP_COMMIT:        COMMIT4res opcommit;\n    case OP_CREATE:        CREATE4res\
    \ opcreate;\n    case OP_DELEGPURGE:    DELEGPURGE4res opdelegpurge;\n    case\
    \ OP_DELEGRETURN:   DELEGRETURN4res opdelegreturn;\n    case OP_GETATTR:     \
    \  GETATTR4res opgetattr;\n    case OP_GETFH:         GETFH4res opgetfh;\n   \
    \ case OP_LINK:          LINK4res oplink;\n    case OP_LOCK:          LOCK4res\
    \ oplock;\n    case OP_LOCKT:         LOCKT4res oplockt;\n    case OP_LOCKU: \
    \        LOCKU4res oplocku;\n    case OP_LOOKUP:        LOOKUP4res oplookup;\n\
    \    case OP_LOOKUPP:       LOOKUPP4res oplookupp;\n    case OP_NVERIFY:     \
    \  NVERIFY4res opnverify;\n    case OP_OPEN:          OPEN4res opopen;\n    case\
    \ OP_OPENATTR:      OPENATTR4res opopenattr;\n    /* Not for NFSv4.1 */\n    case\
    \ OP_OPEN_CONFIRM:  OPEN_CONFIRM4res opopen_confirm;\n    case OP_OPEN_DOWNGRADE:\n\
    \                           OPEN_DOWNGRADE4res\n    case OP_PUTFH:         PUTFH4res\
    \ opputfh;\n    case OP_PUTPUBFH:      PUTPUBFH4res opputpubfh;\n    case OP_PUTROOTFH:\
    \     PUTROOTFH4res opputrootfh;\n    case OP_READ:          READ4res opread;\n\
    \    case OP_READDIR:       READDIR4res opreaddir;\n    case OP_READLINK:    \
    \  READLINK4res opreadlink;\n    case OP_REMOVE:        REMOVE4res opremove;\n\
    \    case OP_RENAME:        RENAME4res oprename;\n    /* Not for NFSv4.1 */\n\
    \    case OP_RENEW:         RENEW4res oprenew;\n    case OP_RESTOREFH:     RESTOREFH4res\
    \ oprestorefh;\n    case OP_SAVEFH:        SAVEFH4res opsavefh;\n    case OP_SECINFO:\
    \       SECINFO4res opsecinfo;\n    case OP_SETATTR:       SETATTR4res opsetattr;\n\
    \    /* Not for NFSv4.1 */\n    case OP_SETCLIENTID: SETCLIENTID4res opsetclientid;\n\
    \    /* Not for NFSv4.1 */\n    case OP_SETCLIENTID_CONFIRM:\n               \
    \            SETCLIENTID_CONFIRM4res\n    case OP_VERIFY:        VERIFY4res opverify;\n\
    \    case OP_WRITE:         WRITE4res opwrite;\n    /* Not for NFSv4.1 */\n  \
    \  case OP_RELEASE_LOCKOWNER:\n                           RELEASE_LOCKOWNER4res\n\
    \    /* Operations new to NFSv4.1 */\n    case OP_BACKCHANNEL_CTL:\n         \
    \                  BACKCHANNEL_CTL4res\n    case OP_BIND_CONN_TO_SESSION:\n  \
    \                         BIND_CONN_TO_SESSION4res\n    case OP_EXCHANGE_ID: \
    \  EXCHANGE_ID4res opexchange_id;\n    case OP_CREATE_SESSION:\n             \
    \              CREATE_SESSION4res\n    case OP_DESTROY_SESSION:\n            \
    \               DESTROY_SESSION4res\n    case OP_FREE_STATEID:  FREE_STATEID4res\n\
    \    case OP_GET_DIR_DELEGATION:\n                           GET_DIR_DELEGATION4res\n\
    \    case OP_GETDEVICEINFO: GETDEVICEINFO4res\n    case OP_GETDEVICELIST: GETDEVICELIST4res\n\
    \    case OP_LAYOUTCOMMIT:  LAYOUTCOMMIT4res oplayoutcommit;\n    case OP_LAYOUTGET:\
    \     LAYOUTGET4res oplayoutget;\n    case OP_LAYOUTRETURN:  LAYOUTRETURN4res\
    \ oplayoutreturn;\n    case OP_SECINFO_NO_NAME:\n                           SECINFO_NO_NAME4res\n\
    \    case OP_SEQUENCE:      SEQUENCE4res opsequence;\n    case OP_SET_SSV:   \
    \    SET_SSV4res opset_ssv;\n    case OP_TEST_STATEID:  TEST_STATEID4res optest_stateid;\n\
    \    case OP_WANT_DELEGATION:\n                           WANT_DELEGATION4res\n\
    \    case OP_DESTROY_CLIENTID:\n                           DESTROY_CLIENTID4res\n\
    \    case OP_RECLAIM_COMPLETE:\n                           RECLAIM_COMPLETE4res\n\
    \    /* Operations not new to NFSv4.1 */\n    case OP_ILLEGAL:       ILLEGAL4res\
    \ opillegal;\n   };\n   struct COMPOUND4res {\n           nfsstat4        status;\n\
    \           utf8str_cs      tag;\n           nfs_resop4      resarray<>;\n   };\n"
- title: 16.2.3.  DESCRIPTION
  contents:
  - "16.2.3.  DESCRIPTION\n   The COMPOUND procedure is used to combine one or more\
    \ NFSv4\n   operations into a single RPC request.  The server interprets each\
    \ of\n   the operations in turn.  If an operation is executed by the server\n\
    \   and the status of that operation is NFS4_OK, then the next operation\n   in\
    \ the COMPOUND procedure is executed.  The server continues this\n   process until\
    \ there are no more operations to be executed or until\n   one of the operations\
    \ has a status value other than NFS4_OK.\n   In the processing of the COMPOUND\
    \ procedure, the server may find that\n   it does not have the available resources\
    \ to execute any or all of the\n   operations within the COMPOUND sequence.  See\
    \ Section 2.10.6.4 for a\n   more detailed discussion.\n   The server will generally\
    \ choose between two methods of decoding the\n   client's request.  The first\
    \ would be the traditional one-pass XDR\n   decode.  If there is an XDR decoding\
    \ error in this case, the RPC XDR\n   decode error would be returned.  The second\
    \ method would be to make\n   an initial pass to decode the basic COMPOUND request\
    \ and then to XDR\n   decode the individual operations; the most interesting is\
    \ the decode\n   of attributes.  In this case, the server may encounter an XDR\
    \ decode\n   error during the second pass.  If it does, the server would return\n\
    \   the error NFS4ERR_BADXDR to signify the decode error.\n   The COMPOUND arguments\
    \ contain a \"minorversion\" field.  For NFSv4.1,\n   the value for this field\
    \ is 1.  If the server receives a COMPOUND\n   procedure with a minorversion field\
    \ value that it does not support,\n   the server MUST return an error of NFS4ERR_MINOR_VERS_MISMATCH\
    \ and a\n   zero-length resultdata array.\n   Contained within the COMPOUND results\
    \ is a \"status\" field.  If the\n   results array length is non-zero, this status\
    \ must be equivalent to\n   the status of the last operation that was executed\
    \ within the\n   COMPOUND procedure.  Therefore, if an operation incurred an error\n\
    \   then the \"status\" value will be the same error value as is being\n   returned\
    \ for the operation that failed.\n   Note that operations zero and one are not\
    \ defined for the COMPOUND\n   procedure.  Operation 2 is not defined and is reserved\
    \ for future\n   definition and use with minor versioning.  If the server receives\
    \ an\n   operation array that contains operation 2 and the minorversion field\n\
    \   has a value of zero, an error of NFS4ERR_OP_ILLEGAL, as described in\n   the\
    \ next paragraph, is returned to the client.  If an operation array\n   contains\
    \ an operation 2 and the minorversion field is non-zero and\n   the server does\
    \ not support the minor version, the server returns an\n   error of NFS4ERR_MINOR_VERS_MISMATCH.\
    \  Therefore, the\n   NFS4ERR_MINOR_VERS_MISMATCH error takes precedence over\
    \ all other\n   errors.\n   It is possible that the server receives a request\
    \ that contains an\n   operation that is less than the first legal operation (OP_ACCESS)\
    \ or\n   greater than the last legal operation (OP_RELEASE_LOCKOWNER).  In\n \
    \  this case, the server's response will encode the opcode OP_ILLEGAL\n   rather\
    \ than the illegal opcode of the request.  The status field in\n   the ILLEGAL\
    \ return results will be set to NFS4ERR_OP_ILLEGAL.  The\n   COMPOUND procedure's\
    \ return results will also be NFS4ERR_OP_ILLEGAL.\n   The definition of the \"\
    tag\" in the request is left to the\n   implementor.  It may be used to summarize\
    \ the content of the Compound\n   request for the benefit of packet-sniffers and\
    \ engineers debugging\n   implementations.  However, the value of \"tag\" in the\
    \ response SHOULD\n   be the same value as provided in the request.  This applies\
    \ to the\n   tag field of the CB_COMPOUND procedure as well.\n"
- title: 16.2.3.1.  Current Filehandle and Stateid
  contents:
  - "16.2.3.1.  Current Filehandle and Stateid\n   The COMPOUND procedure offers a\
    \ simple environment for the execution\n   of the operations specified by the\
    \ client.  The first two relate to\n   the filehandle while the second two relate\
    \ to the current stateid.\n"
- title: 16.2.3.1.1.  Current Filehandle
  contents:
  - "16.2.3.1.1.  Current Filehandle\n   The current and saved filehandles are used\
    \ throughout the protocol.\n   Most operations implicitly use the current filehandle\
    \ as an argument,\n   and many set the current filehandle as part of the results.\
    \  The\n   combination of client-specified sequences of operations and current\n\
    \   and saved filehandle arguments and results allows for greater\n   protocol\
    \ flexibility.  The best or easiest example of current\n   filehandle usage is\
    \ a sequence like the following:\n         PUTFH fh1              {fh1}\n    \
    \     LOOKUP \"compA\"         {fh2}\n         GETATTR                {fh2}\n\
    \         LOOKUP \"compB\"         {fh3}\n         GETATTR                {fh3}\n\
    \         LOOKUP \"compC\"         {fh4}\n         GETATTR                {fh4}\n\
    \         GETFH\n   In this example, the PUTFH (Section 18.19) operation explicitly\
    \ sets\n   the current filehandle value while the result of each LOOKUP\n   operation\
    \ sets the current filehandle value to the resultant file\n   system object. \
    \ Also, the client is able to insert GETATTR operations\n   using the current\
    \ filehandle as an argument.\n   The PUTROOTFH (Section 18.21) and PUTPUBFH (Section\
    \ 18.20) operations\n   also set the current filehandle.  The above example would\
    \ replace\n   \"PUTFH fh1\" with PUTROOTFH or PUTPUBFH with no filehandle argument\
    \ in\n   order to achieve the same effect (on the assumption that \"compA\" is\n\
    \   directly below the root of the namespace).\n   Along with the current filehandle,\
    \ there is a saved filehandle.\n   While the current filehandle is set as the\
    \ result of operations like\n   LOOKUP, the saved filehandle must be set directly\
    \ with the use of the\n   SAVEFH operation.  The SAVEFH operation copies the current\
    \ filehandle\n   value to the saved value.  The saved filehandle value is used\
    \ in\n   combination with the current filehandle value for the LINK and RENAME\n\
    \   operations.  The RESTOREFH operation will copy the saved filehandle\n   value\
    \ to the current filehandle value; as a result, the saved\n   filehandle value\
    \ may be used a sort of \"scratch\" area for the\n   client's series of operations.\n"
- title: 16.2.3.1.2.  Current Stateid
  contents:
  - "16.2.3.1.2.  Current Stateid\n   With NFSv4.1, additions of a current stateid\
    \ and a saved stateid have\n   been made to the COMPOUND processing environment;\
    \ this allows for the\n   passing of stateids between operations.  There are no\
    \ changes to the\n   syntax of the protocol, only changes to the semantics of\
    \ a few\n   operations.\n   A \"current stateid\" is the stateid that is associated\
    \ with the\n   current filehandle.  The current stateid may only be changed by\
    \ an\n   operation that modifies the current filehandle or returns a stateid.\n\
    \   If an operation returns a stateid, it MUST set the current stateid to\n  \
    \ the returned value.  If an operation sets the current filehandle but\n   does\
    \ not return a stateid, the current stateid MUST be set to the\n   all-zeros special\
    \ stateid, i.e., (seqid, other) = (0, 0).  If an\n   operation uses a stateid\
    \ as an argument but does not return a\n   stateid, the current stateid MUST NOT\
    \ be changed.  For example,\n   PUTFH, PUTROOTFH, and PUTPUBFH will change the\
    \ current server state\n   from {ocfh, (osid)} to {cfh, (0, 0)}, while LOCK will\
    \ change the\n   current state from {cfh, (osid} to {cfh, (nsid)}.  Operations\
    \ like\n   LOOKUP that transform a current filehandle and component name into\
    \ a\n   new current filehandle will also change the current state to {0, 0}.\n\
    \   The SAVEFH and RESTOREFH operations will save and restore both the\n   current\
    \ filehandle and the current stateid as a set.\n   The following example is the\
    \ common case of a simple READ operation\n   with a normal stateid showing that\
    \ the PUTFH initializes the current\n   stateid to (0, 0).  The subsequent READ\
    \ with stateid (sid1) leaves\n   the current stateid unchanged.\n       PUTFH\
    \ fh1                             - -> {fh1, (0, 0)}\n       READ (sid1), 0, 1024\
    \      {fh1, (0, 0)} -> {fh1, (0, 0)}\n   This next example performs an OPEN with\
    \ the root filehandle and, as a\n   result, generates stateid (sid1).  The next\
    \ operation specifies the\n   READ with the argument stateid set such that (seqid,\
    \ other) are equal\n   to (1, 0), but the current stateid set by the previous\
    \ operation is\n   actually used when the operation is evaluated.  This allows\
    \ correct\n   interaction with any existing, potentially conflicting, locks.\n\
    \       PUTROOTFH                             - -> {fh1, (0, 0)}\n       OPEN\
    \ \"compA\"              {fh1, (0, 0)} -> {fh2, (sid1)}\n       READ (1, 0), 0,\
    \ 1024      {fh2, (sid1)} -> {fh2, (sid1)}\n       CLOSE (1, 0)              {fh2,\
    \ (sid1)} -> {fh2, (sid2)}\n   This next example is similar to the second in how\
    \ it passes the\n   stateid sid2 generated by the LOCK operation to the next READ\n\
    \   operation.  This allows the client to explicitly surround a single I/\n  \
    \ O operation with a lock and its appropriate stateid to guarantee\n   correctness\
    \ with other client locks.  The example also shows how\n   SAVEFH and RESTOREFH\
    \ can save and later reuse a filehandle and\n   stateid, passing them as the current\
    \ filehandle and stateid to a READ\n   operation.\n       PUTFH fh1          \
    \                   - -> {fh1, (0, 0)}\n       LOCK 0, 1024, (sid1)      {fh1,\
    \ (sid1)} -> {fh1, (sid2)}\n       READ (1, 0), 0, 1024      {fh1, (sid2)} ->\
    \ {fh1, (sid2)}\n       LOCKU 0, 1024, (1, 0)     {fh1, (sid2)} -> {fh1, (sid3)}\n\
    \       SAVEFH                    {fh1, (sid3)} -> {fh1, (sid3)}\n       PUTFH\
    \ fh2                 {fh1, (sid3)} -> {fh2, (0, 0)}\n       WRITE (1, 0), 0,\
    \ 1024     {fh2, (0, 0)} -> {fh2, (0, 0)}\n       RESTOREFH                 {fh2,\
    \ (0, 0)} -> {fh1, (sid3)}\n       READ (1, 0), 1024, 1024   {fh1, (sid3)} ->\
    \ {fh1, (sid3)}\n   The final example shows a disallowed use of the current stateid.\
    \  The\n   client is attempting to implicitly pass an anonymous special stateid,\n\
    \   (0,0), to the READ operation.  The server MUST return\n   NFS4ERR_BAD_STATEID\
    \ in the reply to the READ operation.\n       PUTFH fh1                      \
    \       - -> {fh1, (0, 0)}\n       READ (1, 0), 0, 1024      {fh1, (0, 0)} ->\
    \ NFS4ERR_BAD_STATEID\n"
- title: 16.2.4.  ERRORS
  contents:
  - "16.2.4.  ERRORS\n   COMPOUND will of course return every error that each operation\
    \ on the\n   fore channel can return (see Table 12).  However, if COMPOUND returns\n\
    \   zero operations, obviously the error returned by COMPOUND has nothing\n  \
    \ to do with an error returned by an operation.  The list of errors\n   COMPOUND\
    \ will return if it processes zero operations include:\n    | Error          \
    \              | Notes                            |\n    | NFS4ERR_BADCHAR   \
    \           | The tag argument has a character |\n    | NFS4ERR_BADXDR       \
    \        |                                  |\n    | NFS4ERR_DELAY           \
    \     |                                  |\n    | NFS4ERR_INVAL              \
    \  | The tag argument is not in UTF-8 |\n    | NFS4ERR_MINOR_VERS_MISMATCH  |\
    \                                  |\n    | NFS4ERR_SERVERFAULT          |   \
    \                               |\n    | NFS4ERR_TOO_MANY_OPS         |      \
    \                            |\n    | NFS4ERR_REP_TOO_BIG          |         \
    \                         |\n    | NFS4ERR_REP_TOO_BIG_TO_CACHE |            \
    \                      |\n    | NFS4ERR_REQ_TOO_BIG          |               \
    \                   |\n                      Table 15: COMPOUND Error Returns\n"
- title: '17.  Operations: REQUIRED, RECOMMENDED, or OPTIONAL'
  contents:
  - "17.  Operations: REQUIRED, RECOMMENDED, or OPTIONAL\n   The following tables\
    \ summarize the operations of the NFSv4.1 protocol\n   and the corresponding designation\
    \ of REQUIRED, RECOMMENDED, and\n   OPTIONAL to implement or MUST NOT implement.\
    \  The designation of MUST\n   NOT implement is reserved for those operations\
    \ that were defined in\n   NFSv4.0 and MUST NOT be implemented in NFSv4.1.\n \
    \  For the most part, the REQUIRED, RECOMMENDED, or OPTIONAL designation\n   for\
    \ operations sent by the client is for the server implementation.\n   The client\
    \ is generally required to implement the operations needed\n   for the operating\
    \ environment for which it serves.  For example, a\n   read-only NFSv4.1 client\
    \ would have no need to implement the WRITE\n   operation and is not required\
    \ to do so.\n   The REQUIRED or OPTIONAL designation for callback operations sent\
    \ by\n   the server is for both the client and server.  Generally, the client\n\
    \   has the option of creating the backchannel and sending the operations\n  \
    \ on the fore channel that will be a catalyst for the server sending\n   callback\
    \ operations.  A partial exception is CB_RECALL_SLOT; the only\n   way the client\
    \ can avoid supporting this operation is by not creating\n   a backchannel.\n\
    \   Since this is a summary of the operations and their designation,\n   there\
    \ are subtleties that are not presented here.  Therefore, if\n   there is a question\
    \ of the requirements of implementation, the\n   operation descriptions themselves\
    \ must be consulted along with other\n   relevant explanatory text within this\
    \ specification.\n   The abbreviations used in the second and third columns of\
    \ the table\n   are defined as follows.\n   REQ  REQUIRED to implement\n   REC\
    \  RECOMMEND to implement\n   OPT  OPTIONAL to implement\n   MNI  MUST NOT implement\n\
    \   For the NFSv4.1 features that are OPTIONAL, the operations that\n   support\
    \ those features are OPTIONAL, and the server would return\n   NFS4ERR_NOTSUPP\
    \ in response to the client's use of those operations.\n   If an OPTIONAL feature\
    \ is supported, it is possible that a set of\n   operations related to the feature\
    \ become REQUIRED to implement.  The\n   third column of the table designates\
    \ the feature(s) and if the\n   operation is REQUIRED or OPTIONAL in the presence\
    \ of support for the\n   feature.\n   The OPTIONAL features identified and their\
    \ abbreviations are as\n   follows:\n   pNFS  Parallel NFS\n   FDELG  File Delegations\n\
    \   DDELG  Directory Delegations\n    | Operation            | REQ, REC,   | Feature\
    \    | Definition    |\n    |                      | OPT, or MNI | (REQ, REC,\
    \ |               |\n    | ACCESS               | REQ         |            | Section\
    \ 18.1  |\n    | BACKCHANNEL_CTL      | REQ         |            | Section 18.33\
    \ |\n    | BIND_CONN_TO_SESSION | REQ         |            | Section 18.34 |\n\
    \    | CLOSE                | REQ         |            | Section 18.2  |\n   \
    \ | COMMIT               | REQ         |            | Section 18.3  |\n    | CREATE\
    \               | REQ         |            | Section 18.4  |\n    | CREATE_SESSION\
    \       | REQ         |            | Section 18.36 |\n    | DELEGPURGE       \
    \    | OPT         | FDELG      | Section 18.5  |\n    | DELEGRETURN         \
    \ | OPT         | FDELG,     | Section 18.6  |\n    | DESTROY_CLIENTID     | REQ\
    \         |            | Section 18.50 |\n    | DESTROY_SESSION      | REQ   \
    \      |            | Section 18.37 |\n    | EXCHANGE_ID          | REQ      \
    \   |            | Section 18.35 |\n    | FREE_STATEID         | REQ         |\
    \            | Section 18.38 |\n    | GETATTR              | REQ         |   \
    \         | Section 18.7  |\n    | GETDEVICEINFO        | OPT         | pNFS (REQ)\
    \ | Section 18.40 |\n    | GETDEVICELIST        | OPT         | pNFS (OPT) | Section\
    \ 18.41 |\n    | GETFH                | REQ         |            | Section 18.8\
    \  |\n    | GET_DIR_DELEGATION   | OPT         | DDELG      | Section 18.39 |\n\
    \    | LAYOUTCOMMIT         | OPT         | pNFS (REQ) | Section 18.42 |\n   \
    \ | LAYOUTGET            | OPT         | pNFS (REQ) | Section 18.43 |\n    | LAYOUTRETURN\
    \         | OPT         | pNFS (REQ) | Section 18.44 |\n    | LINK           \
    \      | OPT         |            | Section 18.9  |\n    | LOCK              \
    \   | REQ         |            | Section 18.10 |\n    | LOCKT                |\
    \ REQ         |            | Section 18.11 |\n    | LOCKU                | REQ\
    \         |            | Section 18.12 |\n    | LOOKUP               | REQ   \
    \      |            | Section 18.13 |\n    | LOOKUPP              | REQ      \
    \   |            | Section 18.14 |\n    | NVERIFY              | REQ         |\
    \            | Section 18.15 |\n    | OPEN                 | REQ         |   \
    \         | Section 18.16 |\n    | OPENATTR             | OPT         |      \
    \      | Section 18.17 |\n    | OPEN_CONFIRM         | MNI         |         \
    \   | N/A           |\n    | OPEN_DOWNGRADE       | REQ         |            |\
    \ Section 18.18 |\n    | PUTFH                | REQ         |            | Section\
    \ 18.19 |\n    | PUTPUBFH             | REQ         |            | Section 18.20\
    \ |\n    | PUTROOTFH            | REQ         |            | Section 18.21 |\n\
    \    | READ                 | REQ         |            | Section 18.22 |\n   \
    \ | READDIR              | REQ         |            | Section 18.23 |\n    | READLINK\
    \             | OPT         |            | Section 18.24 |\n    | RECLAIM_COMPLETE\
    \     | REQ         |            | Section 18.51 |\n    | RELEASE_LOCKOWNER  \
    \  | MNI         |            | N/A           |\n    | REMOVE               |\
    \ REQ         |            | Section 18.25 |\n    | RENAME               | REQ\
    \         |            | Section 18.26 |\n    | RENEW                | MNI   \
    \      |            | N/A           |\n    | RESTOREFH            | REQ      \
    \   |            | Section 18.27 |\n    | SAVEFH               | REQ         |\
    \            | Section 18.28 |\n    | SECINFO              | REQ         |   \
    \         | Section 18.29 |\n    | SECINFO_NO_NAME      | REC         | pNFS file\
    \  | Section       |\n    | SEQUENCE             | REQ         |            |\
    \ Section 18.46 |\n    | SETATTR              | REQ         |            | Section\
    \ 18.30 |\n    | SETCLIENTID          | MNI         |            | N/A       \
    \    |\n    | SETCLIENTID_CONFIRM  | MNI         |            | N/A          \
    \ |\n    | SET_SSV              | REQ         |            | Section 18.47 |\n\
    \    | TEST_STATEID         | REQ         |            | Section 18.48 |\n   \
    \ | VERIFY               | REQ         |            | Section 18.31 |\n    | WANT_DELEGATION\
    \      | OPT         | FDELG      | Section 18.49 |\n    | WRITE             \
    \   | REQ         |            | Section 18.32 |\n                           \
    \ Table 16: Operations\n    | Operation               | REQ, REC,   | Feature\
    \    | Definition |\n    | CB_GETATTR              | OPT         | FDELG     \
    \ | Section    |\n    | CB_LAYOUTRECALL         | OPT         | pNFS (REQ) | Section\
    \    |\n    | CB_NOTIFY               | OPT         | DDELG      | Section   \
    \ |\n    | CB_NOTIFY_DEVICEID      | OPT         | pNFS (OPT) | Section    |\n\
    \    | CB_NOTIFY_LOCK          | OPT         |            | Section    |\n   \
    \ | CB_PUSH_DELEG           | OPT         | FDELG      | Section    |\n    | CB_RECALL\
    \               | OPT         | FDELG,     | Section    |\n    | CB_RECALL_ANY\
    \           | OPT         | FDELG,     | Section    |\n    | CB_RECALL_SLOT  \
    \        | REQ         |            | Section    |\n    | CB_RECALLABLE_OBJ_AVAIL\
    \ | OPT         | DDELG,     | Section    |\n    | CB_SEQUENCE             | OPT\
    \         | FDELG,     | Section    |\n    | CB_WANTS_CANCELLED      | OPT   \
    \      | FDELG,     | Section    |\n                       Table 17: Callback\
    \ Operations\n"
- title: 18.  NFSv4.1 Operations
  contents:
  - '18.  NFSv4.1 Operations

    '
- title: '18.1.  Operation 3: ACCESS - Check Access Rights'
  contents:
  - '18.1.  Operation 3: ACCESS - Check Access Rights

    '
- title: 18.1.1.  ARGUMENTS
  contents:
  - "18.1.1.  ARGUMENTS\n   const ACCESS4_READ      = 0x00000001;\n   const ACCESS4_LOOKUP\
    \    = 0x00000002;\n   const ACCESS4_MODIFY    = 0x00000004;\n   const ACCESS4_EXTEND\
    \    = 0x00000008;\n   const ACCESS4_DELETE    = 0x00000010;\n   const ACCESS4_EXECUTE\
    \   = 0x00000020;\n   struct ACCESS4args {\n           /* CURRENT_FH: object */\n\
    \           uint32_t        access;\n   };\n"
- title: 18.1.2.  RESULTS
  contents:
  - "18.1.2.  RESULTS\n   struct ACCESS4resok {\n           uint32_t        supported;\n\
    \           uint32_t        access;\n   };\n   union ACCESS4res switch (nfsstat4\
    \ status) {\n    case NFS4_OK:\n            ACCESS4resok   resok4;\n    default:\n\
    \            void;\n   };\n"
- title: 18.1.3.  DESCRIPTION
  contents:
  - "18.1.3.  DESCRIPTION\n   ACCESS determines the access rights that a user, as\
    \ identified by the\n   credentials in the RPC request, has with respect to the\
    \ file system\n   object specified by the current filehandle.  The client encodes\
    \ the\n   set of access rights that are to be checked in the bit mask \"access\"\
    .\n   The server checks the permissions encoded in the bit mask.  If a\n   status\
    \ of NFS4_OK is returned, two bit masks are included in the\n   response.  The\
    \ first, \"supported\", represents the access rights for\n   which the server\
    \ can verify reliably.  The second, \"access\",\n   represents the access rights\
    \ available to the user for the filehandle\n   provided.  On success, the current\
    \ filehandle retains its value.\n   Note that the reply's supported and access\
    \ fields MUST NOT contain\n   more values than originally set in the request's\
    \ access field.  For\n   example, if the client sends an ACCESS operation with\
    \ just the\n   ACCESS4_READ value set and the server supports this value, the\
    \ server\n   MUST NOT set more than ACCESS4_READ in the supported field even if\
    \ it\n   could have reliably checked other values.\n   The reply's access field\
    \ MUST NOT contain more values than the\n   supported field.\n   The results of\
    \ this operation are necessarily advisory in nature.  A\n   return status of NFS4_OK\
    \ and the appropriate bit set in the bit mask\n   do not imply that such access\
    \ will be allowed to the file system\n   object in the future.  This is because\
    \ access rights can be revoked\n   by the server at any time.\n   The following\
    \ access permissions may be requested:\n   ACCESS4_READ  Read data from file or\
    \ read a directory.\n   ACCESS4_LOOKUP  Look up a name in a directory (no meaning\
    \ for non-\n      directory objects).\n   ACCESS4_MODIFY  Rewrite existing file\
    \ data or modify existing\n      directory entries.\n   ACCESS4_EXTEND  Write\
    \ new data or add directory entries.\n   ACCESS4_DELETE  Delete an existing directory\
    \ entry.\n   ACCESS4_EXECUTE  Execute a regular file (no meaning for a directory).\n\
    \   On success, the current filehandle retains its value.\n   ACCESS4_EXECUTE\
    \ is a challenging semantic to implement because NFS\n   provides remote file\
    \ access, not remote execution.  This leads to the\n   following:\n   *  Whether\
    \ or not a regular file is executable ought to be the\n      responsibility of\
    \ the NFS client and not the server.  And yet the\n      ACCESS operation is specified\
    \ to seemingly require a server to own\n      that responsibility.\n   *  When\
    \ a client executes a regular file, it has to read the file\n      from the server.\
    \  Strictly speaking, the server should not allow\n      the client to read a\
    \ file being executed unless the user has read\n      permissions on the file.\
    \  Requiring explicit read permissions on\n      executable files in order to\
    \ access them over NFS is not going to\n      be acceptable to some users and\
    \ storage administrators.\n      Historically, NFS servers have allowed a user\
    \ to READ a file if\n      the user has execute access to the file.\n   As a practical\
    \ example, the UNIX specification [60] states that an\n   implementation claiming\
    \ conformance to UNIX may indicate in the\n   access() programming interface's\
    \ result that a privileged user has\n   execute rights, even if no execute permission\
    \ bits are set on the\n   regular file's attributes.  It is possible to claim\
    \ conformance to\n   the UNIX specification and instead not indicate execute rights\
    \ in\n   that situation, which is true for some operating environments.\n   Suppose\
    \ the operating environments of the client and server are\n   implementing the\
    \ access() semantics for privileged users differently,\n   and the ACCESS operation\
    \ implementations of the client and server\n   follow their respective access()\
    \ semantics.  This can cause undesired\n   behavior:\n   *  Suppose the client's\
    \ access() interface returns X_OK if the user\n      is privileged and no execute\
    \ permission bits are set on the\n      regular file's attribute, and the server's\
    \ access() interface does\n      not return X_OK in that situation.  Then the\
    \ client will be unable\n      to execute files stored on the NFS server that\
    \ could be executed\n      if stored on a non-NFS file system.\n   *  Suppose\
    \ the client's access() interface does not return X_OK if\n      the user is privileged,\
    \ and no execute permission bits are set on\n      the regular file's attribute,\
    \ and the server's access() interface\n      does return X_OK in that situation.\
    \  Then:\n      -  The client will be able to execute files stored on the NFS\n\
    \         server that could be executed if stored on a non-NFS file\n        \
    \ system, unless the client's execution subsystem also checks for\n         execute\
    \ permission bits.\n      -  Even if the execution subsystem is checking for execute\n\
    \         permission bits, there are more potential issues.  For example,\n  \
    \       suppose the client is invoking access() to build a \"path search\n   \
    \      table\" of all executable files in the user's \"search path\",\n      \
    \   where the path is a list of directories each containing\n         executable\
    \ files.  Suppose there are two files each in separate\n         directories of\
    \ the search path, such that files have the same\n         component name.  In\
    \ the first directory the file has no execute\n         permission bits set, and\
    \ in the second directory the file has\n         execute bits set.  The path search\
    \ table will indicate that the\n         first directory has the executable file,\
    \ but the execute\n         subsystem will fail to execute it.  The command shell\
    \ might\n         fail to try the second file in the second directory.  And even\n\
    \         if it did, this is a potential performance issue.  Clearly, the\n  \
    \       desired outcome for the client is for the path search table to\n     \
    \    not contain the first file.\n   To deal with the problems described above,\
    \ the \"smart client, stupid\n   server\" principle is used.  The client owns\
    \ overall responsibility\n   for determining execute access and relies on the\
    \ server to parse the\n   execution permissions within the file's mode, acl, and\
    \ dacl\n   attributes.  The rules for the client and server follow:\n   *  If\
    \ the client is sending ACCESS in order to determine if the user\n      can read\
    \ the file, the client SHOULD set ACCESS4_READ in the\n      request's access\
    \ field.\n   *  If the client's operating environment only grants execution to\
    \ the\n      user if the user has execute access according to the execute\n  \
    \    permissions in the mode, acl, and dacl attributes, then if the\n      client\
    \ wants to determine execute access, the client SHOULD send\n      an ACCESS request\
    \ with ACCESS4_EXECUTE bit set in the request's\n      access field.\n   *  If\
    \ the client's operating environment grants execution to the user\n      even\
    \ if the user does not have execute access according to the\n      execute permissions\
    \ in the mode, acl, and dacl attributes, then if\n      the client wants to determine\
    \ execute access, it SHOULD send an\n      ACCESS request with both the ACCESS4_EXECUTE\
    \ and ACCESS4_READ bits\n      set in the request's access field.  This way, if\
    \ any read or\n      execute permission grants the user read or execute access\
    \ (or if\n      the server interprets the user as privileged), as indicated by\
    \ the\n      presence of ACCESS4_EXECUTE and/or ACCESS4_READ in the reply's\n\
    \      access field, the client will be able to grant the user execute\n     \
    \ access to the file.\n   *  If the server supports execute permission bits, or\
    \ some other\n      method for denoting executability (e.g., the suffix of the\
    \ name of\n      the file might indicate execute), it MUST check only execute\n\
    \      permissions, not read permissions, when determining whether or not\n  \
    \    the reply will have ACCESS4_EXECUTE set in the access field.  The\n     \
    \ server MUST NOT also examine read permission bits when determining\n      whether\
    \ or not the reply will have ACCESS4_EXECUTE set in the\n      access field. \
    \ Even if the server's operating environment would\n      grant execute access\
    \ to the user (e.g., the user is privileged),\n      the server MUST NOT reply\
    \ with ACCESS4_EXECUTE set in reply's\n      access field unless there is at least\
    \ one execute permission bit\n      set in the mode, acl, or dacl attributes.\
    \  In the case of acl and\n      dacl, the \"one execute permission bit\" MUST\
    \ be an ACE4_EXECUTE bit\n      set in an ALLOW ACE.\n   *  If the server does\
    \ not support execute permission bits or some\n      other method for denoting\
    \ executability, it MUST NOT set\n      ACCESS4_EXECUTE in the reply's supported\
    \ and access fields.  If\n      the client set ACCESS4_EXECUTE in the ACCESS request's\
    \ access\n      field, and ACCESS4_EXECUTE is not set in the reply's supported\n\
    \      field, then the client will have to send an ACCESS request with\n     \
    \ the ACCESS4_READ bit set in the request's access field.\n   *  If the server\
    \ supports read permission bits, it MUST only check\n      for read permissions\
    \ in the mode, acl, and dacl attributes when it\n      receives an ACCESS request\
    \ with ACCESS4_READ set in the access\n      field.  The server MUST NOT also\
    \ examine execute permission bits\n      when determining whether the reply will\
    \ have ACCESS4_READ set in\n      the access field or not.\n   Note that if the\
    \ ACCESS reply has ACCESS4_READ or ACCESS_EXECUTE set,\n   then the user also\
    \ has permissions to OPEN (Section 18.16) or READ\n   (Section 18.22) the file.\
    \  In other words, if the client sends an\n   ACCESS request with the ACCESS4_READ\
    \ and ACCESS_EXECUTE set in the\n   access field (or two separate requests, one\
    \ with ACCESS4_READ set and\n   the other with ACCESS4_EXECUTE set), and the reply\
    \ has just\n   ACCESS4_EXECUTE set in the access field (or just one reply has\n\
    \   ACCESS4_EXECUTE set), then the user has authorization to OPEN or READ\n  \
    \ the file.\n"
- title: 18.1.4.  IMPLEMENTATION
  contents:
  - "18.1.4.  IMPLEMENTATION\n   In general, it is not sufficient for the client to\
    \ attempt to deduce\n   access permissions by inspecting the uid, gid, and mode\
    \ fields in the\n   file attributes or by attempting to interpret the contents\
    \ of the ACL\n   attribute.  This is because the server may perform uid or gid\
    \ mapping\n   or enforce additional access-control restrictions.  It is also\n\
    \   possible that the server may not be in the same ID space as the\n   client.\
    \  In these cases (and perhaps others), the client cannot\n   reliably perform\
    \ an access check with only current file attributes.\n   In the NFSv2 protocol,\
    \ the only reliable way to determine whether an\n   operation was allowed was\
    \ to try it and see if it succeeded or\n   failed.  Using the ACCESS operation\
    \ in the NFSv4.1 protocol, the\n   client can ask the server to indicate whether\
    \ or not one or more\n   classes of operations are permitted.  The ACCESS operation\
    \ is\n   provided to allow clients to check before doing a series of\n   operations\
    \ that will result in an access failure.  The OPEN operation\n   provides a point\
    \ where the server can verify access to the file\n   object and a method to return\
    \ that information to the client.  The\n   ACCESS operation is still useful for\
    \ directory operations or for use\n   in the case that the UNIX interface access()\
    \ is used on the client.\n   The information returned by the server in response\
    \ to an ACCESS call\n   is not permanent.  It was correct at the exact time that\
    \ the server\n   performed the checks, but not necessarily afterwards.  The server\
    \ can\n   revoke access permission at any time.\n   The client should use the\
    \ effective credentials of the user to build\n   the authentication information\
    \ in the ACCESS request used to\n   determine access rights.  It is the effective\
    \ user and group\n   credentials that are used in subsequent READ and WRITE operations.\n\
    \   Many implementations do not directly support the ACCESS4_DELETE\n   permission.\
    \  Operating systems like UNIX will ignore the\n   ACCESS4_DELETE bit if set on\
    \ an access request on a non-directory\n   object.  In these systems, delete permission\
    \ on a file is determined\n   by the access permissions on the directory in which\
    \ the file resides,\n   instead of being determined by the permissions of the\
    \ file itself.\n   Therefore, the mask returned enumerating which access rights\
    \ can be\n   determined will have the ACCESS4_DELETE value set to 0.  This\n \
    \  indicates to the client that the server was unable to check that\n   particular\
    \ access right.  The ACCESS4_DELETE bit in the access mask\n   returned will then\
    \ be ignored by the client.\n"
- title: '18.2.  Operation 4: CLOSE - Close File'
  contents:
  - '18.2.  Operation 4: CLOSE - Close File

    '
- title: 18.2.1.  ARGUMENTS
  contents:
  - "18.2.1.  ARGUMENTS\n   struct CLOSE4args {\n           /* CURRENT_FH: object\
    \ */\n           seqid4          seqid;\n           stateid4        open_stateid;\n\
    \   };\n"
- title: 18.2.2.  RESULTS
  contents:
  - "18.2.2.  RESULTS\n   union CLOSE4res switch (nfsstat4 status) {\n    case NFS4_OK:\n\
    \            stateid4       open_stateid;\n    default:\n            void;\n \
    \  };\n"
- title: 18.2.3.  DESCRIPTION
  contents:
  - "18.2.3.  DESCRIPTION\n   The CLOSE operation releases share reservations for\
    \ the regular or\n   named attribute file as specified by the current filehandle.\
    \  The\n   share reservations and other state information released at the server\n\
    \   as a result of this CLOSE are only those associated with the supplied\n  \
    \ stateid.  State associated with other OPENs is not affected.\n   If byte-range\
    \ locks are held, the client SHOULD release all locks\n   before sending a CLOSE.\
    \  The server MAY free all outstanding locks on\n   CLOSE, but some servers may\
    \ not support the CLOSE of a file that\n   still has byte-range locks held.  The\
    \ server MUST return failure if\n   any locks would exist after the CLOSE.\n \
    \  The argument seqid MAY have any value, and the server MUST ignore\n   seqid.\n\
    \   On success, the current filehandle retains its value.\n   The server MAY require\
    \ that the combination of principal, security\n   flavor, and, if applicable,\
    \ GSS mechanism that sent the OPEN request\n   also be the one to CLOSE the file.\
    \  This might not be possible if\n   credentials for the principal are no longer\
    \ available.  The server\n   MAY allow the machine credential or SSV credential\
    \ (see\n   Section 18.35) to send CLOSE.\n"
- title: 18.2.4.  IMPLEMENTATION
  contents:
  - "18.2.4.  IMPLEMENTATION\n   Even though CLOSE returns a stateid, this stateid\
    \ is not useful to\n   the client and should be treated as deprecated.  CLOSE\
    \ \"shuts down\"\n   the state associated with all OPENs for the file by a single\
    \ open-\n   owner.  As noted above, CLOSE will either release all file-locking\n\
    \   state or return an error.  Therefore, the stateid returned by CLOSE\n   is\
    \ not useful for operations that follow.  To help find any uses of\n   this stateid\
    \ by clients, the server SHOULD return the invalid special\n   stateid (the \"\
    other\" value is zero and the \"seqid\" field is\n   NFS4_UINT32_MAX, see Section\
    \ 8.2.3).\n   A CLOSE operation may make delegations grantable where they were\
    \ not\n   previously.  Servers may choose to respond immediately if there are\n\
    \   pending delegation want requests or may respond to the situation at a\n  \
    \ later time.\n"
- title: '18.3.  Operation 5: COMMIT - Commit Cached Data'
  contents:
  - '18.3.  Operation 5: COMMIT - Commit Cached Data

    '
- title: 18.3.1.  ARGUMENTS
  contents:
  - "18.3.1.  ARGUMENTS\n   struct COMMIT4args {\n           /* CURRENT_FH: file */\n\
    \           offset4         offset;\n           count4          count;\n   };\n"
- title: 18.3.2.  RESULTS
  contents:
  - "18.3.2.  RESULTS\n   struct COMMIT4resok {\n           verifier4       writeverf;\n\
    \   };\n   union COMMIT4res switch (nfsstat4 status) {\n    case NFS4_OK:\n  \
    \          COMMIT4resok   resok4;\n    default:\n            void;\n   };\n"
- title: 18.3.3.  DESCRIPTION
  contents:
  - "18.3.3.  DESCRIPTION\n   The COMMIT operation forces or flushes uncommitted,\
    \ modified data to\n   stable storage for the file specified by the current filehandle.\
    \  The\n   flushed data is that which was previously written with one or more\n\
    \   WRITE operations that had the \"committed\" field of their results\n   field\
    \ set to UNSTABLE4.\n   The offset specifies the position within the file where\
    \ the flush is\n   to begin.  An offset value of zero means to flush data starting\
    \ at\n   the beginning of the file.  The count specifies the number of bytes\n\
    \   of data to flush.  If the count is zero, a flush from the offset to\n   the\
    \ end of the file is done.\n   The server returns a write verifier upon successful\
    \ completion of the\n   COMMIT.  The write verifier is used by the client to determine\
    \ if the\n   server has restarted between the initial WRITE operations and the\n\
    \   COMMIT.  The client does this by comparing the write verifier\n   returned\
    \ from the initial WRITE operations and the verifier returned\n   by the COMMIT\
    \ operation.  The server must vary the value of the write\n   verifier at each\
    \ server event or instantiation that may lead to a\n   loss of uncommitted data.\
    \  Most commonly this occurs when the server\n   is restarted; however, other\
    \ events at the server may result in\n   uncommitted data loss as well.\n   On\
    \ success, the current filehandle retains its value.\n"
- title: 18.3.4.  IMPLEMENTATION
  contents:
  - "18.3.4.  IMPLEMENTATION\n   The COMMIT operation is similar in operation and\
    \ semantics to the\n   POSIX fsync() [22] system interface that synchronizes a\
    \ file's state\n   with the disk (file data and metadata is flushed to disk or\
    \ stable\n   storage).  COMMIT performs the same operation for a client, flushing\n\
    \   any unsynchronized data and metadata on the server to the server's\n   disk\
    \ or stable storage for the specified file.  Like fsync(), it may\n   be that\
    \ there is some modified data or no modified data to\n   synchronize.  The data\
    \ may have been synchronized by the server's\n   normal periodic buffer synchronization\
    \ activity.  COMMIT should\n   return NFS4_OK, unless there has been an unexpected\
    \ error.\n   COMMIT differs from fsync() in that it is possible for the client\
    \ to\n   flush a range of the file (most likely triggered by a buffer-\n   reclamation\
    \ scheme on the client before the file has been completely\n   written).\n   The\
    \ server implementation of COMMIT is reasonably simple.  If the\n   server receives\
    \ a full file COMMIT request, that is, starting at\n   offset zero and count zero,\
    \ it should do the equivalent of applying\n   fsync() to the entire file.  Otherwise,\
    \ it should arrange to have the\n   modified data in the range specified by offset\
    \ and count to be\n   flushed to stable storage.  In both cases, any metadata\
    \ associated\n   with the file must be flushed to stable storage before returning.\
    \  It\n   is not an error for there to be nothing to flush on the server.  This\n\
    \   means that the data and metadata that needed to be flushed have\n   already\
    \ been flushed or lost during the last server failure.\n   The client implementation\
    \ of COMMIT is a little more complex.  There\n   are two reasons for wanting to\
    \ commit a client buffer to stable\n   storage.  The first is that the client\
    \ wants to reuse a buffer.  In\n   this case, the offset and count of the buffer\
    \ are sent to the server\n   in the COMMIT request.  The server then flushes any\
    \ modified data\n   based on the offset and count, and flushes any modified metadata\n\
    \   associated with the file.  It then returns the status of the flush\n   and\
    \ the write verifier.  The second reason for the client to generate\n   a COMMIT\
    \ is for a full file flush, such as may be done at close.  In\n   this case, the\
    \ client would gather all of the buffers for this file\n   that contain uncommitted\
    \ data, do the COMMIT operation with an offset\n   of zero and count of zero,\
    \ and then free all of those buffers.  Any\n   other dirty buffers would be sent\
    \ to the server in the normal\n   fashion.\n   After a buffer is written (via\
    \ the WRITE operation) by the client\n   with the \"committed\" field in the result\
    \ of WRITE set to UNSTABLE4,\n   the buffer must be considered as modified by\
    \ the client until the\n   buffer has either been flushed via a COMMIT operation\
    \ or written via\n   a WRITE operation with the \"committed\" field in the result\
    \ set to\n   FILE_SYNC4 or DATA_SYNC4.  This is done to prevent the buffer from\n\
    \   being freed and reused before the data can be flushed to stable\n   storage\
    \ on the server.\n   When a response is returned from either a WRITE or a COMMIT\
    \ operation\n   and it contains a write verifier that differs from that previously\n\
    \   returned by the server, the client will need to retransmit all of the\n  \
    \ buffers containing uncommitted data to the server.  How this is to be\n   done\
    \ is up to the implementor.  If there is only one buffer of\n   interest, then\
    \ it should be sent in a WRITE request with the\n   FILE_SYNC4 stable parameter.\
    \  If there is more than one buffer, it\n   might be worthwhile retransmitting\
    \ all of the buffers in WRITE\n   operations with the stable parameter set to\
    \ UNSTABLE4 and then\n   retransmitting the COMMIT operation to flush all of the\
    \ data on the\n   server to stable storage.  However, if the server repeatably\
    \ returns\n   from COMMIT a verifier that differs from that returned by WRITE,\
    \ the\n   only way to ensure progress is to retransmit all of the buffers with\n\
    \   WRITE requests with the FILE_SYNC4 stable parameter.\n   The above description\
    \ applies to page-cache-based systems as well as\n   buffer-cache-based systems.\
    \  In the former systems, the virtual\n   memory system will need to be modified\
    \ instead of the buffer cache.\n"
- title: '18.4.  Operation 6: CREATE - Create a Non-Regular File Object'
  contents:
  - '18.4.  Operation 6: CREATE - Create a Non-Regular File Object

    '
- title: 18.4.1.  ARGUMENTS
  contents:
  - "18.4.1.  ARGUMENTS\n   union createtype4 switch (nfs_ftype4 type) {\n    case\
    \ NF4LNK:\n            linktext4 linkdata;\n    case NF4BLK:\n    case NF4CHR:\n\
    \            specdata4 devdata;\n    case NF4SOCK:\n    case NF4FIFO:\n    case\
    \ NF4DIR:\n            void;\n    default:\n            void;  /* server should\
    \ return NFS4ERR_BADTYPE */\n   };\n   struct CREATE4args {\n           /* CURRENT_FH:\
    \ directory for creation */\n           createtype4     objtype;\n           component4\
    \      objname;\n           fattr4          createattrs;\n   };\n"
- title: 18.4.2.  RESULTS
  contents:
  - "18.4.2.  RESULTS\n   struct CREATE4resok {\n           change_info4    cinfo;\n\
    \           bitmap4         attrset;        /* attributes set */\n   };\n   union\
    \ CREATE4res switch (nfsstat4 status) {\n    case NFS4_OK:\n            /* new\
    \ CURRENTFH: created object */\n            CREATE4resok resok4;\n    default:\n\
    \            void;\n   };\n"
- title: 18.4.3.  DESCRIPTION
  contents:
  - "18.4.3.  DESCRIPTION\n   The CREATE operation creates a file object other than\
    \ an ordinary\n   file in a directory with a given name.  The OPEN operation MUST\
    \ be\n   used to create a regular file or a named attribute.\n   The current filehandle\
    \ must be a directory: an object of type NF4DIR.\n   If the current filehandle\
    \ is an attribute directory (type\n   NF4ATTRDIR), the error NFS4ERR_WRONG_TYPE\
    \ is returned.  If the\n   current filehandle designates any other type of object,\
    \ the error\n   NFS4ERR_NOTDIR results.\n   The objname specifies the name for\
    \ the new object.  The objtype\n   determines the type of object to be created:\
    \ directory, symlink, etc.\n   If the object type specified is that of an ordinary\
    \ file, a named\n   attribute, or a named attribute directory, the error NFS4ERR_BADTYPE\n\
    \   results.\n   If an object of the same name already exists in the directory,\
    \ the\n   server will return the error NFS4ERR_EXIST.\n   For the directory where\
    \ the new file object was created, the server\n   returns change_info4 information\
    \ in cinfo.  With the atomic field of\n   the change_info4 data type, the server\
    \ will indicate if the before\n   and after change attributes were obtained atomically\
    \ with respect to\n   the file object creation.\n   If the objname has a length\
    \ of zero, or if objname does not obey the\n   UTF-8 definition, the error NFS4ERR_INVAL\
    \ will be returned.\n   The current filehandle is replaced by that of the new\
    \ object.\n   The createattrs specifies the initial set of attributes for the\n\
    \   object.  The set of attributes may include any writable attribute\n   valid\
    \ for the object type.  When the operation is successful, the\n   server will\
    \ return to the client an attribute mask signifying which\n   attributes were\
    \ successfully set for the object.\n   If createattrs includes neither the owner\
    \ attribute nor an ACL with\n   an ACE for the owner, and if the server's file\
    \ system both supports\n   and requires an owner attribute (or an owner ACE),\
    \ then the server\n   MUST derive the owner (or the owner ACE).  This would typically\
    \ be\n   from the principal indicated in the RPC credentials of the call, but\n\
    \   the server's operating environment or file system semantics may\n   dictate\
    \ other methods of derivation.  Similarly, if createattrs\n   includes neither\
    \ the group attribute nor a group ACE, and if the\n   server's file system both\
    \ supports and requires the notion of a group\n   attribute (or group ACE), the\
    \ server MUST derive the group attribute\n   (or the corresponding owner ACE)\
    \ for the file.  This could be from\n   the RPC call's credentials, such as the\
    \ group principal if the\n   credentials include it (such as with AUTH_SYS), from\
    \ the group\n   identifier associated with the principal in the credentials (e.g.,\n\
    \   POSIX systems have a user database [23] that has a group identifier\n   for\
    \ every user identifier), inherited from the directory in which the\n   object\
    \ is created, or whatever else the server's operating\n   environment or file\
    \ system semantics dictate.  This applies to the\n   OPEN operation too.\n   Conversely,\
    \ it is possible that the client will specify in\n   createattrs an owner attribute,\
    \ group attribute, or ACL that the\n   principal indicated the RPC call's credentials\
    \ does not have\n   permissions to create files for.  The error to be returned\
    \ in this\n   instance is NFS4ERR_PERM.  This applies to the OPEN operation too.\n\
    \   If the current filehandle designates a directory for which another\n   client\
    \ holds a directory delegation, then, unless the delegation is\n   such that the\
    \ situation can be resolved by sending a notification,\n   the delegation MUST\
    \ be recalled, and the CREATE operation MUST NOT\n   proceed until the delegation\
    \ is returned or revoked.  Except where\n   this happens very quickly, one or\
    \ more NFS4ERR_DELAY errors will be\n   returned to requests made while delegation\
    \ remains outstanding.\n   When the current filehandle designates a directory\
    \ for which one or\n   more directory delegations exist, then, when those delegations\n\
    \   request such notifications, NOTIFY4_ADD_ENTRY will be generated as a\n   result\
    \ of this operation.\n   If the capability FSCHARSET_CAP4_ALLOWS_ONLY_UTF8 is\
    \ set\n   (Section 14.4), and a symbolic link is being created, then the\n   content\
    \ of the symbolic link MUST be in UTF-8 encoding.\n"
- title: 18.4.4.  IMPLEMENTATION
  contents:
  - "18.4.4.  IMPLEMENTATION\n   If the client desires to set attribute values after\
    \ the create, a\n   SETATTR operation can be added to the COMPOUND request so\
    \ that the\n   appropriate attributes will be set.\n"
- title: '18.5.  Operation 7: DELEGPURGE - Purge Delegations Awaiting Recovery'
  contents:
  - '18.5.  Operation 7: DELEGPURGE - Purge Delegations Awaiting Recovery

    '
- title: 18.5.1.  ARGUMENTS
  contents:
  - "18.5.1.  ARGUMENTS\n   struct DELEGPURGE4args {\n           clientid4       clientid;\n\
    \   };\n"
- title: 18.5.2.  RESULTS
  contents:
  - "18.5.2.  RESULTS\n   struct DELEGPURGE4res {\n           nfsstat4        status;\n\
    \   };\n"
- title: 18.5.3.  DESCRIPTION
  contents:
  - "18.5.3.  DESCRIPTION\n   This operation purges all of the delegations awaiting\
    \ recovery for a\n   given client.  This is useful for clients that do not commit\n\
    \   delegation information to stable storage to indicate that conflicting\n  \
    \ requests need not be delayed by the server awaiting recovery of\n   delegation\
    \ information.\n   The client is NOT specified by the clientid field of the request.\n\
    \   The client SHOULD set the client field to zero, and the server MUST\n   ignore\
    \ the clientid field.  Instead, the server MUST derive the\n   client ID from\
    \ the value of the session ID in the arguments of the\n   SEQUENCE operation that\
    \ precedes DELEGPURGE in the COMPOUND request.\n   The DELEGPURGE operation should\
    \ be used by clients that record\n   delegation information on stable storage\
    \ on the client.  In this\n   case, after the client recovers all delegations\
    \ it knows of, it\n   should immediately send a DELEGPURGE operation.  Doing so\
    \ will notify\n   the server that no additional delegations for the client will\
    \ be\n   recovered allowing it to free resources, and avoid delaying other\n \
    \  clients which make requests that conflict with the unrecovered\n   delegations.\
    \  The set of delegations known to the server and the\n   client might be different.\
    \  The reason for this is that after sending\n   a request that resulted in a\
    \ delegation, the client might experience\n   a failure before it both received\
    \ the delegation and committed the\n   delegation to the client's stable storage.\n\
    \   The server MAY support DELEGPURGE, but if it does not, it MUST NOT\n   support\
    \ CLAIM_DELEGATE_PREV and MUST NOT support CLAIM_DELEG_PREV_FH.\n"
- title: '18.6.  Operation 8: DELEGRETURN - Return Delegation'
  contents:
  - '18.6.  Operation 8: DELEGRETURN - Return Delegation

    '
- title: 18.6.1.  ARGUMENTS
  contents:
  - "18.6.1.  ARGUMENTS\n   struct DELEGRETURN4args {\n           /* CURRENT_FH: delegated\
    \ object */\n           stateid4        deleg_stateid;\n   };\n"
- title: 18.6.2.  RESULTS
  contents:
  - "18.6.2.  RESULTS\n   struct DELEGRETURN4res {\n           nfsstat4        status;\n\
    \   };\n"
- title: 18.6.3.  DESCRIPTION
  contents:
  - "18.6.3.  DESCRIPTION\n   The DELEGRETURN operation returns the delegation represented\
    \ by the\n   current filehandle and stateid.\n   Delegations may be returned voluntarily\
    \ (i.e., before the server has\n   recalled them) or when recalled.  In either\
    \ case, the client must\n   properly propagate state changed under the context\
    \ of the delegation\n   to the server before returning the delegation.\n   The\
    \ server MAY require that the principal, security flavor, and if\n   applicable,\
    \ the GSS mechanism, combination that acquired the\n   delegation also be the\
    \ one to send DELEGRETURN on the file.  This\n   might not be possible if credentials\
    \ for the principal are no longer\n   available.  The server MAY allow the machine\
    \ credential or SSV\n   credential (see Section 18.35) to send DELEGRETURN.\n"
- title: '18.7.  Operation 9: GETATTR - Get Attributes'
  contents:
  - '18.7.  Operation 9: GETATTR - Get Attributes

    '
- title: 18.7.1.  ARGUMENTS
  contents:
  - "18.7.1.  ARGUMENTS\n   struct GETATTR4args {\n           /* CURRENT_FH: object\
    \ */\n           bitmap4         attr_request;\n   };\n"
- title: 18.7.2.  RESULTS
  contents:
  - "18.7.2.  RESULTS\n   struct GETATTR4resok {\n           fattr4          obj_attributes;\n\
    \   };\n   union GETATTR4res switch (nfsstat4 status) {\n    case NFS4_OK:\n \
    \           GETATTR4resok  resok4;\n    default:\n            void;\n   };\n"
- title: 18.7.3.  DESCRIPTION
  contents:
  - "18.7.3.  DESCRIPTION\n   The GETATTR operation will obtain attributes for the\
    \ file system\n   object specified by the current filehandle.  The client sets\
    \ a bit in\n   the bitmap argument for each attribute value that it would like\
    \ the\n   server to return.  The server returns an attribute bitmap that\n   indicates\
    \ the attribute values that it was able to return, which will\n   include all\
    \ attributes requested by the client that are attributes\n   supported by the\
    \ server for the target file system.  This bitmap is\n   followed by the attribute\
    \ values ordered lowest attribute number\n   first.\n   The server MUST return\
    \ a value for each attribute that the client\n   requests if the attribute is\
    \ supported by the server for the target\n   file system.  If the server does\
    \ not support a particular attribute\n   on the target file system, then it MUST\
    \ NOT return the attribute\n   value and MUST NOT set the attribute bit in the\
    \ result bitmap.  The\n   server MUST return an error if it supports an attribute\
    \ on the target\n   but cannot obtain its value.  In that case, no attribute values\
    \ will\n   be returned.\n   File systems that are absent should be treated as\
    \ having support for\n   a very small set of attributes as described in Section\
    \ 11.4.1, even\n   if previously, when the file system was present, more attributes\
    \ were\n   supported.\n   All servers MUST support the REQUIRED attributes as\
    \ specified in\n   Section 5.6, for all file systems, with the exception of absent\
    \ file\n   systems.\n   On success, the current filehandle retains its value.\n"
- title: 18.7.4.  IMPLEMENTATION
  contents:
  - "18.7.4.  IMPLEMENTATION\n   Suppose there is an OPEN_DELEGATE_WRITE delegation\
    \ held by another\n   client for the file in question and size and/or change are\
    \ among the\n   set of attributes being interrogated.  The server has two choices.\n\
    \   First, the server can obtain the actual current value of these\n   attributes\
    \ from the client holding the delegation by using the\n   CB_GETATTR callback.\
    \  Second, the server, particularly when the\n   delegated client is unresponsive,\
    \ can recall the delegation in\n   question.  The GETATTR MUST NOT proceed until\
    \ one of the following\n   occurs:\n   *  The requested attribute values are returned\
    \ in the response to\n      CB_GETATTR.\n   *  The OPEN_DELEGATE_WRITE delegation\
    \ is returned.\n   *  The OPEN_DELEGATE_WRITE delegation is revoked.\n   Unless\
    \ one of the above happens very quickly, one or more\n   NFS4ERR_DELAY errors\
    \ will be returned while a delegation is\n   outstanding.\n"
- title: '18.8.  Operation 10: GETFH - Get Current Filehandle'
  contents:
  - '18.8.  Operation 10: GETFH - Get Current Filehandle

    '
- title: 18.8.1.  ARGUMENTS
  contents:
  - "18.8.1.  ARGUMENTS\n   /* CURRENT_FH: */\n   void;\n"
- title: 18.8.2.  RESULTS
  contents:
  - "18.8.2.  RESULTS\n   struct GETFH4resok {\n           nfs_fh4         object;\n\
    \   };\n   union GETFH4res switch (nfsstat4 status) {\n    case NFS4_OK:\n   \
    \        GETFH4resok     resok4;\n    default:\n           void;\n   };\n"
- title: 18.8.3.  DESCRIPTION
  contents:
  - "18.8.3.  DESCRIPTION\n   This operation returns the current filehandle value.\n\
    \   On success, the current filehandle retains its value.\n   As described in\
    \ Section 2.10.6.4, GETFH is REQUIRED or RECOMMENDED to\n   immediately follow\
    \ certain operations, and servers are free to reject\n   such operations if the\
    \ client fails to insert GETFH in the request as\n   REQUIRED or RECOMMENDED.\
    \  Section 18.16.4.1 provides additional\n   justification for why GETFH MUST\
    \ follow OPEN.\n"
- title: 18.8.4.  IMPLEMENTATION
  contents:
  - "18.8.4.  IMPLEMENTATION\n   Operations that change the current filehandle like\
    \ LOOKUP or CREATE\n   do not automatically return the new filehandle as a result.\
    \  For\n   instance, if a client needs to look up a directory entry and obtain\n\
    \   its filehandle, then the following request is needed.\n      PUTFH (directory\
    \ filehandle)\n      LOOKUP (entry name)\n      GETFH\n"
- title: '18.9.  Operation 11: LINK - Create Link to a File'
  contents:
  - '18.9.  Operation 11: LINK - Create Link to a File

    '
- title: 18.9.1.  ARGUMENTS
  contents:
  - "18.9.1.  ARGUMENTS\n   struct LINK4args {\n           /* SAVED_FH: source object\
    \ */\n           /* CURRENT_FH: target directory */\n           component4   \
    \   newname;\n   };\n"
- title: 18.9.2.  RESULTS
  contents:
  - "18.9.2.  RESULTS\n   struct LINK4resok {\n           change_info4    cinfo;\n\
    \   };\n   union LINK4res switch (nfsstat4 status) {\n    case NFS4_OK:\n    \
    \        LINK4resok resok4;\n    default:\n            void;\n   };\n"
- title: 18.9.3.  DESCRIPTION
  contents:
  - "18.9.3.  DESCRIPTION\n   The LINK operation creates an additional newname for\
    \ the file\n   represented by the saved filehandle, as set by the SAVEFH operation,\n\
    \   in the directory represented by the current filehandle.  The existing\n  \
    \ file and the target directory must reside within the same file system\n   on\
    \ the server.  On success, the current filehandle will continue to\n   be the\
    \ target directory.  If an object exists in the target directory\n   with the\
    \ same name as newname, the server must return NFS4ERR_EXIST.\n   For the target\
    \ directory, the server returns change_info4 information\n   in cinfo.  With the\
    \ atomic field of the change_info4 data type, the\n   server will indicate if\
    \ the before and after change attributes were\n   obtained atomically with respect\
    \ to the link creation.\n   If the newname has a length of zero, or if newname\
    \ does not obey the\n   UTF-8 definition, the error NFS4ERR_INVAL will be returned.\n"
- title: 18.9.4.  IMPLEMENTATION
  contents:
  - "18.9.4.  IMPLEMENTATION\n   The server MAY impose restrictions on the LINK operation\
    \ such that\n   LINK may not be done when the file is open or when that open is\
    \ done\n   by particular protocols, or with particular options or access modes.\n\
    \   When LINK is rejected because of such restrictions, the error\n   NFS4ERR_FILE_OPEN\
    \ is returned.\n   If a server does implement such restrictions and those restrictions\n\
    \   include cases of NFSv4 opens preventing successful execution of a\n   link,\
    \ the server needs to recall any delegations that could hide the\n   existence\
    \ of opens relevant to that decision.  The reason is that\n   when a client holds\
    \ a delegation, the server might not have an\n   accurate account of the opens\
    \ for that client, since the client may\n   execute OPENs and CLOSEs locally.\
    \  The LINK operation must be delayed\n   only until a definitive result can be\
    \ obtained.  For example, suppose\n   there are multiple delegations and one of\
    \ them establishes an open\n   whose presence would prevent the link.  Given the\
    \ server's semantics,\n   NFS4ERR_FILE_OPEN may be returned to the caller as soon\
    \ as that\n   delegation is returned without waiting for other delegations to\
    \ be\n   returned.  Similarly, if such opens are not associated with\n   delegations,\
    \ NFS4ERR_FILE_OPEN can be returned immediately with no\n   delegation recall\
    \ being done.\n   If the current filehandle designates a directory for which another\n\
    \   client holds a directory delegation, then, unless the delegation is\n   such\
    \ that the situation can be resolved by sending a notification,\n   the delegation\
    \ MUST be recalled, and the operation cannot be\n   performed successfully until\
    \ the delegation is returned or revoked.\n   Except where this happens very quickly,\
    \ one or more NFS4ERR_DELAY\n   errors will be returned to requests made while\
    \ delegation remains\n   outstanding.\n   When the current filehandle designates\
    \ a directory for which one or\n   more directory delegations exist, then, when\
    \ those delegations\n   request such notifications, instead of a recall, NOTIFY4_ADD_ENTRY\n\
    \   will be generated as a result of the LINK operation.\n   If the current file\
    \ system supports the numlinks attribute, and other\n   clients have delegations\
    \ to the file being linked, then those\n   delegations MUST be recalled and the\
    \ LINK operation MUST NOT proceed\n   until all delegations are returned or revoked.\
    \  Except where this\n   happens very quickly, one or more NFS4ERR_DELAY errors\
    \ will be\n   returned to requests made while delegation remains outstanding.\n\
    \   Changes to any property of the \"hard\" linked files are reflected in\n  \
    \ all of the linked files.  When a link is made to a file, the\n   attributes\
    \ for the file should have a value for numlinks that is one\n   greater than the\
    \ value before the LINK operation.\n   The statement \"file and the target directory\
    \ must reside within the\n   same file system on the server\" means that the fsid\
    \ fields in the\n   attributes for the objects are the same.  If they reside on\
    \ different\n   file systems, the error NFS4ERR_XDEV is returned.  This error\
    \ may be\n   returned by some servers when there is an internal partitioning of\
    \ a\n   file system that the LINK operation would violate.\n   On some servers,\
    \ \".\" and \"..\" are illegal values for newname and the\n   error NFS4ERR_BADNAME\
    \ will be returned if they are specified.\n   When the current filehandle designates\
    \ a named attribute directory\n   and the object to be linked (the saved filehandle)\
    \ is not a named\n   attribute for the same object, the error NFS4ERR_XDEV MUST\
    \ be\n   returned.  When the saved filehandle designates a named attribute and\n\
    \   the current filehandle is not the appropriate named attribute\n   directory,\
    \ the error NFS4ERR_XDEV MUST also be returned.\n   When the current filehandle\
    \ designates a named attribute directory\n   and the object to be linked (the\
    \ saved filehandle) is a named\n   attribute within that directory, the server\
    \ may return the error\n   NFS4ERR_NOTSUPP.\n   In the case that newname is already\
    \ linked to the file represented by\n   the saved filehandle, the server will\
    \ return NFS4ERR_EXIST.\n   Note that symbolic links are created with the CREATE\
    \ operation.\n"
- title: '18.10.  Operation 12: LOCK - Create Lock'
  contents:
  - '18.10.  Operation 12: LOCK - Create Lock

    '
- title: 18.10.1.  ARGUMENTS
  contents:
  - "18.10.1.  ARGUMENTS\n   /*\n    * For LOCK, transition from open_stateid and\
    \ lock_owner\n    * to a lock stateid.\n    */\n   struct open_to_lock_owner4\
    \ {\n           seqid4          open_seqid;\n           stateid4        open_stateid;\n\
    \           seqid4          lock_seqid;\n           lock_owner4     lock_owner;\n\
    \   };\n   /*\n    * For LOCK, existing lock stateid continues to request new\n\
    \    * file lock for the same lock_owner and open_stateid.\n    */\n   struct\
    \ exist_lock_owner4 {\n           stateid4        lock_stateid;\n           seqid4\
    \          lock_seqid;\n   };\n   union locker4 switch (bool new_lock_owner) {\n\
    \    case TRUE:\n           open_to_lock_owner4     open_owner;\n    case FALSE:\n\
    \           exist_lock_owner4       lock_owner;\n   };\n   /*\n    * LOCK/LOCKT/LOCKU:\
    \ Record lock management\n    */\n   struct LOCK4args {\n           /* CURRENT_FH:\
    \ file */\n           nfs_lock_type4  locktype;\n           bool            reclaim;\n\
    \           offset4         offset;\n           length4         length;\n    \
    \       locker4         locker;\n   };\n"
- title: 18.10.2.  RESULTS
  contents:
  - "18.10.2.  RESULTS\n   struct LOCK4denied {\n           offset4         offset;\n\
    \           length4         length;\n           nfs_lock_type4  locktype;\n  \
    \         lock_owner4     owner;\n   };\n   struct LOCK4resok {\n           stateid4\
    \        lock_stateid;\n   };\n   union LOCK4res switch (nfsstat4 status) {\n\
    \    case NFS4_OK:\n            LOCK4resok     resok4;\n    case NFS4ERR_DENIED:\n\
    \            LOCK4denied    denied;\n    default:\n            void;\n   };\n"
- title: 18.10.3.  DESCRIPTION
  contents:
  - "18.10.3.  DESCRIPTION\n   The LOCK operation requests a byte-range lock for the\
    \ byte-range\n   specified by the offset and length parameters, and lock type\n\
    \   specified in the locktype parameter.  If this is a reclaim request,\n   the\
    \ reclaim parameter will be TRUE.\n   Bytes in a file may be locked even if those\
    \ bytes are not currently\n   allocated to the file.  To lock the file from a\
    \ specific offset\n   through the end-of-file (no matter how long the file actually\
    \ is) use\n   a length field equal to NFS4_UINT64_MAX.  The server MUST return\n\
    \   NFS4ERR_INVAL under the following combinations of length and offset:\n   *\
    \  Length is equal to zero.\n   *  Length is not equal to NFS4_UINT64_MAX, and\
    \ the sum of length and\n      offset exceeds NFS4_UINT64_MAX.\n   32-bit servers\
    \ are servers that support locking for byte offsets that\n   fit within 32 bits\
    \ (i.e., less than or equal to NFS4_UINT32_MAX).  If\n   the client specifies\
    \ a range that overlaps one or more bytes beyond\n   offset NFS4_UINT32_MAX but\
    \ does not end at offset NFS4_UINT64_MAX,\n   then such a 32-bit server MUST return\
    \ the error NFS4ERR_BAD_RANGE.\n   If the server returns NFS4ERR_DENIED, the owner,\
    \ offset, and length\n   of a conflicting lock are returned.\n   The locker argument\
    \ specifies the lock-owner that is associated with\n   the LOCK operation.  The\
    \ locker4 structure is a switched union that\n   indicates whether the client\
    \ has already created byte-range locking\n   state associated with the current\
    \ open file and lock-owner.  In the\n   case in which it has, the argument is\
    \ just a stateid representing the\n   set of locks associated with that open file\
    \ and lock-owner, together\n   with a lock_seqid value that MAY be any value and\
    \ MUST be ignored by\n   the server.  In the case where no byte-range locking\
    \ state has been\n   established, or the client does not have the stateid available,\
    \ the\n   argument contains the stateid of the open file with which this lock\n\
    \   is to be associated, together with the lock-owner with which the lock\n  \
    \ is to be associated.  The open_to_lock_owner case covers the very\n   first\
    \ lock done by a lock-owner for a given open file and offers a\n   method to use\
    \ the established state of the open_stateid to transition\n   to the use of a\
    \ lock stateid.\n   The following fields of the locker parameter MAY be set to\
    \ any value\n   by the client and MUST be ignored by the server:\n   *  The clientid\
    \ field of the lock_owner field of the open_owner field\n      (locker.open_owner.lock_owner.clientid).\
    \  The reason the server\n      MUST ignore the clientid field is that the server\
    \ MUST derive the\n      client ID from the session ID from the SEQUENCE operation\
    \ of the\n      COMPOUND request.\n   *  The open_seqid and lock_seqid fields\
    \ of the open_owner field\n      (locker.open_owner.open_seqid and locker.open_owner.lock_seqid).\n\
    \   *  The lock_seqid field of the lock_owner field\n      (locker.lock_owner.lock_seqid).\n\
    \   Note that the client ID appearing in a LOCK4denied structure is the\n   actual\
    \ client associated with the conflicting lock, whether this is\n   the client\
    \ ID associated with the current session or a different one.\n   Thus, if the\
    \ server returns NFS4ERR_DENIED, it MUST set the clientid\n   field of the owner\
    \ field of the denied field.\n   If the current filehandle is not an ordinary\
    \ file, an error will be\n   returned to the client.  In the case that the current\
    \ filehandle\n   represents an object of type NF4DIR, NFS4ERR_ISDIR is returned.\
    \  If\n   the current filehandle designates a symbolic link, NFS4ERR_SYMLINK is\n\
    \   returned.  In all other cases, NFS4ERR_WRONG_TYPE is returned.\n   On success,\
    \ the current filehandle retains its value.\n"
- title: 18.10.4.  IMPLEMENTATION
  contents:
  - "18.10.4.  IMPLEMENTATION\n   If the server is unable to determine the exact offset\
    \ and length of\n   the conflicting byte-range lock, the same offset and length\
    \ that were\n   provided in the arguments should be returned in the denied results.\n\
    \   LOCK operations are subject to permission checks and to checks\n   against\
    \ the access type of the associated file.  However, the\n   specific right and\
    \ modes required for various types of locks reflect\n   the semantics of the server-exported\
    \ file system, and are not\n   specified by the protocol.  For example, Windows\
    \ 2000 allows a write\n   lock of a file open for read access, while a POSIX-compliant\
    \ system\n   does not.\n   When the client sends a LOCK operation that corresponds\
    \ to a range\n   that the lock-owner has locked already (with the same or different\n\
    \   lock type), or to a sub-range of such a range, or to a byte-range\n   that\
    \ includes multiple locks already granted to that lock-owner, in\n   whole or\
    \ in part, and the server does not support such locking\n   operations (i.e.,\
    \ does not support POSIX locking semantics), the\n   server will return the error\
    \ NFS4ERR_LOCK_RANGE.  In that case, the\n   client may return an error, or it\
    \ may emulate the required\n   operations, using only LOCK for ranges that do\
    \ not include any bytes\n   already locked by that lock-owner and LOCKU of locks\
    \ held by that\n   lock-owner (specifying an exactly matching range and type).\n\
    \   Similarly, when the client sends a LOCK operation that amounts to\n   upgrading\
    \ (changing from a READ_LT lock to a WRITE_LT lock) or\n   downgrading (changing\
    \ from WRITE_LT lock to a READ_LT lock) an\n   existing byte-range lock, and the\
    \ server does not support such a\n   lock, the server will return NFS4ERR_LOCK_NOTSUPP.\
    \  Such operations\n   may not perfectly reflect the required semantics in the\
    \ face of\n   conflicting LOCK operations from other clients.\n   When a client\
    \ holds an OPEN_DELEGATE_WRITE delegation, the client\n   holding that delegation\
    \ is assured that there are no opens by other\n   clients.  Thus, there can be\
    \ no conflicting LOCK operations from such\n   clients.  Therefore, the client\
    \ may be handling locking requests\n   locally, without doing LOCK operations\
    \ on the server.  If it does\n   that, it must be prepared to update the lock\
    \ status on the server, by\n   sending appropriate LOCK and LOCKU operations before\
    \ returning the\n   delegation.\n   When one or more clients hold OPEN_DELEGATE_READ\
    \ delegations, any\n   LOCK operation where the server is implementing mandatory\
    \ locking\n   semantics MUST result in the recall of all such delegations.  The\n\
    \   LOCK operation may not be granted until all such delegations are\n   returned\
    \ or revoked.  Except where this happens very quickly, one or\n   more NFS4ERR_DELAY\
    \ errors will be returned to requests made while the\n   delegation remains outstanding.\n"
- title: '18.11.  Operation 13: LOCKT - Test for Lock'
  contents:
  - '18.11.  Operation 13: LOCKT - Test for Lock

    '
- title: 18.11.1.  ARGUMENTS
  contents:
  - "18.11.1.  ARGUMENTS\n   struct LOCKT4args {\n           /* CURRENT_FH: file */\n\
    \           nfs_lock_type4  locktype;\n           offset4         offset;\n  \
    \         length4         length;\n           lock_owner4     owner;\n   };\n"
- title: 18.11.2.  RESULTS
  contents:
  - "18.11.2.  RESULTS\n   union LOCKT4res switch (nfsstat4 status) {\n    case NFS4ERR_DENIED:\n\
    \            LOCK4denied    denied;\n    case NFS4_OK:\n            void;\n  \
    \  default:\n            void;\n   };\n"
- title: 18.11.3.  DESCRIPTION
  contents:
  - "18.11.3.  DESCRIPTION\n   The LOCKT operation tests the lock as specified in\
    \ the arguments.  If\n   a conflicting lock exists, the owner, offset, length,\
    \ and type of the\n   conflicting lock are returned.  The owner field in the results\n\
    \   includes the client ID of the owner of the conflicting lock, whether\n   this\
    \ is the client ID associated with the current session or a\n   different client\
    \ ID.  If no lock is held, nothing other than NFS4_OK\n   is returned.  Lock types\
    \ READ_LT and READW_LT are processed in the\n   same way in that a conflicting\
    \ lock test is done without regard to\n   blocking or non-blocking.  The same\
    \ is true for WRITE_LT and\n   WRITEW_LT.\n   The ranges are specified as for\
    \ LOCK.  The NFS4ERR_INVAL and\n   NFS4ERR_BAD_RANGE errors are returned under\
    \ the same circumstances as\n   for LOCK.\n   The clientid field of the owner\
    \ MAY be set to any value by the client\n   and MUST be ignored by the server.\
    \  The reason the server MUST ignore\n   the clientid field is that the server\
    \ MUST derive the client ID from\n   the session ID from the SEQUENCE operation\
    \ of the COMPOUND request.\n   If the current filehandle is not an ordinary file,\
    \ an error will be\n   returned to the client.  In the case that the current filehandle\n\
    \   represents an object of type NF4DIR, NFS4ERR_ISDIR is returned.  If\n   the\
    \ current filehandle designates a symbolic link, NFS4ERR_SYMLINK is\n   returned.\
    \  In all other cases, NFS4ERR_WRONG_TYPE is returned.\n   On success, the current\
    \ filehandle retains its value.\n"
- title: 18.11.4.  IMPLEMENTATION
  contents:
  - "18.11.4.  IMPLEMENTATION\n   If the server is unable to determine the exact offset\
    \ and length of\n   the conflicting lock, the same offset and length that were\
    \ provided\n   in the arguments should be returned in the denied results.\n  \
    \ LOCKT uses a lock_owner4 rather a stateid4, as is used in LOCK to\n   identify\
    \ the owner.  This is because the client does not have to open\n   the file to\
    \ test for the existence of a lock, so a stateid might not\n   be available.\n\
    \   As noted in Section 18.10.4, some servers may return\n   NFS4ERR_LOCK_RANGE\
    \ to certain (otherwise non-conflicting) LOCK\n   operations that overlap ranges\
    \ already granted to the current lock-\n   owner.\n   The LOCKT operation's test\
    \ for conflicting locks SHOULD exclude locks\n   for the current lock-owner, and\
    \ thus should return NFS4_OK in such\n   cases.  Note that this means that a server\
    \ might return NFS4_OK to a\n   LOCKT request even though a LOCK operation for\
    \ the same range and\n   lock-owner would fail with NFS4ERR_LOCK_RANGE.\n   When\
    \ a client holds an OPEN_DELEGATE_WRITE delegation, it may choose\n   (see Section\
    \ 18.10.4) to handle LOCK requests locally.  In such a\n   case, LOCKT requests\
    \ will similarly be handled locally.\n"
- title: '18.12.  Operation 14: LOCKU - Unlock File'
  contents:
  - '18.12.  Operation 14: LOCKU - Unlock File

    '
- title: 18.12.1.  ARGUMENTS
  contents:
  - "18.12.1.  ARGUMENTS\n   struct LOCKU4args {\n           /* CURRENT_FH: file */\n\
    \           nfs_lock_type4  locktype;\n           seqid4          seqid;\n   \
    \        stateid4        lock_stateid;\n           offset4         offset;\n \
    \          length4         length;\n   };\n"
- title: 18.12.2.  RESULTS
  contents:
  - "18.12.2.  RESULTS\n   union LOCKU4res switch (nfsstat4 status) {\n    case  \
    \ NFS4_OK:\n            stateid4       lock_stateid;\n    default:\n         \
    \   void;\n   };\n"
- title: 18.12.3.  DESCRIPTION
  contents:
  - "18.12.3.  DESCRIPTION\n   The LOCKU operation unlocks the byte-range lock specified\
    \ by the\n   parameters.  The client may set the locktype field to any value that\n\
    \   is legal for the nfs_lock_type4 enumerated type, and the server MUST\n   accept\
    \ any legal value for locktype.  Any legal value for locktype\n   has no effect\
    \ on the success or failure of the LOCKU operation.\n   The ranges are specified\
    \ as for LOCK.  The NFS4ERR_INVAL and\n   NFS4ERR_BAD_RANGE errors are returned\
    \ under the same circumstances as\n   for LOCK.\n   The seqid parameter MAY be\
    \ any value and the server MUST ignore it.\n   If the current filehandle is not\
    \ an ordinary file, an error will be\n   returned to the client.  In the case\
    \ that the current filehandle\n   represents an object of type NF4DIR, NFS4ERR_ISDIR\
    \ is returned.  If\n   the current filehandle designates a symbolic link, NFS4ERR_SYMLINK\
    \ is\n   returned.  In all other cases, NFS4ERR_WRONG_TYPE is returned.\n   On\
    \ success, the current filehandle retains its value.\n   The server MAY require\
    \ that the principal, security flavor, and if\n   applicable, the GSS mechanism,\
    \ combination that sent a LOCK operation\n   also be the one to send LOCKU on\
    \ the file.  This might not be\n   possible if credentials for the principal are\
    \ no longer available.\n   The server MAY allow the machine credential or SSV\
    \ credential (see\n   Section 18.35) to send LOCKU.\n"
- title: 18.12.4.  IMPLEMENTATION
  contents:
  - "18.12.4.  IMPLEMENTATION\n   If the area to be unlocked does not correspond exactly\
    \ to a lock\n   actually held by the lock-owner, the server may return the error\n\
    \   NFS4ERR_LOCK_RANGE.  This includes the case in which the area is not\n   locked,\
    \ where the area is a sub-range of the area locked, where it\n   overlaps the\
    \ area locked without matching exactly, or the area\n   specified includes multiple\
    \ locks held by the lock-owner.  In all of\n   these cases, allowed by POSIX locking\
    \ [21] semantics, a client\n   receiving this error should, if it desires support\
    \ for such\n   operations, simulate the operation using LOCKU on ranges\n   corresponding\
    \ to locks it actually holds, possibly followed by LOCK\n   operations for the\
    \ sub-ranges not being unlocked.\n   When a client holds an OPEN_DELEGATE_WRITE\
    \ delegation, it may choose\n   (see Section 18.10.4) to handle LOCK requests\
    \ locally.  In such a\n   case, LOCKU operations will similarly be handled locally.\n"
- title: '18.13.  Operation 15: LOOKUP - Lookup Filename'
  contents:
  - '18.13.  Operation 15: LOOKUP - Lookup Filename

    '
- title: 18.13.1.  ARGUMENTS
  contents:
  - "18.13.1.  ARGUMENTS\n   struct LOOKUP4args {\n           /* CURRENT_FH: directory\
    \ */\n           component4      objname;\n   };\n"
- title: 18.13.2.  RESULTS
  contents:
  - "18.13.2.  RESULTS\n   struct LOOKUP4res {\n           /* New CURRENT_FH: object\
    \ */\n           nfsstat4        status;\n   };\n"
- title: 18.13.3.  DESCRIPTION
  contents:
  - "18.13.3.  DESCRIPTION\n   The LOOKUP operation looks up or finds a file system\
    \ object using the\n   directory specified by the current filehandle.  LOOKUP\
    \ evaluates the\n   component and if the object exists, the current filehandle\
    \ is\n   replaced with the component's filehandle.\n   If the component cannot\
    \ be evaluated either because it does not exist\n   or because the client does\
    \ not have permission to evaluate the\n   component, then an error will be returned\
    \ and the current filehandle\n   will be unchanged.\n   If the component is a\
    \ zero-length string or if any component does not\n   obey the UTF-8 definition,\
    \ the error NFS4ERR_INVAL will be returned.\n"
- title: 18.13.4.  IMPLEMENTATION
  contents:
  - "18.13.4.  IMPLEMENTATION\n   If the client wants to achieve the effect of a multi-component\
    \ look\n   up, it may construct a COMPOUND request such as (and obtain each\n\
    \   filehandle):\n         PUTFH  (directory filehandle)\n         LOOKUP \"pub\"\
    \n         GETFH\n         LOOKUP \"foo\"\n         GETFH\n         LOOKUP \"\
    bar\"\n         GETFH\n   Unlike NFSv3, NFSv4.1 allows LOOKUP requests to cross\
    \ mountpoints on\n   the server.  The client can detect a mountpoint crossing\
    \ by comparing\n   the fsid attribute of the directory with the fsid attribute\
    \ of the\n   directory looked up.  If the fsids are different, then the new\n\
    \   directory is a server mountpoint.  UNIX clients that detect a\n   mountpoint\
    \ crossing will need to mount the server's file system.\n   This needs to be done\
    \ to maintain the file object identity checking\n   mechanisms common to UNIX\
    \ clients.\n   Servers that limit NFS access to \"shared\" or \"exported\" file\
    \ systems\n   should provide a pseudo file system into which the exported file\n\
    \   systems can be integrated, so that clients can browse the server's\n   namespace.\
    \  The clients view of a pseudo file system will be limited\n   to paths that\
    \ lead to exported file systems.\n   Note: previous versions of the protocol assigned\
    \ special semantics to\n   the names \".\" and \"..\".  NFSv4.1 assigns no special\
    \ semantics to\n   these names.  The LOOKUPP operator must be used to look up\
    \ a parent\n   directory.\n   Note that this operation does not follow symbolic\
    \ links.  The client\n   is responsible for all parsing of filenames including\
    \ filenames that\n   are modified by symbolic links encountered during the look\
    \ up\n   process.\n   If the current filehandle supplied is not a directory but\
    \ a symbolic\n   link, the error NFS4ERR_SYMLINK is returned as the error.  For\
    \ all\n   other non-directory file types, the error NFS4ERR_NOTDIR is returned.\n"
- title: '18.14.  Operation 16: LOOKUPP - Lookup Parent Directory'
  contents:
  - '18.14.  Operation 16: LOOKUPP - Lookup Parent Directory

    '
- title: 18.14.1.  ARGUMENTS
  contents:
  - "18.14.1.  ARGUMENTS\n   /* CURRENT_FH: object */\n   void;\n"
- title: 18.14.2.  RESULTS
  contents:
  - "18.14.2.  RESULTS\n   struct LOOKUPP4res {\n           /* new CURRENT_FH: parent\
    \ directory */\n           nfsstat4        status;\n   };\n"
- title: 18.14.3.  DESCRIPTION
  contents:
  - "18.14.3.  DESCRIPTION\n   The current filehandle is assumed to refer to a regular\
    \ directory or\n   a named attribute directory.  LOOKUPP assigns the filehandle\
    \ for its\n   parent directory to be the current filehandle.  If there is no parent\n\
    \   directory, an NFS4ERR_NOENT error must be returned.  Therefore,\n   NFS4ERR_NOENT\
    \ will be returned by the server when the current\n   filehandle is at the root\
    \ or top of the server's file tree.\n   As is the case with LOOKUP, LOOKUPP will\
    \ also cross mountpoints.\n   If the current filehandle is not a directory or\
    \ named attribute\n   directory, the error NFS4ERR_NOTDIR is returned.\n   If\
    \ the requester's security flavor does not match that configured for\n   the parent\
    \ directory, then the server SHOULD return NFS4ERR_WRONGSEC\n   (a future minor\
    \ revision of NFSv4 may upgrade this to MUST) in the\n   LOOKUPP response.  However,\
    \ if the server does so, it MUST support\n   the SECINFO_NO_NAME operation (Section\
    \ 18.45), so that the client can\n   gracefully determine the correct security\
    \ flavor.\n   If the current filehandle is a named attribute directory that is\n\
    \   associated with a file system object via OPENATTR (i.e., not a sub-\n   directory\
    \ of a named attribute directory), LOOKUPP SHOULD return the\n   filehandle of\
    \ the associated file system object.\n"
- title: 18.14.4.  IMPLEMENTATION
  contents:
  - "18.14.4.  IMPLEMENTATION\n   An issue to note is upward navigation from named\
    \ attribute\n   directories.  The named attribute directories are essentially\n\
    \   detached from the namespace, and this property should be safely\n   represented\
    \ in the client operating environment.  LOOKUPP on a named\n   attribute directory\
    \ may return the filehandle of the associated file,\n   and conveying this to\
    \ applications might be unsafe as many\n   applications expect the parent of an\
    \ object to always be a directory.\n   Therefore, the client may want to hide\
    \ the parent of named attribute\n   directories (represented as \"..\" in UNIX)\
    \ or represent the named\n   attribute directory as its own parent (as is typically\
    \ done for the\n   file system root directory in UNIX).\n"
- title: '18.15.  Operation 17: NVERIFY - Verify Difference in Attributes'
  contents:
  - '18.15.  Operation 17: NVERIFY - Verify Difference in Attributes

    '
- title: 18.15.1.  ARGUMENTS
  contents:
  - "18.15.1.  ARGUMENTS\n   struct NVERIFY4args {\n           /* CURRENT_FH: object\
    \ */\n           fattr4          obj_attributes;\n   };\n"
- title: 18.15.2.  RESULTS
  contents:
  - "18.15.2.  RESULTS\n   struct NVERIFY4res {\n           nfsstat4        status;\n\
    \   };\n"
- title: 18.15.3.  DESCRIPTION
  contents:
  - "18.15.3.  DESCRIPTION\n   This operation is used to prefix a sequence of operations\
    \ to be\n   performed if one or more attributes have changed on some file system\n\
    \   object.  If all the attributes match, then the error NFS4ERR_SAME\n   MUST\
    \ be returned.\n   On success, the current filehandle retains its value.\n"
- title: 18.15.4.  IMPLEMENTATION
  contents:
  - "18.15.4.  IMPLEMENTATION\n   This operation is useful as a cache validation operator.\
    \  If the\n   object to which the attributes belong has changed, then the following\n\
    \   operations may obtain new data associated with that object, for\n   instance,\
    \ to check if a file has been changed and obtain new data if\n   it has:\n   \
    \      SEQUENCE\n         PUTFH fh\n         NVERIFY attrbits attrs\n        \
    \ READ 0 32767\n   Contrast this with NFSv3, which would first send a GETATTR\
    \ in one\n   request/reply round trip, and then if attributes indicated that the\n\
    \   client's cache was stale, then send a READ in another request/reply\n   round\
    \ trip.\n   In the case that a RECOMMENDED attribute is specified in the NVERIFY\n\
    \   operation and the server does not support that attribute for the file\n  \
    \ system object, the error NFS4ERR_ATTRNOTSUPP is returned to the\n   client.\n\
    \   When the attribute rdattr_error or any set-only attribute (e.g.,\n   time_modify_set)\
    \ is specified, the error NFS4ERR_INVAL is returned to\n   the client.\n"
- title: '18.16.  Operation 18: OPEN - Open a Regular File'
  contents:
  - '18.16.  Operation 18: OPEN - Open a Regular File

    '
- title: 18.16.1.  ARGUMENTS
  contents:
  - "18.16.1.  ARGUMENTS\n   /*\n    * Various definitions for OPEN\n    */\n   enum\
    \ createmode4 {\n           UNCHECKED4      = 0,\n           GUARDED4        =\
    \ 1,\n           /* Deprecated in NFSv4.1. */\n           EXCLUSIVE4      = 2,\n\
    \           /*\n            * New to NFSv4.1. If session is persistent,\n    \
    \        * GUARDED4 MUST be used.  Otherwise, use\n            * EXCLUSIVE4_1\
    \ instead of EXCLUSIVE4.\n            */\n           EXCLUSIVE4_1    = 3\n   };\n\
    \   struct creatverfattr {\n            verifier4      cva_verf;\n           \
    \ fattr4         cva_attrs;\n   };\n   union createhow4 switch (createmode4 mode)\
    \ {\n    case UNCHECKED4:\n    case GUARDED4:\n            fattr4         createattrs;\n\
    \    case EXCLUSIVE4:\n            verifier4      createverf;\n    case EXCLUSIVE4_1:\n\
    \            creatverfattr  ch_createboth;\n   };\n   enum opentype4 {\n     \
    \      OPEN4_NOCREATE  = 0,\n           OPEN4_CREATE    = 1\n   };\n   union openflag4\
    \ switch (opentype4 opentype) {\n    case OPEN4_CREATE:\n            createhow4\
    \     how;\n    default:\n            void;\n   };\n   /* Next definitions used\
    \ for OPEN delegation */\n   enum limit_by4 {\n           NFS_LIMIT_SIZE     \
    \     = 1,\n           NFS_LIMIT_BLOCKS        = 2\n           /* others as needed\
    \ */\n   };\n   struct nfs_modified_limit4 {\n           uint32_t        num_blocks;\n\
    \           uint32_t        bytes_per_block;\n   };\n   union nfs_space_limit4\
    \ switch (limit_by4 limitby) {\n    /* limit specified as file size */\n    case\
    \ NFS_LIMIT_SIZE:\n            uint64_t               filesize;\n    /* limit\
    \ specified by number of blocks */\n    case NFS_LIMIT_BLOCKS:\n            nfs_modified_limit4\
    \    mod_blocks;\n   } ;\n   /*\n    * Share Access and Deny constants for open\
    \ argument\n    */\n   const OPEN4_SHARE_ACCESS_READ   = 0x00000001;\n   const\
    \ OPEN4_SHARE_ACCESS_WRITE  = 0x00000002;\n   const OPEN4_SHARE_ACCESS_BOTH  \
    \ = 0x00000003;\n   const OPEN4_SHARE_DENY_NONE     = 0x00000000;\n   const OPEN4_SHARE_DENY_READ\
    \     = 0x00000001;\n   const OPEN4_SHARE_DENY_WRITE    = 0x00000002;\n   const\
    \ OPEN4_SHARE_DENY_BOTH     = 0x00000003;\n   /* new flags for share_access field\
    \ of OPEN4args */\n   const OPEN4_SHARE_ACCESS_WANT_DELEG_MASK        = 0xFF00;\n\
    \   const OPEN4_SHARE_ACCESS_WANT_NO_PREFERENCE     = 0x0000;\n   const OPEN4_SHARE_ACCESS_WANT_READ_DELEG\
    \        = 0x0100;\n   const OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG       = 0x0200;\n\
    \   const OPEN4_SHARE_ACCESS_WANT_ANY_DELEG         = 0x0300;\n   const OPEN4_SHARE_ACCESS_WANT_NO_DELEG\
    \          = 0x0400;\n   const OPEN4_SHARE_ACCESS_WANT_CANCEL            = 0x0500;\n\
    \   const\n    OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL\n    = 0x10000;\n\
    \   const\n    OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED\n    = 0x20000;\n\
    \   enum open_delegation_type4 {\n           OPEN_DELEGATE_NONE      = 0,\n  \
    \         OPEN_DELEGATE_READ      = 1,\n           OPEN_DELEGATE_WRITE     = 2,\n\
    \           OPEN_DELEGATE_NONE_EXT  = 3 /* new to v4.1 */\n   };\n   enum open_claim_type4\
    \ {\n           /*\n            * Not a reclaim.\n            */\n           CLAIM_NULL\
    \              = 0,\n           CLAIM_PREVIOUS          = 1,\n           CLAIM_DELEGATE_CUR\
    \      = 2,\n           CLAIM_DELEGATE_PREV     = 3,\n           /*\n        \
    \    * Not a reclaim.\n            *\n            * Like CLAIM_NULL, but object\
    \ identified\n            * by the current filehandle.\n            */\n     \
    \      CLAIM_FH                = 4, /* new to v4.1 */\n           /*\n       \
    \     * Like CLAIM_DELEGATE_CUR, but object identified\n            * by current\
    \ filehandle.\n            */\n           CLAIM_DELEG_CUR_FH      = 5, /* new\
    \ to v4.1 */\n           /*\n            * Like CLAIM_DELEGATE_PREV, but object\
    \ identified\n            * by current filehandle.\n            */\n         \
    \  CLAIM_DELEG_PREV_FH     = 6 /* new to v4.1 */\n   };\n   struct open_claim_delegate_cur4\
    \ {\n           stateid4        delegate_stateid;\n           component4     \
    \ file;\n   };\n   union open_claim4 switch (open_claim_type4 claim) {\n    /*\n\
    \     * No special rights to file.\n     * Ordinary OPEN of the specified file.\n\
    \     */\n    case CLAIM_NULL:\n           /* CURRENT_FH: directory */\n     \
    \      component4      file;\n    /*\n     * Right to the file established by\
    \ an\n     * open previous to server reboot.  File\n     * identified by filehandle\
    \ obtained at\n     * that time rather than by name.\n     */\n    case CLAIM_PREVIOUS:\n\
    \           /* CURRENT_FH: file being reclaimed */\n           open_delegation_type4\
    \   delegate_type;\n    /*\n     * Right to file based on a delegation\n     *\
    \ granted by the server.  File is\n     * specified by name.\n     */\n    case\
    \ CLAIM_DELEGATE_CUR:\n           /* CURRENT_FH: directory */\n           open_claim_delegate_cur4\
    \        delegate_cur_info;\n    /*\n     * Right to file based on a delegation\n\
    \     * granted to a previous boot instance\n     * of the client.  File is specified\
    \ by name.\n     */\n    case CLAIM_DELEGATE_PREV:\n            /* CURRENT_FH:\
    \ directory */\n           component4      file_delegate_prev;\n    /*\n     *\
    \ Like CLAIM_NULL.  No special rights\n     * to file.  Ordinary OPEN of the\n\
    \     * specified file by current filehandle.\n     */\n    case CLAIM_FH: /*\
    \ new to v4.1 */\n           /* CURRENT_FH: regular file to open */\n        \
    \   void;\n    /*\n     * Like CLAIM_DELEGATE_PREV.  Right to file based on a\n\
    \     * delegation granted to a previous boot\n     * instance of the client.\
    \  File is identified\n     * by filehandle.\n     */\n    case CLAIM_DELEG_PREV_FH:\
    \ /* new to v4.1 */\n           /* CURRENT_FH: file being opened */\n        \
    \   void;\n    /*\n     * Like CLAIM_DELEGATE_CUR.  Right to file based on\n \
    \    * a delegation granted by the server.\n     * File is identified by filehandle.\n\
    \     */\n    case CLAIM_DELEG_CUR_FH: /* new to v4.1 */\n            /* CURRENT_FH:\
    \ file being opened */\n            stateid4       oc_delegate_stateid;\n   };\n\
    \   /*\n    * OPEN: Open a file, potentially receiving an OPEN delegation\n  \
    \  */\n   struct OPEN4args {\n           seqid4          seqid;\n           uint32_t\
    \        share_access;\n           uint32_t        share_deny;\n           open_owner4\
    \     owner;\n           openflag4       openhow;\n           open_claim4    \
    \ claim;\n   };\n"
- title: 18.16.2.  RESULTS
  contents:
  - "18.16.2.  RESULTS\n   struct open_read_delegation4 {\n    stateid4 stateid; \
    \   /* Stateid for delegation*/\n    bool     recall;     /* Pre-recalled flag\
    \ for\n                            delegations obtained\n                    \
    \        by reclaim (CLAIM_PREVIOUS) */\n    nfsace4 permissions; /* Defines users\
    \ who don't\n                            need an ACCESS call to\n            \
    \                open for read */\n   };\n   struct open_write_delegation4 {\n\
    \    stateid4 stateid;      /* Stateid for delegation */\n    bool     recall;\
    \       /* Pre-recalled flag for\n                              delegations obtained\n\
    \                              by reclaim\n                              (CLAIM_PREVIOUS)\
    \ */\n    nfs_space_limit4\n              space_limit; /* Defines condition that\n\
    \                              the client must check to\n                    \
    \          determine whether the\n                              file needs to\
    \ be flushed\n                              to the server on close.  */\n    nfsace4\
    \   permissions; /* Defines users who don't\n                              need\
    \ an ACCESS call as\n                              part of a delegated\n     \
    \                         open. */\n   };\n   enum why_no_delegation4 { /* new\
    \ to v4.1 */\n           WND4_NOT_WANTED         = 0,\n           WND4_CONTENTION\
    \         = 1,\n           WND4_RESOURCE           = 2,\n           WND4_NOT_SUPP_FTYPE\
    \     = 3,\n           WND4_WRITE_DELEG_NOT_SUPP_FTYPE = 4,\n           WND4_NOT_SUPP_UPGRADE\
    \   = 5,\n           WND4_NOT_SUPP_DOWNGRADE = 6,\n           WND4_CANCELLED \
    \         = 7,\n           WND4_IS_DIR             = 8\n   };\n   union open_none_delegation4\
    \ /* new to v4.1 */\n   switch (why_no_delegation4 ond_why) {\n           case\
    \ WND4_CONTENTION:\n                   bool ond_server_will_push_deleg;\n    \
    \       case WND4_RESOURCE:\n                   bool ond_server_will_signal_avail;\n\
    \           default:\n                   void;\n   };\n   union open_delegation4\n\
    \   switch (open_delegation_type4 delegation_type) {\n           case OPEN_DELEGATE_NONE:\n\
    \                   void;\n           case OPEN_DELEGATE_READ:\n             \
    \      open_read_delegation4 read;\n           case OPEN_DELEGATE_WRITE:\n   \
    \                open_write_delegation4 write;\n           case OPEN_DELEGATE_NONE_EXT:\
    \ /* new to v4.1 */\n                   open_none_delegation4 od_whynone;\n  \
    \ };\n   /*\n    * Result flags\n    */\n   /* Client must confirm open */\n \
    \  const OPEN4_RESULT_CONFIRM      = 0x00000002;\n   /* Type of file locking behavior\
    \ at the server */\n   const OPEN4_RESULT_LOCKTYPE_POSIX = 0x00000004;\n   /*\
    \ Server will preserve file if removed while open */\n   const OPEN4_RESULT_PRESERVE_UNLINKED\
    \ = 0x00000008;\n   /*\n    * Server may use CB_NOTIFY_LOCK on locks\n    * derived\
    \ from this open\n    */\n   const OPEN4_RESULT_MAY_NOTIFY_LOCK = 0x00000020;\n\
    \   struct OPEN4resok {\n    stateid4       stateid;      /* Stateid for open\
    \ */\n    change_info4   cinfo;        /* Directory Change Info */\n    uint32_t\
    \       rflags;       /* Result flags */\n    bitmap4        attrset;      /*\
    \ attribute set for create*/\n    open_delegation4 delegation; /* Info on any\
    \ open\n   };\n   union OPEN4res switch (nfsstat4 status) {\n    case NFS4_OK:\n\
    \           /* New CURRENT_FH: opened file */\n           OPEN4resok      resok4;\n\
    \    default:\n           void;\n   };\n"
- title: 18.16.3.  DESCRIPTION
  contents:
  - "18.16.3.  DESCRIPTION\n   The OPEN operation opens a regular file in a directory\
    \ with the\n   provided name or filehandle.  OPEN can also create a file if a\
    \ name\n   is provided, and the client specifies it wants to create a file.\n\
    \   Specification of whether or not a file is to be created, and the\n   method\
    \ of creation is via the openhow parameter.  The openhow\n   parameter consists\
    \ of a switched union (data type opengflag4), which\n   switches on the value\
    \ of opentype (OPEN4_NOCREATE or OPEN4_CREATE).\n   If OPEN4_CREATE is specified,\
    \ this leads to another switched union\n   (data type createhow4) that supports\
    \ four cases of creation methods:\n   UNCHECKED4, GUARDED4, EXCLUSIVE4, or EXCLUSIVE4_1.\
    \  If opentype is\n   OPEN4_CREATE, then the claim field of the claim field MUST\
    \ be one of\n   CLAIM_NULL, CLAIM_DELEGATE_CUR, or CLAIM_DELEGATE_PREV, because\
    \ these\n   claim methods include a component of a file name.\n   Upon success\
    \ (which might entail creation of a new file), the current\n   filehandle is replaced\
    \ by that of the created or existing object.\n   If the current filehandle is\
    \ a named attribute directory, OPEN will\n   then create or open a named attribute\
    \ file.  Note that exclusive\n   create of a named attribute is not supported.\
    \  If the createmode is\n   EXCLUSIVE4 or EXCLUSIVE4_1 and the current filehandle\
    \ is a named\n   attribute directory, the server will return EINVAL.\n   UNCHECKED4\
    \ means that the file should be created if a file of that\n   name does not exist\
    \ and encountering an existing regular file of that\n   name is not an error.\
    \  For this type of create, createattrs specifies\n   the initial set of attributes\
    \ for the file.  The set of attributes\n   may include any writable attribute\
    \ valid for regular files.  When an\n   UNCHECKED4 create encounters an existing\
    \ file, the attributes\n   specified by createattrs are not used, except that\
    \ when createattrs\n   specifies the size attribute with a size of zero, the existing\
    \ file\n   is truncated.\n   If GUARDED4 is specified, the server checks for the\
    \ presence of a\n   duplicate object by name before performing the create.  If\
    \ a\n   duplicate exists, NFS4ERR_EXIST is returned.  If the object does not\n\
    \   exist, the request is performed as described for UNCHECKED4.\n   For the UNCHECKED4\
    \ and GUARDED4 cases, where the operation is\n   successful, the server will return\
    \ to the client an attribute mask\n   signifying which attributes were successfully\
    \ set for the object.\n   EXCLUSIVE4_1 and EXCLUSIVE4 specify that the server\
    \ is to follow\n   exclusive creation semantics, using the verifier to ensure\
    \ exclusive\n   creation of the target.  The server should check for the presence\
    \ of\n   a duplicate object by name.  If the object does not exist, the server\n\
    \   creates the object and stores the verifier with the object.  If the\n   object\
    \ does exist and the stored verifier matches the client provided\n   verifier,\
    \ the server uses the existing object as the newly created\n   object.  If the\
    \ stored verifier does not match, then an error of\n   NFS4ERR_EXIST is returned.\n\
    \   If using EXCLUSIVE4, and if the server uses attributes to store the\n   exclusive\
    \ create verifier, the server will signify which attributes\n   it used by setting\
    \ the appropriate bits in the attribute mask that is\n   returned in the results.\
    \  Unlike UNCHECKED4, GUARDED4, and\n   EXCLUSIVE4_1, EXCLUSIVE4 does not support\
    \ the setting of attributes\n   at file creation, and after a successful OPEN\
    \ via EXCLUSIVE4, the\n   client MUST send a SETATTR to set attributes to a known\
    \ state.\n   In NFSv4.1, EXCLUSIVE4 has been deprecated in favor of EXCLUSIVE4_1.\n\
    \   Unlike EXCLUSIVE4, attributes may be provided in the EXCLUSIVE4_1\n   case,\
    \ but because the server may use attributes of the target object\n   to store\
    \ the verifier, the set of allowable attributes may be fewer\n   than the set\
    \ of attributes SETATTR allows.  The allowable attributes\n   for EXCLUSIVE4_1\
    \ are indicated in the suppattr_exclcreat\n   (Section 5.8.1.14) attribute.  If\
    \ the client attempts to set in\n   cva_attrs an attribute that is not in suppattr_exclcreat,\
    \ the server\n   MUST return NFS4ERR_INVAL.  The response field, attrset, indicates\n\
    \   both which attributes the server set from cva_attrs and which\n   attributes\
    \ the server used to store the verifier.  As described in\n   Section 18.16.4,\
    \ the client can compare cva_attrs.attrmask with\n   attrset to determine which\
    \ attributes were used to store the\n   verifier.\n   With the addition of persistent\
    \ sessions and pNFS, under some\n   conditions EXCLUSIVE4 MUST NOT be used by\
    \ the client or supported by\n   the server.  The following table summarizes the\
    \ appropriate and\n   mandated exclusive create methods for implementations of\
    \ NFSv4.1:\n     | Persistent  | Server   | Server       | Client Allowed    \
    \    |\n     | Reply Cache | Supports | REQUIRED     |                       |\n\
    \     | Enabled     | pNFS     |              |                       |\n    \
    \ | no          | no       | EXCLUSIVE4_1 | EXCLUSIVE4_1 (SHOULD) |\n     | no\
    \          | yes      | EXCLUSIVE4_1 | EXCLUSIVE4_1          |\n     | yes   \
    \      | no       | GUARDED4     | GUARDED4              |\n     | yes       \
    \  | yes      | GUARDED4     | GUARDED4              |\n              Table 18:\
    \ Required Methods for Exclusive Create\n   If CREATE_SESSION4_FLAG_PERSIST is\
    \ set in the results of\n   CREATE_SESSION, the reply cache is persistent (see\
    \ Section 18.36).\n   If the EXCHGID4_FLAG_USE_PNFS_MDS flag is set in the results\
    \ from\n   EXCHANGE_ID, the server is a pNFS server (see Section 18.35).  If the\n\
    \   client attempts to use EXCLUSIVE4 on a persistent session, or a\n   session\
    \ derived from an EXCHGID4_FLAG_USE_PNFS_MDS client ID, the\n   server MUST return\
    \ NFS4ERR_INVAL.\n   With persistent sessions, exclusive create semantics are\
    \ fully\n   achievable via GUARDED4, and so EXCLUSIVE4 or EXCLUSIVE4_1 MUST NOT\n\
    \   be used.  When pNFS is being used, the layout_hint attribute might\n   not\
    \ be supported after the file is created.  Only the EXCLUSIVE4_1\n   and GUARDED\
    \ methods of exclusive file creation allow the atomic\n   setting of attributes.\n\
    \   For the target directory, the server returns change_info4 information\n  \
    \ in cinfo.  With the atomic field of the change_info4 data type, the\n   server\
    \ will indicate if the before and after change attributes were\n   obtained atomically\
    \ with respect to the link creation.\n   The OPEN operation provides for Windows\
    \ share reservation capability\n   with the use of the share_access and share_deny\
    \ fields of the OPEN\n   arguments.  The client specifies at OPEN the required\
    \ share_access\n   and share_deny modes.  For clients that do not directly support\n\
    \   SHAREs (i.e., UNIX), the expected deny value is\n   OPEN4_SHARE_DENY_NONE.\
    \  In the case that there is an existing SHARE\n   reservation that conflicts\
    \ with the OPEN request, the server returns\n   the error NFS4ERR_SHARE_DENIED.\
    \  For additional discussion of SHARE\n   semantics, see Section 9.7.\n   For\
    \ each OPEN, the client provides a value for the owner field of the\n   OPEN argument.\
    \  The owner field is of data type open_owner4, and\n   contains a field called\
    \ clientid and a field called owner.  The\n   client can set the clientid field\
    \ to any value and the server MUST\n   ignore it.  Instead, the server MUST derive\
    \ the client ID from the\n   session ID of the SEQUENCE operation of the COMPOUND\
    \ request.\n   The \"seqid\" field of the request is not used in NFSv4.1, but\
    \ it MAY\n   be any value and the server MUST ignore it.\n   In the case that\
    \ the client is recovering state from a server\n   failure, the claim field of\
    \ the OPEN argument is used to signify that\n   the request is meant to reclaim\
    \ state previously held.\n   The \"claim\" field of the OPEN argument is used\
    \ to specify the file to\n   be opened and the state information that the client\
    \ claims to\n   possess.  There are seven claim types as follows:\n   | open type\
    \            | description                                |\n   | CLAIM_NULL,\
    \ CLAIM_FH | For the client, this is a new OPEN         |\n   |              \
    \        | request and there is no previous state     |\n   |                \
    \      | associated with the file for the           |\n   |                  \
    \    | client.  With CLAIM_NULL, the file is      |\n   |                    \
    \  | identified by the current filehandle       |\n   |                      |\
    \ and the specified component name.          |\n   |                      | With\
    \ CLAIM_FH (new to NFSv4.1), the        |\n   |                      | file is\
    \ identified by just the current     |\n   |                      | filehandle.\
    \                                |\n   | CLAIM_PREVIOUS       | The client is\
    \ claiming basic OPEN          |\n   |                      | state for a file\
    \ that was held             |\n   |                      | previous to a server\
    \ restart.              |\n   |                      | Generally used when a server\
    \ is            |\n   |                      | returning persistent filehandles;\
    \ the      |\n   |                      | client may not have the file name to\
    \       |\n   |                      | reclaim the OPEN.                     \
    \     |\n   | CLAIM_DELEGATE_CUR,  | The client is claiming a delegation     \
    \   |\n   | CLAIM_DELEG_CUR_FH   | for OPEN as granted by the server.        \
    \ |\n   |                      | Generally, this is done as part of         |\n\
    \   |                      | recalling a delegation.  With              |\n  \
    \ |                      | CLAIM_DELEGATE_CUR, the file is            |\n   |\
    \                      | identified by the current filehandle       |\n   |  \
    \                    | and the specified component name.          |\n   |    \
    \                  | With CLAIM_DELEG_CUR_FH (new to            |\n   |      \
    \                | NFSv4.1), the file is identified by        |\n   |        \
    \              | just the current filehandle.               |\n   | CLAIM_DELEGATE_PREV,\
    \ | The client is claiming a delegation        |\n   | CLAIM_DELEG_PREV_FH  |\
    \ granted to a previous client instance;     |\n   |                      | used\
    \ after the client restarts.  The       |\n   |                      | server\
    \ MAY support CLAIM_DELEGATE_PREV     |\n   |                      | and/or CLAIM_DELEG_PREV_FH\
    \ (new to         |\n   |                      | NFSv4.1).  If it does support\
    \ either       |\n   |                      | claim type, CREATE_SESSION MUST\
    \ NOT        |\n   |                      | remove the client's delegation state,\
    \      |\n   |                      | and the server MUST support the        \
    \    |\n   |                      | DELEGPURGE operation.                    \
    \  |\n   For OPEN requests that reach the server during the grace period, the\n\
    \   server returns an error of NFS4ERR_GRACE.  The following claim types\n   are\
    \ exceptions:\n   *  OPEN requests specifying the claim type CLAIM_PREVIOUS are\
    \ devoted\n      to reclaiming opens after a server restart and are typically\
    \ only\n      valid during the grace period.\n   *  OPEN requests specifying the\
    \ claim types CLAIM_DELEGATE_CUR and\n      CLAIM_DELEG_CUR_FH are valid both\
    \ during and after the grace\n      period.  Since the granting of the delegation\
    \ that they are\n      subordinate to assures that there is no conflict with locks\
    \ to be\n      reclaimed by other clients, the server need not return\n      NFS4ERR_GRACE\
    \ when these are received during the grace period.\n   For any OPEN request, the\
    \ server may return an OPEN delegation, which\n   allows further opens and closes\
    \ to be handled locally on the client\n   as described in Section 10.4.  Note\
    \ that delegation is up to the\n   server to decide.  The client should never\
    \ assume that delegation\n   will or will not be granted in a particular instance.\
    \  It should\n   always be prepared for either case.  A partial exception is the\n\
    \   reclaim (CLAIM_PREVIOUS) case, in which a delegation type is claimed.\n  \
    \ In this case, delegation will always be granted, although the server\n   may\
    \ specify an immediate recall in the delegation structure.\n   The rflags returned\
    \ by a successful OPEN allow the server to return\n   information governing how\
    \ the open file is to be handled.\n   *  OPEN4_RESULT_CONFIRM is deprecated and\
    \ MUST NOT be returned by an\n      NFSv4.1 server.\n   *  OPEN4_RESULT_LOCKTYPE_POSIX\
    \ indicates that the server's byte-range\n      locking behavior supports the\
    \ complete set of POSIX locking\n      techniques [21].  From this, the client\
    \ can choose to manage byte-\n      range locking state in a way to handle a mismatch\
    \ of byte-range\n      locking management.\n   *  OPEN4_RESULT_PRESERVE_UNLINKED\
    \ indicates that the server will\n      preserve the open file if the client (or\
    \ any other client) removes\n      the file as long as it is open.  Furthermore,\
    \ the server promises\n      to preserve the file through the grace period after\
    \ server\n      restart, thereby giving the client the opportunity to reclaim\
    \ its\n      open.\n   *  OPEN4_RESULT_MAY_NOTIFY_LOCK indicates that the server\
    \ may attempt\n      CB_NOTIFY_LOCK callbacks for locks on this file.  This flag\
    \ is a\n      hint only, and may be safely ignored by the client.\n   If the component\
    \ is of zero length, NFS4ERR_INVAL will be returned.\n   The component is also\
    \ subject to the normal UTF-8, character support,\n   and name checks.  See Section\
    \ 14.5 for further discussion.\n   When an OPEN is done and the specified open-owner\
    \ already has the\n   resulting filehandle open, the result is to \"OR\" together\
    \ the new\n   share and deny status together with the existing status.  In this\n\
    \   case, only a single CLOSE need be done, even though multiple OPENs\n   were\
    \ completed.  When such an OPEN is done, checking of share\n   reservations for\
    \ the new OPEN proceeds normally, with no exception\n   for the existing OPEN\
    \ held by the same open-owner.  In this case, the\n   stateid returned as an \"\
    other\" field that matches that of the\n   previous open while the \"seqid\" field\
    \ is incremented to reflect the\n   change status due to the new open.\n   If\
    \ the underlying file system at the server is only accessible in a\n   read-only\
    \ mode and the OPEN request has specified ACCESS_WRITE or\n   ACCESS_BOTH, the\
    \ server will return NFS4ERR_ROFS to indicate a read-\n   only file system.\n\
    \   As with the CREATE operation, the server MUST derive the owner, owner\n  \
    \ ACE, group, or group ACE if any of the four attributes are required\n   and\
    \ supported by the server's file system.  For an OPEN with the\n   EXCLUSIVE4\
    \ createmode, the server has no choice, since such OPEN\n   calls do not include\
    \ the createattrs field.  Conversely, if\n   createattrs (UNCHECKED4 or GUARDED4)\
    \ or cva_attrs (EXCLUSIVE4_1) is\n   specified, and includes an owner, owner_group,\
    \ or ACE that the\n   principal in the RPC call's credentials does not have authorization\n\
    \   to create files for, then the server may return NFS4ERR_PERM.\n   In the case\
    \ of an OPEN that specifies a size of zero (e.g.,\n   truncation) and the file\
    \ has named attributes, the named attributes\n   are left as is and are not removed.\n\
    \   NFSv4.1 gives more precise control to clients over acquisition of\n   delegations\
    \ via the following new flags for the share_access field of\n   OPEN4args:\n \
    \  OPEN4_SHARE_ACCESS_WANT_READ_DELEG\n   OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG\n\
    \   OPEN4_SHARE_ACCESS_WANT_ANY_DELEG\n   OPEN4_SHARE_ACCESS_WANT_NO_DELEG\n \
    \  OPEN4_SHARE_ACCESS_WANT_CANCEL\n   OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL\n\
    \   OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED\n   If (share_access &\
    \ OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) is not zero,\n   then the client will have\
    \ specified one and only one of:\n   OPEN4_SHARE_ACCESS_WANT_READ_DELEG\n   OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG\n\
    \   OPEN4_SHARE_ACCESS_WANT_ANY_DELEG\n   OPEN4_SHARE_ACCESS_WANT_NO_DELEG\n \
    \  OPEN4_SHARE_ACCESS_WANT_CANCEL\n   Otherwise, the client is neither indicating\
    \ a desire nor a non-desire\n   for a delegation, and the server MAY or MAY not\
    \ return a delegation\n   in the OPEN response.\n   If the server supports the\
    \ new _WANT_ flags and the client sends one\n   or more of the new flags, then\
    \ in the event the server does not\n   return a delegation, it MUST return a delegation\
    \ type of\n   OPEN_DELEGATE_NONE_EXT.  The field ond_why in the reply indicates\
    \ why\n   no delegation was returned and will be one of:\n   WND4_NOT_WANTED\n\
    \      The client specified OPEN4_SHARE_ACCESS_WANT_NO_DELEG.\n   WND4_CONTENTION\n\
    \      There is a conflicting delegation or open on the file.\n   WND4_RESOURCE\n\
    \      Resource limitations prevent the server from granting a\n      delegation.\n\
    \   WND4_NOT_SUPP_FTYPE\n      The server does not support delegations on this\
    \ file type.\n   WND4_WRITE_DELEG_NOT_SUPP_FTYPE\n      The server does not support\
    \ OPEN_DELEGATE_WRITE delegations on\n      this file type.\n   WND4_NOT_SUPP_UPGRADE\n\
    \      The server does not support atomic upgrade of an\n      OPEN_DELEGATE_READ\
    \ delegation to an OPEN_DELEGATE_WRITE\n      delegation.\n   WND4_NOT_SUPP_DOWNGRADE\n\
    \      The server does not support atomic downgrade of an\n      OPEN_DELEGATE_WRITE\
    \ delegation to an OPEN_DELEGATE_READ\n      delegation.\n   WND4_CANCELED\n \
    \     The client specified OPEN4_SHARE_ACCESS_WANT_CANCEL and now any\n      \"\
    want\" for this file object is cancelled.\n   WND4_IS_DIR\n      The specified\
    \ file object is a directory, and the operation is\n      OPEN or WANT_DELEGATION,\
    \ which do not support delegations on\n      directories.\n   OPEN4_SHARE_ACCESS_WANT_READ_DELEG,\n\
    \   OPEN_SHARE_ACCESS_WANT_WRITE_DELEG, or\n   OPEN_SHARE_ACCESS_WANT_ANY_DELEG\
    \ mean, respectively, the client wants\n   an OPEN_DELEGATE_READ, OPEN_DELEGATE_WRITE,\
    \ or any delegation\n   regardless which of OPEN4_SHARE_ACCESS_READ,\n   OPEN4_SHARE_ACCESS_WRITE,\
    \ or OPEN4_SHARE_ACCESS_BOTH is set.  If the\n   client has an OPEN_DELEGATE_READ\
    \ delegation on a file and requests an\n   OPEN_DELEGATE_WRITE delegation, then\
    \ the client is requesting atomic\n   upgrade of its OPEN_DELEGATE_READ delegation\
    \ to an\n   OPEN_DELEGATE_WRITE delegation.  If the client has an\n   OPEN_DELEGATE_WRITE\
    \ delegation on a file and requests an\n   OPEN_DELEGATE_READ delegation, then\
    \ the client is requesting atomic\n   downgrade to an OPEN_DELEGATE_READ delegation.\
    \  A server MAY support\n   atomic upgrade or downgrade.  If it does, then the\
    \ returned\n   delegation_type of OPEN_DELEGATE_READ or OPEN_DELEGATE_WRITE that\
    \ is\n   different from the delegation type the client currently has,\n   indicates\
    \ successful upgrade or downgrade.  If the server does not\n   support atomic\
    \ delegation upgrade or downgrade, then ond_why will be\n   set to WND4_NOT_SUPP_UPGRADE\
    \ or WND4_NOT_SUPP_DOWNGRADE.\n   OPEN4_SHARE_ACCESS_WANT_NO_DELEG means that\
    \ the client wants no\n   delegation.\n   OPEN4_SHARE_ACCESS_WANT_CANCEL means\
    \ that the client wants no\n   delegation and wants to cancel any previously registered\
    \ \"want\" for a\n   delegation.\n   The client may set one or both of\n   OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL\
    \ and\n   OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED.  However, they\n\
    \   will have no effect unless one of following is set:\n   *  OPEN4_SHARE_ACCESS_WANT_READ_DELEG\n\
    \   *  OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG\n   *  OPEN4_SHARE_ACCESS_WANT_ANY_DELEG\n\
    \   If the client specifies\n   OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL,\
    \ then it wishes\n   to register a \"want\" for a delegation, in the event the\
    \ OPEN results\n   do not include a delegation.  If so and the server denies the\n\
    \   delegation due to insufficient resources, the server MAY later inform\n  \
    \ the client, via the CB_RECALLABLE_OBJ_AVAIL operation, that the\n   resource\
    \ limitation condition has eased.  The server will tell the\n   client that it\
    \ intends to send a future CB_RECALLABLE_OBJ_AVAIL\n   operation by setting delegation_type\
    \ in the results to\n   OPEN_DELEGATE_NONE_EXT, ond_why to WND4_RESOURCE, and\n\
    \   ond_server_will_signal_avail set to TRUE.  If\n   ond_server_will_signal_avail\
    \ is set to TRUE, the server MUST later\n   send a CB_RECALLABLE_OBJ_AVAIL operation.\n\
    \   If the client specifies\n   OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_UNCONTENDED,\
    \ then it wishes\n   to register a \"want\" for a delegation, in the event the\
    \ OPEN results\n   do not include a delegation.  If so and the server denies the\n\
    \   delegation due to contention, the server MAY later inform the client,\n  \
    \ via the CB_PUSH_DELEG operation, that the contention condition has\n   eased.\
    \  The server will tell the client that it intends to send a\n   future CB_PUSH_DELEG\
    \ operation by setting delegation_type in the\n   results to OPEN_DELEGATE_NONE_EXT,\
    \ ond_why to WND4_CONTENTION, and\n   ond_server_will_push_deleg to TRUE.  If\
    \ ond_server_will_push_deleg is\n   TRUE, the server MUST later send a CB_PUSH_DELEG\
    \ operation.\n   If the client has previously registered a want for a delegation\
    \ on a\n   file, and then sends a request to register a want for a delegation\
    \ on\n   the same file, the server MUST return a new error:\n   NFS4ERR_DELEG_ALREADY_WANTED.\
    \  If the client wishes to register a\n   different type of delegation want for\
    \ the same file, it MUST cancel\n   the existing delegation WANT.\n"
- title: 18.16.4.  IMPLEMENTATION
  contents:
  - "18.16.4.  IMPLEMENTATION\n   In absence of a persistent session, the client invokes\
    \ exclusive\n   create by setting the how parameter to EXCLUSIVE4 or EXCLUSIVE4_1.\n\
    \   In these cases, the client provides a verifier that can reasonably be\n  \
    \ expected to be unique.  A combination of a client identifier, perhaps\n   the\
    \ client network address, and a unique number generated by the\n   client, perhaps\
    \ the RPC transaction identifier, may be appropriate.\n   If the object does not\
    \ exist, the server creates the object and\n   stores the verifier in stable storage.\
    \  For file systems that do not\n   provide a mechanism for the storage of arbitrary\
    \ file attributes, the\n   server may use one or more elements of the object's\
    \ metadata to store\n   the verifier.  The verifier MUST be stored in stable storage\
    \ to\n   prevent erroneous failure on retransmission of the request.  It is\n\
    \   assumed that an exclusive create is being performed because exclusive\n  \
    \ semantics are critical to the application.  Because of the expected\n   usage,\
    \ exclusive CREATE does not rely solely on the server's reply\n   cache for storage\
    \ of the verifier.  A nonpersistent reply cache does\n   not survive a crash and\
    \ the session and reply cache may be deleted\n   after a network partition that\
    \ exceeds the lease time, thus opening\n   failure windows.\n   An NFSv4.1 server\
    \ SHOULD NOT store the verifier in any of the file's\n   RECOMMENDED or REQUIRED\
    \ attributes.  If it does, the server SHOULD\n   use time_modify_set or time_access_set\
    \ to store the verifier.  The\n   server SHOULD NOT store the verifier in the\
    \ following attributes:\n      acl (it is desirable for access control to be established\
    \ at\n      creation),\n      dacl (ditto),\n      mode (ditto),\n      owner\
    \ (ditto),\n      owner_group (ditto),\n      retentevt_set (it may be desired\
    \ to establish retention at\n      creation)\n      retention_hold (ditto),\n\
    \      retention_set (ditto),\n      sacl (it is desirable for auditing control\
    \ to be established at\n      creation),\n      size (on some servers, size may\
    \ have a limited range of values),\n      mode_set_masked (as with mode),\n  \
    \       and\n      time_creation (a meaningful file creation should be set when\
    \ the\n      file is created).\n   Another alternative for the server is to use\
    \ a named attribute to\n   store the verifier.\n   Because the EXCLUSIVE4 create\
    \ method does not specify initial\n   attributes when processing an EXCLUSIVE4\
    \ create, the server\n   *  SHOULD set the owner of the file to that corresponding\
    \ to the\n      credential of request's RPC header.\n   *  SHOULD NOT leave the\
    \ file's access control to anyone but the owner\n      of the file.\n   If the\
    \ server cannot support exclusive create semantics, possibly\n   because of the\
    \ requirement to commit the verifier to stable storage,\n   it should fail the\
    \ OPEN request with the error NFS4ERR_NOTSUPP.\n   During an exclusive CREATE\
    \ request, if the object already exists, the\n   server reconstructs the object's\
    \ verifier and compares it with the\n   verifier in the request.  If they match,\
    \ the server treats the\n   request as a success.  The request is presumed to\
    \ be a duplicate of\n   an earlier, successful request for which the reply was\
    \ lost and that\n   the server duplicate request cache mechanism did not detect.\
    \  If the\n   verifiers do not match, the request is rejected with the status\n\
    \   NFS4ERR_EXIST.\n   After the client has performed a successful exclusive create,\
    \ the\n   attrset response indicates which attributes were used to store the\n\
    \   verifier.  If EXCLUSIVE4 was used, the attributes set in attrset were\n  \
    \ used for the verifier.  If EXCLUSIVE4_1 was used, the client\n   determines\
    \ the attributes used for the verifier by comparing attrset\n   with cva_attrs.attrmask;\
    \ any bits set in the former but not the\n   latter identify the attributes used\
    \ to store the verifier.  The\n   client MUST immediately send a SETATTR to set\
    \ attributes used to\n   store the verifier.  Until it does so, the attributes\
    \ used to store\n   the verifier cannot be relied upon.  The subsequent SETATTR\
    \ MUST NOT\n   occur in the same COMPOUND request as the OPEN.\n   Unless a persistent\
    \ session is used, use of the GUARDED4 attribute\n   does not provide exactly\
    \ once semantics.  In particular, if a reply\n   is lost and the server does not\
    \ detect the retransmission of the\n   request, the operation can fail with NFS4ERR_EXIST,\
    \ even though the\n   create was performed successfully.  The client would use\
    \ this\n   behavior in the case that the application has not requested an\n  \
    \ exclusive create but has asked to have the file truncated when the\n   file\
    \ is opened.  In the case of the client timing out and\n   retransmitting the\
    \ create request, the client can use GUARDED4 to\n   prevent against a sequence\
    \ like create, write, create (retransmitted)\n   from occurring.\n   For SHARE\
    \ reservations, the value of the expression (share_access &\n   ~OPEN4_SHARE_ACCESS_WANT_DELEG_MASK)\
    \ MUST be one of\n   OPEN4_SHARE_ACCESS_READ, OPEN4_SHARE_ACCESS_WRITE, or\n \
    \  OPEN4_SHARE_ACCESS_BOTH.  If not, the server MUST return\n   NFS4ERR_INVAL.\
    \  The value of share_deny MUST be one of\n   OPEN4_SHARE_DENY_NONE, OPEN4_SHARE_DENY_READ,\
    \ OPEN4_SHARE_DENY_WRITE,\n   or OPEN4_SHARE_DENY_BOTH.  If not, the server MUST\
    \ return\n   NFS4ERR_INVAL.\n   Based on the share_access value (OPEN4_SHARE_ACCESS_READ,\n\
    \   OPEN4_SHARE_ACCESS_WRITE, or OPEN4_SHARE_ACCESS_BOTH), the client\n   should\
    \ check that the requester has the proper access rights to\n   perform the specified\
    \ operation.  This would generally be the results\n   of applying the ACL access\
    \ rules to the file for the current\n   requester.  However, just as with the\
    \ ACCESS operation, the client\n   should not attempt to second-guess the server's\
    \ decisions, as access\n   rights may change and may be subject to server administrative\n\
    \   controls outside the ACL framework.  If the requester's READ or WRITE\n  \
    \ operation is not authorized (depending on the share_access value),\n   the server\
    \ MUST return NFS4ERR_ACCESS.\n   Note that if the client ID was not created with\
    \ the\n   EXCHGID4_FLAG_BIND_PRINC_STATEID capability set in the reply to\n  \
    \ EXCHANGE_ID, then the server MUST NOT impose any requirement that\n   READs\
    \ and WRITEs sent for an open file have the same credentials as\n   the OPEN itself,\
    \ and the server is REQUIRED to perform access\n   checking on the READs and WRITEs\
    \ themselves.  Otherwise, if the reply\n   to EXCHANGE_ID did have EXCHGID4_FLAG_BIND_PRINC_STATEID\
    \ set, then\n   with one exception, the credentials used in the OPEN request MUST\n\
    \   match those used in the READs and WRITEs, and the stateids in the\n   READs\
    \ and WRITEs MUST match, or be derived from the stateid from the\n   reply to\
    \ OPEN.  The exception is if SP4_SSV or SP4_MACH_CRED state\n   protection is\
    \ used, and the spo_must_allow result of EXCHANGE_ID\n   includes the READ and/or\
    \ WRITE operations.  In that case, the machine\n   or SSV credential will be allowed\
    \ to send READ and/or WRITE.  See\n   Section 18.35.\n   If the component provided\
    \ to OPEN is a symbolic link, the error\n   NFS4ERR_SYMLINK will be returned to\
    \ the client, while if it is a\n   directory the error NFS4ERR_ISDIR will be returned.\
    \  If the component\n   is neither of those but not an ordinary file, the error\n\
    \   NFS4ERR_WRONG_TYPE is returned.  If the current filehandle is not a\n   directory,\
    \ the error NFS4ERR_NOTDIR will be returned.\n   The use of the OPEN4_RESULT_PRESERVE_UNLINKED\
    \ result flag allows a\n   client to avoid the common implementation practice\
    \ of renaming an\n   open file to \".nfs<unique value>\" after it removes the\
    \ file.  After\n   the server returns OPEN4_RESULT_PRESERVE_UNLINKED, if a client\
    \ sends\n   a REMOVE operation that would reduce the file's link count to zero,\n\
    \   the server SHOULD report a value of zero for the numlinks attribute\n   on\
    \ the file.\n   If another client has a delegation of the file being opened that\n\
    \   conflicts with open being done (sometimes depending on the\n   share_access\
    \ or share_deny value specified), the delegation(s) MUST\n   be recalled, and\
    \ the operation cannot proceed until each such\n   delegation is returned or revoked.\
    \  Except where this happens very\n   quickly, one or more NFS4ERR_DELAY errors\
    \ will be returned to\n   requests made while delegation remains outstanding.\
    \  In the case of\n   an OPEN_DELEGATE_WRITE delegation, any open by a different\
    \ client\n   will conflict, while for an OPEN_DELEGATE_READ delegation, only opens\n\
    \   with one of the following characteristics will be considered\n   conflicting:\n\
    \   *  The value of share_access includes the bit\n      OPEN4_SHARE_ACCESS_WRITE.\n\
    \   *  The value of share_deny specifies OPEN4_SHARE_DENY_READ or\n      OPEN4_SHARE_DENY_BOTH.\n\
    \   *  OPEN4_CREATE is specified together with UNCHECKED4, the size\n      attribute\
    \ is specified as zero (for truncation), and an existing\n      file is truncated.\n\
    \   If OPEN4_CREATE is specified and the file does not exist and the\n   current\
    \ filehandle designates a directory for which another client\n   holds a directory\
    \ delegation, then, unless the delegation is such\n   that the situation can be\
    \ resolved by sending a notification, the\n   delegation MUST be recalled, and\
    \ the operation cannot proceed until\n   the delegation is returned or revoked.\
    \  Except where this happens\n   very quickly, one or more NFS4ERR_DELAY errors\
    \ will be returned to\n   requests made while delegation remains outstanding.\n\
    \   If OPEN4_CREATE is specified and the file does not exist and the\n   current\
    \ filehandle designates a directory for which one or more\n   directory delegations\
    \ exist, then, when those delegations request\n   such notifications, NOTIFY4_ADD_ENTRY\
    \ will be generated as a result\n   of this operation.\n"
- title: 18.16.4.1.  Warning to Client Implementors
  contents:
  - "18.16.4.1.  Warning to Client Implementors\n   OPEN resembles LOOKUP in that\
    \ it generates a filehandle for the\n   client to use.  Unlike LOOKUP though,\
    \ OPEN creates server state on\n   the filehandle.  In normal circumstances, the\
    \ client can only release\n   this state with a CLOSE operation.  CLOSE uses the\
    \ current filehandle\n   to determine which file to close.  Therefore, the client\
    \ MUST follow\n   every OPEN operation with a GETFH operation in the same COMPOUND\n\
    \   procedure.  This will supply the client with the filehandle such that\n  \
    \ CLOSE can be used appropriately.\n   Simply waiting for the lease on the file\
    \ to expire is insufficient\n   because the server may maintain the state indefinitely\
    \ as long as\n   another client does not attempt to make a conflicting access\
    \ to the\n   same file.\n   See also Section 2.10.6.4.\n"
- title: '18.17.  Operation 19: OPENATTR - Open Named Attribute Directory'
  contents:
  - '18.17.  Operation 19: OPENATTR - Open Named Attribute Directory

    '
- title: 18.17.1.  ARGUMENTS
  contents:
  - "18.17.1.  ARGUMENTS\n   struct OPENATTR4args {\n           /* CURRENT_FH: object\
    \ */\n           bool    createdir;\n   };\n"
- title: 18.17.2.  RESULTS
  contents:
  - "18.17.2.  RESULTS\n   struct OPENATTR4res {\n           /*\n            * If\
    \ status is NFS4_OK,\n            *   new CURRENT_FH: named attribute\n      \
    \      */\n           nfsstat4        status;\n   };\n"
- title: 18.17.3.  DESCRIPTION
  contents:
  - "18.17.3.  DESCRIPTION\n   The OPENATTR operation is used to obtain the filehandle\
    \ of the named\n   attribute directory associated with the current filehandle.\
    \  The\n   result of the OPENATTR will be a filehandle to an object of type\n\
    \   NF4ATTRDIR.  From this filehandle, READDIR and LOOKUP operations can\n   be\
    \ used to obtain filehandles for the various named attributes\n   associated with\
    \ the original file system object.  Filehandles\n   returned within the named\
    \ attribute directory will designate objects\n   of type of NF4NAMEDATTR.\n  \
    \ The createdir argument allows the client to signify if a named\n   attribute\
    \ directory should be created as a result of the OPENATTR\n   operation.  Some\
    \ clients may use the OPENATTR operation with a value\n   of FALSE for createdir\
    \ to determine if any named attributes exist for\n   the object.  If none exist,\
    \ then NFS4ERR_NOENT will be returned.  If\n   createdir has a value of TRUE and\
    \ no named attribute directory\n   exists, one is created and its filehandle becomes\
    \ the current\n   filehandle.  On the other hand, if createdir has a value of\
    \ TRUE and\n   the named attribute directory already exists, no error results\
    \ and\n   the filehandle of the existing directory becomes the current\n   filehandle.\
    \  The creation of a named attribute directory assumes that\n   the server has\
    \ implemented named attribute support in this fashion\n   and is not required\
    \ to do so by this definition.\n   If the current filehandle designates an object\
    \ of type NF4NAMEDATTR\n   (a named attribute) or NF4ATTRDIR (a named attribute\
    \ directory), an\n   error of NFS4ERR_WRONG_TYPE is returned to the client.  Named\n\
    \   attributes or a named attribute directory MUST NOT have their own\n   named\
    \ attributes.\n"
- title: 18.17.4.  IMPLEMENTATION
  contents:
  - "18.17.4.  IMPLEMENTATION\n   If the server does not support named attributes\
    \ for the current\n   filehandle, an error of NFS4ERR_NOTSUPP will be returned\
    \ to the\n   client.\n"
- title: '18.18.  Operation 21: OPEN_DOWNGRADE - Reduce Open File Access'
  contents:
  - '18.18.  Operation 21: OPEN_DOWNGRADE - Reduce Open File Access

    '
- title: 18.18.1.  ARGUMENTS
  contents:
  - "18.18.1.  ARGUMENTS\n   struct OPEN_DOWNGRADE4args {\n           /* CURRENT_FH:\
    \ opened file */\n           stateid4        open_stateid;\n           seqid4\
    \          seqid;\n           uint32_t        share_access;\n           uint32_t\
    \        share_deny;\n   };\n"
- title: 18.18.2.  RESULTS
  contents:
  - "18.18.2.  RESULTS\n   struct OPEN_DOWNGRADE4resok {\n           stateid4    \
    \    open_stateid;\n   };\n   union OPEN_DOWNGRADE4res switch(nfsstat4 status)\
    \ {\n    case NFS4_OK:\n           OPEN_DOWNGRADE4resok    resok4;\n    default:\n\
    \            void;\n   };\n"
- title: 18.18.3.  DESCRIPTION
  contents:
  - "18.18.3.  DESCRIPTION\n   This operation is used to adjust the access and deny\
    \ states for a\n   given open.  This is necessary when a given open-owner opens\
    \ the same\n   file multiple times with different access and deny values.  In\
    \ this\n   situation, a close of one of the opens may change the appropriate\n\
    \   share_access and share_deny flags to remove bits associated with\n   opens\
    \ no longer in effect.\n   Valid values for the expression (share_access &\n \
    \  ~OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) are OPEN4_SHARE_ACCESS_READ,\n   OPEN4_SHARE_ACCESS_WRITE,\
    \ or OPEN4_SHARE_ACCESS_BOTH.  If the client\n   specifies other values, the server\
    \ MUST reply with NFS4ERR_INVAL.\n   Valid values for the share_deny field are\
    \ OPEN4_SHARE_DENY_NONE,\n   OPEN4_SHARE_DENY_READ, OPEN4_SHARE_DENY_WRITE, or\n\
    \   OPEN4_SHARE_DENY_BOTH.  If the client specifies other values, the\n   server\
    \ MUST reply with NFS4ERR_INVAL.\n   After checking for valid values of share_access\
    \ and share_deny, the\n   server replaces the current access and deny modes on\
    \ the file with\n   share_access and share_deny subject to the following constraints:\n\
    \   *  The bits in share_access SHOULD equal the union of the\n      share_access\
    \ bits (not including OPEN4_SHARE_WANT_* bits)\n      specified for some subset\
    \ of the OPENs in effect for the current\n      open-owner on the current file.\n\
    \   *  The bits in share_deny SHOULD equal the union of the share_deny\n     \
    \ bits specified for some subset of the OPENs in effect for the\n      current\
    \ open-owner on the current file.\n   If the above constraints are not respected,\
    \ the server SHOULD return\n   the error NFS4ERR_INVAL.  Since share_access and\
    \ share_deny bits\n   should be subsets of those already granted, short of a defect\
    \ in the\n   client or server implementation, it is not possible for the\n   OPEN_DOWNGRADE\
    \ request to be denied because of conflicting share\n   reservations.\n   The\
    \ seqid argument is not used in NFSv4.1, MAY be any value, and MUST\n   be ignored\
    \ by the server.\n   On success, the current filehandle retains its value.\n"
- title: 18.18.4.  IMPLEMENTATION
  contents:
  - "18.18.4.  IMPLEMENTATION\n   An OPEN_DOWNGRADE operation may make OPEN_DELEGATE_READ\
    \ delegations\n   grantable where they were not previously.  Servers may choose\
    \ to\n   respond immediately if there are pending delegation want requests or\n\
    \   may respond to the situation at a later time.\n"
- title: '18.19.  Operation 22: PUTFH - Set Current Filehandle'
  contents:
  - '18.19.  Operation 22: PUTFH - Set Current Filehandle

    '
- title: 18.19.1.  ARGUMENTS
  contents:
  - "18.19.1.  ARGUMENTS\n   struct PUTFH4args {\n           nfs_fh4         object;\n\
    \   };\n"
- title: 18.19.2.  RESULTS
  contents:
  - "18.19.2.  RESULTS\n   struct PUTFH4res {\n           /*\n            * If status\
    \ is NFS4_OK,\n            *    new CURRENT_FH: argument to PUTFH\n          \
    \  */\n           nfsstat4        status;\n   };\n"
- title: 18.19.3.  DESCRIPTION
  contents:
  - "18.19.3.  DESCRIPTION\n   This operation replaces the current filehandle with\
    \ the filehandle\n   provided as an argument.  It clears the current stateid.\n\
    \   If the security mechanism used by the requester does not meet the\n   requirements\
    \ of the filehandle provided to this operation, the server\n   MUST return NFS4ERR_WRONGSEC.\n\
    \   See Section 16.2.3.1.1 for more details on the current filehandle.\n   See\
    \ Section 16.2.3.1.2 for more details on the current stateid.\n"
- title: 18.19.4.  IMPLEMENTATION
  contents:
  - "18.19.4.  IMPLEMENTATION\n   This operation is used in an NFS request to set\
    \ the context for file\n   accessing operations that follow in the same COMPOUND\
    \ request.\n"
- title: '18.20.  Operation 23: PUTPUBFH - Set Public Filehandle'
  contents:
  - '18.20.  Operation 23: PUTPUBFH - Set Public Filehandle

    '
- title: 18.20.1.  ARGUMENT
  contents:
  - "18.20.1.  ARGUMENT\n   void;\n"
- title: 18.20.2.  RESULT
  contents:
  - "18.20.2.  RESULT\n   struct PUTPUBFH4res {\n           /*\n            * If status\
    \ is NFS4_OK,\n            *   new CURRENT_FH: public fh\n            */\n   \
    \        nfsstat4        status;\n   };\n"
- title: 18.20.3.  DESCRIPTION
  contents:
  - "18.20.3.  DESCRIPTION\n   This operation replaces the current filehandle with\
    \ the filehandle\n   that represents the public filehandle of the server's namespace.\n\
    \   This filehandle may be different from the \"root\" filehandle that may\n \
    \  be associated with some other directory on the server.\n   PUTPUBFH also clears\
    \ the current stateid.\n   The public filehandle represents the concepts embodied\
    \ in RFC 2054\n   [49], RFC 2055 [50], and RFC 2224 [61].  The intent for NFSv4.1\
    \ is\n   that the public filehandle (represented by the PUTPUBFH operation) be\n\
    \   used as a method of providing WebNFS server compatibility with NFSv3.\n  \
    \ The public filehandle and the root filehandle (represented by the\n   PUTROOTFH\
    \ operation) SHOULD be equivalent.  If the public and root\n   filehandles are\
    \ not equivalent, then the directory corresponding to\n   the public filehandle\
    \ MUST be a descendant of the directory\n   corresponding to the root filehandle.\n\
    \   See Section 16.2.3.1.1 for more details on the current filehandle.\n   See\
    \ Section 16.2.3.1.2 for more details on the current stateid.\n"
- title: 18.20.4.  IMPLEMENTATION
  contents:
  - "18.20.4.  IMPLEMENTATION\n   This operation is used in an NFS request to set\
    \ the context for file\n   accessing operations that follow in the same COMPOUND\
    \ request.\n   With the NFSv3 public filehandle, the client is able to specify\n\
    \   whether the pathname provided in the LOOKUP should be evaluated as\n   either\
    \ an absolute path relative to the server's root or relative to\n   the public\
    \ filehandle.  RFC 2224 [61] contains further discussion of\n   the functionality.\
    \  With NFSv4.1, that type of specification is not\n   directly available in the\
    \ LOOKUP operation.  The reason for this is\n   because the component separators\
    \ needed to specify absolute vs.\n   relative are not allowed in NFSv4.  Therefore,\
    \ the client is\n   responsible for constructing its request such that the use\
    \ of either\n   PUTROOTFH or PUTPUBFH signifies absolute or relative evaluation\
    \ of an\n   NFS URL, respectively.\n   Note that there are warnings mentioned\
    \ in RFC 2224 [61] with respect\n   to the use of absolute evaluation and the\
    \ restrictions the server may\n   place on that evaluation with respect to how\
    \ much of its namespace\n   has been made available.  These same warnings apply\
    \ to NFSv4.1.  It\n   is likely, therefore, that because of server implementation\
    \ details,\n   an NFSv3 absolute public filehandle look up may behave differently\n\
    \   than an NFSv4.1 absolute resolution.\n   There is a form of security negotiation\
    \ as described in RFC 2755 [62]\n   that uses the public filehandle and an overloading\
    \ of the pathname.\n   This method is not available with NFSv4.1 as filehandles\
    \ are not\n   overloaded with special meaning and therefore do not provide the\
    \ same\n   framework as NFSv3.  Clients should therefore use the security\n  \
    \ negotiation mechanisms described in Section 2.6.\n"
- title: '18.21.  Operation 24: PUTROOTFH - Set Root Filehandle'
  contents:
  - '18.21.  Operation 24: PUTROOTFH - Set Root Filehandle

    '
- title: 18.21.1.  ARGUMENTS
  contents:
  - "18.21.1.  ARGUMENTS\n   void;\n"
- title: 18.21.2.  RESULTS
  contents:
  - "18.21.2.  RESULTS\n   struct PUTROOTFH4res {\n           /*\n            * If\
    \ status is NFS4_OK,\n            *   new CURRENT_FH: root fh\n            */\n\
    \           nfsstat4        status;\n   };\n"
- title: 18.21.3.  DESCRIPTION
  contents:
  - "18.21.3.  DESCRIPTION\n   This operation replaces the current filehandle with\
    \ the filehandle\n   that represents the root of the server's namespace.  From\
    \ this\n   filehandle, a LOOKUP operation can locate any other filehandle on the\n\
    \   server.  This filehandle may be different from the \"public\"\n   filehandle\
    \ that may be associated with some other directory on the\n   server.\n   PUTROOTFH\
    \ also clears the current stateid.\n   See Section 16.2.3.1.1 for more details\
    \ on the current filehandle.\n   See Section 16.2.3.1.2 for more details on the\
    \ current stateid.\n"
- title: 18.21.4.  IMPLEMENTATION
  contents:
  - "18.21.4.  IMPLEMENTATION\n   This operation is used in an NFS request to set\
    \ the context for file\n   accessing operations that follow in the same COMPOUND\
    \ request.\n"
- title: '18.22.  Operation 25: READ - Read from File'
  contents:
  - '18.22.  Operation 25: READ - Read from File

    '
- title: 18.22.1.  ARGUMENTS
  contents:
  - "18.22.1.  ARGUMENTS\n   struct READ4args {\n           /* CURRENT_FH: file */\n\
    \           stateid4        stateid;\n           offset4         offset;\n   \
    \        count4          count;\n   };\n"
- title: 18.22.2.  RESULTS
  contents:
  - "18.22.2.  RESULTS\n   struct READ4resok {\n           bool            eof;\n\
    \           opaque          data<>;\n   };\n   union READ4res switch (nfsstat4\
    \ status) {\n    case NFS4_OK:\n            READ4resok     resok4;\n    default:\n\
    \            void;\n   };\n"
- title: 18.22.3.  DESCRIPTION
  contents:
  - "18.22.3.  DESCRIPTION\n   The READ operation reads data from the regular file\
    \ identified by the\n   current filehandle.\n   The client provides an offset\
    \ of where the READ is to start and a\n   count of how many bytes are to be read.\
    \  An offset of zero means to\n   read data starting at the beginning of the file.\
    \  If offset is\n   greater than or equal to the size of the file, the status\
    \ NFS4_OK is\n   returned with a data length set to zero and eof is set to TRUE.\
    \  The\n   READ is subject to access permissions checking.\n   If the client specifies\
    \ a count value of zero, the READ succeeds and\n   returns zero bytes of data\
    \ again subject to access permissions\n   checking.  The server may choose to\
    \ return fewer bytes than specified\n   by the client.  The client needs to check\
    \ for this condition and\n   handle the condition appropriately.\n   Except when\
    \ special stateids are used, the stateid value for a READ\n   request represents\
    \ a value returned from a previous byte-range lock\n   or share reservation request\
    \ or the stateid associated with a\n   delegation.  The stateid identifies the\
    \ associated owners if any and\n   is used by the server to verify that the associated\
    \ locks are still\n   valid (e.g., have not been revoked).\n   If the read ended\
    \ at the end-of-file (formally, in a correctly formed\n   READ operation, if offset\
    \ + count is equal to the size of the file),\n   or the READ operation extends\
    \ beyond the size of the file (if offset\n   + count is greater than the size\
    \ of the file), eof is returned as\n   TRUE; otherwise, it is FALSE.  A successful\
    \ READ of an empty file\n   will always return eof as TRUE.\n   If the current\
    \ filehandle is not an ordinary file, an error will be\n   returned to the client.\
    \  In the case that the current filehandle\n   represents an object of type NF4DIR,\
    \ NFS4ERR_ISDIR is returned.  If\n   the current filehandle designates a symbolic\
    \ link, NFS4ERR_SYMLINK is\n   returned.  In all other cases, NFS4ERR_WRONG_TYPE\
    \ is returned.\n   For a READ with a stateid value of all bits equal to zero,\
    \ the server\n   MAY allow the READ to be serviced subject to mandatory byte-range\n\
    \   locks or the current share deny modes for the file.  For a READ with\n   a\
    \ stateid value of all bits equal to one, the server MAY allow READ\n   operations\
    \ to bypass locking checks at the server.\n   On success, the current filehandle\
    \ retains its value.\n"
- title: 18.22.4.  IMPLEMENTATION
  contents:
  - "18.22.4.  IMPLEMENTATION\n   If the server returns a \"short read\" (i.e., fewer\
    \ data than requested\n   and eof is set to FALSE), the client should send another\
    \ READ to get\n   the remaining data.  A server may return less data than requested\n\
    \   under several circumstances.  The file may have been truncated by\n   another\
    \ client or perhaps on the server itself, changing the file\n   size from what\
    \ the requesting client believes to be the case.  This\n   would reduce the actual\
    \ amount of data available to the client.  It\n   is possible that the server\
    \ reduce the transfer size and so return a\n   short read result.  Server resource\
    \ exhaustion may also occur in a\n   short read.\n   If mandatory byte-range locking\
    \ is in effect for the file, and if the\n   byte-range corresponding to the data\
    \ to be read from the file is\n   WRITE_LT locked by an owner not associated with\
    \ the stateid, the\n   server will return the NFS4ERR_LOCKED error.  The client\
    \ should try\n   to get the appropriate READ_LT via the LOCK operation before\
    \ re-\n   attempting the READ.  When the READ completes, the client should\n \
    \  release the byte-range lock via LOCKU.\n   If another client has an OPEN_DELEGATE_WRITE\
    \ delegation for the file\n   being read, the delegation must be recalled, and\
    \ the operation cannot\n   proceed until that delegation is returned or revoked.\
    \  Except where\n   this happens very quickly, one or more NFS4ERR_DELAY errors\
    \ will be\n   returned to requests made while the delegation remains outstanding.\n\
    \   Normally, delegations will not be recalled as a result of a READ\n   operation\
    \ since the recall will occur as a result of an earlier OPEN.\n   However, since\
    \ it is possible for a READ to be done with a special\n   stateid, the server\
    \ needs to check for this case even though the\n   client should have done an\
    \ OPEN previously.\n"
- title: '18.23.  Operation 26: READDIR - Read Directory'
  contents:
  - '18.23.  Operation 26: READDIR - Read Directory

    '
- title: 18.23.1.  ARGUMENTS
  contents:
  - "18.23.1.  ARGUMENTS\n   struct READDIR4args {\n           /* CURRENT_FH: directory\
    \ */\n           nfs_cookie4     cookie;\n           verifier4       cookieverf;\n\
    \           count4          dircount;\n           count4          maxcount;\n\
    \           bitmap4         attr_request;\n   };\n"
- title: 18.23.2.  RESULTS
  contents:
  - "18.23.2.  RESULTS\n   struct entry4 {\n           nfs_cookie4     cookie;\n \
    \          component4      name;\n           fattr4          attrs;\n        \
    \   entry4          *nextentry;\n   };\n   struct dirlist4 {\n           entry4\
    \          *entries;\n           bool            eof;\n   };\n   struct READDIR4resok\
    \ {\n           verifier4       cookieverf;\n           dirlist4        reply;\n\
    \   };\n   union READDIR4res switch (nfsstat4 status) {\n    case NFS4_OK:\n \
    \           READDIR4resok  resok4;\n    default:\n            void;\n   };\n"
- title: 18.23.3.  DESCRIPTION
  contents:
  - "18.23.3.  DESCRIPTION\n   The READDIR operation retrieves a variable number of\
    \ entries from a\n   file system directory and returns client-requested attributes\
    \ for\n   each entry along with information to allow the client to request\n \
    \  additional directory entries in a subsequent READDIR.\n   The arguments contain\
    \ a cookie value that represents where the\n   READDIR should start within the\
    \ directory.  A value of zero for the\n   cookie is used to start reading at the\
    \ beginning of the directory.\n   For subsequent READDIR requests, the client\
    \ specifies a cookie value\n   that is provided by the server on a previous READDIR\
    \ request.\n   The request's cookieverf field should be set to 0 zero) when the\n\
    \   request's cookie field is zero (first read of the directory).  On\n   subsequent\
    \ requests, the cookieverf field must match the cookieverf\n   returned by the\
    \ READDIR in which the cookie was acquired.  If the\n   server determines that\
    \ the cookieverf is no longer valid for the\n   directory, the error NFS4ERR_NOT_SAME\
    \ must be returned.\n   The dircount field of the request is a hint of the maximum\
    \ number of\n   bytes of directory information that should be returned.  This\
    \ value\n   represents the total length of the names of the directory entries\
    \ and\n   the cookie value for these entries.  This length represents the XDR\n\
    \   encoding of the data (names and cookies) and not the length in the\n   native\
    \ format of the server.\n   The maxcount field of the request represents the maximum\
    \ total size\n   of all of the data being returned within the READDIR4resok structure\n\
    \   and includes the XDR overhead.  The server MAY return less data.  If\n   the\
    \ server is unable to return a single directory entry within the\n   maxcount\
    \ limit, the error NFS4ERR_TOOSMALL MUST be returned to the\n   client.\n   Finally,\
    \ the request's attr_request field represents the list of\n   attributes to be\
    \ returned for each directory entry supplied by the\n   server.\n   A successful\
    \ reply consists of a list of directory entries.  Each of\n   these entries contains\
    \ the name of the directory entry, a cookie\n   value for that entry, and the\
    \ associated attributes as requested.\n   The \"eof\" flag has a value of TRUE\
    \ if there are no more entries in\n   the directory.\n   The cookie value is only\
    \ meaningful to the server and is used as a\n   cursor for the directory entry.\
    \  As mentioned, this cookie is used by\n   the client for subsequent READDIR\
    \ operations so that it may continue\n   reading a directory.  The cookie is similar\
    \ in concept to a READ\n   offset but MUST NOT be interpreted as such by the client.\
    \  Ideally,\n   the cookie value SHOULD NOT change if the directory is modified\
    \ since\n   the client may be caching these values.\n   In some cases, the server\
    \ may encounter an error while obtaining the\n   attributes for a directory entry.\
    \  Instead of returning an error for\n   the entire READDIR operation, the server\
    \ can instead return the\n   attribute rdattr_error (Section 5.8.1.12).  With\
    \ this, the server is\n   able to communicate the failure to the client and not\
    \ fail the entire\n   operation in the instance of what might be a transient failure.\n\
    \   Obviously, the client must request the fattr4_rdattr_error attribute\n   for\
    \ this method to work properly.  If the client does not request the\n   attribute,\
    \ the server has no choice but to return failure for the\n   entire READDIR operation.\n\
    \   For some file system environments, the directory entries \".\" and \"..\"\n\
    \   have special meaning, and in other environments, they do not.  If the\n  \
    \ server supports these special entries within a directory, they SHOULD\n   NOT\
    \ be returned to the client as part of the READDIR response.  To\n   enable some\
    \ client environments, the cookie values of zero, 1, and 2\n   are to be considered\
    \ reserved.  Note that the UNIX client will use\n   these values when combining\
    \ the server's response and local\n   representations to enable a fully formed\
    \ UNIX directory presentation\n   to the application.\n   For READDIR arguments,\
    \ cookie values of one and two SHOULD NOT be\n   used, and for READDIR results,\
    \ cookie values of zero, one, and two\n   SHOULD NOT be returned.\n   On success,\
    \ the current filehandle retains its value.\n"
- title: 18.23.4.  IMPLEMENTATION
  contents:
  - "18.23.4.  IMPLEMENTATION\n   The server's file system directory representations\
    \ can differ\n   greatly.  A client's programming interfaces may also be bound\
    \ to the\n   local operating environment in a way that does not translate well\n\
    \   into the NFS protocol.  Therefore, the use of the dircount and\n   maxcount\
    \ fields are provided to enable the client to provide hints to\n   the server.\
    \  If the client is aggressive about attribute collection\n   during a READDIR,\
    \ the server has an idea of how to limit the encoded\n   response.\n   If dircount\
    \ is zero, the server bounds the reply's size based on the\n   request's maxcount\
    \ field.\n   The cookieverf may be used by the server to help manage cookie values\n\
    \   that may become stale.  It should be a rare occurrence that a server\n   is\
    \ unable to continue properly reading a directory with the provided\n   cookie/cookieverf\
    \ pair.  The server SHOULD make every effort to avoid\n   this condition since\
    \ the application at the client might be unable to\n   properly handle this type\
    \ of failure.\n   The use of the cookieverf will also protect the client from\
    \ using\n   READDIR cookie values that might be stale.  For example, if the file\n\
    \   system has been migrated, the server might or might not be able to\n   use\
    \ the same cookie values to service READDIR as the previous server\n   used. \
    \ With the client providing the cookieverf, the server is able\n   to provide\
    \ the appropriate response to the client.  This prevents the\n   case where the\
    \ server accepts a cookie value but the underlying\n   directory has changed and\
    \ the response is invalid from the client's\n   context of its previous READDIR.\n\
    \   Since some servers will not be returning \".\" and \"..\" entries as has\n\
    \   been done with previous versions of the NFS protocol, the client that\n  \
    \ requires these entries be present in READDIR responses must fabricate\n   them.\n"
- title: '18.24.  Operation 27: READLINK - Read Symbolic Link'
  contents:
  - '18.24.  Operation 27: READLINK - Read Symbolic Link

    '
- title: 18.24.1.  ARGUMENTS
  contents:
  - "18.24.1.  ARGUMENTS\n   /* CURRENT_FH: symlink */\n   void;\n"
- title: 18.24.2.  RESULTS
  contents:
  - "18.24.2.  RESULTS\n   struct READLINK4resok {\n           linktext4       link;\n\
    \   };\n   union READLINK4res switch (nfsstat4 status) {\n    case NFS4_OK:\n\
    \            READLINK4resok resok4;\n    default:\n            void;\n   };\n"
- title: 18.24.3.  DESCRIPTION
  contents:
  - "18.24.3.  DESCRIPTION\n   READLINK reads the data associated with a symbolic\
    \ link.  Depending\n   on the value of the UTF-8 capability attribute (Section\
    \ 14.4), the\n   data is encoded in UTF-8.  Whether created by an NFS client or\n\
    \   created locally on the server, the data in a symbolic link is not\n   interpreted\
    \ (except possibly to check for proper UTF-8 encoding) when\n   created, but is\
    \ simply stored.\n   On success, the current filehandle retains its value.\n"
- title: 18.24.4.  IMPLEMENTATION
  contents:
  - "18.24.4.  IMPLEMENTATION\n   A symbolic link is nominally a pointer to another\
    \ file.  The data is\n   not necessarily interpreted by the server, just stored\
    \ in the file.\n   It is possible for a client implementation to store a pathname\
    \ that\n   is not meaningful to the server operating system in a symbolic link.\n\
    \   A READLINK operation returns the data to the client for\n   interpretation.\
    \  If different implementations want to share access to\n   symbolic links, then\
    \ they must agree on the interpretation of the\n   data in the symbolic link.\n\
    \   The READLINK operation is only allowed on objects of type NF4LNK.\n   The\
    \ server should return the error NFS4ERR_WRONG_TYPE if the object\n   is not of\
    \ type NF4LNK.\n"
- title: '18.25.  Operation 28: REMOVE - Remove File System Object'
  contents:
  - '18.25.  Operation 28: REMOVE - Remove File System Object

    '
- title: 18.25.1.  ARGUMENTS
  contents:
  - "18.25.1.  ARGUMENTS\n   struct REMOVE4args {\n           /* CURRENT_FH: directory\
    \ */\n           component4      target;\n   };\n"
- title: 18.25.2.  RESULTS
  contents:
  - "18.25.2.  RESULTS\n   struct REMOVE4resok {\n           change_info4    cinfo;\n\
    \   };\n   union REMOVE4res switch (nfsstat4 status) {\n    case NFS4_OK:\n  \
    \          REMOVE4resok   resok4;\n    default:\n            void;\n   };\n"
- title: 18.25.3.  DESCRIPTION
  contents:
  - "18.25.3.  DESCRIPTION\n   The REMOVE operation removes (deletes) a directory\
    \ entry named by\n   filename from the directory corresponding to the current\
    \ filehandle.\n   If the entry in the directory was the last reference to the\n\
    \   corresponding file system object, the object may be destroyed.  The\n   directory\
    \ may be either of type NF4DIR or NF4ATTRDIR.\n   For the directory where the\
    \ filename was removed, the server returns\n   change_info4 information in cinfo.\
    \  With the atomic field of the\n   change_info4 data type, the server will indicate\
    \ if the before and\n   after change attributes were obtained atomically with\
    \ respect to the\n   removal.\n   If the target has a length of zero, or if the\
    \ target does not obey\n   the UTF-8 definition (and the server is enforcing UTF-8\
    \ encoding; see\n   Section 14.4), the error NFS4ERR_INVAL will be returned.\n\
    \   On success, the current filehandle retains its value.\n"
- title: 18.25.4.  IMPLEMENTATION
  contents:
  - "18.25.4.  IMPLEMENTATION\n   NFSv3 required a different operator RMDIR for directory\
    \ removal and\n   REMOVE for non-directory removal.  This allowed clients to skip\n\
    \   checking the file type when being passed a non-directory delete\n   system\
    \ call (e.g., unlink() [24] in POSIX) to remove a directory, as\n   well as the\
    \ converse (e.g., a rmdir() on a non-directory) because\n   they knew the server\
    \ would check the file type.  NFSv4.1 REMOVE can\n   be used to delete any directory\
    \ entry independent of its file type.\n   The implementor of an NFSv4.1 client's\
    \ entry points from the unlink()\n   and rmdir() system calls should first check\
    \ the file type against the\n   types the system call is allowed to remove before\
    \ sending a REMOVE\n   operation.  Alternatively, the implementor can produce\
    \ a COMPOUND\n   call that includes a LOOKUP/VERIFY sequence of operations to\
    \ verify\n   the file type before a REMOVE operation in the same COMPOUND call.\n\
    \   The concept of last reference is server specific.  However, if the\n   numlinks\
    \ field in the previous attributes of the object had the value\n   1, the client\
    \ should not rely on referring to the object via a\n   filehandle.  Likewise,\
    \ the client should not rely on the resources\n   (disk space, directory entry,\
    \ and so on) formerly associated with the\n   object becoming immediately available.\
    \  Thus, if a client needs to be\n   able to continue to access a file after using\
    \ REMOVE to remove it,\n   the client should take steps to make sure that the\
    \ file will still be\n   accessible.  While the traditional mechanism used is\
    \ to RENAME the\n   file from its old name to a new hidden name, the NFSv4.1 OPEN\n\
    \   operation MAY return a result flag, OPEN4_RESULT_PRESERVE_UNLINKED,\n   which\
    \ indicates to the client that the file will be preserved if the\n   file has\
    \ an outstanding open (see Section 18.16).\n   If the server finds that the file\
    \ is still open when the REMOVE\n   arrives:\n   *  The server SHOULD NOT delete\
    \ the file's directory entry if the\n      file was opened with OPEN4_SHARE_DENY_WRITE\
    \ or\n      OPEN4_SHARE_DENY_BOTH.\n   *  If the file was not opened with OPEN4_SHARE_DENY_WRITE\
    \ or\n      OPEN4_SHARE_DENY_BOTH, the server SHOULD delete the file's\n     \
    \ directory entry.  However, until last CLOSE of the file, the\n      server MAY\
    \ continue to allow access to the file via its\n      filehandle.\n   *  The server\
    \ MUST NOT delete the directory entry if the reply from\n      OPEN had the flag\
    \ OPEN4_RESULT_PRESERVE_UNLINKED set.\n   The server MAY implement its own restrictions\
    \ on removal of a file\n   while it is open.  The server might disallow such a\
    \ REMOVE (or a\n   removal that occurs as part of RENAME).  The conditions that\n\
    \   influence the restrictions on removal of a file while it is still\n   open\
    \ include:\n   *  Whether certain access protocols (i.e., not just NFS) are holding\n\
    \      the file open.\n   *  Whether particular options, access modes, or policies\
    \ on the\n      server are enabled.\n   If a file has an outstanding OPEN and\
    \ this prevents the removal of\n   the file's directory entry, the error NFS4ERR_FILE_OPEN\
    \ is returned.\n   Where the determination above cannot be made definitively because\n\
    \   delegations are being held, they MUST be recalled to allow processing\n  \
    \ of the REMOVE to continue.  When a delegation is held, the server has\n   no\
    \ reliable knowledge of the status of OPENs for that client, so\n   unless there\
    \ are files opened with the particular deny modes by\n   clients without delegations,\
    \ the determination cannot be made until\n   delegations are recalled, and the\
    \ operation cannot proceed until each\n   sufficient delegation has been returned\
    \ or revoked to allow the\n   server to make a correct determination.\n   In all\
    \ cases in which delegations are recalled, the server is likely\n   to return\
    \ one or more NFS4ERR_DELAY errors while delegations remain\n   outstanding.\n\
    \   If the current filehandle designates a directory for which another\n   client\
    \ holds a directory delegation, then, unless the situation can\n   be resolved\
    \ by sending a notification, the directory delegation MUST\n   be recalled, and\
    \ the operation MUST NOT proceed until the delegation\n   is returned or revoked.\
    \  Except where this happens very quickly, one\n   or more NFS4ERR_DELAY errors\
    \ will be returned to requests made while\n   delegation remains outstanding.\n\
    \   When the current filehandle designates a directory for which one or\n   more\
    \ directory delegations exist, then, when those delegations\n   request such notifications,\
    \ NOTIFY4_REMOVE_ENTRY will be generated as\n   a result of this operation.\n\
    \   Note that when a remove occurs as a result of a RENAME,\n   NOTIFY4_REMOVE_ENTRY\
    \ will only be generated if the removal happens as\n   a separate operation. \
    \ In the case in which the removal is integrated\n   and atomic with RENAME, the\
    \ notification of the removal is integrated\n   with notification for the RENAME.\
    \  See the discussion of the\n   NOTIFY4_RENAME_ENTRY notification in Section\
    \ 20.4.\n"
- title: '18.26.  Operation 29: RENAME - Rename Directory Entry'
  contents:
  - '18.26.  Operation 29: RENAME - Rename Directory Entry

    '
- title: 18.26.1.  ARGUMENTS
  contents:
  - "18.26.1.  ARGUMENTS\n   struct RENAME4args {\n           /* SAVED_FH: source\
    \ directory */\n           component4      oldname;\n           /* CURRENT_FH:\
    \ target directory */\n           component4      newname;\n   };\n"
- title: 18.26.2.  RESULTS
  contents:
  - "18.26.2.  RESULTS\n   struct RENAME4resok {\n           change_info4    source_cinfo;\n\
    \           change_info4    target_cinfo;\n   };\n   union RENAME4res switch (nfsstat4\
    \ status) {\n    case NFS4_OK:\n           RENAME4resok    resok4;\n    default:\n\
    \           void;\n   };\n"
- title: 18.26.3.  DESCRIPTION
  contents:
  - "18.26.3.  DESCRIPTION\n   The RENAME operation renames the object identified\
    \ by oldname in the\n   source directory corresponding to the saved filehandle,\
    \ as set by the\n   SAVEFH operation, to newname in the target directory corresponding\
    \ to\n   the current filehandle.  The operation is required to be atomic to\n\
    \   the client.  Source and target directories MUST reside on the same\n   file\
    \ system on the server.  On success, the current filehandle will\n   continue\
    \ to be the target directory.\n   If the target directory already contains an\
    \ entry with the name\n   newname, the source object MUST be compatible with the\
    \ target: either\n   both are non-directories or both are directories and the\
    \ target MUST\n   be empty.  If compatible, the existing target is removed before\
    \ the\n   rename occurs or, preferably, the target is removed atomically as\n\
    \   part of the rename.  See Section 18.25.4 for client and server\n   actions\
    \ whenever a target is removed.  Note however that when the\n   removal is performed\
    \ atomically with the rename, certain parts of the\n   removal described there\
    \ are integrated with the rename.  For example,\n   notification of the removal\
    \ will not be via a NOTIFY4_REMOVE_ENTRY\n   but will be indicated as part of\
    \ the NOTIFY4_ADD_ENTRY or\n   NOTIFY4_RENAME_ENTRY generated by the rename.\n\
    \   If the source object and the target are not compatible or if the\n   target\
    \ is a directory but not empty, the server will return the error\n   NFS4ERR_EXIST.\n\
    \   If oldname and newname both refer to the same file (e.g., they might\n   be\
    \ hard links of each other), then unless the file is open (see\n   Section 18.26.4),\
    \ RENAME MUST perform no action and return NFS4_OK.\n   For both directories involved\
    \ in the RENAME, the server returns\n   change_info4 information.  With the atomic\
    \ field of the change_info4\n   data type, the server will indicate if the before\
    \ and after change\n   attributes were obtained atomically with respect to the\
    \ rename.\n   If oldname refers to a named attribute and the saved and current\n\
    \   filehandles refer to different file system objects, the server will\n   return\
    \ NFS4ERR_XDEV just as if the saved and current filehandles\n   represented directories\
    \ on different file systems.\n   If oldname or newname has a length of zero, or\
    \ if oldname or newname\n   does not obey the UTF-8 definition, the error NFS4ERR_INVAL\
    \ will be\n   returned.\n"
- title: 18.26.4.  IMPLEMENTATION
  contents:
  - "18.26.4.  IMPLEMENTATION\n   The server MAY impose restrictions on the RENAME\
    \ operation such that\n   RENAME may not be done when the file being renamed is\
    \ open or when\n   that open is done by particular protocols, or with particular\
    \ options\n   or access modes.  Similar restrictions may be applied when a file\n\
    \   exists with the target name and is open.  When RENAME is rejected\n   because\
    \ of such restrictions, the error NFS4ERR_FILE_OPEN is\n   returned.\n   When\
    \ oldname and rename refer to the same file and that file is open\n   in a fashion\
    \ such that RENAME would normally be rejected with\n   NFS4ERR_FILE_OPEN if oldname\
    \ and newname were different files, then\n   RENAME SHOULD be rejected with NFS4ERR_FILE_OPEN.\n\
    \   If a server does implement such restrictions and those restrictions\n   include\
    \ cases of NFSv4 opens preventing successful execution of a\n   rename, the server\
    \ needs to recall any delegations that could hide\n   the existence of opens relevant\
    \ to that decision.  This is because\n   when a client holds a delegation, the\
    \ server might not have an\n   accurate account of the opens for that client,\
    \ since the client may\n   execute OPENs and CLOSEs locally.  The RENAME operation\
    \ need only be\n   delayed until a definitive result can be obtained.  For example,\
    \ if\n   there are multiple delegations and one of them establishes an open\n\
    \   whose presence would prevent the rename, given the server's\n   semantics,\
    \ NFS4ERR_FILE_OPEN may be returned to the caller as soon as\n   that delegation\
    \ is returned without waiting for other delegations to\n   be returned.  Similarly,\
    \ if such opens are not associated with\n   delegations, NFS4ERR_FILE_OPEN can\
    \ be returned immediately with no\n   delegation recall being done.\n   If the\
    \ current filehandle or the saved filehandle designates a\n   directory for which\
    \ another client holds a directory delegation,\n   then, unless the situation\
    \ can be resolved by sending a notification,\n   the delegation MUST be recalled,\
    \ and the operation cannot proceed\n   until the delegation is returned or revoked.\
    \  Except where this\n   happens very quickly, one or more NFS4ERR_DELAY errors\
    \ will be\n   returned to requests made while delegation remains outstanding.\n\
    \   When the current and saved filehandles are the same and they\n   designate\
    \ a directory for which one or more directory delegations\n   exist, then, when\
    \ those delegations request such notifications, a\n   notification of type NOTIFY4_RENAME_ENTRY\
    \ will be generated as a\n   result of this operation.  When oldname and rename\
    \ refer to the same\n   file, no notification is generated (because, as Section\
    \ 18.26.3\n   states, the server MUST take no action).  When a file is removed\n\
    \   because it has the same name as the target, if that removal is done\n   atomically\
    \ with the rename, a NOTIFY4_REMOVE_ENTRY notification will\n   not be generated.\
    \  Instead, the deletion of the file will be reported\n   as part of the NOTIFY4_RENAME_ENTRY\
    \ notification.\n   When the current and saved filehandles are not the same:\n\
    \   *  If the current filehandle designates a directory for which one or\n   \
    \   more directory delegations exist, then, when those delegations\n      request\
    \ such notifications, NOTIFY4_ADD_ENTRY will be generated as\n      a result of\
    \ this operation.  When a file is removed because it has\n      the same name\
    \ as the target, if that removal is done atomically\n      with the rename, a\
    \ NOTIFY4_REMOVE_ENTRY notification will not be\n      generated.  Instead, the\
    \ deletion of the file will be reported as\n      part of the NOTIFY4_ADD_ENTRY\
    \ notification.\n   *  If the saved filehandle designates a directory for which\
    \ one or\n      more directory delegations exist, then, when those delegations\n\
    \      request such notifications, NOTIFY4_REMOVE_ENTRY will be generated\n  \
    \    as a result of this operation.\n   If the object being renamed has file delegations\
    \ held by clients\n   other than the one doing the RENAME, the delegations MUST\
    \ be\n   recalled, and the operation cannot proceed until each such delegation\n\
    \   is returned or revoked.  Note that in the case of multiply linked\n   files,\
    \ the delegation recall requirement applies even if the\n   delegation was obtained\
    \ through a different name than the one being\n   renamed.  In all cases in which\
    \ delegations are recalled, the server\n   is likely to return one or more NFS4ERR_DELAY\
    \ errors while the\n   delegation(s) remains outstanding, although it might not\
    \ do that if\n   the delegations are returned quickly.\n   The RENAME operation\
    \ must be atomic to the client.  The statement\n   \"source and target directories\
    \ MUST reside on the same file system on\n   the server\" means that the fsid\
    \ fields in the attributes for the\n   directories are the same.  If they reside\
    \ on different file systems,\n   the error NFS4ERR_XDEV is returned.\n   Based\
    \ on the value of the fh_expire_type attribute for the object,\n   the filehandle\
    \ may or may not expire on a RENAME.  However, server\n   implementors are strongly\
    \ encouraged to attempt to keep filehandles\n   from expiring in this fashion.\n\
    \   On some servers, the file names \".\" and \"..\" are illegal as either\n \
    \  oldname or newname, and will result in the error NFS4ERR_BADNAME.  In\n   addition,\
    \ on many servers the case of oldname or newname being an\n   alias for the source\
    \ directory will be checked for.  Such servers\n   will return the error NFS4ERR_INVAL\
    \ in these cases.\n   If either of the source or target filehandles are not directories,\n\
    \   the server will return NFS4ERR_NOTDIR.\n"
- title: '18.27.  Operation 31: RESTOREFH - Restore Saved Filehandle'
  contents:
  - '18.27.  Operation 31: RESTOREFH - Restore Saved Filehandle

    '
- title: 18.27.1.  ARGUMENTS
  contents:
  - "18.27.1.  ARGUMENTS\n   /* SAVED_FH: */\n   void;\n"
- title: 18.27.2.  RESULTS
  contents:
  - "18.27.2.  RESULTS\n   struct RESTOREFH4res {\n           /*\n            * If\
    \ status is NFS4_OK,\n            *     new CURRENT_FH: value of saved fh\n  \
    \          */\n           nfsstat4        status;\n   };\n"
- title: 18.27.3.  DESCRIPTION
  contents:
  - "18.27.3.  DESCRIPTION\n   The RESTOREFH operation sets the current filehandle\
    \ and stateid to\n   the values in the saved filehandle and stateid.  If there\
    \ is no saved\n   filehandle, then the server will return the error\n   NFS4ERR_NOFILEHANDLE.\n\
    \   See Section 16.2.3.1.1 for more details on the current filehandle.\n   See\
    \ Section 16.2.3.1.2 for more details on the current stateid.\n"
- title: 18.27.4.  IMPLEMENTATION
  contents:
  - "18.27.4.  IMPLEMENTATION\n   Operations like OPEN and LOOKUP use the current\
    \ filehandle to\n   represent a directory and replace it with a new filehandle.\
    \  Assuming\n   that the previous filehandle was saved with a SAVEFH operator,\
    \ the\n   previous filehandle can be restored as the current filehandle.  This\n\
    \   is commonly used to obtain post-operation attributes for the\n   directory,\
    \ e.g.,\n         PUTFH (directory filehandle)\n         SAVEFH\n         GETATTR\
    \ attrbits     (pre-op dir attrs)\n         CREATE optbits \"foo\" attrs\n   \
    \      GETATTR attrbits     (file attributes)\n         RESTOREFH\n         GETATTR\
    \ attrbits     (post-op dir attrs)\n"
- title: '18.28.  Operation 32: SAVEFH - Save Current Filehandle'
  contents:
  - '18.28.  Operation 32: SAVEFH - Save Current Filehandle

    '
- title: 18.28.1.  ARGUMENTS
  contents:
  - "18.28.1.  ARGUMENTS\n   /* CURRENT_FH: */\n   void;\n"
- title: 18.28.2.  RESULTS
  contents:
  - "18.28.2.  RESULTS\n   struct SAVEFH4res {\n           /*\n            * If status\
    \ is NFS4_OK,\n            *    new SAVED_FH: value of current fh\n          \
    \  */\n           nfsstat4        status;\n   };\n"
- title: 18.28.3.  DESCRIPTION
  contents:
  - "18.28.3.  DESCRIPTION\n   The SAVEFH operation saves the current filehandle and\
    \ stateid.  If a\n   previous filehandle was saved, then it is no longer accessible.\
    \  The\n   saved filehandle can be restored as the current filehandle with the\n\
    \   RESTOREFH operator.\n   On success, the current filehandle retains its value.\n\
    \   See Section 16.2.3.1.1 for more details on the current filehandle.\n   See\
    \ Section 16.2.3.1.2 for more details on the current stateid.\n"
- title: 18.28.4.  IMPLEMENTATION
  contents:
  - '18.28.4.  IMPLEMENTATION

    '
- title: '18.29.  Operation 33: SECINFO - Obtain Available Security'
  contents:
  - '18.29.  Operation 33: SECINFO - Obtain Available Security

    '
- title: 18.29.1.  ARGUMENTS
  contents:
  - "18.29.1.  ARGUMENTS\n   struct SECINFO4args {\n           /* CURRENT_FH: directory\
    \ */\n           component4      name;\n   };\n"
- title: 18.29.2.  RESULTS
  contents:
  - "18.29.2.  RESULTS\n   /*\n    * From RFC 2203\n    */\n   enum rpc_gss_svc_t\
    \ {\n           RPC_GSS_SVC_NONE        = 1,\n           RPC_GSS_SVC_INTEGRITY\
    \   = 2,\n           RPC_GSS_SVC_PRIVACY     = 3\n   };\n   struct rpcsec_gss_info\
    \ {\n           sec_oid4        oid;\n           qop4            qop;\n      \
    \     rpc_gss_svc_t   service;\n   };\n   /* RPCSEC_GSS has a value of '6' - See\
    \ RFC 2203 */\n   union secinfo4 switch (uint32_t flavor) {\n    case RPCSEC_GSS:\n\
    \            rpcsec_gss_info        flavor_info;\n    default:\n            void;\n\
    \   };\n   typedef secinfo4 SECINFO4resok<>;\n   union SECINFO4res switch (nfsstat4\
    \ status) {\n    case NFS4_OK:\n           /* CURRENTFH: consumed */\n       \
    \     SECINFO4resok resok4;\n    default:\n            void;\n   };\n"
- title: 18.29.3.  DESCRIPTION
  contents:
  - "18.29.3.  DESCRIPTION\n   The SECINFO operation is used by the client to obtain\
    \ a list of valid\n   RPC authentication flavors for a specific directory filehandle,\
    \ file\n   name pair.  SECINFO should apply the same access methodology used for\n\
    \   LOOKUP when evaluating the name.  Therefore, if the requester does\n   not\
    \ have the appropriate access to LOOKUP the name, then SECINFO MUST\n   behave\
    \ the same way and return NFS4ERR_ACCESS.\n   The result will contain an array\
    \ that represents the security\n   mechanisms available, with an order corresponding\
    \ to the server's\n   preferences, the most preferred being first in the array.\
    \  The client\n   is free to pick whatever security mechanism it both desires\
    \ and\n   supports, or to pick in the server's preference order the first one\n\
    \   it supports.  The array entries are represented by the secinfo4\n   structure.\
    \  The field 'flavor' will contain a value of AUTH_NONE,\n   AUTH_SYS (as defined\
    \ in RFC 5531 [3]), or RPCSEC_GSS (as defined in\n   RFC 2203 [4]).  The field\
    \ flavor can also be any other security\n   flavor registered with IANA.\n   For\
    \ the flavors AUTH_NONE and AUTH_SYS, no additional security\n   information is\
    \ returned.  The same is true of many (if not most)\n   other security flavors,\
    \ including AUTH_DH.  For a return value of\n   RPCSEC_GSS, a security triple\
    \ is returned that contains the mechanism\n   object identifier (OID, as defined\
    \ in RFC 2743 [7]), the quality of\n   protection (as defined in RFC 2743 [7]),\
    \ and the service type (as\n   defined in RFC 2203 [4]).  It is possible for SECINFO\
    \ to return\n   multiple entries with flavor equal to RPCSEC_GSS with different\n\
    \   security triple values.\n   On success, the current filehandle is consumed\
    \ (see\n   Section 2.6.3.1.1.8), and if the next operation after SECINFO tries\n\
    \   to use the current filehandle, that operation will fail with the\n   status\
    \ NFS4ERR_NOFILEHANDLE.\n   If the name has a length of zero, or if the name does\
    \ not obey the\n   UTF-8 definition (assuming UTF-8 capabilities are enabled;\
    \ see\n   Section 14.4), the error NFS4ERR_INVAL will be returned.\n   See Section\
    \ 2.6 for additional information on the use of SECINFO.\n"
- title: 18.29.4.  IMPLEMENTATION
  contents:
  - "18.29.4.  IMPLEMENTATION\n   The SECINFO operation is expected to be used by\
    \ the NFS client when\n   the error value of NFS4ERR_WRONGSEC is returned from\
    \ another NFS\n   operation.  This signifies to the client that the server's security\n\
    \   policy is different from what the client is currently using.  At this\n  \
    \ point, the client is expected to obtain a list of possible security\n   flavors\
    \ and choose what best suits its policies.\n   As mentioned, the server's security\
    \ policies will determine when a\n   client request receives NFS4ERR_WRONGSEC.\
    \  See Table 14 for a list of\n   operations that can return NFS4ERR_WRONGSEC.\
    \  In addition, when\n   READDIR returns attributes, the rdattr_error (Section\
    \ 5.8.1.12) can\n   contain NFS4ERR_WRONGSEC.  Note that CREATE and REMOVE MUST\
    \ NOT\n   return NFS4ERR_WRONGSEC.  The rationale for CREATE is that unless the\n\
    \   target name exists, it cannot have a separate security policy from\n   the\
    \ parent directory, and the security policy of the parent was\n   checked when\
    \ its filehandle was injected into the COMPOUND request's\n   operations stream\
    \ (for similar reasons, an OPEN operation that\n   creates the target MUST NOT\
    \ return NFS4ERR_WRONGSEC).  If the target\n   name exists, while it might have\
    \ a separate security policy, that is\n   irrelevant because CREATE MUST return\
    \ NFS4ERR_EXIST.  The rationale\n   for REMOVE is that while that target might\
    \ have a separate security\n   policy, the target is going to be removed, and\
    \ so the security policy\n   of the parent trumps that of the object being removed.\
    \  RENAME and\n   LINK MAY return NFS4ERR_WRONGSEC, but the NFS4ERR_WRONGSEC error\n\
    \   applies only to the saved filehandle (see Section 2.6.3.1.2).  Any\n   NFS4ERR_WRONGSEC\
    \ error on the current filehandle used by LINK and\n   RENAME MUST be returned\
    \ by the PUTFH, PUTPUBFH, PUTROOTFH, or\n   RESTOREFH operation that injected\
    \ the current filehandle.\n   With the exception of LINK and RENAME, the set of\
    \ operations that can\n   return NFS4ERR_WRONGSEC represents the point at which\
    \ the client can\n   inject a filehandle into the \"current filehandle\" at the\
    \ server.  The\n   filehandle is either provided by the client (PUTFH, PUTPUBFH,\n\
    \   PUTROOTFH), generated as a result of a name-to-filehandle translation\n  \
    \ (LOOKUP and OPEN), or generated from the saved filehandle via\n   RESTOREFH.\
    \  As Section 2.6.3.1.1.1 states, a put filehandle operation\n   followed by SAVEFH\
    \ MUST NOT return NFS4ERR_WRONGSEC.  Thus, the\n   RESTOREFH operation, under\
    \ certain conditions (see\n   Section 2.6.3.1.1), is permitted to return NFS4ERR_WRONGSEC\
    \ so that\n   security policies can be honored.\n   The READDIR operation will\
    \ not directly return the NFS4ERR_WRONGSEC\n   error.  However, if the READDIR\
    \ request included a request for\n   attributes, it is possible that the READDIR\
    \ request's security triple\n   did not match that of a directory entry.  If this\
    \ is the case and the\n   client has requested the rdattr_error attribute, the\
    \ server will\n   return the NFS4ERR_WRONGSEC error in rdattr_error for the entry.\n\
    \   To resolve an error return of NFS4ERR_WRONGSEC, the client does the\n   following:\n\
    \   *  For LOOKUP and OPEN, the client will use SECINFO with the same\n      current\
    \ filehandle and name as provided in the original LOOKUP or\n      OPEN to enumerate\
    \ the available security triples.\n   *  For the rdattr_error, the client will\
    \ use SECINFO with the same\n      current filehandle as provided in the original\
    \ READDIR.  The name\n      passed to SECINFO will be that of the directory entry\
    \ (as returned\n      from READDIR) that had the NFS4ERR_WRONGSEC error in the\n\
    \      rdattr_error attribute.\n   *  For PUTFH, PUTROOTFH, PUTPUBFH, RESTOREFH,\
    \ LINK, and RENAME, the\n      client will use SECINFO_NO_NAME { style =\n   \
    \   SECINFO_STYLE4_CURRENT_FH }.  The client will prefix the\n      SECINFO_NO_NAME\
    \ operation with the appropriate PUTFH, PUTPUBFH, or\n      PUTROOTFH operation\
    \ that provides the filehandle originally\n      provided by the PUTFH, PUTPUBFH,\
    \ PUTROOTFH, or RESTOREFH\n      operation.\n      NOTE: In NFSv4.0, the client\
    \ was required to use SECINFO, and had\n      to reconstruct the parent of the\
    \ original filehandle and the\n      component name of the original filehandle.\
    \  The introduction in\n      NFSv4.1 of SECINFO_NO_NAME obviates the need for\
    \ reconstruction.\n   *  For LOOKUPP, the client will use SECINFO_NO_NAME { style\
    \ =\n      SECINFO_STYLE4_PARENT } and provide the filehandle that equals the\n\
    \      filehandle originally provided to LOOKUPP.\n   See Section 21 for a discussion\
    \ on the recommendations for the\n   security flavor used by SECINFO and SECINFO_NO_NAME.\n"
- title: '18.30.  Operation 34: SETATTR - Set Attributes'
  contents:
  - '18.30.  Operation 34: SETATTR - Set Attributes

    '
- title: 18.30.1.  ARGUMENTS
  contents:
  - "18.30.1.  ARGUMENTS\n   struct SETATTR4args {\n           /* CURRENT_FH: target\
    \ object */\n           stateid4        stateid;\n           fattr4          obj_attributes;\n\
    \   };\n"
- title: 18.30.2.  RESULTS
  contents:
  - "18.30.2.  RESULTS\n   struct SETATTR4res {\n           nfsstat4        status;\n\
    \           bitmap4         attrsset;\n   };\n"
- title: 18.30.3.  DESCRIPTION
  contents:
  - "18.30.3.  DESCRIPTION\n   The SETATTR operation changes one or more of the attributes\
    \ of a file\n   system object.  The new attributes are specified with a bitmap\
    \ and\n   the attributes that follow the bitmap in bit order.\n   The stateid\
    \ argument for SETATTR is used to provide byte-range\n   locking context that\
    \ is necessary for SETATTR requests that set the\n   size attribute.  Since setting\
    \ the size attribute modifies the file's\n   data, it has the same locking requirements\
    \ as a corresponding WRITE.\n   Any SETATTR that sets the size attribute is incompatible\
    \ with a share\n   reservation that specifies OPEN4_SHARE_DENY_WRITE.  The area\
    \ between\n   the old end-of-file and the new end-of-file is considered to be\n\
    \   modified just as would have been the case had the area in question\n   been\
    \ specified as the target of WRITE, for the purpose of checking\n   conflicts\
    \ with byte-range locks, for those cases in which a server is\n   implementing\
    \ mandatory byte-range locking behavior.  A valid stateid\n   SHOULD always be\
    \ specified.  When the file size attribute is not set,\n   the special stateid\
    \ consisting of all bits equal to zero MAY be\n   passed.\n   On either success\
    \ or failure of the operation, the server will return\n   the attrsset bitmask\
    \ to represent what (if any) attributes were\n   successfully set.  The attrsset\
    \ in the response is a subset of the\n   attrmask field of the obj_attributes\
    \ field in the argument.\n   On success, the current filehandle retains its value.\n"
- title: 18.30.4.  IMPLEMENTATION
  contents:
  - "18.30.4.  IMPLEMENTATION\n   If the request specifies the owner attribute to\
    \ be set, the server\n   SHOULD allow the operation to succeed if the current\
    \ owner of the\n   object matches the value specified in the request.  Some servers\
    \ may\n   be implemented in a way as to prohibit the setting of the owner\n  \
    \ attribute unless the requester has privilege to do so.  If the server\n   is\
    \ lenient in this one case of matching owner values, the client\n   implementation\
    \ may be simplified in cases of creation of an object\n   (e.g., an exclusive\
    \ create via OPEN) followed by a SETATTR.\n   The file size attribute is used\
    \ to request changes to the size of a\n   file.  A value of zero causes the file\
    \ to be truncated, a value less\n   than the current size of the file causes data\
    \ from new size to the\n   end of the file to be discarded, and a size greater\
    \ than the current\n   size of the file causes logically zeroed data bytes to\
    \ be added to\n   the end of the file.  Servers are free to implement this using\n\
    \   unallocated bytes (holes) or allocated data bytes set to zero.\n   Clients\
    \ should not make any assumptions regarding a server's\n   implementation of this\
    \ feature, beyond that the bytes in the affected\n   byte-range returned by READ\
    \ will be zeroed.  Servers MUST support\n   extending the file size via SETATTR.\n\
    \   SETATTR is not guaranteed to be atomic.  A failed SETATTR may\n   partially\
    \ change a file's attributes, hence the reason why the reply\n   always includes\
    \ the status and the list of attributes that were set.\n   If the object whose\
    \ attributes are being changed has a file\n   delegation that is held by a client\
    \ other than the one doing the\n   SETATTR, the delegation(s) must be recalled,\
    \ and the operation cannot\n   proceed to actually change an attribute until each\
    \ such delegation is\n   returned or revoked.  In all cases in which delegations\
    \ are recalled,\n   the server is likely to return one or more NFS4ERR_DELAY errors\
    \ while\n   the delegation(s) remains outstanding, although it might not do that\n\
    \   if the delegations are returned quickly.\n   If the object whose attributes\
    \ are being set is a directory and\n   another client holds a directory delegation\
    \ for that directory, then\n   if enabled, asynchronous notifications will be\
    \ generated when the set\n   of attributes changed has a non-null intersection\
    \ with the set of\n   attributes for which notification is requested.  Notifications\
    \ of\n   type NOTIFY4_CHANGE_DIR_ATTRS will be sent to the appropriate\n   client(s),\
    \ but the SETATTR is not delayed by waiting for these\n   notifications to be\
    \ sent.\n   If the object whose attributes are being set is a member of the\n\
    \   directory for which another client holds a directory delegation, then\n  \
    \ asynchronous notifications will be generated when the set of\n   attributes\
    \ changed has a non-null intersection with the set of\n   attributes for which\
    \ notification is requested.  Notifications of\n   type NOTIFY4_CHANGE_CHILD_ATTRS\
    \ will be sent to the appropriate\n   clients, but the SETATTR is not delayed\
    \ by waiting for these\n   notifications to be sent.\n   Changing the size of\
    \ a file with SETATTR indirectly changes the\n   time_modify and change attributes.\
    \  A client must account for this as\n   size changes can result in data deletion.\n\
    \   The attributes time_access_set and time_modify_set are write-only\n   attributes\
    \ constructed as a switched union so the client can direct\n   the server in setting\
    \ the time values.  If the switched union\n   specifies SET_TO_CLIENT_TIME4, the\
    \ client has provided an nfstime4 to\n   be used for the operation.  If the switch\
    \ union does not specify\n   SET_TO_CLIENT_TIME4, the server is to use its current\
    \ time for the\n   SETATTR operation.\n   If server and client times differ, programs\
    \ that compare client time\n   to file times can break.  A time synchronization\
    \ protocol should be\n   used to limit client/server time skew.\n   Use of a COMPOUND\
    \ containing a VERIFY operation specifying only the\n   change attribute, immediately\
    \ followed by a SETATTR, provides a means\n   whereby a client may specify a request\
    \ that emulates the\n   functionality of the SETATTR guard mechanism of NFSv3.\
    \  Since the\n   function of the guard mechanism is to avoid changes to the file\n\
    \   attributes based on stale information, delays between checking of the\n  \
    \ guard condition and the setting of the attributes have the potential\n   to\
    \ compromise this function, as would the corresponding delay in the\n   NFSv4\
    \ emulation.  Therefore, NFSv4.1 servers SHOULD take care to\n   avoid such delays,\
    \ to the degree possible, when executing such a\n   request.\n   If the server\
    \ does not support an attribute as requested by the\n   client, the server SHOULD\
    \ return NFS4ERR_ATTRNOTSUPP.\n   A mask of the attributes actually set is returned\
    \ by SETATTR in all\n   cases.  That mask MUST NOT include attribute bits not\
    \ requested to be\n   set by the client.  If the attribute masks in the request\
    \ and reply\n   are equal, the status field in the reply MUST be NFS4_OK.\n"
- title: '18.31.  Operation 37: VERIFY - Verify Same Attributes'
  contents:
  - '18.31.  Operation 37: VERIFY - Verify Same Attributes

    '
- title: 18.31.1.  ARGUMENTS
  contents:
  - "18.31.1.  ARGUMENTS\n   struct VERIFY4args {\n           /* CURRENT_FH: object\
    \ */\n           fattr4          obj_attributes;\n   };\n"
- title: 18.31.2.  RESULTS
  contents:
  - "18.31.2.  RESULTS\n   struct VERIFY4res {\n           nfsstat4        status;\n\
    \   };\n"
- title: 18.31.3.  DESCRIPTION
  contents:
  - "18.31.3.  DESCRIPTION\n   The VERIFY operation is used to verify that attributes\
    \ have the value\n   assumed by the client before proceeding with the following\
    \ operations\n   in the COMPOUND request.  If any of the attributes do not match,\
    \ then\n   the error NFS4ERR_NOT_SAME must be returned.  The current filehandle\n\
    \   retains its value after successful completion of the operation.\n"
- title: 18.31.4.  IMPLEMENTATION
  contents:
  - "18.31.4.  IMPLEMENTATION\n   One possible use of the VERIFY operation is the\
    \ following series of\n   operations.  With this, the client is attempting to\
    \ verify that the\n   file being removed will match what the client expects to\
    \ be removed.\n   This series can help prevent the unintended deletion of a file.\n\
    \         PUTFH (directory filehandle)\n         LOOKUP (file name)\n        \
    \ VERIFY (filehandle == fh)\n         PUTFH (directory filehandle)\n         REMOVE\
    \ (file name)\n   This series does not prevent a second client from removing and\n\
    \   creating a new file in the middle of this sequence, but it does help\n   avoid\
    \ the unintended result.\n   In the case that a RECOMMENDED attribute is specified\
    \ in the VERIFY\n   operation and the server does not support that attribute for\
    \ the file\n   system object, the error NFS4ERR_ATTRNOTSUPP is returned to the\n\
    \   client.\n   When the attribute rdattr_error or any set-only attribute (e.g.,\n\
    \   time_modify_set) is specified, the error NFS4ERR_INVAL is returned to\n  \
    \ the client.\n"
- title: '18.32.  Operation 38: WRITE - Write to File'
  contents:
  - '18.32.  Operation 38: WRITE - Write to File

    '
- title: 18.32.1.  ARGUMENTS
  contents:
  - "18.32.1.  ARGUMENTS\n   enum stable_how4 {\n           UNSTABLE4       = 0,\n\
    \           DATA_SYNC4      = 1,\n           FILE_SYNC4      = 2\n   };\n   struct\
    \ WRITE4args {\n           /* CURRENT_FH: file */\n           stateid4       \
    \ stateid;\n           offset4         offset;\n           stable_how4     stable;\n\
    \           opaque          data<>;\n   };\n"
- title: 18.32.2.  RESULTS
  contents:
  - "18.32.2.  RESULTS\n   struct WRITE4resok {\n           count4          count;\n\
    \           stable_how4     committed;\n           verifier4       writeverf;\n\
    \   };\n   union WRITE4res switch (nfsstat4 status) {\n    case NFS4_OK:\n   \
    \         WRITE4resok    resok4;\n    default:\n            void;\n   };\n"
- title: 18.32.3.  DESCRIPTION
  contents:
  - "18.32.3.  DESCRIPTION\n   The WRITE operation is used to write data to a regular\
    \ file.  The\n   target file is specified by the current filehandle.  The offset\n\
    \   specifies the offset where the data should be written.  An offset of\n   zero\
    \ specifies that the write should start at the beginning of the\n   file.  The\
    \ count, as encoded as part of the opaque data parameter,\n   represents the number\
    \ of bytes of data that are to be written.  If\n   the count is zero, the WRITE\
    \ will succeed and return a count of zero\n   subject to permissions checking.\
    \  The server MAY write fewer bytes\n   than requested by the client.\n   The\
    \ client specifies with the stable parameter the method of how the\n   data is\
    \ to be processed by the server.  If stable is FILE_SYNC4, the\n   server MUST\
    \ commit the data written plus all file system metadata to\n   stable storage\
    \ before returning results.  This corresponds to the\n   NFSv2 protocol semantics.\
    \  Any other behavior constitutes a protocol\n   violation.  If stable is DATA_SYNC4,\
    \ then the server MUST commit all\n   of the data to stable storage and enough\
    \ of the metadata to retrieve\n   the data before returning.  The server implementor\
    \ is free to\n   implement DATA_SYNC4 in the same fashion as FILE_SYNC4, but with\
    \ a\n   possible performance drop.  If stable is UNSTABLE4, the server is\n  \
    \ free to commit any part of the data and the metadata to stable\n   storage,\
    \ including all or none, before returning a reply to the\n   client.  There is\
    \ no guarantee whether or when any uncommitted data\n   will subsequently be committed\
    \ to stable storage.  The only\n   guarantees made by the server are that it will\
    \ not destroy any data\n   without changing the value of writeverf and that it\
    \ will not commit\n   the data and metadata at a level less than that requested\
    \ by the\n   client.\n   Except when special stateids are used, the stateid value\
    \ for a WRITE\n   request represents a value returned from a previous byte-range\
    \ LOCK\n   or OPEN request or the stateid associated with a delegation.  The\n\
    \   stateid identifies the associated owners if any and is used by the\n   server\
    \ to verify that the associated locks are still valid (e.g.,\n   have not been\
    \ revoked).\n   Upon successful completion, the following results are returned.\
    \  The\n   count result is the number of bytes of data written to the file.  The\n\
    \   server may write fewer bytes than requested.  If so, the actual\n   number\
    \ of bytes written starting at location, offset, is returned.\n   The server also\
    \ returns an indication of the level of commitment of\n   the data and metadata\
    \ via committed.  Per Table 20,\n   *  The server MAY commit the data at a stronger\
    \ level than requested.\n   *  The server MUST commit the data at a level at least\
    \ as high as\n      that committed.\n            | stable     | committed    \
    \                     |\n            | UNSTABLE4  | FILE_SYNC4, DATA_SYNC4, UNSTABLE4\
    \ |\n            | DATA_SYNC4 | FILE_SYNC4, DATA_SYNC4            |\n        \
    \    | FILE_SYNC4 | FILE_SYNC4                        |\n                Table\
    \ 20: Valid Combinations of the Fields\n                Stable in the Request\
    \ and Committed in the\n   The final portion of the result is the field writeverf.\
    \  This field\n   is the write verifier and is a cookie that the client can use\
    \ to\n   determine whether a server has changed instance state (e.g., server\n\
    \   restart) between a call to WRITE and a subsequent call to either\n   WRITE\
    \ or COMMIT.  This cookie MUST be unchanged during a single\n   instance of the\
    \ NFSv4.1 server and MUST be unique between instances\n   of the NFSv4.1 server.\
    \  If the cookie changes, then the client MUST\n   assume that any data written\
    \ with an UNSTABLE4 value for committed\n   and an old writeverf in the reply\
    \ has been lost and will need to be\n   recovered.\n   If a client writes data\
    \ to the server with the stable argument set to\n   UNSTABLE4 and the reply yields\
    \ a committed response of DATA_SYNC4 or\n   UNSTABLE4, the client will follow\
    \ up some time in the future with a\n   COMMIT operation to synchronize outstanding\
    \ asynchronous data and\n   metadata with the server's stable storage, barring\
    \ client error.  It\n   is possible that due to client crash or other error that\
    \ a subsequent\n   COMMIT will not be received by the server.\n   For a WRITE\
    \ with a stateid value of all bits equal to zero, the\n   server MAY allow the\
    \ WRITE to be serviced subject to mandatory byte-\n   range locks or the current\
    \ share deny modes for the file.  For a\n   WRITE with a stateid value of all\
    \ bits equal to 1, the server MUST\n   NOT allow the WRITE operation to bypass\
    \ locking checks at the server\n   and otherwise is treated as if a stateid of\
    \ all bits equal to zero\n   were used.\n   On success, the current filehandle\
    \ retains its value.\n"
- title: 18.32.4.  IMPLEMENTATION
  contents:
  - "18.32.4.  IMPLEMENTATION\n   It is possible for the server to write fewer bytes\
    \ of data than\n   requested by the client.  In this case, the server SHOULD NOT\
    \ return\n   an error unless no data was written at all.  If the server writes\n\
    \   less than the number of bytes specified, the client will need to send\n  \
    \ another WRITE to write the remaining data.\n   It is assumed that the act of\
    \ writing data to a file will cause the\n   time_modified and change attributes\
    \ of the file to be updated.\n   However, these attributes SHOULD NOT be changed\
    \ unless the contents\n   of the file are changed.  Thus, a WRITE request with\
    \ count set to\n   zero SHOULD NOT cause the time_modified and change attributes\
    \ of the\n   file to be updated.\n   Stable storage is persistent storage that\
    \ survives:\n   1.  Repeated power failures.\n   2.  Hardware failures (of any\
    \ board, power supply, etc.).\n   3.  Repeated software crashes and restarts.\n\
    \   This definition does not address failure of the stable storage module\n  \
    \ itself.\n   The verifier is defined to allow a client to detect different\n\
    \   instances of an NFSv4.1 protocol server over which cached,\n   uncommitted\
    \ data may be lost.  In the most likely case, the verifier\n   allows the client\
    \ to detect server restarts.  This information is\n   required so that the client\
    \ can safely determine whether the server\n   could have lost cached data.  If\
    \ the server fails unexpectedly and\n   the client has uncommitted data from previous\
    \ WRITE requests (done\n   with the stable argument set to UNSTABLE4 and in which\
    \ the result\n   committed was returned as UNSTABLE4 as well), the server might\
    \ not\n   have flushed cached data to stable storage.  The burden of recovery\n\
    \   is on the client, and the client will need to retransmit the data to\n   the\
    \ server.\n   A suggested verifier would be to use the time that the server was\n\
    \   last started (if restarting the server results in lost buffers).\n   The reply's\
    \ committed field allows the client to do more effective\n   caching.  If the\
    \ server is committing all WRITE requests to stable\n   storage, then it SHOULD\
    \ return with committed set to FILE_SYNC4,\n   regardless of the value of the\
    \ stable field in the arguments.  A\n   server that uses an NVRAM accelerator\
    \ may choose to implement this\n   policy.  The client can use this to increase\
    \ the effectiveness of the\n   cache by discarding cached data that has already\
    \ been committed on\n   the server.\n   Some implementations may return NFS4ERR_NOSPC\
    \ instead of\n   NFS4ERR_DQUOT when a user's quota is exceeded.\n   In the case\
    \ that the current filehandle is of type NF4DIR, the server\n   will return NFS4ERR_ISDIR.\
    \  If the current file is a symbolic link,\n   the error NFS4ERR_SYMLINK will\
    \ be returned.  Otherwise, if the\n   current filehandle does not designate an\
    \ ordinary file, the server\n   will return NFS4ERR_WRONG_TYPE.\n   If mandatory\
    \ byte-range locking is in effect for the file, and the\n   corresponding byte-range\
    \ of the data to be written to the file is\n   READ_LT or WRITE_LT locked by an\
    \ owner that is not associated with\n   the stateid, the server MUST return NFS4ERR_LOCKED.\
    \  If so, the\n   client MUST check if the owner corresponding to the stateid\
    \ used with\n   the WRITE operation has a conflicting READ_LT lock that overlaps\
    \ with\n   the byte-range that was to be written.  If the stateid's owner has\
    \ no\n   conflicting READ_LT lock, then the client SHOULD try to get the\n   appropriate\
    \ write byte-range lock via the LOCK operation before re-\n   attempting the WRITE.\
    \  When the WRITE completes, the client SHOULD\n   release the byte-range lock\
    \ via LOCKU.\n   If the stateid's owner had a conflicting READ_LT lock, then the\n\
    \   client has no choice but to return an error to the application that\n   attempted\
    \ the WRITE.  The reason is that since the stateid's owner\n   had a READ_LT lock,\
    \ either the server attempted to temporarily\n   effectively upgrade this READ_LT\
    \ lock to a WRITE_LT lock or the\n   server has no upgrade capability.  If the\
    \ server attempted to upgrade\n   the READ_LT lock and failed, it is pointless\
    \ for the client to re-\n   attempt the upgrade via the LOCK operation, because\
    \ there might be\n   another client also trying to upgrade.  If two clients are\
    \ blocked\n   trying to upgrade the same lock, the clients deadlock.  If the server\n\
    \   has no upgrade capability, then it is pointless to try a LOCK\n   operation\
    \ to upgrade.\n   If one or more other clients have delegations for the file being\n\
    \   written, those delegations MUST be recalled, and the operation cannot\n  \
    \ proceed until those delegations are returned or revoked.  Except\n   where this\
    \ happens very quickly, one or more NFS4ERR_DELAY errors\n   will be returned\
    \ to requests made while the delegation remains\n   outstanding.  Normally, delegations\
    \ will not be recalled as a result\n   of a WRITE operation since the recall will\
    \ occur as a result of an\n   earlier OPEN.  However, since it is possible for\
    \ a WRITE to be done\n   with a special stateid, the server needs to check for\
    \ this case even\n   though the client should have done an OPEN previously.\n"
- title: '18.33.  Operation 40: BACKCHANNEL_CTL - Backchannel Control'
  contents:
  - '18.33.  Operation 40: BACKCHANNEL_CTL - Backchannel Control

    '
- title: 18.33.1.  ARGUMENT
  contents:
  - "18.33.1.  ARGUMENT\n   typedef opaque gsshandle4_t<>;\n   struct gss_cb_handles4\
    \ {\n           rpc_gss_svc_t           gcbp_service; /* RFC 2203 */\n       \
    \    gsshandle4_t            gcbp_handle_from_server;\n           gsshandle4_t\
    \            gcbp_handle_from_client;\n   };\n   union callback_sec_parms4 switch\
    \ (uint32_t cb_secflavor) {\n   case AUTH_NONE:\n           void;\n   case AUTH_SYS:\n\
    \           authsys_parms   cbsp_sys_cred; /* RFC 5531 */\n   case RPCSEC_GSS:\n\
    \           gss_cb_handles4 cbsp_gss_handles;\n   };\n   struct BACKCHANNEL_CTL4args\
    \ {\n           uint32_t                bca_cb_program;\n           callback_sec_parms4\
    \     bca_sec_parms<>;\n   };\n"
- title: 18.33.2.  RESULT
  contents:
  - "18.33.2.  RESULT\n   struct BACKCHANNEL_CTL4res {\n           nfsstat4      \
    \          bcr_status;\n   };\n"
- title: 18.33.3.  DESCRIPTION
  contents:
  - "18.33.3.  DESCRIPTION\n   The BACKCHANNEL_CTL operation replaces the backchannel's\
    \ callback\n   program number and adds (not replaces) RPCSEC_GSS handles for use\
    \ by\n   the backchannel.\n   The arguments of the BACKCHANNEL_CTL call are a\
    \ subset of the\n   CREATE_SESSION parameters.  In the arguments of BACKCHANNEL_CTL,\
    \ the\n   bca_cb_program field and bca_sec_parms fields correspond respectively\n\
    \   to the csa_cb_program and csa_sec_parms fields of the arguments of\n   CREATE_SESSION\
    \ (Section 18.36).\n   BACKCHANNEL_CTL MUST appear in a COMPOUND that starts with\
    \ SEQUENCE.\n   If the RPCSEC_GSS handle identified by gcbp_handle_from_server\
    \ does\n   not exist on the server, the server MUST return NFS4ERR_NOENT.\n  \
    \ If an RPCSEC_GSS handle is using the SSV context (see\n   Section 2.10.9), then\
    \ because each SSV RPCSEC_GSS handle shares a\n   common SSV GSS context, there\
    \ are security considerations specific to\n   this situation discussed in Section\
    \ 2.10.10.\n"
- title: '18.34.  Operation 41: BIND_CONN_TO_SESSION - Associate Connection with'
  contents:
  - "18.34.  Operation 41: BIND_CONN_TO_SESSION - Associate Connection with\n    \
    \    Session\n"
- title: 18.34.1.  ARGUMENT
  contents:
  - "18.34.1.  ARGUMENT\n   enum channel_dir_from_client4 {\n    CDFC4_FORE      \
    \       = 0x1,\n    CDFC4_BACK             = 0x2,\n    CDFC4_FORE_OR_BOTH    \
    \ = 0x3,\n    CDFC4_BACK_OR_BOTH     = 0x7\n   };\n   struct BIND_CONN_TO_SESSION4args\
    \ {\n    sessionid4     bctsa_sessid;\n    channel_dir_from_client4\n        \
    \           bctsa_dir;\n    bool           bctsa_use_conn_in_rdma_mode;\n   };\n"
- title: 18.34.2.  RESULT
  contents:
  - "18.34.2.  RESULT\n   enum channel_dir_from_server4 {\n    CDFS4_FORE     = 0x1,\n\
    \    CDFS4_BACK     = 0x2,\n    CDFS4_BOTH     = 0x3\n   };\n   struct BIND_CONN_TO_SESSION4resok\
    \ {\n    sessionid4     bctsr_sessid;\n    channel_dir_from_server4\n        \
    \           bctsr_dir;\n    bool           bctsr_use_conn_in_rdma_mode;\n   };\n\
    \   union BIND_CONN_TO_SESSION4res\n    switch (nfsstat4 bctsr_status) {\n   \
    \ case NFS4_OK:\n     BIND_CONN_TO_SESSION4resok\n                   bctsr_resok4;\n\
    \    default:       void;\n   };\n"
- title: 18.34.3.  DESCRIPTION
  contents:
  - "18.34.3.  DESCRIPTION\n   BIND_CONN_TO_SESSION is used to associate additional\
    \ connections with\n   a session.  It MUST be used on the connection being associated\
    \ with\n   the session.  It MUST be the only operation in the COMPOUND\n   procedure.\
    \  If SP4_NONE (Section 18.35) state protection is used, any\n   principal, security\
    \ flavor, or RPCSEC_GSS context MAY be used to\n   invoke the operation.  If SP4_MACH_CRED\
    \ is used, RPCSEC_GSS MUST be\n   used with the integrity or privacy services,\
    \ using the principal that\n   created the client ID.  If SP4_SSV is used, RPCSEC_GSS\
    \ with the SSV\n   GSS mechanism (Section 2.10.9) and integrity or privacy MUST\
    \ be used.\n   If, when the client ID was created, the client opted for SP4_NONE\n\
    \   state protection, the client is not required to use\n   BIND_CONN_TO_SESSION\
    \ to associate the connection with the session,\n   unless the client wishes to\
    \ associate the connection with the\n   backchannel.  When SP4_NONE protection\
    \ is used, simply sending a\n   COMPOUND request with a SEQUENCE operation is\
    \ sufficient to associate\n   the connection with the session specified in SEQUENCE.\n\
    \   The field bctsa_dir indicates whether the client wants to associate\n   the\
    \ connection with the fore channel or the backchannel or both\n   channels.  The\
    \ value CDFC4_FORE_OR_BOTH indicates that the client\n   wants to associate the\
    \ connection with both the fore channel and\n   backchannel, but will accept the\
    \ connection being associated to just\n   the fore channel.  The value CDFC4_BACK_OR_BOTH\
    \ indicates that the\n   client wants to associate with both the fore channel\
    \ and backchannel,\n   but will accept the connection being associated with just\
    \ the\n   backchannel.  The server replies in bctsr_dir which channel(s) the\n\
    \   connection is associated with.  If the client specified CDFC4_FORE,\n   the\
    \ server MUST return CDFS4_FORE.  If the client specified\n   CDFC4_BACK, the\
    \ server MUST return CDFS4_BACK.  If the client\n   specified CDFC4_FORE_OR_BOTH,\
    \ the server MUST return CDFS4_FORE or\n   CDFS4_BOTH.  If the client specified\
    \ CDFC4_BACK_OR_BOTH, the server\n   MUST return CDFS4_BACK or CDFS4_BOTH.\n \
    \  See the CREATE_SESSION operation (Section 18.36), and the description\n   of\
    \ the argument csa_use_conn_in_rdma_mode to understand\n   bctsa_use_conn_in_rdma_mode,\
    \ and the description of\n   csr_use_conn_in_rdma_mode to understand bctsr_use_conn_in_rdma_mode.\n\
    \   Invoking BIND_CONN_TO_SESSION on a connection already associated with\n  \
    \ the specified session has no effect, and the server MUST respond with\n   NFS4_OK,\
    \ unless the client is demanding changes to the set of\n   channels the connection\
    \ is associated with.  If so, the server MUST\n   return NFS4ERR_INVAL.\n"
- title: 18.34.4.  IMPLEMENTATION
  contents:
  - "18.34.4.  IMPLEMENTATION\n   If a session's channel loses all connections, depending\
    \ on the client\n   ID's state protection and type of channel, the client might\
    \ need to\n   use BIND_CONN_TO_SESSION to associate a new connection.  If the\n\
    \   server restarted and does not keep the reply cache in stable storage,\n  \
    \ the server will not recognize the session ID.  The client will\n   ultimately\
    \ have to invoke EXCHANGE_ID to create a new client ID and\n   session.\n   Suppose\
    \ SP4_SSV state protection is being used, and\n   BIND_CONN_TO_SESSION is among\
    \ the operations included in the\n   spo_must_enforce set when the client ID was\
    \ created (Section 18.35).\n   If so, there is an issue if SET_SSV is sent, no\
    \ response is returned,\n   and the last connection associated with the client\
    \ ID drops.  The\n   client, per the sessions model, MUST retry the SET_SSV. \
    \ But it needs\n   a new connection to do so, and MUST associate that connection\
    \ with\n   the session via a BIND_CONN_TO_SESSION authenticated with the SSV GSS\n\
    \   mechanism.  The problem is that the RPCSEC_GSS message integrity\n   codes\
    \ use a subkey derived from the SSV as the key and the SSV may\n   have changed.\
    \  While there are multiple recovery strategies, a\n   single, general strategy\
    \ is described here.\n   *  The client reconnects.\n   *  The client assumes that\
    \ the SET_SSV was executed, and so sends\n      BIND_CONN_TO_SESSION with the\
    \ subkey (derived from the new SSV,\n      i.e., what SET_SSV would have set the\
    \ SSV to) used as the key for\n      the RPCSEC_GSS credential message integrity\
    \ codes.\n   *  If the request succeeds, this means that the original attempted\n\
    \      SET_SSV did execute successfully.  The client re-sends the\n      original\
    \ SET_SSV, which the server will reply to via the reply\n      cache.\n   *  If\
    \ the server returns an RPC authentication error, this means that\n      the server's\
    \ current SSV was not changed (and the SET_SSV was\n      likely not executed).\
    \  The client then tries BIND_CONN_TO_SESSION\n      with the subkey derived from\
    \ the old SSV as the key for the\n      RPCSEC_GSS message integrity codes.\n\
    \   *  The attempted BIND_CONN_TO_SESSION with the old SSV should\n      succeed.\
    \  If so, the client re-sends the original SET_SSV.  If the\n      original SET_SSV\
    \ was not executed, then the server executes it.\n      If the original SET_SSV\
    \ was executed but failed, the server will\n      return the SET_SSV from the\
    \ reply cache.\n"
- title: '18.35.  Operation 42: EXCHANGE_ID - Instantiate Client ID'
  contents:
  - "18.35.  Operation 42: EXCHANGE_ID - Instantiate Client ID\n   The EXCHANGE_ID\
    \ operation exchanges long-hand client and server\n   identifiers (owners) and\
    \ provides access to a client ID, creating one\n   if necessary.  This client\
    \ ID becomes associated with the connection\n   on which the operation is done,\
    \ so that it is available when a\n   CREATE_SESSION is done or when the connection\
    \ is used to issue a\n   request on an existing session associated with the current\
    \ client.\n"
- title: 18.35.1.  ARGUMENT
  contents:
  - "18.35.1.  ARGUMENT\n   const EXCHGID4_FLAG_SUPP_MOVED_REFER    = 0x00000001;\n\
    \   const EXCHGID4_FLAG_SUPP_MOVED_MIGR     = 0x00000002;\n   const EXCHGID4_FLAG_BIND_PRINC_STATEID\
    \  = 0x00000100;\n   const EXCHGID4_FLAG_USE_NON_PNFS        = 0x00010000;\n \
    \  const EXCHGID4_FLAG_USE_PNFS_MDS        = 0x00020000;\n   const EXCHGID4_FLAG_USE_PNFS_DS\
    \         = 0x00040000;\n   const EXCHGID4_FLAG_MASK_PNFS           = 0x00070000;\n\
    \   const EXCHGID4_FLAG_UPD_CONFIRMED_REC_A = 0x40000000;\n   const EXCHGID4_FLAG_CONFIRMED_R\
    \         = 0x80000000;\n   struct state_protect_ops4 {\n           bitmap4 spo_must_enforce;\n\
    \           bitmap4 spo_must_allow;\n   };\n   struct ssv_sp_parms4 {\n      \
    \     state_protect_ops4      ssp_ops;\n           sec_oid4                ssp_hash_algs<>;\n\
    \           sec_oid4                ssp_encr_algs<>;\n           uint32_t    \
    \            ssp_window;\n           uint32_t                ssp_num_gss_handles;\n\
    \   };\n   enum state_protect_how4 {\n           SP4_NONE = 0,\n           SP4_MACH_CRED\
    \ = 1,\n           SP4_SSV = 2\n   };\n   union state_protect4_a switch(state_protect_how4\
    \ spa_how) {\n           case SP4_NONE:\n                   void;\n          \
    \ case SP4_MACH_CRED:\n                   state_protect_ops4      spa_mach_ops;\n\
    \           case SP4_SSV:\n                   ssv_sp_parms4           spa_ssv_parms;\n\
    \   };\n   struct EXCHANGE_ID4args {\n           client_owner4           eia_clientowner;\n\
    \           uint32_t                eia_flags;\n           state_protect4_a  \
    \      eia_state_protect;\n           nfs_impl_id4            eia_client_impl_id<1>;\n\
    \   };\n"
- title: 18.35.2.  RESULT
  contents:
  - "18.35.2.  RESULT\n   struct ssv_prot_info4 {\n    state_protect_ops4     spi_ops;\n\
    \    uint32_t               spi_hash_alg;\n    uint32_t               spi_encr_alg;\n\
    \    uint32_t               spi_ssv_len;\n    uint32_t               spi_window;\n\
    \    gsshandle4_t           spi_handles<>;\n   };\n   union state_protect4_r switch(state_protect_how4\
    \ spr_how) {\n    case SP4_NONE:\n            void;\n    case SP4_MACH_CRED:\n\
    \            state_protect_ops4     spr_mach_ops;\n    case SP4_SSV:\n       \
    \     ssv_prot_info4         spr_ssv_info;\n   };\n   struct EXCHANGE_ID4resok\
    \ {\n    clientid4        eir_clientid;\n    sequenceid4      eir_sequenceid;\n\
    \    uint32_t         eir_flags;\n    state_protect4_r eir_state_protect;\n  \
    \  server_owner4    eir_server_owner;\n    opaque           eir_server_scope<NFS4_OPAQUE_LIMIT>;\n\
    \    nfs_impl_id4     eir_server_impl_id<1>;\n   };\n   union EXCHANGE_ID4res\
    \ switch (nfsstat4 eir_status) {\n   case NFS4_OK:\n    EXCHANGE_ID4resok    \
    \  eir_resok4;\n   default:\n    void;\n   };\n"
- title: 18.35.3.  DESCRIPTION
  contents:
  - "18.35.3.  DESCRIPTION\n   The client uses the EXCHANGE_ID operation to register\
    \ a particular\n   instance of that client with the server, as represented by\
    \ a\n   client_owner4.  However, when the client_owner4 has already been\n   registered\
    \ by other means (e.g., Transparent State Migration), the\n   client may still\
    \ use EXCHANGE_ID to obtain the client ID assigned\n   previously.\n   The client\
    \ ID returned from this operation will be associated with\n   the connection on\
    \ which the EXCHANGE_ID is received and will serve as\n   a parent object for\
    \ sessions created by the client on this connection\n   or to which the connection\
    \ is bound.  As a result of using those\n   sessions to make requests involving\
    \ the creation of state, that state\n   will become associated with the client\
    \ ID returned.\n   In situations in which the registration of the client_owner\
    \ has not\n   occurred previously, the client ID must first be used, along with\
    \ the\n   returned eir_sequenceid, in creating an associated session using\n \
    \  CREATE_SESSION.\n   If the flag EXCHGID4_FLAG_CONFIRMED_R is set in the result,\n\
    \   eir_flags, then it is an indication that the registration of the\n   client_owner\
    \ has already occurred and that a further CREATE_SESSION\n   is not needed to\
    \ confirm it.  Of course, subsequent CREATE_SESSION\n   operations may be needed\
    \ for other reasons.\n   The value eir_sequenceid is used to establish an initial\
    \ sequence\n   value associated with the client ID returned.  In cases in which\
    \ a\n   CREATE_SESSION has already been done, there is no need for this\n   value,\
    \ since sequencing of such request has already been established,\n   and the client\
    \ has no need for this value and will ignore it.\n   EXCHANGE_ID MAY be sent in\
    \ a COMPOUND procedure that starts with\n   SEQUENCE.  However, when a client\
    \ communicates with a server for the\n   first time, it will not have a session,\
    \ so using SEQUENCE will not be\n   possible.  If EXCHANGE_ID is sent without\
    \ a preceding SEQUENCE, then\n   it MUST be the only operation in the COMPOUND\
    \ procedure's request.\n   If it is not, the server MUST return NFS4ERR_NOT_ONLY_OP.\n\
    \   The eia_clientowner field is composed of a co_verifier field and a\n   co_ownerid\
    \ string.  As noted in Section 2.4, the co_ownerid\n   identifies the client,\
    \ and the co_verifier specifies a particular\n   incarnation of that client. \
    \ An EXCHANGE_ID sent with a new\n   incarnation of the client will lead to the\
    \ server removing lock state\n   of the old incarnation.  On the other hand, when\
    \ an EXCHANGE_ID sent\n   with the current incarnation and co_ownerid does not\
    \ result in an\n   unrelated error, it will potentially update an existing client\
    \ ID's\n   properties or simply return information about the existing client_id.\n\
    \   The latter would happen when this operation is done to the same\n   server\
    \ using different network addresses as part of creating trunked\n   connections.\n\
    \   A server MUST NOT provide the same client ID to two different\n   incarnations\
    \ of an eia_clientowner.\n   In addition to the client ID and sequence ID, the\
    \ server returns a\n   server owner (eir_server_owner) and server scope (eir_server_scope).\n\
    \   The former field is used in connection with network trunking as\n   described\
    \ in Section 2.10.5.  The latter field is used to allow\n   clients to determine\
    \ when client IDs sent by one server may be\n   recognized by another in the event\
    \ of file system migration (see\n   Section 11.11.9 of the current document).\n\
    \   The client ID returned by EXCHANGE_ID is only unique relative to the\n   combination\
    \ of eir_server_owner.so_major_id and eir_server_scope.\n   Thus, if two servers\
    \ return the same client ID, the onus is on the\n   client to distinguish the\
    \ client IDs on the basis of\n   eir_server_owner.so_major_id and eir_server_scope.\
    \  In the event two\n   different servers claim matching server_owner.so_major_id\
    \ and\n   eir_server_scope, the client can use the verification techniques\n \
    \  discussed in Section 2.10.5.1 to determine if the servers are\n   distinct.\
    \  If they are distinct, then the client will need to note\n   the destination\
    \ network addresses of the connections used with each\n   server and use the network\
    \ address as the final discriminator.\n   The server, as defined by the unique\
    \ identity expressed in the\n   so_major_id of the server owner and the server\
    \ scope, needs to track\n   several properties of each client ID it hands out.\
    \  The properties\n   apply to the client ID and all sessions associated with\
    \ the client\n   ID.  The properties are derived from the arguments and results\
    \ of\n   EXCHANGE_ID.  The client ID properties include:\n   *  The capabilities\
    \ expressed by the following bits, which come from\n      the results of EXCHANGE_ID:\n\
    \      -  EXCHGID4_FLAG_SUPP_MOVED_REFER\n      -  EXCHGID4_FLAG_SUPP_MOVED_MIGR\n\
    \      -  EXCHGID4_FLAG_BIND_PRINC_STATEID\n      -  EXCHGID4_FLAG_USE_NON_PNFS\n\
    \      -  EXCHGID4_FLAG_USE_PNFS_MDS\n      -  EXCHGID4_FLAG_USE_PNFS_DS\n   \
    \   These properties may be updated by subsequent EXCHANGE_ID\n      operations\
    \ on confirmed client IDs though the server MAY refuse to\n      change them.\n\
    \   *  The state protection method used, one of SP4_NONE, SP4_MACH_CRED,\n   \
    \   or SP4_SSV, as set by the spa_how field of the arguments to\n      EXCHANGE_ID.\
    \  Once the client ID is confirmed, this property\n      cannot be updated by\
    \ subsequent EXCHANGE_ID operations.\n   *  For SP4_MACH_CRED or SP4_SSV state\
    \ protection:\n      -  The list of operations (spo_must_enforce) that MUST use\
    \ the\n         specified state protection.  This list comes from the results\n\
    \         of EXCHANGE_ID.\n      -  The list of operations (spo_must_allow) that\
    \ MAY use the\n         specified state protection.  This list comes from the\
    \ results\n         of EXCHANGE_ID.\n      Once the client ID is confirmed, these\
    \ properties cannot be\n      updated by subsequent EXCHANGE_ID requests.\n  \
    \ *  For SP4_SSV protection:\n      -  The OID of the hash algorithm.  This property\
    \ is represented by\n         one of the algorithms in the ssp_hash_algs field\
    \ of the\n         EXCHANGE_ID arguments.  Once the client ID is confirmed, this\n\
    \         property cannot be updated by subsequent EXCHANGE_ID requests.\n   \
    \   -  The OID of the encryption algorithm.  This property is\n         represented\
    \ by one of the algorithms in the ssp_encr_algs field\n         of the EXCHANGE_ID\
    \ arguments.  Once the client ID is confirmed,\n         this property cannot\
    \ be updated by subsequent EXCHANGE_ID\n         requests.\n      -  The length\
    \ of the SSV.  This property is represented by the\n         spi_ssv_len field\
    \ in the EXCHANGE_ID results.  Once the client\n         ID is confirmed, this\
    \ property cannot be updated by subsequent\n         EXCHANGE_ID operations.\n\
    \         There are REQUIRED and RECOMMENDED relationships among the\n       \
    \  length of the key of the encryption algorithm (\"key length\"),\n         the\
    \ length of the output of hash algorithm (\"hash length\"), and\n         the\
    \ length of the SSV (\"SSV length\").\n         o  key length MUST be <= hash\
    \ length.  This is because the keys\n            used for the encryption algorithm\
    \ are actually subkeys\n            derived from the SSV, and the derivation is\
    \ via the hash\n            algorithm.  The selection of an encryption algorithm\
    \ with a\n            key length that exceeded the length of the output of the\n\
    \            hash algorithm would require padding, and thus weaken the\n     \
    \       use of the encryption algorithm.\n         o  hash length SHOULD be <=\
    \ SSV length.  This is because the\n            SSV is a key used to derive subkeys\
    \ via an HMAC, and it is\n            recommended that the key used as input to\
    \ an HMAC be at\n            least as long as the length of the HMAC's hash algorithm's\n\
    \            output (see Section 3 of [52]).\n         o  key length SHOULD be\
    \ <= SSV length.  This is a transitive\n            result of the above two invariants.\n\
    \         o  key length SHOULD be >= hash length / 2.  This is because\n     \
    \       the subkey derivation is via an HMAC and it is recommended\n         \
    \   that if the HMAC has to be truncated, it should not be\n            truncated\
    \ to less than half the hash length (see Section 4\n            of RFC 2104 [52]).\n\
    \      -  Number of concurrent versions of the SSV the client and server\n   \
    \      will support (see Section 2.10.9).  This property is\n         represented\
    \ by spi_window in the EXCHANGE_ID results.  The\n         property may be updated\
    \ by subsequent EXCHANGE_ID operations.\n   *  The client's implementation ID\
    \ as represented by the\n      eia_client_impl_id field of the arguments.  The\
    \ property may be\n      updated by subsequent EXCHANGE_ID requests.\n   *  The\
    \ server's implementation ID as represented by the\n      eir_server_impl_id field\
    \ of the reply.  The property may be\n      updated by replies to subsequent EXCHANGE_ID\
    \ requests.\n   The eia_flags passed as part of the arguments and the eir_flags\n\
    \   results allow the client and server to inform each other of their\n   capabilities\
    \ as well as indicate how the client ID will be used.\n   Whether a bit is set\
    \ or cleared on the arguments' flags does not\n   force the server to set or clear\
    \ the same bit on the results' side.\n   Bits not defined above cannot be set\
    \ in the eia_flags field.  If they\n   are, the server MUST reject the operation\
    \ with NFS4ERR_INVAL.\n   The EXCHGID4_FLAG_UPD_CONFIRMED_REC_A bit can only be\
    \ set in\n   eia_flags; it is always off in eir_flags.  The\n   EXCHGID4_FLAG_CONFIRMED_R\
    \ bit can only be set in eir_flags; it is\n   always off in eia_flags.  If the\
    \ server recognizes the co_ownerid and\n   co_verifier as mapping to a confirmed\
    \ client ID, it sets\n   EXCHGID4_FLAG_CONFIRMED_R in eir_flags.  The\n   EXCHGID4_FLAG_CONFIRMED_R\
    \ flag allows a client to tell if the client\n   ID it is trying to create already\
    \ exists and is confirmed.\n   If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set in\
    \ eia_flags, this means\n   that the client is attempting to update properties\
    \ of an existing\n   confirmed client ID (if the client wants to update properties\
    \ of an\n   unconfirmed client ID, it MUST NOT set\n   EXCHGID4_FLAG_UPD_CONFIRMED_REC_A).\
    \  If so, it is RECOMMENDED that\n   the client send the update EXCHANGE_ID operation\
    \ in the same COMPOUND\n   as a SEQUENCE so that the EXCHANGE_ID is executed exactly\
    \ once.\n   Whether the client can update the properties of client ID depends\
    \ on\n   the state protection it selected when the client ID was created, and\n\
    \   the principal and security flavor it used when sending the\n   EXCHANGE_ID\
    \ operation.  The situations described in items 6, 7, 8, or\n   9 of the second\
    \ numbered list of Section 18.35.4 below will apply.\n   Note that if the operation\
    \ succeeds and returns a client ID that is\n   already confirmed, the server MUST\
    \ set the EXCHGID4_FLAG_CONFIRMED_R\n   bit in eir_flags.\n   If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A\
    \ is not set in eia_flags, this\n   means that the client is trying to establish\
    \ a new client ID; it is\n   attempting to trunk data communication to the server\
    \ (See\n   Section 2.10.5); or it is attempting to update properties of an\n \
    \  unconfirmed client ID.  The situations described in items 1, 2, 3, 4,\n   or\
    \ 5 of the second numbered list of Section 18.35.4 below will apply.\n   Note\
    \ that if the operation succeeds and returns a client ID that was\n   previously\
    \ confirmed, the server MUST set the\n   EXCHGID4_FLAG_CONFIRMED_R bit in eir_flags.\n\
    \   When the EXCHGID4_FLAG_SUPP_MOVED_REFER flag bit is set, the client\n   indicates\
    \ that it is capable of dealing with an NFS4ERR_MOVED error\n   as part of a referral\
    \ sequence.  When this bit is not set, it is\n   still legal for the server to\
    \ perform a referral sequence.  However,\n   a server may use the fact that the\
    \ client is incapable of correctly\n   responding to a referral, by avoiding it\
    \ for that particular client.\n   It may, for instance, act as a proxy for that\
    \ particular file system,\n   at some cost in performance, although it is not\
    \ obligated to do so.\n   If the server will potentially perform a referral, it\
    \ MUST set\n   EXCHGID4_FLAG_SUPP_MOVED_REFER in eir_flags.\n   When the EXCHGID4_FLAG_SUPP_MOVED_MIGR\
    \ is set, the client indicates\n   that it is capable of dealing with an NFS4ERR_MOVED\
    \ error as part of\n   a file system migration sequence.  When this bit is not\
    \ set, it is\n   still legal for the server to indicate that a file system has\
    \ moved,\n   when this in fact happens.  However, a server may use the fact that\n\
    \   the client is incapable of correctly responding to a migration in its\n  \
    \ scheduling of file systems to migrate so as to avoid migration of\n   file systems\
    \ being actively used.  It may also hide actual migrations\n   from clients unable\
    \ to deal with them by acting as a proxy for a\n   migrated file system for particular\
    \ clients, at some cost in\n   performance, although it is not obligated to do\
    \ so.  If the server\n   will potentially perform a migration, it MUST set\n \
    \  EXCHGID4_FLAG_SUPP_MOVED_MIGR in eir_flags.\n   When EXCHGID4_FLAG_BIND_PRINC_STATEID\
    \ is set, the client indicates\n   that it wants the server to bind the stateid\
    \ to the principal.  This\n   means that when a principal creates a stateid, it\
    \ has to be the one\n   to use the stateid.  If the server will perform binding,\
    \ it will\n   return EXCHGID4_FLAG_BIND_PRINC_STATEID.  The server MAY return\n\
    \   EXCHGID4_FLAG_BIND_PRINC_STATEID even if the client does not request\n   it.\
    \  If an update to the client ID changes the value of\n   EXCHGID4_FLAG_BIND_PRINC_STATEID's\
    \ client ID property, the effect\n   applies only to new stateids.  Existing stateids\
    \ (and all stateids\n   with the same \"other\" field) that were created with\
    \ stateid to\n   principal binding in force will continue to have binding in force.\n\
    \   Existing stateids (and all stateids with the same \"other\" field) that\n\
    \   were created with stateid to principal not in force will continue to\n   have\
    \ binding not in force.\n   The EXCHGID4_FLAG_USE_NON_PNFS, EXCHGID4_FLAG_USE_PNFS_MDS,\
    \ and\n   EXCHGID4_FLAG_USE_PNFS_DS bits are described in Section 13.1 and\n \
    \  convey roles the client ID is to be used for in a pNFS environment.\n   The\
    \ server MUST set one of the acceptable combinations of these bits\n   (roles)\
    \ in eir_flags, as specified in that section.  Note that the\n   same client owner/server\
    \ owner pair can have multiple roles.\n   Multiple roles can be associated with\
    \ the same client ID or with\n   different client IDs.  Thus, if a client sends\
    \ EXCHANGE_ID from the\n   same client owner to the same server owner multiple\
    \ times, but\n   specifies different pNFS roles each time, the server might return\n\
    \   different client IDs.  Given that different pNFS roles might have\n   different\
    \ client IDs, the client may ask for different properties for\n   each role/client\
    \ ID.\n   The spa_how field of the eia_state_protect field specifies how the\n\
    \   client wants to protect its client, locking, and session states from\n   unauthorized\
    \ changes (Section 2.10.8.3):\n   *  SP4_NONE.  The client does not request the\
    \ NFSv4.1 server to\n      enforce state protection.  The NFSv4.1 server MUST\
    \ NOT enforce\n      state protection for the returned client ID.\n   *  SP4_MACH_CRED.\
    \  If spa_how is SP4_MACH_CRED, then the client MUST\n      send the EXCHANGE_ID\
    \ operation with RPCSEC_GSS as the security\n      flavor, and with a service\
    \ of RPC_GSS_SVC_INTEGRITY or\n      RPC_GSS_SVC_PRIVACY.  If SP4_MACH_CRED is\
    \ specified, then the\n      client wants to use an RPCSEC_GSS-based machine credential\
    \ to\n      protect its state.  The server MUST note the principal the\n     \
    \ EXCHANGE_ID operation was sent with, and the GSS mechanism used.\n      These\
    \ notes collectively comprise the machine credential.\n      After the client\
    \ ID is confirmed, as long as the lease associated\n      with the client ID is\
    \ unexpired, a subsequent EXCHANGE_ID\n      operation that uses the same eia_clientowner.co_owner\
    \ as the first\n      EXCHANGE_ID MUST also use the same machine credential as\
    \ the first\n      EXCHANGE_ID.  The server returns the same client ID for the\n\
    \      subsequent EXCHANGE_ID as that returned from the first\n      EXCHANGE_ID.\n\
    \   *  SP4_SSV.  If spa_how is SP4_SSV, then the client MUST send the\n      EXCHANGE_ID\
    \ operation with RPCSEC_GSS as the security flavor, and\n      with a service\
    \ of RPC_GSS_SVC_INTEGRITY or RPC_GSS_SVC_PRIVACY.\n      If SP4_SSV is specified,\
    \ then the client wants to use the SSV to\n      protect its state.  The server\
    \ records the credential used in the\n      request as the machine credential\
    \ (as defined above) for the\n      eia_clientowner.co_owner.  The CREATE_SESSION\
    \ operation that\n      confirms the client ID MUST use the same machine credential.\n\
    \   When a client specifies SP4_MACH_CRED or SP4_SSV, it also provides\n   two\
    \ lists of operations (each expressed as a bitmap).  The first list\n   is spo_must_enforce\
    \ and consists of those operations the client MUST\n   send (subject to the server\
    \ confirming the list of operations in the\n   result of EXCHANGE_ID) with the\
    \ machine credential (if SP4_MACH_CRED\n   protection is specified) or the SSV-based\
    \ credential (if SP4_SSV\n   protection is used).  The client MUST send the operations\
    \ with\n   RPCSEC_GSS credentials that specify the RPC_GSS_SVC_INTEGRITY or\n\
    \   RPC_GSS_SVC_PRIVACY security service.  Typically, the first list of\n   operations\
    \ includes EXCHANGE_ID, CREATE_SESSION, DELEGPURGE,\n   DESTROY_SESSION, BIND_CONN_TO_SESSION,\
    \ and DESTROY_CLIENTID.  The\n   client SHOULD NOT specify in this list any operations\
    \ that require a\n   filehandle because the server's access policies MAY conflict\
    \ with the\n   client's choice, and thus the client would then be unable to access\
    \ a\n   subset of the server's namespace.\n   Note that if SP4_SSV protection\
    \ is specified, and the client\n   indicates that CREATE_SESSION must be protected\
    \ with SP4_SSV, because\n   the SSV cannot exist without a confirmed client ID,\
    \ the first\n   CREATE_SESSION MUST instead be sent using the machine credential,\
    \ and\n   the server MUST accept the machine credential.\n   There is a corresponding\
    \ result, also called spo_must_enforce, of the\n   operations for which the server\
    \ will require SP4_MACH_CRED or SP4_SSV\n   protection.  Normally, the server's\
    \ result equals the client's\n   argument, but the result MAY be different.  If\
    \ the client requests\n   one or more operations in the set { EXCHANGE_ID, CREATE_SESSION,\n\
    \   DELEGPURGE, DESTROY_SESSION, BIND_CONN_TO_SESSION, DESTROY_CLIENTID\n   },\
    \ then the result spo_must_enforce MUST include the operations the\n   client\
    \ requested from that set.\n   If spo_must_enforce in the results has BIND_CONN_TO_SESSION\
    \ set, then\n   connection binding enforcement is enabled, and the client MUST\
    \ use\n   the machine (if SP4_MACH_CRED protection is used) or SSV (if SP4_SSV\n\
    \   protection is used) credential on calls to BIND_CONN_TO_SESSION.\n   The second\
    \ list is spo_must_allow and consists of those operations\n   the client wants\
    \ to have the option of sending with the machine\n   credential or the SSV-based\
    \ credential, even if the object the\n   operations are performed on is not owned\
    \ by the machine or SSV\n   credential.\n   The corresponding result, also called\
    \ spo_must_allow, consists of the\n   operations the server will allow the client\
    \ to use SP4_SSV or\n   SP4_MACH_CRED credentials with.  Normally, the server's\
    \ result equals\n   the client's argument, but the result MAY be different.\n\
    \   The purpose of spo_must_allow is to allow clients to solve the\n   following\
    \ conundrum.  Suppose the client ID is confirmed with\n   EXCHGID4_FLAG_BIND_PRINC_STATEID,\
    \ and it calls OPEN with the\n   RPCSEC_GSS credentials of a normal user.  Now\
    \ suppose the user's\n   credentials expire, and cannot be renewed (e.g., a Kerberos\
    \ ticket\n   granting ticket expires, and the user has logged off and will not\
    \ be\n   acquiring a new ticket granting ticket).  The client will be unable\n\
    \   to send CLOSE without the user's credentials, which is to say the\n   client\
    \ has to either leave the state on the server or re-send\n   EXCHANGE_ID with\
    \ a new verifier to clear all state, that is, unless\n   the client includes CLOSE\
    \ on the list of operations in spo_must_allow\n   and the server agrees.\n   The\
    \ SP4_SSV protection parameters also have:\n   ssp_hash_algs:\n      This is the\
    \ set of algorithms the client supports for the purpose\n      of computing the\
    \ digests needed for the internal SSV GSS mechanism\n      and for the SET_SSV\
    \ operation.  Each algorithm is specified as an\n      object identifier (OID).\
    \  The REQUIRED algorithms for a server are\n      id-sha1, id-sha224, id-sha256,\
    \ id-sha384, and id-sha512 [25].\n      Due to known weaknesses in id-sha1, it\
    \ is RECOMMENDED that the\n      client specify at least one algorithm within\
    \ ssp_hash_algs other\n      than id-sha1.\n      The algorithm the server selects\
    \ among the set is indicated in\n      spi_hash_alg, a field of spr_ssv_prot_info.\
    \  The field\n      spi_hash_alg is an index into the array ssp_hash_algs.  Because\
    \ of\n      known the weaknesses in id-sha1, it is RECOMMENDED that it not be\n\
    \      selected by the server as long as ssp_hash_algs contains any other\n  \
    \    supported algorithm.\n      If the server does not support any of the offered\
    \ algorithms, it\n      returns NFS4ERR_HASH_ALG_UNSUPP.  If ssp_hash_algs is\
    \ empty, the\n      server MUST return NFS4ERR_INVAL.\n   ssp_encr_algs:\n   \
    \   This is the set of algorithms the client supports for the purpose\n      of\
    \ providing privacy protection for the internal SSV GSS\n      mechanism.  Each\
    \ algorithm is specified as an OID.  The REQUIRED\n      algorithm for a server\
    \ is id-aes256-CBC.  The RECOMMENDED\n      algorithms are id-aes192-CBC and id-aes128-CBC\
    \ [26].  The selected\n      algorithm is returned in spi_encr_alg, an index into\n\
    \      ssp_encr_algs.  If the server does not support any of the offered\n   \
    \   algorithms, it returns NFS4ERR_ENCR_ALG_UNSUPP.  If ssp_encr_algs\n      is\
    \ empty, the server MUST return NFS4ERR_INVAL.  Note that due to\n      previously\
    \ stated requirements and recommendations on the\n      relationships between\
    \ key length and hash length, some\n      combinations of RECOMMENDED and REQUIRED\
    \ encryption algorithm and\n      hash algorithm either SHOULD NOT or MUST NOT\
    \ be used.  Table 21\n      summarizes the illegal and discouraged combinations.\n\
    \   ssp_window:\n      This is the number of SSV versions the client wants the\
    \ server to\n      maintain (i.e., each successful call to SET_SSV produces a\
    \ new\n      version of the SSV).  If ssp_window is zero, the server MUST\n  \
    \    return NFS4ERR_INVAL.  The server responds with spi_window, which\n     \
    \ MUST NOT exceed ssp_window and MUST be at least one.  Any requests\n      on\
    \ the backchannel or fore channel that are using a version of the\n      SSV that\
    \ is outside the window will fail with an ONC RPC\n      authentication error,\
    \ and the requester will have to retry them\n      with the same slot ID and sequence\
    \ ID.\n   ssp_num_gss_handles:\n      This is the number of RPCSEC_GSS handles\
    \ the server should create\n      that are based on the GSS SSV mechanism (see\
    \ Section 2.10.9).  It\n      is not the total number of RPCSEC_GSS handles for\
    \ the client ID.\n      Indeed, subsequent calls to EXCHANGE_ID will add RPCSEC_GSS\n\
    \      handles.  The server responds with a list of handles in\n      spi_handles.\
    \  If the client asks for at least one handle and the\n      server cannot create\
    \ it, the server MUST return an error.  The\n      handles in spi_handles are\
    \ not available for use until the client\n      ID is confirmed, which could be\
    \ immediately if EXCHANGE_ID returns\n      EXCHGID4_FLAG_CONFIRMED_R, or upon\
    \ successful confirmation from\n      CREATE_SESSION.\n      While a client ID\
    \ can span all the connections that are connected\n      to a server sharing the\
    \ same eir_server_owner.so_major_id, the\n      RPCSEC_GSS handles returned in\
    \ spi_handles can only be used on\n      connections connected to a server that\
    \ returns the same the\n      eir_server_owner.so_major_id and eir_server_owner.so_minor_id\
    \ on\n      each connection.  It is permissible for the client to set\n      ssp_num_gss_handles\
    \ to zero; the client can create more handles\n      with another EXCHANGE_ID\
    \ call.\n      Because each SSV RPCSEC_GSS handle shares a common SSV GSS\n  \
    \    context, there are security considerations specific to this\n      situation\
    \ discussed in Section 2.10.10.\n      The seq_window (see Section 5.2.3.1 of\
    \ RFC 2203 [4]) of each\n      RPCSEC_GSS handle in spi_handle MUST be the same\
    \ as the seq_window\n      of the RPCSEC_GSS handle used for the credential of\
    \ the RPC\n      request of which the EXCHANGE_ID operation was sent as a part.\n\
    \   | Encryption Algorithm | MUST NOT be combined with | SHOULD NOT be |\n   |\
    \ id-aes128-CBC        |                           | id-sha384,    |\n   | id-aes192-CBC\
    \        | id-sha1                   | id-sha512     |\n   | id-aes256-CBC   \
    \     | id-sha1, id-sha224        |               |\n   The arguments include\
    \ an array of up to one element in length called\n   eia_client_impl_id.  If eia_client_impl_id\
    \ is present, it contains\n   the information identifying the implementation of\
    \ the client.\n   Similarly, the results include an array of up to one element\
    \ in\n   length called eir_server_impl_id that identifies the implementation\n\
    \   of the server.  Servers MUST accept a zero-length eia_client_impl_id\n   array,\
    \ and clients MUST accept a zero-length eir_server_impl_id\n   array.\n   A possible\
    \ use for implementation identifiers would be in diagnostic\n   software that\
    \ extracts this information in an attempt to identify\n   interoperability problems,\
    \ performance workload behaviors, or general\n   usage statistics.  Since the\
    \ intent of having access to this\n   information is for planning or general diagnosis\
    \ only, the client and\n   server MUST NOT interpret this implementation identity\
    \ information in\n   a way that affects how the implementation interacts with\
    \ its peer.\n   The client and server are not allowed to depend on the peer's\n\
    \   manifesting a particular allowed behavior based on an implementation\n   identifier\
    \ but are required to interoperate as specified elsewhere in\n   the protocol\
    \ specification.\n   Because it is possible that some implementations might violate\
    \ the\n   protocol specification and interpret the identity information,\n   implementations\
    \ MUST provide facilities to allow the NFSv4 client and\n   server to be configured\
    \ to set the contents of the nfs_impl_id\n   structures sent to any specified\
    \ value.\n"
- title: 18.35.4.  IMPLEMENTATION
  contents:
  - "18.35.4.  IMPLEMENTATION\n   A server's client record is a 5-tuple:\n   1.  co_ownerid:\n\
    \       The client identifier string, from the eia_clientowner structure\n   \
    \    of the EXCHANGE_ID4args structure.\n   2.  co_verifier:\n       A client-specific\
    \ value used to indicate incarnations (where a\n       client restart represents\
    \ a new incarnation), from the\n       eia_clientowner structure of the EXCHANGE_ID4args\
    \ structure.\n   3.  principal:\n       The principal that was defined in the\
    \ RPC header's credential\n       and/or verifier at the time the client record\
    \ was established.\n   4.  client ID:\n       The shorthand client identifier,\
    \ generated by the server and\n       returned via the eir_clientid field in the\
    \ EXCHANGE_ID4resok\n       structure.\n   5.  confirmed:\n       A private field\
    \ on the server indicating whether or not a client\n       record has been confirmed.\
    \  A client record is confirmed if there\n       has been a successful CREATE_SESSION\
    \ operation to confirm it.\n       Otherwise, it is unconfirmed.  An unconfirmed\
    \ record is\n       established by an EXCHANGE_ID call.  Any unconfirmed record\
    \ that\n       is not confirmed within a lease period SHOULD be removed.\n   The\
    \ following identifiers represent special values for the fields in\n   the records.\n\
    \   ownerid_arg:\n      The value of the eia_clientowner.co_ownerid subfield of\
    \ the\n      EXCHANGE_ID4args structure of the current request.\n   verifier_arg:\n\
    \      The value of the eia_clientowner.co_verifier subfield of the\n      EXCHANGE_ID4args\
    \ structure of the current request.\n   old_verifier_arg:\n      A value of the\
    \ eia_clientowner.co_verifier field of a client\n      record received in a previous\
    \ request; this is distinct from\n      verifier_arg.\n   principal_arg:\n   \
    \   The value of the RPCSEC_GSS principal for the current request.\n   old_principal_arg:\n\
    \      A value of the principal of a client record as defined by the RPC\n   \
    \   header's credential or verifier of a previous request.  This is\n      distinct\
    \ from principal_arg.\n   clientid_ret:\n      The value of the eir_clientid field\
    \ the server will return in the\n      EXCHANGE_ID4resok structure for the current\
    \ request.\n   old_clientid_ret:\n      The value of the eir_clientid field the\
    \ server returned in the\n      EXCHANGE_ID4resok structure for a previous request.\
    \  This is\n      distinct from clientid_ret.\n   confirmed:\n      The client\
    \ ID has been confirmed.\n   unconfirmed:\n      The client ID has not been confirmed.\n\
    \   Since EXCHANGE_ID is a non-idempotent operation, we must consider the\n  \
    \ possibility that retries occur as a result of a client restart,\n   network\
    \ partition, malfunctioning router, etc.  Retries are\n   identified by the value\
    \ of the eia_clientowner field of\n   EXCHANGE_ID4args, and the method for dealing\
    \ with them is outlined in\n   the scenarios below.\n   The scenarios are described\
    \ in terms of the client record(s) a server\n   has for a given co_ownerid.  Note\
    \ that if the client ID was created\n   specifying SP4_SSV state protection and\
    \ EXCHANGE_ID as the one of the\n   operations in spo_must_allow, then the server\
    \ MUST authorize\n   EXCHANGE_IDs with the SSV principal in addition to the principal\
    \ that\n   created the client ID.\n   1.  New Owner ID\n       If the server has\
    \ no client records with\n       eia_clientowner.co_ownerid matching ownerid_arg,\
    \ and\n       EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set in the EXCHANGE_ID,\n\
    \       then a new shorthand client ID (let us call it clientid_ret) is\n    \
    \   generated, and the following unconfirmed record is added to the\n       server's\
    \ state.\n       { ownerid_arg, verifier_arg, principal_arg, clientid_ret,\n \
    \      unconfirmed }\n       Subsequently, the server returns clientid_ret.\n\
    \   2.  Non-Update on Existing Client ID\n       If the server has the following\
    \ confirmed record, and the request\n       does not have EXCHGID4_FLAG_UPD_CONFIRMED_REC_A\
    \ set, then the\n       request is the result of a retried request due to a faulty\
    \ router\n       or lost connection, or the client is trying to determine if it\n\
    \       can perform trunking.\n       { ownerid_arg, verifier_arg, principal_arg,\
    \ clientid_ret,\n       confirmed }\n       Since the record has been confirmed,\
    \ the client must have\n       received the server's reply from the initial EXCHANGE_ID\
    \ request.\n       Since the server has a confirmed record, and since\n      \
    \ EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is not set, with the possible\n       exception\
    \ of eir_server_owner.so_minor_id, the server returns the\n       same result\
    \ it did when the client ID's properties were last\n       updated (or if never\
    \ updated, the result when the client ID was\n       created).  The confirmed\
    \ record is unchanged.\n   3.  Client Collision\n       If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A\
    \ is not set, and if the\n       server has the following confirmed record, then\
    \ this request is\n       likely the result of a chance collision between the\
    \ values of the\n       eia_clientowner.co_ownerid subfield of EXCHANGE_ID4args\
    \ for two\n       different clients.\n       { ownerid_arg, *, old_principal_arg,\
    \ old_clientid_ret, confirmed\n       }\n       If there is currently no state\
    \ associated with old_clientid_ret,\n       or if there is state but the lease\
    \ has expired, then this case is\n       effectively equivalent to the New Owner\
    \ ID case of\n       Section 18.35.4, Paragraph 7, Item 1.  The confirmed record\
    \ is\n       deleted, the old_clientid_ret and its lock state are deleted, a\n\
    \       new shorthand client ID is generated, and the following\n       unconfirmed\
    \ record is added to the server's state.\n       { ownerid_arg, verifier_arg,\
    \ principal_arg, clientid_ret,\n       unconfirmed }\n       Subsequently, the\
    \ server returns clientid_ret.\n       If old_clientid_ret has an unexpired lease\
    \ with state, then no\n       state of old_clientid_ret is changed or deleted.\
    \  The server\n       returns NFS4ERR_CLID_INUSE to indicate that the client should\n\
    \       retry with a different value for the eia_clientowner.co_ownerid\n    \
    \   subfield of EXCHANGE_ID4args.  The client record is not changed.\n   4.  Replacement\
    \ of Unconfirmed Record\n       If the EXCHGID4_FLAG_UPD_CONFIRMED_REC_A flag\
    \ is not set, and the\n       server has the following unconfirmed record, then\
    \ the client is\n       attempting EXCHANGE_ID again on an unconfirmed client\
    \ ID, perhaps\n       due to a retry, a client restart before client ID confirmation\n\
    \       (i.e., before CREATE_SESSION was called), or some other reason.\n    \
    \   { ownerid_arg, *, *, old_clientid_ret, unconfirmed }\n       It is possible\
    \ that the properties of old_clientid_ret are\n       different than those specified\
    \ in the current EXCHANGE_ID.\n       Whether or not the properties are being\
    \ updated, to eliminate\n       ambiguity, the server deletes the unconfirmed\
    \ record, generates a\n       new client ID (clientid_ret), and establishes the\
    \ following\n       unconfirmed record:\n       { ownerid_arg, verifier_arg, principal_arg,\
    \ clientid_ret,\n       unconfirmed }\n   5.  Client Restart\n       If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A\
    \ is not set, and if the\n       server has the following confirmed client record,\
    \ then this\n       request is likely from a previously confirmed client that\
    \ has\n       restarted.\n       { ownerid_arg, old_verifier_arg, principal_arg,\
    \ old_clientid_ret,\n       confirmed }\n       Since the previous incarnation\
    \ of the same client will no longer\n       be making requests, once the new client\
    \ ID is confirmed by\n       CREATE_SESSION, byte-range locks and share reservations\
    \ should be\n       released immediately rather than forcing the new incarnation\
    \ to\n       wait for the lease time on the previous incarnation to expire.\n\
    \       Furthermore, session state should be removed since if the client\n   \
    \    had maintained that information across restart, this request\n       would\
    \ not have been sent.  If the server supports neither the\n       CLAIM_DELEGATE_PREV\
    \ nor CLAIM_DELEG_PREV_FH claim types,\n       associated delegations should be\
    \ purged as well; otherwise,\n       delegations are retained and recovery proceeds\
    \ according to\n       Section 10.2.1.\n       After processing, clientid_ret\
    \ is returned to the client and this\n       client record is added:\n       {\
    \ ownerid_arg, verifier_arg, principal_arg, clientid_ret,\n       unconfirmed\
    \ }\n       The previously described confirmed record continues to exist, and\n\
    \       thus the same ownerid_arg exists in both a confirmed and\n       unconfirmed\
    \ state at the same time.  The number of states can\n       collapse to one once\
    \ the server receives an applicable\n       CREATE_SESSION or EXCHANGE_ID.\n \
    \      *  If the server subsequently receives a successful\n          CREATE_SESSION\
    \ that confirms clientid_ret, then the server\n          atomically destroys the\
    \ confirmed record and makes the\n          unconfirmed record confirmed as described\
    \ in Section 18.36.3.\n       *  If the server instead subsequently receives an\
    \ EXCHANGE_ID\n          with the client owner equal to ownerid_arg, one strategy\
    \ is to\n          simply delete the unconfirmed record, and process the\n   \
    \       EXCHANGE_ID as described in the entirety of Section 18.35.4.\n   6.  Update\n\
    \       If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set, and the server has\n    \
    \   the following confirmed record, then this request is an attempt\n       at\
    \ an update.\n       { ownerid_arg, verifier_arg, principal_arg, clientid_ret,\n\
    \       confirmed }\n       Since the record has been confirmed, the client must\
    \ have\n       received the server's reply from the initial EXCHANGE_ID request.\n\
    \       The server allows the update, and the client record is left\n       intact.\n\
    \   7.  Update but No Confirmed Record\n       If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A\
    \ is set, and the server has\n       no confirmed record corresponding ownerid_arg,\
    \ then the server\n       returns NFS4ERR_NOENT and leaves any unconfirmed record\
    \ intact.\n   8.  Update but Wrong Verifier\n       If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A\
    \ is set, and the server has\n       the following confirmed record, then this\
    \ request is an illegal\n       attempt at an update, perhaps because of a retry\
    \ from a previous\n       client incarnation.\n       { ownerid_arg, old_verifier_arg,\
    \ *, clientid_ret, confirmed }\n       The server returns NFS4ERR_NOT_SAME and\
    \ leaves the client record\n       intact.\n   9.  Update but Wrong Principal\n\
    \       If EXCHGID4_FLAG_UPD_CONFIRMED_REC_A is set, and the server has\n    \
    \   the following confirmed record, then this request is an illegal\n       attempt\
    \ at an update by an unauthorized principal.\n       { ownerid_arg, verifier_arg,\
    \ old_principal_arg, clientid_ret,\n       confirmed }\n       The server returns\
    \ NFS4ERR_PERM and leaves the client record\n       intact.\n"
- title: '18.36.  Operation 43: CREATE_SESSION - Create New Session and Confirm'
  contents:
  - "18.36.  Operation 43: CREATE_SESSION - Create New Session and Confirm\n     \
    \   Client ID\n"
- title: 18.36.1.  ARGUMENT
  contents:
  - "18.36.1.  ARGUMENT\n   struct channel_attrs4 {\n           count4           \
    \       ca_headerpadsize;\n           count4                  ca_maxrequestsize;\n\
    \           count4                  ca_maxresponsesize;\n           count4   \
    \               ca_maxresponsesize_cached;\n           count4                \
    \  ca_maxoperations;\n           count4                  ca_maxrequests;\n   \
    \        uint32_t                ca_rdma_ird<1>;\n   };\n   const CREATE_SESSION4_FLAG_PERSIST\
    \              = 0x00000001;\n   const CREATE_SESSION4_FLAG_CONN_BACK_CHAN   \
    \    = 0x00000002;\n   const CREATE_SESSION4_FLAG_CONN_RDMA            = 0x00000004;\n\
    \   struct CREATE_SESSION4args {\n           clientid4               csa_clientid;\n\
    \           sequenceid4             csa_sequence;\n           uint32_t       \
    \         csa_flags;\n           channel_attrs4          csa_fore_chan_attrs;\n\
    \           channel_attrs4          csa_back_chan_attrs;\n           uint32_t\
    \                csa_cb_program;\n           callback_sec_parms4     csa_sec_parms<>;\n\
    \   };\n"
- title: 18.36.2.  RESULT
  contents:
  - "18.36.2.  RESULT\n   struct CREATE_SESSION4resok {\n           sessionid4   \
    \           csr_sessionid;\n           sequenceid4             csr_sequence;\n\
    \           uint32_t                csr_flags;\n           channel_attrs4    \
    \      csr_fore_chan_attrs;\n           channel_attrs4          csr_back_chan_attrs;\n\
    \   };\n   union CREATE_SESSION4res switch (nfsstat4 csr_status) {\n   case NFS4_OK:\n\
    \           CREATE_SESSION4resok    csr_resok4;\n   default:\n           void;\n\
    \   };\n"
- title: 18.36.3.  DESCRIPTION
  contents:
  - "18.36.3.  DESCRIPTION\n   This operation is used by the client to create new\
    \ session objects on\n   the server.\n   CREATE_SESSION can be sent with or without\
    \ a preceding SEQUENCE\n   operation in the same COMPOUND procedure.  If CREATE_SESSION\
    \ is sent\n   with a preceding SEQUENCE operation, any session created by\n  \
    \ CREATE_SESSION has no direct relation to the session specified in the\n   SEQUENCE\
    \ operation, although the two sessions might be associated\n   with the same client\
    \ ID.  If CREATE_SESSION is sent without a\n   preceding SEQUENCE, then it MUST\
    \ be the only operation in the\n   COMPOUND procedure's request.  If it is not,\
    \ the server MUST return\n   NFS4ERR_NOT_ONLY_OP.\n   In addition to creating\
    \ a session, CREATE_SESSION has the following\n   effects:\n   *  The first session\
    \ created with a new client ID serves to confirm\n      the creation of that client's\
    \ state on the server.  The server\n      returns the parameter values for the\
    \ new session.\n   *  The connection CREATE_SESSION that is sent over is associated\
    \ with\n      the session's fore channel.\n   The arguments and results of CREATE_SESSION\
    \ are described as follows:\n   csa_clientid:  This is the client ID with which\
    \ the new session will\n      be associated.  The corresponding result is csr_sessionid,\
    \ the\n      session ID of the new session.\n   csa_sequence:  Each client ID\
    \ serializes CREATE_SESSION via a per-\n      client ID sequence number (see Section\
    \ 18.36.4).  The\n      corresponding result is csr_sequence, which MUST be equal\
    \ to\n      csa_sequence.\n   In the next three arguments, the client offers a\
    \ value that is to be\n   a property of the session.  Except where stated otherwise,\
    \ it is\n   RECOMMENDED that the server accept the value.  If it is not\n   acceptable,\
    \ the server MAY use a different value.  Regardless, the\n   server MUST return\
    \ the value the session will use (which will be\n   either what the client offered,\
    \ or what the server is insisting on)\n   to the client.\n   csa_flags:  The csa_flags\
    \ field contains a list of the following flag\n      bits:\n      CREATE_SESSION4_FLAG_PERSIST:\n\
    \         If CREATE_SESSION4_FLAG_PERSIST is set, the client wants the\n     \
    \    server to provide a persistent reply cache.  For sessions in\n         which\
    \ only idempotent operations will be used (e.g., a read-\n         only session),\
    \ clients SHOULD NOT set\n         CREATE_SESSION4_FLAG_PERSIST.  If the server\
    \ does not or cannot\n         provide a persistent reply cache, the server MUST\
    \ NOT set\n         CREATE_SESSION4_FLAG_PERSIST in the field csr_flags.\n   \
    \      If the server is a pNFS metadata server, for reasons described\n      \
    \   in Section 12.5.2 it SHOULD support\n         CREATE_SESSION4_FLAG_PERSIST\
    \ if it supports the layout_hint\n         (Section 5.12.4) attribute.\n     \
    \ CREATE_SESSION4_FLAG_CONN_BACK_CHAN:\n         If CREATE_SESSION4_FLAG_CONN_BACK_CHAN\
    \ is set in csa_flags, the\n         client is requesting that the connection\
    \ over which the\n         CREATE_SESSION operation arrived be associated with\
    \ the\n         session's backchannel in addition to its fore channel.  If the\n\
    \         server agrees, it sets CREATE_SESSION4_FLAG_CONN_BACK_CHAN in\n    \
    \     the result field csr_flags.  If\n         CREATE_SESSION4_FLAG_CONN_BACK_CHAN\
    \ is not set in csa_flags,\n         then CREATE_SESSION4_FLAG_CONN_BACK_CHAN\
    \ MUST NOT be set in\n         csr_flags.\n      CREATE_SESSION4_FLAG_CONN_RDMA:\n\
    \         If CREATE_SESSION4_FLAG_CONN_RDMA is set in csa_flags, and if\n    \
    \     the connection over which the CREATE_SESSION operation arrived\n       \
    \  is currently in non-RDMA mode but has the capability to operate\n         in\
    \ RDMA mode, then the client is requesting that the server\n         \"step up\"\
    \ to RDMA mode on the connection.  If the server\n         agrees, it sets CREATE_SESSION4_FLAG_CONN_RDMA\
    \ in the result\n         field csr_flags.  If CREATE_SESSION4_FLAG_CONN_RDMA\
    \ is not set\n         in csa_flags, then CREATE_SESSION4_FLAG_CONN_RDMA MUST\
    \ NOT be\n         set in csr_flags.  Note that once the server agrees to step\
    \ up,\n         it and the client MUST exchange all future traffic on the\n  \
    \       connection with RPC RDMA framing and not Record Marking ([32]).\n   csa_fore_chan_attrs,\
    \ csa_back_chan_attrs:  The csa_fore_chan_attrs\n      and csa_back_chan_attrs\
    \ fields apply to attributes of the fore\n      channel (which conveys requests\
    \ originating from the client to the\n      server), and the backchannel (the\
    \ channel that conveys callback\n      requests originating from the server to\
    \ the client), respectively.\n      The results are in corresponding structures\
    \ called\n      csr_fore_chan_attrs and csr_back_chan_attrs.  The results\n  \
    \    establish attributes for each channel, and on all subsequent use\n      of\
    \ each channel of the session.  Each structure has the following\n      fields:\n\
    \      ca_headerpadsize:\n         The maximum amount of padding the requester\
    \ is willing to apply\n         to ensure that write payloads are aligned on some\
    \ boundary at\n         the replier.  For each channel, the server\n         *\
    \  will reply in ca_headerpadsize with its preferred value, or\n            zero\
    \ if padding is not in use, and\n         *  MAY decrease this value but MUST\
    \ NOT increase it.\n      ca_maxrequestsize:\n         The maximum size of a COMPOUND\
    \ or CB_COMPOUND request that will\n         be sent.  This size represents the\
    \ XDR encoded size of the\n         request, including the RPC headers (including\
    \ security flavor\n         credentials and verifiers) but excludes any RPC transport\n\
    \         framing headers.  Imagine a request coming over a non-RDMA TCP/\n  \
    \       IP connection, and that it has a single Record Marking header\n      \
    \   preceding it.  The maximum allowable count encoded in the\n         header\
    \ will be ca_maxrequestsize.  If a requester sends a\n         request that exceeds\
    \ ca_maxrequestsize, the error\n         NFS4ERR_REQ_TOO_BIG will be returned\
    \ per the description in\n         Section 2.10.6.4.  For each channel, the server\
    \ MAY decrease\n         this value but MUST NOT increase it.\n      ca_maxresponsesize:\n\
    \         The maximum size of a COMPOUND or CB_COMPOUND reply that the\n     \
    \    requester will accept from the replier including RPC headers\n         (see\
    \ the ca_maxrequestsize definition).  For each channel, the\n         server MAY\
    \ decrease this value, but MUST NOT increase it.\n         However, if the client\
    \ selects a value for ca_maxresponsesize\n         such that a replier on a channel\
    \ could never send a response,\n         the server SHOULD return NFS4ERR_TOOSMALL\
    \ in the CREATE_SESSION\n         reply.  After the session is created, if a requester\
    \ sends a\n         request for which the size of the reply would exceed this\n\
    \         value, the replier will return NFS4ERR_REP_TOO_BIG, per the\n      \
    \   description in Section 2.10.6.4.\n      ca_maxresponsesize_cached:\n     \
    \    Like ca_maxresponsesize, but the maximum size of a reply that\n         will\
    \ be stored in the reply cache (Section 2.10.6.1).  For each\n         channel,\
    \ the server MAY decrease this value, but MUST NOT\n         increase it.  If,\
    \ in the reply to CREATE_SESSION, the value of\n         ca_maxresponsesize_cached\
    \ of a channel is less than the value\n         of ca_maxresponsesize of the same\
    \ channel, then this is an\n         indication to the requester that it needs\
    \ to be selective about\n         which replies it directs the replier to cache;\
    \ for example,\n         large replies from non-idempotent operations (e.g., COMPOUND\n\
    \         requests with a READ operation) should not be cached.  The\n       \
    \  requester decides which replies to cache via an argument to the\n         SEQUENCE\
    \ (the sa_cachethis field, see Section 18.46) or\n         CB_SEQUENCE (the csa_cachethis\
    \ field, see Section 20.9)\n         operations.  After the session is created,\
    \ if a requester sends\n         a request for which the size of the reply would\
    \ exceed\n         ca_maxresponsesize_cached, the replier will return\n      \
    \   NFS4ERR_REP_TOO_BIG_TO_CACHE, per the description in\n         Section 2.10.6.4.\n\
    \      ca_maxoperations:\n         The maximum number of operations the replier\
    \ will accept in a\n         COMPOUND or CB_COMPOUND.  For the backchannel, the\
    \ server MUST\n         NOT change the value the client offers.  For the fore\
    \ channel,\n         the server MAY change the requested value.  After the session\n\
    \         is created, if a requester sends a COMPOUND or CB_COMPOUND with\n  \
    \       more operations than ca_maxoperations, the replier MUST return\n     \
    \    NFS4ERR_TOO_MANY_OPS.\n      ca_maxrequests:\n         The maximum number\
    \ of concurrent COMPOUND or CB_COMPOUND\n         requests the requester will\
    \ send on the session.  Subsequent\n         requests will each be assigned a\
    \ slot identifier by the\n         requester within the range zero to ca_maxrequests\
    \ - 1\n         inclusive.  For the backchannel, the server MUST NOT change the\n\
    \         value the client offers.  For the fore channel, the server MAY\n   \
    \      change the requested value.\n      ca_rdma_ird:\n         This array has\
    \ a maximum of one element.  If this array has one\n         element, then the\
    \ element contains the inbound RDMA read queue\n         depth (IRD).  For each\
    \ channel, the server MAY decrease this\n         value, but MUST NOT increase\
    \ it.\n   csa_cb_program  This is the ONC RPC program number the server MUST\n\
    \      use in any callbacks sent through the backchannel to the client.\n    \
    \  The server MUST specify an ONC RPC program number equal to\n      csa_cb_program\
    \ and an ONC RPC version number equal to 4 in\n      callbacks sent to the client.\
    \  If a CB_COMPOUND is sent to the\n      client, the server MUST use a minor\
    \ version number of 1.  There is\n      no corresponding result.\n   csa_sec_parms\
    \  The field csa_sec_parms is an array of acceptable\n      security credentials\
    \ the server can use on the session's\n      backchannel.  Three security flavors\
    \ are supported: AUTH_NONE,\n      AUTH_SYS, and RPCSEC_GSS.  If AUTH_NONE is\
    \ specified for a\n      credential, then this says the client is authorizing\
    \ the server to\n      use AUTH_NONE on all callbacks for the session.  If AUTH_SYS\
    \ is\n      specified, then the client is authorizing the server to use\n    \
    \  AUTH_SYS on all callbacks, using the credential specified\n      cbsp_sys_cred.\
    \  If RPCSEC_GSS is specified, then the server is\n      allowed to use the RPCSEC_GSS\
    \ context specified in cbsp_gss_parms\n      as the RPCSEC_GSS context in the\
    \ credential of the RPC header of\n      callbacks to the client.  There is no\
    \ corresponding result.\n      The RPCSEC_GSS context for the backchannel is specified\
    \ via a pair\n      of values of data type gsshandle4_t.  The data type gsshandle4_t\n\
    \      represents an RPCSEC_GSS handle, and is precisely the same as the\n   \
    \   data type of the \"handle\" field of the rpc_gss_init_res data type\n    \
    \  defined in \"Context Creation Response - Successful Acceptance\",\n      Section\
    \ 5.2.3.1 of [4].\n      The first RPCSEC_GSS handle, gcbp_handle_from_server,\
    \ is the fore\n      handle the server returned to the client (either in the handle\n\
    \      field of data type rpc_gss_init_res or as one of the elements of\n    \
    \  the spi_handles field returned in the reply to EXCHANGE_ID) when\n      the\
    \ RPCSEC_GSS context was created on the server.  The second\n      handle, gcbp_handle_from_client,\
    \ is the back handle to which the\n      client will map the RPCSEC_GSS context.\
    \  The server can\n      immediately use the value of gcbp_handle_from_client\
    \ in the\n      RPCSEC_GSS credential in callback RPCs.  That is, the value in\n\
    \      gcbp_handle_from_client can be used as the value of the field\n      \"\
    handle\" in data type rpc_gss_cred_t (see \"Elements of the\n      RPCSEC_GSS\
    \ Security Protocol\", Section 5 of [4]) in callback RPCs.\n      The server MUST\
    \ use the RPCSEC_GSS security service specified in\n      gcbp_service, i.e.,\
    \ it MUST set the \"service\" field of the\n      rpc_gss_cred_t data type in\
    \ RPCSEC_GSS credential to the value of\n      gcbp_service (see \"RPC Request\
    \ Header\", Section 5.3.1 of [4]).\n      If the RPCSEC_GSS handle identified\
    \ by gcbp_handle_from_server\n      does not exist on the server, the server will\
    \ return\n      NFS4ERR_NOENT.\n      Within each element of csa_sec_parms, the\
    \ fore and back RPCSEC_GSS\n      contexts MUST share the same GSS context and\
    \ MUST have the same\n      seq_window (see Section 5.2.3.1 of RFC 2203 [4]).\
    \  The fore and\n      back RPCSEC_GSS context state are independent of each other\
    \ as far\n      as the RPCSEC_GSS sequence number (see the seq_num field in the\n\
    \      rpc_gss_cred_t data type of Sections 5 and 5.3.1 of [4]).\n      If an\
    \ RPCSEC_GSS handle is using the SSV context (see\n      Section 2.10.9), then\
    \ because each SSV RPCSEC_GSS handle shares a\n      common SSV GSS context, there\
    \ are security considerations specific\n      to this situation discussed in Section\
    \ 2.10.10.\n   Once the session is created, the first SEQUENCE or CB_SEQUENCE\n\
    \   received on a slot MUST have a sequence ID equal to 1; if not, the\n   replier\
    \ MUST return NFS4ERR_SEQ_MISORDERED.\n"
- title: 18.36.4.  IMPLEMENTATION
  contents:
  - "18.36.4.  IMPLEMENTATION\n   To describe a possible implementation, the same\
    \ notation for client\n   records introduced in the description of EXCHANGE_ID\
    \ is used with the\n   following addition:\n      clientid_arg: The value of the\
    \ csa_clientid field of the\n      CREATE_SESSION4args structure of the current\
    \ request.\n   Since CREATE_SESSION is a non-idempotent operation, we need to\n\
    \   consider the possibility that retries may occur as a result of a\n   client\
    \ restart, network partition, malfunctioning router, etc.  For\n   each client\
    \ ID created by EXCHANGE_ID, the server maintains a\n   separate reply cache (called\
    \ the CREATE_SESSION reply cache) similar\n   to the session reply cache used\
    \ for SEQUENCE operations, with two\n   distinctions.\n   *  First, this is a\
    \ reply cache just for detecting and processing\n      CREATE_SESSION requests\
    \ for a given client ID.\n   *  Second, the size of the client ID reply cache\
    \ is of one slot (and\n      as a result, the CREATE_SESSION request does not\
    \ carry a slot\n      number).  This means that at most one CREATE_SESSION request\
    \ for a\n      given client ID can be outstanding.\n   As previously stated, CREATE_SESSION\
    \ can be sent with or without a\n   preceding SEQUENCE operation.  Even if a SEQUENCE\
    \ precedes\n   CREATE_SESSION, the server MUST maintain the CREATE_SESSION reply\n\
    \   cache, which is separate from the reply cache for the session\n   associated\
    \ with a SEQUENCE.  If CREATE_SESSION was originally sent by\n   itself, the client\
    \ MAY send a retry of the CREATE_SESSION operation\n   within a COMPOUND preceded\
    \ by a SEQUENCE.  If CREATE_SESSION was\n   originally sent in a COMPOUND that\
    \ started with a SEQUENCE, then the\n   client SHOULD send a retry in a COMPOUND\
    \ that starts with a SEQUENCE\n   that has the same session ID as the SEQUENCE\
    \ of the original request.\n   However, the client MAY send a retry in a COMPOUND\
    \ that either has no\n   preceding SEQUENCE, or has a preceding SEQUENCE that\
    \ refers to a\n   different session than the original CREATE_SESSION.  This might\
    \ be\n   necessary if the client sends a CREATE_SESSION in a COMPOUND preceded\n\
    \   by a SEQUENCE with session ID X, and session X no longer exists.\n   Regardless,\
    \ any retry of CREATE_SESSION, with or without a preceding\n   SEQUENCE, MUST\
    \ use the same value of csa_sequence as the original.\n   After the client received\
    \ a reply to an EXCHANGE_ID operation that\n   contains a new, unconfirmed client\
    \ ID, the server expects the client\n   to follow with a CREATE_SESSION operation\
    \ to confirm the client ID.\n   The server expects value of csa_sequenceid in\
    \ the arguments to that\n   CREATE_SESSION to be to equal the value of the field\
    \ eir_sequenceid\n   that was returned in results of the EXCHANGE_ID that returned\
    \ the\n   unconfirmed client ID.  Before the server replies to that EXCHANGE_ID\n\
    \   operation, it initializes the client ID slot to be equal to\n   eir_sequenceid\
    \ - 1 (accounting for underflow), and records a\n   contrived CREATE_SESSION result\
    \ with a \"cached\" result of\n   NFS4ERR_SEQ_MISORDERED.  With the client ID\
    \ slot thus initialized,\n   the processing of the CREATE_SESSION operation is\
    \ divided into four\n   phases:\n   1.  Client record look up.  The server looks\
    \ up the client ID in its\n       client record table.  If the server contains\
    \ no records with\n       client ID equal to clientid_arg, then most likely the\
    \ client's\n       state has been purged during a period of inactivity, possibly\
    \ due\n       to a loss of connectivity.  NFS4ERR_STALE_CLIENTID is returned,\n\
    \       and no changes are made to any client records on the server.\n       Otherwise,\
    \ the server goes to phase 2.\n   2.  Sequence ID processing.  If csa_sequenceid\
    \ is equal to the\n       sequence ID in the client ID's slot, then this is a\
    \ replay of the\n       previous CREATE_SESSION request, and the server returns\
    \ the\n       cached result.  If csa_sequenceid is not equal to the sequence ID\n\
    \       in the slot, and is more than one greater (accounting for\n       wraparound),\
    \ then the server returns the error\n       NFS4ERR_SEQ_MISORDERED, and does not\
    \ change the slot.  If\n       csa_sequenceid is equal to the slot's sequence\
    \ ID + 1 (accounting\n       for wraparound), then the slot's sequence ID is set\
    \ to\n       csa_sequenceid, and the CREATE_SESSION processing goes to the\n \
    \      next phase.  A subsequent new CREATE_SESSION call over the same\n     \
    \  client ID MUST use a csa_sequenceid that is one greater than the\n       sequence\
    \ ID in the slot.\n   3.  Client ID confirmation.  If this would be the first\
    \ session for\n       the client ID, the CREATE_SESSION operation serves to confirm\
    \ the\n       client ID.  Otherwise, the client ID confirmation phase is\n   \
    \    skipped and only the session creation phase occurs.  Any case in\n      \
    \ which there is more than one record with identical values for\n       client\
    \ ID represents a server implementation error.  Operation in\n       the potential\
    \ valid cases is summarized as follows.\n       *  Successful Confirmation\n \
    \            If the server has the following unconfirmed record, then\n      \
    \       this is the expected confirmation of an unconfirmed record.\n        \
    \     { ownerid, verifier, principal_arg, clientid_arg,\n             unconfirmed\
    \ }\n             As noted in Section 18.35.4, the server might also have the\n\
    \             following confirmed record.\n             { ownerid, old_verifier,\
    \ principal_arg, old_clientid,\n             confirmed }\n             The server\
    \ schedules the replacement of both records with:\n             { ownerid, verifier,\
    \ principal_arg, clientid_arg, confirmed\n             }\n             The processing\
    \ of CREATE_SESSION continues on to session\n             creation.  Once the\
    \ session is successfully created, the\n             scheduled client record replacement\
    \ is committed.  If the\n             session is not successfully created, then\
    \ no changes are\n             made to any client records on the server.\n   \
    \    *  Unsuccessful Confirmation\n             If the server has the following\
    \ record, then the client has\n             changed principals after the previous\
    \ EXCHANGE_ID request,\n             or there has been a chance collision between\
    \ shorthand\n             client identifiers.\n             { *, *, old_principal_arg,\
    \ clientid_arg, * }\n             Neither of these cases is permissible.  Processing\
    \ stops\n             and NFS4ERR_CLID_INUSE is returned to the client.  No\n\
    \             changes are made to any client records on the server.\n   4.  Session\
    \ creation.  The server confirmed the client ID, either in\n       this CREATE_SESSION\
    \ operation, or a previous CREATE_SESSION\n       operation.  The server examines\
    \ the remaining fields of the\n       arguments.\n       The server creates the\
    \ session by recording the parameter values\n       used (including whether the\
    \ CREATE_SESSION4_FLAG_PERSIST flag is\n       set and has been accepted by the\
    \ server) and allocating space for\n       the session reply cache (if there is\
    \ not enough space, the server\n       returns NFS4ERR_NOSPC).  For each slot\
    \ in the reply cache, the\n       server sets the sequence ID to zero, and records\
    \ an entry\n       containing a COMPOUND reply with zero operations and the error\n\
    \       NFS4ERR_SEQ_MISORDERED.  This way, if the first SEQUENCE request\n   \
    \    sent has a sequence ID equal to zero, the server can simply\n       return\
    \ what is in the reply cache: NFS4ERR_SEQ_MISORDERED.  The\n       client initializes\
    \ its reply cache for receiving callbacks in the\n       same way, and similarly,\
    \ the first CB_SEQUENCE operation on a\n       slot after session creation MUST\
    \ have a sequence ID of one.\n       If the session state is created successfully,\
    \ the server\n       associates the session with the client ID provided by the\
    \ client.\n       When a request that had CREATE_SESSION4_FLAG_CONN_RDMA set needs\n\
    \       to be retried, the retry MUST be done on a new connection that is\n  \
    \     in non-RDMA mode.  If properties of the new connection are\n       different\
    \ enough that the arguments to CREATE_SESSION need to\n       change, then a non-retry\
    \ MUST be sent.  The server will\n       eventually dispose of any session that\
    \ was created on the\n       original connection.\n   On the backchannel, the\
    \ client and server might wish to have many\n   slots, in some cases perhaps more\
    \ that the fore channel, in order to\n   deal with the situations where the network\
    \ link has high latency and\n   is the primary bottleneck for response to recalls.\
    \  If so, and if the\n   client provides too few slots to the backchannel, the\
    \ server might\n   limit the number of recallable objects it gives to the client.\n\
    \   Implementing RPCSEC_GSS callback support requires changes to both the\n  \
    \ client and server implementations of RPCSEC_GSS.  One possible set of\n   changes\
    \ includes:\n   *  Adding a data structure that wraps the GSS-API context with\
    \ a\n      reference count.\n   *  New functions to increment and decrement the\
    \ reference count.  If\n      the reference count is decremented to zero, the\
    \ wrapper data\n      structure and the GSS-API context it refers to would be\
    \ freed.\n   *  Change RPCSEC_GSS to create the wrapper data structure upon\n\
    \      receiving GSS-API context from gss_accept_sec_context() and\n      gss_init_sec_context().\
    \  The reference count would be initialized\n      to 1.\n   *  Adding a function\
    \ to map an existing RPCSEC_GSS handle to a\n      pointer to the wrapper data\
    \ structure.  The reference count would\n      be incremented.\n   *  Adding a\
    \ function to create a new RPCSEC_GSS handle from a pointer\n      to the wrapper\
    \ data structure.  The reference count would be\n      incremented.\n   *  Replacing\
    \ calls from RPCSEC_GSS that free GSS-API contexts, with\n      calls to decrement\
    \ the reference count on the wrapper data\n      structure.\n"
- title: '18.37.  Operation 44: DESTROY_SESSION - Destroy a Session'
  contents:
  - '18.37.  Operation 44: DESTROY_SESSION - Destroy a Session

    '
- title: 18.37.1.  ARGUMENT
  contents:
  - "18.37.1.  ARGUMENT\n   struct DESTROY_SESSION4args {\n           sessionid4 \
    \     dsa_sessionid;\n   };\n"
- title: 18.37.2.  RESULT
  contents:
  - "18.37.2.  RESULT\n   struct DESTROY_SESSION4res {\n           nfsstat4      \
    \  dsr_status;\n   };\n"
- title: 18.37.3.  DESCRIPTION
  contents:
  - "18.37.3.  DESCRIPTION\n   The DESTROY_SESSION operation closes the session and\
    \ discards the\n   session's reply cache, if any.  Any remaining connections associated\n\
    \   with the session are immediately disassociated.  If the connection\n   has\
    \ no remaining associated sessions, the connection MAY be closed by\n   the server.\
    \  Locks, delegations, layouts, wants, and the lease, which\n   are all tied to\
    \ the client ID, are not affected by DESTROY_SESSION.\n   DESTROY_SESSION MUST\
    \ be invoked on a connection that is associated\n   with the session being destroyed.\
    \  In addition, if SP4_MACH_CRED\n   state protection was specified when the client\
    \ ID was created, the\n   RPCSEC_GSS principal that created the session MUST be\
    \ the one that\n   destroys the session, using RPCSEC_GSS privacy or integrity.\
    \  If\n   SP4_SSV state protection was specified when the client ID was\n   created,\
    \ RPCSEC_GSS using the SSV mechanism (Section 2.10.9) MUST be\n   used, with integrity\
    \ or privacy.\n   If the COMPOUND request starts with SEQUENCE, and if the sessionids\n\
    \   specified in SEQUENCE and DESTROY_SESSION are the same, then\n   *  DESTROY_SESSION\
    \ MUST be the final operation in the COMPOUND\n      request.\n   *  It is advisable\
    \ to avoid placing DESTROY_SESSION in a COMPOUND\n      request with other state-modifying\
    \ operations, because the\n      DESTROY_SESSION will destroy the reply cache.\n\
    \   *  Because the session and its reply cache are destroyed, a client\n     \
    \ that retries the request may receive an error in reply to the\n      retry,\
    \ even though the original request was successful.\n   If the COMPOUND request\
    \ starts with SEQUENCE, and if the sessionids\n   specified in SEQUENCE and DESTROY_SESSION\
    \ are different, then\n   DESTROY_SESSION can appear in any position of the COMPOUND\
    \ request\n   (except for the first position).  The two sessionids can belong\
    \ to\n   different client IDs.\n   If the COMPOUND request does not start with\
    \ SEQUENCE, and if\n   DESTROY_SESSION is not the sole operation, then server\
    \ MUST return\n   NFS4ERR_NOT_ONLY_OP.\n   If there is a backchannel on the session\
    \ and the server has\n   outstanding CB_COMPOUND operations for the session which\
    \ have not\n   been replied to, then the server MAY refuse to destroy the session\n\
    \   and return an error.  If so, then in the event the backchannel is\n   down,\
    \ the server SHOULD return NFS4ERR_CB_PATH_DOWN to inform the\n   client that\
    \ the backchannel needs to be repaired before the server\n   will allow the session\
    \ to be destroyed.  Otherwise, the error\n   CB_BACK_CHAN_BUSY SHOULD be returned\
    \ to indicate that there are\n   CB_COMPOUNDs that need to be replied to.  The\
    \ client SHOULD reply to\n   all outstanding CB_COMPOUNDs before re-sending DESTROY_SESSION.\n"
- title: '18.38.  Operation 45: FREE_STATEID - Free Stateid with No Locks'
  contents:
  - '18.38.  Operation 45: FREE_STATEID - Free Stateid with No Locks

    '
- title: 18.38.1.  ARGUMENT
  contents:
  - "18.38.1.  ARGUMENT\n   struct FREE_STATEID4args {\n           stateid4      \
    \  fsa_stateid;\n   };\n"
- title: 18.38.2.  RESULT
  contents:
  - "18.38.2.  RESULT\n   struct FREE_STATEID4res {\n           nfsstat4        fsr_status;\n\
    \   };\n"
- title: 18.38.3.  DESCRIPTION
  contents:
  - "18.38.3.  DESCRIPTION\n   The FREE_STATEID operation is used to free a stateid\
    \ that no longer\n   has any associated locks (including opens, byte-range locks,\n\
    \   delegations, and layouts).  This may be because of client LOCKU\n   operations\
    \ or because of server revocation.  If there are valid locks\n   (of any kind)\
    \ associated with the stateid in question, the error\n   NFS4ERR_LOCKS_HELD will\
    \ be returned, and the associated stateid will\n   not be freed.\n   When a stateid\
    \ is freed that had been associated with revoked locks,\n   by sending the FREE_STATEID\
    \ operation, the client acknowledges the\n   loss of those locks.  This allows\
    \ the server, once all such revoked\n   state is acknowledged, to allow that client\
    \ again to reclaim locks,\n   without encountering the edge conditions discussed\
    \ in Section 8.4.2.\n   Once a successful FREE_STATEID is done for a given stateid,\
    \ any\n   subsequent use of that stateid will result in an NFS4ERR_BAD_STATEID\n\
    \   error.\n"
- title: '18.39.  Operation 46: GET_DIR_DELEGATION - Get a Directory Delegation'
  contents:
  - '18.39.  Operation 46: GET_DIR_DELEGATION - Get a Directory Delegation

    '
- title: 18.39.1.  ARGUMENT
  contents:
  - "18.39.1.  ARGUMENT\n   typedef nfstime4 attr_notice4;\n   struct GET_DIR_DELEGATION4args\
    \ {\n           /* CURRENT_FH: delegated directory */\n           bool       \
    \     gdda_signal_deleg_avail;\n           bitmap4         gdda_notification_types;\n\
    \           attr_notice4    gdda_child_attr_delay;\n           attr_notice4  \
    \  gdda_dir_attr_delay;\n           bitmap4         gdda_child_attributes;\n \
    \          bitmap4         gdda_dir_attributes;\n   };\n"
- title: 18.39.2.  RESULT
  contents:
  - "18.39.2.  RESULT\n   struct GET_DIR_DELEGATION4resok {\n           verifier4\
    \       gddr_cookieverf;\n           /* Stateid for get_dir_delegation */\n  \
    \         stateid4        gddr_stateid;\n           /* Which notifications can\
    \ the server support */\n           bitmap4         gddr_notification;\n     \
    \      bitmap4         gddr_child_attributes;\n           bitmap4         gddr_dir_attributes;\n\
    \   };\n   enum gddrnf4_status {\n           GDD4_OK         = 0,\n          \
    \ GDD4_UNAVAIL    = 1\n   };\n   union GET_DIR_DELEGATION4res_non_fatal\n    switch\
    \ (gddrnf4_status gddrnf_status) {\n    case GDD4_OK:\n     GET_DIR_DELEGATION4resok\
    \      gddrnf_resok4;\n    case GDD4_UNAVAIL:\n     bool                     \
    \     gddrnf_will_signal_deleg_avail;\n   };\n   union GET_DIR_DELEGATION4res\n\
    \    switch (nfsstat4 gddr_status) {\n    case NFS4_OK:\n     GET_DIR_DELEGATION4res_non_fatal\
    \      gddr_res_non_fatal4;\n    default:\n     void;\n   };\n"
- title: 18.39.3.  DESCRIPTION
  contents:
  - "18.39.3.  DESCRIPTION\n   The GET_DIR_DELEGATION operation is used by a client\
    \ to request a\n   directory delegation.  The directory is represented by the\
    \ current\n   filehandle.  The client also specifies whether it wants the server\
    \ to\n   notify it when the directory changes in certain ways by setting one\n\
    \   or more bits in a bitmap.  The server may refuse to grant the\n   delegation.\
    \  In that case, the server will return\n   NFS4ERR_DIRDELEG_UNAVAIL.  If the\
    \ server decides to hand out the\n   delegation, it will return a cookie verifier\
    \ for that directory.  If\n   the cookie verifier changes when the client is holding\
    \ the\n   delegation, the delegation will be recalled unless the client has\n\
    \   asked for notification for this event.\n   The server will also return a directory\
    \ delegation stateid,\n   gddr_stateid, as a result of the GET_DIR_DELEGATION\
    \ operation.  This\n   stateid will appear in callback messages related to the\
    \ delegation,\n   such as notifications and delegation recalls.  The client will\
    \ use\n   this stateid to return the delegation voluntarily or upon recall.  A\n\
    \   delegation is returned by calling the DELEGRETURN operation.\n   The server\
    \ might not be able to support notifications of certain\n   events.  If the client\
    \ asks for such notifications, the server MUST\n   inform the client of its inability\
    \ to do so as part of the\n   GET_DIR_DELEGATION reply by not setting the appropriate\
    \ bits in the\n   supported notifications bitmask, gddr_notification, contained\
    \ in the\n   reply.  The server MUST NOT add bits to gddr_notification that the\n\
    \   client did not request.\n   The GET_DIR_DELEGATION operation can be used for\
    \ both normal and\n   named attribute directories.\n   If client sets gdda_signal_deleg_avail\
    \ to TRUE, then it is\n   registering with the client a \"want\" for a directory\
    \ delegation.  If\n   the delegation is not available, and the server supports\
    \ and will\n   honor the \"want\", the results will have\n   gddrnf_will_signal_deleg_avail\
    \ set to TRUE and no error will be\n   indicated on return.  If so, the client\
    \ should expect a future\n   CB_RECALLABLE_OBJ_AVAIL operation to indicate that\
    \ a directory\n   delegation is available.  If the server does not wish to honor\
    \ the\n   \"want\" or is not able to do so, it returns the error\n   NFS4ERR_DIRDELEG_UNAVAIL.\
    \  If the delegation is immediately\n   available, the server SHOULD return it\
    \ with the response to the\n   operation, rather than via a callback.\n   When\
    \ a client makes a request for a directory delegation while it\n   already holds\
    \ a directory delegation for that directory (including\n   the case where it has\
    \ been recalled but not yet returned by the\n   client or revoked by the server),\
    \ the server MUST reply with the\n   value of gddr_status set to NFS4_OK, the\
    \ value of gddrnf_status set\n   to GDD4_UNAVAIL, and the value of gddrnf_will_signal_deleg_avail\
    \ set\n   to FALSE.  The delegation the client held before the request remains\n\
    \   intact, and its state is unchanged.  The current stateid is not\n   changed\
    \ (see Section 16.2.3.1.2 for a description of the current\n   stateid).\n"
- title: 18.39.4.  IMPLEMENTATION
  contents:
  - "18.39.4.  IMPLEMENTATION\n   Directory delegations provide the benefit of improving\
    \ cache\n   consistency of namespace information.  This is done through\n   synchronous\
    \ callbacks.  A server must support synchronous callbacks\n   in order to support\
    \ directory delegations.  In addition to that,\n   asynchronous notifications\
    \ provide a way to reduce network traffic as\n   well as improve client performance\
    \ in certain conditions.\n   Notifications are specified in terms of potential\
    \ changes to the\n   directory.  A client can ask to be notified of events by\
    \ setting one\n   or more bits in gdda_notification_types.  The client can ask\
    \ for\n   notifications on addition of entries to a directory (by setting the\n\
    \   NOTIFY4_ADD_ENTRY in gdda_notification_types), notifications on entry\n  \
    \ removal (NOTIFY4_REMOVE_ENTRY), renames (NOTIFY4_RENAME_ENTRY),\n   directory\
    \ attribute changes (NOTIFY4_CHANGE_DIR_ATTRIBUTES), and\n   cookie verifier changes\
    \ (NOTIFY4_CHANGE_COOKIE_VERIFIER) by setting\n   one or more corresponding bits\
    \ in the gdda_notification_types field.\n   The client can also ask for notifications\
    \ of changes to attributes of\n   directory entries (NOTIFY4_CHANGE_CHILD_ATTRIBUTES)\
    \ in order to keep\n   its attribute cache up to date.  However, any changes made\
    \ to child\n   attributes do not cause the delegation to be recalled.  If a client\n\
    \   is interested in directory entry caching or negative name caching, it\n  \
    \ can set the gdda_notification_types appropriately to its particular\n   need\
    \ and the server will notify it of all changes that would\n   otherwise invalidate\
    \ its name cache.  The kind of notification a\n   client asks for may depend on\
    \ the directory size, its rate of change,\n   and the applications being used\
    \ to access that directory.  The\n   enumeration of the conditions under which\
    \ a client might ask for a\n   notification is out of the scope of this specification.\n\
    \   For attribute notifications, the client will set bits in the\n   gdda_dir_attributes\
    \ bitmap to indicate which attributes it wants to\n   be notified of.  If the\
    \ server does not support notifications for\n   changes to a certain attribute,\
    \ it SHOULD NOT set that attribute in\n   the supported attribute bitmap specified\
    \ in the reply\n   (gddr_dir_attributes).  The client will also set in the\n \
    \  gdda_child_attributes bitmap the attributes of directory entries it\n   wants\
    \ to be notified of, and the server will indicate in\n   gddr_child_attributes\
    \ which attributes of directory entries it will\n   notify the client of.\n  \
    \ The client will also let the server know if it wants to get the\n   notification\
    \ as soon as the attribute change occurs or after a\n   certain delay by setting\
    \ a delay factor; gdda_child_attr_delay is for\n   attribute changes to directory\
    \ entries and gdda_dir_attr_delay is for\n   attribute changes to the directory.\
    \  If this delay factor is set to\n   zero, that indicates to the server that\
    \ the client wants to be\n   notified of any attribute changes as soon as they\
    \ occur.  If the\n   delay factor is set to N seconds, the server will make a\
    \ best-effort\n   guarantee that attribute updates are synchronized within N seconds.\n\
    \   If the client asks for a delay factor that the server does not\n   support\
    \ or that may cause significant resource consumption on the\n   server by causing\
    \ the server to send a lot of notifications, the\n   server should not commit\
    \ to sending out notifications for attributes\n   and therefore must not set the\
    \ appropriate bit in the\n   gddr_child_attributes and gddr_dir_attributes bitmaps\
    \ in the\n   response.\n   The client MUST use a security tuple (Section 2.6.1)\
    \ that the\n   directory or its applicable ancestor (Section 2.6) is exported\
    \ with.\n   If not, the server MUST return NFS4ERR_WRONGSEC to the operation that\n\
    \   both precedes GET_DIR_DELEGATION and sets the current filehandle (see\n  \
    \ Section 2.6.3.1).\n   The directory delegation covers all the entries in the\
    \ directory\n   except the parent entry.  That means if a directory and its parent\n\
    \   both hold directory delegations, any changes to the parent will not\n   cause\
    \ a notification to be sent for the child even though the child's\n   parent entry\
    \ points to the parent directory.\n"
- title: '18.40.  Operation 47: GETDEVICEINFO - Get Device Information'
  contents:
  - '18.40.  Operation 47: GETDEVICEINFO - Get Device Information

    '
- title: 18.40.1.  ARGUMENT
  contents:
  - "18.40.1.  ARGUMENT\n   struct GETDEVICEINFO4args {\n           deviceid4    \
    \   gdia_device_id;\n           layouttype4     gdia_layout_type;\n          \
    \ count4          gdia_maxcount;\n           bitmap4         gdia_notify_types;\n\
    \   };\n"
- title: 18.40.2.  RESULT
  contents:
  - "18.40.2.  RESULT\n   struct GETDEVICEINFO4resok {\n           device_addr4  \
    \  gdir_device_addr;\n           bitmap4         gdir_notification;\n   };\n \
    \  union GETDEVICEINFO4res switch (nfsstat4 gdir_status) {\n   case NFS4_OK:\n\
    \           GETDEVICEINFO4resok     gdir_resok4;\n   case NFS4ERR_TOOSMALL:\n\
    \           count4                  gdir_mincount;\n   default:\n           void;\n\
    \   };\n"
- title: 18.40.3.  DESCRIPTION
  contents:
  - "18.40.3.  DESCRIPTION\n   The GETDEVICEINFO operation returns pNFS storage device\
    \ address\n   information for the specified device ID.  The client identifies\
    \ the\n   device information to be returned by providing the gdia_device_id and\n\
    \   gdia_layout_type that uniquely identify the device.  The client\n   provides\
    \ gdia_maxcount to limit the number of bytes for the result.\n   This maximum\
    \ size represents all of the data being returned within\n   the GETDEVICEINFO4resok\
    \ structure and includes the XDR overhead.  The\n   server may return less data.\
    \  If the server is unable to return any\n   information within the gdia_maxcount\
    \ limit, the error\n   NFS4ERR_TOOSMALL will be returned.  However, if gdia_maxcount\
    \ is\n   zero, NFS4ERR_TOOSMALL MUST NOT be returned.\n   The da_layout_type field\
    \ of the gdir_device_addr returned by the\n   server MUST be equal to the gdia_layout_type\
    \ specified by the client.\n   If it is not equal, the client SHOULD ignore the\
    \ response as invalid\n   and behave as if the server returned an error, even\
    \ if the client\n   does have support for the layout type returned.\n   The client\
    \ also provides a notification bitmap, gdia_notify_types,\n   for the device ID\
    \ mapping notification for which it is interested in\n   receiving; the server\
    \ must support device ID notifications for the\n   notification request to have\
    \ affect.  The notification mask is\n   composed in the same manner as the bitmap\
    \ for file attributes\n   (Section 3.3.7).  The numbers of bit positions are listed\
    \ in the\n   notify_device_type4 enumeration type (Section 20.12).  Only two\n\
    \   enumerated values of notify_device_type4 currently apply to\n   GETDEVICEINFO:\
    \ NOTIFY_DEVICEID4_CHANGE and NOTIFY_DEVICEID4_DELETE\n   (see Section 20.12).\n\
    \   The notification bitmap applies only to the specified device ID.  If\n   a\
    \ client sends a GETDEVICEINFO operation on a deviceID multiple\n   times, the\
    \ last notification bitmap is used by the server for\n   subsequent notifications.\
    \  If the bitmap is zero or empty, then the\n   device ID's notifications are\
    \ turned off.\n   If the client wants to just update or turn off notifications,\
    \ it MAY\n   send a GETDEVICEINFO operation with gdia_maxcount set to zero.  In\n\
    \   that event, if the device ID is valid, the reply's da_addr_body field\n  \
    \ of the gdir_device_addr field will be of zero length.\n   If an unknown device\
    \ ID is given in gdia_device_id, the server\n   returns NFS4ERR_NOENT.  Otherwise,\
    \ the device address information is\n   returned in gdir_device_addr.  Finally,\
    \ if the server supports\n   notifications for device ID mappings, the gdir_notification\
    \ result\n   will contain a bitmap of which notifications it will actually send\
    \ to\n   the client (via CB_NOTIFY_DEVICEID, see Section 20.12).\n   If NFS4ERR_TOOSMALL\
    \ is returned, the results also contain\n   gdir_mincount.  The value of gdir_mincount\
    \ represents the minimum\n   size necessary to obtain the device information.\n"
- title: 18.40.4.  IMPLEMENTATION
  contents:
  - "18.40.4.  IMPLEMENTATION\n   Aside from updating or turning off notifications,\
    \ another use case\n   for gdia_maxcount being set to zero is to validate a device\
    \ ID.\n   The client SHOULD request a notification for changes or deletion of\
    \ a\n   device ID to device address mapping so that the server can allow the\n\
    \   client gracefully use a new mapping, without having pending I/O fail\n   abruptly,\
    \ or force layouts using the device ID to be recalled or\n   revoked.\n   It is\
    \ possible that GETDEVICEINFO (and GETDEVICELIST) will race with\n   CB_NOTIFY_DEVICEID,\
    \ i.e., CB_NOTIFY_DEVICEID arrives before the\n   client gets and processes the\
    \ response to GETDEVICEINFO or\n   GETDEVICELIST.  The analysis of the race leverages\
    \ the fact that the\n   server MUST NOT delete a device ID that is referred to\
    \ by a layout\n   the client has.\n   *  CB_NOTIFY_DEVICEID deletes a device ID.\
    \  If the client believes it\n      has layouts that refer to the device ID, then\
    \ it is possible that\n      layouts referring to the deleted device ID have been\
    \ revoked.  The\n      client should send a TEST_STATEID request using the stateid\
    \ for\n      each layout that might have been revoked.  If TEST_STATEID\n    \
    \  indicates that any layouts have been revoked, the client must\n      recover\
    \ from layout revocation as described in Section 12.5.6.  If\n      TEST_STATEID\
    \ indicates that at least one layout has not been\n      revoked, the client should\
    \ send a GETDEVICEINFO operation on the\n      supposedly deleted device ID to\
    \ verify that the device ID has been\n      deleted.\n      If GETDEVICEINFO indicates\
    \ that the device ID does not exist, then\n      the client assumes the server\
    \ is faulty and recovers by sending an\n      EXCHANGE_ID operation.  If GETDEVICEINFO\
    \ indicates that the device\n      ID does exist, then while the server is faulty\
    \ for sending an\n      erroneous device ID deletion notification, the degree\
    \ to which it\n      is faulty does not require the client to create a new client\
    \ ID.\n      If the client does not have layouts that refer to the device ID,\n\
    \      no harm is done.  The client should mark the device ID as deleted,\n  \
    \    and when GETDEVICEINFO or GETDEVICELIST results are received that\n     \
    \ indicate that the device ID has been in fact deleted, the device\n      ID should\
    \ be removed from the client's cache.\n   *  CB_NOTIFY_DEVICEID indicates that\
    \ a device ID's device addressing\n      mappings have changed.  The client should\
    \ assume that the results\n      from the in-progress GETDEVICEINFO will be stale\
    \ for the device ID\n      once received, and so it should send another GETDEVICEINFO\
    \ on the\n      device ID.\n"
- title: '18.41.  Operation 48: GETDEVICELIST - Get All Device Mappings for a File'
  contents:
  - "18.41.  Operation 48: GETDEVICELIST - Get All Device Mappings for a File\n  \
    \      System\n"
- title: 18.41.1.  ARGUMENT
  contents:
  - "18.41.1.  ARGUMENT\n   struct GETDEVICELIST4args {\n           /* CURRENT_FH:\
    \ object belonging to the file system */\n           layouttype4     gdla_layout_type;\n\
    \           /* number of deviceIDs to return */\n           count4          gdla_maxdevices;\n\
    \           nfs_cookie4     gdla_cookie;\n           verifier4       gdla_cookieverf;\n\
    \   };\n"
- title: 18.41.2.  RESULT
  contents:
  - "18.41.2.  RESULT\n   struct GETDEVICELIST4resok {\n           nfs_cookie4   \
    \          gdlr_cookie;\n           verifier4               gdlr_cookieverf;\n\
    \           deviceid4               gdlr_deviceid_list<>;\n           bool   \
    \                 gdlr_eof;\n   };\n   union GETDEVICELIST4res switch (nfsstat4\
    \ gdlr_status) {\n   case NFS4_OK:\n           GETDEVICELIST4resok     gdlr_resok4;\n\
    \   default:\n           void;\n   };\n"
- title: 18.41.3.  DESCRIPTION
  contents:
  - "18.41.3.  DESCRIPTION\n   This operation is used by the client to enumerate all\
    \ of the device\n   IDs that a server's file system uses.\n   The client provides\
    \ a current filehandle of a file object that\n   belongs to the file system (i.e.,\
    \ all file objects sharing the same\n   fsid as that of the current filehandle)\
    \ and the layout type in\n   gdia_layout_type.  Since this operation might require\
    \ multiple calls\n   to enumerate all the device IDs (and is thus similar to the\
    \ READDIR\n   (Section 18.23) operation), the client also provides gdia_cookie\
    \ and\n   gdia_cookieverf to specify the current cursor position in the list.\n\
    \   When the client wants to read from the beginning of the file system's\n  \
    \ device mappings, it sets gdla_cookie to zero.  The field\n   gdla_cookieverf\
    \ MUST be ignored by the server when gdla_cookie is\n   zero.  The client provides\
    \ gdla_maxdevices to limit the number of\n   device IDs in the result.  If gdla_maxdevices\
    \ is zero, the server\n   MUST return NFS4ERR_INVAL.  The server MAY return fewer\
    \ device IDs.\n   The successful response to the operation will contain the cookie,\n\
    \   gdlr_cookie, and the cookie verifier, gdlr_cookieverf, to be used on\n   the\
    \ subsequent GETDEVICELIST.  A gdlr_eof value of TRUE signifies\n   that there\
    \ are no remaining entries in the server's device list.\n   Each element of gdlr_deviceid_list\
    \ contains a device ID.\n"
- title: 18.41.4.  IMPLEMENTATION
  contents:
  - "18.41.4.  IMPLEMENTATION\n   An example of the use of this operation is for pNFS\
    \ clients and\n   servers that use LAYOUT4_BLOCK_VOLUME layouts.  In these environments\n\
    \   it may be helpful for a client to determine device accessibility upon\n  \
    \ first file system access.\n"
- title: '18.42.  Operation 49: LAYOUTCOMMIT - Commit Writes Made Using a Layout'
  contents:
  - '18.42.  Operation 49: LAYOUTCOMMIT - Commit Writes Made Using a Layout

    '
- title: 18.42.1.  ARGUMENT
  contents:
  - "18.42.1.  ARGUMENT\n   union newtime4 switch (bool nt_timechanged) {\n   case\
    \ TRUE:\n           nfstime4           nt_time;\n   case FALSE:\n           void;\n\
    \   };\n   union newoffset4 switch (bool no_newoffset) {\n   case TRUE:\n    \
    \       offset4           no_offset;\n   case FALSE:\n           void;\n   };\n\
    \   struct LAYOUTCOMMIT4args {\n           /* CURRENT_FH: file */\n          \
    \ offset4                 loca_offset;\n           length4                 loca_length;\n\
    \           bool                    loca_reclaim;\n           stateid4       \
    \         loca_stateid;\n           newoffset4              loca_last_write_offset;\n\
    \           newtime4                loca_time_modify;\n           layoutupdate4\
    \           loca_layoutupdate;\n   };\n"
- title: 18.42.2.  RESULT
  contents:
  - "18.42.2.  RESULT\n   union newsize4 switch (bool ns_sizechanged) {\n   case TRUE:\n\
    \           length4         ns_size;\n   case FALSE:\n           void;\n   };\n\
    \   struct LAYOUTCOMMIT4resok {\n           newsize4                locr_newsize;\n\
    \   };\n   union LAYOUTCOMMIT4res switch (nfsstat4 locr_status) {\n   case NFS4_OK:\n\
    \           LAYOUTCOMMIT4resok      locr_resok4;\n   default:\n           void;\n\
    \   };\n"
- title: 18.42.3.  DESCRIPTION
  contents:
  - "18.42.3.  DESCRIPTION\n   The LAYOUTCOMMIT operation commits changes in the layout\
    \ represented\n   by the current filehandle, client ID (derived from the session\
    \ ID in\n   the preceding SEQUENCE operation), byte-range, and stateid.  Since\n\
    \   layouts are sub-dividable, a smaller portion of a layout, retrieved\n   via\
    \ LAYOUTGET, can be committed.  The byte-range being committed is\n   specified\
    \ through the byte-range (loca_offset and loca_length).  This\n   byte-range MUST\
    \ overlap with one or more existing layouts previously\n   granted via LAYOUTGET\
    \ (Section 18.43), each with an iomode of\n   LAYOUTIOMODE4_RW.  In the case where\
    \ the iomode of any held layout\n   segment is not LAYOUTIOMODE4_RW, the server\
    \ should return the error\n   NFS4ERR_BAD_IOMODE.  For the case where the client\
    \ does not hold\n   matching layout segment(s) for the defined byte-range, the\
    \ server\n   should return the error NFS4ERR_BAD_LAYOUT.\n   The LAYOUTCOMMIT\
    \ operation indicates that the client has completed\n   writes using a layout\
    \ obtained by a previous LAYOUTGET.  The client\n   may have only written a subset\
    \ of the data range it previously\n   requested.  LAYOUTCOMMIT allows it to commit\
    \ or discard provisionally\n   allocated space and to update the server with a\
    \ new end-of-file.  The\n   layout referenced by LAYOUTCOMMIT is still valid after\
    \ the operation\n   completes and can be continued to be referenced by the client\
    \ ID,\n   filehandle, byte-range, layout type, and stateid.\n   If the loca_reclaim\
    \ field is set to TRUE, this indicates that the\n   client is attempting to commit\
    \ changes to a layout after the restart\n   of the metadata server during the\
    \ metadata server's recovery grace\n   period (see Section 12.7.4).  This type\
    \ of request may be necessary\n   when the client has uncommitted writes to provisionally\
    \ allocated\n   byte-ranges of a file that were sent to the storage devices before\n\
    \   the restart of the metadata server.  In this case, the layout\n   provided\
    \ by the client MUST be a subset of a writable layout that the\n   client held\
    \ immediately before the restart of the metadata server.\n   The value of the\
    \ field loca_stateid MUST be a value that the metadata\n   server returned before\
    \ it restarted.  The metadata server is free to\n   accept or reject this request\
    \ based on its own internal metadata\n   consistency checks.  If the metadata\
    \ server finds that the layout\n   provided by the client does not pass its consistency\
    \ checks, it MUST\n   reject the request with the status NFS4ERR_RECLAIM_BAD.\
    \  The\n   successful completion of the LAYOUTCOMMIT request with loca_reclaim\n\
    \   set to TRUE does NOT provide the client with a layout for the file.\n   It\
    \ simply commits the changes to the layout specified in the\n   loca_layoutupdate\
    \ field.  To obtain a layout for the file, the client\n   must send a LAYOUTGET\
    \ request to the server after the server's grace\n   period has expired.  If the\
    \ metadata server receives a LAYOUTCOMMIT\n   request with loca_reclaim set to\
    \ TRUE when the metadata server is not\n   in its recovery grace period, it MUST\
    \ reject the request with the\n   status NFS4ERR_NO_GRACE.\n   Setting the loca_reclaim\
    \ field to TRUE is required if and only if the\n   committed layout was acquired\
    \ before the metadata server restart.  If\n   the client is committing a layout\
    \ that was acquired during the\n   metadata server's grace period, it MUST set\
    \ the \"reclaim\" field to\n   FALSE.\n   The loca_stateid is a layout stateid\
    \ value as returned by previously\n   successful layout operations (see Section\
    \ 12.5.3).\n   The loca_last_write_offset field specifies the offset of the last\n\
    \   byte written by the client previous to the LAYOUTCOMMIT.  Note that\n   this\
    \ value is never equal to the file's size (at most it is one byte\n   less than\
    \ the file's size) and MUST be less than or equal to\n   NFS4_MAXFILEOFF.  Also,\
    \ loca_last_write_offset MUST overlap the range\n   described by loca_offset and\
    \ loca_length.  The metadata server may\n   use this information to determine\
    \ whether the file's size needs to be\n   updated.  If the metadata server updates\
    \ the file's size as the\n   result of the LAYOUTCOMMIT operation, it must return\
    \ the new size\n   (locr_newsize.ns_size) as part of the results.\n   The loca_time_modify\
    \ field allows the client to suggest a\n   modification time it would like the\
    \ metadata server to set.  The\n   metadata server may use the suggestion or it\
    \ may use the time of the\n   LAYOUTCOMMIT operation to set the modification time.\
    \  If the metadata\n   server uses the client-provided modification time, it should\
    \ ensure\n   that time does not flow backwards.  If the client wants to force\
    \ the\n   metadata server to set an exact time, the client should use a SETATTR\n\
    \   operation in a COMPOUND right after LAYOUTCOMMIT.  See Section 12.5.4\n  \
    \ for more details.  If the client desires the resultant modification\n   time,\
    \ it should construct the COMPOUND so that a GETATTR follows the\n   LAYOUTCOMMIT.\n\
    \   The loca_layoutupdate argument to LAYOUTCOMMIT provides a mechanism\n   for\
    \ a client to provide layout-specific updates to the metadata\n   server.  For\
    \ example, the layout update can describe what byte-ranges\n   of the original\
    \ layout have been used and what byte-ranges can be\n   deallocated.  There is\
    \ no NFSv4.1 file layout-specific layoutupdate4\n   structure.\n   The layout\
    \ information is more verbose for block devices than for\n   objects and files\
    \ because the latter two hide the details of block\n   allocation behind their\
    \ storage protocols.  At the minimum, the\n   client needs to communicate changes\
    \ to the end-of-file location back\n   to the server, and, if desired, its view\
    \ of the file's modification\n   time.  For block/volume layouts, it needs to\
    \ specify precisely which\n   blocks have been used.\n   If the layout identified\
    \ in the arguments does not exist, the error\n   NFS4ERR_BADLAYOUT is returned.\
    \  The layout being committed may also\n   be rejected if it does not correspond\
    \ to an existing layout with an\n   iomode of LAYOUTIOMODE4_RW.\n   On success,\
    \ the current filehandle retains its value and the current\n   stateid retains\
    \ its value.\n"
- title: 18.42.4.  IMPLEMENTATION
  contents:
  - "18.42.4.  IMPLEMENTATION\n   The client MAY also use LAYOUTCOMMIT with the loca_reclaim\
    \ field set\n   to TRUE to convey hints to modified file attributes or to report\n\
    \   layout-type specific information such as I/O errors for object-based\n   storage\
    \ layouts, as normally done during normal operation.  Doing so\n   may help the\
    \ metadata server to recover files more efficiently after\n   restart.  For example,\
    \ some file system implementations may require\n   expansive recovery of file\
    \ system objects if the metadata server does\n   not get a positive indication\
    \ from all clients holding a\n   LAYOUTIOMODE4_RW layout that they have successfully\
    \ completed all\n   their writes.  Sending a LAYOUTCOMMIT (if required) and then\n\
    \   following with LAYOUTRETURN can provide such an indication and allow\n   for\
    \ graceful and efficient recovery.\n   If loca_reclaim is TRUE, the metadata server\
    \ is free to either\n   examine or ignore the value in the field loca_stateid.\
    \  The metadata\n   server implementation might or might not encode in its layout\
    \ stateid\n   information that allows the metadata server to perform a consistency\n\
    \   check on the LAYOUTCOMMIT request.\n"
- title: '18.43.  Operation 50: LAYOUTGET - Get Layout Information'
  contents:
  - '18.43.  Operation 50: LAYOUTGET - Get Layout Information

    '
- title: 18.43.1.  ARGUMENT
  contents:
  - "18.43.1.  ARGUMENT\n   struct LAYOUTGET4args {\n           /* CURRENT_FH: file\
    \ */\n           bool                    loga_signal_layout_avail;\n         \
    \  layouttype4             loga_layout_type;\n           layoutiomode4       \
    \    loga_iomode;\n           offset4                 loga_offset;\n         \
    \  length4                 loga_length;\n           length4                 loga_minlength;\n\
    \           stateid4                loga_stateid;\n           count4         \
    \         loga_maxcount;\n   };\n"
- title: 18.43.2.  RESULT
  contents:
  - "18.43.2.  RESULT\n   struct LAYOUTGET4resok {\n           bool              \
    \ logr_return_on_close;\n           stateid4           logr_stateid;\n       \
    \    layout4            logr_layout<>;\n   };\n   union LAYOUTGET4res switch (nfsstat4\
    \ logr_status) {\n   case NFS4_OK:\n           LAYOUTGET4resok     logr_resok4;\n\
    \   case NFS4ERR_LAYOUTTRYLATER:\n           bool                logr_will_signal_layout_avail;\n\
    \   default:\n           void;\n   };\n"
- title: 18.43.3.  DESCRIPTION
  contents:
  - "18.43.3.  DESCRIPTION\n   The LAYOUTGET operation requests a layout from the\
    \ metadata server\n   for reading or writing the file given by the filehandle\
    \ at the byte-\n   range specified by offset and length.  Layouts are identified\
    \ by the\n   client ID (derived from the session ID in the preceding SEQUENCE\n\
    \   operation), current filehandle, layout type (loga_layout_type), and\n   the\
    \ layout stateid (loga_stateid).  The use of the loga_iomode field\n   depends\
    \ upon the layout type, but should reflect the client's data\n   access intent.\n\
    \   If the metadata server is in a grace period, and does not persist\n   layouts\
    \ and device ID to device address mappings, then it MUST return\n   NFS4ERR_GRACE\
    \ (see Section 8.4.2.1).\n   The LAYOUTGET operation returns layout information\
    \ for the specified\n   byte-range: a layout.  The client actually specifies two\
    \ ranges, both\n   starting at the offset in the loga_offset field.  The first\
    \ range is\n   between loga_offset and loga_offset + loga_length - 1 inclusive.\n\
    \   This range indicates the desired range the client wants the layout to\n  \
    \ cover.  The second range is between loga_offset and loga_offset +\n   loga_minlength\
    \ - 1 inclusive.  This range indicates the required\n   range the client needs\
    \ the layout to cover.  Thus, loga_minlength\n   MUST be less than or equal to\
    \ loga_length.\n   When a length field is set to NFS4_UINT64_MAX, this indicates\
    \ a\n   desire (when loga_length is NFS4_UINT64_MAX) or requirement (when\n  \
    \ loga_minlength is NFS4_UINT64_MAX) to get a layout from loga_offset\n   through\
    \ the end-of-file, regardless of the file's length.\n   The following rules govern\
    \ the relationships among, and the minima\n   of, loga_length, loga_minlength,\
    \ and loga_offset.\n   *  If loga_length is less than loga_minlength, the metadata\
    \ server\n      MUST return NFS4ERR_INVAL.\n   *  If loga_minlength is zero, this\
    \ is an indication to the metadata\n      server that the client desires any layout\
    \ at offset loga_offset or\n      less that the metadata server has \"readily\
    \ available\".  Readily is\n      subjective, and depends on the layout type and\
    \ the pNFS server\n      implementation.  For example, some metadata servers might\
    \ have to\n      pre-allocate stable storage when they receive a request for a\n\
    \      range of a file that goes beyond the file's current length.  If\n     \
    \ loga_minlength is zero and loga_length is greater than zero, this\n      tells\
    \ the metadata server what range of the layout the client\n      would prefer\
    \ to have.  If loga_length and loga_minlength are both\n      zero, then the client\
    \ is indicating that it desires a layout of\n      any length with the ending\
    \ offset of the range no less than the\n      value specified loga_offset, and\
    \ the starting offset at or below\n      loga_offset.  If the metadata server\
    \ does not have a layout that\n      is readily available, then it MUST return\
    \ NFS4ERR_LAYOUTTRYLATER.\n   *  If the sum of loga_offset and loga_minlength\
    \ exceeds\n      NFS4_UINT64_MAX, and loga_minlength is not NFS4_UINT64_MAX, the\n\
    \      error NFS4ERR_INVAL MUST result.\n   *  If the sum of loga_offset and loga_length\
    \ exceeds NFS4_UINT64_MAX,\n      and loga_length is not NFS4_UINT64_MAX, the\
    \ error NFS4ERR_INVAL\n      MUST result.\n   After the metadata server has performed\
    \ the above checks on\n   loga_offset, loga_minlength, and loga_offset, the metadata\
    \ server\n   MUST return a layout according to the rules in Table 22.\n   Acceptable\
    \ layouts based on loga_minlength.  Note: u64m =\n   NFS4_UINT64_MAX; a_off =\
    \ loga_offset; a_minlen = loga_minlength.\n   | Layout    | Layout     | Layout\
    \   | Layout   | Layout length of  |\n   | iomode of | a_minlen   | iomode   |\
    \ offset   | reply             |\n   | request   | of request | of reply | of\
    \ reply |                   |\n   | _READ     | u64m       | MAY be   | MUST be\
    \  | MUST be >= file   |\n   |           |            | _READ    | <= a_off |\
    \ length - layout   |\n   | _READ     | u64m       | MAY be   | MUST be  | MUST\
    \ be u64m      |\n   |           |            | _RW      | <= a_off |        \
    \           |\n   | _READ     | > 0 and <  | MAY be   | MUST be  | MUST be >=\
    \        |\n   |           | u64m       | _READ    | <= a_off | MIN(file length,\
    \  |\n   | _READ     | > 0 and <  | MAY be   | MUST be  | MUST be >= a_off  |\n\
    \   |           | u64m       | _RW      | <= a_off | - layout offset + |\n   |\
    \ _READ     | 0          | MAY be   | MUST be  | MUST be > 0       |\n   |   \
    \        |            | _READ    | <= a_off |                   |\n   | _READ\
    \     | 0          | MAY be   | MUST be  | MUST be > 0       |\n   |         \
    \  |            | _RW      | <= a_off |                   |\n   | _RW       |\
    \ u64m       | MUST be  | MUST be  | MUST be u64m      |\n   |           |   \
    \         | _RW      | <= a_off |                   |\n   | _RW       | > 0 and\
    \ <  | MUST be  | MUST be  | MUST be >= a_off  |\n   |           | u64m      \
    \ | _RW      | <= a_off | - layout offset + |\n   | _RW       | 0          | MUST\
    \ be  | MUST be  | MUST be > 0       |\n   |           |            | _RW    \
    \  | <= a_off |                   |\n   If loga_minlength is not zero and the\
    \ metadata server cannot return a\n   layout according to the rules in Table 22,\
    \ then the metadata server\n   MUST return the error NFS4ERR_BADLAYOUT.  If loga_minlength\
    \ is zero\n   and the metadata server cannot or will not return a layout according\n\
    \   to the rules in Table 22, then the metadata server MUST return the\n   error\
    \ NFS4ERR_LAYOUTTRYLATER.  Assuming that loga_length is greater\n   than loga_minlength\
    \ or equal to zero, the metadata server SHOULD\n   return a layout according to\
    \ the rules in Table 23.\n   Desired layouts based on loga_length.  The rules\
    \ of Table 22 MUST be\n   applied first.  Note: u64m = NFS4_UINT64_MAX; a_off\
    \ = loga_offset;\n   a_len = loga_length.\n    | Layout iomode | Layout   | Layout\
    \   | Layout   | Layout length  |\n    | of request    | a_len of | iomode   |\
    \ offset   | of reply       |\n    |               | request  | of reply | of\
    \ reply |                |\n    | _READ         | u64m     | MAY be   | MUST be\
    \  | SHOULD be u64m |\n    | _READ         | u64m     | MAY be   | MUST be  |\
    \ SHOULD be u64m |\n    | _READ         | > 0 and  | MAY be   | MUST be  | SHOULD\
    \ be >=   |\n    |               | < u64m   | _READ    | <= a_off | a_off - layout\
    \ |\n    | _READ         | > 0 and  | MAY be   | MUST be  | SHOULD be >=   |\n\
    \    |               | < u64m   | _RW      | <= a_off | a_off - layout |\n   \
    \ | _READ         | 0        | MAY be   | MUST be  | SHOULD be >    |\n    | _READ\
    \         | 0        | MAY be   | MUST be  | SHOULD be >    |\n    | _RW     \
    \      | u64m     | MUST be  | MUST be  | SHOULD be u64m |\n    | _RW        \
    \   | > 0 and  | MUST be  | MUST be  | SHOULD be >=   |\n    |               |\
    \ < u64m   | _RW      | <= a_off | a_off - layout |\n    | _RW           | 0 \
    \       | MUST be  | MUST be  | SHOULD be >    |\n   The loga_stateid field specifies\
    \ a valid stateid.  If a layout is not\n   currently held by the client, the loga_stateid\
    \ field represents a\n   stateid reflecting the correspondingly valid open, byte-range\
    \ lock,\n   or delegation stateid.  Once a layout is held on the file by the\n\
    \   client, the loga_stateid field MUST be a stateid as returned from a\n   previous\
    \ LAYOUTGET or LAYOUTRETURN operation or provided by a\n   CB_LAYOUTRECALL operation\
    \ (see Section 12.5.3).\n   The loga_maxcount field specifies the maximum layout\
    \ size (in bytes)\n   that the client can handle.  If the size of the layout structure\n\
    \   exceeds the size specified by maxcount, the metadata server will\n   return\
    \ the NFS4ERR_TOOSMALL error.\n   The returned layout is expressed as an array,\
    \ logr_layout, with each\n   element of type layout4.  If a file has a single\
    \ striping pattern,\n   then logr_layout SHOULD contain just one entry.  Otherwise,\
    \ if the\n   requested range overlaps more than one striping pattern, logr_layout\n\
    \   will contain the required number of entries.  The elements of\n   logr_layout\
    \ MUST be sorted in ascending order of the value of the\n   lo_offset field of\
    \ each element.  There MUST be no gaps or overlaps\n   in the range between two\
    \ successive elements of logr_layout.  The\n   lo_iomode field in each element\
    \ of logr_layout MUST be the same.\n   Table 22 and Table 23 both refer to a returned\
    \ layout iomode, offset,\n   and length.  Because the returned layout is encoded\
    \ in the\n   logr_layout array, more description is required.\n   iomode  The\
    \ value of the returned layout iomode listed in Table 22\n      and Table 23 is\
    \ equal to the value of the lo_iomode field in each\n      element of logr_layout.\
    \  As shown in Table 22 and Table 23, the\n      metadata server MAY return a\
    \ layout with an lo_iomode different\n      from the requested iomode (field loga_iomode\
    \ of the request).  If\n      it does so, it MUST ensure that the lo_iomode is\
    \ more permissive\n      than the loga_iomode requested.  For example, this behavior\
    \ allows\n      an implementation to upgrade LAYOUTIOMODE4_READ requests to\n\
    \      LAYOUTIOMODE4_RW requests at its discretion, within the limits of\n   \
    \   the layout type specific protocol.  A lo_iomode of either\n      LAYOUTIOMODE4_READ\
    \ or LAYOUTIOMODE4_RW MUST be returned.\n   offset  The value of the returned\
    \ layout offset listed in Table 22\n      and Table 23 is always equal to the\
    \ lo_offset field of the first\n      element logr_layout.\n   length  When setting\
    \ the value of the returned layout length, the\n      situation is complicated\
    \ by the possibility that the special\n      layout length value NFS4_UINT64_MAX\
    \ is involved.  For a\n      logr_layout array of N elements, the lo_length field\
    \ in the first\n      N-1 elements MUST NOT be NFS4_UINT64_MAX.  The lo_length\
    \ field of\n      the last element of logr_layout can be NFS4_UINT64_MAX under\
    \ some\n      conditions as described in the following list.\n      *  If an applicable\
    \ rule of Table 22 states that the metadata\n         server MUST return a layout\
    \ of length NFS4_UINT64_MAX, then the\n         lo_length field of the last element\
    \ of logr_layout MUST be\n         NFS4_UINT64_MAX.\n      *  If an applicable\
    \ rule of Table 22 states that the metadata\n         server MUST NOT return a\
    \ layout of length NFS4_UINT64_MAX, then\n         the lo_length field of the\
    \ last element of logr_layout MUST NOT\n         be NFS4_UINT64_MAX.\n      *\
    \  If an applicable rule of Table 23 states that the metadata\n         server\
    \ SHOULD return a layout of length NFS4_UINT64_MAX, then\n         the lo_length\
    \ field of the last element of logr_layout SHOULD\n         be NFS4_UINT64_MAX.\n\
    \      *  When the value of the returned layout length of Table 22 and\n     \
    \    Table 23 is not NFS4_UINT64_MAX, then the returned layout\n         length\
    \ is equal to the sum of the lo_length fields of each\n         element of logr_layout.\n\
    \   The logr_return_on_close result field is a directive to return the\n   layout\
    \ before closing the file.  When the metadata server sets this\n   return value\
    \ to TRUE, it MUST be prepared to recall the layout in the\n   case in which the\
    \ client fails to return the layout before close.\n   For the metadata server\
    \ that knows a layout must be returned before a\n   close of the file, this return\
    \ value can be used to communicate the\n   desired behavior to the client and\
    \ thus remove one extra step from\n   the client's and metadata server's interaction.\n\
    \   The logr_stateid stateid is returned to the client for use in\n   subsequent\
    \ layout related operations.  See Sections 8.2, 12.5.3, and\n   12.5.5.2 for a\
    \ further discussion and requirements.\n   The format of the returned layout (lo_content)\
    \ is specific to the\n   layout type.  The value of the layout type (lo_content.loc_type)\
    \ for\n   each of the elements of the array of layouts returned by the metadata\n\
    \   server (logr_layout) MUST be equal to the loga_layout_type specified\n   by\
    \ the client.  If it is not equal, the client SHOULD ignore the\n   response as\
    \ invalid and behave as if the metadata server returned an\n   error, even if\
    \ the client does have support for the layout type\n   returned.\n   If neither\
    \ the requested file nor its containing file system support\n   layouts, the metadata\
    \ server MUST return NFS4ERR_LAYOUTUNAVAILABLE.\n   If the layout type is not\
    \ supported, the metadata server MUST return\n   NFS4ERR_UNKNOWN_LAYOUTTYPE. \
    \ If layouts are supported but no layout\n   matches the client provided layout\
    \ identification, the metadata\n   server MUST return NFS4ERR_BADLAYOUT.  If an\
    \ invalid loga_iomode is\n   specified, or a loga_iomode of LAYOUTIOMODE4_ANY\
    \ is specified, the\n   metadata server MUST return NFS4ERR_BADIOMODE.\n   If\
    \ the layout for the file is unavailable due to transient\n   conditions, e.g.,\
    \ file sharing prohibits layouts, the metadata server\n   MUST return NFS4ERR_LAYOUTTRYLATER.\n\
    \   If the layout request is rejected due to an overlapping layout\n   recall,\
    \ the metadata server MUST return NFS4ERR_RECALLCONFLICT.  See\n   Section 12.5.5.2\
    \ for details.\n   If the layout conflicts with a mandatory byte-range lock held\
    \ on the\n   file, and if the storage devices have no method of enforcing\n  \
    \ mandatory locks, other than through the restriction of layouts, the\n   metadata\
    \ server SHOULD return NFS4ERR_LOCKED.\n   If client sets loga_signal_layout_avail\
    \ to TRUE, then it is\n   registering with the client a \"want\" for a layout\
    \ in the event the\n   layout cannot be obtained due to resource exhaustion. \
    \ If the\n   metadata server supports and will honor the \"want\", the results\
    \ will\n   have logr_will_signal_layout_avail set to TRUE.  If so, the client\n\
    \   should expect a CB_RECALLABLE_OBJ_AVAIL operation to indicate that a\n   layout\
    \ is available.\n   On success, the current filehandle retains its value and the\
    \ current\n   stateid is updated to match the value as returned in the results.\n"
- title: 18.43.4.  IMPLEMENTATION
  contents:
  - "18.43.4.  IMPLEMENTATION\n   Typically, LAYOUTGET will be called as part of a\
    \ COMPOUND request\n   after an OPEN operation and results in the client having\
    \ location\n   information for the file.  This requires that loga_stateid be set\
    \ to\n   the special stateid that tells the metadata server to use the current\n\
    \   stateid, which is set by OPEN (see Section 16.2.3.1.2).  A client may\n  \
    \ also hold a layout across multiple OPENs.  The client specifies a\n   layout\
    \ type that limits what kind of layout the metadata server will\n   return.  This\
    \ prevents metadata servers from granting layouts that\n   are unusable by the\
    \ client.\n   As indicated by Table 22 and Table 23, the specification of LAYOUTGET\n\
    \   allows a pNFS client and server considerable flexibility.  A pNFS\n   client\
    \ can take several strategies for sending LAYOUTGET.  Some\n   examples are as\
    \ follows.\n   *  If LAYOUTGET is preceded by OPEN in the same COMPOUND request\
    \ and\n      the OPEN requests OPEN4_SHARE_ACCESS_READ access, the client might\n\
    \      opt to request a _READ layout with loga_offset set to zero,\n      loga_minlength\
    \ set to zero, and loga_length set to\n      NFS4_UINT64_MAX.  If the file has\
    \ space allocated to it, that\n      space is striped over one or more storage\
    \ devices, and there is\n      either no conflicting layout or the concept of\
    \ a conflicting\n      layout does not apply to the pNFS server's layout type\
    \ or\n      implementation, then the metadata server might return a layout\n \
    \     with a starting offset of zero, and a length equal to the length\n     \
    \ of the file, if not NFS4_UINT64_MAX.  If the length of the file is\n      not\
    \ a multiple of the pNFS server's stripe width (see Section 13.2\n      for a\
    \ formal definition), the metadata server might round up the\n      returned layout's\
    \ length.\n   *  If LAYOUTGET is preceded by OPEN in the same COMPOUND request,\
    \ and\n      the OPEN requests OPEN4_SHARE_ACCESS_WRITE access and does not\n\
    \      truncate the file, the client might opt to request a _RW layout\n     \
    \ with loga_offset set to zero, loga_minlength set to zero, and\n      loga_length\
    \ set to the file's current length (if known), or\n      NFS4_UINT64_MAX.  As\
    \ with the previous case, under some conditions\n      the metadata server might\
    \ return a layout that covers the entire\n      length of the file or beyond.\n\
    \   *  This strategy is as above, but the OPEN truncates the file.  In\n     \
    \ this case, the client might anticipate it will be writing to the\n      file\
    \ from offset zero, and so loga_offset and loga_minlength are\n      set to zero,\
    \ and loga_length is set to the value of\n      threshold4_write_iosize.  The\
    \ metadata server might return a\n      layout from offset zero with a length\
    \ at least as long as\n      threshold4_write_iosize.\n   *  A process on the\
    \ client invokes a request to read from offset\n      10000 for length 50000.\
    \  The client is using buffered I/O, and has\n      buffer sizes of 4096 bytes.\
    \  The client intends to map the request\n      of the process into a series of\
    \ READ requests starting at offset\n      8192.  The end offset needs to be higher\
    \ than 10000 + 50000 =\n      60000, and the next offset that is a multiple of\
    \ 4096 is 61440.\n      The difference between 61440 and that starting offset\
    \ of the\n      layout is 53248 (which is the product of 4096 and 15).  The value\n\
    \      of threshold4_read_iosize is less than 53248, so the client sends\n   \
    \   a LAYOUTGET request with loga_offset set to 8192, loga_minlength\n      set\
    \ to 53248, and loga_length set to the file's length (if known)\n      minus 8192\
    \ or NFS4_UINT64_MAX (if the file's length is not known).\n      Since this LAYOUTGET\
    \ request exceeds the metadata server's\n      threshold, it grants the layout,\
    \ possibly with an initial offset\n      of zero, with an end offset of at least\
    \ 8192 + 53248 - 1 = 61439,\n      but preferably a layout with an offset aligned\
    \ on the stripe width\n      and a length that is a multiple of the stripe width.\n\
    \   *  This strategy is as above, but the client is not using buffered I/\n  \
    \    O, and instead all internal I/O requests are sent directly to the\n     \
    \ server.  The LAYOUTGET request has loga_offset equal to 10000 and\n      loga_minlength\
    \ set to 50000.  The value of loga_length is set to\n      the length of the file.\
    \  The metadata server is free to return a\n      layout that fully overlaps the\
    \ requested range, with a starting\n      offset and length aligned on the stripe\
    \ width.\n   *  Again, a process on the client invokes a request to read from\n\
    \      offset 10000 for length 50000 (i.e. a range with a starting offset\n  \
    \    of 10000 and an ending offset of 69999), and buffered I/O is in\n      use.\
    \  The client is expecting that the server might not be able to\n      return\
    \ the layout for the full I/O range.  The client intends to\n      map the request\
    \ of the process into a series of thirteen READ\n      requests starting at offset\
    \ 8192, each with length 4096, with a\n      total length of 53248 (which equals\
    \ 13 * 4096), which fully\n      contains the range that client's process wants\
    \ to read.  Because\n      the value of threshold4_read_iosize is equal to 4096,\
    \ it is\n      practical and reasonable for the client to use several LAYOUTGET\n\
    \      operations to complete the series of READs.  The client sends a\n     \
    \ LAYOUTGET request with loga_offset set to 8192, loga_minlength set\n      to\
    \ 4096, and loga_length set to 53248 or higher.  The server will\n      grant\
    \ a layout possibly with an initial offset of zero, with an\n      end offset\
    \ of at least 8192 + 4096 - 1 = 12287, but preferably a\n      layout with an\
    \ offset aligned on the stripe width and a length\n      that is a multiple of\
    \ the stripe width.  This will allow the\n      client to make forward progress,\
    \ possibly sending more LAYOUTGET\n      operations for the remainder of the range.\n\
    \   *  An NFS client detects a sequential read pattern, and so sends a\n     \
    \ LAYOUTGET operation that goes well beyond any current or pending\n      read\
    \ requests to the server.  The server might likewise detect\n      this pattern,\
    \ and grant the LAYOUTGET request.  Once the client\n      reads from an offset\
    \ of the file that represents 50% of the way\n      through the range of the last\
    \ layout it received, in order to\n      avoid stalling I/O that would wait for\
    \ a layout, the client sends\n      more operations from an offset of the file\
    \ that represents 50% of\n      the way through the last layout it received. \
    \ The client continues\n      to request layouts with byte-ranges that are well\
    \ in advance of\n      the byte-ranges of recent and/or read requests of processes\n\
    \      running on the client.\n   *  This strategy is as above, but the client\
    \ fails to detect the\n      pattern, but the server does.  The next time the\
    \ metadata server\n      gets a LAYOUTGET, it returns a layout with a length that\
    \ is well\n      beyond loga_minlength.\n   *  A client is using buffered I/O,\
    \ and has a long queue of write-\n      behinds to process and also detects a\
    \ sequential write pattern.\n      It sends a LAYOUTGET for a layout that spans\
    \ the range of the\n      queued write-behinds and well beyond, including ranges\
    \ beyond the\n      filer's current length.  The client continues to send LAYOUTGET\n\
    \      operations once the write-behind queue reaches 50% of the maximum\n   \
    \   queue length.\n   Once the client has obtained a layout referring to a particular\n\
    \   device ID, the metadata server MUST NOT delete the device ID until\n   the\
    \ layout is returned or revoked.\n   CB_NOTIFY_DEVICEID can race with LAYOUTGET.\
    \  One race scenario is\n   that LAYOUTGET returns a device ID for which the client\
    \ does not have\n   device address mappings, and the metadata server sends a\n\
    \   CB_NOTIFY_DEVICEID to add the device ID to the client's awareness and\n  \
    \ meanwhile the client sends GETDEVICEINFO on the device ID.  This\n   scenario\
    \ is discussed in Section 18.40.4.  Another scenario is that\n   the CB_NOTIFY_DEVICEID\
    \ is processed by the client before it processes\n   the results from LAYOUTGET.\
    \  The client will send a GETDEVICEINFO on\n   the device ID.  If the results\
    \ from GETDEVICEINFO are received before\n   the client gets results from LAYOUTGET,\
    \ then there is no longer a\n   race.  If the results from LAYOUTGET are received\
    \ before the results\n   from GETDEVICEINFO, the client can either wait for results\
    \ of\n   GETDEVICEINFO or send another one to get possibly more up-to-date\n \
    \  device address mappings for the device ID.\n"
- title: '18.44.  Operation 51: LAYOUTRETURN - Release Layout Information'
  contents:
  - '18.44.  Operation 51: LAYOUTRETURN - Release Layout Information

    '
- title: 18.44.1.  ARGUMENT
  contents:
  - "18.44.1.  ARGUMENT\n   /* Constants used for LAYOUTRETURN and CB_LAYOUTRECALL\
    \ */\n   const LAYOUT4_RET_REC_FILE      = 1;\n   const LAYOUT4_RET_REC_FSID \
    \     = 2;\n   const LAYOUT4_RET_REC_ALL       = 3;\n   enum layoutreturn_type4\
    \ {\n           LAYOUTRETURN4_FILE = LAYOUT4_RET_REC_FILE,\n           LAYOUTRETURN4_FSID\
    \ = LAYOUT4_RET_REC_FSID,\n           LAYOUTRETURN4_ALL  = LAYOUT4_RET_REC_ALL\n\
    \   };\n   struct layoutreturn_file4 {\n           offset4         lrf_offset;\n\
    \           length4         lrf_length;\n           stateid4        lrf_stateid;\n\
    \           /* layouttype4 specific data */\n           opaque          lrf_body<>;\n\
    \   };\n   union layoutreturn4 switch(layoutreturn_type4 lr_returntype) {\n  \
    \         case LAYOUTRETURN4_FILE:\n                   layoutreturn_file4    \
    \  lr_layout;\n           default:\n                   void;\n   };\n   struct\
    \ LAYOUTRETURN4args {\n           /* CURRENT_FH: file */\n           bool    \
    \                lora_reclaim;\n           layouttype4             lora_layout_type;\n\
    \           layoutiomode4           lora_iomode;\n           layoutreturn4   \
    \        lora_layoutreturn;\n   };\n"
- title: 18.44.2.  RESULT
  contents:
  - "18.44.2.  RESULT\n   union layoutreturn_stateid switch (bool lrs_present) {\n\
    \   case TRUE:\n           stateid4                lrs_stateid;\n   case FALSE:\n\
    \           void;\n   };\n   union LAYOUTRETURN4res switch (nfsstat4 lorr_status)\
    \ {\n   case NFS4_OK:\n           layoutreturn_stateid    lorr_stateid;\n   default:\n\
    \           void;\n   };\n"
- title: 18.44.3.  DESCRIPTION
  contents:
  - "18.44.3.  DESCRIPTION\n   This operation returns from the client to the server\
    \ one or more\n   layouts represented by the client ID (derived from the session\
    \ ID in\n   the preceding SEQUENCE operation), lora_layout_type, and lora_iomode.\n\
    \   When lr_returntype is LAYOUTRETURN4_FILE, the returned layout is\n   further\
    \ identified by the current filehandle, lrf_offset, lrf_length,\n   and lrf_stateid.\
    \  If the lrf_length field is NFS4_UINT64_MAX, all\n   bytes of the layout, starting\
    \ at lrf_offset, are returned.  When\n   lr_returntype is LAYOUTRETURN4_FSID,\
    \ the current filehandle is used\n   to identify the file system and all layouts\
    \ matching the client ID,\n   the fsid of the file system, lora_layout_type, and\
    \ lora_iomode are\n   returned.  When lr_returntype is LAYOUTRETURN4_ALL, all\
    \ layouts\n   matching the client ID, lora_layout_type, and lora_iomode are\n\
    \   returned and the current filehandle is not used.  After this call,\n   the\
    \ client MUST NOT use the returned layout(s) and the associated\n   storage protocol\
    \ to access the file data.\n   If the set of layouts designated in the case of\
    \ LAYOUTRETURN4_FSID or\n   LAYOUTRETURN4_ALL is empty, then no error results.\
    \  In the case of\n   LAYOUTRETURN4_FILE, the byte-range specified is returned\
    \ even if it\n   is a subdivision of a layout previously obtained with LAYOUTGET,\
    \ a\n   combination of multiple layouts previously obtained with LAYOUTGET,\n\
    \   or a combination including some layouts previously obtained with\n   LAYOUTGET,\
    \ and one or more subdivisions of such layouts.  When the\n   byte-range does\
    \ not designate any bytes for which a layout is held\n   for the specified file,\
    \ client ID, layout type and mode, no error\n   results.  See Section 12.5.5.2.1.5\
    \ for considerations with \"bulk\"\n   return of layouts.\n   The layout being\
    \ returned may be a subset or superset of a layout\n   specified by CB_LAYOUTRECALL.\
    \  However, if it is a subset, the recall\n   is not complete until the full recalled\
    \ scope has been returned.\n   Recalled scope refers to the byte-range in the\
    \ case of\n   LAYOUTRETURN4_FILE, the use of LAYOUTRETURN4_FSID, or the use of\n\
    \   LAYOUTRETURN4_ALL.  There must be a LAYOUTRETURN with a matching\n   scope\
    \ to complete the return even if all current layout ranges have\n   been previously\
    \ individually returned.\n   For all lr_returntype values, an iomode of LAYOUTIOMODE4_ANY\n\
    \   specifies that all layouts that match the other arguments to\n   LAYOUTRETURN\
    \ (i.e., client ID, lora_layout_type, and one of current\n   filehandle and range;\
    \ fsid derived from current filehandle; or\n   LAYOUTRETURN4_ALL) are being returned.\n\
    \   In the case that lr_returntype is LAYOUTRETURN4_FILE, the lrf_stateid\n  \
    \ provided by the client is a layout stateid as returned from previous\n   layout\
    \ operations.  Note that the \"seqid\" field of lrf_stateid MUST\n   NOT be zero.\
    \  See Sections 8.2, 12.5.3, and 12.5.5.2 for a further\n   discussion and requirements.\n\
    \   Return of a layout or all layouts does not invalidate the mapping of\n   storage\
    \ device ID to a storage device address.  The mapping remains\n   in effect until\
    \ specifically changed or deleted via device ID\n   notification callbacks.  Of\
    \ course if there are no remaining layouts\n   that refer to a previously used\
    \ device ID, the server is free to\n   delete a device ID without a notification\
    \ callback, which will be the\n   case when notifications are not in effect.\n\
    \   If the lora_reclaim field is set to TRUE, the client is attempting to\n  \
    \ return a layout that was acquired before the restart of the metadata\n   server\
    \ during the metadata server's grace period.  When returning\n   layouts that\
    \ were acquired during the metadata server's grace period,\n   the client MUST\
    \ set the lora_reclaim field to FALSE.  The\n   lora_reclaim field MUST be set\
    \ to FALSE also when lr_layoutreturn is\n   LAYOUTRETURN4_FSID or LAYOUTRETURN4_ALL.\
    \  See LAYOUTCOMMIT\n   (Section 18.42) for more details.\n   Layouts may be returned\
    \ when recalled or voluntarily (i.e., before\n   the server has recalled them).\
    \  In either case, the client must\n   properly propagate state changed under\
    \ the context of the layout to\n   the storage device(s) or to the metadata server\
    \ before returning the\n   layout.\n   If the client returns the layout in response\
    \ to a CB_LAYOUTRECALL\n   where the lor_recalltype field of the clora_recall\
    \ field was\n   LAYOUTRECALL4_FILE, the client should use the lor_stateid value\
    \ from\n   CB_LAYOUTRECALL as the value for lrf_stateid.  Otherwise, it should\n\
    \   use logr_stateid (from a previous LAYOUTGET result) or lorr_stateid\n   (from\
    \ a previous LAYRETURN result).  This is done to indicate the\n   point in time\
    \ (in terms of layout stateid transitions) when the\n   recall was sent.  The\
    \ client uses the precise lora_recallstateid\n   value and MUST NOT set the stateid's\
    \ seqid to zero; otherwise,\n   NFS4ERR_BAD_STATEID MUST be returned.  NFS4ERR_OLD_STATEID\
    \ can be\n   returned if the client is using an old seqid, and the server knows\n\
    \   the client should not be using the old seqid.  For example, the\n   client\
    \ uses the seqid on slot 1 of the session, receives the response\n   with the\
    \ new seqid, and uses the slot to send another request with\n   the old seqid.\n\
    \   If a client fails to return a layout in a timely manner, then the\n   metadata\
    \ server SHOULD use its control protocol with the storage\n   devices to fence\
    \ the client from accessing the data referenced by the\n   layout.  See Section\
    \ 12.5.5 for more details.\n   If the LAYOUTRETURN request sets the lora_reclaim\
    \ field to TRUE after\n   the metadata server's grace period, NFS4ERR_NO_GRACE\
    \ is returned.\n   If the LAYOUTRETURN request sets the lora_reclaim field to\
    \ TRUE and\n   lr_returntype is set to LAYOUTRETURN4_FSID or LAYOUTRETURN4_ALL,\n\
    \   NFS4ERR_INVAL is returned.\n   If the client sets the lr_returntype field\
    \ to LAYOUTRETURN4_FILE,\n   then the lrs_stateid field will represent the layout\
    \ stateid as\n   updated for this operation's processing; the current stateid\
    \ will\n   also be updated to match the returned value.  If the last byte of any\n\
    \   layout for the current file, client ID, and layout type is being\n   returned\
    \ and there are no remaining pending CB_LAYOUTRECALL\n   operations for which\
    \ a LAYOUTRETURN operation must be done,\n   lrs_present MUST be FALSE, and no\
    \ stateid will be returned.  In\n   addition, the COMPOUND request's current stateid\
    \ will be set to the\n   all-zeroes special stateid (see Section 16.2.3.1.2).\
    \  The server MUST\n   reject with NFS4ERR_BAD_STATEID any further use of the\
    \ current\n   stateid in that COMPOUND until the current stateid is re-established\n\
    \   by a later stateid-returning operation.\n   On success, the current filehandle\
    \ retains its value.\n   If the EXCHGID4_FLAG_BIND_PRINC_STATEID capability is\
    \ set on the\n   client ID (see Section 18.35), the server will require that the\n\
    \   principal, security flavor, and if applicable, the GSS mechanism,\n   combination\
    \ that acquired the layout also be the one to send\n   LAYOUTRETURN.  This might\
    \ not be possible if credentials for the\n   principal are no longer available.\
    \  The server will allow the machine\n   credential or SSV credential (see Section\
    \ 18.35) to send LAYOUTRETURN\n   if LAYOUTRETURN's operation code was set in\
    \ the spo_must_allow result\n   of EXCHANGE_ID.\n"
- title: 18.44.4.  IMPLEMENTATION
  contents:
  - "18.44.4.  IMPLEMENTATION\n   The final LAYOUTRETURN operation in response to\
    \ a CB_LAYOUTRECALL\n   callback MUST be serialized with any outstanding, intersecting\n\
    \   LAYOUTRETURN operations.  Note that it is possible that while a\n   client\
    \ is returning the layout for some recalled range, the server\n   may recall a\
    \ superset of that range (e.g., LAYOUTRECALL4_ALL); the\n   final return operation\
    \ for the latter must block until the former\n   layout recall is done.\n   Returning\
    \ all layouts in a file system using LAYOUTRETURN4_FSID is\n   typically done\
    \ in response to a CB_LAYOUTRECALL for that file system\n   as the final return\
    \ operation.  Similarly, LAYOUTRETURN4_ALL is used\n   in response to a recall\
    \ callback for all layouts.  It is possible\n   that the client already returned\
    \ some outstanding layouts via\n   individual LAYOUTRETURN calls and the call\
    \ for LAYOUTRETURN4_FSID or\n   LAYOUTRETURN4_ALL marks the end of the LAYOUTRETURN\
    \ sequence.  See\n   Section 12.5.5.1 for more details.\n   Once the client has\
    \ returned all layouts referring to a particular\n   device ID, the server MAY\
    \ delete the device ID.\n"
- title: '18.45.  Operation 52: SECINFO_NO_NAME - Get Security on Unnamed Object'
  contents:
  - '18.45.  Operation 52: SECINFO_NO_NAME - Get Security on Unnamed Object

    '
- title: 18.45.1.  ARGUMENT
  contents:
  - "18.45.1.  ARGUMENT\n   enum secinfo_style4 {\n           SECINFO_STYLE4_CURRENT_FH\
    \       = 0,\n           SECINFO_STYLE4_PARENT           = 1\n   };\n   /* CURRENT_FH:\
    \ object or child directory */\n   typedef secinfo_style4 SECINFO_NO_NAME4args;\n"
- title: 18.45.2.  RESULT
  contents:
  - "18.45.2.  RESULT\n   /* CURRENTFH: consumed if status is NFS4_OK */\n   typedef\
    \ SECINFO4res SECINFO_NO_NAME4res;\n"
- title: 18.45.3.  DESCRIPTION
  contents:
  - "18.45.3.  DESCRIPTION\n   Like the SECINFO operation, SECINFO_NO_NAME is used\
    \ by the client to\n   obtain a list of valid RPC authentication flavors for a\
    \ specific file\n   object.  Unlike SECINFO, SECINFO_NO_NAME only works with objects\
    \ that\n   are accessed by filehandle.\n   There are two styles of SECINFO_NO_NAME,\
    \ as determined by the value\n   of the secinfo_style4 enumeration.  If SECINFO_STYLE4_CURRENT_FH\
    \ is\n   passed, then SECINFO_NO_NAME is querying for the required security\n\
    \   for the current filehandle.  If SECINFO_STYLE4_PARENT is passed, then\n  \
    \ SECINFO_NO_NAME is querying for the required security of the current\n   filehandle's\
    \ parent.  If the style selected is SECINFO_STYLE4_PARENT,\n   then SECINFO should\
    \ apply the same access methodology used for\n   LOOKUPP when evaluating the traversal\
    \ to the parent directory.\n   Therefore, if the requester does not have the appropriate\
    \ access to\n   LOOKUPP the parent, then SECINFO_NO_NAME must behave the same\
    \ way and\n   return NFS4ERR_ACCESS.\n   If PUTFH, PUTPUBFH, PUTROOTFH, or RESTOREFH\
    \ returns NFS4ERR_WRONGSEC,\n   then the client resolves the situation by sending\
    \ a COMPOUND request\n   that consists of PUTFH, PUTPUBFH, or PUTROOTFH immediately\
    \ followed\n   by SECINFO_NO_NAME, style SECINFO_STYLE4_CURRENT_FH.  See Section\
    \ 2.6\n   for instructions on dealing with NFS4ERR_WRONGSEC error returns from\n\
    \   PUTFH, PUTROOTFH, PUTPUBFH, or RESTOREFH.\n   If SECINFO_STYLE4_PARENT is\
    \ specified and there is no parent\n   directory, SECINFO_NO_NAME MUST return\
    \ NFS4ERR_NOENT.\n   On success, the current filehandle is consumed (see\n   Section\
    \ 2.6.3.1.1.8), and if the next operation after SECINFO_NO_NAME\n   tries to use\
    \ the current filehandle, that operation will fail with\n   the status NFS4ERR_NOFILEHANDLE.\n\
    \   Everything else about SECINFO_NO_NAME is the same as SECINFO.  See\n   the\
    \ discussion on SECINFO (Section 18.29.3).\n"
- title: 18.45.4.  IMPLEMENTATION
  contents:
  - "18.45.4.  IMPLEMENTATION\n   See the discussion on SECINFO (Section 18.29.4).\n"
- title: '18.46.  Operation 53: SEQUENCE - Supply Per-Procedure Sequencing and'
  contents:
  - "18.46.  Operation 53: SEQUENCE - Supply Per-Procedure Sequencing and\n      \
    \  Control\n"
- title: 18.46.1.  ARGUMENT
  contents:
  - "18.46.1.  ARGUMENT\n   struct SEQUENCE4args {\n           sessionid4     sa_sessionid;\n\
    \           sequenceid4    sa_sequenceid;\n           slotid4        sa_slotid;\n\
    \           slotid4        sa_highest_slotid;\n           bool           sa_cachethis;\n\
    \   };\n"
- title: 18.46.2.  RESULT
  contents:
  - "18.46.2.  RESULT\n   const SEQ4_STATUS_CB_PATH_DOWN                  = 0x00000001;\n\
    \   const SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRING      = 0x00000002;\n   const SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED\
    \       = 0x00000004;\n   const SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED     = 0x00000008;\n\
    \   const SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED    = 0x00000010;\n   const SEQ4_STATUS_ADMIN_STATE_REVOKED\
    \           = 0x00000020;\n   const SEQ4_STATUS_RECALLABLE_STATE_REVOKED     \
    \ = 0x00000040;\n   const SEQ4_STATUS_LEASE_MOVED                   = 0x00000080;\n\
    \   const SEQ4_STATUS_RESTART_RECLAIM_NEEDED        = 0x00000100;\n   const SEQ4_STATUS_CB_PATH_DOWN_SESSION\
    \          = 0x00000200;\n   const SEQ4_STATUS_BACKCHANNEL_FAULT             =\
    \ 0x00000400;\n   const SEQ4_STATUS_DEVID_CHANGED                 = 0x00000800;\n\
    \   const SEQ4_STATUS_DEVID_DELETED                 = 0x00001000;\n   struct SEQUENCE4resok\
    \ {\n           sessionid4      sr_sessionid;\n           sequenceid4     sr_sequenceid;\n\
    \           slotid4         sr_slotid;\n           slotid4         sr_highest_slotid;\n\
    \           slotid4         sr_target_highest_slotid;\n           uint32_t   \
    \     sr_status_flags;\n   };\n   union SEQUENCE4res switch (nfsstat4 sr_status)\
    \ {\n   case NFS4_OK:\n           SEQUENCE4resok  sr_resok4;\n   default:\n  \
    \         void;\n   };\n"
- title: 18.46.3.  DESCRIPTION
  contents:
  - "18.46.3.  DESCRIPTION\n   The SEQUENCE operation is used by the server to implement\
    \ session\n   request control and the reply cache semantics.\n   SEQUENCE MUST\
    \ appear as the first operation of any COMPOUND in which\n   it appears.  The\
    \ error NFS4ERR_SEQUENCE_POS will be returned when it\n   is found in any position\
    \ in a COMPOUND beyond the first.  Operations\n   other than SEQUENCE, BIND_CONN_TO_SESSION,\
    \ EXCHANGE_ID,\n   CREATE_SESSION, and DESTROY_SESSION, MUST NOT appear as the\
    \ first\n   operation in a COMPOUND.  Such operations MUST yield the error\n \
    \  NFS4ERR_OP_NOT_IN_SESSION if they do appear at the start of a\n   COMPOUND.\n\
    \   If SEQUENCE is received on a connection not associated with the\n   session\
    \ via CREATE_SESSION or BIND_CONN_TO_SESSION, and connection\n   association enforcement\
    \ is enabled (see Section 18.35), then the\n   server returns NFS4ERR_CONN_NOT_BOUND_TO_SESSION.\n\
    \   The sa_sessionid argument identifies the session to which this\n   request\
    \ applies.  The sr_sessionid result MUST equal sa_sessionid.\n   The sa_slotid\
    \ argument is the index in the reply cache for the\n   request.  The sa_sequenceid\
    \ field is the sequence number of the\n   request for the reply cache entry (slot).\
    \  The sr_slotid result MUST\n   equal sa_slotid.  The sr_sequenceid result MUST\
    \ equal sa_sequenceid.\n   The sa_highest_slotid argument is the highest slot\
    \ ID for which the\n   client has a request outstanding; it could be equal to\
    \ sa_slotid.\n   The server returns two \"highest_slotid\" values: sr_highest_slotid\
    \ and\n   sr_target_highest_slotid.  The former is the highest slot ID the\n \
    \  server will accept in future SEQUENCE operation, and SHOULD NOT be\n   less\
    \ than the value of sa_highest_slotid (but see Section 2.10.6.1\n   for an exception).\
    \  The latter is the highest slot ID the server\n   would prefer the client use\
    \ on a future SEQUENCE operation.\n   If sa_cachethis is TRUE, then the client\
    \ is requesting that the\n   server cache the entire reply in the server's reply\
    \ cache; therefore,\n   the server MUST cache the reply (see Section 2.10.6.1.3).\
    \  The server\n   MAY cache the reply if sa_cachethis is FALSE.  If the server\
    \ does not\n   cache the entire reply, it MUST still record that it executed the\n\
    \   request at the specified slot and sequence ID.\n   The response to the SEQUENCE\
    \ operation contains a word of status\n   flags (sr_status_flags) that can provide\
    \ to the client information\n   related to the status of the client's lock state\
    \ and communications\n   paths.  Note that any status bits relating to lock state\
    \ MAY be reset\n   when lock state is lost due to a server restart (even if the\
    \ session\n   is persistent across restarts; session persistence does not imply\n\
    \   lock state persistence) or the establishment of a new client\n   instance.\n\
    \   SEQ4_STATUS_CB_PATH_DOWN\n      When set, indicates that the client has no\
    \ operational backchannel\n      path for any session associated with the client\
    \ ID, making it\n      necessary for the client to re-establish one.  This bit\
    \ remains\n      set on all SEQUENCE responses on all sessions associated with\
    \ the\n      client ID until at least one backchannel is available on any\n  \
    \    session associated with the client ID.  If the client fails to re-\n    \
    \  establish a backchannel for the client ID, it is subject to having\n      recallable\
    \ state revoked.\n   SEQ4_STATUS_CB_PATH_DOWN_SESSION\n      When set, indicates\
    \ that the session has no operational\n      backchannel.  There are two reasons\
    \ why\n      SEQ4_STATUS_CB_PATH_DOWN_SESSION may be set and not\n      SEQ4_STATUS_CB_PATH_DOWN.\
    \  First is that a callback operation that\n      applies specifically to the\
    \ session (e.g., CB_RECALL_SLOT, see\n      Section 20.8) needs to be sent.  Second\
    \ is that the server did\n      send a callback operation, but the connection\
    \ was lost before the\n      reply.  The server cannot be sure whether or not\
    \ the client\n      received the callback operation, and so, per rules on request\n\
    \      retry, the server MUST retry the callback operation over the same\n   \
    \   session.  The SEQ4_STATUS_CB_PATH_DOWN_SESSION bit is the\n      indication\
    \ to the client that it needs to associate a connection\n      to the session's\
    \ backchannel.  This bit remains set on all\n      SEQUENCE responses of the session\
    \ until a connection is associated\n      with the session's a backchannel.  If\
    \ the client fails to re-\n      establish a backchannel for the session, it is\
    \ subject to having\n      recallable state revoked.\n   SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRING\n\
    \      When set, indicates that all GSS contexts or RPCSEC_GSS handles\n     \
    \ assigned to the session's backchannel will expire within a period\n      equal\
    \ to the lease time.  This bit remains set on all SEQUENCE\n      replies until\
    \ at least one of the following are true:\n      *  All SSV RPCSEC_GSS handles\
    \ on the session's backchannel have\n         been destroyed and all non-SSV GSS\
    \ contexts have expired.\n      *  At least one more SSV RPCSEC_GSS handle has\
    \ been added to the\n         backchannel.\n      *  The expiration time of at\
    \ least one non-SSV GSS context of an\n         RPCSEC_GSS handle is beyond the\
    \ lease period from the current\n         time (relative to the time of when a\
    \ SEQUENCE response was\n         sent)\n   SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED\n\
    \      When set, indicates all non-SSV GSS contexts and all SSV\n      RPCSEC_GSS\
    \ handles assigned to the session's backchannel have\n      expired or have been\
    \ destroyed.  This bit remains set on all\n      SEQUENCE replies until at least\
    \ one non-expired non-SSV GSS\n      context for the session's backchannel has\
    \ been established or at\n      least one SSV RPCSEC_GSS handle has been assigned\
    \ to the\n      backchannel.\n   SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED\n     \
    \ When set, indicates that the lease has expired and as a result the\n      server\
    \ released all of the client's locking state.  This status\n      bit remains\
    \ set on all SEQUENCE replies until the loss of all such\n      locks has been\
    \ acknowledged by use of FREE_STATEID (see\n      Section 18.38), or by establishing\
    \ a new client instance by\n      destroying all sessions (via DESTROY_SESSION),\
    \ the client ID (via\n      DESTROY_CLIENTID), and then invoking EXCHANGE_ID and\n\
    \      CREATE_SESSION to establish a new client ID.\n   SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED\n\
    \      When set, indicates that some subset of the client's locks have\n     \
    \ been revoked due to expiration of the lease period followed by\n      another\
    \ client's conflicting LOCK operation.  This status bit\n      remains set on\
    \ all SEQUENCE replies until the loss of all such\n      locks has been acknowledged\
    \ by use of FREE_STATEID.\n   SEQ4_STATUS_ADMIN_STATE_REVOKED\n      When set,\
    \ indicates that one or more locks have been revoked\n      without expiration\
    \ of the lease period, due to administrative\n      action.  This status bit remains\
    \ set on all SEQUENCE replies until\n      the loss of all such locks has been\
    \ acknowledged by use of\n      FREE_STATEID.\n   SEQ4_STATUS_RECALLABLE_STATE_REVOKED\n\
    \      When set, indicates that one or more recallable objects have been\n   \
    \   revoked without expiration of the lease period, due to the\n      client's\
    \ failure to return them when recalled, which may be a\n      consequence of there\
    \ being no working backchannel and the client\n      failing to re-establish a\
    \ backchannel per the\n      SEQ4_STATUS_CB_PATH_DOWN, SEQ4_STATUS_CB_PATH_DOWN_SESSION,\
    \ or\n      SEQ4_STATUS_CB_GSS_CONTEXTS_EXPIRED status flags.  This status bit\n\
    \      remains set on all SEQUENCE replies until the loss of all such\n      locks\
    \ has been acknowledged by use of FREE_STATEID.\n   SEQ4_STATUS_LEASE_MOVED\n\
    \      When set, indicates that responsibility for lease renewal has been\n  \
    \    transferred to one or more new servers.  This condition will\n      continue\
    \ until the client receives an NFS4ERR_MOVED error and the\n      server receives\
    \ the subsequent GETATTR for the fs_locations or\n      fs_locations_info attribute\
    \ for an access to each file system for\n      which a lease has been moved to\
    \ a new server.  See\n      Section 11.11.9.2.\n   SEQ4_STATUS_RESTART_RECLAIM_NEEDED\n\
    \      When set, indicates that due to server restart, the client must\n     \
    \ reclaim locking state.  Until the client sends a global\n      RECLAIM_COMPLETE\
    \ (Section 18.51), every SEQUENCE operation will\n      return SEQ4_STATUS_RESTART_RECLAIM_NEEDED.\n\
    \   SEQ4_STATUS_BACKCHANNEL_FAULT\n      The server has encountered an unrecoverable\
    \ fault with the\n      backchannel (e.g., it has lost track of the sequence ID\
    \ for a slot\n      in the backchannel).  The client MUST stop sending more requests\n\
    \      on the session's fore channel, wait for all outstanding requests\n    \
    \  to complete on the fore and back channel, and then destroy the\n      session.\n\
    \   SEQ4_STATUS_DEVID_CHANGED\n      The client is using device ID notifications\
    \ and the server has\n      changed a device ID mapping held by the client.  This\
    \ flag will\n      stay present until the client has obtained the new mapping\
    \ with\n      GETDEVICEINFO.\n   SEQ4_STATUS_DEVID_DELETED\n      The client is\
    \ using device ID notifications and the server has\n      deleted a device ID\
    \ mapping held by the client.  This flag will\n      stay in effect until the\
    \ client sends a GETDEVICEINFO on the\n      device ID with a null value in the\
    \ argument gdia_notify_types.\n   The value of the sa_sequenceid argument relative\
    \ to the cached\n   sequence ID on the slot falls into one of three cases.\n \
    \  *  If the difference between sa_sequenceid and the server's cached\n      sequence\
    \ ID at the slot ID is two (2) or more, or if sa_sequenceid\n      is less than\
    \ the cached sequence ID (accounting for wraparound of\n      the unsigned sequence\
    \ ID value), then the server MUST return\n      NFS4ERR_SEQ_MISORDERED.\n   *\
    \  If sa_sequenceid and the cached sequence ID are the same, this is\n      a\
    \ retry, and the server replies with what is recorded in the reply\n      cache.\
    \  The lease is possibly renewed as described below.\n   *  If sa_sequenceid is\
    \ one greater (accounting for wraparound) than\n      the cached sequence ID,\
    \ then this is a new request, and the slot's\n      sequence ID is incremented.\
    \  The operations subsequent to\n      SEQUENCE, if any, are processed.  If there\
    \ are no other\n      operations, the only other effects are to cache the SEQUENCE\
    \ reply\n      in the slot, maintain the session's activity, and possibly renew\n\
    \      the lease.\n   If the client reuses a slot ID and sequence ID for a completely\n\
    \   different request, the server MAY treat the request as if it is a\n   retry\
    \ of what it has already executed.  The server MAY however detect\n   the client's\
    \ illegal reuse and return NFS4ERR_SEQ_FALSE_RETRY.\n   If SEQUENCE returns an\
    \ error, then the state of the slot (sequence\n   ID, cached reply) MUST NOT change,\
    \ and the associated lease MUST NOT\n   be renewed.\n   If SEQUENCE returns NFS4_OK,\
    \ then the associated lease MUST be\n   renewed (see Section 8.3), except if\n\
    \   SEQ4_STATUS_EXPIRED_ALL_STATE_REVOKED is returned in sr_status_flags.\n"
- title: 18.46.4.  IMPLEMENTATION
  contents:
  - "18.46.4.  IMPLEMENTATION\n   The server MUST maintain a mapping of session ID\
    \ to client ID in\n   order to validate any operations that follow SEQUENCE that\
    \ take a\n   stateid as an argument and/or result.\n   If the client establishes\
    \ a persistent session, then a SEQUENCE\n   received after a server restart might\
    \ encounter requests performed\n   and recorded in a persistent reply cache before\
    \ the server restart.\n   In this case, SEQUENCE will be processed successfully,\
    \ while requests\n   that were not previously performed and recorded are rejected\
    \ with\n   NFS4ERR_DEADSESSION.\n   Depending on which of the operations within\
    \ the COMPOUND were\n   successfully performed before the server restart, these\
    \ operations\n   will also have replies sent from the server reply cache.  Note\
    \ that\n   when these operations establish locking state, it is locking state\n\
    \   that applies to the previous server instance and to the previous\n   client\
    \ ID, even though the server restart, which logically happened\n   after these\
    \ operations, eliminated that state.  In the case of a\n   partially executed\
    \ COMPOUND, processing may reach an operation not\n   processed during the earlier\
    \ server instance, making this operation a\n   new one and not performable on\
    \ the existing session.  In this case,\n   NFS4ERR_DEADSESSION will be returned\
    \ from that operation.\n"
- title: '18.47.  Operation 54: SET_SSV - Update SSV for a Client ID'
  contents:
  - '18.47.  Operation 54: SET_SSV - Update SSV for a Client ID

    '
- title: 18.47.1.  ARGUMENT
  contents:
  - "18.47.1.  ARGUMENT\n   struct ssa_digest_input4 {\n           SEQUENCE4args sdi_seqargs;\n\
    \   };\n   struct SET_SSV4args {\n           opaque          ssa_ssv<>;\n    \
    \       opaque          ssa_digest<>;\n   };\n"
- title: 18.47.2.  RESULT
  contents:
  - "18.47.2.  RESULT\n   struct ssr_digest_input4 {\n           SEQUENCE4res sdi_seqres;\n\
    \   };\n   struct SET_SSV4resok {\n           opaque          ssr_digest<>;\n\
    \   };\n   union SET_SSV4res switch (nfsstat4 ssr_status) {\n   case NFS4_OK:\n\
    \           SET_SSV4resok   ssr_resok4;\n   default:\n           void;\n   };\n"
- title: 18.47.3.  DESCRIPTION
  contents:
  - "18.47.3.  DESCRIPTION\n   This operation is used to update the SSV for a client\
    \ ID.  Before\n   SET_SSV is called the first time on a client ID, the SSV is\
    \ zero.\n   The SSV is the key used for the SSV GSS mechanism (Section 2.10.9)\n\
    \   SET_SSV MUST be preceded by a SEQUENCE operation in the same\n   COMPOUND.\
    \  It MUST NOT be used if the client did not opt for SP4_SSV\n   state protection\
    \ when the client ID was created (see Section 18.35);\n   the server returns NFS4ERR_INVAL\
    \ in that case.\n   The field ssa_digest is computed as the output of the HMAC\
    \ (RFC 2104\n   [52]) using the subkey derived from the SSV4_SUBKEY_MIC_I2T and\n\
    \   current SSV as the key (see Section 2.10.9 for a description of\n   subkeys),\
    \ and an XDR encoded value of data type ssa_digest_input4.\n   The field sdi_seqargs\
    \ is equal to the arguments of the SEQUENCE\n   operation for the COMPOUND procedure\
    \ that SET_SSV is within.\n   The argument ssa_ssv is XORed with the current SSV\
    \ to produce the new\n   SSV.  The argument ssa_ssv SHOULD be generated randomly.\n\
    \   In the response, ssr_digest is the output of the HMAC using the\n   subkey\
    \ derived from SSV4_SUBKEY_MIC_T2I and new SSV as the key, and\n   an XDR encoded\
    \ value of data type ssr_digest_input4.  The field\n   sdi_seqres is equal to\
    \ the results of the SEQUENCE operation for the\n   COMPOUND procedure that SET_SSV\
    \ is within.\n   As noted in Section 18.35, the client and server can maintain\n\
    \   multiple concurrent versions of the SSV.  The client and server each\n   MUST\
    \ maintain an internal SSV version number, which is set to one the\n   first time\
    \ SET_SSV executes on the server and the client receives the\n   first SET_SSV\
    \ reply.  Each subsequent SET_SSV increases the internal\n   SSV version number\
    \ by one.  The value of this version number\n   corresponds to the smpt_ssv_seq,\
    \ smt_ssv_seq, sspt_ssv_seq, and\n   ssct_ssv_seq fields of the SSV GSS mechanism\
    \ tokens (see\n   Section 2.10.9).\n"
- title: 18.47.4.  IMPLEMENTATION
  contents:
  - "18.47.4.  IMPLEMENTATION\n   When the server receives ssa_digest, it MUST verify\
    \ the digest by\n   computing the digest the same way the client did and comparing\
    \ it\n   with ssa_digest.  If the server gets a different result, this is an\n\
    \   error, NFS4ERR_BAD_SESSION_DIGEST.  This error might be the result of\n  \
    \ another SET_SSV from the same client ID changing the SSV.  If so, the\n   client\
    \ recovers by sending a SET_SSV operation again with a\n   recomputed digest based\
    \ on the subkey of the new SSV.  If the\n   transport connection is dropped after\
    \ the SET_SSV request is sent,\n   but before the SET_SSV reply is received, then\
    \ there are special\n   considerations for recovery if the client has no more\
    \ connections\n   associated with sessions associated with the client ID of the\
    \ SSV.\n   See Section 18.34.4.\n   Clients SHOULD NOT send an ssa_ssv that is\
    \ equal to a previous\n   ssa_ssv, nor equal to a previous or current SSV (including\
    \ an ssa_ssv\n   equal to zero since the SSV is initialized to zero when the client\
    \ ID\n   is created).\n   Clients SHOULD send SET_SSV with RPCSEC_GSS privacy.\
    \  Servers MUST\n   support RPCSEC_GSS with privacy for any COMPOUND that has\
    \ { SEQUENCE,\n   SET_SSV }.\n   A client SHOULD NOT send SET_SSV with the SSV\
    \ GSS mechanism's\n   credential because the purpose of SET_SSV is to seed the\
    \ SSV from\n   non-SSV credentials.  Instead, SET_SSV SHOULD be sent with the\n\
    \   credential of a user that is accessing the client ID for the first\n   time\
    \ (Section 2.10.8.3).  However, if the client does send SET_SSV\n   with SSV credentials,\
    \ the digest protecting the arguments uses the\n   value of the SSV before ssa_ssv\
    \ is XORed in, and the digest\n   protecting the results uses the value of the\
    \ SSV after the ssa_ssv is\n   XORed in.\n"
- title: '18.48.  Operation 55: TEST_STATEID - Test Stateids for Validity'
  contents:
  - '18.48.  Operation 55: TEST_STATEID - Test Stateids for Validity

    '
- title: 18.48.1.  ARGUMENT
  contents:
  - "18.48.1.  ARGUMENT\n   struct TEST_STATEID4args {\n           stateid4      \
    \  ts_stateids<>;\n   };\n"
- title: 18.48.2.  RESULT
  contents:
  - "18.48.2.  RESULT\n   struct TEST_STATEID4resok {\n           nfsstat4       \
    \ tsr_status_codes<>;\n   };\n   union TEST_STATEID4res switch (nfsstat4 tsr_status)\
    \ {\n       case NFS4_OK:\n           TEST_STATEID4resok tsr_resok4;\n       default:\n\
    \           void;\n   };\n"
- title: 18.48.3.  DESCRIPTION
  contents:
  - "18.48.3.  DESCRIPTION\n   The TEST_STATEID operation is used to check the validity\
    \ of a set of\n   stateids.  It can be used at any time, but the client should\n\
    \   definitely use it when it receives an indication that one or more of\n   its\
    \ stateids have been invalidated due to lock revocation.  This\n   occurs when\
    \ the SEQUENCE operation returns with one of the following\n   sr_status_flags\
    \ set:\n   *  SEQ4_STATUS_EXPIRED_SOME_STATE_REVOKED\n   *  SEQ4_STATUS_EXPIRED_ADMIN_STATE_REVOKED\n\
    \   *  SEQ4_STATUS_EXPIRED_RECALLABLE_STATE_REVOKED\n   The client can use TEST_STATEID\
    \ one or more times to test the\n   validity of its stateids.  Each use of TEST_STATEID\
    \ allows a large\n   set of such stateids to be tested and avoids problems with\
    \ earlier\n   stateids in a COMPOUND request from interfering with the checking\
    \ of\n   subsequent stateids, as would happen if individual stateids were\n  \
    \ tested by a series of corresponding by operations in a COMPOUND\n   request.\n\
    \   For each stateid, the server returns the status code that would be\n   returned\
    \ if that stateid were to be used in normal operation.\n   Returning such a status\
    \ indication is not an error and does not cause\n   COMPOUND processing to terminate.\
    \  Checks for the validity of the\n   stateid proceed as they would for normal\
    \ operations with a number of\n   exceptions:\n   *  There is no check for the\
    \ type of stateid object, as would be the\n      case for normal use of a stateid.\n\
    \   *  There is no reference to the current filehandle.\n   *  Special stateids\
    \ are always considered invalid (they result in the\n      error code NFS4ERR_BAD_STATEID).\n\
    \   All stateids are interpreted as being associated with the client for\n   the\
    \ current session.  Any possible association with a previous\n   instance of the\
    \ client (as stale stateids) is not considered.\n   The valid status values in\
    \ the returned status_code array are\n   NFS4ERR_OK, NFS4ERR_BAD_STATEID, NFS4ERR_OLD_STATEID,\n\
    \   NFS4ERR_EXPIRED, NFS4ERR_ADMIN_REVOKED, and NFS4ERR_DELEG_REVOKED.\n"
- title: 18.48.4.  IMPLEMENTATION
  contents:
  - "18.48.4.  IMPLEMENTATION\n   See Sections 8.2.2 and 8.2.4 for a discussion of\
    \ stateid structure,\n   lifetime, and validation.\n"
- title: '18.49.  Operation 56: WANT_DELEGATION - Request Delegation'
  contents:
  - '18.49.  Operation 56: WANT_DELEGATION - Request Delegation

    '
- title: 18.49.1.  ARGUMENT
  contents:
  - "18.49.1.  ARGUMENT\n   union deleg_claim4 switch (open_claim_type4 dc_claim)\
    \ {\n   /*\n    * No special rights to object.  Ordinary delegation\n    * request\
    \ of the specified object.  Object identified\n    * by filehandle.\n    */\n\
    \   case CLAIM_FH: /* new to v4.1 */\n           /* CURRENT_FH: object being delegated\
    \ */\n           void;\n   /*\n    * Right to file based on a delegation granted\n\
    \    * to a previous boot instance of the client.\n    * File is specified by\
    \ filehandle.\n    */\n   case CLAIM_DELEG_PREV_FH: /* new to v4.1 */\n      \
    \     /* CURRENT_FH: object being delegated */\n           void;\n   /*\n    *\
    \ Right to the file established by an open previous\n    * to server reboot. \
    \ File identified by filehandle.\n    * Used during server reclaim grace period.\n\
    \    */\n   case CLAIM_PREVIOUS:\n           /* CURRENT_FH: object being reclaimed\
    \ */\n           open_delegation_type4   dc_delegate_type;\n   };\n   struct WANT_DELEGATION4args\
    \ {\n           uint32_t        wda_want;\n           deleg_claim4    wda_claim;\n\
    \   };\n"
- title: 18.49.2.  RESULT
  contents:
  - "18.49.2.  RESULT\n   union WANT_DELEGATION4res switch (nfsstat4 wdr_status) {\n\
    \   case NFS4_OK:\n           open_delegation4 wdr_resok4;\n   default:\n    \
    \       void;\n   };\n"
- title: 18.49.3.  DESCRIPTION
  contents:
  - "18.49.3.  DESCRIPTION\n   Where this description mandates the return of a specific\
    \ error code\n   for a specific condition, and where multiple conditions apply,\
    \ the\n   server MAY return any of the mandated error codes.\n   This operation\
    \ allows a client to:\n   *  Get a delegation on all types of files except directories.\n\
    \   *  Register a \"want\" for a delegation for the specified file object,\n \
    \     and be notified via a callback when the delegation is available.\n     \
    \ The server MAY support notifications of availability via\n      callbacks. \
    \ If the server does not support registration of wants,\n      it MUST NOT return\
    \ an error to indicate that, and instead MUST\n      return with ond_why set to\
    \ WND4_CONTENTION or WND4_RESOURCE and\n      ond_server_will_push_deleg or ond_server_will_signal_avail\
    \ set to\n      FALSE.  When the server indicates that it will notify the client\n\
    \      by means of a callback, it will either provide the delegation\n      using\
    \ a CB_PUSH_DELEG operation or cancel its promise by sending a\n      CB_WANTS_CANCELLED\
    \ operation.\n   *  Cancel a want for a delegation.\n   The client SHOULD NOT\
    \ set OPEN4_SHARE_ACCESS_READ and SHOULD NOT set\n   OPEN4_SHARE_ACCESS_WRITE\
    \ in wda_want.  If it does, the server MUST\n   ignore them.\n   The meanings\
    \ of the following flags in wda_want are the same as they\n   are in OPEN, except\
    \ as noted below.\n   *  OPEN4_SHARE_ACCESS_WANT_READ_DELEG\n   *  OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG\n\
    \   *  OPEN4_SHARE_ACCESS_WANT_ANY_DELEG\n   *  OPEN4_SHARE_ACCESS_WANT_NO_DELEG.\
    \  Unlike the OPEN operation, this\n      flag SHOULD NOT be set by the client\
    \ in the arguments to\n      WANT_DELEGATION, and MUST be ignored by the server.\n\
    \   *  OPEN4_SHARE_ACCESS_WANT_CANCEL\n   *  OPEN4_SHARE_ACCESS_WANT_SIGNAL_DELEG_WHEN_RESRC_AVAIL\n\
    \   *  OPEN4_SHARE_ACCESS_WANT_PUSH_DELEG_WHEN_UNCONTENDED\n   The handling of\
    \ the above flags in WANT_DELEGATION is the same as in\n   OPEN.  Information\
    \ about the delegation and/or the promises the\n   server is making regarding\
    \ future callbacks are the same as those\n   described in the open_delegation4\
    \ structure.\n   The successful results of WANT_DELEGATION are of data type\n\
    \   open_delegation4, which is the same data type as the \"delegation\"\n   field\
    \ in the results of the OPEN operation (see Section 18.16.3).\n   The server constructs\
    \ wdr_resok4 the same way it constructs OPEN's\n   \"delegation\" with one difference:\
    \ WANT_DELEGATION MUST NOT return a\n   delegation type of OPEN_DELEGATE_NONE.\n\
    \   If ((wda_want & OPEN4_SHARE_ACCESS_WANT_DELEG_MASK) &\n   ~OPEN4_SHARE_ACCESS_WANT_NO_DELEG)\
    \ is zero, then the client is\n   indicating no explicit desire or non-desire\
    \ for a delegation and the\n   server MUST return NFS4ERR_INVAL.\n   The client\
    \ uses the OPEN4_SHARE_ACCESS_WANT_CANCEL flag in the\n   WANT_DELEGATION operation\
    \ to cancel a previously requested want for a\n   delegation.  Note that if the\
    \ server is in the process of sending the\n   delegation (via CB_PUSH_DELEG) at\
    \ the time the client sends a\n   cancellation of the want, the delegation might\
    \ still be pushed to the\n   client.\n   If WANT_DELEGATION fails to return a\
    \ delegation, and the server\n   returns NFS4_OK, the server MUST set the delegation\
    \ type to\n   OPEN4_DELEGATE_NONE_EXT, and set od_whynone, as described in\n \
    \  Section 18.16.  Write delegations are not available for file types\n   that\
    \ are not writable.  This includes file objects of types NF4BLK,\n   NF4CHR, NF4LNK,\
    \ NF4SOCK, and NF4FIFO.  If the client requests\n   OPEN4_SHARE_ACCESS_WANT_WRITE_DELEG\
    \ without\n   OPEN4_SHARE_ACCESS_WANT_READ_DELEG on an object with one of the\n\
    \   aforementioned file types, the server must set\n   wdr_resok4.od_whynone.ond_why\
    \ to WND4_WRITE_DELEG_NOT_SUPP_FTYPE.\n"
- title: 18.49.4.  IMPLEMENTATION
  contents:
  - "18.49.4.  IMPLEMENTATION\n   A request for a conflicting delegation is not normally\
    \ intended to\n   trigger the recall of the existing delegation.  Servers may\
    \ choose to\n   treat some clients as having higher priority such that their wants\n\
    \   will trigger recall of an existing delegation, although that is\n   expected\
    \ to be an unusual situation.\n   Servers will generally recall delegations assigned\
    \ by WANT_DELEGATION\n   on the same basis as those assigned by OPEN.  CB_RECALL\
    \ will\n   generally be done only when other clients perform operations\n   inconsistent\
    \ with the delegation.  The normal response to aging of\n   delegations is to\
    \ use CB_RECALL_ANY, in order to give the client the\n   opportunity to keep the\
    \ delegations most useful from its point of\n   view.\n"
- title: '18.50.  Operation 57: DESTROY_CLIENTID - Destroy a Client ID'
  contents:
  - '18.50.  Operation 57: DESTROY_CLIENTID - Destroy a Client ID

    '
- title: 18.50.1.  ARGUMENT
  contents:
  - "18.50.1.  ARGUMENT\n   struct DESTROY_CLIENTID4args {\n           clientid4 \
    \      dca_clientid;\n   };\n"
- title: 18.50.2.  RESULT
  contents:
  - "18.50.2.  RESULT\n   struct DESTROY_CLIENTID4res {\n           nfsstat4     \
    \   dcr_status;\n   };\n"
- title: 18.50.3.  DESCRIPTION
  contents:
  - "18.50.3.  DESCRIPTION\n   The DESTROY_CLIENTID operation destroys the client\
    \ ID.  If there are\n   sessions (both idle and non-idle), opens, locks, delegations,\n\
    \   layouts, and/or wants (Section 18.49) associated with the unexpired\n   lease\
    \ of the client ID, the server MUST return NFS4ERR_CLIENTID_BUSY.\n   DESTROY_CLIENTID\
    \ MAY be preceded with a SEQUENCE operation as long as\n   the client ID derived\
    \ from the session ID of SEQUENCE is not the same\n   as the client ID to be destroyed.\
    \  If the client IDs are the same,\n   then the server MUST return NFS4ERR_CLIENTID_BUSY.\n\
    \   If DESTROY_CLIENTID is not prefixed by SEQUENCE, it MUST be the only\n   operation\
    \ in the COMPOUND request (otherwise, the server MUST return\n   NFS4ERR_NOT_ONLY_OP).\
    \  If the operation is sent without a SEQUENCE\n   preceding it, a client that\
    \ retransmits the request may receive an\n   error in response, because the original\
    \ request might have been\n   successfully executed.\n"
- title: 18.50.4.  IMPLEMENTATION
  contents:
  - "18.50.4.  IMPLEMENTATION\n   DESTROY_CLIENTID allows a server to immediately\
    \ reclaim the resources\n   consumed by an unused client ID, and also to forget\
    \ that it ever\n   generated the client ID.  By forgetting that it ever generated\
    \ the\n   client ID, the server can safely reuse the client ID on a future\n \
    \  EXCHANGE_ID operation.\n"
- title: '18.51.  Operation 58: RECLAIM_COMPLETE - Indicates Reclaims Finished'
  contents:
  - '18.51.  Operation 58: RECLAIM_COMPLETE - Indicates Reclaims Finished

    '
- title: 18.51.1.  ARGUMENT
  contents:
  - "18.51.1.  ARGUMENT\n   struct RECLAIM_COMPLETE4args {\n           /*\n      \
    \      * If rca_one_fs TRUE,\n            *\n            *    CURRENT_FH: object\
    \ in\n            *    file system reclaim is\n            *    complete for.\n\
    \            */\n           bool            rca_one_fs;\n   };\n"
- title: 18.51.2.  RESULTS
  contents:
  - "18.51.2.  RESULTS\n   struct RECLAIM_COMPLETE4res {\n           nfsstat4    \
    \    rcr_status;\n   };\n"
- title: 18.51.3.  DESCRIPTION
  contents:
  - "18.51.3.  DESCRIPTION\n   A RECLAIM_COMPLETE operation is used to indicate that\
    \ the client has\n   reclaimed all of the locking state that it will recover using\n\
    \   reclaim, when it is recovering state due to either a server restart\n   or\
    \ the migration of a file system to another server.  There are two\n   types of\
    \ RECLAIM_COMPLETE operations:\n   *  When rca_one_fs is FALSE, a global RECLAIM_COMPLETE\
    \ is being done.\n      This indicates that recovery of all locks that the client\
    \ held on\n      the previous server instance has been completed.  The current\n\
    \      filehandle need not be set in this case.\n   *  When rca_one_fs is TRUE,\
    \ a file system-specific RECLAIM_COMPLETE\n      is being done.  This indicates\
    \ that recovery of locks for a single\n      fs (the one designated by the current\
    \ filehandle) due to the\n      migration of the file system has been completed.\
    \  Presence of a\n      current filehandle is required when rca_one_fs is set\
    \ to TRUE.\n      When the current filehandle designates a filehandle in a file\n\
    \      system not in the process of migration, the operation returns\n      NFS4_OK\
    \ and is otherwise ignored.\n   Once a RECLAIM_COMPLETE is done, there can be\
    \ no further reclaim\n   operations for locks whose scope is defined as having\
    \ completed\n   recovery.  Once the client sends RECLAIM_COMPLETE, the server\
    \ will\n   not allow the client to do subsequent reclaims of locking state for\n\
    \   that scope and, if these are attempted, will return NFS4ERR_NO_GRACE.\n  \
    \ Whenever a client establishes a new client ID and before it does the\n   first\
    \ non-reclaim operation that obtains a lock, it MUST send a\n   RECLAIM_COMPLETE\
    \ with rca_one_fs set to FALSE, even if there are no\n   locks to reclaim.  If\
    \ non-reclaim locking operations are done before\n   the RECLAIM_COMPLETE, an\
    \ NFS4ERR_GRACE error will be returned.\n   Similarly, when the client accesses\
    \ a migrated file system on a new\n   server, before it sends the first non-reclaim\
    \ operation that obtains\n   a lock on this new server, it MUST send a RECLAIM_COMPLETE\
    \ with\n   rca_one_fs set to TRUE and current filehandle within that file\n  \
    \ system, even if there are no locks to reclaim.  If non-reclaim\n   locking operations\
    \ are done on that file system before the\n   RECLAIM_COMPLETE, an NFS4ERR_GRACE\
    \ error will be returned.\n   It should be noted that there are situations in\
    \ which a client needs\n   to issue both forms of RECLAIM_COMPLETE.  An example\
    \ is an instance\n   of file system migration in which the file system is migrated\
    \ to a\n   server for which the client has no clientid.  As a result, the client\n\
    \   needs to obtain a clientid from the server (incurring the\n   responsibility\
    \ to do RECLAIM_COMPLETE with rca_one_fs set to FALSE)\n   as well as RECLAIM_COMPLETE\
    \ with rca_one_fs set to TRUE to complete\n   the per-fs grace period associated\
    \ with the file system migration.\n   These two may be done in any order as long\
    \ as all necessary lock\n   reclaims have been done before issuing either of them.\n\
    \   Any locks not reclaimed at the point at which RECLAIM_COMPLETE is\n   done\
    \ become non-reclaimable.  The client MUST NOT attempt to reclaim\n   them, either\
    \ during the current server instance or in any subsequent\n   server instance,\
    \ or on another server to which responsibility for\n   that file system is transferred.\
    \  If the client were to do so, it\n   would be violating the protocol by representing\
    \ itself as owning\n   locks that it does not own, and so has no right to reclaim.\
    \  See\n   Section 8.4.3 of [66] for a discussion of edge conditions related to\n\
    \   lock reclaim.\n   By sending a RECLAIM_COMPLETE, the client indicates readiness\
    \ to\n   proceed to do normal non-reclaim locking operations.  The client\n  \
    \ should be aware that such operations may temporarily result in\n   NFS4ERR_GRACE\
    \ errors until the server is ready to terminate its grace\n   period.\n"
- title: 18.51.4.  IMPLEMENTATION
  contents:
  - "18.51.4.  IMPLEMENTATION\n   Servers will typically use the information as to\
    \ when reclaim\n   activity is complete to reduce the length of the grace period.\
    \  When\n   the server maintains in persistent storage a list of clients that\n\
    \   might have had locks, it is able to use the fact that all such\n   clients\
    \ have done a RECLAIM_COMPLETE to terminate the grace period\n   and begin normal\
    \ operations (i.e., grant requests for new locks)\n   sooner than it might otherwise.\n\
    \   Latency can be minimized by doing a RECLAIM_COMPLETE as part of the\n   COMPOUND\
    \ request in which the last lock-reclaiming operation is done.\n   When there\
    \ are no reclaims to be done, RECLAIM_COMPLETE should be\n   done immediately\
    \ in order to allow the grace period to end as soon as\n   possible.\n   RECLAIM_COMPLETE\
    \ should only be done once for each server instance or\n   occasion of the transition\
    \ of a file system.  If it is done a second\n   time, the error NFS4ERR_COMPLETE_ALREADY\
    \ will result.  Note that\n   because of the session feature's retry protection,\
    \ retries of\n   COMPOUND requests containing RECLAIM_COMPLETE operation will\
    \ not\n   result in this error.\n   When a RECLAIM_COMPLETE is sent, the client\
    \ effectively acknowledges\n   any locks not yet reclaimed as lost.  This allows\
    \ the server to re-\n   enable the client to recover locks if the occurrence of\
    \ edge\n   conditions, as described in Section 8.4.3, had caused the server to\n\
    \   disable the client's ability to recover locks.\n   Because previous descriptions\
    \ of RECLAIM_COMPLETE were not\n   sufficiently explicit about the circumstances\
    \ in which use of\n   RECLAIM_COMPLETE with rca_one_fs set to TRUE was appropriate,\
    \ there\n   have been cases in which it has been misused by clients who have\n\
    \   issued RECLAIM_COMPLETE with rca_one_fs set to TRUE when it should\n   have\
    \ not been.  There have also been cases in which servers have, in\n   various\
    \ ways, not responded to such misuse as described above, either\n   ignoring the\
    \ rca_one_fs setting (treating the operation as a global\n   RECLAIM_COMPLETE)\
    \ or ignoring the entire operation.\n   While clients SHOULD NOT misuse this feature,\
    \ and servers SHOULD\n   respond to such misuse as described above, implementors\
    \ need to be\n   aware of the following considerations as they make necessary\
    \ trade-\n   offs between interoperability with existing implementations and\n\
    \   proper support for facilities to allow lock recovery in the event of\n   file\
    \ system migration.\n   *  When servers have no support for becoming the destination\
    \ server\n      of a file system subject to migration, there is no possibility\
    \ of\n      a per-fs RECLAIM_COMPLETE being done legitimately, and occurrences\n\
    \      of it SHOULD be ignored.  However, the negative consequences of\n     \
    \ accepting such mistaken use are quite limited as long as the\n      client does\
    \ not issue it before all necessary reclaims are done.\n   *  When a server might\
    \ become the destination for a file system being\n      migrated, inappropriate\
    \ use of per-fs RECLAIM_COMPLETE is more\n      concerning.  In the case in which\
    \ the file system designated is\n      not within a per-fs grace period, the per-fs\
    \ RECLAIM_COMPLETE\n      SHOULD be ignored, with the negative consequences of\
    \ accepting it\n      being limited, as in the case in which migration is not\
    \ supported.\n      However, if the server encounters a file system undergoing\n\
    \      migration, the operation cannot be accepted as if it were a global\n  \
    \    RECLAIM_COMPLETE without invalidating its intended use.\n"
- title: '18.52.  Operation 10044: ILLEGAL - Illegal Operation'
  contents:
  - '18.52.  Operation 10044: ILLEGAL - Illegal Operation

    '
- title: 18.52.1.  ARGUMENTS
  contents:
  - "18.52.1.  ARGUMENTS\n   void;\n"
- title: 18.52.2.  RESULTS
  contents:
  - "18.52.2.  RESULTS\n   struct ILLEGAL4res {\n           nfsstat4        status;\n\
    \   };\n"
- title: 18.52.3.  DESCRIPTION
  contents:
  - "18.52.3.  DESCRIPTION\n   This operation is a placeholder for encoding a result\
    \ to handle the\n   case of the client sending an operation code within COMPOUND\
    \ that is\n   not supported.  See the COMPOUND procedure description for more\n\
    \   details.\n   The status field of ILLEGAL4res MUST be set to NFS4ERR_OP_ILLEGAL.\n"
- title: 18.52.4.  IMPLEMENTATION
  contents:
  - "18.52.4.  IMPLEMENTATION\n   A client will probably not send an operation with\
    \ code OP_ILLEGAL but\n   if it does, the response will be ILLEGAL4res just as\
    \ it would be with\n   any other invalid operation code.  Note that if the server\
    \ gets an\n   illegal operation code that is not OP_ILLEGAL, and if the server\n\
    \   checks for legal operation codes during the XDR decode phase, then\n   the\
    \ ILLEGAL4res would not be returned.\n"
- title: 19.  NFSv4.1 Callback Procedures
  contents:
  - "19.  NFSv4.1 Callback Procedures\n   The procedures used for callbacks are defined\
    \ in the following\n   sections.  In the interest of clarity, the terms \"client\"\
    \ and\n   \"server\" refer to NFS clients and servers, despite the fact that for\n\
    \   an individual callback RPC, the sense of these terms would be\n   precisely\
    \ the opposite.\n   Both procedures, CB_NULL and CB_COMPOUND, MUST be implemented.\n"
- title: '19.1.  Procedure 0: CB_NULL - No Operation'
  contents:
  - '19.1.  Procedure 0: CB_NULL - No Operation

    '
- title: 19.1.1.  ARGUMENTS
  contents:
  - "19.1.1.  ARGUMENTS\n   void;\n"
- title: 19.1.2.  RESULTS
  contents:
  - "19.1.2.  RESULTS\n   void;\n"
- title: 19.1.3.  DESCRIPTION
  contents:
  - "19.1.3.  DESCRIPTION\n   CB_NULL is the standard ONC RPC NULL procedure, with\
    \ the standard\n   void argument and void response.  Even though there is no direct\n\
    \   functionality associated with this procedure, the server will use\n   CB_NULL\
    \ to confirm the existence of a path for RPCs from the server\n   to client.\n"
- title: 19.1.4.  ERRORS
  contents:
  - "19.1.4.  ERRORS\n   None.\n"
- title: '19.2.  Procedure 1: CB_COMPOUND - Compound Operations'
  contents:
  - '19.2.  Procedure 1: CB_COMPOUND - Compound Operations

    '
- title: 19.2.1.  ARGUMENTS
  contents:
  - "19.2.1.  ARGUMENTS\n   enum nfs_cb_opnum4 {\n           OP_CB_GETATTR       \
    \    = 3,\n           OP_CB_RECALL            = 4,\n   /* Callback operations\
    \ new to NFSv4.1 */\n           OP_CB_LAYOUTRECALL      = 5,\n           OP_CB_NOTIFY\
    \            = 6,\n           OP_CB_PUSH_DELEG        = 7,\n           OP_CB_RECALL_ANY\
    \        = 8,\n           OP_CB_RECALLABLE_OBJ_AVAIL = 9,\n           OP_CB_RECALL_SLOT\
    \       = 10,\n           OP_CB_SEQUENCE          = 11,\n           OP_CB_WANTS_CANCELLED\
    \   = 12,\n           OP_CB_NOTIFY_LOCK       = 13,\n           OP_CB_NOTIFY_DEVICEID\
    \   = 14,\n           OP_CB_ILLEGAL           = 10044\n   };\n   union nfs_cb_argop4\
    \ switch (unsigned argop) {\n    case OP_CB_GETATTR:\n         CB_GETATTR4args\
    \           opcbgetattr;\n    case OP_CB_RECALL:\n         CB_RECALL4args    \
    \        opcbrecall;\n    case OP_CB_LAYOUTRECALL:\n         CB_LAYOUTRECALL4args\
    \      opcblayoutrecall;\n    case OP_CB_NOTIFY:\n         CB_NOTIFY4args    \
    \        opcbnotify;\n    case OP_CB_PUSH_DELEG:\n         CB_PUSH_DELEG4args\
    \        opcbpush_deleg;\n    case OP_CB_RECALL_ANY:\n         CB_RECALL_ANY4args\
    \        opcbrecall_any;\n    case OP_CB_RECALLABLE_OBJ_AVAIL:\n         CB_RECALLABLE_OBJ_AVAIL4args\
    \ opcbrecallable_obj_avail;\n    case OP_CB_RECALL_SLOT:\n         CB_RECALL_SLOT4args\
    \       opcbrecall_slot;\n    case OP_CB_SEQUENCE:\n         CB_SEQUENCE4args\
    \          opcbsequence;\n    case OP_CB_WANTS_CANCELLED:\n         CB_WANTS_CANCELLED4args\
    \   opcbwants_cancelled;\n    case OP_CB_NOTIFY_LOCK:\n         CB_NOTIFY_LOCK4args\
    \       opcbnotify_lock;\n    case OP_CB_NOTIFY_DEVICEID:\n         CB_NOTIFY_DEVICEID4args\
    \   opcbnotify_deviceid;\n    case OP_CB_ILLEGAL:            void;\n   };\n  \
    \ struct CB_COMPOUND4args {\n           utf8str_cs      tag;\n           uint32_t\
    \        minorversion;\n           uint32_t        callback_ident;\n         \
    \  nfs_cb_argop4   argarray<>;\n   };\n"
- title: 19.2.2.  RESULTS
  contents:
  - "19.2.2.  RESULTS\n   union nfs_cb_resop4 switch (unsigned resop) {\n    case\
    \ OP_CB_GETATTR:    CB_GETATTR4res  opcbgetattr;\n    case OP_CB_RECALL:     CB_RECALL4res\
    \   opcbrecall;\n    /* new NFSv4.1 operations */\n    case OP_CB_LAYOUTRECALL:\n\
    \                           CB_LAYOUTRECALL4res\n    case OP_CB_NOTIFY:     CB_NOTIFY4res\
    \   opcbnotify;\n    case OP_CB_PUSH_DELEG: CB_PUSH_DELEG4res\n    case OP_CB_RECALL_ANY:\
    \ CB_RECALL_ANY4res\n    case OP_CB_RECALLABLE_OBJ_AVAIL:\n                  \
    \         CB_RECALLABLE_OBJ_AVAIL4res\n    case OP_CB_RECALL_SLOT:\n         \
    \                  CB_RECALL_SLOT4res\n    case OP_CB_SEQUENCE:   CB_SEQUENCE4res\
    \ opcbsequence;\n    case OP_CB_WANTS_CANCELLED:\n                           CB_WANTS_CANCELLED4res\n\
    \    case OP_CB_NOTIFY_LOCK:\n                           CB_NOTIFY_LOCK4res\n\
    \    case OP_CB_NOTIFY_DEVICEID:\n                           CB_NOTIFY_DEVICEID4res\n\
    \    /* Not new operation */\n    case OP_CB_ILLEGAL:    CB_ILLEGAL4res  opcbillegal;\n\
    \   };\n   struct CB_COMPOUND4res {\n           nfsstat4 status;\n           utf8str_cs\
    \      tag;\n           nfs_cb_resop4   resarray<>;\n   };\n"
- title: 19.2.3.  DESCRIPTION
  contents:
  - "19.2.3.  DESCRIPTION\n   The CB_COMPOUND procedure is used to combine one or\
    \ more of the\n   callback procedures into a single RPC request.  The main callback\
    \ RPC\n   program has two main procedures: CB_NULL and CB_COMPOUND.  All other\n\
    \   operations use the CB_COMPOUND procedure as a wrapper.\n   During the processing\
    \ of the CB_COMPOUND procedure, the client may\n   find that it does not have\
    \ the available resources to execute any or\n   all of the operations within the\
    \ CB_COMPOUND sequence.  Refer to\n   Section 2.10.6.4 for details.\n   The minorversion\
    \ field of the arguments MUST be the same as the\n   minorversion of the COMPOUND\
    \ procedure used to create the client ID\n   and session.  For NFSv4.1, minorversion\
    \ MUST be set to 1.\n   Contained within the CB_COMPOUND results is a \"status\"\
    \ field.  This\n   status MUST be equal to the status of the last operation that\
    \ was\n   executed within the CB_COMPOUND procedure.  Therefore, if an\n   operation\
    \ incurred an error, then the \"status\" value will be the same\n   error value\
    \ as is being returned for the operation that failed.\n   The \"tag\" field is\
    \ handled the same way as that of the COMPOUND\n   procedure (see Section 16.2.3).\n\
    \   Illegal operation codes are handled in the same way as they are\n   handled\
    \ for the COMPOUND procedure.\n"
- title: 19.2.4.  IMPLEMENTATION
  contents:
  - "19.2.4.  IMPLEMENTATION\n   The CB_COMPOUND procedure is used to combine individual\
    \ operations\n   into a single RPC request.  The client interprets each of the\n\
    \   operations in turn.  If an operation is executed by the client and\n   the\
    \ status of that operation is NFS4_OK, then the next operation in\n   the CB_COMPOUND\
    \ procedure is executed.  The client continues this\n   process until there are\
    \ no more operations to be executed or one of\n   the operations has a status\
    \ value other than NFS4_OK.\n"
- title: 19.2.5.  ERRORS
  contents:
  - "19.2.5.  ERRORS\n   CB_COMPOUND will of course return every error that each operation\
    \ on\n   the backchannel can return (see Table 13).  However, if CB_COMPOUND\n\
    \   returns zero operations, obviously the error returned by COMPOUND has\n  \
    \ nothing to do with an error returned by an operation.  The list of\n   errors\
    \ CB_COMPOUND will return if it processes zero operations\n   includes:\n    |\
    \ Error                        | Notes                            |\n    | NFS4ERR_BADCHAR\
    \              | The tag argument has a character |\n    | NFS4ERR_BADXDR    \
    \           |                                  |\n    | NFS4ERR_DELAY        \
    \        |                                  |\n    | NFS4ERR_INVAL           \
    \     | The tag argument is not in UTF-8 |\n    | NFS4ERR_MINOR_VERS_MISMATCH\
    \  |                                  |\n    | NFS4ERR_SERVERFAULT          |\
    \                                  |\n    | NFS4ERR_TOO_MANY_OPS         |   \
    \                               |\n    | NFS4ERR_REP_TOO_BIG          |      \
    \                            |\n    | NFS4ERR_REP_TOO_BIG_TO_CACHE |         \
    \                         |\n    | NFS4ERR_REQ_TOO_BIG          |            \
    \                      |\n                    Table 24: CB_COMPOUND Error Returns\n"
- title: 20.  NFSv4.1 Callback Operations
  contents:
  - '20.  NFSv4.1 Callback Operations

    '
- title: '20.1.  Operation 3: CB_GETATTR - Get Attributes'
  contents:
  - '20.1.  Operation 3: CB_GETATTR - Get Attributes

    '
- title: 20.1.1.  ARGUMENT
  contents:
  - "20.1.1.  ARGUMENT\n   struct CB_GETATTR4args {\n           nfs_fh4 fh;\n    \
    \       bitmap4 attr_request;\n   };\n"
- title: 20.1.2.  RESULT
  contents:
  - "20.1.2.  RESULT\n   struct CB_GETATTR4resok {\n           fattr4  obj_attributes;\n\
    \   };\n   union CB_GETATTR4res switch (nfsstat4 status) {\n    case NFS4_OK:\n\
    \            CB_GETATTR4resok       resok4;\n    default:\n            void;\n\
    \   };\n"
- title: 20.1.3.  DESCRIPTION
  contents:
  - "20.1.3.  DESCRIPTION\n   The CB_GETATTR operation is used by the server to obtain\
    \ the current\n   modified state of a file that has been OPEN_DELEGATE_WRITE delegated.\n\
    \   The size and change attributes are the only ones guaranteed to be\n   serviced\
    \ by the client.  See Section 10.4.3 for a full description of\n   how the client\
    \ and server are to interact with the use of CB_GETATTR.\n   If the filehandle\
    \ specified is not one for which the client holds an\n   OPEN_DELEGATE_WRITE delegation,\
    \ an NFS4ERR_BADHANDLE error is\n   returned.\n"
- title: 20.1.4.  IMPLEMENTATION
  contents:
  - "20.1.4.  IMPLEMENTATION\n   The client returns attrmask bits and the associated\
    \ attribute values\n   only for the change attribute, and attributes that it may\
    \ change\n   (time_modify, and size).\n"
- title: '20.2.  Operation 4: CB_RECALL - Recall a Delegation'
  contents:
  - '20.2.  Operation 4: CB_RECALL - Recall a Delegation

    '
- title: 20.2.1.  ARGUMENT
  contents:
  - "20.2.1.  ARGUMENT\n   struct CB_RECALL4args {\n           stateid4        stateid;\n\
    \           bool            truncate;\n           nfs_fh4         fh;\n   };\n"
- title: 20.2.2.  RESULT
  contents:
  - "20.2.2.  RESULT\n   struct CB_RECALL4res {\n           nfsstat4        status;\n\
    \   };\n"
- title: 20.2.3.  DESCRIPTION
  contents:
  - "20.2.3.  DESCRIPTION\n   The CB_RECALL operation is used to begin the process\
    \ of recalling a\n   delegation and returning it to the server.\n   The truncate\
    \ flag is used to optimize recall for a file object that\n   is a regular file\
    \ and is about to be truncated to zero.  When it is\n   TRUE, the client is freed\
    \ of the obligation to propagate modified\n   data for the file to the server,\
    \ since this data is irrelevant.\n   If the handle specified is not one for which\
    \ the client holds a\n   delegation, an NFS4ERR_BADHANDLE error is returned.\n\
    \   If the stateid specified is not one corresponding to an OPEN\n   delegation\
    \ for the file specified by the filehandle, an\n   NFS4ERR_BAD_STATEID is returned.\n"
- title: 20.2.4.  IMPLEMENTATION
  contents:
  - "20.2.4.  IMPLEMENTATION\n   The client SHOULD reply to the callback immediately.\
    \  Replying does\n   not complete the recall except when the value of the reply's\
    \ status\n   field is neither NFS4ERR_DELAY nor NFS4_OK.  The recall is not\n\
    \   complete until the delegation is returned using a DELEGRETURN\n   operation.\n"
- title: '20.3.  Operation 5: CB_LAYOUTRECALL - Recall Layout from Client'
  contents:
  - '20.3.  Operation 5: CB_LAYOUTRECALL - Recall Layout from Client

    '
- title: 20.3.1.  ARGUMENT
  contents:
  - "20.3.1.  ARGUMENT\n   /*\n    * NFSv4.1 callback arguments and results\n    */\n\
    \   enum layoutrecall_type4 {\n           LAYOUTRECALL4_FILE = LAYOUT4_RET_REC_FILE,\n\
    \           LAYOUTRECALL4_FSID = LAYOUT4_RET_REC_FSID,\n           LAYOUTRECALL4_ALL\
    \  = LAYOUT4_RET_REC_ALL\n   };\n   struct layoutrecall_file4 {\n           nfs_fh4\
    \         lor_fh;\n           offset4         lor_offset;\n           length4\
    \         lor_length;\n           stateid4        lor_stateid;\n   };\n   union\
    \ layoutrecall4 switch(layoutrecall_type4 lor_recalltype) {\n   case LAYOUTRECALL4_FILE:\n\
    \           layoutrecall_file4 lor_layout;\n   case LAYOUTRECALL4_FSID:\n    \
    \       fsid4              lor_fsid;\n   case LAYOUTRECALL4_ALL:\n           void;\n\
    \   };\n   struct CB_LAYOUTRECALL4args {\n           layouttype4             clora_type;\n\
    \           layoutiomode4           clora_iomode;\n           bool           \
    \         clora_changed;\n           layoutrecall4           clora_recall;\n \
    \  };\n"
- title: 20.3.2.  RESULT
  contents:
  - "20.3.2.  RESULT\n   struct CB_LAYOUTRECALL4res {\n           nfsstat4       \
    \ clorr_status;\n   };\n"
- title: 20.3.3.  DESCRIPTION
  contents:
  - "20.3.3.  DESCRIPTION\n   The CB_LAYOUTRECALL operation is used by the server\
    \ to recall layouts\n   from the client; as a result, the client will begin the\
    \ process of\n   returning layouts via LAYOUTRETURN.  The CB_LAYOUTRECALL operation\n\
    \   specifies one of three forms of recall processing with the value of\n   layoutrecall_type4.\
    \  The recall is for one of the following: a\n   specific layout of a specific\
    \ file (LAYOUTRECALL4_FILE), an entire\n   file system ID (LAYOUTRECALL4_FSID),\
    \ or all file systems\n   (LAYOUTRECALL4_ALL).\n   The behavior of the operation\
    \ varies based on the value of the\n   layoutrecall_type4.  The value and behaviors\
    \ are:\n   LAYOUTRECALL4_FILE\n      For a layout to match the recall request,\
    \ the values of the\n      following fields must match those of the layout: clora_type,\n\
    \      clora_iomode, lor_fh, and the byte-range specified by lor_offset\n    \
    \  and lor_length.  The clora_iomode field may have a special value\n      of\
    \ LAYOUTIOMODE4_ANY.  The special value LAYOUTIOMODE4_ANY will\n      match any\
    \ iomode originally returned in a layout; therefore, it\n      acts as a wild\
    \ card.  The other special value used is for\n      lor_length.  If lor_length\
    \ has a value of NFS4_UINT64_MAX, the\n      lor_length field means the maximum\
    \ possible file size.  If a\n      matching layout is found, it MUST be returned\
    \ using the\n      LAYOUTRETURN operation (see Section 18.44).  An example of\
    \ the\n      field's special value use is if clora_iomode is LAYOUTIOMODE4_ANY,\n\
    \      lor_offset is zero, and lor_length is NFS4_UINT64_MAX, then the\n     \
    \ entire layout is to be returned.\n      The NFS4ERR_NOMATCHING_LAYOUT error\
    \ is only returned when the\n      client does not hold layouts for the file or\
    \ if the client does\n      not have any overlapping layouts for the specification\
    \ in the\n      layout recall.\n   LAYOUTRECALL4_FSID and LAYOUTRECALL4_ALL\n\
    \      If LAYOUTRECALL4_FSID is specified, the fsid specifies the file\n     \
    \ system for which any outstanding layouts MUST be returned.  If\n      LAYOUTRECALL4_ALL\
    \ is specified, all outstanding layouts MUST be\n      returned.  In addition,\
    \ LAYOUTRECALL4_FSID and LAYOUTRECALL4_ALL\n      specify that all the storage\
    \ device ID to storage device address\n      mappings in the affected file system(s)\
    \ are also recalled.  The\n      respective LAYOUTRETURN with either LAYOUTRETURN4_FSID\
    \ or\n      LAYOUTRETURN4_ALL acknowledges to the server that the client\n   \
    \   invalidated the said device mappings.  See Section 12.5.5.2.1.5\n      for\
    \ considerations with \"bulk\" recall of layouts.\n      The NFS4ERR_NOMATCHING_LAYOUT\
    \ error is only returned when the\n      client does not hold layouts and does\
    \ not have valid deviceid\n      mappings.\n   In processing the layout recall\
    \ request, the client also varies its\n   behavior based on the value of the clora_changed\
    \ field.  This field\n   is used by the server to provide additional context for\
    \ the reason\n   why the layout is being recalled.  A FALSE value for clora_changed\n\
    \   indicates that no change in the layout is expected and the client may\n  \
    \ write modified data to the storage devices involved; this must be\n   done prior\
    \ to returning the layout via LAYOUTRETURN.  A TRUE value\n   for clora_changed\
    \ indicates that the server is changing the layout.\n   Examples of layout changes\
    \ and reasons for a TRUE indication are the\n   following: the metadata server\
    \ is restriping the file or a permanent\n   error has occurred on a storage device\
    \ and the metadata server would\n   like to provide a new layout for the file.\
    \  Therefore, a\n   clora_changed value of TRUE indicates some level of change\
    \ for the\n   layout and the client SHOULD NOT write and commit modified data\
    \ to\n   the storage devices.  In this case, the client writes and commits\n \
    \  data through the metadata server.\n   See Section 12.5.3 for a description\
    \ of how the lor_stateid field in\n   the arguments is to be constructed.  Note\
    \ that the \"seqid\" field of\n   lor_stateid MUST NOT be zero.  See Sections\
    \ 8.2, 12.5.3, and 12.5.5.2\n   for a further discussion and requirements.\n"
- title: 20.3.4.  IMPLEMENTATION
  contents:
  - "20.3.4.  IMPLEMENTATION\n   The client's processing for CB_LAYOUTRECALL is similar\
    \ to CB_RECALL\n   (recall of file delegations) in that the client responds to\
    \ the\n   request before actually returning layouts via the LAYOUTRETURN\n   operation.\
    \  While the client responds to the CB_LAYOUTRECALL\n   immediately, the operation\
    \ is not considered complete (i.e.,\n   considered pending) until all affected\
    \ layouts are returned to the\n   server via the LAYOUTRETURN operation.\n   Before\
    \ returning the layout to the server via LAYOUTRETURN, the\n   client should wait\
    \ for the response from in-process or in-flight\n   READ, WRITE, or COMMIT operations\
    \ that use the recalled layout.\n   If the client is holding modified data that\
    \ is affected by a recalled\n   layout, the client has various options for writing\
    \ the data to the\n   server.  As always, the client may write the data through\
    \ the\n   metadata server.  In fact, the client may not have a choice other\n\
    \   than writing to the metadata server when the clora_changed argument\n   is\
    \ TRUE and a new layout is unavailable from the server.  However,\n   the client\
    \ may be able to write the modified data to the storage\n   device if the clora_changed\
    \ argument is FALSE; this needs to be done\n   before returning the layout via\
    \ LAYOUTRETURN.  If the client were to\n   obtain a new layout covering the modified\
    \ data's byte-range, then\n   writing to the storage devices is an available alternative.\
    \  Note\n   that before obtaining a new layout, the client must first return the\n\
    \   original layout.\n   In the case of modified data being written while the\
    \ layout is held,\n   the client must use LAYOUTCOMMIT operations at the appropriate\
    \ time;\n   as required LAYOUTCOMMIT must be done before the LAYOUTRETURN.  If\
    \ a\n   large amount of modified data is outstanding, the client may send\n  \
    \ LAYOUTRETURNs for portions of the recalled layout; this allows the\n   server\
    \ to monitor the client's progress and adherence to the original\n   recall request.\
    \  However, the last LAYOUTRETURN in a sequence of\n   returns MUST specify the\
    \ full range being recalled (see\n   Section 12.5.5.1 for details).\n   If a server\
    \ needs to delete a device ID and there are layouts\n   referring to the device\
    \ ID, CB_LAYOUTRECALL MUST be invoked to cause\n   the client to return all layouts\
    \ referring to the device ID before\n   the server can delete the device ID. \
    \ If the client does not return\n   the affected layouts, the server MAY revoke\
    \ the layouts.\n"
- title: '20.4.  Operation 6: CB_NOTIFY - Notify Client of Directory Changes'
  contents:
  - '20.4.  Operation 6: CB_NOTIFY - Notify Client of Directory Changes

    '
- title: 20.4.1.  ARGUMENT
  contents:
  - "20.4.1.  ARGUMENT\n   /*\n    * Directory notification types.\n    */\n   enum\
    \ notify_type4 {\n           NOTIFY4_CHANGE_CHILD_ATTRS = 0,\n           NOTIFY4_CHANGE_DIR_ATTRS\
    \ = 1,\n           NOTIFY4_REMOVE_ENTRY = 2,\n           NOTIFY4_ADD_ENTRY = 3,\n\
    \           NOTIFY4_RENAME_ENTRY = 4,\n           NOTIFY4_CHANGE_COOKIE_VERIFIER\
    \ = 5\n   };\n   /* Changed entry information.  */\n   struct notify_entry4 {\n\
    \           component4      ne_file;\n           fattr4          ne_attrs;\n \
    \  };\n   /* Previous entry information */\n   struct prev_entry4 {\n        \
    \   notify_entry4   pe_prev_entry;\n           /* what READDIR returned for this\
    \ entry */\n           nfs_cookie4     pe_prev_entry_cookie;\n   };\n   struct\
    \ notify_remove4 {\n           notify_entry4   nrm_old_entry;\n           nfs_cookie4\
    \     nrm_old_entry_cookie;\n   };\n   struct notify_add4 {\n           /*\n \
    \           * Information on object\n            * possibly renamed over.\n  \
    \          */\n           notify_remove4      nad_old_entry<1>;\n           notify_entry4\
    \       nad_new_entry;\n           /* what READDIR would have returned for this\
    \ entry */\n           nfs_cookie4         nad_new_entry_cookie<1>;\n        \
    \   prev_entry4         nad_prev_entry<1>;\n           bool                nad_last_entry;\n\
    \   };\n   struct notify_attr4 {\n           notify_entry4   na_changed_entry;\n\
    \   };\n   struct notify_rename4 {\n           notify_remove4  nrn_old_entry;\n\
    \           notify_add4     nrn_new_entry;\n   };\n   struct notify_verifier4\
    \ {\n           verifier4       nv_old_cookieverf;\n           verifier4     \
    \  nv_new_cookieverf;\n   };\n   /*\n    * Objects of type notify_<>4 and\n  \
    \  * notify_device_<>4 are encoded in this.\n    */\n   typedef opaque notifylist4<>;\n\
    \   struct notify4 {\n           /* composed from notify_type4 or notify_deviceid_type4\
    \ */\n           bitmap4         notify_mask;\n           notifylist4     notify_vals;\n\
    \   };\n   struct CB_NOTIFY4args {\n           stateid4    cna_stateid;\n    \
    \       nfs_fh4     cna_fh;\n           notify4     cna_changes<>;\n   };\n"
- title: 20.4.2.  RESULT
  contents:
  - "20.4.2.  RESULT\n   struct CB_NOTIFY4res {\n           nfsstat4    cnr_status;\n\
    \   };\n"
- title: 20.4.3.  DESCRIPTION
  contents:
  - "20.4.3.  DESCRIPTION\n   The CB_NOTIFY operation is used by the server to send\
    \ notifications\n   to clients about changes to delegated directories.  The registration\n\
    \   of notifications for the directories occurs when the delegation is\n   established\
    \ using GET_DIR_DELEGATION.  These notifications are sent\n   over the backchannel.\
    \  The notification is sent once the original\n   request has been processed on\
    \ the server.  The server will send an\n   array of notifications for changes\
    \ that might have occurred in the\n   directory.  The notifications are sent as\
    \ list of pairs of bitmaps\n   and values.  See Section 3.3.7 for a description\
    \ of how NFSv4.1\n   bitmaps work.\n   If the server has more notifications than\
    \ can fit in the CB_COMPOUND\n   request, it SHOULD send a sequence of serial\
    \ CB_COMPOUND requests so\n   that the client's view of the directory does not\
    \ become confused.\n   For example, if the server indicates that a file named\
    \ \"foo\" is added\n   and that the file \"foo\" is removed, the order in which\
    \ the client\n   receives these notifications needs to be the same as the order\
    \ in\n   which the corresponding operations occurred on the server.\n   If the\
    \ client holding the delegation makes any changes in the\n   directory that cause\
    \ files or sub-directories to be added or removed,\n   the server will notify\
    \ that client of the resulting change(s).  If\n   the client holding the delegation\
    \ is making attribute or cookie\n   verifier changes only, the server does not\
    \ need to send notifications\n   to that client.  The server will send the following\
    \ information for\n   each operation:\n   NOTIFY4_ADD_ENTRY\n      The server\
    \ will send information about the new directory entry\n      being created along\
    \ with the cookie for that entry.  The entry\n      information (data type notify_add4)\
    \ includes the component name of\n      the entry and attributes.  The server\
    \ will send this type of entry\n      when a file is actually being created, when\
    \ an entry is being\n      added to a directory as a result of a rename across\
    \ directories\n      (see below), and when a hard link is being created to an\
    \ existing\n      file.  If this entry is added to the end of the directory, the\n\
    \      server will set the nad_last_entry flag to TRUE.  If the file is\n    \
    \  added such that there is at least one entry before it, the server\n      will\
    \ also return the previous entry information (nad_prev_entry, a\n      variable-length\
    \ array of up to one element.  If the array is of\n      zero length, there is\
    \ no previous entry), along with its cookie.\n      This is to help clients find\
    \ the right location in their file name\n      caches and directory caches where\
    \ this entry should be cached.  If\n      the new entry's cookie is available,\
    \ it will be in the\n      nad_new_entry_cookie (another variable-length array\
    \ of up to one\n      element) field.  If the addition of the entry causes another\
    \ entry\n      to be deleted (which can only happen in the rename case)\n    \
    \  atomically with the addition, then information on this entry is\n      reported\
    \ in nad_old_entry.\n   NOTIFY4_REMOVE_ENTRY\n      The server will send information\
    \ about the directory entry being\n      deleted.  The server will also send the\
    \ cookie value for the\n      deleted entry so that clients can get to the cached\
    \ information\n      for this entry.\n   NOTIFY4_RENAME_ENTRY\n      The server\
    \ will send information about both the old entry and the\n      new entry.  This\
    \ includes the name and attributes for each entry.\n      In addition, if the\
    \ rename causes the deletion of an entry (i.e.,\n      the case of a file renamed\
    \ over), then this is reported in\n      nrn_new_new_entry.nad_old_entry.  This\
    \ notification is only sent\n      if both entries are in the same directory.\
    \  If the rename is\n      across directories, the server will send a remove notification\
    \ to\n      one directory and an add notification to the other directory,\n  \
    \    assuming both have a directory delegation.\n   NOTIFY4_CHANGE_CHILD_ATTRS/NOTIFY4_CHANGE_DIR_ATTRS\n\
    \      The client will use the attribute mask to inform the server of\n      attributes\
    \ for which it wants to receive notifications.  This\n      change notification\
    \ can be requested for changes to the attributes\n      of the directory as well\
    \ as changes to any file's attributes in\n      the directory by using two separate\
    \ attribute masks.  The client\n      cannot ask for change attribute notification\
    \ for a specific file.\n      One attribute mask covers all the files in the directory.\
    \  Upon\n      any attribute change, the server will send back the values of\n\
    \      changed attributes.  Notifications might not make sense for some\n    \
    \  file system-wide attributes, and it is up to the server to decide\n      which\
    \ subset it wants to support.  The client can negotiate the\n      frequency of\
    \ attribute notifications by letting the server know\n      how often it wants\
    \ to be notified of an attribute change.  The\n      server will return supported\
    \ notification frequencies or an\n      indication that no notification is permitted\
    \ for directory or\n      child attributes by setting the dir_notif_delay and\n\
    \      dir_entry_notif_delay attributes, respectively.\n   NOTIFY4_CHANGE_COOKIE_VERIFIER\n\
    \      If the cookie verifier changes while a client is holding a\n      delegation,\
    \ the server will notify the client so that it can\n      invalidate its cookies\
    \ and re-send a READDIR to get the new set of\n      cookies.\n"
- title: '20.5.  Operation 7: CB_PUSH_DELEG - Offer Previously Requested'
  contents:
  - "20.5.  Operation 7: CB_PUSH_DELEG - Offer Previously Requested\n       Delegation\
    \ to Client\n"
- title: 20.5.1.  ARGUMENT
  contents:
  - "20.5.1.  ARGUMENT\n   struct CB_PUSH_DELEG4args {\n           nfs_fh4       \
    \   cpda_fh;\n           open_delegation4 cpda_delegation;\n   };\n"
- title: 20.5.2.  RESULT
  contents:
  - "20.5.2.  RESULT\n   struct CB_PUSH_DELEG4res {\n           nfsstat4 cpdr_status;\n\
    \   };\n"
- title: 20.5.3.  DESCRIPTION
  contents:
  - "20.5.3.  DESCRIPTION\n   CB_PUSH_DELEG is used by the server both to signal to\
    \ the client that\n   the delegation it wants (previously indicated via a want\
    \ established\n   from an OPEN or WANT_DELEGATION operation) is available and\
    \ to\n   simultaneously offer the delegation to the client.  The client has\n\
    \   the choice of accepting the delegation by returning NFS4_OK to the\n   server,\
    \ delaying the decision to accept the offered delegation by\n   returning NFS4ERR_DELAY,\
    \ or permanently rejecting the offer of the\n   delegation by returning NFS4ERR_REJECT_DELEG.\
    \  When a delegation is\n   rejected in this fashion, the want previously established\
    \ is\n   permanently deleted and the delegation is subject to acquisition by\n\
    \   another client.\n"
- title: 20.5.4.  IMPLEMENTATION
  contents:
  - "20.5.4.  IMPLEMENTATION\n   If the client does return NFS4ERR_DELAY and there\
    \ is a conflicting\n   delegation request, the server MAY process it at the expense\
    \ of the\n   client that returned NFS4ERR_DELAY.  The client's want will not be\n\
    \   cancelled, but MAY be processed behind other delegation requests or\n   registered\
    \ wants.\n   When a client returns a status other than NFS4_OK, NFS4ERR_DELAY,\
    \ or\n   NFS4ERR_REJECT_DELAY, the want remains pending, although servers may\n\
    \   decide to cancel the want by sending a CB_WANTS_CANCELLED.\n"
- title: '20.6.  Operation 8: CB_RECALL_ANY - Keep Any N Recallable Objects'
  contents:
  - '20.6.  Operation 8: CB_RECALL_ANY - Keep Any N Recallable Objects

    '
- title: 20.6.1.  ARGUMENT
  contents:
  - "20.6.1.  ARGUMENT\n   const RCA4_TYPE_MASK_RDATA_DLG          = 0;\n   const\
    \ RCA4_TYPE_MASK_WDATA_DLG          = 1;\n   const RCA4_TYPE_MASK_DIR_DLG    \
    \        = 2;\n   const RCA4_TYPE_MASK_FILE_LAYOUT        = 3;\n   const RCA4_TYPE_MASK_BLK_LAYOUT\
    \         = 4;\n   const RCA4_TYPE_MASK_OBJ_LAYOUT_MIN     = 8;\n   const RCA4_TYPE_MASK_OBJ_LAYOUT_MAX\
    \     = 9;\n   const RCA4_TYPE_MASK_OTHER_LAYOUT_MIN   = 12;\n   const RCA4_TYPE_MASK_OTHER_LAYOUT_MAX\
    \   = 15;\n   struct  CB_RECALL_ANY4args      {\n           uint32_t        craa_objects_to_keep;\n\
    \           bitmap4         craa_type_mask;\n   };\n"
- title: 20.6.2.  RESULT
  contents:
  - "20.6.2.  RESULT\n   struct CB_RECALL_ANY4res {\n           nfsstat4        crar_status;\n\
    \   };\n"
- title: 20.6.3.  DESCRIPTION
  contents:
  - "20.6.3.  DESCRIPTION\n   The server may decide that it cannot hold all of the\
    \ state for\n   recallable objects, such as delegations and layouts, without running\n\
    \   out of resources.  In such a case, while not optimal, the server is\n   free\
    \ to recall individual objects to reduce the load.\n   Because the general purpose\
    \ of such recallable objects as delegations\n   is to eliminate client interaction\
    \ with the server, the server cannot\n   interpret lack of recent use as indicating\
    \ that the object is no\n   longer useful.  The absence of visible use is consistent\
    \ with a\n   delegation keeping potential operations from being sent to the\n\
    \   server.  In the case of layouts, while it is true that the usefulness\n  \
    \ of a layout is indicated by the use of the layout when storage\n   devices receive\
    \ I/O requests, because there is no mandate that a\n   storage device indicate\
    \ to the metadata server any past or present\n   use of a layout, the metadata\
    \ server is not likely to know which\n   layouts are good candidates to recall\
    \ in response to low resources.\n   In order to implement an effective reclaim\
    \ scheme for such objects,\n   the server's knowledge of available resources must\
    \ be used to\n   determine when objects must be recalled with the clients selecting\n\
    \   the actual objects to be returned.\n   Server implementations may differ in\
    \ their resource allocation\n   requirements.  For example, one server may share\
    \ resources among all\n   classes of recallable objects, whereas another may use\
    \ separate\n   resource pools for layouts and for delegations, or further separate\n\
    \   resources by types of delegations.\n   When a given resource pool is over-utilized,\
    \ the server can send a\n   CB_RECALL_ANY to clients holding recallable objects\
    \ of the types\n   involved, allowing it to keep a certain number of such objects\
    \ and\n   return any excess.  A mask specifies which types of objects are to be\n\
    \   limited.  The client chooses, based on its own knowledge of current\n   usefulness,\
    \ which of the objects in that class should be returned.\n   A number of bits\
    \ are defined.  For some of these, ranges are defined\n   and it is up to the\
    \ definition of the storage protocol to specify how\n   these are to be used.\
    \  There are ranges reserved for object-based\n   storage protocols and for other\
    \ experimental storage protocols.  An\n   RFC defining such a storage protocol\
    \ needs to specify how particular\n   bits within its range are to be used.  For\
    \ example, it may specify a\n   mapping between attributes of the layout (read\
    \ vs. write, size of\n   area) and the bit to be used, or it may define a field\
    \ in the layout\n   where the associated bit position is made available by the\
    \ server to\n   the client.\n   RCA4_TYPE_MASK_RDATA_DLG\n      The client is\
    \ to return OPEN_DELEGATE_READ delegations on non-\n      directory file objects.\n\
    \   RCA4_TYPE_MASK_WDATA_DLG\n      The client is to return OPEN_DELEGATE_WRITE\
    \ delegations on regular\n      file objects.\n   RCA4_TYPE_MASK_DIR_DLG\n   \
    \   The client is to return directory delegations.\n   RCA4_TYPE_MASK_FILE_LAYOUT\n\
    \      The client is to return layouts of type LAYOUT4_NFSV4_1_FILES.\n   RCA4_TYPE_MASK_BLK_LAYOUT\n\
    \      See [48] for a description.\n   RCA4_TYPE_MASK_OBJ_LAYOUT_MIN to RCA4_TYPE_MASK_OBJ_LAYOUT_MAX\n\
    \      See [47] for a description.\n   RCA4_TYPE_MASK_OTHER_LAYOUT_MIN to RCA4_TYPE_MASK_OTHER_LAYOUT_MAX\n\
    \      This range is reserved for telling the client to recall layouts of\n  \
    \    experimental or site-specific layout types (see Section 3.3.13).\n   When\
    \ a bit is set in the type mask that corresponds to an undefined\n   type of recallable\
    \ object, NFS4ERR_INVAL MUST be returned.  When a\n   bit is set that corresponds\
    \ to a defined type of object but the\n   client does not support an object of\
    \ the type, NFS4ERR_INVAL MUST NOT\n   be returned.  Future minor versions of\
    \ NFSv4 may expand the set of\n   valid type mask bits.\n   CB_RECALL_ANY specifies\
    \ a count of objects that the client may keep\n   as opposed to a count that the\
    \ client must return.  This is to avoid\n   a potential race between a CB_RECALL_ANY\
    \ that had a count of objects\n   to free with a set of client-originated operations\
    \ to return layouts\n   or delegations.  As a result of the race, the client and\
    \ server would\n   have differing ideas as to how many objects to return.  Hence,\
    \ the\n   client could mistakenly free too many.\n   If resource demands prompt\
    \ it, the server may send another\n   CB_RECALL_ANY with a lower count, even if\
    \ it has not yet received an\n   acknowledgment from the client for a previous\
    \ CB_RECALL_ANY with the\n   same type mask.  Although the possibility exists\
    \ that these will be\n   received by the client in an order different from the\
    \ order in which\n   they were sent, any such permutation of the callback stream\
    \ is\n   harmless.  It is the job of the client to bring down the size of the\n\
    \   recallable object set in line with each CB_RECALL_ANY received, and\n   until\
    \ that obligation is met, it cannot be cancelled or modified by\n   any subsequent\
    \ CB_RECALL_ANY for the same type mask.  Thus, if the\n   server sends two CB_RECALL_ANYs,\
    \ the effect will be the same as if\n   the lower count was sent, whatever the\
    \ order of recall receipt.  Note\n   that this means that a server may not cancel\
    \ the effect of a\n   CB_RECALL_ANY by sending another recall with a higher count.\
    \  When a\n   CB_RECALL_ANY is received and the count is already within the limit\n\
    \   set or is above a limit that the client is working to get down to,\n   that\
    \ callback has no effect.\n   Servers are generally free to deny recallable objects\
    \ when\n   insufficient resources are available.  Note that the effect of such\
    \ a\n   policy is implicitly to give precedence to existing objects relative\n\
    \   to requested ones, with the result that resources might not be\n   optimally\
    \ used.  To prevent this, servers are well advised to make\n   the point at which\
    \ they start sending CB_RECALL_ANY callbacks\n   somewhat below that at which\
    \ they cease to give out new delegations\n   and layouts.  This allows the client\
    \ to purge its less-used objects\n   whenever appropriate and so continue to have\
    \ its subsequent requests\n   given new resources freed up by object returns.\n"
- title: 20.6.4.  IMPLEMENTATION
  contents:
  - "20.6.4.  IMPLEMENTATION\n   The client can choose to return any type of object\
    \ specified by the\n   mask.  If a server wishes to limit the use of objects of\
    \ a specific\n   type, it should only specify that type in the mask it sends.\
    \  Should\n   the client fail to return requested objects, it is up to the server\n\
    \   to handle this situation, typically by sending specific recalls\n   (i.e.,\
    \ sending CB_RECALL operations) to properly limit resource\n   usage.  The server\
    \ should give the client enough time to return\n   objects before proceeding to\
    \ specific recalls.  This time should not\n   be less than the lease period.\n"
- title: '20.7.  Operation 9: CB_RECALLABLE_OBJ_AVAIL - Signal Resources for'
  contents:
  - "20.7.  Operation 9: CB_RECALLABLE_OBJ_AVAIL - Signal Resources for\n       Recallable\
    \ Objects\n"
- title: 20.7.1.  ARGUMENT
  contents:
  - "20.7.1.  ARGUMENT\n   typedef CB_RECALL_ANY4args CB_RECALLABLE_OBJ_AVAIL4args;\n"
- title: 20.7.2.  RESULT
  contents:
  - "20.7.2.  RESULT\n   struct CB_RECALLABLE_OBJ_AVAIL4res {\n           nfsstat4\
    \        croa_status;\n   };\n"
- title: 20.7.3.  DESCRIPTION
  contents:
  - "20.7.3.  DESCRIPTION\n   CB_RECALLABLE_OBJ_AVAIL is used by the server to signal\
    \ the client\n   that the server has resources to grant recallable objects that\
    \ might\n   previously have been denied by OPEN, WANT_DELEGATION, GET_DIR_DELEG,\n\
    \   or LAYOUTGET.\n   The argument craa_objects_to_keep means the total number\
    \ of\n   recallable objects of the types indicated in the argument type_mask\n\
    \   that the server believes it can allow the client to have, including\n   the\
    \ number of such objects the client already has.  A client that\n   tries to acquire\
    \ more recallable objects than the server informs it\n   can have runs the risk\
    \ of having objects recalled.\n   The server is not obligated to reserve the difference\
    \ between the\n   number of the objects the client currently has and the value\
    \ of\n   craa_objects_to_keep, nor does delaying the reply to\n   CB_RECALLABLE_OBJ_AVAIL\
    \ prevent the server from using the resources\n   of the recallable objects for\
    \ another purpose.  Indeed, if a client\n   responds slowly to CB_RECALLABLE_OBJ_AVAIL,\
    \ the server might\n   interpret the client as having reduced capability to manage\n\
    \   recallable objects, and so cancel or reduce any reservation it is\n   maintaining\
    \ on behalf of the client.  Thus, if the client desires to\n   acquire more recallable\
    \ objects, it needs to reply quickly to\n   CB_RECALLABLE_OBJ_AVAIL, and then\
    \ send the appropriate operations to\n   acquire recallable objects.\n"
- title: '20.8.  Operation 10: CB_RECALL_SLOT - Change Flow Control Limits'
  contents:
  - '20.8.  Operation 10: CB_RECALL_SLOT - Change Flow Control Limits

    '
- title: 20.8.1.  ARGUMENT
  contents:
  - "20.8.1.  ARGUMENT\n   struct CB_RECALL_SLOT4args {\n           slotid4      \
    \ rsa_target_highest_slotid;\n   };\n"
- title: 20.8.2.  RESULT
  contents:
  - "20.8.2.  RESULT\n   struct CB_RECALL_SLOT4res {\n           nfsstat4   rsr_status;\n\
    \   };\n"
- title: 20.8.3.  DESCRIPTION
  contents:
  - "20.8.3.  DESCRIPTION\n   The CB_RECALL_SLOT operation requests the client to\
    \ return session\n   slots, and if applicable, transport credits (e.g., RDMA credits\
    \ for\n   connections associated with the operations channel) of the session's\n\
    \   fore channel.  CB_RECALL_SLOT specifies rsa_target_highest_slotid,\n   the\
    \ value of the target highest slot ID the server wants for the\n   session.  The\
    \ client MUST then progress toward reducing the session's\n   highest slot ID\
    \ to the target value.\n   If the session has only non-RDMA connections associated\
    \ with its\n   operations channel, then the client need only wait for all\n  \
    \ outstanding requests with a slot ID > rsa_target_highest_slotid to\n   complete,\
    \ then send a single COMPOUND consisting of a single SEQUENCE\n   operation, with\
    \ the sa_highestslot field set to\n   rsa_target_highest_slotid.  If there are\
    \ RDMA-based connections\n   associated with operation channel, then the client\
    \ needs to also send\n   enough zero-length \"RDMA Send\" messages to take the\
    \ total RDMA credit\n   count to rsa_target_highest_slotid + 1 or below.\n"
- title: 20.8.4.  IMPLEMENTATION
  contents:
  - "20.8.4.  IMPLEMENTATION\n   If the client fails to reduce highest slot it has\
    \ on the fore channel\n   to what the server requests, the server can force the\
    \ issue by\n   asserting flow control on the receive side of all connections bound\n\
    \   to the fore channel, and then finish servicing all outstanding\n   requests\
    \ that are in slots greater than rsa_target_highest_slotid.\n   Once that is done,\
    \ the server can then open the flow control, and any\n   time the client sends\
    \ a new request on a slot greater than\n   rsa_target_highest_slotid, the server\
    \ can return NFS4ERR_BADSLOT.\n"
- title: '20.9.  Operation 11: CB_SEQUENCE - Supply Backchannel Sequencing and'
  contents:
  - "20.9.  Operation 11: CB_SEQUENCE - Supply Backchannel Sequencing and\n      \
    \ Control\n"
- title: 20.9.1.  ARGUMENT
  contents:
  - "20.9.1.  ARGUMENT\n   struct referring_call4 {\n           sequenceid4     rc_sequenceid;\n\
    \           slotid4         rc_slotid;\n   };\n   struct referring_call_list4\
    \ {\n           sessionid4      rcl_sessionid;\n           referring_call4 rcl_referring_calls<>;\n\
    \   };\n   struct CB_SEQUENCE4args {\n           sessionid4           csa_sessionid;\n\
    \           sequenceid4          csa_sequenceid;\n           slotid4         \
    \     csa_slotid;\n           slotid4              csa_highest_slotid;\n     \
    \      bool                 csa_cachethis;\n           referring_call_list4 csa_referring_call_lists<>;\n\
    \   };\n"
- title: 20.9.2.  RESULT
  contents:
  - "20.9.2.  RESULT\n   struct CB_SEQUENCE4resok {\n           sessionid4       \
    \  csr_sessionid;\n           sequenceid4        csr_sequenceid;\n           slotid4\
    \            csr_slotid;\n           slotid4            csr_highest_slotid;\n\
    \           slotid4            csr_target_highest_slotid;\n   };\n   union CB_SEQUENCE4res\
    \ switch (nfsstat4 csr_status) {\n   case NFS4_OK:\n           CB_SEQUENCE4resok\
    \   csr_resok4;\n   default:\n           void;\n   };\n"
- title: 20.9.3.  DESCRIPTION
  contents:
  - "20.9.3.  DESCRIPTION\n   The CB_SEQUENCE operation is used to manage operational\
    \ accounting\n   for the backchannel of the session on which a request is sent.\
    \  The\n   contents include the session ID to which this request belongs, the\n\
    \   slot ID and sequence ID used by the server to implement session\n   request\
    \ control and exactly once semantics, and exchanged slot ID\n   maxima that are\
    \ used to adjust the size of the reply cache.  In each\n   CB_COMPOUND request,\
    \ CB_SEQUENCE MUST appear once and MUST be the\n   first operation.  The error\
    \ NFS4ERR_SEQUENCE_POS MUST be returned\n   when CB_SEQUENCE is found in any position\
    \ in a CB_COMPOUND beyond the\n   first.  If any other operation is in the first\
    \ position of\n   CB_COMPOUND, NFS4ERR_OP_NOT_IN_SESSION MUST be returned.\n \
    \  See Section 18.46.3 for a description of how slots are processed.\n   If csa_cachethis\
    \ is TRUE, then the server is requesting that the\n   client cache the reply in\
    \ the callback reply cache.  The client MUST\n   cache the reply (see Section\
    \ 2.10.6.1.3).\n   The csa_referring_call_lists array is the list of COMPOUND\
    \ requests,\n   identified by session ID, slot ID, and sequence ID.  These are\n\
    \   requests that the client previously sent to the server.  These\n   previous\
    \ requests created state that some operation(s) in the same\n   CB_COMPOUND as\
    \ the csa_referring_call_lists are identifying.  A\n   session ID is included\
    \ because leased state is tied to a client ID,\n   and a client ID can have multiple\
    \ sessions.  See Section 2.10.6.3.\n   The value of the csa_sequenceid argument\
    \ relative to the cached\n   sequence ID on the slot falls into one of three cases.\n\
    \   *  If the difference between csa_sequenceid and the client's cached\n    \
    \  sequence ID at the slot ID is two (2) or more, or if\n      csa_sequenceid\
    \ is less than the cached sequence ID (accounting for\n      wraparound of the\
    \ unsigned sequence ID value), then the client\n      MUST return NFS4ERR_SEQ_MISORDERED.\n\
    \   *  If csa_sequenceid and the cached sequence ID are the same, this is\n  \
    \    a retry, and the client returns the CB_COMPOUND request's cached\n      reply.\n\
    \   *  If csa_sequenceid is one greater (accounting for wraparound) than\n   \
    \   the cached sequence ID, then this is a new request, and the slot's\n     \
    \ sequence ID is incremented.  The operations subsequent to\n      CB_SEQUENCE,\
    \ if any, are processed.  If there are no other\n      operations, the only other\
    \ effects are to cache the CB_SEQUENCE\n      reply in the slot, maintain the\
    \ session's activity, and when the\n      server receives the CB_SEQUENCE reply,\
    \ renew the lease of state\n      related to the client ID.\n   If the server\
    \ reuses a slot ID and sequence ID for a completely\n   different request, the\
    \ client MAY treat the request as if it is a\n   retry of what it has already\
    \ executed.  The client MAY however detect\n   the server's illegal reuse and\
    \ return NFS4ERR_SEQ_FALSE_RETRY.\n   If CB_SEQUENCE returns an error, then the\
    \ state of the slot (sequence\n   ID, cached reply) MUST NOT change.  See Section\
    \ 2.10.6.1.3 for the\n   conditions when the error NFS4ERR_RETRY_UNCACHED_REP\
    \ might be\n   returned.\n   The client returns two \"highest_slotid\" values:\
    \ csr_highest_slotid\n   and csr_target_highest_slotid.  The former is the highest\
    \ slot ID the\n   client will accept in a future CB_SEQUENCE operation, and SHOULD\
    \ NOT\n   be less than the value of csa_highest_slotid (but see\n   Section 2.10.6.1\
    \ for an exception).  The latter is the highest slot\n   ID the client would prefer\
    \ the server use on a future CB_SEQUENCE\n   operation.\n"
- title: '20.10.  Operation 12: CB_WANTS_CANCELLED - Cancel Pending Delegation'
  contents:
  - "20.10.  Operation 12: CB_WANTS_CANCELLED - Cancel Pending Delegation\n      \
    \  Wants\n"
- title: 20.10.1.  ARGUMENT
  contents:
  - "20.10.1.  ARGUMENT\n   struct CB_WANTS_CANCELLED4args {\n           bool cwca_contended_wants_cancelled;\n\
    \           bool cwca_resourced_wants_cancelled;\n   };\n"
- title: 20.10.2.  RESULT
  contents:
  - "20.10.2.  RESULT\n   struct CB_WANTS_CANCELLED4res {\n           nfsstat4   \
    \     cwcr_status;\n   };\n"
- title: 20.10.3.  DESCRIPTION
  contents:
  - "20.10.3.  DESCRIPTION\n   The CB_WANTS_CANCELLED operation is used to notify\
    \ the client that\n   some or all of the wants it registered for recallable delegations\
    \ and\n   layouts have been cancelled.\n   If cwca_contended_wants_cancelled is\
    \ TRUE, this indicates that the\n   server will not be pushing to the client any\
    \ delegations that become\n   available after contention passes.\n   If cwca_resourced_wants_cancelled\
    \ is TRUE, this indicates that the\n   server will not notify the client when\
    \ there are resources on the\n   server to grant delegations or layouts.\n   After\
    \ receiving a CB_WANTS_CANCELLED operation, the client is free to\n   attempt\
    \ to acquire the delegations or layouts it was waiting for, and\n   possibly re-register\
    \ wants.\n"
- title: 20.10.4.  IMPLEMENTATION
  contents:
  - "20.10.4.  IMPLEMENTATION\n   When a client has an OPEN, WANT_DELEGATION, or GET_DIR_DELEGATION\n\
    \   request outstanding, when a CB_WANTS_CANCELLED is sent, the server\n   may\
    \ need to make clear to the client whether a promise to signal\n   delegation\
    \ availability happened before the CB_WANTS_CANCELLED and is\n   thus covered\
    \ by it, or after the CB_WANTS_CANCELLED in which case it\n   was not covered\
    \ by it.  The server can make this distinction by\n   putting the appropriate\
    \ requests into the list of referring calls in\n   the associated CB_SEQUENCE.\n"
- title: '20.11.  Operation 13: CB_NOTIFY_LOCK - Notify Client of Possible Lock'
  contents:
  - "20.11.  Operation 13: CB_NOTIFY_LOCK - Notify Client of Possible Lock\n     \
    \   Availability\n"
- title: 20.11.1.  ARGUMENT
  contents:
  - "20.11.1.  ARGUMENT\n   struct CB_NOTIFY_LOCK4args {\n       nfs_fh4     cnla_fh;\n\
    \       lock_owner4 cnla_lock_owner;\n   };\n"
- title: 20.11.2.  RESULT
  contents:
  - "20.11.2.  RESULT\n   struct CB_NOTIFY_LOCK4res {\n           nfsstat4       \
    \ cnlr_status;\n   };\n"
- title: 20.11.3.  DESCRIPTION
  contents:
  - "20.11.3.  DESCRIPTION\n   The server can use this operation to indicate that\
    \ a byte-range lock\n   for the given file and lock-owner, previously requested\
    \ by the client\n   via an unsuccessful LOCK operation, might be available.\n\
    \   This callback is meant to be used by servers to help reduce the\n   latency\
    \ of blocking locks in the case where they recognize that a\n   client that has\
    \ been polling for a blocking byte-range lock may now\n   be able to acquire the\
    \ lock.  If the server supports this callback\n   for a given file, it MUST set\
    \ the OPEN4_RESULT_MAY_NOTIFY_LOCK flag\n   when responding to successful opens\
    \ for that file.  This does not\n   commit the server to the use of CB_NOTIFY_LOCK,\
    \ but the client may\n   use this as a hint to decide how frequently to poll for\
    \ locks derived\n   from that open.\n   If an OPEN operation results in an upgrade,\
    \ in which the stateid\n   returned has an \"other\" value matching that of a\
    \ stateid already\n   allocated, with a new \"seqid\" indicating a change in the\
    \ lock being\n   represented, then the value of the OPEN4_RESULT_MAY_NOTIFY_LOCK\
    \ flag\n   when responding to that new OPEN controls handling from that point\n\
    \   going forward.  When parallel OPENs are done on the same file and\n   open-owner,\
    \ the ordering of the \"seqid\" fields of the returned\n   stateids (subject to\
    \ wraparound) are to be used to select the\n   controlling value of the OPEN4_RESULT_MAY_NOTIFY_LOCK\
    \ flag.\n"
- title: 20.11.4.  IMPLEMENTATION
  contents:
  - "20.11.4.  IMPLEMENTATION\n   The server MUST NOT grant the byte-range lock to\
    \ the client unless\n   and until it receives a LOCK operation from the client.\
    \  Similarly,\n   the client receiving this callback cannot assume that it now\
    \ has the\n   lock or that a subsequent LOCK operation for the lock will be\n\
    \   successful.\n   The server is not required to implement this callback, and\
    \ even if it\n   does, it is not required to use it in any particular case.\n\
    \   Therefore, the client must still rely on polling for blocking locks,\n   as\
    \ described in Section 9.6.\n   Similarly, the client is not required to implement\
    \ this callback, and\n   even it does, is still free to ignore it.  Therefore,\
    \ the server MUST\n   NOT assume that the client will act based on the callback.\n"
- title: '20.12.  Operation 14: CB_NOTIFY_DEVICEID - Notify Client of Device ID'
  contents:
  - "20.12.  Operation 14: CB_NOTIFY_DEVICEID - Notify Client of Device ID\n     \
    \   Changes\n"
- title: 20.12.1.  ARGUMENT
  contents:
  - "20.12.1.  ARGUMENT\n   /*\n    * Device notification types.\n    */\n   enum\
    \ notify_deviceid_type4 {\n           NOTIFY_DEVICEID4_CHANGE = 1,\n         \
    \  NOTIFY_DEVICEID4_DELETE = 2\n   };\n   /* For NOTIFY4_DEVICEID4_DELETE */\n\
    \   struct notify_deviceid_delete4 {\n           layouttype4     ndd_layouttype;\n\
    \           deviceid4       ndd_deviceid;\n   };\n   /* For NOTIFY4_DEVICEID4_CHANGE\
    \ */\n   struct notify_deviceid_change4 {\n           layouttype4     ndc_layouttype;\n\
    \           deviceid4       ndc_deviceid;\n           bool            ndc_immediate;\n\
    \   };\n   struct CB_NOTIFY_DEVICEID4args {\n           notify4 cnda_changes<>;\n\
    \   };\n"
- title: 20.12.2.  RESULT
  contents:
  - "20.12.2.  RESULT\n   struct CB_NOTIFY_DEVICEID4res {\n           nfsstat4   \
    \     cndr_status;\n   };\n"
- title: 20.12.3.  DESCRIPTION
  contents:
  - "20.12.3.  DESCRIPTION\n   The CB_NOTIFY_DEVICEID operation is used by the server\
    \ to send\n   notifications to clients about changes to pNFS device IDs.  The\n\
    \   registration of device ID notifications is optional and is done via\n   GETDEVICEINFO.\
    \  These notifications are sent over the backchannel\n   once the original request\
    \ has been processed on the server.  The\n   server will send an array of notifications,\
    \ cnda_changes, as a list\n   of pairs of bitmaps and values.  See Section 3.3.7\
    \ for a description\n   of how NFSv4.1 bitmaps work.\n   As with CB_NOTIFY (Section\
    \ 20.4.3), it is possible the server has\n   more notifications than can fit in\
    \ a CB_COMPOUND, thus requiring\n   multiple CB_COMPOUNDs.  Unlike CB_NOTIFY,\
    \ serialization is not an\n   issue because unlike directory entries, device IDs\
    \ cannot be re-used\n   after being deleted (Section 12.2.10).\n   All device\
    \ ID notifications contain a device ID and a layout type.\n   The layout type\
    \ is necessary because two different layout types can\n   share the same device\
    \ ID, and the common device ID can have\n   completely different mappings for\
    \ each layout type.\n   The server will send the following notifications:\n  \
    \ NOTIFY_DEVICEID4_CHANGE\n      A previously provided device-ID-to-device-address\
    \ mapping has\n      changed and the client uses GETDEVICEINFO to obtain the updated\n\
    \      mapping.  The notification is encoded in a value of data type\n      notify_deviceid_change4.\
    \  This data type also contains a boolean\n      field, ndc_immediate, which if\
    \ TRUE indicates that the change will\n      be enforced immediately, and so the\
    \ client might not be able to\n      complete any pending I/O to the device ID.\
    \  If ndc_immediate is\n      FALSE, then for an indefinite time, the client can\
    \ complete\n      pending I/O.  After pending I/O is complete, the client SHOULD\
    \ get\n      the new device-ID-to-device-address mappings before sending new I/\n\
    \      O requests to the storage devices addressed by the device ID.\n   NOTIFY4_DEVICEID_DELETE\n\
    \      Deletes a device ID from the mappings.  This notification MUST NOT\n  \
    \    be sent if the client has a layout that refers to the device ID.\n      In\
    \ other words, if the server is sending a delete device ID\n      notification,\
    \ one of the following is true for layouts associated\n      with the layout type:\n\
    \      *  The client never had a layout referring to that device ID.\n      *\
    \  The client has returned all layouts referring to that device\n         ID.\n\
    \      *  The server has revoked all layouts referring to that device ID.\n  \
    \    The notification is encoded in a value of data type\n      notify_deviceid_delete4.\
    \  After a server deletes a device ID, it\n      MUST NOT reuse that device ID\
    \ for the same layout type until the\n      client ID is deleted.\n"
- title: '20.13.  Operation 10044: CB_ILLEGAL - Illegal Callback Operation'
  contents:
  - '20.13.  Operation 10044: CB_ILLEGAL - Illegal Callback Operation

    '
- title: 20.13.1.  ARGUMENT
  contents:
  - "20.13.1.  ARGUMENT\n           void;\n"
- title: 20.13.2.  RESULT
  contents:
  - "20.13.2.  RESULT\n   /*\n    * CB_ILLEGAL: Response for illegal operation numbers\n\
    \    */\n   struct CB_ILLEGAL4res {\n           nfsstat4        status;\n   };\n"
- title: 20.13.3.  DESCRIPTION
  contents:
  - "20.13.3.  DESCRIPTION\n   This operation is a placeholder for encoding a result\
    \ to handle the\n   case of the server sending an operation code within CB_COMPOUND\
    \ that\n   is not defined in the NFSv4.1 specification.  See Section 19.2.3 for\n\
    \   more details.\n   The status field of CB_ILLEGAL4res MUST be set to NFS4ERR_OP_ILLEGAL.\n"
- title: 20.13.4.  IMPLEMENTATION
  contents:
  - "20.13.4.  IMPLEMENTATION\n   A server will probably not send an operation with\
    \ code OP_CB_ILLEGAL,\n   but if it does, the response will be CB_ILLEGAL4res\
    \ just as it would\n   be with any other invalid operation code.  Note that if\
    \ the client\n   gets an illegal operation code that is not OP_ILLEGAL, and if\
    \ the\n   client checks for legal operation codes during the XDR decode phase,\n\
    \   then an instance of data type CB_ILLEGAL4res will not be returned.\n"
- title: 21.  Security Considerations
  contents:
  - "21.  Security Considerations\n   Historically, the authentication model of NFS\
    \ was based on the entire\n   machine being the NFS client, with the NFS server\
    \ trusting the NFS\n   client to authenticate the end-user.  The NFS server in\
    \ turn shared\n   its files only to specific clients, as identified by the client's\n\
    \   source network address.  Given this model, the AUTH_SYS RPC security\n   flavor\
    \ simply identified the end-user using the client to the NFS\n   server.  When\
    \ processing NFS responses, the client ensured that the\n   responses came from\
    \ the same network address and port number to which\n   the request was sent.\
    \  While such a model is easy to implement and\n   simple to deploy and use, it\
    \ is unsafe.  Thus, NFSv4.1\n   implementations are REQUIRED to support a security\
    \ model that uses\n   end-to-end authentication, where an end-user on a client\
    \ mutually\n   authenticates (via cryptographic schemes that do not expose passwords\n\
    \   or keys in the clear on the network) to a principal on an NFS server.\n  \
    \ Consideration is also given to the integrity and privacy of NFS\n   requests\
    \ and responses.  The issues of end-to-end mutual\n   authentication, integrity,\
    \ and privacy are discussed in\n   Section 2.2.1.1.1.  There are specific considerations\
    \ when using\n   Kerberos V5 as described in Section 2.2.1.1.1.2.1.1.\n   Note\
    \ that being REQUIRED to implement does not mean REQUIRED to use;\n   AUTH_SYS\
    \ can be used by NFSv4.1 clients and servers.  However,\n   AUTH_SYS is merely\
    \ an OPTIONAL security flavor in NFSv4.1, and so\n   interoperability via AUTH_SYS\
    \ is not assured.\n   For reasons of reduced administration overhead, better performance,\n\
    \   and/or reduction of CPU utilization, users of NFSv4.1 implementations\n  \
    \ might decline to use security mechanisms that enable integrity\n   protection\
    \ on each remote procedure call and response.  The use of\n   mechanisms without\
    \ integrity leaves the user vulnerable to a man-in-\n   the-middle of the NFS\
    \ client and server that modifies the RPC request\n   and/or the response.  While\
    \ implementations are free to provide the\n   option to use weaker security mechanisms,\
    \ there are three operations\n   in particular that warrant the implementation\
    \ overriding user\n   choices.\n   *  The first two such operations are SECINFO\
    \ and SECINFO_NO_NAME.  It\n      is RECOMMENDED that the client send both operations\
    \ such that they\n      are protected with a security flavor that has integrity\n\
    \      protection, such as RPCSEC_GSS with either the\n      rpc_gss_svc_integrity\
    \ or rpc_gss_svc_privacy service.  Without\n      integrity protection encapsulating\
    \ SECINFO and SECINFO_NO_NAME and\n      their results, a man-in-the-middle could\
    \ modify results such that\n      the client might select a weaker algorithm in\
    \ the set allowed by\n      the server, making the client and/or server vulnerable\
    \ to further\n      attacks.\n   *  The third operation that SHOULD use integrity\
    \ protection is any\n      GETATTR for the fs_locations and fs_locations_info\
    \ attributes, in\n      order to mitigate the severity of a man-in-the-middle\
    \ attack.  The\n      attack has two steps.  First the attacker modifies the unprotected\n\
    \      results of some operation to return NFS4ERR_MOVED.  Second, when\n    \
    \  the client follows up with a GETATTR for the fs_locations or\n      fs_locations_info\
    \ attributes, the attacker modifies the results to\n      cause the client to\
    \ migrate its traffic to a server controlled by\n      the attacker.  With integrity\
    \ protection, this attack is\n      mitigated.\n   Relative to previous NFS versions,\
    \ NFSv4.1 has additional security\n   considerations for pNFS (see Sections 12.9\
    \ and 13.12), locking and\n   session state (see Section 2.10.8.3), and state\
    \ recovery during grace\n   period (see Section 8.4.2.1.1).  With respect to locking\
    \ and session\n   state, if SP4_SSV state protection is being used, Section 2.10.10\
    \ has\n   specific security considerations for the NFSv4.1 client and server.\n\
    \   Security considerations for lock reclaim differ between the two\n   different\
    \ situations in which state reclaim is to be done.  The\n   server failure situation\
    \ is discussed in Section 8.4.2.1.1, while the\n   per-fs state reclaim done in\
    \ support of migration/replication is\n   discussed in Section 11.11.9.1.\n  \
    \ The use of the multi-server namespace features described in\n   Section 11 raises\
    \ the possibility that requests to determine the set\n   of network addresses\
    \ corresponding to a given server might be\n   interfered with or have their responses\
    \ modified in flight.  In light\n   of this possibility, the following considerations\
    \ should be noted:\n   *  When DNS is used to convert server names to addresses\
    \ and DNSSEC\n      [29] is not available, the validity of the network addresses\n\
    \      returned generally cannot be relied upon.  However, when combined\n   \
    \   with a trusted resolver, DNS over TLS [30] and DNS over HTTPS [34]\n     \
    \ can be relied upon to provide valid address resolutions.\n      In situations\
    \ in which the validity of the provided addresses\n      cannot be relied upon\
    \ and the client uses RPCSEC_GSS to access the\n      designated server, it is\
    \ possible for mutual authentication to\n      discover invalid server addresses\
    \ as long as the RPCSEC_GSS\n      implementation used does not use insecure DNS\
    \ queries to\n      canonicalize the hostname components of the service principal\n\
    \      names, as explained in [28].\n   *  The fetching of attributes containing\
    \ file system location\n      information SHOULD be performed using integrity\
    \ protection.  It is\n      important to note here that a client making a request\
    \ of this sort\n      without using integrity protection needs be aware of the\
    \ negative\n      consequences of doing so, which can lead to invalid hostnames\
    \ or\n      network addresses being returned.  These include cases in which\n\
    \      the client is directed to a server under the control of an\n      attacker,\
    \ who might get access to data written or provide\n      incorrect values for\
    \ data read.  In light of this, the client\n      needs to recognize that using\
    \ such returned location information\n      to access an NFSv4 server without\
    \ use of RPCSEC_GSS (i.e., by\n      using AUTH_SYS) poses dangers as it can result\
    \ in the client\n      interacting with such an attacker-controlled server without\
    \ any\n      authentication facilities to verify the server's identity.\n   *\
    \  Despite the fact that it is a requirement that implementations\n      provide\
    \ \"support\" for use of RPCSEC_GSS, it cannot be assumed that\n      use of RPCSEC_GSS\
    \ is always available between any particular\n      client-server pair.\n   *\
    \  When a client has the network addresses of a server but not the\n      associated\
    \ hostnames, that would interfere with its ability to use\n      RPCSEC_GSS.\n\
    \   In light of the above, a server SHOULD present file system location\n   entries\
    \ that correspond to file systems on other servers using a\n   hostname.  This\
    \ would allow the client to interrogate the\n   fs_locations on the destination\
    \ server to obtain trunking information\n   (as well as replica information) using\
    \ integrity protection,\n   validating the name provided while assuring that the\
    \ response has not\n   been modified in flight.\n   When RPCSEC_GSS is not available\
    \ on a server, the client needs to be\n   aware of the fact that the location\
    \ entries are subject to\n   modification in flight and so cannot be relied upon.\
    \  In the case of\n   a client being directed to another server after NFS4ERR_MOVED,\
    \ this\n   could vitiate the authentication provided by the use of RPCSEC_GSS\
    \ on\n   the designated destination server.  Even when RPCSEC_GSS\n   authentication\
    \ is available on the destination, the server might\n   still properly authenticate\
    \ as the server to which the client was\n   erroneously directed.  Without a way\
    \ to decide whether the server is\n   a valid one, the client can only determine,\
    \ using RPCSEC_GSS, that\n   the server corresponds to the name provided, with\
    \ no basis for\n   trusting that server.  As a result, the client SHOULD NOT use\
    \ such\n   unverified location entries as a basis for migration, even though\n\
    \   RPCSEC_GSS might be available on the destination.\n   When a file system location\
    \ attribute is fetched upon connecting with\n   an NFS server, it SHOULD, as stated\
    \ above, be done with integrity\n   protection.  When this not possible, it is\
    \ generally best for the\n   client to ignore trunking and replica information\
    \ or simply not fetch\n   the location information for these purposes.\n   When\
    \ location information cannot be verified, it can be subjected to\n   additional\
    \ filtering to prevent the client from being inappropriately\n   directed.  For\
    \ example, if a range of network addresses can be\n   determined that assure that\
    \ the servers and clients using AUTH_SYS\n   are subject to the appropriate set\
    \ of constraints (e.g., physical\n   network isolation, administrative controls\
    \ on the operating systems\n   used), then network addresses in the appropriate\
    \ range can be used\n   with others discarded or restricted in their use of AUTH_SYS.\n\
    \   To summarize considerations regarding the use of RPCSEC_GSS in\n   fetching\
    \ location information, we need to consider the following\n   possibilities for\
    \ requests to interrogate location information, with\n   interrogation approaches\
    \ on the referring and destination servers\n   arrived at separately:\n   *  The\
    \ use of integrity protection is RECOMMENDED in all cases, since\n      the absence\
    \ of integrity protection exposes the client to the\n      possibility of the\
    \ results being modified in transit.\n   *  The use of requests issued without\
    \ RPCSEC_GSS (i.e., using\n      AUTH_SYS, which has no provision to avoid modification\
    \ of data in\n      flight), while undesirable and a potential security exposure,\
    \ may\n      not be avoidable in all cases.  Where the use of the returned\n \
    \     information cannot be avoided, it is made subject to filtering as\n    \
    \  described above to eliminate the possibility that the client would\n      treat\
    \ an invalid address as if it were a NFSv4 server.  The\n      specifics will\
    \ vary depending on the degree of network isolation\n      and whether the request\
    \ is to the referring or destination\n      servers.\n   Even if such requests\
    \ are not interfered with in flight, it is\n   possible for a compromised server\
    \ to direct the client to use\n   inappropriate servers, such as those under the\
    \ control of the\n   attacker.  It is not clear that being directed to such servers\n\
    \   represents a greater threat to the client than the damage that could\n   be\
    \ done by the compromised server itself.  However, it is possible\n   that some\
    \ sorts of transient server compromises might be exploited to\n   direct a client\
    \ to a server capable of doing greater damage over a\n   longer time.  One useful\
    \ step to guard against this possibility is to\n   issue requests to fetch location\
    \ data using RPCSEC_GSS, even if no\n   mapping to an RPCSEC_GSS principal is\
    \ available.  In this case,\n   RPCSEC_GSS would not be used, as it typically\
    \ is, to identify the\n   client principal to the server, but rather to make sure\
    \ (via\n   RPCSEC_GSS mutual authentication) that the server being contacted is\n\
    \   the one intended.\n   Similar considerations apply if the threat to be avoided\
    \ is the\n   redirection of client traffic to inappropriate (i.e., poorly\n  \
    \ performing) servers.  In both cases, there is no reason for the\n   information\
    \ returned to depend on the identity of the client\n   principal requesting it,\
    \ while the validity of the server\n   information, which has the capability to\
    \ affect all client\n   principals, is of considerable importance.\n"
- title: 22.  IANA Considerations
  contents:
  - "22.  IANA Considerations\n   This section uses terms that are defined in [63].\n"
- title: 22.1.  IANA Actions
  contents:
  - "22.1.  IANA Actions\n   This update does not require any modification of, or\
    \ additions to,\n   registry entries or registry rules associated with NFSv4.1.\
    \  However,\n   since this document obsoletes RFC 5661, IANA has updated all registry\n\
    \   entries and registry rules references that point to RFC 5661 to point\n  \
    \ to this document instead.\n   Previous actions by IANA related to NFSv4.1 are\
    \ listed in the\n   remaining subsections of Section 22.\n"
- title: 22.2.  Named Attribute Definitions
  contents:
  - "22.2.  Named Attribute Definitions\n   IANA created a registry called the \"\
    NFSv4 Named Attribute Definitions\n   Registry\".\n   The NFSv4.1 protocol supports\
    \ the association of a file with zero or\n   more named attributes.  The namespace\
    \ identifiers for these\n   attributes are defined as string names.  The protocol\
    \ does not define\n   the specific assignment of the namespace for these file\
    \ attributes.\n   The IANA registry promotes interoperability where common interests\n\
    \   exist.  While application developers are allowed to define and use\n   attributes\
    \ as needed, they are encouraged to register the attributes\n   with IANA.\n \
    \  Such registered named attributes are presumed to apply to all minor\n   versions\
    \ of NFSv4, including those defined subsequently to the\n   registration.  If\
    \ the named attribute is intended to be limited to\n   specific minor versions,\
    \ this will be clearly stated in the\n   registry's assignment.\n   All assignments\
    \ to the registry are made on a First Come First Served\n   basis, per Section\
    \ 4.4 of [63].  The policy for each assignment is\n   Specification Required,\
    \ per Section 4.6 of [63].\n   Under the NFSv4.1 specification, the name of a\
    \ named attribute can in\n   theory be up to 2^(32) - 1 bytes in length, but in\
    \ practice NFSv4.1\n   clients and servers will be unable to handle a string that\
    \ long.\n   IANA should reject any assignment request with a named attribute that\n\
    \   exceeds 128 UTF-8 characters.  To give the IESG the flexibility to\n   set\
    \ up bases of assignment of Experimental Use and Standards Action,\n   the prefixes\
    \ of \"EXPE\" and \"STDS\" are Reserved.  The named attribute\n   with a zero-length\
    \ name is Reserved.\n   The prefix \"PRIV\" is designated for Private Use.  A\
    \ site that wants\n   to make use of unregistered named attributes without risk\
    \ of\n   conflicting with an assignment in IANA's registry should use the\n  \
    \ prefix \"PRIV\" in all of its named attributes.\n   Because some NFSv4.1 clients\
    \ and servers have case-insensitive\n   semantics, the fifteen additional lower\
    \ case and mixed case\n   permutations of each of \"EXPE\", \"PRIV\", and \"STDS\"\
    \ are Reserved\n   (e.g., \"expe\", \"expE\", \"exPe\", etc. are Reserved).  Similarly,\
    \ IANA\n   must not allow two assignments that would conflict if both named\n\
    \   attributes were converted to a common case.\n   The registry of named attributes\
    \ is a list of assignments, each\n   containing three fields for each assignment.\n\
    \   1.  A US-ASCII string name that is the actual name of the attribute.\n   \
    \    This name must be unique.  This string name can be 1 to 128 UTF-8\n     \
    \  characters long.\n   2.  A reference to the specification of the named attribute.\
    \  The\n       reference can consume up to 256 bytes (or more if IANA permits).\n\
    \   3.  The point of contact of the registrant.  The point of contact can\n  \
    \     consume up to 256 bytes (or more if IANA permits).\n"
- title: 22.2.1.  Initial Registry
  contents:
  - "22.2.1.  Initial Registry\n   There is no initial registry.\n"
- title: 22.2.2.  Updating Registrations
  contents:
  - "22.2.2.  Updating Registrations\n   The registrant is always permitted to update\
    \ the point of contact\n   field.  Any other change will require Expert Review\
    \ or IESG Approval.\n"
- title: 22.3.  Device ID Notifications
  contents:
  - "22.3.  Device ID Notifications\n   IANA created a registry called the \"NFSv4\
    \ Device ID Notifications\n   Registry\".\n   The potential exists for new notification\
    \ types to be added to the\n   CB_NOTIFY_DEVICEID operation (see Section 20.12).\
    \  This can be done\n   via changes to the operations that register notifications,\
    \ or by\n   adding new operations to NFSv4.  This requires a new minor version\
    \ of\n   NFSv4, and requires a Standards Track document from the IETF.\n   Another\
    \ way to add a notification is to specify a new layout type\n   (see Section 22.5).\n\
    \   Hence, all assignments to the registry are made on a Standards Action\n  \
    \ basis per Section 4.6 of [63], with Expert Review required.\n   The registry\
    \ is a list of assignments, each containing five fields\n   per assignment.\n\
    \   1.  The name of the notification type.  This name must have the\n       prefix\
    \ \"NOTIFY_DEVICEID4_\".  This name must be unique.\n   2.  The value of the notification.\
    \  IANA will assign this number, and\n       the request from the registrant will\
    \ use TBD1 instead of an\n       actual value.  IANA MUST use a whole number that\
    \ can be no higher\n       than 2^(32)-1, and should be the next available value.\
    \  The value\n       assigned must be unique.  A Designated Expert must be used\
    \ to\n       ensure that when the name of the notification type and its value\n\
    \       are added to the NFSv4.1 notify_deviceid_type4 enumerated data\n     \
    \  type in the NFSv4.1 XDR description [10], the result continues to\n       be\
    \ a valid XDR description.\n   3.  The Standards Track RFC(s) that describe the\
    \ notification.  If\n       the RFC(s) have not yet been published, the registrant\
    \ will use\n       RFCTBD2, RFCTBD3, etc. instead of an actual RFC number.\n \
    \  4.  How the RFC introduces the notification.  This is indicated by a\n    \
    \   single US-ASCII value.  If the value is N, it means a minor\n       revision\
    \ to the NFSv4 protocol.  If the value is L, it means a\n       new pNFS layout\
    \ type.  Other values can be used with IESG\n       Approval.\n   5.  The minor\
    \ versions of NFSv4 that are allowed to use the\n       notification.  While these\
    \ are numeric values, IANA will not\n       allocate and assign them; the author\
    \ of the relevant RFCs with\n       IESG Approval assigns these numbers.  Each\
    \ time there is a new\n       minor version of NFSv4 approved, a Designated Expert\
    \ should\n       review the registry to make recommended updates as needed.\n"
- title: 22.3.1.  Initial Registry
  contents:
  - "22.3.1.  Initial Registry\n   The initial registry is in Table 25.  Note that\
    \ the next available\n   value is zero.\n   | Notification Name       | Value\
    \ | RFC      | How | Minor Versions |\n   | NOTIFY_DEVICEID4_CHANGE | 1     |\
    \ RFC      | N   | 1              |\n   | NOTIFY_DEVICEID4_DELETE | 2     | RFC\
    \      | N   | 1              |\n            Table 25: Initial Device ID Notification\
    \ Assignments\n"
- title: 22.3.2.  Updating Registrations
  contents:
  - "22.3.2.  Updating Registrations\n   The update of a registration will require\
    \ IESG Approval on the advice\n   of a Designated Expert.\n"
- title: 22.4.  Object Recall Types
  contents:
  - "22.4.  Object Recall Types\n   IANA created a registry called the \"NFSv4 Recallable\
    \ Object Types\n   Registry\".\n   The potential exists for new object types to\
    \ be added to the\n   CB_RECALL_ANY operation (see Section 20.6).  This can be\
    \ done via\n   changes to the operations that add recallable types, or by adding\
    \ new\n   operations to NFSv4.  This requires a new minor version of NFSv4, and\n\
    \   requires a Standards Track document from IETF.  Another way to add a\n   new\
    \ recallable object is to specify a new layout type (see\n   Section 22.5).\n\
    \   All assignments to the registry are made on a Standards Action basis\n   per\
    \ Section 4.9 of [63], with Expert Review required.\n   Recallable object types\
    \ are 32-bit unsigned numbers.  There are no\n   Reserved values.  Values in the\
    \ range 12 through 15, inclusive, are\n   designated for Private Use.\n   The\
    \ registry is a list of assignments, each containing five fields\n   per assignment.\n\
    \   1.  The name of the recallable object type.  This name must have the\n   \
    \    prefix \"RCA4_TYPE_MASK_\".  The name must be unique.\n   2.  The value of\
    \ the recallable object type.  IANA will assign this\n       number, and the request\
    \ from the registrant will use TBD1 instead\n       of an actual value.  IANA\
    \ MUST use a whole number that can be no\n       higher than 2^(32)-1, and should\
    \ be the next available value.\n       The value must be unique.  A Designated\
    \ Expert must be used to\n       ensure that when the name of the recallable type\
    \ and its value\n       are added to the NFSv4 XDR description [10], the result\
    \ continues\n       to be a valid XDR description.\n   3.  The Standards Track\
    \ RFC(s) that describe the recallable object\n       type.  If the RFC(s) have\
    \ not yet been published, the registrant\n       will use RFCTBD2, RFCTBD3, etc.\
    \ instead of an actual RFC number.\n   4.  How the RFC introduces the recallable\
    \ object type.  This is\n       indicated by a single US-ASCII value.  If the\
    \ value is N, it\n       means a minor revision to the NFSv4 protocol.  If the\
    \ value is L,\n       it means a new pNFS layout type.  Other values can be used\
    \ with\n       IESG Approval.\n   5.  The minor versions of NFSv4 that are allowed\
    \ to use the\n       recallable object type.  While these are numeric values,\
    \ IANA\n       will not allocate and assign them; the author of the relevant\n\
    \       RFCs with IESG Approval assigns these numbers.  Each time there\n    \
    \   is a new minor version of NFSv4 approved, a Designated Expert\n       should\
    \ review the registry to make recommended updates as needed.\n"
- title: 22.4.1.  Initial Registry
  contents:
  - "22.4.1.  Initial Registry\n   The initial registry is in Table 26.  Note that\
    \ the next available\n   value is five.\n     | Recallable Object Type Name  \
    \ | Value | RFC  | How | Minor    |\n     | RCA4_TYPE_MASK_RDATA_DLG      | 0\
    \     | RFC  | N   | 1        |\n     | RCA4_TYPE_MASK_WDATA_DLG      | 1    \
    \ | RFC  | N   | 1        |\n     | RCA4_TYPE_MASK_DIR_DLG        | 2     | RFC\
    \  | N   | 1        |\n     | RCA4_TYPE_MASK_FILE_LAYOUT    | 3     | RFC  | N\
    \   | 1        |\n     | RCA4_TYPE_MASK_BLK_LAYOUT     | 4     | RFC  | L   |\
    \ 1        |\n     | RCA4_TYPE_MASK_OBJ_LAYOUT_MIN | 8     | RFC  | L   | 1  \
    \      |\n     | RCA4_TYPE_MASK_OBJ_LAYOUT_MAX | 9     | RFC  | L   | 1      \
    \  |\n            Table 26: Initial Recallable Object Type Assignments\n"
- title: 22.4.2.  Updating Registrations
  contents:
  - "22.4.2.  Updating Registrations\n   The update of a registration will require\
    \ IESG Approval on the advice\n   of a Designated Expert.\n"
- title: 22.5.  Layout Types
  contents:
  - "22.5.  Layout Types\n   IANA created a registry called the \"pNFS Layout Types\
    \ Registry\".\n   All assignments to the registry are made on a Standards Action\
    \ basis,\n   with Expert Review required.\n   Layout types are 32-bit numbers.\
    \  The value zero is Reserved.  Values\n   in the range 0x80000000 to 0xFFFFFFFF\
    \ inclusive are designated for\n   Private Use.  IANA will assign numbers from\
    \ the range 0x00000001 to\n   0x7FFFFFFF inclusive.\n   The registry is a list\
    \ of assignments, each containing five fields.\n   1.  The name of the layout\
    \ type.  This name must have the prefix\n       \"LAYOUT4_\".  The name must be\
    \ unique.\n   2.  The value of the layout type.  IANA will assign this number,\
    \ and\n       the request from the registrant will use TBD1 instead of an\n  \
    \     actual value.  The value assigned must be unique.  A Designated\n      \
    \ Expert must be used to ensure that when the name of the layout\n       type\
    \ and its value are added to the NFSv4.1 layouttype4\n       enumerated data type\
    \ in the NFSv4.1 XDR description [10], the\n       result continues to be a valid\
    \ XDR description.\n   3.  The Standards Track RFC(s) that describe the notification.\
    \  If\n       the RFC(s) have not yet been published, the registrant will use\n\
    \       RFCTBD2, RFCTBD3, etc. instead of an actual RFC number.\n       Collectively,\
    \ the RFC(s) must adhere to the guidelines listed in\n       Section 22.5.3.\n\
    \   4.  How the RFC introduces the layout type.  This is indicated by a\n    \
    \   single US-ASCII value.  If the value is N, it means a minor\n       revision\
    \ to the NFSv4 protocol.  If the value is L, it means a\n       new pNFS layout\
    \ type.  Other values can be used with IESG\n       Approval.\n   5.  The minor\
    \ versions of NFSv4 that are allowed to use the\n       notification.  While these\
    \ are numeric values, IANA will not\n       allocate and assign them; the author\
    \ of the relevant RFCs with\n       IESG Approval assigns these numbers.  Each\
    \ time there is a new\n       minor version of NFSv4 approved, a Designated Expert\
    \ should\n       review the registry to make recommended updates as needed.\n"
- title: 22.5.1.  Initial Registry
  contents:
  - "22.5.1.  Initial Registry\n   The initial registry is in Table 27.\n    | Layout\
    \ Type Name      | Value | RFC      | How | Minor Versions |\n    | LAYOUT4_NFSV4_1_FILES\
    \ | 0x1   | RFC 8881 | N   | 1              |\n    | LAYOUT4_OSD2_OBJECTS  | 0x2\
    \   | RFC 5664 | L   | 1              |\n    | LAYOUT4_BLOCK_VOLUME  | 0x3   |\
    \ RFC 5663 | L   | 1              |\n                 Table 27: Initial Layout\
    \ Type Assignments\n"
- title: 22.5.2.  Updating Registrations
  contents:
  - "22.5.2.  Updating Registrations\n   The update of a registration will require\
    \ IESG Approval on the advice\n   of a Designated Expert.\n"
- title: 22.5.3.  Guidelines for Writing Layout Type Specifications
  contents:
  - "22.5.3.  Guidelines for Writing Layout Type Specifications\n   The author of\
    \ a new pNFS layout specification must follow these steps\n   to obtain acceptance\
    \ of the layout type as a Standards Track RFC:\n   1.  The author devises the\
    \ new layout specification.\n   2.  The new layout type specification MUST, at\
    \ a minimum:\n       *  Define the contents of the layout-type-specific fields\
    \ of the\n          following data types:\n          -  the da_addr_body field\
    \ of the device_addr4 data type;\n          -  the loh_body field of the layouthint4\
    \ data type;\n          -  the loc_body field of layout_content4 data type (which\
    \ in\n             turn is the lo_content field of the layout4 data type);\n \
    \         -  the lou_body field of the layoutupdate4 data type;\n       *  Describe\
    \ or define the storage access protocol used to access\n          the storage\
    \ devices.\n       *  Describe whether revocation of layouts is supported.\n \
    \      *  At a minimum, describe the methods of recovery from:\n          1. \
    \ Failure and restart for client, server, storage device.\n          2.  Lease\
    \ expiration from perspective of the active client,\n              server, storage\
    \ device.\n          3.  Loss of layout state resulting in fencing of client access\n\
    \              to storage devices (for an example, see Section 12.7.3).\n    \
    \   *  Include an IANA considerations section, which will in turn\n          include:\n\
    \          -  A request to IANA for a new layout type per Section 22.5.\n    \
    \      -  A list of requests to IANA for any new recallable object\n         \
    \    types for CB_RECALL_ANY; each entry is to be presented in\n             the\
    \ form described in Section 22.4.\n          -  A list of requests to IANA for\
    \ any new notification values\n             for CB_NOTIFY_DEVICEID; each entry\
    \ is to be presented in\n             the form described in Section 22.3.\n  \
    \     *  Include a security considerations section.  This section MUST\n     \
    \     explain how the NFSv4.1 authentication, authorization, and\n          access-control\
    \ models are preserved.  That is, if a metadata\n          server would restrict\
    \ a READ or WRITE operation, how would\n          pNFS via the layout similarly\
    \ restrict a corresponding input\n          or output operation?\n   3.  The author\
    \ documents the new layout specification as an Internet-\n       Draft.\n   4.\
    \  The author submits the Internet-Draft for review through the IETF\n       standards\
    \ process as defined in \"The Internet Standards Process--\n       Revision 3\"\
    \ (BCP 9 [35]).  The new layout specification will be\n       submitted for eventual\
    \ publication as a Standards Track RFC.\n   5.  The layout specification progresses\
    \ through the IETF standards\n       process.\n"
- title: 22.6.  Path Variable Definitions
  contents:
  - "22.6.  Path Variable Definitions\n   This section deals with the IANA considerations\
    \ associated with the\n   variable substitution feature for location names as\
    \ described in\n   Section 11.17.3.  As described there, variables subject to\n\
    \   substitution consist of a domain name and a specific name within that\n  \
    \ domain, with the two separated by a colon.  There are two sets of\n   IANA considerations\
    \ here:\n   1.  The list of variable names.\n   2.  For each variable name, the\
    \ list of possible values.\n   Thus, there will be one registry for the list of\
    \ variable names, and\n   possibly one registry for listing the values of each\
    \ variable name.\n"
- title: 22.6.1.  Path Variables Registry
  contents:
  - "22.6.1.  Path Variables Registry\n   IANA created a registry called the \"NFSv4\
    \ Path Variables Registry\".\n"
- title: 22.6.1.1.  Path Variable Values
  contents:
  - "22.6.1.1.  Path Variable Values\n   Variable names are of the form \"${\", followed\
    \ by a domain name,\n   followed by a colon (\":\"), followed by a domain-specific\
    \ portion of\n   the variable name, followed by \"}\".  When the domain name is\n\
    \   \"ietf.org\", all variables names must be registered with IANA on a\n   Standards\
    \ Action basis, with Expert Review required.  Path variables\n   with registered\
    \ domain names neither part of nor equal to ietf.org\n   are assigned on a Hierarchical\
    \ Allocation basis (delegating to the\n   domain owner) and thus of no concern\
    \ to IANA, unless the domain owner\n   chooses to register a variable name from\
    \ his domain.  If the domain\n   owner chooses to do so, IANA will do so on a\
    \ First Come First Serve\n   basis.  To accommodate registrants who do not have\
    \ their own domain,\n   IANA will accept requests to register variables with the\
    \ prefix\n   \"${FCFS.ietf.org:\" on a First Come First Served basis.  Assignments\n\
    \   on a First Come First Basis do not require Expert Review, unless the\n   registrant\
    \ also wants IANA to establish a registry for the values of\n   the registered\
    \ variable.\n   The registry is a list of assignments, each containing three fields.\n\
    \   1.  The name of the variable.  The name of this variable must start\n    \
    \   with a \"${\" followed by a registered domain name, followed by\n       \"\
    :\", or it must start with \"${FCFS.ietf.org\".  The name must be\n       no more\
    \ than 64 UTF-8 characters long.  The name must be unique.\n   2.  For assignments\
    \ made on Standards Action basis, the Standards\n       Track RFC(s) that describe\
    \ the variable.  If the RFC(s) have not\n       yet been published, the registrant\
    \ will use RFCTBD1, RFCTBD2,\n       etc. instead of an actual RFC number.  Note\
    \ that the RFCs do not\n       have to be a part of an NFS minor version.  For\
    \ assignments made\n       on a First Come First Serve basis, an explanation (consuming\
    \ no\n       more than 1024 bytes, or more if IANA permits) of the purpose of\n\
    \       the variable.  A reference to the explanation can be substituted.\n  \
    \ 3.  The point of contact, including an email address.  The point of\n      \
    \ contact can consume up to 256 bytes (or more if IANA permits).\n       For assignments\
    \ made on a Standards Action basis, the point of\n       contact is always IESG.\n"
- title: 22.6.1.1.1.  Initial Registry
  contents:
  - "22.6.1.1.1.  Initial Registry\n   The initial registry is in Table 28.\n    \
    \     | Variable Name          | RFC      | Point of Contact |\n         | ${ietf.org:CPU_ARCH}\
    \   | RFC 8881 | IESG             |\n         | ${ietf.org:OS_TYPE}    | RFC 8881\
    \ | IESG             |\n         | ${ietf.org:OS_VERSION} | RFC 8881 | IESG  \
    \           |\n                 Table 28: Initial List of Path Variables\n   IANA\
    \ has created registries for the values of the variable names\n   ${ietf.org:CPU_ARCH}\
    \ and ${ietf.org:OS_TYPE}. See Sections 22.6.2 and\n   22.6.3.\n   For the values\
    \ of the variable ${ietf.org:OS_VERSION}, no registry is\n   needed as the specifics\
    \ of the values of the variable will vary with\n   the value of ${ietf.org:OS_TYPE}.\
    \ Thus, values for\n   ${ietf.org:OS_VERSION} are on a Hierarchical Allocation\
    \ basis and are\n   of no concern to IANA.\n"
- title: 22.6.1.1.2.  Updating Registrations
  contents:
  - "22.6.1.1.2.  Updating Registrations\n   The update of an assignment made on a\
    \ Standards Action basis will\n   require IESG Approval on the advice of a Designated\
    \ Expert.\n   The registrant can always update the point of contact of an\n  \
    \ assignment made on a First Come First Serve basis.  Any other update\n   will\
    \ require Expert Review.\n"
- title: 22.6.2.  Values for the ${ietf.org:CPU_ARCH} Variable
  contents:
  - "22.6.2.  Values for the ${ietf.org:CPU_ARCH} Variable\n   IANA created a registry\
    \ called the \"NFSv4 ${ietf.org:CPU_ARCH} Value\n   Registry\".\n   Assignments\
    \ to the registry are made on a First Come First Serve\n   basis.  The zero-length\
    \ value of ${ietf.org:CPU_ARCH} is Reserved.\n   Values with a prefix of \"PRIV\"\
    \ are designated for Private Use.\n   The registry is a list of assignments, each\
    \ containing three fields.\n   1.  A value of the ${ietf.org:CPU_ARCH} variable.\
    \  The value must be\n       1 to 32 UTF-8 characters long.  The value must be\
    \ unique.\n   2.  An explanation (consuming no more than 1024 bytes, or more if\n\
    \       IANA permits) of what CPU architecture the value denotes.  A\n       reference\
    \ to the explanation can be substituted.\n   3.  The point of contact, including\
    \ an email address.  The point of\n       contact can consume up to 256 bytes\
    \ (or more if IANA permits).\n"
- title: 22.6.2.1.  Initial Registry
  contents:
  - "22.6.2.1.  Initial Registry\n   There is no initial registry.\n"
- title: 22.6.2.2.  Updating Registrations
  contents:
  - "22.6.2.2.  Updating Registrations\n   The registrant is free to update the assignment,\
    \ i.e., change the\n   explanation and/or point-of-contact fields.\n"
- title: 22.6.3.  Values for the ${ietf.org:OS_TYPE} Variable
  contents:
  - "22.6.3.  Values for the ${ietf.org:OS_TYPE} Variable\n   IANA created a registry\
    \ called the \"NFSv4 ${ietf.org:OS_TYPE} Value\n   Registry\".\n   Assignments\
    \ to the registry are made on a First Come First Serve\n   basis.  The zero-length\
    \ value of ${ietf.org:OS_TYPE} is Reserved.\n   Values with a prefix of \"PRIV\"\
    \ are designated for Private Use.\n   The registry is a list of assignments, each\
    \ containing three fields.\n   1.  A value of the ${ietf.org:OS_TYPE} variable.\
    \  The value must be 1\n       to 32 UTF-8 characters long.  The value must be\
    \ unique.\n   2.  An explanation (consuming no more than 1024 bytes, or more if\n\
    \       IANA permits) of what CPU architecture the value denotes.  A\n       reference\
    \ to the explanation can be substituted.\n   3.  The point of contact, including\
    \ an email address.  The point of\n       contact can consume up to 256 bytes\
    \ (or more if IANA permits).\n"
- title: 22.6.3.1.  Initial Registry
  contents:
  - "22.6.3.1.  Initial Registry\n   There is no initial registry.\n"
- title: 22.6.3.2.  Updating Registrations
  contents:
  - "22.6.3.2.  Updating Registrations\n   The registrant is free to update the assignment,\
    \ i.e., change the\n   explanation and/or point of contact fields.\n"
- title: 23.  References
  contents:
  - '23.  References

    '
- title: 23.1.  Normative References
  contents:
  - "23.1.  Normative References\n   [1]        Bradner, S., \"Key words for use in\
    \ RFCs to Indicate\n              Requirement Levels\", BCP 14, RFC 2119,\n  \
    \            DOI 10.17487/RFC2119, March 1997,\n              <https://www.rfc-editor.org/info/rfc2119>.\n\
    \   [2]        Eisler, M., Ed., \"XDR: External Data Representation\n        \
    \      Standard\", STD 67, RFC 4506, DOI 10.17487/RFC4506, May\n             \
    \ 2006, <https://www.rfc-editor.org/info/rfc4506>.\n   [3]        Thurlow, R.,\
    \ \"RPC: Remote Procedure Call Protocol\n              Specification Version 2\"\
    , RFC 5531, DOI 10.17487/RFC5531,\n              May 2009, <https://www.rfc-editor.org/info/rfc5531>.\n\
    \   [4]        Eisler, M., Chiu, A., and L. Ling, \"RPCSEC_GSS Protocol\n    \
    \          Specification\", RFC 2203, DOI 10.17487/RFC2203, September\n      \
    \        1997, <https://www.rfc-editor.org/info/rfc2203>.\n   [5]        Zhu,\
    \ L., Jaganathan, K., and S. Hartman, \"The Kerberos\n              Version 5\
    \ Generic Security Service Application Program\n              Interface (GSS-API)\
    \ Mechanism: Version 2\", RFC 4121,\n              DOI 10.17487/RFC4121, July\
    \ 2005,\n              <https://www.rfc-editor.org/info/rfc4121>.\n   [6]    \
    \    The Open Group, \"Section 3.191 of Chapter 3 of Base\n              Definitions\
    \ of The Open Group Base Specifications Issue 6\n              IEEE Std 1003.1,\
    \ 2004 Edition, HTML Version\",\n              ISBN 1931624232, 2004, <https://www.opengroup.org>.\n\
    \   [7]        Linn, J., \"Generic Security Service Application Program\n    \
    \          Interface Version 2, Update 1\", RFC 2743,\n              DOI 10.17487/RFC2743,\
    \ January 2000,\n              <https://www.rfc-editor.org/info/rfc2743>.\n  \
    \ [8]        Recio, R., Metzler, B., Culley, P., Hilland, J., and D.\n       \
    \       Garcia, \"A Remote Direct Memory Access Protocol\n              Specification\"\
    , RFC 5040, DOI 10.17487/RFC5040, October\n              2007, <https://www.rfc-editor.org/info/rfc5040>.\n\
    \   [9]        Eisler, M., \"RPCSEC_GSS Version 2\", RFC 5403,\n             \
    \ DOI 10.17487/RFC5403, February 2009,\n              <https://www.rfc-editor.org/info/rfc5403>.\n\
    \   [10]       Shepler, S., Ed., Eisler, M., Ed., and D. Noveck, Ed.,\n      \
    \        \"Network File System (NFS) Version 4 Minor Version 1\n             \
    \ External Data Representation Standard (XDR) Description\",\n              RFC\
    \ 5662, DOI 10.17487/RFC5662, January 2010,\n              <https://www.rfc-editor.org/info/rfc5662>.\n\
    \   [11]       The Open Group, \"Section 3.372 of Chapter 3 of Base\n        \
    \      Definitions of The Open Group Base Specifications Issue 6\n           \
    \   IEEE Std 1003.1, 2004 Edition, HTML Version\",\n              ISBN 1931624232,\
    \ 2004, <https://www.opengroup.org>.\n   [12]       Eisler, M., \"IANA Considerations\
    \ for Remote Procedure Call\n              (RPC) Network Identifiers and Universal\
    \ Address Formats\",\n              RFC 5665, DOI 10.17487/RFC5665, January 2010,\n\
    \              <https://www.rfc-editor.org/info/rfc5665>.\n   [13]       The Open\
    \ Group, \"Section 'read()' of System Interfaces of\n              The Open Group\
    \ Base Specifications Issue 6 IEEE Std\n              1003.1, 2004 Edition, HTML\
    \ Version\", ISBN 1931624232,\n              2004, <https://www.opengroup.org>.\n\
    \   [14]       The Open Group, \"Section 'readdir()' of System Interfaces\n  \
    \            of The Open Group Base Specifications Issue 6 IEEE Std\n        \
    \      1003.1, 2004 Edition, HTML Version\", ISBN 1931624232,\n              2004,\
    \ <https://www.opengroup.org>.\n   [15]       The Open Group, \"Section 'write()'\
    \ of System Interfaces of\n              The Open Group Base Specifications Issue\
    \ 6 IEEE Std\n              1003.1, 2004 Edition, HTML Version\", ISBN 1931624232,\n\
    \              2004, <https://www.opengroup.org>.\n   [16]       Hoffman, P. and\
    \ M. Blanchet, \"Preparation of\n              Internationalized Strings (\"stringprep\"\
    )\", RFC 3454,\n              DOI 10.17487/RFC3454, December 2002,\n         \
    \     <https://www.rfc-editor.org/info/rfc3454>.\n   [17]       The Open Group,\
    \ \"Section 'chmod()' of System Interfaces of\n              The Open Group Base\
    \ Specifications Issue 6 IEEE Std\n              1003.1, 2004 Edition, HTML Version\"\
    , ISBN 1931624232,\n              2004, <https://www.opengroup.org>.\n   [18]\
    \       International Organization for Standardization,\n              \"Information\
    \ Technology - Universal Multiple-octet coded\n              Character Set (UCS)\
    \ - Part 1: Architecture and Basic\n              Multilingual Plane\", ISO Standard\
    \ 10646-1, May 1993.\n   [19]       Alvestrand, H., \"IETF Policy on Character\
    \ Sets and\n              Languages\", BCP 18, RFC 2277, DOI 10.17487/RFC2277,\n\
    \              January 1998, <https://www.rfc-editor.org/info/rfc2277>.\n   [20]\
    \       Hoffman, P. and M. Blanchet, \"Nameprep: A Stringprep\n              Profile\
    \ for Internationalized Domain Names (IDN)\",\n              RFC 3491, DOI 10.17487/RFC3491,\
    \ March 2003,\n              <https://www.rfc-editor.org/info/rfc3491>.\n   [21]\
    \       The Open Group, \"Section 'fcntl()' of System Interfaces of\n        \
    \      The Open Group Base Specifications Issue 6 IEEE Std\n              1003.1,\
    \ 2004 Edition, HTML Version\", ISBN 1931624232,\n              2004, <https://www.opengroup.org>.\n\
    \   [22]       The Open Group, \"Section 'fsync()' of System Interfaces of\n \
    \             The Open Group Base Specifications Issue 6 IEEE Std\n          \
    \    1003.1, 2004 Edition, HTML Version\", ISBN 1931624232,\n              2004,\
    \ <https://www.opengroup.org>.\n   [23]       The Open Group, \"Section 'getpwnam()'\
    \ of System Interfaces\n              of The Open Group Base Specifications Issue\
    \ 6 IEEE Std\n              1003.1, 2004 Edition, HTML Version\", ISBN 1931624232,\n\
    \              2004, <https://www.opengroup.org>.\n   [24]       The Open Group,\
    \ \"Section 'unlink()' of System Interfaces\n              of The Open Group Base\
    \ Specifications Issue 6 IEEE Std\n              1003.1, 2004 Edition, HTML Version\"\
    , ISBN 1931624232,\n              2004, <https://www.opengroup.org>.\n   [25]\
    \       Schaad, J., Kaliski, B., and R. Housley, \"Additional\n              Algorithms\
    \ and Identifiers for RSA Cryptography for use in\n              the Internet\
    \ X.509 Public Key Infrastructure Certificate\n              and Certificate Revocation\
    \ List (CRL) Profile\", RFC 4055,\n              DOI 10.17487/RFC4055, June 2005,\n\
    \              <https://www.rfc-editor.org/info/rfc4055>.\n   [26]       National\
    \ Institute of Standards and Technology, \"Computer\n              Security Objects\
    \ Register\", May 2016,\n              <https://csrc.nist.gov/projects/computer-security-objects-\n\
    \              register/algorithm-registration>.\n   [27]       Adamson, A. and\
    \ N. Williams, \"Remote Procedure Call (RPC)\n              Security Version 3\"\
    , RFC 7861, DOI 10.17487/RFC7861,\n              November 2016, <https://www.rfc-editor.org/info/rfc7861>.\n\
    \   [28]       Neuman, C., Yu, T., Hartman, S., and K. Raeburn, \"The\n      \
    \        Kerberos Network Authentication Service (V5)\", RFC 4120,\n         \
    \     DOI 10.17487/RFC4120, July 2005,\n              <https://www.rfc-editor.org/info/rfc4120>.\n\
    \   [29]       Arends, R., Austein, R., Larson, M., Massey, D., and S.\n     \
    \         Rose, \"DNS Security Introduction and Requirements\",\n            \
    \  RFC 4033, DOI 10.17487/RFC4033, March 2005,\n              <https://www.rfc-editor.org/info/rfc4033>.\n\
    \   [30]       Hu, Z., Zhu, L., Heidemann, J., Mankin, A., Wessels, D.,\n    \
    \          and P. Hoffman, \"Specification for DNS over Transport\n          \
    \    Layer Security (TLS)\", RFC 7858, DOI 10.17487/RFC7858, May\n           \
    \   2016, <https://www.rfc-editor.org/info/rfc7858>.\n   [31]       Adamson, A.\
    \ and N. Williams, \"Requirements for NFSv4\n              Multi-Domain Namespace\
    \ Deployment\", RFC 8000,\n              DOI 10.17487/RFC8000, November 2016,\n\
    \              <https://www.rfc-editor.org/info/rfc8000>.\n   [32]       Lever,\
    \ C., Ed., Simpson, W., and T. Talpey, \"Remote Direct\n              Memory Access\
    \ Transport for Remote Procedure Call Version\n              1\", RFC 8166, DOI\
    \ 10.17487/RFC8166, June 2017,\n              <https://www.rfc-editor.org/info/rfc8166>.\n\
    \   [33]       Lever, C., \"Network File System (NFS) Upper-Layer Binding\n  \
    \            to RPC-over-RDMA Version 1\", RFC 8267,\n              DOI 10.17487/RFC8267,\
    \ October 2017,\n              <https://www.rfc-editor.org/info/rfc8267>.\n  \
    \ [34]       Hoffman, P. and P. McManus, \"DNS Queries over HTTPS\n          \
    \    (DoH)\", RFC 8484, DOI 10.17487/RFC8484, October 2018,\n              <https://www.rfc-editor.org/info/rfc8484>.\n\
    \   [35]       Bradner, S., \"The Internet Standards Process -- Revision\n   \
    \           3\", BCP 9, RFC 2026, October 1996.\n              Kolkman, O., Bradner,\
    \ S., and S. Turner, \"Characterization\n              of Proposed Standards\"\
    , BCP 9, RFC 7127, January 2014.\n              Dusseault, L. and R. Sparks, \"\
    Guidance on Interoperation\n              and Implementation Reports for Advancement\
    \ to Draft\n              Standard\", BCP 9, RFC 5657, September 2009.\n     \
    \         Housley, R., Crocker, D., and E. Burger, \"Reducing the\n          \
    \    Standards Track to Two Maturity Levels\", BCP 9, RFC 6410,\n            \
    \  October 2011.\n              Resnick, P., \"Retirement of the \"Internet Official\n\
    \              Protocol Standards\" Summary Document\", BCP 9, RFC 7100,\n   \
    \           December 2013.\n              Dawkins, S., \"Increasing the Number\
    \ of Area Directors in\n              an IETF Area\", BCP 9, RFC 7475, March 2015.\n\
    \              <https://www.rfc-editor.org/info/bcp9>\n"
- title: 23.2.  Informative References
  contents:
  - "23.2.  Informative References\n   [36]       Roach, A., \"Process for Handling\
    \ Non-Major Revisions to\n              Existing RFCs\", Work in Progress, Internet-Draft,\
    \ draft-\n              roach-bis-documents-00, 7 May 2019,\n              <https://tools.ietf.org/html/draft-roach-bis-documents-\n\
    \              00>.\n   [37]       Shepler, S., Callaghan, B., Robinson, D., Thurlow,\
    \ R.,\n              Beame, C., Eisler, M., and D. Noveck, \"Network File System\n\
    \              (NFS) version 4 Protocol\", RFC 3530, DOI 10.17487/RFC3530,\n \
    \             April 2003, <https://www.rfc-editor.org/info/rfc3530>.\n   [38]\
    \       Callaghan, B., Pawlowski, B., and P. Staubach, \"NFS\n              Version\
    \ 3 Protocol Specification\", RFC 1813,\n              DOI 10.17487/RFC1813, June\
    \ 1995,\n              <https://www.rfc-editor.org/info/rfc1813>.\n   [39]   \
    \    Eisler, M., \"LIPKEY - A Low Infrastructure Public Key\n              Mechanism\
    \ Using SPKM\", RFC 2847, DOI 10.17487/RFC2847,\n              June 2000, <https://www.rfc-editor.org/info/rfc2847>.\n\
    \   [40]       Eisler, M., \"NFS Version 2 and Version 3 Security Issues\n   \
    \           and the NFS Protocol's Use of RPCSEC_GSS and Kerberos V5\",\n    \
    \          RFC 2623, DOI 10.17487/RFC2623, June 1999,\n              <https://www.rfc-editor.org/info/rfc2623>.\n\
    \   [41]       Juszczak, C., \"Improving the Performance and Correctness\n   \
    \           of an NFS Server\", USENIX Conference Proceedings, June\n        \
    \      1990.\n   [42]       Reynolds, J., Ed., \"Assigned Numbers: RFC 1700 is\
    \ Replaced\n              by an On-line Database\", RFC 3232, DOI 10.17487/RFC3232,\n\
    \              January 2002, <https://www.rfc-editor.org/info/rfc3232>.\n   [43]\
    \       Srinivasan, R., \"Binding Protocols for ONC RPC Version 2\",\n       \
    \       RFC 1833, DOI 10.17487/RFC1833, August 1995,\n              <https://www.rfc-editor.org/info/rfc1833>.\n\
    \   [44]       Werme, R., \"RPC XID Issues\", USENIX Conference\n            \
    \  Proceedings, February 1996.\n   [45]       Nowicki, B., \"NFS: Network File\
    \ System Protocol\n              specification\", RFC 1094, DOI 10.17487/RFC1094,\
    \ March\n              1989, <https://www.rfc-editor.org/info/rfc1094>.\n   [46]\
    \       Bhide, A., Elnozahy, E. N., and S. P. Morgan, \"A Highly\n           \
    \   Available Network Server\", USENIX Conference Proceedings,\n             \
    \ January 1991.\n   [47]       Halevy, B., Welch, B., and J. Zelenka, \"Object-Based\n\
    \              Parallel NFS (pNFS) Operations\", RFC 5664,\n              DOI\
    \ 10.17487/RFC5664, January 2010,\n              <https://www.rfc-editor.org/info/rfc5664>.\n\
    \   [48]       Black, D., Fridella, S., and J. Glasgow, \"Parallel NFS\n     \
    \         (pNFS) Block/Volume Layout\", RFC 5663,\n              DOI 10.17487/RFC5663,\
    \ January 2010,\n              <https://www.rfc-editor.org/info/rfc5663>.\n  \
    \ [49]       Callaghan, B., \"WebNFS Client Specification\", RFC 2054,\n     \
    \         DOI 10.17487/RFC2054, October 1996,\n              <https://www.rfc-editor.org/info/rfc2054>.\n\
    \   [50]       Callaghan, B., \"WebNFS Server Specification\", RFC 2055,\n   \
    \           DOI 10.17487/RFC2055, October 1996,\n              <https://www.rfc-editor.org/info/rfc2055>.\n\
    \   [51]       IESG, \"IESG Processing of RFC Errata for the IETF Stream\",\n\
    \              July 2008,\n              <https://www.ietf.org/about/groups/iesg/statements/\n\
    \              processing-rfc-errata/>.\n   [52]       Krawczyk, H., Bellare,\
    \ M., and R. Canetti, \"HMAC: Keyed-\n              Hashing for Message Authentication\"\
    , RFC 2104,\n              DOI 10.17487/RFC2104, February 1997,\n            \
    \  <https://www.rfc-editor.org/info/rfc2104>.\n   [53]       Shepler, S., \"NFS\
    \ Version 4 Design Considerations\",\n              RFC 2624, DOI 10.17487/RFC2624,\
    \ June 1999,\n              <https://www.rfc-editor.org/info/rfc2624>.\n   [54]\
    \       The Open Group, \"Protocols for Interworking: XNFS, Version\n        \
    \      3W\", ISBN 1-85912-184-5, February 1998.\n   [55]       Floyd, S. and V.\
    \ Jacobson, \"The Synchronization of\n              Periodic Routing Messages\"\
    , IEEE/ACM Transactions on\n              Networking, 2(2), pp. 122-136, April\
    \ 1994.\n   [56]       Chadalapaka, M., Satran, J., Meth, K., and D. Black,\n\
    \              \"Internet Small Computer System Interface (iSCSI) Protocol\n \
    \             (Consolidated)\", RFC 7143, DOI 10.17487/RFC7143, April\n      \
    \        2014, <https://www.rfc-editor.org/info/rfc7143>.\n   [57]       Snively,\
    \ R., \"Fibre Channel Protocol for SCSI, 2nd Version\n              (FCP-2)\"\
    , ANSI/INCITS, 350-2003, October 2003.\n   [58]       Weber, R.O., \"Object-Based\
    \ Storage Device Commands (OSD)\",\n              ANSI/INCITS, 400-2004, July\
    \ 2004,\n              <https://www.t10.org/drafts.htm>.\n   [59]       Carns,\
    \ P. H., Ligon III, W. B., Ross, R. B., and R.\n              Thakur, \"PVFS:\
    \ A Parallel File System for Linux\n              Clusters.\", Proceedings of\
    \ the 4th Annual Linux Showcase\n              and Conference, 2000.\n   [60]\
    \       The Open Group, \"The Open Group Base Specifications Issue\n         \
    \     6, IEEE Std 1003.1, 2004 Edition\", 2004,\n              <https://www.opengroup.org>.\n\
    \   [61]       Callaghan, B., \"NFS URL Scheme\", RFC 2224,\n              DOI\
    \ 10.17487/RFC2224, October 1997,\n              <https://www.rfc-editor.org/info/rfc2224>.\n\
    \   [62]       Chiu, A., Eisler, M., and B. Callaghan, \"Security\n          \
    \    Negotiation for WebNFS\", RFC 2755, DOI 10.17487/RFC2755,\n             \
    \ January 2000, <https://www.rfc-editor.org/info/rfc2755>.\n   [63]       Cotton,\
    \ M., Leiba, B., and T. Narten, \"Guidelines for\n              Writing an IANA\
    \ Considerations Section in RFCs\", BCP 26,\n              RFC 8126, DOI 10.17487/RFC8126,\
    \ June 2017,\n              <https://www.rfc-editor.org/info/rfc8126>.\n   [64]\
    \       RFC Errata, Erratum ID 2006, RFC 5661,\n              <https://www.rfc-editor.org/errata/eid2006>.\n\
    \   [65]       Spasojevic, M. and M. Satayanarayanan, \"An Empirical Study\n \
    \             of a Wide-Area Distributed File System\", ACM Transactions\n   \
    \           on Computer Systems, Vol. 14, No. 2, pp. 200-222,\n              DOI\
    \ 10.1145/227695.227698, May 1996,\n              <https://doi.org/10.1145/227695.227698>.\n\
    \   [66]       Shepler, S., Ed., Eisler, M., Ed., and D. Noveck, Ed.,\n      \
    \        \"Network File System (NFS) Version 4 Minor Version 1\n             \
    \ Protocol\", RFC 5661, DOI 10.17487/RFC5661, January 2010,\n              <https://www.rfc-editor.org/info/rfc5661>.\n\
    \   [67]       Noveck, D., \"Rules for NFSv4 Extensions and Minor\n          \
    \    Versions\", RFC 8178, DOI 10.17487/RFC8178, July 2017,\n              <https://www.rfc-editor.org/info/rfc8178>.\n\
    \   [68]       Haynes, T., Ed. and D. Noveck, Ed., \"Network File System\n   \
    \           (NFS) Version 4 Protocol\", RFC 7530, DOI 10.17487/RFC7530,\n    \
    \          March 2015, <https://www.rfc-editor.org/info/rfc7530>.\n   [69]   \
    \    Noveck, D., Ed., Shivam, P., Lever, C., and B. Baker,\n              \"NFSv4.0\
    \ Migration: Specification Update\", RFC 7931,\n              DOI 10.17487/RFC7931,\
    \ July 2016,\n              <https://www.rfc-editor.org/info/rfc7931>.\n   [70]\
    \       Haynes, T., \"Requirements for Parallel NFS (pNFS) Layout\n          \
    \    Types\", RFC 8434, DOI 10.17487/RFC8434, August 2018,\n              <https://www.rfc-editor.org/info/rfc8434>.\n\
    \   [71]       Farrell, S. and H. Tschofenig, \"Pervasive Monitoring Is an\n \
    \             Attack\", BCP 188, RFC 7258, DOI 10.17487/RFC7258, May\n       \
    \       2014, <https://www.rfc-editor.org/info/rfc7258>.\n   [72]       Rescorla,\
    \ E. and B. Korver, \"Guidelines for Writing RFC\n              Text on Security\
    \ Considerations\", BCP 72, RFC 3552,\n              DOI 10.17487/RFC3552, July\
    \ 2003,\n              <https://www.rfc-editor.org/info/rfc3552>.\n"
- title: Appendix A.  The Need for This Update
  contents:
  - "Appendix A.  The Need for This Update\n   This document includes an explanation\
    \ of how clients and servers are\n   to determine the particular network access\
    \ paths to be used to access\n   a file system.  This includes descriptions of\
    \ how to handle changes\n   to the specific replica to be used or to the set of\
    \ addresses to be\n   used to access it, and how to deal transparently with transfers\
    \ of\n   responsibility that need to be made.  This includes cases in which\n\
    \   there is a shift between one replica and another and those in which\n   different\
    \ network access paths are used to access the same replica.\n   As a result of\
    \ the following problems in RFC 5661 [66], it was\n   necessary to provide the\
    \ specific updates that are made by this\n   document.  These updates are described\
    \ in Appendix B.\n   *  RFC 5661 [66], while it dealt with situations in which\
    \ various\n      forms of clustering allowed coordination of the state assigned\
    \ by\n      cooperating servers to be used, made no provisions for Transparent\n\
    \      State Migration.  Within NFSv4.0, Transparent State Migration was\n   \
    \   first explained clearly in RFC 7530 [68] and corrected and\n      clarified\
    \ by RFC 7931 [69].  No corresponding explanation for\n      NFSv4.1 had been\
    \ provided.\n   *  Although NFSv4.1 provided a clear definition of how trunking\n\
    \      detection was to be done, there was no clear specification of how\n   \
    \   trunking discovery was to be done, despite the fact that the\n      specification\
    \ clearly indicated that this information could be\n      made available via the\
    \ file system location attributes.\n   *  Because the existence of multiple network\
    \ access paths to the same\n      file system was dealt with as if there were\
    \ multiple replicas,\n      issues relating to transitions between replicas could\
    \ never be\n      clearly distinguished from trunking-related transitions between\n\
    \      the addresses used to access a particular file system instance.\n     \
    \ As a result, in situations in which both migration and trunking\n      configuration\
    \ changes were involved, neither of these could be\n      clearly dealt with,\
    \ and the relationship between these two\n      features was not seriously addressed.\n\
    \   *  Because use of two network access paths to the same file system\n     \
    \ instance (i.e., trunking) was often treated as if two replicas\n      were involved,\
    \ it was considered that two replicas were being used\n      simultaneously. \
    \ As a result, the treatment of replicas being used\n      simultaneously in RFC\
    \ 5661 [66] was not clear, as it covered the\n      two distinct cases of a single\
    \ file system instance being accessed\n      by two different network access paths\
    \ and two replicas being\n      accessed simultaneously, with the limitations\
    \ of the latter case\n      not being clearly laid out.\n   The majority of the\
    \ consequences of these issues are dealt with by\n   presenting in Section 11\
    \ a replacement for Section 11 of RFC 5661\n   [66].  This replacement modifies\
    \ existing subsections within that\n   section and adds new ones as described\
    \ in Appendix B.1.  Also, some\n   existing sections were deleted.  These changes\
    \ were made in order to\n   do the following:\n   *  Reorganize the description\
    \ so that the case of two network access\n      paths to the same file system\
    \ instance is distinguished clearly\n      from the case of two different replicas\
    \ since, in the former case,\n      locking state is shared and there also can\
    \ be sharing of session\n      state.\n   *  Provide a clear statement regarding\
    \ the desirability of\n      transparent transfer of state between replicas together\
    \ with a\n      recommendation that either transparent transfer or a single-fs\n\
    \      grace period be provided.\n   *  Specifically delineate how a client is\
    \ to handle such transfers,\n      taking into account the differences from the\
    \ treatment in [69]\n      made necessary by the major protocol changes to NFSv4.1.\n\
    \   *  Discuss the relationship between transparent state transfer and\n     \
    \ Parallel NFS (pNFS).\n   *  Clarify the fs_locations_info attribute in order\
    \ to specify which\n      portions of the provided information apply to a specific\
    \ network\n      access path and which apply to the replica that the path is used\n\
    \      to access.\n   In addition, other sections of RFC 5661 [66] were updated\
    \ to correct\n   the consequences of the incorrect assumptions underlying the\n\
    \   treatment of multi-server namespace issues.  These are described in\n   Appendices\
    \ B.2 through B.4.\n   *  A revised introductory section regarding multi-server\
    \ namespace\n      facilities is provided.\n   *  A more realistic treatment of\
    \ server scope is provided.  This\n      treatment reflects the more limited coordination\
    \ of locking state\n      adopted by servers actually sharing a common server\
    \ scope.\n   *  Some confusing text regarding changes in server_owner has been\n\
    \      clarified.\n   *  The description of some existing errors has been modified\
    \ to more\n      clearly explain certain error situations to reflect the existence\n\
    \      of trunking and the possible use of fs-specific grace periods.\n      For\
    \ details, see Appendix B.3.\n   *  New descriptions of certain existing operations\
    \ are provided,\n      either because the existing treatment did not account for\n\
    \      situations that would arise in dealing with Transparent State\n      Migration,\
    \ or because some types of reclaim issues were not\n      adequately dealt with\
    \ in the context of fs-specific grace periods.\n      For details, see Appendix\
    \ B.2.\n"
- title: Appendix B.  Changes in This Update
  contents:
  - 'Appendix B.  Changes in This Update

    '
- title: B.1.  Revisions Made to Section 11 of RFC 5661
  contents:
  - "B.1.  Revisions Made to Section 11 of RFC 5661\n   A number of areas have been\
    \ revised or extended, in many cases\n   replacing subsections within Section\
    \ 11 of RFC 5661 [66]:\n   *  New introductory material, including a terminology\
    \ section,\n      replaces the material in RFC 5661 [66], ranging from the start\
    \ of\n      the original Section 11 up to and including Section 11.1.  The new\n\
    \      material starts at the beginning of Section 11 and continues\n      through\
    \ 11.2.\n   *  A significant reorganization of the material in Sections 11.4 and\n\
    \      11.5 of RFC 5661 [66] was necessary.  The reasons for the\n      reorganization\
    \ of these sections into a single section with\n      multiple subsections are\
    \ discussed in Appendix B.1.1 below.  This\n      replacement appears as Section\
    \ 11.5.\n      New material relating to the handling of the file system location\n\
    \      attributes is contained in Sections 11.5.1 and 11.5.7.\n   *  A new section\
    \ describing requirements for user and group handling\n      within a multi-server\
    \ namespace has been added as Section 11.7.\n   *  A major replacement for Section\
    \ 11.7 of RFC 5661 [66], entitled\n      \"Effecting File System Transitions\"\
    , appears as Sections 11.9\n      through 11.14.  The reasons for the reorganization\
    \ of this section\n      into multiple sections are discussed in Appendix B.1.2.\n\
    \   *  A replacement for Section 11.10 of RFC 5661 [66], entitled \"The\n    \
    \  Attribute fs_locations_info\", appears as Section 11.17, with\n      Appendix\
    \ B.1.3 describing the differences between the new section\n      and the treatment\
    \ within [66].  A revised treatment was necessary\n      because the original\
    \ treatment did not make clear how the added\n      attribute information relates\
    \ to the case of trunked paths to the\n      same replica.  These issues were\
    \ not addressed in RFC 5661 [66]\n      where the concepts of a replica and a\
    \ network path used to access\n      a replica were not clearly distinguished.\n"
- title: B.1.1.  Reorganization of Sections 11.4 and 11.5 of RFC 5661
  contents:
  - "B.1.1.  Reorganization of Sections 11.4 and 11.5 of RFC 5661\n   Previously,\
    \ issues related to the fact that multiple location entries\n   directed the client\
    \ to the same file system instance were dealt with\n   in Section 11.5 of RFC\
    \ 5661 [66].  Because of the new treatment of\n   trunking, these issues now belong\
    \ within Section 11.5.\n   In this new section, trunking is covered in Section\
    \ 11.5.2 together\n   with the other uses of file system location information\
    \ described in\n   Sections 11.5.3 through 11.5.6.\n   As a result, Section 11.5,\
    \ which replaces Section 11.4 of RFC 5661\n   [66], is substantially different\
    \ than the section it replaces in that\n   some original sections have been replaced\
    \ by corresponding sections\n   as described below, while new sections have been\
    \ added:\n   *  The material in Section 11.5, exclusive of subsections, replaces\n\
    \      the material in Section 11.4 of RFC 5661 [66] exclusive of\n      subsections.\n\
    \   *  Section 11.5.1 is the new first subsection of the overall section.\n  \
    \ *  Section 11.5.2 is the new second subsection of the overall\n      section.\n\
    \   *  Each of the Sections 11.5.4, 11.5.5, and 11.5.6 replaces (in\n      order)\
    \ one of the corresponding Sections 11.4.1, 11.4.2, and\n      11.4.3 of RFC 5661\
    \ [66].\n   *  Section 11.5.7 is the new final subsection of the overall section.\n"
- title: B.1.2.  Reorganization of Material Dealing with File System Transitions
  contents:
  - "B.1.2.  Reorganization of Material Dealing with File System Transitions\n   The\
    \ material relating to file system transition, previously contained\n   in Section\
    \ 11.7 of RFC 5661 [66] has been reorganized and augmented\n   as described below:\n\
    \   *  Because there can be a shift of the network access paths used to\n    \
    \  access a file system instance without any shift between replicas,\n      a\
    \ new Section 11.9 distinguishes between those cases in which\n      there is\
    \ a shift between distinct replicas and those involving a\n      shift in network\
    \ access paths with no shift between replicas.\n      As a result, the new Section\
    \ 11.10 deals with network address\n      transitions, while the bulk of the original\
    \ Section 11.7 of RFC\n      5661 [66] has been extensively modified as reflected\
    \ in\n      Section 11.11, which is now limited to cases in which there is a\n\
    \      shift between two different sets of replicas.\n   *  The additional Section\
    \ 11.12 discusses the case in which a shift\n      to a different replica is made\
    \ and state is transferred to allow\n      the client the ability to have continued\
    \ access to its accumulated\n      locking state on the new server.\n   *  The\
    \ additional Section 11.13 discusses the client's response to\n      access transitions,\
    \ how it determines whether migration has\n      occurred, and how it gets access\
    \ to any transferred locking and\n      session state.\n   *  The additional Section\
    \ 11.14 discusses the responsibilities of the\n      source and destination servers\
    \ when transferring locking and\n      session state.\n   This reorganization\
    \ has caused a renumbering of the sections within\n   Section 11 of [66] as described\
    \ below:\n   *  The new Sections 11.9 and 11.10 have resulted in the renumbering\n\
    \      of existing sections with these numbers.\n   *  Section 11.7 of [66] has\
    \ been substantially modified and appears\n      as Section 11.11.  The necessary\
    \ modifications reflect the fact\n      that this section only deals with transitions\
    \ between replicas,\n      while transitions between network addresses are dealt\
    \ with in\n      other sections.  Details of the reorganization are described\
    \ later\n      in this section.\n   *  Sections 11.12, 11.13, and 11.14 have been\
    \ added.\n   *  Consequently, Sections 11.8, 11.9, 11.10, and 11.11 in [66] now\n\
    \      appear as Sections 11.15, 11.16, 11.17, and 11.18, respectively.\n   As\
    \ part of this general reorganization, Section 11.7 of RFC 5661 [66]\n   has been\
    \ modified as described below:\n   *  Sections 11.7 and 11.7.1 of RFC 5661 [66]\
    \ have been replaced by\n      Sections 11.11 and 11.11.1, respectively.\n   *\
    \  Section 11.7.2 of RFC 5661 (and included subsections) has been\n      deleted.\n\
    \   *  Sections 11.7.3, 11.7.4, 11.7.5, 11.7.5.1, and 11.7.6 of RFC 5661\n   \
    \   [66] have been replaced by Sections 11.11.2, 11.11.3, 11.11.4,\n      11.11.4.1,\
    \ and 11.11.5 respectively in this document.\n   *  Section 11.7.7 of RFC 5661\
    \ [66] has been replaced by\n      Section 11.11.9.  This subsection has been\
    \ moved to the end of the\n      section dealing with file system transitions.\n\
    \   *  Sections 11.7.8, 11.7.9, and 11.7.10 of RFC 5661 [66] have been\n     \
    \ replaced by Sections 11.11.6, 11.11.7, and 11.11.8 respectively in\n      this\
    \ document.\n"
- title: B.1.3.  Updates to the Treatment of fs_locations_info
  contents:
  - "B.1.3.  Updates to the Treatment of fs_locations_info\n   Various elements of\
    \ the fs_locations_info attribute contain\n   information that applies to either\
    \ a specific file system replica or\n   to a network path or set of network paths\
    \ used to access such a\n   replica.  The original treatment of fs_locations_info\
    \ (Section 11.10\n   of RFC 5661 [66]) did not clearly distinguish these cases,\
    \ in part\n   because the document did not clearly distinguish replicas from the\n\
    \   paths used to access them.\n   In addition, special clarification has been\
    \ provided with regard to\n   the following fields:\n   *  With regard to the\
    \ handling of FSLI4GF_GOING, it was clarified\n      that this only applies to\
    \ the unavailability of a replica rather\n      than to a path to access a replica.\n\
    \   *  In describing the appropriate value for a server to use for\n      fli_valid_for,\
    \ it was clarified that there is no need for the\n      client to frequently fetch\
    \ the fs_locations_info value to be\n      prepared for shifts in trunking patterns.\n\
    \   *  Clarification of the rules for extensions to the fls_info has been\n  \
    \    provided.  The original treatment reflected the extension model\n      that\
    \ was in effect at the time RFC 5661 [66] was written, but has\n      been updated\
    \ in accordance with the extension model described in\n      RFC 8178 [67].\n"
- title: B.2.  Revisions Made to Operations in RFC 5661
  contents:
  - "B.2.  Revisions Made to Operations in RFC 5661\n   Descriptions have been revised\
    \ to address issues that arose in\n   effecting necessary changes to multi-server\
    \ namespace features.\n   *  The treatment of EXCHANGE_ID (Section 18.35 of RFC\
    \ 5661 [66])\n      assumed that client IDs cannot be created/confirmed other\
    \ than by\n      the EXCHANGE_ID and CREATE_SESSION operations.  Also, the\n \
    \     necessary use of EXCHANGE_ID in recovery from migration and\n      related\
    \ situations was not clearly addressed.  A revised treatment\n      of EXCHANGE_ID\
    \ was necessary, and it appears in Section 18.35,\n      while the specific differences\
    \ between it and the treatment within\n      [66] are explained in Appendix B.2.1\
    \ below.\n   *  The treatment of RECLAIM_COMPLETE in Section 18.51 of RFC 5661\n\
    \      [66] was not sufficiently clear about the purpose and use of the\n    \
    \  rca_one_fs and how the server was to deal with inappropriate\n      values\
    \ of this argument.  Because the resulting confusion raised\n      interoperability\
    \ issues, a new treatment of RECLAIM_COMPLETE was\n      necessary, and it appears\
    \ in Section 18.51, while the specific\n      differences between it and the treatment\
    \ within RFC 5661 [66] are\n      discussed in Appendix B.2.2 below.  In addition,\
    \ the definitions\n      of the reclaim-related errors have received an updated\
    \ treatment\n      in Section 15.1.9 to reflect the fact that there are multiple\n\
    \      contexts for lock reclaim operations.\n"
- title: B.2.1.  Revision of Treatment of EXCHANGE_ID
  contents:
  - "B.2.1.  Revision of Treatment of EXCHANGE_ID\n   There was a number of issues\
    \ in the original treatment of EXCHANGE_ID\n   in RFC 5661 [66] that caused problems\
    \ for Transparent State Migration\n   and for the transfer of access between different\
    \ network access paths\n   to the same file system instance.\n   These issues\
    \ arose from the fact that this treatment was written:\n   *  Assuming that a\
    \ client ID can only become known to a server by\n      having been created by\
    \ executing an EXCHANGE_ID, with confirmation\n      of the ID only possible by\
    \ execution of a CREATE_SESSION.\n   *  Considering the interactions between a\
    \ client and a server only\n      occurring on a single network address.\n   As\
    \ these assumptions have become invalid in the context of\n   Transparent State\
    \ Migration and active use of trunking, the treatment\n   has been modified in\
    \ several respects:\n   *  It had been assumed that an EXCHANGE_ID executed when\
    \ the server\n      was already aware that a given client instance was either\
    \ updating\n      associated parameters (e.g., with respect to callbacks) or dealing\n\
    \      with a previously lost reply by retransmitting.  As a result, any\n   \
    \   slot sequence returned by that operation would be of no use.  The\n      original\
    \ treatment went so far as to say that it \"MUST NOT\" be\n      used, although\
    \ this usage was not in accord with [1].  This\n      created a difficulty when\
    \ an EXCHANGE_ID is done after Transparent\n      State Migration since that slot\
    \ sequence would need to be used in\n      a subsequent CREATE_SESSION.\n    \
    \  In the updated treatment, CREATE_SESSION is a way that client IDs\n      are\
    \ confirmed, but it is understood that other ways are possible.\n      The slot\
    \ sequence can be used as needed, and cases in which it\n      would be of no\
    \ use are appropriately noted.\n   *  It had been assumed that the only functions\
    \ of EXCHANGE_ID were to\n      inform the server of the client, to create the\
    \ client ID, and to\n      communicate it to the client.  When multiple simultaneous\n\
    \      connections are involved, as often happens when trunking, that\n      treatment\
    \ was inadequate in that it ignored the role of\n      EXCHANGE_ID in associating\
    \ the client ID with the connection on\n      which it was done, so that it could\
    \ be used by a subsequent\n      CREATE_SESSION whose parameters do not include\
    \ an explicit client\n      ID.\n      The new treatment explicitly discusses\
    \ the role of EXCHANGE_ID in\n      associating the client ID with the connection\
    \ so it can be used by\n      CREATE_SESSION and in associating a connection with\
    \ an existing\n      session.\n   The new treatment can be found in Section 18.35\
    \ above.  It supersedes\n   the treatment in Section 18.35 of RFC 5661 [66].\n"
- title: B.2.2.  Revision of Treatment of RECLAIM_COMPLETE
  contents:
  - "B.2.2.  Revision of Treatment of RECLAIM_COMPLETE\n   The following changes were\
    \ made to the treatment of RECLAIM_COMPLETE\n   in RFC 5661 [66] to arrive at\
    \ the treatment in Section 18.51:\n   *  In a number of places, the text was made\
    \ more explicit about the\n      purpose of rca_one_fs and its connection to file\
    \ system migration.\n   *  There is a discussion of situations in which particular\
    \ forms of\n      RECLAIM_COMPLETE would need to be done.\n   *  There is a discussion\
    \ of interoperability issues between\n      implementations that may have arisen\
    \ due to the lack of clarity of\n      the previous treatment of RECLAIM_COMPLETE.\n"
- title: B.3.  Revisions Made to Error Definitions in RFC 5661
  contents:
  - "B.3.  Revisions Made to Error Definitions in RFC 5661\n   The new handling of\
    \ various situations required revisions to some\n   existing error definitions:\n\
    \   *  Because of the need to appropriately address trunking-related\n      issues,\
    \ some uses of the term \"replica\" in RFC 5661 [66] became\n      problematic\
    \ because a shift in network access paths was considered\n      to be a shift\
    \ to a different replica.  As a result, the original\n      definition of NFS4ERR_MOVED\
    \ (in Section 15.1.2.4 of RFC 5661 [66])\n      was updated to reflect the different\
    \ handling of unavailability of\n      a particular fs via a specific network\
    \ address.\n      Since such a situation is no longer considered to constitute\n\
    \      unavailability of a file system instance, the description has been\n  \
    \    changed, even though the set of circumstances in which it is to be\n    \
    \  returned remains the same.  The new paragraph explicitly\n      recognizes\
    \ that a different network address might be used, while\n      the previous description,\
    \ misleadingly, treated this as a shift\n      between two replicas while only\
    \ a single file system instance\n      might be involved.  The updated description\
    \ appears in\n      Section 15.1.2.4.\n   *  Because of the need to accommodate\
    \ the use of fs-specific grace\n      periods, it was necessary to clarify some\
    \ of the definitions of\n      reclaim-related errors in Section 15 of RFC 5661\
    \ [66] so that the\n      text applies properly to reclaims for all types of grace\
    \ periods.\n      The updated descriptions appear within Section 15.1.9.\n   *\
    \  Because of the need to provide the clarifications in errata report\n      2006\
    \ [64] and to adapt these to properly explain the interaction\n      of NFS4ERR_DELAY\
    \ with the reply cache, a revised description of\n      NFS4ERR_DELAY appears\
    \ in Section 15.1.1.3.  This errata report,\n      unlike many other RFC 5661\
    \ errata reports, is addressed in this\n      document because of the extensive\
    \ use of NFS4ERR_DELAY in\n      connection with state migration and session migration.\n"
- title: B.4.  Other Revisions Made to RFC 5661
  contents:
  - "B.4.  Other Revisions Made to RFC 5661\n   Besides the major reworking of Section\
    \ 11 of RFC 5661 [66] and the\n   associated revisions to existing operations\
    \ and errors, there were a\n   number of related changes that were necessary:\n\
    \   *  The summary in Section 1.7.3.3 of RFC 5661 [66] was revised to\n      reflect\
    \ the changes made to Section 11 above.  The updated summary\n      appears as\
    \ Section 1.8.3.3 above.\n   *  The discussion of server scope in Section 2.10.4\
    \ of RFC 5661 [66]\n      was replaced since it appeared to require a level of\
    \ inter-server\n      coordination incompatible with its basic function of avoiding\
    \ the\n      need for a globally uniform means of assigning server_owner\n   \
    \   values.  A revised treatment appears in Section 2.10.4.\n   *  The discussion\
    \ of trunking in Section 2.10.5 of RFC 5661 [66] was\n      revised to more clearly\
    \ explain the multiple types of trunking\n      support and how the client can\
    \ be made aware of the existing\n      trunking configuration.  In addition, while\
    \ the last paragraph\n      (exclusive of subsections) of that section dealing\
    \ with\n      server_owner changes was literally true, it had been a source of\n\
    \      confusion.  Since the original paragraph could be read as\n      suggesting\
    \ that such changes be handled nondisruptively, the issue\n      was clarified\
    \ in the revised Section 2.10.5.\n"
- title: Appendix C.  Security Issues That Need to Be Addressed
  contents:
  - "Appendix C.  Security Issues That Need to Be Addressed\n   The following issues\
    \ in the treatment of security within the NFSv4.1\n   specification need to be\
    \ addressed:\n   *  The Security Considerations Section of RFC 5661 [66] was not\n\
    \      written in accordance with RFC 3552 (BCP 72) [72].  Of particular\n   \
    \   concern was the fact that the section did not contain a threat\n      analysis.\n\
    \   *  Initial analysis of the existing security issues with NFSv4.1 has\n   \
    \   made it likely that a revised Security Considerations section for\n      the\
    \ existing protocol (one containing a threat analysis) would be\n      likely\
    \ to conclude that NFSv4.1 does not meet the goal of secure\n      use on the\
    \ Internet.\n   The Security Considerations section of this document (Section\
    \ 21) has\n   not been thoroughly revised to correct the difficulties mentioned\n\
    \   above.  Instead, it has been modified to take proper account of\n   issues\
    \ related to the multi-server namespace features discussed in\n   Section 11,\
    \ leaving the incomplete discussion and security weaknesses\n   pretty much as\
    \ they were.\n   The following major security issues need to be addressed in a\n\
    \   satisfactory fashion before an updated Security Considerations\n   section\
    \ can be published as part of a bis document for NFSv4.1:\n   *  The continued\
    \ use of AUTH_SYS and the security exposures it\n      creates need to be addressed.\
    \  Addressing this issue must not be\n      limited to the questions of whether\
    \ the designation of this as\n      OPTIONAL was justified and whether it should\
    \ be changed.\n      In any event, it may not be possible at this point to correct\
    \ the\n      security problems created by continued use of AUTH_SYS simply by\n\
    \      revising this designation.\n   *  The lack of attention within the protocol\
    \ to the possibility of\n      pervasive monitoring attacks such as those described\
    \ in RFC 7258\n      [71] (also BCP 188).\n      In that connection, the use of\
    \ CREATE_SESSION without privacy\n      protection needs to be addressed as it\
    \ exposes the session ID to\n      view by an attacker.  This is worrisome as\
    \ this is precisely the\n      type of protocol artifact alluded to in RFC 7258,\
    \ which can enable\n      further mischief on the part of the attacker as it enables\
    \ denial-\n      of-service attacks that can be executed effectively with only\
    \ a\n      single, normally low-value, credential, even when RPCSEC_GSS\n    \
    \  authentication is in use.\n   *  The lack of effective use of privacy and integrity,\
    \ even where the\n      infrastructure to support use of RPCSEC_GSS is present,\
    \ needs to\n      be addressed.\n      In light of the security exposures that\
    \ this situation creates, it\n      is not enough to define a protocol that could\
    \ address this problem\n      with the provision of sufficient resources.  Instead,\
    \ what is\n      needed is a way to provide the necessary security with very\n\
    \      limited performance costs and without requiring security\n      infrastructure,\
    \ which experience has shown is difficult for many\n      clients and servers\
    \ to provide.\n   In trying to provide a major security upgrade for a deployed\
    \ protocol\n   such as NFSv4.1, the working group and the Internet community are\n\
    \   likely to find themselves dealing with a number of considerations\n   such\
    \ as the following:\n   *  The need to accommodate existing deployments of protocols\n\
    \      specified previously in existing Proposed Standards.\n   *  The difficulty\
    \ of effecting changes to existing, interoperating\n      implementations.\n \
    \  *  The difficulty of making changes to NFSv4 protocols other than\n      those\
    \ in the form of OPTIONAL extensions.\n   *  The tendency of those responsible\
    \ for existing NFSv4 deployments\n      to ignore security flaws in the context\
    \ of local area networks\n      under the mistaken impression that network isolation\
    \ provides, in\n      and of itself, isolation from all potential attackers.\n\
    \   Given that the above-mentioned difficulties apply to minor version\n   zero\
    \ as well, it may make sense to deal with these security issues in\n   a common\
    \ document that applies to all NFSv4 minor versions.  If that\n   approach is\
    \ taken, the Security Considerations section of an eventual\n   NFv4.1 bis document\
    \ would reference that common document, and the\n   defining RFCs for other minor\
    \ versions might do so as well.\n"
- title: Acknowledgments
  contents:
  - 'Acknowledgments

    '
- title: Acknowledgments for This Update
  contents:
  - "Acknowledgments for This Update\n   The authors wish to acknowledge the important\
    \ role of Andy Adamson of\n   Netapp in clarifying the need for trunking discovery\
    \ functionality,\n   and exploring the role of the file system location attributes\
    \ in\n   providing the necessary support.\n   The authors wish to thank Tom Haynes\
    \ of Hammerspace for drawing our\n   attention to the fact that internationalization\
    \ and security might\n   best be handled in documents dealing with such protocol\
    \ issues as\n   they apply to all NFSv4 minor versions.\n   The authors also wish\
    \ to acknowledge the work of Xuan Qi of Oracle\n   with NFSv4.1 client and server\
    \ prototypes of Transparent State\n   Migration functionality.\n   The authors\
    \ wish to thank others that brought attention to important\n   issues.  The comments\
    \ of Trond Myklebust of Primary Data related to\n   trunking helped to clarify\
    \ the role of DNS in trunking discovery.\n   Rick Macklem's comments brought attention\
    \ to problems in the handling\n   of the per-fs version of RECLAIM_COMPLETE.\n\
    \   The authors wish to thank Olga Kornievskaia of Netapp for her helpful\n  \
    \ review comments.\n"
- title: Acknowledgments for RFC 5661
  contents:
  - "Acknowledgments for RFC 5661\n   The initial text for the SECINFO extensions\
    \ were edited by Mike\n   Eisler with contributions from Peng Dai, Sergey Klyushin,\
    \ and Carl\n   Burnett.\n   The initial text for the SESSIONS extensions were\
    \ edited by Tom\n   Talpey, Spencer Shepler, Jon Bauman with contributions from\
    \ Charles\n   Antonelli, Brent Callaghan, Mike Eisler, John Howard, Chet Juszczak,\n\
    \   Trond Myklebust, Dave Noveck, John Scott, Mike Stolarchuk, and Mark\n   Wittle.\n\
    \   Initial text relating to multi-server namespace features, including\n   the\
    \ concept of referrals, were contributed by Dave Noveck, Carl\n   Burnett, and\
    \ Charles Fan with contributions from Ted Anderson, Neil\n   Brown, and Jon Haswell.\n\
    \   The initial text for the Directory Delegations support were\n   contributed\
    \ by Saadia Khan with input from Dave Noveck, Mike Eisler,\n   Carl Burnett, Ted\
    \ Anderson, and Tom Talpey.\n   The initial text for the ACL explanations were\
    \ contributed by Sam\n   Falkner and Lisa Week.\n   The pNFS work was inspired\
    \ by the NASD and OSD work done by Garth\n   Gibson.  Gary Grider has also been\
    \ a champion of high-performance\n   parallel I/O.  Garth Gibson and Peter Corbett\
    \ started the pNFS effort\n   with a problem statement document for the IETF that\
    \ formed the basis\n   for the pNFS work in NFSv4.1.\n   The initial text for\
    \ the parallel NFS support was edited by Brent\n   Welch and Garth Goodson.  Additional\
    \ authors for those documents were\n   Benny Halevy, David Black, and Andy Adamson.\
    \  Additional input came\n   from the informal group that contributed to the construction\
    \ of the\n   initial pNFS drafts; specific acknowledgment goes to Gary Grider,\n\
    \   Peter Corbett, Dave Noveck, Peter Honeyman, and Stephen Fridella.\n   Fredric\
    \ Isaman found several errors in draft versions of the ONC RPC\n   XDR description\
    \ of the NFSv4.1 protocol.\n   Audrey Van Belleghem provided, in numerous ways,\
    \ essential\n   coordination and management of the process of editing the\n  \
    \ specification documents.\n   Richard Jernigan gave feedback on the file layout's\
    \ striping pattern\n   design.\n   Several formal inspection teams were formed\
    \ to review various areas\n   of the protocol.  All the inspections found significant\
    \ errors and\n   room for improvement.  NFSv4.1's inspection teams were:\n   *\
    \  ACLs, with the following inspectors: Sam Falkner, Bruce Fields,\n      Rahul\
    \ Iyer, Saadia Khan, Dave Noveck, Lisa Week, Mario Wurzl, and\n      Alan Yoder.\n\
    \   *  Sessions, with the following inspectors: William Brown, Tom\n      Doeppner,\
    \ Robert Gordon, Benny Halevy, Fredric Isaman, Rick\n      Macklem, Trond Myklebust,\
    \ Dave Noveck, Karen Rochford, John Scott,\n      and Peter Shah.\n   *  Initial\
    \ pNFS inspection, with the following inspectors: Andy\n      Adamson, David Black,\
    \ Mike Eisler, Marc Eshel, Sam Falkner, Garth\n      Goodson, Benny Halevy, Rahul\
    \ Iyer, Trond Myklebust, Spencer\n      Shepler, and Lisa Week.\n   *  Global\
    \ namespace, with the following inspectors: Mike Eisler, Dan\n      Ellard, Craig\
    \ Everhart, Fredric Isaman, Trond Myklebust, Dave\n      Noveck, Theresa Raj,\
    \ Spencer Shepler, Renu Tewari, and Robert\n      Thurlow.\n   *  NFSv4.1 file\
    \ layout type, with the following inspectors: Andy\n      Adamson, Marc Eshel,\
    \ Sam Falkner, Garth Goodson, Rahul Iyer, Trond\n      Myklebust, and Lisa Week.\n\
    \   *  NFSv4.1 locking and directory delegations, with the following\n      inspectors:\
    \ Mike Eisler, Pranoop Erasani, Robert Gordon, Saadia\n      Khan, Eric Kustarz,\
    \ Dave Noveck, Spencer Shepler, and Amy Weaver.\n   *  EXCHANGE_ID and DESTROY_CLIENTID,\
    \ with the following inspectors:\n      Mike Eisler, Pranoop Erasani, Robert Gordon,\
    \ Benny Halevy, Fredric\n      Isaman, Saadia Khan, Ricardo Labiaga, Rick Macklem,\
    \ Trond\n      Myklebust, Spencer Shepler, and Brent Welch.\n   *  Final pNFS\
    \ inspection, with the following inspectors: Andy\n      Adamson, Mike Eisler,\
    \ Mark Eshel, Sam Falkner, Jason Glasgow,\n      Garth Goodson, Robert Gordon,\
    \ Benny Halevy, Dean Hildebrand, Rahul\n      Iyer, Suchit Kaura, Trond Myklebust,\
    \ Anatoly Pinchuk, Spencer\n      Shepler, Renu Tewari, Lisa Week, and Brent Welch.\n\
    \   A review team worked together to generate the tables of assignments\n   of\
    \ error sets to operations and make sure that each such assignment\n   had two\
    \ or more people validating it.  Participating in the process\n   were Andy Adamson,\
    \ Mike Eisler, Sam Falkner, Garth Goodson, Robert\n   Gordon, Trond Myklebust,\
    \ Dave Noveck, Spencer Shepler, Tom Talpey,\n   Amy Weaver, and Lisa Week.\n \
    \  Jari Arkko, David Black, Scott Bradner, Lisa Dusseault, Lars Eggert,\n   Chris\
    \ Newman, and Tim Polk provided valuable review and guidance.\n   Olga Kornievskaia\
    \ found several errors in the SSV specification.\n   Ricardo Labiaga found several\
    \ places where the use of RPCSEC_GSS was\n   underspecified.\n   Those who provided\
    \ miscellaneous comments include: Andy Adamson,\n   Sunil Bhargo, Alex Burlyga,\
    \ Pranoop Erasani, Bruce Fields, Vadim\n   Finkelstein, Jason Goldschmidt, Vijay\
    \ K. Gurbani, Sergey Klyushin,\n   Ricardo Labiaga, James Lentini, Anshul Madan,\
    \ Daniel Muntz, Daniel\n   Picken, Archana Ramani, Jim Rees, Mahesh Siddheshwar,\
    \ Tom Talpey, and\n   Peter Varga.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   David Noveck (editor)\n   NetApp\n   1601 Trapelo Road,\
    \ Suite 16\n   Waltham, MA 02451\n   United States of America\n   Phone: +1-781-768-5347\n\
    \   Email: dnoveck@netapp.com\n   Charles Lever\n   Oracle Corporation\n   1015\
    \ Granger Avenue\n   Ann Arbor, MI 48104\n   United States of America\n"
