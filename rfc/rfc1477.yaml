- title: __initial_text__
  contents:
  - '                      IDPR as a Proposed Standard

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard.  Distribution of this memo is\n\
    \   unlimited.\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document contains a discussion of inter-domain policy\
    \ routing\n   (IDPR), including an overview of functionality and a discussion\
    \ of\n   experiments.  The objective of IDPR is to construct and maintain\n  \
    \ routes between source and destination administrative domains, that\n   provide\
    \ user traffic with the services requested within the\n   constraints stipulated\
    \ for the domains transited.\n   Four documents describe IDPR in detail:\n   \
    \   M. Steenstrup.  An architecture for inter-domain policy routing.\n      RFC\
    \ 1478.  July 1993.\n      M. Steenstrup.  Inter-domain policy routing protocol\n\
    \      specification: version 1.  RFC 1479.  July 1993.\n      H. Bowns and M.\
    \ Steenstrup.  Inter-domain policy routing\n      configuration and usage.  Work\
    \ in Progress.  July 1991.\n      R. Woodburn.  Definitions of managed objects\
    \ for inter-domain\n      policy routing (version 1).  Work in Progress.  March\
    \ 1993.\n   This is a product of the Inter-Domain Policy Routing Working Group\
    \ of\n   the Internet Engineering Task Force (IETF).\n"
- title: 2.  The Internet Environment
  contents:
  - "2.  The Internet Environment\n   As data communications technologies evolve and\
    \ user populations grow,\n   the demand for internetworking increases.  The Internet\
    \ currently\n   comprises over 7000 operational networks and over 10,000 registered\n\
    \   networks.  In fact, for the last several years, the number of\n   constituent\
    \ networks has approximately doubled annually.  Although we\n   do not expect\
    \ the Internet to sustain this growth rate, we must\n   prepare for the Internet\
    \ of five to ten years in the future.\n   Internet connectivity has increased\
    \ along with the number of\n   component networks.  Internetworks proliferate\
    \ through\n   interconnection of autonomous, heterogeneous networks administered\
    \ by\n   separate authorities.  We use the term \"administrative domain\" (AD)\n\
    \   to refer to any collection of contiguous networks, gateways, links,\n   and\
    \ hosts governed by a single administrative authority that selects\n   the intra-domain\
    \ routing procedures and addressing schemes, specifies\n   service restrictions\
    \ for transit traffic, and defines service\n   requirements for locally-generated\
    \ traffic.\n   In the early 1980s, the Internet was purely hierarchical, with\
    \ the\n   ARPANET as the single backbone.  The current Internet possesses a\n\
    \   semblance of a hierarchy in the collection of backbone, regional,\n   metropolitan,\
    \ and campus domains that compose it.  However,\n   technological, economical,\
    \ and political incentives have prompted the\n   introduction of inter-domain\
    \ links outside of those in the strict\n   hierarchy.  Hence, the Internet has\
    \ the properties of both\n   hierarchical and mesh connectivity.\n   We expect\
    \ that, over the next five years, the Internet will grow to\n   contain O(10)\
    \ backbone domains, most providing connectivity between\n   many source and destination\
    \ domains and offering a wide range of\n   qualities of service, for a fee.  Most\
    \ domains will connect directly\n   or indirectly to at least one Internet backbone\
    \ domain, in order to\n   communicate with other domains.  In addition, some domains\
    \ may\n   install direct links to their most favored destinations.  Domains at\n\
    \   the lower levels of the hierarchy will provide some transit service,\n   limited\
    \ to traffic between selected sources and destinations.\n   However, the majority\
    \ of Internet domains will be \"stubs\", that is,\n   domains that do not provide\
    \ any transit service for any other domains\n   but that connect directly to one\
    \ or more transit domains.\n   The bulk of Internet traffic will be generated\
    \ by hosts in the stub\n   domains, and thus, the applications running in these\
    \ hosts will\n   determine the traffic service requirements.  We expect application\n\
    \   diversity encompassing electronic mail, desktop videoconferencing,\n   scientific\
    \ visualization, and distributed simulation, for example.\n   Many of these applications\
    \ have strict requirements on loss, delay,\n   and throughput.\n   In such a large\
    \ and heterogeneous Internet, the routing procedures\n   must be capable of ensuring\
    \ that traffic is forwarded along routes\n   that offer the required services\
    \ without violating domain usage\n   restrictions.  We believe that IDPR meets\
    \ this goal; it has been\n   designed to accommodate an Internet comprising O(10,000)\n\
    \   administrative domains with diverse service offerings and\n   requirements.\n"
- title: 3.  An Overview of IDPR
  contents:
  - "3.  An Overview of IDPR\n   IDPR generates, establishes, and maintains \"policy\
    \ routes\" that\n   satisfy the service requirements of the users and respect\
    \ the service\n   restrictions of the transit domains.  Policy routes are constructed\n\
    \   using information about the services offered by and the connectivity\n   between\
    \ administrative domains and information about the services\n   requested by the\
    \ users.\n"
- title: 3.1  Policies
  contents:
  - "3.1  Policies\n   With IDPR, each domain administrator sets \"transit policies\"\
    \ that\n   dictate how and by whom the resources in its domain should be used.\n\
    \   Transit policies are usually public, and they specify offered\n   services\
    \ comprising:\n   - Access restrictions: e.g., applied to traffic to or from certain\n\
    \     domains or classes of users.\n   - Quality: e.g., delay, throughput, or\
    \ error characteristics.\n   - Monetary cost: e.g., charge per byte, message,\
    \ or session time.\n   Each domain administrator also sets \"source policies\"\
    \ for traffic\n   originating in its domain.  Source policies are usually private,\
    \ and\n   they specify requested services comprising:\n   - Access: e.g., domains\
    \ to favor or avoid in routes.\n   - Quality: e.g., acceptable delay, throughput,\
    \ and reliability.\n   - Monetary cost: e.g., acceptable cost per byte, message,\
    \ or session\n     time.\n"
- title: 3.2  Functions
  contents:
  - "3.2  Functions\n   The basic IDPR functions include:\n   - Collecting and distributing\
    \ routing information, i.e., domain\n     transit policy and connectivity information.\
    \  IDPR uses link state\n     routing information distribution, so that each source\
    \ domain may\n     obtain routing information about all other domains.\n   - Generating\
    \ and selecting policy routes based on the routing\n     information distributed\
    \ and on source policy information.  IDPR\n     gives each source domain complete\
    \ control over the routes it\n     generates.\n   - Setting up paths across the\
    \ Internet, using the policy routes\n     generated.\n   - Forwarding messages\
    \ across and between administrative domains along\n     the established paths.\
    \  IDPR uses source-specified message\n     forwarding, giving each source domain\
    \ complete control over the\n     paths traversed by its hosts' inter-domain traffic.\n\
    \   - Maintaining databases of routing information, inter-domain policy\n    \
    \ routes, forwarding information, and configuration information.\n"
- title: 3.3  Entities
  contents:
  - "3.3  Entities\n   Several different entities are responsible for performing the\
    \ IDPR\n   functions:\n   - \"Policy gateways\", the only IDPR-recognized connecting\
    \ points\n     between adjacent domains, collect and distribute routing\n    \
    \ information, participate in path setup, maintain forwarding\n     information\
    \ databases, and forward data messages along established\n     paths.\n   - \"\
    Path agents\", resident within policy gateways, act on behalf of\n     hosts to\
    \ select policy routes, to set up and manage paths, and to\n     maintain forwarding\
    \ information databases.  Any Internet host can\n     reap the benefits of IDPR,\
    \ as long as there exists a path agent\n     willing to act on its behalf and\
    \ a means by which the host's\n     messages can reach that path agent.\n   -\
    \ Special-purpose servers maintain all other IDPR databases as\n     follows:\n\
    \      o  Each \"route server\" is responsible for both its database of\n    \
    \     routing information, including domain connectivity and transit\n       \
    \  policy information, and its database of policy routes.  Also,\n         each\
    \ route server generates policy routes on behalf of its\n         domain, using\
    \ entries from its routing information database\n         and using source policy\
    \ information supplied through\n         configuration or obtained directly from\
    \ the path agents.  A\n         route server may reside within a policy gateway,\
    \ or it may\n         exist as an autonomous entity.  Separating the route server\n\
    \         functions from the policy gateways frees the policy gateways\n     \
    \    from both the memory intensive task of routing information\n         database\
    \ and route database maintenance and the\n         computationally intensive task\
    \ of route generation.\n      o  Each \"mapping server\" is responsible for its\
    \ database of\n         mappings that resolve Internet names and addresses to\n\
    \         administrative domains.  The mapping server function can be\n      \
    \   easily integrated into an existing name service such as the\n         DNS.\n\
    \      o  Each \"configuration server\" is responsible for its database of\n \
    \        configured information that applies to policy gateways, path\n      \
    \   agents, and route servers in the given administrative domain.\n         Configuration\
    \ information for a given domain includes source\n         and transit policies\
    \ and mappings between local IDPR entities\n         and their addresses.  The\
    \ configuration server function can be\n         easily integrated into a domain's\
    \ existing network management\n         system.\n"
- title: 3.4  Message Handling
  contents:
  - "3.4  Message Handling\n   There are two kinds of IDPR messages:\n   - \"Data\
    \ messages\" containing user data generated by hosts.\n   - \"Control messages\"\
    \ containing IDPR protocol-related control\n     information generated by policy\
    \ gateways and route servers.\n   Within the Internet, only policy gateways and\
    \ route servers must be\n   able to generate, recognize, and process IDPR messages.\
    \  Mapping\n   servers and configuration servers perform necessary but ancillary\n\
    \   functions for IDPR, and they are not required to execute IDPR\n   protocols.\
    \  The existence of IDPR is invisible to all other gateways\n   and hosts.  Using\
    \ encapsulation across each domain, an IDPR message\n   tunnels from source to\
    \ destination across the Internet through\n   domains that may employ disparate\
    \ intra-domain addressing schemes and\n   routing procedures.\n"
- title: 4.  Security
  contents:
  - "4.  Security\n   IDPR contains mechanisms for verifying message integrity and\
    \ source\n   authenticity and for protecting against certain types of denial of\n\
    \   service attacks.  It is particularly important to keep IDPR control\n   messages\
    \ intact, because they carry control information critical to\n   the construction\
    \ and use of viable policy routes between domains.\n"
- title: 4.1  Integrity and Authenticity
  contents:
  - "4.1  Integrity and Authenticity\n   All IDPR messages carry a single piece of\
    \ information, referred to in\n   the IDPR documentation as the \"integrity/authentication\
    \ value\", which\n   may be used not only to detect message corruption but also\
    \ to verify\n   the authenticity of the message's source IDPR entity.  The Internet\n\
    \   Assigned Numbers Authority (IANA) specifies the set of valid\n   algorithms\
    \ which may be used to compute the integrity/authentication\n   values.  This\
    \ set may include algorithms that perform only message\n   integrity checks such\
    \ as n-bit cyclic redundancy checksums (CRCs), as\n   well as algorithms that\
    \ perform both message integrity and source\n   authentication checks such as\
    \ signed hash functions of message\n   contents.\n   Each domain administrator\
    \ is free to select any\n   integrity/authentication algorithm, from the set specified\
    \ by the\n   IANA, for computing the integrity/authentication values contained\
    \ in\n   its domain's messages.  However, we recommend that IDPR entities in\n\
    \   each domain be capable of executing all of the valid algorithms so\n   that\
    \ an IDPR message originating at an entity in one domain can be\n   properly checked\
    \ by an entity in another domain.\n   IDPR control messages must carry a non-null\
    \ integrity/authentication\n   value.  We recommend that control message integrity/authentication\
    \ be\n   based on a digital signature algorithm applied to a one-way hash\n  \
    \ function, such as RSA applied to MD5, which simultaneously verifies\n   message\
    \ integrity and source authenticity.  The digital signature may\n   be based on\
    \ either public key or private key cryptography.  However,\n   we do not require\
    \ that IDPR data messages carry a non-null\n   integrity/authentication value.\
    \  In fact, we recommend that a higher\n   layer (end-to-end) procedure assume\
    \ responsibility for checking the\n   integrity and authenticity of data messages,\
    \ because of the amount of\n   computation involved.\n"
- title: 4.2  Timestamps
  contents:
  - "4.2  Timestamps\n   Each IDPR message carries a timestamp (expressed in seconds\
    \ elapsed\n   since 1 January 1970 0:00 GMT) supplied by the source IDPR entity,\n\
    \   which serves to indicate the age of the message.  IDPR entities use\n   the\
    \ absolute value of a timestamp to confirm that the message is\n   current and\
    \ use the relative difference between timestamps to\n   determine which message\
    \ contains the most recent information.  All\n   IDPR entities must possess internal\
    \ clocks that are synchronized to\n   some degree, in order for the absolute value\
    \ of a message timestamp\n   to be meaningful.  The synchronization granularity\
    \ required by IDPR\n   is on the order of minutes and can be achieved manually.\n\
    \   Each IDPR recipient of an IDPR control message must check that the\n   message's\
    \ timestamp is in the acceptable range.  A message whose\n   timestamp lies outside\
    \ of the acceptable range may contain stale or\n   corrupted information or may\
    \ have been issued by a source whose clock\n   has lost synchronization with the\
    \ message recipient.  Such messages\n   must therefore be discarded, to prevent\
    \ propagation of incorrect IDPR\n   control information.  We do not require IDPR\
    \ entities to perform a\n   timestamp acceptability test for IDPR data messages,\
    \ but instead\n   leave the choice to the individual domain administrators.\n"
- title: 5.  Size Considerations
  contents:
  - "5.  Size Considerations\n   IDPR provides policy routing among administrative\
    \ domains and has\n   been designed to accommodate an Internet containing tens\
    \ of thousands\n   of domains, supporting diverse source and transit policies.\n\
    \   In order to construct policy routes, route servers require routing\n   information\
    \ at the domain level only; no intra-domain details need be\n   included in IDPR\
    \ routing information.  Thus, the size of the routing\n   information database\
    \ maintained by a route server depends on the\n   number of domains and transit\
    \ policies and not on the number hosts,\n   gateways, or networks in the Internet.\n\
    \   We expect that, within a domain, a pair of IDPR entities will\n   normally\
    \ be connected such that when the primary intra-domain route\n   fails, the intra-domain\
    \ routing procedure will be able to use an\n   alternate route.  In this case,\
    \ a temporary intra-domain failure is\n   invisible at the inter-domain level.\
    \  Thus, we expect that most\n   intra-domain routing changes will be unlikely\
    \ to force inter-domain\n   routing changes.\n   Policy gateways distribute routing\
    \ information when detectable\n   inter-domain changes occur but may also elect\
    \ to distribute routing\n   information periodically as a backup.  Thus, policy\
    \ gateways do not\n   often need to generate and distribute routing information\
    \ messages,\n   and the frequency of distribution of these messages depends only\n\
    \   weakly on intra-domain routing changes.\n   IDPR entities rely on intra-domain\
    \ routing procedures operating\n   within domains to transport inter-domain messages\
    \ across domains.\n   Hence, IDPR messages must appear well-formed according to\
    \ the intra-\n   domain routing procedures and addressing schemes in each domain\n\
    \   traversed; this requires appropriate header encapsulation of IDPR\n   messages\
    \ at domain boundaries.  Only policy gateways and route\n   servers must be capable\
    \ of handling IDPR-specific messages; other\n   gateways and hosts simply treat\
    \ the encapsulated IDPR messages like\n   any other.  Thus, for the Internet to\
    \ support IDPR, only a small\n   proportion of Internet entities require special\
    \ IDPR software.\n   With domain-level routes, many different traffic flows may\
    \ use not\n   only the same policy route but also the same path, as long their\n\
    \   source domains, destination domains, and requested services are\n   identical.\
    \  Thus, the size of the forwarding information database\n   maintained by a policy\
    \ gateway depends on the number of domains and\n   source policies and not on\
    \ the number of hosts in the Internet.\n   Moreover, memory associated with failed,\
    \ expired, or disused paths\n   can be reclaimed for new paths, and thus forwarding\
    \ information for\n   many paths can be accommodated.\n"
- title: 6.  Interactions with Other Inter-Domain Routing Procedures
  contents:
  - "6.  Interactions with Other Inter-Domain Routing Procedures\n   We believe that\
    \ many Internet domains will benefit from the\n   introduction of IDPR.  However,\
    \ the decision to support IDPR in a\n   given domain is an individual one, left\
    \ to the domain administrator;\n   not all domains must support IDPR.\n   Within\
    \ a domain that supports IDPR, other inter-domain routing\n   procedures, such\
    \ as BGP and EGP, can comfortably coexist.  Each\n   inter-domain routing procedure\
    \ is independent of the others.  The\n   domain administrator determines the relationship\
    \ among the inter-\n   domain routing procedures by deciding which of its traffic\
    \ flows\n   should use which inter-domain routing procedures and by configuring\n\
    \   this information for use by the policy gateways.\n   Hosts in stub domains\
    \ may have strict service requirements and hence\n   will benefit from the policy\
    \ routing provided by IDPR.  However, the\n   stub domain itself need not support\
    \ IDPR in order for its traffic\n   flows to use IDPR routes.  Instead, a \"proxy\
    \ domain\" may perform IDPR\n   functions on behalf of the stub.  The proxy domain\
    \ must be reachable\n   from the stub domain according to an inter-domain routing\
    \ procedure\n   independent of IDPR.  Administrators of the stub and potential\
    \ proxy\n   domains mutually negotiate the relationship.  Once an agreement is\n\
    \   reached, the administrator of the stub domain should provide the\n   proxy\
    \ domain with its hosts' service requirements.\n   IDPR policy routes must traverse\
    \ a contiguous set of IDPR domains.\n   Hence, the degree of IDPR deployment in\
    \ transit domains will\n   determine the availability of IDPR policy routes for\
    \ Internet users.\n   For a given traffic flow, if there exists no contiguous\
    \ set of IDPR\n   domains between the source and destination, the traffic flow\
    \ relies\n   on an alternate inter-domain routing procedure to provide a route.\n\
    \   However, if there does exist a contiguous set of IDPR domains between\n  \
    \ the source and destination, the traffic flow may take advantage of\n   policy\
    \ routes provided by IDPR.\n"
- title: 7.  Implementation Experience
  contents:
  - "7.  Implementation Experience\n   To date, there exist two implementations of\
    \ IDPR: one an independent\n   prototype and the other an integral part of the\
    \ gated UNIX process.\n   We describe each of these implementations and our experience\
    \ with\n   them in the following sections.\n"
- title: 7.1  The Prototype
  contents:
  - "7.1  The Prototype\n   During the summer of 1990, the IDPR development group\
    \ consisting of\n   participants from USC, SAIC, and BBN began work on a UNIX-based\n\
    \   software prototype of IDPR, designed for implementation in Sun\n   workstations.\
    \  This prototype consisted of multiple user-level\n   processes to provide the\
    \ basic IDPR functions together with kernel\n   modifications to speed up IDPR\
    \ data message forwarding.\n   Most, but not all, of the IDPR functionality was\
    \ captured in the\n   prototype.  In the interests of producing working software\
    \ as quickly\n   as possible, we intentionally left out of the IDPR prototype\
    \ support\n   for source policies and for multiple policy gateways connecting\
    \ two\n   domains.  This simplified configuration and route generation without\n\
    \   compromising the basic functionality of IDPR.\n   The IDPR prototype software\
    \ was extensively instrumented to provide\n   detailed information for monitoring\
    \ its behavior.  The\n   instrumentation allowed us to detect events including\
    \ but not limited\n   to:\n   - Change in policy gateway connectivity to adjacent\
    \ domains.\n   - Change in transit policies configured for a domain.\n   - Transmission\
    \ and reception of link state routing information.\n   - Generation of policy\
    \ routes, providing a description of the actual\n     route.\n   - Transmission\
    \ and reception of path control information.\n   - Change of path state, such\
    \ as path setup or teardown.\n   With the extensive behavioral information available,\
    \ we were able to\n   track most events occurring in our test networks and hence\
    \ determine\n   whether the prototype software provided the expected functionality.\n"
- title: 7.1.1  Test Networks
  contents:
  - "7.1.1  Test Networks\n   In February 1991, the IDPR development group began experimenting\
    \ with\n   the completed IDPR prototype software.  Each IDPR development site\n\
    \   had its own testing environment, consisting of a set of\n   interconnected\
    \ Sun workstations, each workstation performing the\n   functions of a policy\
    \ gateway and route server:\n   - USC used a laboratory test network consisting\
    \ of SPARC1+\n     workstations, each pair of workstations connected by an Ethernet\n\
    \     segment.  The topology of the test network could be arbitrarily\n     configured.\n\
    \   - SAIC used Sun3 workstations in networks at Sparta and at MITRE.\n     These\
    \ two sites were connected through Alternet using a 9.6kb SLIP\n     link and\
    \ through an X.25 path across the DCA EDN testbed.\n   - BBN used SPARC1+ workstations\
    \ at BBN and ISI connected over both\n     DARTnet and TWBnet.\n"
- title: 7.1.2  Experiments
  contents:
  - "7.1.2  Experiments\n   The principal goal of our experiments with the IDPR prototype\n\
    \   software was to provide a proof of concept.  In particular, we set\n   out\
    \ to verify tha t the IDPR prototype software was able to:\n   - Monitor connectivity\
    \ across and between domains.\n   - Update routing information when inter-domain\
    \ connectivity changed\n     or when new transit policies were configured.\n \
    \  - Distribute routing information to all domains.\n   - Generate acceptable\
    \ policy routes based on current link state\n     routing information.\n   - Set\
    \ up and maintain paths for these policy routes.\n   - Tear down paths that contained\
    \ failed components, supported stale\n     policies, or attained their maximum\
    \ age.\n   Furthermore, we wanted to verify that the IDPR prototype software\n\
    \   quickly detected and adapted to those events that directly affected\n   policy\
    \ routes.\n   The internetwork topology on which we based most of our experiments\n\
    \   consisted of four distinct administrative domains connected in a\n   ring.\
    \  Two of the four domains served as host traffic source and\n   destination,\
    \ AD S and AD D respectively, while the two intervening\n   domains provided transit\
    \ service for the host traffic, AD T1 and AD\n   T2.  AD S and AD D each contained\
    \ a single policy gateway that\n   connected to two other policy gateways, one\
    \ in each transit domain.\n   AD T1 and AD T2 each contained at most two policy\
    \ gateways, each\n   policy gateway connected to the other and to a policy gateway\
    \ in the\n   source or destination domain.  This internetwork topology provided\n\
    \   two distinct inter-domain routes between AD S and AD D, allowing us\n   to\
    \ experiment with various component failure and transit policy\n   reconfiguration\
    \ scenarios in the transit domains.\n   For the first set of experiments, we configured\
    \ transit policies for\n   AD T1 and AD T2 that were devoid of access restrictions.\
    \  We then\n   initialized each policy gateway in our internetwork, loading in\
    \ the\n   domain-specific configurations and starting up the IDPR processes.\n\
    \   In our experiments, we did not use mapping servers; instead, we\n   configured\
    \ address/domain mapping tables in each policy gateway.\n   After policy gateway\
    \ initialization, we observed that each policy\n   gateway immediately determined\
    \ the connectivity to policy gateways in\n   its own domain and in the adjacent\
    \ domains.  The representative\n   policy gateway in each domain then generated\
    \ a routing information\n   message that was received by all other policy gateways\
    \ in the\n   internetwork.\n   To test the route generation and path setup functionality\
    \ of the IDPR\n   prototype software, we began a telnet session between a host\
    \ in AD S\n   and a host in AD D.  We observed that the telnet traffic prompted\
    \ the\n   path agent resident in the policy gateway in AD S to request a policy\n\
    \   route from its route server.  The route server then generated a\n   policy\
    \ route and returned it to the path agent.  Using the policy\n   route supplied\
    \ by the route server, the path agent initiated path\n   setup, and the telnet\
    \ session was established immediately.\n   Having confirmed that the prototype\
    \ software satisfactorily performed\n   the basic IDPR functions, we proceeded\
    \ to test the software under\n   changing network conditions.  The first of these\
    \ tests showed that\n   the IDPR prototype software was able to deal successfully\
    \ with a\n   component failure along a path.  To simulate a path component\n \
    \  failure, we terminated the IDPR processes on a policy gateway in the\n   transit\
    \ domain, AD T1, traversed by the current path.  The policy\n   gateways on either\
    \ side of the failed policy gateway immediately\n   detected the failure.  Next,\
    \ these two policy gateways, representing\n   two different domains, each issued\
    \ a routing information message\n   indicating the connectivity change and each\
    \ initiated path teardown\n   for its remaining path section.\n   Once the path\
    \ was torn down, the path agent agent in AD S requested a\n   new route from its\
    \ route server, to carry the existing telnet\n   traffic.  The route server, having\
    \ received the new routing\n   information messages, proceeded to generate a policy\
    \ route through\n   the other transit domain, AD T2.  Then, the path agent in\
    \ AD S set up\n   a path for the new route supplied by the route server.  Throughout\n\
    \   the component failure and traffic rerouting, the telnet session\n   remained\
    \ intact.\n   At this point, we restored the failed policy gateway in AD T1 to\
    \ the\n   functional state, by restarting its IDPR processes.  The restored\n\
    \   policy gateway connectivity prompted the generation and distribution\n   of\
    \ routing information messages indicating the change in domain\n   connectivity.\n\
    \   Having returned the internetwork topology to its initial\n   configuration,\
    \ we proceeded to test that the IDPR prototype software\n   was able to deal successfully\
    \ with transit policy reconfiguration.\n   The current policy route carrying the\
    \ telnet traffic traversed AD T2.\n   We then reconfigured the transit policy\
    \ for AD T2 to preclude access\n   of traffic travelling from AD S to AD D.  The\
    \ transit policy\n   reconfiguration prompted both the distribution of routing\
    \ information\n   advertising the new transit policy for AD T2 and the initiation\
    \ of\n   path teardown.\n   Once the path was torn down, the path agent in AD\
    \ S requested a new\n   route from its route server, to carry the existing telnet\
    \ traffic.\n   The route server, having received the new routing information\n\
    \   message, proceeded to generate a policy route through the original\n   transit\
    \ domain, AD T1.  Then, the path agent in AD S set up a path\n   for the new route\
    \ supplied by the route server.  Throughout the\n   policy reconfiguration and\
    \ rerouting, the telnet session remained\n   intact.\n   This set of experiments,\
    \ although simple, tested all of the major\n   functionality of the IDPR prototype\
    \ software and demonstrated that\n   the prototype software could quickly and\
    \ accurately adapt to changes\n   in the internetwork.\n"
- title: 7.1.3  Performance Analysis
  contents:
  - "7.1.3  Performance Analysis\n   We (USC and SAIC members of the IDPR development\
    \ group) evaluated the\n   performance of the path setup and message forwarding\
    \ portions of the\n   IDPR prototype software.  For path setup, we measured the\
    \ amount of\n   processing required at the source path agent and at intermediate\n\
    \   policy gateways during path setup.  For message forwarding, we\n   compared\
    \ the processing required at each policy gateway when using\n   IDPR forwarding\
    \ with IP encapsulation and when using only IP\n   forwarding.  We also compared\
    \ the processing required when no\n   integrity/authentication value was calculated\
    \ for the message and\n   when the RSA/MD4 algorithms were employed.\n   Our performance\
    \ measurements were encouraging, but we have not listed\n   them here.  We emphasize\
    \ that although we tried to produce efficient\n   software for the IDPR prototype,\
    \ we were not able to devote much\n   effort to optimizing this software.  Hence,\
    \ the performance\n   measurements for the IDPR prototype software should not\
    \ be blindly\n   extrapolated to other implementations of IDPR.  To obtain a copy\
    \ of\n   the performance measurements for path setup and message forwarding in\n\
    \   the IDPR prototype software, contact Robert Woodburn\n   (woody@sparta.com)\
    \ and Deborah Estrin (estrin@usc.edu).\n"
- title: 7.2  The Gated Version
  contents:
  - "7.2  The Gated Version\n   In 1992, SRI joined the IDPR development group, and\
    \ together SRI,\n   SAIC, and BBN completed the task of integrating IDPR into\
    \ the gated\n   UNIX process.  As a result, IDPR is now available as part of gated.\n\
    \   The gated version of IDPR contains the full functionality of IDPR\n   together\
    \ with a simple yet versatile user interface for IDPR\n   configuration.  As a\
    \ single process, the gated version of IDPR\n   performs more efficiently than\
    \ the multiple-process prototype\n   version.\n   The gated version of IDPR is\
    \ freely available to the Internet\n   community.  Hence, anyone with a UNIX-based\
    \ machine can experiment\n   with IDPR, without investing any money or implementation\
    \ effort.  By\n   making IDPR widely accessible, we can gain Internet experience\
    \ by\n   introducing IDPR into operational networks with real usage\n   constraints\
    \ and transporting host traffic with real service\n   requirements.  Currently,\
    \ a pilot deployment and demonstration of\n   IDPR is under way in selected locations\
    \ in the Internet.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   Refer to section 4 for details on security in\
    \ IDPR.\n"
- title: 9.  Author's Address
  contents:
  - "9.  Author's Address\n   Martha Steenstrup\n   BBN Systems and Technologies\n\
    \   10 Moulton Street\n   Cambridge, MA 02138\n   Phone: (617) 873-3192\n   Email:\
    \ msteenst@bbn.com\n"
