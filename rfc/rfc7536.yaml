- title: __initial_text__
  contents:
  - '              Large-Scale Broadband Measurement Use Cases

    '
- title: Abstract
  contents:
  - "Abstract\n   Measuring broadband performance on a large scale is important for\n\
    \   network diagnostics by providers and users, as well as for public\n   policy.\
    \  Understanding the various scenarios and users of measuring\n   broadband performance\
    \ is essential to development of the Large-scale\n   Measurement of Broadband\
    \ Performance (LMAP) framework, information\n   model, and protocol.  This document\
    \ details two use cases that can\n   assist in developing that framework.  The\
    \ details of the measurement\n   metrics themselves are beyond the scope of this\
    \ document.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7536.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2015 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Use Cases .......................................................3\n  \
    \    2.1. Internet Service Provider (ISP) Use Case ...................3\n    \
    \  2.2. Regulator Use Case .........................................4\n   3. Details\
    \ of ISP Use Case .........................................5\n      3.1. Understanding\
    \ the Quality Experienced by Customers .........5\n      3.2. Understanding the\
    \ Impact and Operation of New Devices\n           and Technology .............................................6\n\
    \      3.3. Design and Planning ........................................6\n  \
    \    3.4. Monitoring Service Level Agreements ........................7\n    \
    \  3.5. Identifying, Isolating, and Fixing Network Problems ........7\n   4. Details\
    \ of Regulator Use Case ...................................8\n      4.1. Providing\
    \ Transparent Performance Information ..............8\n      4.2. Measuring Broadband\
    \ Deployment .............................9\n      4.3. Monitoring Traffic Management\
    \ Practices ...................10\n   5. Implementation Options .........................................10\n\
    \   6. Conclusions ....................................................12\n  \
    \ 7. Security Considerations ........................................13\n   8.\
    \ Informative References .........................................15\n   Contributors\
    \ ......................................................17\n   Authors' Addresses\
    \ ................................................17\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document describes two use cases for the Large-scale\
    \ Measurement\n   of Broadband Performance (LMAP).  The use cases contained in\
    \ this\n   document are (1) the Internet Service Provider Use Case and (2) the\n\
    \   Regulator Use Case.  In the first, a network operator wants to\n   understand\
    \ the performance of the network and the quality experienced\n   by customers,\
    \ while in the second, a regulator wants to provide\n   information on the performance\
    \ of the ISPs in their jurisdiction.\n   There are other use cases that are not\
    \ the focus of the initial LMAP\n   work (for example, end users would like to\
    \ use measurements to help\n   identify problems in their home network and to\
    \ monitor the\n   performance of their broadband provider); it is expected that\
    \ the\n   same mechanisms are applicable.\n   Large-scale measurements raise several\
    \ security concerns, including\n   privacy issues.  These are summarized in Section\
    \ 7 and considered in\n   further detail in [Framework].\n"
- title: 2.  Use Cases
  contents:
  - "2.  Use Cases\n   From the LMAP perspective, there is no difference between fixed\n\
    \   service and mobile (cellular) service used for Internet access.\n   Hence,\
    \ like measurements will take place on both fixed and mobile\n   networks.  Fixed\
    \ services include technologies like Digital\n   Subscriber Line (DSL), Cable,\
    \ and Carrier Ethernet.  Mobile services\n   include all those advertised as 2G,\
    \ 3G, 4G, and Long Term Evolution\n   (LTE).  A metric defined to measure end-to-end\
    \ services will execute\n   similarly on all access technologies.  Other metrics\
    \ may be access\n   technology specific.  The LMAP architecture covers both IPv4\
    \ and IPv6\n   networks.\n"
- title: 2.1.  Internet Service Provider (ISP) Use Case
  contents:
  - "2.1.  Internet Service Provider (ISP) Use Case\n   A network operator needs to\
    \ understand the performance of their\n   networks, the performance of the suppliers\
    \ (downstream and upstream\n   networks), the performance of Internet access services,\
    \ and the\n   impact that such performance has on the experience of their\n  \
    \ customers.  Largely, the processes that ISPs operate (which are based\n   on\
    \ network measurement) include:\n   o  Identifying, isolating, and fixing problems,\
    \ which may be in the\n      network, with the service provider, or in the end-user\
    \ equipment.\n      Such problems may be common to a point in the network topology\n\
    \      (e.g., a single exchange), common to a vendor or equipment type\n     \
    \ (e.g., line card or home gateway), or unique to a single user line\n      (e.g.,\
    \ copper access).  Part of this process may also be helping\n      users understand\
    \ whether the problem exists in their home network\n      or with a third-party\
    \ application service instead of with their\n      broadband (BB) product.\n \
    \  o  Design and planning.  Through monitoring the end-user experience,\n    \
    \  the ISP can design and plan their network to ensure specified\n      levels\
    \ of user experience.  Services may be moved closer to end\n      users, services\
    \ upgraded, the impact of QoS assessed, or more\n      capacity deployed at certain\
    \ locations.  Service Level Agreements\n      (SLAs) may be defined at network\
    \ or product boundaries.\n   o  Understanding the quality experienced by customers.\
    \  The network\n      operator would like to gain better insight into the end-to-end\n\
    \      performance experienced by its customers.  \"End-to-end\" could, for\n\
    \      instance, incorporate home and enterprise networks, and the impact\n  \
    \    of peering, caching, and Content Delivery Networks (CDNs).\n   o  Understanding\
    \ the impact and operation of new devices and\n      technology.  As a new product\
    \ is deployed, or a new technology\n      introduced into the network, it is essential\
    \ that its operation\n      and its impact are measured.  This also helps to quantify\
    \ the\n      advantage that the new technology is bringing and support the\n \
    \     business case for larger roll-out.\n"
- title: 2.2.  Regulator Use Case
  contents:
  - "2.2.  Regulator Use Case\n   A regulator may want to evaluate the performance\
    \ of the Internet\n   access services offered by operators.\n   While each jurisdiction\
    \ responds to distinct consumer, industry, and\n   regulatory concerns, much commonality\
    \ exists in the need to produce\n   datasets that can be used to compare multiple\
    \ Internet access service\n   providers, diverse technical solutions, geographic\
    \ and regional\n   distributions, and marketed and provisioned levels and combinations\n\
    \   of broadband Internet access services.\n   Regulators may want to publish\
    \ performance measures of different ISPs\n   as background information for end\
    \ users.  They may also want to track\n   the growth of high-speed broadband deployment,\
    \ or to monitor the\n   traffic management practices of Internet providers.\n\
    \   A regulator's role in the development and enforcement of broadband\n   Internet\
    \ access service policies requires that the measurement\n   approaches meet a\
    \ high level of verifiability, accuracy, and\n   provider-independence to support\
    \ valid and meaningful comparisons of\n   Internet access service performance.\
    \  Standards can help regulators'\n   shared needs for scalable, cost-effective,\
    \ scientifically robust\n   solutions to the measurement and collection of broadband\
    \ Internet\n   access service performance information.\n"
- title: 3.  Details of ISP Use Case
  contents:
  - '3.  Details of ISP Use Case

    '
- title: 3.1.  Understanding the Quality Experienced by Customers
  contents:
  - "3.1.  Understanding the Quality Experienced by Customers\n   Operators want to\
    \ understand the quality of experience (QoE) of their\n   broadband customers.\
    \  The understanding can be gained through a\n   \"panel\", i.e., measurement\
    \ probes deployed to several customers.  A\n   probe is a device or piece of software\
    \ that makes measurements and\n   reports the results, under the control of the\
    \ measurement system.\n   Implementation options are discussed in Section 5. \
    \ The panel needs\n   to include a representative sample of the operator's technologies\
    \ and\n   broadband speeds.  For instance, it might encompass speeds ranging\n\
    \   from below 8 Mbps to over 100 Mbps.  The operator would like the\n   end-to-end\
    \ view of the service, rather than just the access portion.\n   This involves\
    \ relating the pure network parameters to something like\n   a 'mean opinion score'\
    \ [MOS], which will be service dependent (for\n   instance, web-browsing QoE is\
    \ largely determined by latency above a\n   few Mbps).\n   An operator will also\
    \ want compound metrics such as \"reliability\",\n   which might involve packet\
    \ loss, DNS failures, retraining of the\n   line, video streaming under-runs,\
    \ etc.\n   The operator really wants to understand the end-to-end service\n  \
    \ experience.  However, the home network (Ethernet, Wi-Fi, powerline)\n   is highly\
    \ variable and outside its control.  To date, operators (and\n   regulators) have\
    \ instead measured performance from the home gateway.\n   However, mobile operators\
    \ clearly must include the wireless link in\n   the measurement.\n   Active measurements\
    \ are the most obvious approach, i.e., special\n   measurement traffic is sent\
    \ by -- and to -- the probe.  In order not\n   to degrade the service of the customer,\
    \ the measurement data should\n   only be sent when the user is silent, and it\
    \ shouldn't reduce the\n   customer's data allowance.  The other approach is passive\n\
    \   measurements on the customer's ordinary traffic; the advantage is\n   that\
    \ it measures what the customer actually does, but it creates\n   extra variability\
    \ (different traffic mixes give different results)\n   and, in particular, it\
    \ raises privacy concerns.  [RFC6973] discusses\n   privacy considerations for\
    \ Internet protocols in general, while\n   [Framework] discusses them specifically\
    \ for large-scale measurement\n   systems.\n   From an operator's viewpoint, understanding\
    \ customer experience\n   enables it to offer better services.  Also, simple metrics\
    \ can be\n   more easily understood by senior managers who make investment\n \
    \  decisions and by sales and marketing.\n"
- title: 3.2.  Understanding the Impact and Operation of New Devices and
  contents:
  - "3.2.  Understanding the Impact and Operation of New Devices and\n      Technology\n\
    \   Another type of measurement is to test new capabilities before they\n   are\
    \ rolled out.  For example, the operator may want to:\n   o  Check whether a customer\
    \ can be upgraded to a new broadband\n      option.\n   o  Understand the impact\
    \ of IPv6 before it is made available to\n      customers.  Questions such as\
    \ these could be assessed: Will v6\n      packets get through?  What will the\
    \ latency be to major websites?\n      What transition mechanisms will be most\
    \ appropriate?\n   o  Check whether a new capability can be signaled using TCP\
    \ options\n      (how often it will be blocked by a middlebox -- along the lines\
    \ of\n      the experiments described in [Extend-TCP]).\n   o  Investigate a QoS\
    \ mechanism (e.g., checking whether Diffserv\n      markings are respected on\
    \ some path).\n"
- title: 3.3.  Design and Planning
  contents:
  - "3.3.  Design and Planning\n   Operators can use large-scale measurements to help\
    \ with their network\n   planning -- proactive activities to improve the network.\n\
    \   For example, by probing from several different vantage points the\n   operator\
    \ can see that a particular group of customers has performance\n   below that\
    \ expected during peak hours, which should help with\n   capacity planning.  Naturally,\
    \ operators already have tools to help\n   with this -- a network element reports\
    \ its individual utilization\n   (and perhaps other parameters).  However, making\
    \ measurements across\n   a path rather than at a point may make it easier to\
    \ understand the\n   network.  There may also be parameters like bufferbloat that\
    \ aren't\n   currently reported by equipment and/or that are intrinsically path\n\
    \   metrics.\n   With information gained from measurement results, capacity planning\n\
    \   and network design can be more effective.  Such planning typically\n   uses\
    \ simulations to emulate the measured performance of the current\n   network and\
    \ understand the likely impact of new capacity and\n   potential changes to the\
    \ topology.  Simulations, informed by data\n   from a limited panel of probes,\
    \ can help quantify the advantage that\n   a new technology brings and support\
    \ the business case for larger\n   roll-out.\n   It may also be possible to use\
    \ probes to run stress tests for risk\n   analysis.  For example, an operator\
    \ could run a carefully controlled\n   and limited experiment in which probing\
    \ is used to assess the\n   potential impact if some new application becomes popular.\n"
- title: 3.4.  Monitoring Service Level Agreements
  contents:
  - "3.4.  Monitoring Service Level Agreements\n   Another example is that the operator\
    \ may want to monitor performance\n   where there is a Service Level Agreement\
    \ (SLA).  This could be with\n   its own customers; in particular, enterprises\
    \ may have an SLA.  The\n   operator can proactively spot when the service is\
    \ degrading near the\n   point of the SLA limit and get information that will\
    \ enable more\n   informed conversations with the customer at contract renewal.\n\
    \   An operator may also want to monitor the performance of its\n   suppliers,\
    \ to check whether they meet their SLA or to compare two\n   suppliers if it is\
    \ dual-sourcing.  This could include its transit\n   operator, CDNs, peering,\
    \ video source, or local network provider for\n   a global operator in countries\
    \ where it doesn't have its own network.\n   A virtual operator may monitor the\
    \ whole underlying network.\n   Through a better understanding of its own network\
    \ and its suppliers,\n   the operator should be able to focus investment more\
    \ effectively --\n   in the right place at the right time with the right technology.\n"
- title: 3.5.  Identifying, Isolating, and Fixing Network Problems
  contents:
  - "3.5.  Identifying, Isolating, and Fixing Network Problems\n   Operators can use\
    \ large-scale measurements to help identify a fault\n   more rapidly and decide\
    \ how to solve it.\n   Operators already have Test and Diagnostic tools, where\
    \ a network\n   element reports some problem or failure to a management system.\n\
    \   However, many issues are not caused by a point failure but something\n   wider\
    \ and so will trigger too many alarms, while other issues will\n   cause degradation\
    \ rather than failure and so not trigger any alarm.\n   Large-scale measurements\
    \ can help provide a more nuanced view that\n   helps network management to identify\
    \ and fix problems more rapidly\n   and accurately.  The network management tools\
    \ may use simulations to\n   emulate the network and so help identify a fault\
    \ and assess possible\n   solutions.\n   An operator can obtain useful information\
    \ without measuring the\n   performance on every broadband line.  By measuring\
    \ a subset, the\n   operator can identify problems that affect a group of customers.\
    \  For\n   example, the issue could be at a shared point in the network topology\n\
    \   (such as an exchange), or common to a vendor, or equipment type; for\n   instance,\
    \ [IETF85-Plenary] describes a case where a particular home\n   gateway upgrade\
    \ had caused a (mistaken!) drop in line rate.\n   A more extensive deployment\
    \ of the measurement capability to every\n   broadband line would enable an operator\
    \ to identify issues unique to\n   a single customer.  Overall, large-scale measurements\
    \ can help an\n   operator fix the fault more rapidly and/or allow the affected\n\
    \   customers to be informed of what's happening.  More accurate\n   information\
    \ enables the operator to reassure customers and take more\n   rapid and effective\
    \ action to cure the problem.\n   Often, customers experience poor broadband due\
    \ to problems in the\n   home network -- the ISP's network is fine.  For example,\
    \ they may\n   have moved too far away from their wireless access point.\n   Anecdotally,\
    \ a large fraction of customer calls about fixed BB\n   problems are due to in-home\
    \ wireless issues.  These issues are\n   expensive and frustrating for an operator,\
    \ as they are extremely hard\n   to diagnose and solve.  The operator would like\
    \ to narrow down\n   whether the problem is in the home (a problem with the home\
    \ network,\n   edge device, or home gateway), in the operator's network, or with\
    \ an\n   application service.  The operator would like two capabilities:\n   firstly,\
    \ self-help tools that customers use to improve their own\n   service or understand\
    \ its performance better -- for example, to\n   reposition their devices for better\
    \ Wi-Fi coverage; and secondly,\n   on-demand tests that the operator can run\
    \ instantly, so that the call\n   center person answering the phone (or e-chat)\
    \ could trigger a test\n   and get the result while the customer is still in an\
    \ online session.\n"
- title: 4.  Details of Regulator Use Case
  contents:
  - '4.  Details of Regulator Use Case

    '
- title: 4.1.  Providing Transparent Performance Information
  contents:
  - "4.1.  Providing Transparent Performance Information\n   Some regulators publish\
    \ information about the quality of the various\n   Internet access services provided\
    \ in their national market.  Quality\n   information about service offers could\
    \ include speed, delay, and\n   jitter.  Such information can be published to\
    \ facilitate end users'\n   choice of service provider and offer.  Regulators\
    \ may check the\n   accuracy of the marketing claims of Internet service providers\
    \ and\n   may also encourage ISPs to all use the same metrics in their service\n\
    \   level contracts.  The goal of these transparency mechanisms is to\n   promote\
    \ competition for end users and potentially also help content,\n   application,\
    \ service, and device providers develop their Internet\n   offerings.\n   The\
    \ published information needs to be:\n   o  Accurate - the measurement results\
    \ must be correct and not\n      influenced by errors or side effects.  The results\
    \ should be\n      reproducible and consistent over time.\n   o  Comparable -\
    \ common metrics should be used across different ISPs\n      and service offerings,\
    \ and over time, so that measurement results\n      can be compared.\n   o  Meaningful\
    \ - the metrics used for measurements need to reflect\n      what end users value\
    \ about their broadband Internet access\n      service.\n   o  Reliable - the\
    \ number and distribution of measurement agents, and\n      the statistical processing\
    \ of the raw measurement data, need to be\n      appropriate.\n   In practical\
    \ terms, the regulators may measure network performance\n   from users towards\
    \ multiple content and application providers,\n   including dedicated test measurement\
    \ servers.  Measurement probes are\n   distributed to a 'panel' of selected end\
    \ users.  The panel covers all\n   the operators and packages in the market, spread\
    \ over urban,\n   suburban, and rural areas, and often includes both fixed and\
    \ mobile\n   Internet access.  Periodic tests running on the probes can, for\n\
    \   example, measure actual speed at peak and off-peak hours, but can\n   also\
    \ measure other detailed quality metrics like delay and jitter.\n   Collected\
    \ data goes afterwards through statistical analysis, deriving\n   estimates for\
    \ the whole population.  Summary information, such as a\n   service quality index,\
    \ is published regularly, perhaps alongside more\n   detailed information.\n \
    \  The regulator can also facilitate end users to monitor the\n   performance\
    \ of their own broadband Internet access service.  They\n   might use this information\
    \ to check that the performance meets that\n   specified in their contract or\
    \ to understand whether their current\n   subscription is the most appropriate.\n"
- title: 4.2.  Measuring Broadband Deployment
  contents:
  - "4.2.  Measuring Broadband Deployment\n   Regulators may also want to monitor\
    \ the improvement over time of\n   actual broadband Internet access performance\
    \ in a specific country or\n   a region.  The motivation is often to evaluate\
    \ the effect of the\n   stimulated growth over time, when government has set a\
    \ strategic goal\n   for high-speed broadband deployment, whether in absolute\
    \ terms or\n   benchmarked against other countries.  An example of such an\n \
    \  initiative is [DAE].  The actual measurements can be made in the same\n   way\
    \ as described in Section 4.1.\n"
- title: 4.3.  Monitoring Traffic Management Practices
  contents:
  - "4.3.  Monitoring Traffic Management Practices\n   A regulator may want to monitor\
    \ traffic management practices or\n   compare the performance of Internet access\
    \ service with specialized\n   services offered in parallel to, but separate from,\
    \ Internet access\n   service  (for example, IPTV).  A regulator could monitor\
    \ for\n   departures from application agnosticism such as blocking or\n   throttling\
    \ of traffic from specific applications, or preferential\n   treatment of specific\
    \ applications.  A measurement system could send,\n   or passively monitor, application-specific\
    \ traffic and then measure\n   in detail the transfer of the different packets.\
    \  While it is\n   relatively easy to measure port blocking, how to detect other\
    \ types\n   of differentiated treatment is a research topic in itself.  The\n\
    \   \"Glasnost: Enabling End Users to Detect Traffic Differentiation\"\n   paper\
    \ [M-Labs_NSDI-2010] and follow-on tool \"Glasnost\" [Glasnost]\n   provide an\
    \ example of work in this area.\n   A regulator could also monitor the performance\
    \ of the broadband\n   service over time, to try and detect if the specialized\
    \ service is\n   provided at the expense of the Internet access service.  Comparison\n\
    \   between ISPs or between different countries may also be relevant for\n   this\
    \ kind of evaluation.\n   The motivation for a regulator monitoring such traffic\
    \ management\n   practices is that regulatory approaches related to net neutrality\
    \ and\n   the open Internet have been introduced in some jurisdictions.\n   Examples\
    \ of such efforts are the Internet policy as outlined by the\n   Body of European\
    \ Regulators for Electronic Communications guidelines\n   for quality of service\
    \ [BEREC-Guidelines] and the US FCC's\n   \"Preserving the Open Internet\" Report\
    \ and Order [FCC-R&O].  Although\n   legal challenges can change the status of\
    \ policy, the take-away for\n   LMAP purposes is that policy-makers are looking\
    \ for measurement\n   solutions to assist them in discovering biased treatment\
    \ of traffic\n   flows.  The exact definitions and requirements vary from one\n\
    \   jurisdiction to another.\n"
- title: 5.  Implementation Options
  contents:
  - "5.  Implementation Options\n   There are several ways of implementing a measurement\
    \ system.  The\n   choice may be influenced by the details of the particular use\
    \ case\n   and what the most important criteria are for the regulator, ISP, or\n\
    \   third party operating the measurement system.\n   One type of probe is a special\
    \ hardware device that is connected\n   directly to the home gateway.  The devices\
    \ are deployed to a\n   carefully selected panel of end users, and they perform\
    \ measurements\n   according to a defined schedule.  The schedule can run throughout\
    \ the\n   day, to allow continuous assessment of the network.  Careful design\n\
    \   ensures that measurements do not detrimentally impact the home user\n   experience\
    \ or corrupt the results by testing when the user is also\n   using the broadband\
    \ line.  The system is therefore tightly controlled\n   by the operator of the\
    \ measurement system.  One advantage of this\n   approach is that it is possible\
    \ to get reliable benchmarks for the\n   performance of a network with only a\
    \ few devices.  One disadvantage\n   is that it would be expensive to deploy hardware\
    \ devices on a mass\n   scale sufficient to understand the performance of the\
    \ network at the\n   granularity of a single broadband user.\n   Another type\
    \ of probe involves implementing the measurement\n   capability as a webpage or\
    \ an \"app\" that end users are encouraged to\n   download onto their mobile phone\
    \ or computing device.  Measurements\n   are triggered by the end user; for example,\
    \ the user interface may\n   have a button to \"test my broadband now.\"  One\
    \ advantage of this\n   approach is that the performance is measured to the end\
    \ user, rather\n   than to the home gateway, and so includes the home network.\
    \  Another\n   difference is that the system is much more loosely controlled,\
    \ as the\n   panel of end users and the schedule of tests are determined by the\n\
    \   end users themselves rather than the measurement system.  While this\n   approach\
    \ makes it easier to make measurements on a large scale, it is\n   harder to get\
    \ comparable benchmarks, as the measurements are affected\n   by the home network;\
    \ also, the population is self-selecting and so\n   potentially biased towards\
    \ those who think they have a problem.  This\n   could be alleviated by encouraging\
    \ widespread downloading of the app\n   and careful post-processing of the results\
    \ to reduce biases.\n   There are several other possibilities.  For example, as\
    \ a variant on\n   the first approach, the measurement capability could be implemented\n\
    \   as software embedded in the home gateway, which would make it more\n   viable\
    \ to have the capability on every user line.  As a variant on\n   the second approach,\
    \ the end user could initiate measurements in\n   response to a request from the\
    \ measurement system.\n   The operator of the measurement system should be careful\
    \ to ensure\n   that measurements do not detrimentally impact users.  Potential\n\
    \   issues include the following:\n   *  Measurement traffic generated on a particular\
    \ user's line may\n      impact that end user's quality of experience.  The danger\
    \ is\n      greater for measurements that generate a lot of traffic over a\n \
    \     lengthy period.\n   *  The measurement traffic may impact that particular\
    \ user's bill or\n      traffic cap.\n   *  The measurement traffic from several\
    \ end users may, in\n      combination, congest a shared link.\n   *  The traffic\
    \ associated with the control and reporting of\n      measurements may overload\
    \ the network.  The danger is greater\n      where the traffic associated with\
    \ many end users is synchronized.\n"
- title: 6.  Conclusions
  contents:
  - "6.  Conclusions\n   Large-scale measurements of broadband performance are useful\
    \ for both\n   network operators and regulators.  Network operators would like\
    \ to\n   use measurements to help them better understand the quality\n   experienced\
    \ by their customers, identify problems in the network, and\n   design network\
    \ improvements.  Regulators would like to use\n   measurements to help promote\
    \ competition between network operators,\n   stimulate the growth of broadband\
    \ access, and monitor 'net\n   neutrality'.  There are other use cases that are\
    \ not the focus of the\n   initial LMAP charter (although it is expected that\
    \ the mechanisms\n   developed would be readily applied); for example, end users\
    \ would\n   like to use measurements to help identify problems in their home\n\
    \   network and to monitor the performance of their broadband provider.\n   From\
    \ consideration of the various use cases, several common themes\n   emerge, while\
    \ there are also some detailed differences.  These\n   characteristics guide the\
    \ development of LMAP's framework,\n   information model, and protocol.\n   A\
    \ measurement capability is needed across a wide number of\n   heterogeneous environments.\
    \  Tests may be needed in the home network,\n   in the ISP's network, or beyond;\
    \ they may be measuring a fixed or\n   wireless network; they may measure just\
    \ the access network or across\n   several networks.\n   There is a role for both\
    \ standardized and non-standardized\n   measurements.  For example, a regulator\
    \ would like to publish\n   standardized performance metrics for all network operators,\
    \ while an\n   ISP may need their own tests to understand some feature special\
    \ to\n   their network.  Most use cases need active measurements, which create\n\
    \   and measure specific test traffic, but some need passive measurements\n  \
    \ of the end user's traffic.\n   Regardless of the tests being operated, there\
    \ needs to be a way to\n   demand or schedule the tests.  Most use cases need\
    \ a regular schedule\n   of measurements, but sometimes ad hoc testing is needed\
    \ -- for\n   example, for troubleshooting.  It needs to be ensured that\n   measurements\
    \ do not affect the user experience and are not affected\n   by user traffic (unless\
    \ desired).  In addition, there needs to be a\n   common way to collect the results.\
    \  Standardization of this control\n   and reporting functionality allows the\
    \ operator of a measurement\n   system to buy the various components from different\
    \ vendors.\n   After the measurement results are collected, they need to be\n\
    \   understood and analyzed.  Often, it is sufficient to measure only a\n   small\
    \ subset of end users, but per-line fault diagnosis requires the\n   ability to\
    \ test every individual line.  Analysis requires accurate\n   definition and understanding\
    \ of where the test points are, as well as\n   contextual information about the\
    \ topology, line, product, and the\n   subscriber's contract.  The actual analysis\
    \ of results is beyond the\n   scope of LMAP, as is the key challenge of how to\
    \ integrate the\n   measurement system into a network operator's existing tools\
    \ for\n   diagnostics and network planning.\n   Finally, the test data, along\
    \ with any associated network, product,\n   or subscriber contract data, is commercial\
    \ or private information and\n   needs to be protected.\n"
- title: 7.  Security Considerations
  contents:
  - "7.  Security Considerations\n   Large-scale measurements raise several potential\
    \ security, privacy\n   (data protection) [RFC6973], and business sensitivity\
    \ issues:\n   1. A malicious party may try to gain control of probes to launch\
    \ DoS\n      (Denial of Service) attacks at a target.  A DoS attack could be\n\
    \      targeted at a particular end user or set of end users, a certain\n    \
    \  network, or a specific service provider.\n   2. A malicious party may try to\
    \ gain control of probes to create a\n      platform for pervasive monitoring\
    \ [RFC7258] or for more targeted\n      monitoring.  [RFC7258] summarizes the\
    \ threats as follows: \"An\n      attack may change the content of the communication,\
    \ record the\n      content or external characteristics of the communication,\
    \ or\n      through correlation with other communication events, reveal\n    \
    \  information the parties did not intend to be revealed.\"  For\n      example,\
    \ a malicious party could distribute to the probes a new\n      measurement test\
    \ that recorded (and later reported) information of\n      maleficent interest.\
    \  Similar concerns also arise if the\n      measurement results are intercepted\
    \ or corrupted.\n      *  From the end user's perspective, the concerns include\
    \ a\n         malicious party monitoring the traffic they send and receive,\n\
    \         who they communicate with, the websites they visit, and such\n     \
    \    information about their behavior as when they are at home and\n         the\
    \ location of their devices.  Some of the concerns may be\n         greater when\
    \ the probe is on the end user's device rather than\n         on their home gateway.\n\
    \      *  From the network operator's perspective, the concerns include\n    \
    \     the leakage of commercially sensitive information about the\n         design\
    \ and operation of their network, their customers, and\n         suppliers.  Some\
    \ threats are indirect; for example, the\n         attacker could reconnoiter\
    \ potential weaknesses, such as open\n         ports and paths through the network,\
    \ which enabled it to launch\n         an attack later.\n      *  From the regulator's\
    \ perspective, the concerns include\n         distortion of the measurement tests\
    \ or alteration of the\n         measurement results.  Also, a malicious network\
    \ operator could\n         try to identify the broadband lines that the regulator\
    \ was\n         measuring and prioritize that traffic (\"game the system\").\n\
    \   3. Another potential issue is a measurement system that does not\n      obtain\
    \ the end user's informed consent, fails to specify a\n      specific purpose\
    \ in the consent, or uses the collected information\n      for secondary uses\
    \ beyond those specified.\n   4. Another potential issue is a measurement system\
    \ that does not\n      indicate who is responsible for the collection and processing\
    \ of\n      personal data and who is responsible for fulfilling the rights of\n\
    \      users.  The responsible party (often termed the \"data controller\")\n\
    \      should, as good practice, consider such issues as defining:\n      o  the\
    \ purpose for which the data is collected and used,\n      o  how the data is\
    \ stored, accessed, and processed,\n      o  how long the data is retained, and\n\
    \      o  how the end user can view, update, and even delete their\n         personal\
    \ data.\n      If anonymized personal data is shared with a third party, the data\n\
    \      controller should consider the possibility that the third party\n     \
    \ can de-anonymize it by combining it with other information.\n   These security\
    \ and privacy issues will need to be considered\n   carefully by any measurement\
    \ system.  In the context of LMAP,\n   [Framework] considers them further, along\
    \ with some potential\n   mitigations.  Other LMAP documents will specify one\
    \ or more protocols\n   that enable the measurement system to instruct a probe\
    \ about what\n   measurements to make and that enable the probe to report the\n\
    \   measurement results.  Those documents will need to discuss solutions\n   to\
    \ the security and privacy issues.  However, the protocol documents\n   will not\
    \ consider the actual usage of the measurement information.\n   Many use cases\
    \ can be envisaged, and earlier in this document we\n   described some likely\
    \ ones for the network operator and regulator.\n"
- title: 8.  Informative References
  contents:
  - "8.  Informative References\n   [IETF85-Plenary]\n              Crawford, S.,\
    \ \"Large-Scale Active Measurement of Broadband\n              Networks\", 'example'\
    \ from slide 18, November 2012,\n              <http://www.ietf.org/proceedings/85/slides/\n\
    \              slides-85-iesg-opsandtech-7.pdf>.\n   [Extend-TCP]\n          \
    \    Honda, M., Nishida, Y., Raiciu, C., Greenhalgh, A.,\n              Handley,\
    \ M., and H. Tokuda, \"Is it Still Possible to\n              Extend TCP?\", Proceedings\
    \ of IETF 82, November 2011,\n              <http://www.ietf.org/proceedings/82/slides/IRTF-1.pdf>.\n\
    \   [Framework]\n              Eardley, P., Morton, A., Bagnulo, M., Burbridge,\
    \ T.,\n              Aitken, P., and A. Akhter, \"A framework for Large-Scale\n\
    \              Measurement of Broadband Performance (LMAP)\", Work in\n      \
    \        Progress, draft-ietf-lmap-framework-14, April 2015.\n   [RFC6973]  Cooper,\
    \ A., Tschofenig, H., Aboba, B., Peterson, J.,\n              Morris, J., Hansen,\
    \ M., and R. Smith, \"Privacy\n              Considerations for Internet Protocols\"\
    , RFC 6973,\n              July 2013, <http://www.rfc-editor.org/info/rfc6973>.\n\
    \   [RFC7258]  Farrell, S. and H. Tschofenig, \"Pervasive Monitoring Is an\n \
    \             Attack\", BCP 188, RFC 7258, May 2014,\n              <http://www.rfc-editor.org/info/rfc7258>.\n\
    \   [FCC-R&O]  United States Federal Communications Commission,\n            \
    \  \"Preserving the Open Internet; Broadband Industries\n              Practices:\
    \ Report and Order\", FCC 10-201, December 2010,\n              <http://hraunfoss.fcc.gov/edocs_public/attachmatch/\n\
    \              FCC-10-201A1.pdf>.\n   [BEREC-Guidelines]\n              Body of\
    \ European Regulators for Electronic Communications,\n              \"BEREC Guidelines\
    \ for quality of service in the scope of\n              net neutrality\", <http://berec.europa.eu/eng/\n\
    \              document_register/subject_matter/berec/download/0/\n          \
    \    1101-berec-guidelines-for-quality-of-service-_0.pdf>.\n   [M-Labs_NSDI-2010]\n\
    \              M-Lab, \"Glasnost: Enabling End Users to Detect Traffic\n     \
    \         Differentiation\", <http://www.measurementlab.net/\n              download/AMIfv945ljiJXzG-fgUrZSTu2hs1xRl5Oh-\n\
    \              rpGQMWL305BNQh-BSq5oBoYU4a7zqXOvrztpJhK9gwk5unOe-\n           \
    \   fOzj4X-vOQz_HRrnYU-aFd0rv332RDReRfOYkJuagysstN3GZ__lQHTS8_\n             \
    \ UHJTWkrwyqIUjffVeDxQ/>.\n   [Glasnost] M-Lab tool \"Glasnost\", <http://mlab-live.appspot.com/\n\
    \              tools/glasnost>.\n   [MOS]      Wikipedia, \"Mean Opinion Score\"\
    , January 2015,\n              <http://en.wikipedia.org/w/index.php?\n       \
    \       title=Mean_opinion_score&oldid=644494161>.\n   [DAE]      Digital Agenda\
    \ for Europe, COM(2010)245 final,\n              \"Communication from the Commission\
    \ to the European\n              Parliament, the Council, the European Economic\
    \ and Social\n              Committee and the Committee of the Regions\",\n  \
    \            <http://eur-lex.europa.eu/legal-content/EN/TXT/\n              PDF/?uri=CELEX:52010DC0245&from=EN>.\n"
- title: Contributors
  contents:
  - "Contributors\n   The information in this document is partially derived from text\n\
    \   written by the following contributors:\n      James Miller          jamesmilleresquire@gmail.com\n\
    \      Rachel Huang          rachel.huang@huawei.com\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Marc Linsner\n   Cisco Systems, Inc.\n   Marco Island,\
    \ FL\n   United States\n   EMail: mlinsner@cisco.com\n   Philip Eardley\n   BT\n\
    \   B54 Room 77, Adastral Park, Martlesham\n   Ipswich, IP5 3RE\n   United Kingdom\n\
    \   EMail: philip.eardley@bt.com\n   Trevor Burbridge\n   BT\n   B54 Room 70,\
    \ Adastral Park, Martlesham\n   Ipswich, IP5 3RE\n   United Kingdom\n   EMail:\
    \ trevor.burbridge@bt.com\n   Frode Sorensen\n   Norwegian Communications Authority\
    \ (Nkom)\n   Lillesand\n   Norway\n   EMail: frode.sorensen@nkom.no\n"
