- title: __initial_text__
  contents:
  - "                   Bandwidth Constraints Models for\n  Differentiated Services\
    \ (Diffserv)-aware MPLS Traffic Engineering:\n                        Performance\
    \ Evaluation\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2005).\n"
- title: IESG Note
  contents:
  - "IESG Note\n   The content of this RFC has been considered by the IETF (specifically\n\
    \   in the TE-WG working group, which has no problem with publication as\n   an\
    \ Informational RFC), and therefore it may resemble a current IETF\n   work in\
    \ progress or a published IETF work.  However, this document is\n   an individual\
    \ submission and not a candidate for any level of\n   Internet Standard.  The\
    \ IETF disclaims any knowledge of the fitness\n   of this RFC for any purpose,\
    \ and in particular notes that it has not\n   had complete IETF review for such\
    \ things as security, congestion\n   control or inappropriate interaction with\
    \ deployed protocols.  The\n   RFC Editor has chosen to publish this document\
    \ at its discretion.\n   Readers of this RFC should exercise caution in evaluating\
    \ its value\n   for implementation and deployment.  See RFC 3932 for more\n  \
    \ information.\n"
- title: Abstract
  contents:
  - "Abstract\n   \"Differentiated Services (Diffserv)-aware MPLS Traffic Engineering\n\
    \   Requirements\", RFC 3564, specifies the requirements and selection\n   criteria\
    \ for Bandwidth Constraints Models.  Two such models, the\n   Maximum Allocation\
    \ and the Russian Dolls, are described therein.\n   This document complements\
    \ RFC 3564 by presenting the results of a\n   performance evaluation of these\
    \ two models under various operational\n   conditions: normal load, overload,\
    \ preemption fully or partially\n   enabled, pure blocking, or complete sharing.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \      1.1. Conventions used in this document ..........................4\n  \
    \ 2. Bandwidth Constraints Models ....................................4\n   3.\
    \ Performance Model ...............................................5\n      3.1.\
    \ LSP Blocking and Preemption ................................6\n      3.2. Example\
    \ Link Traffic Model .................................8\n      3.3. Performance\
    \ under Normal Load ..............................9\n   4. Performance under Overload\
    \ .....................................10\n      4.1. Bandwidth Sharing versus\
    \ Isolation ........................10\n      4.2. Improving Class 2 Performance\
    \ at the Expense of Class 3 ...12\n      4.3. Comparing Bandwidth Constraints\
    \ of Different Models .......13\n   5. Performance under Partial Preemption ...........................15\n\
    \      5.1. Russian Dolls Model .......................................16\n  \
    \    5.2. Maximum Allocation Model ..................................16\n   6.\
    \ Performance under Pure Blocking ................................17\n      6.1.\
    \ Russian Dolls Model .......................................17\n      6.2. Maximum\
    \ Allocation Model ..................................18\n   7. Performance under\
    \ Complete Sharing .............................19\n   8. Implications on Performance\
    \ Criteria ...........................20\n   9. Conclusions ....................................................21\n\
    \   10. Security Considerations .......................................22\n  \
    \ 11. Acknowledgements ..............................................22\n   12.\
    \ References ....................................................22\n       12.1.\
    \ Normative References ....................................22\n       12.2. Informative\
    \ References ..................................22\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Differentiated Services (Diffserv)-aware MPLS Traffic Engineering\n\
    \   (DS-TE) mechanisms operate on the basis of different Diffserv classes\n  \
    \ of traffic to improve network performance.  Requirements for DS-TE\n   and the\
    \ associated protocol extensions are specified in references\n   [1] and [2] respectively.\n\
    \   To achieve per-class traffic engineering, rather than on an aggregate\n  \
    \ basis across all classes, DS-TE enforces different Bandwidth\n   Constraints\
    \ (BCs) on different classes.  Reference [1] specifies the\n   requirements and\
    \ selection criteria for Bandwidth Constraints Models\n   (BCMs) for the purpose\
    \ of allocating bandwidth to individual classes.\n   This document presents a\
    \ performance analysis for the two BCMs\n   described in [1]:\n   (1) Maximum\
    \ Allocation Model (MAM) - the maximum allowable bandwidth\n       usage of each\
    \ class, together with the aggregate usage across all\n       classes, are explicitly\
    \ specified.\n   (2) Russian Dolls Model (RDM) - specification of maximum allowable\n\
    \       usage is done cumulatively by grouping successive priority\n       classes\
    \ recursively.\n   The following criteria are also listed in [1] for investigating\
    \ the\n   performance and trade-offs of different operational aspects of BCMs:\n\
    \   (1) addresses the scenarios in Section 2 of [1]\n   (2) works well under both\
    \ normal and overload conditions\n   (3) applies equally when preemption is either\
    \ enabled or disabled\n   (4) minimizes signaling load processing requirements\n\
    \   (5) maximizes efficient use of the network\n   (6) minimizes implementation\
    \ and deployment complexity\n   The use of any given BCM has significant impacts\
    \ on the capability of\n   a network to provide protection for different classes\
    \ of traffic,\n   particularly under high load, so that performance objectives\
    \ can be\n   met [3].  This document complements [1] by presenting the results\
    \ of\n   a performance evaluation of the above two BCMs under various\n   operational\
    \ conditions: normal load, overload, preemption fully or\n   partially enabled,\
    \ pure blocking, or complete sharing.  Thus, our\n   focus is only on the performance-oriented\
    \ criteria and their\n   implications for a network implementation.  In other\
    \ words, we are\n   only concerned with criteria (2), (3), and (5); we will not\
    \ address\n   criteria (1), (4), or (6).\n   Related documents in this area include\
    \ [4], [5], [6], [7], and [8].\n   In the rest of this document, the following\
    \ DS-TE acronyms are used:\n      BC    Bandwidth Constraint\n      BCM   Bandwidth\
    \ Constraints Model\n      MAM   Maximum Allocation Model\n      RDM   Russian\
    \ Dolls Model\n   There may be differences between the quality of service expressed\
    \ and\n   obtained with Diffserv without DS-TE and with DS-TE.  Because DS-TE\n\
    \   uses Constraint Based Routing, and because of the type of admission\n   control\
    \ capabilities it adds to Diffserv, DS-TE has capabilities for\n   traffic that\
    \ Diffserv does not.  Diffserv does not indicate\n   preemption, by intent, whereas\
    \ DS-TE describes multiple levels of\n   preemption for its Class-Types.  Also,\
    \ Diffserv does not support any\n   means of explicitly controlling overbooking,\
    \ while DS-TE allows this.\n   When considering a complete quality of service\
    \ environment, with\n   Diffserv routers and DS-TE, it is important to consider\
    \ these\n   differences carefully.\n"
- title: 1.1.  Conventions used in this document
  contents:
  - "1.1.  Conventions used in this document\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in RFC 2119.\n"
- title: 2.  Bandwidth Constraints Models
  contents:
  - "2.  Bandwidth Constraints Models\n   To simplify our presentation, we use the\
    \ informal name \"class of\n   traffic\" for the terms Class-Type and TE-Class,\
    \ defined in [1].  We\n   assume that (1) there are only three classes of traffic,\
    \ and that (2)\n   all label-switched paths (LSPs), regardless of class, require\
    \ the\n   same amount of bandwidth.  Furthermore, the focus is on the bandwidth\n\
    \   usage of an individual link with a given capacity; routing aspects of\n  \
    \ LSP setup are not considered.\n   The concept of reserved bandwidth is also\
    \ defined in [1] to account\n   for the possible use of overbooking.  Rather than\
    \ get into these\n   details, we assume that each LSP is allocated 1 unit of bandwidth\
    \ on\n   a given link after establishment.  This allows us to express link\n \
    \  bandwidth usage simply in terms of the number of simultaneously\n   established\
    \ LSPs.  Link capacity can then be used as the aggregate\n   constraint on bandwidth\
    \ usage across all classes.\n   Suppose that the three classes of traffic assumed\
    \ above for the\n   purposes of this document are denoted by class 1 (highest\
    \ priority),\n   class 2, and class 3 (lowest priority).  When preemption is enabled,\n\
    \   these are the preemption priorities.  To define a generic class of\n   BCMs\
    \ for the purpose of our analysis in accordance with the above\n   assumptions,\
    \ let\n      Nmax = link capacity; i.e., the maximum number of simultaneously\n\
    \             established LSPs for all classes together\n      Nc = the number\
    \ of simultaneously established class c LSPs,\n           for c = 1, 2, and 3,\
    \ respectively.\n   For MAM, let\n      Bc = maximum number of simultaneously\
    \ established class c LSPs.\n   Then, Bc is the Bandwidth Constraint for class\
    \ c, and we have\n      Nc <= Bc <= Nmax, for c = 1, 2, and 3\n      N1 + N2 +\
    \ N3 <= Nmax\n      B1 + B2 + B3 >= Nmax\n   For RDM, the BCs are specified as:\n\
    \      B1 = maximum number of simultaneously established class 1 LSPs\n      B2\
    \ = maximum number of simultaneously established LSPs for classes\n          \
    \ 1 and 2 together\n      B3 = maximum number of simultaneously established LSPs\
    \ for classes\n           1, 2, and 3 together\n   Then, we have the following\
    \ relationships:\n      N1 <= B1\n      N1 + N2 <= B2\n      N1 + N2 + N3 <= B3\n\
    \      B1 < B2 < B3 = Nmax\n"
- title: 3.  Performance Model
  contents:
  - "3.  Performance Model\n   Reference [8] presents a 3-class Markov-chain performance\
    \ model to\n   analyze a general class of BCMs.  The BCMs that can be analyzed\n\
    \   include, besides MAM and RDM, BCMs with privately reserved bandwidth\n   that\
    \ cannot be preempted by other classes.\n   The Markov-chain performance model\
    \ in [8] assumes Poisson arrivals\n   for LSP requests with exponentially distributed\
    \ lifetime.  The\n   Poisson assumption for LSP requests is relevant since we\
    \ are not\n   dealing with the arrivals of individual packets within an LSP. \
    \ Also,\n   LSP lifetime may exhibit heavy-tail characteristics.  This effect\n\
    \   should be accounted for when the performance of a particular BCM by\n   itself\
    \ is evaluated.  As the effect would be common for all BCMs, we\n   ignore it\
    \ for simplicity in the comparative analysis of the relative\n   performance of\
    \ different BCMs.  In principle, a suitably chosen\n   hyperexponential distribution\
    \ may be used to capture some aspects of\n   heavy tail.  However, this will significantly\
    \ increase the complexity\n   of the non-product-form preemption model in [8].\n\
    \   The model in [8] assumes the use of admission control to allocate\n   link\
    \ bandwidth to LSPs of different classes in accordance with their\n   respective\
    \ BCs.  Thus, the model accepts as input the link capacity\n   and offered load\
    \ from different classes.  The blocking and preemption\n   probabilities for different\
    \ classes under different BCs are generated\n   as output.  Thus, from a service\
    \ provider's perspective, given the\n   desired level of blocking and preemption\
    \ performance, the model can\n   be used iteratively to determine the corresponding\
    \ set of BCs.\n   To understand the implications of using criteria (2), (3), and\
    \ (5) in\n   the Introduction Section to select a BCM, we present some numerical\n\
    \   results of the analysis in [8].  This is intended to facilitate\n   discussion\
    \ of the issues that can arise.  The major performance\n   objective is to achieve\
    \ a balance between the need for bandwidth\n   sharing (for increasing bandwidth\
    \ efficiency) and the need for\n   bandwidth isolation (for protecting bandwidth\
    \ access by different\n   classes).\n"
- title: 3.1.  LSP Blocking and Preemption
  contents:
  - "3.1.  LSP Blocking and Preemption\n   As described in Section 2, the three classes\
    \ of traffic used as an\n   example are class 1 (highest priority), class 2, and\
    \ class 3 (lowest\n   priority).  Preemption may or may not be used, and we will\
    \ examine\n   the performance of each scenario.  When preemption is used, the\n\
    \   priorities are the preemption priorities.  We consider cross-class\n   preemption\
    \ only, with no within-class preemption.  In other words,\n   preemption is enabled\
    \ so that, when necessary, class 1 can preempt\n   class 3 or class 2 (in that\
    \ order), and class 2 can preempt class 3.\n   Each class offers a load of traffic\
    \ to the network that is expressed\n   in terms of the arrival rate of its LSP\
    \ requests and the average\n   lifetime of an LSP.  A unit of such a load is an\
    \ erlang.  (In\n   packet-based networks, traffic volume is usually measured by\
    \ counting\n   the number of bytes and/or packets that are sent or received over\
    \ an\n   interface during a measurement period.  Here we are only concerned\n\
    \   with bandwidth allocation and usage at the LSP level.  Therefore, as\n   a\
    \ measure of resource utilization in a link-speed independent manner,\n   the\
    \ erlang is an appropriate unit for our purpose [9].)\n   To prevent Diffserv\
    \ QoS degradation at the packet level, the expected\n   number of established\
    \ LSPs for a given class should be kept in line\n   with the average service rate\
    \ that the Diffserv scheduler can provide\n   to that class.  Because of the use\
    \ of overbooking, the actual traffic\n   carried by a link may be higher than\
    \ expected, and hence QoS\n   degradation may not be totally avoidable.\n   However,\
    \ the use of admission control at the LSP level helps minimize\n   QoS degradation\
    \ by enforcing the BCs established for the different\n   classes, according to\
    \ the rules of the BCM adopted.  That is, the BCs\n   are used to determine the\
    \ number of LSPs that can be simultaneously\n   established for different classes\
    \ under various operational\n   conditions.  By controlling the number of LSPs\
    \ admitted from\n   different classes, this in turn ensures that the amount of\
    \ traffic\n   submitted to the Diffserv scheduler is compatible with the targeted\n\
    \   packet-level QoS objectives.\n   The performance of a BCM can therefore be\
    \ measured by how well the\n   given BCM handles the offered traffic, under normal\
    \ or overload\n   conditions, while maintaining packet-level service objectives.\
    \  Thus,\n   assuming that the enforcement of Diffserv QoS objectives by admission\n\
    \   control is a given, the performance of a BCM can be expressed in\n   terms\
    \ of LSP blocking and preemption probabilities.\n   Different BCMs have different\
    \ strengths and weaknesses.  Depending on\n   the BCs chosen for a given load,\
    \ a BCM may perform well in one\n   operating region and poorly in another.  Service\
    \ providers are mainly\n   concerned with the utility of a BCM to meet their operational\
    \ needs.\n   Regardless of which BCM is deployed, the foremost consideration is\n\
    \   that the BCM works well under the engineered load, such as the\n   ability\
    \ to deliver service-level objectives for LSP blocking\n   probabilities.  It\
    \ is also expected that the BCM handles overload\n   \"reasonably\" well.  Thus,\
    \ for comparison, the common operating point\n   we choose for BCMs is that they\
    \ meet specified performance objectives\n   in terms of blocking/preemption under\
    \ given normal load.  We then\n   observe how their performance varies under overload.\
    \  More will be\n   said about this aspect later in Section 4.2.\n"
- title: 3.2.  Example Link Traffic Model
  contents:
  - "3.2.  Example Link Traffic Model\n   For example, consider a link with a capacity\
    \ that allows a maximum of\n   15 LSPs from different classes to be established\
    \ simultaneously.  All\n   LSPs are assumed to have an average lifetime of 1 time\
    \ unit.  Suppose\n   that this link is being offered a load of\n   2.7 erlangs\
    \ from class 1,\n   3.5 erlangs from class 2, and\n   3.5 erlangs from class 3.\n\
    \   We now consider a scenario wherein the blocking/preemption\n   performance\
    \ objectives for the three classes are desired to be\n   comparable under normal\
    \ conditions (other scenarios are covered in\n   later sections).  To meet this\
    \ service requirement under the above\n   given load, the BCs are selected as\
    \ follows:\n   For MAM:\n   up to 6 simultaneous LSPs for class 1,\n   up to 7\
    \ simultaneous LSPs for class 2, and\n   up to 15 simultaneous LSPs for class\
    \ 3.\n   For RDM:\n   up to 6 simultaneous LSPs for class 1 by itself,\n   up\
    \ to 11 simultaneous LSPs for classes 1 and 2 together, and\n   up to 15 simultaneous\
    \ LSPs for all three classes together.\n   Note that the driver is service requirement,\
    \ independent of BCM.  The\n   above BCs are not picked arbitrarily; they are\
    \ chosen to meet\n   specific performance objectives in terms of blocking/preemption\n\
    \   (detailed in the next section).\n   An intuitive \"explanation\" for the above\
    \ set of BCs may be as\n   follows.  Class 1 BC is the same (6) for both models,\
    \ as class 1 is\n   treated the same way under either model with preemption. \
    \ However,\n   MAM and RDM operate in fundamentally different ways and give\n\
    \   different treatments to classes with lower preemption priorities.  It\n  \
    \ can be seen from Section 2 that although RDM imposes a strict\n   ordering of\
    \ the different BCs (B1 < B2 < B3) and a hard boundary\n   (B3 = Nmax), MAM uses\
    \ a soft boundary (B1+B2+B3 >= Nmax) with no\n   specific ordering.  As will be\
    \ explained in Section 4.3, this allows\n   RDM to have a higher degree of sharing\
    \ among different classes.  Such\n   a higher degree of coupling means that the\
    \ numerical values of the\n   BCs can be relatively smaller than those for MAM,\
    \ to meet given\n   performance requirements under normal load.\n   Thus, in the\
    \ above example, the RDM BCs of (6, 11, 15) may be thought\n   of as roughly corresponding\
    \ to the MAM BCs of (6, 6+7, 6+7+15).  (The\n   intent here is just to point out\
    \ that the design parameters for the\n   two BCMs need to be different, as they\
    \ operate differently; strictly\n   speaking, the numerical correspondence is\
    \ incorrect.)  Of course,\n   both BCMs are bounded by the same aggregate constraint\
    \ of the link\n   capacity (15).\n   The BCs chosen in the above example are not\
    \ intended to be regarded\n   as typical values used by any service provider.\
    \  They are used here\n   mainly for illustrative purposes.  The method we used\
    \ for analysis\n   can easily accommodate another set of parameter values as input.\n"
- title: 3.3.  Performance under Normal Load
  contents:
  - "3.3.  Performance under Normal Load\n   In the example above, based on the BCs\
    \ chosen, the blocking and\n   preemption probabilities for LSP setup requests\
    \ under normal\n   conditions for the two BCMs are given in Table 1.  Remember\
    \ that the\n   BCs have been selected for this scenario to address the service\n\
    \   requirement to offer comparable blocking/preemption objectives for\n   the\
    \ three classes.\n   Table 1.  Blocking and preemption probabilities\n   BCM \
    \    PB1      PB2      PB3      PP2      PP3    PB2+PP2  PB3+PP3\n   MAM   0.03692\
    \  0.03961  0.02384     0     0.02275  0.03961  0.04659\n   RDM   0.03692  0.02296\
    \  0.02402  0.01578  0.01611  0.03874  0.04013\n   In the above table, the following\
    \ apply:\n   PB1 = blocking probability of class 1\n   PB2 = blocking probability\
    \ of class 2\n   PB3 = blocking probability of class 3\n   PP2 = preemption probability\
    \ of class 2\n   PP3 = preemption probability of class 3\n   PB2+PP2 = combined\
    \ blocking/preemption probability of class 2\n   PB3+PP3 = combined blocking/preemption\
    \ probability of class 3\n   First, we observe that, indeed, the values for (PB1,\
    \ PB2+PP2,\n   PB3+PP3) are very similar one to another.  This confirms that the\n\
    \   service requirement (of comparable blocking/preemption objectives for\n  \
    \ the three classes) has been met for both BCMs.\n   Then, we observe that the\
    \ (PB1, PB2+PP2, PB3+PP3) values for MAM are\n   very similar to the (PB1, PB2+PP2,\
    \ PB3+PP3) values for RDM.  This\n   indicates that, in this scenario, both BCMs\
    \ offer very similar\n   performance under normal load.\n   From column 2 of Table\
    \ 1, it can be seen that class 1 sees exactly\n   the same blocking under both\
    \ BCMs.  This should be obvious since both\n   allocate up to 6 simultaneous LSPs\
    \ for use by class 1 only.  Slightly\n   better results are obtained from RDM,\
    \ as shown by the last two\n   columns in Table 1.  This comes about because the\
    \ cascaded bandwidth\n   separation in RDM effectively gives class 3 some form\
    \ of protection\n   from being preempted by higher-priority classes.\n   Also,\
    \ note that PP2 is zero in this particular case, simply because\n   the BCs for\
    \ MAM happen to have been chosen in such a way that class 1\n   never has to preempt\
    \ class 2 for any of the bandwidth that class 1\n   needs.  (This is because class\
    \ 1 can, in the worst case, get all the\n   bandwidth it needs simply by preempting\
    \ class 3 alone.)  In general,\n   this will not be the case.\n   It is interesting\
    \ to compare these results with those for the case of\n   a single class.  Based\
    \ on the Erlang loss formula, a capacity of 15\n   servers can support an offered\
    \ load of 10 erlangs with a blocking\n   probability of 0.0364969.  Whereas the\
    \ total load for the 3-class BCM\n   is less with 2.7 + 3.5 + 3.5 = 9.7 erlangs,\
    \ the probabilities of\n   blocking/preemption are higher.  Thus, there is some\
    \ loss of\n   efficiency due to the link bandwidth being partitioned to accommodate\n\
    \   for different traffic classes, thereby resulting in less sharing.\n   This\
    \ aspect will be examined in more detail later, in Section 7 on\n   Complete Sharing.\n"
- title: 4.  Performance under Overload
  contents:
  - "4.  Performance under Overload\n   Overload occurs when the traffic on a system\
    \ is greater than the\n   traffic capacity of the system.  To investigate the\
    \ performance under\n   overload conditions, the load of each class is varied\
    \ separately.\n   Blocking and preemption probabilities are not shown separately\
    \ for\n   each case; they are added together to yield a combined\n   blocking/preemption\
    \ probability.\n"
- title: 4.1.  Bandwidth Sharing versus Isolation
  contents:
  - "4.1.  Bandwidth Sharing versus Isolation\n   Figures 1 and 2 show the relative\
    \ performance when the load of each\n   class in the example of Section 3.2 is\
    \ varied separately.  The three\n   series of data in each of these figures are,\
    \ respectively,\n   class 1 blocking probability (\"Class 1 B\"),\n   class 2\
    \ blocking/preemption probability (\"Class 2 B+P\"), and\n   class 3 blocking/preemption\
    \ probability (\"Class 3 B+P\").\n   For each of these series, the first set of\
    \ four points is for the\n   performance when class 1 load is increased from half\
    \ of its normal\n   load to twice its normal.  Similarly, the next and the last\
    \ sets of\n   four points are when class 2 and class 3 loads are increased\n \
    \  correspondingly.\n   The following observations apply to both BCMs:\n   1.\
    \ The performance of any class generally degrades as its load\n      increases.\n\
    \   2. The performance of class 1 is not affected by any changes\n      (increases\
    \ or decreases) in either class 2 or class 3 traffic,\n      because class 1 can\
    \ always preempt others.\n   3. Similarly, the performance of class 2 is not affected\
    \ by any\n      changes in class 3 traffic.\n   4. Class 3 sees better (worse)\
    \ than normal performance when either\n      class 1 or class 2 traffic is below\
    \ (above) normal.\n   In contrast, the impact of the changes in class 1 traffic\
    \ on class 2\n   performance is different for the two BCMs: It is negligible in\
    \ MAM\n   and significant in RDM.\n   1. Although class 2 sees little improvement\
    \ (no improvement in this\n      particular example) in performance when class\
    \ 1 traffic is below\n      normal when MAM is used, it sees better than normal\
    \ performance\n      under RDM.\n   2. Class 2 sees no degradation in performance\
    \ when class 1 traffic is\n      above normal when MAM is used.  In this example,\
    \ with BCs 6 + 7 <\n      15, class 1 and class 2 traffic is effectively being\
    \ served by\n      separate pools.  Therefore, class 2 sees no preemption, and\
    \ only\n      class 3 is being preempted whenever necessary.  This fact is\n \
    \     confirmed by the Erlang loss formula: a load of 2.7 erlangs\n      offered\
    \ to 6 servers sees a 0.03692 blocking, and a load of 3.5\n      erlangs offered\
    \ to 7 servers sees a 0.03961 blocking.  These\n      blocking probabilities are\
    \ exactly the same as the corresponding\n      entries in Table 1: PB1 and PB2\
    \ for MAM.\n   3. This is not the case in RDM.  Here, the probability for class\
    \ 2 to\n      be preempted by class 1 is nonzero because of two effects.  (1)\n\
    \      Through the cascaded bandwidth arrangement, class 3 is protected\n    \
    \  somewhat from preemption.  (2) Class 2 traffic is sharing a BC\n      with\
    \ class 1.  Consequently, class 2 suffers when class 1 traffic\n      increases.\n\
    \   Thus, it appears that although the cascaded bandwidth arrangement and\n  \
    \ the resulting bandwidth sharing makes RDM work better under normal\n   conditions,\
    \ such interaction makes it less effective to provide class\n   isolation under\
    \ overload conditions.\n"
- title: 4.2.  Improving Class 2 Performance at the Expense of Class 3
  contents:
  - "4.2.  Improving Class 2 Performance at the Expense of Class 3\n   We now consider\
    \ a scenario in which the service requirement is to\n   give better blocking/preemption\
    \ performance to class 2 than to class\n   3, while maintaining class 1 performance\
    \ at the same level as in the\n   previous scenario.  (The use of minimum deterministic\
    \ guarantee for\n   class 3 is to be considered in the next section.)  So that\
    \ the\n   specified class 2 performance objective can be met, class 2 BC is\n\
    \   increased appropriately.  As an example, BCs (6, 9, 15) are now used\n   for\
    \ MAM, and (6, 13, 15) for RDM.  For both BCMs, as shown in Figures\n   1bis and\
    \ 2bis, although class 1 performance remains unchanged, class\n   2 now receives\
    \ better performance, at the expense of class 3. This is\n   of course due to\
    \ the increased access of bandwidth by class 2 over\n   class 3.  Under normal\
    \ conditions, the performance of the two BCMs is\n   similar in terms of their\
    \ blocking and preemption probabilities for\n   LSP setup requests, as shown in\
    \ Table 2.\n   Table 2.  Blocking and preemption probabilities\n   BCM      PB1\
    \      PB2      PB3      PP2      PP3    PB2+PP2  PB3+PP3\n   MAM    0.03692 \
    \ 0.00658  0.02733     0     0.02709  0.00658  0.05441\n   RDM    0.03692  0.00449\
    \  0.02759  0.00272  0.02436  0.00721  0.05195\n   Under overload, the observations\
    \ in Section 4.1 regarding the\n   difference in the general behavior between\
    \ the two BCMs still apply,\n   as shown in Figures 1bis and 2bis.\n   The following\
    \ are two frequently asked questions about the operation\n   of BCMs.\n   (1)\
    \ For a link capacity of 15, would a class 1 BC of 6 and a class 2\n       BC\
    \ of 9 in MAM result in the possibility of a total lockout for\n       class 3?\n\
    \   This will certainly be the case when there are 6 class 1 and 9 class\n   2\
    \ LSPs being established simultaneously.  Such an offered load (with\n   6 class\
    \ 1 and 9 class 2 LSP requests) will not cause a lockout of\n   class 3 with RDM\
    \ having a BC of 13 for classes 1 and 2 combined, but\n   will result in class\
    \ 2 LSPs being rejected.  If class 2 traffic were\n   considered relatively more\
    \ important than class 3 traffic, then RDM\n   would perform very poorly compared\
    \ to MAM with BCs of (6, 9, 15).\n   (2) Should MAM with BCs of (6, 7, 15) be\
    \ used instead so as to make\n       the performance of RDM look comparable?\n\
    \   The answer is that the above scenario is not very realistic when the\n   offered\
    \ load is assumed to be (2.7, 3.5, 3.5) for the three classes,\n   as stated in\
    \ Section 3.2.  Treating an overload of (6, 9, x) as a\n   normal operating condition\
    \ is incompatible with the engineering of\n   BCs according to needed bandwidth\
    \ from different classes.  It would\n   be rare for a given class to need so much\
    \ more than its engineered\n   bandwidth level.  But if the class did, the expectation\
    \ based on\n   design and normal traffic fluctuations is that this class would\n\
    \   quickly release unneeded bandwidth toward its engineered level,\n   freeing\
    \ up bandwidth for other classes.\n   Service providers engineer their networks\
    \ based on traffic\n   projections to determine network configurations and needed\
    \ capacity.\n   All BCMs should be designed to operate under realistic network\n\
    \   conditions.  For any BCM to work properly, the selection of values\n   for\
    \ different BCs must therefore be based on the projected bandwidth\n   needs of\
    \ each class, as well as on the bandwidth allocation rules of\n   the BCM itself.\
    \  This is to ensure that the BCM works as expected\n   under the intended design\
    \ conditions.  In operation, the actual load\n   may well turn out to be different\
    \ from that of the design.  Thus, an\n   assessment of the performance of a BCM\
    \ under overload is essential to\n   see how well the BCM can cope with traffic\
    \ surges or network\n   failures.  Reflecting this view, the basis for comparison\
    \ of two BCMs\n   is that they meet the same or similar performance requirements\
    \ under\n   normal conditions, and how they withstand overload.\n   In operational\
    \ practice, load measurement and forecast would be\n   useful to calibrate and\
    \ fine-tune the BCs so that traffic from\n   different classes could be redistributed\
    \ accordingly.  Dynamic\n   adjustment of the Diffserv scheduler could also be\
    \ used to minimize\n   QoS degradation.\n"
- title: 4.3.  Comparing Bandwidth Constraints of Different Models
  contents:
  - "4.3.  Comparing Bandwidth Constraints of Different Models\n   As is pointed out\
    \ in Section 3.2, the higher degree of sharing among\n   the different classes\
    \ in RDM means that the numerical values of the\n   BCs could be relatively smaller\
    \ than those for MAM. We now examine\n   this aspect in more detail by considering\
    \ the following scenario.  We\n   set the BCs so that (1) for both BCMs, the same\
    \ value is used for\n   class 1, (2) the same minimum deterministic guarantee\
    \ of bandwidth\n   for class 3 is offered by both BCMs, and (3) the blocking/preemption\n\
    \   probability is minimized for class 2.  We want to emphasize that this\n  \
    \ may not be the way service providers select BCs.  It is done here to\n   investigate\
    \ the statistical behavior of such a deterministic\n   mechanism.\n   For illustration,\
    \ we use BCs (6, 7, 15) for MAM, and (6, 13, 15) for\n   RDM.  In this case, both\
    \ BCMs have 13 units of bandwidth for classes\n   1 and 2 together, and dedicate\
    \ 2 units of bandwidth for use by class\n   3 only.  The performance of the two\
    \ BCMs under normal conditions is\n   shown in Table 3.  It is clear that MAM\
    \ with (6, 7, 15) gives fairly\n   comparable performance objectives across the\
    \ three classes, whereas\n   RDM with (6, 13, 15) strongly favors class 2 at the\
    \ expense of class\n   3.  They therefore cater to different service requirements.\n\
    \   Table 3.  Blocking and preemption probabilities\n   BCM      PB1      PB2\
    \      PB3      PP2      PP3    PB2+PP2  PB3+PP3\n   MAM    0.03692  0.03961 \
    \ 0.02384     0     0.02275  0.03961  0.04659\n   RDM    0.03692  0.00449  0.02759\
    \  0.00272  0.02436  0.00721  0.05195\n   By comparing Figures 1 and 2bis, it\
    \ can be seen that, when being\n   subjected to the same set of BCs, RDM gives\
    \ class 2 much better\n   performance than MAM, with class 3 being only slightly\
    \ worse.\n   This confirms the observation in Section 3.2 that, when the same\n\
    \   service requirements under normal conditions are to be met, the\n   numerical\
    \ values of the BCs for RDM can be relatively smaller than\n   those for MAM.\
    \  This should not be surprising in view of the hard\n   boundary (B3 = Nmax)\
    \ in RDM versus the soft boundary (B1+B2+B3 >=\n   Nmax) in MAM.  The strict ordering\
    \ of BCs (B1 < B2 < B3) gives RDM\n   the advantage of a higher degree of sharing\
    \ among the different\n   classes; i.e., the ability to reallocate the unused\
    \ bandwidth of\n   higher-priority classes to lower-priority ones, if needed.\n\
    \   Consequently, this leads to better performance when an identical set\n   of\
    \ BCs is used as exemplified above.  Such a higher degree of sharing\n   may necessitate\
    \ the use of minimum deterministic bandwidth guarantee\n   to offer some protection\
    \ for lower-priority traffic from preemption.\n   The explicit lack of ordering\
    \ of BCs in MAM and its soft boundary\n   imply that the use of minimum deterministic\
    \ guarantees for lower-\n   priority classes may not need to be enforced when\
    \ there is a lesser\n   degree of sharing.  This is demonstrated by the example\
    \ in Section\n   4.2 with BCs (6, 9, 15) for MAM.\n   For illustration, Table\
    \ 4 shows the performance under normal\n   conditions of RDM with BCs (6, 15,\
    \ 15).\n   Table 4.  Blocking and preemption probabilities\n   BCM      PB1  \
    \    PB2      PB3      PP2      PP3    PB2+PP2  PB3+PP3\n   RDM    0.03692  0.00060\
    \  0.02800  0.00032  0.02740  0.00092  0.05540\n   Regardless of whether deterministic\
    \ guarantees are used, both BCMs\n   are bounded by the same aggregate constraint\
    \ of the link capacity.\n   Also, in both BCMs, bandwidth access guarantees are\
    \ necessarily\n   achieved statistically because of traffic fluctuations, as explained\n\
    \   in Section 4.2.  (As a result, service-level objectives are typically\n  \
    \ specified as monthly averages, under the use of statistical\n   guarantees rather\
    \ than deterministic guarantees.) Thus, given the\n   fundamentally different\
    \ operating principles of the two BCMs\n   (ordering, hard versus soft boundary),\
    \ the dimensions of one BCM\n   should not be adopted to design for the other.\
    \  Rather, it is the\n   service requirements, and perhaps also the operational\
    \ needs, of a\n   service provider that should be used to drive how the BCs of\
    \ a BCM\n   are selected.\n"
- title: 5.  Performance under Partial Preemption
  contents:
  - "5.  Performance under Partial Preemption\n   In the previous two sections, preemption\
    \ is fully enabled in the\n   sense that class 1 can preempt class 3 or class\
    \ 2 (in that order),\n   and class 2 can preempt class 3.  That is, both classes\
    \ 1 and 2 are\n   preemptor-enabled, whereas classes 2 and 3 are preemptable.\
    \  A class\n   that is preemptor-enabled can preempt lower-priority classes\n\
    \   designated as preemptable.  A class not designated as preemptable\n   cannot\
    \ be preempted by any other classes, regardless of relative\n   priorities.\n\
    \   We now consider the three cases shown in Table 5, in which preemption\n  \
    \ is only partially enabled.\n   Table 5.  Partial preemption modes\n   preemption\
    \ modes         preemptor-enabled     preemptable\n   \"1+2 on 3\" (Fig. 3, 6)\
    \   class 1, class 2        class 3\n   \"1 on 3\"   (Fig. 4, 7)       class 1\
    \             class 3\n   \"1 on 2+3\" (Fig. 5, 8)       class 1         class\
    \ 3, class 2\n   In this section, we evaluate how these preemption modes affect\
    \ the\n   performance of a particular BCM.  Thus, we are comparing how a given\n\
    \   BCM performs when preemption is fully enabled versus how the same BCM\n  \
    \ performs when preemption is partially enabled.  The performance of\n   these\
    \ preemption modes is shown in Figures 3 to 5 for RDM, and in\n   Figures 6 through\
    \ 8 for MAM, respectively.  In all of these figures,\n   the BCs of Section 3.2\
    \ are used for illustration; i.e., (6, 7, 15)\n   for MAM and (6, 11, 15) for\
    \ RDM.  However, the general behavior is\n   similar when the BCs are changed\
    \ to those in Sections 4.2 and 4.3;\n   i.e., (6, 9, 15) and (6, 13, 15), respectively.\n"
- title: 5.1.  Russian Dolls Model
  contents:
  - "5.1.  Russian Dolls Model\n   Let us first examine the performance under RDM.\
    \  There are two sets\n   of results, depending on whether class 2 is preemptable:\
    \ (1) Figures\n   3 and 4 for the two modes when only class 3 is preemptable,\
    \ and (2)\n   Figure 2 in the previous section and Figure 5 for the two modes\
    \ when\n   both classes 2 and 3 are preemptable.  By comparing these two sets\
    \ of\n   results, the following impacts can be observed.  Specifically, when\n\
    \   class 2 is non-preemptable, the behavior of each class is as follows:\n  \
    \ 1. Class 1 generally sees a higher blocking probability.  As the\n      class\
    \ 1 space allocated by the class 1 BC is shared with class 2,\n      which is\
    \ now non-preemptable, class 1 cannot reclaim any such\n      space occupied by\
    \ class 2 when needed.  Also, class 1 has less\n      opportunity to preempt,\
    \ as it is able to preempt class 3 only.\n   2. Class 3 also sees higher blocking/preemption\
    \ when its own load is\n      increased, as it is being preempted more frequently\
    \ by class 1,\n      when class 1 cannot preempt class 2.  (See the last set of\
    \ four\n      points in the series for class 3 shown in Figures 3 and 4, when\n\
    \      comparing with Figures 2 and 5.)\n   3. Class 2 blocking/preemption is\
    \ reduced even when its own load is\n      increased, since it is not being preempted\
    \ by class 1.  (See the\n      middle set of four points in the series for class\
    \ 2 shown in\n      Figures 3 and 4, when comparing with Figures 2 and 5.)\n \
    \  Another two sets of results are related to whether class 2 is\n   preemptor-enabled.\
    \  In this case, when class 2 is not preemptor-\n   enabled, class 2 blocking/preemption\
    \ is increased when class 3 load\n   is increased.  (See the last set of four\
    \ points in the series for\n   class 2 shown in Figures 4 and 5, when comparing\
    \ with Figures 2 and\n   3.)  This is because both classes 2 and 3 are now competing\n\
    \   independently with each other for resources.\n"
- title: 5.2.  Maximum Allocation Model
  contents:
  - "5.2.  Maximum Allocation Model\n   Turning now to MAM, the significant impact\
    \ appears to be only on\n   class 2, when it cannot preempt class 3, thereby causing\
    \ its\n   blocking/preemption to increase in two situations.\n   1. When class\
    \ 1 load is increased.  (See the first set of four points\n      in the series\
    \ for class 2 shown in Figures 7 and 8, when comparing\n      with Figures 1 and\
    \ 6.)\n   2. When class 3 load is increased.  (See the last set of four points\n\
    \      in the series for class 2 shown in Figures 7 and 8, when comparing\n  \
    \    with Figures 1 and 6.)  This is similar to RDM; i.e., class 2 and\n     \
    \ class 3 are now competing with each other.\n   When Figure 1 (for the case of\
    \ fully enabled preemption) is compared\n   to Figures 6 through 8 (for partially\
    \ enabled preemption), it can be\n   seen that the performance of MAM is relatively\
    \ insensitive to the\n   different preemption modes.  This is because when each\
    \ class has its\n   own bandwidth access limits, the degree of interference among\
    \ the\n   different classes is reduced.\n   This is in contrast with RDM, whose\
    \ behavior is more dependent on the\n   preemption mode in use.\n"
- title: 6.  Performance under Pure Blocking
  contents:
  - "6.  Performance under Pure Blocking\n   This section covers the case in which\
    \ preemption is completely\n   disabled.  We continue with the numerical example\
    \ used in the\n   previous sections, with the same link capacity and offered load.\n"
- title: 6.1.  Russian Dolls Model
  contents:
  - "6.1.  Russian Dolls Model\n   For RDM, we consider two different settings:\n\
    \   \"Russian Dolls (1)\" BCs:\n   up to 6 simultaneous LSPs for class 1 by itself,\n\
    \   up to 11 simultaneous LSPs for classes 1 and 2 together, and\n   up to 15\
    \ simultaneous LSPs for all three classes together.\n   \"Russian Dolls (2)\"\
    \ BCs:\n   up to 9 simultaneous LSPs for class 3 by itself,\n   up to 14 simultaneous\
    \ LSPs for classes 3 and 2 together, and\n   up to 15 simultaneous LSPs for all\
    \ three classes together.\n   Note that the \"Russian Dolls (1)\" set of BCs is\
    \ the same as\n   previously with preemption enabled, whereas the \"Russian Dolls\
    \ (2)\"\n   has the cascade of bandwidth arranged in reverse order of the\n  \
    \ classes.\n   As observed in Section 4, the cascaded bandwidth arrangement is\n\
    \   intended to offer lower-priority traffic some protection from\n   preemption\
    \ by higher-priority traffic.  This is to avoid starvation.\n   In a pure blocking\
    \ environment, such protection is no longer\n   necessary.  As depicted in Figure\
    \ 9, it actually produces the\n   opposite, undesirable effect: higher-priority\
    \ traffic sees higher\n   blocking than lower-priority traffic.  With no preemption,\
    \ higher-\n   priority traffic should be protected instead to ensure that it could\n\
    \   get through when under high load.  Indeed, when the reverse cascade\n   is\
    \ used in \"Russian Dolls (2)\", the required performance of lower\n   blocking\
    \ for higher-priority traffic is achieved, as shown in Figure\n   10.  In this\
    \ specific example, there is very little difference among\n   the performance\
    \ of the three classes in the first eight data points\n   for each of the three\
    \ series.  However, the BCs can be tuned to get a\n   bigger differentiation.\n"
- title: 6.2.  Maximum Allocation Model
  contents:
  - "6.2.  Maximum Allocation Model\n   For MAM, we also consider two different settings:\n\
    \   \"Exp. Max. Alloc. (1)\" BCs:\n   up to 7 simultaneous LSPs for class 1,\n\
    \   up to 8 simultaneous LSPs for class 2, and\n   up to 8 simultaneous LSPs for\
    \ class 3.\n   \"Exp. Max. Alloc. (2)\" BCs:\n   up to 7 simultaneous LSPs for\
    \ class 1, with additional bandwidth for\n      1 LSP privately reserved\n   up\
    \ to 8 simultaneous LSPs for class 2, and\n   up to 8 simultaneous LSPs for class\
    \ 3.\n   These BCs are chosen so that, under normal conditions, the blocking\n\
    \   performance is similar to all the previous scenarios.  The only\n   difference\
    \ between these two sets of values is that the \"Exp. Max.\n   Alloc. (2)\" algorithm\
    \ gives class 1 a private pool of 1 server for\n   class protection.  As a result,\
    \ class 1 has a relatively lower\n   blocking especially when its traffic is above\
    \ normal, as can be seen\n   by comparing Figures 11 and 12.  This comes, of course,\
    \ with a slight\n   increase in the blocking of classes 2 and 3 traffic.\n   When\
    \ comparing the \"Russian Dolls (2)\" in Figure 10 with MAM in\n   Figures 11\
    \ or 12, the difference between their behavior and the\n   associated explanation\
    \ are again similar to the case when preemption\n   is used.  The higher degree\
    \ of sharing in the cascaded bandwidth\n   arrangement of RDM leads to a tighter\
    \ coupling between the different\n   classes of traffic when under overload. \
    \ Their performance therefore\n   tends to degrade together when the load of any\
    \ one class is\n   increased.  By imposing explicit maximum bandwidth usage on\
    \ each\n   class individually, better class isolation is achieved.  The trade-\n\
    \   off is that, generally, blocking performance in MAM is somewhat\n   higher\
    \ than in RDM, because of reduced sharing.\n   The difference in the behavior\
    \ of RDM with or without preemption has\n   already been discussed at the beginning\
    \ of this section.  For MAM,\n   some notable differences can also be observed\
    \ from a comparison of\n   Figures 1 and 11.  If preemption is used, higher-priority\
    \ traffic\n   tends to be able to maintain its performance despite the overloading\n\
    \   of other classes.  This is not so if preemption is not allowed.  The\n   trade-off\
    \ is that, generally, the overloaded class sees a relatively\n   higher blocking/preemption\
    \ when preemption is enabled than there\n   would be if preemption is disabled.\n"
- title: 7.  Performance under Complete Sharing
  contents:
  - "7.  Performance under Complete Sharing\n   As observed towards the end of Section\
    \ 3, the partitioning of\n   bandwidth capacity for access by different traffic\
    \ classes tends to\n   reduce the maximum link efficiency achievable.  We now\
    \ consider the\n   case where there is no such partitioning, thereby resulting\
    \ in full\n   sharing of the total bandwidth among all the classes.  This is\n\
    \   referred to as the Complete Sharing Model.\n   For MAM, this means that the\
    \ BCs are such that up to 15 simultaneous\n   LSPs are allowed for any class.\n\
    \   Similarly, for RDM, the BCs are\n   up to 15 simultaneous LSPs for class 1\
    \ by itself,\n   up to 15 simultaneous LSPs for classes 1 and 2 together, and\n\
    \   up to 15 simultaneous LSPs for all three classes together.\n   Effectively,\
    \ there is now no distinction between MAM and RDM.  Figure\n   13 shows the performance\
    \ when all classes have equal access to link\n   bandwidth under Complete Sharing.\n\
    \   With preemption being fully enabled, class 1 sees virtually no\n   blocking,\
    \ regardless of the loading conditions of the link.  Since\n   class 2 can only\
    \ preempt class 3, class 2 sees some blocking and/or\n   preemption when either\
    \ class 1 load or its own load is above normal;\n   otherwise, class 2 is unaffected\
    \ by increases of class 3 load.  As\n   higher priority classes always preempt\
    \ class 3 when the link is full,\n   class 3 suffers the most, with high blocking/preemption\
    \ when there is\n   any load increase from any class.  A comparison of Figures\
    \ 1, 2, and\n   13 shows that, although the performance of both classes 1 and\
    \ 2 is\n   far superior under Complete Sharing, class 3 performance is much\n\
    \   better off under either MAM or RDM.  In a sense, class 3 is starved\n   under\
    \ overload as no protection of its traffic is being provided\n   under Complete\
    \ Sharing.\n"
- title: 8.  Implications on Performance Criteria
  contents:
  - "8.  Implications on Performance Criteria\n   Based on the previous results, a\
    \ general theme is shown to be the\n   trade-off between bandwidth sharing and\
    \ class protection/isolation.\n   To show this more concretely, let us compare\
    \ the different BCMs in\n   terms of the overall loss probability.  This quantity\
    \ is defined as\n   the long-term proportion of LSP requests from all classes\
    \ combined\n   that are lost as a result of either blocking or preemption, for\
    \ a\n   given level of offered load.\n   As noted in the previous sections, although\
    \ RDM has a higher degree\n   of sharing than MAM, both ultimately converge to\
    \ the Complete Sharing\n   Model as the degree of sharing in each of them is increased.\
    \  Figure\n   14 shows that, for a single link, the overall loss probability is\
    \ the\n   smallest under Complete Sharing and the largest under MAM, with that\n\
    \   under RDM being intermediate.  Expressed differently, Complete\n   Sharing\
    \ yields the highest link efficiency and MAM the lowest.  As a\n   matter of fact,\
    \ the overall loss probability of Complete Sharing is\n   identical to the loss\
    \ probability of a single class as computed by\n   the Erlang loss formula.  Yet\
    \ Complete Sharing has the poorest class\n   protection capability.  (Note that,\
    \ in a network with many links and\n   multiple-link routing paths, analysis in\
    \ [6] showed that Complete\n   Sharing does not necessarily lead to maximum network-wide\
    \ bandwidth\n   efficiency.)\n   Increasing the degree of bandwidth sharing among\
    \ the different\n   traffic classes helps increase link efficiency.  Such increase,\n\
    \   however, will lead to a tighter coupling between different classes.\n   Under\
    \ normal loading conditions, proper dimensioning of the link so\n   that there\
    \ is adequate capacity for each class can minimize the\n   effect of such coupling.\
    \  Under overload conditions, when there is a\n   scarcity of capacity, such coupling\
    \ will be unavoidable and can cause\n   severe degradation of service to the lower-priority\
    \ classes.  Thus,\n   the objective of maximizing link usage as stated in criterion\
    \ (5) of\n   Section 1 must be exercised with care, with due consideration to\
    \ the\n   effect of interactions among the different classes.  Otherwise, use\n\
    \   of this criterion alone will lead to the selection of the Complete\n   Sharing\
    \ Model, as shown in Figure 14.\n   The intention of criterion (2) in judging\
    \ the effectiveness of\n   different BCMs is to evaluate how they help the network\
    \ achieve the\n   expected performance.  This can be expressed in terms of the\
    \ blocking\n   and/or preemption behavior as seen by different classes under various\n\
    \   loading conditions.  For example, the relative strength of a BCM can\n   be\
    \ demonstrated by examining how many times the per-class blocking or\n   preemption\
    \ probability under overload is worse than the corresponding\n   probability under\
    \ normal load.\n"
- title: 9.  Conclusions
  contents:
  - "9.  Conclusions\n   BCMs are used in DS-TE for path computation and admission\
    \ control of\n   LSPs by enforcing different BCs for different classes of traffic\
    \ so\n   that Diffserv QoS performance can be maximized.  Therefore, it is of\n\
    \   interest to measure the performance of a BCM by the LSP\n   blocking/preemption\
    \ probabilities under various operational\n   conditions.  Based on this, the\
    \ performance of RDM and MAM for LSP\n   establishment has been analyzed and compared.\
    \  In particular, three\n   different scenarios have been examined: (1) all three\
    \ classes have\n   comparable performance objectives in terms of LSP blocking/preemption\n\
    \   under normal conditions, (2) class 2 is given better performance at\n   the\
    \ expense of class 3, and (3) class 3 receives some minimum\n   deterministic\
    \ guarantee.\n   A general theme is the trade-off between bandwidth sharing to\
    \ achieve\n   greater efficiency under normal conditions, and to achieve robust\n\
    \   class protection/isolation under overload.  The general properties of\n  \
    \ the two BCMs are as follows:\n   RDM\n   - allows greater sharing of bandwidth\
    \ among different classes\n   - performs somewhat better under normal conditions\n\
    \   - works well when preemption is fully enabled; under partial\n     preemption,\
    \ not all preemption modes work equally well\n   MAM\n   - does not depend on\
    \ the use of preemption\n   - is relatively insensitive to the different preemption\
    \ modes when\n     preemption is used\n   - provides more robust class isolation\
    \ under overload\n   Generally, the use of preemption gives higher-priority traffic\
    \ some\n   degree of immunity to the overloading of other classes.  This results\n\
    \   in a higher blocking/preemption for the overloaded class than that in\n  \
    \ a pure blocking environment.\n"
- title: 10.  Security Considerations
  contents:
  - "10.  Security Considerations\n   This document does not introduce additional\
    \ security threats beyond\n   those described for Diffserv [10] and MPLS Traffic\
    \ Engineering [11,\n   12, 13, 14], and the same security measures and procedures\
    \ described\n   in those documents apply here.  For example, the approach for\
    \ defense\n   against theft- and denial-of-service attacks discussed in [10],\
    \ which\n   consists of the combination of traffic conditioning at Diffserv\n\
    \   boundary nodes along with security and integrity of the network\n   infrastructure\
    \ within a Diffserv domain, may be followed when DS-TE\n   is in use.\n   Also,\
    \ as stated in [11], it is specifically important that\n   manipulation of administratively\
    \ configurable parameters (such as\n   those related to DS-TE LSPs) be executed\
    \ in a secure manner by\n   authorized entities.  For example, as preemption is\
    \ an\n   administratively configurable parameter, it is critical that its\n  \
    \ values be set properly throughout the network.  Any misconfiguration\n   in\
    \ any label switch may cause new LSP setup requests either to be\n   blocked or\
    \ to unnecessarily preempt LSPs already established.\n   Similarly, the preemption\
    \ values of LSP setup requests must be\n   configured properly; otherwise, they\
    \ may affect the operation of\n   existing LSPs.\n"
- title: 11.  Acknowledgements
  contents:
  - "11.  Acknowledgements\n   Inputs from Jerry Ash, Jim Boyle, Anna Charny, Sanjaya\
    \ Choudhury,\n   Dimitry Haskin, Francois Le Faucheur, Vishal Sharma, and Jing\
    \ Shen\n   are much appreciated.\n"
- title: 12.  References
  contents:
  - '12.  References

    '
- title: 12.1.  Normative References
  contents:
  - "12.1.  Normative References\n   [1]  Le Faucheur, F. and W. Lai, \"Requirements\
    \ for Support of\n        Differentiated Services-aware MPLS Traffic Engineering\"\
    , RFC\n        3564, July 2003.\n"
- title: 12.2.  Informative References
  contents:
  - "12.2.  Informative References\n   [2]  Le Faucheur, F., Ed., \"Protocol Extensions\
    \ for Support of\n        Diffserv-aware MPLS Traffic Engineering\", RFC 4124,\
    \ June 2005.\n   [3]  Boyle, J., Gill, V., Hannan, A., Cooper, D., Awduche, D.,\n\
    \        Christian, B., and W. Lai, \"Applicability Statement for Traffic\n  \
    \      Engineering with MPLS\", RFC 3346, August 2002.\n   [4]  Le Faucheur, F.\
    \ and W. Lai, \"Maximum Allocation Bandwidth\n        Constraints Model for Diffserv-aware\
    \ MPLS Traffic Engineering\",\n        RFC 4125, June 2005.\n   [5]  Le Faucheur,\
    \ F., Ed., \"Russian Dolls Bandwidth Constraints Model\n        for Diffserv-aware\
    \ MPLS Traffic Engineering\", RFC 4127, June\n        2005.\n   [6]  Ash, J.,\
    \ \"Max Allocation with Reservation Bandwidth Constraint\n        Model for MPLS/DiffServ\
    \ TE & Performance Comparisons\", RFC 4126,\n        June 2005.\n   [7]  F. Le\
    \ Faucheur, \"Considerations on Bandwidth Constraints Models\n        for DS-TE\"\
    , Work in Progress.\n   [8]  W.S. Lai, \"Traffic Engineering for MPLS,\" Internet\
    \ Performance\n        and Control of Network Systems III Conference, SPIE Proceedings\n\
    \        Vol. 4865, Boston, Massachusetts, USA, 30-31 July 2002, pp.\n       \
    \ 256-267.\n   [9]  W.S. Lai, \"Traffic Measurement for Dimensioning and Control\
    \ of\n        IP Networks,\" Internet Performance and Control of Network\n   \
    \     Systems II Conference, SPIE Proceedings Vol. 4523, Denver,\n        Colorado,\
    \ USA, 21-22 August 2001, pp. 359-367.\n   [10] Blake, S., Black, D., Carlson,\
    \ M., Davies, E., Wang, Z., and W.\n        Weiss, \"An Architecture for Differentiated\
    \ Service\", RFC 2475,\n        December 1998.\n   [11] Awduche, D., Malcolm,\
    \ J., Agogbua, J., O'Dell, M., and J.\n        McManus, \"Requirements for Traffic\
    \ Engineering Over MPLS\", RFC\n        2702, September 1999.\n   [12] Awduche,\
    \ D., Berger, L., Gan, D., Li, T., Srinivasan, V., and G.\n        Swallow, \"\
    RSVP-TE: Extensions to RSVP for LSP Tunnels\", RFC\n        3209, December 2001.\n\
    \   [13] Katz, D., Kompella, K., and D. Yeung, \"Traffic Engineering (TE)\n  \
    \      Extensions to OSPF Version 2\", RFC 3630, September 2003.\n   [14] Smit,\
    \ H. and T. Li, \"Intermediate System to Intermediate System\n        (IS-IS)\
    \ Extensions for Traffic Engineering (TE)\", RFC 3784, June\n        2004.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Wai Sum Lai\n   AT&T Labs\n   Room D5-3D18\n   200 Laurel\
    \ Avenue\n   Middletown, NJ 07748\n   USA\n   Phone: +1 732-420-3712\n   EMail:\
    \ wlai@att.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2005).\n   This\
    \ document is subject to the rights, licenses and restrictions\n   contained in\
    \ BCP 78 and at www.rfc-editor.org/copyright.html, and\n   except as set forth\
    \ therein, the authors retain all their rights.\n   This document and the information\
    \ contained herein are provided on an\n   \"AS IS\" basis and THE CONTRIBUTOR,\
    \ THE ORGANIZATION HE/SHE REPRESENTS\n   OR IS SPONSORED BY (IF ANY), THE INTERNET\
    \ SOCIETY AND THE INTERNET\n   ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES,\
    \ EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE\
    \ OF THE\n   INFORMATION HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED\n\
    \   WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at ietf-\n   ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
