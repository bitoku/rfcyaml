- title: __initial_text__
  contents:
  - '    Analysis of Threats Motivating DomainKeys Identified Mail (DKIM)

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2006).\n"
- title: Abstract
  contents:
  - "Abstract\n   This document provides an analysis of some threats against Internet\n\
    \   mail that are intended to be addressed by signature-based mail\n   authentication,\
    \ in particular DomainKeys Identified Mail.  It\n   discusses the nature and location\
    \ of the bad actors, what their\n   capabilities are, and what they intend to\
    \ accomplish via their\n   attacks.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \      1.1. Terminology and Model ......................................3\n  \
    \    1.2. Document Structure .........................................5\n   2.\
    \ The Bad Actors ..................................................6\n      2.1.\
    \ Characteristics ............................................6\n      2.2. Capabilities\
    \ ...............................................6\n      2.3. Location ...................................................8\n\
    \           2.3.1. Externally-Located Bad Actors .......................8\n  \
    \         2.3.2. Within Claimed Originator's Administrative Unit .....8\n    \
    \       2.3.3. Within Recipient's Administrative Unit ..............9\n   3. Representative\
    \ Bad Acts .........................................9\n      3.1. Use of Arbitrary\
    \ Identities ................................9\n      3.2. Use of Specific Identities\
    \ ................................10\n           3.2.1. Exploitation of Social\
    \ Relationships ...............10\n           3.2.2. Identity-Related Fraud .............................11\n\
    \           3.2.3. Reputation Attacks .................................11\n  \
    \         3.2.4. Reflection Attacks .................................11\n   4.\
    \ Attacks on Message Signing .....................................12\n      4.1.\
    \ Attacks against Message Signatures ........................12\n           4.1.1.\
    \ Theft of Private Key for Domain ....................13\n           4.1.2. Theft\
    \ of Delegated Private Key .....................13\n           4.1.3. Private\
    \ Key Recovery via Side Channel Attack .......14\n           4.1.4. Chosen Message\
    \ Replay ..............................14\n           4.1.5. Signed Message Replay\
    \ ..............................16\n           4.1.6. Denial-of-Service Attack\
    \ against Verifier ..........16\n           4.1.7. Denial-of-Service Attack against\
    \ Key Service .......17\n           4.1.8. Canonicalization Abuse .............................17\n\
    \           4.1.9. Body Length Limit Abuse ............................17\n  \
    \         4.1.10. Use of Revoked Key ................................18\n    \
    \       4.1.11. Compromise of Key Server ..........................18\n      \
    \     4.1.12. Falsification of Key Service Replies ..............19\n        \
    \   4.1.13. Publication of Malformed Key Records\n                   and/or Signatures\
    \ .................................19\n           4.1.14. Cryptographic Weaknesses\
    \ in Signature Generation ..20\n           4.1.15. Display Name Abuse ................................21\n\
    \           4.1.16. Compromised System within Originator's Network ....21\n  \
    \         4.1.17. Verification Probe Attack .........................21\n    \
    \       4.1.18. Key Publication by Higher-Level Domain ............22\n      4.2.\
    \ Attacks against Message Signing Practices .................23\n           4.2.1.\
    \ Look-Alike Domain Names ............................23\n           4.2.2. Internationalized\
    \ Domain Name Abuse ................23\n           4.2.3. Denial-of-Service Attack\
    \ against Signing\n                  Practices ..........................................24\n\
    \           4.2.4. Use of Multiple From Addresses .....................24\n  \
    \         4.2.5. Abuse of Third-Party Signatures ....................24\n    \
    \       4.2.6. Falsification of Sender Signing Practices Replies ..25\n      4.3.\
    \ Other Attacks .............................................25\n           4.3.1.\
    \ Packet Amplification Attacks via DNS ...............25\n   5. Derived Requirements\
    \ ...........................................26\n   6. Security Considerations\
    \ ........................................26\n   7. Informative References .........................................27\n\
    \   Appendix A. Acknowledgements ......................................28\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The DomainKeys Identified Mail (DKIM) protocol is being\
    \ specified by\n   the IETF DKIM Working Group.  The DKIM protocol defines a mechanism\n\
    \   by which email messages can be cryptographically signed, permitting a\n  \
    \ signing domain to claim responsibility for the use of a given email\n   address.\
    \  Message recipients can verify the signature by querying the\n   signer's domain\
    \ directly to retrieve the appropriate public key, and\n   thereby confirm that\
    \ the message was attested to by a party in\n   possession of the private key\
    \ for the signing domain.  This document\n   addresses threats relative to two\
    \ works in progress by the DKIM\n   Working Group, the DKIM signature specification\
    \ [DKIM-BASE] and DKIM\n   Sender Signing Practices [DKIM-SSP].\n   Once the attesting\
    \ party or parties have been established, the\n   recipient may evaluate the message\
    \ in the context of additional\n   information such as locally-maintained whitelists,\
    \ shared reputation\n   services, and/or third-party accreditation.  The description\
    \ of these\n   mechanisms is outside the scope of the IETF DKIM Working Group\n\
    \   effort.  By applying a signature, a good player enables a verifier to\n  \
    \ associate a positive reputation with the message, in hopes that it\n   will\
    \ receive preferential treatment by the recipient.\n   This effort is not intended\
    \ to address threats associated with\n   message confidentiality nor does it intend\
    \ to provide a long-term\n   archival signature.\n"
- title: 1.1.  Terminology and Model
  contents:
  - "1.1.  Terminology and Model\n   An administrative unit (AU) is the portion of\
    \ the path of an email\n   message that is under common administration.  The originator\
    \ and\n   recipient typically develop trust relationships with the\n   administrative\
    \ units that send and receive their email, respectively,\n   to perform the signing\
    \ and verification of their messages.\n   The origin address is the address on\
    \ an email message, typically the\n   RFC 2822 From: address, which is associated\
    \ with the alleged author\n   of the message and is displayed by the recipient's\
    \ Mail User Agent\n   (MUA) as the source of the message.\n   The following diagram\
    \ illustrates a typical usage flowchart for DKIM:\n                      +---------------------------------+\n\
    \                      |       SIGNATURE CREATION        |\n                 \
    \     |  (Originating or Relaying AU)   |\n                      |           \
    \                      |\n                      |   Sign (Message, Domain, Key)\
    \   |\n                      |                                 |\n           \
    \           +---------------------------------+\n                            \
    \           | - Message (Domain, Key)\n                                      \
    \ |\n                                   [Internet]\n                         \
    \              |\n                                       V\n                 \
    \     +---------------------------------+\n     +-----------+    |     SIGNATURE\
    \ VERIFICATION      |\n     |           |    |  (Relaying or Delivering AU)  \
    \  |\n     |    KEY    |    |                                 |\n     |   QUERY\
    \   +--->|  Verify (Message, Domain, Key)  |\n     |           |    |        \
    \                         |\n     +-----------+    +----------------+----------------+\n\
    \                                       |  - Verified Domain\n     +-----------+\
    \                     V  - [Report]\n     |  SENDER   |    +----------------+----------------+\n\
    \     |  SIGNING  |    |                                 |\n     | PRACTICES +--->|\
    \        SIGNER EVALUATION        |\n     |   QUERY   |    |                 \
    \                |\n     |           |    +---------------------------------+\n\
    \     +-----------+\n   DKIM operates entirely on the content (body and selected\
    \ header\n   fields) of the message, as defined in RFC 2822 [RFC2822].  The\n\
    \   transmission of messages via SMTP, defined in RFC 2821 [RFC2821], and\n  \
    \ such elements as the envelope-from and envelope-to addresses and the\n   HELO\
    \ domain are not relevant to DKIM verification.  This is an\n   intentional decision\
    \ made to allow verification of messages via\n   protocols other than SMTP, such\
    \ as POP [RFC1939] and IMAP [RFC3501]\n   which an MUA acting as a verifier might\
    \ use.\n   The Sender Signing Practices Query referred to in the diagram above\n\
    \   is a means by which the verifier can query the alleged author's\n   domain\
    \ to determine their practices for signing messages, which in\n   turn may influence\
    \ their evaluation of the message.  If, for example,\n   a message arrives without\
    \ any valid signatures, and the alleged\n   author's domain advertises that they\
    \ sign all messages, the verifier\n   might handle that message differently than\
    \ if a signature was not\n   necessarily to be expected.\n"
- title: 1.2.  Document Structure
  contents:
  - "1.2.  Document Structure\n   The remainder of this document describes the problems\
    \ that DKIM might\n   be expected to address, and the extent to which it may be\
    \ successful\n   in so doing.  These are described in terms of the potential bad\n\
    \   actors, their capabilities and location in the network, and the bad\n   acts\
    \ that they might wish to commit.\n   This is followed by a description of postulated\
    \ attacks on DKIM\n   message signing and on the use of Sender Signing Practices\
    \ to assist\n   in the treatment of unsigned messages.  A list of derived\n  \
    \ requirements is also presented, which is intended to guide the DKIM\n   design\
    \ and review process.\n   The sections dealing with attacks on DKIM each begin\
    \ with a table\n   summarizing the postulated attacks in each category along with\
    \ their\n   expected impact and likelihood.  The following definitions were used\n\
    \   as rough criteria for scoring the attacks:\n   Impact:\n      High:  Affects\
    \ the verification of messages from an entire domain\n         or multiple domains\n\
    \      Medium:  Affects the verification of messages from specific users,\n  \
    \       Mail Transfer Agents (MTAs), and/or bounded time periods\n      Low: \
    \ Affects the verification of isolated individual messages\n         only\n  \
    \ Likelihood:\n      High:  All email users should expect this attack on a frequent\n\
    \         basis\n      Medium:  Email users should expect this attack occasionally;\n\
    \         frequently for a few users\n      Low:  Attack is expected to be rare\
    \ and/or very infrequent\n"
- title: 2.  The Bad Actors
  contents:
  - '2.  The Bad Actors

    '
- title: 2.1.  Characteristics
  contents:
  - "2.1.  Characteristics\n   The problem space being addressed by DKIM is characterized\
    \ by a wide\n   range of attackers in terms of motivation, sophistication, and\n\
    \   capabilities.\n   At the low end of the spectrum are bad actors who may simply\
    \ send\n   email, perhaps using one of many commercially available tools, that\n\
    \   the recipient does not want to receive.  These tools typically allow\n   one\
    \ to falsify the origin address of messages, and may, in the\n   future, be capable\
    \ of generating message signatures as well.\n   At the next tier are what would\
    \ be considered \"professional\" senders\n   of unwanted email.  These attackers\
    \ would deploy specific\n   infrastructure, including Mail Transfer Agents (MTAs),\
    \ registered\n   domains and networks of compromised computers (\"zombies\") to\
    \ send\n   messages, and in some cases to harvest addresses to which to send.\n\
    \   These senders often operate as commercial enterprises and send\n   messages\
    \ on behalf of third parties.\n   The most sophisticated and financially-motivated\
    \ senders of messages\n   are those who stand to receive substantial financial\
    \ benefit, such as\n   from an email-based fraud scheme.  These attackers can\
    \ be expected to\n   employ all of the above mechanisms and additionally may attack\
    \ the\n   Internet infrastructure itself, including DNS cache-poisoning attacks\n\
    \   and IP routing attacks.\n"
- title: 2.2.  Capabilities
  contents:
  - "2.2.  Capabilities\n   In general, the bad actors described above should be expected\
    \ to have\n   access to the following:\n   1.  An extensive corpus of messages\
    \ from domains they might wish to\n       impersonate\n   2.  Knowledge of the\
    \ business aims and model for domains they might\n       wish to impersonate\n\
    \   3.  Access to public keys and associated authorization records\n       associated\
    \ with the domain\n   and the ability to do at least some of the following:\n\
    \   1.  Submit messages to MTAs and Message Submission Agents (MSAs) at\n    \
    \   multiple locations in the Internet\n   2.  Construct arbitrary message header\
    \ fields, including those\n       claiming to be mailing lists, resenders, and\
    \ other mail agents\n   3.  Sign messages on behalf of domains under their control\n\
    \   4.  Generate substantial numbers of either unsigned or apparently-\n     \
    \  signed messages that might be used to attempt a denial-of-service\n       attack\n\
    \   5.  Resend messages that may have been previously signed by the\n       domain\n\
    \   6.  Transmit messages using any envelope information desired\n   7.  Act as\
    \ an authorized submitter for messages from a compromised\n       computer\n \
    \  As noted above, certain classes of bad actors may have substantial\n   financial\
    \ motivation for their activities, and therefore should be\n   expected to have\
    \ more capabilities at their disposal.  These include:\n   1.  Manipulation of\
    \ IP routing.  This could be used to submit\n       messages from specific IP\
    \ addresses or difficult-to-trace\n       addresses, or to cause diversion of\
    \ messages to a specific\n       domain.\n   2.  Limited influence over portions\
    \ of DNS using mechanisms such as\n       cache poisoning.  This might be used\
    \ to influence message routing\n       or to falsify advertisements of DNS-based\
    \ keys or signing\n       practices.\n   3.  Access to significant computing resources,\
    \ for example, through\n       the conscription of worm-infected \"zombie\" computers.\
    \  This could\n       allow the bad actor to perform various types of brute-force\n\
    \       attacks.\n   4.  Ability to eavesdrop on existing traffic, perhaps from\
    \ a wireless\n       network.\n   Either of the first two of these mechanisms\
    \ could be used to allow\n   the bad actor to function as a man-in-the-middle\
    \ between author and\n   recipient, if that attack is useful.\n"
- title: 2.3.  Location
  contents:
  - "2.3.  Location\n   Bad actors or their proxies can be located anywhere in the\
    \ Internet.\n   Certain attacks are possible primarily within the administrative\
    \ unit\n   of the claimed originator and/or recipient domain have capabilities\n\
    \   beyond those elsewhere, as described in the below sections.  Bad\n   actors\
    \ can also collude by acting from multiple locations (a\n   \"distributed bad\
    \ actor\").\n   It should also be noted that with the use of \"zombies\" and other\n\
    \   proxies, externally-located bad actors may gain some of the\n   capabilities\
    \ of being located within the claimed originator's or\n   recipient's administrative\
    \ unit.  This emphasizes the importance of\n   appropriate security measures,\
    \ such as authenticated submission of\n   messages, even within administrative\
    \ units.\n"
- title: 2.3.1.  Externally-Located Bad Actors
  contents:
  - "2.3.1.  Externally-Located Bad Actors\n   DKIM focuses primarily on bad actors\
    \ located outside of the\n   administrative units of the claimed originator and\
    \ the recipient.\n   These administrative units frequently correspond to the protected\n\
    \   portions of the network adjacent to the originator and recipient.  It\n  \
    \ is in this area that the trust relationships required for\n   authenticated\
    \ message submission do not exist and do not scale\n   adequately to be practical.\
    \  Conversely, within these administrative\n   units, there are other mechanisms\
    \ such as authenticated message\n   submission that are easier to deploy and more\
    \ likely to be used than\n   DKIM.\n   External bad actors are usually attempting\
    \ to exploit the \"any to\n   any\" nature of email that motivates most recipient\
    \ MTAs to accept\n   messages from anywhere for delivery to their local domain.\
    \  They may\n   generate messages without signatures, with incorrect signatures,\
    \ or\n   with correct signatures from domains with little traceability.  They\n\
    \   may also pose as mailing lists, greeting cards, or other agents that\n   legitimately\
    \ send or resend messages on behalf of others.\n"
- title: 2.3.2.  Within Claimed Originator's Administrative Unit
  contents:
  - "2.3.2.  Within Claimed Originator's Administrative Unit\n   Bad actors in the\
    \ form of rogue or unauthorized users or malware-\n   infected computers can exist\
    \ within the administrative unit\n   corresponding to a message's origin address.\
    \  Since the submission of\n   messages in this area generally occurs prior to\
    \ the application of a\n   message signature, DKIM is not directly effective against\
    \ these bad\n   actors.  Defense against these bad actors is dependent upon other\n\
    \   means, such as proper use of firewalls, and Message Submission Agents\n  \
    \ that are configured to authenticate the author.\n   In the special case where\
    \ the administrative unit is non-contiguous\n   (e.g., a company that communicates\
    \ between branches over the external\n   Internet), DKIM signatures can be used\
    \ to distinguish between\n   legitimate externally-originated messages and attempts\
    \ to spoof\n   addresses in the local domain.\n"
- title: 2.3.3.  Within Recipient's Administrative Unit
  contents:
  - "2.3.3.  Within Recipient's Administrative Unit\n   Bad actors may also exist\
    \ within the administrative unit of the\n   message recipient.  These bad actors\
    \ may attempt to exploit the trust\n   relationships that exist within the unit.\
    \  Since messages will\n   typically only have undergone DKIM verification at\
    \ the administrative\n   unit boundary, DKIM is not effective against messages\
    \ submitted in\n   this area.\n   For example, the bad actor may attempt to spoof\
    \ a header field\n   indicating the results of verification.  This header field\
    \ would\n   normally be added by the verifier, which would also detect spoofed\n\
    \   header fields on messages it was attempting to verify.  This could be\n  \
    \ used to falsely indicate that the message was authenticated\n   successfully.\n\
    \   As in the originator case, these bad actors can be dealt with by\n   controlling\
    \ the submission of messages within the administrative\n   unit.  Since DKIM permits\
    \ verification to occur anywhere within the\n   recipient's administrative unit,\
    \ these threats can also be minimized\n   by moving verification closer to the\
    \ recipient, such as at the Mail\n   Delivery Agent (MDA), or on the recipient's\
    \ MUA itself.\n"
- title: 3.  Representative Bad Acts
  contents:
  - "3.  Representative Bad Acts\n   One of the most fundamental bad acts being attempted\
    \ is the delivery\n   of messages that are not intended to have been sent by the\
    \ alleged\n   originating domain.  As described above, these messages might merely\n\
    \   be unwanted by the recipient, or might be part of a confidence scheme\n  \
    \ or a delivery vector for malware.\n"
- title: 3.1.  Use of Arbitrary Identities
  contents:
  - "3.1.  Use of Arbitrary Identities\n   This class of bad acts includes the sending\
    \ of messages that aim to\n   obscure the identity of the actual author.  In some\
    \ cases, the actual\n   sender might be the bad actor, or in other cases might\
    \ be a third-\n   party under the control of the bad actor (e.g., a compromised\n\
    \   computer).\n   Particularly when coupled with sender signing practices that\
    \ indicate\n   the domain owner signs all messages, DKIM can be effective in\n\
    \   mitigating against the abuse of addresses not controlled by bad\n   actors.\
    \  DKIM is not effective against the use of addresses\n   controlled by bad actors.\
    \  In other words, the presence of a valid\n   DKIM signature does not guarantee\
    \ that the signer is not a bad actor.\n   It also does not guarantee the accountability\
    \ of the signer, since\n   DKIM does not attempt to identify the signer individually,\
    \ but rather\n   identifies the domain that they control.  Accreditation and\n\
    \   reputation systems and locally-maintained whitelists and blacklists\n   can\
    \ be used to enhance the accountability of DKIM-verified addresses\n   and/or\
    \ the likelihood that signed messages are desirable.\n"
- title: 3.2.  Use of Specific Identities
  contents:
  - "3.2.  Use of Specific Identities\n   A second major class of bad acts involves\
    \ the assertion of specific\n   identities in email.\n   Note that some bad acts\
    \ involving specific identities can sometimes\n   be accomplished, although perhaps\
    \ less effectively, with similar\n   looking identities that mislead some recipients.\
    \  For example, if the\n   bad actor is able to control the domain \"examp1e.com\"\
    \ (note the \"one\"\n   between the p and e), they might be able to convince some\
    \ recipients\n   that a message from admin@examp1e.com is really from\n   admin@example.com.\
    \  Similar types of attacks using internationalized\n   domain names have been\
    \ hypothesized where it could be very difficult\n   to see character differences\
    \ in popular typefaces.  Similarly, if\n   example2.com was controlled by a bad\
    \ actor, the bad actor could sign\n   messages from bigbank.example2.com, which\
    \ might also mislead some\n   recipients.  To the extent that these domains are\
    \ controlled by bad\n   actors, DKIM is not effective against these attacks, although\
    \ it\n   could support the ability of reputation and/or accreditation systems\n\
    \   to aid the user in identifying them.\n   DKIM is effective against the use\
    \ of specific identities only when\n   there is an expectation that such messages\
    \ will, in fact, be signed.\n   The primary means for establishing this is the\
    \ use of Sender Signing\n   Practices (SSP), which will be specified by the IETF\
    \ DKIM Working\n   Group.\n"
- title: 3.2.1.  Exploitation of Social Relationships
  contents:
  - "3.2.1.  Exploitation of Social Relationships\n   One reason for asserting a specific\
    \ origin address is to encourage a\n   recipient to read and act on particular\
    \ email messages by appearing\n   to be an acquaintance or previous correspondent\
    \ that the recipient\n   might trust.  This tactic has been used by email-propagated\
    \ malware\n   that mail themselves to addresses in the infected host's address\n\
    \   book.  In this case, however, the author's address may not be\n   falsified,\
    \ so DKIM would not be effective in defending against this\n   act.\n   It is\
    \ also possible for address books to be harvested and used by an\n   attacker\
    \ to post messages from elsewhere.  DKIM could be effective in\n   mitigating\
    \ these acts by limiting the scope of origin addresses for\n   which a valid signature\
    \ can be obtained when sending the messages\n   from other locations.\n"
- title: 3.2.2.  Identity-Related Fraud
  contents:
  - "3.2.2.  Identity-Related Fraud\n   Bad acts related to email-based fraud often,\
    \ but not always, involve\n   the transmission of messages using specific origin\
    \ addresses of other\n   entities as part of the fraud scheme.  The use of a specific\
    \ address\n   of origin sometimes contributes to the success of the fraud by\n\
    \   helping convince the recipient that the message was actually sent by\n   the\
    \ alleged author.\n   To the extent that the success of the fraud depends on or\
    \ is enhanced\n   by the use of a specific origin address, the bad actor may have\n\
    \   significant financial motivation and resources to circumvent any\n   measures\
    \ taken to protect specific addresses from unauthorized use.\n   When signatures\
    \ are verified by or for the recipient, DKIM is\n   effective in defending against\
    \ the fraudulent use of origin addresses\n   on signed messages.  When the published\
    \ sender signing practices of\n   the origin address indicate that all messages\
    \ from that address\n   should be signed, DKIM further mitigates against the attempted\n\
    \   fraudulent use of the origin address on unsigned messages.\n"
- title: 3.2.3.  Reputation Attacks
  contents:
  - "3.2.3.  Reputation Attacks\n   Another motivation for using a specific origin\
    \ address in a message\n   is to harm the reputation of another, commonly referred\
    \ to as a\n   \"joe-job\".  For example, a commercial entity might wish to harm\
    \ the\n   reputation of a competitor, perhaps by sending unsolicited bulk email\n\
    \   on behalf of that competitor.  It is for this reason that reputation\n   systems\
    \ must be based on an identity that is, in practice, fairly\n   reliable.\n"
- title: 3.2.4.  Reflection Attacks
  contents:
  - "3.2.4.  Reflection Attacks\n   A commonly-used tactic by some bad actors is the\
    \ indirect\n   transmission of messages by intentionally mis-addressing the message\n\
    \   and causing it to be \"bounced\", or sent to the return address (RFC\n   2821\
    \ envelope-from address) on the message.  In this case, the\n   specific identity\
    \ asserted in the email is that of the actual target\n   of the message, to whom\
    \ the message is \"returned\".\n   DKIM does not, in general, attempt to validate\
    \ the RFC2821.mailfrom\n   return address on messages, either directly (noting\
    \ that the mailfrom\n   address is an element of the SMTP protocol, and not the\
    \ message\n   content on which DKIM operates), or via the optional Return-Path\n\
    \   header field.  Furthermore, as is noted in Section 4.4 of RFC 2821\n   [RFC2821],\
    \ it is common and useful practice for a message's return\n   path not to correspond\
    \ to the origin address.  For these reasons,\n   DKIM is not effective against\
    \ reflection attacks.\n"
- title: 4.  Attacks on Message Signing
  contents:
  - "4.  Attacks on Message Signing\n   Bad actors can be expected to exploit all\
    \ of the limitations of\n   message authentication systems.  They are also likely\
    \ to be motivated\n   to degrade the usefulness of message authentication systems\
    \ in order\n   to hinder their deployment.  Both the signature mechanism itself\
    \ and\n   declarations made regarding use of message signatures (referred to\n\
    \   here as Sender Signing Practices or SSP) can be expected to be the\n   target\
    \ of attacks.\n"
- title: 4.1.  Attacks against Message Signatures
  contents:
  - "4.1.  Attacks against Message Signatures\n   The following is a summary of postulated\
    \ attacks against DKIM\n   signatures:\n   +---------------------------------------------+--------+------------+\n\
    \   | Attack Name                                 | Impact | Likelihood |\n  \
    \ +---------------------------------------------+--------+------------+\n   |\
    \ Theft of private key for domain             |  High  |     Low    |\n   | Theft\
    \ of delegated private key              | Medium |   Medium   |\n   | Private\
    \ key recovery via side channel attack|  High  |     Low    |\n   | Chosen message\
    \ replay                       |   Low  |     M/H    |\n   | Signed message replay\
    \                       |   Low  |    High    |\n   | Denial-of-service attack\
    \ against verifier   |  High  |   Medium   |\n   | Denial-of-service attack against\
    \ key service|  High  |   Medium   |\n   | Canonicalization abuse            \
    \          |   Low  |   Medium   |\n   | Body length limit abuse             \
    \        | Medium |   Medium   |\n   | Use of revoked key                    \
    \      | Medium |     Low    |\n   | Compromise of key server                \
    \    |  High  |     Low    |\n   | Falsification of key service replies      \
    \  | Medium |   Medium   |\n   | Publication of malformed key records and/or |\
    \  High  |     Low    |\n   |  signatures                                 |  \
    \      |            |\n   | Cryptographic weaknesses in signature       |  High\
    \  |     Low    |\n   |  generation                                 |        |\
    \            |\n   | Display name abuse                          | Medium |  \
    \  High    |\n   | Compromised system within originator's      |  High  |   Medium\
    \   |\n   |  network                                    |        |           \
    \ |\n   | Verification probe attack                   | Medium |   Medium   |\n\
    \   | Key publication by higher-level domain      |  High  |     Low    |\n  \
    \ +---------------------------------------------+--------+------------+\n"
- title: 4.1.1.  Theft of Private Key for Domain
  contents:
  - "4.1.1.  Theft of Private Key for Domain\n   Message signing technologies such\
    \ as DKIM are vulnerable to theft of\n   the private keys used to sign messages.\
    \  This includes \"out-of-band\"\n   means for this theft, such as burglary, bribery,\
    \ extortion, and the\n   like, as well as electronic means for such theft, such\
    \ as a\n   compromise of network and host security around the place where a\n\
    \   private key is stored.\n   Keys that are valid for all addresses in a domain\
    \ typically reside in\n   MTAs that should be located in well-protected sites,\
    \ such as data\n   centers.  Various means should be employed for minimizing access\
    \ to\n   private keys, such as non-existence of commands for displaying their\n\
    \   value, although ultimately memory dumps and the like will probably\n   contain\
    \ the keys.  Due to the unattended nature of MTAs, some\n   countermeasures, such\
    \ as the use of a pass phrase to \"unlock\" a key,\n   are not practical to use.\
    \  Other mechanisms, such as the use of\n   dedicated hardware devices that contain\
    \ the private key and perform\n   the cryptographic signature operation, would\
    \ be very effective in\n   denying export of the private key to those without\
    \ physical access to\n   the device.  Such devices would almost certainly make\
    \ the theft of\n   the key visible, so that appropriate action (revocation of\
    \ the\n   corresponding public key) can be taken should that happen.\n"
- title: 4.1.2.  Theft of Delegated Private Key
  contents:
  - "4.1.2.  Theft of Delegated Private Key\n   There are several circumstances where\
    \ a domain owner will want to\n   delegate the ability to sign messages for the\
    \ domain to an individual\n   user or a third party associated with an outsourced\
    \ activity such as\n   a corporate benefits administrator or a marketing campaign.\
    \  Since\n   these keys may exist on less well-protected devices than the domain's\n\
    \   own MTAs, they will in many cases be more susceptible to compromise.\n   In\
    \ order to mitigate this exposure, keys used to sign such messages\n   can be\
    \ restricted by the domain owner to be valid for signing\n   messages only on\
    \ behalf of specific addresses in the domain.  This\n   maintains protection for\
    \ the majority of addresses in the domain.\n   A related threat is the exploitation\
    \ of weaknesses in the delegation\n   process itself.  This threat can be mitigated\
    \ through the use of\n   customary precautions against the theft of private keys\
    \ and the\n   falsification of public keys in transit.  For example, the exposure\n\
    \   to theft can be minimized if the delegate generates the keypair to be\n  \
    \ used, and sends the public key to the domain owner.  The exposure to\n   falsification\
    \ (substitution of a different public key) can be reduced\n   if this transmission\
    \ is signed by the delegate and verified by the\n   domain owner.\n"
- title: 4.1.3.  Private Key Recovery via Side Channel Attack
  contents:
  - "4.1.3.  Private Key Recovery via Side Channel Attack\n   All popular digital\
    \ signature algorithms are subject to a variety of\n   side channel attacks. \
    \ The most well-known of these are timing\n   channels [Kocher96], power analysis\
    \ [Kocher99], and cache timing\n   analysis [Bernstein04].  Most of these attacks\
    \ require either\n   physical access to the machine or the ability to run processes\n\
    \   directly on the target machine.  Defending against these attacks is\n   out\
    \ of scope for DKIM.\n   However, remote timing analysis (at least on local area\
    \ networks) is\n   known to be feasible [Boneh03], particularly in server-type\
    \ platforms\n   where the attacker can inject traffic that will immediately be\n\
    \   subject to the cryptographic operation in question.  With enough\n   samples,\
    \ these techniques can be used to extract private keys even in\n   the face of\
    \ modest amounts of noise in the timing measurements.\n   The three commonly proposed\
    \ countermeasures against timing analysis\n   are:\n   1.  Make the operation\
    \ run in constant time.  This turns out in\n       practice to be rather difficult.\n\
    \   2.  Make the time independent of the input data.  This can be\n       difficult,\
    \ but see [Boneh03] for more details.\n   3.  Use blinding.  This is generally\
    \ considered the best current\n       practice countermeasure, and while not proved\
    \ generally secure is\n       a countermeasure against known timing attacks. \
    \ It adds about\n       2-10% to the cost of the operation and is implemented\
    \ in many\n       common cryptographic libraries.  Unfortunately, Digital Signature\n\
    \       Algorithm (DSA) and Elliptic Curve DSA (ECDSA) do not have\n       standard\
    \ methods though some defenses may exist.\n   Note that adding random delays to\
    \ the operation is only a partial\n   countermeasure.  Because the noise is generally\
    \ uniformly\n   distributed, a large enough number of samples can be used to average\n\
    \   it out and extract an accurate timing signal.\n"
- title: 4.1.4.  Chosen Message Replay
  contents:
  - "4.1.4.  Chosen Message Replay\n   Chosen message replay refers to the scenario\
    \ where the attacker\n   creates a message and obtains a signature for it by sending\
    \ it\n   through an MTA authorized by the originating domain to\n   himself/herself\
    \ or an accomplice.  They then \"replay\" the signed\n   message by sending it,\
    \ using different envelope addresses, to a\n   (typically large) number of other\
    \ recipients.\n   Due to the requirement to get an attacker-generated message\
    \ signed,\n   chosen message replay would most commonly be experienced by consumer\n\
    \   ISPs or others offering email accounts to clients, particularly where\n  \
    \ there is little or no accountability to the account holder (the\n   attacker\
    \ in this case).  One approach to solving this problem is for\n   the domain to\
    \ only sign email for clients that have passed a vetting\n   process to provide\
    \ traceability to the message originator in the\n   event of abuse.  At present,\
    \ the low cost of email accounts (zero)\n   does not make it practical for any\
    \ vetting to occur.  It remains to\n   be seen whether this will be the model\
    \ with signed mail as well, or\n   whether a higher level of trust will be required\
    \ to obtain an email\n   signature.\n   A variation on this attack involves the\
    \ attacker sending a message\n   with the intent of obtaining a signed reply containing\
    \ their original\n   message.  The reply might come from an innocent user or might\
    \ be an\n   automatic response such as a \"user unknown\" bounce message.  In\
    \ some\n   cases, this signed reply message might accomplish the attacker's\n\
    \   objectives if replayed.  This variation on chosen message replay can\n   be\
    \ mitigated by limiting the extent to which the original content is\n   quoted\
    \ in automatic replies, and by the use of complementary\n   mechanisms such as\
    \ egress content filtering.\n   Revocation of the signature or the associated\
    \ key is a potential\n   countermeasure.  However, the rapid pace at which the\
    \ message might\n   be replayed (especially with an army of \"zombie\" computers),\
    \ compared\n   with the time required to detect the attack and implement the\n\
    \   revocation, is likely to be problematic.  A related problem is the\n   likelihood\
    \ that domains will use a small number of signing keys for a\n   large number\
    \ of customers, which is beneficial from a caching\n   standpoint but is likely\
    \ to result in a great deal of collateral\n   damage (in the form of signature\
    \ verification failures) should a key\n   be revoked suddenly.\n   Signature revocation\
    \ addresses the collateral damage problem at the\n   expense of significant scaling\
    \ requirements.  At the extreme,\n   verifiers could be required to check for\
    \ revocation of each signature\n   verified, which would result in very significant\
    \ transaction rates.\n   An alternative, \"revocation identifiers\", has been\
    \ proposed, which\n   would permit revocation on an intermediate level of granularity,\n\
    \   perhaps on a per-account basis.  Messages containing these\n   identifiers\
    \ would result in a query to a revocation database, which\n   might be represented\
    \ in DNS.\n   Further study is needed to determine if the benefits from revocation\n\
    \   (given the potential speed of a replay attack) outweigh the\n   transactional\
    \ cost of querying a revocation database.\n"
- title: 4.1.5.  Signed Message Replay
  contents:
  - "4.1.5.  Signed Message Replay\n   Signed message replay refers to the retransmission\
    \ of already-signed\n   messages to additional recipients beyond those intended\
    \ by the author\n   or the original poster of the message.  The attacker arranges\
    \ to\n   receive a message from the victim, and then retransmits it intact but\n\
    \   with different envelope addresses.  This might be done, for example,\n   to\
    \ make it look like a legitimate sender of messages is sending a\n   large amount\
    \ of spam.  When reputation services are deployed, this\n   could damage the author's\
    \ reputation or that of the author's domain.\n   A larger number of domains are\
    \ potential victims of signed message\n   replay than chosen message replay because\
    \ the former does not require\n   the ability for the attacker to send messages\
    \ from the victim domain.\n   However, the capabilities of the attacker are lower.\
    \  Unless coupled\n   with another attack such as body length limit abuse, it\
    \ isn't\n   possible for the attacker to use this, for example, for advertising.\n\
    \   Many mailing lists, especially those that do not modify the content\n   of\
    \ the message and signed header fields and hence do not invalidate\n   the signature,\
    \ engage in a form of signed message replay.  The use of\n   body length limits\
    \ and other mechanisms to enhance the survivability\n   of messages effectively\
    \ enhances the ability to do so.  The only\n   things that distinguish this case\
    \ from undesirable forms of signed\n   message replay is the intent of the replayer,\
    \ which cannot be\n   determined by the network.\n"
- title: 4.1.6.  Denial-of-Service Attack against Verifier
  contents:
  - "4.1.6.  Denial-of-Service Attack against Verifier\n   While it takes some computing\
    \ resources to sign and verify a\n   signature, it takes negligible computing\
    \ resources to generate an\n   invalid signature.  An attacker could therefore\
    \ construct a \"make\n   work\" attack against a verifier, by sending a large\
    \ number of\n   incorrectly-signed messages to a given verifier, perhaps with\n\
    \   multiple signatures each.  The motivation might be to make it too\n   expensive\
    \ to verify messages.\n   While this attack is feasible, it can be greatly mitigated\
    \ by the\n   manner in which the verifier operates.  For example, it might decide\n\
    \   to accept only a certain number of signatures per message, limit the\n   maximum\
    \ key size it will accept (to prevent outrageously large\n   signatures from causing\
    \ unneeded work), and verify signatures in a\n   particular order.  The verifier\
    \ could also maintain state\n   representing the current signature verification\
    \ failure rate and\n   adopt a defensive posture when attacks may be under way.\n"
- title: 4.1.7.  Denial-of-Service Attack against Key Service
  contents:
  - "4.1.7.  Denial-of-Service Attack against Key Service\n   An attacker might also\
    \ attempt to degrade the availability of an\n   originator's key service, in order\
    \ to cause that originator's\n   messages to be unverifiable.  One way to do this\
    \ might be to quickly\n   send a large number of messages with signatures that\
    \ reference a\n   particular key, thereby creating a heavy load on the key server.\n\
    \   Other types of DoS attacks on the key server or the network\n   infrastructure\
    \ serving it are also possible.\n   The best defense against this attack is to\
    \ provide redundant key\n   servers, preferably on geographically-separate parts\
    \ of the Internet.\n   Caching also helps a great deal, by decreasing the load\
    \ on\n   authoritative key servers when there are many simultaneous key\n   requests.\
    \  The use of a key service protocol that minimizes the\n   transactional cost\
    \ of key lookups is also beneficial.  It is noted\n   that the Domain Name System\
    \ has all these characteristics.\n"
- title: 4.1.8.  Canonicalization Abuse
  contents:
  - "4.1.8.  Canonicalization Abuse\n   Canonicalization algorithms represent a tradeoff\
    \ between the survival\n   of the validity of a message signature and the desire\
    \ not to allow\n   the message to be altered inappropriately.  In the past,\n\
    \   canonicalization algorithms have been proposed that would have\n   permitted\
    \ attackers, in some cases, to alter the meaning of a\n   message.\n   Message\
    \ signatures that support multiple canonicalization algorithms\n   give the signer\
    \ the ability to decide the relative importance of\n   signature survivability\
    \ and immutability of the signed content.  If\n   an unexpected vulnerability\
    \ appears in a canonicalization algorithm\n   in general use, new algorithms can\
    \ be deployed, although it will be a\n   slow process because the signer can never\
    \ be sure which algorithm(s)\n   the verifier supports.  For this reason, canonicalization\
    \ algorithms,\n   like cryptographic algorithms, should undergo a wide and careful\n\
    \   review process.\n"
- title: 4.1.9.  Body Length Limit Abuse
  contents:
  - "4.1.9.  Body Length Limit Abuse\n   A body length limit is an optional indication\
    \ from the signer of how\n   much content has been signed.  The verifier can either\
    \ ignore the\n   limit, verify the specified portion of the message, or truncate\
    \ the\n   message to the specified portion and verify it.  The motivation for\n\
    \   this feature is the behavior of many mailing lists that add a\n   trailer,\
    \ perhaps identifying the list, at the end of messages.\n   When body length limits\
    \ are used, there is the potential for an\n   attacker to add content to the message.\
    \  It has been shown that this\n   content, although at the end, can cover desirable\
    \ content, especially\n   in the case of HTML messages.\n   If the body length\
    \ isn't specified, or if the verifier decides to\n   ignore the limit, body length\
    \ limits are moot.  If the verifier or\n   recipient truncates the message at\
    \ the signed content, there is no\n   opportunity for the attacker to add anything.\n\
    \   If the verifier observes body length limits when present, there is\n   the\
    \ potential that an attacker can make undesired content visible to\n   the recipient.\
    \  The size of the appended content makes little\n   difference, because it can\
    \ simply be a URL reference pointing to the\n   actual content.  Receiving MUAs\
    \ can mitigate this threat by, at a\n   minimum, identifying the unsigned content\
    \ in the message.\n"
- title: 4.1.10.  Use of Revoked Key
  contents:
  - "4.1.10.  Use of Revoked Key\n   The benefits obtained by caching of key records\
    \ opens the possibility\n   that keys that have been revoked may be used for some\
    \ period of time\n   after their revocation.  The best examples of this occur\
    \ when a\n   holder of a key delegated by the domain administrator must be\n \
    \  unexpectedly deauthorized from sending mail on behalf of one or more\n   addresses\
    \ in the domain.\n   The caching of key records is normally short-lived, on the\
    \ order of\n   hours to days.  In many cases, this threat can be mitigated simply\
    \ by\n   setting a short time-to-live (TTL) for keys not under the domain\n  \
    \ administrator's direct control (assuming, of course, that control of\n   the\
    \ TTL value may be specified for each record, as it can with DNS).\n   In some\
    \ cases, such as the recovery following a stolen private key\n   belonging to\
    \ one of the domain's MTAs, the possibility of theft and\n   the effort required\
    \ to revoke the key authorization must be\n   considered when choosing a TTL.\
    \  The chosen TTL must be long enough\n   to mitigate denial-of-service attacks\
    \ and provide reasonable\n   transaction efficiency, and no longer.\n"
- title: 4.1.11.  Compromise of Key Server
  contents:
  - "4.1.11.  Compromise of Key Server\n   Rather than by attempting to obtain a private\
    \ key, an attacker might\n   instead focus efforts on the server used to publish\
    \ public keys for a\n   domain.  As in the key theft case, the motive might be\
    \ to allow the\n   attacker to sign messages on behalf of the domain.  This attack\n\
    \   provides the attacker with the additional capability to remove\n   legitimate\
    \ keys from publication, thereby denying the domain the\n   ability for the signatures\
    \ on its mail to verify correctly.\n   In order to limit the ability to sign a\
    \ message to entities\n   authorized by the owner of a signing domain, a relationship\
    \ must be\n   established between the signing address and the location from which\
    \ a\n   public key is obtained to verify the message.  DKIM does this by\n   publishing\
    \ either the public key or a reference to it within the DNS\n   hierarchy of the\
    \ signing domain.  The verifier derives the location\n   from which to retrieve\
    \ the public key from the signing address or\n   domain.  The security of the\
    \ verification process is therefore\n   dependent on the security of the DNS hierarchy\
    \ for the signing\n   domain.\n   An attacker might successfully compromise the\
    \ host that is the\n   primary key server for the signing domain, such as the\
    \ domain's DNS\n   master server.  Another approach might be to compromise a higher-\n\
    \   level DNS server and change the delegation of name servers for the\n   signing\
    \ domain to others under the control of the attacker.\n   This attack can be mitigated\
    \ somewhat by independent monitoring to\n   audit the key service.  Such auditing\
    \ of the key service should occur\n   by means of zone transfers rather than queries\
    \ to the zone's primary\n   server, so that the addition of records to the zone\
    \ can be detected.\n"
- title: 4.1.12.  Falsification of Key Service Replies
  contents:
  - "4.1.12.  Falsification of Key Service Replies\n   Replies from the key service\
    \ may also be spoofed by a suitably\n   positioned attacker.  For DNS, one such\
    \ way to do this is \"cache\n   poisoning\", in which the attacker provides unnecessary\
    \ (and\n   incorrect) additional information in DNS replies, which is cached.\n\
    \   DNSSEC [RFC4033] is the preferred means of mitigating this threat,\n   but\
    \ the current uptake rate for DNSSEC is slow enough that one would\n   not like\
    \ to create a dependency on its deployment.  In the case of a\n   cache poisoning\
    \ attack, the vulnerabilities created by this attack\n   are both localized and\
    \ of limited duration, although records with\n   relatively long TTL may persist\
    \ beyond the attack itself.\n"
- title: 4.1.13.  Publication of Malformed Key Records and/or Signatures
  contents:
  - "4.1.13.  Publication of Malformed Key Records and/or Signatures\n   In this attack,\
    \ the attacker publishes suitably crafted key records\n   or sends mail with intentionally\
    \ malformed signatures, in an attempt\n   to confuse the verifier and perhaps\
    \ disable verification altogether.\n   This attack is really a characteristic\
    \ of an implementation\n   vulnerability, a buffer overflow or lack of bounds\
    \ checking, for\n   example, rather than a vulnerability of the signature mechanism\n\
    \   itself.  This threat is best mitigated by careful implementation and\n   creation\
    \ of test suites that challenge the verification process.\n"
- title: 4.1.14.  Cryptographic Weaknesses in Signature Generation
  contents:
  - "4.1.14.  Cryptographic Weaknesses in Signature Generation\n   The cryptographic\
    \ algorithms used to generate mail signatures,\n   specifically the hash algorithm\
    \ and digital signature generation and\n   verification operations, may over time\
    \ be subject to mathematical\n   techniques that degrade their security.  At this\
    \ writing, the SHA-1\n   hash algorithm is the subject of extensive mathematical\
    \ analysis that\n   has considerably lowered the time required to create two messages\n\
    \   with the same hash value.  This trend can be expected to continue.\n   One\
    \ consequence of a weakness in the hash algorithm is a hash\n   collision attack.\
    \  Hash collision attacks in message signing systems\n   involve the same person\
    \ creating two different messages that have the\n   same hash value, where only\
    \ one of the two messages would normally be\n   signed.  The attack is based on\
    \ the second message inheriting the\n   signature of the first.  For DKIM, this\
    \ means that a sender might\n   create a \"good\" message and a \"bad\" message,\
    \ where some filter at the\n   signing party's site would sign the good message\
    \ but not the bad\n   message.  The attacker gets the good message signed, and\
    \ then\n   incorporates that signature in the bad message.  This scenario is not\n\
    \   common, but could happen, for example, at a site that does content\n   analysis\
    \ on messages before signing them.\n   Current known attacks against SHA-1 make\
    \ this attack extremely\n   difficult to mount, but as attacks improve and computing\
    \ power\n   becomes more readily available, such an attack could become\n   achievable.\n\
    \   The message signature system must be designed to support multiple\n   signature\
    \ and hash algorithms, and the signing domain must be able to\n   specify which\
    \ algorithms it uses to sign messages.  The choice of\n   algorithms must be published\
    \ in key records, and not only in the\n   signature itself, to ensure that an\
    \ attacker is not able to create\n   signatures using algorithms weaker than the\
    \ domain wishes to permit.\n   Because the signer and verifier of email do not,\
    \ in general,\n   communicate directly, negotiation of the algorithms used for\
    \ signing\n   cannot occur.  In other words, a signer has no way of knowing which\n\
    \   algorithm(s) a verifier supports or (due to mail forwarding) where\n   the\
    \ verifier is.  For this reason, it is expected that once message\n   signing\
    \ is widely deployed, algorithm change will occur slowly, and\n   legacy algorithms\
    \ will need to be supported for a considerable\n   period.  Algorithms used for\
    \ message signatures therefore need to be\n   secure against expected cryptographic\
    \ developments several years into\n   the future.\n"
- title: 4.1.15.  Display Name Abuse
  contents:
  - "4.1.15.  Display Name Abuse\n   Message signatures only relate to the address-specification\
    \ portion\n   of an email address, while some MUAs only display (or some recipients\n\
    \   only pay attention to) the display name portion of the address.  This\n  \
    \ inconsistency leads to an attack where the attacker uses a From\n   header field\
    \ such as:\n   From: \"Dudley DoRight\" <whiplash@example.org>\n   In this example,\
    \ the attacker, whiplash@example.org, can sign the\n   message and still convince\
    \ some recipients that the message is from\n   Dudley DoRight, who is presumably\
    \ a trusted individual.  Coupled with\n   the use of a throw-away domain or email\
    \ address, it may be difficult\n   to hold the attacker accountable for using\
    \ another's display name.\n   This is an attack that must be dealt with in the\
    \ recipient's MUA.\n   One approach is to require that the signer's address specification\n\
    \   (and not just the display name) be visible to the recipient.\n"
- title: 4.1.16.  Compromised System within Originator's Network
  contents:
  - "4.1.16.  Compromised System within Originator's Network\n   In many cases, MTAs\
    \ may be configured to accept and sign messages\n   that originate within the\
    \ topological boundaries of the originator's\n   network (i.e., within a firewall).\
    \  The increasing use of compromised\n   systems to send email presents a problem\
    \ for such policies, because\n   the attacker, using a compromised system as a\
    \ proxy, can generate\n   signed mail at will.\n   Several approaches exist for\
    \ mitigating this attack.  The use of\n   authenticated submission, even within\
    \ the network boundaries, can be\n   used to limit the addresses for which the\
    \ attacker may obtain a\n   signature.  It may also help locate the compromised\
    \ system that is\n   the source of the messages more quickly.  Content analysis\
    \ of\n   outbound mail to identify undesirable and malicious content, as well\n\
    \   as monitoring of the volume of messages being sent by users, may also\n  \
    \ prevent arbitrary messages from being signed and sent.\n"
- title: 4.1.17.  Verification Probe Attack
  contents:
  - "4.1.17.  Verification Probe Attack\n   As noted above, bad actors (attackers)\
    \ can sign messages on behalf of\n   domains they control.  Since they may also\
    \ control the key service\n   (e.g., the authoritative DNS name servers for the\
    \ _domainkey\n   subdomain), it is possible for them to observe public key lookups,\n\
    \   and their source, when messages are verified.\n   One such attack, which we\
    \ will refer to as a \"verification probe\", is\n   to send a message with a DKIM\
    \ signature to each of many addresses in\n   a mailing list.  The messages need\
    \ not contain valid signatures, and\n   each instance of the message would typically\
    \ use a different\n   selector.  The attacker could then monitor key service requests\
    \ and\n   determine which selectors had been accessed, and correspondingly\n \
    \  which addressees used DKIM verification.  This could be used to\n   target\
    \ future mailings at recipients who do not use DKIM\n   verification, on the premise\
    \ that these addressees are more likely to\n   act on the message contents.\n"
- title: 4.1.18.  Key Publication by Higher-Level Domain
  contents:
  - "4.1.18.  Key Publication by Higher-Level Domain\n   In order to support the ability\
    \ of a domain to sign for subdomains\n   under its administrative control, DKIM\
    \ permits the domain of a\n   signature (d= tag) to be any higher-level domain\
    \ than the signature's\n   address (i= or equivalent).  However, since there is\
    \ no mechanism for\n   determining common administrative control of a subdomain,\
    \ it is\n   possible for a parent to publish keys that are valid for any domain\n\
    \   below them in the DNS hierarchy.  In other words, mail from the\n   domain\
    \ example.anytown.ny.us could be signed using keys published by\n   anytown.ny.us,\
    \ ny.us, or us, in addition to the domain itself.\n   Operation of a domain always\
    \ requires a trust relationship with\n   higher-level domains.  Higher-level domains\
    \ already have ultimate\n   power over their subdomains:  they could change the\
    \ name server\n   delegation for the domain or disenfranchise it entirely.  So\
    \ it is\n   unlikely that a higher-level domain would intentionally compromise\
    \ a\n   subdomain in this manner.  However, if higher-level domains send mail\n\
    \   on their own behalf, they may wish to publish keys at their own\n   level.\
    \  Higher-level domains must employ special care in the\n   delegation of keys\
    \ they publish to ensure that any of their\n   subdomains are not compromised\
    \ by misuse of such keys.\n"
- title: 4.2.  Attacks against Message Signing Practices
  contents:
  - "4.2.  Attacks against Message Signing Practices\n   The following is a summary\
    \ of postulated attacks against signing\n   practices:\n   +---------------------------------------------+--------+------------+\n\
    \   | Attack Name                                 | Impact | Likelihood |\n  \
    \ +---------------------------------------------+--------+------------+\n   |\
    \ Look-alike domain names                     |  High  |    High    |\n   | Internationalized\
    \ domain name abuse         |  High  |    High    |\n   | Denial-of-service attack\
    \ against signing    | Medium |   Medium   |\n   | practices                 \
    \                  |        |            |\n   | Use of multiple From addresses\
    \              |   Low  |   Medium   |\n   | Abuse of third-party signatures \
    \            | Medium |    High    |\n   | Falsification of Sender Signing Practices\
    \   | Medium |   Medium   |\n   | replies                                    \
    \ |        |            |\n   +---------------------------------------------+--------+------------+\n"
- title: 4.2.1.  Look-Alike Domain Names
  contents:
  - "4.2.1.  Look-Alike Domain Names\n   Attackers may attempt to circumvent signing\
    \ practices of a domain by\n   using a domain name that is close to, but not the\
    \ same as, the domain\n   with signing practices.  For instance, \"example.com\"\
    \ might be\n   replaced by \"examp1e.com\".  If the message is not to be signed,\
    \ DKIM\n   does not require that the domain used actually exist (although other\n\
    \   mechanisms may make this a requirement).  Services exist to monitor\n   domain\
    \ registrations to identify potential domain name abuse, but\n   naturally do\
    \ not identify the use of unregistered domain names.\n   A related attack is possible\
    \ when the MUA does not render the domain\n   name in an easily recognizable format.\
    \  If, for example, a Chinese\n   domain name is rendered in \"punycode\" as xn--cjsp26b3obxw7f.com,\
    \ the\n   unfamiliarity of that representation may enable other domains to more\n\
    \   easily be mis-recognized as the expected domain.\n   Users that are unfamiliar\
    \ with internet naming conventions may also\n   mis-recognize certain names. \
    \ For example, users may confuse\n   online.example.com with online-example.com,\
    \ the latter of which may\n   have been registered by an attacker.\n"
- title: 4.2.2.  Internationalized Domain Name Abuse
  contents:
  - "4.2.2.  Internationalized Domain Name Abuse\n   Internationalized domain names\
    \ present a special case of the look-\n   alike domain name attack described above.\
    \  Due to similarities in the\n   appearance of many Unicode characters, domains\
    \ (particularly those\n   drawing characters from different groups) may be created\
    \ that are\n   visually indistinguishable from other, possibly high-value domains.\n\
    \   This is discussed in detail in Unicode Technical Report 36 [UTR36].\n   Surveillance\
    \ of domain registration records may point out some of\n   these, but there are\
    \ many such similarities.  As in the look-alike\n   domain attack above, this\
    \ technique may also be used to circumvent\n   sender signing practices of other\
    \ domains.\n"
- title: 4.2.3.  Denial-of-Service Attack against Signing Practices
  contents:
  - "4.2.3.  Denial-of-Service Attack against Signing Practices\n   Just as the publication\
    \ of public keys by a domain can be impacted by\n   an attacker, so can the publication\
    \ of Sender Signing Practices (SSP)\n   by a domain.  In the case of SSP, the\
    \ transmission of large amounts\n   of unsigned mail purporting to come from the\
    \ domain can result in a\n   heavy transaction load requesting the SSP record.\
    \  More general DoS\n   attacks against the servers providing the SSP records\
    \ are possible as\n   well.  This is of particular concern since the default signing\n\
    \   practices are \"we don't sign everything\", which means that SSP\n   failures\
    \ result in the verifier's failure to heed more stringent\n   signing practices.\n\
    \   As with defense against DoS attacks for key servers, the best defense\n  \
    \ against this attack is to provide redundant servers, preferably on\n   geographically-separate\
    \ parts of the Internet.  Caching again helps a\n   great deal, and signing practices\
    \ should rarely change, so TTL values\n   can be relatively large.\n"
- title: 4.2.4.  Use of Multiple From Addresses
  contents:
  - "4.2.4.  Use of Multiple From Addresses\n   Although this usage is never seen\
    \ by most recipients, RFC 2822\n   [RFC2822] permits the From address to contain\
    \ multiple address\n   specifications.  The lookup of Sender Signing Practices\
    \ is based on\n   the From address, so if addresses from multiple domains are\
    \ in the\n   From address, the question arises which signing practices to use.\
    \  A\n   rule (say, \"use the first address\") could be specified, but then an\n\
    \   attacker could put a throwaway address prior to that of a high-value\n   domain.\
    \  It is also possible for SSP to look at all addresses, and\n   choose the most\
    \ restrictive rule.  This is an area in need of further\n   study.\n"
- title: 4.2.5.  Abuse of Third-Party Signatures
  contents:
  - "4.2.5.  Abuse of Third-Party Signatures\n   In a number of situations, including\
    \ mailing lists, event\n   invitations, and \"send this article to a friend\"\
    \ services, the DKIM\n   signature on a message may not come from the originating\
    \ address\n   domain.  For this reason, \"third-party\" signatures, those attached\
    \ by\n   the mailing list, invitation service, or news service, frequently\n \
    \  need to be regarded as having some validity.  Since this effectively\n   makes\
    \ it possible for any domain to sign any message, a sending\n   domain may publish\
    \ sender signing practices stating that it does not\n   use such services, and\
    \ accordingly that verifiers should view such\n   signatures with suspicion.\n\
    \   However, the restrictions placed on a domain by publishing \"no\n   third-party\"\
    \ signing practices effectively disallows many existing\n   uses of email.  For\
    \ the majority of domains that are unable to adopt\n   these practices, an attacker\
    \ may with some degree of success sign\n   messages purporting to come from the\
    \ domain.  For this reason,\n   accreditation and reputation services, as well\
    \ as locally-maintained\n   whitelists and blacklists, will need to play a significant\
    \ role in\n   evaluating messages that have been signed by third parties.\n"
- title: 4.2.6.  Falsification of Sender Signing Practices Replies
  contents:
  - "4.2.6.  Falsification of Sender Signing Practices Replies\n   In an analogous\
    \ manner to the falsification of key service replies\n   described in Section\
    \ 4.1.12, replies to sender signing practices\n   queries can also be falsified.\
    \  One such attack would be to weaken\n   the signing practices to make unsigned\
    \ messages allegedly from a\n   given domain appear less suspicious.  Another\
    \ attack on a victim\n   domain that is not signing messages could attempt to\
    \ make the\n   domain's messages look more suspicious, in order to interfere with\n\
    \   the victim's ability to send mail.\n   As with the falsification of key service\
    \ replies, DNSSEC is the\n   preferred means of mitigating this attack.  Even\
    \ in the absence of\n   DNSSEC, vulnerabilities due to cache poisoning are localized.\n"
- title: 4.3.  Other Attacks
  contents:
  - "4.3.  Other Attacks\n   This section describes attacks against other Internet\
    \ infrastructure\n   that are enabled by deployment of DKIM.  A summary of these\n\
    \   postulated attacks is as follows:\n      +--------------------------------------+--------+------------+\n\
    \      | Attack Name                          | Impact | Likelihood |\n      +--------------------------------------+--------+------------+\n\
    \      | Packet amplification attacks via DNS |   N/A  |   Medium   |\n      +--------------------------------------+--------+------------+\n"
- title: 4.3.1.  Packet Amplification Attacks via DNS
  contents:
  - "4.3.1.  Packet Amplification Attacks via DNS\n   Recently, there has been an\
    \ increase in denial-of-service attacks\n   involving the transmission of spoofed\
    \ UDP DNS requests to openly-\n   accessible domain name servers [US-CERT-DNS].\
    \  To the extent that the\n   response from the name server is larger than the\
    \ request, the name\n   server functions as an amplifier for such an attack.\n\
    \   DKIM contributes indirectly to this attack by requiring the\n   publication\
    \ of fairly large DNS records for distributing public keys.\n   The names of these\
    \ records are also well known, since the record\n   names can be determined by\
    \ examining properly-signed messages.  This\n   attack does not have an impact\
    \ on DKIM itself.  DKIM, however, is not\n   the only application that uses large\
    \ DNS records, and a DNS-based\n   solution to this problem will likely be required.\n"
- title: 5.  Derived Requirements
  contents:
  - "5.  Derived Requirements\n   This section lists requirements for DKIM not explicitly\
    \ stated in the\n   above discussion.  These requirements include:\n      The\
    \ store for key and SSP records must be capable of utilizing\n      multiple geographically-dispersed\
    \ servers.\n      Key and SSP records must be cacheable, either by the verifier\n\
    \      requesting them or by other infrastructure.\n      The cache time-to-live\
    \ for key records must be specifiable on a\n      per-record basis.\n      The\
    \ signature algorithm identifier in the message must be one of\n      the ones\
    \ listed in a key record for the identified domain.\n      The algorithm(s) used\
    \ for message signatures need to be secure\n      against expected cryptographic\
    \ developments several years in the\n      future.\n"
- title: 6.  Security Considerations
  contents:
  - "6.  Security Considerations\n   This document describes the security threat environment\
    \ in which\n   DomainKeys Identified Mail (DKIM) is expected to provide some\n\
    \   benefit, and it presents a number of attacks relevant to its\n   deployment.\n"
- title: 7.  Informative References
  contents:
  - "7.  Informative References\n   [Bernstein04]  Bernstein, D., \"Cache Timing Attacks\
    \ on AES\",\n                  April 2004.\n   [Boneh03]      Boneh, D. and D.\
    \ Brumley, \"Remote Timing Attacks are\n                  Practical\", Proc. 12th\
    \ USENIX Security Symposium,\n                  2003.\n   [DKIM-BASE]    Allman,\
    \ E., \"DomainKeys Identified Mail (DKIM)\n                  Signatures\", Work\
    \ in Progress, August 2006.\n   [DKIM-SSP]     Allman, E., \"DKIM Sender Signing\
    \ Practices\", Work in\n                  Progress, August 2006.\n   [Kocher96]\
    \     Kocher, P., \"Timing Attacks on Implementations of\n                  Diffie-Hellman,\
    \ RSA, and other Cryptosystems\",\n                  Advances in Cryptology, pages\
    \ 104-113, 1996.\n   [Kocher99]     Kocher, P., Joffe, J., and B. Yun, \"Differential\
    \ Power\n                  Analysis: Leaking Secrets\", Crypto '99, pages 388-397,\n\
    \                  1999.\n   [RFC1939]      Myers, J. and M. Rose, \"Post Office\
    \ Protocol - Version\n                  3\", STD 53, RFC 1939, May 1996.\n   [RFC2821]\
    \      Klensin, J., \"Simple Mail Transfer Protocol\",\n                  RFC\
    \ 2821, April 2001.\n   [RFC2822]      Resnick, P., \"Internet Message Format\"\
    , RFC 2822,\n                  April 2001.\n   [RFC3501]      Crispin, M., \"\
    INTERNET MESSAGE ACCESS PROTOCOL -\n                  VERSION 4rev1\", RFC 3501,\
    \ March 2003.\n   [RFC4033]      Arends, R., Austein, R., Larson, M., Massey,\
    \ D., and\n                  S. Rose, \"DNS Security Introduction and Requirements\"\
    ,\n                  RFC 4033, March 2005.\n   [US-CERT-DNS]  US-CERT, \"The Continuing\
    \ Denial of Service Threat\n                  Posed by DNS Recursion\".\n   [UTR36]\
    \        Davis, M. and M. Suignard, \"Unicode Technical Report\n             \
    \     #36: Unicode Security Considerations\", UTR 36,\n                  July\
    \ 2005.\n"
- title: Appendix A.  Acknowledgements
  contents:
  - "Appendix A.  Acknowledgements\n   The author wishes to thank Phillip Hallam-Baker,\
    \ Eliot Lear, Tony\n   Finch, Dave Crocker, Barry Leiba, Arvel Hathcock, Eric\
    \ Allman, Jon\n   Callas, Stephen Farrell, Doug Otis, Frank Ellermann, Eric Rescorla,\n\
    \   Paul Hoffman, Hector Santos, and numerous others on the ietf-dkim\n   mailing\
    \ list for valuable suggestions and constructive criticism of\n   earlier versions\
    \ of this document.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Jim Fenton\n   Cisco Systems, Inc.\n   MS SJ-9/2\n   170\
    \ W. Tasman Drive\n   San Jose, CA  95134-1706\n   USA\n   Phone:  +1 408 526\
    \ 5914\n   EMail:  fenton@cisco.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2006).\n   This\
    \ document is subject to the rights, licenses and restrictions\n   contained in\
    \ BCP 78, and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET\n   ENGINEERING\
    \ TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT\
    \ LIMITED TO ANY WARRANTY THAT THE USE OF THE\n   INFORMATION HEREIN WILL NOT\
    \ INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS\
    \ FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at\n   ietf-ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is provided by the IETF\n\
    \   Administrative Support Activity (IASA).\n"
