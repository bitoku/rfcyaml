- title: __initial_text__
  contents:
  - '   Reporting IP Network Performance Metrics: Different Points of View

    '
- title: Abstract
  contents:
  - "Abstract\n   Consumers of IP network performance metrics have many different\
    \ uses\n   in mind.  This memo provides \"long-term\" reporting considerations\n\
    \   (e.g., hours, days, weeks, or months, as opposed to 10 seconds),\n   based\
    \ on analysis of the points of view of two key audiences.  It\n   describes how\
    \ these audience categories affect the selection of\n   metric parameters and\
    \ options when seeking information that serves\n   their needs.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6703.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2012 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n   This document\
    \ may contain material from IETF Documents or IETF\n   Contributions published\
    \ or made publicly available before November\n   10, 2008.  The person(s) controlling\
    \ the copyright in some of this\n   material may not have granted the IETF Trust\
    \ the right to allow\n   modifications of such material outside the IETF Standards\
    \ Process.\n   Without obtaining an adequate license from the person(s) controlling\n\
    \   the copyright in such materials, this document may not be modified\n   outside\
    \ the IETF Standards Process, and derivative works of it may\n   not be created\
    \ outside the IETF Standards Process, except to format\n   it for publication\
    \ as an RFC or to translate it into languages other\n   than English.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \   2. Purpose and Scope ...............................................4\n  \
    \ 3. Reporting Results ...............................................5\n    \
    \  3.1. Overview of Metric Statistics ..............................5\n      3.2.\
    \ Long-Term Reporting Considerations .........................6\n   4. Effect\
    \ of POV on the Loss Metric ................................8\n      4.1. Loss\
    \ Threshold .............................................8\n           4.1.1.\
    \ Network Characterization ............................8\n           4.1.2. Application\
    \ Performance ............................11\n      4.2. Errored Packet Designation\
    \ ................................11\n      4.3. Causes of Lost Packets ....................................11\n\
    \      4.4. Summary for Loss ..........................................12\n  \
    \ 5. Effect of POV on the Delay Metric ..............................12\n    \
    \  5.1. Treatment of Lost Packets .................................12\n      \
    \     5.1.1. Application Performance ............................13\n        \
    \   5.1.2. Network Characterization ...........................13\n          \
    \ 5.1.3. Delay Variation ....................................14\n           5.1.4.\
    \ Reordering .........................................15\n      5.2. Preferred\
    \ Statistics ......................................15\n      5.3. Summary for\
    \ Delay .........................................16\n   6. Reporting Raw Capacity\
    \ Metrics .................................16\n      6.1. Type-P Parameter ..........................................17\n\
    \      6.2. A priori Factors ..........................................17\n  \
    \    6.3. IP-Layer Capacity .........................................17\n    \
    \  6.4. IP-Layer Utilization ......................................18\n      6.5.\
    \ IP-Layer Available Capacity ...............................18\n      6.6. Variability\
    \ in Utilization and Available Capacity .........19\n           6.6.1. General\
    \ Summary of Variability .....................19\n   7. Reporting Restricted Capacity\
    \ Metrics ..........................20\n      7.1. Type-P Parameter and Type-C\
    \ Parameter .....................21\n      7.2. A Priori Factors ..........................................21\n\
    \      7.3. Measurement Interval ......................................22\n  \
    \    7.4. Bulk Transfer Capacity Reporting ..........................22\n    \
    \  7.5. Variability in Bulk Transfer Capacity .....................23\n   8. Reporting\
    \ on Test Streams and Sample Size ......................23\n      8.1. Test Stream\
    \ Characteristics ...............................23\n      8.2. Sample Size ...............................................24\n\
    \   9. Security Considerations ........................................25\n  \
    \ 10. Acknowledgements ..............................................25\n   11.\
    \ References ....................................................25\n      11.1.\
    \ Normative References .....................................25\n      11.2. Informative\
    \ References ...................................26\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   When designing measurements of IP networks and presenting\
    \ a result,\n   knowledge of the audience is a key consideration.  To present\
    \ a\n   useful and relevant portrait of network conditions, one must answer\n\
    \   the following question:\n   \"How will the results be used?\"\n   There are\
    \ two main audience categories for the report of results:\n   1.  Network Characterization\
    \ - describes conditions in an IP network\n       for quality assurance, troubleshooting,\
    \ modeling, Service Level\n       Agreements (SLAs), etc.  This point of view\
    \ (POV) looks inward\n       toward the network where the report consumer intends\
    \ their\n       actions.\n   2.  Application Performance Estimation - describes\
    \ the network\n       conditions in a way that facilitates determining effects\
    \ on user\n       applications, and ultimately the users themselves.  This POV\n\
    \       looks outward, toward the user(s), accepting the network as is.\n    \
    \   This report consumer intends to estimate a network-dependent\n       aspect\
    \ of performance or design some aspect of an application's\n       accommodation\
    \ of the network.  (These are *not* application\n       metrics; they are defined\
    \ at the IP layer.)\n   This memo considers how these different POVs affect both\
    \ the\n   measurement design (parameters and options of the metrics) and\n   statistics\
    \ reported when serving the report consumer's needs.\n   The IP Performance Metrics\
    \ (IPPM) Framework [RFC2330] and other RFCs\n   describing IPPM provide a background\
    \ for this memo.\n"
- title: 2.  Purpose and Scope
  contents:
  - "2.  Purpose and Scope\n   The purpose of this memo is to clearly delineate two\
    \ POVs for using\n   measurements and describe their effects on the test design,\
    \ including\n   the selection of metric parameters and reporting the results.\n\
    \   The scope of this memo primarily covers the test design and reporting\n  \
    \ of the loss and delay metrics [RFC2680] [RFC2679].  It will also\n   discuss\
    \ the delay variation [RFC3393] and reordering metrics\n   [RFC4737] where applicable.\n\
    \   With capacity metrics growing in relevance to the industry, the memo\n   also\
    \ covers POV and reporting considerations for metrics resulting\n   from the Bulk\
    \ Transfer Capacity Framework [RFC3148] and Network\n   Capacity Definitions [RFC5136].\
    \  These memos effectively describe two\n   different categories of metrics:\n\
    \   o  Restricted [RFC3148]: includes restrictions of congestion control\n   \
    \   and the notion of unique data bits delivered, and\n   o  Raw [RFC5136]: uses\
    \ a definition of raw capacity without the\n      restrictions of data uniqueness\
    \ or congestion awareness.\n   It might seem, at first glance, that each of these\
    \ metrics has an\n   obvious audience (raw = network characterization, restricted\
    \ =\n   application performance), but reality is more complex and consistent\n\
    \   with the overall topic of capacity measurement and reporting.  For\n   example,\
    \ TCP is usually used in restricted capacity measurement\n   methods, while UDP\
    \ appears in raw capacity measurement.  The raw and\n   restricted capacity metrics\
    \ will be treated in separate sections,\n   although they share one common reporting\
    \ issue: representing\n   variability in capacity metric results as part of a\
    \ long-term report.\n   Sampling, or the design of the active packet stream that\
    \ is the basis\n   for the measurements, is also discussed.\n"
- title: 3.  Reporting Results
  contents:
  - "3.  Reporting Results\n   This section gives an overview of recommendations,\
    \ followed by\n   additional considerations for reporting results in the \"long\
    \ term\",\n   based on the discussion and conclusions of the major sections that\n\
    \   follow.\n"
- title: 3.1.  Overview of Metric Statistics
  contents:
  - "3.1.  Overview of Metric Statistics\n   This section gives an overview of reporting\
    \ recommendations for all\n   the metrics considered in this memo.\n   The minimal\
    \ report on measurements must include both loss and delay\n   metrics.\n   For\
    \ packet loss, the loss ratio defined in [RFC2680] is a sufficient\n   starting\
    \ point -- especially the existing guidance for setting the\n   loss threshold\
    \ waiting time.  In Section 4.1.1, we have calculated a\n   waiting time -- 51\
    \ seconds -- that should be sufficient to\n   differentiate between packets that\
    \ are truly lost or have long finite\n   delays under general measurement circumstances.\
    \  Knowledge of\n   specific conditions can help to reduce this threshold, and\
    \ a waiting\n   time of approximately 50 seconds is considered to be manageable\
    \ in\n   practice.\n   We note that a loss ratio calculated according to [Y.1540]\
    \ would\n   exclude errored packets from the numerator.  In practice, the\n  \
    \ difference between these two loss metrics is small, if any, depending\n   on\
    \ whether the last link prior to the Destination contributes errored\n   packets.\n\
    \   For packet delay, we recommend providing both the mean delay and the\n   median\
    \ delay with lost packets designated as undefined (as permitted\n   by [RFC2679]).\
    \  Both statistics are based on a conditional\n   distribution, and the condition\
    \ is packet arrival prior to a waiting\n   time dT, where dT has been set to take\
    \ maximum packet lifetimes into\n   account, as discussed above for loss.  Using\
    \ a long dT helps to\n   ensure that delay distributions are not truncated.\n\
    \   For Packet Delay Variation (PDV), the minimum delay of the\n   conditional\
    \ distribution should be used as the reference delay for\n   computing PDV according\
    \ to [Y.1540] or [RFC5481] and [RFC3393].  A\n   useful value to report is a \"\
    pseudo\" range of delay variation based\n   on calculating the difference between\
    \ a high percentile of delay and\n   the minimum delay.  For example, the 99.9th\
    \ percentile minus the\n   minimum will give a value that can be compared with\
    \ objectives in\n   [Y.1541].\n   For both raw capacity and restricted capacity,\
    \ reporting the\n   variability in a useful way is identified as the main challenge.\
    \  The\n   min, max, and range statistics are suggested along with a ratio of\n\
    \   max to min and moving averages.  In the end, a simple plot of the\n   singleton\
    \ results over time may succeed where summary metrics fail or\n   may serve to\
    \ confirm that the summaries are valid.\n"
- title: 3.2.  Long-Term Reporting Considerations
  contents:
  - "3.2.  Long-Term Reporting Considerations\n   [IPPM-RPT] describes methods to\
    \ conduct measurements and report the\n   results on a near-immediate time scale\
    \ (10 seconds, which we consider\n   to be \"short-term\").\n   Measurement intervals\
    \ and reporting intervals need not be the same\n   length.  Sometimes, the user\
    \ is only concerned with the performance\n   levels achieved over a relatively\
    \ long interval of time (e.g., days,\n   weeks, or months, as opposed to 10 seconds).\
    \  However, there can be\n   risks involved with running a measurement continuously\
    \ over a long\n   period without recording intermediate results:\n   o  Temporary\
    \ power failure may cause loss of all results to date.\n   o  Measurement system\
    \ timing synchronization signals may experience a\n      temporary outage, causing\
    \ subsets of measurements to be in error\n      or invalid.\n   o  Maintenance\
    \ on the measurement system or on its connectivity to\n      the network under\
    \ test may be necessary.\n   For these and other reasons, such as\n   o  the constraint\
    \ to collect measurements on intervals similar to\n      user session length,\n\
    \   o  the dual use of measurements in monitoring activities where\n      results\
    \ are needed on a period of a few minutes, or\n   o  the ability to inspect results\
    \ of a single measurement interval\n      for deeper analysis,\n   there is value\
    \ in conducting measurements on intervals that are much\n   shorter than the reporting\
    \ interval.\n   There are several approaches for aggregating a series of measurement\n\
    \   results over time in order to make a statement about the longer\n   reporting\
    \ interval.  One approach requires the storage of all metric\n   singletons collected\
    \ throughout the reporting interval, even though\n   the measurement interval\
    \ stops and starts many times.\n   Another approach is described in [RFC5835]\
    \ as \"temporal aggregation\".\n   This approach would estimate the results for\
    \ the reporting interval\n   based on combining many individual short-term measurement\
    \ interval\n   statistics to yield a long-term result.  The result would ideally\n\
    \   appear in the same form as though a continuous measurement had been\n   conducted.\
    \  A memo addressing the details of temporal aggregation is\n   yet to be prepared.\n\
    \   Yet another approach requires a numerical objective for the metric,\n   and\
    \ the results of each measurement interval are compared with the\n   objective.\
    \  Every measurement interval where the results meet the\n   objective contribute\
    \ to the fraction of time with performance as\n   specified.  When the reporting\
    \ interval contains many measurement\n   intervals, it is possible to present\
    \ the results as \"metric A was\n   less than or equal to objective X during Y%\
    \ of time\".\n      NOTE that numerical thresholds of acceptability are not set\
    \ in\n      IETF performance work and are therefore excluded from the scope of\n\
    \      this memo.\n   In all measurements, it is important to avoid unintended\n\
    \   synchronization with network events.  This topic is treated in\n   [RFC2330]\
    \ for Poisson-distributed inter-packet time streams and in\n   [RFC3432] for Periodic\
    \ streams.  Both avoid synchronization by using\n   random start times.\n   There\
    \ are network conditions where it is simply more useful to report\n   the connectivity\
    \ status of the Source-Destination path, and to\n   distinguish time intervals\
    \ where connectivity can be demonstrated\n   from other time intervals (where\
    \ connectivity does not appear to\n   exist).  [RFC2678] specifies a number of\
    \ one-way and two-way\n   connectivity metrics of increasing complexity.  In this\
    \ memo, we\n   recommend that long-term reporting of loss, delay, and other metrics\n\
    \   be limited to time intervals where connectivity can be demonstrated,\n   and\
    \ that other intervals be summarized as the percent of time where\n   connectivity\
    \ does not appear to exist.  We note that this same\n   approach has been adopted\
    \ in ITU-T Recommendation [Y.1540] where\n   performance parameters are only valid\
    \ during periods of service\n   \"availability\" (evaluated according to a function\
    \ based on packet\n   loss, and sustained periods of loss ratio greater than a\
    \ threshold\n   are declared \"unavailable\").\n"
- title: 4.  Effect of POV on the Loss Metric
  contents:
  - "4.  Effect of POV on the Loss Metric\n   This section describes the ways in which\
    \ the loss metric can be tuned\n   to reflect the preferences of the two audience\
    \ categories, or\n   different POVs.  The waiting time before declaring that a\
    \ packet is\n   lost -- the loss threshold -- is one area where there would appear\
    \ to\n   be a difference, but the ability to post-process the results may\n  \
    \ resolve it.\n"
- title: 4.1.  Loss Threshold
  contents:
  - "4.1.  Loss Threshold\n   RFC 2680 [RFC2680] defines the concept of a waiting\
    \ time for packets\n   to arrive, beyond which they are declared lost.  The text\
    \ of the RFC\n   declines to recommend a value, instead saying that \"good engineering,\n\
    \   including an understanding of packet lifetimes, will be needed in\n   practice\"\
    .  Later, in the methodology, they give reasons for waiting\n   \"a reasonable\
    \ period of time\" and leave the definition of\n   \"reasonable\" intentionally\
    \ vague.  Below, we estimate a practical\n   bound on waiting time.\n"
- title: 4.1.1.  Network Characterization
  contents:
  - "4.1.1.  Network Characterization\n   Practical measurement experience has shown\
    \ that unusual network\n   circumstances can cause long delays.  One such circumstance\
    \ is when\n   routing loops form during IGP re-convergence following a failure\
    \ or\n   drastic link cost change.  Packets will loop between two routers\n  \
    \ until new routes are installed or until the IPv4 Time-to-Live (TTL)\n   field\
    \ (or the IPv6 Hop Limit) decrements to zero.  Very long delays\n   on the order\
    \ of several seconds have been measured [Casner] [Cia03].\n   Therefore, network\
    \ characterization activities prefer a long waiting\n   time in order to distinguish\
    \ these events from other causes of loss\n   (such as packet discard at a full\
    \ queue, or tail drop).  This way,\n   the metric design helps to distinguish\
    \ more reliably between packets\n   that might yet arrive and those that are no\
    \ longer traversing the\n   network.\n   It is possible to calculate a worst-case\
    \ waiting time, assuming that\n   a routing loop is the cause.  We model the path\
    \ between Source and\n   Destination as a series of delays in links (t) and queues\
    \ (q), as\n   these are the dominant contributors to delay (in active measurement,\n\
    \   the Source and Destination hosts contribute minimal delay).  The\n   normal\
    \ path delay, D, across n queues (where TTL is decremented at a\n   node with\
    \ a queue) and n+1 links without encountering a loop, is\n        Path model with\
    \ n=5\n          Source --- q1 --- q2 --- q3 --- q4 --- q5 --- Destination\n \
    \                t0     t1     t2     t3     t4     t5\n                     \
    \              n\n                                  ---\n                    \
    \              \\\n                        D = t  +   >  (t  +  q)\n         \
    \                    0    /     i     i\n                                  ---\n\
    \                                 i = 1\n                        Figure 1: Normal\
    \ Path Delay\n   and the time spent in the loop with L queues is\n           \
    \ Path model with n=5 and L=3\n            Time in one loop = (qx+tx + qy+ty +\
    \ qz+tz)\n                                   qy -- qz\n                      \
    \              |  ?/exit?\n                                   qx--/\\\n      \
    \        Src --- q1 --- q2 ---/    q3 --- q4 --- q5 --- Dst\n                \
    \  t0     t1     t2         t3     t4     t5\n                       j + L-1\n\
    \                        ---\n                        \\                     \
    \     (TTL - n)\n                 R = C   >  (t  +  q)  where C   = ---------\n\
    \                        /     i     i         max      L\n                  \
    \      ---\n                        i=j\n                Figure 2: Delay Due to\
    \ Rotations in a Loop\n   where n is the total number of queues in the non-loop\
    \ path (with n+1\n   links), j is the queue number where the loop begins, C is\
    \ the number\n   of times a packet circles the loop, and TTL is the packet's initial\n\
    \   Time-to-Live value at the Source (or Hop Count in IPv6).\n   If we take the\
    \ delays of all links and queues as 100 ms each, the\n   TTL=255, the number of\
    \ queues n=5, and the queues in the loop L=4,\n   then using C_max:\n      D =\
    \ 1.1 seconds and R ~= 50 seconds, and D + R ~= 51.1 seconds\n   We note that\
    \ the link delays of 100 ms would span most continents,\n   and a constant queue\
    \ length of 100 ms is also very generous.  When a\n   loop occurs, it is almost\
    \ certain to be resolved in 10 seconds or\n   less.  The value calculated above\
    \ is an upper limit for almost any\n   real-world circumstance.\n   A waiting\
    \ time threshold parameter, dT, set consistent with this\n   calculation, would\
    \ not truncate the delay distribution (possibly\n   causing a change in its mathematical\
    \ properties), because the packets\n   that might arrive have been given sufficient\
    \ time to traverse the\n   network.\n   It is worth noting that packets that are\
    \ stored and deliberately\n   forwarded at a much later time constitute a replay\
    \ attack on the\n   measurement system and are beyond the scope of normal performance\n\
    \   reporting.\n"
- title: 4.1.2.  Application Performance
  contents:
  - "4.1.2.  Application Performance\n   Fortunately, application performance estimation\
    \ activities are not\n   adversely affected by the long estimated limit on waiting\
    \ time,\n   because most applications will use shorter time thresholds.  Although\n\
    \   the designer's tendency might be to set the loss threshold at a value\n  \
    \ equivalent to a particular application's threshold, this specific\n   threshold\
    \ can be applied when post-processing the measurements.  A\n   shorter waiting\
    \ time can be enforced by locating packets with delays\n   longer than the application's\
    \ threshold and re-designating such\n   packets as lost.  Thus, the measurement\
    \ system can use a single loss\n   waiting time and support both application and\
    \ network performance\n   POVs simultaneously.\n"
- title: 4.2.  Errored Packet Designation
  contents:
  - "4.2.  Errored Packet Designation\n   RFC 2680 designates packets that arrive\
    \ containing errors as lost\n   packets.  Many packets that are corrupted by bit\
    \ errors are discarded\n   within the network and do not reach their intended\
    \ destination.\n   This is consistent with applications that would check the payload\n\
    \   integrity at higher layers and discard the packet.  However, some\n   applications\
    \ prefer to deal with errored payloads on their own, and\n   even a corrupted\
    \ payload is better than no packet at all.\n   To address this possibility, and\
    \ to make network characterization\n   more complete, distinguishing between packets\
    \ that do not arrive\n   (lost) and errored packets that arrive (conditionally\
    \ lost) is\n   recommended.\n"
- title: 4.3.  Causes of Lost Packets
  contents:
  - "4.3.  Causes of Lost Packets\n   Although many measurement systems use a waiting\
    \ time to determine\n   whether or not a packet is lost, most of the waiting is\
    \ in vain.  The\n   packets are no longer traversing the network and have not\
    \ reached\n   their destination.\n   There are many causes of packet loss, including\
    \ the following:\n   1.  Queue drop, or discard\n   2.  Corruption of the IP header,\
    \ or other essential header\n       information\n   3.  TTL expiration (or use\
    \ of a TTL value that is too small)\n   4.  Link or router failure\n   5.  Layers\
    \ below the Source-to-Destination IP layer can discard\n       packets that fail\
    \ error checking, and link-layer checksums often\n       cover the entire packet\n\
    \   It is reasonable to consider a packet that has not arrived after a\n   large\
    \ amount of time to be lost (due to one of the causes above)\n   because packets\
    \ do not \"live forever\" in the network or have infinite\n   delay.\n"
- title: 4.4.  Summary for Loss
  contents:
  - "4.4.  Summary for Loss\n   Given that measurement post-processing is possible\
    \ (even encouraged\n   in the definitions of IPPM), measurements of loss can easily\
    \ serve\n   both POVs:\n   o  Use a long waiting time to serve network characterization\
    \ and\n      revise results for specific application delay thresholds as\n   \
    \   needed.\n   o  Distinguish between errored packets and lost packets when possible\n\
    \      to aid network characterization, and combine the results for\n      application\
    \ performance if appropriate.\n"
- title: 5.  Effect of POV on the Delay Metric
  contents:
  - "5.  Effect of POV on the Delay Metric\n   This section describes the ways in\
    \ which the delay metric can be\n   tuned to reflect the preferences of the two\
    \ consumer categories, or\n   different POVs.\n"
- title: 5.1.  Treatment of Lost Packets
  contents:
  - "5.1.  Treatment of Lost Packets\n   The delay metric [RFC2679] specifies the\
    \ treatment of packets that do\n   not successfully traverse the network: their\
    \ delay is undefined.\n      >>The *Type-P-One-way-Delay* from Src to Dst at T\
    \ is undefined\n      (informally, infinite)<< means that Src sent the first bit\
    \ of a\n      Type-P packet to Dst at wire-time T and that Dst did not receive\n\
    \      that packet.\n   It is an accepted but informal practice to assign infinite\
    \ delay to\n   lost packets.  We next look at how these two different treatments\n\
    \   align with the needs of measurement consumers who wish to\n   characterize\
    \ networks or estimate application performance.  Also, we\n   look at the way\
    \ that lost packets have been treated in other metrics:\n   delay variation and\
    \ reordering.\n"
- title: 5.1.1.  Application Performance
  contents:
  - "5.1.1.  Application Performance\n   Applications need to perform different functions,\
    \ dependent on\n   whether or not each packet arrives within some finite tolerance.\
    \  In\n   other words, a receiver's packet processing takes only one of two\n\
    \   alternative directions (a \"fork\" in the road):\n   o  Packets that arrive\
    \ within expected tolerance are handled by\n      removing headers, restoring\
    \ smooth delivery timing (as in a\n      de-jitter buffer), restoring sending\
    \ order, checking for errors in\n      payloads, and many other operations.\n\
    \   o  Packets that do not arrive when expected lead to attempted\n      recovery\
    \ from the apparent loss, such as retransmission requests,\n      loss concealment,\
    \ or forward error correction to replace the\n      missing packet.\n   So, it\
    \ is important to maintain a distinction between packets that\n   actually arrive\
    \ and those that do not.  Therefore, it is preferable\n   to leave the delay of\
    \ lost packets undefined and to characterize the\n   delay distribution as a conditional\
    \ distribution (conditioned on\n   arrival).\n"
- title: 5.1.2.  Network Characterization
  contents:
  - "5.1.2.  Network Characterization\n   In this discussion, we assume that both\
    \ loss and delay metrics will\n   be reported for network characterization (at\
    \ least).\n   Assume that packets that do not arrive are reported as lost, usually\n\
    \   as a fraction of all sent packets.  If these lost packets are\n   assigned\
    \ an undefined delay, then the network's inability to deliver\n   them (in a timely\
    \ way) is relegated only in the loss metric when we\n   report statistics on the\
    \ delay distribution conditioned on the event\n   of packet arrival (within the\
    \ loss waiting time threshold).  We can\n   say that the delay and loss metrics\
    \ are orthogonal in that they\n   convey non-overlapping information about the\
    \ network under test.\n   This is a valuable property whose absence is discussed\
    \ below.\n   However, if we assign infinite delay to all lost packets, then\n\
    \   o  The delay metric results are influenced both by packets that\n      arrive\
    \ and those that do not.\n   o  The delay singleton and the loss singleton do\
    \ not appear to be\n      orthogonal (delay is finite when loss=0; delay is infinite\
    \ when\n      loss=1).\n   o  The network is penalized in both the loss and delay\
    \ metrics,\n      effectively double-counting the lost packets.\n   As further\
    \ evidence of overlap, consider the Cumulative Distribution\n   Function (CDF)\
    \ of delay when the value \"positive infinity\" is\n   assigned to all lost packets.\
    \  Figure 3 shows a CDF where a small\n   fraction of packets are lost.\n    \
    \             1 | - - - - - - - - - - - - - - - - - -+\n                   | \
    \                                   |\n                   |          _..----''''''''''''''''''''\n\
    \                   |      ,-''\n                   |    ,'\n                \
    \   |   /                         Mass at\n                   |  /           \
    \               +infinity\n                   | /                           =\
    \ fraction\n                   ||                            lost\n          \
    \         |/\n                 0 |_____________________________________\n    \
    \               0               Delay               +o0\n           Figure 3:\
    \ Cumulative Distribution Function for Delay\n                           When\
    \ Loss = +Infinity\n   We note that a delay CDF that is conditioned on packet\
    \ arrival would\n   not exhibit this apparent overlap with loss.\n   Although\
    \ infinity is a familiar mathematical concept, it is somewhat\n   disconcerting\
    \ to see any time-related metric reported as infinity.\n   Questions are bound\
    \ to arise and tend to detract from the goal of\n   informing the consumer with\
    \ a performance report.\n"
- title: 5.1.3.  Delay Variation
  contents:
  - "5.1.3.  Delay Variation\n   [RFC3393] excludes lost packets from samples, effectively\
    \ assigning\n   an undefined delay to packets that do not arrive in a reasonable\n\
    \   time.  Section 4.1 of [RFC3393] describes this specification and its\n   rationale\
    \ (ipdv = inter-packet delay variation in the quote below).\n      The treatment\
    \ of lost packets as having \"infinite\" or \"undefined\"\n      delay complicates\
    \ the derivation of statistics for ipdv.\n      Specifically, when packets in\
    \ the measurement sequence are lost,\n      simple statistics such as sample mean\
    \ cannot be computed.  One\n      possible approach to handling this problem is\
    \ to reduce the event\n      space by conditioning.  That is, we consider conditional\n\
    \      statistics; namely we estimate the mean ipdv (or other derivative\n   \
    \   statistic) conditioned on the event that selected packet pairs\n      arrive\
    \ at the Destination (within the given timeout).  While this\n      itself is\
    \ not without problems (what happens, for example, when\n      every other packet\
    \ is lost), it offers a way to make some (valid)\n      statements about ipdv,\
    \ at the same time avoiding events with\n      undefined outcomes.\n   We note\
    \ that the argument above applies to all forms of packet delay\n   variation that\
    \ can be constructed using the \"selection function\"\n   concept of [RFC3393].\
    \  In recent work, the two main forms of delay\n   variation metrics have been\
    \ compared, and the results are summarized\n   in [RFC5481].\n"
- title: 5.1.4.  Reordering
  contents:
  - "5.1.4.  Reordering\n   [RFC4737] defines metrics that are based on evaluation\
    \ of packet\n   arrival order and that include a waiting time before declaring\
    \ that a\n   packet is lost (to exclude the packet from further processing).\n\
    \   If packets are assigned a delay value, then the reordering metric\n   would\
    \ declare any packets with infinite delay to be reordered,\n   because their sequence\
    \ numbers will surely be less than the \"Next\n   Expected\" threshold when (or\
    \ if) they arrive.  But this practice\n   would fail to maintain orthogonality\
    \ between the reordering metric\n   and the loss metric.  Confusion can be avoided\
    \ by designating the\n   delay of non-arriving packets as undefined and reserving\
    \ delay values\n   only for packets that arrive within a sufficiently long waiting\
    \ time.\n"
- title: 5.2.  Preferred Statistics
  contents:
  - "5.2.  Preferred Statistics\n   Today in network characterization, the sample\
    \ mean is one statistic\n   that is almost ubiquitously reported.  It is easily\
    \ computed and\n   understood by virtually everyone in this audience category.\
    \  Also,\n   the sample is usually filtered on packet arrival, so that the mean\
    \ is\n   based on a conditional distribution.\n   The median is another statistic\
    \ that summarizes a distribution,\n   having somewhat different properties from\
    \ the sample mean.  The\n   median is stable in distributions with a few outliers\
    \ or without\n   them.  However, the median's stability prevents it from indicating\n\
    \   when a large fraction of the distribution changes value.  50% or more\n  \
    \ values would need to change for the median to capture the change.\n   Both the\
    \ median and sample mean have difficulty with bimodal\n   distributions.  The\
    \ median will reside in only one of the modes, and\n   the mean may not lie in\
    \ either mode range.  For this and other\n   reasons, additional statistics such\
    \ as the minimum, maximum, and 95th\n   percentile have value when summarizing\
    \ a distribution.\n   When both the sample mean and median are available, a comparison\
    \ will\n   sometimes be informative, because these two statistics are equal only\n\
    \   under unusual circumstances, such as when the delay distribution is\n   perfectly\
    \ symmetrical.\n   Also, these statistics are generally useful from the application\n\
    \   performance POV, so there is a common set that should satisfy\n   audiences.\n\
    \   Plots of the delay distribution may also be useful when single-value\n   statistics\
    \ indicate that new conditions are present.  An empirically\n   derived probability\
    \ distribution function will usually describe\n   multiple modes more efficiently\
    \ than any other form of result.\n"
- title: 5.3.  Summary for Delay
  contents:
  - "5.3.  Summary for Delay\n   From the perspectives of\n   1.  application/receiver\
    \ analysis, where subsequent processing\n       depends on whether the packet\
    \ arrives or times out,\n   2.  straightforward network characterization without\
    \ double-counting\n       defects, and\n   3.  consistency with delay variation\
    \ and reordering metric\n       definitions,\n   the most efficient practice is\
    \ to distinguish between packets that\n   are truly lost and those that are delayed\
    \ packets with a sufficiently\n   long waiting time, and to designate the delay\
    \ of non-arriving packets\n   as undefined.\n"
- title: 6.  Reporting Raw Capacity Metrics
  contents:
  - "6.  Reporting Raw Capacity Metrics\n   Raw capacity refers to the metrics defined\
    \ in [RFC5136], which do not\n   include restrictions such as data uniqueness\
    \ or flow-control response\n   to congestion.\n   The metrics considered are IP-layer\
    \ capacity, utilization (or used\n   capacity), and available capacity, for individual\
    \ links and complete\n   paths.  These three metrics form a triad: knowing one\
    \ metric\n   constrains the other two (within their allowed range), and knowing\n\
    \   two determines the third.  The link metrics have another key aspect\n   in\
    \ common: they are single-measurement-point metrics at the egress of\n   a link.\
    \  The path capacity and available capacity are derived by\n   examining the set\
    \ of single-point link measurements and taking the\n   minimum value.\n"
- title: 6.1.  Type-P Parameter
  contents:
  - "6.1.  Type-P Parameter\n   The concept of \"packets of Type-P\" is defined in\
    \ [RFC2330].  The\n   Type-P categorization has critical relevance in all forms\
    \ of capacity\n   measurement and reporting.  The ability to categorize packets\
    \ based\n   on header fields for assignment to different queues and scheduling\n\
    \   mechanisms is now commonplace.  When unused resources are shared\n   across\
    \ queues, the conditions in all packet categories will affect\n   capacity and\
    \ related measurements.  This is one source of variability\n   in the results\
    \ that all audiences would prefer to see reported in a\n   useful and easily understood\
    \ way.\n   Communication of Type-P within the One-Way Active Measurement\n   Protocol\
    \ (OWAMP) and the Two-Way Active Measurement Protocol (TWAMP)\n   is essentially\
    \ confined to the Diffserv Code Point (DSCP) [RFC4656].\n   DSCP is the most common\
    \ qualifier for Type-P.\n   Each audience will have a set of Type-P qualifications\
    \ and value\n   combinations that are of interest.  Measurements and reports should\n\
    \   have the flexibility to report per-type and aggregate performance.\n"
- title: 6.2.  A priori Factors
  contents:
  - "6.2.  A priori Factors\n   The audience for network characterization may have\
    \ detailed\n   information about each link that comprises a complete path (due\
    \ to\n   ownership, for example), or some of the links in the path but not\n \
    \  others, or none of the links.\n   There are cases where the measurement audience\
    \ only has information\n   on one of the links (the local access link) and wishes\
    \ to measure one\n   or more of the raw capacity metrics.  This scenario is quite\
    \ common\n   and has spawned a substantial number of experimental measurement\n\
    \   methods (e.g., http://www.caida.org/tools/taxonomy/).  Many of these\n   methods\
    \ respect that their users want a result fairly quickly and in\n   one trial.\
    \  Thus, the measurement interval is kept short (a few\n   seconds to a minute).\
    \  For long-term reporting, a sample of\n   short-term results needs to be summarized.\n"
- title: 6.3.  IP-Layer Capacity
  contents:
  - "6.3.  IP-Layer Capacity\n   For links, this metric's theoretical maximum value\
    \ can be determined\n   from the physical-layer bit rate and the bit rate reduction\
    \ due to\n   the layers between the physical layer and IP.  When measured, this\n\
    \   metric takes additional factors into account, such as the ability of\n   the\
    \ sending device to process and forward traffic under various\n   conditions.\
    \  For example, the arrival of routing updates may spawn\n   high-priority processes\
    \ that reduce the sending rate temporarily.\n   Thus, the measured capacity of\
    \ a link will be variable, and the\n   maximum capacity observed applies to a\
    \ specific time, time interval,\n   and other relevant circumstances.\n   For\
    \ paths composed of a series of links, it is easy to see how the\n   sources of\
    \ variability for the results grow with each link in the\n   path.  Variability\
    \ of results will be discussed in more detail below.\n"
- title: 6.4.  IP-Layer Utilization
  contents:
  - "6.4.  IP-Layer Utilization\n   The ideal metric definition of link utilization\
    \ [RFC5136] is based on\n   the actual usage (bits successfully received during\
    \ a time interval)\n   and the maximum capacity for the same interval.\n   In\
    \ practice, link utilization can be calculated by counting the\n   IP-layer (or\
    \ other layer) octets received over a time interval and\n   dividing by the theoretical\
    \ maximum number of octets that could have\n   been delivered in the same interval.\
    \  A commonly used time interval\n   is 5 minutes, and this interval has been\
    \ sufficient to support\n   network operations and design for some time.  5 minutes\
    \ is somewhat\n   long compared with the expected download time for web pages\
    \ but short\n   with respect to large file transfers and TV program viewing. \
    \ It is\n   fair to say that considerable variability is concealed by reporting\
    \ a\n   single (average) utilization value for each 5-minute interval.  Some\n\
    \   performance management systems have begun to make 1-minute averages\n   available.\n\
    \   There is also a limit on the smallest useful measurement interval.\n   Intervals\
    \ on the order of the serialization time for a single Maximum\n   Transmission\
    \ Unit (MTU) packet will observe on/off behavior and\n   report 100% or 0%.  The\
    \ smallest interval needs to be some multiple\n   of MTU serialization time for\
    \ averaging to be effective.\n"
- title: 6.5.  IP-Layer Available Capacity
  contents:
  - "6.5.  IP-Layer Available Capacity\n   The available capacity of a link can be\
    \ calculated using the capacity\n   and utilization metrics.\n   When available\
    \ capacity of a link or path is estimated through some\n   measurement technique,\
    \ the following parameters should be reported:\n   o  Name and reference to the\
    \ exact method of measurement\n   o  IP packet length, octets (including IP header)\n\
    \   o  Maximum capacity that can be assessed in the measurement\n      configuration\n\
    \   o  Time duration of the measurement\n   o  All other parameters specific to\
    \ the measurement method\n   Many methods of available capacity measurement have\
    \ a maximum\n   capacity that they can measure, and this maximum may be less than\
    \ the\n   actual available capacity of the link or path.  Therefore, it is\n \
    \  important to know the capacity value beyond which there will be no\n   measured\
    \ improvement.\n   The application performance estimation audience may have a\
    \ desired\n   target capacity value and simply wish to assess whether there is\n\
    \   sufficient available capacity.  This case simplifies the measurement\n   of\
    \ link and path capacity to some degree, as long as the measurable\n   maximum\
    \ exceeds the target capacity.\n"
- title: 6.6.  Variability in Utilization and Available Capacity
  contents:
  - "6.6.  Variability in Utilization and Available Capacity\n   As with most metrics\
    \ and measurements, assessing the consistency or\n   variability in the results\
    \ gives the user an intuitive feel for the\n   degree (or confidence) that any\
    \ one value is representative of other\n   results, or the spread of the underlying\
    \ distribution of the\n   singleton measurements.\n   How can utilization be measured\
    \ and summarized to describe the\n   potential variability in a useful way?\n\
    \   How can the variability in available capacity estimates be reported,\n   so\
    \ that the confidence in the results is also conveyed?\n   We suggest some methods\
    \ below.\n"
- title: 6.6.1.  General Summary of Variability
  contents:
  - "6.6.1.  General Summary of Variability\n   With a set of singleton utilization\
    \ or available capacity estimates,\n   each representing a time interval needed\
    \ to ascertain the estimate,\n   we seek to describe the variation over the set\
    \ of singletons as\n   though reporting summary statistics of a distribution.\
    \  Three useful\n   summary statistics are\n   o  Minimum,\n   o  Maximum, and\n\
    \   o  Range\n   An alternate way to represent the range is as a ratio of maximum\
    \ to\n   minimum value.  This enables an easily understandable statistic to\n\
    \   describe the range observed.  For example, when maximum = 3*minimum,\n   then\
    \ the max/min ratio is 3, and users may see variability of this\n   order.  On\
    \ the other hand, capacity estimates with a max/min ratio\n   near 1 are quite\
    \ consistent and near the central measure or statistic\n   reported.\n   For an\
    \ ongoing series of singleton estimates, a moving average of n\n   estimates may\
    \ provide a single value estimate to more easily\n   distinguish substantial changes\
    \ in performance over time.  For\n   example, in a window of n singletons observed\
    \ in time interval t, a\n   percentage change of x% is declared to be a substantial\
    \ change and\n   reported as an exception.\n   Often, the most informative summary\
    \ of the results is a two-axis plot\n   rather than a table of statistics, where\
    \ time is plotted on the\n   x-axis and the singleton value on the y-axis.  The\
    \ time-series plot\n   can illustrate sudden changes in an otherwise stable range,\
    \ identify\n   bi-modality easily, and help quickly assess correlation with other\n\
    \   time-series.  Plots of frequency of the singleton values are likewise\n  \
    \ useful tools to visualize the variation.\n"
- title: 7.  Reporting Restricted Capacity Metrics
  contents:
  - "7.  Reporting Restricted Capacity Metrics\n   Restricted capacity refers to the\
    \ metrics defined in [RFC3148], which\n   include criteria of data uniqueness\
    \ or flow-control response to\n   congestion.\n   One primary metric considered\
    \ is Bulk Transfer Capacity (BTC) for\n   complete paths.  [RFC3148] defines BTC\
    \ as\n      BTC = data_sent / elapsed_time\n   for a connection with congestion-aware\
    \ flow control, where data_sent\n   is the total number of unique payload bits\
    \ (no headers).\n   We note that this definition *differs* from the raw capacity\n\
    \   definition in Section 2.3.1 of [RFC5136], where IP-layer capacity\n   *includes*\
    \ all bits in the IP header and payload.  This means that\n   restricted capacity\
    \ BTC is already operating at a disadvantage when\n   compared to the raw capacity\
    \ at layers below TCP.  Further, there are\n   cases where one IP layer is encapsulated\
    \ in another IP layer or other\n   form of tunneling protocol, designating more\
    \ and more of the\n   fundamental transport capacity as header bits that are pure\
    \ overhead\n   to the BTC measurement.\n   We also note that raw and restricted\
    \ capacity metrics are not\n   orthogonal in the sense defined in Section 5.1.2\
    \ above.  The\n   information they convey about the network under test is certainly\n\
    \   overlapping, but they reveal two different and important aspects of\n   performance.\n\
    \   When thinking about the triad of raw capacity metrics, BTC is most\n   akin\
    \ to the \"IP-Type-P Available Path Capacity\", at least in the eyes\n   of a\
    \ network user who seeks to know what transmission performance a\n   path might\
    \ support.\n"
- title: 7.1.  Type-P Parameter and Type-C Parameter
  contents:
  - "7.1.  Type-P Parameter and Type-C Parameter\n   The concept of \"packets of Type-P\"\
    \ is defined in [RFC2330].  The\n   considerations for restricted capacity are\
    \ identical to the raw\n   capacity section on this topic, with the addition that\
    \ the various\n   fields and options in the TCP header must be included in the\n\
    \   description.\n   The vast array of TCP flow-control options are not well captured\
    \ by\n   Type-P, because they do not exist in the TCP header bits.  Therefore,\n\
    \   we introduce a new notion here: TCP Configuration of \"Type-C\".  The\n  \
    \ elements of Type-C describe all of the settings for TCP options and\n   congestion\
    \ control algorithm variables, including the main form of\n   congestion control\
    \ in use.  Readers should consider the parameters\n   and variables of [RFC3148]\
    \ and [RFC6349] when constructing Type-C.\n"
- title: 7.2.  A Priori Factors
  contents:
  - "7.2.  A Priori Factors\n   The audience for network characterization may have\
    \ detailed\n   information about each link that comprises a complete path (due\
    \ to\n   ownership, for example), or some of the links in the path but not\n \
    \  others, or none of the links.\n   There are cases where the measurement audience\
    \ only has information\n   on one of the links (the local access link) and wishes\
    \ to measure one\n   or more BTC metrics.  The discussion in Section 6.2 applies\
    \ here\n   as well.\n"
- title: 7.3.  Measurement Interval
  contents:
  - "7.3.  Measurement Interval\n   There are limits on a useful measurement interval\
    \ for BTC.  Three\n   factors that influence the interval duration are listed\
    \ below:\n   1.  Measurements may choose to include or exclude the 3-way handshake\n\
    \       of TCP connection establishment, which requires at least 1.5 *\n     \
    \  RTT (round-trip time) and contains both the delay of the path and\n       the\
    \ host processing time for responses.  However, user experience\n       includes\
    \ the 3-way handshake for all new TCP connections.\n   2.  Measurements may choose\
    \ to include or exclude Slow-Start,\n       preferring instead to focus on a portion\
    \ of the transfer that\n       represents \"equilibrium\" (which needs to be defined\
    \ for\n       particular circumstances if used).  However, user experience\n \
    \      includes the Slow-Start for all new TCP connections.\n   3.  Measurements\
    \ may choose to use a fixed block of data to transfer,\n       where the size\
    \ of the block has a relationship to the file size\n       of the application\
    \ of interest.  This approach yields variable\n       size measurement intervals,\
    \ where a path with faster BTC is\n       measured for less time than a path with\
    \ slower BTC, and this has\n       implications when path impairments are time-varying,\
    \ or\n       transient.  Users are likely to turn their immediate attention\n\
    \       elsewhere when a very large file must be transferred; thus, they\n   \
    \    do not directly experience such a long transfer -- they see the\n       result\
    \ (success or failure) and possibly an objective measurement\n       of the transfer\
    \ time (which will likely include the 3-way\n       handshake, Slow-Start, and\
    \ application file management processing\n       time as well as the BTC).\n \
    \  Individual measurement intervals may be short or long, but there is a\n   need\
    \ to report the results on a long-term basis that captures the BTC\n   variability\
    \ experienced between each interval.  Consistent BTC is a\n   valuable commodity\
    \ along with the value attained.\n"
- title: 7.4.  Bulk Transfer Capacity Reporting
  contents:
  - "7.4.  Bulk Transfer Capacity Reporting\n   When BTC of a link or path is estimated\
    \ through some measurement\n   technique, the following parameters should be reported:\n\
    \   o  Name and reference to the exact method of measurement\n   o  Maximum Transmission\
    \ Unit (MTU)\n   o  Maximum BTC that can be assessed in the measurement configuration\n\
    \   o  Time and duration of the measurement\n   o  Number of BTC connections used\
    \ simultaneously\n   o  *All* other parameters specific to the measurement method,\n\
    \      especially the congestion control algorithm in use\n   See also [RFC6349].\n\
    \   Many methods of BTC measurement have a maximum capacity that they can\n  \
    \ measure, and this maximum may be less than the available capacity of\n   the\
    \ link or path.  Therefore, it is important to specify the measured\n   BTC value\
    \ beyond which there will be no measured improvement.\n   The application performance\
    \ estimation audience may have a desired\n   target capacity value and simply\
    \ wish to assess whether there is\n   sufficient BTC.  This case simplifies the\
    \ measurement of link and\n   path capacity to some degree, as long as the measurable\
    \ maximum\n   exceeds the target capacity.\n"
- title: 7.5.  Variability in Bulk Transfer Capacity
  contents:
  - "7.5.  Variability in Bulk Transfer Capacity\n   As with most metrics and measurements,\
    \ assessing the consistency or\n   variability in the results gives the user an\
    \ intuitive feel for the\n   degree (or confidence) that any one value is representative\
    \ of other\n   results, or the underlying distribution from which these singleton\n\
    \   measurements have come.\n   With two questions looming --\n   1.  What ways\
    \ can BTC be measured and summarized to describe the\n       potential variability\
    \ in a useful way?\n   2.  How can the variability in BTC estimates be reported,\
    \ so that the\n       confidence in the results is also conveyed?\n   -- we suggest\
    \ the methods listed in Section 6.6.1 above, and the\n   additional results presentations\
    \ given in [RFC6349].\n"
- title: 8.  Reporting on Test Streams and Sample Size
  contents:
  - "8.  Reporting on Test Streams and Sample Size\n   This section discusses two\
    \ key aspects of measurement that are\n   sometimes omitted from the report: the\
    \ description of the test stream\n   on which the measurements are based, and\
    \ the sample size.\n"
- title: 8.1.  Test Stream Characteristics
  contents:
  - "8.1.  Test Stream Characteristics\n   Network characterization has traditionally\
    \ used Poisson-distributed\n   inter-packet spacing, as this provides an unbiased\
    \ sample.  The\n   average inter-packet spacing may be selected to allow observation\
    \ of\n   specific network phenomena.  Other test streams are designed to\n   sample\
    \ some property of the network, such as the presence of\n   congestion, link bandwidth,\
    \ or packet reordering.\n   If measuring a network in order to make inferences\
    \ about applications\n   or receiver performance, then there are usually efficiencies\
    \ derived\n   from a test stream that has similar characteristics to the sender.\n\
    \   In some cases, it is essential to synthesize the sender stream, as\n   with\
    \ BTC estimates.  In other cases, it may be sufficient to sample\n   with a \"\
    known bias\", e.g., a Periodic stream to estimate real-time\n   application performance.\n"
- title: 8.2.  Sample Size
  contents:
  - "8.2.  Sample Size\n   Sample size is directly related to the accuracy of the\
    \ results and\n   plays a critical role in the report.  Even if only the sample\
    \ size\n   (in terms of number of packets) is given for each value or summary\n\
    \   statistic, it imparts a notion of the confidence in the result.\n   In practice,\
    \ the sample size will be selected taking both statistical\n   and practical factors\
    \ into account.  Among these factors are the\n   following:\n   1.  The estimated\
    \ variability of the quantity being measured.\n   2.  The desired confidence in\
    \ the result (although this may be\n       dependent on assumption of the underlying\
    \ distribution of the\n       measured quantity).\n   3.  The effects of active\
    \ measurement traffic on user traffic.\n   A sample size may sometimes be referred\
    \ to as \"large\".  This is a\n   relative and qualitative term.  It is preferable\
    \ to describe what one\n   is attempting to achieve with his sample.  For example,\
    \ stating an\n   implication may be helpful: this sample is large enough that\
    \ a single\n   outlying value at ten times the \"typical\" sample mean (the mean\n\
    \   without the outlying value) would influence the mean by no more\n   than X.\n\
    \   The Appendix of [RFC2330] indicates that a sample size of 128\n   singletons\
    \ worked well for goodness-of-fit testing, while a much\n   larger size (8192\
    \ singletons) almost always failed.\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   The security considerations that apply to any\
    \ active measurement of\n   live networks are relevant here as well.  See the\
    \ Security\n   Considerations section of [RFC4656] for mandatory-to-implement\n\
    \   security features that intend to mitigate attacks.\n   Measurement systems\
    \ conducting long-term measurements are more\n   exposed to threats as a by-product\
    \ of ports open longer to perform\n   their task, and more easily detected measurement\
    \ activity on those\n   ports.  Further, use of long packet waiting times affords\
    \ an attacker\n   a better opportunity to prepare and launch a replay attack.\n"
- title: 10.  Acknowledgements
  contents:
  - "10.  Acknowledgements\n   The authors thank Phil Chimento for his suggestion\
    \ to employ\n   conditional distributions for delay, Steve Konish Jr. for his\
    \ careful\n   review and suggestions, Dave McDysan and Don McLachlan for useful\n\
    \   comments based on their long experience with measurement and\n   reporting,\
    \ Daniel Genin for his observation of non-orthogonality\n   between raw and restricted\
    \ capacity metrics (and for noticing our\n   previous omission of this fact),\
    \ and Matt Zekauskas for suggestions\n   on organizing the memo for easier consumption.\n"
- title: 11.  References
  contents:
  - '11.  References

    '
- title: 11.1.  Normative References
  contents:
  - "11.1.  Normative References\n   [RFC2330]   Paxson, V., Almes, G., Mahdavi, J.,\
    \ and M. Mathis,\n               \"Framework for IP Performance Metrics\", RFC\
    \ 2330,\n               May 1998.\n   [RFC2678]   Mahdavi, J. and V. Paxson, \"\
    IPPM Metrics for Measuring\n               Connectivity\", RFC 2678, September\
    \ 1999.\n   [RFC2679]   Almes, G., Kalidindi, S., and M. Zekauskas, \"A One-way\n\
    \               Delay Metric for IPPM\", RFC 2679, September 1999.\n   [RFC2680]\
    \   Almes, G., Kalidindi, S., and M. Zekauskas, \"A One-way\n               Packet\
    \ Loss Metric for IPPM\", RFC 2680, September 1999.\n   [RFC3148]   Mathis, M.\
    \ and M. Allman, \"A Framework for Defining\n               Empirical Bulk Transfer\
    \ Capacity Metrics\", RFC 3148,\n               July 2001.\n   [RFC3393]   Demichelis,\
    \ C. and P. Chimento, \"IP Packet Delay\n               Variation Metric for IP\
    \ Performance Metrics (IPPM)\",\n               RFC 3393, November 2002.\n   [RFC3432]\
    \   Raisanen, V., Grotefeld, G., and A. Morton, \"Network\n               performance\
    \ measurement with periodic streams\", RFC 3432,\n               November 2002.\n\
    \   [RFC4656]   Shalunov, S., Teitelbaum, B., Karp, A., Boote, J., and M.\n  \
    \             Zekauskas, \"A One-way Active Measurement Protocol\n           \
    \    (OWAMP)\", RFC 4656, September 2006.\n   [RFC4737]   Morton, A., Ciavattone,\
    \ L., Ramachandran, G., Shalunov,\n               S., and J. Perser, \"Packet\
    \ Reordering Metrics\", RFC 4737,\n               November 2006.\n   [RFC5136]\
    \   Chimento, P. and J. Ishac, \"Defining Network Capacity\",\n              \
    \ RFC 5136, February 2008.\n"
- title: 11.2.  Informative References
  contents:
  - "11.2.  Informative References\n   [Casner]    Casner, S., Alaettinoglu, C., and\
    \ C. Kuan, \"A Fine-\n               Grained View of High-Performance Networking\"\
    ,\n               NANOG 22 Conf., May 20-22 2001,\n               <http://www.nanog.org/presentations/archive/index.php>.\n\
    \   [Cia03]     Ciavattone, L., Morton, A., and G. Ramachandran,\n           \
    \    \"Standardized Active Measurements on a Tier 1 IP\n               Backbone\"\
    , IEEE Communications Magazine, Vol. 41\n               No. 6, pp. 90-97, June\
    \ 2003.\n   [IPPM-RPT]  Shalunov, S. and M. Swany, \"Reporting IP Performance\n\
    \               Metrics to Users\", Work in Progress, March 2011.\n   [RFC5481]\
    \   Morton, A. and B. Claise, \"Packet Delay Variation\n               Applicability\
    \ Statement\", RFC 5481, March 2009.\n   [RFC5835]   Morton, A., Ed., and S. Van\
    \ den Berghe, Ed., \"Framework\n               for Metric Composition\", RFC 5835,\
    \ April 2010.\n   [RFC6349]   Constantine, B., Forget, G., Geib, R., and R. Schrage,\n\
    \               \"Framework for TCP Throughput Testing\", RFC 6349,\n        \
    \       August 2011.\n   [Y.1540]    International Telecommunication Union, \"\
    Internet protocol\n               data communication service - IP packet transfer\
    \ and\n               availability performance parameters\", ITU-T\n         \
    \      Recommendation Y.1540, March 2011.\n   [Y.1541]    International Telecommunication\
    \ Union, \"Network\n               performance objectives for IP-based services\"\
    , ITU-T\n               Recommendation Y.1541, December 2011.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Al Morton\n   AT&T Labs\n   200 Laurel Avenue South\n\
    \   Middletown, NJ  07748\n   USA\n   Phone: +1 732 420 1571\n   Fax:   +1 732\
    \ 368 1192\n   EMail: acmorton@att.com\n   URI:   http://home.comcast.net/~acmacm/\n\
    \   Gomathi Ramachandran\n   AT&T Labs\n   200 Laurel Avenue South\n   Middletown,\
    \ New Jersey  07748\n   USA\n   Phone: +1 732 420 2353\n   EMail: gomathi@att.com\n\
    \   Ganga Maguluri\n   AT&T Labs\n   200 Laurel Avenue South\n   Middletown, New\
    \ Jersey  07748\n   USA\n   Phone: +1 732 420 2486\n   EMail: gmaguluri@att.com\n"
