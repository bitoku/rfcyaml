- title: __initial_text__
  contents:
  - '                On Packet Switches With Infinite Storage

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   The purpose of this RFC is to focus discussion on particular\
    \ problems\n   in the ARPA-Internet and possible methods of solution.  No proposed\n\
    \   solutions in this document are intended as standards for the\n   ARPA-Internet\
    \ at this time.  Rather, it is hoped that a general\n   consensus will emerge\
    \ as to the appropriate solution to such\n   problems, leading eventually to the\
    \ adoption of standards.\n   Distribution of this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   Most prior work on congestion in datagram systems focuses on buffer\n\
    \   management.  We find it illuminating to consider the case of a packet\n  \
    \ switch with infinite storage.  Such a packet switch can never run out\n   of\
    \ buffers. It can, however, still become congested.  The meaning of\n   congestion\
    \ in an infinite-storage system is explored.  We demonstrate\n   the unexpected\
    \ result that a datagram network with infinite storage,\n   first-in-first-out\
    \ queuing, at least two packet switches, and a\n   finite packet lifetime will,\
    \ under overload, drop all packets.  By\n   attacking the problem of congestion\
    \ for the infinite-storage case, we\n   discover new solutions applicable to switches\
    \ with finite storage.\n"
- title: Introduction
  contents:
  - "Introduction\n   Packet switching was first introduced in an era when computer\
    \ data\n   storage was several orders of magnitude more expensive than it is\n\
    \   today.  Strenuous efforts were made in the early days to build packet\n  \
    \ switches with the absolute minimum of storage required for operation.\n   The\
    \ problem of congestion control was generally considered to be one\n   of avoiding\
    \ buffer exhaustion in the packet switches.  We take a\n   different view here.\
    \  We choose to begin our analysis by assuming the\n   availablity of infinite\
    \ memory. This forces us to look at congestion\n   from a fresh perspective. \
    \ We no longer worry about when to block or\n   which packets to discard; instead,\
    \ we must think about how we want\n   the system to perform.\n   Pure datagram\
    \ systems are especially prone to congestion problems.\n   The blocking mechanisms\
    \ provided by virtual circuit systems are\n   absent.  No fully effective solutions\
    \ to congestion in pure datagram\n   systems are known.  Most existing datagram\
    \ systems behave badly under\n   overload.  We will show that substantial progress\
    \ can be made on the\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   congestion control problem even\
    \ for pure datagram systems when the\n   problem is defined as determining the\
    \ order of packet transmission,\n   rather than the allocation of buffer space.\n"
- title: A Packet Switch with Infinite Storage
  contents:
  - "A Packet Switch with Infinite Storage\n   Let us begin by describing a simple\
    \ packet switch with infinite\n   storage.  A switch has incoming and outgoing\
    \ links.  Each link has a\n   fixed data transfer rate.  Not all links need have\
    \ the same data\n   rate. Packets arrive on incoming links and are immediately\
    \ assigned\n   an outgoing link by some routing mechanism not examined here. \
    \ Each\n   outgoing link has a queue.  Packets are removed from that queue and\n\
    \   sent on its outgoing link at the data rate for that link.  Initially,\n  \
    \ we will assume that queues are managed in a first in, first out\n   manner.\n\
    \   We assume that packets have a finite lifetime.  In the DoD IP\n   protocol,\
    \ packets have a time-to-live field, which is the number of\n   seconds remaining\
    \ until the packet must be discarded as\n   uninteresting. As the packet travels\
    \ through the network, this field\n   is decremented; if it becomes zero, the\
    \ packet must be discarded.\n   The initial value for this field is fixed; in\
    \ the DoD IP protocol,\n   this value is by default 15.\n   The time-to-live mechanism\
    \ prevents queues from growing without\n   bound; when the queues become sufficiently\
    \ long, packets will time\n   out before being sent.  This places an upper bound\
    \ on the total size\n   of all queues; this bound is determined by the total data\
    \ rate for\n   all incoming links and the upper limit on the time-to-live.\n \
    \  However, this does not eliminate congestion.  Let us see why.\n   Consider\
    \ a simple node, with one incoming link and one outgoing link.\n   Assume that\
    \ the packet arrival rate at a node exceeds the departure\n   rate.  The queue\
    \ length for the outgoing link will then grow until\n   the transit time through\
    \ the queue exceeds the time-to-live of the\n   incoming packets.  At this point,\
    \ as the process serving the outgoing\n   link removes packets from the queue,\
    \ it will sometimes find a packet\n   whose time-to-live field has been decremented\
    \ to zero.  In such a\n   case, it will discard that packet and will try again\
    \ with the next\n   packet on the queue.  Packets with nonzero time-to-live fields\
    \ will\n   be transmitted on the outgoing link.\n   The packets that do get transmitted\
    \ have nonzero time-to- live\n   values. But once the steady state under overload\
    \ has been reached,\n   these values will be small, since the packet will have\
    \ been on the\n   queue for slightly less than the maximum time-to-live.  In fact,\
    \ if\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   the departure rate is greater than\
    \ one per time-to-live unit, the\n   time-to-live of any forwarded packet will\
    \ be exactly one.  This\n   follows from the observation that if more than one\
    \ packet is sent per\n   time-to-live unit, consecutive packets on the queue will\
    \ have\n   time-to-live values that differ by no more than 1.  Thus, as the\n\
    \   component of the packet switch that removes packets from the queue\n   and\
    \ either sends them or discards them as expired operates, it will\n   either find\
    \ packets with negative or zero time to live values (which\n   it will discard)\
    \ or packets with values of 1, which it will send.\n   So, clearly enough, at\
    \ the next node of the packet switching system,\n   the arriving packets will\
    \ all have time-to-live values of 1.  Since\n   we always decrement the time-to-live\
    \ value by at least 1 in each\n   node, to guarantee that the time-to-live value\
    \ decreases as the\n   packet travels through the network, we will in this case\
    \ decrement it\n   to zero for each incoming packet and will then discard that\
    \ packet.\n   We have thus shown that a datagram network with infinite storage,\n\
    \   first-in-first-out queuing, and a finite packet lifetime will, under\n   overload,\
    \ drop all packets.  This is a rather unexpected result.  But\n   it is quite\
    \ real.  It is not an artifact of the infinite-buffer\n   assumption.  The problem\
    \ still occurs in networks with finite\n   storage, but the effects are less clearly\
    \ seen.  Datagram networks\n   are known to behave badly under overload, but analysis\
    \ of this\n   behavior has been lacking.  In the infinite-buffer case, the analysis\n\
    \   is quite simple, as we have shown, and we obtain considerable insight\n  \
    \ into the problem.\n   One would expect this phenomenon to have been discovered\
    \ previously.\n   But previous work on congestion control in packet switching\
    \ systems\n   almost invariably focuses on buffer management.  Analysis of the\n\
    \   infinite buffer case is apparently unique with this writer.\n   This result\
    \ is directly applicable to networks with finite resources.\n   The storage required\
    \ to implement a switch that can never run out of\n   buffers turns out to be\
    \ quite reasonable.  Let us consider a pure\n   datagram switch for an ARPANET-like\
    \ network.  For the case of a\n   packet switch with four 56Kb links, and an upper\
    \ bound on the\n   time-to-live of 15 seconds, the maximum buffer space that could\
    \ ever\n   be required is 420K bytes <1>.  A switch provided with this rather\n\
    \   modest amount of memory need never drop a packet due to buffer\n   exhaustion.\n\
    \   This problem is not just theoretical.  We have demonstrated it\n   experimentally\
    \ on our own network, using a supermini with several\n   megabytes of memory as\
    \ a switch.  We now have experimental evidence\n   that the phenomenon described\
    \ above occurs in practice.  Our first\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   experiment, using an Ethernet on\
    \ one side of the switch and a 9600\n   baud line on the other, resulted in 916\
    \ IP datagrams queued in the\n   switch at peak.  However, we were applying the\
    \ load over a TCP\n   transport connection, and the transport connection timed\
    \ out due to\n   excessive round trip time before the queue reached the time to\
    \ live\n   limit, so we did not actually reach the stable state with the queue\n\
    \   at the maximum length as predicted by our analysis above.  It is\n   interesting\
    \ that we can force this condition from the position of a\n   user application\
    \ atop the transport layer (TCP), and this deserves\n   further analysis.\n"
- title: Interaction with Transport Protocols
  contents:
  - "Interaction with Transport Protocols\n   We have thus far assumed packet sources\
    \ that emit packets at a fixed\n   rate.  This is a valid model for certain sources\
    \ such as packet voice\n   systems.  Systems that use transport protocols of the\
    \ ISO TP4 or DoD\n   TCP class, however, ought to be better behaved.  The key\
    \ point is\n   that transport protocols used in datagram systems should behave\
    \ in\n   such a way as to not overload the network, even where the network has\n\
    \   no means of keeping them from doing so.  This is quite possible.  In\n   a\
    \ previous paper by this writer [1], the behavior of the TCP\n   transport protocol\
    \ over a congested network is explored.  We have\n   shown that a badly behaved\
    \ transport protocol implementation can\n   cause serious harm to a datagram network,\
    \ and discussed how such an\n   implementation ought to behave.  In that paper\
    \ we offered some\n   specific guidance on how to implement a well-behaved TCP,\
    \ and\n   demonstrated that proper behavior could in some cases reduce network\n\
    \   load by an order of magnitude.  In summary, the conclusions of that\n   paper\
    \ are that a transport protocol, to be well behaved, should not\n   have a retransmit\
    \ time shorter than the current round trip time\n   between the hosts involved,\
    \ and that when informed by the network of\n   congestion, the transport protocol\
    \ should take steps to reduce the\n   number of packets outstanding on the connection.\n\
    \   We reference our earlier work here to show that the network load\n   imposed\
    \ by a transport protocol is not necessarily fixed by the\n   protocol specification.\
    \  Some existing implementations of transport\n   protocols are well-behaved.\
    \  Others are not. We have observed a wide\n   variability among existing TCP\
    \ implementations.  We have reason to\n   suspect that ISO TP4 implementations\
    \ will be more uniform, given the\n   greater rigidity of the specification, but\
    \ we see enough open space\n   in the TP4 standard to allow for considerable variability.\
    \  We\n   suspect that there will be marginal TP4 implementations, from a\n  \
    \ network viewpoint, just as there are marginal TCP implementations\n   today.\
    \ These implementations will typically work quite well until\n   asked to operate\
    \ over a heavily loaded network with significant\n   delays.  Then we find out\
    \ which ones are well-behaved.\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   Even if all hosts are moderately\
    \ well-behaved, there is potential for\n   trouble.  Each host can normally obtain\
    \ more network bandwidth by\n   transmitting more packets per unit time, since\
    \ the first in, first\n   out strategy gives the most resources to the sender\
    \ of the most\n   packets. But collectively, as the hosts overload the network,\
    \ total\n   throughput drops.  As shown above, throughput may drop to zero.\n\
    \   Thus, the optimal strategy for each host is strongly suboptimal for\n   the\
    \ network as a whole.\n"
- title: Game Theoretic Aspects of Network Congestion
  contents:
  - "Game Theoretic Aspects of Network Congestion\n   This game-theory view of datagram\
    \ networks leads us to a digression\n   on the stability of multi-player games.\
    \  Systems in which the optimal\n   strategy for each player is suboptimal for\
    \ all players are known to\n   tend towards the suboptimal state.  The well-known\
    \ prisoner's dilemma\n   problem in game theory is an example of a system with\
    \ this property.\n   But a closer analogue is the tragedy of the commons problem\
    \ in\n   economics.  Where each individual can improve their own position by\n\
    \   using more of a free resource, but the total amount of the resource\n   degrades\
    \ as the number of users increases, self-interest leads to\n   overload of the\
    \ resource and collapse.  Historically this analysis\n   was applied to the use\
    \ of common grazing lands; it also applies to\n   such diverse resources as air\
    \ quality and time-sharing systems.  In\n   general, experience indicates that\
    \ many-player systems with this type\n   of instability tend to get into serious\
    \ trouble.\n   Solutions to the tragedy of the commons problem fall into three\n\
    \   classes: cooperative, authoritarian, and market solutions.\n   Cooperative\
    \ solutions, where everyone agrees to be well-behaved, are\n   adequate for small\
    \ numbers of players, but tend to break down as the\n   number of players increases.\
    \  Authoritarian solutions are effective\n   when behavior can be easily monitored,\
    \ but tend to fail if the\n   definition of good behavior is subtle.  A market\
    \ solution is possible\n   only if the rules of the game can be changed so that\
    \ the optimal\n   strategy for players results in a situation that is optimal\
    \ for all.\n   Where this is possible, market solutions can be quite effective.\n\
    \   The above analysis is generally valid for human players.  In the\n   network\
    \ case, we have the interesting situation that the player is a\n   computer executing\
    \ a preprogrammed strategy.  But this alone does not\n   insure good behavior;\
    \ the strategy in the computer may be programmed\n   to optimize performance for\
    \ that computer, regardless of network\n   considerations.  A similar situation\
    \ exists with automatic redialing\n   devices in telephony, where the user's equipment\
    \ attempts to improve\n   performance over an overloaded network by rapidly redialing\
    \ failed\n   calls.  Since call-setup facilities are scarce resources in telephone\n\
    \   systems, this can seriously impact the network; there are countries\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   that have been forced to prohibit\
    \ such devices.  (Brazil, for one).\n   This solution by administrative fiat is\
    \ sometimes effective and\n   sometimes not, depending on the relative power of\
    \ the administrative\n   authority and the users.\n   As transport protocols become\
    \ more commercialized and competing\n   systems are available, we should expect\
    \ to see attempts to tune the\n   protocols in ways that may be optimal from the\
    \ point of view of a\n   single host but suboptimal from the point of view of\
    \ the entire\n   network.  We already see signs of this in the transport protocol\n\
    \   implementation of one popular workstation manufacturer.\n   So, to return\
    \ to our analysis of a pure datagram internetwork, an\n   authoritarian solution\
    \ would order all hosts to be \"well-behaved\" by\n   fiat; this might be difficult\
    \ since the definition of a well-behaved\n   host in terms of its externally observed\
    \ behavior is subtle.  A\n   cooperative solution faces the same problem, along\
    \ with the difficult\n   additional problem of applying the requisite social pressures\
    \ in a\n   distributed system.  A market solution requires that we make it pay\n\
    \   to be well-behaved.  To do this, we will have to change the rules of\n   the\
    \ game.\n"
- title: Fairness in Packet Switching Systems
  contents:
  - "Fairness in Packet Switching Systems\n   We would like to protect the network\
    \ from hosts that are not\n   well-behaved.  More specifically, we would like,\
    \ in the presence of\n   both well-behaved and badly-behaved hosts, to insure\
    \ that\n   well-behaved hosts receive better service than badly-behaved hosts.\n\
    \   We have devised a means of achieving this.\n   Let us consider a network that\
    \ consists of high-bandwidth\n   pure-datagram local area networks without flow\
    \ control (Ethernet and\n   most IEEE 802.x datagram systems are of this class,\
    \ whether based on\n   carrier sensing or token passing), hosts connected to these\
    \ local\n   area networks, and an interconnected wide area network composed of\n\
    \   packet switches and long-haul links.  The wide area network may have\n   internal\
    \ flow control, but has no way of imposing mandatory flow\n   control on the source\
    \ hosts.  The DoD Internet, Xerox Network Systems\n   internetworks, and the networks\
    \ derived from them fit this model.\n   If any host on a local area network generates\
    \ packets routed to the\n   wide area network at a rate greater than the wide\
    \ area network can\n   absorb them, congestion will result in the packet switch\
    \ connecting\n   the local and wide area networks.  If the packet switches queue\
    \ on a\n   strictly first in, first out basis, the badly behaved host will\n \
    \  interfere with the transmission of data by other, better-behaved\n   hosts.\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   We introduce the concept of fairness.\
    \  We would like to make our\n   packet switches fair; in other words, each source\
    \ host should be able\n   to obtain an equal fraction of the resources of each\
    \ packet switch.\n   We can do this by replacing the single first in, first out\
    \ queue\n   associated with each outgoing link with multiple queues, one for each\n\
    \   source host in the entire network. We service these queues in a\n   round-\
    \ robin fashion, taking one packet from each non-empty queue in\n   turn and transmitting\
    \ the packets with positive time to live values\n   on the associated outgoing\
    \ link, while dropping the expired packets.\n   Empty queues are skipped over\
    \ and lose their turn.\n   This mechanism is fair; outgoing link bandwidth is\
    \ parcelled out\n   equally amongst source hosts.  Each source host with packets\
    \ queued\n   in the switch for the specified outgoing link gets exactly one packet\n\
    \   sent on the outgoing link each time the round robin algorithm cycles.\n  \
    \ So we have implemented a form of load-balancing.\n   We have also improved the\
    \ system from a game theory point of view.\n   The optimal strategy for a given\
    \ host is no longer to send as many\n   packets as possible.  The optimal strategy\
    \ is now to send packets at\n   a rate that keeps exactly one packet waiting to\
    \ be sent in each\n   packet switch, since in this way the host will be serviced\
    \ each time\n   the round-robin algorithm cycles, and the host's packets will\n\
    \   experience the minimum transit delay.  This strategy is quite\n   acceptable\
    \ from the network's point of view, since the length of each\n   queue will in\
    \ general be between 1 and 2.\n   The hosts need advisory information from the\
    \ network to optimize\n   their strategies.  The existing Source Quench mechanism\
    \ in DoD IP,\n   while minimal, is sufficient to provide this.  The packet switches\n\
    \   should send a Source Quench message to a source host whenever the\n   number\
    \ of packets in the queue for that source host exceeds some\n   small value, probably\
    \ 2.  If the hosts act to keep their traffic just\n   below the point at which\
    \ Source Quench messages are received, the\n   network should run with mean queue\
    \ lengths below 2 for each host.\n   Badly-behaved hosts can send all the datagrams\
    \ they want, but will\n   not thereby increase their share of the network resources.\
    \  All that\n   will happen is that packets from such hosts will experience long\n\
    \   transit times through the network.  A sufficiently badly-behaved host\n  \
    \ can send enough datagrams to push its own transit times up to the\n   time to\
    \ live limit, in which case none of its datagrams will get\n   through.  This\
    \ effect will happen sooner with fair queuing than with\n   first in, first out\
    \ queuing, because the badly- behaved host will\n   only obtain a share of the\
    \ bandwidth inversely proportional to the\n   number of hosts using the packet\
    \ switch at the moment.  This is much\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - "On Packet Switches With Infinite Storage\n   less than the share it would have\
    \ under the old system, where more\n   verbose hosts obtained more bandwidth.\
    \  This provides a strong\n   incentive for badly-behaved hosts to improve their\
    \ behavior.\n   It is worth noting that malicious, as opposed to merely\n   badly-behaved,\
    \ hosts, can overload the network by using many\n   different source addresses\
    \ in their datagrams, thereby impersonating\n   a large number of different hosts\
    \ and obtaining a larger share of the\n   network bandwidth. This is an attack\
    \ on the network; it is not likely\n   to happen by accident. It is thus a network\
    \ security problem, and\n   will not be discussed further here.\n   Although we\
    \ have made the packet switches fair, we have not thereby\n   made the network\
    \ as a whole fair.  This is a weakness of our\n   approach. The strategy outlined\
    \ here is most applicable to a packet\n   switch at a choke point in a network,\
    \ such as an entry node of a wide\n   area network or an internetwork gateway.\
    \  As a strategy applicable to\n   an intermediate node of a large packet switching\
    \ network, where the\n   packets from many hosts at different locations pass through\
    \ the\n   switch, it is less applicable.  The writer does not claim that the\n\
    \   approach described here is a complete solution to the problem of\n   congestion\
    \ in datagram networks.  However, it presents a solution to\n   a serious problem\
    \ and a direction for future work on the general\n   case.\n"
- title: Implementation
  contents:
  - "Implementation\n   The problem of maintaining a separate queue for each source\
    \ host for\n   each outgoing link in each packet switch seems at first to add\n\
    \   considerably to the complexity of the queuing mechanism in the packet\n  \
    \ switches.  There is some complexity involved, but the manipulations\n   are\
    \ simpler than those required with, say, balanced binary trees.\n   One simple\
    \ implementation involves providing space for pointers as\n   part of the header\
    \ of each datagram buffer.  The queue for each\n   source host need only be singly\
    \ linked, and the queue heads (which\n   are the first buffer of each queue) need\
    \ to be doubly linked so that\n   we can delete an entire queue when it is empty.\
    \  Thus, we need three\n   pointers in each buffer.  More elaborate strategies\
    \ can be devised to\n   speed up the process when the queues are long.  But the\
    \ additional\n   complexity is probably not justified in practice.\n   Given a\
    \ finite buffer supply, we may someday be faced with buffer\n   exhaustion.  In\
    \ such a case, we should drop the packet at the end of\n   the longest queue,\
    \ since it is the one that would be transmitted\n   last. This, of course, is\
    \ unfavorable to the host with the most\n   datagrams in the network, which is\
    \ in keeping with our goal of\n   fairness.\n"
- title: RFC 970                                                    December 1985
  contents:
  - 'RFC 970                                                    December 1985

    '
- title: On Packet Switches With Infinite Storage
  contents:
  - 'On Packet Switches With Infinite Storage

    '
- title: Conclusion
  contents:
  - "Conclusion\n   By breaking away from packet switching's historical fixation on\n\
    \   buffer management, we have achieved some new insights into congestion\n  \
    \ control in datagram systems and developed solutions for some known\n   problems\
    \ in real systems. We hope that others, given this new\n   insight, will go on\
    \ to make some real progress on the general\n   datagram congestion problem.\n"
- title: References
  contents:
  - "References\n   [1]  Nagle, J. \"Congestion Control in IP/TCP Internetworks\"\
    , ACM\n        Computer Communications Review, October 1984.\n"
- title: Editor's Notes
  contents:
  - "Editor's Notes\n   <1>  The buffer space required for just one 10Mb Ethernet\
    \ with an\n        upper bound on the time-to-live of 255 is 318 million bytes.\n"
