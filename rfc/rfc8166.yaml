- title: __initial_text__
  contents:
  - "               Remote Direct Memory Access Transport for\n                  \
    \  Remote Procedure Call Version 1\n"
- title: Abstract
  contents:
  - "Abstract\n   This document specifies a protocol for conveying Remote Procedure\n\
    \   Call (RPC) messages on physical transports capable of Remote Direct\n   Memory\
    \ Access (RDMA).  This protocol is referred to as the RPC-over-\n   RDMA version\
    \ 1 protocol in this document.  It requires no revision to\n   application RPC\
    \ protocols or the RPC protocol itself.  This document\n   obsoletes RFC 5666.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This is an Internet Standards Track document.\n   This\
    \ document is a product of the Internet Engineering Task Force\n   (IETF).  It\
    \ represents the consensus of the IETF community.  It has\n   received public\
    \ review and has been approved for publication by the\n   Internet Engineering\
    \ Steering Group (IESG).  Further information on\n   Internet Standards is available\
    \ in Section 2 of RFC 7841.\n   Information about the current status of this document,\
    \ any errata,\n   and how to provide feedback on it may be obtained at\n   http://www.rfc-editor.org/info/rfc8166.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2017 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n   This document\
    \ may contain material from IETF Documents or IETF\n   Contributions published\
    \ or made publicly available before November\n   10, 2008.  The person(s) controlling\
    \ the copyright in some of this\n   material may not have granted the IETF Trust\
    \ the right to allow\n   modifications of such material outside the IETF Standards\
    \ Process.\n   Without obtaining an adequate license from the person(s) controlling\n\
    \   the copyright in such materials, this document may not be modified\n   outside\
    \ the IETF Standards Process, and derivative works of it may\n   not be created\
    \ outside the IETF Standards Process, except to format\n   it for publication\
    \ as an RFC or to translate it into languages other\n   than English.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction  . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   4\n     1.1.  RPCs on RDMA Transports . . . . . . . . . . . . .\
    \ . . . .   4\n   2.  Terminology . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .   5\n     2.1.  Requirements Language . . . . . . . . . . . . . . . .\
    \ . .   5\n     2.2.  RPCs  . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ .   5\n     2.3.  RDMA  . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \   8\n   3.  RPC-over-RDMA Protocol Framework  . . . . . . . . . . . . . .  10\n\
    \     3.1.  Transfer Models . . . . . . . . . . . . . . . . . . . . .  10\n  \
    \   3.2.  Message Framing . . . . . . . . . . . . . . . . . . . . .  11\n    \
    \ 3.3.  Managing Receiver Resources . . . . . . . . . . . . . . .  11\n     3.4.\
    \  XDR Encoding with Chunks  . . . . . . . . . . . . . . . .  14\n     3.5.  Message\
    \ Size  . . . . . . . . . . . . . . . . . . . . . .  19\n   4.  RPC-over-RDMA\
    \ in Operation  . . . . . . . . . . . . . . . . .  23\n     4.1.  XDR Protocol\
    \ Definition . . . . . . . . . . . . . . . . .  23\n     4.2.  Fixed Header Fields\
    \ . . . . . . . . . . . . . . . . . . .  28\n     4.3.  Chunk Lists . . . . .\
    \ . . . . . . . . . . . . . . . . . .  30\n     4.4.  Memory Registration . .\
    \ . . . . . . . . . . . . . . . . .  33\n     4.5.  Error Handling  . . . . .\
    \ . . . . . . . . . . . . . . . .  34\n     4.6.  Protocol Elements No Longer\
    \ Supported . . . . . . . . . .  37\n     4.7.  XDR Examples  . . . . . . . .\
    \ . . . . . . . . . . . . . .  38\n   5.  RPC Bind Parameters . . . . . . . .\
    \ . . . . . . . . . . . . .  39\n   6.  ULB Specifications  . . . . . . . . .\
    \ . . . . . . . . . . . .  41\n     6.1.  DDP-Eligibility . . . . . . . . . .\
    \ . . . . . . . . . . .  41\n     6.2.  Maximum Reply Size  . . . . . . . . .\
    \ . . . . . . . . . .  43\n     6.3.  Additional Considerations . . . . . . .\
    \ . . . . . . . . .  43\n     6.4.  ULP Extensions  . . . . . . . . . . . . .\
    \ . . . . . . . .  43\n   7.  Protocol Extensibility  . . . . . . . . . . . .\
    \ . . . . . . .  44\n     7.1.  Conventional Extensions . . . . . . . . . . .\
    \ . . . . . .  44\n   8.  Security Considerations . . . . . . . . . . . . . .\
    \ . . . . .  44\n     8.1.  Memory Protection . . . . . . . . . . . . . . . .\
    \ . . . .  44\n     8.2.  RPC Message Security  . . . . . . . . . . . . . . .\
    \ . . .  46\n   9.  IANA Considerations . . . . . . . . . . . . . . . . . . .\
    \ . .  49\n   10. References  . . . . . . . . . . . . . . . . . . . . . . . .\
    \ .  50\n     10.1.  Normative References . . . . . . . . . . . . . . . . . .\
    \  50\n     10.2.  Informative References . . . . . . . . . . . . . . . . .  51\n\
    \   Appendix A.  Changes from RFC 5666  . . . . . . . . . . . . . . .  53\n  \
    \   A.1.  Changes to the Specification  . . . . . . . . . . . . . .  53\n    \
    \ A.2.  Changes to the Protocol . . . . . . . . . . . . . . . . .  53\n   Acknowledgments\
    \ . . . . . . . . . . . . . . . . . . . . . . . . .  54\n   Authors' Addresses\
    \  . . . . . . . . . . . . . . . . . . . . . . .  55\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document specifies the RPC-over-RDMA version 1 protocol,\
    \ based\n   on existing implementations of RFC 5666 and experience gained through\n\
    \   deployment.  This document obsoletes RFC 5666.\n   This specification clarifies\
    \ text that was subject to multiple\n   interpretations and removes support for\
    \ unimplemented RPC-over-RDMA\n   version 1 protocol elements.  It clarifies the\
    \ role of Upper-Layer\n   Bindings (ULBs) and describes what they are to contain.\n\
    \   In addition, this document describes current practice using\n   RPCSEC_GSS\
    \ [RFC7861] on RDMA transports.\n   The protocol version number has not been changed\
    \ because the protocol\n   specified in this document fully interoperates with\
    \ implementations\n   of the RPC-over-RDMA version 1 protocol specified in [RFC5666].\n"
- title: 1.1.  RPCs on RDMA Transports
  contents:
  - "1.1.  RPCs on RDMA Transports\n   RDMA [RFC5040] [RFC5041] [IBARCH] is a technique\
    \ for moving data\n   efficiently between end nodes.  By directing data into destination\n\
    \   buffers as it is sent on a network, and placing it via direct memory\n   access\
    \ by hardware, the benefits of faster transfers and reduced host\n   overhead\
    \ are obtained.\n   Open Network Computing Remote Procedure Call (ONC RPC, often\n\
    \   shortened in NFSv4 documents to RPC) [RFC5531] is a remote procedure\n   call\
    \ protocol that runs over a variety of transports.  Most RPC\n   implementations\
    \ today use UDP [RFC768] or TCP [RFC793].  On UDP, RPC\n   messages are encapsulated\
    \ inside datagrams, while on a TCP byte\n   stream, RPC messages are delineated\
    \ by a record marking protocol.  An\n   RDMA transport also conveys RPC messages\
    \ in a specific fashion that\n   must be fully described if RPC implementations\
    \ are to interoperate.\n   RDMA transports present semantics that differ from\
    \ either UDP or TCP.\n   They retain message delineations like UDP but provide\
    \ reliable and\n   sequenced data transfer like TCP.  They also provide an offloaded\n\
    \   bulk transfer service not provided by UDP or TCP.  RDMA transports\n   are\
    \ therefore appropriately viewed as a new transport type by RPC.\n   In this context,\
    \ the Network File System (NFS) protocols, as\n   described in [RFC1094], [RFC1813],\
    \ [RFC7530], [RFC5661], and future\n   NFSv4 minor versions, are all obvious beneficiaries\
    \ of RDMA\n   transports.  A complete problem statement is presented in [RFC5532].\n\
    \   Many other RPC-based protocols can also benefit.\n   Although the RDMA transport\
    \ described herein can provide relatively\n   transparent support for any RPC\
    \ application, this document also\n   describes mechanisms that can optimize data\
    \ transfer even further,\n   when RPC applications are willing to exploit awareness\
    \ of RDMA as the\n   transport.\n"
- title: 2.  Terminology
  contents:
  - '2.  Terminology

    '
- title: 2.1.  Requirements Language
  contents:
  - "2.1.  Requirements Language\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\"\
    , \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"\
    NOT RECOMMENDED\", \"MAY\", and\n   \"OPTIONAL\" in this document are to be interpreted\
    \ as described in BCP\n   14 [RFC2119] [RFC8174] when, and only when, they appear\
    \ in all\n   capitals, as shown here.\n"
- title: 2.2.  RPCs
  contents:
  - "2.2.  RPCs\n   This section highlights key elements of the RPC [RFC5531] and\n\
    \   External Data Representation (XDR) [RFC4506] protocols, upon which\n   RPC-over-RDMA\
    \ version 1 is constructed.  Strong grounding with these\n   protocols is recommended\
    \ before reading this document.\n"
- title: 2.2.1.  Upper-Layer Protocols
  contents:
  - "2.2.1.  Upper-Layer Protocols\n   RPCs are an abstraction used to implement the\
    \ operations of an Upper-\n   Layer Protocol (ULP).  \"ULP\" refers to an RPC\
    \ Program and Version\n   tuple, which is a versioned set of procedure calls that\
    \ comprise a\n   single well-defined API.  One example of a ULP is the Network\
    \ File\n   System Version 4.0 [RFC7530].\n   In this document, the term \"RPC\
    \ consumer\" refers to an implementation\n   of a ULP running on an RPC client\
    \ endpoint.\n"
- title: 2.2.2.  Requesters and Responders
  contents:
  - "2.2.2.  Requesters and Responders\n   Like a local procedure call, every RPC\
    \ procedure has a set of\n   \"arguments\" and a set of \"results\".  A calling\
    \ context invokes a\n   procedure, passing arguments to it, and the procedure\
    \ subsequently\n   returns a set of results.  Unlike a local procedure call, the\
    \ called\n   procedure is executed remotely rather than in the local application's\n\
    \   execution context.\n   The RPC protocol as described in [RFC5531] is fundamentally\
    \ a\n   message-passing protocol between one or more clients (where RPC\n   consumers\
    \ are running) and a server (where a remote execution context\n   is available\
    \ to process RPC transactions on behalf of those\n   consumers).\n   ONC RPC transactions\
    \ are made up of two types of messages:\n   CALL\n      An \"RPC Call message\"\
    \ requests that work be done.  This type of\n      message is designated by the\
    \ value zero (0) in the message's\n      msg_type field.  An arbitrary unique\
    \ value is placed in the\n      message's XID field in order to match this RPC\
    \ Call message to a\n      corresponding RPC Reply message.\n   REPLY\n      An\
    \ \"RPC Reply message\" reports the results of work requested by an\n      RPC\
    \ Call message.  An RPC Reply message is designated by the value\n      one (1)\
    \ in the message's msg_type field.  The value contained in\n      an RPC Reply\
    \ message's XID field is copied from the RPC Call\n      message whose results\
    \ are being reported.\n   The RPC client endpoint acts as a \"Requester\".  It\
    \ serializes the\n   procedure's arguments and conveys them to a server endpoint\
    \ via an\n   RPC Call message.  This message contains an RPC protocol header,\
    \ a\n   header describing the requested upper-layer operation, and all\n   arguments.\n\
    \   The RPC server endpoint acts as a \"Responder\".  It deserializes the\n  \
    \ arguments and processes the requested operation.  It then serializes\n   the\
    \ operation's results into another byte stream.  This byte stream\n   is conveyed\
    \ back to the Requester via an RPC Reply message.  This\n   message contains an\
    \ RPC protocol header, a header describing the\n   upper-layer reply, and all\
    \ results.\n   The Requester deserializes the results and allows the original\
    \ caller\n   to proceed.  At this point, the RPC transaction designated by the\
    \ XID\n   in the RPC Call message is complete, and the XID is retired.\n   In\
    \ summary, RPC Call messages are sent by Requesters to Responders to\n   initiate\
    \ RPC transactions.  RPC Reply messages are sent by Responders\n   to Requesters\
    \ to complete the processing on an RPC transaction.\n"
- title: 2.2.3.  RPC Transports
  contents:
  - "2.2.3.  RPC Transports\n   The role of an \"RPC transport\" is to mediate the\
    \ exchange of RPC\n   messages between Requesters and Responders.  An RPC transport\
    \ bridges\n   the gap between the RPC message abstraction and the native operations\n\
    \   of a particular network transport.\n   RPC-over-RDMA is a connection-oriented\
    \ RPC transport.  When a\n   connection-oriented transport is used, clients initiate\
    \ transport\n   connections, while servers wait passively for incoming connection\n\
    \   requests.\n"
- title: 2.2.4.  External Data Representation
  contents:
  - "2.2.4.  External Data Representation\n   One cannot assume that all Requesters\
    \ and Responders represent data\n   objects the same way internally.  RPC uses\
    \ External Data\n   Representation (XDR) to translate native data types and serialize\n\
    \   arguments and results [RFC4506].\n   The XDR protocol encodes data independently\
    \ of the endianness or size\n   of host-native data types, allowing unambiguous\
    \ decoding of data on\n   the receiving end.  RPC Programs are specified by writing\
    \ an XDR\n   definition of their procedures, argument data types, and result data\n\
    \   types.\n   XDR assumes that the number of bits in a byte (octet) and their\
    \ order\n   are the same on both endpoints and on the physical network.  The\n\
    \   smallest indivisible unit of XDR encoding is a group of four octets.\n   XDR\
    \ also flattens lists, arrays, and other complex data types so they\n   can be\
    \ conveyed as a stream of bytes.\n   A serialized stream of bytes that is the\
    \ result of XDR encoding is\n   referred to as an \"XDR stream\".  A sending endpoint\
    \ encodes native\n   data into an XDR stream and then transmits that stream to\
    \ a receiver.\n   A receiving endpoint decodes incoming XDR byte streams into\
    \ its\n   native data representation format.\n"
- title: 2.2.4.1.  XDR Opaque Data
  contents:
  - "2.2.4.1.  XDR Opaque Data\n   Sometimes, a data item must be transferred as is:\
    \ without encoding or\n   decoding.  The contents of such a data item are referred\
    \ to as\n   \"opaque data\".  XDR encoding places the content of opaque data items\n\
    \   directly into an XDR stream without altering it in any way.  ULPs or\n   applications\
    \ perform any needed data translation in this case.\n   Examples of opaque data\
    \ items include the content of files or generic\n   byte strings.\n"
- title: 2.2.4.2.  XDR Roundup
  contents:
  - "2.2.4.2.  XDR Roundup\n   The number of octets in a variable-length data item\
    \ precedes that\n   item in an XDR stream.  If the size of an encoded data item\
    \ is not a\n   multiple of four octets, octets containing zero are added after\
    \ the\n   end of the item; this is the case so that the next encoded data item\n\
    \   in the XDR stream starts on a four-octet boundary.  The encoded size\n   of\
    \ the item is not changed by the addition of the extra octets.\n   These extra\
    \ octets are never exposed to ULPs.\n   This technique is referred to as \"XDR\
    \ roundup\", and the extra octets\n   are referred to as \"XDR roundup padding\"\
    .\n"
- title: 2.3.  RDMA
  contents:
  - "2.3.  RDMA\n   RPC Requesters and Responders can be made more efficient if large\
    \ RPC\n   messages are transferred by a third party, such as intelligent\n   network-interface\
    \ hardware (data movement offload), and placed in the\n   receiver's memory so\
    \ that no additional adjustment of data alignment\n   has to be made (direct data\
    \ placement or \"DDP\").  RDMA transports\n   enable both optimizations.\n"
- title: 2.3.1.  DDP
  contents:
  - "2.3.1.  DDP\n   Typically, RPC implementations copy the contents of RPC messages\
    \ into\n   a buffer before being sent.  An efficient RPC implementation sends\n\
    \   bulk data without copying it into a separate send buffer first.\n   However,\
    \ socket-based RPC implementations are often unable to receive\n   data directly\
    \ into its final place in memory.  Receivers often need\n   to copy incoming data\
    \ to finish an RPC operation: sometimes, only to\n   adjust data alignment.\n\
    \   In this document, \"RDMA\" refers to the physical mechanism an RDMA\n   transport\
    \ utilizes when moving data.  Although this may not be\n   efficient, before an\
    \ RDMA transfer, a sender may copy data into an\n   intermediate buffer.  After\
    \ an RDMA transfer, a receiver may copy\n   that data again to its final destination.\n\
    \   In this document, the term \"DDP\" refers to any optimized data\n   transfer\
    \ where it is unnecessary for a receiving host's CPU to copy\n   transferred data\
    \ to another location after it has been received.\n   Just as [RFC5666] did, this\
    \ document focuses on the use of RDMA Read\n   and Write operations to achieve\
    \ both data movement offload and DDP.\n   However, not all RDMA-based data transfer\
    \ qualifies as DDP, and DDP\n   can be achieved using non-RDMA mechanisms.\n"
- title: 2.3.2.  RDMA Transport Requirements
  contents:
  - "2.3.2.  RDMA Transport Requirements\n   To achieve good performance during receive\
    \ operations, RDMA\n   transports require that RDMA consumers provision resources\
    \ in advance\n   to receive incoming messages.\n   An RDMA consumer might provide\
    \ Receive buffers in advance by posting\n   an RDMA Receive Work Request for every\
    \ expected RDMA Send from a\n   remote peer.  These buffers are provided before\
    \ the remote peer posts\n   RDMA Send Work Requests; thus, this is often referred\
    \ to as \"pre-\n   posting\" buffers.\n   An RDMA Receive Work Request remains\
    \ outstanding until hardware\n   matches it to an inbound Send operation.  The\
    \ resources associated\n   with that Receive must be retained in host memory,\
    \ or \"pinned\", until\n   the Receive completes.\n   Given these basic tenets\
    \ of RDMA transport operation, the RPC-over-\n   RDMA version 1 protocol assumes\
    \ each transport provides the following\n   abstract operations.  A more complete\
    \ discussion of these operations\n   is found in [RFC5040].\n   Registered Memory\n\
    \      Registered memory is a region of memory that is assigned a\n      steering\
    \ tag that temporarily permits access by the RDMA provider\n      to perform data-transfer\
    \ operations.  The RPC-over-RDMA version 1\n      protocol assumes that each region\
    \ of registered memory MUST be\n      identified with a steering tag of no more\
    \ than 32 bits and memory\n      addresses of up to 64 bits in length.\n   RDMA\
    \ Send\n      The RDMA provider supports an RDMA Send operation, with completion\n\
    \      signaled on the receiving peer after data has been placed in a\n      pre-posted\
    \ buffer.  Sends complete at the receiver in the order\n      they were issued\
    \ at the sender.  The amount of data transferred by\n      a single RDMA Send\
    \ operation is limited by the size of the remote\n      peer's pre-posted buffers.\n\
    \   RDMA Receive\n      The RDMA provider supports an RDMA Receive operation to\
    \ receive\n      data conveyed by incoming RDMA Send operations.  To reduce the\n\
    \      amount of memory that must remain pinned awaiting incoming Sends,\n   \
    \   the amount of pre-posted memory is limited.  Flow control to\n      prevent\
    \ overrunning receiver resources is provided by the RDMA\n      consumer (in this\
    \ case, the RPC-over-RDMA version 1 protocol).\n   RDMA Write\n      The RDMA\
    \ provider supports an RDMA Write operation to place data\n      directly into\
    \ a remote memory region.  The local host initiates an\n      RDMA Write, and\
    \ completion is signaled there.  No completion is\n      signaled on the remote\
    \ peer.  The local host provides a steering\n      tag, memory address, and length\
    \ of the remote peer's memory\n      region.\n      RDMA Writes are not ordered\
    \ with respect to one another, but are\n      ordered with respect to RDMA Sends.\
    \  A subsequent RDMA Send\n      completion obtained at the write initiator guarantees\
    \ that prior\n      RDMA Write data has been successfully placed in the remote\
    \ peer's\n      memory.\n   RDMA Read\n      The RDMA provider supports an RDMA\
    \ Read operation to place peer\n      source data directly into the read initiator's\
    \ memory.  The local\n      host initiates an RDMA Read, and completion is signaled\
    \ there.  No\n      completion is signaled on the remote peer.  The local host\n\
    \      provides steering tags, memory addresses, and a length for the\n      remote\
    \ source and local destination memory region.\n      The local host signals Read\
    \ completion to the remote peer as part\n      of a subsequent RDMA Send message.\
    \  The remote peer can then\n      release steering tags and subsequently free\
    \ associated source\n      memory regions.\n   The RPC-over-RDMA version 1 protocol\
    \ is designed to be carried over\n   RDMA transports that support the above abstract\
    \ operations.  This\n   protocol conveys information sufficient for an RPC peer\
    \ to direct an\n   RDMA provider to perform transfers containing RPC data and\
    \ to\n   communicate their result(s).\n"
- title: 3.  RPC-over-RDMA Protocol Framework
  contents:
  - '3.  RPC-over-RDMA Protocol Framework

    '
- title: 3.1.  Transfer Models
  contents:
  - "3.1.  Transfer Models\n   A \"transfer model\" designates which endpoint exposes\
    \ its memory and\n   which is responsible for initiating the transfer of data.\
    \  To enable\n   RDMA Read and Write operations, for example, an endpoint first\n\
    \   exposes regions of its memory to a remote endpoint, which initiates\n   these\
    \ operations against the exposed memory.\n   Read-Read\n      Requesters expose\
    \ their memory to the Responder, and the Responder\n      exposes its memory to\
    \ Requesters.  The Responder reads, or pulls,\n      RPC arguments or whole RPC\
    \ calls from each Requester.  Requesters\n      pull RPC results or whole RPC\
    \ relies from the Responder.\n   Write-Write\n      Requesters expose their memory\
    \ to the Responder, and the Responder\n      exposes its memory to Requesters.\
    \  Requesters write, or push, RPC\n      arguments or whole RPC calls to the Responder.\
    \  The Responder\n      pushes RPC results or whole RPC relies to each Requester.\n\
    \   Read-Write\n      Requesters expose their memory to the Responder, but the\
    \ Responder\n      does not expose its memory.  The Responder pulls RPC arguments\
    \ or\n      whole RPC calls from each Requester.  The Responder pushes RPC\n \
    \     results or whole RPC relies to each Requester.\n   Write-Read\n      The\
    \ Responder exposes its memory to Requesters, but Requesters do\n      not expose\
    \ their memory.  Requesters push RPC arguments or whole\n      RPC calls to the\
    \ Responder.  Requesters pull RPC results or whole\n      RPC relies from the\
    \ Responder.\n"
- title: 3.2.  Message Framing
  contents:
  - "3.2.  Message Framing\n   On an RPC-over-RDMA transport, each RPC message is\
    \ encapsulated by an\n   RPC-over-RDMA message.  An RPC-over-RDMA message consists\
    \ of two XDR\n   streams.\n   RPC Payload Stream\n      The \"Payload stream\"\
    \ contains the encapsulated RPC message being\n      transferred by this RPC-over-RDMA\
    \ message.  This stream always\n      begins with the Transaction ID (XID) field\
    \ of the encapsulated RPC\n      message.\n   Transport Stream\n      The \"Transport\
    \ stream\" contains a header that describes and\n      controls the transfer of\
    \ the Payload stream in this RPC-over-RDMA\n      message.  This header is analogous\
    \ to the record marking used for\n      RPC on TCP sockets but is more extensive,\
    \ since RDMA transports\n      support several modes of data transfer.\n   In\
    \ its simplest form, an RPC-over-RDMA message consists of a\n   Transport stream\
    \ followed immediately by a Payload stream conveyed\n   together in a single RDMA\
    \ Send.  To transmit large RPC messages, a\n   combination of one RDMA Send operation\
    \ and one or more other RDMA\n   operations is employed.\n   RPC-over-RDMA framing\
    \ replaces all other RPC framing (such as TCP\n   record marking) when used atop\
    \ an RPC-over-RDMA association, even\n   when the underlying RDMA protocol may\
    \ itself be layered atop a\n   transport with a defined RPC framing (such as TCP).\n\
    \   However, it is possible for RPC-over-RDMA to be dynamically enabled\n   in\
    \ the course of negotiating the use of RDMA via a ULP exchange.\n   Because RPC\
    \ framing delimits an entire RPC request or reply, the\n   resulting shift in\
    \ framing must occur between distinct RPC messages,\n   and in concert with the\
    \ underlying transport.\n"
- title: 3.3.  Managing Receiver Resources
  contents:
  - "3.3.  Managing Receiver Resources\n   It is critical to provide RDMA Send flow\
    \ control for an RDMA\n   connection.  If any pre-posted Receive buffer on the\
    \ connection is\n   not large enough to accept an incoming RDMA Send, or if a\
    \ pre-posted\n   Receive buffer is not available to accept an incoming RDMA Send,\
    \ the\n   RDMA connection can be terminated.  This is different than\n   conventional\
    \ TCP/IP networking, in which buffers are allocated\n   dynamically as messages\
    \ are received.\n   The longevity of an RDMA connection mandates that sending\
    \ endpoints\n   respect the resource limits of peer receivers.  To ensure messages\n\
    \   can be sent and received reliably, there are two operational\n   parameters\
    \ for each connection.\n"
- title: 3.3.1.  RPC-over-RDMA Credits
  contents:
  - "3.3.1.  RPC-over-RDMA Credits\n   Flow control for RDMA Send operations directed\
    \ to the Responder is\n   implemented as a simple request/grant protocol in the\
    \ RPC-over-RDMA\n   header associated with each RPC message.\n   An RPC-over-RDMA\
    \ version 1 credit is the capability to handle one\n   RPC-over-RDMA transaction.\
    \  Each RPC-over-RDMA message sent from\n   Requester to Responder requests a\
    \ number of credits from the\n   Responder.  Each RPC-over-RDMA message sent from\
    \ Responder to\n   Requester informs the Requester how many credits the Responder\
    \ has\n   granted.  The requested and granted values are carried in each RPC-\n\
    \   over-RDMA message's rdma_credit field (see Section 4.2.3).\n   Practically\
    \ speaking, the critical value is the granted value.  A\n   Requester MUST NOT\
    \ send unacknowledged requests in excess of the\n   Responder's granted credit\
    \ limit.  If the granted value is exceeded,\n   the RDMA layer may signal an error,\
    \ possibly terminating the\n   connection.  The granted value MUST NOT be zero,\
    \ since such a value\n   would result in deadlock.\n   RPC calls complete in any\
    \ order, but the current granted credit limit\n   at the Responder is known to\
    \ the Requester from RDMA Send ordering\n   properties.  The number of allowed\
    \ new requests the Requester may\n   send is then the lower of the current requested\
    \ and granted credit\n   values, minus the number of requests in flight.  Advertised\
    \ credit\n   values are not altered when individual RPCs are started or completed.\n\
    \   The requested and granted credit values MAY be adjusted to match the\n   needs\
    \ or policies in effect on either peer.  For instance, a\n   Responder may reduce\
    \ the granted credit value to accommodate the\n   available resources in a Shared\
    \ Receive Queue.  The Responder MUST\n   ensure that an increase in receive resources\
    \ is effected before the\n   next RPC Reply message is sent.\n   A Requester MUST\
    \ maintain enough receive resources to accommodate\n   expected replies.  Responders\
    \ have to be prepared for there to be no\n   receive resources available on Requesters\
    \ with no pending RPC\n   transactions.\n   Certain RDMA implementations may impose\
    \ additional flow-control\n   restrictions, such as limits on RDMA Read operations\
    \ in progress at\n   the Responder.  Accommodation of such restrictions is considered\
    \ the\n   responsibility of each RPC-over-RDMA version 1 implementation.\n"
- title: 3.3.2.  Inline Threshold
  contents:
  - "3.3.2.  Inline Threshold\n   An \"inline threshold\" value is the largest message\
    \ size (in octets)\n   that can be conveyed in one direction between peer implementations\n\
    \   using RDMA Send and Receive.  The inline threshold value is the\n   smaller\
    \ of the largest number of bytes the sender can post via a\n   single RDMA Send\
    \ operation and the largest number of bytes the\n   receiver can accept via a\
    \ single RDMA Receive operation.  Each\n   connection has two inline threshold\
    \ values: one for messages flowing\n   from Requester-to-Responder (referred to\
    \ as the \"call inline\n   threshold\") and one for messages flowing from Responder-to-Requester\n\
    \   (referred to as the \"reply inline threshold\").\n   Unlike credit limits,\
    \ inline threshold values are not advertised to\n   peers via the RPC-over-RDMA\
    \ version 1 protocol, and there is no\n   provision for inline threshold values\
    \ to change during the lifetime\n   of an RPC-over-RDMA version 1 connection.\n"
- title: 3.3.3.  Initial Connection State
  contents:
  - "3.3.3.  Initial Connection State\n   When a connection is first established,\
    \ peers might not know how many\n   receive resources the other has, nor how large\
    \ the other peer's\n   inline thresholds are.\n   As a basis for an initial exchange\
    \ of RPC requests, each RPC-over-\n   RDMA version 1 connection provides the ability\
    \ to exchange at least\n   one RPC message at a time, whose RPC Call and Reply\
    \ messages are no\n   more than 1024 bytes in size.  A Responder MAY exceed this\
    \ basic\n   level of configuration, but a Requester MUST NOT assume more than\
    \ one\n   credit is available and MUST receive a valid reply from the Responder\n\
    \   carrying the actual number of available credits, prior to sending its\n  \
    \ next request.\n   Receiver implementations MUST support inline thresholds of\
    \ 1024 bytes\n   but MAY support larger inline thresholds values.  An independent\n\
    \   mechanism for discovering a peer's inline thresholds before a\n   connection\
    \ is established may be used to optimize the use of RDMA\n   Send and Receive\
    \ operations.  In the absence of such a mechanism,\n   senders and receives MUST\
    \ assume the inline thresholds are 1024\n   bytes.\n"
- title: 3.4.  XDR Encoding with Chunks
  contents:
  - "3.4.  XDR Encoding with Chunks\n   When a DDP capability is available, the transport\
    \ places the contents\n   of one or more XDR data items directly into the receiver's\
    \ memory,\n   separately from the transfer of other parts of the containing XDR\n\
    \   stream.\n"
- title: 3.4.1.  Reducing an XDR Stream
  contents:
  - "3.4.1.  Reducing an XDR Stream\n   RPC-over-RDMA version 1 provides a mechanism\
    \ for moving part of an\n   RPC message via a data transfer distinct from an RDMA\
    \ Send/Receive\n   pair.  The sender removes one or more XDR data items from the\
    \ Payload\n   stream.  They are conveyed via other mechanisms, such as one or\
    \ more\n   RDMA Read or Write operations.  As the receiver decodes an incoming\n\
    \   message, it skips over directly placed data items.\n   The portion of an XDR\
    \ stream that is split out and moved separately\n   is referred to as a \"chunk\"\
    .  In some contexts, data in an RPC-over-\n   RDMA header that describes these\
    \ split out regions of memory may also\n   be referred to as a \"chunk\".\n  \
    \ A Payload stream after chunks have been removed is referred to as a\n   \"reduced\"\
    \ Payload stream.  Likewise, a data item that has been\n   removed from a Payload\
    \ stream to be transferred separately is\n   referred to as a \"reduced\" data\
    \ item.\n"
- title: 3.4.2.  DDP-Eligibility
  contents:
  - "3.4.2.  DDP-Eligibility\n   Not all XDR data items benefit from DDP.  For example,\
    \ small data\n   items or data items that require XDR unmarshaling by the receiver\
    \ do\n   not benefit from DDP.  In addition, it is impractical for receivers\n\
    \   to prepare for every possible XDR data item in a protocol to be\n   transferred\
    \ in a chunk.\n   To maintain interoperability on an RPC-over-RDMA transport,\
    \ a\n   determination must be made of which few XDR data items in each ULP\n \
    \  are allowed to use DDP.\n   This is done by additional specifications that\
    \ describe how ULPs\n   employ DDP.  A \"ULB specification\" identifies which\
    \ specific\n   individual XDR data items in a ULP MAY be transferred via DDP.\
    \  Such\n   data items are referred to as \"DDP-eligible\".  All other XDR data\n\
    \   items MUST NOT be reduced.\n   Detailed requirements for ULBs are provided\
    \ in Section 6.\n"
- title: 3.4.3.  RDMA Segments
  contents:
  - "3.4.3.  RDMA Segments\n   When encoding a Payload stream that contains a DDP-eligible\
    \ data\n   item, a sender may choose to reduce that data item.  When it chooses\n\
    \   to do so, the sender does not place the item into the Payload stream.\n  \
    \ Instead, the sender records in the RPC-over-RDMA header the location\n   and\
    \ size of the memory region containing that data item.\n   The Requester provides\
    \ location information for DDP-eligible data\n   items in both RPC Call and Reply\
    \ messages.  The Responder uses this\n   information to retrieve arguments contained\
    \ in the specified region\n   of the Requester's memory or place results in that\
    \ memory region.\n   An \"RDMA segment\", or \"plain segment\", is an RPC-over-RDMA\
    \ Transport\n   header data object that contains the precise coordinates of a\n\
    \   contiguous memory region that is to be conveyed separately from the\n   Payload\
    \ stream.  Plain segments contain the following information:\n   Handle\n    \
    \  Steering tag (STag) or R_key generated by registering this memory\n      with\
    \ the RDMA provider.\n   Length\n      The length of the RDMA segment's memory\
    \ region, in octets.  An\n      \"empty segment\" is an RDMA segment with the\
    \ value zero (0) in its\n      length field.\n   Offset\n      The offset or beginning\
    \ memory address of the RDMA segment's\n      memory region.\n   See [RFC5040]\
    \ for further discussion.\n"
- title: 3.4.4.  Chunks
  contents:
  - "3.4.4.  Chunks\n   In RPC-over-RDMA version 1, a \"chunk\" refers to a portion\
    \ of the\n   Payload stream that is moved independently of the RPC-over-RDMA\n\
    \   Transport header and Payload stream.  Chunk data is removed from the\n   sender's\
    \ Payload stream, transferred via separate operations, and\n   then reinserted\
    \ into the receiver's Payload stream to form a complete\n   RPC message.\n   Each\
    \ chunk is comprised of RDMA segments.  Each RDMA segment\n   represents a single\
    \ contiguous piece of that chunk.  A Requester MAY\n   divide a chunk into RDMA\
    \ segments using any boundaries that are\n   convenient.  The length of a chunk\
    \ is the sum of the lengths of the\n   RDMA segments that comprise it.\n   The\
    \ RPC-over-RDMA version 1 transport protocol does not place a limit\n   on chunk\
    \ size.  However, each ULP may cap the amount of data that can\n   be transferred\
    \ by a single RPC (for example, NFS has \"rsize\" and\n   \"wsize\", which restrict\
    \ the payload size of NFS READ and WRITE\n   operations).  The Responder can use\
    \ such limits to sanity check chunk\n   sizes before using them in RDMA operations.\n"
- title: 3.4.4.1.  Counted Arrays
  contents:
  - "3.4.4.1.  Counted Arrays\n   If a chunk contains a counted array data type, the\
    \ count of array\n   elements MUST remain in the Payload stream, while the array\
    \ elements\n   MUST be moved to the chunk.  For example, when encoding an opaque\n\
    \   byte array as a chunk, the count of bytes stays in the Payload\n   stream,\
    \ while the bytes in the array are removed from the Payload\n   stream and transferred\
    \ within the chunk.\n   Individual array elements appear in a chunk in their entirety.\
    \  For\n   example, when encoding an array of arrays as a chunk, the count of\n\
    \   items in the enclosing array stays in the Payload stream, but each\n   enclosed\
    \ array, including its item count, is transferred as part of\n   the chunk.\n"
- title: 3.4.4.2.  Optional-Data
  contents:
  - "3.4.4.2.  Optional-Data\n   If a chunk contains an optional-data data type, the\
    \ \"is present\"\n   field MUST remain in the Payload stream, while the data,\
    \ if present,\n   MUST be moved to the chunk.\n"
- title: 3.4.4.3.  XDR Unions
  contents:
  - "3.4.4.3.  XDR Unions\n   A union data type MUST NOT be made DDP-eligible, but\
    \ one or more of\n   its arms MAY be DDP-eligible, subject to the other requirements\
    \ in\n   this section.\n"
- title: 3.4.4.4.  Chunk Roundup
  contents:
  - "3.4.4.4.  Chunk Roundup\n   Except in special cases (covered in Section 3.5.3),\
    \ a chunk MUST\n   contain exactly one XDR data item.  This makes it straightforward\
    \ to\n   reduce variable-length data items without affecting the XDR alignment\n\
    \   of data items in the Payload stream.\n   When a variable-length XDR data item\
    \ is reduced, the sender MUST\n   remove XDR roundup padding for that data item\
    \ from the Payload stream\n   so that data items remaining in the Payload stream\
    \ begin on four-byte\n   alignment.\n"
- title: 3.4.5.  Read Chunks
  contents:
  - "3.4.5.  Read Chunks\n   A \"Read chunk\" represents an XDR data item that is\
    \ to be pulled from\n   the Requester to the Responder.\n   A Read chunk is a\
    \ list of one or more RDMA read segments.  An RDMA\n   read segment consists of\
    \ a Position field followed by a plain\n   segment.  See Section 4.1.2 for details.\n\
    \   Position\n      The byte offset in the unreduced Payload stream where the\
    \ receiver\n      reinserts the data item conveyed in a chunk.  The Position value\n\
    \      MUST be computed from the beginning of the unreduced Payload\n      stream,\
    \ which begins at Position zero.  All RDMA read segments\n      belonging to the\
    \ same Read chunk have the same value in their\n      Position field.\n   While\
    \ constructing an RPC Call message, a Requester registers memory\n   regions that\
    \ contain data to be transferred via RDMA Read operations.\n   It advertises the\
    \ coordinates of these regions in the RPC-over-RDMA\n   Transport header of the\
    \ RPC Call message.\n   After receiving an RPC Call message sent via an RDMA Send\
    \ operation,\n   a Responder transfers the chunk data from the Requester using\
    \ RDMA\n   Read operations.  The Responder reconstructs the transferred chunk\n\
    \   data by concatenating the contents of each RDMA segment, in list\n   order,\
    \ into the received Payload stream at the Position value\n   recorded in that\
    \ RDMA segment.\n   Put another way, the Responder inserts the first RDMA segment\
    \ in a\n   Read chunk into the Payload stream at the byte offset indicated by\n\
    \   its Position field.  RDMA segments whose Position field value match\n   this\
    \ offset are concatenated afterwards, until there are no more RDMA\n   segments\
    \ at that Position value.\n   The Position field in a read segment indicates where\
    \ the containing\n   Read chunk starts in the Payload stream.  The value in this\
    \ field\n   MUST be a multiple of four.  All segments in the same Read chunk\n\
    \   share the same Position value, even if one or more of the RDMA\n   segments\
    \ have a non-four-byte-aligned length.\n"
- title: 3.4.5.1.  Decoding Read Chunks
  contents:
  - "3.4.5.1.  Decoding Read Chunks\n   While decoding a received Payload stream,\
    \ whenever the XDR offset in\n   the Payload stream matches that of a Read chunk,\
    \ the Responder\n   initiates an RDMA Read to pull the chunk's data content into\n\
    \   registered local memory.\n   The Responder acknowledges its completion of\
    \ use of Read chunk source\n   buffers when it sends an RPC Reply message to the\
    \ Requester.  The\n   Requester may then release Read chunks advertised in the\
    \ request.\n"
- title: 3.4.5.2.  Read Chunk Roundup
  contents:
  - "3.4.5.2.  Read Chunk Roundup\n   When reducing a variable-length argument data\
    \ item, the Requester\n   SHOULD NOT include the data item's XDR roundup padding\
    \ in the chunk.\n   The length of a Read chunk is determined as follows:\n   o\
    \  If the Requester chooses to include roundup padding in a Read\n      chunk,\
    \ the chunk's total length MUST be the sum of the encoded\n      length of the\
    \ data item and the length of the roundup padding.\n      The length of the data\
    \ item that was encoded into the Payload\n      stream remains unchanged.\n  \
    \    The sender can increase the length of the chunk by adding another\n     \
    \ RDMA segment containing only the roundup padding, or it can do so\n      by\
    \ extending the final RDMA segment in the chunk.\n   o  If the sender chooses\
    \ not to include roundup padding in the chunk,\n      the chunk's total length\
    \ MUST be the same as the encoded length of\n      the data item.\n"
- title: 3.4.6.  Write Chunks
  contents:
  - "3.4.6.  Write Chunks\n   While constructing an RPC Call message, a Requester\
    \ prepares memory\n   regions in which to receive DDP-eligible result data items.\
    \  A \"Write\n   chunk\" represents an XDR data item that is to be pushed from\
    \ a\n   Responder to a Requester.  It is made up of an array of zero or more\n\
    \   plain segments.\n   Write chunks are provisioned by a Requester long before\
    \ the Responder\n   has prepared the reply Payload stream.  A Requester often\
    \ does not\n   know the actual length of the result data items to be returned,\
    \ since\n   the result does not yet exist.  Thus, it MUST register Write chunks\n\
    \   long enough to accommodate the maximum possible size of each returned\n  \
    \ data item.\n   In addition, the XDR position of DDP-eligible data items in the\n\
    \   reply's Payload stream is not predictable when a Requester constructs\n  \
    \ an RPC Call message.  Therefore, RDMA segments in a Write chunk do\n   not have\
    \ a Position field.\n   For each Write chunk provided by a Requester, the Responder\
    \ pushes\n   one data item to the Requester, filling the chunk contiguously and\
    \ in\n   segment array order until that data item has been completely written\n\
    \   to the Requester.  The Responder MUST copy the segment count and all\n   segments\
    \ from the Requester-provided Write chunk into the RPC Reply\n   message's Transport\
    \ header.  As it does so, the Responder updates\n   each segment length field\
    \ to reflect the actual amount of data that\n   is being returned in that segment.\
    \  The Responder then sends the RPC\n   Reply message via an RDMA Send operation.\n\
    \   An \"empty Write chunk\" is a Write chunk with a zero segment count.\n   By\
    \ definition, the length of an empty Write chunk is zero.  An\n   \"unused Write\
    \ chunk\" has a non-zero segment count, but all of its\n   segments are empty\
    \ segments.\n"
- title: 3.4.6.1.  Decoding Write Chunks
  contents:
  - "3.4.6.1.  Decoding Write Chunks\n   After receiving the RPC Reply message, the\
    \ Requester reconstructs the\n   transferred data by concatenating the contents\
    \ of each segment, in\n   array order, into the RPC Reply message's XDR stream\
    \ at the known XDR\n   position of the associated DDP-eligible result data item.\n"
- title: 3.4.6.2.  Write Chunk Roundup
  contents:
  - "3.4.6.2.  Write Chunk Roundup\n   When provisioning a Write chunk for a variable-length\
    \ result data\n   item, the Requester SHOULD NOT include additional space for\
    \ XDR\n   roundup padding.  A Responder MUST NOT write XDR roundup padding into\n\
    \   a Write chunk, even if the Requester made space available for it.\n   Therefore,\
    \ when returning a single variable-length result data item,\n   a returned Write\
    \ chunk's total length MUST be the same as the encoded\n   length of the result\
    \ data item.\n"
- title: 3.5.  Message Size
  contents:
  - "3.5.  Message Size\n   A receiver of RDMA Send operations is required by RDMA\
    \ to have\n   previously posted one or more adequately sized buffers.  Memory\n\
    \   savings are achieved on both Requesters and Responders by posting\n   small\
    \ Receive buffers.  However, not all RPC messages are small.\n   RPC-over-RDMA\
    \ version 1 provides several mechanisms that allow\n   messages of any size to\
    \ be conveyed efficiently.\n"
- title: 3.5.1.  Short Messages
  contents:
  - "3.5.1.  Short Messages\n   RPC messages are frequently smaller than typical inline\
    \ thresholds.\n   For example, the NFS version 3 GETATTR operation is only 56\
    \ bytes: 20\n   bytes of RPC header, a 32-byte file handle argument, and 4 bytes\
    \ for\n   its length.  The reply to this common request is about 100 bytes.\n\
    \   Since all RPC messages conveyed via RPC-over-RDMA require an RDMA\n   Send\
    \ operation, the most efficient way to send an RPC message that is\n   smaller\
    \ than the inline threshold is to append the Payload stream\n   directly to the\
    \ Transport stream.  An RPC-over-RDMA header with a\n   small RPC Call or Reply\
    \ message immediately following is transferred\n   using a single RDMA Send operation.\
    \  No other operations are needed.\n   An RPC-over-RDMA transaction using Short\
    \ Messages:\n           Requester                             Responder\n    \
    \           |        RDMA Send (RDMA_MSG)         |\n          Call |   ------------------------------>\
    \   |\n               |                                     |\n              \
    \ |                                     | Processing\n               |       \
    \                              |\n               |        RDMA Send (RDMA_MSG)\
    \         |\n               |   <------------------------------   | Reply\n"
- title: 3.5.2.  Chunked Messages
  contents:
  - "3.5.2.  Chunked Messages\n   If DDP-eligible data items are present in a Payload\
    \ stream, a sender\n   MAY reduce some or all of these items by removing them\
    \ from the\n   Payload stream.  The sender uses a separate mechanism to transfer\
    \ the\n   reduced data items.  The Transport stream with the reduced Payload\n\
    \   stream immediately following is then transferred using a single RDMA\n   Send\
    \ operation.\n   After receiving the Transport and Payload streams of an RPC Call\n\
    \   message accompanied by Read chunks, the Responder uses RDMA Read\n   operations\
    \ to move reduced data items in Read chunks.  Before sending\n   the Transport\
    \ and Payload streams of an RPC Reply message containing\n   Write chunks, the\
    \ Responder uses RDMA Write operations to move\n   reduced data items in Write\
    \ and Reply chunks.\n   An RPC-over-RDMA transaction with a Read chunk:\n    \
    \       Requester                             Responder\n               |    \
    \    RDMA Send (RDMA_MSG)         |\n          Call |   ------------------------------>\
    \   |\n               |        RDMA Read                    |\n              \
    \ |   <------------------------------   |\n               |        RDMA Response\
    \ (arg data)     |\n               |   ------------------------------>   |\n \
    \              |                                     |\n               |     \
    \                                | Processing\n               |              \
    \                       |\n               |        RDMA Send (RDMA_MSG)      \
    \   |\n               |   <------------------------------   | Reply\n   An RPC-over-RDMA\
    \ transaction with a Write chunk:\n           Requester                      \
    \       Responder\n               |        RDMA Send (RDMA_MSG)         |\n  \
    \        Call |   ------------------------------>   |\n               |      \
    \                               |\n               |                          \
    \           | Processing\n               |                                   \
    \  |\n               |        RDMA Write (result data)     |\n               |\
    \   <------------------------------   |\n               |        RDMA Send (RDMA_MSG)\
    \         |\n               |   <------------------------------   | Reply\n"
- title: 3.5.3.  Long Messages
  contents:
  - "3.5.3.  Long Messages\n   When a Payload stream is larger than the receiver's\
    \ inline threshold,\n   the Payload stream is reduced by removing DDP-eligible\
    \ data items and\n   placing them in chunks to be moved separately.  If there\
    \ are no DDP-\n   eligible data items in the Payload stream, or the Payload stream\
    \ is\n   still too large after it has been reduced, the RDMA transport MUST\n\
    \   use RDMA Read or Write operations to convey the Payload stream\n   itself.\
    \  This mechanism is referred to as a \"Long Message\".\n   To transmit a Long\
    \ Message, the sender conveys only the Transport\n   stream with an RDMA Send\
    \ operation.  The Payload stream is not\n   included in the Send buffer in this\
    \ instance.  Instead, the Requester\n   provides chunks that the Responder uses\
    \ to move the Payload stream.\n   Long Call\n      To send a Long Call message,\
    \ the Requester provides a special Read\n      chunk that contains the RPC Call\
    \ message's Payload stream.  Every\n      RDMA read segment in this chunk MUST\
    \ contain zero in its Position\n      field.  Thus, this chunk is known as a \"\
    Position Zero Read chunk\".\n   Long Reply\n      To send a Long Reply, the Requester\
    \ provides a single special\n      Write chunk in advance, known as the \"Reply\
    \ chunk\", that will\n      contain the RPC Reply message's Payload stream.  The\
    \ Requester\n      sizes the Reply chunk to accommodate the maximum expected reply\n\
    \      size for that upper-layer operation.\n   Though the purpose of a Long Message\
    \ is to handle large RPC messages,\n   Requesters MAY use a Long Message at any\
    \ time to convey an RPC Call\n   message.\n   A Responder chooses which form of\
    \ reply to use based on the chunks\n   provided by the Requester.  If Write chunks\
    \ were provided and the\n   Responder has a DDP-eligible result, it first reduces\
    \ the reply\n   Payload stream.  If a Reply chunk was provided and the reduced\n\
    \   Payload stream is larger than the reply inline threshold, the\n   Responder\
    \ MUST use the Requester-provided Reply chunk for the reply.\n   XDR data items\
    \ may appear in these special chunks without regard to\n   their DDP-eligibility.\
    \  As these chunks contain a Payload stream,\n   such chunks MUST include appropriate\
    \ XDR roundup padding to maintain\n   proper XDR alignment of their contents.\n\
    \   An RPC-over-RDMA transaction using a Long Call:\n           Requester    \
    \                         Responder\n               |        RDMA Send (RDMA_NOMSG)\
    \       |\n          Call |   ------------------------------>   |\n          \
    \     |        RDMA Read                    |\n               |   <------------------------------\
    \   |\n               |        RDMA Response (RPC call)     |\n              \
    \ |   ------------------------------>   |\n               |                  \
    \                   |\n               |                                     |\
    \ Processing\n               |                                     |\n       \
    \        |        RDMA Send (RDMA_MSG)         |\n               |   <------------------------------\
    \   | Reply\n   An RPC-over-RDMA transaction using a Long Reply:\n           Requester\
    \                             Responder\n               |        RDMA Send (RDMA_MSG)\
    \         |\n          Call |   ------------------------------>   |\n        \
    \       |                                     |\n               |            \
    \                         | Processing\n               |                     \
    \                |\n               |        RDMA Write (RPC reply)       |\n \
    \              |   <------------------------------   |\n               |     \
    \   RDMA Send (RDMA_NOMSG)       |\n               |   <------------------------------\
    \   | Reply\n"
- title: 4.  RPC-over-RDMA in Operation
  contents:
  - "4.  RPC-over-RDMA in Operation\n   Every RPC-over-RDMA version 1 message has\
    \ a header that includes a\n   copy of the message's transaction ID, data for\
    \ managing RDMA flow-\n   control credits, and lists of RDMA segments describing\
    \ chunks.  All\n   RPC-over-RDMA header content is contained in the Transport\
    \ stream;\n   thus, it MUST be XDR encoded.\n   RPC message layout is unchanged\
    \ from that described in [RFC5531]\n   except for the possible reduction of data\
    \ items that are moved by\n   separate operations.\n   The RPC-over-RDMA protocol\
    \ passes RPC messages without regard to\n   their type (CALL or REPLY).  Apart\
    \ from restrictions imposed by ULBs,\n   each endpoint of a connection MAY send\
    \ RDMA_MSG or RDMA_NOMSG message\n   header types at any time (subject to credit\
    \ limits).\n"
- title: 4.1.  XDR Protocol Definition
  contents:
  - "4.1.  XDR Protocol Definition\n   This section contains a description of the\
    \ core features of the RPC-\n   over-RDMA version 1 protocol, expressed in the\
    \ XDR language\n   [RFC4506].\n   This description is provided in a way that makes\
    \ it simple to extract\n   into ready-to-compile form.  The reader can apply the\
    \ following shell\n   script to this document to produce a machine-readable XDR\
    \ description\n   of the RPC-over-RDMA version 1 protocol.\n   <CODE BEGINS>\n\
    \   #!/bin/sh\n   grep '^ *///' | sed 's?^ /// ??' | sed 's?^ *///$??'\n   <CODE\
    \ ENDS>\n   That is, if the above script is stored in a file called \"extract.sh\"\
    \n   and this document is in a file called \"spec.txt\", then the reader can\n\
    \   do the following to extract an XDR description file:\n   <CODE BEGINS>\n \
    \  sh extract.sh < spec.txt > rpcrdma_corev1.x\n   <CODE ENDS>\n"
- title: 4.1.1.  Code Component License
  contents:
  - "4.1.1.  Code Component License\n   Code components extracted from this document\
    \ must include the\n   following license text.  When the extracted XDR code is\
    \ combined with\n   other complementary XDR code, which itself has an identical\
    \ license,\n   only a single copy of the license text need be preserved.\n   <CODE\
    \ BEGINS>\n   /// /*\n   ///  * Copyright (c) 2010-2017 IETF Trust and the persons\n\
    \   ///  * identified as authors of the code.  All rights reserved.\n   ///  *\n\
    \   ///  * The authors of the code are:\n   ///  * B. Callaghan, T. Talpey, and\
    \ C. Lever\n   ///  *\n   ///  * Redistribution and use in source and binary forms,\
    \ with\n   ///  * or without modification, are permitted provided that the\n \
    \  ///  * following conditions are met:\n   ///  *\n   ///  * - Redistributions\
    \ of source code must retain the above\n   ///  *   copyright notice, this list\
    \ of conditions and the\n   ///  *   following disclaimer.\n   ///  *\n   ///\
    \  * - Redistributions in binary form must reproduce the above\n   ///  *   copyright\
    \ notice, this list of conditions and the\n   ///  *   following disclaimer in\
    \ the documentation and/or other\n   ///  *   materials provided with the distribution.\n\
    \   ///  *\n   ///  * - Neither the name of Internet Society, IETF or IETF\n \
    \  ///  *   Trust, nor the names of specific contributors, may be\n   ///  * \
    \  used to endorse or promote products derived from this\n   ///  *   software\
    \ without specific prior written permission.\n   ///  *\n   ///  *   THIS SOFTWARE\
    \ IS PROVIDED BY THE COPYRIGHT HOLDERS\n   ///  *   AND CONTRIBUTORS \"AS IS\"\
    \ AND ANY EXPRESS OR IMPLIED\n   ///  *   WARRANTIES, INCLUDING, BUT NOT LIMITED\
    \ TO, THE\n   ///  *   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n   ///\
    \  *   FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO\n   ///  *   EVENT SHALL\
    \ THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n   ///  *   LIABLE FOR ANY DIRECT, INDIRECT,\
    \ INCIDENTAL, SPECIAL,\n   ///  *   EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\
    \ BUT\n   ///  *   NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n   ///\
    \  *   SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n   ///  *   INTERRUPTION)\
    \ HOWEVER CAUSED AND ON ANY THEORY OF\n   ///  *   LIABILITY, WHETHER IN CONTRACT,\
    \ STRICT LIABILITY,\n   ///  *   OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\n\
    \   ///  *   IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n   ///  *  \
    \ ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n   ///  */\n   ///\n   <CODE ENDS>\n"
- title: 4.1.2.  RPC-over-RDMA Version 1 XDR
  contents:
  - "4.1.2.  RPC-over-RDMA Version 1 XDR\n   XDR data items defined in this section\
    \ encodes the Transport Header\n   Stream in each RPC-over-RDMA version 1 message.\
    \  Comments identify\n   items that cannot be changed in subsequent versions.\n\
    \   <CODE BEGINS>\n   /// /*\n   ///  * Plain RDMA segment (Section 3.4.3)\n \
    \  ///  */\n   /// struct xdr_rdma_segment {\n   ///    uint32 handle;       \
    \    /* Registered memory handle */\n   ///    uint32 length;           /* Length\
    \ of the chunk in bytes */\n   ///    uint64 offset;           /* Chunk virtual\
    \ address or offset */\n   /// };\n   ///\n   /// /*\n   ///  * RDMA read segment\
    \ (Section 3.4.5)\n   ///  */\n   /// struct xdr_read_chunk {\n   ///    uint32\
    \ position;        /* Position in XDR stream */\n   ///    struct xdr_rdma_segment\
    \ target;\n   /// };\n   ///\n   /// /*\n   ///  * Read list (Section 4.3.1)\n\
    \   ///  */\n   /// struct xdr_read_list {\n   ///         struct xdr_read_chunk\
    \ entry;\n   ///         struct xdr_read_list  *next;\n   /// };\n   ///\n   ///\
    \ /*\n   ///  * Write chunk (Section 3.4.6)\n   ///  */\n   /// struct xdr_write_chunk\
    \ {\n   ///         struct xdr_rdma_segment target<>;\n   /// };\n   ///\n   ///\
    \ /*\n   ///  * Write list (Section 4.3.2)\n   ///  */\n   /// struct xdr_write_list\
    \ {\n   ///         struct xdr_write_chunk entry;\n   ///         struct xdr_write_list\
    \  *next;\n   /// };\n   ///\n   /// /*\n   ///  * Chunk lists (Section 4.3)\n\
    \   ///  */\n   /// struct rpc_rdma_header {\n   ///    struct xdr_read_list \
    \  *rdma_reads;\n   ///    struct xdr_write_list  *rdma_writes;\n   ///    struct\
    \ xdr_write_chunk *rdma_reply;\n   ///    /* rpc body follows */\n   /// };\n\
    \   ///\n   /// struct rpc_rdma_header_nomsg {\n   ///    struct xdr_read_list\
    \   *rdma_reads;\n   ///    struct xdr_write_list  *rdma_writes;\n   ///    struct\
    \ xdr_write_chunk *rdma_reply;\n   /// };\n   ///\n   /// /* Not to be used */\n\
    \   /// struct rpc_rdma_header_padded {\n   ///    uint32                 rdma_align;\n\
    \   ///    uint32                 rdma_thresh;\n   ///    struct xdr_read_list\
    \   *rdma_reads;\n   ///    struct xdr_write_list  *rdma_writes;\n   ///    struct\
    \ xdr_write_chunk *rdma_reply;\n   ///    /* rpc body follows */\n   /// };\n\
    \   ///\n   /// /*\n   ///  * Error handling (Section 4.5)\n   ///  */\n   ///\
    \ enum rpc_rdma_errcode {\n   ///    ERR_VERS = 1,       /* Value fixed for all\
    \ versions */\n   ///    ERR_CHUNK = 2\n   /// };\n   ///\n   /// /* Structure\
    \ fixed for all versions */\n   /// struct rpc_rdma_errvers {\n   ///    uint32\
    \ rdma_vers_low;\n   ///    uint32 rdma_vers_high;\n   /// };\n   ///\n   ///\
    \ union rpc_rdma_error switch (rpc_rdma_errcode err) {\n   ///    case ERR_VERS:\n\
    \   ///      rpc_rdma_errvers range;\n   ///    case ERR_CHUNK:\n   ///      void;\n\
    \   /// };\n   ///\n   /// /*\n   ///  * Procedures (Section 4.2.4)\n   ///  */\n\
    \   /// enum rdma_proc {\n   ///    RDMA_MSG = 0,     /* Value fixed for all versions\
    \ */\n   ///    RDMA_NOMSG = 1,   /* Value fixed for all versions */\n   /// \
    \   RDMA_MSGP = 2,    /* Not to be used */\n   ///    RDMA_DONE = 3,    /* Not\
    \ to be used */\n   ///    RDMA_ERROR = 4    /* Value fixed for all versions */\n\
    \   /// };\n   ///\n   /// /* The position of the proc discriminator field is\n\
    \   ///  * fixed for all versions */\n   /// union rdma_body switch (rdma_proc\
    \ proc) {\n   ///    case RDMA_MSG:\n   ///      rpc_rdma_header rdma_msg;\n \
    \  ///    case RDMA_NOMSG:\n   ///      rpc_rdma_header_nomsg rdma_nomsg;\n  \
    \ ///    case RDMA_MSGP:   /* Not to be used */\n   ///      rpc_rdma_header_padded\
    \ rdma_msgp;\n   ///    case RDMA_DONE:   /* Not to be used */\n   ///      void;\n\
    \   ///    case RDMA_ERROR:\n   ///      rpc_rdma_error rdma_error;\n   /// };\n\
    \   ///\n   /// /*\n   ///  * Fixed header fields (Section 4.2)\n   ///  */\n\
    \   /// struct rdma_msg {\n   ///    uint32    rdma_xid;      /* Position fixed\
    \ for all versions */\n   ///    uint32    rdma_vers;     /* Position fixed for\
    \ all versions */\n   ///    uint32    rdma_credit;   /* Position fixed for all\
    \ versions */\n   ///    rdma_body rdma_body;\n   /// };\n   <CODE ENDS>\n"
- title: 4.2.  Fixed Header Fields
  contents:
  - "4.2.  Fixed Header Fields\n   The RPC-over-RDMA header begins with four fixed\
    \ 32-bit fields that\n   control the RDMA interaction.\n   The first three words\
    \ are individual fields in the rdma_msg\n   structure.  The fourth word is the\
    \ first word of the rdma_body union,\n   which acts as the discriminator for the\
    \ switched union.  The contents\n   of this field are described in Section 4.2.4.\n\
    \   These four fields must remain with the same meanings and in the same\n   positions\
    \ in all subsequent versions of the RPC-over-RDMA protocol.\n"
- title: 4.2.1.  Transaction ID (XID)
  contents:
  - "4.2.1.  Transaction ID (XID)\n   The XID generated for the RPC Call and Reply\
    \ messages.  Having the\n   XID at a fixed location in the header makes it easy\
    \ for the receiver\n   to establish context as soon as each RPC-over-RDMA message\
    \ arrives.\n   This XID MUST be the same as the XID in the RPC message.  The\n\
    \   receiver MAY perform its processing based solely on the XID in the\n   RPC-over-RDMA\
    \ header, and thereby ignore the XID in the RPC message,\n   if it so chooses.\n"
- title: 4.2.2.  Version Number
  contents:
  - "4.2.2.  Version Number\n   For RPC-over-RDMA version 1, this field MUST contain\
    \ the value one\n   (1).  Rules regarding changes to this transport protocol version\n\
    \   number can be found in Section 7.\n"
- title: 4.2.3.  Credit Value
  contents:
  - "4.2.3.  Credit Value\n   When sent with an RPC Call message, the requested credit\
    \ value is\n   provided.  When sent with an RPC Reply message, the granted credit\n\
    \   value is returned.  Further discussion of how the credit value is\n   determined\
    \ can be found in Section 3.3.\n"
- title: 4.2.4.  Procedure Number
  contents:
  - "4.2.4.  Procedure Number\n   RDMA_MSG = 0         indicates that chunk lists\
    \ and a Payload stream\n                        follow.  The format of the chunk\
    \ lists is\n                        discussed below.\n   RDMA_NOMSG = 1      \
    \ indicates that after the chunk lists there is no\n                        Payload\
    \ stream.  In this case, the chunk lists\n                        provide information\
    \ to allow the Responder to\n                        transfer the Payload stream\
    \ using explicit RDMA\n                        operations.\n   RDMA_MSGP = 2 \
    \       is reserved.\n   RDMA_DONE = 3        is reserved.\n   RDMA_ERROR = 4\
    \       is used to signal an encoding error in the RPC-\n                    \
    \    over-RDMA header.\n   An RDMA_MSG procedure conveys the Transport stream\
    \ and the Payload\n   stream via an RDMA Send operation.  The Transport stream\
    \ contains the\n   four fixed fields followed by the Read and Write lists and\
    \ the Reply\n   chunk, though any or all three MAY be marked as not present. \
    \ The\n   Payload stream then follows, beginning with its XID field.  If a Read\n\
    \   or Write chunk list is present, a portion of the Payload stream has\n   been\
    \ reduced and is conveyed via separate operations.\n   An RDMA_NOMSG procedure\
    \ conveys the Transport stream via an RDMA Send\n   operation.  The Transport\
    \ stream contains the four fixed fields\n   followed by the Read and Write chunk\
    \ lists and the Reply chunk.\n   Though any of these MAY be marked as not present,\
    \ one MUST be present\n   and MUST hold the Payload stream for this RPC-over-RDMA\
    \ message.  If\n   a Read or Write chunk list is present, a portion of the Payload\n\
    \   stream has been excised and is conveyed via separate operations.\n   An RDMA_ERROR\
    \ procedure conveys the Transport stream via an RDMA Send\n   operation.  The\
    \ Transport stream contains the four fixed fields\n   followed by formatted error\
    \ information.  No Payload stream is\n   conveyed in this type of RPC-over-RDMA\
    \ message.\n   A Requester MUST NOT send an RPC-over-RDMA header with the RDMA_ERROR\n\
    \   procedure.  A Responder MUST silently discard RDMA_ERROR procedures.\n   The\
    \ Transport stream and Payload stream can be constructed in\n   separate buffers.\
    \  However, the total length of the gathered buffers\n   cannot exceed the inline\
    \ threshold.\n"
- title: 4.3.  Chunk Lists
  contents:
  - "4.3.  Chunk Lists\n   The chunk lists in an RPC-over-RDMA version 1 header are\
    \ three XDR\n   optional-data fields that follow the fixed header fields in RDMA_MSG\n\
    \   and RDMA_NOMSG procedures.  Read Section 4.19 of [RFC4506] carefully\n   to\
    \ understand how optional-data fields work.  Examples of XDR-encoded\n   chunk\
    \ lists are provided in Section 4.7 as an aid to understanding.\n   Often, an\
    \ RPC-over-RDMA message has no associated chunks.  In this\n   case, the Read\
    \ list, Write list, and Reply chunk are all marked \"not\n   present\".\n"
- title: 4.3.1.  Read List
  contents:
  - "4.3.1.  Read List\n   Each RDMA_MSG or RDMA_NOMSG procedure has one \"Read list\"\
    .  The Read\n   list is a list of zero or more RDMA read segments, provided by\
    \ the\n   Requester, that are grouped by their Position fields into Read\n   chunks.\
    \  Each Read chunk advertises the location of argument data the\n   Responder\
    \ is to pull from the Requester.  The Requester has reduced\n   the data items\
    \ in these chunks from the call's Payload stream.\n   A Requester may transmit\
    \ the Payload stream of an RPC Call message\n   using a Position Zero Read chunk.\
    \  If the RPC Call message has no\n   argument data that is DDP-eligible and the\
    \ Position Zero Read chunk\n   is not being used, the Requester leaves the Read\
    \ list empty.\n   Responders MUST leave the Read list empty in all replies.\n"
- title: 4.3.1.1.  Matching Read Chunks to Arguments
  contents:
  - "4.3.1.1.  Matching Read Chunks to Arguments\n   When reducing a DDP-eligible\
    \ argument data item, a Requester records\n   the XDR stream offset of that data\
    \ item in the Read chunk's Position\n   field.  The Responder can then tell unambiguously\
    \ where that chunk is\n   to be reinserted into the received Payload stream to\
    \ form a complete\n   RPC Call message.\n"
- title: 4.3.2.  Write List
  contents:
  - "4.3.2.  Write List\n   Each RDMA_MSG or RDMA_NOMSG procedure has one \"Write\
    \ list\".  The\n   Write list is a list of zero or more Write chunks, provided\
    \ by the\n   Requester.  Each Write chunk is an array of plain segments; thus,\
    \ the\n   Write list is a list of counted arrays.\n   If an RPC Reply message\
    \ has no possible DDP-eligible result data\n   items, the Requester leaves the\
    \ Write list empty.  When a Requester\n   provides a Write list, the Responder\
    \ MUST push data corresponding to\n   DDP-eligible result data items to Requester\
    \ memory referenced in the\n   Write list.  The Responder removes these data items\
    \ from the reply's\n   Payload stream.\n"
- title: 4.3.2.1.  Matching Write Chunks to Results
  contents:
  - "4.3.2.1.  Matching Write Chunks to Results\n   A Requester constructs the Write\
    \ list for an RPC transaction before\n   the Responder has formulated its reply.\
    \  When there is only one DDP-\n   eligible result data item, the Requester inserts\
    \ only a single Write\n   chunk in the Write list.  If the returned Write chunk\
    \ is not an\n   unused Write chunk, the Requester knows with certainty which result\n\
    \   data item is contained in it.\n   When a Requester has provided multiple Write\
    \ chunks, the Responder\n   fills in each Write chunk with one DDP-eligible result\
    \ until there\n   are either no more DDP-eligible results or no more Write chunks.\n\
    \   The Requester might not be able to predict in advance which DDP-\n   eligible\
    \ data item goes in which chunk.  Thus, the Requester is\n   responsible for allocating\
    \ and registering Write chunks large enough\n   to accommodate the largest result\
    \ data item that might be associated\n   with each chunk in the Write list.\n\
    \   As a Requester decodes a reply Payload stream, it is clear from the\n   contents\
    \ of the RPC Reply message which Write chunk contains which\n   result data item.\n"
- title: 4.3.2.2.  Unused Write Chunks
  contents:
  - "4.3.2.2.  Unused Write Chunks\n   There are occasions when a Requester provides\
    \ a non-empty Write chunk\n   but the Responder is not able to use it.  For example,\
    \ a ULP may\n   define a union result where some arms of the union contain a DDP-\n\
    \   eligible data item while other arms do not.  The Responder is\n   required\
    \ to use Requester-provided Write chunks in this case, but if\n   the Responder\
    \ returns a result that uses an arm of the union that has\n   no DDP-eligible\
    \ data item, that Write chunk remains unconsumed.\n   If there is a subsequent\
    \ DDP-eligible result data item in the RPC\n   Reply message, it MUST be placed\
    \ in that unconsumed Write chunk.\n   Therefore, the Requester MUST provision\
    \ each Write chunk so it can be\n   filled with the largest DDP-eligible data\
    \ item that can be placed in\n   it.\n   If this is the last or only Write chunk\
    \ available and it remains\n   unconsumed, the Responder MUST return this Write\
    \ chunk as an unused\n   Write chunk (see Section 3.4.6).  The Responder sets\
    \ the segment\n   count to a value matching the Requester-provided Write chunk,\
    \ but\n   returns only empty segments in that Write chunk.\n   Unused Write chunks,\
    \ or unused bytes in Write chunk segments, are\n   returned to the RPC consumer\
    \ as part of RPC completion.  Even if a\n   Responder indicates that a Write chunk\
    \ is not consumed, the Responder\n   may have written data into one or more segments\
    \ before choosing not\n   to return that data item.  The Requester MUST NOT assume\
    \ that the\n   memory regions backing a Write chunk have not been modified.\n"
- title: 4.3.2.3.  Empty Write Chunks
  contents:
  - "4.3.2.3.  Empty Write Chunks\n   To force a Responder to return a DDP-eligible\
    \ result inline, a\n   Requester employs the following mechanism:\n   o  When\
    \ there is only one DDP-eligible result item in an RPC Reply\n      message, the\
    \ Requester provides an empty Write list.\n   o  When there are multiple DDP-eligible\
    \ result data items and a\n      Requester prefers that a data item is returned\
    \ inline, the\n      Requester provides an empty Write chunk for that item (see\n\
    \      Section 3.4.6).  The Responder MUST return the corresponding\n      result\
    \ data item inline and MUST return an empty Write chunk in\n      that Write list\
    \ position in the RPC Reply message.\n   As always, a Requester and Responder\
    \ must prepare for a Long Reply to\n   be used if the resulting RPC Reply might\
    \ be too large to be conveyed\n   in an RDMA Send.\n"
- title: 4.3.3.  Reply Chunk
  contents:
  - "4.3.3.  Reply Chunk\n   Each RDMA_MSG or RDMA_NOMSG procedure has one \"Reply\
    \ chunk\" slot.  A\n   Requester MUST provide a Reply chunk whenever the maximum\
    \ possible\n   size of the RPC Reply message's Transport and Payload streams is\n\
    \   larger than the inline threshold for messages from Responder to\n   Requester.\
    \  Otherwise, the Requester marks the Reply chunk as not\n   present.\n   If the\
    \ Transport stream and Payload stream together are smaller than\n   the reply\
    \ inline threshold, the Responder MAY return the RPC Reply\n   message as a Short\
    \ message rather than using the Requester-provided\n   Reply chunk.\n   When a\
    \ Requester provides a Reply chunk in an RPC Call message, the\n   Responder MUST\
    \ copy that chunk into the Transport header of the RPC\n   Reply message.  As\
    \ with Write chunks, the Responder modifies the\n   copied Reply chunk in the\
    \ RPC Reply message to reflect the actual\n   amount of data that is being returned\
    \ in the Reply chunk.\n"
- title: 4.4.  Memory Registration
  contents:
  - "4.4.  Memory Registration\n   The cost of registering and invalidating memory\
    \ can be a significant\n   proportion of the cost of an RPC-over-RDMA transaction.\
    \  Thus, an\n   important implementation consideration is how to minimize\n  \
    \ registration activity without exposing system memory needlessly.\n"
- title: 4.4.1.  Registration Longevity
  contents:
  - "4.4.1.  Registration Longevity\n   Data transferred via RDMA Read and Write can\
    \ reside in a memory\n   allocation not in the control of the RPC-over-RDMA transport.\
    \  These\n   memory allocations can persist outside the bounds of an RPC\n   transaction.\
    \  They are registered and invalidated as needed, as part\n   of each RPC transaction.\n\
    \   The Requester endpoint must ensure that memory regions associated\n   with\
    \ each RPC transaction are protected from Responder access before\n   allowing\
    \ upper-layer access to the data contained in them.  Moreover,\n   the Requester\
    \ must not access these memory regions while the\n   Responder has access to them.\n\
    \   This includes memory regions that are associated with canceled RPCs.\n   A\
    \ Responder cannot know that the Requester is no longer waiting for a\n   reply,\
    \ and it might proceed to read or even update memory that the\n   Requester might\
    \ have released for other use.\n"
- title: 4.4.2.  Communicating DDP-Eligibility
  contents:
  - "4.4.2.  Communicating DDP-Eligibility\n   The interface by which a ULP implementation\
    \ communicates the\n   eligibility of a data item locally to its local RPC-over-RDMA\n\
    \   endpoint is not described by this specification.\n   Depending on the implementation\
    \ and constraints imposed by ULBs, it\n   is possible to implement reduction transparently\
    \ to upper layers.\n   Such implementations may lead to inefficiencies, either\
    \ because they\n   require the RPC layer to perform expensive registration and\n\
    \   invalidation of memory \"on the fly\", or they may require using RDMA\n  \
    \ chunks in RPC Reply messages, along with the resulting additional\n   handshaking\
    \ with the RPC-over-RDMA peer.\n   However, these issues are internal and generally\
    \ confined to the\n   local interface between RPC and its upper layers, one in\
    \ which\n   implementations are free to innovate.  The only requirement, beyond\n\
    \   constraints imposed by the ULB, is that the resulting RPC-over-RDMA\n   protocol\
    \ sent to the peer be valid for the upper layer.\n"
- title: 4.4.3.  Registration Strategies
  contents:
  - "4.4.3.  Registration Strategies\n   The choice of which memory registration strategies\
    \ to employ is left\n   to Requester and Responder implementers.  To support the\
    \ widest array\n   of RDMA implementations, as well as the most general steering\
    \ tag\n   scheme, an Offset field is included in each RDMA segment.\n   While\
    \ zero-based offset schemes are available in many RDMA\n   implementations, their\
    \ use by RPC requires individual registration of\n   each memory region.  For\
    \ such implementations, this can be a\n   significant overhead.  By providing\
    \ an offset in each chunk, many\n   pre-registration or region-based registrations\
    \ can be readily\n   supported.\n"
- title: 4.5.  Error Handling
  contents:
  - "4.5.  Error Handling\n   A receiver performs basic validity checks on the RPC-over-RDMA\
    \ header\n   and chunk contents before it passes the RPC message to the RPC layer.\n\
    \   If an incoming RPC-over-RDMA message is not as long as a minimal size\n  \
    \ RPC-over-RDMA header (28 bytes), the receiver cannot trust the value\n   of\
    \ the XID field; therefore, it MUST silently discard the message\n   before performing\
    \ any parsing.  If other errors are detected in the\n   RPC-over-RDMA header of\
    \ an RPC Call message, a Responder MUST send an\n   RDMA_ERROR message back to\
    \ the Requester.  If errors are detected in\n   the RPC-over-RDMA header of an\
    \ RPC Reply message, a Requester MUST\n   silently discard the message.\n   To\
    \ form an RDMA_ERROR procedure:\n   o  The rdma_xid field MUST contain the same\
    \ XID that was in the\n      rdma_xid field in the failing request;\n   o  The\
    \ rdma_vers field MUST contain the same version that was in the\n      rdma_vers\
    \ field in the failing request;\n   o  The rdma_proc field MUST contain the value\
    \ RDMA_ERROR; and\n   o  The rdma_err field contains a value that reflects the\
    \ type of\n      error that occurred, as described below.\n   An RDMA_ERROR procedure\
    \ indicates a permanent error.  Receipt of this\n   procedure completes the RPC\
    \ transaction associated with XID in the\n   rdma_xid field.  A receiver MUST\
    \ silently discard an RDMA_ERROR\n   procedure that it cannot decode.\n"
- title: 4.5.1.  Header Version Mismatch
  contents:
  - "4.5.1.  Header Version Mismatch\n   When a Responder detects an RPC-over-RDMA\
    \ header version that it does\n   not support (currently this document defines\
    \ only version 1), it MUST\n   reply with an RDMA_ERROR procedure and set the\
    \ rdma_err value to\n   ERR_VERS, also providing the low and high inclusive version\
    \ numbers\n   it does, in fact, support.\n"
- title: 4.5.2.  XDR Errors
  contents:
  - "4.5.2.  XDR Errors\n   A receiver might encounter an XDR parsing error that prevents\
    \ it from\n   processing the incoming Transport stream.  Examples of such errors\n\
    \   include an invalid value in the rdma_proc field; an RDMA_NOMSG\n   message\
    \ where the Read list, Write list, and Reply chunk are marked\n   not present;\
    \ or the value of the rdma_xid field does not match the\n   value of the XID field\
    \ in the accompanying RPC message.  If the\n   rdma_vers field contains a recognized\
    \ value, but an XDR parsing error\n   occurs, the Responder MUST reply with an\
    \ RDMA_ERROR procedure and set\n   the rdma_err value to ERR_CHUNK.\n   When a\
    \ Responder receives a valid RPC-over-RDMA header but the\n   Responder's ULP\
    \ implementation cannot parse the RPC arguments in the\n   RPC Call message, the\
    \ Responder SHOULD return an RPC Reply message\n   with status GARBAGE_ARGS, using\
    \ an RDMA_MSG procedure.  This type of\n   parsing failure might be due to mismatches\
    \ between chunk sizes or\n   offsets and the contents of the Payload stream, for\
    \ example.\n"
- title: 4.5.3.  Responder RDMA Operational Errors
  contents:
  - "4.5.3.  Responder RDMA Operational Errors\n   In RPC-over-RDMA version 1, the\
    \ Responder initiates RDMA Read and\n   Write operations that target the Requester's\
    \ memory.  Problems might\n   arise as the Responder attempts to use Requester-provided\
    \ resources\n   for RDMA operations.  For example:\n   o  Usually, chunks can\
    \ be validated only by using their contents to\n      perform data transfers.\
    \  If chunk contents are invalid (e.g., a\n      memory region is no longer registered\
    \ or a chunk length exceeds\n      the end of the registered memory region), a\
    \ Remote Access Error\n      occurs.\n   o  If a Requester's Receive buffer is\
    \ too small, the Responder's Send\n      operation completes with a Local Length\
    \ Error.\n   o  If the Requester-provided Reply chunk is too small to accommodate\n\
    \      a large RPC Reply message, a Remote Access Error occurs.  A\n      Responder\
    \ might detect this problem before attempting to write\n      past the end of\
    \ the Reply chunk.\n   RDMA operational errors are typically fatal to the connection.\
    \  To\n   avoid a retransmission loop and repeated connection loss that\n   deadlocks\
    \ the connection, once the Requester has re-established a\n   connection, the\
    \ Responder should send an RDMA_ERROR reply with an\n   rdma_err value of ERR_CHUNK\
    \ to indicate that no RPC-level reply is\n   possible for that XID.\n"
- title: 4.5.4.  Other Operational Errors
  contents:
  - "4.5.4.  Other Operational Errors\n   While a Requester is constructing an RPC\
    \ Call message, an\n   unrecoverable problem might occur that prevents the Requester\
    \ from\n   posting further RDMA Work Requests on behalf of that message.  As\n\
    \   with other transports, if a Requester is unable to construct and\n   transmit\
    \ an RPC Call message, the associated RPC transaction fails\n   immediately.\n\
    \   After a Requester has received a reply, if it is unable to invalidate\n  \
    \ a memory region due to an unrecoverable problem, the Requester MUST\n   close\
    \ the connection to protect that memory from Responder access\n   before the associated\
    \ RPC transaction is complete.\n   While a Responder is constructing an RPC Reply\
    \ message or error\n   message, an unrecoverable problem might occur that prevents\
    \ the\n   Responder from posting further RDMA Work Requests on behalf of that\n\
    \   message.  If a Responder is unable to construct and transmit an RPC\n   Reply\
    \ or RPC-over-RDMA error message, the Responder MUST close the\n   connection\
    \ to signal to the Requester that a reply was lost.\n"
- title: 4.5.5.  RDMA Transport Errors
  contents:
  - "4.5.5.  RDMA Transport Errors\n   The RDMA connection and physical link provide\
    \ some degree of error\n   detection and retransmission.  iWARP's Marker PDU Aligned\
    \ (MPA) layer\n   (when used over TCP), the Stream Control Transmission Protocol\n\
    \   (SCTP), as well as the InfiniBand [IBARCH] link layer all provide\n   Cyclic\
    \ Redundancy Check (CRC) protection of the RDMA payload, and\n   CRC-class protection\
    \ is a general attribute of such transports.\n   Additionally, the RPC layer itself\
    \ can accept errors from the\n   transport and recover via retransmission.  RPC\
    \ recovery can handle\n   complete loss and re-establishment of a transport connection.\n\
    \   The details of reporting and recovery from RDMA link-layer errors are\n  \
    \ described in specific link-layer APIs and operational specifications\n   and\
    \ are outside the scope of this protocol specification.  See\n   Section 8 for\
    \ further discussion of the use of RPC-level integrity\n   schemes to detect errors.\n"
- title: 4.6.  Protocol Elements No Longer Supported
  contents:
  - "4.6.  Protocol Elements No Longer Supported\n   The following protocol elements\
    \ are no longer supported in RPC-over-\n   RDMA version 1.  Related enum values\
    \ and structure definitions remain\n   in the RPC-over-RDMA version 1 protocol\
    \ for backwards compatibility.\n"
- title: 4.6.1.  RDMA_MSGP
  contents:
  - "4.6.1.  RDMA_MSGP\n   The specification of RDMA_MSGP in Section 3.9 of [RFC5666]\
    \ is\n   incomplete.  To fully specify RDMA_MSGP would require:\n   o  Updating\
    \ the definition of DDP-eligibility to include data items\n      that may be transferred,\
    \ with padding, via RDMA_MSGP procedures\n   o  Adding full operational descriptions\
    \ of the alignment and\n      threshold fields\n   o  Discussing how alignment\
    \ preferences are communicated between two\n      peers without using CCP\n  \
    \ o  Describing the treatment of RDMA_MSGP procedures that convey Read\n     \
    \ or Write chunks\n   The RDMA_MSGP message type is beneficial only when the padded\
    \ data\n   payload is at the end of an RPC message's argument or result list.\n\
    \   This is not typical for NFSv4 COMPOUND RPCs, which often include a\n   GETATTR\
    \ operation as the final element of the compound operation\n   array.\n   Without\
    \ a full specification of RDMA_MSGP, there has been no fully\n   implemented prototype\
    \ of it.  Without a complete prototype of\n   RDMA_MSGP support, it is difficult\
    \ to assess whether this protocol\n   element has benefit or can even be made\
    \ to work interoperably.\n   Therefore, senders MUST NOT send RDMA_MSGP procedures.\
    \  When\n   receiving an RDMA_MSGP procedure, Responders SHOULD reply with an\n\
    \   RDMA_ERROR procedure, setting the rdma_err field to ERR_CHUNK;\n   Requesters\
    \ MUST silently discard the message.\n"
- title: 4.6.2.  RDMA_DONE
  contents:
  - "4.6.2.  RDMA_DONE\n   Because no implementation of RPC-over-RDMA version 1 uses\
    \ the Read-\n   Read transfer model, there is never a need to send an RDMA_DONE\n\
    \   procedure.\n   Therefore, senders MUST NOT send RDMA_DONE messages.  Receivers\
    \ MUST\n   silently discard RDMA_DONE messages.\n"
- title: 4.7.  XDR Examples
  contents:
  - "4.7.  XDR Examples\n   RPC-over-RDMA chunk lists are complex data types.  In\
    \ this section,\n   illustrations are provided to help readers grasp how chunk\
    \ lists are\n   represented inside an RPC-over-RDMA header.\n   A plain segment\
    \ is the simplest component, being made up of a 32-bit\n   handle (H), a 32-bit\
    \ length (L), and 64 bits of offset (OO).  Once\n   flattened into an XDR stream,\
    \ plain segments appear as\n      HLOO\n   An RDMA read segment has an additional\
    \ 32-bit position field (P).\n   RDMA read segments appear as\n      PHLOO\n \
    \  A Read chunk is a list of RDMA read segments.  Each RDMA read segment\n   is\
    \ preceded by a 32-bit word containing a one if a segment follows or\n   a zero\
    \ if there are no more segments in the list.  In XDR form, this\n   would look\
    \ like\n      1 PHLOO 1 PHLOO 1 PHLOO 0\n   where P would hold the same value\
    \ for each RDMA read segment\n   belonging to the same Read chunk.\n   The Read\
    \ list is also a list of RDMA read segments.  In XDR form,\n   this would look\
    \ like a Read chunk, except that the P values could\n   vary across the list.\
    \  An empty Read list is encoded as a single\n   32-bit zero.\n   One Write chunk\
    \ is a counted array of plain segments.  In XDR form,\n   the count would appear\
    \ as the first 32-bit word, followed by an HLOO\n   for each element of the array.\
    \  For instance, a Write chunk with\n   three elements would look like\n     \
    \ 3 HLOO HLOO HLOO\n   The Write list is a list of counted arrays.  In XDR form,\
    \ this is a\n   combination of optional-data and counted arrays.  To represent\
    \ a\n   Write list containing a Write chunk with three segments and a Write\n\
    \   chunk with two segments, XDR would encode\n      1 3 HLOO HLOO HLOO 1 2 HLOO\
    \ HLOO 0\n   An empty Write list is encoded as a single 32-bit zero.\n   The Reply\
    \ chunk is a Write chunk.  However, since it is an optional-\n   data field, there\
    \ is a 32-bit field in front of it that contains a\n   one if the Reply chunk\
    \ is present or a zero if it is not.  After\n   encoding, a Reply chunk with two\
    \ segments would look like\n      1 2 HLOO HLOO\n   Frequently, a Requester does\
    \ not provide any chunks.  In that case,\n   after the four fixed fields in the\
    \ RPC-over-RDMA header, there are\n   simply three 32-bit fields that contain\
    \ zero.\n"
- title: 5.  RPC Bind Parameters
  contents:
  - "5.  RPC Bind Parameters\n   In setting up a new RDMA connection, the first action\
    \ by a Requester\n   is to obtain a transport address for the Responder.  The\
    \ means used\n   to obtain this address, and to open an RDMA connection, is dependent\n\
    \   on the type of RDMA transport and is the responsibility of each RPC\n   protocol\
    \ binding and its local implementation.\n   RPC services normally register with\
    \ a portmap or rpcbind service\n   [RFC1833], which associates an RPC Program\
    \ number with a service\n   address.  This policy is no different with RDMA transports.\
    \  However,\n   a different and distinct service address (port number) might\n\
    \   sometimes be required for ULP operation with RPC-over-RDMA.\n   When mapped\
    \ atop the iWARP transport [RFC5040] [RFC5041], which uses\n   IP port addressing\
    \ due to its layering on TCP and/or SCTP, port\n   mapping is trivial and consists\
    \ merely of issuing the port in the\n   connection process.  The NFS/RDMA protocol\
    \ service address has been\n   assigned port 20049 by IANA, for both iWARP/TCP\
    \ and iWARP/SCTP\n   [RFC5667].\n   When mapped atop InfiniBand [IBARCH], which\
    \ uses a service endpoint\n   naming scheme based on a Group Identifier (GID),\
    \ a translation MUST\n   be employed.  One such translation is described in Annexes\
    \ A3\n   (Application Specific Identifiers), A4 (Sockets Direct Protocol\n   (SDP)),\
    \ and A11 (RDMA IP CM Service) of [IBARCH], which is\n   appropriate for translating\
    \ IP port addressing to the InfiniBand\n   network.  Therefore, in this case,\
    \ IP port addressing may be readily\n   employed by the upper layer.\n   When\
    \ a mapping standard or convention exists for IP ports on an RDMA\n   interconnect,\
    \ there are several possibilities for each upper layer to\n   consider:\n   o\
    \  One possibility is to have the Responder register its mapped IP\n      port\
    \ with the rpcbind service under the netid (or netids) defined\n      here.  An\
    \ RPC-over-RDMA-aware Requester can then resolve its\n      desired service to\
    \ a mappable port and proceed to connect.  This\n      is the most flexible and\
    \ compatible approach, for those upper\n      layers that are defined to use the\
    \ rpcbind service.\n   o  A second possibility is to have the Responder's portmapper\n\
    \      register itself on the RDMA interconnect at a \"well-known\" service\n\
    \      address (on UDP or TCP, this corresponds to port 111).  A\n      Requester\
    \ could connect to this service address and use the\n      portmap protocol to\
    \ obtain a service address in response to a\n      program number, e.g., an iWARP\
    \ port number or an InfiniBand GID.\n   o  Alternately, the Requester could simply\
    \ connect to the mapped\n      well-known port for the service itself, if it is\
    \ appropriately\n      defined.  By convention, the NFS/RDMA service, when operating\
    \ atop\n      such an InfiniBand fabric, uses the same 20049 assignment as for\n\
    \      iWARP.\n   Historically, different RPC protocols have taken different approaches\n\
    \   to their port assignment.  Therefore, the specific method is left to\n   each\
    \ RPC-over-RDMA-enabled ULB and is not addressed in this document.\n   In Section\
    \ 9, this specification defines two new netid values, to be\n   used for registration\
    \ of upper layers atop iWARP [RFC5040] [RFC5041]\n   and (when a suitable port\
    \ translation service is available)\n   InfiniBand [IBARCH].  Additional RDMA-capable\
    \ networks MAY define\n   their own netids, or if they provide a port translation,\
    \ they MAY\n   share the one defined in this document.\n"
- title: 6.  ULB Specifications
  contents:
  - "6.  ULB Specifications\n   An ULP is typically defined independently of any particular\
    \ RPC\n   transport.  An ULB (ULB) specification provides guidance that helps\n\
    \   the ULP interoperate correctly and efficiently over a particular\n   transport.\
    \  For RPC-over-RDMA version 1, a ULB may provide:\n   o  A taxonomy of XDR data\
    \ items that are eligible for DDP\n   o  Constraints on which upper-layer procedures\
    \ may be reduced and on\n      how many chunks may appear in a single RPC request\n\
    \   o  A method for determining the maximum size of the reply Payload\n      stream\
    \ for all procedures in the ULP\n   o  An rpcbind port assignment for operation\
    \ of the RPC Program and\n      Version on an RPC-over-RDMA transport\n   Each\
    \ RPC Program and Version tuple that utilizes RPC-over-RDMA\n   version 1 needs\
    \ to have a ULB specification.\n"
- title: 6.1.  DDP-Eligibility
  contents:
  - "6.1.  DDP-Eligibility\n   An ULB designates some XDR data items as eligible for\
    \ DDP.  As an\n   RPC-over-RDMA message is formed, DDP-eligible data items can\
    \ be\n   removed from the Payload stream and placed directly in the receiver's\n\
    \   memory.\n   An XDR data item should be considered for DDP-eligibility if there\
    \ is\n   a clear benefit to moving the contents of the item directly from the\n\
    \   sender's memory to the receiver's memory.  Criteria for DDP-\n   eligibility\
    \ include:\n   o  The XDR data item is frequently sent or received, and its size\
    \ is\n      often much larger than typical inline thresholds.\n   o  If the XDR\
    \ data item is a result, its maximum size must be\n      predictable in advance\
    \ by the Requester.\n   o  Transport-level processing of the XDR data item is\
    \ not needed.\n      For example, the data item is an opaque byte array, which\
    \ requires\n      no XDR encoding and decoding of its content.\n   o  The content\
    \ of the XDR data item is sensitive to address\n      alignment.  For example,\
    \ a data copy operation would be required\n      on the receiver to enable the\
    \ message to be parsed correctly, or\n      to enable the data item to be accessed.\n\
    \   o  The XDR data item does not contain DDP-eligible data items.\n   In addition\
    \ to defining the set of data items that are DDP-eligible,\n   a ULB may also\
    \ limit the use of chunks to particular upper-layer\n   procedures.  If more than\
    \ one data item in a procedure is DDP-\n   eligible, the ULB may also limit the\
    \ number of chunks that a\n   Requester can provide for a particular upper-layer\
    \ procedure.\n   Senders MUST NOT reduce data items that are not DDP-eligible.\
    \  Such\n   data items MAY, however, be moved as part of a Position Zero Read\n\
    \   chunk or a Reply chunk.\n   The programming interface by which an upper-layer\
    \ implementation\n   indicates the DDP-eligibility of a data item to the RPC transport\
    \ is\n   not described by this specification.  The only requirements are that\n\
    \   the receiver can re-assemble the transmitted RPC-over-RDMA message\n   into\
    \ a valid XDR stream, and that DDP-eligibility rules specified by\n   the ULB\
    \ are respected.\n   There is no provision to express DDP-eligibility within the\
    \ XDR\n   language.  The only definitive specification of DDP-eligibility is a\n\
    \   ULB.\n   In general, a DDP-eligibility violation occurs when:\n   o  A Requester\
    \ reduces a non-DDP-eligible argument data item.  The\n      Responder MUST NOT\
    \ process this RPC Call message and MUST report\n      the violation as described\
    \ in Section 4.5.2.\n   o  A Responder reduces a non-DDP-eligible result data\
    \ item.  The\n      Requester MUST terminate the pending RPC transaction and report\
    \ an\n      appropriate permanent error to the RPC consumer.\n   o  A Responder\
    \ does not reduce a DDP-eligible result data item into\n      an available Write\
    \ chunk.  The Requester MUST terminate the\n      pending RPC transaction and\
    \ report an appropriate permanent error\n      to the RPC consumer.\n"
- title: 6.2.  Maximum Reply Size
  contents:
  - "6.2.  Maximum Reply Size\n   A Requester provides resources for both an RPC Call\
    \ message and its\n   matching RPC Reply message.  A Requester forms the RPC Call\
    \ message\n   itself; thus, the Requester can compute the exact resources needed.\n\
    \   A Requester must allocate resources for the RPC Reply message (an\n   RPC-over-RDMA\
    \ credit, a Receive buffer, and possibly a Write list and\n   Reply chunk) before\
    \ the Responder has formed the actual reply.  To\n   accommodate all possible\
    \ replies for the procedure in the RPC Call\n   message, a Requester must allocate\
    \ reply resources based on the\n   maximum possible size of the expected RPC Reply\
    \ message.\n   If there are procedures in the ULP for which there is no clear\
    \ reply\n   size maximum, the ULB needs to specify a dependable means for\n  \
    \ determining the maximum.\n"
- title: 6.3.  Additional Considerations
  contents:
  - "6.3.  Additional Considerations\n   There may be other details provided in a\
    \ ULB.\n   o  An ULB may recommend inline threshold values or other transport-\n\
    \      related parameters for RPC-over-RDMA version 1 connections bearing\n  \
    \    that ULP.\n   o  An ULP may provide a means to communicate these transport-related\n\
    \      parameters between peers.  Note that RPC-over-RDMA version 1 does\n   \
    \   not specify any mechanism for changing any transport-related\n      parameter\
    \ after a connection has been established.\n   o  Multiple ULPs may share a single\
    \ RPC-over-RDMA version 1\n      connection when their ULBs allow the use of RPC-over-RDMA\
    \ version\n      1 and the rpcbind port assignments for the Protocols allow\n\
    \      connection sharing.  In this case, the same transport parameters\n    \
    \  (such as inline threshold) apply to all Protocols using that\n      connection.\n\
    \   Each ULB needs to be designed to allow correct interoperation without\n  \
    \ regard to the transport parameters actually in use.  Furthermore,\n   implementations\
    \ of ULPs must be designed to interoperate correctly\n   regardless of the connection\
    \ parameters in effect on a connection.\n"
- title: 6.4.  ULP Extensions
  contents:
  - "6.4.  ULP Extensions\n   An RPC Program and Version tuple may be extensible.\
    \  For instance,\n   there may be a minor versioning scheme that is not reflected\
    \ in the\n   RPC version number, or the ULP may allow additional features to be\n\
    \   specified after the original RPC Program specification was ratified.\n   ULBs\
    \ are provided for interoperable RPC Programs and Versions by\n   extending existing\
    \ ULBs to reflect the changes made necessary by each\n   addition to the existing\
    \ XDR.\n"
- title: 7.  Protocol Extensibility
  contents:
  - "7.  Protocol Extensibility\n   The RPC-over-RDMA header format is specified using\
    \ XDR, unlike the\n   message header used with RPC-over-TCP.  To maintain a high\
    \ degree of\n   interoperability among implementations of RPC-over-RDMA, any change\n\
    \   to this XDR requires a protocol version number change.  New versions\n   of\
    \ RPC-over-RDMA may be published as separate protocol specifications\n   without\
    \ updating this document.\n   The first four fields in every RPC-over-RDMA header\
    \ must remain\n   aligned at the same fixed offsets for all versions of the RPC-over-\n\
    \   RDMA protocol.  The version number must be in a fixed place to enable\n  \
    \ implementations to detect protocol version mismatches.\n   For version mismatches\
    \ to be reported in a fashion that all future\n   version implementations can\
    \ reliably decode, the rdma_proc field must\n   remain in a fixed place, the value\
    \ of ERR_VERS must always remain the\n   same, and the field placement in struct\
    \ rpc_rdma_errvers must always\n   remain the same.\n"
- title: 7.1.  Conventional Extensions
  contents:
  - "7.1.  Conventional Extensions\n   Introducing new capabilities to RPC-over-RDMA\
    \ version 1 is limited to\n   the adoption of conventions that make use of existing\
    \ XDR (defined in\n   this document) and allowed abstract RDMA operations.  Because\
    \ no\n   mechanism for detecting optional features exists in RPC-over-RDMA\n \
    \  version 1, implementations must rely on ULPs to communicate the\n   existence\
    \ of such extensions.\n   Such extensions must be specified in a Standards Track\
    \ RFC with\n   appropriate review by the NFSv4 Working Group and the IESG.  An\n\
    \   example of a conventional extension to RPC-over-RDMA version 1 is the\n  \
    \ specification of backward direction message support to enable NFSv4.1\n   callback\
    \ operations, described in [RFC8167].\n"
- title: 8.  Security Considerations
  contents:
  - '8.  Security Considerations

    '
- title: 8.1.  Memory Protection
  contents:
  - "8.1.  Memory Protection\n   A primary consideration is the protection of the\
    \ integrity and\n   confidentiality of local memory by an RPC-over-RDMA transport.\
    \  The\n   use of an RPC-over-RDMA transport protocol MUST NOT introduce\n   vulnerabilities\
    \ to system memory contents nor to memory owned by user\n   processes.\n   It\
    \ is REQUIRED that any RDMA provider used for RPC transport be\n   conformant\
    \ to the requirements of [RFC5042] in order to satisfy these\n   protections.\
    \  These protections are provided by the RDMA layer\n   specifications, and in\
    \ particular, their security models.\n"
- title: 8.1.1.  Protection Domains
  contents:
  - "8.1.1.  Protection Domains\n   The use of Protection Domains to limit the exposure\
    \ of memory regions\n   to a single connection is critical.  Any attempt by an\
    \ endpoint not\n   participating in that connection to reuse memory handles needs\
    \ to\n   result in immediate failure of that connection.  Because ULP security\n\
    \   mechanisms rely on this aspect of Reliable Connection behavior,\n   strong\
    \ authentication of remote endpoints is recommended.\n"
- title: 8.1.2.  Handle Predictability
  contents:
  - "8.1.2.  Handle Predictability\n   Unpredictable memory handles should be used\
    \ for any operation\n   requiring advertised memory regions.  Advertising a continuously\n\
    \   registered memory region allows a remote host to read or write to\n   that\
    \ region even when an RPC involving that memory is not under way.\n   Therefore,\
    \ implementations should avoid advertising persistently\n   registered memory.\n"
- title: 8.1.3.  Memory Protection
  contents:
  - "8.1.3.  Memory Protection\n   Requesters should register memory regions for remote\
    \ access only when\n   they are about to be the target of an RPC operation that\
    \ involves an\n   RDMA Read or Write.\n   Registered memory regions should be\
    \ invalidated as soon as related\n   RPC operations are complete.  Invalidation\
    \ and DMA unmapping of\n   memory regions should be complete before message integrity\
    \ checking\n   is done and before the RPC consumer is allowed to continue execution\n\
    \   and use or alter the contents of a memory region.\n   An RPC transaction on\
    \ a Requester might be terminated before a reply\n   arrives if the RPC consumer\
    \ exits unexpectedly (for example, it is\n   signaled or a segmentation fault\
    \ occurs).  When an RPC terminates\n   abnormally, memory regions associated with\
    \ that RPC should be\n   invalidated appropriately before the regions are released\
    \ to be\n   reused for other purposes on the Requester.\n"
- title: 8.1.4.  Denial of Service
  contents:
  - "8.1.4.  Denial of Service\n   A detailed discussion of denial-of-service exposures\
    \ that can result\n   from the use of an RDMA transport is found in Section 6.4\
    \ of\n   [RFC5042].\n   A Responder is not obliged to pull Read chunks that are\
    \ unreasonably\n   large.  The Responder can use an RDMA_ERROR response to terminate\n\
    \   RPCs with unreadable Read chunks.  If a Responder transmits more data\n  \
    \ than a Requester is prepared to receive in a Write or Reply chunk,\n   the RDMA\
    \ Network Interface Cards (RNICs) typically terminate the\n   connection.  For\
    \ further discussion, see Section 4.5.  Such repeated\n   chunk errors can deny\
    \ service to other users sharing the connection\n   from the errant Requester.\n\
    \   An RPC-over-RDMA transport implementation is not responsible for\n   throttling\
    \ the RPC request rate, other than to keep the number of\n   concurrent RPC transactions\
    \ at or under the number of credits granted\n   per connection.  This is explained\
    \ in Section 3.3.1.  A sender can\n   trigger a self denial of service by exceeding\
    \ the credit grant\n   repeatedly.\n   When an RPC has been canceled due to a\
    \ signal or premature exit of an\n   application process, a Requester may invalidate\
    \ the RPC's Write and\n   Reply chunks.  Invalidation prevents the subsequent\
    \ arrival of the\n   Responder's reply from altering the memory regions associated\
    \ with\n   those chunks after the memory has been reused.\n   On the Requester,\
    \ a malfunctioning application or a malicious user\n   can create a situation\
    \ where RPCs are continuously initiated and then\n   aborted, resulting in Responder\
    \ replies that terminate the underlying\n   RPC-over-RDMA connection repeatedly.\
    \  Such situations can deny\n   service to other users sharing the connection\
    \ from that Requester.\n"
- title: 8.2.  RPC Message Security
  contents:
  - "8.2.  RPC Message Security\n   ONC RPC provides cryptographic security via the\
    \ RPCSEC_GSS framework\n   [RFC7861].  RPCSEC_GSS implements message authentication\n\
    \   (rpc_gss_svc_none), per-message integrity checking\n   (rpc_gss_svc_integrity),\
    \ and per-message confidentiality\n   (rpc_gss_svc_privacy) in the layer above\
    \ RPC-over-RDMA.  The latter\n   two services require significant computation\
    \ and movement of data on\n   each endpoint host.  Some performance benefits enabled\
    \ by RDMA\n   transports can be lost.\n"
- title: 8.2.1.  RPC-over-RDMA Protection at Lower Layers
  contents:
  - "8.2.1.  RPC-over-RDMA Protection at Lower Layers\n   For any RPC transport, utilizing\
    \ RPCSEC_GSS integrity or privacy\n   services has performance implications. \
    \ Protection below the RPC\n   transport is often more appropriate in performance-sensitive\n\
    \   deployments, especially if it, too, can be offloaded.  Certain\n   configurations\
    \ of IPsec can be co-located in RDMA hardware, for\n   example, without change\
    \ to RDMA consumers and little loss of data\n   movement efficiency.  Such arrangements\
    \ can also provide a higher\n   degree of privacy by hiding endpoint identity\
    \ or altering the\n   frequency at which messages are exchanged, at a performance\
    \ cost.\n   The use of protection in a lower layer MAY be negotiated through the\n\
    \   use of an RPCSEC_GSS security flavor defined in [RFC7861] in\n   conjunction\
    \ with the Channel Binding mechanism [RFC5056] and IPsec\n   Channel Connection\
    \ Latching [RFC5660].  Use of such mechanisms is\n   REQUIRED where integrity\
    \ or confidentiality is desired and where\n   efficiency is required.\n"
- title: 8.2.2.  RPCSEC_GSS on RPC-over-RDMA Transports
  contents:
  - "8.2.2.  RPCSEC_GSS on RPC-over-RDMA Transports\n   Not all RDMA devices and fabrics\
    \ support the above protection\n   mechanisms.  Also, per-message authentication\
    \ is still required on\n   NFS clients where multiple users access NFS files.\
    \  In these cases,\n   RPCSEC_GSS can protect NFS traffic conveyed on RPC-over-RDMA\n\
    \   connections.\n   RPCSEC_GSS extends the ONC RPC protocol [RFC5531] without\
    \ changing\n   the format of RPC messages.  By observing the conventions described\n\
    \   in this section, an RPC-over-RDMA transport can convey RPCSEC_GSS-\n   protected\
    \ RPC messages interoperably.\n   As part of the ONC RPC protocol, protocol elements\
    \ of RPCSEC_GSS that\n   appear in the Payload stream of an RPC-over-RDMA message\
    \ (such as\n   control messages exchanged as part of establishing or destroying\
    \ a\n   security context or data items that are part of RPCSEC_GSS\n   authentication\
    \ material) MUST NOT be reduced.\n"
- title: 8.2.2.1.  RPCSEC_GSS Context Negotiation
  contents:
  - "8.2.2.1.  RPCSEC_GSS Context Negotiation\n   Some NFS client implementations\
    \ use a separate connection to\n   establish a Generic Security Service (GSS)\
    \ context for NFS operation.\n   These clients use TCP and the standard NFS port\
    \ (2049) for context\n   establishment.  To enable the use of RPCSEC_GSS with\
    \ NFS/RDMA, an NFS\n   server MUST also provide a TCP-based NFS service on port\
    \ 2049.\n"
- title: 8.2.2.2.  RPC-over-RDMA with RPCSEC_GSS Authentication
  contents:
  - "8.2.2.2.  RPC-over-RDMA with RPCSEC_GSS Authentication\n   The RPCSEC_GSS authentication\
    \ service has no impact on the DDP-\n   eligibility of data items in a ULP.\n\
    \   However, RPCSEC_GSS authentication material appearing in an RPC\n   message\
    \ header can be larger than, say, an AUTH_SYS authenticator.\n   In particular,\
    \ when an RPCSEC_GSS pseudoflavor is in use, a Requester\n   needs to accommodate\
    \ a larger RPC credential when marshaling RPC Call\n   messages and needs to provide\
    \ for a maximum size RPCSEC_GSS verifier\n   when allocating reply buffers and\
    \ Reply chunks.\n   RPC messages, and thus Payload streams, are made larger as\
    \ a result.\n   ULP operations that fit in a Short Message when a simpler form\
    \ of\n   authentication is in use might need to be reduced, or conveyed via a\n\
    \   Long Message, when RPCSEC_GSS authentication is in use.  It is more\n   likely\
    \ that a Requester provides both a Read list and a Reply chunk\n   in the same\
    \ RPC-over-RDMA header to convey a Long Call and provision\n   a receptacle for\
    \ a Long Reply.  More frequent use of Long Messages\n   can impact transport efficiency.\n"
- title: 8.2.2.3.  RPC-over-RDMA with RPCSEC_GSS Integrity or Privacy
  contents:
  - "8.2.2.3.  RPC-over-RDMA with RPCSEC_GSS Integrity or Privacy\n   The RPCSEC_GSS\
    \ integrity service enables endpoints to detect\n   modification of RPC messages\
    \ in flight.  The RPCSEC_GSS privacy\n   service prevents all but the intended\
    \ recipient from viewing the\n   cleartext content of RPC arguments and results.\
    \  RPCSEC_GSS integrity\n   and privacy services are end-to-end.  They protect\
    \ RPC arguments and\n   results from application to server endpoint, and back.\n\
    \   The RPCSEC_GSS integrity and encryption services operate on whole RPC\n  \
    \ messages after they have been XDR encoded for transmit, and before\n   they\
    \ have been XDR decoded after receipt.  Both sender and receiver\n   endpoints\
    \ use intermediate buffers to prevent exposure of encrypted\n   data or unverified\
    \ cleartext data to RPC consumers.  After\n   verification, encryption, and message\
    \ wrapping has been performed,\n   the transport layer MAY use RDMA data transfer\
    \ between these\n   intermediate buffers.\n   The process of reducing a DDP-eligible\
    \ data item removes the data\n   item and its XDR padding from the encoded XDR\
    \ stream.  XDR padding of\n   a reduced data item is not transferred in an RPC-over-RDMA\
    \ message.\n   After reduction, the Payload stream contains fewer octets than\
    \ the\n   whole XDR stream did beforehand.  XDR padding octets are often zero\n\
    \   bytes, but they don't have to be.  Thus, reducing DDP-eligible items\n   affects\
    \ the result of message integrity verification or encryption.\n   Therefore, a\
    \ sender MUST NOT reduce a Payload stream when RPCSEC_GSS\n   integrity or encryption\
    \ services are in use.  Effectively, no data\n   item is DDP-eligible in this\
    \ situation, and Chunked Messages cannot\n   be used.  In this mode, an RPC-over-RDMA\
    \ transport operates in the\n   same manner as a transport that does not support\
    \ DDP.\n   When an RPCSEC_GSS integrity or privacy service is in use, a\n   Requester\
    \ provides both a Read list and a Reply chunk in the same\n   RPC-over-RDMA header\
    \ to convey a Long Call and provision a receptacle\n   for a Long Reply.\n"
- title: 8.2.2.4.  Protecting RPC-over-RDMA Transport Headers
  contents:
  - "8.2.2.4.  Protecting RPC-over-RDMA Transport Headers\n   Like the base fields\
    \ in an ONC RPC message (XID, call direction, and\n   so on), the contents of\
    \ an RPC-over-RDMA message's Transport stream\n   are not protected by RPCSEC_GSS.\
    \  This exposes XIDs, connection\n   credit limits, and chunk lists (but not the\
    \ content of the data items\n   they refer to) to malicious behavior, which could\
    \ redirect data that\n   is transferred by the RPC-over-RDMA message, result in\
    \ spurious\n   retransmits, or trigger connection loss.\n   In particular, if\
    \ an attacker alters the information contained in the\n   chunk lists of an RPC-over-RDMA\
    \ header, data contained in those\n   chunks can be redirected to other registered\
    \ memory regions on\n   Requesters.  An attacker might alter the arguments of\
    \ RDMA Read and\n   RDMA Write operations on the wire to similar effect.  If such\n\
    \   alterations occur, the use of RPCSEC_GSS integrity or privacy\n   services\
    \ enable a Requester to detect unexpected material in a\n   received RPC message.\n\
    \   Encryption at lower layers, as described in Section 8.2.1, protects\n   the\
    \ content of the Transport stream.  To address attacks on RDMA\n   protocols themselves,\
    \ RDMA transport implementations should conform\n   to [RFC5042].\n"
- title: 9.  IANA Considerations
  contents:
  - "9.  IANA Considerations\n   A set of RPC netids for resolving RPC-over-RDMA services\
    \ is specified\n   by this document.  This is unchanged from [RFC5666].\n   The\
    \ RPC-over-RDMA transport has been assigned an RPC netid, which is\n   an rpcbind\
    \ [RFC1833] string used to describe the underlying protocol\n   in order for RPC\
    \ to select the appropriate transport framing, as well\n   as the format of the\
    \ service addresses and ports.\n   The following netid registry strings are defined\
    \ for this purpose:\n      NC_RDMA \"rdma\"\n      NC_RDMA6 \"rdma6\"\n   The\
    \ \"rdma\" netid is to be used when IPv4 addressing is employed by\n   the underlying\
    \ transport, and \"rdma6\" for IPv6 addressing.  The netid\n   assignment policy\
    \ and registry are defined in [RFC5665].\n   These netids MAY be used for any\
    \ RDMA network that satisfies the\n   requirements of Section 2.3.2 and that is\
    \ able to identify service\n   endpoints using IP port addressing, possibly through\
    \ use of a\n   translation service as described in Section 5.\n   The use of the\
    \ RPC-over-RDMA protocol has no effect on RPC Program\n   numbers or existing\
    \ registered port numbers.  However, new port\n   numbers MAY be registered for\
    \ use by RPC-over-RDMA-enabled services,\n   as appropriate to the new networks\
    \ over which the services will\n   operate.\n   For example, the NFS/RDMA service\
    \ defined in [RFC5667] has been\n   assigned the port 20049 in the \"Service Name\
    \ and Transport Protocol\n   Port Number Registry\".  This is distinct from the\
    \ port number defined\n   for NFS on TCP, which is assigned the port 2049 in the\
    \ same registry.\n   NFS clients use the same RPC Program number for NFS (100003)\
    \ when\n   using either transport [RFC5531] (see the \"Remote Procedure Call\n\
    \   (RPC) Program Numbers\" registry).\n"
- title: 10.  References
  contents:
  - '10.  References

    '
- title: 10.1.  Normative References
  contents:
  - "10.1.  Normative References\n   [RFC1833]  Srinivasan, R., \"Binding Protocols\
    \ for ONC RPC Version 2\",\n              RFC 1833, DOI 10.17487/RFC1833, August\
    \ 1995,\n              <http://www.rfc-editor.org/info/rfc1833>.\n   [RFC2119]\
    \  Bradner, S., \"Key words for use in RFCs to Indicate\n              Requirement\
    \ Levels\", BCP 14, RFC 2119,\n              DOI 10.17487/RFC2119, March 1997,\n\
    \              <http://www.rfc-editor.org/info/rfc2119>.\n   [RFC4506]  Eisler,\
    \ M., Ed., \"XDR: External Data Representation\n              Standard\", STD\
    \ 67, RFC 4506, DOI 10.17487/RFC4506, May\n              2006, <http://www.rfc-editor.org/info/rfc4506>.\n\
    \   [RFC5042]  Pinkerton, J. and E. Deleganes, \"Direct Data Placement\n     \
    \         Protocol (DDP) / Remote Direct Memory Access Protocol\n            \
    \  (RDMAP) Security\", RFC 5042, DOI 10.17487/RFC5042, October\n             \
    \ 2007, <http://www.rfc-editor.org/info/rfc5042>.\n   [RFC5056]  Williams, N.,\
    \ \"On the Use of Channel Bindings to Secure\n              Channels\", RFC 5056,\
    \ DOI 10.17487/RFC5056, November 2007,\n              <http://www.rfc-editor.org/info/rfc5056>.\n\
    \   [RFC5531]  Thurlow, R., \"RPC: Remote Procedure Call Protocol\n          \
    \    Specification Version 2\", RFC 5531, DOI 10.17487/RFC5531,\n            \
    \  May 2009, <http://www.rfc-editor.org/info/rfc5531>.\n   [RFC5660]  Williams,\
    \ N., \"IPsec Channels: Connection Latching\",\n              RFC 5660, DOI 10.17487/RFC5660,\
    \ October 2009,\n              <http://www.rfc-editor.org/info/rfc5660>.\n   [RFC5665]\
    \  Eisler, M., \"IANA Considerations for Remote Procedure Call\n             \
    \ (RPC) Network Identifiers and Universal Address Formats\",\n              RFC\
    \ 5665, DOI 10.17487/RFC5665, January 2010,\n              <http://www.rfc-editor.org/info/rfc5665>.\n\
    \   [RFC7861]  Adamson, A. and N. Williams, \"Remote Procedure Call (RPC)\n  \
    \            Security Version 3\", RFC 7861, DOI 10.17487/RFC7861,\n         \
    \     November 2016, <http://www.rfc-editor.org/info/rfc7861>.\n   [RFC8174] \
    \ Leiba, B., \"Ambiguity of Uppercase vs Lowercase in RFC\n              2119\
    \ Key Words\", BCP 14, RFC 8174, DOI 10.17487/RFC8174,\n              May 2017,\
    \ <http://www.rfc-editor.org/info/rfc8174>.\n"
- title: 10.2.  Informative References
  contents:
  - "10.2.  Informative References\n   [IBARCH]   InfiniBand Trade Association, \"\
    InfiniBand Architecture\n              Specification Volume 1\", Release 1.3,\
    \ March 2015,\n              <http://www.infinibandta.org/content/\n         \
    \     pages.php?pg=technology_download>.\n   [RFC768]   Postel, J., \"User Datagram\
    \ Protocol\", STD 6, RFC 768,\n              DOI 10.17487/RFC0768, August 1980,\n\
    \              <http://www.rfc-editor.org/info/rfc768>.\n   [RFC793]   Postel,\
    \ J., \"Transmission Control Protocol\", STD 7,\n              RFC 793, DOI 10.17487/RFC0793,\
    \ September 1981,\n              <http://www.rfc-editor.org/info/rfc793>.\n  \
    \ [RFC1094]  Nowicki, B., \"NFS: Network File System Protocol\n              specification\"\
    , RFC 1094, DOI 10.17487/RFC1094, March\n              1989, <http://www.rfc-editor.org/info/rfc1094>.\n\
    \   [RFC1813]  Callaghan, B., Pawlowski, B., and P. Staubach, \"NFS\n        \
    \      Version 3 Protocol Specification\", RFC 1813,\n              DOI 10.17487/RFC1813,\
    \ June 1995,\n              <http://www.rfc-editor.org/info/rfc1813>.\n   [RFC5040]\
    \  Recio, R., Metzler, B., Culley, P., Hilland, J., and D.\n              Garcia,\
    \ \"A Remote Direct Memory Access Protocol\n              Specification\", RFC\
    \ 5040, DOI 10.17487/RFC5040, October\n              2007, <http://www.rfc-editor.org/info/rfc5040>.\n\
    \   [RFC5041]  Shah, H., Pinkerton, J., Recio, R., and P. Culley, \"Direct\n \
    \             Data Placement over Reliable Transports\", RFC 5041,\n         \
    \     DOI 10.17487/RFC5041, October 2007,\n              <http://www.rfc-editor.org/info/rfc5041>.\n\
    \   [RFC5532]  Talpey, T. and C. Juszczak, \"Network File System (NFS)\n     \
    \         Remote Direct Memory Access (RDMA) Problem Statement\",\n          \
    \    RFC 5532, DOI 10.17487/RFC5532, May 2009,\n              <http://www.rfc-editor.org/info/rfc5532>.\n\
    \   [RFC5661]  Shepler, S., Ed., Eisler, M., Ed., and D. Noveck, Ed.,\n      \
    \        \"Network File System (NFS) Version 4 Minor Version 1\n             \
    \ Protocol\", RFC 5661, DOI 10.17487/RFC5661, January 2010,\n              <http://www.rfc-editor.org/info/rfc5661>.\n\
    \   [RFC5662]  Shepler, S., Ed., Eisler, M., Ed., and D. Noveck, Ed.,\n      \
    \        \"Network File System (NFS) Version 4 Minor Version 1\n             \
    \ External Data Representation Standard (XDR) Description\",\n              RFC\
    \ 5662, DOI 10.17487/RFC5662, January 2010,\n              <http://www.rfc-editor.org/info/rfc5662>.\n\
    \   [RFC5666]  Talpey, T. and B. Callaghan, \"Remote Direct Memory Access\n  \
    \            Transport for Remote Procedure Call\", RFC 5666,\n              DOI\
    \ 10.17487/RFC5666, January 2010,\n              <http://www.rfc-editor.org/info/rfc5666>.\n\
    \   [RFC5667]  Talpey, T. and B. Callaghan, \"Network File System (NFS)\n    \
    \          Direct Data Placement\", RFC 5667, DOI 10.17487/RFC5667,\n        \
    \      January 2010, <http://www.rfc-editor.org/info/rfc5667>.\n   [RFC7530] \
    \ Haynes, T., Ed. and D. Noveck, Ed., \"Network File System\n              (NFS)\
    \ Version 4 Protocol\", RFC 7530, DOI 10.17487/RFC7530,\n              March 2015,\
    \ <http://www.rfc-editor.org/info/rfc7530>.\n   [RFC8167]  Lever, C., \"Bidirectional\
    \ Remote Procedure Call on RPC-\n              over-RDMA Transports\", RFC 8167,\
    \ DOI 10.17487/RFC8167,\n              June 2017, <http://www.rfc-editor.org/info/rfc8167>.\n"
- title: Appendix A.  Changes from RFC 5666
  contents:
  - 'Appendix A.  Changes from RFC 5666

    '
- title: A.1.  Changes to the Specification
  contents:
  - "A.1.  Changes to the Specification\n   The following alterations have been made\
    \ to the RPC-over-RDMA version\n   1 specification.  The section numbers below\
    \ refer to [RFC5666].\n   o  Section 2 has been expanded to introduce and explain\
    \ key RPC\n      [RFC5531], XDR [RFC4506], and RDMA [RFC5040] terminology.  These\n\
    \      terms are now used consistently throughout the specification.\n   o  Section\
    \ 3 has been reorganized and split into subsections to help\n      readers locate\
    \ specific requirements and definitions.\n   o  Sections 4 and 5 have been combined\
    \ to improve the organization of\n      this information.\n   o  The optional\
    \ Connection Configuration Protocol has never been\n      implemented.  The specification\
    \ of CCP has been deleted from this\n      specification.\n   o  A section consolidating\
    \ requirements for ULBs has been added.\n   o  An XDR extraction mechanism is\
    \ provided, along with full\n      copyright, matching the approach used in [RFC5662].\n\
    \   o  The \"Security Considerations\" section has been expanded to include\n\
    \      a discussion of how RPC-over-RDMA security depends on features of\n   \
    \   the underlying RDMA transport.\n   o  A subsection describing the use of RPCSEC_GSS\
    \ [RFC7861] with RPC-\n      over-RDMA version 1 has been added.\n"
- title: A.2.  Changes to the Protocol
  contents:
  - "A.2.  Changes to the Protocol\n   Although the protocol described herein interoperates\
    \ with existing\n   implementations of [RFC5666], the following changes have been\
    \ made\n   relative to the protocol described in that document:\n   o  Support\
    \ for the Read-Read transfer model has been removed.  Read-\n      Read is a slower\
    \ transfer model than Read-Write.  As a result,\n      implementers have chosen\
    \ not to support it.  Removal of Read-Read\n      simplifies explanatory text,\
    \ and the RDMA_DONE procedure is no\n      longer part of the protocol.\n   o\
    \  The specification of RDMA_MSGP in [RFC5666] is not adequate,\n      although\
    \ some incomplete implementations exist.  Even if an\n      adequate specification\
    \ were provided and an implementation were\n      produced, benefit for protocols\
    \ such as NFSv4.0 [RFC7530] is\n      doubtful.  Therefore, the RDMA_MSGP message\
    \ type is no longer\n      supported.\n   o  Technical issues with regard to handling\
    \ RPC-over-RDMA header\n      errors have been corrected.\n   o  Specific requirements\
    \ related to implicit XDR roundup and complex\n      XDR data types have been\
    \ added.\n   o  Explicit guidance is provided related to sizing Write chunks,\n\
    \      managing multiple chunks in the Write list, and handling unused\n     \
    \ Write chunks.\n   o  Clear guidance about Send and Receive buffer sizes has\
    \ been\n      introduced.  This enables better decisions about when a Reply\n\
    \      chunk must be provided.\n"
- title: Acknowledgments
  contents:
  - "Acknowledgments\n   The editor gratefully acknowledges the work of Brent Callaghan\
    \ and\n   Tom Talpey on the original RPC-over-RDMA Version 1 specification\n \
    \  [RFC5666].\n   Dave Noveck provided excellent review, constructive suggestions,\
    \ and\n   consistent navigational guidance throughout the process of drafting\n\
    \   this document.  Dave also contributed much of the organization and\n   content\
    \ of Section 7 and helped the authors understand the\n   complexities of XDR extensibility.\n\
    \   The comments and contributions of Karen Deitke, Dai Ngo, Chunli\n   Zhang,\
    \ Dominique Martinet, and Mahesh Siddheshwar are accepted with\n   great thanks.\
    \  The editor also wishes to thank Bill Baker, Greg\n   Marsden, and Matt Benjamin\
    \ for their support of this work.\n   The extract.sh shell script and formatting\
    \ conventions were first\n   described by the authors of the NFSv4.1 XDR specification\
    \ [RFC5662].\n   Special thanks go to Transport Area Director Spencer Dawkins,\
    \ NFSV4\n   Working Group Chair and Document Shepherd Spencer Shepler, and NFSV4\n\
    \   Working Group Secretary Thomas Haynes for their support.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Charles Lever (editor)\n   Oracle Corporation\n   1015\
    \ Granger Avenue\n   Ann Arbor, MI  48104\n   United States of America\n   Phone:\
    \ +1 248 816 6463\n   Email: chuck.lever@oracle.com\n   William Allen Simpson\n\
    \   Red Hat\n   1384 Fontaine\n   Madison Heights, MI  48071\n   United States\
    \ of America\n   Email: william.allen.simpson@gmail.com\n   Tom Talpey\n   Microsoft\
    \ Corp.\n   One Microsoft Way\n   Redmond, WA  98052\n   United States of America\n\
    \   Phone: +1 425 704-9945\n   Email: ttalpey@microsoft.com\n"
