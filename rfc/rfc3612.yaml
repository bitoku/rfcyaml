- title: __initial_text__
  contents:
  - "            Applicability Statement for Restart Mechanisms\n               for\
    \ the Label Distribution Protocol (LDP)\n"
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2003).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document provides guidance on when it is advisable to implement\n\
    \   some form of Label Distribution Protocol (LDP) restart mechanism and\n   which\
    \ approach might be more suitable.  The issues and extensions\n   described in\
    \ this document are equally applicable to RFC 3212,\n   \"Constraint-Based LSP\
    \ Setup Using LDP\".\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Multiprotocol Label Switching (MPLS) systems are used in\
    \ core\n   networks where system downtime must be kept to a minimum.  Similarly,\n\
    \   where MPLS is at the network edges (e.g., in Provider Edge (PE)\n   routers)\
    \ [RFC2547], system downtime must also be kept to a minimum.\n   Many MPLS Label\
    \ Switching Routers (LSRs) may, therefore, exploit\n   Fault Tolerant (FT) hardware\
    \ or software to provide high availability\n   of the core networks.\n   The details\
    \ of how FT is achieved for the various components of an FT\n   LSR, including\
    \ the switching hardware and the TCP stack, are\n   implementation specific. \
    \ How the software module itself chooses to\n   implement FT for the state created\
    \ by the LDP is also implementation\n   specific.  However, there are several\
    \ issues in the LDP specification\n   [RFC3036] that make it difficult to implement\
    \ an FT LSR using the LDP\n   protocols without some extensions to those protocols.\n\
    \   Proposals have been made in [RFC3478] and [RFC3479] to address these\n   issues.\n"
- title: 2.  Requirements of an LDP FT System
  contents:
  - "2.  Requirements of an LDP FT System\n   Many MPLS LSRs may exploit FT hardware\
    \ or software to provide high\n   availability (HA) of core networks.  In order\
    \ to provide HA, an MPLS\n   system needs to be able to survive a variety of faults\
    \ with minimal\n   disruption to the Data Plane, including the following fault\
    \ types:\n   -  failure/hot-swap of the switching fabric in an LSR,\n   -  failure/hot-swap\
    \ of a physical connection between LSRs,\n   -  failure of the TCP or LDP stack\
    \ in an LSR,\n   -  software upgrade to the TCP or LDP stacks in an LSR.\n   The\
    \ first two examples of faults listed above may be confined to the\n   Data Plane.\
    \  Such faults can be handled by providing redundancy in\n   the Data Plane which\
    \ is transparent to LDP operating in the Control\n   Plane.  However, the failure\
    \ of the switching fabric or a physical\n   link may have repercussions in the\
    \ Control Plane since signaling may\n   be disrupted.\n   The third example may\
    \ be caused by a variety of events including\n   processor or other hardware failure,\
    \ and software failure.\n   Any of the last three examples may impact the Control\
    \ Plane and will\n   require action in the Control Plane to recover.  Such action\
    \ should\n   be designed to avoid disrupting traffic in the Data Plane.  Since\n\
    \   many recent router architectures can separate the Control and Data\n   Planes,\
    \ it is possible that forwarding can continue unaffected by\n   recovery action\
    \ in the Control Plane.\n   In other scenarios, the Data and Control Planes may\
    \ be impacted by a\n   fault, but the needs of HA require the coordinated recovery\
    \ of the\n   Data and Control Planes to a state that existed before the fault.\n\
    \   The provision of protection paths for MPLS LSP and the protection of\n   links,\
    \ IP routes or tunnels through the use of protection LSPs is\n   outside the scope\
    \ of this document.  See [RFC3469] for further\n   information.\n"
- title: 3.  General Considerations
  contents:
  - "3.  General Considerations\n   In order for the Data and Control Plane states\
    \ to be successfully\n   recovered after a fault, procedures are required to ensure\
    \ that the\n   state held on a pair of LDP peers (at least one of which was affected\n\
    \   directly by the fault) are synchronized.  Such procedures must be\n   implemented\
    \ in the Control Plane software modules on the peers using\n   Control Plane protocols.\n\
    \   The required actions may operate fully after the failure (reactive\n   recovery)\
    \ or may contain elements that operate before the fault in\n   order to minimize\
    \ the actions taken after the fault (proactive\n   recovery).  It is rare to implement\
    \ actions that operate solely in\n   advance of the failure and do not require\
    \ any further processing\n   after the failure (preventive recovery) - this is\
    \ because of the\n   dynamic nature of signaling protocols and the unpredictability\
    \ of\n   fault timing.\n   Reactive recovery actions may include full re-signaling\
    \ of state and\n   re-synchronization of state between peers and synchronization\
    \ based\n   on checkpointing.\n   Proactive recovery actions may include hand-shaking\
    \ state transitions\n   and checkpointing.\n"
- title: 4.  Specific Issues with the LDP Protocol
  contents:
  - "4.  Specific Issues with the LDP Protocol\n   LDP uses TCP to provide reliable\
    \ connections between LSRs to exchange\n   protocol messages to distribute labels\
    \ and to set up LSPs.  A pair of\n   LSRs that have such a connection are referred\
    \ to as LDP peers.\n   TCP enables LDP to assume reliable transfer of protocol\
    \ messages.\n   This means that some of the messages do not need to be acknowledged\n\
    \   (e.g., Label Release).\n   LDP is defined such that if the TCP connection\
    \ fails, the LSR should\n   immediately tear down the LSPs associated with the\
    \ session between\n   the LDP peers, and release any labels and resources assigned\
    \ to those\n   LSPs.\n   It is notoriously difficult to provide a Fault Tolerant\n\
    \   implementation of TCP.  To do so might involve making copies of all\n   data\
    \ sent and received.  This is an issue familiar to implementers of\n   other TCP\
    \ applications, such as BGP.\n   During failover affecting the TCP or LDP stacks,\
    \ therefore, the TCP\n   connection may be lost.  Recovery from this position\
    \ is made worse by\n   the fact that LDP control messages may have been lost during\
    \ the\n   connection failure.  Since these messages are unconfirmed, it is\n \
    \  possible that LSP or label state information will be lost.\n   At the very\
    \ least, the solution to this problem must include a change\n   to the basic requirements\
    \ of LDP so that the failure of an LDP\n   session does not require that associated\
    \ LDP or forwarding state be\n   torn down.\n   Any changes made to LDP in support\
    \ of recovery processing must meet\n   the following requirements:\n   -  offer\
    \ backward-compatibility with LSRs that do not implement the\n      extensions\
    \ to LDP,\n   -  preserve existing protocol rules described in [RFC3036] for\n\
    \      handling unexpected duplicate messages and for processing\n      unexpected\
    \ messages referring to unknown LSPs/labels.\n   Ideally, any solution applicable\
    \ to LDP should be equally applicable\n   to CR-LDP.\n"
- title: 5.  Summary of the Features of LDP FT
  contents:
  - "5.  Summary of the Features of LDP FT\n   LDP Fault Tolerance extensions are\
    \ described in [RFC3479].  This\n   approach involves:\n   -  negotiation between\
    \ LDP peers of the intent to support extensions\n      to LDP that facilitate\
    \ recovery from failover without loss of\n      LSPs,\n   -  selection of FT survival\
    \ on a per LSP/label basis or for all\n      labels on a session,\n   -  sequence\
    \ numbering of LDP messages to facilitate acknowledgement\n      and checkpointing,\n\
    \   -  acknowledgement of LDP messages to ensure that a full handshake is\n  \
    \    performed on those messages either frequently (such as per\n      message)\
    \ or less frequently as in checkpointing,\n   -  solicitation of up-to-date acknowledgement\
    \ (checkpointing) of\n      previous LDP messages to ensure the current state\
    \ is secured, with\n      an additional option that allows an LDP partner to request\
    \ that\n      state is flushed in both directions if graceful shutdown is\n  \
    \    required,\n   -  a timer to control how long LDP and forwarding state should\
    \ be\n      retained after the LDP session failure, but before being discarded\n\
    \      if LDP communications are not re-established,\n   -  exchange of checkpointing\
    \ information on LDP session recovery to\n      establish what state has been\
    \ retained by recovering LDP peers,\n   -  re-issuing lost messages after failover\
    \ to ensure that LSP/label\n      state is correctly recovered after reconnection\
    \ of the LDP\n      session.\n   The FT procedures in [RFC3479] concentrate on\
    \ the preservation of\n   label state for labels exchanged between a pair of adjacent\
    \ LSRs when\n   the TCP connection between those LSRs is lost.  There is no intention\n\
    \   within these procedures to support end-to-end protection for LSPs.\n"
- title: 6.  Summary of the Features of LDP Graceful Restart
  contents:
  - "6.  Summary of the Features of LDP Graceful Restart\n   LDP graceful restart\
    \ extensions are defined in [RFC3478].  This\n   approach involves:\n   -  negotiation\
    \ between LDP peers of the intent to support extensions\n      to LDP that facilitate\
    \ recovery from failover without loss of\n      LSPs,\n   -  a mechanism whereby\
    \ an LSR that restarts can relearn LDP state by\n      resynchronization with\
    \ its peers,\n   -  use of the same mechanism to allow LSRs recovering from an\
    \ LDP\n      session failure to resynchronize LDP state with their peers\n   \
    \   provided that at least one of the LSRs has retained state across\n      the\
    \ failure or has itself resynchronized state with its peers,\n   -  a timer to\
    \ control how long LDP and forwarding state should be\n      retained after the\
    \ LDP session failure, but before being discarded\n      if LDP communications\
    \ are not re-established,\n   -  a timer to control the length of the resynchronization\
    \ period\n      between adjacent peers should be completed.\n   The procedures\
    \ in [RFC3478] are applicable to all LSRs, both those\n   with the ability to\
    \ preserve forwarding state during LDP restart and\n   those without.  LSRs that\
    \ can not preserve their MPLS forwarding\n   state across the LDP restart would\
    \ impact MPLS traffic during\n   restart.  However, by implementing a subset of\
    \ the mechanisms in\n   [RFC3478] they can minimize the impact if their neighbor(s)\
    \ are\n   capable of preserving their forwarding state across the restart of\n\
    \   their LDP sessions or control planes by implementing the mechanism in\n  \
    \ [RFC3478].\n"
- title: 7.  Applicability Considerations
  contents:
  - "7.  Applicability Considerations\n   This section considers the applicability\
    \ of fault tolerance schemes\n   within LDP networks and considers issues that\
    \ might lead to the\n   choice of one method or another.  Many of the points raised\
    \ below\n   should be viewed as implementation issues rather than specific\n \
    \  drawbacks of either solution.\n"
- title: 7.1.  General Applicability
  contents:
  - "7.1.  General Applicability\n   The procedures described in [RFC3478] and [RFC3479]\
    \ are intended to\n   cover two distinct scenarios.  In Session Failure, the LDP\
    \ peers at\n   the ends of a session remain active, but the session fails and\
    \ is\n   restarted.  Note that session failure does not imply failure of the\n\
    \   data channel even when using an in-band control channel.  In Node\n   Failure,\
    \ the session fails because one of the peers has been\n   restarted (or at least,\
    \ the LDP component of the node has been\n   restarted).  These two scenarios\
    \ have different implications for the\n   ease of retention of LDP state within\
    \ an individual LSR, and are\n   described in sections below.\n   These techniques\
    \ are only applicable in LDP networks where at least\n   one LSR has the capability\
    \ to retain LDP signaling state and the\n   associated forwarding state across\
    \ LDP session failure and recovery.\n   In [RFC3478], the LSRs retaining state\
    \ do not need to be adjacent to\n   the failed LSR or session.\n   If traffic\
    \ is not to be impacted, both LSRs at the ends of an LDP\n   session must at least\
    \ preserve forwarding state.  Preserving LDP\n   state is not a requirement to\
    \ preserve traffic.\n   [RFC3479] requires that the LSRs at both ends of the session\n\
    \   implement the procedures that it describes.  Thus, either traffic is\n   preserved\
    \ and recovery resynchronizes state, or no traffic is\n   preserved and the LSP\
    \ fails.\n   Further, to use the procedures of [RFC3479] to recover state on a\n\
    \   session, both LSRs must have a mechanism for maintaining some session\n  \
    \ state and a way of auditing the forwarding state and the\n   resynhcronized\
    \ control state.\n   [RFC3478] is scoped to support preservation of traffic if\
    \ both LSRs\n   implement the procedures that it describes.  Additionally, it\n\
    \   functions if only one LSR on the failed session supports retention of\n  \
    \ forwarding state, and implements the mechanisms in the document.  In\n   this\
    \ case, traffic will be impacted by the session failure, but the\n   forwarding\
    \ state will be recovered on session recovery.  Further, in\n   the event of simultaneous\
    \ failures, [RFC3478] is capable of\n   relearning and redistributing state across\
    \ multiple LSRs by combining\n   its mechanisms with the usual LDP message exchanges\
    \ of [RFC3036].\n"
- title: 7.2.  Session Failure
  contents:
  - "7.2.  Session Failure\n   In Session Failure, an LDP session between two peers\
    \ fails and is\n   restarted.  There is no restart of the LSRs at either end of\
    \ the\n   session and LDP continues to function on those nodes.\n   In these cases,\
    \ it is simple for LDP implementations to retain the\n   LDP state associated\
    \ with the failed session and to associate the\n   state with the new session\
    \ when it is established.  Housekeeping may\n   be applied to determine that the\
    \ failed session is not returning and\n   to release the old LDP state.  Both\
    \ [RFC3478] and [RFC3479] handle\n   this case.\n   Applicability of [RFC3478]\
    \ and [RFC3479] to the Session Failure\n   scenario should be considered with\
    \ respect to the availability of the\n   data plane.\n   In some cases the failure\
    \ of the LDP session may be independent of\n   any failure of the physical (or\
    \ virtual) link(s) between adjacent\n   peers; for example, it might represent\
    \ a failure of the TCP/IP stack.\n   In these cases, the data plane is not impacted\
    \ and both [RFC3478] and\n   [RFC3479] are applicable to preserve or restore LDP\
    \ state.\n   LDP signaling may also operate out of band; that is, it may use\n\
    \   different links from the data plane.  In this case, a failure of the\n   LDP\
    \ session may be a result of a failure of the control channel, but\n   there is\
    \ no implied failure of the data plane.  For this scenario\n   [RFC3478] and [RFC3479]\
    \ are both applicable to preserve or restore\n   LDP state.\n   In the case where\
    \ the failure of the LDP session also implies the\n   failure of the data plane,\
    \ it may be an implementation decision\n   whether LDP peers retain forwarding\
    \ state, and for how long.  In such\n   situations, if forwarding state is retained,\
    \ and if the LDP session\n   is re-established, both [RFC3478] and [RFC3479] are\
    \ applicable to\n   preserve or restore LDP state.\n   When the data plane has\
    \ been disrupted an objective of a recovery\n   implementation might be to restore\
    \ data traffic as quickly as\n   possible.\n"
- title: 7.3.  Controlled Session Failure
  contents:
  - "7.3.  Controlled Session Failure\n   In some circumstances, the LSRs may know\
    \ in advance that an LDP\n   session is going fail (e.g., perhaps a link is going\
    \ to be taken out\n   of service).\n   [RFC3036] includes provision for controlled\
    \ shutdown of a session.\n   [RFC3478] and [RFC3479] allow resynchronization of\
    \ LDP state upon\n   re-establishment of the session.\n   [RFC3479] offers the\
    \ facility to both checkpoint all LDP states\n   before the shut-down, and to\
    \ quiesce the session so that no new state\n   changes are attempted between the\
    \ checkpoint and the shut-down.  This\n   means that on recovery, resynchronization\
    \ is simple and fast.\n   [RFC3478] resynchronizes all state on recovery regardless\
    \ of the\n   nature of the shut-down.\n"
- title: 7.4.  Node Failure
  contents:
  - "7.4.  Node Failure\n   Node Failure describes events where a whole node is restarted\
    \ or\n   where the component responsible for LDP signaling is restarted.  Such\n\
    \   an event will be perceived by the LSR's peers as session failure, but\n  \
    \ the restarting node sees the restart as full re-initialization.\n   The basic\
    \ requirement is that the forwarding state is retained,\n   otherwise the data\
    \ plane will necessarily be interrupted.  If\n   forwarding state is not retained,\
    \ it may be relearned from the saved\n   control state in [RFC3479].  [RFC3478]\
    \ does not utilize or expect a\n   saved control state.  If a node restarts without\
    \ preserved forwarding\n   state it informs its neighbors, which immediately delete\
    \ all label-\n   FEC bindings previously received from the restarted node.\n \
    \  The ways to retain a forwarding and control state are numerous and\n   implementation\
    \ specific.  It is not the purpose of this document to\n   espouse one mechanism\
    \ or another, nor even to suggest how this might\n   be done.  If state has been\
    \ preserved across the restart,\n   synchronization with peers can be carried\
    \ out as though recovering\n   from Session Failure as in the previous section.\
    \  Both [RFC3478] and\n   [RFC3479] support this case.\n   How much control state\
    \ is retained is largely an implementation\n   choice, but [RFC3479] requires\
    \ that at least small amount of per-\n   session control state be retained.  [RFC3478]\
    \ does not require or\n   expect control state to be retained.\n   It is also\
    \ possible that the restarting LSR has not preserved any\n   state.  In this case,\
    \ [RFC3479] is of no help.  [RFC3478] however,\n   allows the restarting LSR to\
    \ relearn state from each adjacent peer\n   through the processes for resynchronizing\
    \ after Session Failure.\n   Further, in the event of simultaneous failure of\
    \ multiple adjacent\n   nodes, the nodes at the edge of the failure zone can recover\
    \ state\n   from their active neighbors and distribute it to the other recovering\n\
    \   LSRs without any failed LSR having to have saved state.\n"
- title: 7.5.  Controlled Node Failure
  contents:
  - "7.5.  Controlled Node Failure\n   In some cases (hardware repair, software upgrade,\
    \ etc.), node failure\n   may be predictable.  In these cases all sessions with\
    \ peers may be\n   shutdown and existing state retention may be enhanced by special\n\
    \   actions.\n   [RFC3479] checkpointing and quiesce may be applied to all sessions\
    \ so\n   that state is up-to-date.\n   As above, [RFC3478] does not require that\
    \ state is retained by the\n   restarting node, but can utilize it if it is.\n"
- title: 7.6.  Speed of Recovery
  contents:
  - "7.6.  Speed of Recovery\n   Speed of recovery is impacted by the amount of signaling\
    \ required.\n   If forwarding state is preserved on both LSRs on the failed session,\n\
    \   then the recovery time is constrained by the time to resynchronize\n   the\
    \ state between the two LSRs.\n   [RFC3479] may resynchronize very quickly.  In\
    \ a stable network, this\n   resolves to a handshake of a checkpoint.  At the\
    \ most,\n   resynchronization involves this handshake plus an exchange of\n  \
    \ messages to handle state changes since the checkpoint was taken.\n   Implementations\
    \ that support only the periodic checkpointing subset\n   of [RFC3479] are more\
    \ likely to have additional state to\n   resynchronize.\n   [RFC3478] must resynchronize\
    \ state for all label mappings that have\n   been retained.  At the same time,\
    \ resources that have been retained\n   by a restarting upstream LSR but are not\
    \ actually required, because\n   they have been released by the downstream LSR\
    \ (perhaps because it was\n   in the process of releasing the state), they must\
    \ be held for the\n   full resynchronization time to ensure that they are not\
    \ needed.\n   The impact of recovery time will vary according to the use of the\n\
    \   network.  Both [RFC3478] and [RFC3479] allow advertisement of new\n   labels\
    \ while resynchronization is in progress.  Issues to consider\n   are re-availability\
    \ of falsely retained resources and conflict\n   between retained label mappings\
    \ and newly advertised ones.  This may\n   cause incorrect forwarding of data\
    \ (since labels are advertised from\n   downstream), an LSR upstream of a failure\
    \ may continue to forward\n   data for one FEC on an old label while the recovering\
    \ downstream LSR\n   might re-assign that label to another FEC and advertise it.\
    \  For this\n   reason, restarting LSRs may choose to not advertise new labels\
    \ until\n   resynchronization with their peers has completed, or may decide to\n\
    \   use special techniques to cover the short period of overlap between\n   resynchronization\
    \ and new LSP setup.\n"
- title: 7.7.  Scalability
  contents:
  - "7.7.  Scalability\n   Scalability is largely the same issue as speed of recovery\
    \ and is\n   governed by the number of LSPs managed through the failed session(s).\n\
    \   Note that there are limits to how small the resynchronization time in\n  \
    \ [RFC3478] may be made given the capabilities of the LSRs, the\n   throughput\
    \ on the link between them, and the number of labels that\n   must be resynchronized.\n\
    \   Impact on normal operation should also be considered.\n   [RFC3479] requires\
    \ acknowledgement of all messages.  These\n   acknowledgements may be deferred\
    \ as for checkpointing described in\n   section 4, or may be frequent.  Although\
    \ acknowledgements can be\n   piggy-backed on other state messages, an option\
    \ for frequent\n   acknowledgement is to send a message solely for the purpose\
    \ of\n   acknowledging a state change message.  Such an implementation would\n\
    \   clearly be unwise in a busy network.\n   [RFC3478] has no impact on normal\
    \ operations.\n"
- title: 7.8.  Rate of Change of LDP State
  contents:
  - "7.8.  Rate of Change of LDP State\n   Some networks do not show a high degree\
    \ of change over time, such as\n   those using targeted LDP sessions; others change\
    \ the LDP forwarding\n   state frequently, perhaps reacting to changes in routing\
    \ information\n   on LDP discovery sessions.\n   Rate of change of LDP state exchanged\
    \ over an LDP session depends on\n   the application for which the LDP session\
    \ is being used.  LDP\n   sessions used for exchanging <FEC, label> bindings for\
    \ establishing\n   hop by hop LSPs will typically exchange state reacting to IGP\n\
    \   changes.  Such exchanges could be frequent.  On the other hand, LDP\n   sessions\
    \ established for exchanging MPLS Layer 2 VPN FECs will\n   typically exhibit\
    \ a smaller rate of state exchange.\n   In [RFC3479], two options exist.  The\
    \ first uses a frequent (up to\n   per-message) acknowledgement system which is\
    \ most likely to be\n   applicable in a more dynamic system where it is desirable\
    \ to preserve\n   the maximum amount of state over a failure to reduce the level\
    \ of\n   resynchronization required and to speed the recovery time.\n   The second\
    \ option in [RFC3479] uses a less-frequent acknowledgement\n   scheme known as\
    \ checkpointing.  This is particularly suitable to\n   networks where changes\
    \ are infrequent or bursty.\n   [RFC3478] resynchronizes all state on recovery\
    \ regardless of the rate\n   of change of the network before the failure.  This\
    \ consideration is\n   thus not relevant to the choice of [RFC3478].\n"
- title: 7.9.  Label Distribution Modes
  contents:
  - "7.9.  Label Distribution Modes\n   Both [RFC3478] and [RFC3479] are suitable\
    \ for use with Downstream\n   Unsolicited label distribution.\n   [RFC3478] describes\
    \ Downstream-On-Demand as an area for future study\n   and is therefore not applicable\
    \ for a network in which this label\n   distribution mode is used.  It is possible\
    \ that future examination of\n   this issue will reveal that once a label has\
    \ been distributed in\n   either distribution mode, it can be redistributed by\
    \ [RFC3478] upon\n   session recovery.\n   [RFC3479] is suitable for use in a\
    \ network that uses Downstream-On-\n   Demand label distribution.\n   In theory,\
    \ and according to [RFC3036], even in networks configured to\n   utilize Downstream\
    \ Unsolicited label distribution, there may be\n   occasions when the use of Downstream-On-Deman\
    \ distribution is\n   desirable.  The use of the Label Request message is not\
    \ prohibited in\n   a Downstream Unsolicited label distribution LDP network.\n\
    \   Opinion varies as to whether there is a practical requirement for the\n  \
    \ use of the Label Request message in a Downstream Unsolicited label\n   distribution\
    \ LDP network.  Current deployment experience suggests\n   that there is no requirement.\n"
- title: 7.10.  Implementation Complexity
  contents:
  - "7.10.  Implementation Complexity\n   Implementation complexity has consequences\
    \ for the implementer and\n   also for the deployer since complex software is\
    \ more error prone and\n   harder to manage.\n   [RFC3479] is a more complex solution\
    \ than [RFC3478].  In particular,\n   [RFC3478] does not require any modification\
    \ to the normal signaling\n   and processing of LDP state changing messages.\n\
    \   [RFC3479] implementations may be simplified by implementing only the\n   checkpointing\
    \ subset of the functionality.\n"
- title: 7.11.  Implementation Robustness
  contents:
  - "7.11.  Implementation Robustness\n   In addition to the implication for robustness\
    \ associated with\n   complexity of the solutions, consideration should be given\
    \ to the\n   effects of state preservation on robustness.\n   If state has become\
    \ incorrect for whatever reason, then state\n   preservation may retain incorrect\
    \ state.  In extreme cases, it may be\n   that the incorrect state is the cause\
    \ of the failure in which case\n   preserving that state would be inappropriate.\n\
    \   When state is preserved, the precise amount that is retained is an\n   implementation\
    \ issue.  The basic requirement is that forwarding state\n   is retained (to preserve\
    \ the data path) and that that state can be\n   accessed by the LDP software component.\n\
    \   In both solutions, if the forwarding state is incorrect and is\n   retained,\
    \ it will continue to be incorrect.  Both solutions have a\n   mechanism to housekeep\
    \ and free the unwanted state after\n   resynchronization is complete.  [RFC3478]\
    \ may be better at\n   eradicating incorrect forwarding state, because it replays\
    \ all\n   message exchanges that caused the state to be populated.\n   In [RFC3478],\
    \ no more data than the forwarding state needs to have\n   been saved by the recovering\
    \ node.  All LDP state may be relearned by\n   message exchanges with peers. \
    \ Whether those exchanges may cause the\n   same incorrect state to arise on the\
    \ recovering node is an obvious\n   concern.\n   In [RFC3479], the forwarding\
    \ state must be supplemented by a small\n   amount of state specific to the protocol\
    \ extensions.  LDP state may\n   be retained directly or reconstructed from the\
    \ forwarding state.  The\n   same issues apply when reconstructing state but are\
    \ mitigated by the\n   fact that this is likely a different code path.  Errors\
    \ in the\n   retained state specific to the protocol extensions will persist.\n"
- title: 7.12.  Interoperability and Backward Compatibility
  contents:
  - "7.12.  Interoperability and Backward Compatibility\n   It is important that new\
    \ additions to LDP interoperate with existing\n   implementations at least in\
    \ provision of the existing levels of\n   function.\n   Both [RFC3478] and [RFC3479]\
    \ do this through rules for handling the\n   absence of the FT optional negotiation\
    \ object during session\n   initialization.\n   Additionally, [RFC3478] is able\
    \ to perform limited recovery (i.e.,\n   redistribution of state) even when only\
    \ one of the participating LSRs\n   supports the procedures.  This may offer considerable\
    \ advantages in\n   interoperation with legacy implementations.\n"
- title: 7.13.  Interaction With Other Label Distribution Mechanisms
  contents:
  - "7.13.  Interaction With Other Label Distribution Mechanisms\n   Many LDP LSRs\
    \ also run other label distribution mechanisms.  These\n   include management\
    \ interfaces for configuration of static label\n   mappings, other distinct instances\
    \ of LDP, and other label\n   distribution protocols.  The last example includes\
    \ traffic\n   engineering label distribution protocol that are used to construct\n\
    \   tunnels through which LDP LSPs are established.\n   As with re-use of individual\
    \ labels by LDP within a restarting LDP\n   system, care must be taken to prevent\
    \ labels that need to be retained\n   by a restarting LDP session or protocol\
    \ component from being used by\n   another label distribution mechanism.  This\
    \ might compromise data\n   security, amongst other things.\n   It is a matter\
    \ for implementations to avoid this issue through the\n   use of techniques, such\
    \ as a common label management component or\n   segmented label spaces.\n"
- title: 7.14.  Applicability to CR-LDP
  contents:
  - "7.14.  Applicability to CR-LDP\n   CR-LDP [RFC3212] utilizes Downstream-On-Demand\
    \ label distribution.\n   [RFC3478] describes Downstream-On-Demand as an area\
    \ for future study\n   and is therefore not applicable for CR-LDP.  [RFC3479]\
    \ is suitable\n   for use in a network entirely based on CR-LDP or in one that\
    \ is mixed\n   between LDP and CR-LDP.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   This document is informational and introduces\
    \ no new security\n   concerns.\n   The security considerations pertaining to\
    \ the original LDP protocol\n   [RFC3036] remain relevant.\n   [RFC3478] introduces\
    \ the possibility of additional denial-of- service\n   attacks.  All of these\
    \ attacks may be countered by use of an\n   authentication scheme between LDP\
    \ peers, such as the MD5-based scheme\n   outlined in [LDP].\n   In MPLS, a data\
    \ mis-delivery security issue can arise if an LSR\n   continues to use labels\
    \ after expiration of the session that first\n   caused them to be used.  Both\
    \ [RFC3478] and [RFC3479] are open to\n   this issue.\n"
- title: 9.  Intellectual Property Statement
  contents:
  - "9.  Intellectual Property Statement\n   The IETF takes no position regarding\
    \ the validity or scope of any\n   intellectual property or other rights that\
    \ might be claimed to\n   pertain to the implementation or use of the technology\
    \ described in\n   this document or the extent to which any license under such\
    \ rights\n   might or might not be available; neither does it represent that it\n\
    \   has made any effort to identify any such rights.  Information on the\n   IETF's\
    \ procedures with respect to rights in standards-track and\n   standards-related\
    \ documentation can be found in BCP-11.  Copies of\n   claims of rights made available\
    \ for publication and any assurances of\n   licenses to be made available, or\
    \ the result of an attempt made to\n   obtain a general license or permission\
    \ for the use of such\n   proprietary rights by implementors or users of this\
    \ specification can\n   be obtained from the IETF Secretariat.\n   The IETF invites\
    \ any interested party to bring to its attention any\n   copyrights, patents or\
    \ patent applications, or other proprietary\n   rights which may cover technology\
    \ that may be required to practice\n   this standard.  Please address the information\
    \ to the IETF Executive\n   Director.\n"
- title: 10.  References
  contents:
  - '10.  References

    '
- title: 10.1.  Normative References
  contents:
  - "10.1.  Normative References\n   [RFC2026]    Bradner, S., \"The Internet Standards\
    \ Process -- Revision\n                3\", BCP 9, RFC 2026, October 1996.\n \
    \  [RFC2119]    Bradner, S., \"Key words for use in RFCs to Indicate\n       \
    \         Requirement Levels\", BCP 14, RFC 2119, March 1997.\n   [RFC3036]  \
    \  Andersson, L., Doolan, P., Feldman, N., Fredette, A. and\n                B.\
    \ Thomas, \"LDP Specification\", RFC 3036, January 2001.\n   [RFC3478]    Leelanivas,\
    \ M., Rekhter, Y. and R. Aggarwal, \"Graceful\n                Restart Mechanism\
    \ for LDP\", RFC 3478, February 2003.\n   [RFC3479]    Farrel, A., Editor, \"\
    Fault Tolerance for the Label\n                Distribution Protocol (LDP)\",\
    \ RFC 3479, February 2003.\n"
- title: 10.2.  Informative References
  contents:
  - "10.2.  Informative References\n   [RFC2547]    Rosen, E. and Y. Rekhter, \"BGP/MPLS\
    \ VPNs\", RFC 2547,\n                March 1999.\n   [RFC3212]    Jamoussi, B.,\
    \ Editor, Andersson, L., Callon, R., Dantu,\n                R., Wu, L., Doolan,\
    \ P., Worster, T., Feldman, N.,\n                Fredette, A., Girish, M., Gray,\
    \ E., Heinanen, J., Kilty,\n                T. and A. Malis, \"Constraint-Based\
    \ LSP Setup using LDP\",\n                RFC 3212, January 2002.\n   [RFC3469]\
    \    Sharma, V., Ed., and F. Hellstrand, Ed., \"Framework for\n              \
    \  Multi-Protocol Label Switching (MPLS)-based Recovery\",\n                RFC\
    \ 3469, February 2003.\n"
- title: 11.  Acknowledgements
  contents:
  - "11.  Acknowledgements\n   The author would like to thank the authors of [RFC3478]\
    \ and [RFC3479]\n   for their work on fault tolerance of LDP.  Many thanks to\
    \ Yakov\n   Rekhter, Rahul Aggarwal, Manoj Leelanivas and Andrew Malis for their\n\
    \   considered input to this applicability statement.\n"
- title: 12.  Author's Address
  contents:
  - "12.  Author's Address\n   Adrian Farrel\n   Old Dog Consulting\n   Phone:  +44\
    \ (0) 1978 860944\n   EMail:  adrian@olddog.co.uk\n"
- title: 13.  Full Copyright Statement
  contents:
  - "13.  Full Copyright Statement\n   Copyright (C) The Internet Society (2003).\
    \  All Rights Reserved.\n   This document and translations of it may be copied\
    \ and furnished to\n   others, and derivative works that comment on or otherwise\
    \ explain it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assignees.\n\
    \   This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
