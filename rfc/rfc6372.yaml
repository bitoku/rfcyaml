- title: __initial_text__
  contents:
  - '        MPLS Transport Profile (MPLS-TP) Survivability Framework

    '
- title: Abstract
  contents:
  - "Abstract\n   Network survivability is the ability of a network to recover traffic\n\
    \   delivery following failure or degradation of network resources.\n   Survivability\
    \ is critical for the delivery of guaranteed network\n   services, such as those\
    \ subject to strict Service Level Agreements\n   (SLAs) that place maximum bounds\
    \ on the length of time that services\n   may be degraded or unavailable.\n  \
    \ The Transport Profile of Multiprotocol Label Switching (MPLS-TP) is a\n   packet-based\
    \ transport technology based on the MPLS data plane that\n   reuses many aspects\
    \ of the MPLS management and control planes.\n   This document comprises a framework\
    \ for the provision of\n   survivability in an MPLS-TP network; it describes recovery\
    \ elements,\n   types, methods, and topological considerations.  To enable data-plane\n\
    \   recovery, survivability may be supported by the control plane,\n   management\
    \ plane, and by Operations, Administration, and Maintenance\n   (OAM) functions.\
    \  This document describes mechanisms for recovering\n   MPLS-TP Label Switched\
    \ Paths (LSPs).  A detailed description of\n   pseudowire recovery in MPLS-TP\
    \ networks is beyond the scope of this\n   document.\n   This document is a product\
    \ of a joint Internet Engineering Task Force\n   (IETF) / International Telecommunication\
    \ Union Telecommunication\n   Standardization Sector (ITU-T) effort to include\
    \ an MPLS Transport\n   Profile within the IETF MPLS and Pseudowire Emulation\
    \ Edge-to-Edge\n   (PWE3) architectures to support the capabilities and functionalities\n\
    \   of a packet-based transport network as defined by the ITU-T.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6372.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \      1.1. Recovery Schemes ...........................................4\n  \
    \    1.2. Recovery Action Initiation .................................5\n    \
    \  1.3. Recovery Context ...........................................6\n      1.4.\
    \ Scope of This Framework ....................................7\n   2. Terminology\
    \ and References ......................................8\n   3. Requirements for\
    \ Survivability .................................10\n   4. Functional Architecture\
    \ ........................................10\n      4.1. Elements of Control .......................................10\n\
    \           4.1.1. Operator Control ...................................11\n  \
    \         4.1.2. Defect-Triggered Actions ...........................12\n    \
    \       4.1.3. OAM Signaling ......................................12\n      \
    \     4.1.4. Control-Plane Signaling ............................12\n      4.2.\
    \ Recovery Scope ............................................13\n           4.2.1.\
    \ Span Recovery ......................................13\n           4.2.2. Segment\
    \ Recovery ...................................13\n           4.2.3. End-to-End\
    \ Recovery ................................14\n      4.3. Grades of Recovery ........................................15\n\
    \           4.3.1. Dedicated Protection ...............................15\n  \
    \         4.3.2. Shared Protection ..................................16\n    \
    \       4.3.3. Extra Traffic ......................................17\n      \
    \     4.3.4. Restoration ........................................19\n        \
    \   4.3.5. Reversion ..........................................20\n      4.4.\
    \ Mechanisms for Protection .................................20\n           4.4.1.\
    \ Link-Level Protection ..............................20\n           4.4.2. Alternate\
    \ Paths and Segments .......................21\n           4.4.3. Protection Tunnels\
    \ .................................22\n      4.5. Recovery Domains ..........................................23\n\
    \      4.6. Protection in Different Topologies ........................24\n  \
    \    4.7. Mesh Networks .............................................25\n    \
    \       4.7.1. 1:n Linear Protection ..............................26\n      \
    \     4.7.2. 1+1 Linear Protection ..............................28\n        \
    \   4.7.3. P2MP Linear Protection .............................29\n          \
    \ 4.7.4. Triggers for the Linear Protection\n                  Switching Action\
    \ ...................................30\n           4.7.5. Applicability of Linear\
    \ Protection for LSP\n                  Segments ...........................................31\n\
    \           4.7.6. Shared Mesh Protection .............................32\n  \
    \    4.8. Ring Networks .............................................33\n    \
    \  4.9. Recovery in Layered Networks ..............................34\n      \
    \     4.9.1. Inherited Link-Level Protection ....................35\n        \
    \   4.9.2. Shared Risk Groups .................................35\n          \
    \ 4.9.3. Fault Correlation ..................................36\n   5. Applicability\
    \ and Scope of Survivability in MPLS-TP ............37\n   6. Mechanisms for Providing\
    \ Survivability for MPLS-TP LSPs ........39\n      6.1. Management Plane ..........................................39\n\
    \           6.1.1. Configuration of Protection Operation ..............40\n  \
    \         6.1.2. External Manual Commands ...........................41\n    \
    \  6.2. Fault Detection ...........................................41\n      6.3.\
    \ Fault Localization ........................................42\n      6.4. OAM\
    \ Signaling .............................................43\n           6.4.1.\
    \ Fault Detection ....................................44\n           6.4.2. Testing\
    \ for Faults .................................44\n           6.4.3. Fault Localization\
    \ .................................45\n           6.4.4. Fault Reporting ....................................45\n\
    \           6.4.5. Coordination of Recovery Actions ...................46\n  \
    \    6.5. Control Plane .............................................46\n    \
    \       6.5.1. Fault Detection ....................................47\n      \
    \     6.5.2. Testing for Faults .................................47\n        \
    \   6.5.3. Fault Localization .................................48\n          \
    \ 6.5.4. Fault Status Reporting .............................48\n           6.5.5.\
    \ Coordination of Recovery Actions ...................49\n           6.5.6. Establishment\
    \ of Protection and Restoration LSPs ...49\n   7. Pseudowire Recovery Considerations\
    \ .............................50\n      7.1. Utilization of Underlying MPLS-TP\
    \ Recovery ................50\n      7.2. Recovery in the Pseudowire Layer ..........................51\n\
    \   8. Manageability Considerations ...................................51\n  \
    \ 9. Security Considerations ........................................52\n   10.\
    \ Acknowledgments ...............................................52\n   11. References\
    \ ....................................................53\n      11.1. Normative\
    \ References .....................................53\n      11.2. Informative\
    \ References ...................................54\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   Network survivability is the network's ability to recover\
    \ traffic\n   delivery following the failure or degradation of traffic delivery\n\
    \   caused by a network fault or a denial-of-service attack on the\n   network.\
    \  Survivability plays a critical role in the delivery of\n   reliable services\
    \ in transport networks.  Guaranteed services in the\n   form of Service Level\
    \ Agreements (SLAs) require a resilient network\n   that very rapidly detects\
    \ facility or node degradation or failures,\n   and immediately starts to recover\
    \ network operations in accordance\n   with the terms of the SLA.\n   The MPLS\
    \ Transport Profile (MPLS-TP) is described in [RFC5921].\n   MPLS-TP is designed\
    \ to be consistent with existing transport network\n   operations and management\
    \ models, while providing survivability\n   mechanisms, such as protection and\
    \ restoration.  The functionality\n   provided is intended to be similar to or\
    \ better than that found in\n   established transport networks that set a high\
    \ benchmark for\n   reliability.  That is, it is intended to provide the operator\
    \ with\n   functions with which they are familiar through their experience with\n\
    \   other transport networks, although this does not preclude additional\n   techniques.\n\
    \   This document provides a framework for MPLS-TP-based survivability\n   that\
    \ meets the recovery requirements specified in [RFC5654].  It uses\n   the recovery\
    \ terminology defined in [RFC4427], which draws heavily on\n   [G.808.1], and\
    \ it refers to the requirements specified in [RFC5654].\n   This document is a\
    \ product of a joint Internet Engineering Task Force\n   (IETF) / International\
    \ Telecommunication Union Telecommunication\n   Standardization Sector (ITU-T)\
    \ effort to include an MPLS Transport\n   Profile within the IETF MPLS and PWE3\
    \ architectures to support the\n   capabilities and functionalities of a packet-based\
    \ transport network,\n   as defined by the ITU-T.\n"
- title: 1.1.  Recovery Schemes
  contents:
  - "1.1.  Recovery Schemes\n   Various recovery schemes (for protection and restoration)\
    \ and\n   processes have been defined and analyzed in [RFC4427] and [RFC4428].\n\
    \   These schemes can also be applied in MPLS-TP networks to re-establish\n  \
    \ end-to-end traffic delivery according to the agreed service\n   parameters,\
    \ and to trigger recovery from \"failed\" or \"degraded\"\n   transport entities.\
    \  In the context of this document, transport\n   entities are nodes, links, transport\
    \ path segments, concatenated\n   transport path segments, and entire transport\
    \ paths.  Recovery\n   actions are initiated by the detection of a defect, or\
    \ by an external\n   request (e.g., an operator's request for manual control of\
    \ protection\n   switching).\n   [RFC4427] makes a distinction between protection\
    \ switching and\n   restoration mechanisms.\n   - Protection switching uses pre-assigned\
    \ capacity between nodes,\n     where the simplest scheme has a single, dedicated\
    \ protection entity\n     for each working entity, while the most complex scheme\
    \ has m\n     protection entities shared between n working entities (m:n).\n \
    \  - Restoration uses any capacity available between nodes and usually\n     involves\
    \ rerouting.  The resources used for restoration may be pre-\n     planned (i.e.,\
    \ predetermined, but not yet allocated to the recovery\n     path), and recovery\
    \ priority may be used as a differentiation\n     mechanism to determine which\
    \ services are recovered and which are\n     not recovered.\n   Both protection\
    \ switching and restoration may be either\n   unidirectional or bidirectional;\
    \ unidirectional implies that\n   protection switching is performed independently\
    \ for each direction of\n   a bidirectional transport path, while bidirectional\
    \ means that both\n   directions are switched simultaneously using appropriate\n\
    \   coordination, even if the fault applies to only one direction of the\n   path.\n\
    \   Both protection and restoration mechanisms may be either revertive or\n  \
    \ non-revertive as described in Section 4.11 of [RFC4427].\n   Preemption priority\
    \ may be used to determine which services are\n   sacrificed to enable the recovery\
    \ of other services.  Restoration may\n   also be either unidirectional or bidirectional.\
    \  In general,\n   protection actions are completed within time frames amounting\
    \ to tens\n   of milliseconds, while automated restoration actions are normally\n\
    \   completed within periods ranging from hundreds of milliseconds to a\n   maximum\
    \ of a few seconds.  Restoration is not guaranteed (for\n   example, because network\
    \ resources may not be available at the time\n   of the defect).\n"
- title: 1.2.  Recovery Action Initiation
  contents:
  - "1.2.  Recovery Action Initiation\n   The recovery schemes described in [RFC4427]\
    \ and evaluated in\n   [RFC4428] are presented in the context of control-plane-driven\n\
    \   actions (such as the configuration of the protection entities and\n   functions,\
    \ etc.).  The presence of a distributed control plane in an\n   MPLS-TP network\
    \ is optional.  However, the absence of such a control\n   plane does not affect\
    \ the operation of the network and the use of\n   MPLS-TP forwarding, Operations,\
    \ Administration, and Maintenance\n   (OAM), and survivability capabilities. \
    \ In particular, the concepts\n   discussed in [RFC4427] and [RFC4428] refer to\
    \ recovery actions\n   effected in the data plane; they are equally applicable\
    \ in MPLS-TP,\n   with or without the use of a control plane.\n   Thus, some of\
    \ the MPLS-TP recovery mechanisms do not depend on a\n   control plane and use\
    \ MPLS-TP OAM mechanisms or management actions to\n   trigger recovery actions.\n\
    \   The principles of MPLS-TP protection-switching actions are similar to\n  \
    \ those described in [RFC4427], since the protection mechanism is based\n   on\
    \ the capability to detect certain defects in the transport entities\n   within\
    \ the recovery domain.  The protection-switching controller does\n   not care\
    \ which initiation method is used, provided that it can be\n   given information\
    \ about the status of the transport entities within\n   the recovery domain (e.g.,\
    \ OK, signal failure, signal degradation,\n   etc.).\n   In the context of MPLS-TP,\
    \ it is imperative to ensure that performing\n   switchovers is possible, regardless\
    \ of the way in which the network\n   is configured and managed (for example,\
    \ regardless of whether a\n   control-plane, management-plane, or OAM initiation\
    \ mechanism is\n   used).\n   All MPLS and GMPLS protection mechanisms [RFC4428]\
    \ are applicable in\n   an MPLS-TP environment.  It is also possible to provision\
    \ and manage\n   the related protection entities and functions defined in MPLS\
    \ and\n   GMPLS using the management plane [RFC5654].  Regardless of whether an\n\
    \   OAM, management, or control plane initiation mechanism is used, the\n   protection-switching\
    \ operation is a data-plane operation.\n   In some recovery schemes (such as bidirectional\
    \ protection\n   switching), it is necessary to coordinate the protection state\n\
    \   between the edges of the recovery domain to achieve initiation of\n   recovery\
    \ actions for both directions.  An MPLS-TP protocol may be\n   used as an in-band\
    \ (i.e., data-plane based) control protocol in order\n   to coordinate the protection\
    \ state between the edges of the\n   protection domain.  When the MPLS-TP control\
    \ plane is in use, a\n   control-plane-based mechanism can also be used to coordinate\
    \ the\n   protection states between the edges of the protection domain.\n"
- title: 1.3.  Recovery Context
  contents:
  - "1.3.  Recovery Context\n   An MPLS-TP Label Switched Path (LSP) may be subject\
    \ to any part of or\n   all of MPLS-TP link recovery, path-segment recovery, or\
    \ end-to-end\n   recovery, where:\n   o  MPLS-TP link recovery refers to the recovery\
    \ of an individual link\n      (and hence all or a subset of the LSPs routed over\
    \ the link)\n      between two MPLS-TP nodes.  For example, link recovery may\
    \ be\n      provided by server-layer recovery.\n   o  Segment recovery refers\
    \ to the recovery of an LSP segment (i.e.,\n      segment and concatenated segment\
    \ in the language of [RFC5654])\n      between two nodes and is used to recover\
    \ from the failure of one\n      or more links or nodes.\n   o  End-to-end recovery\
    \ refers to the recovery of an entire LSP, from\n      its ingress to its egress\
    \ node.\n   For additional resiliency, more than one of these recovery techniques\n\
    \   may be configured concurrently for a single path.\n   Co-routed bidirectional\
    \ MPLS-TP LSPs are defined in a way that allows\n   both directions of the LSP\
    \ to follow the same route through the\n   network.  In this scenario, the operator\
    \ often requires the\n   directions to fate-share (that is, if one direction fails,\
    \ both\n   directions should cease to operate).\n   Associated bidirectional MPLS-TP\
    \ LSPs exist where the two directions\n   of a bidirectional LSP follow different\
    \ paths through the network.\n   An operator may also request fate-sharing for\
    \ associated\n   bidirectional LSPs.\n   The requirement for fate-sharing causes\
    \ a direct interaction between\n   the recovery processes affecting the two directions\
    \ of an LSP, so\n   that both directions of the bidirectional LSP are recovered\
    \ at the\n   same time.  This mode of recovery is termed bidirectional recovery\n\
    \   and may be seen as a consequence of fate-sharing.\n   The recovery scheme\
    \ operating at the data-plane level can function in\n   a multi-domain environment\
    \ (in the wider sense of a \"domain\"\n   [RFC4726]).  It can also protect against\
    \ a failure of a boundary node\n   in the case of inter-domain operation.  MPLS-TP\
    \ recovery schemes are\n   intended to protect client services when they are sent\
    \ across the\n   MPLS-TP network.\n"
- title: 1.4.  Scope of This Framework
  contents:
  - "1.4.  Scope of This Framework\n   This framework introduces the architecture\
    \ of the MPLS-TP recovery\n   domain and describes the recovery schemes in MPLS-TP\
    \ (based on the\n   recovery types defined in [RFC4427]) as well as the principles\
    \ of\n   operation, recovery states, recovery triggers, and information\n   exchanges\
    \ between the different elements that support the reference\n   model.\n   The\
    \ framework also describes the qualitative grades of the\n   survivability functions\
    \ that can be provided, such as dedicated\n   recovery, shared protection, restoration,\
    \ etc.  In the event of a\n   network failure, the grade of recovery directly\
    \ affects the service\n   grade provided to the end-user.\n   The general description\
    \ of the functional architecture is applicable\n   to both LSPs and pseudowires\
    \ (PWs); however, PW recovery is only\n   introduced in Section 7, and the relevant\
    \ details are beyond the\n   scope of this document and are for further study.\n\
    \   This framework applies to general recovery schemes as well as to\n   mechanisms\
    \ that are optimized for specific topologies and are\n   tailored to efficiently\
    \ handle protection switching.\n   This document addresses the need for the coordination\
    \ of protection\n   switching across multiple layers and at sub-layers (for clarity,\
    \ we\n   use the term \"layer\" to refer equally to layers and sub-layers).\n\
    \   This allows an operator to prevent race conditions and allows the\n   protection-switching\
    \ mechanism of one layer to recover from a failure\n   before switching is invoked\
    \ at another layer.\n   This framework also specifies the functions that must\
    \ be supported by\n   MPLS-TP to provide the recovery mechanisms.  MPLS-TP introduces\
    \ a\n   tool kit to enable recovery in MPLS-TP-based networks and to ensure\n\
    \   that affected services are recovered in the event of a failure.\n   Generally,\
    \ network operators aim to provide the fastest, most stable,\n   and best protection\
    \ mechanism at a reasonable cost in accordance with\n   customer requirements.\
    \  The greater the grade of protection required,\n   the greater the number of\
    \ resources will be consumed.  It is\n   therefore expected that network operators\
    \ will offer a wide spectrum\n   of service grade.  MPLS-TP-based recovery offers\
    \ the flexibility to\n   select a recovery mechanism, define the granularity at\
    \ which traffic\n   delivery is to be protected, and choose the specific traffic\
    \ types\n   that are to be protected.  With MPLS-TP-based recovery, it should\
    \ be\n   possible to provide different grades of protection for different\n  \
    \ traffic classes within the same path based on the service\n   requirements.\n"
- title: 2.  Terminology and References
  contents:
  - "2.  Terminology and References\n   The terminology used in this document is consistent\
    \ with that defined\n   in [RFC4427].  The latter is consistent with [G.808.1].\n\
    \   However, certain protection concepts (such as ring protection) are\n   not\
    \ discussed in [RFC4427]; for those concepts, the terminology used\n   in this\
    \ document is drawn from [G.841].\n   Readers should refer to those documents\
    \ for normative definitions.\n   This document supplies brief summaries of a number\
    \ of terms for\n   reasons of clarity and to assist the reader, but it does not\
    \ redefine\n   terms.\n   Note, in particular, the distinction and definitions\
    \ made in\n   [RFC4427] for the following three terms:\n   o  Protection: re-establishing\
    \ end-to-end traffic delivery using pre-\n      allocated resources.\n   o  Restoration:\
    \ re-establishing end-to-end traffic delivery using\n      resources allocated\
    \ at the time of need; sometimes referred to as\n      \"repair\" of a service,\
    \ LSP, or the traffic.\n   o  Recovery: a generic term covering both Protection\
    \ and Restoration.\n   Note that the term \"survivability\" is used in [RFC5654]\
    \ to cover the\n   functional elements of \"protection\" and \"restoration\",\
    \ which are\n   collectively known as \"recovery\".\n   Important background information\
    \ on survivability can be found in\n   [RFC3386], [RFC3469], [RFC4426], [RFC4427],\
    \ and [RFC4428].\n   In this document, the following additional terminology is\
    \ applied:\n   o  \"Fault Management\", as defined in [RFC5950].\n   o  The terms\
    \ \"defect\" and \"failure\" are used interchangeably to\n      indicate any defect\
    \ or failure in the sense that they are defined\n      in [G.806].  The terms\
    \ also include any signal degradation event\n      as defined in [G.806].\n  \
    \ o  A \"fault\" is a fault or fault cause as defined in [G.806].\n   o  \"Trigger\"\
    \ indicates any event that may initiate a recovery action.\n      See Section\
    \ 4.1 for a more detailed discussion of triggers.\n   o  The acronym \"OAM\" is\
    \ defined as Operations, Administration, and\n      Maintenance, consistent with\
    \ [RFC6291].\n   o  A \"Transport Entity\" is a node, link, transport path segment,\n\
    \      concatenated transport path segment, or entire transport path.\n   o  A\
    \ \"Working Entity\" is a transport entity that carries traffic\n      during\
    \ normal network operation.\n   o  A \"Protection Entity\" is a transport entity\
    \ that is pre-allocated\n      and used to protect and transport traffic when\
    \ the working entity\n      fails.\n   o  A \"Recovery Entity\" is a transport\
    \ entity that is used to recover\n      and transport traffic when the working\
    \ entity fails.\n   o  \"Survivability Actions\" are the steps that may be taken\
    \ by network\n      nodes to communicate faults and to switch traffic from faulted\
    \ or\n      degraded paths to other paths.  This may include sending messages\n\
    \      and establishing new paths.\n   General terminology for MPLS-TP is found\
    \ in [RFC5921] and [ROSETTA].\n   Background information on MPLS-TP requirements\
    \ can be found in\n   [RFC5654].\n"
- title: 3.  Requirements for Survivability
  contents:
  - "3.  Requirements for Survivability\n   MPLS-TP requirements are presented in\
    \ [RFC5654] and serve as\n   normative references for the definition of all MPLS-TP\
    \ functionality,\n   including survivability.  Survivability is presented in [RFC5654]\
    \ as\n   playing a critical role in the delivery of reliable services, and the\n\
    \   requirements for survivability are set out using the recovery\n   terminology\
    \ defined in [RFC4427].\n"
- title: 4.  Functional Architecture
  contents:
  - "4.  Functional Architecture\n   This section presents an overview of the elements\
    \ relating to the\n   functional architecture for survivability within an MPLS-TP\
    \ network.\n   The components are presented separately to demonstrate the way\
    \ in\n   which they may be combined to provide the different grades of\n   recovery\
    \ needed to meet the requirements set out in the previous\n   section.\n"
- title: 4.1.  Elements of Control
  contents:
  - "4.1.  Elements of Control\n   Recovery is achieved by implementing specific actions.\
    \  These actions\n   aim to repair network resources or redirect traffic along\
    \ paths that\n   avoid failures in the network.  They may be triggered automatically\n\
    \   by the MPLS-TP network nodes upon detection of a network defect, or\n   they\
    \ may be triggered by an operator.  Automated actions may be\n   enhanced by in-band\
    \ (i.e., data-plane-based) OAM mechanisms, or by\n   in-band or out-of-band control-plane\
    \ signaling.\n"
- title: 4.1.1.  Operator Control
  contents:
  - "4.1.1.  Operator Control\n   The survivability behavior of the network as a whole,\
    \ and the\n   reaction of each transport path when a fault is reported, may be\n\
    \   controlled by the operator.  This control can be split into two sets\n   of\
    \ functions: policies and actions performed when the transport path\n   is set\
    \ up, and commands used to control or force recovery actions for\n   established\
    \ transport paths.\n   The operator may establish network-wide or local policies\
    \ that\n   determine the actions that will be taken when various defects are\n\
    \   reported that affect different transport paths.  Also, when a service\n  \
    \ request is made that causes the establishment of one or more\n   transport paths\
    \ in the network, the operator (or requesting\n   application) may define a particular\
    \ grade of service, and this will\n   be mapped to specific survivability actions\
    \ taken before and during\n   transport path setup, after the discovery of a failure\
    \ of network\n   resources, and upon recovery of those resources.\n   It should\
    \ be noted that it is unusual to present a user or customer\n   with options directly\
    \ related to recovery actions.  Instead, the\n   user/customer enters into an\
    \ SLA with the network provider, and the\n   network operator maps the terms of\
    \ the SLA (for example, for\n   guaranteed delivery, availability, or reliability)\
    \ to recovery\n   schemes within the network.\n   The operator can also issue\
    \ commands to control recovery actions and\n   events.  For example, the operator\
    \ may perform the following actions:\n   o  Enable or disable the survivability\
    \ function.\n   o  Invoke the simulation of a network fault.\n   o  Force a switchover\
    \ from a working path to a recovery path or vice\n      versa.\n   Forced switchover\
    \ may be performed for network optimization purposes\n   with minimal service\
    \ interruption, such as when modifying protected\n   or unprotected services,\
    \ when replacing MPLS-TP network nodes, etc.\n   In some circumstances, a fault\
    \ may be reported to the operator, and\n   the operator may then select and initiate\
    \ the appropriate recovery\n   action.  A description of the different operator\
    \ commands is found in\n   Section 4.12 of [RFC4427].\n"
- title: 4.1.2.  Defect-Triggered Actions
  contents:
  - "4.1.2.  Defect-Triggered Actions\n   Survivability actions may be directly triggered\
    \ by network defects.\n   This means that the device that detects the defect (for\
    \ example,\n   notification of an issue reported from equipment in a lower layer,\n\
    \   failure to receive an OAM Continuity message, or receipt of an OAM\n   message\
    \ reporting a failure condition) may immediately perform a\n   survivability action.\n\
    \   The action is directly triggered by events in the data plane.  Note,\n   however,\
    \ that coordination of recovery actions between the edges of\n   the recovery\
    \ domain may require message exchanges for some recovery\n   functions or for\
    \ performing a bidirectional recovery action.\n"
- title: 4.1.3.  OAM Signaling
  contents:
  - "4.1.3.  OAM Signaling\n   OAM signaling refers to data-plane OAM message exchange.\
    \  Such\n   messages may be used to detect and localize faults or to indicate\
    \ a\n   degradation in the operation of the network.  However, in this\n   context\
    \ these messages are used to control or trigger survivability\n   actions.  The\
    \ mechanisms to achieve this are discussed in [RFC6371].\n   OAM signaling may\
    \ also be used to coordinate recovery actions within\n   the protection domain.\n"
- title: 4.1.4.  Control-Plane Signaling
  contents:
  - "4.1.4.  Control-Plane Signaling\n   Control-plane signaling is responsible for\
    \ setup, maintenance, and\n   teardown of transport paths that do not fall under\
    \ management-plane\n   control.  The control plane may also be used to coordinate\
    \ the\n   detection, localization, and reaction to network defects pertaining\n\
    \   to peer relationships (neighbor-to-neighbor or end-to-end).  Thus,\n   control-plane\
    \ signaling may initiate and coordinate survivability\n   actions.\n   The control\
    \ plane can also be used to distribute topology and\n   information relating to\
    \ resource availability.  In this way, the\n   \"graceful shutdown\" [RFC5817]\
    \ of resources may be affected by\n   withdrawing them; this can be used to invoke\
    \ a survivability action\n   in a similar way to that used when reporting or discovering\
    \ a fault,\n   as described in the previous sections.\n   The use of a control\
    \ plane for MPLS-TP is discussed in [RFC6373].\n"
- title: 4.2.  Recovery Scope
  contents:
  - "4.2.  Recovery Scope\n   This section describes the elements of recovery.  These\
    \ are the\n   quantitative aspects of recovery, that is, the parts of the network\n\
    \   for which recovery can be provided.\n   Note that the terminology in this\
    \ section is consistent with\n   [RFC4427].  Where the terms differ from those\
    \ in [RFC5654], mapping\n   is provided.\n"
- title: 4.2.1.  Span Recovery
  contents:
  - "4.2.1.  Span Recovery\n   A span is a single hop between neighboring MPLS-TP\
    \ nodes in the same\n   network layer.  A span is sometimes referred to as a link,\
    \ and this\n   may cause some confusion between the concept of a data link and\
    \ a\n   traffic engineering (TE) link.  LSPs traverse TE links between\n   neighboring\
    \ MPLS-TP nodes in the MPLS-TP network layer.  However, a\n   TE link may be provided\
    \ by any of the following:\n   o  A single data link.\n   o  A series of data\
    \ links in a lower layer, established as an LSP and\n      presented to the upper\
    \ layer as a single TE link.\n   o A set of parallel data links in the same layer,\
    \ presented either as\n      a bundle of TE links, or as a collection of data\
    \ links that\n      together provide a data-link-layer protection scheme.\n  \
    \ Thus, span recovery may be provided by any of the following:\n   o  Selecting\
    \ a different TE link from a bundle.\n   o  Moving the TE link so that it is supported\
    \ by a different data\n      link between the same pair of neighbors.\n   o  Rerouting\
    \ the LSP in the lower layer.\n   Moving the protected LSP to another TE link\
    \ between the same pair of\n   neighbors is a form of segment recovery and not\
    \ a form of span\n   recovery.  Segment Recovery is described in Section 4.2.2.\n"
- title: 4.2.2.  Segment Recovery
  contents:
  - "4.2.2.  Segment Recovery\n   An LSP segment comprises one or more continuous\
    \ hops on the path of\n   the LSP.  [RFC5654] defines two terms.  A \"segment\"\
    \ is a single hop\n   along the path of an LSP, while a \"concatenated segment\"\
    \ is more than\n   one hop along the path of an LSP.  In the context of this document,\
    \ a\n   segment covers both of these concepts.\n   A PW segment refers to a Single-Segment\
    \ PW (SS-PW) or to a single\n   segment of a Multi-Segment PW (MS-PW) that is\
    \ set up between two PE\n   devices that may be Terminating PEs (T-PEs) or Switching\
    \ PEs (S-PEs)\n   so that the full set of possibilities is T-PE to S-PE, S-PE\
    \ to S-PE,\n   S-PE to T-PE, or T-PE to T-PE (for the SS-PW case).  As indicated\
    \ in\n   Section 1, the recovery of PWs and PW segments is beyond the scope of\n\
    \   this document; however, see Section 7.\n   Segment recovery involves redirecting\
    \ or copying traffic at the\n   source end of a segment onto an alternate path\
    \ leading to the other\n   end of the segment.  According to the required grade\
    \ of recovery\n   (described in Section 4.3), traffic may be either redirected\
    \ to a\n   pre-established segment, through rerouting the protected segment, or\n\
    \   tunneled to the far end of the protected segment through a \"bypass\"\n  \
    \ LSP.  For details on recovery mechanisms, see Section 4.4.\n   Note that protecting\
    \ a transport path against node failure requires\n   the use of segment recovery\
    \ or end-to-end recovery, while a link\n   failure can be protected using span,\
    \ segment, or end-to-end recovery.\n"
- title: 4.2.3.  End-to-End Recovery
  contents:
  - "4.2.3.  End-to-End Recovery\n   End-to-end recovery is a special case of segment\
    \ recovery where the\n   protected segment comprises the entire transport path.\
    \  End-to-end\n   recovery may be provided as link-diverse or node-diverse recovery\n\
    \   where the recovery path shares no links or no nodes with the working\n   path.\n\
    \   Note that node-diverse paths are necessarily link-diverse and that\n   full,\
    \ end-to-end node-diversity is required to guarantee recovery.\n   Two observations\
    \ need to be made about end-to-end recovery.\n   - Firstly, there may be circumstances\
    \ where node-diverse end-to-end\n     paths do not guarantee recovery.  The ingress\
    \ and egress nodes will\n     themselves be single points of failure.  Additionally,\
    \ there may be\n     shared risks of failure (for example, geographic collocation,\n\
    \     shared resources, etc.) between diverse nodes as described in\n     Section\
    \ 4.9.2.\n   - Secondly, it is possible to use end-to-end recovery techniques\
    \ even\n     when there is not full diversity and the working and protection\n\
    \     paths share links or nodes.\n"
- title: 4.3.  Grades of Recovery
  contents:
  - "4.3.  Grades of Recovery\n   This section describes the qualitative grades of\
    \ survivability that\n   can be provided.  In the event of a network failure,\
    \ the grade of\n   recovery offered directly affects the service grade provided\
    \ to the\n   end-user.  This will be observed as the amount of data lost when\
    \ a\n   network fault occurs, and the length of time required to recover\n   connectivity.\n\
    \   In general, there is a correlation between the recovery service grade\n  \
    \ (i.e., the speed of recovery and reduction of data loss) and the\n   amount\
    \ of resources used in the network; better service grades\n   require the pre-allocation\
    \ of resources to the recovery paths, and\n   those resources cannot be used for\
    \ other purposes if high-quality\n   recovery is required.  An operator will consider\
    \ how providing\n   different grades of recovery may require that network resources\
    \ be\n   provisioned and allocated for exclusive use of the recovery paths\n \
    \  such that the resources cannot be used to support other customer\n   services.\n\
    \   Sections 6 and 7 of [RFC4427] provide a full breakdown of the\n   protection\
    \ and recovery schemes.  This section summarizes the\n   qualitative grades available.\n\
    \   Note that, in the context of recovery, a useful discussion of the\n   term\
    \ \"resource\" and its interpretation in both the IETF and ITU-T\n   contexts\
    \ may be found in Section 3.2 of [RFC4397].\n   The selection of the recovery\
    \ grade and schemes to satisfy the\n   service grades for an LSP using available\
    \ network resources is\n   subject to network and local policy and may be pre-designated\
    \ through\n   network planning or may be dynamically determined by the network.\n"
- title: 4.3.1.  Dedicated Protection
  contents:
  - "4.3.1.  Dedicated Protection\n   In dedicated protection, the resources for the\
    \ recovery entity are\n   pre-assigned for the sole use of the protected transport\
    \ path.  This\n   will clearly be the case in 1+1 protection, and may also be\
    \ the case\n   in 1:1 protection where extra traffic (see Section 4.3.3) is not\n\
    \   supported.\n   Note that when using protection tunnels (see Section 4.4.3),\n\
    \   resources may also be dedicated to the protection of a specific\n   transport\
    \ path.  In some cases (1:1 protection), the entire bypass\n   tunnel may be dedicated\
    \ to providing recovery for a specific\n   transport path, while in other cases\
    \ (such as facility backup), a\n   subset of the resources associated with the\
    \ bypass tunnel may be pre-\n   assigned for the recovery of a specific service.\n\
    \   However, as described in Section 4.4.3, the bypass tunnel method can\n   also\
    \ be used for shared protection (Section 4.3.2), either to carry\n   extra traffic\
    \ (Section 4.3.3) or to achieve best-effort recovery\n   without the need for\
    \ resource reservation.\n"
- title: 4.3.2.  Shared Protection
  contents:
  - "4.3.2.  Shared Protection\n   In shared protection, the resources for the recovery\
    \ entities of\n   several services are shared.  These may be shared as 1:n or\
    \ m:n and\n   are shared on individual links.  Link-by-link resource sharing may\
    \ be\n   managed and operated along LSP segments, on PW segments, or on end-\n\
    \   to-end transport paths (LSP or PW).  Note that there is no\n   requirement\
    \ for m:n recovery in the list of MPLS-TP requirements\n   documented in [RFC5654].\
    \  Shared protection can be applied in\n   different topologies (mesh, ring, etc.)\
    \ and can utilize different\n   protection mechanisms (linear, ring, etc.).\n\
    \   End-to-end shared protection shares resources between a number of\n   paths\
    \ that have common end points.  Thus, a number of paths (n paths)\n   are all\
    \ protected by one or more protection paths (m paths, where m\n   may equal 1).\
    \  When there have been m failures, there are no more\n   available protection\
    \ paths, and the n paths are no longer protected.\n   Thus, in 1:n protection,\
    \ one fault can be protected against before\n   all the n paths are unprotected.\
    \  The fact that the paths have become\n   unprotected needs to be conveyed to\
    \ the path end points since they\n   may need to report the change in service\
    \ grade or may need to take\n   further action to increase their protection. \
    \ In end-to-end shared\n   protection, this communication is simple since the\
    \ end points are\n   common.\n   In shared mesh protection (see Section 4.7.6),\
    \ the paths that share\n   the protection resources do not necessarily have the\
    \ same end points.\n   This provides a more flexible resource-sharing scheme,\
    \ but the\n   network planning and the coordination of protection state after\
    \ a\n   recovery action are more complex.\n   Where a bypass tunnel is used (Section\
    \ 4.4.3), the tunnel might not\n   have sufficient resources to simultaneously\
    \ protect all of the paths\n   for which it offers protection; in the event that\
    \ all paths were\n   affected by network defects and failures at the same time,\
    \ not all of\n   them would be recovered.  Policy would dictate how this situation\n\
    \   should be handled: some paths might be protected, while others would\n   simply\
    \ fail; the traffic for some paths would be guaranteed, while\n   traffic on other\
    \ paths would be treated as best-effort with the risk\n   of dropped packets.\
    \  Alternatively, it is possible that protection\n   would not be attempted according\
    \ to local policy at the nodes that\n   perform the recovery actions.\n   Shared\
    \ protection is a trade-off between assigning network resources\n   to protection\
    \ (which is not required most of the time) and risking\n   unrecoverable services\
    \ in the event that multiple network defects or\n   failures occur.  Rapid recovery\
    \ can be achieved with dedicated\n   protection, but it is delayed by message\
    \ exchanges in the management,\n   control, or data planes for shared protection.\
    \  This means that there\n   is also a trade-off between rapid recovery and resource\
    \ sharing.  In\n   some cases, shared protection might not meet the speed required\
    \ for\n   protection, but it may still be faster than restoration.\n   These trade-offs\
    \ may be somewhat mitigated by the following:\n   o  Adjusting the value of n\
    \ in 1:n protection.\n   o  Using m:n protection for a value of m > 1.\n   o \
    \ Establishing new protection paths as each available protection\n      path is\
    \ put into use.\n   In an MPLS-TP network, the degree to which a resource is shared\n\
    \   between LSPs is a policy issue. This policy may be applied to the\n   resource\
    \ or to the LSPs, and may be pre-configured, configured per\n   LSP and installed\
    \ during LSP establishment, or may be dynamically\n   configured.\n"
- title: 4.3.3.  Extra Traffic
  contents:
  - "4.3.3.  Extra Traffic\n   Section 2.5.1.1 of [RFC5654] says: \"Support for extra\
    \ traffic (as\n   defined in [RFC4427]) is not required in MPLS-TP and MAY be\
    \ omitted\n   from the MPLS-TP specifications\".  This document observes that\
    \ extra\n   traffic facilities may therefore be provided as part of the MPLS-TP\n\
    \   survivability toolkit depending upon the development of suitable\n   solution\
    \ specifications.  The remainder of this section explains the\n   concepts of\
    \ extra traffic without prejudging the decision to specify\n   or not specify\
    \ such solutions.\n   Network resources allocated for protection represent idle\
    \ capacity\n   during the time that recovery is not actually required, and can\
    \ be\n   utilized by carrying other traffic, referred to as \"extra traffic\"\
    .\n   Note that extra traffic does not need to start or terminate at the\n   ends\
    \ of the entity (e.g., LSP) that it uses.\n   When a network resource carrying\
    \ extra traffic is required for the\n   recovery of protected traffic from the\
    \ failed working path, the extra\n   traffic is disrupted.  This disruption make\
    \ take one of two forms:\n   - In \"hard preemption\", the extra traffic is excluded\
    \ from the\n     protection resource.  The disruption of the extra traffic is\
    \ total,\n     and the service supported by the extra traffic must be dropped,\
    \ or\n     some form of rerouting or restoration must be applied to the extra\n\
    \     traffic LSP in order to recover the service.\n     Hard preemption is achieved\
    \ by \"setting a switch\" on the path of\n     the extra traffic such that it\
    \ no longer flows.  This situation may\n     be detected by OAM and reported as\
    \ a fault, or may be proactively\n     reported through OAM or control-plane signaling.\n\
    \   - In \"soft preemption\", the extra traffic is not explicitly excluded\n \
    \    from the protection resource, but is given lower priority than the\n    \
    \ protected traffic.  In a packet network (such as MPLS-TP), this can\n     result\
    \ in oversubscription of the protection resource with the\n     result that the\
    \ extra traffic receives \"best-effort\" delivery.\n     Depending on the volume\
    \ of protection and extra traffic, and the\n     level of oversubscription, the\
    \ extra traffic may be slightly or\n     heavily impacted.\n     The event of\
    \ soft preemption may be detected by OAM and reported as\n     a degradation of\
    \ traffic delivery or as a fault.  It may also be\n     proactively reported through\
    \ OAM or control-plane signaling.\n   Note that both hard and soft preemption\
    \ may utilize additional\n   message exchanges in the management, control, or\
    \ data planes.  These\n   messages do not necessarily mean that recovery is delayed,\
    \ but may\n   increase the complexity of the protection system.  Thus, the benefits\n\
    \   of carrying extra traffic must be weighed against the disadvantages\n   of\
    \ delayed recovery, additional network overhead, and the impact on\n   the services\
    \ that support the extra traffic according to the details\n   of the solutions\
    \ selected.\n   Note that extra traffic is not protected by definition, but may\
    \ be\n   restored.\n   Extra traffic is not supported on dedicated protection\
    \ resources,\n   which, by definition, are used for 1+1 protection (Section 4.3.1),\n\
    \   but it can be supported in other protection schemes, including shared\n  \
    \ protection (Section 4.3.2) and tunnel protection (Section 4.4.3).\n   Best-effort\
    \ traffic should not be confused with extra traffic.  For\n   best-effort traffic,\
    \ the network does not guarantee data delivery,\n   and the user does not receive\
    \ guaranteed quality of service (e.g., in\n   terms of jitter, packet loss, delay,\
    \ etc.).  Best-effort traffic\n   depends on the current traffic load.  However,\
    \ for extra traffic,\n   quality can only be guaranteed until resources are required\
    \ for\n   recovery.  At this point, the extra traffic may be completely\n   displaced,\
    \ may be treated as best effort, or may itself be recovered\n   (for example,\
    \ by restoration techniques).\n"
- title: 4.3.4.  Restoration
  contents:
  - "4.3.4.  Restoration\n   This section refers to LSP restoration.  Restoration\
    \ for PWs is\n   beyond the scope of this document (but see Section 7).\n   Restoration\
    \ represents the most effective use of network resources,\n   since no resources\
    \ are reserved for recovery.  However, restoration\n   requires the computation\
    \ of a new path and the activation of a new\n   LSP (through the management or\
    \ control plane).  It may be more time-\n   consuming to perform these steps than\
    \ to implement recovery using\n   protection techniques.\n   Furthermore, there\
    \ is no guarantee that restoration will be able to\n   recover the service.  It\
    \ may be that all suitable network resources\n   are already in use for other\
    \ LSPs, so that no new path can be found.\n   This problem can be partially mitigated\
    \ by using LSP setup\n   priorities, so that recovery LSPs can preempt existing\
    \ LSPs with\n   lower priorities.\n   Additionally, when a network defect occurs,\
    \ multiple LSPs may be\n   disrupted by the same event.  These LSPs may have been\
    \ established by\n   different Network Management Stations (NMSes) or they may\
    \ have been\n   signaled by different head-end MPLS-TP nodes, meaning that multiple\n\
    \   points in the network will try to compute and establish recovery LSPs\n  \
    \ at the same time.  This can lead to a lack of resources within the\n   network\
    \ and cause recovery failures; some recovery actions will need\n   to be retried,\
    \ resulting in even slower recovery times for some\n   services.\n   Both hard\
    \ and soft LSP restoration may be supported.  For hard LSP\n   restoration, the\
    \ resources of the working LSP are released before the\n   recovery LSP is fully\
    \ established (i.e., break-before-make).  For\n   soft LSP restoration, the resources\
    \ of the working LSP are released\n   after an alternate LSP is fully established\
    \ (i.e., make-before-\n   break).  Note that in the case of reversion (Section\
    \ 4.3.5), the\n   resources associated with the working LSP are not released.\n\
    \   The restoration resources may be pre-calculated and even pre-signaled\n  \
    \ before the restoration action starts, but not pre-allocated.  This is\n   known\
    \ as pre-planned LSP restoration.  The complete\n   establishment/activation of\
    \ the restoration LSP occurs only when the\n   restoration action starts.  Pre-planning\
    \ may occur periodically and\n   provides the most accurate information about\
    \ the available resources\n   in the network.\n"
- title: 4.3.5.  Reversion
  contents:
  - "4.3.5.  Reversion\n   After a service has been recovered and traffic is flowing\
    \ along the\n   recovery LSP, the defective network resource may be replaced.\n\
    \   Traffic can be redirected back onto the original working LSP (known\n   as\
    \ \"reversion\"), or it can be left where it is on the recovery LSP\n   (\"non-revertive\"\
    \ behavior).\n   It should be possible to specify the reversion behavior of each\n\
    \   service; this might even be configured for each recovery instance.\n   In\
    \ non-revertive mode, an additional operational option is possible\n   where protection\
    \ roles are switched, so that the recovery LSP becomes\n   the working LSP, while\
    \ the previous working path (or the resources\n   used by the previous working\
    \ path) are used for recovery in the event\n   of an additional fault.\n   In\
    \ revertive mode, it is important to prevent excessive swapping\n   between the\
    \ working and recovery paths in the case of an intermittent\n   defect.  This\
    \ can be addressed by using a reversion delay timer (the\n   Wait-To-Restore timer),\
    \ which controls the length of time to wait\n   before reversion following the\
    \ repair of a fault on the original\n   working path.  It should be possible for\
    \ an operator to configure\n   this timer per LSP, and a default value should\
    \ be defined.\n"
- title: 4.4.  Mechanisms for Protection
  contents:
  - "4.4.  Mechanisms for Protection\n   This section provides general descriptions\
    \ (MPLS-TP non-specific) of\n   the mechanisms that can be used for protection\
    \ purposes.  As\n   indicated above, while the functional architecture applies\
    \ to both\n   LSPs and PWs, the mechanism for recovery described in this document\n\
    \   refers to LSPs and LSP segments only.  Recovery mechanisms for\n   pseudowires\
    \ and pseudowire segments are for further study and will be\n   described in a\
    \ separate document (see also Section 7).\n"
- title: 4.4.1.  Link-Level Protection
  contents:
  - "4.4.1.  Link-Level Protection\n   Link-level protection refers to two paradigms:\
    \ (1) where protection\n   is provided in a lower network layer and (2) where\
    \ protection is\n   provided by the MPLS-TP link layer.\n   Note that link-level\
    \ protection mechanisms do not protect the nodes\n   at each end of the entity\
    \ (e.g., a link or span) that is protected.\n   End-to-end or segment protection\
    \ should be used in conjunction with\n   link-level protection to protect against\
    \ a failure of the edge nodes.\n   Link-level protection offers the following\
    \ grades of protection:\n   o  Full protection where a dedicated protection entity\
    \ (e.g., a link\n      or span) is pre-established to protect a working entity.\
    \  When the\n      working entity fails, the protected traffic is switched to\
    \ the\n      protecting entity.  In this scenario, all LSPs carried over the\n\
    \      working entity are recovered (in one protection operation) when\n     \
    \ there is a failure condition.  This is referred to in [RFC4427] as\n      \"\
    bulk recovery\".\n   o  Partial protection where only a subset of the LSPs or\
    \ traffic\n      carried over a selected entity is recovered when there is a\n\
    \      failure condition.  The decision as to which LSPs will be\n      recovered\
    \ and which will not depends on local policy.\n   When there is no failure on\
    \ the working entity, the protection entity\n   may transport extra traffic that\
    \ may be preempted when protection\n   switching occurs.\n   If link-level protection\
    \ is available, it may be desirable to allow\n   this to be attempted before attempting\
    \ other recovery mechanisms for\n   the transport paths affected by the fault\
    \ because link-level\n   protection may be faster and more conservative of network\
    \ resources.\n   This can be achieved both by limiting the propagation of fault\n\
    \   condition notifications and by delaying the other recovery actions.\n   This\
    \ consideration of other protection can be compared with the\n   discussion of\
    \ recovery domains (Section 4.5) and recovery in multi-\n   layer networks (Section\
    \ 4.9).\n   A protection mechanism may be provided at the MPLS-TP link layer\n\
    \   (which connects two MPLS-TP nodes).  Such a mechanism can make use of\n  \
    \ the procedures defined in [RFC5586] to set up in-band communication\n   channels\
    \ at the MPLS-TP Section level, to use these channels to\n   monitor the health\
    \ of the MPLS-TP link, and to coordinate the\n   protection states between the\
    \ ends of the MPLS-TP link.\n"
- title: 4.4.2.  Alternate Paths and Segments
  contents:
  - "4.4.2.  Alternate Paths and Segments\n   The use of alternate paths and segments\
    \ refers to the paradigm\n   whereby protection is performed in the network layer\
    \ in which the\n   protected LSP is located; this applies either to the entire\
    \ end-to-\n   end LSP or to a segment of the LSP.  In this case, hierarchical\
    \ LSPs\n   are not used (compare with Section 4.4.3).\n   Different grades of\
    \ protection may be provided:\n   o  Dedicated protection where a dedicated entity\
    \ (e.g., LSP or LSP\n      segment) is (fully) pre-established to protect a working\
    \ entity\n      (e.g., LSP or LSP segment).  When a failure condition occurs on\n\
    \      the working entity, traffic is switched onto the protection\n      entity.\
    \  Dedicated protection may be performed using 1:1 or 1+1\n      linear protection\
    \ schemes.  When the failure condition is\n      eliminated, the traffic may revert\
    \ to the working entity.  This is\n      subject to local configuration.\n   o\
    \  Shared protection where one or more protection entities is pre-\n      established\
    \ to protect against a failure of one or more working\n      entities (1:n or\
    \ m:n).\n   When the fault condition on the working entity is eliminated, the\n\
    \   traffic should revert back to the working entity in order to allow\n   other\
    \ related working entities to be protected by the shared\n   protection resource.\n"
- title: 4.4.3.  Protection Tunnels
  contents:
  - "4.4.3.  Protection Tunnels\n   A protection tunnel is pre-provisioned in order\
    \ to protect against a\n   failure condition along a sequence of spans in the\
    \ network.  This may\n   be achieved using LSP heirarchy.  We call such a sequence\
    \ a network\n   segment.  A failure of a network segment may affect one or more\
    \ LSPs\n   that transit the network segment.\n   When a failure condition occurs\
    \ in the network segment (detected\n   either by OAM on the network segment, or\
    \ by OAM on a concatenated\n   segment of one of the LSPs transiting the network\
    \ segment), one or\n   more of the protected LSPs are switched over at the ingress\
    \ point of\n   the network segment and are transmitted over the protection tunnel.\n\
    \   This is implemented through label stacking.  Label mapping may be an\n   option\
    \ as well.\n   Different grades of protection may be provided:\n   o  Dedicated\
    \ protection where the protection tunnel reserves\n      sufficient resources\
    \ to provide protection for all protected LSPs\n      without causing service\
    \ degradation.\n   o  Partial protection where the protection tunnel has enough\n\
    \      resources to protect some of the protected LSPs, but not all of\n     \
    \ them simultaneously.  Policy dictates how this situation should be\n      handled:\
    \ it is possible that some LSPs would be protected, while\n      others would\
    \ simply fail; it is possible that traffic would be\n      guaranteed for some\
    \ LSPs, while for other LSPs it would be treated\n      as best effort with the\
    \ risk of packets being dropped.\n      Alternatively, it is possible that protection\
    \ would not be\n      attempted.\n"
- title: 4.5.  Recovery Domains
  contents:
  - "4.5.  Recovery Domains\n   Protection and restoration are performed in the context\
    \ of a recovery\n   domain.  A recovery domain is defined between two or more\
    \ recovery\n   reference end points that are located at the edges of the recovery\n\
    \   domain and that border on the element on which recovery can be\n   provided\
    \ (as described in Section 4.2).  This element can be an end-\n   to-end path,\
    \ a segment, or a span.\n   An end-to-end path can be observed as a special segment\
    \ case where\n   the ingress and egress Label Edge Routers (LERs) serve as the\n\
    \   recovery reference end points.\n   In this simple case of a point-to-point\
    \ (P2P) protected entity, two\n   end points reside at the boundary of the protection\
    \ domain.  An LSP\n   can enter through one reference end point and exit the recovery\n\
    \   domain through another reference end point.\n   In the case of unidirectional\
    \ point-to-multipoint (P2MP), three or\n   more end points reside at the boundary\
    \ of the protection domain.  One\n   of the end points is referred to as the source/root,\
    \ while the others\n   are referred to as sinks/leaves.  An LSP can enter the\
    \ recovery\n   domain through the root point and exit the recovery domain through\n\
    \   the leaf points.\n   The recovery mechanism should restore traffic that was\
    \ interrupted by\n   a facility (link or node) fault within the recovery domain.\
    \  Note\n   that a single link may be part of several recovery domains.  If two\n\
    \   recovery domains have common links, one recovery domain must be\n   contained\
    \ within the other.  This can be referred to as nested\n   recovery domains. \
    \ The boundaries of recovery domains may coincide,\n   but recovery domains must\
    \ not overlap.\n   Note that the edges of a recovery domain are not protected,\
    \ and\n   unless the whole domain is contained within another recovery domain,\n\
    \   the edges form a single point of failure.\n   A recovery group is defined\
    \ within a recovery domain and consists of\n   a working (primary) entity and\
    \ one or more recovery (backup) entities\n   that reside between the end points\
    \ of the recovery domain.  To\n   guarantee protection in all situations, a dedicated\
    \ recovery entity\n   should be pre-provisioned using disjoint resources in the\
    \ recovery\n   domain, in order to protect against a failure of a working entity.\n\
    \   Of course, mechanisms to detect faults and to trigger protection\n   switching\
    \ are also needed.\n   The method used to monitor the health of the recovery element\
    \ is\n   beyond the scope of this document.  The end points that are\n   responsible\
    \ for the recovery action must receive information on its\n   condition.  The\
    \ condition of the recovery element may be 'OK',\n   'failed', or 'degraded'.\n\
    \   When the recovery operation is to be triggered by OAM mechanisms, an\n   OAM\
    \ Maintenance Entity Group must be defined for each of the working\n   and protection\
    \ entities.\n   The recovery entities and functions in a recovery domain can be\n\
    \   configured using a management plane or a control plane.  A management\n  \
    \ plane may be used to configure the recovery domain by setting the\n   reference\
    \ points, the working and recovery entities, and the recovery\n   type (e.g.,\
    \ 1:1 bidirectional linear protection, ring protection,\n   etc.).  Additional\
    \ parameters associated with the recovery process\n   may also be configured.\
    \  For more details, see Section 6.1.\n   When a control plane is used, the ingress\
    \ LERs may communicate with\n   the recovery reference points that request that\
    \ protection or\n   restoration be configured across a recovery domain.  For details,\
    \ see\n   Section 6.5.\n   Cases of multiple interconnections between distinct\
    \ recovery domains\n   create a hierarchical arrangement of recovery domains,\
    \ since a single\n   top-level recovery domain is created from the concatenation\
    \ of two\n   recovery domains with multiple interconnections.  In this case,\n\
    \   recovery actions may be taken both in the individual, lower-level\n   recovery\
    \ domains to protect any LSP segment that crosses the domain,\n   and within the\
    \ higher-level recovery domain to protect the longer LSP\n   segment that traverses\
    \ the higher-level domain.\n   The MPLS-TP recovery mechanism can be arranged\
    \ to ensure coordination\n   between domains.  In interconnected rings, for example,\
    \ it may be\n   preferable to allow the upstream ring to perform recovery before\
    \ the\n   downstream ring, in order to ensure that recovery takes place in the\n\
    \   ring in which the defect occurred.  Coordination of recovery actions\n   is\
    \ particularly important in nested domains and is discussed further\n   in Section\
    \ 4.9.\n"
- title: 4.6.  Protection in Different Topologies
  contents:
  - "4.6.  Protection in Different Topologies\n   As described in the requirements\
    \ listed in Section 3 and detailed in\n   [RFC5654], the selected recovery techniques\
    \ may be optimized for\n   different network topologies if the optimized mechanisms\
    \ perform\n   significantly better than the generic mechanisms in the same\n \
    \  topology.\n   These mechanisms are required (R91 of [RFC5654]) to interoperate\
    \ with\n   the mechanisms defined for arbitrary topologies, in order to allow\n\
    \   end-to-end protection and to ensure that consistent protection\n   techniques\
    \ are used across the entire network.  In this context,\n   'interoperate' means\
    \ that the use of one technique must not inhibit\n   the use of another technique\
    \ in an adjacent part of the network for\n   use on the same end-to-end transport\
    \ path, and must not prohibit the\n   use of end-to-end protection mechanisms.\n\
    \   The next sections (4.7 and 4.8) describe two different topologies and\n  \
    \ explain how recovery may be markedly different in those different\n   scenarios.\
    \  They also develop the concept of a recovery domain and\n   show how end-to-end\
    \ survivability may be achieved through a\n   concatenation of recovery domains,\
    \ each providing some grade of\n   recovery in part of the network.\n"
- title: 4.7.  Mesh Networks
  contents:
  - "4.7.  Mesh Networks\n   A mesh network is any network where there is arbitrary\n\
    \   interconnectivity between nodes in the network.  Mesh networks are\n   usually\
    \ contrasted with more specific topologies such as hub-and-\n   spoke or ring\
    \ (see Section 4.8), although such networks are actually\n   examples of mesh\
    \ networks.  This section is limited to the discussion\n   of protection techniques\
    \ in the context of mesh networks.  That is,\n   it does not include optimizations\
    \ for specific topologies.\n   Linear protection is a protection mechanism that\
    \ provides rapid and\n   simple protection switching.  In a mesh network, linear\
    \ protection\n   provides a very suitable protection mechanism because it can\
    \ operate\n   between any pair of points within the network.  It can protect\n\
    \   against a defect in a node, a span, a transport path segment, or an\n   end-to-end\
    \ transport path.  Linear protection gives a clear\n   indication of the protection\
    \ status.\n   Linear protection operates in the context of a protection domain.\
    \  A\n   protection domain is a special type of recovery domain (see Section\n\
    \   4.5) associated with the protection function.  A protection domain is\n  \
    \ composed of the following architectural elements:\n   o  A set of end points\
    \ that reside at the boundary of the protection\n      domain.  In the simple\
    \ case of 1:n or 1+1 P2P protection, two end\n      points reside at the boundary\
    \ of the protection domain.  In each\n      transmission direction, one of the\
    \ end points is referred to as\n      the source, and the other is referred to\
    \ as the sink.  For\n      unidirectional P2MP protection, three or more end points\
    \ reside at\n      the boundary of the protection domain.  One of the end points\
    \ is\n      referred to as the source/root, while the others are referred to\n\
    \      as sinks/leaves.\n   o  A Protection Group consists of one or more working\
    \ (primary) paths\n      and one or more protection (backup) paths that run between\
    \ the end\n      points belonging to the protection domain.  To guarantee\n  \
    \    protection in all scenarios, a dedicated protection path should be\n    \
    \  pre-provisioned to protect against a defect of a working path\n      (i.e.,\
    \ 1:1 or 1+1 protection schemes).  In addition, the working\n      and the protection\
    \ paths should be disjoint; i.e., the physical\n      routes of the working and\
    \ the protection paths should be\n      physically diverse in every respect.\n\
    \   Note that if the resources of the protection path are less than those\n  \
    \ of the working path, the protection path may not have sufficient\n   resources\
    \ to protect the traffic of the working path.\n   As mentioned in Section 4.3.2,\
    \ the resources of the protection path\n   may be shared as 1:n.  In this scenario,\
    \ the protection path will not\n   have sufficient resources to protect all the\
    \ working paths at a\n   specific time.\n   For bidirectional P2P paths, both\
    \ unidirectional and bidirectional\n   protection switching are supported.  If\
    \ a defect occurs when\n   bidirectional protection switching is defined, the\
    \ protection actions\n   are performed in both directions (even if the defect\
    \ is\n   unidirectional).  The protection state is required to operate with a\n\
    \   level of coordination between the end points of the protection\n   domain.\n\
    \   In unidirectional protection switching, the protection actions are\n   only\
    \ performed in the affected direction.\n   Revertive and non-revertive operations\
    \ are provided as options for\n   the network operator.\n   Linear protection\
    \ supports the protection schemes described in the\n   following sub-sections.\n"
- title: 4.7.1.  1:n Linear Protection
  contents:
  - "4.7.1.  1:n Linear Protection\n   In the 1:1 scheme, a protection path is allocated\
    \ to protect against\n   a defect, failure, or a degradation in a working path.\
    \  As described\n   above, to guarantee protection, the protection entity should\
    \ support\n   the full capacity and bandwidth, although it may be configured (for\n\
    \   example, because of limited network resource availability) to offer a\n  \
    \ degraded service when compared with the working entity.\n   Figure 1 presents\
    \ 1:1 protection architecture.  In normal conditions,\n   data traffic is transmitted\
    \ over the working entity, while the\n   protection entity functions in the idle\
    \ state.  (OAM may run on the\n   protection entity to verify its state.)  Normal\
    \ conditions are\n   defined when there is no defect, failure, or degradation\
    \ on the\n   working entity, and no administrative configuration or request causes\n\
    \   traffic to flow over the protection entity.\n           |-----------------Protection\
    \ Domain---------------|\n                      ==============================\n\
    \                   /**********Working path***********\\\n         +--------+\
    \   ==============================   +--------+\n         | Node  /|         \
    \                           |\\  Node |\n         |  A {<  |                 \
    \                   | >}  B  |\n         |        |                          \
    \          |        |\n         +--------+   ==============================  \
    \ +--------+\n                              Protection path\n                \
    \      ==============================\n                  Figure 1: 1:1 Protection\
    \ Architecture\n   If there is a defect on the working entity or a specific\n\
    \   administrative request, traffic is switched to the protection entity.\n  \
    \ Note that when operating with non-revertive behavior (see Section\n   4.3.5),\
    \ after the conditions causing the switchover have been\n   cleared, the traffic\
    \ continues to flow on the protection path, but\n   the working and protection\
    \ roles are not switched.\n   In each transmission direction, the protection domain\
    \ source bridges\n   traffic onto the appropriate entity, while the sink selects\
    \ traffic\n   from the appropriate entity.  The source and the sink need to\n\
    \   coordinate the protection states to ensure that bridging and\n   selection\
    \ are performed to and from the same entity.  For this\n   reason, a signaling\
    \ coordination protocol (either a data-plane in-\n   band signaling protocol or\
    \ a control-plane-based signaling protocol)\n   is required.\n   In bidirectional\
    \ protection switching, both ends of the protection\n   domain are switched to\
    \ the protection entity (even when the fault is\n   unidirectional).  This requires\
    \ a protocol to coordinate the\n   protection state between the two end points\
    \ of the protection domain.\n   When there is no defect, the bandwidth resources\
    \ of the idle entity\n   may be used for traffic with lower priority.  When protection\n\
    \   switching is performed, the traffic with lower priority may be\n   preempted\
    \ by the protected traffic through tearing down the LSP with\n   lower priority,\
    \ reporting a fault on the LSP with lower priority, or\n   by treating the traffic\
    \ with lower priority as best effort and\n   discarding it when there is congestion.\n\
    \   In the general case of 1:n linear protection, one protection entity\n   is\
    \ allocated to protect n working entities.  The protection entity\n   might not\
    \ have sufficient resources to protect all the working\n   entities that may be\
    \ affected by fault conditions at a specific time.\n   In this case, in order\
    \ to guaranteed protection, the protection\n   entity should support enough capacity\
    \ and bandwidth to protect any of\n   the n working entities.\n   When defects\
    \ or failures occur along multiple working entities, the\n   entity to be protected\
    \ should be prioritized.  The protection states\n   between the edges of the protection\
    \ domain should be fully\n   coordinated to ensure consistent behavior.  As explained\
    \ in Section\n   4.3.5, revertive behavior is recommended when 1:n is supported.\n"
- title: 4.7.2.  1+1 Linear Protection
  contents:
  - "4.7.2.  1+1 Linear Protection\n   In the 1+1 protection scheme, a fully dedicated\
    \ protection entity is\n   allocated.\n   As depicted in Figure 2, data traffic\
    \ is copied and fed at the source\n   to both the working and the protection entities.\
    \  The traffic on the\n   working and the protection entities is transmitted simultaneously\
    \ to\n   the sink of the protection domain, where selection between the\n   working\
    \ and protection entities is performed (based on some\n   predetermined criteria).\n\
    \            |---------------Protection Domain---------------|\n             \
    \         ==============================\n                   /**********Working\
    \ path************\\\n         +--------+   ==============================   +--------+\n\
    \         | Node  /|                                    |\\  Node |\n        \
    \ |  A {<  |                                    | >}  Z  |\n         |       \\\
    |                                    |/       |\n         +--------+   ==============================\
    \   +--------+\n                   \\**********Protection path*********/\n   \
    \                   ==============================\n                 Figure 2:\
    \ 1+1 Protection Architecture\n   Note that control traffic between the edges\
    \ of the protection domain\n   (such as OAM or a control protocol to coordinate\
    \ the protection\n   state, etc.) may be transmitted on an entity that differs\
    \ from the\n   one used for the protected traffic.  These packets should not be\n\
    \   discarded by the sink.\n   In 1+1 unidirectional protection switching, there\
    \ is no need to\n   coordinate the protection state between the protection controllers\
    \ at\n   both ends of the protection domain.  In 1+1 bidirectional protection\n\
    \   switching, a protocol is required to coordinate the protection state\n   between\
    \ the edges of the protection domain.\n   In both protection schemes, traffic\
    \ flows end-to-end on the working\n   entity after the conditions causing the\
    \ switchover have been cleared.\n   Data selection may return to selecting traffic\
    \ from the working\n   entity if reversion is enabled, and it will require coordination\
    \ of\n   the protection state between the edges of the protection domain.  To\n\
    \   avoid frequent switching caused by intermittent defects or failures\n   when\
    \ the network is not stable, traffic is not selected from the\n   working entity\
    \ before the Wait-To-Restore (WTR) timer has expired.\n"
- title: 4.7.3.  P2MP Linear Protection
  contents:
  - "4.7.3.  P2MP Linear Protection\n   Linear protection may be applied to protect\
    \ unidirectional P2MP\n   entities using 1+1 protection architecture.  The source/root\
    \ MPLS-TP\n   node bridges the user traffic to both the working and protection\n\
    \   entities.  Each sink/leaf MPLS-TP node selects the traffic from one\n   entity\
    \ according to some predetermined criteria.  Note that when\n   there is a fault\
    \ condition on one of the branches of the P2MP path,\n   some leaf MPLS-TP nodes\
    \ may select the working entity, while other\n   leaf MPLS-TP nodes may select\
    \ traffic from the protection entity.\n   In a 1:1 P2MP protection scheme, the\
    \ source/root MPLS-TP node needs\n   to identify the existence of a fault condition\
    \ on any of the branches\n   of the network.  This means that the sink/leaf MPLS-TP\
    \ nodes need to\n   notify the source/root MPLS-TP node of any fault condition.\
    \  This\n   also necessitates a return path from the sinks/leaves to the\n   source/root\
    \ MPLS-TP node.  When protection switching is triggered,\n   the source/root MPLS-TP\
    \ node selects the protection transport path\n   for traffic transfer.\n   A form\
    \ of \"segment recovery for P2MP LSPs\" could be constructed.\n   Given a P2MP\
    \ LSP, one can protect any possible point of failure (link\n   or node) using\
    \ N backup P2MP LSPs.  Each backup P2MP LSP originates\n   from the upstream node\
    \ with respect to a different possible failure\n   point and terminates at all\
    \ of the destinations downstream of the\n   potential failure point.  In case\
    \ of a failure, traffic is redirected\n   to the backup P2MP path.\n   Note that\
    \ such mechanisms do not yet exist, and their exact behavior\n   is for further\
    \ study.\n   A 1:n protection scheme for P2MP transport paths is also required\
    \ by\n   [RFC5654].  Such a mechanism is for future study.\n"
- title: 4.7.4.  Triggers for the Linear Protection Switching Action
  contents:
  - "4.7.4.  Triggers for the Linear Protection Switching Action\n  Protection switching\
    \ may be performed when:\n   o  A defect condition is detected on the working\
    \ entity, and the\n      protection entity has \"no\" or an inferior condition.\
    \  Proactive\n      in-band OAM Continuity Check and Connectivity Verification\
    \ (CC-V)\n      monitoring of both the working and the protection entities may\
    \ be\n      used to enable the rapid detection of a fault condition.  For\n  \
    \    protection switching, it is common to run a CC-V every 3.33 ms.\n      In\
    \ the absence of three consecutive CC-V messages, a fault\n      condition is\
    \ declared.  In order to monitor the working and the\n      protection entities,\
    \ an OAM Maintenance Entity Group should be\n      defined for each entity.  OAM\
    \ indications associated with fault\n      conditions should be provided at the\
    \ edges of the protection\n      domain that is responsible for the protection-switching\
    \ operation.\n      Input from OAM performance monitoring that indicates degradation\n\
    \      in the working entity may also be used as a trigger for protection\n  \
    \    switching.  In the case of degradation, switching to the\n      protection\
    \ entity is needed only if the protection entity can\n      exhibit better operating\
    \ conditions.\n   o  An indication is received from a lower-layer server that\
    \ there is\n      a defect in the lower layer.\n   o  An external operator command\
    \ is received (e.g., 'Forced Switch',\n      'Manual Switch').  For details, see\
    \ Section 6.1.2.\n   o  A request to switch over is received from the far end.\
    \  The far\n      end may initiate this request, for example, on receipt of an\n\
    \      administrative request to switch over, or when bidirectional 1:1\n    \
    \  protection switching is supported and a defect occurred that could\n      only\
    \ be detected by the far end, etc.\n   As described above, the protection state\
    \ should be coordinated\n   between the end points of the protection domain. \
    \ Control messages\n   should be exchanged between the edges of the protection\
    \ domain to\n   coordinate the protection state of the edge nodes.  Control messages\n\
    \   can be delivered using an in-band, data-plane-driven control protocol\n  \
    \ or a control-plane-based protocol.\n   For 50-ms protection switching, it is\
    \ recommended that an in-band,\n   data-plane-driven signaling protocol be used\
    \ in order to coordinate\n   the protection states.  An in-band, data-plane protocol\
    \ for use in\n   MPLS-TP networks is documented in [MPLS-TP-LP] for linear protection\n\
    \   (ring protection is discussed in Section 4.8 of this document).  This\n  \
    \ protocol is also used to detect mismatches between the configurations\n   provisioned\
    \ at the ends of the protection domain.\n   As described in Section 6.5, the GMPLS\
    \ control plane already includes\n   procedures and message elements to coordinate\
    \ the protection states\n   between the edges of the protection domain.  These\
    \ procedures and\n   protocol messages are specified in [RFC4426], [RFC4872],\
    \ and\n   [RFC4873].  However, these messages lack the capability to coordinate\n\
    \   the revertive/non-revertive behavior and the consistency of\n   configured\
    \ timers at the edges of the protection domain (timers such\n   as WTR, hold-off\
    \ timer, etc.).\n"
- title: 4.7.5.  Applicability of Linear Protection for LSP Segments
  contents:
  - "4.7.5.  Applicability of Linear Protection for LSP Segments\n   In order to implement\
    \ data-plane-based linear protection on LSP\n   segments, use is made of the Sub-Path\
    \ Maintenance Element (SPME), an\n   MPLS-TP architectural element defined in\
    \ [RFC5921].  Maintenance\n   operations (e.g., monitoring, protection, or management)\
    \ engage with\n   message transmission (e.g., OAM, Protection Path Coordination,\
    \ etc.)\n   in the maintained domain.  Further discussion of the architecture\
    \ for\n   OAM and SPME is found in [RFC5921] and [RFC6371].  An SPME is an LSP\n\
    \   that is basically defined and used for the purposes of OAM\n   monitoring,\
    \ protection, or management of LSP segments.  The SPME uses\n   the MPLS construct\
    \ of a hierarchical, nested LSP, as defined in\n   [RFC3031].\n   For linear protection,\
    \ SPMEs should be defined over the working and\n   protection entities between\
    \ the edges of a protection domain.  OAM\n   messages and messages used to coordinate\
    \ protection state can be\n   initiated at the edge of the SPME and sent to the\
    \ peer edge of the\n   SPME.  Note that these messages are sent over the Generic\
    \ Associated\n   Channel (G-ACh) within the SPME, and that they use a two-label\
    \ stack,\n   the SPME label, and, at the bottom of the stack, the G-ACh label\n\
    \   (GAL) [RFC5586].\n   The end-to-end traffic of the LSP, which includes data\
    \ traffic and\n   control traffic (messages for OAM, management, signaling, and\
    \ to\n   coordinate protection state), is tunneled within the SPMEs by means\n\
    \   of label stacking, as defined in [RFC3031].\n   Mapping between an LSP and\
    \ an SPME can be 1:1; this is similar to the\n   ITU-T Tandem Connection element\
    \ that defines a sub-layer\n   corresponding to a segment of a path.  Mapping\
    \ can also be 1:n to\n   allow the scalable protection of a set of LSP segments\
    \ traversing the\n   part of the network in which a protection domain is defined.\
    \  Note\n   that each of these LSPs can be initiated or terminated at different\n\
    \   end points in the network, but that they all traverse the protection\n   domain\
    \ and share similar constraints (such as requirements for\n   quality of service\
    \ (QoS), terms of protection, etc.).\n   Note also that in the context of segment\
    \ protection, the SPMEs serve\n   as the working and protection entities.\n"
- title: 4.7.6.  Shared Mesh Protection
  contents:
  - "4.7.6.  Shared Mesh Protection\n   For shared mesh protection, the protection\
    \ resources are used to\n   protect multiple LSPs that do not all share the same\
    \ end points; for\n   example, in Figure 3 there are two paths, ABCDE and VWXYZ.\
    \  These\n   paths do not share end points and cannot, therefore, make use of\
    \ 1:n\n   linear protection, even though they do not have any common points of\n\
    \   failure.\n   ABCDE may be protected by the path APQRE, while VWXYZ can be\n\
    \   protected by the path VPQRZ.  In both cases, 1:1 or 1+1 protection\n   may\
    \ be used.  However, it can be seen that if 1:1 protection is used\n   for both\
    \ paths, the PQR network segment does not carry traffic when\n   no failures affect\
    \ either of the two working paths.  Furthermore, in\n   the event of only one\
    \ failure, the PQR segment carries traffic from\n   only one of the working paths.\n\
    \   Thus, it is possible for the network resources on the PQR segment to\n   be\
    \ shared by the two recovery paths.  In this way, mesh protection\n   can substantially\
    \ reduce the number of network resources that have to\n   be reserved in order\
    \ to provide 1:n protection.\n             A----B----C----D----E\n           \
    \   \\                 /\n               \\               /\n                \\\
    \             /\n                 P-----Q-----R\n                /           \
    \  \\\n               /               \\\n              /                 \\\n\
    \             V----W----X----Y----Z\n       Figure 3: A Shared Mesh Protection\
    \ Topology\n   As the network becomes more complex and the number of LSPs increases,\n\
    \   the potential for shared mesh protection also increases.  However,\n   this\
    \ can quickly become unmanageable owing to the increased\n   complexity.  Therefore,\
    \ shared mesh protection is normally pre-\n   planned and configured by the operator,\
    \ although an automated system\n   cannot be ruled out.\n   Note that shared mesh\
    \ protection operates as 1:n linear protection\n   (see Section 4.7.1).  However,\
    \ the protection state needs to be\n   coordinated between a larger number of\
    \ nodes: the end points of the\n   shared concatenated protection segment (nodes\
    \ P and R in the example)\n   as well as the end points of the protected LSPs\
    \ (nodes A, E, V, and Z\n   in the example).\n   Additionally, note that the shared-protection\
    \ resources could be used\n   to carry extra traffic.  For example, in Figure\
    \ 4, an LSP JPQRK could\n   be a preemptable LSP that constitutes extra traffic\
    \ over the PQR\n   hops; it would be displaced in the event of a protection event.\
    \  In\n   this case, it should be noted that the protection state must also be\n\
    \   coordinated with the ends of the extra-traffic LSPs.\n             A----B----C----D----E\n\
    \              \\                 /\n               \\               /\n     \
    \           \\             /\n           J-----P-----Q-----R-----K\n         \
    \       /             \\\n               /               \\\n              / \
    \                \\\n             V----W----X----Y----Z\n       Figure 4: Shared\
    \ Mesh Protection with Extra Traffic\n"
- title: 4.8.  Ring Networks
  contents:
  - "4.8.  Ring Networks\n   Several service providers have expressed great interest\
    \ in the\n   operation of MPLS-TP in ring topologies; they demand a high degree\
    \ of\n   survivability functionality in these topologies.\n   Various criteria\
    \ for optimization are considered in ring topologies,\n   such as:\n   1.  Simplification\
    \ in ring operation in terms of the number of OAM\n       Maintenance Entities\
    \ that are needed to trigger the recovery\n       actions, the number of recovery\
    \ elements, the number of\n       management-plane transactions during maintenance\
    \ operations, etc.\n   2.  Optimization of resource consumption around the ring,\
    \ such as the\n       number of labels needed for the protection paths that traverse\n\
    \       the network, the total bandwidth required in the ring to ensure\n    \
    \   path protection, etc. (see R91 of [RFC5654]).\n   [RFC5654] introduces a list\
    \ of requirements for ring protection\n   covering the recovery mechanisms needed\
    \ to protect traffic in a\n   single ring as well as traffic that traverses more\
    \ than one ring.\n   Note that configuration and the operation of the recovery\
    \ mechanisms\n   in a ring must scale well with the number of transport paths,\
    \ the\n   number of nodes, and the number of ring interconnects.\n   The requirements\
    \ for ring protection are fully compatible with the\n   generic requirements for\
    \ recovery.\n   The architecture and the mechanisms for ring protection are specified\n\
    \   in separate documents.  These mechanisms need to be evaluated against\n  \
    \ the requirements specified in [RFC5654], which includes guidance on\n   the\
    \ principles for the development of new mechanisms.\n"
- title: 4.9.  Recovery in Layered Networks
  contents:
  - "4.9.  Recovery in Layered Networks\n   In multi-layer or multi-regional networking\
    \ [RFC5212], recovery may\n   be performed at multiple layers or across nested\
    \ recovery domains.\n   The MPLS-TP recovery mechanism must ensure that the timing\
    \ of\n   recovery is coordinated in order to avoid race scenarios.  This also\n\
    \   allows the recovery mechanism of the server layer to fix the problem\n   before\
    \ recovery takes place in the MPLS-TP layer, or the MPLS-TP\n   layer to perform\
    \ recovery before a client network.\n   A hold-off timer is required to coordinate\
    \ recovery timing in\n   multiple layers or across nested recovery domains.  Setting\
    \ this\n   configurable timer involves a trade-off between rapid recovery and\n\
    \   the creation of a race condition where multiple layers respond to the\n  \
    \ same fault, potentially allocating resources in an inefficient\n   manner. \
    \ Thus, the detection of a defect condition in the MPLS-TP\n   layer should not\
    \ immediately trigger the recovery process if the\n   hold-off timer is configured\
    \ as a value other than zero.  Instead,\n   the hold-off timer should be started\
    \ when the defect is detected and,\n   on expiry, the recovery element should\
    \ be checked to determine\n   whether the defect condition still exists.  If it\
    \ does exist, the\n   defect triggers the recovery operation.\n   The hold-off\
    \ timer should be configurable.\n   In other configurations, where the lower layer\
    \ does not have a\n   restoration capability, or where it is not expected to provide\n\
    \   protection, the lower layer needs to trigger the higher layer to\n   immediately\
    \ perform recovery.  Although this can be forced by\n   configuring the hold-off\
    \ timer as zero, it may be that because of\n   layer independence, the higher\
    \ layer does not know whether the lower\n   layer will perform restoration.  In\
    \ this case, the higher layer will\n   configure a non-zero hold-off timer and\
    \ rely on the receipt of a\n   specific notification from the lower layer if the\
    \ lower layer cannot\n   perform restoration.  Since layer boundaries are always\
    \ within nodes,\n   such coordination is implementation-specific and does not\
    \ need to be\n   covered here.\n   Reference should be made to [RFC3386], which\
    \ discusses the\n   interaction between layers in survivable networks.\n"
- title: 4.9.1.  Inherited Link-Level Protection
  contents:
  - "4.9.1.  Inherited Link-Level Protection\n   Where a link in the MPLS-TP network\
    \ is formed through connectivity\n   (i.e., a packet or non-packet LSP) in a lower-layer\
    \ network, that\n   connectivity may itself be protected; for example, the LSP\
    \ in the\n   lower-layer network may be provisioned with 1+1 protection.  In this\n\
    \   case, the link in the MPLS-TP network has an inherited grade of\n   protection.\n\
    \   An LSP in the MPLS-TP network may be provisioned with protection in\n   the\
    \ MPLS-TP network, as already described, or it may be provisioned\n   to utilize\
    \ only those links that have inherited protection.\n   By classifying the links\
    \ in the MPLS-TP network according to the\n   grade of protection that they inherited\
    \ from the server network, it\n   is possible to compute an end-to-end path in\
    \ the MPLS-TP network that\n   uses only those links with a specific or superior\
    \ grade of inherited\n   protection.  This means that the end-to-end MPLS-TP LSP\
    \ can be\n   protected at the grade necessary to conform to the SLA without\n\
    \   needing to provide any additional protection in the MPLS-TP layer.\n   This\
    \ reduces complexity, saves network resources, and eliminates\n   protection-switching\
    \ coordination problems.\n   When the requisite grade of inherited protection\
    \ is not available on\n   all segments along the path in the MPLS-TP network,\
    \ segment\n   protection may be used to achieve the desired protection grade.\n\
    \   It should be noted, however, that inherited protection only applies\n   to\
    \ links.  Nodes cannot be protected in this way.  An operator will\n   need to\
    \ perform an analysis of the relative likelihood and\n   consequences of node\
    \ failure if this approach is taken without\n   providing protection in the MPLS-TP\
    \ LSP or PW layer to handle node\n   failure.\n"
- title: 4.9.2.  Shared Risk Groups
  contents:
  - "4.9.2.  Shared Risk Groups\n   When an MPLS-TP protection scheme is established,\
    \ it is important\n   that the working and protection paths do not share resources\
    \ in the\n   network.  If this is not achieved, a single defect may affect both\n\
    \   the working and the protection paths with the result that traffic\n   cannot\
    \ be delivered -- since under such a condition the traffic was\n   not protected.\n\
    \   Note that this restriction does not apply to restoration, since this\n   takes\
    \ place after the fault has occurred, which means that the point\n   of failure\
    \ can be avoided if an available path exists.\n   When planning a recovery scheme,\
    \ it is possible to use a topology map\n   of the MPLS-TP layer to select paths\
    \ that use diverse links and nodes\n   within the MPLS-TP network.  However, this\
    \ does not guarantee that\n   the paths are truly diverse; for example, two separate\
    \ links in an\n   MPLS-TP network may be provided by two lambdas in the same optical\n\
    \   fiber, or by two fibers that cross the same bridge.  Moreover, two\n   completely\
    \ separate MPLS-TP nodes might be situated in the same\n   building with a shared\
    \ power supply.\n   Thus, in order to achieve proper recovery planning, the MPLS-TP\n\
    \   network must have an understanding of the groups of lower-layer\n   resources\
    \ that share a common risk of failure.  From this, MPLS-TP\n   shared risk groups\
    \ can be constructed that show which MPLS-TP\n   resources share a common risk\
    \ of failure.  Diversity of working and\n   protection paths can be planned, not\
    \ only with regard to nodes and\n   links but also in order to refrain from using\
    \ resources from the same\n   shared risk groups.\n"
- title: 4.9.3.  Fault Correlation
  contents:
  - "4.9.3.  Fault Correlation\n   In a layered network, a low-layer fault may be\
    \ detected and reported\n   by multiple layers and may sometimes lead to the generation\
    \ of\n   multiple fault reports from the same layer.  For example, a failure\n\
    \   of a data link may be reported by the line cards in an MPLS-TP node,\n   but\
    \ it could also be detected and reported by the MPLS-TP OAM.\n   Section 4.6 explains\
    \ how it is important to coordinate the\n   survivability actions configured and\
    \ operated in a multi-layer\n   network in a way that will avoid over-equipping\
    \ the survivability\n   resources in the network, while ensuring that recovery\
    \ actions are\n   performed in only one layer at a time.\n   Fault correlation\
    \ is about understanding which single event has\n   generated a set of fault reports,\
    \ so that recovery actions can be\n   coordinated, and so that the fault logging\
    \ system does not become\n   overloaded.  Fault correlation depends on understanding\
    \ resource use\n   at lower layers, shared risk groups, and a wider view with\
    \ regard to\n   the way in which the layers are interrelated.\n   Fault correlation\
    \ is most easily performed at the point of fault\n   detection; for example, an\
    \ MPLS-TP node that receives a fault\n   notification from the lower layer, and\
    \ detects a fault on an LSP in\n   the MPLS-TP layer, can easily correlate these\
    \ two events.\n   Furthermore, if the same node detects multiple faults on LSPs\
    \ that\n   share the same faulty data link, it can easily correlate them.  Such\n\
    \   a node may use correlation to perform group-based recovery actions\n   and\
    \ can reduce the number of alarm events that it generates to its\n   management\
    \ station.\n   Fault correlation may also be performed at a management station\
    \ that\n   receives fault reports from different layers and different nodes in\n\
    \   the network.  This enables the management station to coordinate\n   management-originated\
    \ recovery actions and to present consolidated\n   fault information to the user\
    \ and automated management systems.\n   It is also necessary to correlate fault\
    \ information detected and\n   reported through OAM.  This function would enable\
    \ a fault detected at\n   a lower layer, and reported at a transit node of an\
    \ MPLS-TP LSP, to\n   be correlated with an MPLS-TP-layer fault detected at a\
    \ Maintenance\n   End Point (MEP) -- for example, the egress of the MPLS-TP LSP.\
    \  Such\n   correlation allows the coordination of recovery actions performed\
    \ at\n   the MEP, but it also requires that the lower-layer fault information\n\
    \   is propagated to the MEP, which is most easily achieved using a\n   control\
    \ plane, management plane, or OAM message.\n"
- title: 5.  Applicability and Scope of Survivability in MPLS-TP
  contents:
  - "5.  Applicability and Scope of Survivability in MPLS-TP\n   The MPLS-TP network\
    \ can be viewed as two layers (the MPLS LSP layer\n   and the PW layer).  The\
    \ MPLS-TP network operates over data-link\n   connections and data-link networks\
    \ whereby the MPLS-TP links are\n   provided by individual data links or by connections\
    \ in a lower-layer\n   network.  The MPLS LSP layer is a mandatory part of the\
    \ MPLS-TP\n   network, while the PW layer is an optional addition for supporting\n\
    \   specific services.\n   MPLS-TP survivability provides recovery from failure\
    \ of the links and\n   nodes in the MPLS-TP network.  The link defects and failures\
    \ are\n   typically caused by defects or failures in the underlying data-link\n\
    \   connections and networks, but this section is only concerned with\n   recovery\
    \ actions performed in the MPLS-TP network, which must recover\n   from the manifestation\
    \ of any problem as a defect failure in the\n   MPLS-TP network.\n   This section\
    \ lists the recovery elements (see Section 1) supported in\n   each of the two\
    \ layers that can recover from defects or failures of\n   nodes or links in the\
    \ MPLS-TP network.\n   +--------------+---------------------+------------------------------+\n\
    \   | Recovery     | MPLS LSP Layer      | PW Layer                     |\n  \
    \ | Element      |                     |                              |\n   +--------------+---------------------+------------------------------+\n\
    \   | Link         | MPLS LSP recovery   | The PW layer is not aware of |\n  \
    \ | Recovery     | can be used to      | the underlying network.      |\n   |\
    \              | survive the failure | This function is not         |\n   |  \
    \            | of an MPLS-TP link. | supported.                   |\n   +--------------+---------------------+------------------------------+\n\
    \   | Segment/Span | An individual LSP   | For an SS-PW, segment        |\n  \
    \ | Recovery     | segment can be      | recovery is the same as      |\n   |\
    \              | recovered to        | end-to-end recovery.         |\n   |  \
    \            | survive the failure | Segment recovery for an MS-PW|\n   |    \
    \          | of an MPLS-TP link. | is for future study, and     |\n   |      \
    \        |                     | this function is now         |\n   |        \
    \      |                     | provided using end-to-end    |\n   |          \
    \    |                     | recovery.                    |\n   +--------------+---------------------+------------------------------+\n\
    \   | Concatenated | A concatenated LSP  | Concatenated segment         |\n  \
    \ | Segment      | segment can be      | recovery (in an MS-PW) is for|\n   |\
    \ Recovery     | recovered to        | future study, and this       |\n   |  \
    \            | survive the failure | function is now provided     |\n   |    \
    \          | of an MPLS-TP link  | using end-to-end recovery.   |\n   |      \
    \        | or node.            |                              |\n   +--------------+---------------------+------------------------------+\n\
    \   | End-to-End   | An end-to-end LSP   | End-to-end PW recovery can   |\n  \
    \ | Recovery     | can be recovered to | be applied to survive any    |\n   |\
    \              | survive any node or | node (including S-PE) or     |\n   |  \
    \            | link failure,       | link failure, except for     |\n   |    \
    \          | except for the      | failure of the ingress or    |\n   |      \
    \        | failure of the      | egress T-PE.                 |\n   |        \
    \      | ingress or egress   |                              |\n   |          \
    \    | node.               |                              |\n   +--------------+---------------------+------------------------------+\n\
    \   | Service      | The MPLS LSP layer  | PW-layer service recovery    |\n  \
    \ | Recovery     | is service-         | requires surviving faults in |\n   |\
    \              | agnostic.  This     | T-PEs or on Attachment       |\n   |  \
    \            | function is not     | Circuits (ACs).  This is     |\n   |    \
    \          | supported.          | currently out of scope for   |\n   |      \
    \        |                     | MPLS-TP.                     |\n   +--------------+---------------------+------------------------------+\n\
    \                 Table 1: Recovery Elements Supported\n                  by the\
    \ MPLS LSP Layer and PW Layer\n   Section 6 provides a description of mechanisms\
    \ for MPLS-TP-LSP\n   survivability.  Section 7 provides a brief overview of mechanisms\
    \ for\n   MPLS-TP-PW survivability.\n"
- title: 6.  Mechanisms for Providing Survivability for MPLS-TP LSPs
  contents:
  - "6.  Mechanisms for Providing Survivability for MPLS-TP LSPs\n   This section\
    \ describes the existing mechanisms that provide LSP\n   protection within MPLS-TP\
    \ networks and highlights areas where new\n   work is required.\n"
- title: 6.1.  Management Plane
  contents:
  - "6.1.  Management Plane\n   As described above, a fundamental requirement of MPLS-TP\
    \ is that\n   recovery mechanisms should be capable of functioning in the absence\n\
    \   of a control plane.  Recovery may be triggered by MPLS-TP OAM fault\n   management\
    \ functions or by external requests (e.g., an operator's\n   request for manual\
    \ control of protection switching).  Recovery LSPs\n   (and in particular Restoration\
    \ LSPs) may be provisioned through the\n   management plane.\n   The management\
    \ plane may be used to configure the recovery domain by\n   setting the reference\
    \ end-point points (which control the recovery\n   actions), the working and the\
    \ recovery entities, and the recovery\n   type (e.g., 1:1 bidirectional linear\
    \ protection, ring protection,\n   etc.).\n   Additional parameters associated\
    \ with the recovery process (such as\n   WTR and hold-off timers, revertive/non-revertive\
    \ operation, etc.) may\n   also be configured.\n   In addition, the management\
    \ plane may initiate manual control of the\n   recovery function.  A priority\
    \ should be set for the fault conditions\n   and the operator's requests.\n  \
    \ Since provisioning the recovery domain involves the selection of a\n   number\
    \ of options, mismatches may occur at the different reference\n   points.  The\
    \ MPLS-TP protocol to coordinate protection state, which\n   is specified in [MPLS-TP-LP],\
    \ may be used as an in-band (i.e., data-\n   plane-based) control protocol to\
    \ coordinate the protection states\n   between the end points of the recovery\
    \ domain, and to check the\n   consistency of configured parameters (such as timers,\
    \ revertive/non-\n   revertive behavior, etc.) with discovered inconsistencies\
    \ that are\n   reported to the operator.\n   It should also be possible for the\
    \ management plane to track the\n   recovery status by receiving reports or by\
    \ issuing polls.\n"
- title: 6.1.1.  Configuration of Protection Operation
  contents:
  - "6.1.1.  Configuration of Protection Operation\n   To implement the protection-switching\
    \ mechanisms, the following\n   entities and information should be configured\
    \ and provisioned:\n   o  The end points of a recovery domain.  As described above,\
    \ these\n      end points border on the element of recovery to which recovery\
    \ is\n      applied.\n   o  The protection group, which, depending on the required\
    \ protection\n      scheme, consists of a recovery entity and one or more working\n\
    \      entities.  In 1:1 or 1+1 P2P protection, the paths of the working\n   \
    \   entity and the recovery entities must be physically diverse in\n      every\
    \ respect (i.e., not share any resources or physical\n      locations), in order\
    \ to guarantee protection.\n   o  As defined in Section 4.8, the SPME must be\
    \ supported in order to\n      implement data-plane-based LSP segment recovery,\
    \ since related\n      control messages (e.g., for OAM, Protection Path Coordination,\n\
    \      etc.) can be initiated and terminated at the edges of a path where\n  \
    \    push and pop operations are enabled.  The SPME is an end-to-end\n      LSP\
    \ that in this context corresponds to the recovery entities\n      (working and\
    \ protection) and makes use of the MPLS construct of\n      hierarchical nested\
    \ LSP, as defined in [RFC3031].  OAM messages\n      and messages to coordinate\
    \ protection state can be initiated at\n      the edge of the SPME and sent over\
    \ G-ACH to the peer edge of the\n      SPME.  It is necessary to configure the\
    \ related SPMEs and map\n      between the LSP segments being protected and the\
    \ SPME.  Mapping\n      can be 1:1 or 1:N to allow scalable protection of a set\
    \ of LSP\n      segments traversing the part of the network in which a protection\n\
    \      domain is defined.\n      Note that each of these LSPs can be initiated\
    \ or terminated at\n      different end points in the network, but that they all\
    \ traverse\n      the protection domain and share similar constraints (such as\n\
    \      requirements for QoS, terms of protection, etc.).\n   o  The protection\
    \ type that should be defined (e.g., unidirectional\n      1:1, bidirectional\
    \ 1+1, etc.)\n   o  Revertive/non-revertive behavior should be configured.\n \
    \  o  Timers (such as WTR, hold-off timer, etc.) should be set.\n"
- title: 6.1.2.  External Manual Commands
  contents:
  - "6.1.2.  External Manual Commands\n   The following external, manual commands\
    \ may be provided for manual\n   control of the protection-switching operation.\
    \  These commands apply\n   to a protection group; they are listed in descending\
    \ order of\n   priority:\n   o  Blocked protection action - a manual command to\
    \ prevent data\n      traffic from switching to the recovery entity.  This command\n\
    \      actually disables the protection group.\n   o  Force protection action\
    \ - a manual command that forces a switch of\n      normal data traffic to the\
    \ recovery entity.\n   o Manual protection action - a manual command that forces\
    \ a switch of\n      data traffic to the recovery entity only when there is no\
    \ defect\n      in the recovery entity.\n   o Clear switching command - the operator\
    \ may request that a previous\n      administrative switch command (manual or\
    \ force switch) be cleared.\n"
- title: 6.2.  Fault Detection
  contents:
  - "6.2.  Fault Detection\n   Fault detection is a fundamental part of recovery and\
    \ survivability.\n   In all schemes, with the exception of some types of 1+1 protection,\n\
    \   the actions required for the recovery of traffic delivery depend on\n   the\
    \ discovery of some kind of fault.  In 1+1 protection, the selector\n   (at the\
    \ receiving end) may simply be configured to choose the better\n   signal; thus,\
    \ it does not detect a fault or degradation of itself,\n   but simply identifies\
    \ the path that is better for data delivery.\n   Faults may be detected in a number\
    \ of ways depending on the traffic\n   pattern and the underlying hardware.  End-to-end\
    \ faults may be\n   reported by the application or by knowledge of the application's\
    \ data\n   pattern, but this is an unusual approach.  There are two more common\n\
    \   mechanisms for detecting faults in the MPLS-TP layer:\n   o  Faults reported\
    \ by the lower layers.\n   o  Faults detected by protocols within the MPLS-TP\
    \ layer.\n   In an IP/MPLS network, the second mechanism may utilize control-plane\n\
    \   protocols (such as the routing protocols) to detect a failure of\n   adjacency\
    \ between neighboring nodes.  In an MPLS-TP network, it is\n   possible that no\
    \ control plane will be present.  Even if a control\n   plane is present, it will\
    \ be a GMPLS control plane [RFC3945], which\n   logically separates control channels\
    \ from data channels; thus, no\n   conclusion about the health of a data channel\
    \ can be drawn from the\n   failure of an associated control channel.  MPLS-TP-layer\
    \ faults are,\n   therefore, only detected through the use of OAM protocols, as\n\
    \   described in Section 6.4.1.\n   Faults may, however, be reported by a lower\
    \ layer.  These generally\n   show up as interface failures or data-link failures\
    \ (sometimes known\n   as connectivity failures) within the MPLS-TP network, for\
    \ example, an\n   underlying optical link may detect loss of light and report\
    \ a failure\n   of the MPLS-TP link that uses it.  Alternatively, an interface\
    \ card\n   failure may be reported to the MPLS-TP layer.\n   Faults reported by\
    \ lower layers are only visible in specific nodes\n   within the MPLS-TP network\
    \ (i.e., at the adjacent end points of the\n   MPLS-TP link).  This would only\
    \ allow recovery to be performed\n   locally, so, to enable recovery to be performed\
    \ by nodes that are not\n   immediately local to the fault, the fault must be\
    \ reported (Sections\n   6.4.3 and 6.5.4).\n"
- title: 6.3.  Fault Localization
  contents:
  - "6.3.  Fault Localization\n   If an MPLS-TP node detects that there is a fault\
    \ in an LSP (that is,\n   not a network fault reported from a lower layer, but\
    \ a fault detected\n   by examining the LSP), it can immediately perform a recovery\
    \ action.\n   However, unless the location of the fault is known, the only\n \
    \  practical options are:\n   o  Perform end-to-end recovery.\n   o  Perform some\
    \ other recovery as a speculative act.\n   Since the speculative acts are not\
    \ guaranteed to achieve the desired\n   results and could consume resources unnecessarily,\
    \ and since end-to-\n   end recovery can require a lot of network resources, it\
    \ is important\n   to be able to localize the fault.\n   Fault localization may\
    \ be achieved by dividing the network into\n   protection domains.  End-to-end\
    \ protection is thereby operated on LSP\n   segments, depending on the domain\
    \ in which the fault is discovered.\n   This necessitates monitoring of the LSP\
    \ at the domain edges.\n   Alternatively, a proactive mechanism of fault localization\
    \ through\n   OAM (Section 6.4.3) or through the control plane (Section 6.5.3)\
    \ is\n   required.\n   Fault localization is particularly important for restoration\
    \ because\n   a new path must be selected that avoids the fault.  It may not be\n\
    \   practical or desirable to select a path that avoids the entire failed\n  \
    \ working path, and it is therefore necessary to isolate the fault's\n   location.\n"
- title: 6.4.  OAM Signaling
  contents:
  - "6.4.  OAM Signaling\n   MPLS-TP provides a comprehensive set of OAM tools for\
    \ fault\n   management and performance monitoring at different nested levels\n\
    \   (end-to-end, a portion of a path (LSP or PW), and at the link level)\n   [RFC6371].\n\
    \   These tools support proactive and on-demand fault management (for\n   fault\
    \ detection and fault localization) as well as performance\n   monitoring (to\
    \ measure the quality of the signals and detect\n   degradation).\n   To support\
    \ fast recovery, it is useful to use some of the proactive\n   tools to detect\
    \ fault conditions (e.g., link/node failure or\n   degradation) and to trigger\
    \ the recovery action.\n   The MPLS-TP OAM messages run in-band with the traffic\
    \ and support\n   unidirectional and bidirectional P2P paths as well as P2MP paths.\n\
    \   As described in [RFC6371], MPLS-TP OAM operates in the context of a\n   Maintenance\
    \ Entity that borders on the OAM responsibilities and\n   represents the portion\
    \ of a path between two points that is monitored\n   and maintained, and along\
    \ which OAM messages are exchanged.\n   [RFC6371] refers also to a Maintenance\
    \ Entity Group (MEG), which is a\n   collection of one or more Maintenance Entities\
    \ (MEs) that belong to\n   the same transport path (e.g., P2MP transport path)\
    \ and which are\n   maintained and monitored as a group.\n   An ME includes two\
    \ MEPs (Maintenance Entity Group End Points) that\n   reside at the boundaries\
    \ of an ME, and a set of zero or more MIPs\n   (Maintenance Entity Group Intermediate\
    \ Points) that reside within the\n   Maintenance Entity along the path.  A MEP\
    \ is capable of initiating\n   and terminating OAM messages, and as such can only\
    \ be located at the\n   edges of a path where push and pop operations are supported.\
    \  In\n   order to define an ME over a portion of path, it is necessary to\n \
    \  support SPMEs.\n   The SPME is an end-to-end LSP that in this context corresponds\
    \ to the\n   ME; it uses the MPLS construct of hierarchical nested LSPs, which\
    \ is\n   defined in [RFC3031].  OAM messages can be initiated at the edge of\n\
    \   the SPME and sent over G-ACH to the peer edge of the SPME.\n   The related\
    \ SPMEs must be configured, and mapping must be performed\n   between the LSP\
    \ segments being monitored and the SPME.  Mapping can\n   be 1:1 or 1:N to allow\
    \ scalable operation.  Note that each of these\n   LSPs can be initiated or terminated\
    \ at different end points in the\n   network and can share similar constraints\
    \ (such as requirements for\n   QoS, terms of protection, etc.).\n   With regard\
    \ to recovery, where MPLS-TP OAM is supported, an OAM\n   Maintenance Entity Group\
    \ is defined for each of the working and\n   protection entities.\n"
- title: 6.4.1.  Fault Detection
  contents:
  - "6.4.1.  Fault Detection\n   MPLS-TP OAM tools may be used proactively to detect\
    \ the following\n   fault conditions between MEPs:\n   o  Loss of continuity and\
    \ misconnectivity - the proactive Continuity\n      Check (CC) function is used\
    \ to detect loss of continuity between\n      two MEPs in an MEG.  The proactive\
    \ Connectivity Verification (CV)\n      allows a sink MEP to detect a misconnectivity\
    \ defect (e.g.,\n      mismerge or misconnection) with its peer source MEP when\
    \ the\n      received packet carries an incorrect ME identifier.  For\n      protection\
    \ switching, it is common to run a CC-V (Continuity Check\n      and Connectivity\
    \ Verification) message every 3.33 ms.  In the\n      absence of three consecutive\
    \ CC-V messages, loss of continuity is\n      declared and is notified locally\
    \ to the edge of the recovery\n      domain in order to trigger a recovery action.\
    \  In some cases, when\n      a slower recovery time is acceptable, it is also\
    \ possible to\n      lengthen the transmission rate.\n   o  Signal degradation\
    \ - notification from OAM performance monitoring\n      indicating degradation\
    \ in the working entity may also be used as a\n      trigger for protection switching.\
    \  In the event of degradation,\n      switching to the recovery entity is necessary\
    \ only if the recovery\n      entity can guarantee better conditions.  Degradation\
    \ can be\n      measured by proactively activating MPLS-TP OAM packet loss\n \
    \     measurement or delay measurement.\n   o  A MEP can receive an indication\
    \ from its sink MEP of a Remote\n      Defect Indication and locally notify the\
    \ end point of the recovery\n      domain regarding the fault condition, in order\
    \ to trigger the\n      recovery action.\n"
- title: 6.4.2.  Testing for Faults
  contents:
  - "6.4.2.  Testing for Faults\n   The management plane may be used to initiate the\
    \ testing of links,\n   LSP segments, or entire LSPs.\n   MPLS-TP provides OAM\
    \ tools that may be manually invoked on-demand for\n   a limited period, in order\
    \ to troubleshoot links, LSP segments, or\n   entire LSPs (e.g., diagnostics,\
    \ connectivity verification, packet\n   loss measurements, etc.).  On-demand monitoring\
    \ covers a combination\n   of \"in-service\" and \"out-of-service\" monitoring\
    \ functions.  Out-of-\n   service testing is supported by the OAM on-demand lock\
    \ operation.\n   The lock operation temporarily disables the transport entity\
    \ (LSP,\n   LSP segment, or link), preventing the transmission of all types of\n\
    \   traffic, with the exceptions of test traffic and OAM (dedicated to\n   the\
    \ locked entity).\n   [RFC6371] describes the operations of the OAM functions\
    \ that may be\n   initiated on-demand and provides some considerations.\n   MPLS-TP\
    \ also supports in-service and out-of-service testing of the\n   recovery (protection\
    \ and restoration) mechanism, the integrity of the\n   protection/recovery transport\
    \ paths, and the coordination protocol\n   between the end points of the recovery\
    \ domain.  The testing operation\n   emulates a protection-switching request but\
    \ does not perform the\n   actual switching action.\n"
- title: 6.4.3.  Fault Localization
  contents:
  - "6.4.3.  Fault Localization\n   MPLS-TP provides OAM tools to locate a fault and\
    \ determine its\n   precise location.  Fault detection often only takes place\
    \ at key\n   points in the network (such as at LSP end points or at MEPs).  This\n\
    \   means that a fault may be located anywhere within a segment of the\n   relevant\
    \ LSP.  Finer information granularity is needed to implement\n   optimal recovery\
    \ actions or to diagnose the fault.  On-demand tools\n   like trace-route, loopback,\
    \ and on-demand CC-V can be used to\n   localize a fault.\n   The information\
    \ may be notified locally to the end point of the\n   recovery domain to allow\
    \ implementation of optimal recovery action.\n   This may be useful for the re-calculation\
    \ of a recovery path.\n   The information should also be reported to network management\
    \ for\n   diagnostic purposes.\n"
- title: 6.4.4.  Fault Reporting
  contents:
  - "6.4.4.  Fault Reporting\n   The end points of a recovery domain should be able\
    \ to detect fault\n   conditions in the recovery domain and to notify the management\
    \ plane.\n   In addition, a node within a recovery domain that detects a fault\n\
    \   condition should also be able to report this to network management.\n   Network\
    \ management should be capable of correlating the fault reports\n   and identifying\
    \ the source of the fault.\n   MPLS-TP OAM tools support a function where an intermediate\
    \ node along\n   a path is able to send an alarm report message to the MEP, indicating\n\
    \   the presence of a fault condition in the server layer that connects\n   it\
    \ to its adjacent node.  This capability allows a MEP to suppress\n   alarms that\
    \ may be generated as a result of a failure condition in\n   the server layer.\n"
- title: 6.4.5.  Coordination of Recovery Actions
  contents:
  - "6.4.5.  Coordination of Recovery Actions\n   As described above, in some cases\
    \ (such as in bidirectional\n   protection switching, etc.) it is necessary to\
    \ coordinate the\n   protection states between the edges of the recovery domain.\n\
    \   [MPLS-TP-LP] defines procedures, protocol messages, and elements for\n   this\
    \ purpose.\n   The protocol is also used to signal administrative requests (e.g.,\n\
    \   manual switch, etc.), but only when these are provisioned at the edge\n  \
    \ of the recovery domain.\n   The protocol also enables mismatches to be detected\
    \ between the\n   configurations at the ends of the protection domain (such as\
    \ timers,\n   revertive/non-revertive behavior); these mismatches can subsequently\n\
    \   be reported to the management plane.\n   In the absence of suitable coordination\
    \ (owing to failures in the\n   delivery or processing of the coordination protocol\
    \ messages),\n   protection switching will fail.  This means that the operation\
    \ of the\n   protocol that coordinates the protection state is a fundamental part\n\
    \   of protection switching.\n"
- title: 6.5.  Control Plane
  contents:
  - "6.5.  Control Plane\n   The GMPLS control plane has been proposed as the control\
    \ plane for\n   MPLS-TP [RFC5317].  Since GMPLS was designed for use in transport\n\
    \   networks, and since it has been implemented and deployed in many\n   networks,\
    \ it is not surprising that it contains many features that\n   support a high\
    \ degree of survivability.\n   The signaling elements of the GMPLS control plane\
    \ utilize extensions\n   to the Resource Reservation Protocol (RSVP) (as described\
    \ in a series\n   of documents commencing with [RFC3471] and [RFC3473]), although\
    \ it is\n   based on [RFC3209] and [RFC2205].  The architecture for GMPLS is\n\
    \   provided in [RFC3945], while [RFC4426] gives a functional description\n  \
    \ of the protocol extensions needed to support GMPLS-based recovery\n   (i.e.,\
    \ protection and restoration).\n   A further control-plane protocol called the\
    \ Link Management Protocol\n   (LMP) [RFC4204] is part of the GMPLS protocol family\
    \ and can be used\n   to coordinate fault localization and reporting.\n   Clearly,\
    \ the control-plane techniques described here only apply where\n   an MPLS-TP\
    \ control plane is deployed and operated.  All mandatory\n   MPLS-TP survivability\
    \ features must be enabled, even in the absence\n   of the control plane.  However,\
    \ when present, the control plane may\n   be used to provide alternative mechanisms\
    \ that may be desirable,\n   since they offer simple automation or a richer feature\
    \ set.\n"
- title: 6.5.1.  Fault Detection
  contents:
  - "6.5.1.  Fault Detection\n   The control plane is unable to detect data-plane\
    \ faults.  However, it\n   does provide mechanisms that detect control-plane faults,\
    \ and these\n   can be used to recognize data-plane faults when it is evident\
    \ that\n   the control and data planes are fate-sharing.  Although [RFC5654]\n\
    \   specifies that MPLS-TP must support an out-of-band control channel,\n   it\
    \ does not insist that it be used exclusively.  This means that\n   there may\
    \ be deployments where an in-band (or at least an in-fiber)\n   control channel\
    \ is used.  In this scenario, failure of the control\n   channel can be used to\
    \ infer that there is a failure of the data\n   channel, or, at least, it can\
    \ be used to trigger an investigation of\n   the health of the data channel.\n\
    \   Both RSVP and LMP provide a control channel \"keep-alive\" mechanism\n   (called\
    \ the Hello message in both cases).  Failure to receive a\n   message in the configured/negotiated\
    \ time period indicates a control-\n   plane failure.  GMPLS routing protocols\
    \ ([RFC4203] and [RFC5307])\n   also include keep-alive mechanisms designed to\
    \ detect routing\n   adjacency failures.  Although these keep-alive mechanisms\
    \ tend to\n   operate at a relatively low frequency (on the order of seconds),\
    \ it\n   is still possible that the first indication of a control-plane fault\n\
    \   will be received through the routing protocol.\n   Note, however, that care\
    \ must be taken to ascertain that a specific\n   failure is not caused by a problem\
    \ in the control-plane software or\n   in a processor component at the far end\
    \ of a link.\n   Because of the various issues involved, it is not recommended\
    \ that\n   the control plane be used as the primary mechanism for fault\n   detection\
    \ in an MPLS-TP network.\n"
- title: 6.5.2.  Testing for Faults
  contents:
  - "6.5.2.  Testing for Faults\n   The control plane may be used to initiate and\
    \ coordinate the testing\n   of links, LSP segments, or entire LSPs.  This is\
    \ important in some\n   technologies where it is necessary to halt data transmission\
    \ while\n   testing, but it may also be useful where testing needs to be\n   specifically\
    \ enabled or configured.\n   LMP provides a control-plane mechanism to test the\
    \ continuity and\n   connectivity (and naming) of individual links.  A single\
    \ management\n   operation is required to initiate the test at one end of the\
    \ link,\n   while the LMP handles the coordination with the other end of the\n\
    \   link.  The test mechanism for an MPLS packet link relies on the LMP\n   Test\
    \ message inserted into the data stream at one end of the link and\n   extracted\
    \ at the other end of the link.  This mechanism need not\n   disrupt data flowing\
    \ over the link.\n   Note that a link in the LMP may, in fact, be an LSP tunnel\
    \ used to\n   form a link in the MPLS-TP network.\n   GMPLS signaling (RSVP) offers\
    \ two mechanisms that may also assist\n   with fault testing.  The first mechanism\
    \ [RFC3473] defines the\n   Admin_Status object that allows an LSP to be set into\
    \ \"testing mode\".\n   The interpretation of this mode is implementation-specific\
    \ and could\n   be documented more precisely for MPLS-TP.  The mode sets the whole\n\
    \   LSP into a state where it can be tested; this need not be disruptive\n   to\
    \ data traffic.\n   The second mechanism provided by GMPLS to support testing\
    \ is\n   described in [GMPLS-OAM].  This protocol extension supports the\n   configuration\
    \ (including enabling and disabling) of OAM mechanisms\n   for a specific LSP.\n"
- title: 6.5.3.  Fault Localization
  contents:
  - "6.5.3.  Fault Localization\n   Fault localization is the process whereby the\
    \ exact location of a\n   fault is determined.  Fault detection often only takes\
    \ place at key\n   points in the network (such as at LSP end points or at MEPs).\
    \  This\n   means that a fault may be located anywhere within a segment of the\n\
    \   relevant LSP.\n   If segment or end-to-end protection is in use, this level\
    \ of\n   information is often sufficient to repair the LSP.  However, if finer\n\
    \   information granularity is required (either to implement optimal\n   recovery\
    \ actions or to diagnose a fault), it is necessary to localize\n   the specific\
    \ fault.\n   LMP provides a cascaded test-and-propagate mechanism that is designed\n\
    \   specifically for this purpose.\n"
- title: 6.5.4.  Fault Status Reporting
  contents:
  - "6.5.4.  Fault Status Reporting\n   GMPLS signaling uses the Notify message to\
    \ report fault status\n   [RFC3473].  The Notify message can apply to a single\
    \ LSP or can carry\n   fault information for a set of LSPs, in order to improve\
    \ the\n   scalability of fault notification.\n   Since the Notify message is targeted\
    \ at a specific node, it can be\n   delivered rapidly without requiring hop-by-hop\
    \ processing.  It can be\n   targeted at LSP end points or at segment end points\
    \ (such as MEPs).\n   The target points for Notify messages can be manually configured\n\
    \   within the network, or they may be signaled when the LSP is set up.\n   This\
    \ enables the process to be made consistent with segment\n   protection as well\
    \ as with the concept of Maintenance Entities.\n   GMPLS signaling also provides\
    \ a slower, hop-by-hop mechanism for\n   reporting individual LSP faults on a\
    \ hop-by-hop basis using PathErr\n   and ResvErr messages.\n   [RFC4783] provides\
    \ a mechanism to coordinate alarms and other event\n   or fault information through\
    \ GMPLS signaling.  This mechanism is\n   useful for understanding the status\
    \ of the resources used by an LSP\n   and for providing information as to why\
    \ an LSP is not functioning;\n   however, it is not intended to replace other\
    \ fault-reporting\n   mechanisms.\n   GMPLS routing protocols [RFC4203] and [RFC5307]\
    \ are used to advertise\n   link availability and capabilities within a GMPLS-enabled\
    \ network.\n   Thus, the routing protocols can also provide indirect information\n\
    \   about network faults; that is, the protocol may stop advertising or\n   may\
    \ withdraw the advertisement for a failed link, or it may advertise\n   that the\
    \ link is about to be shut down gracefully [RFC5817].  This\n   mechanisms is,\
    \ however, not normally considered to be fast enough for\n   use as a trigger\
    \ for protection switching.\n"
- title: 6.5.5.  Coordination of Recovery Actions
  contents:
  - "6.5.5.  Coordination of Recovery Actions\n   Fault coordination is an important\
    \ feature for certain protection\n   mechanisms (such as bidirectional 1:1 protection).\
    \  The use of the\n   GMPLS Notify message for this purpose is described in [RFC4426];\n\
    \   however, specific message field values have not yet been defined for\n   this\
    \ operation.\n   Further work is needed in GMPLS for control and configuration\
    \ of\n   reversion behavior for end-to-end and segment protection, and the\n \
    \  coordination of timer values.\n"
- title: 6.5.6.  Establishment of Protection and Restoration LSPs
  contents:
  - "6.5.6.  Establishment of Protection and Restoration LSPs\n   The management plane\
    \ may be used to set up protection and recovery\n   LSPs, but, when present, the\
    \ control plane may be used.\n   Several protocol extensions exist that simplify\
    \ this process:\n   o  [RFC4872] provides features that support end-to-end protection\n\
    \      switching.\n   o  [RFC4873] describes the establishment of a single, segment-\n\
    \      protected LSP.  Note that end-to-end protection is a special case\n   \
    \   of segment protection, and [RFC4872] can also be used to provide\n      end-to-end\
    \ protection.\n   o  [RFC4874] allows an LSP to be signaled with a request that\
    \ its\n      path exclude specified resources such as links, nodes, and shared\n\
    \      risk link groups (SRLGs).  This allows a disjoint protection path\n   \
    \   to be requested or a recovery path to be set up to avoid failed\n      resources.\n\
    \   o  Lastly, it should be noted that [RFC5298] provides an overview of\n   \
    \   the GMPLS techniques available to achieve protection in multi-\n      domain\
    \ environments.\n"
- title: 7.  Pseudowire Recovery Considerations
  contents:
  - "7.  Pseudowire Recovery Considerations\n   Pseudowires provide end-to-end connectivity\
    \ over the MPLS-TP network\n   and may comprise a single pseudowire segment, or\
    \ multiple segments\n   \"stitched\" together to provide end-to-end connectivity.\n\
    \   The pseudowire may, itself, require protection, in order to meet the\n   service-level\
    \ guarantees of its SLA.  This protection could be\n   provided by the MPLS-TP\
    \ LSPs that support the pseudowire, or could be\n   a feature of the pseudowire\
    \ layer itself.\n   As indicated above, the functional architecture described\
    \ in this\n   document applies to both LSPs and pseudowires.  However, the recovery\n\
    \   mechanisms for pseudowires are for further study and will be defined\n   in\
    \ a separate document by the PWE3 working group.\n"
- title: 7.1.  Utilization of Underlying MPLS-TP Recovery
  contents:
  - "7.1.  Utilization of Underlying MPLS-TP Recovery\n   MPLS-TP PWs are carried\
    \ across the network inside MPLS-TP LSPs.\n   Therefore, an obvious way to provide\
    \ protection for a PW is to\n   protect the LSP that carries it.  Such protection\
    \ can take any of the\n   forms described in this document.  The choice of recovery\
    \ scheme will\n   depend on the required speed of recovery and the traffic loss\
    \ that is\n   acceptable for the SLA that the PW is providing.\n   If the PW is\
    \ a Multi-Segment PW, then LSP recovery can only protect\n   the PW in individual\
    \ segments.  This means that a single LSP recovery\n   action cannot protect against\
    \ a failure of a PW switching point (an\n   S-PE), nor can it protect more than\
    \ one segment at a time, since the\n   LSP tunnel is terminated at each S-PE.\
    \  In this respect, LSP\n   protection of a PW is very similar to link-level protection\
    \ offered\n   to the MPLS-TP LSP layer by an underlying network layer (see Section\n\
    \   4.9).\n"
- title: 7.2.  Recovery in the Pseudowire Layer
  contents:
  - "7.2.  Recovery in the Pseudowire Layer\n   Recovery in the PW layer can be provided\
    \ by simply running separate\n   PWs end-to-end.  Other recovery mechanisms in\
    \ the PW layer, such as\n   segment or concatenated segment recovery, or service-level\
    \ recovery\n   involving survivability of T-PE or AC faults will be described\
    \ in a\n   separate document.\n   As with any recovery mechanism, it is important\
    \ to coordinate between\n   layers.  This coordination is necessary to ensure\
    \ that actions\n   associated with recovery mechanisms are only performed in one\
    \ layer\n   at a time (that is, the recovery of an underlying LSP needs to be\n\
    \   coordinated with the recovery of the PW itself).  It also makes sure\n   that\
    \ the working and protection PWs do not both use the same MPLS\n   resources within\
    \ the network (for example, by running over the same\n   LSP tunnel; see also\
    \ Section 4.9).\n"
- title: 8.  Manageability Considerations
  contents:
  - "8.  Manageability Considerations\n   Manageability of MPLS-TP networks and their\
    \ functions is discussed in\n   [RFC5950].  OAM features are discussed in [RFC6371].\n\
    \   Survivability has some key interactions with management, as described\n  \
    \ in this document.  In particular:\n   o  Recovery domains may be configured\
    \ in a way that prevents one-to-\n      one correspondence between the MPLS-TP\
    \ network and the recovery\n      domains.\n   o  Survivability policies may be\
    \ configured per network, per recovery\n      domain, or per LSP.\n   o  Configuration\
    \ of OAM may involve the selection of MEPs; enabling\n      OAM on network segments,\
    \ spans, and links; and the operation of\n      OAM on LSPs, concatenated LSP\
    \ segments, and LSP segments.\n   o  Manual commands may be used to control recovery\
    \ functions,\n      including forcing recovery and locking recovery actions.\n\
    \   See also the considerations regarding security for management and OAM\n  \
    \ in Section 9 of this document.\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   This framework does not introduce any new security\
    \ considerations;\n   general issues relating to MPLS security can be found in\
    \ [RFC5920].\n   However, several points about MPLS-TP survivability should be\
    \ noted\n   here.\n   o  If an attacker is able to force a protection switch-over,\
    \ this may\n      result in a small perturbation to user traffic and could result\
    \ in\n      extra traffic being preempted or displaced from the protection\n \
    \     resources.  In the case of 1:n protection or shared mesh\n      protection,\
    \ this may result in other traffic becoming unprotected.\n      Therefore, it\
    \ is important that OAM protocols for detecting or\n      notifying faults use\
    \ adequate security to prevent them from being\n      used (through the insertion\
    \ of bogus messages or through the\n      capture of legitimate messages) to falsely\
    \ trigger a recovery\n      event.\n   o  If manual commands are modified, captured,\
    \ or simulated (including\n      replay), it might be possible for an attacker\
    \ to perform forced\n      recovery actions or to impose lock-out.  These actions\
    \ could\n      impact the capability to provide the recovery function and could\n\
    \      also affect the normal operation of the network for other traffic.\n  \
    \    Therefore, management protocols used to perform manual commands\n      must\
    \ allow the operator to use appropriate security mechanisms.\n      This includes\
    \ verification that the user who performs the commands\n      has appropriate\
    \ authorization.\n   o  If the control plane is used to configure or operate recovery\n\
    \      mechanisms, the control-plane protocols must also be capable of\n     \
    \ providing adequate security.\n"
- title: 10.  Acknowledgments
  contents:
  - "10.  Acknowledgments\n   Thanks to the following people for useful comments and\
    \ discussions:\n   Italo Busi, David McWalter, Lou Berger, Yaacov Weingarten,\
    \ Stewart\n   Bryant, Dan Frost, Lievren Levrau, Xuehui Dai, Liu Guoman, Xiao\
    \ Min,\n   Daniele Ceccarelli, Scott Bradner, Francesco Fondelli, Curtis\n   Villamizar,\
    \ Maarten Vissers, and Greg Mirsky.\n   The Editors would like to thank the participants\
    \ in ITU-T Study Group\n   15 for their detailed review.\n   Some figures and\
    \ text on shared mesh protection were borrowed from\n   [MPLS-TP-MESH] with thanks\
    \ to Tae-sik Cheung and Jeong-dong Ryoo.\n"
- title: 11.  References
  contents:
  - '11.  References

    '
- title: 11.1.  Normative References
  contents:
  - "11.1.  Normative References\n   [G.806]        ITU-T, \"Characteristics of transport\
    \ equipment -\n                  Description methodology and generic functionality\"\
    ,\n                  Recommendation G.806, January 2009.\n   [G.808.1]      ITU-T,\
    \ \"Generic Protection Switching - Linear trail\n                  and subnetwork\
    \ protection\", Recommendation G.808.1,\n                  December 2003.\n  \
    \ [G.841]        ITU-T, \"Types and Characteristics of SDH Network\n         \
    \         Protection Architectures\", Recommendation G.841,\n                \
    \  October 1998.\n   [RFC2205]      Braden, R., Ed., Zhang, L., Berson, S., Herzog,\
    \ S.,\n                  and S. Jamin, \"Resource ReSerVation Protocol (RSVP)\
    \ --\n                  Version 1 Functional Specification\", RFC 2205,\n    \
    \              September 1997.\n   [RFC3209]      Awduche, D., Berger, L., Gan,\
    \ D., Li, T., Srinivasan,\n                  V., and G. Swallow, \"RSVP-TE: Extensions\
    \ to RSVP for\n                  LSP Tunnels\", RFC 3209, December 2001.\n   [RFC3471]\
    \      Berger, L., Ed., \"Generalized Multi-Protocol Label\n                 \
    \ Switching (GMPLS) Signaling Functional Description\",\n                  RFC\
    \ 3471, January 2003.\n   [RFC3473]      Berger, L., Ed., \"Generalized Multi-Protocol\
    \ Label\n                  Switching (GMPLS) Signaling Resource ReserVation\n\
    \                  Protocol-Traffic Engineering (RSVP-TE) Extensions\",\n    \
    \              RFC 3473, January 2003.\n   [RFC3945]      Mannie, E., Ed., \"\
    Generalized Multi-Protocol Label\n                  Switching (GMPLS) Architecture\"\
    , RFC 3945, October\n                  2004.\n   [RFC4203]      Kompella, K.,\
    \ Ed., and Y. Rekhter, Ed., \"OSPF\n                  Extensions in Support of\
    \ Generalized Multi-Protocol\n                  Label Switching (GMPLS)\", RFC\
    \ 4203, October 2005.\n   [RFC4204]      Lang, J., Ed., \"Link Management Protocol\
    \ (LMP)\", RFC\n                  4204, October 2005.\n   [RFC4427]      Mannie,\
    \ E., Ed., and D. Papadimitriou, Ed., \"Recovery\n                  (Protection\
    \ and Restoration) Terminology for\n                  Generalized Multi-Protocol\
    \ Label Switching (GMPLS)\",\n                  RFC 4427, March 2006.\n   [RFC4428]\
    \      Papadimitriou, D., Ed., and E. Mannie, Ed., \"Analysis\n              \
    \    of Generalized Multi-Protocol Label Switching\n                  (GMPLS)-based\
    \ Recovery Mechanisms (including\n                  Protection and Restoration)\"\
    , RFC 4428, March 2006.\n   [RFC4873]      Berger, L., Bryskin, I., Papadimitriou,\
    \ D., and A.\n                  Farrel, \"GMPLS Segment Recovery\", RFC 4873,\
    \ May 2007.\n   [RFC5307]      Kompella, K., Ed., and Y. Rekhter, Ed., \"IS-IS\n\
    \                  Extensions in Support of Generalized Multi-Protocol\n     \
    \             Label Switching (GMPLS)\", RFC 5307, October 2008.\n   [RFC5317]\
    \      Bryant, S., Ed., and L. Andersson, Ed., \"Joint Working\n             \
    \     Team (JWT) Report on MPLS Architectural Considerations\n               \
    \   for a Transport Profile\", RFC 5317, February 2009.\n   [RFC5586]      Bocci,\
    \ M., Ed., Vigoureux, M., Ed., and S. Bryant,\n                  Ed., \"MPLS Generic\
    \ Associated Channel\", RFC 5586, June\n                  2009.\n   [RFC5654]\
    \      Niven-Jenkins, B., Ed., Brungard, D., Ed., Betts, M.,\n               \
    \   Ed., Sprecher, N., and S. Ueno, \"Requirements of an\n                  MPLS\
    \ Transport Profile\", RFC 5654, September 2009.\n   [RFC5921]      Bocci, M.,\
    \ Ed., Bryant, S., Ed., Frost, D., Ed.,\n                  Levrau, L., and L.\
    \ Berger, \"A Framework for MPLS in\n                  Transport Networks\", RFC\
    \ 5921, July 2010.\n   [RFC5950]      Mansfield, S., Ed., Gray, E., Ed., and K.\
    \ Lam, Ed.,\n                  \"Network Management Framework for MPLS-based Transport\n\
    \                  Networks\", RFC 5950, September 2010.\n   [RFC6371]      Buci,\
    \ I., Ed. and B. Niven-Jenkins, Ed., \"A Framework\n                  for MPLS\
    \ in Transport Networks\", RFC 6371, September\n                  2011.\n"
- title: 11.2.  Informative References
  contents:
  - "11.2.  Informative References\n   [GMPLS-OAM]    Takacs, A., Fedyk, D., and J.\
    \ He, \"GMPLS RSVP-TE\n                  extensions for OAM Configuration\", Work\
    \ in Progress,\n                  July 2011.\n   [MPLS-TP-LP]   Weingarten, Y.,\
    \ Osborne, E., Sprecher, N., Fulignoli,\n                  A., Ed., and Y. Weingarten,\
    \ Ed., \"MPLS-TP Linear\n                  Protection\", Work in Progress, August\
    \ 2011.\n   [MPLS-TP-MESH] Cheung, T. and J. Ryoo, \"MPLS-TP Shared Mesh\n   \
    \               Protection\", Work in Progress, April 2011.\n   [RFC3031]    \
    \  Rosen, E., Viswanathan, A., and R. Callon,\n                  \"Multiprotocol\
    \ Label Switching Architecture\", RFC\n                  3031, January 2001.\n\
    \   [RFC3386]      Lai, W., Ed., and D. McDysan, Ed., \"Network Hierarchy\n  \
    \                and Multilayer Survivability\", RFC 3386, November\n        \
    \          2002.\n   [RFC3469]      Sharma, V., Ed., and F. Hellstrand, Ed., \"\
    Framework\n                  for Multi-Protocol Label Switching (MPLS)-based\n\
    \                  Recovery\", RFC 3469, February 2003.\n   [RFC4397]      Bryskin,\
    \ I. and A. Farrel, \"A Lexicography for the\n                  Interpretation\
    \ of Generalized Multiprotocol Label\n                  Switching (GMPLS) Terminology\
    \ within the Context of\n                  the ITU-T's Automatically Switched\
    \ Optical Network\n                  (ASON) Architecture\", RFC 4397, February\
    \ 2006.\n   [RFC4426]      Lang, J., Ed., Rajagopalan, B., Ed., and D.\n     \
    \             Papadimitriou, Ed., \"Generalized Multi-Protocol Label\n       \
    \           Switching (GMPLS) Recovery Functional Specification\",\n         \
    \         RFC 4426, March 2006.\n   [RFC4726]      Farrel, A., Vasseur, J.-P.,\
    \ and A. Ayyangar, \"A\n                  Framework for Inter-Domain Multiprotocol\
    \ Label\n                  Switching Traffic Engineering\", RFC 4726, November\n\
    \                  2006.\n   [RFC4783]      Berger, L., Ed., \"GMPLS - Communication\
    \ of Alarm\n                  Information\", RFC 4783, December 2006.\n   [RFC4872]\
    \      Lang, J., Ed., Rekhter, Y., Ed., and D. Papadimitriou,\n              \
    \    Ed., \"RSVP-TE Extensions in Support of End-to-End\n                  Generalized\
    \ Multi-Protocol Label Switching (GMPLS)\n                  Recovery\", RFC 4872,\
    \ May 2007.\n   [RFC4874]      Lee, CY., Farrel, A., and S. De Cnodder, \"Exclude\n\
    \                  Routes - Extension to Resource ReserVation Protocol-\n    \
    \              Traffic Engineering (RSVP-TE)\", RFC 4874, April 2007.\n   [RFC5212]\
    \      Shiomoto, K., Papadimitriou, D., Le Roux, JL.,\n                  Vigoureux,\
    \ M., and D. Brungard, \"Requirements for\n                  GMPLS-Based Multi-Region\
    \ and Multi-Layer Networks\n                  (MRN/MLN)\", RFC 5212, July 2008.\n\
    \   [RFC5298]      Takeda, T., Ed., Farrel, A., Ed., Ikejiri, Y., and JP.\n  \
    \                Vasseur, \"Analysis of Inter-Domain Label Switched Path\n   \
    \               (LSP) Recovery\", RFC 5298, August 2008.\n   [RFC5817]      Ali,\
    \ Z., Vasseur, JP., Zamfir, A., and J. Newton,\n                  \"Graceful Shutdown\
    \ in MPLS and Generalized MPLS\n                  Traffic Engineering Networks\"\
    , RFC 5817, April 2010.\n   [RFC5920]      Fang, L., Ed., \"Security Framework\
    \ for MPLS and GMPLS\n                  Networks\", RFC 5920, July 2010.\n   [RFC6373]\
    \      Andersson, L., Ed., Berger, L., Ed., Fang, L., Ed.,\n                 \
    \ and Bitar, N., Ed, and E. Gray, Ed., \"MPLS-TP Control\n                  Plane\
    \ Framework\", RFC 6373, September 2011.\n   [RFC6291]      Andersson, L., van\
    \ Helvoort, H., Bonica, R.,\n                  Romascanu, D., and S. Mansfield,\
    \ \"Guidelines for the\n                  Use of the \"OAM\" Acronym in the IETF\"\
    , BCP 161, RFC\n                  6291, June 2011.\n   [ROSETTA]      Van Helvoort,\
    \ H., Ed., Andersson, L., Ed., and N.\n                  Sprecher, Ed., \"A Thesaurus\
    \ for the Terminology used\n                  in Multiprotocol Label Switching\
    \ Transport Profile\n                  (MPLS-TP) drafts/RFCs and ITU-T's Transport\
    \ Network\n                  Recommendations\", Work in Progress, June 2011.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Nurit Sprecher (editor)\n   Nokia Siemens Networks\n \
    \  3 Hanagar St.\n   Neve Ne'eman B Hod\n   Hasharon, 45241 Israel\n   EMail:\
    \ nurit.sprecher@nsn.com\n   Adrian Farrel (editor)\n   Juniper Networks\n   EMail:\
    \ adrian@olddog.co.uk\n"
