- title: __initial_text__
  contents:
  - '   Security Implications of Using the Data Encryption Standard (DES)

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The IETF Trust (2006).\n"
- title: Abstract
  contents:
  - "Abstract\n   The Data Encryption Standard (DES) is susceptible to brute-force\n\
    \   attacks, which are well within the reach of a modestly financed\n   adversary.\
    \  As a result, DES has been deprecated, and replaced by the\n   Advanced Encryption\
    \ Standard (AES).  Nonetheless, many applications\n   continue to rely on DES\
    \ for security, and designers and implementers\n   continue to support it in new\
    \ applications.  While this is not always\n   inappropriate, it frequently is.\
    \  This note discusses DES security\n   implications in detail, so that designers\
    \ and implementers have all\n   the information they need to make judicious decisions\
    \ regarding its\n   use.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \      1.1. Executive Summary of Findings and Recommendations ..........4\n  \
    \         1.1.1. Recommendation Summary ..............................4\n   2.\
    \ Why Use Encryption? .............................................5\n   3. Real-World\
    \ Applications and Threats .............................6\n   4. Attacking DES\
    \ ...................................................8\n      4.1. Brute-Force\
    \ Attacks ........................................9\n           4.1.1. Parallel\
    \ and Distributed Attacks ...................10\n      4.2. Cryptanalytic Attacks\
    \ .....................................10\n      4.3. Practical Considerations\
    \ ..................................12\n   5. The EFF DES Cracker ............................................12\n\
    \   6. Other DES-Cracking Projects ....................................13\n  \
    \ 7. Building a DES Cracker Today ...................................14\n    \
    \  7.1. FPGAs .....................................................15\n      7.2.\
    \ ASICs .....................................................16\n      7.3. Distributed\
    \ PCs ...........................................16\n           7.3.1. Willing\
    \ Participants ...............................17\n           7.3.2. Spyware and\
    \ Viruses and Botnets (oh my!) ...........18\n   8. Why is DES Still Used? .........................................19\n\
    \   9. Security Considerations ........................................20\n  \
    \ 10. Acknowledgements ..............................................21\n   Appendix\
    \ A.  What About 3DES? .....................................22\n      A.1. Brute-Force\
    \ Attacks on 3DES ...............................22\n      A.2. Cryptanalytic\
    \ Attacks Against 3DES ........................23\n           A.2.1. Meet-In-The-Middle\
    \ (MITM) Attacks ..................23\n           A.2.2. Related Key Attacks ................................24\n\
    \      A.3. 3DES Block Size ...........................................25\n  \
    \ Informative References ............................................25\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The Data Encryption Standard [DES] is the first encryption\
    \ algorithm\n   approved by the U.S. government for public disclosure.  Brute-force\n\
    \   attacks became a subject of speculation immediately following the\n   algorithm's\
    \ release into the public sphere, and a number of\n   researchers published discussions\
    \ of attack feasibility and explicit\n   brute-force attack methodologies, beginning\
    \ with [DH77].\n   In the early to mid 1990s, numerous additional papers appeared,\n\
    \   including Wiener's \"Efficient DES Key Search\" [WIEN94], and \"Minimal\n\
    \   Key Lengths for Symmetric Ciphers to Provide Adequate Commercial\n   Security\"\
    \ [BLAZ96].  While these and various other papers discussed\n   the theoretical\
    \ aspects of DES-cracking machinery, none described a\n   specific implementation\
    \ of such a machine.  In 1998, the Electronic\n   Frontier Foundation (EFF) went\
    \ much further, actually building a\n   device and freely publishing the implementation\
    \ details for public\n   review [EFF98].\n   Despite the fact that the EFF clearly\
    \ demonstrated that DES could be\n   brute-forced in an average of about 4.5 days\
    \ with an investment of\n   less than $250,000 in 1998, many continue to rely\
    \ on this algorithm\n   even now, more than 8 years later.  Today, the landscape\
    \ is\n   significantly different: DES can be broken by a broad range of\n   attackers\
    \ using technologies that were not available in 1998,\n   including cheap Field\
    \ Programmable Gate Arrays (FPGAs) and botnets\n   [BOT05].  These and other attack\
    \ methodologies are described in\n   detail below.\n   Given that the Advanced\
    \ Encryption Standard [AES] has been approved\n   by the U.S. government (under\
    \ certain usage scenarios) for top-secret\n   applications [AES-NSA], and that\
    \ triple DES (3DES) is not susceptible\n   to these same attacks, one might wonder:\
    \ why even bother with DES\n   anymore?  Under more ideal circumstances, we might\
    \ simply dispense\n   with it, but unfortunately, this would not be so simple\
    \ today.  DES\n   has been widely deployed since its release in the 1970s, and\
    \ many\n   systems rely on it today.  Wholesale replacement of such systems\n\
    \   would be very costly.  A more realistic approach entails gradual\n   replacement\
    \ of these systems, and this implies a term of backward\n   compatibility support\
    \ of indefinite duration.\n   In addition to backward compatibility, in isolated\
    \ instances there\n   may be other valid arguments for continued DES support.\
    \  Still,\n   reliance upon this deprecated algorithm is a serious error from\
    \ a\n   security design perspective in many cases.  This note aims to clarify\n\
    \   the security implications of this choice given the state of\n   technology\
    \ today, so that developers can make an informed decision as\n   to whether or\
    \ not to implement this algorithm.\n"
- title: 1.1.  Executive Summary of Findings and Recommendations
  contents:
  - "1.1.  Executive Summary of Findings and Recommendations\n   For many years now,\
    \ DES usage has been actively discouraged by the\n   security area of the IETF,\
    \ but we nevertheless continue to see it in\n   use.  Given that there are widely\
    \ published accounts of real attacks\n   and that we have been vocally discouraging\
    \ its use, a question\n   arises: why aren't people listening?  We can only speculate,\
    \ but one\n   possibility is that they simply do not understand the extent to\
    \ which\n   DES has been marginalized by advancing cryptographic science and\n\
    \   technology.  Another possibility is that we have not yet been\n   appropriately\
    \ explicit and aggressive about this.  With these\n   particular possibilities\
    \ in mind, this note sets out to dispel any\n   remaining illusions.\n   The depth\
    \ of background knowledge required to truly understand and\n   fully appreciate\
    \ the security risks of using DES today is somewhat\n   daunting, and an extensive\
    \ survey of the literature suggests that\n   there are very few published materials\
    \ encompassing more than a\n   fraction of the considerations all in one place,\
    \ with [CURT05] being\n   one notable exception.  However, even that work does\
    \ not gather all\n   of the pieces in such a way as to inform an implementer of\
    \ the\n   current real-world risks, so here we try to fill in any remaining\n\
    \   gaps.\n   For convenience, the next section contains a brief summary of\n\
    \   recommendations.  If you don't know the IETF's current position on\n   DES,\
    \ and all you want is a summary, you may be content to simply read\n   the recommendation\
    \ summary section, and skip the rest of the\n   document.  If you want a more\
    \ detailed look at the history and\n   current state-of-the-art with respect to\
    \ attacking DES, you will find\n   that in subsequent sections.\n"
- title: 1.1.1.  Recommendation Summary
  contents:
  - "1.1.1.  Recommendation Summary\n   There are several ways to attack a cryptographic\
    \ algorithm, from\n   simple brute force (trying each key until you find the right\
    \ one) to\n   more subtle cryptanalytic approaches, which take into account the\n\
    \   internal structure of the cipher.  As noted in the introduction, a\n   dedicated\
    \ system capable of brute-forcing DES keys in less than 5\n   days was created\
    \ in 1998.  Current \"Moore's Law\" estimates suggest\n   that a similar machine\
    \ could be built today for around $15,000 or\n   less, and for the cost of the\
    \ original system (~$250,000) we could\n   probably build a machine capable of\
    \ cracking DES keys in a few hours.\n   Additionally, there have been a number\
    \ of successful distributed\n   attacks on DES [CURT05], and with the recent arrival\
    \ of botnets\n   [BOT05], these results are all the more onerous.  Furthermore,\
    \ there\n   are a number of cryptanalytic attacks against DES, and while some\
    \ of\n   these remain purely theoretical in nature at present, at least one\n\
    \   was recently implemented using a FPGA that can deduce a DES key in\n   12-15\
    \ hours [FPL02].  Clearly, DES cannot be considered a \"strong\"\n   cryptographic\
    \ algorithm by today's standards.\n   To summarize current recommendations on\
    \ using DES, the simple answer\n   is \"don't use it - it's not safe.\"  While\
    \ there may be use cases for\n   which the security of DES would be sufficient,\
    \ it typically requires\n   a security expert to determine when this is true.\
    \  Also, there are\n   much more secure algorithms available today (e.g., 3DES,\
    \ AES) that\n   are much safer choices.  The only general case in which DES should\n\
    \   still be supported is when it is strictly required for backward\n   compatibility,\
    \ and when the cost of upgrading outweighs the risk of\n   exposure.  However,\
    \ even in these cases, recommendations should\n   probably be made to phase out\
    \ such systems.\n   If you are simply interested in the current recommendations,\
    \ there\n   you have it: don't use DES.  If you are interested in understanding\n\
    \   how we arrive at this conclusion, read on.\n"
- title: 2.  Why Use Encryption?
  contents:
  - "2.  Why Use Encryption?\n   In order to assess the security implications of using\
    \ DES, it is\n   useful and informative to review the basic rationale for using\n\
    \   encryption.  In general, we encrypt information because we desire\n   confidentiality.\
    \  That is, we want to limit access to information, to\n   keep something private\
    \ or secret.  In some cases, we want to share\n   the information within a limited\
    \ group, and in other cases, we may\n   want to be the sole owner of the information\
    \ in question.\n   Sometimes, the information we want to protect has value only\
    \ to the\n   individual (e.g., a diary), and a loss of confidentiality, while\n\
    \   potentially damaging in some limited ways, would typically not be\n   catastrophic.\
    \  In other cases, the information might have significant\n   financial implications\
    \ (e.g., a company's strategic marketing plan).\n   And in yet others, lives could\
    \ be at stake.\n   In order to gauge our confidentiality requirements in terms\
    \ of\n   encryption strength, we must assess the value of the information we\n\
    \   are trying to protect, both to us and to a potential attacker.  There\n  \
    \ are various metrics we can employ for this purpose:\n   o  Cost of confidentiality\
    \ loss: What could we lose if an adversary\n      were to discover our secret?\
    \  This gives some measure of how much\n      effort we should be willing to expend\
    \ to protect the secret.\n   o  Value to adversary: What does the attacker have\
    \ to gain by\n      discovering our secret?  This gives some measure of how much\
    \ an\n      adversary might reasonably be willing to spend to learn the\n    \
    \  secret.\n   o  Window of opportunity: How long does the information have value\
    \ to\n      an adversary?  This gives some measure of how acceptable a\n     \
    \ weakness might be.  For example, if the information is valuable to\n      an\
    \ attacker for months and it takes only days to break the\n      encryption, we\
    \ probably need much stronger encryption.  On the\n      other hand, if the window\
    \ of opportunity is measured in seconds,\n      then an encryption algorithm that\
    \ takes days to break may be\n      acceptable.\n   There are certainly other\
    \ factors we would consider in conducting a\n   comprehensive security analysis,\
    \ but these are enough to give a\n   general sense of important questions to answer\
    \ when evaluating DES as\n   a candidate encryption algorithm.\n"
- title: 3.  Real-World Applications and Threats
  contents:
  - "3.  Real-World Applications and Threats\n   Numerous commonly used applications\
    \ rely on encryption for\n   confidentiality in today's Internet.  To evaluate\
    \ the sufficiency of\n   a given cryptographic algorithm in this context, we should\
    \ begin by\n   asking some basic questions: what are the real-world risks to these\n\
    \   applications, i.e., how likely is it that an application might\n   actually\
    \ be attacked, and by whom, and for what reasons?\n   While it is difficult to\
    \ come up with one-size-fits-all answers based\n   on general application descriptions,\
    \ we can easily get some sense of\n   the relative threat to many of these applications.\
    \  It is important\n   to note that what follows is not an exhaustive enumeration\
    \ of all\n   likely threats and attacks, but rather, a sampling that illustrates\n\
    \   that real threats are more prevalent than intuition might suggest.\n   Here\
    \ are some examples of common applications and related threats:\n   o  Site-to-site\
    \ VPNs: Often, these are used to connect geographically\n      separate corporate\
    \ offices.  Data traversing such links is often\n      business critical, and\
    \ sometimes highly confidential.  The FBI\n      estimates that every year, billions\
    \ of U.S. dollars are lost to\n      foreign competitors who deliberately target\
    \ economic intelligence\n      in U.S. industry and technologies [FBI06].  Searching\
    \ for\n      'corporate espionage' in Google yields many interesting links,\n\
    \      some of which indicate that foreign competitors are not the only\n    \
    \  threat to U.S. businesses.  Obviously, this threat can be\n      generalized\
    \ to include businesses of any nationality.\n   o  Remote network access for business:\
    \ See previous item.\n   o  Webmail/email encryption: See Site-to-site VPNs.\n\
    \   o  Online banking: Currently, the most common threat to online\n      banking\
    \ is in the form of \"phishing\", which does not rely on\n      breaking session\
    \ encryption, but instead relies on tricking users\n      into providing their\
    \ account information.  In general, direct\n      attacks on session encryption\
    \ for this application do not scale\n      well.  However, if a particular bank\
    \ were known to use a weak\n      encryption algorithm for session security, it\
    \ might become\n      worthwhile to develop a broader attack against that bank.\
    \  Given\n      that organized criminal elements have been found behind many\n\
    \      phishing attacks, it is not difficult to imagine such scenarios.\n   o\
    \  Electronic funds transfers (EFTs): The ability to replay or\n      otherwise\
    \ modify legitimate EFTs has obvious financial incentives\n      (and implications).\
    \  Also, an industrial spy might see a great\n      deal of intelligence value\
    \ in the financial transactions of a\n      target company.\n   o  Online purchases\
    \ (E-commerce): The FBI has investigated a number\n      of organized attacks\
    \ on e-commerce applications [FBI01].  If an\n      attacker has the ability to\
    \ monitor e-commerce traffic directed to\n      a large merchant that relies on\
    \ weak encryption, the attacker\n      could harvest a great deal of consumer\
    \ credit information.  This\n      is the sort of data \"phishers\" currently\
    \ harvest on a much smaller\n      scale, so one can easily imagine the value\
    \ of such a target.\n   o  Internet-based VoIP applications (e.g., Skype): While\
    \ many uses of\n      this technology are innocuous (e.g., long distance calls\
    \ to family\n      members), VoIP technology is also used for business purposes\
    \ (see\n      discussion of FBI estimates regarding corporate espionage above).\n\
    \   o  Cellular telephony: Cell phones are very common, and are\n      frequently\
    \ used for confidential conversations in business,\n      medicine, law enforcement,\
    \ and other applications.\n   o  Wireless LAN: Wireless technology is used by\
    \ many businesses,\n      including the New York Stock Exchange [NYSE1].  The\
    \ financial\n      incentives for an attacker are significant in some cases.\n\
    \   o  Personal communications (e.g., secure instant messaging): Such\n      communication\
    \ may be used for corporate communications (see\n      industrial espionage discussion\
    \ above), and may also be used for\n      financial applications such as stock/securities\
    \ trading.  This has\n      both corporate/industrial espionage and financial\
    \ implications.\n   o  Laptop hard-drive encryption: See discussion on corporate/\n\
    \      industrial espionage above.  Also, consider that stolen and lost\n    \
    \  laptops have been cited for some of the more significant losses of\n      control\
    \ over sensitive personal information in recent years,\n      notably the Veterans\
    \ Affairs data loss [VA1].\n   There are real-world threats to everyday encryption\
    \ applications,\n   some of which could be very lucrative to an attacker (and\
    \ by\n   extension, very costly to the victim).  It is important to note that\n\
    \   if some of these attacks are infrequent today, it is precisely\n   because\
    \ the threats are recognized, and appropriately strong\n   cryptographic algorithms\
    \ are used.  If \"weak\" cryptographic\n   algorithms were to be used instead,\
    \ the implications are indeed\n   thought-provoking.\n   In keeping with the objectives\
    \ of this document, it is important to\n   note that the U.S. government has never\
    \ approved the use of DES for\n   anything but unclassified applications.  While\
    \ DES is still approved\n   for unclassified uses until May 19, 2007, the U.S.\
    \ government clearly\n   sees the need to move to higher ground.  For details\
    \ on the National\n   Institute of Standards and Technology (NIST) DES Transition\
    \ plan, see\n   [NIST-TP].  Despite this fact, DES is still sometimes chosen to\n\
    \   protect some of the applications described above.  Below, we discuss\n   why\
    \ this should, in many cases, be remedied.\n"
- title: 4.  Attacking DES
  contents:
  - "4.  Attacking DES\n   DES is a 64-bit block cipher having a key size of 56 bits.\
    \  The key\n   actually has 64 bits (matching the block size), but 1 bit in each\n\
    \   byte has been designated a 'parity' bit, and is not used for\n   cryptographic\
    \ purposes.  For a full discussion of the history of DES\n   along with an accessible\
    \ description of the algorithm, see [SCHN96].\n   A detailed description of the\
    \ various types of attacks on\n   cryptographic algorithms is beyond the scope\
    \ of this document, but\n   for clarity, we provide the following brief descriptions.\
    \  There are\n   two general aspects of attacks we must consider: the form of\
    \ the\n   inputs/outputs along with how we might influence them, and the\n   internal\
    \ function of the cryptographic operations themselves.\n   In terms of input/output\
    \ form, some of the more commonly discussed\n   attack characteristics include\
    \ the following:\n   o  known plaintext - the attacker knows some of the plaintext\n\
    \      corresponding to some of the ciphertext\n   o  ciphertext-only - only ciphertext\
    \ is available to the attacker,\n      who has little or no information about\
    \ the plaintext\n   o  chosen plaintext - the attacker can choose which plaintext\
    \ is\n      encrypted, and obtain the corresponding ciphertext\n   o  birthday\
    \ attacks - relies on the fact that for N elements,\n      collisions can be expected\
    \ in ~sqrt(N) randomly chosen samples;\n      for systems using CBC mode with\
    \ random Initialization Vectors\n      (IVs), ciphertext collisions can be expected\
    \ in about 2^28\n      samples.  Such collisions leak information about the corresponding\n\
    \      plaintexts: if the same cryptographic key is used, then the xor of\n  \
    \    the IVs is equal to the xor of the plaintexts.\n   o  meet-in-the-middle\
    \ attacks - leverages birthday characteristic to\n      precompute potential key\
    \ collision values\n   Due to the limited scope of this document, these are very\
    \ brief\n   descriptions of very complex subject matter.  For more detailed\n\
    \   discussions on these and many related topics, see [SCHN96], [HAC], or\n  \
    \ [FERG03].\n   As for attack characteristics relating to the operational aspects\
    \ of\n   cipher algorithms, there are essentially two broad classes we\n   consider:\
    \ cryptanalytic attacks, which exploit some internal\n   structure or function\
    \ of the cipher algorithm, and brute-force\n   attacks, in which the attacker\
    \ systematically tries keys until the\n   right one is found.  These could alternatively\
    \ be referred to as\n   white box and black box attacks, respectively.  These\
    \ are discussed\n   further below.\n"
- title: 4.1.  Brute-Force Attacks
  contents:
  - "4.1.  Brute-Force Attacks\n   In general, a brute-force attack consists of trying\
    \ each possible key\n   until the correct key is found.  In the worst case, this\
    \ will require\n   2^n steps for a key size of n bits, and on average, it will\
    \ require\n   2^n-1 steps.  For DES, this implies 2^56 encryption operations in\
    \ the\n   worst case, and 2^55 encryption operations on average, if we assume\n\
    \   no shortcuts exist.  As it turns out, the complementation property of\n  \
    \ DES provides an attack that yields a reduction by a factor of 2 for a\n   chosen\
    \ plaintext attack, so this attack requires an average of 2^54\n   encryption\
    \ operations.\n   Above, we refer to 2^n 'steps'; note that what a 'step' entails\n\
    \   depends to some extent on the first attack aspect described above,\n   i.e.,\
    \ what influence and knowledge we have with respect to input/\n   output forms.\
    \  Remember, in the worst case, we will be performing\n   72,057,594,037,927,936\
    \ -- over 72 quadrillion -- of these 'steps'.\n   In the most difficult case,\
    \ we have ciphertext only, and no knowledge\n   of the input, and this is very\
    \ important.\n   If the input is effectively random, we cannot tell by simply\
    \ looking\n   at a decrypted block whether we've succeeded or not.  We may have\
    \ to\n   resort to other potentially expensive computation to make this\n   determination.\
    \  While the effect of any additional computation will\n   be linear across all\
    \ keys, repeating a large amount of added\n   computation up to 72 quadrillion\
    \ times could have a significant\n   impact on the cost of a brute-force attack\
    \ against the algorithm.\n   For example, if it takes 1 additional microsecond\
    \ per computation,\n   this will add almost 101 days to our worst-case search\
    \ time, assuming\n   a serial key search.\n   On the other hand, if we can control\
    \ the input to the encryption\n   function (known plaintext), we know precisely\
    \ what to expect from the\n   decryption function, so detecting that we've found\
    \ the key is\n   straightforward.  Alternatively, even if we don't know the exact\n\
    \   input, if we know something about it (e.g., that it's ASCII), with\n   limited\
    \ additional computation we can infer that we've most likely\n   found a key.\
    \  Obviously, which of these conditions holds may\n   significantly influence\
    \ attack time.\n"
- title: 4.1.1.  Parallel and Distributed Attacks
  contents:
  - "4.1.1.  Parallel and Distributed Attacks\n   Given that a brute-force attack\
    \ involves systematically trying keys\n   until we find the right one, it is obviously\
    \ a good candidate for\n   parallelization.  If we have N processors, we can find\
    \ the key\n   roughly N times faster than if we have only 1 processor.  This\n\
    \   requires some sort of centralized control entity that distributes the\n  \
    \ work and monitors the search process, but is quite straightforward to\n   implement.\n\
    \   There are at least two approaches to parallelization of a brute-force\n  \
    \ attack on a block cipher: the first is to build specialized high-\n   speed\
    \ hardware that can rapidly cycle through keys while performing\n   the cryptographic\
    \ and comparison operations, and then replicate that\n   hardware many times,\
    \ while providing for centralized control.  The\n   second involves using many\
    \ copies of general purpose hardware (e.g.,\n   a PC), and distributing the load\
    \ across these while placing them\n   under the control of one or more central\
    \ systems.  Both of these\n   approaches are discussed further in sections 5 and\
    \ 6.\n"
- title: 4.2.  Cryptanalytic Attacks
  contents:
  - "4.2.  Cryptanalytic Attacks\n   Brute-force attacks are so named because they\
    \ don't require much\n   intelligence in the attack process -- they simply try\
    \ one key after\n   the other, with little or no intelligent keyspace pruning.\n\
    \   Cryptanalytic attacks, on the other hand, rely on application of some\n  \
    \ intelligence ahead of time, and by doing so, provide for a\n   significant reduction\
    \ of the search space.\n   While an in-depth discussion of cryptanalytic techniques\
    \ and the\n   resulting attacks is well beyond the scope of this document, it\
    \ is\n   important to briefly touch on this area in order to set the stage for\n\
    \   subsequent discussion.  It is also important to note that, in\n   general,\
    \ cryptanalysis can be applied to any cryptographic algorithm\n   with varying\
    \ degrees of success.  However, we confine ourselves here\n   to discussing specific\
    \ results with respect to DES.\n   Here is a very brief summary of the currently\
    \ known cryptanalytic\n   attacks on DES:\n   o  Differential Cryptanalysis -\
    \ First discussed by Biham and Shamir,\n      this technique (putting it very\
    \ simply) analyzes how differences\n      in plaintext correspond to differences\
    \ in ciphertext.  For more\n      detail, see [BIH93].\n   o  Linear Cryptanalysis\
    \ - First described by Matsui, this technique\n      uses linear approximations\
    \ to describe the internal functions of\n      DES.  For more detail, see [MAT93].\n\
    \   o  Interpolation Attack - This technique represents the S-boxes of\n     \
    \ DES with algebraic functions, and then estimates the coefficients\n      of\
    \ the functions.  For more information, see [JAK97].\n   o  Key Collision Attack\
    \ - This technique exploits the birthday\n      paradox to produce key collisions\
    \ [BIH96].\n   o  Differential Fault Analysis - This attack exploits the electrical\n\
    \      characteristics of the encryption device, selectively inducing\n      faults\
    \ and comparing the results with uninfluenced outputs.  For\n      more information,\
    \ see [BIH96-2].\n   Currently, the best publicly known cryptanalytic attacks\
    \ on DES are\n   linear and differential cryptanalysis.  These attacks are not\n\
    \   generally considered practical, as they require 2^43 and 2^47 known\n   plaintext/ciphertext\
    \ pairs, respectively.  To get a feel for what\n   this means in practical terms,\
    \ consider the following:\n   o  For linear cryptanalysis (the more efficient\
    \ of the two attacks),\n      the attacker must pre-compute and store 2^43 ciphertexts;\
    \ this\n      requires 8,796,093,022,208 (almost 9 trillion) encryption\n    \
    \  operations.\n   o  Each ciphertext block is 8 bytes, so the total required\
    \ storage is\n      70,368,744,177,664 bytes, or about 70,369 gigabytes of storage.\n\
    \      If the plaintext blocks cannot be automatically derived, they too\n   \
    \   must be stored, potentially doubling the storage requirements.\n   o  The\
    \ 2^43 known plaintext blocks must be somehow fed to the device\n      under attack,\
    \ and that device must not change the encryption key\n      during this time.\n\
    \   Clearly, there are practical issues with this attack.  Still, it is\n   sobering\
    \ to look at how much more realistic 70,000 gigabytes of\n   storage is today\
    \ than it must have seemed in 1993, when Matsui first\n   proposed this attack.\
    \  Today, 400-GB hard drives can be had for\n   around $0.35/gigabyte.  If we\
    \ only needed to store the known\n   ciphertext, this amounts to ~176 hard drives\
    \ at a cost of less than\n   $25,000.  This is probably practical with today's\
    \ technology for an\n   adversary with significant financial resources, though\
    \ it was\n   difficult to imagine in 1993.  Still, numerous other practical issues\n\
    \   remain.\n"
- title: 4.3.  Practical Considerations
  contents:
  - "4.3.  Practical Considerations\n   Above, we described several types of attacks\
    \ on DES, some of which\n   are more practical than others, but it's very important\
    \ to recognize\n   that brute force represents the very worst case, and cryptanalytic\n\
    \   attacks can only improve on this.  If a brute-force attack against a\n   given\
    \ DES application really is feasible, then worrying about the\n   practicality\
    \ of the other theoretical attack modes is just a\n   distraction.  The bottom\
    \ line is this: if DES can be brute-forced at\n   a cost the attacker can stomach\
    \ today, this cost will invariably come\n   down as technology advances.\n"
- title: 5.  The EFF DES Cracker
  contents:
  - "5.  The EFF DES Cracker\n   On the question as to whether DES is susceptible\
    \ to brute-force\n   attack from a practical perspective, the answer is a resounding\
    \ and\n   unequivocal \"yes\".  In 1998, the Electronic Frontier Foundation\n\
    \   financed the construction of a \"DES Cracker\", and subsequently\n   published\
    \ \"Cracking DES\" [EFF98].  For a cost of less than $250,000,\n   this system\
    \ can find a 56-bit DES key in the worst-case time of\n   around 9 days, and in\
    \ 4.5 days on average.\n   Quoting from [EFF98],\n   \"The design of the EFF DES\
    \ Cracker is simple in concept.  It consists\n   of an ordinary personal computer\
    \ connected with a large array of\n   custom chips.  Software in the personal\
    \ computer instructs the custom\n   chips to begin searching, and interacts with\
    \ the user.  The chips run\n   without further help from the software until they\
    \ find a potentially\n   interesting key, or need to be directed to search a new\
    \ part of the\n   key space.  The software periodically polls the chips to find\
    \ any\n   potentially interesting keys that they have turned up.\n   The hardware's\
    \ job isn't to find the answer. but rather to eliminate\n   most of the answers\
    \ that are incorrect.  Software is then fast enough\n   to search the remaining\
    \ potentially-correct keys, winnowing the false\n   positives from the real answer.\
    \  The strength of the machine is that\n   it replicates a simple but useful search\
    \ circuit thousands of times,\n   allowing the software to find the answer by\
    \ searching only a tiny\n   fraction of the key space.\n   As long as there is\
    \ a small bit of software to coordinate the effort,\n   the problem of searching\
    \ for a DES key is 'highly parallelizable'.\n   This means the problem can be\
    \ usefully solved by many machines\n   working in parallel, simultaneously.  For\
    \ example, a single DES-\n   Cracker chip could find a key by searching for many\
    \ years.  A\n   thousand DES-Cracker chips can solve the same problem in one\n\
    \   thousandth of the time.  A million DES-Cracker chips could\n   theoretically\
    \ solve the same problem in about a millionth of the\n   time, though the overhead\
    \ of starting each chip would become visible\n   in the time required.  The actual\
    \ machine we built contains 1536\n   chips.\"\n   This project clearly demonstrated\
    \ that a practical system for brute\n   force DES attacks was well within reach\
    \ of many more than previously\n   assumed.  Practically any government in the\
    \ world could easily\n   produce such a machine, and in fact, so could many businesses.\
    \  And\n   that was in 1998; the technological advances since then have greatly\n\
    \   reduced the cost of such a device.  This is discussed further below.\n"
- title: 6.  Other DES-Cracking Projects
  contents:
  - "6.  Other DES-Cracking Projects\n   In the mid-1990s, many were interested in\
    \ whether or not DES was\n   breakable in a practical sense.  RSA sponsored a\
    \ series of DES\n   Challenges over a 3-year period beginning January of 1997.\
    \  These\n   challenges were created in order to help underscore the point that\n\
    \   cryptographic strength limitations imposed by the U.S. government's\n   export\
    \ policies were far too modest to meet the security requirements\n   of many users.\n\
    \   The first DES challenge was solved by the DESCHALL group, led by\n   Rocke\
    \ Verser, Matt Curtin, and Justin Dolske [CURT05][RSA1].  They\n   created a loosely-knit\
    \ distributed effort staffed by volunteers and\n   backed by Universities and\
    \ corporations all over the world who\n   donated their unused CPU cycles to the\
    \ effort.  They found the key in\n   90 days.\n   The second DES challenge was\
    \ announced on December 19, 1997\n   [RSA2][CURT05], and on February 26, 1998,\
    \ RSA announced a winner.\n   This time, the challenge was solved by group called\
    \ distributed.net\n   working together with the EFF, in a total of 39 days [RSA3]\
    \ [CURT05].\n   This group coordinated 22,000 participants and over 50,000 CPUs.\n\
    \   The third DES challenge was announced on December 22, 1998\n   [RSA4][CURT05],\
    \ and on January 19, 1999, RSA announced the winner.\n   This time, the challenge\
    \ was again solved by distributed.net working\n   together with the EFF, in a\
    \ total of 22 hours [RSA5].  This was a\n   dramatic improvement over the second\
    \ challenge, and should give some\n   idea of where we're headed with respect\
    \ to DES.\n"
- title: 7.  Building a DES Cracker Today
  contents:
  - "7.  Building a DES Cracker Today\n   We've seen what was done in the late 1990s\
    \ -- what about today?  A\n   survey of the literature might lead one to conclude\
    \ that this topic\n   is no longer interesting to cryptographers.  Hence, we are\
    \ left to\n   infer the possibilities based on currently available technologies.\n\
    \   One way to derive an approximation is to apply a variation on\n   \"Moore's\
    \ Law\": assume that the cost of a device comparable to the one\n   built by the\
    \ EFF would be halved roughly every N months.  If we take\n   N=18, then for a\
    \ device costing $250,000 at the end of 1998, this\n   would predict the following\
    \ cost curve:\n   o  mid-2000............: $125,000\n   o  beginning of 2002...:\
    \ $62,500\n   o  mid-2003............: $31,250\n   o  beginning of 2006...: $15,625\n\
    \   It's important to note that strictly speaking, \"Moore's Law\" is more\n \
    \  an informal approximation than a law, although it has proven to be\n   uncannily\
    \ accurate over the last 40 years or so.  Also, some would\n   disagree with the\
    \ use of an 18-month interval, preferring a more\n   conservative 24 months instead.\
    \  So, these figures should be taken\n   with the proverbial grain of salt.  Still,\
    \ it's important to\n   recognize that this is the cost needed not to crack one\
    \ key, but to\n   get into the key-cracking business.  Offering key-cracking services\n\
    \   and keeping the machine relatively busy would dramatically decrease\n   the\
    \ cost to a few hundred dollars per unit or less.\n   Given that such calculations\
    \ roughly hold for other computing\n   technologies over the same time interval,\
    \ the estimate above does not\n   seem too unreasonable, and is probably within\
    \ a factor of two of\n   today's costs.  Clearly, this would seem to indicate\
    \ that DES-\n   cracking hardware is within reach of a much broader group than\
    \ in\n   1998, and it is important to note that this assumes no design or\n  \
    \ algorithm improvements since then.\n   To put this in a slightly different light,\
    \ let's consider the typical\n   rendition of Moore's Law for such discussions.\
    \  Rather than\n   considering shrinking cost for the same capability, consider\
    \ instead\n   increasing capability for the same cost (i.e., doubling circuit\n\
    \   densities every N months).  Again choosing N=18, our DES-cracking\n   capability\
    \ (in worst-case time per key) could be expected to have\n   approximately followed\
    \ this performance curve over the last 7 or so\n   years:\n   o  1998................:\
    \ 9 days\n   o  mid-2000............: 4.5 days\n   o  beginning of 2002...: 2.25\
    \ days\n   o  mid-2003............: 1.125 days\n   o  beginning of 2006...: 0.5625\
    \ days\n   That's just over a half-day in the worst case for 2006, and under 7\n\
    \   hours on average.  And this, for an investment of less than $250,000.\n  \
    \ It's also very important to note that we are talking about worst-case\n   and\
    \ average times here - sometimes, keys will be found much more\n   quickly.  For\
    \ example, using such a machine, 1/4 of all possible DES\n   keys will be found\
    \ within 3.375 hours. 1/8 of the keys will be found\n   in less than 1 hour and\
    \ 42 minutes.  And this assumes no algorithmic\n   improvements have occurred.\
    \  And again, this is an estimate; your\n   actual mileage may vary, but the estimate\
    \ is probably not far from\n   reality.\n"
- title: 7.1.  FPGAs
  contents:
  - "7.1.  FPGAs\n   Since the EFF device first appeared, Field Programmable Gate\
    \ Arrays\n   (FPGAs) have become quite common, and far less costly than they were\n\
    \   in 1998.  These devices allow low-level logic programming, and are\n   frequently\
    \ used to prototype new logic designs prior to the creation\n   of more expensive\
    \ custom chips (also known as Application Specific\n   Integrated Circuits, or\
    \ ASICs).  They are also frequently used in\n   place of ASICs due to their lower\
    \ cost and/or flexibility.  In fact,\n   a number of embedded systems implementing\
    \ cryptography have employed\n   FPGAs for this purpose.\n   Due to their generalized\
    \ nature, FPGAs are naturally slower than\n   ASICs.  While the speed difference\
    \ varies based on many factors, it\n   is reasonable for purposes of this discussion\
    \ to say that well-\n   designed FPGA implementations typically perform cryptographic\n\
    \   operations at perhaps 1/4 the speed of well-designed ASICs performing\n  \
    \ the same operations, and sometimes much slower than that.  The\n   significance\
    \ of this comparison will become obvious shortly.\n   In our Moore's Law estimate\
    \ above, we noted that the cost\n   extrapolation assumes no design or algorithm\
    \ improvements since 1998.\n   It also implies that we are still talking about\
    \ a brute-force attack.\n   In section 4 (\"Attacking DES\"), we discussed several\
    \ cryptanalytic\n   attacks, including an attack that employs linear cryptanalysis\n\
    \   [MAT93].  In general, this attack has been considered impractical,\n   but\
    \ in 2002, a group at Universite Catholique de Louvain in Belgium\n   built a\
    \ DES cracker based on linear cryptanalysis, which, employing a\n   single FPGA,\
    \ returns a DES key in 12-15 hours [FPL02].\n   While there are still some issues\
    \ of practicality in terms of\n   applying this attack in the real world (i.e.,\
    \ the required number of\n   known plaintext-ciphertext pairs), this gives a glimpse\
    \ of where\n   technology is taking us with respect to DES attack capabilities.\n"
- title: 7.2.  ASICs
  contents:
  - "7.2.  ASICs\n   Application Specific Integrated Circuits are specialized chips,\n\
    \   typically optimized for a particular set of operations (e.g.,\n   encryption).\
    \  There are a number of companies that are in the\n   business of designing and\
    \ selling cryptographic ASICs, and such chips\n   can be had for as little as\
    \ $15 each at the low end.  But while these\n   chips are potentially much faster\
    \ than FPGAs, they usually do not\n   represent a proportionally higher threat\
    \ when it comes to\n   DES-cracking system construction.\n   The primary reason\
    \ for this is cost: it currently costs more than\n   $1,000,000 to produce an\
    \ ASIC.  There is no broad commercial market\n   for crypto-cracking ASICs, so\
    \ the number a manufacturer could expect\n   to sell is probably small.  Likewise,\
    \ a single attacker is not likely\n   to require more than a few of these.  The\
    \ bottom line: per-chip costs\n   would be very high; when compared to the costs\
    \ of FPGAs capable of\n   similar performance, the FPGAs are clear winners.  This\
    \ doesn't mean\n   such ASICs have never been built, but the return is probably\
    \ not\n   worth the investment for the average attacker today, given the other\n\
    \   available options.\n"
- title: 7.3.  Distributed PCs
  contents:
  - "7.3.  Distributed PCs\n   Parallel processing is a powerful tool for conducting\
    \ brute-force\n   attacks against a block cipher.  Since each key can be tested\n\
    \   independently, the keyspace can easily be carved up and distributed\n   across\
    \ an arbitrary number of processors, all of which are running\n   identical code.\
    \  A central \"control\" processor is required for\n   distributing tasks and\
    \ evaluating results, but this is\n   straightforward to implement, and this paradigm\
    \ has been applied to\n   many computing problems.\n   While the EFF demonstrated\
    \ that a purpose-built system is far\n   superior to general purpose PCs when\
    \ applied to cracking DES, the\n   DESCHALL effort [CURT05][RSA1] aptly demonstrated\
    \ that the idle\n   cycles of everyday users' PCs could be efficiently applied\
    \ to this\n   problem.  As noted above, distributed.net teamed with the EFF group\n\
    \   to solve the third RSA DES Challenge using a combination of PCs and\n   the\
    \ EFF's \"Deep Crack\" machine to find a DES key in 22 hours.  And\n   that was\
    \ using 1999 technologies.\n   Clearly, PCs have improved dramatically since 1999.\
    \  At that time,\n   state-of-the-art desktops ran at around 800MHz.  Today, desktop\
    \ PCs\n   commonly run at 3-4 times that speed, and supporting technologies\n\
    \   (memory, cache, storage) offer far higher performance as well.  Since\n  \
    \ the distributed.net effort used a broad spectrum of computers (from\n   early\
    \ 1990s desktops to state-of-the-art (in 1999) multiprocessors,\n   according\
    \ to [DIST99]), it is difficult to do a direct comparison\n   with today's technologies.\
    \  Still, we know that performance has, in\n   general, followed the prediction\
    \ of Moore's Law, so we should expect\n   an improvement on the order of a factor\
    \ of 8-16 by now, even with no\n   algorithmic improvements\n"
- title: 7.3.1.  Willing Participants
  contents:
  - "7.3.1.  Willing Participants\n   It is important to note that the distributed.net\
    \ efforts have relied\n   upon willing participants.  That is, participants must\
    \ explicitly and\n   voluntarily join the effort.  It is equally important to\
    \ note that\n   only the idle cycles of the enrolled systems are used.  Depending\
    \ on\n   the way in which \"idle\" is defined, along with the user's habits and\n\
    \   computing requirements, this could have a significant effect on the\n   contribution\
    \ level of a given system.\n   These factors impose significant limitations in\
    \ terms of scale.\n   While distributed.net was able to enlist over 100,000 computers\
    \ from\n   around the world for the third RSA DES Challenge, this is actually\
    \ a\n   rather small number when compared to 2^56 (over 72 quadrillion)\n   possible\
    \ DES keys.  And when you consider the goal (i.e., to prove\n   DES can be cracked),\
    \ it seems reasonable to assume these same\n   participants would not willingly\
    \ offer up their compute cycles for a\n   more nefarious use (like attacking the\
    \ keys used to encrypt your\n   online banking session).  Hence, this particular\
    \ model does not\n   appear to pose a significant threat to most uses of encryption\
    \ today.\n   However, below, we discuss a variation on this approach that does\n\
    \   pose an immediate threat.\n"
- title: 7.3.2.  Spyware and Viruses and Botnets (oh my!)
  contents:
  - "7.3.2.  Spyware and Viruses and Botnets (oh my!)\n   \"Spyware\" is a popular\
    \ topic in security newsfeeds these days.  Most\n   of these applications are\
    \ intended to display context-sensitive\n   advertisements to users, and some\
    \ actually modify a user's web\n   browsing experience, directing them to sites\
    \ of the distributor's\n   choice in an effort to generate revenue.  There are\
    \ many names for\n   this type of software, but for our purposes, we will refer\
    \ to it\n   simply as \"spyware\".  And while there are some instances in which\n\
    \   rogue software actually does spy on hapless users and report things\n   back\
    \ to the issuer, we do not focus here on such distinctions.\n   Indeed, what we\
    \ are more interested in is the broader modality in\n   which this software functions:\
    \ it is typically installed without the\n   explicit knowledge and/or understanding\
    \ of the user, and typically\n   runs without the user's knowledge, sometimes\
    \ slowing the user's PC to\n   a crawl.  One might note that such behavior seems\
    \ quite surprising in\n   view of the fact that displaying ads to users is actually\
    \ a light-\n   weight task, and wonder what this software is actually doing with\
    \ all\n   those compute cycles.\n   Worms and viruses are also very interesting:\
    \ like spyware, these are\n   installed without the user's knowledge or consent,\
    \ and they use the\n   computer in ways the user would not voluntarily allow.\
    \  And unlike\n   the spyware that is most common today, this malware usually\
    \ contains\n   explicit propagation technology by which it automatically spreads.\n\
    \   It is not difficult to imagine where we are going with this: if you\n   combine\
    \ these techniques, forcible induction of user machines into an\n   \"army\" of\
    \ systems becomes possible.  This approach was alluded to in\n   [CURT98] and,\
    \ in fact, is being done today.\n   Botnets [BOT05] represent a relatively recent\
    \ phenomena.  Using\n   various propagation techniques, malware is distributed\
    \ across a range\n   of systems, where it lies in wait for a trigger of some sort.\
    \  These\n   \"triggers\" may be implemented through periodic polling of a\n \
    \  centralized authority, the arrival of a particular date, or any of a\n   large\
    \ number of other events.  Upon triggering, the malware executes\n   its task,\
    \ which may involve participating in a Distributed Denial of\n   Service (DDoS)\
    \ attack, or some other type of activity.\n   Criminal groups are currently renting\
    \ out botnets for various uses\n   [CERT01].  While reported occurrences have\
    \ typically involved using\n   these rogue networks for DDoS attacks, we would\
    \ be naive to think\n   other uses (e.g., breaking encryption keys) have not been\
    \ considered.\n   Botnets greatly mitigate the scaling problem faced by\n   distributed.net:\
    \ it is no longer a volunteer-only effort, and user\n   activity no longer significantly\
    \ impedes the application's progress.\n   This should give us pause.\n   It is\
    \ very important to clearly recognize the implications of this:\n   botnets are\
    \ cheap, and there are lots of PCs out there.  You don't\n   need the $15,625\
    \ that we speculated would be enough to build a copy\n   of the EFF system today\
    \ -- you only need a commodity PC on which to\n   develop the malware, and the\
    \ requisite skills.  Or, you need access\n   to someone with those things, and\
    \ a relatively modest sum of cash.\n   The game has changed dramatically.\n"
- title: 8.  Why is DES Still Used?
  contents:
  - "8.  Why is DES Still Used?\n   Obviously, DES is not secure by most measures\
    \ -- why is it still used\n   today?  There are probably many reasons, but here\
    \ are perhaps the\n   most common:\n   o  Backward compatibility - Numerous deployed\
    \ systems support DES,\n      and rather than replace those systems, new systems\
    \ are implemented\n      with compatibility in mind.\n   o  Performance - Many\
    \ early VPN clients provided DES as the default\n      cryptographic algorithm,\
    \ because PCs of the day suffered a\n      noticeable performance hit when applying\
    \ stronger cryptography\n      (e.g., 3DES).\n   o  Ignorance - People simply\
    \ do not understand that DES is no longer\n      secure for most uses.\n   While\
    \ there are probably other reasons, these are the most frequently\n   cited.\n\
    \   Performance arguments are easily dispensed with today.  PCs have more\n  \
    \ than ample power to implement stronger cryptography with no\n   noticeable performance\
    \ impact, and for systems that are resource\n   constrained, there are strong\
    \ algorithms that are far better\n   performers than DES (e.g., AES-128).  And\
    \ while backward\n   compatibility is sometimes a valid argument, this must be\
    \ weighed\n   carefully.  At the point where the risk is higher than the cost\
    \ of\n   replacement, legacy systems should be abandoned.\n   With respect to\
    \ the third reason (ignorance), this note attempts to\n   address this, and we\
    \ should continue to make every effort to get the\n   word out.  DES is no longer\
    \ secure for most uses, and it requires\n   significant security expertise to\
    \ evaluate those small number of\n   cases in which it might be acceptable.  Technologies\
    \ exist that put\n   DES-cracking capability within reach of a modestly financed\
    \ or\n   modestly skilled motivated attacker.  There are stronger, cheaper,\n\
    \   faster encryption algorithms available.  It is time to move on.\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   This entire document deals with security considerations.\
    \  Still, it\n   makes sense to summarize a few key points here.  It should be\
    \ clear\n   by now that the DES algorithm offers little deterrence for a\n   determined\
    \ adversary.  While it might have cost $250,000 to build a\n   dedicated DES cracker\
    \ in 1998, nowadays it can be done for\n   considerably less.  Indeed, botnets\
    \ are arguably free, if you don't\n   count the malware author's time in your\
    \ cost computation.\n   Does this mean DES should never be used?  Well, no - but\
    \ it does mean\n   that if it is used at all, it should be used with extreme care.\
    \  It\n   is important to carefully evaluate the value of the information being\n\
    \   protected, both to its owner and to an attacker, and to fully grasp\n   the\
    \ potential risks.  In some cases, DES may still provide an\n   acceptable level\
    \ of security, e.g., when you want to encrypt a file\n   on the family PC, and\
    \ there are no real threats in your household.\n   However, it is important to\
    \ recognize that, in such cases, DES is\n   much like a cheap suitcase lock: it\
    \ usually helps honest people\n   remain honest, but it won't stop a determined\
    \ thief.  Given that\n   strong, more efficient cryptographic algorithms (e.g.,\
    \ AES) are\n   available, it seems the only rational reason to continue using\
    \ DES\n   today is for compulsory backward compatibility.  In such cases, if\n\
    \   there is no plan for gradually phasing out such products, then, as a\n   security\
    \ implementer, you can do the following:\n   o  Recommend a phased upgrade approach.\n\
    \   o  If possible, use 3DES rather than DES (and in any case, DO NOT\n      make\
    \ DES the default algorithm!).\n   o  Replace keys before exceeding 2^32 blocks\
    \ per key (to avoid\n      various cryptanalytic attacks).\n   o  If there is\
    \ a user interface, make users aware of the fact that\n      the cryptography\
    \ in use is not strong, and for your particular\n      application, make appropriate\
    \ recommendations in this regard.\n   The bottom line: it is simpler to not use\
    \ this algorithm than it is\n   to come up with narrow scenarios in which it might\
    \ be okay.  If you\n   have legacy systems relying on DES, it makes sense to begin\
    \ phasing\n   them out as soon as possible.\n"
- title: 10.  Acknowledgements
  contents:
  - "10.  Acknowledgements\n   The author gratefully acknowledges the contributions\
    \ of Doug Whiting,\n   Matt Curtin, Eric Rescorla, Bob Baldwin, and Yoav Nir.\
    \  Their\n   reviews, comments, and advice immeasurably improved this note.  And\n\
    \   of course, we all have the EFF and all those involved with the \"Deep\n  \
    \ Crack\", DESCHALL, and distributed.net efforts to thank for their\n   pioneering\
    \ research and implementations in this area.\n"
- title: Appendix A.  What About 3DES?
  contents:
  - "Appendix A.  What About 3DES?\n   It seems reasonable, given that we recommend\
    \ avoiding DES, to ask:\n   how about 3DES?  Is it still safe?  Thankfully, most\
    \ of the\n   discussion above does not apply to 3DES, and it is still \"safe\"\
    \ in\n   general.  Below, we briefly explain why this is true, and what\n   caveats\
    \ currently exist.\n"
- title: A.1.  Brute-Force Attacks on 3DES
  contents:
  - "A.1.  Brute-Force Attacks on 3DES\n   Recall that for DES there are 2^56 possible\
    \ keys, and that a brute-\n   force attack consists of trying each key until the\
    \ right one is\n   found.  Since we are equally likely to find the key on the\
    \ first,\n   second, or even last try, on average we expect to find the key after\n\
    \   trying half (2^55) of the keys, or after 36,028,797,018,963,968\n   decryptions.\
    \  This doesn't seem completely impossible given current\n   processor speeds,\
    \ and as we saw above, we can expect with today's\n   technology that such an\
    \ attack could almost certainly be carried out\n   in around half a day.\n   For\
    \ a brute-force attack on 3DES, however, the outlook is far less\n   optimistic.\
    \  Consider the problem: we know C (and possibly p), and we\n   are trying to\
    \ guess k1, k2, and k3 in the following relation:\n                        C =\
    \ E_k3(D_k2(E_k1(p)))\n   In order to guess the keys, we must execute something\
    \ like the\n   following (assuming k1, k2, and k3 are 64-bit values, as are Ci\
    \ and\n   p):\n           for ( k3 = 0 to 2^56 step 1 )\n               compute\
    \ C2 = D_k3(C1)\n               for ( k2 = 0 to 2^56 step 1 )\n              \
    \     compute C3 = E_k2(C2)\n                   for ( k1 = 0 to 2^56 step 1 )\n\
    \                       begin\n                          compute p = D_k1(C3)\
    \ xor IV\n                          if ( p equals p-expected )\n             \
    \                  exit loop; we found the keys\n                       end\n\
    \   Note that in the worst case the correct key combination will be the\n   last\
    \ one we try, meaning we will have tried 2^168 crypto operations.\n   If we assume\
    \ that each 3DES decryption (2 decryptions plus one\n   encryption) takes a single\
    \ microsecond, this would amount to 1.19 x\n   10^37 years.  That's FAR longer\
    \ than scientists currently estimate\n   our universe to have been in existence.\n\
    \   While it is important to note that we could slightly prune the key\n   space\
    \ by assuming that two equal keys would never be used (i.e., k1\n   != k2, k2\
    \ != k3, k1 != k3), this does not result in a significant\n   work reduction when\
    \ you consider the magnitude of the numbers we're\n   dealing with.  And what\
    \ if we instead assumed that technological\n   advances allow us to apply DES\
    \ far more quickly?\n   Today, commercial 3DES chips capable of 10-Gbps encryption\
    \ are widely\n   available, and this translates to 15,625,000 DES blocks per second.\n\
    \   The estimate given above assumed 1,000,000 DES blocks/second, so\n   10-Gbps\
    \ hardware is 15 times as fast.  This means in the worst case\n   it would take\
    \ 7.6 x 10^35 years -- not much faster in the larger\n   scheme of things.\n \
    \  Even if we consider hardware that is 1,000,000 times faster, this\n   would\
    \ still require 7.6 x 10^29 years - still FAR longer than the\n   universe has\
    \ been around.  Obviously, we're getting nowhere fast\n   here. 3DES, for all\
    \ practical purposes, is probably safe from brute-\n   force attacks for the foreseeable\
    \ future.\n"
- title: A.2.  Cryptanalytic Attacks Against 3DES
  contents:
  - "A.2.  Cryptanalytic Attacks Against 3DES\n   Unlike DES, there are only a few\
    \ known cryptanalytic attacks against\n   3DES.  Below, we describe those attacks\
    \ that are currently discussed\n   in the literature.\n"
- title: A.2.1.  Meet-In-The-Middle (MITM) Attacks
  contents:
  - "A.2.1.  Meet-In-The-Middle (MITM) Attacks\n   The most commonly described 3DES\
    \ attack is MITM, described in [HAC]\n   and elsewhere.  It works like this: take\
    \ a ciphertext value 'C' (with\n   corresponding known plaintext value 'p'), and\
    \ compute the values of\n   Cx = D_kx(C) for all possible (2^56) keys.  Store\
    \ each Cx,kx pair in\n   a table indexed by Cx.\n   Now, compute the values of\
    \ Cy = D_ki(E_kj(p)) in a nested loop, as\n   illustrated above in our brute-force\
    \ exercise.  For each Cy, do a\n   lookup on the table of Cx's.  For each match\
    \ found, test the triple\n   of keys.  It is important to note that a match does\
    \ not imply you\n   have the right keys - you must test this against additional\n\
    \   ciphertext/plaintext pairs to be certain (~3 pairs for a strong\n   measure\
    \ of certainty with 3DES).  Ultimately, there will be exactly\n   one correct\
    \ key triplet.\n   Note that computing the initial table of Cx,kx pairs requires\
    \ 2^56\n   encryptions and 2^56 blocks of storage (about 576 gigabytes).\n   Computing\
    \ the lookup elements requires at most 2^112 cryptographic\n   operations (table\
    \ lookups are negligible by comparison), and 2^111\n   operations on average.\
    \  Lucks [LUCKS] has come up with optimizations\n   that reduce this to about\
    \ 2^108.\n   3DES, even at a strength of 2^108, is still very strong.  If we use\n\
    \   our brute-force limits from above (15,625,000 blocks per second),\n   this\
    \ attack will take on the order of 6.586 x 10^17 years to carry\n   out.  Make\
    \ the machine 1 million times faster, and you still need\n   more than 658 BILLION\
    \ years.  We are probably safe from MITM attacks\n   on 3DES for the foreseeable\
    \ future.\n"
- title: A.2.2.  Related Key Attacks
  contents:
  - "A.2.2.  Related Key Attacks\n   For a detailed description of related key attacks\
    \ against 3DES (and\n   other algorithms), see [KELSEY].  In a nutshell, for this\
    \ approach\n   the attacker knows the encryption of given plaintext under the\n\
    \   original key K, and some related keys K'_i.  There are attacks where\n   the\
    \ attacker chooses how the key is to be changed, and attacks in\n   which the\
    \ difference is known, but not controlled, by the attacker.\n   Here's how it\
    \ works.  Assume the following cryptographic relation:\n                     \
    \   C = E_k3(D_k2(E_k1(p)))\n   Then, the following defines the key relation:\n\
    \                    K = (k1,k2,k3) and K' = (k1 + d,k2,k3)\n   with d being a\
    \ fixed constant.  Knowing p and C, we need to decrypt C\n   under K' as follows:\n\
    \                    Let kx = k1 + d (note: '+' represents xor)\n            \
    \                  and\n                        p' = D_kx(E_k1(p))\n   Once we\
    \ have p', we can find kx by exhaustively trying each key until\n   we find a\
    \ match (2^56 encryptions, worst case).  Once we find kx, we\n   can conduct a\
    \ double-DES MITM attack to find k2 and k3, which\n   requires between 2^56 and\
    \ 2^72 trial offline encryptions.\n   From a practical standpoint, it's very important\
    \ to recognize the\n   \"what-if\" nature of this attack: the adversary must know\
    \ the\n   plaintext/ciphertext pair, he must be able to influence a subsequent\n\
    \   encryption key in a highly controlled fashion (or at least, know\n   exactly\
    \ how the key changes), and then have the cryptographic\n   cooperation required\
    \ to compute p'.  This is clearly a very difficult\n   attack in the real world.\n"
- title: A.3.  3DES Block Size
  contents:
  - "A.3.  3DES Block Size\n   While the effective key length for 3DES is clearly\
    \ much larger than\n   for DES, the block size is, unfortunately, still only 64\
    \ bits.  For\n   CBC mode (the most commonly deployed mode in Internet security\n\
    \   protocols), this means that, due to the birthday paradox, information\n  \
    \ about the plaintext begins to leak after around 2^32 blocks have been\n   encrypted.\
    \  For this reason, 3DES may not be the best choice for\n   high-throughput links,\
    \ or other high-density encryption applications.\n   At minimum, care should be\
    \ taken to refresh keys frequently enough to\n   minimize ciphertext collisions\
    \ in such scenarios.\n"
- title: Informative References
  contents:
  - "Informative References\n   [AES]      \"The Advanced Encryption Standard\", November\
    \ 2001,\n              <http://csrc.nist.gov/publications/fips/fips197/\n    \
    \          fips-197.pdf>.\n   [AES-NSA]  \"CNSS Policy No. 15, Fact Sheet No.\
    \ 1\", June 2003,\n              <http://csrc.nist.gov/cryptval/CNSS15FS.pdf>.\n\
    \   [BIH93]    Biham, E. and A. Shamir, \"Differential Cryptanalysis of\n    \
    \          the Data Encryption Standard\", 1993.\n   [BIH96]    Biham, E., \"\
    How to Forge DES-Encrypted Messages in 2^28\n              Steps\", 1996.\n  \
    \ [BIH96-2]  Biham, E. and A. Shamir, \"A New Cryptanalytic Attack on\n      \
    \        DES\", 1996.\n   [BLAZ96]   Blaze, M., Diffie, W., Rivest, R., Schneier,\
    \ B.,\n              Shimomura, T., Thompson, E., and M. Wiener, \"Minimal Key\n\
    \              Lengths for Symmetric Ciphers to Provide Adequate\n           \
    \   Commercial Security\", January 1996.\n   [BOT05]    \"Know Your Enemy: Tracking\
    \ Botnets\", March 2005,\n              <http://www.honeynet.org/papers/bots/>.\n\
    \   [CERT01]   Ianelli, N. and A. Hackworth, \"Botnets as a Vehicle for\n    \
    \          Online Crime\", December 2005,\n              <http://www.cert.org/archive/pdb/Botnets.pdf>.\n\
    \   [CURT05]   Curtin, M., \"Brute Force: Cracking the Data Encryption\n     \
    \         Standard\", 2005.\n   [CURT98]   Curtin, M. and J. Dolske, \"A Brute\
    \ Force Search of DES\n              Keyspace\", 1998,\n              <http://www.interhack.net/pubs/des-key-crack/>.\n\
    \   [DES]      \"Data Encryption Standard\", January 1977,\n              <http://www.nist.gov>.\n\
    \   [DH77]     Hellman, M. and W. Diffie, \"Exhaustive Cryptanalysis of\n    \
    \          the NBS Data Encryption Standard\", June 1977.\n   [DIST99]   Press\
    \ Release, distributed., \"US GOVERNMENT'S ENCRYPTION\n              STANDARD\
    \ BROKEN IN LESS THAN A DAY\", 1999,\n              <http://www1.distributed.net/des/release-desiii.txt>.\n\
    \   [EFF98]    EFF, \"Cracking DES\", July 1998.\n   [FBI01]    \"NIPC Advisory\
    \ 01-003\", March 2001,\n              <http://www.fbi.gov/pressrel/pressrel01/nipc030801.htm>.\n\
    \   [FBI06]    \"FBI Webpage: Focus on Economic Espionage\", January 2006,\n \
    \             <http://www.fbi.gov/hq/ci/economic.htm>.\n   [FERG03]   Ferguson,\
    \ N. and B. Schneier, \"Practical Cryptography\",\n              2003.\n   [FPL02]\
    \    Koeune, F., Rouvroy, G., Standaert, F., Quisquater, J.,\n              David,\
    \ J., and J. Legat, \"An FPGA Implementation of the\n              Linear Cryptanalysis\"\
    , FPL 2002, Volume 2438 of Lecture\n              Notes in Computer Science, pages\
    \ 846-852, Spriger-Verlag,\n              September 2002.\n   [HAC]      Menezes,\
    \ A., van Oorschot, P., and S. Vanstone, \"Handbook\n              of Applied\
    \ Cryptography\", 1997.\n   [JAK97]    Jakobsen, T. and L. Knudsen, \"The Interpolation\
    \ Attack on\n              Block Ciphers\", 1997.\n   [KELSEY]   Kelsey, J., Schneier,\
    \ B., and D. Wagner, \"Key-Schedule\n              Cryptanalysis of 3-WAY, IDEA,\
    \ G-DES, RC4, SAFER, and\n              Triple-DES\", 1996.\n   [LUCKS]    Lucks,\
    \ S., \"Attacking Triple Encryption\", 1998.\n   [MAT93]    Matsui, M., \"Linear\
    \ Cryptanalysis Method for DES Cipher\",\n              1993.\n   [NIST-TP]  \"\
    DES Transition Plan\", May 2005,\n              <http://csrc.nist.gov/cryptval/DESTranPlan.pdf>.\n\
    \   [NYSE1]    \"Extreme availability: New York Stock Exchange's new IT\n    \
    \          infrastructure puts hand-held wireless terminals in\n             \
    \ brokers' hands.\", June 2005.\n   [RSA1]     Press Release, RSA., \"Team of\
    \ Universities, Companies and\n              Individual Computer Users Linked\
    \ Over the Internet Crack\n              RSA's 56-Bit DES Challenge\", 1997, <http://\n\
    \              www.rsasecurity.com/press_release.asp?doc_id=661&id=1034>.\n  \
    \ [RSA2]     Press Release, RSA., \"RSA to Launch \"DES Challenge II\" at\n  \
    \            Data Security Conference\", 1998, <http://\n              www.rsasecurity.com/press_release.asp?doc_id=729&id=1034>.\n\
    \   [RSA3]     Press Release, RSA., \"Distributed Team Collaborates to\n     \
    \         Solve Secret-Key Challenge\", 1998, <http://\n              www.rsasecurity.com/press_release.asp?doc_id=558&id=1034>.\n\
    \   [RSA4]     Press Release, RSA., \"RSA to Launch DES Challenge III\n      \
    \        Contest at 1999 Data Security Conference\", 1998, <http://\n        \
    \      www.rsasecurity.com/press_release.asp?doc_id=627&id=1034>.\n   [RSA5] \
    \    Press Release, RSA., \"RSA Code-Breaking Contest Again Won\n            \
    \  by Distributed.Net and Electronic Frontier Foundation\",\n              1999,\
    \ <http://www.rsasecurity.com/\n              press_release.asp?doc_id=462&id=1034>.\n\
    \   [SCHN96]   Schneier, B., \"Applied Cryptography, Second Ed.\", 1996.\n   [VA1]\
    \      \"Review of Issues Related to the Loss of VA Information\n            \
    \  Involving the Identities of Millions of Veterans (Report\n              #06-02238-163)\"\
    , July 2006, <http://www.va.gov/oig/51/\n              FY2006rpts/VAOIG-06-02238-163.pdf>.\n\
    \   [WIEN94]   Wiener, M., \"Efficient DES Key Search\", August 1993.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Scott G. Kelly\n   Aruba Networks\n   1322 Crossman Ave\n\
    \   Sunnyvale, CA  94089\n   US\n   EMail: scott@hyperthought.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The IETF Trust (2006).\n   This document\
    \ is subject to the rights, licenses and restrictions\n   contained in BCP 78,\
    \ and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY, THE IETF TRUST,\n   AND THE\
    \ INTERNET ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES,\n   EXPRESS OR IMPLIED,\
    \ INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT\n   THE USE OF THE INFORMATION\
    \ HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY\n   IMPLIED WARRANTIES OF MERCHANTABILITY\
    \ OR FITNESS FOR A PARTICULAR\n   PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at\n   ietf-ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
