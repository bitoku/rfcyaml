- title: __initial_text__
  contents:
  - '               HighSpeed TCP for Large Congestion Windows

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo defines an Experimental Protocol for the Internet\n\
    \   community.  It does not specify an Internet standard of any kind.\n   Discussion\
    \ and suggestions for improvement are requested.\n   Distribution of this memo\
    \ is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2003).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   The proposals in this document are experimental.  While they may\
    \ be\n   deployed in the current Internet, they do not represent a consensus\n\
    \   that this is the best method for high-speed congestion control.  In\n   particular,\
    \ we note that alternative experimental proposals are\n   likely to be forthcoming,\
    \ and it is not well understood how the\n   proposals in this document will interact\
    \ with such alternative\n   proposals.\n   This document proposes HighSpeed TCP,\
    \ a modification to TCP's\n   congestion control mechanism for use with TCP connections\
    \ with large\n   congestion windows.  The congestion control mechanisms of the\
    \ current\n   Standard TCP constrains the congestion windows that can be achieved\n\
    \   by TCP in realistic environments.  For example, for a Standard TCP\n   connection\
    \ with 1500-byte packets and a 100 ms round-trip time,\n   achieving a steady-state\
    \ throughput of 10 Gbps would require an\n   average congestion window of 83,333\
    \ segments, and a packet drop rate\n   of at most one congestion event every 5,000,000,000\
    \ packets (or\n   equivalently, at most one congestion event every 1 2/3 hours).\
    \  This\n   is widely acknowledged as an unrealistic constraint.  To address this\n\
    \   limitation of TCP, this document proposes HighSpeed TCP, and solicits\n  \
    \ experimentation and feedback from the wider community.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction. . . . . . . . . . . . . . . . . . . .\
    \ . . . . . .  2\n   2. The Problem Description.. . . . . . . . . . . . . . .\
    \ . . . . .  3\n   3. Design Guidelines.. . . . . . . . . . . . . . . . . . .\
    \ . . . .  4\n   4. Non-Goals.. . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .  5\n   5. Modifying the TCP Response Function.. . . . . . . . . . . .\
    \ . .  6\n   6. Fairness Implications of the HighSpeed Response\n      Function.\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .  9\n   7. Translating\
    \ the HighSpeed Response Function into\n      Congestion Control Parameters .\
    \ . . . . . . . . . . . . . . . . 12\n   8. An alternate, linear response functions..\
    \ . . . . . . . . . . . 13\n   9. Tradeoffs for Choosing Congestion Control Parameters.\
    \ . . . . . 16\n      9.1. The Number of Round-Trip Times between Loss Events\
    \ . . . . 17\n      9.2. The Number of Packet Drops per Loss Event, with Drop-Tail.\
    \ 17\n   10. Related Issues . . . . . . . . . . . . . . . . . . . . . . . . 18\n\
    \      10.1. Slow-Start. . . . . . . . . . . . . . . . . . . . . . . . 18\n  \
    \    10.2. Limiting burstiness on short time scales. . . . . . . . . 19\n    \
    \  10.3. Other limitations on window size. . . . . . . . . . . . . 19\n      10.4.\
    \ Implementation issues.. . . . . . . . . . . . . . . . . . 19\n   11. Deployment\
    \ issues. . . . . . . . . . . . . . . . . . . . . . . 20\n      11.1. Deployment\
    \ issues of HighSpeed TCP. . . . . . . . . . . . 20\n      11.2. Deployment issues\
    \ of Scalable TCP . . . . . . . . . . . . 22\n   12. Related Work in HighSpeed\
    \ TCP. . . . . . . . . . . . . . . . . 23\n   13. Relationship to other Work..\
    \ . . . . . . . . . . . . . . . . . 25\n   14. Conclusions. . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . 25\n   15. Acknowledgements . . . . . . . .\
    \ . . . . . . . . . . . . . . . 25\n   16. Normative References . . . . . . .\
    \ . . . . . . . . . . . . . . 26\n   17. Informative References . . . . . . .\
    \ . . . . . . . . . . . . . 26\n   18. Security Considerations. . . . . . . .\
    \ . . . . . . . . . . . . 28\n   19. IANA Considerations. . . . . . . . . . .\
    \ . . . . . . . . . . . 28\n   A.  TCP's Loss Event Rate in Steady-State. . .\
    \ . . . . . . . . . . 29\n   B.  A table for a(w) and b(w). . . . . . . . . .\
    \ . . . . . . . . . 30\n   C.  Exploring the time to converge to fairness . .\
    \ . . . . . . . . 32\n       Author's Address . . . . . . . . . . . . . . . .\
    \ . . . . . . . 33\n       Full Copyright Statement . . . . . . . . . . . . .\
    \ . . . . . . 34\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document proposes HighSpeed TCP, a modification to\
    \ TCP's\n   congestion control mechanism for use with TCP connections with large\n\
    \   congestion windows.  In a steady-state environment, with a packet\n   loss\
    \ rate p, the current Standard TCP's average congestion window is\n   roughly\
    \ 1.2/sqrt(p) segments.  This places a serious constraint on\n   the congestion\
    \ windows that can be achieved by TCP in realistic\n   environments.  For example,\
    \ for a Standard TCP connection with 1500-\n   byte packets and a 100 ms round-trip\
    \ time, achieving a steady-state\n   throughput of 10 Gbps would require an average\
    \ congestion window of\n   83,333 segments, and a packet drop rate of at most\
    \ one congestion\n   event every 5,000,000,000 packets (or equivalently, at most\
    \ one\n   congestion event every 1 2/3 hours).  The average packet drop rate of\n\
    \   at most 2*10^(-10) needed for full link utilization in this\n   environment\
    \ corresponds to a bit error rate of at most 2*10^(-14),\n   and this is an unrealistic\
    \ requirement for current networks.\n   To address this fundamental limitation\
    \ of TCP and of the TCP response\n   function (the function mapping the steady-state\
    \ packet drop rate to\n   TCP's average sending rate in packets per round-trip\
    \ time), this\n   document describes a modified TCP response function for regimes\
    \ with\n   higher congestion windows.  This document also solicits\n   experimentation\
    \ and feedback on HighSpeed TCP from the wider\n   community.\n   Because HighSpeed\
    \ TCP's modified response function would only take\n   effect with higher congestion\
    \ windows, HighSpeed TCP does not modify\n   TCP behavior in environments with\
    \ heavy congestion, and therefore\n   does not introduce any new dangers of congestion\
    \ collapse.  However,\n   if relative fairness between HighSpeed TCP connections\
    \ is to be\n   preserved, then in our view any modification to the TCP response\n\
    \   function should be addressed in the IETF, rather than made as ad hoc\n   decisions\
    \ by individual implementors or TCP senders.  Modifications\n   to the TCP response\
    \ function would also have implications for\n   transport protocols that use TFRC\
    \ and other forms of equation-based\n   congestion control, as these congestion\
    \ control mechanisms directly\n   use the TCP response function [RFC3448].\n \
    \  This proposal for HighSpeed TCP focuses specifically on a proposed\n   change\
    \ to the TCP response function, and its implications for TCP.\n   This document\
    \ does not address what we view as a separate fundamental\n   issue, of the mechanisms\
    \ required to enable best-effort connections\n   to *start* with large initial\
    \ windows.  In our view, while HighSpeed\n   TCP proposes a somewhat fundamental\
    \ change to the TCP response\n   function, at the same time it is a relatively\
    \ simple change to\n   implement in a single TCP sender, and presents no dangers\
    \ in terms of\n   congestion collapse.  In contrast, in our view, the problem\
    \ of\n   enabling connections to *start* with large initial windows is\n   inherently\
    \ more risky and structurally more difficult, requiring some\n   form of explicit\
    \ feedback from all of the routers along the path.\n   This is another reason\
    \ why we would propose addressing the problem of\n   starting with large initial\
    \ windows separately, and on a separate\n   timetable, from the problem of modifying\
    \ the TCP response function.\n"
- title: 2.  The Problem Description
  contents:
  - "2.  The Problem Description\n   This section describes the number of round-trip\
    \ times between\n   congestion events required for a Standard TCP flow to achieve\
    \ an\n   average throughput of B bps, given packets of D bytes and a round-\n\
    \   trip time of R seconds.  A congestion event refers to a window of\n   data\
    \ with one or more dropped or ECN-marked packets (where ECN stands\n   for Explicit\
    \ Congestion Notification).\n   From Appendix A, achieving an average TCP throughput\
    \ of B bps\n   requires a loss event at most every BR/(12D) round-trip times.\
    \  This\n   is illustrated in Table 1, for R = 0.1 seconds and D = 1500 bytes.\n\
    \   The table also gives the average congestion window W of BR/(8D), and\n   the\
    \ steady-state packet drop rate P of 1.5/W^2.\n    TCP Throughput (Mbps)   RTTs\
    \ Between Losses     W       P\n    ---------------------   -------------------\
    \   ----    -----\n              1                    5.5             8.3    0.02\n\
    \             10                   55.5            83.3    0.0002\n          \
    \  100                  555.5           833.3    0.000002\n           1000   \
    \              5555.5          8333.3    0.00000002\n          10000         \
    \       55555.5         83333.3    0.0000000002\n   Table 1: RTTs Between Congestion\
    \ Events for Standard TCP, for\n   1500-Byte Packets and a Round-Trip Time of\
    \ 0.1 Seconds.\n   This document proposes HighSpeed TCP, a minimal modification\
    \ to TCP's\n   increase and decrease parameters, for TCP connections with larger\n\
    \   congestion windows, to allow TCP to achieve high throughput with more\n  \
    \ realistic requirements for the steady-state packet drop rate.\n   Equivalently,\
    \ HighSpeed TCP has more realistic requirements for the\n   number of round-trip\
    \ times between loss events.\n"
- title: 3.  Design Guidelines
  contents:
  - "3.  Design Guidelines\n   Our proposal for HighSpeed TCP is motivated by the\
    \ following\n   requirements:\n   *  Achieve high per-connection throughput without\
    \ requiring\n      unrealistically low packet loss rates.\n   *  Reach high throughput\
    \ reasonably quickly when in slow-start.\n   *  Reach high throughput without\
    \ overly long delays when recovering\n      from multiple retransmit timeouts,\
    \ or when ramping-up from a\n      period with small congestion windows.\n   *\
    \  No additional feedback or support required from routers:\n   For example, the\
    \ goal is for acceptable performance in both ECN-\n   capable and non-ECN-capable\
    \ environments, and with Drop-Tail as well\n   as with Active Queue Management\
    \ such as RED in the routers.\n   *  No additional feedback required from TCP\
    \ receivers.\n   *  TCP-compatible performance in environments with moderate or\
    \ high\n      congestion (e.g., packet drop rates of 1% or higher):\n   Equivalently,\
    \ the requirement is that there be no additional load on\n   the network (in terms\
    \ of increased packet drop rates) in environments\n   with moderate or high congestion.\n\
    \   *  Performance at least as good as Standard TCP in environments with\n   \
    \   moderate or high congestion.\n   *  Acceptable transient performance, in terms\
    \ of increases in the\n      congestion window in one round-trip time, responses\
    \ to severe\n      congestion, and convergence times to fairness.\n   Currently,\
    \ users wishing to achieve throughputs of 1 Gbps or more\n   typically open up\
    \ multiple TCP connections in parallel, or use MulTCP\n   [CO98,GRK99], which\
    \ behaves roughly like the aggregate of N virtual\n   TCP connections.  While\
    \ this approach suffices for the occasional\n   user on well-provisioned links,\
    \ it leaves the parameter N to be\n   determined by the user, and results in more\
    \ aggressive performance\n   and higher steady-state packet drop rates if used\
    \ in environments\n   with periods of moderate or high congestion.  We believe\
    \ that a new\n   approach is needed that offers more flexibility, more effectively\n\
    \   scales to a wide range of available bandwidths, and competes more\n   fairly\
    \ with Standard TCP in congested environments.\n"
- title: 4.  Non-Goals
  contents:
  - "4.  Non-Goals\n   The following are explicitly *not* goals of our work:\n   *\
    \  Non-goal: TCP-compatible performance in environments with very low\n      packet\
    \ drop rates.\n   We note that our proposal does not require, or deliver, TCP-\n\
    \   compatible performance in environments with very low packet drop\n   rates,\
    \ e.g., with packet loss rates of 10^-5 or 10^-6.  As we discuss\n   later in\
    \ this document, we assume that Standard TCP is unable to make\n   effective use\
    \ of the available bandwidth in environments with loss\n   rates of 10^-6 in any\
    \ case, so that it is acceptable and appropriate\n   for HighSpeed TCP to perform\
    \ more aggressively than Standard TCP in\n   such an environment.\n   *  Non-goal:\
    \ Ramping-up more quickly than allowed by slow-start.\n   It is our belief that\
    \ ramping-up more quickly than allowed by slow-\n   start would necessitate more\
    \ explicit feedback from routers along the\n   path.  The proposal for HighSpeed\
    \ TCP is focused on changes to TCP\n   that could be effectively deployed in the\
    \ current Internet\n   environment.\n   *  Non-goal: Avoiding oscillations in\
    \ environments with only one-way,\n      long-lived flows all with the same round-trip\
    \ times.\n   While we agree that attention to oscillatory behavior is useful,\n\
    \   avoiding oscillations in aggregate throughput has not been our\n   primary\
    \ consideration, particularly for simplified environments\n   limited to one-way,\
    \ long-lived flows all with the same, large round-\n   trip times.  Our assessment\
    \ is that some oscillatory behavior in\n   these extreme environments is an acceptable\
    \ price to pay for the\n   other benefits of HighSpeed TCP.\n"
- title: 5.  Modifying the TCP Response Function
  contents:
  - "5.  Modifying the TCP Response Function\n   The TCP response function, w = 1.2/sqrt(p),\
    \ gives TCP's average\n   congestion window w in MSS-sized segments, as a function\
    \ of the\n   steady-state packet drop rate p [FF98].  This TCP response function\n\
    \   is a direct consequence of TCP's Additive Increase Multiplicative\n   Decrease\
    \ (AIMD) mechanisms of increasing the congestion window by\n   roughly one segment\
    \ per round-trip time in the absence of congestion,\n   and halving the congestion\
    \ window in response to a round-trip time\n   with a congestion event.  This response\
    \ function for Standard TCP is\n   reflected in the table below.  In this proposal\
    \ we restrict our\n   attention to TCP performance in environments with packet\
    \ loss rates\n   of at most 10^-2, and so we can ignore the more complex response\n\
    \   functions that are required to model TCP performance in more\n   congested\
    \ environments with retransmit timeouts.  From Appendix A, an\n   average congestion\
    \ window of W corresponds to an average of 2/3 W\n   round-trip times between\
    \ loss events for Standard TCP (with the\n   congestion window varying from 2/3\
    \ W to 4/3 W).\n     Packet Drop Rate P   Congestion Window W    RTTs Between\
    \ Losses\n     ------------------   -------------------    -------------------\n\
    \            10^-2                     12                8\n            10^-3\
    \                     38               25\n            10^-4                 \
    \   120               80\n            10^-5                    379           \
    \   252\n            10^-6                   1200              800\n         \
    \   10^-7                   3795             2530\n            10^-8         \
    \         12000             8000\n            10^-9                  37948   \
    \         25298\n            10^-10                120000            80000\n \
    \  Table 2: TCP Response Function for Standard TCP.  The average\n   congestion\
    \ window W in MSS-sized segments is given as a function of\n   the packet drop\
    \ rate P.\n   To specify a modified response function for HighSpeed TCP, we use\n\
    \   three parameters, Low_Window, High_Window, and High_P.  To ensure TCP\n  \
    \ compatibility, the HighSpeed response function uses the same response\n   function\
    \ as Standard TCP when the current congestion window is at\n   most Low_Window,\
    \ and uses the HighSpeed response function when the\n   current congestion window\
    \ is greater than Low_Window.  In this\n   document we set Low_Window to 38 MSS-sized\
    \ segments, corresponding to\n   a packet drop rate of 10^-3 for TCP.\n   To specify\
    \ the upper end of the HighSpeed response function, we\n   specify the packet\
    \ drop rate needed in the HighSpeed response\n   function to achieve an average\
    \ congestion window of 83000 segments.\n   This is roughly the window needed to\
    \ sustain 10 Gbps throughput, for\n   a TCP connection with the default packet\
    \ size and round-trip time\n   used earlier in this document.  For High_Window\
    \ set to 83000, we\n   specify High_P of 10^-7; that is, with HighSpeed TCP a\
    \ packet drop\n   rate of 10^-7 allows the HighSpeed TCP connection to achieve\
    \ an\n   average congestion window of 83000 segments.  We believe that this\n\
    \   loss rate sets an achievable target for high-speed environments,\n   while\
    \ still allowing acceptable fairness for the HighSpeed response\n   function when\
    \ competing with Standard TCP in environments with packet\n   drop rates of 10^-4\
    \ or 10^5.\n   For simplicity, for the HighSpeed response function we maintain\
    \ the\n   property that the response function gives a straight line on a log-\n\
    \   log scale (as does the response function for Standard TCP, for low to\n  \
    \ moderate congestion).  This results in the following response\n   function,\
    \ for values of the average congestion window W greater than\n   Low_Window:\n\
    \     W = (p/Low_P)^S Low_Window,\n   for Low_P the packet drop rate corresponding\
    \ to Low_Window, and for S\n   as following constant [FRS02]:\n     S = (log High_Window\
    \ - log Low_Window)/(log High_P - log Low_P).\n   (In this paper, \"log x\" refers\
    \ to the log base 10.)  For example, for\n   Low_Window set to 38, we have Low_P\
    \ of 10^-3 (for compatibility with\n   Standard TCP).  Thus, for High_Window set\
    \ to 83000 and High_P set to\n   10^-7, we get the following response function:\n\
    \     W = 0.12/p^0.835.                                    (1)\n   This HighSpeed\
    \ response function is illustrated in Table 3 below.\n   For HighSpeed TCP, the\
    \ number of round-trip times between losses,\n   1/(pW), equals 12.7 W^0.2, for\
    \ W > 38 segments.\n     Packet Drop Rate P   Congestion Window W    RTTs Between\
    \ Losses\n     ------------------   -------------------    -------------------\n\
    \            10^-2                    12                   8\n            10^-3\
    \                    38                  25\n            10^-4               \
    \    263                  38\n            10^-5                  1795        \
    \          57\n            10^-6                 12279                  83\n \
    \           10^-7                 83981                 123\n            10^-8\
    \                574356                 180\n            10^-9               3928088\
    \                 264\n            10^-10             26864653               \
    \  388\n   Table 3: TCP Response Function for HighSpeed TCP.  The average\n  \
    \ congestion window W in MSS-sized segments is given as a function of\n   the\
    \ packet drop rate P.\n   We believe that the problem of backward compatibility\
    \ with Standard\n   TCP requires a response function that is quite close to that\
    \ of\n   Standard TCP for loss rates of 10^-1, 10^-2, or 10^-3.  We believe,\n\
    \   however, that such stringent TCP-compatibility is not required for\n   smaller\
    \ loss rates, and that an appropriate response function is one\n   that gives\
    \ a plausible packet drop rate for a connection throughput\n   of 10 Gbps.  This\
    \ also gives a slowly increasing number of round-trip\n   times between loss events\
    \ as a function of a decreasing packet drop\n   rate.\n   Another way to look\
    \ at the HighSpeed response function is to consider\n   that HighSpeed TCP is\
    \ roughly emulating the congestion control\n   response of N parallel TCP connections,\
    \ where N is initially one, and\n   where N increases as a function of the HighSpeed\
    \ TCP's congestion\n   window.  Thus for the HighSpeed response function in Equation\
    \ (1)\n   above, the response function can be viewed as equivalent to that of\n\
    \   N(W) parallel TCP connections, where N(W) varies as a function of the\n  \
    \ congestion window W.  Recall that for a single standard TCP\n   connection,\
    \ the average congestion window equals 1.2/sqrt(p).  For N\n   parallel TCP connections,\
    \ the aggregate congestion window for the N\n   connections equals N*1.2/sqrt(p).\
    \  From the HighSpeed response\n   function in Equation (1) and the relationship\
    \ above, we can derive\n   the following:\n    N(W) = 0.23*W^(0.4)\n   for N(W)\
    \ the number of parallel TCP connections emulated by the\n   HighSpeed TCP response\
    \ function, and for N(W) >= 1.  This is shown in\n   Table 4 below.\n     Congestion\
    \ Window W         Number N(W) of Parallel TCPs\n     -------------------    \
    \     -------------------------\n              1                            1\n\
    \             10                            1\n            100               \
    \             1.4\n          1,000                            3.6\n         10,000\
    \                            9.2\n        100,000                           23.0\n\
    \   Table 4: Number N(W) of parallel TCP connections roughly emulated by\n   the\
    \ HighSpeed TCP response function.\n   In this document, we do not attempt to\
    \ seriously evaluate the\n   HighSpeed response function for congestion windows\
    \ greater than\n   100,000 packets.  We believe that we will learn more about\
    \ the\n   requirements for sustaining the throughput of best-effort connections\n\
    \   in that range as we gain more experience with HighSpeed TCP with\n   congestion\
    \ windows of thousands and tens of thousands of packets.\n   There also might\
    \ be limitations to the per-connection throughput that\n   can be realistically\
    \ achieved for best-effort traffic, in terms of\n   congestion window of hundreds\
    \ of thousands of packets or more, in the\n   absence of additional support or\
    \ feedback from the routers along the\n   path.\n"
- title: 6.  Fairness Implications of the HighSpeed Response Function
  contents:
  - "6.  Fairness Implications of the HighSpeed Response Function\n   The Standard\
    \ and Highspeed Response Functions can be used directly to\n   infer the relative\
    \ fairness between flows using the two response\n   functions.  For example, given\
    \ a packet drop rate P, assume that\n   Standard TCP has an average congestion\
    \ window of W_Standard, and\n   HighSpeed TCP has a higher average congestion\
    \ window of W_HighSpeed.\n   In this case, a single HighSpeed TCP connection is\
    \ receiving\n   W_HighSpeed/W_Standard times the throughput of a single Standard\
    \ TCP\n   connection competing in the same environment.\n   This relative fairness\
    \ is illustrated below in Table 5, for the\n   parameters used for the Highspeed\
    \ response function in the section\n   above.  The second column gives the relative\
    \ fairness, for the\n   steady-state packet drop rate specified in the first column.\
    \  To help\n   calibrate, the third column gives the aggregate average congestion\n\
    \   window for the two TCP connections, and the fourth column gives the\n   bandwidth\
    \ that would be needed by the two connections to achieve that\n   aggregate window\
    \ and packet drop rate, given 100 ms round-trip times\n   and 1500-byte packets.\n\
    \     Packet Drop Rate P   Fairness  Aggregate Window  Bandwidth\n     ------------------\
    \   --------  ----------------  ---------\n            10^-2            1.0  \
    \            24        2.8 Mbps\n            10^-3            1.0            \
    \  76        9.1 Mbps\n            10^-4            2.2             383      \
    \ 45.9 Mbps\n            10^-5            4.7            2174      260.8 Mbps\n\
    \            10^-6           10.2           13479        1.6 Gbps\n          \
    \  10^-7           22.1           87776       10.5 Gbps\n   Table 5: Relative\
    \ Fairness between the HighSpeed and Standard\n   Response Functions.\n   Thus,\
    \ for packet drop rates of 10^-4, a flow with the HighSpeed\n   response function\
    \ can expect to receive 2.2 times the throughput of a\n   flow using the Standard\
    \ response function, given the same round-trip\n   times and packet sizes.  With\
    \ packet drop rates of 10^-6 (or 10^-7),\n   the unfairness is more severe, and\
    \ we have entered the regime where a\n   Standard TCP connection requires at most\
    \ one congestion event every\n   800 (or 2530) round-trip times in order to make\
    \ use of the available\n   bandwidth.  Our judgement would be that there are not\
    \ a lot of TCP\n   connections effectively operating in this regime today, with\n\
    \   congestion windows of thousands of packets, and that therefore the\n   benefits\
    \ of the HighSpeed response function would outweigh the\n   unfairness that would\
    \ be experienced by Standard TCP in this regime.\n   However, one purpose of this\
    \ document is to solicit feedback on this\n   issue.  The parameter Low_Window\
    \ determines directly the point of\n   divergence between the Standard and HighSpeed\
    \ Response Functions.\n   The third column of Table 5, the Aggregate Window, gives\
    \ the\n   aggregate congestion window of the two competing TCP connections,\n\
    \   with HighSpeed and Standard TCP, given the packet drop rate specified\n  \
    \ in the first column.  From Table 5, a HighSpeed TCP connection would\n   receive\
    \ ten times the bandwidth of a Standard TCP in an environment\n   with a packet\
    \ drop rate of 10^-6.  This would occur when the two\n   flows sharing a single\
    \ pipe achieved an aggregate window of 13479\n   packets.  Given a round-trip\
    \ time of 100 ms and a packet size of 1500\n   bytes, this would occur with an\
    \ available bandwidth for the two\n   competing flows of 1.6 Gbps.\n   Next we\
    \ consider the time that it takes a standard or HighSpeed TCP\n   flow to converge\
    \ to fairness against a pre-existing HighSpeed TCP\n   flow.  The worst case for\
    \ convergence to fairness occurs when a new\n   flow is starting up, competing\
    \ against a high-bandwidth existing\n   flow, and the new flow suffers a packet\
    \ drop and exits slow-start\n   while its window is still small.  In the worst\
    \ case, consider that\n   the new flow has entered the congestion avoidance phase\
    \ while its\n   window is only one packet.  A standard TCP flow in congestion\n\
    \   avoidance increases its window by at most one packet per round-trip\n   time,\
    \ and after N round-trip times has only achieved a window of N\n   packets (when\
    \ starting with a window of 1 in the first round-trip\n   time).  In contrast,\
    \ a HighSpeed TCP flows increases much faster than\n   a standard TCP flow while\
    \ in the congestion avoidance phase, and we\n   can expect its convergence to\
    \ fairness to be much better.  This is\n   shown in Table 6 below.  The script\
    \ used to generate this table is\n   given in Appendix C.\n     RTT  HS_Window\
    \ Standard_TCP_Window\n     ---  --------- -------------------\n     100     \
    \  131        100\n     200       475        200\n     300      1131        300\n\
    \     400      2160        400\n     500      3601        500\n     600      5477\
    \        600\n     700      7799        700\n     800     10567        800\n \
    \    900     13774        900\n    1000     17409       1000\n    1100     21455\
    \       1100\n    1200     25893       1200\n    1300     30701       1300\n \
    \   1400     35856       1400\n    1500     41336       1500\n    1600     47115\
    \       1600\n    1700     53170       1700\n    1800     59477       1800\n \
    \   1900     66013       1900\n    2000     72754       2000\n   Table 6:  For\
    \ a HighSpeed and a Standard TCP connection, the\n   congestion window during\
    \ congestion avoidance phase (starting with a\n   congestion window of 1 packet\
    \ during RTT 1).\n   The classic paper on relative fairness is from Chiu and Jain\
    \ [CJ89].\n   This paper shows that AIMD (Additive Increase Multiplicative\n \
    \  Decrease) converges to fairness in an environment with synchronized\n   congestion\
    \ events.  From [CJ89], it is easy to see that MIMD and AIAD\n   do not converge\
    \ to fairness in this environment.  However, the\n   results of [CJ89] do not\
    \ apply to an asynchronous environment such as\n   that of the current Internet,\
    \ where the frequency of congestion\n   feedback can be different for different\
    \ flows.  For example, it has\n   been shown that MIMD converges to fair states\
    \ in a model with\n   proportional instead of synchronous feedback in terms of\
    \ packet drops\n   [GV02].  Thus, we are not concerned about abandoning a strict\
    \ model\n   of AIMD for HighSpeed TCP.  However, we note that in an environment\n\
    \   with Drop-Tail queue management, there is likely to be some\n   synchronization\
    \ of packet drops.  In this environment, the model of\n   completely synchronous\
    \ feedback does not hold, but the model of\n   completely asynchronous feedback\
    \ is not accurate either.  Fairness in\n   Drop-Tail environments is discussed\
    \ in more detail in Sections 9 and\n   12.\n"
- title: 7.  Translating the HighSpeed Response Function into Congestion Control
  contents:
  - "7.  Translating the HighSpeed Response Function into Congestion Control\n   \
    \  Parameters\n   For equation-based congestion control such as TFRC, the HighSpeed\n\
    \   Response Function above could be used directly by the TFRC congestion\n  \
    \ control mechanism.  However, for TCP the HighSpeed response function\n   has\
    \ to be translated into additive increase and multiplicative\n   decrease parameters.\
    \  The HighSpeed response function cannot be\n   achieved by TCP with an additive\
    \ increase of one segment per round-\n   trip time and a multiplicative decrease\
    \ of halving the current\n   congestion window; HighSpeed TCP will have to modify\
    \ either the\n   increase or the decrease parameter, or both.  We have concluded\
    \ that\n   HighSpeed TCP is most likely to achieve an acceptable compromise\n\
    \   between moderate increases and timely decreases by modifying both the\n  \
    \ increase and the decrease parameter.\n   That is, for HighSpeed TCP let the\
    \ congestion window increase by a(w)\n   segments per round-trip time in the absence\
    \ of congestion, and let\n   the congestion window decrease to w(1-b(w)) segments\
    \ in response to a\n   round-trip time with one or more loss events.  Thus, in\
    \ response to a\n   single acknowledgement HighSpeed TCP increases its congestion\
    \ window\n   in segments as follows:\n    w <- w + a(w)/w.\n   In response to\
    \ a congestion event, HighSpeed TCP decreases as\n   follows:\n    w <- (1-b(w))w.\n\
    \   For Standard TCP, a(w) = 1 and b(w) = 1/2, regardless of the value of\n  \
    \ w.  HighSpeed TCP uses the same values of a(w) and b(w) for w <=\n   Low_Window.\
    \  This section specifies a(w) and b(w) for HighSpeed TCP\n   for larger values\
    \ of w.\n   For w = High_Window, we have specified a loss rate of High_P.  From\n\
    \   [FRS02], or from elementary calculations, this requires the following\n  \
    \ relationship between a(w) and b(w) for w = High_Window:\n    a(w) = High_Window^2\
    \ * High_P * 2 * b(w)/(2-b(w)).     (2)\n   We use the parameter High_Decrease\
    \ to specify the decrease parameter\n   b(w) for w = High_Window, and use Equation\
    \ (2) to derive the increase\n   parameter a(w) for w = High_Window.  Along with\
    \ High_P = 10^-7 and\n   High_Window = 83000, for example, we specify High_Decrease\
    \ = 0.1,\n   specifying that b(83000) = 0.1, giving a decrease of 10% after a\n\
    \   congestion event.  Equation (2) then gives a(83000) = 72, for an\n   increase\
    \ of 72 segments, or just under 0.1%, within a round-trip\n   time, for w = 83000.\n\
    \   This moderate decrease strikes us as acceptable, particularly when\n   coupled\
    \ with the role of TCP's ACK-clocking in limiting the sending\n   rate in response\
    \ to more severe congestion [BBFS01].  A more severe\n   decrease would require\
    \ a more aggressive increase in the congestion\n   window for a round-trip time\
    \ without congestion.  In particular, a\n   decrease factor High_Decrease of 0.5,\
    \ as in Standard TCP, would\n   require an increase of 459 segments per round-trip\
    \ time when w =\n   83000.\n   Given decrease parameters of b(w) = 1/2 for w =\
    \ Low_Window, and b(w)\n   = High_Decrease for w = High_Window, we are left to\
    \ specify the value\n   of b(w) for other values of w > Low_Window.  From [FRS02],\
    \ we let\n   b(w) vary linearly as the log of w, as follows:\n    b(w) = (High_Decrease\
    \ - 0.5) (log(w)-log(W)) / (log(W_1)-log(W)) +\n   0.5,\n   for W = Low_window\
    \ and W_1 = High_window.  The increase parameter\n   a(w) can then be computed\
    \ as follows:\n    a(w) = w^2 * p(w) * 2 * b(w)/(2-b(w)),\n   for p(w) the packet\
    \ drop rate for congestion window w.  From\n   inverting Equation (1), we get\
    \ p(w) as follows:\n    p(w) = 0.078/w^1.2.\n   We assume that experimental implementations\
    \ of HighSpeed TCP for\n   further investigation will use a pre-computed look-up\
    \ table for\n   finding a(w) and b(w).  For example, the implementation from Tom\n\
    \   Dunigan adjusts the a(w) and b(w) parameters every 0.1 seconds.  In\n   the\
    \ appendix we give such a table for our default values of\n   Low_Window = 38,\
    \ High_Window = 83,000, High_P = 10^-7, and\n   High_Decrease = 0.1.  These are\
    \ also the default values in the NS\n   simulator; example simulations in NS can\
    \ be run with the command\n   \"./test-all-tcpHighspeed\" in the directory tcl/test.\n"
- title: 8.  An alternate, linear response functions
  contents:
  - "8.  An alternate, linear response functions\n   In this section we explore an\
    \ alternate, linear response function for\n   HighSpeed TCP that has been proposed\
    \ by a number of other people, in\n   particular by Glenn Vinnicombe and Tom Kelly.\
    \  Similarly, it has been\n   suggested by others that a less \"ad-hoc\" guideline\
    \ for a response\n   function for HighSpeed TCP would be to specify a constant\
    \ value for\n   the number of round-trip times between congestion events.\n  \
    \ Assume that we keep the value of Low_Window as 38 MSS-sized segments,\n   indicating\
    \ when the HighSpeed response function diverges from the\n   current TCP response\
    \ function, but that we modify the High_Window and\n   High_P parameters that\
    \ specify the upper range of the HighSpeed\n   response function.  In particular,\
    \ consider the response function\n   given by High_Window = 380,000 and High_P\
    \ = 10^-7, with Low_Window =\n   38 and Low_P = 10^-3 as before.\n   Using the\
    \ equations in Section 5, this would give the following\n   Linear response function,\
    \ for w > Low_Window:\n     W = 0.038/p.\n   This Linear HighSpeed response function\
    \ is illustrated in Table 7\n   below.  For HighSpeed TCP, the number of round-trip\
    \ times between\n   losses, 1/(pW), equals 1/0.38, or equivalently, 26, for W\
    \ > 38\n   segments.\n     Packet Drop Rate P   Congestion Window W    RTTs Between\
    \ Losses\n     ------------------   -------------------    -------------------\n\
    \            10^-2                    12                   8\n            10^-3\
    \                    38                  26\n            10^-4               \
    \    380                  26\n            10^-5                  3800        \
    \          26\n            10^-6                 38000                  26\n \
    \           10^-7                380000                  26\n            10^-8\
    \               3800000                  26\n            10^-9              38000000\
    \                  26\n            10^-10            380000000               \
    \   26\n   Table 7: An Alternate, Linear TCP Response Function for HighSpeed\n\
    \   TCP.  The average congestion window W in MSS-sized segments is given\n   as\
    \ a function of the packet drop rate P.\n   Given a constant decrease b(w) of\
    \ 1/2, this would give an increase\n   a(w) of w/Low_Window, or equivalently,\
    \ a constant increase of\n   1/Low_Window packets per acknowledgement, for w >\
    \ Low_Window.\n   Another possibility is Scalable TCP [K03], which uses a fixed\n\
    \   decrease b(w) of 1/8 and a fixed increase per acknowledgement of\n   0.01.\
    \  This gives an increase a(w) per window of 0.005 w, for a TCP\n   with delayed\
    \ acknowledgements, for pure MIMD.\n   The relative fairness between the alternate\
    \ Linear response function\n   and the standard TCP response function is illustrated\
    \ below in Table\n   8.\n     Packet Drop Rate P   Fairness  Aggregate Window\
    \  Bandwidth\n     ------------------   --------  ----------------  ---------\n\
    \            10^-2            1.0              24        2.8 Mbps\n          \
    \  10^-3            1.0              76        9.1 Mbps\n            10^-4   \
    \         3.2             500       60.0 Mbps\n            10^-5           15.1\
    \            4179      501.4 Mbps\n            10^-6           31.6          \
    \ 39200        4.7 Gbps\n            10^-7          100.1          383795    \
    \   46.0 Gbps\n   Table 8: Relative Fairness between the Linear HighSpeed and\
    \ Standard\n   Response Functions.\n   One attraction of the linear response function\
    \ is that it is scale-\n   invariant, with a fixed increase in the congestion\
    \ window per\n   acknowledgement, and a fixed number of round-trip times between\
    \ loss\n   events.  My own assumption would be that having a fixed length for\n\
    \   the congestion epoch in round-trip times, regardless of the packet\n   drop\
    \ rate, would be a poor fit for an imprecise and imperfect world\n   with routers\
    \ with a range of queue management mechanisms, such as the\n   Drop-Tail queue\
    \ management that is common today.  For example, a\n   response function with\
    \ a fixed length for the congestion epoch in\n   round-trip times might give less\
    \ clearly-differentiated feedback in\n   an environment with steady-state background\
    \ losses at fixed intervals\n   for all flows (as might occur with a wireless\
    \ link with occasional\n   short error bursts, giving losses for all flows every\
    \ N seconds\n   regardless of their sending rate).\n   While it is not a goal\
    \ to have perfect fairness in an environment\n   with synchronized losses, it\
    \ would be good to have moderately\n   acceptable performance in this regime.\
    \  This goal might argue against\n   a response function with a constant number\
    \ of round-trip times\n   between congestion events.  However, this is a question\
    \ that could\n   clearly use additional research and investigation.  In addition,\n\
    \   flows with different round-trip times would have different time\n   durations\
    \ for congestion epochs even in the model with a linear\n   response function.\n\
    \   The third column of Table 8, the Aggregate Window, gives the\n   aggregate\
    \ congestion window of two competing TCP connections, one\n   with Linear HighSpeed\
    \ TCP and one with Standard TCP, given the packet\n   drop rate specified in the\
    \ first column.  From Table 8, a Linear\n   HighSpeed TCP connection would receive\
    \ fifteen times the bandwidth of\n   a Standard TCP in an environment with a packet\
    \ drop rate of 10^-5.\n   This would occur when the two flows sharing a single\
    \ pipe achieved an\n   aggregate window of 4179 packets.  Given a round-trip time\
    \ of 100 ms\n   and a packet size of 1500 bytes, this would occur with an available\n\
    \   bandwidth for the two competing flows of 501 Mbps.  Thus, because the\n  \
    \ Linear HighSpeed TCP is more aggressive than the HighSpeed TCP\n   proposed\
    \ above, it also is less fair when competing with Standard TCP\n   in a high-bandwidth\
    \ environment.\n"
- title: 9.  Tradeoffs for Choosing Congestion Control Parameters
  contents:
  - "9.  Tradeoffs for Choosing Congestion Control Parameters\n   A range of metrics\
    \ can be used for evaluating choices for congestion\n   control parameters for\
    \ HighSpeed TCP.  My assumption in this section\n   is that for a response function\
    \ of the form w = c/p^d, for constant c\n   and exponent d, the only response\
    \ functions that would be considered\n   are response functions with 1/2 <= d\
    \ <= 1.  The two ends of this\n   spectrum are represented by current TCP, with\
    \ d = 1/2, and by the\n   linear response function described in Section 8 above,\
    \ with d = 1.\n   HighSpeed TCP lies somewhere in the middle of the spectrum,\
    \ with d =\n   0.835.\n   Response functions with exponents less than 1/2 can\
    \ be eliminated\n   from consideration because they would be even worse than standard\
    \ TCP\n   in accommodating connections with high congestion windows.\n"
- title: 9.1.  The Number of Round-Trip Times between Loss Events
  contents:
  - "9.1.  The Number of Round-Trip Times between Loss Events\n   Response functions\
    \ with exponents greater than 1 can be eliminated\n   from consideration because\
    \ for these response functions, the number\n   of round-trip times between loss\
    \ events decreases as congestion\n   decreases.  For a response function of w\
    \ = c/p^d, with one loss event\n   or congestion event every 1/p packets, the\
    \ number of round-trip times\n   between loss events is w^((1/d)-1)/c^(1/d). \
    \ Thus, for standard TCP\n   the number of round-trip times between loss events\
    \ is linear in w.\n   In contrast, one attraction of the linear response function,\
    \ as\n   described in Section 8 above, is that it is scale-invariant, in terms\n\
    \   of a fixed increase in the congestion window per acknowledgement, and\n  \
    \ a fixed number of round-trip times between loss events.\n   However, for a response\
    \ function with d > 1, the number of round-\n   trip times between loss events\
    \ would be proportional to w^((1/d)-1),\n   for a negative exponent ((1/d)-1),\
    \ setting smaller as w increases.\n   This would seem undesirable.\n"
- title: 9.2.  The Number of Packet Drops per Loss Event, with Drop-Tail
  contents:
  - "9.2.  The Number of Packet Drops per Loss Event, with Drop-Tail\n   A TCP connection\
    \ increases its sending rate by a(w) packets per\n   round-trip time, and in a\
    \ Drop-Tail environment, this is likely to\n   result in a(w) dropped packets\
    \ during a single loss event.  One\n   attraction of standard TCP is that it has\
    \ a fixed increase per\n   round-trip time of one packet, minimizing the number\
    \ of packets that\n   would be dropped in a Drop-Tail environment.  For an environment\
    \ with\n   some form of Active Queue Management, and in particular for an\n  \
    \ environment that uses ECN, the number of packets dropped in a single\n   congestion\
    \ event would not be a problem.  However, even in these\n   environments, larger\
    \ increases in the sending rate per round-trip\n   time result in larger stresses\
    \ on the ability of the queues in the\n   router to absorb the fluctuations.\n\
    \   HighSpeed TCP plays a middle ground between the metrics of a moderate\n  \
    \ number of round-trip times between loss events, and a moderate\n   increase\
    \ in the sending rate per round-trip time.  As shown in\n   Appendix B, for a\
    \ congestion window of 83,000 packets, HighSpeed TCP\n   increases its sending\
    \ rate by 70 packets per round-trip time,\n   resulting in at most 70 packet drops\
    \ when the buffer overflows in a\n   Drop-Tail environment.  This increased aggressiveness\
    \ is the price\n   paid by HighSpeed TCP for its increased scalability.  A large\
    \ number\n   of packets dropped per congestion event could result in synchronized\n\
    \   drops from multiple flows, with a possible loss of throughput as a\n   result.\n\
    \   Scalable TCP has an increase a(w) of 0.005 w packets per round-trip\n   time.\
    \  For a congestion window of 83,000 packets, this gives an\n   increase of 415\
    \ packets per round-trip time, resulting in roughly 415\n   packet drops per congestion\
    \ event in a Drop-Tail environment.\n   Thus, HighSpeed TCP and its variants place\
    \ increased demands on queue\n   management in routers, relative to Standard TCP.\
    \  (This is rather\n   similar to the increased demands on queue management that\
    \ would\n   result from using N parallel TCP connections instead of a single\n\
    \   Standard TCP connection.)\n"
- title: 10.  Related Issues
  contents:
  - '10.  Related Issues

    '
- title: 10.1.  Slow-Start
  contents:
  - "10.1.  Slow-Start\n   A companion internet-draft on \"Limited Slow-Start for\
    \ TCP with Large\n   Congestion Windows\" [F02b] proposes a modification to TCP's\
    \ slow-\n   start procedure that can significantly improve the performance of\
    \ TCP\n   connections slow-starting up to large congestion windows.  For TCP\n\
    \   connections that are able to use congestion windows of thousands (or\n   tens\
    \ of thousands) of MSS-sized segments (for MSS the sender's\n   MAXIMUM SEGMENT\
    \ SIZE), the current slow-start procedure can result in\n   increasing the congestion\
    \ window by thousands of segments in a single\n   round-trip time.  Such an increase\
    \ can easily result in thousands of\n   packets being dropped in one round-trip\
    \ time.  This is often\n   counter-productive for the TCP flow itself, and is\
    \ also hard on the\n   rest of the traffic sharing the congested link.\n   [F02b]\
    \ proposes Limited Slow-Start, limiting the number of segments\n   by which the\
    \ congestion window is increased for one window of data\n   during slow-start,\
    \ in order to improve performance for TCP\n   connections with large congestion\
    \ windows.  We have separated out\n   Limited Slow-Start to a separate draft because\
    \ it can be used both\n   with Standard or with HighSpeed TCP.\n   Limited Slow-Start\
    \ is illustrated in the NS simulator, for snapshots\n   after May 1, 2002, in\
    \ the tests \"./test-all-tcpHighspeed tcp1A\" and\n   \"./test-all-tcpHighspeed\
    \ tcpHighspeed1\" in the subdirectory\n   \"tcl/lib\".\n   In order for best-effort\
    \ flows to safely start-up faster than slow-\n   start, e.g., in future high-bandwidth\
    \ networks, we believe that it\n   would be necessary for the flow to have explicit\
    \ feedback from the\n   routers along the path.  There are a number of proposals\
    \ for this,\n   ranging from a minimal proposal for an IP option that allows TCP\
    \ SYN\n   packets to collect information from routers along the path about the\n\
    \   allowed initial sending rate [J02], to proposals with more power that\n  \
    \ require more fine-tuned and continuous feedback from routers.  These\n   proposals\
    \ are all somewhat longer-term proposals than the HighSpeed\n   TCP proposal in\
    \ this document, requiring longer lead times and more\n   coordination for deployment,\
    \ and will be discussed in later\n   documents.\n"
- title: 10.2.  Limiting burstiness on short time scales
  contents:
  - "10.2.  Limiting burstiness on short time scales\n   Because the congestion window\
    \ achieved by a HighSpeed TCP connection\n   could be quite large, there is a\
    \ possibility for the sender to send a\n   large burst of packets in response\
    \ to a single acknowledgement.  This\n   could happen, for example, when there\
    \ is congestion or reordering on\n   the reverse path, and the sender receives\
    \ an acknowledgement\n   acknowledging hundreds or thousands of new packets. \
    \ Such a burst\n   would also result if the application was idle for a short period\
    \ of\n   time less than a round-trip time, and then suddenly had lots of data\n\
    \   available to send.  In this case, it would be useful for the\n   HighSpeed\
    \ TCP connection to have some method for limiting bursts.\n   In this document,\
    \ we do not specify TCP mechanisms for reducing the\n   short-term burstiness.\
    \  One possible mechanism is to use some form of\n   rate-based pacing, and another\
    \ possibility is to use maxburst, which\n   limits the number of packets that\
    \ are sent in response to a single\n   acknowledgement.  We would caution, however,\
    \ against a permanent\n   reduction in the congestion window as a mechanism for\
    \ limiting\n   short-term bursts.  Such a mechanism has been deployed in some\
    \ TCP\n   stacks, and our view would be that using permanent reductions of the\n\
    \   congestion window to reduce transient bursts would be a bad idea\n   [Fl03].\n"
- title: 10.3.  Other limitations on window size
  contents:
  - "10.3.  Other limitations on window size\n   The TCP header uses a 16-bit field\
    \ to report the receive window size\n   to the sender.  Unmodified, this allows\
    \ a window size of at most\n   2**16 = 65K bytes.  With window scaling, the maximum\
    \ window size is\n   2**30 = 1073M bytes [RFC 1323].  Given 1500-byte packets,\
    \ this allows\n   a window of up to 715,000 packets.\n"
- title: 10.4.  Implementation issues
  contents:
  - "10.4.  Implementation issues\n   One implementation issue that has been raised\
    \ with HighSpeed TCP is\n   that with congestion windows of 4MB or more, the handling\
    \ of\n   successive SACK packets after a packet is dropped becomes very time-\n\
    \   consuming at the TCP sender [S03].  Tom Kelly's Scalable TCP includes\n  \
    \ a \"SACK Fast Path\" patch that addresses this problem.\n   The issues addressed\
    \ in the Web100 project, the Net100 project, and\n   related projects about the\
    \ tuning necessary to achieve high bandwidth\n   data rates with TCP apply to\
    \ HighSpeed TCP as well [Net100, Web100].\n"
- title: 11.  Deployment issues
  contents:
  - '11.  Deployment issues

    '
- title: 11.1.  Deployment issues of HighSpeed TCP
  contents:
  - "11.1.  Deployment issues of HighSpeed TCP\n   We do not claim that the HighSpeed\
    \ TCP modification to TCP described\n   in this paper is an optimal transport\
    \ protocol for high-bandwidth\n   environments.  Based on our experiences with\
    \ HighSpeed TCP in the NS\n   simulator [NS], on simulation studies [SA03], and\
    \ on experimental\n   reports [ABLLS03,D02,CC03,F03], we believe that HighSpeed\
    \ TCP\n   improves the performance of TCP in high-bandwidth environments, and\n\
    \   we are documenting it for the benefit of the IETF community.  We\n   encourage\
    \ the use of HighSpeed TCP, and of its underlying response\n   function, and we\
    \ further encourage feedback about operational\n   experiences with this or related\
    \ modifications.\n   We note that in environments typical of much of the current\
    \ Internet,\n   HighSpeed TCP behaves exactly as does Standard TCP today.  This\
    \ is\n   the case any time the congestion window is less than 38 segments.\n \
    \   Bandwidth   Avg Cwnd w (pkts)    Increase a(w)   Decrease b(w)\n    ---------\
    \   -----------------    -------------   -------------\n      1.5 Mbps       \
    \  12.5               1              0.50\n     10 Mbps           83         \
    \        1              0.50\n    100 Mbps          833                 6    \
    \          0.35\n      1 Gbps         8333                26              0.22\n\
    \     10 Gbps        83333                70              0.10\n   Table 9: Performance\
    \ of a HighSpeed TCP connection\n   To help calibrate, Table 9 considers a TCP\
    \ connection with 1500-byte\n   packets, an RTT of 100 ms (including average queueing\
    \ delay), and no\n   competing traffic, and shows the average congestion window\
    \ if that\n   TCP connection had a pipe all to itself and fully used the link\n\
    \   bandwidth, for a range of bandwidths for the pipe.  This assumes that\n  \
    \ the TCP connection would use Table 12 in determining its increase and\n   decrease\
    \ parameters.  The first column of Table 9 gives the\n   bandwidth, and the second\
    \ column gives the average congestion window\n   w needed to utilize that bandwidth.\
    \  The third column shows the\n   increase a(w) in segments per RTT for window\
    \ w.  The fourth column\n   shows the decrease b(w) for that window w (where the\
    \ TCP sender\n   decreases the congestion window from w to w(1-b(w)) segments\
    \ after a\n   loss event).  When a loss occurs we note that the actual congestion\n\
    \   window is likely to be greater than the average congestion window w\n   in\
    \ column 2, so the decrease parameter used could be slightly smaller\n   than\
    \ the one given in column 4 of Table 9.\n   Table 9 shows that a HighSpeed TCP\
    \ over a 10 Mbps link behaves\n   exactly the same as a Standard TCP connection,\
    \ even in the absence of\n   competing traffic.  One can think of the congestion\
    \ window staying\n   generally in the range of 55 to 110 segments, with the HighSpeed\
    \ TCP\n   behavior being exactly the same as the behavior of Standard TCP.  (If\n\
    \   the congestion window is ever 128 segments or more, then the\n   HighSpeed\
    \ TCP increases by two segments per RTT instead of by one,\n   and uses a decrease\
    \ parameter of 0.44 instead of 0.50.)\n   Table 9 shows that for a HighSpeed TCP\
    \ connection over a 100 Mbps\n   link, with no competing traffic, HighSpeed TCP\
    \ behaves roughly as\n   aggressively as six parallel TCP connections, increasing\
    \ its\n   congestion window by roughly six segments per round-trip time, and\n\
    \   with a decrease parameter of roughly 1/3 (corresponding to decreasing\n  \
    \ down to 2/3-rds of its old congestion window, rather than to half, in\n   response\
    \ to a loss event).\n   For a Standard TCP connection in this environment, the\
    \ congestion\n   window could be thought of as generally varying in the range\
    \ of 550\n   to 1100 segments, with an average packet drop rate of 2.2 * 10^-6\n\
    \   (corresponding to a bit error rate of 1.8 * 10^-10), or equivalently,\n  \
    \ roughly 55 seconds between congestion events.  While a Standard TCP\n   connection\
    \ could sustain such a low packet drop rate in a carefully\n   controlled environment\
    \ with minimal competing traffic, we would\n   contend that in an uncontrolled\
    \ best-effort environment with even a\n   small amount of competing traffic, the\
    \ occasional congestion events\n   from smaller competing flows could easily be\
    \ sufficient to prevent a\n   Standard TCP flow with no lower-speed bottlenecks\
    \ from fully\n   utilizing the available bandwidth of the underutilized 100 Mbps\
    \ link.\n   That is, we would contend that in the environment of 100 Mbps links\n\
    \   with a significant amount of available bandwidth, Standard TCP would\n   sometimes\
    \ be unable to fully utilize the link bandwidth, and that\n   HighSpeed TCP would\
    \ be an improvement in this regard.  We would\n   further contend that in this\
    \ environment, the behavior of HighSpeed\n   TCP is sufficiently close to that\
    \ of Standard TCP that HighSpeed TCP\n   would be safe to deploy in the current\
    \ Internet.  We note that\n   HighSpeed TCP can only use high congestion windows\
    \ if allowed by the\n   receiver's advertised window size.  As a result, even\
    \ if HighSpeed\n   TCP was ubiquitously deployed in the Internet, the impact would\
    \ be\n   limited to those TCP connections with an advertised window from the\n\
    \   receiver of 118 MSS or larger.\n   We do not believe that the deployment of\
    \ HighSpeed TCP would serve as\n   a block to the possible deployment of alternate\
    \ experimental\n   protocols for high-speed congestion control, such as Scalable\
    \ TCP,\n   XCP [KHR02], or FAST TCP [JWL03].  In particular, we don't expect\n\
    \   HighSpeed TCP to interact any more poorly with alternative\n   experimental\
    \ proposals than would the N parallel TCP connections\n   commonly used today\
    \ in the absence of HighSpeed TCP.\n"
- title: 11.2.  Deployment issues of Scalable TCP
  contents:
  - "11.2.  Deployment issues of Scalable TCP\n   We believe that Scalable TCP and\
    \ HighSpeed TCP have sufficiently\n   similar response functions that they could\
    \ easily coexist in the\n   Internet.  However, we have not investigated Scalable\
    \ TCP\n   sufficiently to be able to claim, in this document, that Scalable TCP\n\
    \   is safe for a widespread deployment in the current Internet.\n    Bandwidth\
    \   Avg Cwnd w (pkts)    Increase a(w)   Decrease b(w)\n    ---------   -----------------\
    \    -------------   -------------\n      1.5 Mbps         12.5              \
    \ 1              0.50\n     10 Mbps           83                 0.4         \
    \   0.125\n    100 Mbps          833                 4.1            0.125\n  \
    \    1 Gbps         8333                41.6            0.125\n     10 Gbps  \
    \      83333               416.5            0.125\n   Table 10: Performance of\
    \ a Scalable TCP connection.\n   Table 10 shows the performance of a Scalable\
    \ TCP connection with\n   1500-byte packets, an RTT of 100 ms (including average\
    \ queueing\n   delay), and no competing traffic.  The TCP connection is assumed\
    \ to\n   use delayed acknowledgements.  The first column of Table 10 gives the\n\
    \   bandwidth, the second column gives the average congestion window\n   needed\
    \ to utilize that bandwidth, and the third and fourth columns\n   give the increase\
    \ and decrease parameters.\n   Note that even in an environment with a 10 Mbps\
    \ link, Scalable TCP's\n   behavior is considerably different from that of Standard\
    \ TCP.  The\n   increase parameter is smaller than that of Standard TCP, and the\n\
    \   decrease is smaller also, 1/8-th instead of 1/2.  That is, for 10\n   Mbps\
    \ links, Scalable TCP increases less aggressively than Standard\n   TCP or HighSpeed\
    \ TCP, but decreases less aggressively as well.\n   In an environment with a 100\
    \ Mbps link, Scalable TCP has an increase\n   parameter of roughly four segments\
    \ per round-trip time, with the same\n   decrease parameter of 1/8-th.  A comparison\
    \ of Tables 9 and 10 shows\n   that for this scenario of 100 Mbps links, HighSpeed\
    \ TCP increases\n   more aggressively than Scalable TCP.\n   Next we consider\
    \ the relative fairness between Standard TCP,\n   HighSpeed TCP and Scalable TCP.\
    \  The relative fairness between\n   HighSpeed TCP and Standard TCP was shown\
    \ in Table 5 earlier in this\n   document, and the relative fairness between Scalable\
    \ TCP and Standard\n   TCP was shown in Table 8.  Following the approach in Section\
    \ 6, for a\n   given packet drop rate p, for p < 10^-3, we can estimate the relative\n\
    \   fairness between Scalable and HighSpeed TCP as\n   W_Scalable/W_HighSpeed.\
    \  This relative fairness is shown in Table 11\n   below.  The bandwidth in the\
    \ last column of Table 11 is the aggregate\n   bandwidth of the two competing\
    \ flows given 100 ms round-trip times\n   and 1500-byte packets.\n    Packet Drop\
    \ Rate P   Fairness  Aggregate Window  Bandwidth\n    ------------------   --------\
    \  ----------------  ---------\n         10^-2            1.0              24\
    \        2.8 Mbps\n         10^-3            1.0              76        9.1 Mbps\n\
    \         10^-4            1.4             643       77.1 Mbps\n         10^-5\
    \            2.1            5595      671.4 Mbps\n         10^-6            3.1\
    \           50279        6.0 Gbps\n         10^-7            4.5          463981\
    \       55.7 Gbps\n   Table 11: Relative Fairness between the Scalable and HighSpeed\n\
    \   Response Functions.\n   The second row of Table 11 shows that for a Scalable\
    \ TCP and a\n   HighSpeed TCP flow competing in an environment with 100 ms RTTs\
    \ and a\n   10 Mbps pipe, the two flows would receive essentially the same\n \
    \  bandwidth.  The next row shows that for a Scalable TCP and a\n   HighSpeed\
    \ TCP flow competing in an environment with 100 ms RTTs and a\n   100 Mbps pipe,\
    \ the Scalable TCP flow would receive roughly 50% more\n   bandwidth than would\
    \ HighSpeed TCP.  Table 11 shows the relative\n   fairness in higher-bandwidth\
    \ environments as well.  This relative\n   fairness seems sufficient that there\
    \ should be no problems with\n   Scalable TCP and HighSpeed TCP coexisting in\
    \ the same environment as\n   Experimental variants of TCP.\n   We note that one\
    \ question that requires more investigation with\n   Scalable TCP is that of convergence\
    \ to fairness in environments with\n   Drop-Tail queue management.\n"
- title: 12.  Related Work in HighSpeed TCP
  contents:
  - "12.  Related Work in HighSpeed TCP\n   HighSpeed TCP has been separately investigated\
    \ in simulations by\n   Sylvia Ratnasamy and by Evandro de Souza [SA03].  The\
    \ simulations in\n   [SA03] verify the fairness properties of HighSpeed TCP when\
    \ sharing a\n   link with Standard TCP.\n   These simulations explore the relative\
    \ fairness of HighSpeed TCP\n   flows when competing with Standard TCP.  The simulation\
    \ environment\n   includes background forward and reverse-path TCP traffic limited\
    \ by\n   the TCP receive window, along with a small amount of forward and\n  \
    \ reverse-path traffic from the web traffic generator.  Most of the\n   simulations\
    \ so far explore performance on a simple dumbbell topology\n   with a 1 Gbps link\
    \ with a propagation delay of 50 ms.  Simulations\n   have been run with Adaptive\
    \ RED and with DropTail queue management.\n   The simulations in [SA03] explore\
    \ performance with a varying number\n   of competing flows, with the competing\
    \ traffic being all standard\n   TCP; all HighSpeed TCP; or a mix of standard\
    \ and HighSpeed TCP.  For\n   the simulations in [SA03] with RED queue management,\
    \ the relative\n   fairness between standard and HighSpeed TCP is consistent with\
    \ the\n   relative fairness predicted in Table 5.  For the simulations with\n\
    \   Drop Tail queues, the relative fairness is more skewed, with the\n   HighSpeed\
    \ TCP flows receiving an even larger share of the link\n   bandwidth.  This is\
    \ not surprising; with Active Queue Management at\n   the congested link, the\
    \ fraction of packet drops received by each\n   flow should be roughly proportional\
    \ to that flow's share of the link\n   bandwidth, while this property no longer\
    \ holds with Drop Tail queue\n   management.  We also note that relative fairness\
    \ in simulations with\n   Drop Tail queue management can sometimes depend on small\
    \ details of\n   the simulation scenario, and that Drop Tail simulations need\
    \ special\n   care to avoid phase effects [F92].\n   [SA03] explores the bandwidth\
    \ `stolen' by HighSpeed TCP from standard\n   TCP by exploring the fraction of\
    \ the link bandwidth N standard TCP\n   flows receive when competing against N\
    \ other standard TCP flows, and\n   comparing this to the fraction of the link\
    \ bandwidth the N standard\n   TCP flows receive when competing against N HighSpeed\
    \ TCP flows.  For\n   the 1 Gbps simulation scenarios dominated by long-lived\
    \ traffic, a\n   small number of standard TCP flows are able to achieve high link\n\
    \   utilization, and the HighSpeed TCP flows can be viewed as stealing\n   bandwidth\
    \ from the competing standard TCP flows, as predicted in\n   Section 6 on the\
    \ Fairness Implications of the HighSpeed Response\n   Function.  However, [SA03]\
    \ shows that when even a small fraction of\n   the link bandwidth is used by more\
    \ bursty, short TCP connections, the\n   standard TCP flows are unable to achieve\
    \ high link utilization, and\n   the HighSpeed TCP flows in this case are not\
    \ `stealing' bandwidth\n   from the standard TCP flows, but instead are using\
    \ bandwidth that\n   otherwise would not be utilized.\n   The conclusions of [SA03]\
    \ are that \"HighSpeed TCP behaved as forseen\n   by its response function, and\
    \ appears to be a real and viable option\n   for use on high-speed wide area TCP\
    \ connections.\"\n   Future work that could be explored in more detail includes\n\
    \   convergence times after new flows start-up; recovery time after a\n   transient\
    \ outage; the response to sudden severe congestion, and\n   investigations of\
    \ the potential for oscillations.  We invite\n   contributions from others in\
    \ this work.\n"
- title: 13.  Relationship to other Work
  contents:
  - "13.  Relationship to other Work\n   Our assumption is that HighSpeed TCP will\
    \ be used with the TCP SACK\n   option, and also with the increased Initial Window\
    \ of three or four\n   segments, as allowed by [RFC3390].  For paths that have\
    \ substantial\n   reordering, TCP performance would be greatly improved by some\
    \ of the\n   mechanisms still in the research stages for robust performance in\
    \ the\n   presence of reordered packets.\n   Our view is that HighSpeed TCP is\
    \ largely orthogonal to proposals for\n   higher PMTU (Path MTU) values [M02].\
    \  Unlike changes to the PMTU,\n   HighSpeed TCP does not require any changes\
    \ in the network or at the\n   TCP receiver, and works well in the current Internet.\
    \  Our assumption\n   is that HighSpeed TCP would be useful even with larger values\
    \ for the\n   PMTU.  Unlike the current congestion window, the PMTU gives no\n\
    \   information about the bandwidth-delay product available to that\n   particular\
    \ flow.\n   A related approach is that of a virtual MTU, where the actual MTU\
    \ of\n   the path might be limited [VMSS,S02].  The virtual MTU approach has\n\
    \   not been fully investigated, and we do not explore the virtual MTU\n   approach\
    \ further in this document.\n"
- title: 14.  Conclusions
  contents:
  - "14.  Conclusions\n   This document has proposed HighSpeed TCP, a modification\
    \ to TCP's\n   congestion control mechanism for use with TCP connections with\
    \ large\n   congestion windows.  We have explored this proposal in simulations,\n\
    \   and others have explored HighSpeed TCP with experiments, and we\n   believe\
    \ HighSpeed TCP to be safe to deploy on the current Internet.\n   We would welcome\
    \ additional analysis, simulations, and particularly,\n   experimentation.  More\
    \ information on simulations and experiments is\n   available from the HighSpeed\
    \ TCP Web Page [HSTCP].  There are several\n   independent implementations of\
    \ HighSpeed TCP [D02,F03] and of\n   Scalable TCP [K03] for further investigation.\n"
- title: 15.  Acknowledgements
  contents:
  - "15.  Acknowledgements\n   The HighSpeed TCP proposal is from joint work with\
    \ Sylvia Ratnasamy\n   and Scott Shenker (and was initiated by Scott Shenker).\
    \  Additional\n   investigations of HighSpeed TCP were joint work with Evandro\
    \ de Souza\n   and Deb Agarwal.  We thank Tom Dunigan for the implementation in\
    \ the\n   Linux 2.4.16 Web100 kernel, and for resulting experimentation with\n\
    \   HighSpeed TCP.  We are grateful to the End-to-End Research Group, the\n  \
    \ members of the Transport Area Working Group, and to members of the\n   IPAM\
    \ program in Large Scale Communication Networks for feedback.  We\n   thank Glenn\
    \ Vinnicombe for framing the Linear response function in\n   the parameters of\
    \ HighSpeed TCP.  We are also grateful for\n   contributions and feedback from\
    \ the following individuals: Les\n   Cottrell, Mitchell Erblich, Jeffrey Hsu,\
    \ Tom Kelly, Chuck Jackson,\n   Matt Mathis, Jitendra Padhye, Andrew Reiter, Stanislav\
    \ Shalunov, Alex\n   Solan, Paul Sutter, Brian Tierney, Joe Touch.\n"
- title: 16.  Normative References
  contents:
  - "16.  Normative References\n   [RFC2581]  Allman, M., Paxson, V. and W. Stevens,\
    \ \"TCP Congestion\n              Control\", RFC 2581, April 1999.\n"
- title: 17.  Informative References
  contents:
  - "17.  Informative References\n   [ABLLS03]  A. Antony, J. Blom, C. de Laat, J.\
    \ Lee, and W. Sjouw,\n              \"Microscopic Examination of TCP Flows over\
    \ Transatlantic\n              Links\", iGrid2002 special issue, Future Generation\n\
    \              Computer Systems, volume 19 issue 6 (2003), URL\n             \
    \ \"http://www.science.uva.nl/~delaat/techrep-2003-2-\n              tcp.pdf\"\
    .\n   [BBFS01]   Deepak Bansal, Hari Balakrishnan, Sally Floyd, and Scott\n  \
    \            Shenker, \"Dynamic Behavior of Slowly-Responsive Congestion\n   \
    \           Control Algorithms\", SIGCOMM 2001, August 2001.\n   [CC03]     Fabrizio\
    \ Coccetti and Les Cottrell, \"TCP Stack\n              Measurements on Lightly\
    \ Loaded Testbeds\", 2003.  URL\n              \"http://www-iepm.slac.stanford.edu/monitoring/bulk/fast/\"\
    .\n   [CJ89]     D. Chiu and R. Jain, \"Analysis of the Increase and\n       \
    \       Decrease Algorithms for Congestion Avoidance in Computer\n           \
    \   Networks\", Computer Networks and ISDN Systems, Vol. 17,\n              pp.\
    \ 1-14, 1989.\n   [CO98]     J. Crowcroft and P. Oechslin, \"Differentiated End-to-end\n\
    \              Services using a Weighted Proportional Fair Share TCP\",\n    \
    \          Computer Communication Review, 28(3):53--69, 1998.\n   [D02]      Tom\
    \ Dunigan, \"Floyd's TCP slow-start and AIMD mods\", URL\n              \"http://www.csm.ornl.gov/~dunigan/net100/floyd.html\"\
    .\n   [F03]      Gareth Fairey, \"High-Speed TCP\", 2003.  URL\n             \
    \ \"http://www.hep.man.ac.uk/u/garethf/hstcp/\".\n   [F92]      S. Floyd and V.\
    \ Jacobson, \"On Traffic Phase Effects in\n              Packet-Switched Gateways,\
    \ Internetworking: Research and\n              Experience\", V.3 N.3, September\
    \ 1992, p.115-156.  URL\n              \"http://www.icir.org/floyd/papers.html\"\
    .\n   [Fl03]     Sally Floyd, \"Re: [Tsvwg] taking NewReno (RFC 2582) to\n   \
    \           Proposed Standard\", Email to the tsvwg mailing list, May\n      \
    \        14, 2003.\n   URLs       \"http://www1.ietf.org/mail-archive/working-\n\
    \              groups/tsvwg/current/msg04086.html\" and\n              \"http://www1.ietf.org/mail-archive/working-\n\
    \              groups/tsvwg/current/msg04087.html\".\n   [FF98]     Floyd, S.,\
    \ and Fall, K., \"Promoting the Use of End-to-End\n              Congestion Control\
    \ in the Internet\", IEEE/ACM Transactions\n              on Networking, August\
    \ 1999.\n   [FRS02]    Sally Floyd, Sylvia Ratnasamy, and Scott Shenker,\n   \
    \           \"Modifying TCP's Congestion Control for High Speeds\", May\n    \
    \          2002.  URL \"http://www.icir.org/floyd/notes.html\".\n   [GRK99]  \
    \  Panos Gevros, Fulvio Risso and Peter Kirstein, \"Analysis\n              of\
    \ a Method for Differential TCP Service\".  In Proceedings\n              of the\
    \ IEEE GLOBECOM'99, Symposium on Global Internet ,\n              December 1999,\
    \ Rio de Janeiro, Brazil.\n   [GV02]     S. Gorinsky and H. Vin, \"Extended Analysis\
    \ of Binary\n              Adjustment Algorithms\", Technical Report TR2002-39,\n\
    \              Department of Computer Sciences, The University of Texas\n    \
    \          at Austin, August 2002.  URL\n              \"http://www.cs.utexas.edu/users/gorinsky/pubs.html\"\
    .\n   [HSTCP]    HighSpeed TCP Web Page, URL\n              \"http://www.icir.org/floyd/hstcp.html\"\
    .\n   [J02]      Amit Jain and Sally Floyd, \"Quick-Start for TCP and IP\",\n\
    \              Work in Progress, 2002.\n   [JWL03]    Cheng Jin, David X. Wei\
    \ and Steven H. Low, \"FAST TCP for\n              High-speed Long-distance Networks\"\
    , Work in Progress, June\n              2003.\n   [K03]      Tom Kelly, \"Scalable\
    \ TCP: Improving Performance in\n              HighSpeed Wide Area Networks\"\
    , February 2003.  URL\n              \"http://www-lce.eng.cam.ac.uk/~ctk21/scalable/\"\
    .\n   [KHR02]    Dina Katabi, Mark Handley, and Charlie Rohrs, \"Congestion\n\
    \              Control for High Bandwidth-Delay Product Networks\",\n        \
    \      SIGCOMM 2002.\n   [M02]      Matt Mathis, \"Raising the Internet MTU\"\
    , Web Page, URL\n              \"http://www.psc.edu/~mathis/MTU/\".\n   [Net100]\
    \   The DOE/MICS Net100 project.  URL\n              \"http://www.csm.ornl.gov/~dunigan/net100/\"\
    .\n   [NS]       The NS Simulator, \"http://www.isi.edu/nsnam/ns/\".\n   [RFC\
    \ 1323] Jacobson, V., Braden, R. and D. Borman, \"TCP Extensions\n           \
    \   for High Performance\", RFC 1323, May 1992.\n   [RFC3390]  Allman, M., Floyd,\
    \ S. and C., Partridge, \"Increasing TCP's\n              Initial Window\", RFC\
    \ 3390, October 2002.\n   [RFC3448]  Handley, M., Padhye, J., Floyd, S. and J.\
    \ Widmer, \"TCP\n              Friendly Rate Control (TFRC): Protocol Specification\"\
    , RFC\n              3448, January 2003.\n   [SA03]     Souza, E. and D.A., Agarwal,\
    \ \"A HighSpeed TCP Study:\n              Characteristics and Deployment Issues\"\
    , LBNL Technical\n              Report LBNL-53215.  URL\n              \"http://www.icir.org/floyd/hstcp.html\"\
    .\n   [S02]      Stanislav Shalunov, \"TCP Armonk\", Work in Progress, 2002,\n\
    \              URL \"http://www.internet2.edu/~shalunov/tcpar/\".\n   [S03]  \
    \    Alex Solan, private communication, 2003.\n   [VMSS]     \"Web100 at ORNL\"\
    , Web Page,\n              \"http://www.csm.ornl.gov/~dunigan/netperf/web100.html\"\
    .\n   [Web100]   The Web100 project.  URL \"http://www.web100.org/\".\n"
- title: 18.  Security Considerations
  contents:
  - "18.  Security Considerations\n   This proposal makes no changes to the underlying\
    \ security of TCP.\n"
- title: 19.  IANA Considerations
  contents:
  - "19.  IANA Considerations\n   There are no IANA considerations regarding this\
    \ document.\n"
- title: A.  TCP's Loss Event Rate in Steady-State
  contents:
  - "A.  TCP's Loss Event Rate in Steady-State\n   This section gives the number of\
    \ round-trip times between congestion\n   events for a TCP flow with D-byte packets,\
    \ for D=1500, as a function\n   of the connection's average throughput B in bps.\
    \  To achieve this\n   average throughput B, a TCP connection with round-trip\
    \ time R in\n   seconds requires an average congestion window w of BR/(8D) segments.\n\
    \   In steady-state, TCP's average congestion window w is roughly\n   1.2/sqrt(p)\
    \ segments.  This is equivalent to a lost event at most\n   once every 1/p packets,\
    \ or at most once every 1/(pw) = w/1.5 round-\n   trip times.  Substituting for\
    \ w, this is a loss event at most every\n   (BR)/12D)round-trip times.\n   An\
    \ an example, for R = 0.1 seconds and D = 1500 bytes, this gives\n   B/180000\
    \ round-trip times between loss events.\n"
- title: B.  A table for a(w) and b(w).
  contents:
  - "B.  A table for a(w) and b(w).\n   This section gives a table for the increase\
    \ and decrease parameters\n   a(w) and b(w) for HighSpeed TCP, for the default\
    \ values of Low_Window\n   = 38, High_Window = 83000, High_P = 10^-7, and High_Decrease\
    \ = 0.1.\n        w  a(w)  b(w)\n     ----  ----  ----\n       38     1  0.50\n\
    \      118     2  0.44\n      221     3  0.41\n      347     4  0.38\n      495\
    \     5  0.37\n      663     6  0.35\n      851     7  0.34\n     1058     8 \
    \ 0.33\n     1284     9  0.32\n     1529    10  0.31\n     1793    11  0.30\n\
    \     2076    12  0.29\n     2378    13  0.28\n     2699    14  0.28\n     3039\
    \    15  0.27\n     3399    16  0.27\n     3778    17  0.26\n     4177    18 \
    \ 0.26\n     4596    19  0.25\n     5036    20  0.25\n     5497    21  0.24\n\
    \     5979    22  0.24\n     6483    23  0.23\n     7009    24  0.23\n     7558\
    \    25  0.22\n     8130    26  0.22\n     8726    27  0.22\n     9346    28 \
    \ 0.21\n     9991    29  0.21\n    10661    30  0.21\n    11358    31  0.20\n\
    \    12082    32  0.20\n    12834    33  0.20\n    13614    34  0.19\n    14424\
    \    35  0.19\n    15265    36  0.19\n    16137    37  0.19\n    17042    38 \
    \ 0.18\n    17981    39  0.18\n    18955    40  0.18\n    19965    41  0.17\n\
    \    21013    42  0.17\n    22101    43  0.17\n    23230    44  0.17\n    24402\
    \    45  0.16\n    25618    46  0.16\n    26881    47  0.16\n    28193    48 \
    \ 0.16\n    29557    49  0.15\n    30975    50  0.15\n    32450    51  0.15\n\
    \    33986    52  0.15\n    35586    53  0.14\n    37253    54  0.14\n    38992\
    \    55  0.14\n    40808    56  0.14\n    42707    57  0.13\n    44694    58 \
    \ 0.13\n    46776    59  0.13\n    48961    60  0.13\n    51258    61  0.13\n\
    \    53677    62  0.12\n    56230    63  0.12\n    58932    64  0.12\n    61799\
    \    65  0.12\n    64851    66  0.11\n    68113    67  0.11\n    71617    68 \
    \ 0.11\n    75401    69  0.10\n    79517    70  0.10\n    84035    71  0.10\n\
    \    89053    72  0.10\n    94717    73  0.09\n   Table 12: Parameters for HighSpeed\
    \ TCP.\n   This table was computed with the following Perl program:\n    $top\
    \ = 100000;\n    $num = 38;\n    if ($num == 38) {\n      print \"     w  a(w)\
    \  b(w)\\n\";\n      print \"  ----  ----  ----\\n\";\n      print \"    38  \
    \   1  0.50\\n\";\n      $oldb = 0.50;\n      $olda = 1;\n    }\n    while ($num\
    \ < $top) {\n      $bw = (0.1 -0.5)*(log($num)-log(38))/(log(83000)-log(38))+0.5;\n\
    \      $aw = ($num**2*2.0*$bw) / ((2.0-$bw)*$num**1.2*12.8);\n      if ($aw >\
    \ $olda + 1) {\n         printf \"%6d %5d  %3.2f0, $num, $aw, $bw;\n         $olda\
    \ = $aw;\n      }\n      $num ++;\n    }\n   Table 13: Perl Program for computing\
    \ parameters for HighSpeed TCP.\n"
- title: C.  Exploring the time to converge to fairness.
  contents:
  - "C.  Exploring the time to converge to fairness.\n   This section gives the Perl\
    \ program used to compute the congestion\n   window growth during congestion avoidance.\n\
    \    $top = 2001;\n    $hswin = 1;\n    $regwin = 1;\n    $rtt = 1;\n    $lastrtt\
    \ = 0;\n    $rttstep = 100;\n    if ($hswin == 1) {\n      print \"  RTT  HS_Window\
    \ Standard_TCP_Window0;\n      print \"  ---  --------- -------------------0;\n\
    \    }\n    while ($rtt < $top) {\n      $bw = (0.1 -0.5)*(log($hswin)-log(38))/(log(83000)-log(38))+0.5;\n\
    \      $aw = ($hswin**2*2.0*$bw) / ((2.0-$bw)*$hswin**1.2*12.8);\n      if ($aw\
    \ < 1) {\n          $aw = 1;\n      }\n      if ($rtt >= $lastrtt + $rttstep)\
    \ {\n        printf \"%5d %9d %10d0, $rtt, $hswin, $regwin;\n        $lastrtt\
    \ = $rtt;\n      }\n      $hswin += $aw;\n      $regwin += 1;\n      $rtt ++;\n\
    \    }\n   Table 14: Perl Program for computing the window in congestion\n   avoidance.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Sally Floyd\n   ICIR (ICSI Center for Internet Research)\n\
    \   Phone: +1 (510) 666-2989\n   EMail: floyd@acm.org\n   URL: http://www.icir.org/floyd/\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2003).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assignees.\n\
    \   This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
