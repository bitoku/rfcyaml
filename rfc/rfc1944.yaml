- title: __initial_text__
  contents:
  - '       Benchmarking Methodology for Network Interconnect Devices

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  This memo\n   does not specify an Internet standard of any kind.  Distribution\
    \ of\n   this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document discusses and defines a number of tests that may be\n\
    \   used to describe the performance characteristics of a network\n   interconnecting\
    \  device.  In addition to defining the tests this\n   document also describes\
    \ specific formats for reporting the results of\n   the tests.  Appendix A lists\
    \ the tests and conditions that we believe\n   should be included for specific\
    \ cases and gives additional\n   information about testing practices.  Appendix\
    \ B is a reference\n   listing of maximum frame rates to be used with specific\
    \ frame sizes\n   on various media and Appendix C gives some examples of frame\
    \ formats\n   to be used in testing.\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   Vendors often engage in \"specsmanship\" in an attempt to\
    \ give their\n   products a better position in the marketplace.  This often involves\n\
    \   \"smoke & mirrors\" to confuse the potential users of the products.\n   This\
    \ document defines a specific set of tests that vendors can use to\n   measure\
    \ and report the performance characteristics of network\n   devices.  The results\
    \ of these tests will provide the user comparable\n   data from different vendors\
    \ with which to evaluate these devices.\n   A previous document, \"Benchmarking\
    \ Terminology for Network\n   Interconnect Devices\" (RFC 1242), defined many\
    \ of the terms that are\n   used in this document.  The terminology document should\
    \ be consulted\n   before attempting to make use of this document.\n"
- title: 2. Real world
  contents:
  - "2. Real world\n   In producing this document the authors attempted to keep in\
    \ mind the\n   requirement that apparatus to perform the described tests must\n\
    \   actually be built.  We do not know of \"off the shelf\" equipment\n   available\
    \ to implement all of the tests but it is our opinion that\n   such equipment\
    \ can be constructed.\n"
- title: 3. Tests to be run
  contents:
  - "3. Tests to be run\n   There are a number of tests described in this document.\
    \  Not all of\n   the tests apply to all types of devices under test (DUTs). Vendors\n\
    \   should perform all of the tests that can be supported by a specific\n   type\
    \ of product.  The authors understand that it will take a\n   considerable period\
    \ of time to perform all of the recommended tests\n   nder  all of the recommended\
    \ conditions. We believe that the results\n   are worth the effort.  Appendix\
    \ A lists some of the tests and\n   conditions that we believe should be included\
    \ for specific cases.\n"
- title: 4. Evaluating the results
  contents:
  - "4. Evaluating the results\n   Performing all of the recommended tests will result\
    \ in a great deal\n   of data. Much of this data will not apply to the evaluation\
    \ of the\n   devices under each circumstance.  For example, the rate at which\
    \ a\n   router forwards IPX frames will be of little use in selecting a\n   router\
    \ for an environment that does not (and will not) support that\n   protocol. \
    \ Evaluating even that data which is relevant to a\n   particular network installation\
    \ will require experience which may not\n   be readily available. Furthermore,\
    \ selection of the tests to be run\n   and evaluation of the test data must be\
    \ done with an understanding of\n   generally accepted testing practices regarding\
    \ repeatability,\n   variance and statistical significance of small numbers of\
    \ trials.\n"
- title: 5. Requirements
  contents:
  - "5. Requirements\n   In this document, the words that are used to define the significance\n\
    \   of each particular requirement are capitalized. These words are:\n    * \"\
    MUST\" This word, or the words \"REQUIRED\" and \"SHALL\" mean that\n   the item\
    \ is an absolute requirement of the specification.\n    * \"SHOULD\" This word\
    \ or the adjective \"RECOMMENDED\" means that there\n   may exist valid reasons\
    \ in particular circumstances to ignore this\n   item, but the full implications\
    \ should be understood and the case\n   carefully weighed before choosing a different\
    \ course.\n    * \"MAY\" This word or the adjective \"OPTIONAL\" means that this\
    \ item\n   is truly optional.  One vendor may choose to include the item because\n\
    \   a particular marketplace requires it or because it enhances the\n   product,\
    \ for example; another vendor may omit the same item.\n   An implementation is\
    \ not compliant if it fails to satisfy one or more\n   of the MUST requirements\
    \ for the protocols it implements.  An\n   implementation that satisfies all the\
    \ MUST and all the SHOULD\n   requirements for its protocols is said to be \"\
    unconditionally\n   compliant\"; one that satisfies all the MUST requirements\
    \ but not all\n   the SHOULD requirements for its protocols is said to be\n  \
    \ \"conditionally compliant\".\n"
- title: 6. Test set up
  contents:
  - "6. Test set up\n   The ideal way to implement this series of tests is to use\
    \ a tester\n   with both transmitting and receiving ports.  Connections are made\n\
    \   from the sending ports of the tester to the receiving ports of the\n   DUT\
    \ and from the sending ports of the DUT back to the tester. (see\n   Figure 1)\
    \  Since the tester both sends the test traffic and receives\n   it back, after\
    \ the traffic has been forwarded but the DUT, the tester\n   can easily determine\
    \ if all of the transmitted packets were received\n   and verify that the correct\
    \ packets were received.  The same\n   functionality can be obtained with separate\
    \ transmitting and\n   receiving devices (see Figure 2) but unless they are remotely\n\
    \   controlled by some computer in a way that simulates the single\n   tester,\
    \ the labor required to accurately perform some of the tests\n   (particularly\
    \ the throughput test) can be prohibitive.\n                            +------------+\n\
    \                            |            |\n               +------------|  tester\
    \    |<-------------+\n               |            |            |            \
    \  |\n               |            +------------+              |\n            \
    \   |                                        |\n               |            +------------+\
    \              |\n               |            |            |              |\n\
    \               +----------->|    DUT     |--------------+\n                 \
    \           |            |\n                            +------------+\n     \
    \                         Figure 1\n         +--------+         +------------+\
    \          +----------+\n         |        |         |            |          |\
    \          |\n         | sender |-------->|    DUT     |--------->| receiver |\n\
    \         |        |         |            |          |          |\n         +--------+\
    \         +------------+          +----------+\n                             \
    \ Figure 2\n"
- title: 6.1 Test set up for multiple media types
  contents:
  - "6.1 Test set up for multiple media types\n   Two different setups could be used\
    \ to test a DUT which is used in\n   real-world networks to connect networks of\
    \ differing media type,\n   local Ethernet to a backbone FDDI ring for example.\
    \  The tester could\n   support both media types in which case the set up shown\
    \ in Figure 1\n   would be used.\n   Two identical DUTs are used in the other\
    \ test set up. (see Figure 3)\n   In many cases this set up may more accurately\
    \ simulate the real\n   world.  For example, connecting two LANs together with\
    \ a WAN link or\n   high speed backbone.  This set up would not be as good at\
    \ simulating\n   a system where clients on a Ethernet LAN were interacting with\
    \ a\n   server on an FDDI backbone.\n                               +-----------+\n\
    \                               |           |\n         +---------------------|\
    \  tester   |<---------------------+\n         |                     |       \
    \    |                      |\n         |                     +-----------+  \
    \                    |\n         |                                           \
    \             |\n         |        +----------+               +----------+   \
    \      |\n         |        |          |               |          |         |\n\
    \         +------->|  DUT 1   |-------------->|   DUT 2  |---------+\n       \
    \           |          |               |          |\n                  +----------+\
    \               +----------+\n                                  Figure 3\n"
- title: 7. DUT set up
  contents:
  - "7. DUT set up\n   Before starting to perform the tests, the DUT to be tested\
    \ MUST be\n   configured following the instructions provided to the user.\n  \
    \ Specifically, it is expected that all of the supported protocols will\n   be\
    \ configured and enabled during this set up (See Appendix A).  It is\n   expected\
    \ that all of the tests will be run without changing the\n   configuration or\
    \ setup of the DUT in any way other than that required\n   to do the specific\
    \ test.  For example, it is not acceptable to change\n   the size of frame handling\
    \ buffers between tests of frame handling\n   rates or to disable all but one\
    \ transport protocol when testing the\n   throughput of that protocol.  It is\
    \ necessary to modify the\n   configuration when starting a test to determine\
    \ the effect of filters\n   on throughput, but the only change MUST be to enable\
    \ the specific\n   filter. The DUT set up SHOULD include the normally recommended\n\
    \   routing update intervals and keep alive frequency.  The specific\n   version\
    \ of the software and the exact DUT configuration, including\n   what functions\
    \ are disabled, used during the tests MUST be included\n   as part of the report\
    \ of the results.\n"
- title: 8. Frame formats
  contents:
  - "8. Frame formats\n   The formats of the test frames to use for TCP/IP over Ethernet\
    \ are\n   shown in Appendix C: Test Frame Formats.  These exact frame formats\n\
    \   SHOULD be used in the tests described in this document for this\n   protocol/media\
    \ combination and that these frames will be used as a\n   template for testing\
    \ other protocol/media combinations.  The specific\n   formats that are used to\
    \ define the test frames for a particular test\n   series MUST be included in\
    \ the report of the results.\n"
- title: 9. Frame sizes
  contents:
  - "9. Frame sizes\n   All of the described tests SHOULD be performed at a number\
    \ of frame\n   sizes. Specifically, the sizes SHOULD include the maximum and minimum\n\
    \   legitimate sizes for the protocol under test on the media under test\n   and\
    \ enough sizes in between to be able to get a full characterization\n   of the\
    \ DUT performance.  Except where noted, at least five frame\n   sizes SHOULD be\
    \ tested for each test condition.\n   Theoretically the minimum size UDP Echo\
    \ request frame would consist\n   of an IP header (minimum length 20 octets),\
    \ a UDP header (8 octets)\n   and whatever MAC level header is required by the\
    \ media in use.  The\n   theoretical maximum frame size is determined by the size\
    \ of the\n   length field in the IP header.  In almost all cases the actual\n\
    \   maximum and minimum sizes are determined by the limitations of the\n   media.\n\
    \   In theory it would be ideal to distribute the frame sizes in a way\n   that\
    \ would evenly distribute the theoretical frame rates.  These\n   recommendations\
    \ incorporate this theory but specify frame sizes which\n   are easy to understand\
    \ and remember.  In addition, many of the same\n   frame sizes are specified on\
    \ each of the media types to allow for\n   easy performance comparisons.\n   Note:\
    \ The inclusion of an unrealistically small frame size on some of\n   the media\
    \ types (i.e. with little or no space for data) is to help\n   characterize the\
    \ per-frame processing overhead of the DUT.\n   9.1 Frame sizes to be used on\
    \ Ethernet\n       64, 128, 256, 512, 1024, 1280, 1518\n      These sizes include\
    \ the maximum and minimum frame sizes permitted\n      by the Ethernet standard\
    \ and a selection of sizes between these\n      extremes with a finer granularity\
    \ for the smaller frame sizes and\n      higher frame rates.\n   9.2 Frame sizes\
    \ to be used on 4Mb and 16Mb token ring\n       54, 64, 128, 256, 1024, 1518,\
    \ 2048, 4472\n      The frame size recommendations for token ring assume that\
    \ there is\n      no RIF field in the frames of routed protocols.  A RIF field\
    \ would\n      be present in any direct source route bridge performance test.\n\
    \      The minimum size frame for UDP on token ring is 54 octets.  The\n     \
    \ maximum size of 4472 octets is recommended for 16Mb token ring\n      instead\
    \ of the theoretical size of 17.9Kb because of the size\n      limitations imposed\
    \ by many token ring interfaces.  The reminder\n      of the sizes are selected\
    \ to permit direct comparisons with other\n      types of media.  An IP (i.e.\
    \ not UDP) frame may be used in\n      addition if a higher data rate is desired,\
    \ in which case the\n      minimum frame size is 46 octets.\n   9.3 Frame sizes\
    \ to be used on FDDI\n       54, 64, 128, 256, 1024, 1518, 2048, 4472\n      The\
    \ minimum size frame for UDP on FDDI is 53 octets, the minimum\n      size of\
    \ 54 is recommended to allow direct comparison to token ring\n      performance.\
    \  The maximum size of 4472 is recommended instead of\n      the theoretical maximum\
    \ size of 4500 octets to permit the same\n      type of comparison. An IP (i.e.\
    \ not UDP) frame may be used in\n      addition if a higher data rate is desired,\
    \ in which case the\n      minimum frame size is 45 octets.\n   9.4 Frame sizes\
    \ in the presence of disparate MTUs\n      When the interconnect DUT supports\
    \ connecting links with disparate\n      MTUs, the frame sizes for the link with\
    \ the *larger* MTU SHOULD be\n      used, up to the limit of the protocol being\
    \ tested. If the\n      interconnect DUT does not support the fragmenting of frames\
    \ in the\n      presence of MTU mismatch, the forwarding rate for that frame size\n\
    \      shall be reported as zero.\n      For example, the test of IP forwarding\
    \ with a bridge or router\n      that joins FDDI and Ethernet should use the frame\
    \ sizes of FDDI\n      when going from the FDDI to the Ethernet link. If the bridge\
    \ does\n      not support IP fragmentation, the forwarding rate for those frames\n\
    \      too large for Ethernet should be reported as zero.\n"
- title: 10. Verifying received frames
  contents:
  - "10. Verifying received frames\n   The test equipment SHOULD discard any frames\
    \ received during a test\n   run that are not actual forwarded test frames.  For\
    \ example, keep-\n   alive and routing update frames SHOULD NOT be included in\
    \ the count\n   of received frames.  In any case, the test equipment SHOULD verify\n\
    \   the length of the received frames and check that they match the\n   expected\
    \ length.\n   Preferably, the test equipment SHOULD include sequence numbers in\
    \ the\n   transmitted frames and check for these numbers on the received\n   frames.\
    \  If this is done, the reported results SHOULD include in\n   addition to the\
    \ number of frames dropped, the number of frames that\n   were received out of\
    \ order, the number of duplicate frames received\n   and the number of gaps in\
    \ the received frame numbering sequence.\n   This functionality is required for\
    \ some of the described tests.\n"
- title: 11. Modifiers
  contents:
  - "11. Modifiers\n   It might be useful to know the DUT performance under a number\
    \ of\n   conditions; some of these conditions are noted below.  The reported\n\
    \   results SHOULD include as many of these conditions as the test\n   equipment\
    \ is able to generate.  The suite of tests SHOULD be first\n   run without any\
    \ modifying conditions and then repeated under each of\n   the conditions separately.\
    \  To preserve the ability to compare the\n   results of these tests any frames\
    \ that are required to generate the\n   modifying conditions (management queries\
    \ for example) will be\n   included in the same data stream as the normal test\
    \ frames in place\n   of one of the test frames and not be supplied to the DUT\
    \ on a\n   separate network port.\n   11.1 Broadcast frames\n      In most router\
    \ designs special processing is required when frames\n      addressed to the hardware\
    \ broadcast address are received.  In\n      bridges (or in bridge mode on routers)\
    \ these broadcast frames must\n      be flooded to a number of ports.  The stream\
    \ of test frames SHOULD\n      be augmented with 1% frames addressed to the hardware\
    \ broadcast\n      address.  The frames sent to the broadcast address should be\
    \ of a\n      type that the router will not need to process.  The aim of this\n\
    \      test is to determine if there is any effect on the forwarding rate\n  \
    \    of the other data in the stream.  The specific frames that should\n     \
    \ be used are included in the test frame format document. The\n      broadcast\
    \ frames SHOULD be evenly distributed throughout the data\n      stream, for example,\
    \ every 100th frame.\n      The same test SHOULD be performed on bridge-like DUTs\
    \ but in this\n      case the broadcast packets will be processed and flooded\
    \ to all\n      outputs.\n      It is understood that a level of broadcast frames\
    \ of 1% is much\n      higher than many networks experience but, as in drug toxicity\n\
    \      evaluations, the higher level is required to be able to gage the\n    \
    \  effect which would otherwise often fall within the normal\n      variability\
    \ of the system performance.  Due to design factors some\n      test equipment\
    \ will not be able to generate a level of alternate\n      frames this low.  In\
    \ these cases the percentage SHOULD be as small\n      as the equipment can provide\
    \ and that the actual level be\n      described in the report of the test results.\n\
    \   11.2 Management frames\n      Most data networks now make use of management\
    \ protocols such as\n      SNMP.  In many environments there can be a number of\
    \ management\n      stations sending queries to the same DUT at the same time.\n\
    \      The stream of test frames SHOULD be augmented with one management\n   \
    \   query as the first frame sent each second during the duration of\n      the\
    \ trial.  The result of the query must fit into one response\n      frame. The\
    \ response frame SHOULD be verified by the test\n      equipment. One example\
    \ of the specific query frame that should be\n      used is shown in Appendix\
    \ C.\n   11.3 Routing update frames\n      The processing of dynamic routing protocol\
    \ updates could have a\n      significant impact on the ability of a router to\
    \ forward data\n      frames.  The stream of test frames SHOULD be augmented with\
    \ one\n      routing update frame transmitted as the first frame transmitted\n\
    \      during the trial.  Routing update frames SHOULD be sent at the\n      rate\
    \ specified in Appendix C for the specific routing protocol\n      being used\
    \ in the test. Two routing update frames are defined in\n      Appendix C for\
    \ the TCP/IP over Ethernet example.  The routing\n      frames are designed to\
    \ change the routing to a number of networks\n      that are not involved in the\
    \ forwarding of the test data.  The\n      first frame sets the routing table\
    \ state to \"A\", the second one\n      changes the state to \"B\".  The frames\
    \ MUST be alternated during\n      the trial.\n      The test SHOULD verify that\
    \ the routing update was processed by\n      the DUT.\n   11.4 Filters\n     \
    \ Filters are added to routers and bridges to selectively inhibit\n      the forwarding\
    \ of frames that would normally be forwarded.  This\n      is usually done to\
    \ implement security controls on the data that is\n      accepted between one\
    \ area and another. Different products have\n      different capabilities to implement\
    \ filters.\n      The DUT SHOULD be first configured to add one filter condition\
    \ and\n      the tests performed.  This filter SHOULD permit the forwarding of\n\
    \      the test data stream. In routers this filter SHOULD be of the\n      form:\n\
    \       forward input_protocol_address to output_protocol_address\n      In bridges\
    \ the filter SHOULD be of the form:\n       forward destination_hardware_address\n\
    \      The DUT SHOULD be then reconfigured to implement a total of 25\n      filters.\
    \  The first 24 of these filters SHOULD be of the form:\n       block input_protocol_address\
    \ to output_protocol_address\n      The 24 input and output protocol addresses\
    \ SHOULD not be any that\n      are represented in the test data stream.  The\
    \ last filter SHOULD\n      permit the forwarding of the test data stream.  By\
    \ \"first\" and\n      \"last\" we mean to ensure that in the second case, 25\
    \ conditions\n      must be checked before the data frames will match the conditions\n\
    \      that permit the forwarding of the frame. Of course, if the DUT\n      reorders\
    \ the filters or does not use a linear scan of the filter\n      rules the effect\
    \ of the sequence in which the filters are input is\n      properly lost.\n  \
    \    The exact filters configuration command lines used SHOULD be\n      included\
    \ with the report of the results.\n      11.4.1 Filter Addresses\n         Two\
    \ sets of filter addresses are required, one for the single\n         filter case\
    \ and one for the 25 filter case.\n         The single filter case should permit\
    \ traffic from IP address\n         198.18.1.2 to IP address 198.19.65.2 and deny\
    \ all other\n         traffic.\n         The 25 filter case should follow the\
    \ following sequence.\n          deny aa.ba.1.1 to aa.ba.100.1\n          deny\
    \ aa.ba.2.2 to aa.ba.101.2\n          deny aa.ba.3.3 to aa.ba.103.3\n        \
    \    ...\n          deny aa.ba.12.12 to aa.ba.112.12\n          allow aa.bc.1.2\
    \ to aa.bc.65.1\n          deny aa.ba.13.13 to aa.ba.113.13\n          deny aa.ba.14.14\
    \ to aa.ba.114.14\n            ...\n          deny aa.ba.24.24 to aa.ba.124.24\n\
    \          deny all else\n         All previous filter conditions should be cleared\
    \ from the\n         router before this sequence is entered.  The sequence is\n\
    \         selected to test to see if the router sorts the filter\n         conditions\
    \ or accepts them in the order that they were entered.\n         Both of these\
    \ procedures will result in a greater impact on\n         performance than will\
    \ some form of hash coding.\n"
- title: 12. Protocol addresses
  contents:
  - "12. Protocol addresses\n   It is easier to implement these tests using a single\
    \ logical stream\n   of  data, with one source protocol address and one destination\n\
    \   protocol address, and for some conditions like the filters described\n   above,\
    \ a practical requirement. Networks in the real world are not\n   limited to single\
    \ streams of data. The test suite SHOULD be first run\n   with a single protocol\
    \ (or hardware for bridge tests) source and\n   destination address pair.  The\
    \ tests SHOULD then be repeated with\n   using a random destination address. \
    \ While testing routers the\n   addresses SHOULD be random and uniformly distributed\
    \ over a range of\n   256 networks and random and uniformly distributed over the\
    \ full MAC\n   range for bridges.  The specific address ranges to use for IP are\n\
    \   shown in Appendix C.\n"
- title: 13. Route Set Up
  contents:
  - "13. Route Set Up\n   It is not reasonable that all of the routing information\
    \ necessary to\n   forward the test stream, especially in the multiple address\
    \ case,\n   will be manually set up.  At the start of each trial a routing update\n\
    \   MUST be sent to the DUT. This routing update MUST include all of the\n   network\
    \ addresses that will be required for the trial.  All of the\n   addresses SHOULD\
    \ resolve to the same \"next-hop\". Normally this will\n   be the address of the\
    \ receiving side of the test equipment. This\n   routing update will have to be\
    \ repeated at the interval required by\n   the routing protocol being used.  An\
    \ example of the format and\n   repetition interval of the update frames is given\
    \ in Appendix C.\n"
- title: 14. Bidirectional traffic
  contents:
  - "14. Bidirectional traffic\n   Normal network activity is not all in a single\
    \ direction.  To test\n   the bidirectional performance of a DUT, the test series\
    \ SHOULD be run\n   with the same data rate being offered from each direction.\
    \ The sum of\n   the data rates should not exceed the theoretical limit for the\
    \ media.\n"
- title: 15. Single stream path
  contents:
  - "15. Single stream path\n   The full suite of tests SHOULD be run along with whatever\
    \ modifier\n   conditions that are relevant using a single input and output network\n\
    \   port on the DUT. If the internal design of the DUT has multiple\n   distinct\
    \ pathways, for example, multiple interface cards each with\n   multiple network\
    \ ports, then all possible types of pathways SHOULD be\n   tested separately.\n"
- title: 16. Multi-port
  contents:
  - "16. Multi-port\n   Many current router and bridge products provide many network\
    \ ports in\n   the same module. In performing these tests first half of the ports\n\
    \   are designated as \"input ports\" and half are designated as \"output\n  \
    \ ports\".  These ports SHOULD be evenly distributed across the DUT\n   architecture.\
    \ For example if a DUT has two interface cards each of\n   which has four ports,\
    \ two ports on each interface card are designated\n   as input and two are designated\
    \ as output.  The specified tests are\n   run using the same data rate being offered\
    \ to each of the input\n   ports.  The addresses in the input data streams SHOULD\
    \ be set so that\n   a frame will be directed to each of the output ports in sequence\
    \ so\n   that all \"output\" ports will get an even distribution of packets from\n\
    \   this input.  The same configuration MAY be used to perform a\n   bidirectional\
    \ multi-stream test.  In this case all of the ports are\n   considered both input\
    \ and output ports and each data stream MUST\n   consist of frames addressed to\
    \ all of the other ports.\n   Consider the following 6 port DUT:\n           \
    \                   --------------\n                     ---------| in A  out\
    \ X|--------\n                     ---------| in B  out Y|--------\n         \
    \            ---------| in C  out Z|--------\n                              --------------\n\
    \   The addressing of the data streams for each of the inputs SHOULD be:\n   \
    \ stream sent to input A:\n      packet to out X, packet to out Y, packet to out\
    \ Z\n    stream sent to input B:\n      packet to out X, packet to out Y, packet\
    \ to out Z\n    stream sent to input C\n      packet to out X, packet to out Y,\
    \ packet to out Z\n   Note that these streams each follow the same sequence so\
    \ that 3\n   packets will arrive at output X at the same time, then 3 packets\
    \ at\n   Y, then 3 packets at Z. This procedure ensures that, as in the real\n\
    \   world, the DUT will have to deal with multiple packets addressed to\n   the\
    \ same output at the same time.\n"
- title: 17. Multiple protocols
  contents:
  - "17. Multiple protocols\n   This document does not address the issue of testing\
    \ the effects of a\n   mixed protocol environment other than to suggest that if\
    \ such tests\n   are wanted then frames SHOULD be distributed between all of the\
    \ test\n   protocols.  The distribution MAY approximate the conditions on the\n\
    \   network in which the DUT would be used.\n"
- title: 18. Multiple frame sizes
  contents:
  - "18. Multiple frame sizes\n   This document does not address the issue of testing\
    \ the effects of a\n   mixed frame size environment other than to suggest that\
    \ if such tests\n   are wanted then frames SHOULD be distributed between all of\
    \ the\n   listed sizes for the protocol under test.  The distribution MAY\n  \
    \ approximate the conditions on the network in which the DUT would be\n   used.\
    \ The authors do not have any idea how the results of such a test\n   would be\
    \ interpreted other than to directly compare multiple DUTs in\n   some very specific\
    \ simulated network.\n"
- title: 19. Testing performance beyond a single DUT.
  contents:
  - "19. Testing performance beyond a single DUT.\n   In the performance testing of\
    \ a single DUT, the paradigm can be\n   described as applying some input to a\
    \ DUT and monitoring the output.\n   The results of which can be used to form\
    \ a basis of characterization\n   of that device under those test conditions.\n\
    \   This model is useful when the test input and output are homogenous\n   (e.g.,\
    \ 64-byte IP, 802.3 frames into the DUT; 64 byte IP, 802.3\n   frames out), or\
    \ the method of test can distinguish between dissimilar\n   input/output. (E.g.,\
    \ 1518 byte IP, 802.3 frames in; 576 byte,\n   fragmented IP, X.25 frames out.)\n\
    \   By extending the single DUT test model, reasonable benchmarks\n   regarding\
    \ multiple DUTs or heterogeneous environments may be\n   collected. In this extension,\
    \ the single DUT is replaced by a system\n   of interconnected network DUTs. This\
    \ test methodology would support\n   the benchmarking of a variety of device/media/service/protocol\n\
    \   combinations. For example, a configuration for a LAN-to-WAN-to-LAN\n   test\
    \ might be:\n   (1) 802.3-> DUT 1 -> X.25 @ 64kbps -> DUT 2 -> 802.3\n   Or a\
    \ mixed LAN configuration might be:\n   (2) 802.3 -> DUT 1 -> FDDI -> DUT 2 ->\
    \ FDDI -> DUT 3 -> 802.3\n   In both examples 1 and 2, end-to-end benchmarks of\
    \ each system could\n   be empirically ascertained. Other behavior may be characterized\n\
    \   through the use of intermediate devices. In example 2, the\n   configuration\
    \ may be used to give an indication of the FDDI to FDDI\n   capability exhibited\
    \ by DUT 2.\n   Because multiple DUTs are treated as a single system, there are\n\
    \   limitations to this methodology. For instance, this methodology may\n   yield\
    \ an aggregate benchmark for a tested system. That benchmark\n   alone, however,\
    \ may not necessarily reflect asymmetries in behavior\n   between the DUTs, latencies\
    \ introduce by other apparatus (e.g.,\n   CSUs/DSUs, switches), etc.\n   Further,\
    \ care must be used when comparing benchmarks of different\n   systems by ensuring\
    \ that the DUTs' features/configuration of the\n   tested systems have the appropriate\
    \ common denominators to allow\n   comparison.\n"
- title: 20. Maximum frame rate
  contents:
  - "20. Maximum frame rate\n   The maximum frame rates that should be used when testing\
    \ LAN\n   connections SHOULD be the listed theoretical maximum rate for the\n\
    \   frame size on the media.\n   The maximum frame rate that should be used when\
    \ testing WAN\n   connections SHOULD be greater than the listed theoretical maximum\n\
    \   rate for the frame size on that speed connection.  The higher rate\n   for\
    \ WAN tests is to compensate for the fact that some vendors employ\n   various\
    \ forms of header compression.\n   A list of maximum frame rates for LAN connections\
    \ is included in\n   Appendix B.\n"
- title: 21. Bursty traffic
  contents:
  - "21. Bursty traffic\n   It is convenient to measure the DUT performance under\
    \ steady state\n   load but this is an unrealistic way to gauge the functioning\
    \ of a DUT\n   since actual network traffic normally consists of bursts of frames.\n\
    \   Some of the tests described below SHOULD be performed with both\n   steady\
    \ state traffic and with traffic consisting of repeated bursts\n   of frames.\
    \  The frames within a burst are transmitted with the\n   minimum legitimate inter-frame\
    \ gap.\n   The objective of the test is to determine the minimum interval\n  \
    \ between bursts which the DUT can process with no frame loss. During\n   each\
    \ test the number of frames in each burst is held constant and the\n   inter-burst\
    \ interval varied.  Tests SHOULD be run with burst sizes of\n   16, 64, 256 and\
    \ 1024 frames.\n"
- title: 22. Frames per token
  contents:
  - "22. Frames per token\n   Although it is possible to configure some token ring\
    \ and FDDI\n   interfaces to transmit more than one frame each time that the token\n\
    \   is received, most of the network devices currently available transmit\n  \
    \ only one frame per token.  These tests SHOULD first be performed\n   while transmitting\
    \ only one frame per token.\n   Some current high-performance workstation servers\
    \ do transmit more\n   than one frame per token on FDDI to maximize throughput.\
    \  Since this\n   may be a common feature in future workstations and servers,\n\
    \   interconnect devices with FDDI interfaces SHOULD be tested with 1, 4,\n  \
    \ 8, and 16 frames per token.  The reported frame rate SHOULD be the\n   average\
    \ rate of frame transmission over the total trial period.\n"
- title: 23. Trial description
  contents:
  - "23. Trial description\n   A particular test consists of multiple trials.  Each\
    \ trial returns\n   one piece of information, for example the loss rate at a particular\n\
    \   input frame rate.  Each trial consists of a number of phases:\n    a) If the\
    \ DUT is a router, send the routing update to the \"input\"\n   port and pause\
    \ two seconds to be sure that the routing has settled.\n    b)  Send the \"learning\
    \ frames\" to the \"output\" port and wait 2\n   seconds to be sure that the learning\
    \ has settled.  Bridge learning\n   frames are frames with source addresses that\
    \ are the same as the\n   destination addresses used by the test frames.  Learning\
    \ frames for\n   other protocols are used to prime the address resolution tables\
    \ in\n   the DUT.  The formats of the learning frame that should be used are\n\
    \   shown in the Test Frame Formats document.\n    c) Run the test trial.\n  \
    \  d) Wait for two seconds for any residual frames to be received.\n    e) Wait\
    \ for at least five seconds for the DUT to restabilize.\n"
- title: 24. Trial duration
  contents:
  - "24. Trial duration\n   The aim of these tests is to determine the rate continuously\n\
    \   supportable by the DUT.  The actual duration of the test trials must\n   be\
    \ a compromise between this aim and the duration of the benchmarking\n   test\
    \ suite.  The duration of the test portion of each trial SHOULD be\n   at least\
    \ 60 seconds.  The tests that involve some form of \"binary\n   search\", for\
    \ example the throughput test, to determine the exact\n   result MAY use a shorter\
    \ trial duration to minimize the length of the\n   search procedure, but  the\
    \ final determination SHOULD be made with\n   full length trials.\n"
- title: 25. Address resolution
  contents:
  - "25. Address resolution\n   The DUT SHOULD be able to respond to address resolution\
    \ requests sent\n   by the DUT wherever the protocol requires such a process.\n"
- title: '26. Benchmarking tests:'
  contents:
  - "26. Benchmarking tests:\n   Note: The notation \"type of data stream\" refers\
    \ to the above\n   modifications to a frame stream with a constant inter-frame\
    \ gap, for\n   example, the addition of traffic filters to the configuration of\
    \ the\n   DUT.\n   26.1 Throughput\n      Objective:\n      To determine the DUT\
    \ throughput as defined in RFC 1242.\n      Procedure:\n      Send a specific\
    \ number of frames at a specific rate through the\n      DUT and then count the\
    \ frames that are transmitted by the DUT. If\n      the count of offered frames\
    \ is equal to the count of received\n      frames, the rate of the offered stream\
    \ is raised and the test\n      rerun.  If fewer frames are received than were\
    \ transmitted, the\n      rate of the offered stream is reduced and the test is\
    \ rerun.\n      The throughput is the fastest rate at which the count of test\n\
    \      frames transmitted by the DUT is equal to the number of test\n      frames\
    \ sent to it by the test equipment.\n      Reporting format:\n      The results\
    \ of the throughput test SHOULD be reported in the form\n      of a graph. If\
    \ it is, the x coordinate SHOULD be the frame size,\n      the y coordinate SHOULD\
    \ be the frame rate.  There SHOULD be at\n      least two lines on the graph.\
    \  There SHOULD be one line showing\n      the theoretical frame rate for the\
    \ media at the various frame\n      sizes.  The second line SHOULD be the plot\
    \ of the test results.\n      Additional lines MAY be used on the graph to report\
    \ the results\n      for each type of data stream tested.  Text accompanying the\
    \ graph\n      SHOULD indicate the protocol, data stream format, and type of\n\
    \      media used in the tests.\n      We assume that if a single value is desired\
    \ for advertising\n      purposes the vendor will select the rate for the minimum\
    \ frame\n      size for the media. If this is done then the figure MUST be\n \
    \     expressed in frames per second.  The rate MAY also be expressed in\n   \
    \   bits (or bytes) per second if the vendor so desires.  The\n      statement\
    \ of performance MUST include a/ the measured maximum\n      frame rate, b/ the\
    \ size of the frame used, c/ the theoretical\n      limit of the media for that\
    \ frame size, and d/ the type of\n      protocol used in the test.  Even if a\
    \ single value is used as part\n      of the advertising copy, the full table\
    \ of results SHOULD be\n      included in the product data sheet.\n   26.2 Latency\n\
    \      Objective:\n      To determine the latency as defined in RFC 1242.\n  \
    \    Procedure:\n      First determine the throughput for DUT at each of the listed\
    \ frame\n      sizes. Send a stream of frames at a particular frame size through\n\
    \      the DUT at the determined throughput rate to a specific\n      destination.\
    \  The stream SHOULD be at least 120 seconds in\n      duration.  An identifying\
    \ tag SHOULD be included in one frame\n      after 60 seconds with the type of\
    \ tag being implementation\n      dependent. The time at which this frame is fully\
    \ transmitted is\n      recorded (timestamp A).  The receiver logic in the test\
    \ equipment\n      MUST recognize the tag information in the frame stream and\
    \ record\n      the time at which the tagged frame was received (timestamp B).\n\
    \      The latency is timestamp B minus timestamp A as per the relevant\n    \
    \  definition frm RFC 1242, namely latency as defined for store and\n      forward\
    \ devices or latency as defined for bit forwarding devices.\n      The test MUST\
    \ be repeated at least 20 times with the reported\n      value being the average\
    \ of the recorded values.\n      This test SHOULD be performed with the test frame\
    \ addressed to the\n      same destination as the rest of the data stream and\
    \ also with each\n      of the test frames addressed to a new destination network.\n\
    \      Reporting format:\n      The report MUST state which definition of latency\
    \ (from RFC 1242)\n      was used for this test.  The latency results SHOULD be\
    \ reported\n      in the format of a table with a row for each of the tested frame\n\
    \      sizes.  There SHOULD be columns for the frame size, the rate at\n     \
    \ which the latency test was run for that frame size, for the media\n      types\
    \ tested, and for the resultant latency values for each\n      type of data stream\
    \ tested.\n   26.3 Frame loss rate\n      Objective:\n      To determine the frame\
    \ loss rate, as defined in RFC 1242, of a DUT\n      throughout the entire range\
    \ of input data rates and frame sizes.\n      Procedure:\n      Send a specific\
    \ number of frames at a specific rate through the\n      DUT to be tested and\
    \ count the frames that are transmitted by the\n      DUT.   The frame loss rate\
    \ at each point is calculated using the\n      following equation:\n       ( (\
    \ input_count - output_count ) * 100 ) / input_count\n      The first trial SHOULD\
    \ be run for the frame rate that corresponds\n      to 100% of the maximum rate\
    \ for the frame size on the input media.\n      Repeat the procedure for the rate\
    \ that corresponds to 90% of the\n      maximum rate used and then for 80% of\
    \ this rate.  This sequence\n      SHOULD be continued (at reducing 10% intervals)\
    \ until there are\n      two successive trials in which no frames are lost. The\
    \ maximum\n      granularity of the trials MUST be 10% of the maximum rate, a\
    \ finer\n      granularity is encouraged.\n      Reporting format:\n      The\
    \ results of the frame loss rate test SHOULD be plotted as a\n      graph.  If\
    \ this is done then the X axis MUST be the input frame\n      rate as a percent\
    \ of the theoretical rate for the media at the\n      specific frame size. The\
    \ Y axis MUST be the percent loss at the\n      particular input rate.  The left\
    \ end of the X axis and the bottom\n      of the Y axis MUST be 0 percent; the\
    \ right end of the X axis and\n      the top of the Y axis MUST be 100 percent.\
    \  Multiple lines on the\n      graph MAY used to report the frame loss rate for\
    \ different frame\n      sizes, protocols, and types of data streams.\n      Note:\
    \ See section 18 for the maximum frame rates that SHOULD be\n      used.\n   26.4\
    \ Back-to-back frames\n      Objective:\n      To characterize the ability of\
    \ a DUT to process back-to-back\n      frames as defined in RFC 1242.\n      Procedure:\n\
    \      Send a burst of frames with minimum inter-frame gaps to the DUT\n     \
    \ and count the number of frames forwarded by the DUT.  If the count\n      of\
    \ transmitted frames is equal to the number of frames forwarded\n      the length\
    \ of the burst is increased and the test is rerun.  If\n      the number of forwarded\
    \ frames is less than the number\n      transmitted, the length of the burst is\
    \ reduced and the test is\n      rerun.\n      The back-to-back value is the number\
    \ of frames in the longest\n      burst that the DUT will handle without the loss\
    \ of any frames.\n      The trial length MUST be at least 2 seconds and SHOULD\
    \ be\n      repeated at least 50 times with the average of the recorded values\n\
    \      being reported.\n      Reporting format:\n      The back-to-back results\
    \ SHOULD be reported in the format of a\n      table with a row for each of the\
    \ tested frame sizes.  There SHOULD\n      be columns for the frame size and for\
    \ the resultant average frame\n      count for each type of data stream tested.\
    \  The standard deviation\n      for each measurement MAY also be reported.\n\
    \   26.5 System recovery\n      Objective:\n      To characterize the speed at\
    \ which a DUT recovers from an overload\n      condition.\n      Procedure:\n\
    \      First determine the throughput for a DUT at each of the listed\n      frame\
    \ sizes.\n      Send a stream of frames at a rate 110% of the recorded throughput\n\
    \      rate or the maximum rate for the media, whichever is lower, for at\n  \
    \    least 60 seconds.  At Timestamp A reduce the frame rate to 50% of\n     \
    \ the above rate and record the time of the last frame lost\n      (Timestamp\
    \ B). The system recovery time is determined by\n      subtracting Timestamp B\
    \ from Timestamp A.  The test SHOULD be\n      repeated a number of times and\
    \ the average of the recorded values\n      being reported.\n      Reporting format:\n\
    \      The system recovery results SHOULD be reported in the format of a\n   \
    \   table with a row for each of the tested frame sizes.  There SHOULD\n     \
    \ be columns for the frame size, the frame rate used as the\n      throughput\
    \ rate for each type of data stream tested, and for the\n      measured recovery\
    \ time for each type of data stream tested.\n   26.6 Reset\n      Objective:\n\
    \      To characterize the speed at which a DUT recovers from a device or\n  \
    \    software reset.\n      Procedure:\n      First determine the throughput for\
    \ the DUT for the minimum frame\n      size on the media used in the testing.\n\
    \      Send a continuous stream of frames at the determined throughput\n     \
    \ rate for the minimum sized frames. Cause a reset in the DUT.\n      Monitor\
    \ the output until frames begin to be forwarded and record\n      the time that\
    \ the last frame (Timestamp A) of the initial stream\n      and the first frame\
    \ of the new stream (Timestamp B) are received.\n      A power interruption reset\
    \ test is performed as above except that\n      the power to the DUT should be\
    \ interrupted for 10 seconds in place\n      of causing a reset.\n      This test\
    \ SHOULD only be run using frames addressed to networks\n      directly connected\
    \ to the DUT so that there is no requirement to\n      delay until a routing update\
    \ is received.\n      The reset value is obtained by subtracting Timestamp A from\n\
    \      Timestamp B.\n      Hardware and software resets, as well as a power interruption\n\
    \      SHOULD be tested.\n      Reporting format:\n      The reset value SHOULD\
    \ be reported in a simple set of statements,\n      one for each reset type.\n"
- title: 27. Security Considerations
  contents:
  - "27. Security Considerations\n   Security issues are not addressed in this document.\n"
- title: 28. Editors' Addresses
  contents:
  - "28. Editors' Addresses\n   Scott Bradner\n   Harvard University\n   1350 Mass.\
    \ Ave, room 813\n   Cambridge, MA 02138\n   Phone +1 617 495-3864\n   Fax +1 617\
    \ 496-8500\n   EMail: sob@harvard.edu\n   Jim McQuaid\n   Bay Networks\n   3 Federal\
    \ Street\n   Billerica, MA 01821\n   Phone +1 508 436-3915\n   Fax: +1 508 670-8145\n\
    \   EMail: jmcquaid@baynetworks.com\n"
- title: 'Appendix A: Testing Considerations'
  contents:
  - 'Appendix A: Testing Considerations

    '
- title: A.1 Scope Of This Appendix
  contents:
  - "A.1 Scope Of This Appendix\n   This appendix discusses certain issues in the\
    \ benchmarking\n   methodology where experience or judgment may play a role in\
    \ the tests\n   selected to be run or in the approach to constructing the test\
    \ with a\n   particular DUT.  As such, this appendix MUST not be read as an\n\
    \   amendment to the methodology described in the body of this document\n   but\
    \ as a guide to testing practice.\n   1. Typical testing practice has been to\
    \ enable all protocols to be\n      tested and conduct all testing with no further\
    \ configuration of\n      protocols, even though a given set of trials may exercise\
    \ only one\n      protocol at a time. This minimizes the opportunities to \"tune\"\
    \ a\n      DUT for a single protocol.\n   2. The least common denominator of the\
    \ available filter functions\n      should be used to ensure that there is a basis\
    \ for comparison\n      between vendors. Because of product differences, those\
    \ conducting\n      and evaluating tests must make a judgment about this issue.\n\
    \   3. Architectural considerations may need to be considered.  For\n      example,\
    \ first perform the tests with the stream going between\n      ports on the same\
    \ interface card and the repeat the tests with the\n      stream going into a\
    \ port on one interface card and out of a port\n      on a second interface card.\
    \ There will almost always be a best\n      case and worst case configuration\
    \ for a given DUT architecture.\n   4. Testing done using traffic streams consisting\
    \ of mixed protocols\n      has not shown much difference between testing with\
    \ individual\n      protocols.  That is, if protocol A testing and protocol B\
    \ testing\n      give two different performance results, mixed protocol testing\n\
    \      appears to give a result which is the average of the two.\n   5. Wide Area\
    \ Network (WAN) performance may be tested by setting up\n      two identical devices\
    \ connected by the appropriate short- haul\n      versions of the WAN modems.\
    \  Performance is then measured between\n      a LAN interface on one DUT to a\
    \ LAN interface on the other DUT.\n   The maximum frame rate to be used for LAN-WAN-LAN\
    \ configurations is a\n   judgment that can be based on known characteristics\
    \ of the overall\n   system including compression effects, fragmentation, and\
    \ gross link\n   speeds. Practice suggests that the rate should be at least 110%\
    \ of\n   the slowest link speed. Substantive issues of testing compression\n \
    \  itself are beyond the scope of this document.\n"
- title: 'Appendix B: Maximum frame rates reference'
  contents:
  - "Appendix B: Maximum frame rates reference\n   (Provided by Roger Beeman, Cisco\
    \ Systems)\n     Size       Ethernet    16Mb Token Ring      FDDI\n    (bytes)\
    \       (pps)           (pps)         (pps)\n    64            14880         \
    \  24691         152439\n    128            8445           13793          85616\n\
    \    256            4528            7326          45620\n    512            2349\
    \            3780          23585\n    768            1586            2547    \
    \      15903\n    1024           1197            1921          11996\n    1280\
    \            961            1542           9630\n    1518            812     \
    \       1302           8138\n   Ethernet size\n    Preamble 64 bits\n    Frame\
    \ 8 x N bits\n    Gap  96 bits\n   16Mb Token Ring size\n      SD            \
    \   8 bits\n      AC               8 bits\n      FC               8 bits\n   \
    \   DA              48 bits\n      SA              48 bits\n      RI         \
    \     48 bits ( 06 30 00 12 00 30 )\n      SNAP\n        DSAP           8 bits\n\
    \        SSAP           8 bits\n        Control        8 bits\n        Vendor\
    \        24 bits\n        Type          16 bits\n      Data 8 x ( N - 18) bits\n\
    \      FCS             32 bits\n      ED               8 bits\n      FS      \
    \         8 bits\n   Tokens or idles between packets are not included\n   FDDI\
    \ size\n      Preamble        64 bits\n      SD               8 bits\n      FC\
    \               8 bits\n      DA              48 bits\n      SA              48\
    \ bits\n      SNAP\n        DSAP           8 bits\n        SSAP           8 bits\n\
    \        Control        8 bits\n        Vendor        24 bits\n        Type  \
    \        16 bits\n      Data 8 x ( N - 18) bits\n      FCS             32 bits\n\
    \      ED               4 bits\n      FS              12 bits\n"
- title: 'Appendix C: Test Frame Formats'
  contents:
  - "Appendix C: Test Frame Formats\n   This appendix defines the frame formats that\
    \ may be used with these\n   tests.  It also includes protocol specific parameters\
    \ for TCP/IP over\n   Ethernet to be used with the tests as an example.\n"
- title: C.1. Introduction
  contents:
  - "C.1. Introduction\n   The general logic used in the selection of the parameters\
    \ and the\n   design of the frame formats is explained for each case within the\n\
    \   TCP/IP section.  The same logic has been used in the other sections.\n   Comments\
    \ are used in these sections only if there is a protocol\n   specific feature\
    \ to be explained.  Parameters and frame formats for\n   additional protocols\
    \ can be defined by the reader by using the same\n   logic.\n"
- title: C.2. TCP/IP Information
  contents:
  - "C.2. TCP/IP Information\n   The following section deals with the TCP/IP protocol\
    \ suite.\n   C.2.1 Frame Type.\n      An application level datagram echo request\
    \ is used for the test\n      data frame in the protocols that support such a\
    \ function.  A\n      datagram protocol is used to minimize the chance that a\
    \ router\n      might expect a specific session initialization sequence, as might\n\
    \      be the case for a reliable stream protocol. A specific defined\n      protocol\
    \ is used because some routers verify the protocol field\n      and refuse to\
    \ forward unknown protocols.\n      For TCP/IP a UDP Echo Request is used.\n \
    \  C.2.2 Protocol Addresses\n      Two sets of addresses must be defined: first\
    \ the addresses\n      assigned to the router ports, and second the address that\
    \ are to\n      be used in the frames themselves and in the routing updates.\n\
    \      The network addresses 192.18.0.0 through 192.19.255.255 are have\n    \
    \  been assigned to the BMWG by the IANA for this purpose.  This\n      assignment\
    \ was made to minimize the chance of conflict in case a\n      testing device\
    \ were to be accidentally connected to part of the\n      Internet.  The specific\
    \ use of the addresses is detailed below.\n      C.2.2.1 Router port protocol\
    \ addresses\n         Half of the ports on a multi-port router are referred to\
    \ as\n         \"input\" ports and the other half as \"output\" ports even though\n\
    \         some of the tests use all ports both as input and output.  A\n     \
    \    contiguous series of IP Class C network addresses from\n         198.18.1.0\
    \ to 198.18.64.0 have been assigned for use on the\n         \"input\" ports.\
    \  A second series from 198.19.1.0 to 198.19.64.0\n         have been assigned\
    \ for use on the \"output\" ports. In all cases\n         the router port is node\
    \ 1 on the appropriate network.  For\n         example, a two port DUT would have\
    \ an IP address of 198.18.1.1\n         on one port and 198.19.1.1 on the other\
    \ port.\n         Some of the tests described in the methodology memo make use\
    \ of\n         an SNMP management connection to the DUT.  The management\n   \
    \      access address for the DUT is assumed to be the first of the\n        \
    \ \"input\" ports (198.18.1.1).\n      C.2.2.2 Frame addresses\n         Some\
    \ of the described tests assume adjacent network routing\n         (the reboot\
    \ time test for example).  The IP address used in the\n         test frame is\
    \ that of node 2 on the appropriate Class C\n         network. (198.19.1.2 for\
    \ example)\n         If the test involves non-adjacent network routing the phantom\n\
    \         routers are located at node 10 of each of the appropriate Class\n  \
    \       C networks.  A series of Class C network addresses from\n         198.18.65.0\
    \ to 198.18.254.0 has been assigned for use as the\n         networks accessible\
    \ through the phantom routers on the \"input\"\n         side of DUT.  The series\
    \ of Class C networks from 198.19.65.0\n         to 198.19.254.0 have been assigned\
    \ to be used as the networks\n         visible through the phantom routers on\
    \ the \"output\" side of the\n         DUT.\n   C.2.3 Routing Update Frequency\n\
    \      The update interval for each routing protocol is may have to be\n     \
    \ determined by the specifications of the individual protocol.  For\n      IP\
    \ RIP, Cisco IGRP and for OSPF a routing update frame or frames\n      should\
    \ precede each stream of test frames by 5 seconds.  This\n      frequency is sufficient\
    \ for trial durations of up to 60 seconds.\n      Routing updates must be mixed\
    \ with the stream of test frames if\n      longer trial periods are selected.\
    \  The frequency of updates\n      should be taken from the following table.\n\
    \       IP-RIP  30 sec\n       IGRP  90 sec\n       OSPF  90 sec\n   C.2.4 Frame\
    \ Formats - detailed discussion\n      C.2.4.1 Learning Frame\n         In most\
    \ protocols a procedure is used to determine the mapping\n         between the\
    \ protocol node address and the MAC address.  The\n         Address Resolution\
    \ Protocol (ARP) is used to perform this\n         function in TCP/IP.  No such\
    \ procedure is required in XNS or\n         IPX because the MAC address is used\
    \ as the protocol node\n         address.\n         In the ideal case the tester\
    \ would be able to respond to ARP\n         requests from the DUT.  In cases where\
    \ this is not possible an\n         ARP request should be sent to the router's\
    \ \"output\" port.  This\n         request should be seen as coming from the immediate\
    \ destination\n         of the test frame stream. (i.e. the phantom router (Figure\
    \ 2)\n         or the end node if adjacent network routing is being used.) It\n\
    \         is assumed that the router will cache the MAC address of the\n     \
    \    requesting device.  The ARP request should be sent 5 seconds\n         before\
    \ the test frame stream starts in each trial.  Trial\n         lengths of longer\
    \ than 50 seconds may require that the router\n         be configured for an extended\
    \ ARP timeout.\n                      +--------+            +------------+\n \
    \                     |        |            |  phantom   |------ P LAN\n     \
    \    A\n            IN A------|   DUT  |------------|            |------ P LAN\n\
    \         B\n                      |        |   OUT A    |  router    |------\
    \ P LAN\n         C\n                      +--------+            +------------+\n\
    \                                 Figure 2\n           In the case where full\
    \ routing is being used\n      C.2.4.2 Routing Update Frame\n         If the test\
    \ does not involve adjacent net routing the tester\n         must supply proper\
    \ routing information using a routing update.\n         A single routing update\
    \ is used before each trial on each\n         \"destination\" port (see section\
    \ C.24).  This update includes\n         the network addresses that are reachable\
    \ through a phantom\n         router on the network attached to the port.  For\
    \ a full mesh\n         test, one destination network address is present in the\
    \ routing\n         update for each of the \"input\" ports.  The test stream on\
    \ each\n         \"input\" port consists of a repeating sequence of frames, one\
    \ to\n         each of the \"output\" ports.\n      C.2.4.3 Management Query Frame\n\
    \         The management overhead test uses SNMP to query a set of\n         variables\
    \ that should be present in all DUTs that support SNMP.\n         The variables\
    \ for a single interface only are read by an NMS\n         at the appropriate\
    \ intervals.  The list of variables to\n         retrieve follow:\n          sysUpTime\n\
    \          ifInOctets\n          ifOutOctets\n          ifInUcastPkts\n      \
    \    ifOutUcastPkts\n      C.2.4.4 Test Frames\n         The test frame is an\
    \ UDP Echo Request with enough data to fill\n         out the required frame size.\
    \  The data should not be all bits\n         off or all bits on since these patters\
    \ can cause a \"bit\n         stuffing\" process to be used to maintain clock\
    \ synchronization\n         on WAN links.  This process will result in a longer\
    \ frame than\n         was intended.\n      C.2.4.5 Frame Formats - TCP/IP on\
    \ Ethernet\n         Each of the frames below are described for the 1st pair of\
    \ DUT\n         ports, i.e. \"input\" port #1 and \"output\" port #1.  Addresses\n\
    \         must be changed if the frame is to be used for other ports.\n      C.2.6.1\
    \ Learning Frame\n          ARP Request on Ethernet\n          -- DATAGRAM HEADER\n\
    \          offset data (hex)            description\n          00     FF FF FF\
    \ FF FF FF     dest MAC address send to\n         broadcast address\n        \
    \  06     xx xx xx xx xx xx     set to source MAC address\n          12     08\
    \ 06                 ARP type\n          14     00 01                 hardware\
    \ type Ethernet = 1\n          16     08 00                 protocol type IP =\
    \ 800\n          18     06                    hardware address length 48 bits\n\
    \         on Ethernet\n          19     04                    protocol address\
    \ length 4 octets\n         for IP\n          20     00 01                 opcode\
    \ request = 1\n          22     xx xx xx xx xx xx     source MAC address\n   \
    \       28     xx xx xx xx           source IP address\n          32     FF FF\
    \ FF FF FF FF     requesting DUT's MAC address\n          38     xx xx xx xx \
    \          DUT's IP address\n      C.2.6.2 Routing Update Frame\n          --\
    \ DATAGRAM HEADER\n          offset data (hex)            description\n      \
    \    00     FF FF FF FF FF FF     dest MAC address is broadcast\n          06\
    \     xx xx xx xx xx xx     source hardware address\n          12     08 00  \
    \               type\n          -- IP HEADER\n          14     45            \
    \        IP version - 4, header length (4\n         byte units) - 5\n        \
    \  15     00                    service field\n          16     00 EE        \
    \         total length\n          18     00 00                 ID\n          20\
    \     40 00                 flags (3 bits) 4 (do not\n         fragment),\n  \
    \                                     fragment offset-0\n          22     0A \
    \                   TTL\n          23     11                    protocol - 17\
    \ (UDP)\n          24     C4 8D                 header checksum\n          26\
    \     xx xx xx xx           source IP address\n          30     xx xx xx     \
    \         destination IP address\n          33     FF                    host\
    \ part = FF for broadcast\n          -- UDP HEADER\n          34     02 08   \
    \              source port 208 = RIP\n          36     02 08                 destination\
    \ port 208 = RIP\n          38     00 DA                 UDP message length\n\
    \          40     00 00                 UDP checksum\n          -- RIP packet\n\
    \          42     02                  command = response\n          43     01\
    \                  version = 1\n          44     00 00               0\n     \
    \     -- net 1\n          46     00 02               family = IP\n          48\
    \     00 00               0\n          50     xx xx xx            net 1 IP address\n\
    \          53     00                  net not node\n          54     00 00 00\
    \ 00         0\n          58     00 00 00 00         0\n          62     00 00\
    \ 00 07         metric 7\n          -- net 2\n          66     00 02         \
    \      family = IP\n          68     00 00               0\n          70     xx\
    \ xx xx            net 2 IP address\n          73     00                  net\
    \ not node\n          74     00 00 00 00         0\n          78     00 00 00\
    \ 00         0\n          82     00 00 00 07         metric 7\n          -- net\
    \ 3\n          86     00 02               family = IP\n          88     00 00\
    \               0\n          90     xx xx xx            net 3 IP address\n   \
    \       93     00                  net not node\n          94     00 00 00 00\
    \         0\n          98     00 00 00 00         0\n          102    00 00 00\
    \ 07         metric 7\n          -- net 4\n          106    00 02            \
    \   family = IP\n          108    00 00               0\n          110    xx xx\
    \ xx            net 4 IP address\n          113    00                  net not\
    \ node\n          114    00 00 00 00         0\n          118    00 00 00 00 \
    \        0\n          122    00 00 00 07         metric 7\n          -- net 5\n\
    \          126    00 02               family = IP\n          128    00 00    \
    \           0\n          130    00                  net 5 IP address\n       \
    \   133    00                  net not node\n          134    00 00 00 00    \
    \     0\n          138    00 00 00 00         0\n          142    00 00 00 07\
    \         metric 7\n          -- net 6\n          146    00 02               family\
    \ = IP\n          148    00 00               0\n          150    xx xx xx    \
    \        net 6 IP address\n          153    00                  net not node\n\
    \          154    00 00 00 00         0\n          158    00 00 00 00        \
    \ 0\n          162    00 00 00 07         metric 7\n      C.2.4.6 Management Query\
    \ Frame\n         To be defined.\n      C.2.6.4 Test Frames\n              UDP\
    \ echo request on Ethernet\n          -- DATAGRAM HEADER\n          offset data\
    \ (hex)            description\n          00     xx xx xx xx xx xx     set to\
    \ dest MAC address\n          06     xx xx xx xx xx xx     set to source MAC address\n\
    \          12     08 00                 type\n          -- IP HEADER\n       \
    \   14     45                    IP version - 4 header length 5 4\n         byte\
    \ units\n          15     00                    TOS\n          16     00 2E  \
    \               total length*\n          18     00 00                 ID\n   \
    \       20     00 00                 flags (3 bits) - 0 fragment\n         offset-0\n\
    \          22     0A                    TTL\n          23     11             \
    \       protocol - 17 (UDP)\n          24     C4 8D                 header checksum*\n\
    \          26     xx xx xx xx           set to source IP address**\n         \
    \ 30     xx xx xx xx           set to destination IP address**\n          -- UDP\
    \ HEADER\n          34     C0 20                 source port\n          36   \
    \  00 07                 destination port 07 = Echo\n          38     00 1A  \
    \               UDP message length*\n          40     00 00                 UDP\
    \ checksum\n          -- UDP DATA\n          42     00 01 02 03 04 05 06 07  \
    \  some data***\n          50     08 09 0A 0B 0C 0D 0E 0F\n         * - change\
    \ for different length frames\n         ** - change for different logical streams\n\
    \         *** - fill remainder of frame with incrementing octets,\n         repeated\
    \ if required by frame length\n   Values to be used in Total Length and UDP message\
    \ length fields:\n          frame size   total length  UDP message length\n  \
    \           64            00 2E          00 1A\n             128           00\
    \ 6E          00 5A\n             256           00 EE          00 9A\n       \
    \      512           01 EE          01 9A\n             768           02 EE  \
    \        02 9A\n             1024          03 EE          03 9A\n            \
    \ 1280          04 EE          04 9A\n             1518          05 DC       \
    \   05 C8\n"
