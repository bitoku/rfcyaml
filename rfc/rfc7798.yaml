- contents:
  - '       RTP Payload Format for High Efficiency Video Coding (HEVC)

    '
  title: __initial_text__
- contents:
  - "Abstract\n   This memo describes an RTP payload format for the video coding\n
    \  standard ITU-T Recommendation H.265 and ISO/IEC International\n   Standard
    23008-2, both also known as High Efficiency Video Coding\n   (HEVC) and developed
    by the Joint Collaborative Team on Video Coding\n   (JCT-VC).  The RTP payload
    format allows for packetization of one or\n   more Network Abstraction Layer (NAL)
    units in each RTP packet payload\n   as well as fragmentation of a NAL unit into
    multiple RTP packets.\n   Furthermore, it supports transmission of an HEVC bitstream
    over a\n   single stream as well as multiple RTP streams.  When multiple RTP\n
    \  streams are used, a single transport or multiple transports may be\n   utilized.
    \ The payload format has wide applicability in\n   videoconferencing, Internet
    video streaming, and high-bitrate\n   entertainment-quality video, among others.\n"
  title: Abstract
- contents:
  - "Status of This Memo\n   This is an Internet Standards Track document.\n   This
    document is a product of the Internet Engineering Task Force\n   (IETF).  It represents
    the consensus of the IETF community.  It has\n   received public review and has
    been approved for publication by the\n   Internet Engineering Steering Group (IESG).
    \ Further information on\n   Internet Standards is available in Section 2 of RFC
    5741.\n   Information about the current status of this document, any errata,\n
    \  and how to provide feedback on it may be obtained at\n   http://www.rfc-editor.org/info/rfc7798.\n"
  title: Status of This Memo
- contents:
  - "Copyright Notice\n   Copyright (c) 2016 IETF Trust and the persons identified
    as the\n   document authors.  All rights reserved.\n   This document is subject
    to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n
    \  (http://trustee.ietf.org/license-info) in effect on the date of\n   publication
    of this document.  Please review these documents\n   carefully, as they describe
    your rights and restrictions with respect\n   to this document.  Code Components
    extracted from this document must\n   include Simplified BSD License text as described
    in Section 4.e of\n   the Trust Legal Provisions and are provided without warranty
    as\n   described in the Simplified BSD License.\n"
  title: Copyright Notice
- contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n
    \     1.1. Overview of the HEVC Codec .................................4\n           1.1.1.
    Coding-Tool Features ................................4\n           1.1.2. Systems
    and Transport Interfaces ....................6\n           1.1.3. Parallel Processing
    Support ........................11\n           1.1.4. NAL Unit Header ....................................13\n
    \     1.2. Overview of the Payload Format ............................14\n   2.
    Conventions ....................................................15\n   3. Definitions
    and Abbreviations ..................................15\n      3.1. Definitions
    ...............................................15\n           3.1.1.  Definitions
    from the HEVC Specification ...........15\n           3.1.2.  Definitions Specific
    to This Memo .................17\n      3.2. Abbreviations .............................................19\n
    \  4. RTP Payload Format .............................................20\n      4.1.
    RTP Header Usage ..........................................20\n      4.2. Payload
    Header Usage ......................................22\n      4.3. Transmission
    Modes ........................................23\n      4.4. Payload Structures
    ........................................24\n           4.4.1. Single NAL Unit
    Packets ............................24\n           4.4.2. Aggregation Packets
    (APs) ..........................25\n           4.4.3. Fragmentation Units ................................29\n
    \          4.4.4. PACI Packets .......................................32\n                  4.4.4.1.
    Reasons for the PACI Rules (Informative) ..34\n                  4.4.4.2. PACI
    Extensions (Informative) .............35\n      4.5. Temporal Scalability Control
    Information ..................36\n      4.6. Decoding Order Number .....................................37\n
    \  5. Packetization Rules ............................................39\n   6.
    De-packetization Process .......................................40\n   7. Payload
    Format Parameters ......................................42\n      7.1. Media Type
    Registration ...................................42\n      7.2. SDP Parameters
    ............................................64\n           7.2.1. Mapping of Payload
    Type Parameters to SDP ..........64\n           7.2.2. Usage with SDP Offer/Answer
    Model ..................65\n           7.2.3. Usage in Declarative Session Descriptions
    ..........73\n           7.2.4. Considerations for Parameter Sets ..................75\n
    \          7.2.5. Dependency Signaling in Multi-Stream Mode ..........75\n   8.
    Use with Feedback Messages .....................................75\n      8.1.
    Picture Loss Indication (PLI) .............................75\n      8.2. Slice
    Loss Indication (SLI) ...............................76\n      8.3. Reference
    Picture Selection Indication (RPSI) .............77\n      8.4. Full Intra Request
    (FIR) ..................................77\n   9. Security Considerations ........................................78\n
    \  10. Congestion Control ............................................79\n   11.
    IANA Considerations ...........................................80\n   12. References
    ....................................................80\n      12.1. Normative
    References .....................................80\n      12.2. Informative References
    ...................................82\n   Acknowledgments ...................................................85\n
    \  Authors' Addresses ................................................86\n"
  title: Table of Contents
- contents:
  - "1.  Introduction\n   The High Efficiency Video Coding specification, formally
    published as\n   both ITU-T Recommendation H.265 [HEVC] and ISO/IEC International\n
    \  Standard 23008-2 [ISO23008-2], was ratified by the ITU-T in April\n   2013;
    reportedly, it provides significant coding efficiency gains\n   over H.264 [H.264].\n
    \  This memo describes an RTP payload format for HEVC.  It shares its\n   basic
    design with the RTP payload formats of [RFC6184] and [RFC6190].\n   With respect
    to design philosophy, security, congestion control, and\n   overall implementation
    complexity, it has similar properties to those\n   earlier payload format specifications.
    \ This is a conscious choice,\n   as at least RFC 6184 is widely deployed and
    generally known in the\n   relevant implementer communities.  Mechanisms from
    RFC 6190 were\n   incorporated as HEVC version 1 supports temporal scalability.\n
    \  In order to help the overlapping implementer community, frequently\n   only
    the differences between RFCs 6184 and 6190 and the HEVC payload\n   format are
    highlighted in non-normative, explanatory parts of this\n   memo.  Basic familiarity
    with both specifications is assumed for\n   those parts.  However, the normative
    parts of this memo do not\n   require study of RFCs 6184 or 6190.\n"
  - contents:
    - "1.1.  Overview of the HEVC Codec\n   H.264 and HEVC share a similar hybrid
      video codec design.  In this\n   memo, we provide a very brief overview of those
      features of HEVC that\n   are, in some form, addressed by the payload format
      specified herein.\n   Implementers have to read, understand, and apply the ITU-T/ISO/IEC\n
      \  specifications pertaining to HEVC to arrive at interoperable, well-\n   performing
      implementations.  Implementers should consider testing\n   their design (including
      the interworking between the payload format\n   implementation and the core
      video codec) using the tools provided by\n   ITU-T/ISO/IEC, for example, conformance
      bitstreams as specified in\n   [H.265.1].  Not doing so has historically led
      to systems that perform\n   badly and that are not secure.\n   Conceptually,
      both H.264 and HEVC include a Video Coding Layer (VCL),\n   which is often used
      to refer to the coding-tool features, and a\n   Network Abstraction Layer (NAL),
      which is often used to refer to the\n   systems and transport interface aspects
      of the codecs.\n"
    - contents:
      - "1.1.1.  Coding-Tool Features\n   Similar to earlier hybrid-video-coding-based
        standards, including\n   H.264, the following basic video coding design is
        employed by HEVC.\n   A prediction signal is first formed by either intra-
        or motion-\n   compensated prediction, and the residual (the difference between
        the\n   original and the prediction) is then coded.  The gains in coding\n
        \  efficiency are achieved by redesigning and improving almost all parts\n
        \  of the codec over earlier designs.  In addition, HEVC includes\n   several
        tools to make the implementation on parallel architectures\n   easier.  Below
        is a summary of HEVC coding-tool features.\n   Quad-tree block and transform
        structure\n   One of the major tools that contributes significantly to the
        coding\n   efficiency of HEVC is the use of flexible coding blocks and\n   transforms,
        which are defined in a hierarchical quad-tree manner.\n   Unlike H.264, where
        the basic coding block is a macroblock of fixed-\n   size 16x16, HEVC defines
        a Coding Tree Unit (CTU) of a maximum size\n   of 64x64.  Each CTU can be
        divided into smaller units in a\n   hierarchical quad-tree manner and can
        represent smaller blocks down\n   to size 4x4.  Similarly, the transforms
        used in HEVC can have\n   different sizes, starting from 4x4 and going up
        to 32x32.  Utilizing\n   large blocks and transforms contributes to the major
        gain of HEVC,\n   especially at high resolutions.\n   Entropy coding\n   HEVC
        uses a single entropy-coding engine, which is based on Context\n   Adaptive
        Binary Arithmetic Coding (CABAC) [CABAC], whereas H.264 uses\n   two distinct
        entropy coding engines.  CABAC in HEVC shares many\n   similarities with CABAC
        of H.264, but contains several improvements.\n   Those include improvements
        in coding efficiency and lowered\n   implementation complexity, especially
        for parallel architectures.\n   In-loop filtering\n   H.264 includes an in-loop
        adaptive deblocking filter, where the\n   blocking artifacts around the transform
        edges in the reconstructed\n   picture are smoothed to improve the picture
        quality and compression\n   efficiency.  In HEVC, a similar deblocking filter
        is employed but\n   with somewhat lower complexity.  In addition, pictures
        undergo a\n   subsequent filtering operation called Sample Adaptive Offset
        (SAO),\n   which is a new design element in HEVC.  SAO basically adds a pixel-\n
        \  level offset in an adaptive manner and usually acts as a de-ringing\n   filter.
        \ It is observed that SAO improves the picture quality,\n   especially around
        sharp edges, contributing substantially to visual\n   quality improvements
        of HEVC.\n   Motion prediction and coding\n   There have been a number of
        improvements in this area that are\n   summarized as follows.  The first category
        is motion merge and\n   Advanced Motion Vector Prediction (AMVP) modes.  The
        motion\n   information of a prediction block can be inferred from the spatially\n
        \  or temporally neighboring blocks.  This is similar to the DIRECT mode\n
        \  in H.264 but includes new aspects to incorporate the flexible quad-\n   tree
        structure and methods to improve the parallel implementations.\n   In addition,
        the motion vector predictor can be signaled for improved\n   efficiency.  The
        second category is high-precision interpolation.\n   The interpolation filter
        length is increased to 8-tap from 6-tap,\n   which improves the coding efficiency
        but also comes with increased\n   complexity.  In addition, the interpolation
        filter is defined with\n   higher precision without any intermediate rounding
        operations to\n   further improve the coding efficiency.\n   Intra prediction
        and intra-coding\n   Compared to 8 intra prediction modes in H.264, HEVC supports
        angular\n   intra prediction with 33 directions.  This increased flexibility\n
        \  improves both objective coding efficiency and visual quality as the\n   edges
        can be better predicted and ringing artifacts around the edges\n   can be
        reduced.  In addition, the reference samples are adaptively\n   smoothed based
        on the prediction direction.  To avoid contouring\n   artifacts a new interpolative
        prediction generation is included to\n   improve the visual quality.  Furthermore,
        Discrete Sine Transform\n   (DST) is utilized instead of traditional Discrete
        Cosine Transform\n   (DCT) for 4x4 intra-transform blocks.\n   Other coding-tool
        features\n   HEVC includes some tools for lossless coding and efficient screen-\n
        \  content coding, such as skipping the transform for certain blocks.\n   These
        tools are particularly useful, for example, when streaming the\n   user interface
        of a mobile device to a large display.\n"
      title: 1.1.1.  Coding-Tool Features
    - contents:
      - "1.1.2.  Systems and Transport Interfaces\n   HEVC inherited the basic systems
        and transport interfaces designs\n   from H.264.  These include the NAL-unit-based
        syntax structure, the\n   hierarchical syntax and data unit structure, the
        Supplemental\n   Enhancement Information (SEI) message mechanism, and the
        video\n   buffering model based on the Hypothetical Reference Decoder (HRD).\n
        \  The hierarchical syntax and data unit structure consists of sequence-\n
        \  level parameter sets, multi-picture-level or picture-level parameter\n
        \  sets, slice-level header parameters, and lower-level parameters.  In\n
        \  the following, a list of differences in these aspects compared to\n   H.264
        is summarized.\n   Video parameter set\n   A new type of parameter set, called
        Video Parameter Set (VPS), was\n   introduced.  For the first (2013) version
        of [HEVC], the VPS NAL unit\n   is required to be available prior to its activation,
        while the\n   information contained in the VPS is not necessary for operation
        of\n   the decoding process.  For future HEVC extensions, such as the 3D or\n
        \  scalable extensions, the VPS is expected to include information\n   necessary
        for operation of the decoding process, e.g., decoding\n   dependency or information
        for reference picture set construction of\n   enhancement layers.  The VPS
        provides a \"big picture\" of a bitstream,\n   including what types of operation
        points are provided, the profile,\n   tier, and level of the operation points,
        and some other high-level\n   properties of the bitstream that can be used
        as the basis for session\n   negotiation and content selection, etc. (see
        Section 7.1).\n   Profile, tier, and level\n   The profile, tier, and level
        syntax structure that can be included in\n   both the VPS and Sequence Parameter
        Set (SPS) includes 12 bytes of\n   data to describe the entire bitstream (including
        all temporally\n   scalable layers, which are referred to as sub-layers in
        the HEVC\n   specification), and can optionally include more profile, tier,
        and\n   level information pertaining to individual temporally scalable\n   layers.
        \ The profile indicator shows the \"best viewed as\" profile\n   when the
        bitstream conforms to multiple profiles, similar to the\n   major brand concept
        in the ISO Base Media File Format (ISOBMFF)\n   [IS014496-12] [IS015444-12]
        and file formats derived based on\n   ISOBMFF, such as the 3GPP file format
        [3GPPFF].  The profile, tier,\n   and level syntax structure also includes
        indications such as 1)\n   whether the bitstream is free of frame-packed content,
        2) whether the\n   bitstream is free of interlaced source content, and 3)
        whether the\n   bitstream is free of field pictures.  When the answer is yes
        for both\n   2) and 3), the bitstream contains only frame pictures of progressive\n
        \  source.  Based on these indications, clients/players without support\n
        \  of post-processing functionalities for the handling of frame-packed,\n
        \  interlaced source content or field pictures can reject those\n   bitstreams
        that contain such pictures.\n   Bitstream and elementary stream\n   HEVC includes
        a definition of an elementary stream, which is new\n   compared to H.264.
        \ An elementary stream consists of a sequence of\n   one or more bitstreams.
        \ An elementary stream that consists of two or\n   more bitstreams has typically
        been formed by splicing together two or\n   more bitstreams (or parts thereof).
        \ When an elementary stream\n   contains more than one bitstream, the last
        NAL unit of the last\n   access unit of a bitstream (except the last bitstream
        in the\n   elementary stream) must contain an end of bitstream NAL unit, and
        the\n   first access unit of the subsequent bitstream must be an Intra-Random\n
        \  Access Point (IRAP) access unit.  This IRAP access unit may be a\n   Clean
        Random Access (CRA), Broken Link Access (BLA), or Instantaneous\n   Decoding
        Refresh (IDR) access unit.\n   Random access support\n   HEVC includes signaling
        in the NAL unit header, through NAL unit\n   types, of IRAP pictures beyond
        IDR pictures.  Three types of IRAP\n   pictures, namely IDR, CRA, and BLA
        pictures, are supported: IDR\n   pictures are conventionally referred to as
        closed group-of-pictures\n   (closed-GOP) random access points whereas CRA
        and BLA pictures are\n   conventionally referred to as open-GOP random access
        points.  BLA\n   pictures usually originate from splicing of two bitstreams
        or part\n   thereof at a CRA picture, e.g., during stream switching.  To enable\n
        \  better systems usage of IRAP pictures, altogether six different NAL\n   units
        are defined to signal the properties of the IRAP pictures,\n   which can be
        used to better match the stream access point types as\n   defined in the ISOBMFF
        [IS014496-12] [IS015444-12], which are\n   utilized for random access support
        in both 3GP-DASH [3GPDASH] and\n   MPEG DASH [MPEGDASH].  Pictures following
        an IRAP picture in decoding\n   order and preceding the IRAP picture in output
        order are referred to\n   as leading pictures associated with the IRAP picture.
        \ There are two\n   types of leading pictures: Random Access Decodable Leading
        (RADL)\n   pictures and Random Access Skipped Leading (RASL) pictures.  RADL\n
        \  pictures are decodable when the decoding started at the associated\n   IRAP
        picture; RASL pictures are not decodable when the decoding\n   started at
        the associated IRAP picture and are usually discarded.\n   HEVC provides mechanisms
        to enable specifying the conformance of a\n   bitstream wherein the originally
        present RASL pictures have been\n   discarded.  Consequently, system components
        can discard RASL\n   pictures, when needed, without worrying about causing
        the bitstream\n   to become non-compliant.\n   Temporal scalability support\n
        \  HEVC includes an improved support of temporal scalability, by\n   inclusion
        of the signaling of TemporalId in the NAL unit header, the\n   restriction
        that pictures of a particular temporal sub-layer cannot\n   be used for inter
        prediction reference by pictures of a lower\n   temporal sub-layer, the sub-bitstream
        extraction process, and the\n   requirement that each sub-bitstream extraction
        output be a conforming\n   bitstream.  Media-Aware Network Elements (MANEs)
        can utilize the\n   TemporalId in the NAL unit header for stream adaptation
        purposes\n   based on temporal scalability.\n   Temporal sub-layer switching
        support\n   HEVC specifies, through NAL unit types present in the NAL unit\n
        \  header, the signaling of Temporal Sub-layer Access (TSA) and Step-\n   wise
        Temporal Sub-layer Access (STSA).  A TSA picture and pictures\n   following
        the TSA picture in decoding order do not use pictures prior\n   to the TSA
        picture in decoding order with TemporalId greater than or\n   equal to that
        of the TSA picture for inter prediction reference.  A\n   TSA picture enables
        up-switching, at the TSA picture, to the sub-\n   layer containing the TSA
        picture or any higher sub-layer, from the\n   immediately lower sub-layer.
        \ An STSA picture does not use pictures\n   with the same TemporalId as the
        STSA picture for inter prediction\n   reference.  Pictures following an STSA
        picture in decoding order with\n   the same TemporalId as the STSA picture
        do not use pictures prior to\n   the STSA picture in decoding order with the
        same TemporalId as the\n   STSA picture for inter prediction reference.  An
        STSA picture enables\n   up-switching, at the STSA picture, to the sub-layer
        containing the\n   STSA picture, from the immediately lower sub-layer.\n   Sub-layer
        reference or non-reference pictures\n   The concept and signaling of reference/non-reference
        pictures in HEVC\n   are different from H.264.  In H.264, if a picture may
        be used by any\n   other picture for inter prediction reference, it is a reference\n
        \  picture; otherwise, it is a non-reference picture, and this is\n   signaled
        by two bits in the NAL unit header.  In HEVC, a picture is\n   called a reference
        picture only when it is marked as \"used for\n   reference\".  In addition,
        the concept of sub-layer reference picture\n   was introduced.  If a picture
        may be used by another other picture\n   with the same TemporalId for inter
        prediction reference, it is a sub-\n   layer reference picture; otherwise,
        it is a sub-layer non-reference\n   picture.  Whether a picture is a sub-layer
        reference picture or sub-\n   layer non-reference picture is signaled through
        NAL unit type values.\n   Extensibility\n   Besides the TemporalId in the
        NAL unit header, HEVC also includes the\n   signaling of a six-bit layer ID
        in the NAL unit header, which must be\n   equal to 0 for a single-layer bitstream.
        \ Extension mechanisms have\n   been included in the VPS, SPS, Picture Parameter
        Set (PPS), SEI NAL\n   unit, slice headers, and so on.  All these extension
        mechanisms\n   enable future extensions in a backward-compatible manner, such
        that\n   bitstreams encoded according to potential future HEVC extensions
        can\n   be fed to then-legacy decoders (e.g., HEVC version 1 decoders), and\n
        \  the then-legacy decoders can decode and output the base-layer\n   bitstream.\n
        \  Bitstream extraction\n   HEVC includes a bitstream-extraction process as
        an integral part of\n   the overall decoding process.  The bitstream extraction
        process is\n   used in the process of bitstream conformance tests, which is
        part of\n   the HRD buffering model.\n   Reference picture management\n   The
        reference picture management of HEVC, including reference picture\n   marking
        and removal from the Decoded Picture Buffer (DPB) as well as\n   Reference
        Picture List Construction (RPLC), differs from that of\n   H.264.  Instead
        of the reference picture marking mechanism based on a\n   sliding window plus
        adaptive Memory Management Control Operation\n   (MMCO) described in H.264,
        HEVC specifies a reference picture\n   management and marking mechanism based
        on Reference Picture Set\n   (RPS), and the RPLC is consequently based on
        the RPS mechanism.  An\n   RPS consists of a set of reference pictures associated
        with a\n   picture, consisting of all reference pictures that are prior to
        the\n   associated picture in decoding order, that may be used for inter\n
        \  prediction of the associated picture or any picture following the\n   associated
        picture in decoding order.  The reference picture set\n   consists of five
        lists of reference pictures; RefPicSetStCurrBefore,\n   RefPicSetStCurrAfter,
        RefPicSetStFoll, RefPicSetLtCurr, and\n   RefPicSetLtFoll.  RefPicSetStCurrBefore,
        RefPicSetStCurrAfter, and\n   RefPicSetLtCurr contain all reference pictures
        that may be used in\n   inter prediction of the current picture and that may
        be used in inter\n   prediction of one or more of the pictures following the
        current\n   picture in decoding order.  RefPicSetStFoll and RefPicSetLtFoll\n
        \  consist of all reference pictures that are not used in inter\n   prediction
        of the current picture but may be used in inter prediction\n   of one or more
        of the pictures following the current picture in\n   decoding order.  RPS
        provides an \"intra-coded\" signaling of the DPB\n   status, instead of an
        \"inter-coded\" signaling, mainly for improved\n   error resilience.  The
        RPLC process in HEVC is based on the RPS, by\n   signaling an index to an
        RPS subset for each reference index; this\n   process is simpler than the
        RPLC process in H.264.\n   Ultra-low delay support\n   HEVC specifies a sub-picture-level
        HRD operation, for support of the\n   so-called ultra-low delay.  The mechanism
        specifies a standard-\n   compliant way to enable delay reduction below a
        one-picture interval.\n   Coded Picture Buffer (CPB) and DPB parameters at
        the sub-picture\n   level may be signaled, and utilization of this information
        for the\n   derivation of CPB timing (wherein the CPB removal time corresponds
        to\n   decoding time) and DPB output timing (display time) is specified.\n
        \  Decoders are allowed to operate the HRD at the conventional access-\n   unit
        level, even when the sub-picture-level HRD parameters are\n   present.\n   New
        SEI messages\n   HEVC inherits many H.264 SEI messages with changes in syntax
        and/or\n   semantics making them applicable to HEVC.  Additionally, there
        are a\n   few new SEI messages reviewed briefly in the following paragraphs.\n
        \  The display orientation SEI message informs the decoder of a\n   transformation
        that is recommended to be applied to the cropped\n   decoded picture prior
        to display, such that the pictures can be\n   properly displayed, e.g., in
        an upside-up manner.\n   The structure of pictures SEI message provides information
        on the NAL\n   unit types, picture-order count values, and prediction dependencies\n
        \  of a sequence of pictures.  The SEI message can be used, for example,\n
        \  for concluding what impact a lost picture has on other pictures.\n   The
        decoded picture hash SEI message provides a checksum derived from\n   the
        sample values of a decoded picture.  It can be used for detecting\n   whether
        a picture was correctly received and decoded.\n   The active parameter sets
        SEI message includes the IDs of the active\n   video parameter set and the
        active sequence parameter set and can be\n   used to activate VPSs and SPSs.
        \ In addition, the SEI message\n   includes the following indications: 1)
        An indication of whether \"full\n   random accessibility\" is supported (when
        supported, all parameter\n   sets needed for decoding of the remaining of
        the bitstream when\n   random accessing from the beginning of the current
        CVS by completely\n   discarding all access units earlier in decoding order
        are present in\n   the remaining bitstream, and all coded pictures in the
        remaining\n   bitstream can be correctly decoded); 2) An indication of whether\n
        \  there is no parameter set within the current CVS that updates another\n
        \  parameter set of the same type preceding in decoding order.  An\n   update
        of a parameter set refers to the use of the same parameter set\n   ID but
        with some other parameters changed.  If this property is true\n   for all
        CVSs in the bitstream, then all parameter sets can be sent\n   out-of-band
        before session start.\n   The decoding unit information SEI message provides
        information\n   regarding coded picture buffer removal delay for a decoding
        unit.\n   The message can be used in very-low-delay buffering operations.\n
        \  The region refresh information SEI message can be used together with\n
        \  the recovery point SEI message (present in both H.264 and HEVC) for\n   improved
        support of gradual decoding refresh.  This supports random\n   access from
        inter-coded pictures, wherein complete pictures can be\n   correctly decoded
        or recovered after an indicated number of pictures\n   in output/display order.\n"
      title: 1.1.2.  Systems and Transport Interfaces
    - contents:
      - "1.1.3.  Parallel Processing Support\n   The reportedly significantly higher
        encoding computational demand of\n   HEVC over H.264, in conjunction with
        the ever-increasing video\n   resolution (both spatially and temporally) required
        by the market,\n   led to the adoption of VCL coding tools specifically targeted
        to\n   allow for parallelization on the sub-picture level.  That is,\n   parallelization
        occurs, at the minimum, at the granularity of an\n   integer number of CTUs.
        \ The targets for this type of high-level\n   parallelization are multicore
        CPUs and DSPs as well as multiprocessor\n   systems.  In a system design,
        to be useful, these tools require\n   signaling support, which is provided
        in Section 7 of this memo.  This\n   section provides a brief overview of
        the tools available in [HEVC].\n   Many of the tools incorporated in HEVC
        were designed keeping in mind\n   the potential parallel implementations in
        multicore/multiprocessor\n   architectures.  Specifically, for parallelization,
        four picture\n   partition strategies, as described below, are available.\n
        \  Slices are segments of the bitstream that can be reconstructed\n   independently
        from other slices within the same picture (though there\n   may still be interdependencies
        through loop filtering operations).\n   Slices are the only tool that can
        be used for parallelization that is\n   also available, in virtually identical
        form, in H.264.\n   Parallelization based on slices does not require much
        inter-processor\n   or inter-core communication (except for inter-processor
        or inter-core\n   data sharing for motion compensation when decoding a predictively\n
        \  coded picture, which is typically much heavier than inter-processor\n   or
        inter-core data sharing due to in-picture prediction), as slices\n   are designed
        to be independently decodable.  However, for the same\n   reason, slices can
        require some coding overhead.  Further, slices (in\n   contrast to some of
        the other tools mentioned below) also serve as\n   the key mechanism for bitstream
        partitioning to match Maximum\n   Transfer Unit (MTU) size requirements, due
        to the in-picture\n   independence of slices and the fact that each regular
        slice is\n   encapsulated in its own NAL unit.  In many cases, the goal of\n
        \  parallelization and the goal of MTU size matching can place\n   contradicting
        demands to the slice layout in a picture.  The\n   realization of this situation
        led to the development of the more\n   advanced tools mentioned below.\n   Dependent
        slice segments allow for fragmentation of a coded slice\n   into fragments
        at CTU boundaries without breaking any in-picture\n   prediction mechanisms.
        \ They are complementary to the fragmentation\n   mechanism described in this
        memo in that they need the cooperation of\n   the encoder.  As a dependent
        slice segment necessarily contains an\n   integer number of CTUs, a decoder
        using multiple cores operating on\n   CTUs can process a dependent slice segment
        without communicating\n   parts of the slice segment's bitstream to other
        cores.\n   Fragmentation, as specified in this memo, in contrast, does not\n
        \  guarantee that a fragment contains an integer number of CTUs.\n   In Wavefront
        Parallel Processing (WPP), the picture is partitioned\n   into rows of CTUs.
        \ Entropy decoding and prediction are allowed to\n   use data from CTUs in
        other partitions.  Parallel processing is\n   possible through parallel decoding
        of CTU rows, where the start of\n   the decoding of a row is delayed by two
        CTUs, so to ensure that data\n   related to a CTU above and to the right of
        the subject CTU is\n   available before the subject CTU is being decoded.
        \ Using this\n   staggered start (which appears like a wavefront when represented\n
        \  graphically), parallelization is possible with up to as many\n   processors/cores
        as the picture contains CTU rows.\n   Because in-picture prediction between
        neighboring CTU rows within a\n   picture is allowed, the required inter-processor/inter-core\n
        \  communication to enable in-picture prediction can be substantial.\n   The
        WPP partitioning does not result in the creation of more NAL\n   units compared
        to when it is not applied; thus, WPP cannot be used\n   for MTU size matching,
        though slices can be used in combination for\n   that purpose.\n   Tiles define
        horizontal and vertical boundaries that partition a\n   picture into tile
        columns and rows.  The scan order of CTUs is\n   changed to be local within
        a tile (in the order of a CTU raster scan\n   of a tile), before decoding
        the top-left CTU of the next tile in the\n   order of tile raster scan of
        a picture.  Similar to slices, tiles\n   break in-picture prediction dependencies
        (including entropy decoding\n   dependencies).  However, they do not need
        to be included into\n   individual NAL units (same as WPP in this regard);
        hence, tiles\n   cannot be used for MTU size matching, though slices can be
        used in\n   combination for that purpose.  Each tile can be processed by one\n
        \  processor/core, and the inter-processor/inter-core communication\n   required
        for in-picture prediction between processing units decoding\n   neighboring
        tiles is limited to conveying the shared slice header in\n   cases a slice
        is spanning more than one tile, and loop-filtering-\n   related sharing of
        reconstructed samples and metadata.  Insofar,\n   tiles are less demanding
        in terms of inter-processor communication\n   bandwidth compared to WPP due
        to the in-picture independence between\n   two neighboring partitions.\n"
      title: 1.1.3.  Parallel Processing Support
    - contents:
      - "1.1.4.  NAL Unit Header\n   HEVC maintains the NAL unit concept of H.264
        with modifications.\n   HEVC uses a two-byte NAL unit header, as shown in
        Figure 1.  The\n   payload of a NAL unit refers to the NAL unit excluding
        the NAL unit\n   header.\n            +---------------+---------------+\n
        \           |0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \           |F|   Type    |  LayerId  | TID |\n            +-------------+-----------------+\n
        \  Figure 1: The Structure of the HEVC NAL Unit Header\n   The semantics of
        the fields in the NAL unit header are as specified\n   in [HEVC] and described
        briefly below for convenience.  In addition\n   to the name and size of each
        field, the corresponding syntax element\n   name in [HEVC] is also provided.\n
        \  F: 1 bit\n      forbidden_zero_bit.  Required to be zero in [HEVC].  Note
        that the\n      inclusion of this bit in the NAL unit header was to enable\n
        \     transport of HEVC video over MPEG-2 transport systems (avoidance\n      of
        start code emulations) [MPEG2S].  In the context of this memo,\n      the
        value 1 may be used to indicate a syntax violation, e.g., for\n      a NAL
        unit resulted from aggregating a number of fragmented units\n      of a NAL
        unit but missing the last fragment, as described in\n      Section 4.4.3.\n
        \  Type: 6 bits\n      nal_unit_type.  This field specifies the NAL unit type
        as defined\n      in Table 7-1 of [HEVC].  If the most significant bit of
        this field\n      of a NAL unit is equal to 0 (i.e., the value of this field
        is less\n      than 32), the NAL unit is a VCL NAL unit.  Otherwise, the NAL
        unit\n      is a non-VCL NAL unit.  For a reference of all currently defined\n
        \     NAL unit types and their semantics, please refer to Section 7.4.2\n
        \     in [HEVC].\n   LayerId: 6 bits\n      nuh_layer_id.  Required to be
        equal to zero in [HEVC].  It is\n      anticipated that in future scalable
        or 3D video coding extensions\n      of this specification, this syntax element
        will be used to\n      identify additional layers that may be present in the
        CVS, wherein\n      a layer may be, e.g., a spatial scalable layer, a quality
        scalable\n      layer, a texture view, or a depth view.\n   TID: 3 bits\n
        \     nuh_temporal_id_plus1.  This field specifies the temporal\n      identifier
        of the NAL unit plus 1.  The value of TemporalId is\n      equal to TID minus
        1.  A TID value of 0 is illegal to ensure that\n      there is at least one
        bit in the NAL unit header equal to 1, so to\n      enable independent considerations
        of start code emulations in the\n      NAL unit header and in the NAL unit
        payload data.\n"
      title: 1.1.4.  NAL Unit Header
    title: 1.1.  Overview of the HEVC Codec
  - contents:
    - "1.2.  Overview of the Payload Format\n   This payload format defines the following
      processes required for\n   transport of HEVC coded data over RTP [RFC3550]:\n
      \  o  Usage of RTP header with this payload format\n   o  Packetization of HEVC
      coded NAL units into RTP packets using three\n      types of payload structures:
      a single NAL unit packet, aggregation\n      packet, and fragment unit\n   o
      \ Transmission of HEVC NAL units of the same bitstream within a\n      single
      RTP stream or multiple RTP streams (within one or more RTP\n      sessions),
      where within an RTP stream transmission of NAL units\n      may be either non-interleaved
      (i.e., the transmission order of NAL\n      units is the same as their decoding
      order) or interleaved (i.e.,\n      the transmission order of NAL units is different
      from the decoding\n      order)\n   o  Media type parameters to be used with
      the Session Description\n      Protocol (SDP) [RFC4566]\n   o  A payload header
      extension mechanism and data structures for\n      enhanced support of temporal
      scalability based on that extension\n      mechanism.\n"
    title: 1.2.  Overview of the Payload Format
  title: 1.  Introduction
- contents:
  - "2.  Conventions\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\",
    \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\"
    in this\n   document are to be interpreted as described in BCP 14 [RFC2119].\n
    \  In this document, the above key words will convey that interpretation\n   only
    when in ALL CAPS.  Lowercase uses of these words are not to be\n   interpreted
    as carrying the significance described in RFC 2119.\n   This specification uses
    the notion of setting and clearing a bit when\n   bit fields are handled.  Setting
    a bit is the same as assigning that\n   bit the value of 1 (On).  Clearing a bit
    is the same as assigning\n   that bit the value of 0 (Off).\n"
  title: 2.  Conventions
- contents:
  - '3.  Definitions and Abbreviations

    '
  - contents:
    - "3.1.  Definitions\n   This document uses the terms and definitions of [HEVC].
      \ Section\n   3.1.1 lists relevant definitions from [HEVC] for convenience.\n
      \  Section 3.1.2 provides definitions specific to this memo.\n"
    - contents:
      - "3.1.1.  Definitions from the HEVC Specification\n   access unit: A set of
        NAL units that are associated with each other\n   according to a specified
        classification rule, that are consecutive in\n   decoding order, and that
        contain exactly one coded picture.\n   BLA access unit: An access unit in
        which the coded picture is a BLA\n   picture.\n   BLA picture: An IRAP picture
        for which each VCL NAL unit has\n   nal_unit_type equal to BLA_W_LP, BLA_W_RADL,
        or BLA_N_LP.\n   Coded Video Sequence (CVS): A sequence of access units that
        consists,\n   in decoding order, of an IRAP access unit with NoRaslOutputFlag
        equal\n   to 1, followed by zero or more access units that are not IRAP access\n
        \  units with NoRaslOutputFlag equal to 1, including all subsequent\n   access
        units up to but not including any subsequent access unit that\n   is an IRAP
        access unit with NoRaslOutputFlag equal to 1.\n      Informative note: An
        IRAP access unit may be an IDR access unit, a\n      BLA access unit, or a
        CRA access unit.  The value of\n      NoRaslOutputFlag is equal to 1 for each
        IDR access unit, each BLA\n      access unit, and each CRA access unit that
        is the first access\n      unit in the bitstream in decoding order, is the
        first access unit\n      that follows an end of sequence NAL unit in decoding
        order, or has\n      HandleCraAsBlaFlag equal to 1.\n   CRA access unit: An
        access unit in which the coded picture is a CRA\n   picture.\n   CRA picture:
        A RAP picture for which each VCL NAL unit has\n   nal_unit_type equal to CRA_NUT.\n
        \  IDR access unit: An access unit in which the coded picture is an IDR\n
        \  picture.\n   IDR picture: A RAP picture for which each VCL NAL unit has\n
        \  nal_unit_type equal to IDR_W_RADL or IDR_N_LP.\n   IRAP access unit: An
        access unit in which the coded picture is an\n   IRAP picture.\n   IRAP picture:
        A coded picture for which each VCL NAL unit has\n   nal_unit_type in the range
        of BLA_W_LP (16) to RSV_IRAP_VCL23 (23),\n   inclusive.\n   layer: A set of
        VCL NAL units that all have a particular value of\n   nuh_layer_id and the
        associated non-VCL NAL units, or one of a set of\n   syntactical structures
        having a hierarchical relationship.\n   operation point: bitstream created
        from another bitstream by\n   operation of the sub-bitstream extraction process
        with the another\n   bitstream, a target highest TemporalId, and a target-layer
        identifier\n   list as input.\n   random access: The act of starting the decoding
        process for a\n   bitstream at a point other than the beginning of the bitstream.\n
        \  sub-layer: A temporal scalable layer of a temporal scalable bitstream\n
        \  consisting of VCL NAL units with a particular value of the TemporalId\n
        \  variable, and the associated non-VCL NAL units.\n   sub-layer representation:
        A subset of the bitstream consisting of NAL\n   units of a particular sub-layer
        and the lower sub-layers.\n   tile: A rectangular region of coding tree blocks
        within a particular\n   tile column and a particular tile row in a picture.\n
        \  tile column: A rectangular region of coding tree blocks having a\n   height
        equal to the height of the picture and a width specified by\n   syntax elements
        in the picture parameter set.\n   tile row: A rectangular region of coding
        tree blocks having a height\n   specified by syntax elements in the picture
        parameter set and a width\n   equal to the width of the picture.\n"
      title: 3.1.1.  Definitions from the HEVC Specification
    - contents:
      - "3.1.2.  Definitions Specific to This Memo\n   dependee RTP stream: An RTP
        stream on which another RTP stream\n   depends.  All RTP streams in a Multiple
        RTP streams on a Single media\n   Transport (MRST) or Multiple RTP streams
        on Multiple media Transports\n   (MRMT), except for the highest RTP stream,
        are dependee RTP streams.\n   highest RTP stream: The RTP stream on which
        no other RTP stream\n   depends.  The RTP stream in a Single RTP stream on
        a Single media\n   Transport (SRST) is the highest RTP stream.\n   Media-Aware
        Network Element (MANE): A network element, such as a\n   middlebox, selective
        forwarding unit, or application-layer gateway\n   that is capable of parsing
        certain aspects of the RTP payload headers\n   or the RTP payload and reacting
        to their contents.\n      Informative note: The concept of a MANE goes beyond
        normal routers\n      or gateways in that a MANE has to be aware of the signaling
        (e.g.,\n      to learn about the payload type mappings of the media streams),\n
        \     and in that it has to be trusted when working with Secure RTP\n      (SRTP).
        \ The advantage of using MANEs is that they allow packets\n      to be dropped
        according to the needs of the media coding.  For\n      example, if a MANE
        has to drop packets due to congestion on a\n      certain link, it can identify
        and remove those packets whose\n      elimination produces the least adverse
        effect on the user\n      experience.  After dropping packets, MANEs must
        rewrite RTCP\n      packets to match the changes to the RTP stream, as specified
        in\n      Section 7 of [RFC3550].\n   Media Transport: As used in the MRST,
        MRMT, and SRST definitions\n   below, Media Transport denotes the transport
        of packets over a\n   transport association identified by a 5-tuple (source
        address, source\n   port, destination address, destination port, transport
        protocol).\n   See also Section 2.1.13 of [RFC7656].\n      Informative note:
        The term \"bitstream\" in this document is\n      equivalent to the term \"encoded
        stream\" in [RFC7656].\n   Multiple RTP streams on a Single media Transport
        (MRST):  Multiple\n   RTP streams carrying a single HEVC bitstream on a Single
        Transport.\n   See also Section 3.5 of [RFC7656].\n   Multiple RTP streams
        on Multiple media Transports (MRMT):  Multiple\n   RTP streams carrying a
        single HEVC bitstream on Multiple Transports.\n   See also Section 3.5 of
        [RFC7656].\n   NAL unit decoding order: A NAL unit order that conforms to
        the\n   constraints on NAL unit order given in Section 7.4.2.4 in [HEVC].\n
        \  NAL unit output order: A NAL unit order in which NAL units of\n   different
        access units are in the output order of the decoded\n   pictures corresponding
        to the access units, as specified in [HEVC],\n   and in which NAL units within
        an access unit are in their decoding\n   order.\n   NAL-unit-like structure:
        A data structure that is similar to NAL\n   units in the sense that it also
        has a NAL unit header and a payload,\n   with a difference that the payload
        does not follow the start code\n   emulation prevention mechanism required
        for the NAL unit syntax as\n   specified in Section 7.3.1.1 of [HEVC].  Examples
        of NAL-unit-like\n   structures defined in this memo are packet payloads of
        Aggregation\n   Packet (AP), PAyload Content Information (PACI), and Fragmentation\n
        \  Unit (FU) packets.\n   NALU-time: The value that the RTP timestamp would
        have if the NAL\n   unit would be transported in its own RTP packet.\n   RTP
        stream: See [RFC7656].  Within the scope of this memo, one RTP\n   stream
        is utilized to transport one or more temporal sub-layers.\n   Single RTP stream
        on a Single media Transport (SRST):  Single RTP\n   stream carrying a single
        HEVC bitstream on a Single (Media)\n   Transport.  See also Section 3.5 of
        [RFC7656].\n   transmission order: The order of packets in ascending RTP sequence\n
        \  number order (in modulo arithmetic).  Within an aggregation packet,\n   the
        NAL unit transmission order is the same as the order of\n   appearance of
        NAL units in the packet.\n"
      title: 3.1.2.  Definitions Specific to This Memo
    title: 3.1.  Definitions
  - contents:
    - "3.2.  Abbreviations\n   AP       Aggregation Packet\n   BLA      Broken Link
      Access\n   CRA      Clean Random Access\n   CTB      Coding Tree Block\n   CTU
      \     Coding Tree Unit\n   CVS      Coded Video Sequence\n   DPH      Decoded
      Picture Hash\n   FU       Fragmentation Unit\n   HRD      Hypothetical Reference
      Decoder\n   IDR      Instantaneous Decoding Refresh\n   IRAP     Intra Random
      Access Point\n   MANE     Media-Aware Network Element\n   MRMT     Multiple
      RTP streams on Multiple media Transports\n   MRST     Multiple RTP streams on
      a Single media Transport\n   MTU      Maximum Transfer Unit\n   NAL      Network
      Abstraction Layer\n   NALU     Network Abstraction Layer Unit\n   PACI     PAyload
      Content Information\n   PHES     Payload Header Extension Structure\n   PPS
      \     Picture Parameter Set\n   RADL     Random Access Decodable Leading (Picture)\n
      \  RASL     Random Access Skipped Leading (Picture)\n   RPS      Reference Picture
      Set\n   SEI      Supplemental Enhancement Information\n   SPS      Sequence
      Parameter Set\n   SRST     Single RTP stream on a Single media Transport\n   STSA
      \    Step-wise Temporal Sub-layer Access\n   TSA      Temporal Sub-layer Access\n
      \  TSCI     Temporal Scalability Control Information\n   VCL      Video Coding
      Layer\n   VPS      Video Parameter Set\n"
    title: 3.2.  Abbreviations
  title: 3.  Definitions and Abbreviations
- contents:
  - '4.  RTP Payload Format

    '
  - contents:
    - "4.1.  RTP Header Usage\n   The format of the RTP header is specified in [RFC3550]
      (reprinted as\n   Figure 2 for convenience).  This payload format uses the fields
      of\n   the header in a manner consistent with that specification.\n   The RTP
      payload (and the settings for some RTP header bits) for\n   aggregation packets
      and fragmentation units are specified in Sections\n   4.4.2 and 4.4.3, respectively.\n
      \   0                   1                   2                   3\n    0 1 2
      3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |V=2|P|X|  CC   |M|     PT      |       sequence number         |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |                           timestamp                           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |           synchronization source (SSRC) identifier            |\n   +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n
      \  |            contributing source (CSRC) identifiers             |\n   |                             ....
      \                             |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \              Figure 2: RTP Header According to [RFC3550]\n   The RTP header
      information to be set according to this RTP payload\n   format is set as follows:\n
      \  Marker bit (M): 1 bit\n      Set for the last packet of the access unit,
      carried in the current\n      RTP stream.  This is in line with the normal use
      of the M bit in\n      video formats to allow an efficient playout buffer handling.
      \ When\n      MRST or MRMT is in use, if an access unit appears in multiple
      RTP\n      streams, the marker bit is set on each RTP stream's last packet of\n
      \     the access unit.\n         Informative note: The content of a NAL unit
      does not tell\n         whether or not the NAL unit is the last NAL unit, in
      decoding\n         order, of an access unit.  An RTP sender implementation may\n
      \        obtain this information from the video encoder.  If, however,\n         the
      implementation cannot obtain this information directly from\n         the encoder,
      e.g., when the bitstream was pre-encoded, and also\n         there is no timestamp
      allocated for each NAL unit, then the\n         sender implementation can inspect
      subsequent NAL units in\n         decoding order to determine whether or not
      the NAL unit is the\n         last NAL unit of an access unit as follows.  A
      NAL unit is\n         determined to be the last NAL unit of an access unit if
      it is\n         the last NAL unit of the bitstream.  A NAL unit naluX is also\n
      \        determined to be the last NAL unit of an access unit if both\n         the
      following conditions are true: 1) the next VCL NAL unit\n         naluY in decoding
      order has the high-order bit of the first\n         byte after its NAL unit
      header equal to 1, and 2) all NAL units\n         between naluX and naluY, when
      present, have nal_unit_type in\n         the range of 32 to 35, inclusive, equal
      to 39, or in the ranges\n         of 41 to 44, inclusive, or 48 to 55, inclusive.\n
      \  Payload Type (PT): 7 bits\n      The assignment of an RTP payload type for
      this new packet format\n      is outside the scope of this document and will
      not be specified\n      here.  The assignment of a payload type has to be performed
      either\n      through the profile used or in a dynamic way.\n         Informative
      note: It is not required to use different payload\n         type values for
      different RTP streams in MRST or MRMT.\n   Sequence Number (SN): 16 bits\n      Set
      and used in accordance with [RFC3550].\n   Timestamp: 32 bits\n      The RTP
      timestamp is set to the sampling timestamp of the content.\n      A 90 kHz clock
      rate MUST be used.\n      If the NAL unit has no timing properties of its own
      (e.g.,\n      parameter set and SEI NAL units), the RTP timestamp MUST be set
      to\n      the RTP timestamp of the coded picture of the access unit in which\n
      \     the NAL unit (according to Section 7.4.2.4.4 of [HEVC]) is\n      included.\n
      \     Receivers MUST use the RTP timestamp for the display process, even\n      when
      the bitstream contains picture timing SEI messages or\n      decoding unit information
      SEI messages as specified in [HEVC].\n      However, this does not mean that
      picture timing SEI messages in\n      the bitstream should be discarded, as
      picture timing SEI messages\n      may contain frame-field information that
      is important in\n      appropriately rendering interlaced video.\n   Synchronization
      source (SSRC): 32 bits\n      Used to identify the source of the RTP packets.
      \ When using SRST,\n      by definition a single SSRC is used for all parts
      of a single\n      bitstream.  In MRST or MRMT, different SSRCs are used for
      each RTP\n      stream containing a subset of the sub-layers of the single\n
      \     (temporally scalable) bitstream.  A receiver is required to\n      correctly
      associate the set of SSRCs that are included parts of\n      the same bitstream.\n"
    title: 4.1.  RTP Header Usage
  - contents:
    - "4.2.  Payload Header Usage\n   The first two bytes of the payload of an RTP
      packet are referred to\n   as the payload header.  The payload header consists
      of the same\n   fields (F, Type, LayerId, and TID) as the NAL unit header as
      shown in\n   Section 1.1.4, irrespective of the type of the payload structure.\n
      \  The TID value indicates (among other things) the relative importance\n   of
      an RTP packet, for example, because NAL units belonging to higher\n   temporal
      sub-layers are not used for the decoding of lower temporal\n   sub-layers.  A
      lower value of TID indicates a higher importance.\n   More-important NAL units
      MAY be better protected against transmission\n   losses than less-important
      NAL units.\n"
    title: 4.2.  Payload Header Usage
  - contents:
    - "4.3.  Transmission Modes\n   This memo enables transmission of an HEVC bitstream
      over:\n      o a Single RTP stream on a Single media Transport (SRST),\n      o
      Multiple RTP streams over a Single media Transport (MRST), or\n      o Multiple
      RTP streams on Multiple media Transports (MRMT).\n      Informative note: While
      this specification enables the use of MRST\n      within the H.265 RTP payload,
      the signaling of MRST within SDP\n      offer/answer is not fully specified
      at the time of this writing.\n      See [RFC5576] and [RFC5583] for what is
      supported today as well as\n      [RTP-MULTI-STREAM] and [SDP-NEG] for future
      directions.\n   When in MRMT, the dependency of one RTP stream on another RTP
      stream\n   is typically indicated as specified in [RFC5583].  [RFC5583] can
      also\n   be utilized to specify dependencies within MRST, but only if the RTP\n
      \  streams utilize distinct payload types.\n   SRST or MRST SHOULD be used for
      point-to-point unicast scenarios,\n   whereas MRMT SHOULD be used for point-to-multipoint
      multicast\n   scenarios where different receivers require different operation\n
      \  points of the same HEVC bitstream, to improve bandwidth utilizing\n   efficiency.\n
      \     Informative note: A multicast may degrade to a unicast after all\n      but
      one receivers have left (this is a justification of the first\n      \"SHOULD\"
      instead of \"MUST\"), and there might be scenarios where\n      MRMT is desirable
      but not possible, e.g., when IP multicast is not\n      deployed in certain
      network (this is a justification of the second\n      \"SHOULD\" instead of
      \"MUST\").\n   The transmission mode is indicated by the tx-mode media parameter\n
      \  (see Section 7.1).  If tx-mode is equal to \"SRST\", SRST MUST be used.\n
      \  Otherwise, if tx-mode is equal to \"MRST\", MRST MUST be used.\n   Otherwise
      (tx-mode is equal to \"MRMT\"), MRMT MUST be used.\n      Informative note:
      When an RTP stream does not depend on other RTP\n      streams, any of SRST,
      MRST, or MRMT may be in use for the RTP\n      stream.\n   Receivers MUST support
      all of SRST, MRST, and MRMT.\n      Informative note: The required support of
      MRMT by receivers does\n      not imply that multicast must be supported by
      receivers.\n"
    title: 4.3.  Transmission Modes
  - contents:
    - "4.4.  Payload Structures\n   Four different types of RTP packet payload structures
      are specified.\n   A receiver can identify the type of an RTP packet payload
      through the\n   Type field in the payload header.\n   The four different payload
      structures are as follows:\n   o  Single NAL unit packet: Contains a single
      NAL unit in the payload,\n      and the NAL unit header of the NAL unit also
      serves as the payload\n      header.  This payload structure is specified in
      Section 4.4.1.\n   o  Aggregation Packet (AP): Contains more than one NAL unit
      within\n      one access unit.  This payload structure is specified in Section\n
      \     4.4.2.\n   o  Fragmentation Unit (FU): Contains a subset of a single NAL
      unit.\n      This payload structure is specified in Section 4.4.3.\n   o  PACI
      carrying RTP packet: Contains a payload header (that differs\n      from other
      payload headers for efficiency), a Payload Header\n      Extension Structure
      (PHES), and a PACI payload.  This payload\n      structure is specified in Section
      4.4.4.\n"
    - contents:
      - "4.4.1.  Single NAL Unit Packets\n   A single NAL unit packet contains exactly
        one NAL unit, and consists\n   of a payload header (denoted as PayloadHdr),
        a conditional 16-bit\n   DONL field (in network byte order), and the NAL unit
        payload data\n   (the NAL unit excluding its NAL unit header) of the contained
        NAL\n   unit, as shown in Figure 3.\n    0                   1                   2
        \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3
        4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |           PayloadHdr          |      DONL (conditional)       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                                                               |\n   |
        \                 NAL unit payload data                        |\n   |                                                               |\n
        \  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |
        \                              :...OPTIONAL RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \           Figure 3: The Structure of a Single NAL Unit Packet\n   The payload
        header SHOULD be an exact copy of the NAL unit header of\n   the contained
        NAL unit.  However, the Type (i.e., nal_unit_type)\n   field MAY be changed,
        e.g., when it is desirable to handle a CRA\n   picture to be a BLA picture
        [JCTVC-J0107].\n   The DONL field, when present, specifies the value of the
        16 least\n   significant bits of the decoding order number of the contained
        NAL\n   unit.  If sprop-max-don-diff is greater than 0 for any of the RTP\n
        \  streams, the DONL field MUST be present, and the variable DON for the\n
        \  contained NAL unit is derived as equal to the value of the DONL\n   field.
        \ Otherwise (sprop-max-don-diff is equal to 0 for all the RTP\n   streams),
        the DONL field MUST NOT be present.\n"
      title: 4.4.1.  Single NAL Unit Packets
    - contents:
      - "4.4.2.  Aggregation Packets (APs)\n   Aggregation Packets (APs) are introduced
        to enable the reduction of\n   packetization overhead for small NAL units,
        such as most of the non-\n   VCL NAL units, which are often only a few octets
        in size.\n   An AP aggregates NAL units within one access unit.  Each NAL
        unit to\n   be carried in an AP is encapsulated in an aggregation unit.  NAL\n
        \  units aggregated in one AP are in NAL unit decoding order.\n   An AP consists
        of a payload header (denoted as PayloadHdr) followed\n   by two or more aggregation
        units, as shown in Figure 4.\n    0                   1                   2
        \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3
        4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |    PayloadHdr (Type=48)       |                               |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
        \                              |\n   |                                                               |\n
        \  |             two or more aggregation units                     |\n   |
        \                                                              |\n   |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                               :...OPTIONAL RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \           Figure 4: The Structure of an Aggregation Packet\n   The fields
        in the payload header are set as follows.  The F bit MUST\n   be equal to
        0 if the F bit of each aggregated NAL unit is equal to\n   zero; otherwise,
        it MUST be equal to 1.  The Type field MUST be equal\n   to 48.  The value
        of LayerId MUST be equal to the lowest value of\n   LayerId of all the aggregated
        NAL units.  The value of TID MUST be\n   the lowest value of TID of all the
        aggregated NAL units.\n      Informative note: All VCL NAL units in an AP
        have the same TID\n      value since they belong to the same access unit.
        \ However, an AP\n      may contain non-VCL NAL units for which the TID value
        in the NAL\n      unit header may be different than the TID value of the VCL
        NAL\n      units in the same AP.\n   An AP MUST carry at least two aggregation
        units and can carry as many\n   aggregation units as necessary; however, the
        total amount of data in\n   an AP obviously MUST fit into an IP packet, and
        the size SHOULD be\n   chosen so that the resulting IP packet is smaller than
        the MTU size\n   so to avoid IP layer fragmentation.  An AP MUST NOT contain
        FUs\n   specified in Section 4.4.3.  APs MUST NOT be nested; i.e., an AP must\n
        \  not contain another AP.\n   The first aggregation unit in an AP consists
        of a conditional 16-bit\n   DONL field (in network byte order) followed by
        a 16-bit unsigned size\n   information (in network byte order) that indicates
        the size of the\n   NAL unit in bytes (excluding these two octets, but including
        the NAL\n   unit header), followed by the NAL unit itself, including its NAL
        unit\n   header, as shown in Figure 5.\n    0                   1                   2
        \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3
        4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \                  :       DONL (conditional)      |   NALU size   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |   NALU size   |                                               |\n   +-+-+-+-+-+-+-+-+
        \        NAL unit                              |\n   |                                                               |\n
        \  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |
        \                              :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n     Figure
        5: The Structure of the First Aggregation Unit in an AP\n   The DONL field,
        when present, specifies the value of the 16 least\n   significant bits of
        the decoding order number of the aggregated NAL\n   unit.\n   If sprop-max-don-diff
        is greater than 0 for any of the RTP streams,\n   the DONL field MUST be present
        in an aggregation unit that is the\n   first aggregation unit in an AP, and
        the variable DON for the\n   aggregated NAL unit is derived as equal to the
        value of the DONL\n   field.  Otherwise (sprop-max-don-diff is equal to 0
        for all the RTP\n   streams), the DONL field MUST NOT be present in an aggregation
        unit\n   that is the first aggregation unit in an AP.\n   An aggregation unit
        that is not the first aggregation unit in an AP\n   consists of a conditional
        8-bit DOND field followed by a 16-bit\n   unsigned size information (in network
        byte order) that indicates the\n   size of the NAL unit in bytes (excluding
        these two octets, but\n   including the NAL unit header), followed by the
        NAL unit itself,\n   including its NAL unit header, as shown in Figure 6.\n
        \   0                   1                   2                   3\n    0 1
        2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \                  : DOND (cond)   |          NALU size            |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                                                               |\n   |
        \                      NAL unit                                |\n   |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                               :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  Figure 6: The Structure of an Aggregation Unit That Is Not the\n   First
        Aggregation Unit in an AP\n   When present, the DOND field plus 1 specifies
        the difference between\n   the decoding order number values of the current
        aggregated NAL unit\n   and the preceding aggregated NAL unit in the same
        AP.\n   If sprop-max-don-diff is greater than 0 for any of the RTP streams,\n
        \  the DOND field MUST be present in an aggregation unit that is not the\n
        \  first aggregation unit in an AP, and the variable DON for the\n   aggregated
        NAL unit is derived as equal to the DON of the preceding\n   aggregated NAL
        unit in the same AP plus the value of the DOND field\n   plus 1 modulo 65536.
        \ Otherwise (sprop-max-don-diff is equal to 0 for\n   all the RTP streams),
        the DOND field MUST NOT be present in an\n   aggregation unit that is not
        the first aggregation unit in an AP, and\n   in this case the transmission
        order and decoding order of NAL units\n   carried in the AP are the same as
        the order the NAL units appear in\n   the AP.\n   Figure 7 presents an example
        of an AP that contains two aggregation\n   units, labeled as 1 and 2 in the
        figure, without the DONL and DOND\n   fields being present.\n    0                   1
        \                  2                   3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3
        4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                          RTP Header                           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |   PayloadHdr (Type=48)        |         NALU 1 Size           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |          NALU 1 HDR           |                               |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
        \        NALU 1 Data           |\n   |                   . . .                                       |\n
        \  |                                                               |\n   +
        \              +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |  .
        . .        | NALU 2 Size                   | NALU 2 HDR    |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  | NALU 2 HDR    |                                               |\n   +-+-+-+-+-+-+-+-+
        \             NALU 2 Data                      |\n   |                   .
        . .                                       |\n   |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                               :...OPTIONAL RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  Figure 7: An Example of an AP Packet Containing Two Aggregation\n   Units
        without the DONL and DOND Fields\n   Figure 8 presents an example of an AP
        that contains two aggregation\n   units, labeled as 1 and 2 in the figure,
        with the DONL and DOND\n   fields being present.\n    0                   1
        \                  2                   3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3
        4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                          RTP Header                           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |   PayloadHdr (Type=48)        |        NALU 1 DONL            |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |          NALU 1 Size          |            NALU 1 HDR         |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |                                                               |\n   |
        \                NALU 1 Data   . . .                           |\n   |                                                               |\n
        \  +     . . .     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |
        \              |  NALU 2 DOND  |          NALU 2 Size          |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |          NALU 2 HDR           |                               |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
        \         NALU 2 Data          |\n   |                                                               |\n
        \  |        . . .                  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |
        \                              :...OPTIONAL RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  Figure 8: An Example of an AP Containing Two Aggregation Units\n   with
        the DONL and DOND Fields\n"
      title: 4.4.2.  Aggregation Packets (APs)
    - contents:
      - "4.4.3.  Fragmentation Units\n   Fragmentation Units (FUs) are introduced
        to enable fragmenting a\n   single NAL unit into multiple RTP packets, possibly
        without\n   cooperation or knowledge of the HEVC encoder.  A fragment of a
        NAL\n   unit consists of an integer number of consecutive octets of that NAL\n
        \  unit.  Fragments of the same NAL unit MUST be sent in consecutive\n   order
        with ascending RTP sequence numbers (with no other RTP packets\n   within
        the same RTP stream being sent between the first and last\n   fragment).\n
        \  When a NAL unit is fragmented and conveyed within FUs, it is referred\n
        \  to as a fragmented NAL unit.  APs MUST NOT be fragmented.  FUs MUST\n   NOT
        be nested; i.e., an FU must not contain a subset of another FU.\n   The RTP
        timestamp of an RTP packet carrying an FU is set to the NALU-\n   time of
        the fragmented NAL unit.\n   An FU consists of a payload header (denoted as
        PayloadHdr), an FU\n   header of one octet, a conditional 16-bit DONL field
        (in network byte\n   order), and an FU payload, as shown in Figure 9.\n    0
        \                  1                   2                   3\n    0 1 2 3
        4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |    PayloadHdr (Type=49)       |   FU header   | DONL (cond)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-|\n
        \  | DONL (cond)   |                                               |\n   |-+-+-+-+-+-+-+-+
        \                                              |\n   |                         FU
        payload                            |\n   |                                                               |\n
        \  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |
        \                              :...OPTIONAL RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \               Figure 9: The Structure of an FU\n   The fields in the payload
        header are set as follows.  The Type field\n   MUST be equal to 49.  The fields
        F, LayerId, and TID MUST be equal to\n   the fields F, LayerId, and TID, respectively,
        of the fragmented NAL\n   unit.\n   The FU header consists of an S bit, an
        E bit, and a 6-bit FuType\n   field, as shown in Figure 10.\n   +---------------+\n
        \  |0|1|2|3|4|5|6|7|\n   +-+-+-+-+-+-+-+-+\n   |S|E|  FuType   |\n   +---------------+\n
        \  Figure 10: The Structure of FU Header\n   The semantics of the FU header
        fields are as follows:\n   S: 1 bit\n      When set to 1, the S bit indicates
        the start of a fragmented NAL\n      unit, i.e., the first byte of the FU
        payload is also the first\n      byte of the payload of the fragmented NAL
        unit.  When the FU\n      payload is not the start of the fragmented NAL unit
        payload, the S\n      bit MUST be set to 0.\n   E: 1 bit\n      When set to
        1, the E bit indicates the end of a fragmented NAL\n      unit, i.e., the
        last byte of the payload is also the last byte of\n      the fragmented NAL
        unit.  When the FU payload is not the last\n      fragment of a fragmented
        NAL unit, the E bit MUST be set to 0.\n   FuType: 6 bits\n      The field
        FuType MUST be equal to the field Type of the fragmented\n      NAL unit.\n
        \  The DONL field, when present, specifies the value of the 16 least\n   significant
        bits of the decoding order number of the fragmented NAL\n   unit.\n   If sprop-max-don-diff
        is greater than 0 for any of the RTP streams,\n   and the S bit is equal to
        1, the DONL field MUST be present in the\n   FU, and the variable DON for
        the fragmented NAL unit is derived as\n   equal to the value of the DONL field.
        \ Otherwise (sprop-max-don-diff\n   is equal to 0 for all the RTP streams,
        or the S bit is equal to 0),\n   the DONL field MUST NOT be present in the
        FU.\n   A non-fragmented NAL unit MUST NOT be transmitted in one FU; i.e.,\n
        \  the Start bit and End bit must not both be set to 1 in the same FU\n   header.\n
        \  The FU payload consists of fragments of the payload of the fragmented\n
        \  NAL unit so that if the FU payloads of consecutive FUs, starting with\n
        \  an FU with the S bit equal to 1 and ending with an FU with the E bit\n
        \  equal to 1, are sequentially concatenated, the payload of the\n   fragmented
        NAL unit can be reconstructed.  The NAL unit header of the\n   fragmented
        NAL unit is not included as such in the FU payload, but\n   rather the information
        of the NAL unit header of the fragmented NAL\n   unit is conveyed in F, LayerId,
        and TID fields of the FU payload\n   headers of the FUs and the FuType field
        of the FU header of the FUs.\n   An FU payload MUST NOT be empty.\n   If an
        FU is lost, the receiver SHOULD discard all following\n   fragmentation units
        in transmission order corresponding to the same\n   fragmented NAL unit, unless
        the decoder in the receiver is known to\n   be prepared to gracefully handle
        incomplete NAL units.\n   A receiver in an endpoint or in a MANE MAY aggregate
        the first n-1\n   fragments of a NAL unit to an (incomplete) NAL unit, even
        if fragment\n   n of that NAL unit is not received.  In this case, the\n   forbidden_zero_bit
        of the NAL unit MUST be set to 1 to indicate a\n   syntax violation.\n"
      title: 4.4.3.  Fragmentation Units
    - contents:
      - "4.4.4.  PACI Packets\n   This section specifies the PACI packet structure.
        \ The basic payload\n   header specified in this memo is intentionally limited
        to the 16 bits\n   of the NAL unit header so to keep the packetization overhead
        to a\n   minimum.  However, cases have been identified where it is advisable\n
        \  to include control information in an easily accessible position in\n   the
        packet header, despite the additional overhead.  One such control\n   information
        is the TSCI as specified in Section 4.5.  PACI packets\n   carry this and
        future, similar structures.\n   The PACI packet structure is based on a payload
        header extension\n   mechanism that is generic and extensible to carry payload
        header\n   extensions.  In this section, the focus lies on the use within
        this\n   specification.  Section 4.4.4.2 provides guidance for the\n   specification
        designers in how to employ the extension mechanism in\n   future specifications.\n
        \  A PACI packet consists of a payload header (denoted as PayloadHdr),\n   for
        which the structure follows what is described in Section 4.2.\n   The payload
        header is followed by the fields A, cType, PHSsize,\n   F[0..2], and Y.\n
        \  Figure 11 shows a PACI packet in compliance with this memo, i.e.,\n   without
        any extensions.\n    0                   1                   2                   3\n
        \   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |    PayloadHdr (Type=50)       |A|   cType   | PHSsize |F0..2|Y|\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |        Payload Header Extension Structure (PHES)              |\n   |=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=|\n
        \  |                                                               |\n   |
        \                 PACI payload: NAL unit                       |\n   |                   .
        . .                                       |\n   |                                                               |\n
        \  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |
        \                              :...OPTIONAL RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \              Figure 11: The Structure of a PACI\n   The fields in the payload
        header are set as follows.  The F bit MUST\n   be equal to 0.  The Type field
        MUST be equal to 50.  The value of\n   LayerId MUST be a copy of the LayerId
        field of the PACI payload NAL\n   unit or NAL-unit-like structure.  The value
        of TID MUST be a copy of\n   the TID field of the PACI payload NAL unit or
        NAL-unit-like\n   structure.\n   The semantics of other fields are as follows:\n
        \  A: 1 bit\n      Copy of the F bit of the PACI payload NAL unit or NAL-unit-like\n
        \     structure.\n   cType: 6 bits\n      Copy of the Type field of the PACI
        payload NAL unit or NAL-unit-\n      like structure.\n   PHSsize: 5 bits\n
        \     Indicates the length of the PHES field.  The value is limited to\n      be
        less than or equal to 32 octets, to simplify encoder design for\n      MTU
        size matching.\n   F0:\n      This field equal to 1 specifies the presence
        of a temporal\n      scalability support extension in the PHES.\n   F1, F2:\n
        \     MUST be 0, available for future extensions, see Section 4.4.4.2.\n      Receivers
        compliant with this version of the HEVC payload format\n      MUST ignore
        F1=1 and/or F2=1, and also ignore any information in\n      the PHES indicated
        as present by F1=1 and/or F2=1.\n         Informative note: The receiver can
        do that by first decoding\n         information associated with F0=1, and
        then skipping over any\n         remaining bytes of the PHES based on the
        value of PHSsize.\n   Y: 1 bit\n      MUST be 0, available for future extensions,
        see Section 4.4.4.2.\n      Receivers compliant with this version of the HEVC
        payload format\n      MUST ignore Y=1, and also ignore any information in
        the PHES\n      indicated as present by Y.\n   PHES: variable number of octets\n
        \     A variable number of octets as indicated by the value of PHSsize.\n
        \  PACI Payload:\n      The single NAL unit packet or NAL-unit-like structure
        (such as: FU\n      or AP) to be carried, not including the first two octets.\n
        \        Informative note: The first two octets of the NAL unit or NAL-\n
        \        unit-like structure carried in the PACI payload are not\n         included
        in the PACI payload.  Rather, the respective values\n         are copied in
        locations of the PayloadHdr of the RTP packet.\n         This design offers
        two advantages: first, the overall structure\n         of the payload header
        is preserved, i.e., there is no special\n         case of payload header structure
        that needs to be implemented\n         for PACI.  Second, no additional overhead
        is introduced.\n      A PACI payload MAY be a single NAL unit, an FU, or an
        AP.  PACIs\n      MUST NOT be fragmented or aggregated.  The following subsection\n
        \     documents the reasons for these design choices.\n"
      - contents:
        - "4.4.4.1.  Reasons for the PACI Rules (Informative)\n   A PACI cannot be
          fragmented.  If a PACI could be fragmented, and a\n   fragment other than
          the first fragment got lost, access to the\n   information in the PACI would
          not be possible.  Therefore, a PACI\n   must not be fragmented.  In other
          words, an FU must not carry\n   (fragments of) a PACI.\n   A PACI cannot
          be aggregated.  Aggregation of PACIs is inadvisable\n   from a compression
          viewpoint, as, in many cases, several to be\n   aggregated NAL units would
          share identical PACI fields and values\n   which would be carried redundantly
          for no reason.  Most, if not all,\n   of the practical effects of PACI aggregation
          can be achieved by\n   aggregating NAL units and bundling them with a PACI
          (see below).\n   Therefore, a PACI must not be aggregated.  In other words,
          an AP must\n   not contain a PACI.\n   The payload of a PACI can be a fragment.
          \ Both middleboxes and\n   sending systems with inflexible (often hardware-based)
          encoders\n   occasionally find themselves in situations where a PACI and
          its\n   headers, combined, are larger than the MTU size.  In such a scenario,\n
          \  the middlebox or sender can fragment the NAL unit and encapsulate the\n
          \  fragment in a PACI.  Doing so preserves the payload header extension\n
          \  information for all fragments, allowing downstream middleboxes and\n
          \  the receiver to take advantage of that information.  Therefore, a\n   sender
          may place a fragment into a PACI, and a receiver must be able\n   to handle
          such a PACI.\n   The payload of a PACI can be an aggregation NAL unit.  HEVC\n
          \  bitstreams can contain unevenly sized and/or small (when compared to\n
          \  the MTU size) NAL units.  In order to efficiently packetize such\n   small
          NAL units, APs were introduced.  The benefits of APs are\n   independent
          from the need for a payload header extension.  Therefore,\n   a sender may
          place an AP into a PACI, and a receiver must be able to\n   handle such
          a PACI.\n"
        title: 4.4.4.1.  Reasons for the PACI Rules (Informative)
      - contents:
        - "4.4.4.2.  PACI Extensions (Informative)\n   This section includes recommendations
          for future specification\n   designers on how to extent the PACI syntax
          to accommodate future\n   extensions.  Obviously, designers are free to
          specify whatever\n   appears to be appropriate to them at the time of their
          design.\n   However, a lot of thought has been invested into the extension\n
          \  mechanism described below, and we suggest that deviations from it\n   warrant
          a good explanation.\n   This memo defines only a single payload header extension
          (TSCI,\n   described in Section 4.5); therefore, only the F0 bit carries\n
          \  semantics.  F1 and F2 are already named (and not just marked as\n   reserved,
          as a typical video spec designer would do).  They are\n   intended to signal
          two additional extensions.  The Y bit allows one\n   to, recursively, add
          further F and Y bits to extend the mechanism\n   beyond three possible payload
          header extensions.  It is suggested to\n   define a new packet type (using
          a different value for Type) when\n   assigning the F1, F2, or Y bits different
          semantics than what is\n   suggested below.\n   When a Y bit is set, an
          8-bit flag-extension is inserted after the Y\n   bit.  A flag-extension
          consists of 7 flags F[n..n+6], and another Y\n   bit.\n   The basic PACI
          header already includes F0, F1, and F2.  Therefore,\n   the Fx bits in the
          first flag-extensions are numbered F3, F4, ...,\n   F9; the F bits in the
          second flag-extension are numbered F10, F11,\n   ..., F16, and so forth.
          \ As a result, at least three Fx bits are\n   always in the PACI, but the
          number of Fx bits (and associated types\n   of extensions) can be increased
          by setting the next Y bit and adding\n   an octet of flag-extensions, carrying
          seven flags and another Y bit.\n   The size of this list of flags is subject
          to the limits specified in\n   Section 4.4.4 (32 octets for all flag-extensions
          and the PHES\n   information combined).\n   Each of the F bits can indicate
          either the presence or the absence of\n   certain information in the Payload
          Header Extension Structure (PHES).\n   When a spec developer devises a new
          syntax that takes advantage of\n   the PACI extension mechanism, he/she
          must follow the constraints\n   listed below; otherwise, the extension mechanism
          may break.\n      1) The fields added for a particular Fx bit MUST be fixed
          in\n         length and not depend on what other Fx bits are set (no parsing\n
          \        dependency).\n      2) The Fx bits must be assigned in order.\n
          \     3) An implementation that supports the n-th Fn bit for any value\n
          \        of n must understand the syntax (though not necessarily the\n         semantics)
          of the fields Fk (with k < n), so as to be able to\n         either use
          those bits when present, or at least be able to skip\n         over them.\n"
        title: 4.4.4.2.  PACI Extensions (Informative)
      title: 4.4.4.  PACI Packets
    title: 4.4.  Payload Structures
  - contents:
    - "4.5.  Temporal Scalability Control Information\n   This section describes the
      single payload header extension defined in\n   this specification, known as
      TSCI.  If, in the future, additional\n   payload header extensions become necessary,
      they could be specified\n   in this section of an updated version of this document,
      or in their\n   own documents.\n   When F0 is set to 1 in a PACI, this specifies
      that the PHES field\n   includes the TSCI fields TL0PICIDX, IrapPicID, S, and
      E as follows:\n   0                   1                   2                   3\n
      \  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |    PayloadHdr (Type=50)       |A|   cType   | PHSsize |F0..2|Y|\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |   TL0PICIDX   |   IrapPicID   |S|E|    RES    |               |\n   |-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      \              |\n   |                           ....                                |\n
      \  |               PACI payload: NAL unit                          |\n   |                                                               |\n
      \  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |                               :...OPTIONAL
      RTP padding        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  Figure 12: The Structure of a PACI with a PHES Containing a TSCI\n   TL0PICIDX
      (8 bits)\n      When present, the TL0PICIDX field MUST be set to equal to\n
      \     temporal_sub_layer_zero_idx as specified in Section D.3.22 of\n      [HEVC]
      for the access unit containing the NAL unit in the PACI.\n   IrapPicID (8 bits)\n
      \     When present, the IrapPicID field MUST be set to equal to\n      irap_pic_id
      as specified in Section D.3.22 of [HEVC] for the\n      access unit containing
      the NAL unit in the PACI.\n   S (1 bit)\n      The S bit MUST be set to 1 if
      any of the following conditions is\n      true and MUST be set to 0 otherwise:\n
      \     o  The NAL unit in the payload of the PACI is the first VCL NAL\n         unit,
      in decoding order, of a picture.\n      o  The NAL unit in the payload of the
      PACI is an AP, and the NAL\n         unit in the first contained aggregation
      unit is the first VCL\n         NAL unit, in decoding order, of a picture.\n
      \     o  The NAL unit in the payload of the PACI is an FU with its S bit\n         equal
      to 1 and the FU payload containing a fragment of the\n         first VCL NAL
      unit, in decoding order, of a picture.\n   E (1 bit)\n      The E bit MUST be
      set to 1 if any of the following conditions is\n      true and MUST be set to
      0 otherwise:\n      o  The NAL unit in the payload of the PACI is the last VCL
      NAL\n         unit, in decoding order, of a picture.\n      o  The NAL unit
      in the payload of the PACI is an AP and the NAL\n         unit in the last contained
      aggregation unit is the last VCL NAL\n         unit, in decoding order, of a
      picture.\n      o  The NAL unit in the payload of the PACI is an FU with its
      E bit\n         equal to 1 and the FU payload containing a fragment of the last\n
      \        VCL NAL unit, in decoding order, of a picture.\n   RES (6 bits)\n      MUST
      be equal to 0.  Reserved for future extensions.\n   The value of PHSsize MUST
      be set to 3.  Receivers MUST allow other\n   values of the fields F0, F1, F2,
      Y, and PHSsize, and MUST ignore any\n   additional fields, when present, than
      specified above in the PHES.\n"
    title: 4.5.  Temporal Scalability Control Information
  - contents:
    - "4.6.  Decoding Order Number\n   For each NAL unit, the variable AbsDon is derived,
      representing the\n   decoding order number that is indicative of the NAL unit
      decoding\n   order.\n   Let NAL unit n be the n-th NAL unit in transmission
      order within an\n   RTP stream.\n   If sprop-max-don-diff is equal to 0 for
      all the RTP streams carrying\n   the HEVC bitstream, AbsDon[n], the value of
      AbsDon for NAL unit n, is\n   derived as equal to n.\n   Otherwise (sprop-max-don-diff
      is greater than 0 for any of the RTP\n   streams), AbsDon[n] is derived as follows,
      where DON[n] is the value\n   of the variable DON for NAL unit n:\n   o  If
      n is equal to 0 (i.e., NAL unit n is the very first NAL unit in\n      transmission
      order), AbsDon[0] is set equal to DON[0].\n   o  Otherwise (n is greater than
      0), the following applies for\n      derivation of AbsDon[n]:\n      If DON[n]
      == DON[n-1],\n          AbsDon[n] = AbsDon[n-1]\n      If (DON[n] > DON[n-1]
      and DON[n] - DON[n-1] < 32768),\n          AbsDon[n] = AbsDon[n-1] + DON[n]
      - DON[n-1]\n      If (DON[n] < DON[n-1] and DON[n-1] - DON[n] >= 32768),\n          AbsDon[n]
      = AbsDon[n-1] + 65536 - DON[n-1] + DON[n]\n      If (DON[n] > DON[n-1] and DON[n]
      - DON[n-1] >= 32768),\n          AbsDon[n] = AbsDon[n-1] - (DON[n-1] + 65536
      -\n          DON[n])\n      If (DON[n] < DON[n-1] and DON[n-1] - DON[n] < 32768),\n
      \         AbsDon[n] = AbsDon[n-1] - (DON[n-1] - DON[n])\n   For any two NAL
      units m and n, the following applies:\n   o  AbsDon[n] greater than AbsDon[m]
      indicates that NAL unit n follows\n      NAL unit m in NAL unit decoding order.\n
      \  o  When AbsDon[n] is equal to AbsDon[m], the NAL unit decoding order\n      of
      the two NAL units can be in either order.\n   o  AbsDon[n] less than AbsDon[m]
      indicates that NAL unit n precedes\n      NAL unit m in decoding order.\n         Informative
      note: When two consecutive NAL units in the NAL\n         unit decoding order
      have different values of AbsDon, the\n         absolute difference between the
      two AbsDon values may be\n         greater than or equal to 1.\n         Informative
      note: There are multiple reasons to allow for the\n         absolute difference
      of the values of AbsDon for two consecutive\n         NAL units in the NAL unit
      decoding order to be greater than\n         one.  An increment by one is not
      required, as at the time of\n         associating values of AbsDon to NAL units,
      it may not be known\n         whether all NAL units are to be delivered to the
      receiver.  For\n         example, a gateway may not forward VCL NAL units of
      higher sub-\n         layers or some SEI NAL units when there is congestion
      in the\n         network.  In another example, the first intra-coded picture
      of\n         a pre-encoded clip is transmitted in advance to ensure that it\n
      \        is readily available in the receiver, and when transmitting the\n         first
      intra-coded picture, the originator does not exactly know\n         how many
      NAL units will be encoded before the first intra-coded\n         picture of
      the pre-encoded clip follows in decoding order.\n         Thus, the values of
      AbsDon for the NAL units of the first\n         intra-coded picture of the pre-encoded
      clip have to be\n         estimated when they are transmitted, and gaps in values
      of\n         AbsDon may occur.  Another example is MRST or MRMT with sprop-\n
      \        max-don-diff greater than 0, where the AbsDon values must\n         indicate
      cross-layer decoding order for NAL units conveyed in\n         all the RTP streams.\n"
    title: 4.6.  Decoding Order Number
  title: 4.  RTP Payload Format
- contents:
  - "5.  Packetization Rules\n   The following packetization rules apply:\n   o  If
    sprop-max-don-diff is greater than 0 for any of the RTP\n      streams, the transmission
    order of NAL units carried in the RTP\n      stream MAY be different than the
    NAL unit decoding order and the\n      NAL unit output order.  Otherwise (sprop-max-don-diff
    is equal to\n      0 for all the RTP streams), the transmission order of NAL units\n
    \     carried in the RTP stream MUST be the same as the NAL unit\n      decoding
    order and, when tx-mode is equal to \"MRST\" or \"MRMT\",\n      MUST also be
    the same as the NAL unit output order.\n   o  A NAL unit of a small size SHOULD
    be encapsulated in an\n      aggregation packet together with one or more other
    NAL units in\n      order to avoid the unnecessary packetization overhead for
    small\n      NAL units.  For example, non-VCL NAL units such as access unit\n
    \     delimiters, parameter sets, or SEI NAL units are typically small\n      and
    can often be aggregated with VCL NAL units without violating\n      MTU size constraints.\n
    \  o  Each non-VCL NAL unit SHOULD, when possible from an MTU size match\n      viewpoint,
    be encapsulated in an aggregation packet together with\n      its associated VCL
    NAL unit, as typically a non-VCL NAL unit would\n      be meaningless without
    the associated VCL NAL unit being\n      available.\n   o  For carrying exactly
    one NAL unit in an RTP packet, a single NAL\n      unit packet MUST be used.\n"
  title: 5.  Packetization Rules
- contents:
  - "6.  De-packetization Process\n   The general concept behind de-packetization
    is to get the NAL units\n   out of the RTP packets in an RTP stream and all RTP
    streams the RTP\n   stream depends on, if any, and pass them to the decoder in
    the NAL\n   unit decoding order.\n   The de-packetization process is implementation
    dependent.  Therefore,\n   the following description should be seen as an example
    of a suitable\n   implementation.  Other schemes may be used as well, as long
    as the\n   output for the same input is the same as the process described below.\n
    \  The output is the same when the set of output NAL units and their\n   order
    are both identical.  Optimizations relative to the described\n   algorithms are
    possible.\n   All normal RTP mechanisms related to buffer management apply.  In\n
    \  particular, duplicated or outdated RTP packets (as indicated by the\n   RTP
    sequences number and the RTP timestamp) are removed.  To\n   determine the exact
    time for decoding, factors such as a possible\n   intentional delay to allow for
    proper inter-stream synchronization\n   must be factored in.\n   NAL units with
    NAL unit type values in the range of 0 to 47,\n   inclusive, may be passed to
    the decoder.  NAL-unit-like structures\n   with NAL unit type values in the range
    of 48 to 63, inclusive, MUST\n   NOT be passed to the decoder.\n   The receiver
    includes a receiver buffer, which is used to compensate\n   for transmission delay
    jitter within individual RTP streams and\n   across RTP streams, to reorder NAL
    units from transmission order to\n   the NAL unit decoding order, and to recover
    the NAL unit decoding\n   order in MRST or MRMT, when applicable.  In this section,
    the\n   receiver operation is described under the assumption that there is no\n
    \  transmission delay jitter within an RTP stream and across RTP\n   streams.
    \ To make a difference from a practical receiver buffer that\n   is also used
    for compensation of transmission delay jitter, the\n   receiver buffer is hereafter
    called the de-packetization buffer in\n   this section.  Receivers should also
    prepare for transmission delay\n   jitter; that is, either reserve separate buffers
    for transmission\n   delay jitter buffering and de-packetization buffering or
    use a\n   receiver buffer for both transmission delay jitter and de-\n   packetization.
    \ Moreover, receivers should take transmission delay\n   jitter into account in
    the buffering operation, e.g., by additional\n   initial buffering before starting
    of decoding and playback.\n   When sprop-max-don-diff is equal to 0 for all the
    received RTP\n   streams, the de-packetization buffer size is zero bytes, and
    the\n   process described in the remainder of this paragraph applies.  When\n
    \  there is only one RTP stream received, the NAL units carried in the\n   single
    RTP stream are directly passed to the decoder in their\n   transmission order,
    which is identical to their decoding order.  When\n   there is more than one RTP
    stream received, the NAL units carried in\n   the multiple RTP streams are passed
    to the decoder in their NTP\n   timestamp order.  When there are several NAL units
    of different RTP\n   streams with the same NTP timestamp, the order to pass them
    to the\n   decoder is their dependency order, where NAL units of a dependee RTP\n
    \  stream are passed to the decoder prior to the NAL units of the\n   dependent
    RTP stream.  When there are several NAL units of the same\n   RTP stream with
    the same NTP timestamp, the order to pass them to the\n   decoder is their transmission
    order.\n      Informative note: The mapping between RTP and NTP timestamps is\n
    \     conveyed in RTCP SR packets.  In addition, the mechanisms for\n      faster
    media timestamp synchronization discussed in [RFC6051] may\n      be used to speed
    up the acquisition of the RTP-to-wall-clock\n      mapping.\n   When sprop-max-don-diff
    is greater than 0 for any the received RTP\n   streams, the process described
    in the remainder of this section\n   applies.\n   There are two buffering states
    in the receiver: initial buffering and\n   buffering while playing.  Initial buffering
    starts when the reception\n   is initialized.  After initial buffering, decoding
    and playback are\n   started, and the buffering-while-playing mode is used.\n
    \  Regardless of the buffering state, the receiver stores incoming NAL\n   units,
    in reception order, into the de-packetization buffer.  NAL\n   units carried in
    RTP packets are stored in the de-packetization\n   buffer individually, and the
    value of AbsDon is calculated and stored\n   for each NAL unit.  When MRST or
    MRMT is in use, NAL units of all RTP\n   streams of a bitstream are stored in
    the same de-packetization\n   buffer.  When NAL units carried in any two RTP streams
    are available\n   to be placed into the de-packetization buffer, those NAL units\n
    \  carried in the RTP stream that is lower in the dependency tree are\n   placed
    into the buffer first.  For example, if RTP stream A depends\n   on RTP stream
    B, then NAL units carried in RTP stream B are placed\n   into the buffer first.\n
    \  Initial buffering lasts until condition A (the difference between the\n   greatest
    and smallest AbsDon values of the NAL units in the de-\n   packetization buffer
    is greater than or equal to the value of sprop-\n   max-don-diff of the highest
    RTP stream) or condition B (the number of\n   NAL units in the de-packetization
    buffer is greater than the value of\n   sprop-depack-buf-nalus) is true.\n   After
    initial buffering, whenever condition A or condition B is true,\n   the following
    operation is repeatedly applied until both condition A\n   and condition B become
    false:\n      o  The NAL unit in the de-packetization buffer with the smallest\n
    \        value of AbsDon is removed from the de-packetization buffer and\n         passed
    to the decoder.\n   When no more NAL units are flowing into the de-packetization
    buffer,\n   all NAL units remaining in the de-packetization buffer are removed\n
    \  from the buffer and passed to the decoder in the order of increasing\n   AbsDon
    values.\n"
  title: 6.  De-packetization Process
- contents:
  - "7.  Payload Format Parameters\n   This section specifies the parameters that
    MAY be used to select\n   optional features of the payload format and certain
    features or\n   properties of the bitstream or the RTP stream.  The parameters
    are\n   specified here as part of the media type registration for the HEVC\n   codec.
    \ A mapping of the parameters into the Session Description\n   Protocol (SDP)
    [RFC4566] is also provided for applications that use\n   SDP.  Equivalent parameters
    could be defined elsewhere for use with\n   control protocols that do not use
    SDP.\n"
  - contents:
    - "7.1.  Media Type Registration\n   The media subtype for the HEVC codec is allocated
      from the IETF tree.\n   The receiver MUST ignore any unrecognized parameter.\n
      \  Type name:     video\n   Subtype name:  H265\n   Required parameters: none\n
      \  OPTIONAL parameters:\n      profile-space, tier-flag, profile-id, profile-compatibility-\n
      \     indicator, interop-constraints, and level-id:\n         These parameters
      indicate the profile, tier, default level, and\n         some constraints of
      the bitstream carried by the RTP stream and\n         all RTP streams the RTP
      stream depends on, or a specific set of\n         the profile, tier, default
      level, and some constraints the\n         receiver supports.\n         The profile
      and some constraints are indicated collectively by\n         profile-space,
      profile-id, profile-compatibility-indicator, and\n         interop-constraints.
      \ The profile specifies the subset of\n         coding tools that may have been
      used to generate the bitstream\n         or that the receiver supports.\n            Informative
      note: There are 32 values of profile-id, and\n            there are 32 flags
      in profile-compatibility-indicator, each\n            flag corresponding to
      one value of profile-id.  According to\n            HEVC version 1 in [HEVC],
      when more than one of the 32 flags\n            is set for a bitstream, the
      bitstream would comply with all\n            the profiles corresponding to the
      set flags.  However, in a\n            draft of HEVC version 2 in [HEVCv2],
      Subclause A.3.5, 19\n            Format Range Extensions profiles have been
      specified, all\n            using the same value of profile-id (4), differentiated
      by\n            some of the 48 bits in interop-constraints; this (rather\n            unexpected
      way of profile signaling) means that one of the\n            32 flags may correspond
      to multiple profiles.  To be able to\n            support whatever HEVC extension
      profile that might be\n            specified and indicated using profile-space,
      profile-id,\n            profile-compatibility-indicator, and interop-constraints
      in\n            the future, it would be safe to require symmetric use of\n            these
      parameters in SDP offer/answer unless recv-sub-layer-\n            id is included
      in the SDP answer for choosing one of the\n            sub-layers offered.\n
      \        The tier is indicated by tier-flag.  The default level is\n         indicated
      by level-id.  The tier and the default level specify\n         the limits on
      values of syntax elements or arithmetic\n         combinations of values of
      syntax elements that are followed\n         when generating the bitstream or
      that the receiver supports.\n         A set of profile-space, tier-flag, profile-id,
      profile-\n         compatibility-indicator, interop-constraints, and level-id\n
      \        parameters ptlA is said to be consistent with another set of\n         these
      parameters ptlB if any decoder that conforms to the\n         profile, tier,
      level, and constraints indicated by ptlB can\n         decode any bitstream
      that conforms to the profile, tier, level,\n         and constraints indicated
      by ptlA.\n         In SDP offer/answer, when the SDP answer does not include
      the\n         recv-sub-layer-id parameter that is less than the sprop-sub-\n
      \        layer-id parameter in the SDP offer, the following applies:\n            o
      \ The profile-space, tier-flag, profile-id, profile-\n               compatibility-indicator,
      and interop-constraints\n               parameters MUST be used symmetrically,
      i.e., the value of\n               each of these parameters in the offer MUST
      be the same as\n               that in the answer, either explicitly signaled
      or\n               implicitly inferred.\n            o  The level-id parameter
      is changeable as long as the\n               highest level indicated by the
      answer is either equal to\n               or lower than that in the offer.  Note
      that the highest\n               level is indicated by level-id and max-recv-level-id\n
      \              together.\n         In SDP offer/answer, when the SDP answer
      does include the recv-\n         sub-layer-id parameter that is less than the
      sprop-sub-layer-id\n         parameter in the SDP offer, the set of profile-space,
      tier-\n         flag, profile-id, profile-compatibility-indicator, interop-\n
      \        constraints, and level-id parameters included in the answer\n         MUST
      be consistent with that for the chosen sub-layer\n         representation as
      indicated in the SDP offer, with the\n         exception that the level-id parameter
      in the SDP answer is\n         changeable as long as the highest level indicated
      by the answer\n         is either lower than or equal to that in the offer.\n
      \        More specifications of these parameters, including how they\n         relate
      to the values of the profile, tier, and level syntax\n         elements specified
      in [HEVC] are provided below.\n      profile-space, profile-id:\n         The
      value of profile-space MUST be in the range of 0 to 3,\n         inclusive.
      \ The value of profile-id MUST be in the range of 0\n         to 31, inclusive.\n
      \        When profile-space is not present, a value of 0 MUST be\n         inferred.
      \ When profile-id is not present, a value of 1 (i.e.,\n         the Main profile)
      MUST be inferred.\n         When used to indicate properties of a bitstream,
      profile-space\n         and profile-id are derived from the profile, tier, and
      level\n         syntax elements in SPS or VPS NAL units as follows, where\n
      \        general_profile_space, general_profile_idc,\n         sub_layer_profile_space[j],
      and sub_layer_profile_idc[j] are\n         specified in [HEVC]:\n            If
      the RTP stream is the highest RTP stream, the following\n            applies:\n
      \           o profile-space = general_profile_space\n            o profile-id
      = general_profile_idc\n            Otherwise (the RTP stream is a dependee RTP
      stream), the\n            following applies, with j being the value of the sprop-sub-\n
      \           layer-id parameter:\n            o profile-space = sub_layer_profile_space[j]\n
      \           o profile-id = sub_layer_profile_idc[j]\n      tier-flag, level-id:\n
      \        The value of tier-flag MUST be in the range of 0 to 1,\n         inclusive.
      \ The value of level-id MUST be in the range of 0 to\n         255, inclusive.\n
      \        If the tier-flag and level-id parameters are used to indicate\n         properties
      of a bitstream, they indicate the tier and the\n         highest level the bitstream
      complies with.\n         If the tier-flag and level-id parameters are used for\n
      \        capability exchange, the following applies.  If max-recv-level-\n         id
      is not present, the default level defined by level-id\n         indicates the
      highest level the codec wishes to support.\n         Otherwise, max-recv-level-id
      indicates the highest level the\n         codec supports for receiving.  For
      either receiving or sending,\n         all levels that are lower than the highest
      level supported MUST\n         also be supported.\n         If no tier-flag
      is present, a value of 0 MUST be inferred; if\n         no level-id is present,
      a value of 93 (i.e., level 3.1) MUST be\n         inferred.\n         When used
      to indicate properties of a bitstream, the tier-flag\n         and level-id
      parameters are derived from the profile, tier, and\n         level syntax elements
      in SPS or VPS NAL units as follows, where\n         general_tier_flag, general_level_idc,
      sub_layer_tier_flag[j],\n         and sub_layer_level_idc[j] are specified in
      [HEVC]:\n            If the RTP stream is the highest RTP stream, the following\n
      \           applies:\n            o tier-flag = general_tier_flag\n            o
      level-id = general_level_idc\n            Otherwise (the RTP stream is a dependee
      RTP stream), the\n            following applies, with j being the value of the
      sprop-sub-\n            layer-id parameter:\n            o tier-flag = sub_layer_tier_flag[j]\n
      \           o level-id = sub_layer_level_idc[j]\n      interop-constraints:\n
      \        A base16 [RFC4648] (hexadecimal) representation of six bytes of\n         data,
      consisting of progressive_source_flag,\n         interlaced_source_flag, non_packed_constraint_flag,\n
      \        frame_only_constraint_flag, and reserved_zero_44bits.\n         If
      the interop-constraints parameter is not present, the\n         following MUST
      be inferred:\n            o progressive_source_flag = 1\n            o interlaced_source_flag
      = 0\n            o non_packed_constraint_flag = 1\n            o frame_only_constraint_flag
      = 1\n            o reserved_zero_44bits = 0\n         When the interop-constraints
      parameter is used to indicate\n         properties of a bitstream, the following
      applies, where\n         general_progressive_source_flag,\n         general_interlaced_source_flag,\n
      \        general_non_packed_constraint_flag,\n         general_non_packed_constraint_flag,\n
      \        general_frame_only_constraint_flag,\n         general_reserved_zero_44bits,\n
      \        sub_layer_progressive_source_flag[j],\n         sub_layer_interlaced_source_flag[j],\n
      \        sub_layer_non_packed_constraint_flag[j],\n         sub_layer_frame_only_constraint_flag[j],
      and\n         sub_layer_reserved_zero_44bits[j] are specified in [HEVC]:\n            If
      the RTP stream is the highest RTP stream, the following\n            applies:\n
      \           o progressive_source_flag = general_progressive_source_flag\n            o
      interlaced_source_flag = general_interlaced_source_flag\n            o non_packed_constraint_flag
      =\n                 general_non_packed_constraint_flag\n            o frame_only_constraint_flag
      =\n                 general_frame_only_constraint_flag\n            o reserved_zero_44bits
      = general_reserved_zero_44bits\n            Otherwise (the RTP stream is a dependee
      RTP stream), the\n            following applies, with j being the value of the
      sprop-sub-\n            layer-id parameter:\n            o progressive_source_flag
      =\n                 sub_layer_progressive_source_flag[j]\n            o interlaced_source_flag
      =\n                 sub_layer_interlaced_source_flag[j]\n            o non_packed_constraint_flag
      =\n                 sub_layer_non_packed_constraint_flag[j]\n            o frame_only_constraint_flag
      =\n                 sub_layer_frame_only_constraint_flag[j]\n            o reserved_zero_44bits
      = sub_layer_reserved_zero_44bits[j]\n            Using interop-constraints for
      capability exchange results in\n            a requirement on any bitstream to
      be compliant with the\n            interop-constraints.\n      profile-compatibility-indicator:\n
      \        A base16 [RFC4648] representation of four bytes of data.\n         When
      profile-compatibility-indicator is used to indicate\n         properties of
      a bitstream, the following applies, where\n         general_profile_compatibility_flag[j]
      and\n         sub_layer_profile_compatibility_flag[i][j] are specified in\n
      \        [HEVC]:\n            The profile-compatibility-indicator in this case
      indicates\n            additional profiles to the profile defined by profile-space,\n
      \           profile-id, and interop-constraints the bitstream conforms\n            to.
      \ A decoder that conforms to any of all the profiles the\n            bitstream
      conforms to would be capable of decoding the\n            bitstream.  These
      additional profiles are defined by\n            profile-space, each set bit
      of profile-compatibility-\n            indicator, and interop-constraints.\n
      \           If the RTP stream is the highest RTP stream, the following\n            applies
      for each value of j in the range of 0 to 31,\n            inclusive:\n            o
      bit j of profile-compatibility-indicator =\n                 general_profile_compatibility_flag[j]\n
      \           Otherwise (the RTP stream is a dependee RTP stream), the\n            following
      applies for i equal to sprop-sub-layer-id and for\n            each value of
      j in the range of 0 to 31, inclusive:\n            o bit j of profile-compatibility-indicator
      =\n                 sub_layer_profile_compatibility_flag[i][j]\n         Using
      profile-compatibility-indicator for capability exchange\n         results in
      a requirement on any bitstream to be compliant with\n         the profile-compatibility-indicator.
      \ This is intended to\n         handle cases where any future HEVC profile is
      defined as an\n         intersection of two or more profiles.\n         If this
      parameter is not present, this parameter defaults to\n         the following:
      bit j, with j equal to profile-id, of profile-\n         compatibility-indicator
      is inferred to be equal to 1, and all\n         other bits are inferred to be
      equal to 0.\n      sprop-sub-layer-id:\n         This parameter MAY be used
      to indicate the highest allowed\n         value of TID in the bitstream.  When
      not present, the value of\n         sprop-sub-layer-id is inferred to be equal
      to 6.\n         The value of sprop-sub-layer-id MUST be in the range of 0 to
      6,\n         inclusive.\n      recv-sub-layer-id:\n         This parameter MAY
      be used to signal a receiver's choice of the\n         offered or declared sub-layer
      representations in the sprop-vps.\n         The value of recv-sub-layer-id indicates
      the TID of the highest\n         sub-layer of the bitstream that a receiver
      supports.  When not\n         present, the value of recv-sub-layer-id is inferred
      to be equal\n         to the value of the sprop-sub-layer-id parameter in the
      SDP\n         offer.\n         The value of recv-sub-layer-id MUST be in the
      range of 0 to 6,\n         inclusive.\n      max-recv-level-id:\n         This
      parameter MAY be used to indicate the highest level a\n         receiver supports.
      \ The highest level the receiver supports is\n         equal to the value of
      max-recv-level-id divided by 30.\n         The value of max-recv-level-id MUST
      be in the range of 0 to\n         255, inclusive.\n         When max-recv-level-id
      is not present, the value is inferred to\n         be equal to level-id.\n         max-recv-level-id
      MUST NOT be present when the highest level\n         the receiver supports is
      not higher than the default level.\n      tx-mode:\n         This parameter
      indicates whether the transmission mode is SRST,\n         MRST, or MRMT.\n
      \        The value of tx-mode MUST be equal to \"SRST\", \"MRST\" or \"MRMT\".\n
      \        When not present, the value of tx-mode is inferred to be equal\n         to
      \"SRST\".\n         If the value is equal to \"MRST\", MRST MUST be in use.\n
      \        Otherwise, if the value is equal to \"MRMT\", MRMT MUST be in\n         use.
      \ Otherwise (the value is equal to \"SRST\"), SRST MUST be in\n         use.\n
      \        The value of tx-mode MUST be equal to \"MRST\" for all RTP\n         streams
      in an MRST.\n         The value of tx-mode MUST be equal to \"MRMT\" for all
      RTP\n         streams in an MRMT.\n      sprop-vps:\n         This parameter
      MAY be used to convey any video parameter set\n         NAL unit of the bitstream
      for out-of-band transmission of video\n         parameter sets.  The parameter
      MAY also be used for capability\n         exchange and to indicate sub-stream
      characteristics (i.e.,\n         properties of sub-layer representations as
      defined in [HEVC]).\n         The value of the parameter is a comma-separated
      (',') list of\n         base64 [RFC4648] representations of the video parameter
      set NAL\n         units as specified in Section 7.3.2.1 of [HEVC].\n         The
      sprop-vps parameter MAY contain one or more than one video\n         parameter
      set NAL unit. However, all other video parameter sets\n         contained in
      the sprop-vps parameter MUST be consistent with\n         the first video parameter
      set in the sprop-vps parameter.  A\n         video parameter set vpsB is said
      to be consistent with another\n         video parameter set vpsA if any decoder
      that conforms to the\n         profile, tier, level, and constraints indicated
      by the 12 bytes\n         of data starting from the syntax element general_profile_space\n
      \        to the syntax element general_level_idc, inclusive, in the\n         first
      profile_tier_level( ) syntax structure in vpsA can decode\n         any bitstream
      that conforms to the profile, tier, level, and\n         constraints indicated
      by the 12 bytes of data starting from the\n         syntax element general_profile_space
      to the syntax element\n         general_level_idc, inclusive, in the first profile_tier_level(\n
      \        ) syntax structure in vpsB.\n      sprop-sps:\n         This parameter
      MAY be used to convey sequence parameter set NAL\n         units of the bitstream
      for out-of-band transmission of sequence\n         parameter sets.  The value
      of the parameter is a comma-\n         separated (',') list of base64 [RFC4648]
      representations of the\n         sequence parameter set NAL units as specified
      in Section\n         7.3.2.2 of [HEVC].\n      sprop-pps:\n         This parameter
      MAY be used to convey picture parameter set NAL\n         units of the bitstream
      for out-of-band transmission of picture\n         parameter sets.  The value
      of the parameter is a comma-\n         separated (',') list of base64 [RFC4648]
      representations of the\n         picture parameter set NAL units as specified
      in Section 7.3.2.3\n         of [HEVC].\n      sprop-sei:\n         This parameter
      MAY be used to convey one or more SEI messages\n         that describe bitstream
      characteristics.  When present, a\n         decoder can rely on the bitstream
      characteristics that are\n         described in the SEI messages for the entire
      duration of the\n         session, independently from the persistence scopes
      of the SEI\n         messages as specified in [HEVC].\n         The value of
      the parameter is a comma-separated (',') list of\n         base64 [RFC4648]
      representations of SEI NAL units as specified\n         in Section 7.3.2.4 of
      [HEVC].\n            Informative note: Intentionally, no list of applicable
      or\n            inapplicable SEI messages is specified here.  Conveying\n            certain
      SEI messages in sprop-sei may be sensible in some\n            application scenarios
      and meaningless in others.  However, a\n            few examples are described
      below:\n               1) In an environment where the bitstream was created
      from\n                  film-based source material, and no splicing is going\n
      \                 to occur during the lifetime of the session, the film\n                  grain
      characteristics SEI message or the tone mapping\n                  information
      SEI message are likely meaningful, and\n                  sending them in sprop-sei
      rather than in the bitstream\n                  at each entry point may help
      with saving bits and\n                  allows one to configure the renderer
      only once,\n                  avoiding unwanted artifacts.\n               2)
      The structure of pictures information SEI message in\n                  sprop-sei
      can be used to inform a decoder of\n                  information on the NAL
      unit types, picture-order count\n                  values, and prediction dependencies
      of a sequence of\n                  pictures.  Having such knowledge can be
      helpful for\n                  error recovery.\n               3) Examples for
      SEI messages that would be meaningless to\n                  be conveyed in
      sprop-sei include the decoded picture\n                  hash SEI message (it
      is close to impossible that all\n                  decoded pictures have the
      same hashtag), the display\n                  orientation SEI message when the
      device is a handheld\n                  device (as the display orientation may
      change when the\n                  handheld device is turned around), or the
      filler\n                  payload SEI message (as there is no point in just\n
      \                 having more bits in SDP).\n      max-lsr, max-lps, max-cpb,
      max-dpb, max-br, max-tr, max-tc:\n         These parameters MAY be used to signal
      the capabilities of a\n         receiver implementation.  These parameters MUST
      NOT be used for\n         any other purpose.  The highest level (specified by
      max-recv-\n         level-id) MUST be the highest that the receiver is fully\n
      \        capable of supporting.  max-lsr, max-lps, max-cpb, max-dpb,\n         max-br,
      max-tr, and max-tc MAY be used to indicate capabilities\n         of the receiver
      that extend the required capabilities of the\n         highest level, as specified
      below.\n         When more than one parameter from the set (max-lsr, max-lps,\n
      \        max-cpb, max-dpb, max-br, max-tr, max-tc) is present, the\n         receiver
      MUST support all signaled capabilities simultaneously.\n         For example,
      if both max-lsr and max-br are present, the\n         highest level with the
      extension of both the picture rate and\n         bitrate is supported.  That
      is, the receiver is able to decode\n         bitstreams in which the luma sample
      rate is up to max-lsr\n         (inclusive), the bitrate is up to max-br (inclusive),
      the coded\n         picture buffer size is derived as specified in the semantics
      of\n         the max-br parameter below, and the other properties comply\n         with
      the highest level specified by max-recv-level-id.\n            Informative note:
      When the OPTIONAL media type parameters\n            are used to signal the
      properties of a bitstream, and max-\n            lsr, max-lps, max-cpb, max-dpb,
      max-br, max-tr, and max-tc\n            are not present, the values of profile-space,
      tier-flag,\n            profile-id, profile-compatibility-indicator, interop-\n
      \           constraints, and level-id must always be such that the\n            bitstream
      complies fully with the specified profile, tier,\n            and level.\n      max-lsr:\n
      \        The value of max-lsr is an integer indicating the maximum\n         processing
      rate in units of luma samples per second.  The max-\n         lsr parameter
      signals that the receiver is capable of decoding\n         video at a higher
      rate than is required by the highest level.\n         When max-lsr is signaled,
      the receiver MUST be able to decode\n         bitstreams that conform to the
      highest level, with the\n         exception that the MaxLumaSR value in Table
      A-2 of [HEVC] for\n         the highest level is replaced with the value of
      max-lsr.\n         Senders MAY use this knowledge to send pictures of a given
      size\n         at a higher picture rate than is indicated in the highest\n         level.\n
      \        When not present, the value of max-lsr is inferred to be equal\n         to
      the value of MaxLumaSR given in Table A-2 of [HEVC] for the\n         highest
      level.\n         The value of max-lsr MUST be in the range of MaxLumaSR to 16
      *\n         MaxLumaSR, inclusive, where MaxLumaSR is given in Table A-2 of\n
      \        [HEVC] for the highest level.\n      max-lps:\n         The value of
      max-lps is an integer indicating the maximum\n         picture size in units
      of luma samples.  The max-lps parameter\n         signals that the receiver
      is capable of decoding larger picture\n         sizes than are required by the
      highest level.  When max-lps is\n         signaled, the receiver MUST be able
      to decode bitstreams that\n         conform to the highest level, with the exception
      that the\n         MaxLumaPS value in Table A-1 of [HEVC] for the highest level
      is\n         replaced with the value of max-lps.  Senders MAY use this\n         knowledge
      to send larger pictures at a proportionally lower\n         picture rate than
      is indicated in the highest level.\n         When not present, the value of
      max-lps is inferred to be equal\n         to the value of MaxLumaPS given in
      Table A-1 of [HEVC] for the\n         highest level.\n         The value of
      max-lps MUST be in the range of MaxLumaPS to 16 *\n         MaxLumaPS, inclusive,
      where MaxLumaPS is given in Table A-1 of\n         [HEVC] for the highest level.\n
      \     max-cpb:\n         The value of max-cpb is an integer indicating the maximum
      coded\n         picture buffer size in units of CpbBrVclFactor bits for the
      VCL\n         HRD parameters and in units of CpbBrNalFactor bits for the NAL\n
      \        HRD parameters, where CpbBrVclFactor and CpbBrNalFactor are\n         defined
      in Section A.4 of [HEVC].  The max-cpb parameter\n         signals that the
      receiver has more memory than the minimum\n         amount of coded picture
      buffer memory required by the highest\n         level.  When max-cpb is signaled,
      the receiver MUST be able to\n         decode bitstreams that conform to the
      highest level, with the\n         exception that the MaxCPB value in Table A-1
      of [HEVC] for the\n         highest level is replaced with the value of max-cpb.
      \ Senders\n         MAY use this knowledge to construct coded bitstreams with\n
      \        greater variation of bitrate than can be achieved with the\n         MaxCPB
      value in Table A-1 of [HEVC].\n         When not present, the value of max-cpb
      is inferred to be equal\n         to the value of MaxCPB given in Table A-1
      of [HEVC] for the\n         highest level.\n         The value of max-cpb MUST
      be in the range of MaxCPB to 16 *\n         MaxCPB, inclusive, where MaxLumaCPB
      is given in Table A-1 of\n         [HEVC] for the highest level.\n            Informative
      note: The coded picture buffer is used in the\n            hypothetical reference
      decoder (Annex C of [HEVC]).  The use\n            of the hypothetical reference
      decoder is recommended in HEVC\n            encoders to verify that the produced
      bitstream conforms to\n            the standard and to control the output bitrate.
      \ Thus, the\n            coded picture buffer is conceptually independent of
      any\n            other potential buffers in the receiver, including de-\n            packetization
      and de-jitter buffers.  The coded picture\n            buffer need not be implemented
      in decoders as specified in\n            Annex C of [HEVC], but rather standard-compliant
      decoders\n            can have any buffering arrangements provided that they
      can\n            decode standard-compliant bitstreams.  Thus, in practice,\n
      \           the input buffer for a video decoder can be integrated with\n            de-packetization
      and de-jitter buffers of the receiver.\n      max-dpb:\n         The value of
      max-dpb is an integer indicating the maximum\n         decoded picture buffer
      size in units decoded pictures at the\n         MaxLumaPS for the highest level,
      i.e., the number of decoded\n         pictures at the maximum picture size defined
      by the highest\n         level.  The value of max-dpb MUST be in the range of
      1 to 16,\n         respectively.  The max-dpb parameter signals that the receiver\n
      \        has more memory than the minimum amount of decoded picture\n         buffer
      memory required by default, which is MaxDpbPicBuf as\n         defined in [HEVC]
      (equal to 6).  When max-dpb is signaled, the\n         receiver MUST be able
      to decode bitstreams that conform to the\n         highest level, with the exception
      that the MaxDpbPicBuff value\n         defined in [HEVC] as 6 is replaced with
      the value of max-dpb.\n         Consequently, a receiver that signals max-dpb
      MUST be capable\n         of storing the following number of decoded pictures\n
      \        (MaxDpbSize) in its decoded picture buffer:\n           if( PicSizeInSamplesY
      <= ( MaxLumaPS >> 2 ) )\n              MaxDpbSize = Min( 4 * max-dpb, 16 )\n
      \          else if ( PicSizeInSamplesY <= ( MaxLumaPS >> 1 ) )\n              MaxDpbSize
      = Min( 2 * max-dpb, 16 )\n           else if ( PicSizeInSamplesY <= ( ( 3 *
      MaxLumaPS ) >> 2\n         ) )\n              MaxDpbSize = Min( (4 * max-dpb)
      / 3, 16 )\n           else\n              MaxDpbSize = max-dpb\n         Wherein
      MaxLumaPS given in Table A-1 of [HEVC] for the highest\n         level and PicSizeInSamplesY
      is the current size of each decoded\n         picture in units of luma samples
      as defined in [HEVC].\n         The value of max-dpb MUST be greater than or
      equal to the value\n         of MaxDpbPicBuf (i.e., 6) as defined in [HEVC].
      \ Senders MAY\n         use this knowledge to construct coded bitstreams with
      improved\n         compression.\n         When not present, the value of max-dpb
      is inferred to be equal\n         to the value of MaxDpbPicBuf (i.e., 6) as
      defined in [HEVC].\n            Informative note: This parameter was added primarily
      to\n            complement a similar codepoint in the ITU-T Recommendation\n
      \           H.245, so as to facilitate signaling gateway designs.  The\n            decoded
      picture buffer stores reconstructed samples.  There\n            is no relationship
      between the size of the decoded picture\n            buffer and the buffers
      used in RTP, especially de-\n            packetization and de-jitter buffers.\n
      \     max-br:\n         The value of max-br is an integer indicating the maximum
      video\n         bitrate in units of CpbBrVclFactor bits per second for the VCL\n
      \        HRD parameters and in units of CpbBrNalFactor bits per second\n         for
      the NAL HRD parameters, where CpbBrVclFactor and\n         CpbBrNalFactor are
      defined in Section A.4 of [HEVC].\n         The max-br parameter signals that
      the video decoder of the\n         receiver is capable of decoding video at
      a higher bitrate than\n         is required by the highest level.\n         When
      max-br is signaled, the video codec of the receiver MUST\n         be able to
      decode bitstreams that conform to the highest level,\n         with the following
      exceptions in the limits specified by the\n         highest level:\n            o
      \ The value of max-br replaces the MaxBR value in Table A-2\n               of
      [HEVC] for the highest level.\n            o  When the max-cpb parameter is
      not present, the result of\n               the following formula replaces the
      value of MaxCPB in\n               Table A-1 of [HEVC]:\n               (MaxCPB
      of the highest level) * max-br / (MaxBR of the\n               highest level)\n
      \        For example, if a receiver signals capability for Main profile\n         Level
      2 with max-br equal to 2000, this indicates a maximum\n         video bitrate
      of 2000 kbits/sec for VCL HRD parameters, a\n         maximum video bitrate
      of 2200 kbits/sec for NAL HRD parameters,\n         and a CPB size of 2000000
      bits (2000000 / 1500000 * 1500000).\n         Senders MAY use this knowledge
      to send higher bitrate video as\n         allowed in the level definition of
      Annex A of [HEVC] to achieve\n         improved video quality.\n         When
      not present, the value of max-br is inferred to be equal\n         to the value
      of MaxBR given in Table A-2 of [HEVC] for the\n         highest level.\n         The
      value of max-br MUST be in the range of MaxBR to 16 *\n         MaxBR, inclusive,
      where MaxBR is given in Table A-2 of [HEVC]\n         for the highest level.\n
      \           Informative note: This parameter was added primarily to\n            complement
      a similar codepoint in the ITU-T Recommendation\n            H.245, so as to
      facilitate signaling gateway designs.  The\n            assumption that the
      network is capable of handling such\n            bitrates at any given time
      cannot be made from the value of\n            this parameter.  In particular,
      no conclusion can be drawn\n            that the signaled bitrate is possible
      under congestion\n            control constraints.\n      max-tr:\n         The
      value of max-tr is an integer indication the maximum number\n         of tile
      rows.  The max-tr parameter signals that the receiver\n         is capable of
      decoding video with a larger number of tile rows\n         than the value allowed
      by the highest level.\n         When max-tr is signaled, the receiver MUST be
      able to decode\n         bitstreams that conform to the highest level, with
      the\n         exception that the MaxTileRows value in Table A-1 of [HEVC] for\n
      \        the highest level is replaced with the value of max-tr.\n         Senders
      MAY use this knowledge to send pictures utilizing a\n         larger number
      of tile rows than the value allowed by the\n         highest level.\n         When
      not present, the value of max-tr is inferred to be equal\n         to the value
      of MaxTileRows given in Table A-1 of [HEVC] for\n         the highest level.\n
      \        The value of max-tr MUST be in the range of MaxTileRows to 16 *\n         MaxTileRows,
      inclusive, where MaxTileRows is given in Table A-1\n         of [HEVC] for the
      highest level.\n      max-tc:\n         The value of max-tc is an integer indication
      the maximum number\n         of tile columns.  The max-tc parameter signals
      that the\n         receiver is capable of decoding video with a larger number
      of\n         tile columns than the value allowed by the highest level.\n         When
      max-tc is signaled, the receiver MUST be able to decode\n         bitstreams
      that conform to the highest level, with the\n         exception that the MaxTileCols
      value in Table A-1 of [HEVC] for\n         the highest level is replaced with
      the value of max-tc.\n         Senders MAY use this knowledge to send pictures
      utilizing a\n         larger number of tile columns than the value allowed by
      the\n         highest level.\n         When not present, the value of max-tc
      is inferred to be equal\n         to the value of MaxTileCols given in Table
      A-1 of [HEVC] for\n         the highest level.\n         The value of max-tc
      MUST be in the range of MaxTileCols to 16 *\n         MaxTileCols, inclusive,
      where MaxTileCols is given in Table A-1\n         of [HEVC] for the highest
      level.\n      max-fps:\n         The value of max-fps is an integer indicating
      the maximum\n         picture rate in units of pictures per 100 seconds that
      can be\n         effectively processed by the receiver.  The max-fps parameter\n
      \        MAY be used to signal that the receiver has a constraint in\n         that
      it is not capable of processing video effectively at the\n         full picture
      rate that is implied by the highest level and,\n         when present, one or
      more of the parameters max-lsr, max-lps,\n         and max-br.\n         The
      value of max-fps is not necessarily the picture rate at\n         which the
      maximum picture size can be sent, it constitutes a\n         constraint on maximum
      picture rate for all resolutions.\n            Informative note: The max-fps
      parameter is semantically\n            different from max-lsr, max-lps, max-cpb,
      max-dpb, max-br,\n            max-tr, and max-tc in that max-fps is used to
      signal a\n            constraint, lowering the maximum picture rate from what
      is\n            implied by other parameters.\n         The encoder MUST use
      a picture rate equal to or less than this\n         value.  In cases where the
      max-fps parameter is absent, the\n         encoder is free to choose any picture
      rate according to the\n         highest level and any signaled optional parameters.\n
      \        The value of max-fps MUST be smaller than or equal to the full\n         picture
      rate that is implied by the highest level and, when\n         present, one or
      more of the parameters max-lsr, max-lps, and\n         max-br.\n      sprop-max-don-diff:\n
      \        If tx-mode is equal to \"SRST\" and there is no NAL unit naluA\n         that
      is followed in transmission order by any NAL unit\n         preceding naluA
      in decoding order (i.e., the transmission order\n         of the NAL units is
      the same as the decoding order), the value\n         of this parameter MUST
      be equal to 0.\n         Otherwise, if tx-mode is equal to \"MRST\" or \"MRMT\",
      the\n         decoding order of the NAL units of all the RTP streams is the\n
      \        same as the NAL unit transmission order and the NAL unit output\n         order,
      the value of this parameter MUST be equal to either 0 or\n         1.\n         Otherwise,
      if tx-mode is equal to \"MRST\" or \"MRMT\" and the\n         decoding order
      of the NAL units of all the RTP streams is the\n         same as the NAL unit
      transmission order but not the same as the\n         NAL unit output order,
      the value of this parameter MUST be\n         equal to 1.\n         Otherwise,
      this parameter specifies the maximum absolute\n         difference between the
      decoding order number (i.e., AbsDon)\n         values of any two NAL units naluA
      and naluB, where naluA\n         follows naluB in decoding order and precedes
      naluB in\n         transmission order.\n         The value of sprop-max-don-diff
      MUST be an integer in the range\n         of 0 to 32767, inclusive.\n         When
      not present, the value of sprop-max-don-diff is inferred\n         to be equal
      to 0.\n      sprop-depack-buf-nalus:\n         This parameter specifies the
      maximum number of NAL units that\n         precede a NAL unit in transmission
      order and follow the NAL\n         unit in decoding order.\n         The value
      of sprop-depack-buf-nalus MUST be an integer in the\n         range of 0 to
      32767, inclusive.\n         When not present, the value of sprop-depack-buf-nalus
      is\n         inferred to be equal to 0.\n         When sprop-max-don-diff is
      present and greater than 0, this\n         parameter MUST be present and the
      value MUST be greater than 0.\n      sprop-depack-buf-bytes:\n         This
      parameter signals the required size of the de-\n         packetization buffer
      in units of bytes.  The value of the\n         parameter MUST be greater than
      or equal to the maximum buffer\n         occupancy (in units of bytes) of the
      de-packetization buffer as\n         specified in Section 6.\n         The value
      of sprop-depack-buf-bytes MUST be an integer in the\n         range of 0 to
      4294967295, inclusive.\n         When sprop-max-don-diff is present and greater
      than 0, this\n         parameter MUST be present and the value MUST be greater
      than 0.\n         When not present, the value of sprop-depack-buf-bytes is\n
      \        inferred to be equal to 0.\n            Informative note: The value
      of sprop-depack-buf-bytes\n            indicates the required size of the de-packetization
      buffer\n            only.  When network jitter can occur, an appropriately sized\n
      \           jitter buffer has to be available as well.\n      depack-buf-cap:\n
      \        This parameter signals the capabilities of a receiver\n         implementation
      and indicates the amount of de-packetization\n         buffer space in units
      of bytes that the receiver has available\n         for reconstructing the NAL
      unit decoding order from NAL units\n         carried in one or more RTP streams.
      \ A receiver is able to\n         handle any RTP stream, and all RTP streams
      the RTP stream\n         depends on, when present, for which the value of the
      sprop-\n         depack-buf-bytes parameter is smaller than or equal to this\n
      \        parameter.\n         When not present, the value of depack-buf-cap
      is inferred to be\n         equal to 4294967295.  The value of depack-buf-cap
      MUST be an\n         integer in the range of 1 to 4294967295, inclusive.\n            Informative
      note: depack-buf-cap indicates the maximum\n            possible size of the
      de-packetization buffer of the receiver\n            only, without allowing
      for network jitter.\n      sprop-segmentation-id:\n         This parameter MAY
      be used to signal the segmentation tools\n         present in the bitstream
      and that can be used for\n         parallelization.  The value of sprop-segmentation-id
      MUST be an\n         integer in the range of 0 to 3, inclusive.  When not present,\n
      \        the value of sprop-segmentation-id is inferred to be equal to\n         0.\n
      \        When sprop-segmentation-id is equal to 0, no information about\n         the
      segmentation tools is provided.  When sprop-segmentation-id\n         is equal
      to 1, it indicates that slices are present in the\n         bitstream.  When
      sprop-segmentation-id is equal to 2, it\n         indicates that tiles are present
      in the bitstream.  When sprop-\n         segmentation-id is equal to 3, it indicates
      that WPP is used in\n         the bitstream.\n      sprop-spatial-segmentation-idc:\n
      \        A base16 [RFC4648] representation of the syntax element\n         min_spatial_segmentation_idc
      as specified in [HEVC].  This\n         parameter MAY be used to describe parallelization
      capabilities\n         of the bitstream.\n      dec-parallel-cap:\n         This
      parameter MAY be used to indicate the decoder's additional\n         decoding
      capabilities given the presence of tools enabling\n         parallel decoding,
      such as slices, tiles, and WPP, in the\n         bitstream.  The decoding capability
      of the decoder may vary\n         with the setting of the parallel decoding
      tools present in the\n         bitstream, e.g., the size of the tiles that are
      present in a\n         bitstream.  Therefore, multiple capability points may
      be\n         provided, each indicating the minimum required decoding\n         capability
      that is associated with a parallelism requirement,\n         which is a requirement
      on the bitstream that enables parallel\n         decoding.\n         Each capability
      point is defined as a combination of 1) a\n         parallelism requirement,
      2) a profile (determined by profile-\n         space and profile-id), 3) a highest
      level, and 4) a maximum\n         processing rate, a maximum picture size, and
      a maximum video\n         bitrate that may be equal to or greater than that
      determined by\n         the highest level.  The parameter's syntax in ABNF [RFC5234]
      is\n         as follows:\n         dec-parallel-cap = \"dec-parallel-cap={\"
      cap-point *(\",\"\n                            cap-point) \"}\"\n         cap-point
      = (\"w\" / \"t\") \":\" spatial-seg-idc 1*(\";\"\n                      cap-parameter)\n
      \        spatial-seg-idc = 1*4DIGIT ; (1-4095)\n         cap-parameter = tier-flag
      / level-id / max-lsr\n                         / max-lps / max-br\n         tier-flag
      = \"tier-flag\" EQ (\"0\" / \"1\")\n         level-id  = \"level-id\" EQ 1*3DIGIT
      ; (0-255)\n         max-lsr   = \"max-lsr\" EQ  1*20DIGIT ; (0-\n         18,446,744,073,709,551,615)\n
      \        max-lps   = \"max-lps\" EQ 1*10DIGIT ; (0-4,294,967,295)\n         max-br
      \   = \"max-br\"  EQ 1*20DIGIT ; (0-\n         18,446,744,073,709,551,615)\n
      \        EQ = \"=\"\n         The set of capability points expressed by the
      dec-parallel-cap\n         parameter is enclosed in a pair of curly braces (\"{}\").
      \ Each\n         set of two consecutive capability points is separated by a\n
      \        comma (',').  Within each capability point, each set of two\n         consecutive
      parameters, and, when present, their values, is\n         separated by a semicolon
      (';').\n         The profile of all capability points is determined by profile-\n
      \        space and profile-id, which are outside the dec-parallel-cap\n         parameter.\n
      \        Each capability point starts with an indication of the\n         parallelism
      requirement, which consists of a parallel tool\n         type, which may be
      equal to 'w' or 't', and a decimal value of\n         the spatial-seg-idc parameter.
      \ When the type is 'w', the\n         capability point is valid only for H.265
      bitstreams with WPP in\n         use, i.e., entropy_coding_sync_enabled_flag
      equal to 1.  When\n         the type is 't', the capability point is valid only
      for H.265\n         bitstreams with WPP not in use (i.e.,\n         entropy_coding_sync_enabled_flag
      equal to 0).  The capability-\n         point is valid only for H.265 bitstreams
      with\n         min_spatial_segmentation_idc equal to or greater than spatial-\n
      \        seg-idc.\n         After the parallelism requirement indication, each
      capability\n         point continues with one or more pairs of parameter and
      value\n         in any order for any of the following parameters:\n            o
      tier-flag\n            o level-id\n            o max-lsr\n            o max-lps\n
      \           o max-br\n         At most, one occurrence of each of the above
      five parameters is\n         allowed within each capability point.\n         The
      values of dec-parallel-cap.tier-flag and dec-parallel-\n         cap.level-id
      for a capability point indicate the highest level\n         of the capability
      point.  The values of dec-parallel-cap.max-\n         lsr, dec-parallel-cap.max-lps,
      and dec-parallel-cap.max-br for\n         a capability point indicate the maximum
      processing rate in\n         units of luma samples per second, the maximum picture
      size in\n         units of luma samples, and the maximum video bitrate (in units\n
      \        of CpbBrVclFactor bits per second for the VCL HRD parameters\n         and
      in units of CpbBrNalFactor bits per second for the NAL HRD\n         parameters
      where CpbBrVclFactor and CpbBrNalFactor are defined\n         in Section A.4
      of [HEVC]).\n         When not present, the value of dec-parallel-cap.tier-flag
      is\n         inferred to be equal to the value of tier-flag outside the dec-\n
      \        parallel-cap parameter.  When not present, the value of dec-\n         parallel-cap.level-id
      is inferred to be equal to the value of\n         max-recv-level-id outside
      the dec-parallel-cap parameter.  When\n         not present, the value of dec-parallel-cap.max-lsr,
      dec-\n         parallel-cap.max-lps, or dec-parallel-cap.max-br is inferred
      to\n         be equal to the value of max-lsr, max-lps, or max-br,\n         respectively,
      outside the dec-parallel-cap parameter.\n         The general decoding capability,
      expressed by the set of\n         parameters outside of dec-parallel-cap, is
      defined as the\n         capability point that is determined by the following\n
      \        combination of parameters: 1) the parallelism requirement\n         corresponding
      to the value of sprop-segmentation-id equal to 0\n         for a bitstream,
      2) the profile determined by profile-space,\n         profile-id, profile-compatibility-indicator,
      and interop-\n         constraints, 3) the tier and the highest level determined
      by\n         tier-flag and max-recv-level-id, and 4) the maximum processing\n
      \        rate, the maximum picture size, and the maximum video bitrate\n         determined
      by the highest level.  The general decoding\n         capability MUST NOT be
      included as one of the set of capability\n         points in the dec-parallel-cap
      parameter.\n         For example, the following parameters express the general\n
      \        decoding capability of 720p30 (Level 3.1) plus an additional\n         decoding
      capability of 1080p30 (Level 4) given that the\n         spatially largest tile
      or slice used in the bitstream is equal\n         to or less than 1/3 of the
      picture size:\n            a=fmtp:98 level-id=93;dec-parallel-cap={t:8;level-
      id=120}\n         For another example, the following parameters express an\n
      \        additional decoding capability of 1080p30, using dec-parallel-\n         cap.max-lsr
      and dec-parallel-cap.max-lps, given that WPP is\n         used in the bitstream:\n
      \           a=fmtp:98 level-id=93;dec-parallel-cap={w:8;\n                        max-lsr=62668800;max-lps=2088960}\n
      \           Informative note: When min_spatial_segmentation_idc is\n            present
      in a bitstream and WPP is not used, [HEVC] specifies\n            that there
      is no slice or no tile in the bitstream\n            containing more than 4
      * PicSizeInSamplesY / (\n            min_spatial_segmentation_idc + 4 ) luma
      samples.\n      include-dph:\n         This parameter is used to indicate the
      capability and\n         preference to utilize or include Decoded Picture Hash
      (DPH) SEI\n         messages (see Section D.3.19 of [HEVC]) in the bitstream.
      DPH\n         SEI messages can be used to detect picture corruption so the\n
      \        receiver can request picture repair, see Section 8.  The value\n         is
      a comma-separated list of hash types that is supported or\n         requested
      to be used, each hash type provided as an unsigned\n         integer value (0-255),
      with the hash types listed from most\n         preferred to the least preferred.
      \ Example: \"include-dph=0,2\",\n         which indicates the capability for
      MD5 (most preferred) and\n         Checksum (less preferred).  If the parameter
      is not included or\n         the value contains no hash types, then no capability
      to utilize\n         DPH SEI messages is assumed.  Note that DPH SEI messages
      MAY\n         still be included in the bitstream even when there is no\n         declaration
      of capability to use them, as in general SEI\n         messages do not affect
      the normative decoding process and\n         decoders are allowed to ignore
      SEI messages.\n   Encoding considerations:\n      This type is only defined
      for transfer via RTP (RFC 3550).\n   Security considerations:\n      See Section
      9 of RFC 7798.\n   Published specification:\n      Please refer to RFC 7798
      and its Section 12.\n   Additional information: None\n   File extensions: none\n
      \  Macintosh file type code: none\n   Object identifier or OID: none\n   Person
      & email address to contact for further information:\n      Ye-Kui Wang (yekui.wang@gmail.com)\n
      \  Intended usage: COMMON\n   Author: See Authors' Addresses section of RFC
      7798.\n   Change controller:\n      IETF Audio/Video Transport Payloads working
      group delegated from\n      the IESG.\n"
    title: 7.1.  Media Type Registration
  - contents:
    - "7.2.  SDP Parameters\n   The receiver MUST ignore any parameter unspecified
      in this memo.\n"
    - contents:
      - "7.2.1.  Mapping of Payload Type Parameters to SDP\n   The media type video/H265
        string is mapped to fields in the Session\n   Description Protocol (SDP) [RFC4566]
        as follows:\n   o  The media name in the \"m=\" line of SDP MUST be video.\n
        \  o  The encoding name in the \"a=rtpmap\" line of SDP MUST be H265 (the\n
        \     media subtype).\n   o  The clock rate in the \"a=rtpmap\" line MUST
        be 90000.\n   o  The OPTIONAL parameters profile-space, profile-id, tier-flag,\n
        \     level-id, interop-constraints, profile-compatibility-indicator,\n      sprop-sub-layer-id,
        recv-sub-layer-id, max-recv-level-id, tx-mode,\n      max-lsr, max-lps, max-cpb,
        max-dpb, max-br, max-tr, max-tc, max-\n      fps, sprop-max-don-diff, sprop-depack-buf-nalus,
        sprop-depack-buf-\n      bytes, depack-buf-cap, sprop-segmentation-id, sprop-spatial-\n
        \     segmentation-idc, dec-parallel-cap, and include-dph, when present,\n
        \     MUST be included in the \"a=fmtp\" line of SDP.  This parameter is\n
        \     expressed as a media type string, in the form of a semicolon-\n      separated
        list of parameter=value pairs.\n   o  The OPTIONAL parameters sprop-vps, sprop-sps,
        and sprop-pps, when\n      present, MUST be included in the \"a=fmtp\" line
        of SDP or conveyed\n      using the \"fmtp\" source attribute as specified
        in Section 6.3 of\n      [RFC5576].  For a particular media format (i.e.,
        RTP payload\n      type), sprop-vps sprop-sps, or sprop-pps MUST NOT be both
        included\n      in the \"a=fmtp\" line of SDP and conveyed using the \"fmtp\"
        source\n      attribute.  When included in the \"a=fmtp\" line of SDP, these\n
        \     parameters are expressed as a media type string, in the form of a\n
        \     semicolon-separated list of parameter=value pairs.  When conveyed\n
        \     in the \"a=fmtp\" line of SDP for a particular payload type, the\n      parameters
        sprop-vps, sprop-sps, and sprop-pps MUST be applied to\n      each SSRC with
        the payload type.  When conveyed using the \"fmtp\"\n      source attribute,
        these parameters are only associated with the\n      given source and payload
        type as parts of the \"fmtp\" source\n      attribute.\n         Informative
        note: Conveyance of sprop-vps, sprop-sps, and\n         sprop-pps using the
        \"fmtp\" source attribute allows for out-of-\n         band transport of parameter
        sets in topologies like Topo-Video-\n         switch-MCU as specified in [RFC7667].\n
        \  An example of media representation in SDP is as follows:\n      m=video
        49170 RTP/AVP 98\n      a=rtpmap:98 H265/90000\n      a=fmtp:98 profile-id=1;\n
        \               sprop-vps=<video parameter sets data>\n"
      title: 7.2.1.  Mapping of Payload Type Parameters to SDP
    - contents:
      - "7.2.2.  Usage with SDP Offer/Answer Model\n   When HEVC is offered over RTP
        using SDP in an offer/answer model\n   [RFC3264] for negotiation for unicast
        usage, the following\n   limitations and rules apply:\n   o  The parameters
        identifying a media format configuration for HEVC\n      are profile-space,
        profile-id, tier-flag, level-id, interop-\n      constraints, profile-compatibility-indicator,
        and tx-mode.  These\n      media configuration parameters, except level-id,
        MUST be used\n      symmetrically when the answerer does not include recv-sub-layer-id\n
        \     in the answer for the media format (payload type) or the included\n
        \     recv-sub-layer-id is equal to sprop-sub-layer-id in the offer.\n      The
        answerer MUST:\n      1) maintain all configuration parameters with the values
        remaining\n         the same as in the offer for the media format (payload
        type),\n         with the exception that the value of level-id is changeable
        as\n         long as the highest level indicated by the answer is not higher\n
        \        than that indicated by the offer;\n      2) include in the answer
        the recv-sub-layer-id parameter, with a\n         value less than the sprop-sub-layer-id
        parameter in the offer,\n         for the media format (payload type), and
        maintain all\n         configuration parameters with the values being the
        same as\n         signaled in the sprop-vps for the chosen sub-layer\n         representation,
        with the exception that the value of level-id\n         is changeable as long
        as the highest level indicated by the\n         answer is not higher than
        the level indicated by the sprop-vps\n         in offer for the chosen sub-layer
        representation; or\n      3) remove the media format (payload type) completely
        (when one or\n         more of the parameter values are not supported).\n
        \           Informative note: The above requirement for symmetric use\n            does
        not apply for level-id, and does not apply for the\n            other bitstream
        or RTP stream properties and capability\n            parameters.\n   o  The
        profile-compatibility-indicator, when offered as sendonly,\n      describes
        bitstream properties.  The answerer MAY accept an RTP\n      payload type
        even if the decoder is not capable of handling the\n      profile indicated
        by the profile-space, profile-id, and interop-\n      constraints parameters,
        but capable of any of the profiles\n      indicated by the profile-space,
        profile-compatibility-indicator,\n      and interop-constraints.  However,
        when the profile-compatibility-\n      indicator is used in a recvonly or
        sendrecv media description, the\n      bitstream using this RTP payload type
        is required to conform to\n      all profiles indicated by profile-space,
        profile-compatibility-\n      indicator, and interop-constraints.\n   o  To
        simplify handling and matching of these configurations, the\n      same RTP
        payload type number used in the offer SHOULD also be used\n      in the answer,
        as specified in [RFC3264].\n   o  The same RTP payload type number used in
        the offer for the media\n      subtype H265 MUST be used in the answer when
        the answer includes\n      recv-sub-layer-id.  When the answer does not include
        recv-sub-\n      layer-id, the answer MUST NOT contain a payload type number
        used\n      in the offer for the media subtype H265 unless the configuration\n
        \     is exactly the same as in the offer or the configuration in the\n      answer
        only differs from that in the offer with a different value\n      of level-id.
        \ The answer MAY contain the recv-sub-layer-id\n      parameter if an HEVC
        bitstream contains multiple operation points\n      (using temporal scalability
        and sub-layers) and sprop-vps is\n      included in the offer where information
        of sub-layers are present\n      in the first video parameter set contained
        in sprop-vps.  If the\n      sprop-vps is provided in an offer, an answerer
        MAY select a\n      particular operation point indicated in the first video
        parameter\n      set contained in sprop-vps.  When the answer includes a recv-sub-\n
        \     layer-id that is less than a sprop-sub-layer-id in the offer, all\n
        \     video parameter sets contained in the sprop-vps parameter in the\n      SDP
        answer and all video parameter sets sent in-band for either\n      the offerer-to-answerer
        direction or the answerer-to-offerer\n      direction MUST be consistent with
        the first video parameter set in\n      the sprop-vps parameter of the offer
        (see the semantics of sprop-\n      vps in Section 7.1 of this document on
        one video parameter set\n      being consistent with another video parameter
        set), and the\n      bitstream sent in either direction MUST conform to the
        profile,\n      tier, level, and constraints of the chosen sub-layer\n      representation
        as indicated by the first profile_tier_level( )\n      syntax structure in
        the first video parameter set in the sprop-vps\n      parameter of the offer.\n
        \        Informative note: When an offerer receives an answer that does\n
        \        not include recv-sub-layer-id, it has to compare payload types\n
        \        not declared in the offer based on the media type (i.e.,\n         video/H265)
        and the above media configuration parameters with\n         any payload types
        it has already declared.  This will enable it\n         to determine whether
        the configuration in question is new or if\n         it is equivalent to configuration
        already offered, since a\n         different payload type number may be used
        in the answer.  The\n         ability to perform operation point selection
        enables a receiver\n         to utilize the temporal scalable nature of an
        HEVC bitstream.\n   o  The parameters sprop-max-don-diff, sprop-depack-buf-nalus,
        and\n      sprop-depack-buf-bytes describe the properties of an RTP stream,\n
        \     and all RTP streams the RTP stream depends on, when present, that\n
        \     the offerer or the answerer is sending for the media format\n      configuration.
        \ This differs from the normal usage of the\n      offer/answer parameters:
        normally such parameters declare the\n      properties of the bitstream or
        RTP stream that the offerer or the\n      answerer is able to receive.  When
        dealing with HEVC, the offerer\n      assumes that the answerer will be able
        to receive media encoded\n      using the configuration being offered.\n         Informative
        note:  The above parameters apply for any RTP\n         stream and all RTP
        streams the RTP stream depends on, when\n         present, sent by a declaring
        entity with the same\n         configuration.  In other words, the applicability
        of the above\n         parameters to RTP streams depends on the source endpoint.\n
        \        Rather than being bound to the payload type, the values may\n         have
        to be applied to another payload type when being sent, as\n         they apply
        for the configuration.\n   o  The capability parameters max-lsr, max-lps,
        max-cpb, max-dpb, max-\n      br, max-tr, and max-tc MAY be used to declare
        further capabilities\n      of the offerer or answerer for receiving.  These
        parameters MUST\n      NOT be present when the direction attribute is sendonly.\n
        \  o  The capability parameter max-fps MAY be used to declare lower\n      capabilities
        of the offerer or answerer for receiving.  The\n      parameters MUST NOT
        be present when the direction attribute is\n      sendonly.\n   o  The capability
        parameter dec-parallel-cap MAY be used to declare\n      additional decoding
        capabilities of the offerer or answerer for\n      receiving.  Upon receiving
        such a declaration of a receiver, a\n      sender MAY send a bitstream to
        the receiver utilizing those\n      capabilities under the assumption that
        the bitstream fulfills the\n      parallelism requirement.  A bitstream that
        is sent based on\n      choosing a capability point with parallel tool type
        'w' from dec-\n      parallel-cap MUST have entropy_coding_sync_enabled_flag
        equal to 1\n      and min_spatial_segmentation_idc equal to or larger than
        dec-\n      parallel-cap.spatial-seg-idc of the capability point.  A bitstream\n
        \     that is sent based on choosing a capability point with parallel\n      tool
        type 't' from dec-parallel-cap MUST have\n      entropy_coding_sync_enabled_flag
        equal to 0 and\n      min_spatial_segmentation_idc equal to or larger than
        dec-parallel-\n      cap.spatial-seg-idc of the capability point.\n   o  An
        offerer has to include the size of the de-packetization buffer,\n      sprop-depack-buf-bytes,
        as well as sprop-max-don-diff and sprop-\n      depack-buf-nalus, in the offer
        for an interleaved HEVC bitstream\n      or for the MRST or MRMT transmission
        mode when sprop-max-don-diff\n      is greater than 0 for at least one of
        the RTP streams.  To enable\n      the offerer and answerer to inform each
        other about their\n      capabilities for de-packetization buffering in receiving
        RTP\n      streams, both parties are RECOMMENDED to include depack-buf-cap.\n
        \     For interleaved RTP streams or in MRST or MRMT, it is also\n      RECOMMENDED
        to consider offering multiple payload types with\n      different buffering
        requirements when the capabilities of the\n      receiver are unknown.\n   o
        \ The capability parameter include-dph MAY be used to declare the\n      capability
        to utilize decoded picture hash SEI messages and which\n      types of hashes
        in any HEVC RTP streams received by the offerer or\n      answerer.\n   o
        \ The sprop-vps, sprop-sps, or sprop-pps, when present (included in\n      the
        \"a=fmtp\" line of SDP or conveyed using the \"fmtp\" source\n      attribute
        as specified in Section 6.3 of [RFC5576]), are used for\n      out-of-band
        transport of the parameter sets (VPS, SPS, or PPS,\n      respectively).\n
        \  o  The answerer MAY use either out-of-band or in-band transport of\n      parameter
        sets for the bitstream it is sending, regardless of\n      whether out-of-band
        parameter sets transport has been used in the\n      offerer-to-answerer direction.
        \ Parameter sets included in an\n      answer are independent of those parameter
        sets included in the\n      offer, as they are used for decoding two different
        bitstreams, one\n      from the answerer to the offerer and the other in the
        opposite\n      direction.  In case some RTP streams are sent before the SDP\n
        \     offer/answer settles down, in-band parameter sets MUST be used for\n
        \     those RTP stream parts sent before the SDP offer/answer.\n   o  The
        following rules apply to transport of parameter set in the\n      offerer-to-answerer
        direction.\n      +  An offer MAY include sprop-vps, sprop-sps, and/or sprop-pps.\n
        \        If none of these parameters is present in the offer, then only\n
        \        in-band transport of parameter sets is used.\n      +  If the level
        to use in the offerer-to-answerer direction is\n         equal to the default
        level in the offer, the answerer MUST be\n         prepared to use the parameter
        sets included in sprop-vps,\n         sprop-sps, and sprop-pps (either included
        in the \"a=fmtp\" line\n         of SDP or conveyed using the \"fmtp\" source
        attribute) for\n         decoding the incoming bitstream, e.g., by passing
        these\n         parameter set NAL units to the video decoder before passing
        any\n         NAL units carried in the RTP streams.  Otherwise, the answerer\n
        \        MUST ignore sprop-vps, sprop-sps, and sprop-pps (either\n         included
        in the \"a=fmtp\" line of SDP or conveyed using the\n         \"fmtp\" source
        attribute) and the offerer MUST transmit\n         parameter sets in-band.\n
        \     +  In MRST or MRMT, the answerer MUST be prepared to use the\n         parameter
        sets out-of-band transmitted for the RTP stream and\n         all RTP streams
        the RTP stream depends on, when present, for\n         decoding the incoming
        bitstream, e.g., by passing these\n         parameter set NAL units to the
        video decoder before passing any\n         NAL units carried in the RTP streams.\n
        \  o  The following rules apply to transport of parameter set in the\n      answerer-to-offerer
        direction.\n      +  An answer MAY include sprop-vps, sprop-sps, and/or sprop-pps.\n
        \        If none of these parameters is present in the answer, then only\n
        \        in-band transport of parameter sets is used.\n      +  The offerer
        MUST be prepared to use the parameter sets included\n         in sprop-vps,
        sprop-sps, and sprop-pps (either included in the\n         \"a=fmtp\" line
        of SDP or conveyed using the \"fmtp\" source\n         attribute) for decoding
        the incoming bitstream, e.g., by\n         passing these parameter set NAL
        units to the video decoder\n         before passing any NAL units carried
        in the RTP streams.\n      +  In MRST or MRMT, the offerer MUST be prepared
        to use the\n         parameter sets out-of-band transmitted for the RTP stream
        and\n         all RTP streams the RTP stream depends on, when present, for\n
        \        decoding the incoming bitstream, e.g., by passing these\n         parameter
        set NAL units to the video decoder before passing any\n         NAL units
        carried in the RTP streams.\n   o  When sprop-vps, sprop-sps, and/or sprop-pps
        are conveyed using the\n      \"fmtp\" source attribute as specified in Section
        6.3 of [RFC5576],\n      the receiver of the parameters MUST store the parameter
        sets\n      included in sprop-vps, sprop-sps, and/or sprop-pps and associate\n
        \     them with the source given as part of the \"fmtp\" source attribute.\n
        \     Parameter sets associated with one source (given as part of the\n      \"fmtp\"
        source attribute) MUST only be used to decode NAL units\n      conveyed in
        RTP packets from the same source (given as part of the\n      \"fmtp\" source
        attribute).  When this mechanism is in use, SSRC\n      collision detection
        and resolution MUST be performed as specified\n      in [RFC5576].\n   For
        bitstreams being delivered over multicast, the following rules\n   apply:\n
        \     o  The media format configuration is identified by profile-space,\n
        \        profile-id, tier-flag, level-id, interop-constraints, profile-\n
        \        compatibility-indicator, and tx-mode.  These media format\n         configuration
        parameters, including level-id, MUST be used\n         symmetrically; that
        is, the answerer MUST either maintain all\n         configuration parameters
        or remove the media format (payload\n         type) completely.  Note that
        this implies that the level-id for\n         offer/answer in multicast is
        not changeable.\n      o  To simplify the handling and matching of these configurations,\n
        \        the same RTP payload type number used in the offer SHOULD also\n
        \        be used in the answer, as specified in [RFC3264].  An answer\n         MUST
        NOT contain a payload type number used in the offer unless\n         the configuration
        is the same as in the offer.\n      o  Parameter sets received MUST be associated
        with the originating\n         source and MUST only be used in decoding the
        incoming bitstream\n         from the same source.\n      o  The rules for
        other parameters are the same as above for\n         unicast as long as the
        three above rules are obeyed.\n   Table 1 lists the interpretation of all
        the parameters that MUST be\n   used for the various combinations of offer,
        answer, and direction\n   attributes.  Note that the two columns wherein the
        recv-sub-layer-id\n   parameter is used only apply to answers, whereas the
        other columns\n   apply to both offers and answers.\n   Table 1.  Interpretation
        of parameters for various combinations of\n   offers, answers, direction attributes,
        with and without recv-sub-\n   layer-id.  Columns that do not indicate offer
        or answer apply to\n   both.\n                                       sendonly
        --+\n         answer: recvonly, recv-sub-layer-id --+  |\n           recvonly
        w/o recv-sub-layer-id --+  |  |\n   answer: sendrecv, recv-sub-layer-id --+
        \ |  |  |\n     sendrecv w/o recv-sub-layer-id --+  |  |  |  |\n                                      |
        \ |  |  |  |\n   profile-space                      C  D  C  D  P\n   profile-id
        \                        C  D  C  D  P\n   tier-flag                          C
        \ D  C  D  P\n   level-id                           D  D  D  D  P\n   interop-constraints
        \               C  D  C  D  P\n   profile-compatibility-indicator    C  D
        \ C  D  P\n   tx-mode                            C  C  C  C  P\n   max-recv-level-id
        \                 R  R  R  R  -\n   sprop-max-don-diff                 P  P
        \ -  -  P\n   sprop-depack-buf-nalus             P  P  -  -  P\n   sprop-depack-buf-bytes
        \            P  P  -  -  P\n   depack-buf-cap                     R  R  R
        \ R  -\n   sprop-segmentation-id              P  P  P  P  P\n   sprop-spatial-segmentation-idc
        \    P  P  P  P  P\n   max-br                             R  R  R  R  -\n
        \  max-cpb                            R  R  R  R  -\n   max-dpb                            R
        \ R  R  R  -\n   max-lsr                            R  R  R  R  -\n   max-lps
        \                           R  R  R  R  -\n   max-tr                             R
        \ R  R  R  -\n   max-tc                             R  R  R  R  -\n   max-fps
        \                           R  R  R  R  -\n   sprop-vps                          P
        \ P  -  -  P\n   sprop-sps                          P  P  -  -  P\n   sprop-pps
        \                         P  P  -  -  P\n   sprop-sub-layer-id                 P
        \ P  -  -  P\n   recv-sub-layer-id                  X  O  X  O  -\n   dec-parallel-cap
        \                  R  R  R  R  -\n   include-dph                        R
        \ R  R  R  -\n   Legend:\n    C: configuration for sending and receiving bitstreams\n
        \   D: changeable configuration, same as C except possible\n       to answer
        with a different but consistent value (see the\n       semantics of the six
        parameters related to profile, tier,\n       and level on these parameters
        being consistent)\n    P: properties of the bitstream to be sent\n    R: receiver
        capabilities\n    O: operation point selection\n    X: MUST NOT be present\n
        \   -: not usable, when present MUST be ignored\n   Parameters used for declaring
        receiver capabilities are, in general,\n   downgradable; i.e., they express
        the upper limit for a sender's\n   possible behavior.  Thus, a sender MAY
        select to set its encoder\n   using only lower/lesser or equal values of these
        parameters.\n   When the answer does not include a recv-sub-layer-id that
        is less\n   than the sprop-sub-layer-id in the offer, parameters declaring
        a\n   configuration point are not changeable, with the exception of the\n
        \  level-id parameter for unicast usage, and these parameters express\n   values
        a receiver expects to be used and MUST be used verbatim in the\n   answer
        as in the offer.\n   When a sender's capabilities are declared with the configuration\n
        \  parameters, these parameters express a configuration that is\n   acceptable
        for the sender to receive bitstreams.  In order to achieve\n   high interoperability
        levels, it is often advisable to offer multiple\n   alternative configurations.
        \ It is impossible to offer multiple\n   configurations in a single payload
        type.  Thus, when multiple\n   configuration offers are made, each offer requires
        its own RTP\n   payload type associated with the offer.  However, it is possible
        to\n   offer multiple operation points using one configuration in a single\n
        \  payload type by including sprop-vps in the offer and recv-sub-layer-\n
        \  id in the answer.\n   A receiver SHOULD understand all media type parameters,
        even if it\n   only supports a subset of the payload format's functionality.
        \ This\n   ensures that a receiver is capable of understanding when an offer
        to\n   receive media can be downgraded to what is supported by the receiver\n
        \  of the offer.\n   An answerer MAY extend the offer with additional media
        format\n   configurations.  However, to enable their usage, in most cases
        a\n   second offer is required from the offerer to provide the bitstream\n
        \  property parameters that the media sender will use.  This also has\n   the
        effect that the offerer has to be able to receive this media\n   format configuration,
        not only to send it.\n"
      title: 7.2.2.  Usage with SDP Offer/Answer Model
    - contents:
      - "7.2.3.  Usage in Declarative Session Descriptions\n   When HEVC over RTP
        is offered with SDP in a declarative style, as in\n   Real Time Streaming
        Protocol (RTSP) [RFC2326] or Session Announcement\n   Protocol (SAP) [RFC2974],
        the following considerations are necessary.\n      o  All parameters capable
        of indicating both bitstream properties\n         and receiver capabilities
        are used to indicate only bitstream\n         properties.  For example, in
        this case, the parameter profile-\n         tier-level-id declares the values
        used by the bitstream, not\n         the capabilities for receiving bitstreams.
        \ As a result, the\n         following interpretation of the parameters MUST
        be used:\n         + Declaring actual configuration or bitstream properties:\n
        \           - profile-space\n            - profile-id\n            - tier-flag\n
        \           - level-id\n            - interop-constraints\n            - profile-compatibility-indicator\n
        \           - tx-mode\n            - sprop-vps\n            - sprop-sps\n
        \           - sprop-pps\n            - sprop-max-don-diff\n            - sprop-depack-buf-nalus\n
        \           - sprop-depack-buf-bytes\n            - sprop-segmentation-id\n
        \           - sprop-spatial-segmentation-idc\n         + Not usable (when
        present, they MUST be ignored):\n            - max-lps\n            - max-lsr\n
        \           - max-cpb\n            - max-dpb\n            - max-br\n            -
        max-tr\n            - max-tc\n            - max-fps\n            - max-recv-level-id\n
        \           - depack-buf-cap\n            - sprop-sub-layer-id\n            -
        dec-parallel-cap\n            - include-dph\n      o  A receiver of the SDP
        is required to support all parameters and\n         values of the parameters
        provided; otherwise, the receiver MUST\n         reject (RTSP) or not participate
        in (SAP) the session.  It\n         falls on the creator of the session to
        use values that are\n         expected to be supported by the receiving application.\n"
      title: 7.2.3.  Usage in Declarative Session Descriptions
    - contents:
      - "7.2.4.  Considerations for Parameter Sets\n   When out-of-band transport
        of parameter sets is used, parameter sets\n   MAY still be additionally transported
        in-band unless explicitly\n   disallowed by an application, and some of these
        additional parameter\n   sets may update some of the out-of-band transported
        parameter sets.\n   Update of a parameter set refers to the sending of a parameter
        set of\n   the same type using the same parameter set ID but with different\n
        \  values for at least one other parameter of the parameter set.\n"
      title: 7.2.4.  Considerations for Parameter Sets
    - contents:
      - "7.2.5.  Dependency Signaling in Multi-Stream Mode\n   If MRST or MRMT is
        used, the rules on signaling media decoding\n   dependency in SDP as defined
        in [RFC5583] apply.  The rules on\n   \"hierarchical or layered encoding\"
        with multicast in Section 5.7 of\n   [RFC4566] do not apply.  This means that
        the notation for Connection\n   Data \"c=\" SHALL NOT be used with more than
        one address, i.e., the\n   sub-field <number of addresses> in the sub-field
        <connection-address>\n   of the \"c=\" field, described in [RFC4566], must
        not be present.  The\n   order of session dependency is given from the RTP
        stream containing\n   the lowest temporal sub-layer to the RTP stream containing
        the\n   highest temporal sub-layer.\n"
      title: 7.2.5.  Dependency Signaling in Multi-Stream Mode
    title: 7.2.  SDP Parameters
  title: 7.  Payload Format Parameters
- contents:
  - "8.  Use with Feedback Messages\n   The following subsections define the use of
    the Picture Loss\n   Indication (PLI), Slice Lost Indication (SLI), Reference
    Picture\n   Selection Indication (RPSI), and Full Intra Request (FIR) feedback\n
    \  messages with HEVC.  The PLI, SLI, and RPSI messages are defined in\n   [RFC4585],
    and the FIR message is defined in [RFC5104].\n"
  - contents:
    - "8.1.  Picture Loss Indication (PLI)\n   As specified in RFC 4585, Section 6.3.1,
      the reception of a PLI by a\n   media sender indicates \"the loss of an undefined
      amount of coded\n   video data belonging to one or more pictures\".  Without
      having any\n   specific knowledge of the setup of the bitstream (such as use
      and\n   location of in-band parameter sets, non-IDR decoder refresh points,\n
      \  picture structures, and so forth), a reaction to the reception of an\n   PLI
      by an HEVC sender SHOULD be to send an IDR picture and relevant\n   parameter
      sets; potentially with sufficient redundancy so to ensure\n   correct reception.
      \ However, sometimes information about the\n   bitstream structure is known.
      \ For example, state could have been\n   established outside of the mechanisms
      defined in this document that\n   parameter sets are conveyed out of band only,
      and stay static for the\n   duration of the session.  In that case, it is obviously
      unnecessary\n   to send them in-band as a result of the reception of a PLI.
      \ Other\n   examples could be devised based on a priori knowledge of different\n
      \  aspects of the bitstream structure.  In all cases, the timing and\n   congestion
      control mechanisms of RFC 4585 MUST be observed.\n"
    title: 8.1.  Picture Loss Indication (PLI)
  - contents:
    - "8.2.  Slice Loss Indication (SLI)\n   The SLI described in RFC 4585 can be
      used to indicate, to a sender,\n   the loss of a number of Coded Tree Blocks
      (CTBs) in a CTB raster scan\n   order of a picture.  In the SLI's Feedback Control
      Indication (FCI)\n   field, the subfield \"First\" MUST be set to the CTB address
      of the\n   first lost CTB.  Note that the CTB address is in CTB-raster-scan\n
      \  order of a picture.  For the first CTB of a slice segment, the CTB\n   address
      is the value of slice_segment_address when present, or 0 when\n   the value
      of first_slice_segment_in_pic_flag is equal to 1; both\n   syntax elements are
      in the slice segment header.  The subfield\n   \"Number\" MUST be set to the
      number of consecutive lost CTBs, again in\n   CTB-raster-scan order of a picture.
      \ Note that due to both the\n   \"First\" and \"Number\" being counted in CTBs
      in CTB-raster-scan order,\n   of a picture, not in tile-scan order (which is
      the bitstream order of\n   CTBs), multiple SLI messages may be needed to report
      the loss of one\n   tile covering multiple CTB rows but less wide than the picture.\n
      \  The subfield \"PictureID\" MUST be set to the 6 least significant bits\n
      \  of a binary representation of the value of PicOrderCntVal, as defined\n   in
      [HEVC], of the picture for which the lost CTBs are indicated.\n   Note that
      for IDR pictures the syntax element slice_pic_order_cnt_lsb\n   is not present,
      but then the value is inferred to be equal to 0.\n   As described in RFC 4585,
      an encoder in a media sender can use this\n   information to \"clean up\" the
      corrupted picture by sending intra\n   information, while observing the constraints
      described in RFC 4585,\n   for example, with respect to congestion control.
      \ In many cases,\n   error tracking is required to identify the corrupted region
      in the\n   receiver's state (reference pictures) because of error import in\n
      \  uncorrupted regions of the picture through motion compensation.\n   Reference-picture
      selection can also be used to \"clean up\" the\n   corrupted picture, which
      is usually more efficient and less likely to\n   generate congestion than sending
      intra information.\n   In contrast to the video codecs contemplated in RFCs
      4585 and 5104\n   [RFC5104], in HEVC, the \"macroblock size\" is not fixed to
      16x16 luma\n   samples, but is variable.  That, however, does not create a\n
      \  conceptual difficulty with SLI, because the setting of the CTB size\n   is
      a sequence-level functionality, and using a slice loss indication\n   across
      CVS boundaries is meaningless as there is no prediction across\n   sequence
      boundaries.  However, a proper use of SLI messages is not as\n   straightforward
      as it was with older, fixed-macroblock-sized video\n   codecs, as the state
      of the sequence parameter set (where the CTB\n   size is located) has to be
      taken into account when interpreting the\n   \"First\" subfield in the FCI.\n"
    title: 8.2.  Slice Loss Indication (SLI)
  - contents:
    - "8.3.  Reference Picture Selection Indication (RPSI)\n   Feedback-based reference
      picture selection has been shown as a\n   powerful tool to stop temporal error
      propagation for improved error\n   resilience [Girod99][Wang05].  In one approach,
      the decoder side\n   tracks errors in the decoded pictures and informs the encoder
      side\n   that a particular picture that has been decoded relatively earlier
      is\n   correct and still present in the decoded picture buffer; it requests\n
      \  the encoder to use that correct picture-availability information when\n   encoding
      the next picture, so to stop further temporal error\n   propagation.  For this
      approach, the decoder side should use the RPSI\n   feedback message.\n   Encoders
      can encode some long-term reference pictures as specified in\n   H.264 or HEVC
      for purposes described in the previous paragraph\n   without the need of a huge
      decoded picture buffer.  As shown in\n   [Wang05], with a flexible reference
      picture management scheme, as in\n   H.264 and HEVC, even a decoded picture
      buffer size of two picture\n   storage buffers would work for the approach described
      in the previous\n   paragraph.\n   The field \"Native RPSI bit string defined
      per codec\" is a base16\n   [RFC4648] representation of the 8 bits consisting
      of the 2 most\n   significant bits equal to 0 and 6 bits of nuh_layer_id, as
      defined in\n   [HEVC], followed by the 32 bits representing the value of the\n
      \  PicOrderCntVal (in network byte order), as defined in [HEVC], for the\n   picture
      that is indicated by the RPSI feedback message.\n   The use of the RPSI feedback
      message as positive acknowledgement with\n   HEVC is deprecated.  In other words,
      the RPSI feedback message MUST\n   only be used as a reference picture selection
      request, such that it\n   can also be used in multicast.\n"
    title: 8.3.  Reference Picture Selection Indication (RPSI)
  - contents:
    - "8.4.  Full Intra Request (FIR)\n   The purpose of the FIR message is to force
      an encoder to send an\n   independent decoder refresh point as soon as possible
      (observing, for\n   example, the congestion-control-related constraints set
      out in RFC\n   5104).\n   Upon reception of a FIR, a sender MUST send an IDR
      picture.\n   Parameter sets MUST also be sent, except when there is a priori\n
      \  knowledge that the parameter sets have been correctly established.  A\n   typical
      example for that is an understanding between sender and\n   receiver, established
      by means outside this document, that parameter\n   sets are exclusively sent
      out-of-band.\n"
    title: 8.4.  Full Intra Request (FIR)
  title: 8.  Use with Feedback Messages
- contents:
  - "9.  Security Considerations\n   The scope of this Security Considerations section
    is limited to the\n   payload format itself and to one feature of HEVC that may
    pose a\n   particularly serious security risk if implemented naively.  The\n   payload
    format, in isolation, does not form a complete system.\n   Implementers are advised
    to read and understand relevant security-\n   related documents, especially those
    pertaining to RTP (see the\n   Security Considerations section in [RFC3550]),
    and the security of\n   the call-control stack chosen (that may make use of the
    media type\n   registration of this memo).  Implementers should also consider
    known\n   security vulnerabilities of video coding and decoding implementations\n
    \  in general and avoid those.\n   Within this RTP payload format, and with the
    exception of the user\n   data SEI message as described below, no security threats
    other than\n   those common to RTP payload formats are known.  In other words,\n
    \  neither the various media-plane-based mechanisms, nor the signaling\n   part
    of this memo, seems to pose a security risk beyond those common\n   to all RTP-based
    systems.\n   RTP packets using the payload format defined in this specification\n
    \  are subject to the security considerations discussed in the RTP\n   specification
    [RFC3550], and in any applicable RTP profile such as\n   RTP/AVP [RFC3551], RTP/AVPF
    [RFC4585], RTP/SAVP [RFC3711], or\n   RTP/SAVPF [RFC5124].  However, as \"Securing
    the RTP Framework: Why\n   RTP Does Not Mandate a Single Media Security Solution\"
    [RFC7202]\n   discusses, it is not an RTP payload format's responsibility to\n
    \  discuss or mandate what solutions are used to meet the basic security\n   goals
    like confidentiality, integrity and source authenticity for RTP\n   in general.
    \ This responsibility lays on anyone using RTP in an\n   application.  They can
    find guidance on available security mechanisms\n   and important considerations
    in \"Options for Securing RTP Sessions\"\n   [RFC7201].  Applications SHOULD use
    one or more appropriate strong\n   security mechanisms.  The rest of this section
    discusses the security\n   impacting properties of the payload format itself.\n
    \  Because the data compression used with this payload format is applied\n   end-to-end,
    any encryption needs to be performed after compression.\n   A potential denial-of-service
    threat exists for data encodings using\n   compression techniques that have non-uniform
    receiver-end\n   computational load.  The attacker can inject pathological datagrams\n
    \  into the bitstream that are complex to decode and that cause the\n   receiver
    to be overloaded.  H.265 is particularly vulnerable to such\n   attacks, as it
    is extremely simple to generate datagrams containing\n   NAL units that affect
    the decoding process of many future NAL units.\n   Therefore, the usage of data
    origin authentication and data integrity\n   protection of at least the RTP packet
    is RECOMMENDED, for example,\n   with SRTP [RFC3711].\n   Like [H.264], HEVC includes
    a user data Supplemental Enhancement\n   Information (SEI) message.  This SEI
    message allows inclusion of an\n   arbitrary bitstring into the video bitstream.
    \ Such a bitstring could\n   include JavaScript, machine code, and other active
    content.  HEVC\n   leaves the handling of this SEI message to the receiving system.
    \ In\n   order to avoid harmful side effects of the user data SEI message,\n   decoder
    implementations cannot naively trust its content.  For\n   example, it would be
    a bad and insecure implementation practice to\n   forward any JavaScript a decoder
    implementation detects to a web\n   browser.  The safest way to deal with user
    data SEI messages is to\n   simply discard them, but that can have negative side
    effects on the\n   quality of experience by the user.\n   End-to-end security
    with authentication, integrity, or\n   confidentiality protection will prevent
    a MANE from performing media-\n   aware operations other than discarding complete
    packets.  In the case\n   of confidentiality protection, it will even be prevented
    from\n   discarding packets in a media-aware way.  To be allowed to perform\n
    \  such operations, a MANE is required to be a trusted entity that is\n   included
    in the security context establishment.\n"
  title: 9.  Security Considerations
- contents:
  - "10.  Congestion Control\n   Congestion control for RTP SHALL be used in accordance
    with RTP\n   [RFC3550] and with any applicable RTP profile, e.g., AVP [RFC3551].\n
    \  If best-effort service is being used, an additional requirement is\n   that
    users of this payload format MUST monitor packet loss to ensure\n   that the packet
    loss rate is within an acceptable range.  Packet loss\n   is considered acceptable
    if a TCP flow across the same network path,\n   and experiencing the same network
    conditions, would achieve an\n   average throughput, measured on a reasonable
    timescale, that is not\n   less than all RTP streams combined is achieving.  This
    condition can\n   be satisfied by implementing congestion-control mechanisms to
    adapt\n   the transmission rate, the number of layers subscribed for a layered\n
    \  multicast session, or by arranging for a receiver to leave the\n   session
    if the loss rate is unacceptably high.\n   The bitrate adaptation necessary for
    obeying the congestion control\n   principle is easily achievable when real-time
    encoding is used, for\n   example, by adequately tuning the quantization parameter.\n
    \  However, when pre-encoded content is being transmitted, bandwidth\n   adaptation
    requires the pre-coded bitstream to be tailored for such\n   adaptivity.  The
    key mechanism available in HEVC is temporal\n   scalability.  A media sender can
    remove NAL units belonging to higher\n   temporal sub-layers (i.e., those NAL
    units with a high value of TID)\n   until the sending bitrate drops to an acceptable
    range.  HEVC\n   contains mechanisms that allow the lightweight identification
    of\n   switching points in temporal enhancement layers, as discussed in\n   Section
    1.1.2 of this memo.  An HEVC media sender can send packets\n   belonging to NAL
    units of temporal enhancement layers starting from\n   these switching points
    to probe for available bandwidth and to\n   utilized bandwidth that has been shown
    to be available.\n   Above mechanisms generally work within a defined profile
    and level\n   and, therefore, no renegotiation of the channel is required.  Only\n
    \  when non-downgradable parameters (such as profile) are required to be\n   changed
    does it become necessary to terminate and restart the RTP\n   stream(s).  This
    may be accomplished by using different RTP payload\n   types.\n   MANEs MAY remove
    certain unusable packets from the RTP stream when\n   that RTP stream was damaged
    due to previous packet losses.  This can\n   help reduce the network load in certain
    special cases.  For example,\n   MANES can remove those FUs where the leading
    FUs belonging to the\n   same NAL unit have been lost or those dependent slice
    segments when\n   the leading slice segments belonging to the same slice have
    been\n   lost, because the trailing FUs or dependent slice segments are\n   meaningless
    to most decoders.  MANES can also remove higher temporal\n   scalable layers if
    the outbound transmission (from the MANE's\n   viewpoint) experiences congestion.\n"
  title: 10.  Congestion Control
- contents:
  - "11.  IANA Considerations\n   A new media type, as specified in Section 7.1 of
    this memo, has been\n   registered with IANA.\n"
  title: 11.  IANA Considerations
- contents:
  - '12.  References

    '
  - contents:
    - "12.1.  Normative References\n   [H.264]   ITU-T, \"Advanced video coding for
      generic audiovisual\n             services\", ITU-T Recommendation H.264, April
      2013.\n   [HEVC]    ITU-T, \"High efficiency video coding\", ITU-T Recommendation\n
      \            H.265, April 2013.\n   [ISO23008-2]\n             ISO/IEC, \"Information
      technology -- High efficiency coding\n             and media delivery in heterogeneous
      environments -- Part 2:\n             High efficiency video coding\", ISO/IEC
      23008-2, 2013.\n   [RFC2119] Bradner, S., \"Key words for use in RFCs to Indicate\n
      \            Requirement Levels\", BCP 14, RFC 2119,\n             DOI 10.17487/RFC2119,
      March 1997,\n             <http://www.rfc-editor.org/info/rfc2119>.\n   [RFC3264]
      Rosenberg, J. and H. Schulzrinne, \"An Offer/Answer Model\n             with
      Session Description Protocol (SDP)\", RFC 3264,\n             DOI 10.17487/RFC3264,
      June 2002,\n             <http://www.rfc-editor.org/info/rfc3264>.\n   [RFC3550]
      Schulzrinne, H., Casner, S., Frederick, R., and V.\n             Jacobson, \"RTP:
      A Transport Protocol for Real-Time\n             Applications\", STD 64, RFC
      3550, DOI 10.17487/RFC3550, July\n             2003, <http://www.rfc-editor.org/info/rfc3550>.\n
      \  [RFC3551] Schulzrinne, H. and S. Casner, \"RTP Profile for Audio and\n             Video
      Conferences with Minimal Control\", STD 65, RFC 3551,\n             DOI 10.17487/RFC3551,
      July 2003,\n             <http://www.rfc-editor.org/info/rfc3551>.\n   [RFC3711]
      Baugher, M., McGrew, D., Naslund, M., Carrara, E., and K.\n             Norrman,
      \"The Secure Real-time Transport Protocol (SRTP)\",\n             RFC 3711,
      DOI 10.17487/RFC3711, March 2004,\n             <http://www.rfc-editor.org/info/rfc3711>.\n
      \  [RFC4566] Handley, M., Jacobson, V., and C. Perkins, \"SDP: Session\n             Description
      Protocol\", RFC 4566, DOI 10.17487/RFC4566, July\n             2006, <http://www.rfc-editor.org/info/rfc4566>.\n
      \  [RFC4585] Ott, J., Wenger, S., Sato, N., Burmeister, C., and J. Rey,\n             \"Extended
      RTP Profile for Real-time Transport Control\n             Protocol (RTCP)-Based
      Feedback (RTP/AVPF)\", RFC 4585,\n             DOI 10.17487/RFC4585, July 2006,\n
      \            <http://www.rfc-editor.org/info/rfc4585>.\n   [RFC4648] Josefsson,
      S., \"The Base16, Base32, and Base64 Data\n             Encodings\", RFC 4648,
      DOI 10.17487/RFC4648, October 2006,\n             <http://www.rfc-editor.org/info/rfc4648>.\n
      \  [RFC5104] Wenger, S., Chandra, U., Westerlund, M., and B. Burman,\n             \"Codec
      Control Messages in the RTP Audio-Visual Profile\n             with Feedback
      (AVPF)\", RFC 5104, DOI 10.17487/RFC5104,\n             February 2008, <http://www.rfc-editor.org/info/rfc5104>.\n
      \  [RFC5124] Ott, J. and E. Carrara, \"Extended Secure RTP Profile for\n             Real-time
      Transport Control Protocol (RTCP)-Based Feedback\n             (RTP/SAVPF)\",
      RFC 5124, DOI 10.17487/RFC5124, February\n             2008, <http://www.rfc-editor.org/info/rfc5124>.\n
      \  [RFC5234] Crocker, D., Ed., and P. Overell, \"Augmented BNF for Syntax\n
      \            Specifications: ABNF\", STD 68, RFC 5234,\n             DOI 10.17487/RFC5234,
      January 2008,\n             <http://www.rfc-editor.org/info/rfc5234>.\n   [RFC5576]
      Lennox, J., Ott, J., and T. Schierl, \"Source-Specific Media\n             Attributes
      in the Session Description Protocol (SDP)\",\n             RFC 5576, DOI 10.17487/RFC5576,
      June 2009,\n             <http://www.rfc-editor.org/info/rfc5576>.\n   [RFC5583]
      Schierl, T. and S. Wenger, \"Signaling Media Decoding\n             Dependency
      in the Session Description Protocol (SDP)\",\n             RFC 5583, DOI 10.17487/RFC5583,
      July 2009,\n             <http://www.rfc-editor.org/info/rfc5583>.\n"
    title: 12.1.  Normative References
  - contents:
    - "12.2.  Informative References\n   [3GPDASH] 3GPP, \"Transparent end-to-end
      Packet-switched Streaming\n             Service (PSS); Progressive Download
      and Dynamic Adaptive\n             Streaming over HTTP (3GP-DASH)\", 3GPP TS
      26.247 12.1.0,\n             December 2013.\n   [3GPPFF]  3GPP, \"Transparent
      end-to-end packet switched streaming\n             service (PSS); 3GPP file
      format (3GP)\", 3GPP TS 26.244\n             12.20, December 2013.\n   [CABAC]
      \  Sole, J., Joshi, R., Nguyen, N., Ji, T., Karczewicz, M.,\n             Clare,
      G., Henry, F., and Duenas, A., \"Transform\n             coefficient coding
      in HEVC\", IEEE Transactions on Circuts\n             and Systems for Video
      Technology, Vol. 22, No. 12,\n             pp. 1765-1777, DOI 10.1109/TCSVT.2012.2223055,
      December\n             2012.\n   [Girod99] Girod, B. and Faerber, F., \"Feedback-based
      error control\n             for mobile video transmission\", Proceedings of
      the IEEE,\n             Vol. 87, No. 10, pp. 1707-1723, DOI 10.1109/5.790632,\n
      \            October 1999.\n   [H.265.1] ITU-T, \"Conformance specification
      for ITU-T H.265 high\n             efficiency video coding\", ITU-T Recommendation
      H.265.1,\n             October 2014.\n   [HEVCv2]  Flynn, D., Naccari, M., Rosewarne,
      C., Sharman, K., Sole,\n             J., Sullivan, G. J., and T. Suzuki, \"High
      Efficiency Video\n             Coding (HEVC) Range Extensions text specification:
      Draft\n             7\", JCT-VC document JCTVC-Q1005, 17th JCT-VC meeting,\n
      \            Valencia, Spain, March/April 2014.\n   [IS014496-12]\n             IS0/IEC,
      \"Information technology - Coding of audio-visual\n             objects - Part
      12: ISO base media file format\", IS0/IEC\n             14496-12, 2015.\n   [IS015444-12]\n
      \            IS0/IEC, \"Information technology - JPEG 2000 image coding\n             system
      - Part 12: ISO base media file format\", IS0/IEC\n             15444-12, 2015.\n
      \  [JCTVC-J0107]\n             Wang, Y.-K., Chen, Y., Joshi, R., and Ramasubramonian,
      K.,\n             \"AHG9: On RAP pictures\", JCT-VC document JCTVC-L0107, 10th\n
      \            JCT-VC meeting, Stockholm, Sweden, July 2012.\n   [MPEG2S]  ISO/IEC,
      \"Information technology - Generic coding of moving\n             pictures and
      associated audio information - Part 1:\n             Systems\", ISO International
      Standard 13818-1, 2013.\n   [MPEGDASH] ISO/IEC, \"Information technology - Dynamic
      adaptive\n             streaming over HTTP (DASH) -- Part 1: Media presentation\n
      \            description and segment formats\", ISO International\n             Standard
      23009-1, 2012.\n   [RFC2326] Schulzrinne, H., Rao, A., and R. Lanphier, \"Real
      Time\n             Streaming Protocol (RTSP)\", RFC 2326, DOI 10.17487/RFC2326,\n
      \            April 1998, <http://www.rfc-editor.org/info/rfc2326>.\n   [RFC2974]
      Handley, M., Perkins, C., and E. Whelan, \"Session\n             Announcement
      Protocol\", RFC 2974, DOI 10.17487/RFC2974,\n             October 2000, <http://www.rfc-editor.org/info/rfc2974>.\n
      \  [RFC6051] Perkins, C. and T. Schierl, \"Rapid Synchronisation of RTP\n             Flows\",
      RFC 6051, DOI 10.17487/RFC6051, November 2010,\n             <http://www.rfc-editor.org/info/rfc6051>.\n
      \  [RFC6184] Wang, Y.-K., Even, R., Kristensen, T., and R. Jesup, \"RTP\n             Payload
      Format for H.264 Video\", RFC 6184,\n             DOI 10.17487/RFC6184, May
      2011,\n             <http://www.rfc-editor.org/info/rfc6184>.\n   [RFC6190]
      Wenger, S., Wang, Y.-K., Schierl, T., and A. Eleftheriadis,\n             \"RTP
      Payload Format for Scalable Video Coding\", RFC 6190,\n             DOI 10.17487/RFC6190,
      May 2011,\n             <http://www.rfc-editor.org/info/rfc6190>.\n   [RFC7201]
      Westerlund, M. and C. Perkins, \"Options for Securing RTP\n             Sessions\",
      RFC 7201, DOI 10.17487/RFC7201, April 2014,\n             <http://www.rfc-editor.org/info/rfc7201>.\n
      \  [RFC7202] Perkins, C. and M. Westerlund, \"Securing the RTP Framework:\n
      \            Why RTP Does Not Mandate a Single Media Security Solution\",\n
      \            RFC 7202, DOI 10.17487/RFC7202, April 2014,\n             <http://www.rfc-editor.org/info/rfc7202>.\n
      \  [RFC7656] Lennox, J., Gross, K., Nandakumar, S., Salgueiro, G., and\n             B.
      Burman, Ed., \"A Taxonomy of Semantics and Mechanisms for\n             Real-Time
      Transport Protocol (RTP) Sources\", RFC 7656,\n             DOI 10.17487/RFC7656,
      November 2015,\n             <http://www.rfc-editor.org/info/rfc7656>.\n   [RFC7667]
      Westerlund, M. and S. Wenger, \"RTP Topologies\", RFC 7667,\n             DOI
      10.17487/RFC7667, November 2015,\n             <http://www.rfc-editor.org/info/rfc7667>.\n
      \  [RTP-MULTI-STREAM]\n             Lennox, J., Westerlund, M., Wu, Q., and
      C. Perkins,\n             \"Sending Multiple Media Streams in a Single RTP Session\",\n
      \            Work in Progress, draft-ietf-avtcore-rtp-multi-stream-11,\n             December
      2015.\n   [SDP-NEG] Holmberg, C., Alvestrand, H., and C. Jennings, \"Negotiating\n
      \            Medai Multiplexing Using Session Description Protocol\n             (SDP)\",
      Work in Progress,\n             draft-ietf-mmusic-sdp-bundle-negotiation-25,
      January 2016.\n   [Wang05]  Wang, Y.-K., Zhu, C., and Li, H., \"Error resilient
      video\n             coding using flexible reference fames\", Visual\n             Communications
      and Image Processing 2005 (VCIP 2005),\n             Beijing, China, July 2005.\n"
    title: 12.2.  Informative References
  title: 12.  References
- contents:
  - "Acknowledgements\n   Muhammed Coban and Marta Karczewicz are thanked for discussions
    on\n   the specification of the use with feedback messages and other aspects\n
    \  in this memo.  Jonathan Lennox and Jill Boyce are thanked for their\n   contributions
    to the PACI design included in this memo.  Rickard\n   Sjoberg, Arild Fuldseth,
    Bo Burman, Magnus Westerlund, and Tom\n   Kristensen are thanked for their contributions
    to signaling related\n   to parallel processing.  Magnus Westerlund, Jonathan
    Lennox, Bernard\n   Aboba, Jonatan Samuelsson, Roni Even, Rickard Sjoberg, Sachin\n
    \  Deshpande, Woo Johnman, Mo Zanaty, Ross Finlayson, Danny Hong, Bo\n   Burman,
    Ben Campbell, Brian Carpenter, Qin Wu, Stephen Farrell, and\n   Min Wang made
    valuable review comments that led to improvements.\n"
  title: Acknowledgements
- contents:
  - "Authors' Addresses\n   Ye-Kui Wang\n   Qualcomm Incorporated\n   5775 Morehouse
    Drive\n   San Diego, CA 92121\n   United States\n   Phone: +1-858-651-8345\n   Email:
    yekui.wang@gmail.com\n   Yago Sanchez\n   Fraunhofer HHI\n   Einsteinufer 37\n
    \  D-10587 Berlin\n   Germany\n   Phone: +49 30 31002-663\n   Email: yago.sanchez@hhi.fraunhofer.de\n
    \  Thomas Schierl\n   Fraunhofer HHI\n   Einsteinufer 37\n   D-10587 Berlin\n
    \  Germany\n   Phone: +49-30-31002-227\n   Email: thomas.schierl@hhi.fraunhofer.de\n
    \  Stephan Wenger\n   Vidyo, Inc.\n   433 Hackensack Ave., 7th floor\n   Hackensack,
    NJ 07601\n   United States\n   Phone: +1-415-713-5473\n   Email: stewe@stewe.org\n
    \  Miska M. Hannuksela\n   Nokia Corporation\n   P.O. Box 1000\n   33721 Tampere\n
    \  Finland\n   Phone: +358-7180-08000\n   Email: miska.hannuksela@nokia.com\n"
  title: Authors' Addresses
