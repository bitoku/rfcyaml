- title: __initial_text__
  contents:
  - '                     Device Reset Characterization

    '
- title: Abstract
  contents:
  - "Abstract\n   An operational forwarding device may need to be restarted\n   (automatically\
    \ or manually) for a variety of reasons, an event called\n   a \"reset\" in this\
    \ document.  Since there may be an interruption in\n   the forwarding operation\
    \ during a reset, it is useful to know how\n   long a device takes to resume the\
    \ forwarding operation.\n   This document specifies a methodology for characterizing\
    \ reset (and\n   reset time) during benchmarking of forwarding devices and provides\n\
    \   clarity and consistency in reset test procedures beyond what is\n   specified\
    \ in RFC 2544.  Therefore, it updates RFC 2544.  This\n   document also defines\
    \ the benchmarking term \"reset time\" and, only in\n   this, updates RFC 1242.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6201.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \      1.1. Scope ......................................................3\n  \
    \    1.2. Reset Time .................................................4\n    \
    \  1.3. Reset Time Measurement Methods .............................5\n      1.4.\
    \ Reporting Format ...........................................6\n   2. Key Words\
    \ to Reflect Requirements ...............................7\n   3. Test Requirements\
    \ ...............................................7\n   4. Reset Tests .....................................................8\n\
    \      4.1. Hardware Reset Tests .......................................9\n  \
    \         4.1.1. Routing Processor (RP) / Routing Engine Reset .......9\n    \
    \       4.1.2. Line Card (LC) Removal and Insertion (REQUIRED) ....11\n      4.2.\
    \ Software Reset Tests ......................................12\n           4.2.1.\
    \ Operating System (OS) Reset (REQUIRED) .............12\n           4.2.2. Process\
    \ Reset (OPTIONAL) ...........................13\n      4.3. Power Interruption\
    \ Test ...................................14\n           4.3.1. Power Interruption\
    \ (REQUIRED) ......................14\n   5. Security Considerations ........................................15\n\
    \   6. Acknowledgments ................................................16\n  \
    \ 7. References .....................................................16\n    \
    \  7.1. Normative References ......................................16\n      7.2.\
    \ Informative References ....................................16\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   An operational forwarding device (or one of its components)\
    \ may need\n   to be restarted for a variety of reasons, an event called a \"\
    reset\"\n   in this document.  Since there may be an interruption in the\n   forwarding\
    \ operation during a reset, it is useful to know how long a\n   device takes to\
    \ resume the forwarding operation.  In other words, the\n   duration of the recovery\
    \ time following the reset (see Section 1.2,\n   \"Reset Time\") is what is in\
    \ question.\n   However, the answer to this question is no longer simple and\n\
    \   straightforward as the modern forwarding devices employ many hardware\n  \
    \ advancements (distributed forwarding, etc.) and software advancements\n   (graceful\
    \ restart, etc.) that influence the recovery time after the\n   reset.\n"
- title: 1.1.  Scope
  contents:
  - "1.1.  Scope\n   This document specifies a methodology for characterizing reset\
    \ (and\n   reset time) during benchmarking of forwarding devices and provides\n\
    \   clarity and consistency in reset procedures beyond what is specified\n   in\
    \ [RFC2544].  Software upgrades involve additional benchmarking\n   complexities\
    \ and are outside the scope of this document.\n   These procedures may be used\
    \ by other benchmarking documents such as\n   [RFC2544], [RFC5180], [RFC5695],\
    \ etc., and it is expected that other\n   protocol-specific benchmarking documents\
    \ will reference this document\n   for reset recovery time characterization. \
    \ Specific Routing\n   Information Base (RIB) and Forwarding Information Base\
    \ (FIB) scaling\n   considerations are outside the scope of this document and\
    \ can be\n   quite complex to characterize.  However, other documents can\n  \
    \ characterize specific dynamic protocols' scaling and interactions as\n   well\
    \ as leverage and augment the reset tests defined in this\n   document.\n   This\
    \ document updates Section 26.6 of [RFC2544] and defines the\n   benchmarking\
    \ term \"reset time\", updating [RFC1242].\n   This document focuses only on the\
    \ reset criterion of benchmarking and\n   presumes that it would be beneficial\
    \ to [RFC5180], [RFC5695], and\n   other IETF Benchmarking Methodology Working\
    \ Group (BMWG) efforts.\n"
- title: 1.2.  Reset Time
  contents:
  - "1.2.  Reset Time\n   Definition\n      Reset time is the total time that a device\
    \ is determined to be out\n      of operation and includes the time to perform\
    \ the reset and the\n      time to recover from it.\n   Discussion\n      During\
    \ a period of time after a reset or power up, network devices\n      may not accept\
    \ and forward frames.  The duration of this period of\n      forwarding unavailability\
    \ can be useful in evaluating devices.  In\n      addition, some network devices\
    \ require some form of reset when\n      specific setup variables are modified.\
    \  If the reset period were\n      long, it might discourage network managers\
    \ from modifying these\n      variables on production networks.\n      The events\
    \ characterized in this document are entire reset events.\n      That is, the\
    \ recovery period measured includes the time to perform\n      the reset and the\
    \ time to recover from it.  Some reset events will\n      be atomic (such as pressing\
    \ a reset button) while others (such as\n      power cycling) may comprise multiple\
    \ actions with a recognized\n      interval between them.  In both cases, the\
    \ duration considered is\n      from the start of the event until full recovery\
    \ of forwarding\n      after the completion of the reset events.\n   Measurement\
    \ Units\n      Time, in milliseconds, providing sufficient resolution to\n   \
    \   distinguish between different trials and different\n      implementations.\
    \  See Section 1.4.\n   Issues\n      There are various types of resets: hardware\
    \ resets, software\n      resets, and power interruptions.  See Section 4.\n \
    \  See Also\n      This definition updates [RFC1242].\n"
- title: 1.3.  Reset Time Measurement Methods
  contents:
  - "1.3.  Reset Time Measurement Methods\n   The reset time is the time during which\
    \ traffic forwarding is\n   temporarily interrupted following a reset event. \
    \ Strictly speaking,\n   this is the time over which one or more frames are lost.\
    \  This\n   definition is similar to that of \"Loss of Connectivity Period\"\n\
    \   defined in [IGPConv], Section 4.\n   There are two accepted methods to measure\
    \ the reset time:\n   1.  Frame-Loss Method - This method requires test tool capability\
    \ to\n       monitor the number of lost frames.  In this method, the offered\n\
    \       stream rate (frames per second) must be known.  The reset time is\n  \
    \     calculated per the equation below:\n                                Frames_lost\
    \ (packets)\n          Reset_time = -------------------------------------\n  \
    \                       Offered_rate (packets per second)\n   2.  Timestamp Method\
    \ - This method requires test tool capability to\n       timestamp each frame.\
    \  In this method, the test tool timestamps\n       each transmitted frame and\
    \ monitors the received frame's\n       timestamp.  During the test, the test\
    \ tool records the timestamp\n       (Timestamp A) of the frame that was last\
    \ received prior to the\n       reset interruption and the timestamp of the first\
    \ frame after the\n       interruption stopped (Timestamp B).  The difference\
    \ between\n       Timestamp B and Timestamp A is the reset time.\n   The tester/operator\
    \ MAY use either method for reset time measurement\n   depending on the test tool\
    \ capability.  However, the Frame-Loss\n   method SHOULD be used if the test tool\
    \ is capable of (a) counting the\n   number of lost frames per stream and (b)\
    \ transmitting test frame\n   despite the physical link status, whereas the Timestamp\
    \ method SHOULD\n   be used if the test tool is capable of (a) timestamping each\
    \ frame,\n   (b) monitoring received frame's timestamp, and (c) transmitting\n\
    \   frames only if the physical link status is UP.  That is, specific\n   test\
    \ tool capabilities may dictate which method to use.  If the test\n   tool supports\
    \ both methods based on its capabilities, the\n   tester/operator SHOULD use the\
    \ one that provides more accuracy.\n"
- title: 1.4.  Reporting Format
  contents:
  - "1.4.  Reporting Format\n   All reset results are reported in a simple statement\
    \ including the\n   frame loss (if measured) and reset times.\n   For each test\
    \ case, it is RECOMMENDED that the following parameters\n   be reported in these\
    \ units:\n       Parameter                Units or Examples\n    ---------------------------------------------------------------\n\
    \       Throughput               Frames per second and bits per\n            \
    \                    second\n       Loss (average)           Frames\n       Reset\
    \ Time (average)     Milliseconds\n       Number of trials         Integer count\n\
    \       Protocol                 IPv4, IPv6, MPLS, etc.\n       Frame Size   \
    \            Octets\n       Port Media               Ethernet, Gigabit Ethernet\
    \ (GbE),\n                                Packet over SONET (POS), etc.\n    \
    \   Port Speed               10 Gbps, 1 Gbps, 100 Mbps, etc.\n       Interface\
    \ Encap.         Ethernet, Ethernet VLAN,\n                                PPP,\
    \ High-Level Data Link Control\n                                (HDLC), etc.\n\
    \   For mixed protocol environments, frames SHOULD be distributed between\n  \
    \ all the different protocols.  The distribution MAY approximate the\n   network\
    \ conditions of deployment.  In all cases, the details of the\n   mixed protocol\
    \ distribution MUST be included in the reporting.\n   Additionally, the DUT (Device\
    \ Under Test) or SUT (System Under Test)\n   and test bed provisioning, port and\
    \ line-card arrangement,\n   configuration, and deployed methodologies that may\
    \ influence the\n   overall reset time MUST be listed.  (Refer to the additional\
    \ factors\n   listed in Section 3).\n   The reporting of results MUST regard repeatability\
    \ considerations\n   from Section 4 of [RFC2544].  It is RECOMMENDED to perform\
    \ multiple\n   trials and report average results.\n"
- title: 2.  Key Words to Reflect Requirements
  contents:
  - "2.  Key Words to Reflect Requirements\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in BCP 14, RFC 2119\n   [RFC2119].  RFC 2119 defines the use of these key words\
    \ to help make\n   the intent of Standards-Track documents as clear as possible.\
    \  While\n   this document uses these keywords, this document is not a Standards-\n\
    \   Track document.\n"
- title: 3.  Test Requirements
  contents:
  - "3.  Test Requirements\n   Tests SHOULD first be performed such that the forwarding\
    \ state\n   re-establishment is independent from an external source (i.e., using\n\
    \   static address resolution, routing and forwarding configuration, and\n   not\
    \ dynamic protocols).  However, tests MAY subsequently be performed\n   using\
    \ dynamic protocols that the forwarding state depends on (e.g.,\n   dynamic Interior\
    \ Gateway Protocols (IGP), Address Resolution Protocol\n   (ARP), PPP Control\
    \ Protocols, etc.).  The considerations in this\n   section apply.\n   In order\
    \ to provide consistence and fairness while benchmarking a set\n   of different\
    \ DUTs, the Network tester/operator MUST (a) use identical\n   control and data\
    \ plane information during testing and (b) document\n   and report any factors\
    \ that may influence the overall time after\n   reset/convergence.\n   Some of\
    \ these factors include the following:\n   1.  Type of reset - hardware (line-card\
    \ crash, etc.) versus software\n       (protocol reset, process crash, etc.) or\
    \ even complete power\n       failures\n   2.  Manual versus automatic reset\n\
    \   3.  Scheduled versus non-scheduled reset\n   4.  Local versus remote reset\n\
    \   5.  Scale - Number of line cards present versus in use\n   6.  Scale - Number\
    \ of physical and logical interfaces\n   7.  Scale - Number of routing protocol\
    \ instances\n   8.  Scale - Number of routing table entries\n   9.  Scale - Number\
    \ of route processors available\n   10. Performance - Redundancy strategy deployed\
    \ for route processors\n       and line cards\n   11. Performance - Interface\
    \ encapsulation as well as achievable\n       throughput [RFC2544]\n   12. Any\
    \ other internal or external factor that may influence reset\n       time after\
    \ a hardware or software reset\n   The reset time is one of the key characterization\
    \ results reported\n   after each test run.  While the reset time during a reset\
    \ test event\n   may be zero, there may still be effects on traffic, such as transient\n\
    \   delay variation or increased latency.  However, that is not covered\n   and\
    \ is deemed outside the scope of this document.  In this case, only\n   \"no loss\"\
    \ is reported.\n"
- title: 4.  Reset Tests
  contents:
  - "4.  Reset Tests\n   This section contains descriptions of the tests that are\
    \ related to\n   the characterization of the time needed for DUTs (Devices Under\
    \ Test)\n   or SUTs (Systems Under Test) to recover from a reset.  There are\n\
    \   three types of resets considered in this document:\n   1.  Hardware resets\n\
    \   2.  Software resets\n   3.  Power interruption\n   Different types of resets\
    \ potentially have a different impact on the\n   forwarding behavior of the device.\
    \  As an example, a software reset\n   (of a routing process) might not result\
    \ in forwarding interruption,\n   whereas a hardware reset (of a line card) most\
    \ likely will.\n   Section 4.1 describes various hardware resets, whereas Section\
    \ 4.2\n   describes various software resets.  Additionally, Section 4.3\n   describes\
    \ power interruption tests.  These sections define and\n   characterize these\
    \ resets.\n   Additionally, since device-specific implementations may vary for\n\
    \   hardware and software type resets, it is desirable to classify each\n   test\
    \ case as \"REQUIRED\" or \"OPTIONAL\".\n"
- title: 4.1.  Hardware Reset Tests
  contents:
  - "4.1.  Hardware Reset Tests\n   A hardware reset test is a test designed to characterize\
    \ the time it\n   takes a DUT to recover from a hardware reset.\n   A hardware\
    \ reset generally involves the re-initialization of one or\n   more physical components\
    \ in the DUT, but not the entire DUT.\n   A hardware reset is executed by the\
    \ operator, for example, by\n   physical removal of a hardware component, by pressing\
    \ a reset button\n   for the component, or by being triggered from the command\
    \ line\n   interface (CLI).\n   Reset procedures that do not require the physical\
    \ removal and\n   insertion of a hardware component are RECOMMENDED.  These include\n\
    \   using the command line interface (CLI) or a physical switch or\n   button.\
    \  If such procedures cannot be performed (e.g., because of a\n   lack of platform\
    \ support or because the corresponding test case calls\n   for them), human operation\
    \ time SHOULD be minimized across different\n   platforms and test cases as much\
    \ as possible, and variation in human\n   operator time SHOULD also be minimized\
    \ across different vendors'\n   products as much as practical by having the same\
    \ person perform the\n   operation and by practicing the operation.  Additionally,\
    \ the time\n   between removal and insertion SHOULD be recorded and reported.\n\
    \   For routers that do not contain separate Routing Processor and Line\n   Card\
    \ modules, the hardware reset tests are not performed since they\n   are not relevant;\
    \ instead, the power interruption tests MUST be\n   performed (see Section 4.3)\
    \ in these cases.\n"
- title: 4.1.1.  Routing Processor (RP) / Routing Engine Reset
  contents:
  - "4.1.1.  Routing Processor (RP) / Routing Engine Reset\n   The Routing Processor\
    \ (RP) is the DUT module that is primarily\n   concerned with Control Plane functions.\n"
- title: 4.1.1.1.  RP Reset for a Single-RP Device (REQUIRED)
  contents:
  - "4.1.1.1.  RP Reset for a Single-RP Device (REQUIRED)\n   Objective\n      To\
    \ characterize the time needed for a DUT to recover from a Route\n      Processor\
    \ hardware reset in a single RP environment.\n   Procedure\n      First, ensure\
    \ that the RP is in a permanent state to which it will\n      return after the\
    \ reset by performing some or all of the following\n      operational tasks: save\
    \ the current DUT configuration, specify\n      boot parameters, ensure the appropriate\
    \ software files are\n      available, or perform additional operating system\
    \ or hardware-\n      related tasks.\n      Second, ensure that the DUT is able\
    \ to forward the traffic for at\n      least 15 seconds before any test activities\
    \ are performed.  The\n      traffic should use the minimum frame size possible\
    \ on the media\n      used in the testing, and the rate should be sufficient for\
    \ the DUT\n      to attain the maximum forwarding throughput.  This enables a\
    \ finer\n      granularity in the reset time measurement.\n      Third, perform\
    \ the Route Processor (RP) hardware reset at this\n      point.  This entails,\
    \ for example, physically removing the RP to\n      later re-insert it or triggering\
    \ a hardware reset by other means\n      (e.g., command line interface, physical\
    \ switch, etc.).\n      Finally, complete the characterization by recording the\
    \ frame loss\n      or timestamps (as reported by the test tool) and calculating\
    \ the\n      reset time (as defined in Section 1.3).\n   Reporting Format\n  \
    \    The reporting format is defined in Section 1.4.\n"
- title: 4.1.1.2.  RP Switchover for a Multiple-RP Device (OPTIONAL)
  contents:
  - "4.1.1.2.  RP Switchover for a Multiple-RP Device (OPTIONAL)\n   Objective\n \
    \     To characterize the time needed for the \"secondary\" Route\n      Processor\
    \ (sometimes referred to as the \"backup\" RP) of a DUT to\n      become active\
    \ after a \"primary\" (or \"active\") Route Processor\n      hardware reset. \
    \ This process is often referred to as \"RP\n      Switchover\".  The characterization\
    \ in this test should be done for\n      the default DUT behavior and, if it exists,\
    \ for the DUT's non-\n      default configuration that minimizes frame loss.\n\
    \   Procedure\n      This test characterizes RP Switchover.  Many implementations\
    \ allow\n      for optimized switchover capabilities that minimize the downtime\n\
    \      during the actual switchover.  This test consists of two sub-cases\n  \
    \    from a switchover characteristic's standpoint: first, a default\n      behavior\
    \ (with no switchover-specific configurations) and,\n      potentially second,\
    \ a non-default behavior with switchover\n      configuration to minimize frame\
    \ loss.  Therefore, the procedures\n      hereby described are executed twice\
    \ and reported separately.\n      First, ensure that the RPs are in a permanent\
    \ state such that the\n      secondary RP will be activated to the same state\
    \ as the active RP\n      by performing some or all of the following operational\
    \ tasks: save\n      the current DUT configuration, specify boot parameters, ensure\
    \ the\n      appropriate software files are available, or perform additional\n\
    \      operating system or hardware-related tasks.\n      Second, ensure that\
    \ the DUT is able to forward the traffic for at\n      least 15 seconds before\
    \ any test activities are performed.  The\n      traffic should use the minimum\
    \ frame size possible on the media\n      used in the testing, and the rate should\
    \ be sufficient for the DUT\n      to attain the maximum forwarding throughput.\
    \  This enables a finer\n      granularity in the reset time measurement.\n  \
    \    Third, perform the primary Route Processor (RP) hardware reset at\n     \
    \ this point.  This entails, for example, physically removing the RP\n      or\
    \ triggering a hardware reset by other means (e.g., command line\n      interface,\
    \ physical switch, etc.).  It is up to the operator to\n      decide whether or\
    \ not the primary RP needs to be re-inserted after\n      a grace period.\n  \
    \    Finally, complete the characterization by recording the frame loss\n    \
    \  or timestamps (as reported by the test tool) and calculating the\n      reset\
    \ time (as defined in Section 1.3).\n   Reporting Format\n      The reset results\
    \ are potentially reported twice, one for the\n      default switchover behavior\
    \ (i.e., the DUT without any switchover-\n      specific enhanced configuration)\
    \ and the other for the switchover-\n      specific behavior if it exists (i.e.,\
    \ the DUT configured for\n      optimized switchover capabilities that minimize\
    \ the downtime\n      during the actual switchover).\n      The reporting format\
    \ is defined in Section 1.4 and also includes\n      any specific redundancy scheme\
    \ in place.\n"
- title: 4.1.2.  Line Card (LC) Removal and Insertion (REQUIRED)
  contents:
  - "4.1.2.  Line Card (LC) Removal and Insertion (REQUIRED)\n   The Line Card (LC)\
    \ is the DUT component that is responsible for\n   packet forwarding.\n   Objective\n\
    \      To characterize the time needed for a DUT to recover from a line-\n   \
    \   card removal and insertion event.\n   Procedure\n      For this test, the\
    \ line card that is being hardware-reset MUST be\n      on the forwarding path,\
    \ and all destinations MUST be directly\n      connected.\n      First, complete\
    \ some or all of the following operational tasks:\n      save the current DUT\
    \ configuration, specify boot parameters,\n      ensure the appropriate software\
    \ files are available, or perform\n      additional operating system or hardware-related\
    \ tasks.\n      Second, ensure that the DUT is able to forward the traffic for\
    \ at\n      least 15 seconds before any test activities are performed.  The\n\
    \      traffic should use the minimum frame size possible on the media\n     \
    \ used in the testing, and the rate should be sufficient for the DUT\n      to\
    \ attain the maximum forwarding throughput.  This enables a finer\n      granularity\
    \ in the reset time measurement.\n      Third, perform the Line Card (LC) hardware\
    \ reset at this point.\n      This entails, for example, physically removing the\
    \ LC to later re-\n      insert it or triggering a hardware reset by other means\
    \ (e.g.,\n      CLI, physical switch, etc.).\n      Finally, complete the characterization\
    \ by recording the frame loss\n      or timestamps (as reported by the test tool)\
    \ and calculating the\n      reset time (as defined in Section 1.3).\n   Reporting\
    \ Format\n      The reporting format is defined in Section 1.4.\n"
- title: 4.2.  Software Reset Tests
  contents:
  - "4.2.  Software Reset Tests\n   A software reset test characterizes the time needed\
    \ for a DUT to\n   recover from a software reset.\n   In contrast to a hardware\
    \ reset, a software reset involves only the\n   re-initialization of the execution,\
    \ data structures, and partial\n   state within the software running on the DUT\
    \ module(s).\n   A software reset is initiated, for example, from the DUT's CLI.\n"
- title: 4.2.1.  Operating System (OS) Reset (REQUIRED)
  contents:
  - "4.2.1.  Operating System (OS) Reset (REQUIRED)\n   Objective\n      To characterize\
    \ the time needed for a DUT to recover from an\n      operating system (OS) software\
    \ reset.\n   Procedure\n      First, complete some or all of the following operational\
    \ tasks:\n      save the current DUT configuration, specify software boot\n  \
    \    parameters, ensure the appropriate software files are available,\n      or\
    \ perform additional operating system tasks.\n      Second, ensure that the DUT\
    \ is able to forward the traffic for at\n      least 15 seconds before any test\
    \ activities are performed.  The\n      traffic should use the minimum frame size\
    \ possible on the media\n      used in the testing, and the rate should be sufficient\
    \ for the DUT\n      to attain the maximum forwarding throughput.  This enables\
    \ a finer\n      granularity in the reset time measurement.\n      Third, trigger\
    \ an operating system re-initialization in the DUT by\n      operational means\
    \ such as use of the DUT's CLI or other management\n      interface.\n      Finally,\
    \ complete the characterization by recording the frame loss\n      or timestamps\
    \ (as reported by the test tool) and calculating the\n      reset time (as defined\
    \ in Section 1.3).\n   Reporting Format\n      The reporting format is defined\
    \ in Section 1.4.\n"
- title: 4.2.2.  Process Reset (OPTIONAL)
  contents:
  - "4.2.2.  Process Reset (OPTIONAL)\n   Objective\n      To characterize the time\
    \ needed for a DUT to recover from a\n      software process reset.\n      Such\
    \ a time period may depend upon the number and types of\n      processes running\
    \ in the DUT and which ones are tested.  Different\n      implementations of forwarding\
    \ devices include various common\n      processes.  A process reset should be\
    \ performed only in the\n      processes most relevant to the tester and most\
    \ impactful to\n      forwarding.\n   Procedure\n      First, complete some or\
    \ all of the following operational tasks:\n      save the current DUT configuration,\
    \ specify software parameters or\n      environmental variables, or perform additional\
    \ operating system\n      tasks.\n      Second, ensure that the DUT is able to\
    \ forward the traffic for at\n      least 15 seconds before any test activities\
    \ are performed.  The\n      traffic should use the minimum frame size possible\
    \ on the media\n      used in the testing, and the rate should be sufficient for\
    \ the DUT\n      to attain the maximum forwarding throughput.  This enables a\
    \ finer\n      granularity in the reset time measurement.\n      Third, trigger\
    \ a process reset for each process running in the DUT\n      and considered for\
    \ testing from a management interface (e.g., by\n      means of the CLI, etc.).\n\
    \      Finally, complete the characterization by recording the frame loss\n  \
    \    or timestamps (as reported by the test tool) and calculating the\n      reset\
    \ time (as defined in Section 1.3).\n   Reporting Format\n      The reporting\
    \ format is defined in Section 1.4 and is used for\n      each process running\
    \ in the DUT and tested.  Given the\n      implementation nature of this test,\
    \ details of the actual process\n      tested should be included along with the\
    \ statement.\n"
- title: 4.3.  Power Interruption Test
  contents:
  - "4.3.  Power Interruption Test\n   \"Power interruption\" refers to the complete\
    \ loss of power on the DUT.\n   It can be viewed as a special case of a hardware\
    \ reset, triggered by\n   the loss of the power supply to the DUT or its components,\
    \ and is\n   characterized by the re-initialization of all hardware and software\n\
    \   in the DUT.\n"
- title: 4.3.1.  Power Interruption (REQUIRED)
  contents:
  - "4.3.1.  Power Interruption (REQUIRED)\n   Objective\n      To characterize the\
    \ time needed for a DUT to recover from a\n      complete loss of electric power\
    \ or complete power interruption.\n      This test simulates a complete power\
    \ failure or outage and should\n      be indicative of the DUT/SUT's behavior\
    \ during such event.\n   Procedure\n      First, ensure that the entire DUT is\
    \ at a permanent state to which\n      it will return after the power interruption\
    \ by performing some or\n      all of the following operational tasks: save the\
    \ current DUT\n      configuration, specify boot parameters, ensure the appropriate\n\
    \      software files are available, or perform additional operating\n      system\
    \ or hardware-related tasks.\n      Second, ensure that the DUT is able to forward\
    \ the traffic for at\n      least 15 seconds before any test activities are performed.\
    \  The\n      traffic should use the minimum frame size possible on the media\n\
    \      used in the testing, and the rate should be sufficient for the DUT\n  \
    \    to attain the maximum forwarding throughput.  This enables a finer\n    \
    \  granularity in the reset time measurement.\n      Third, interrupt the power\
    \ (AC or DC) that feeds the corresponding\n      DUT's power supplies at this\
    \ point.  This entails, for example,\n      physically removing the power supplies\
    \ in the DUT to later re-\n      insert them or simply disconnecting or switching\
    \ off their power\n      feeds (AC or DC, as applicable).  The actual power interruption\n\
    \      should last at least 15 seconds.\n      Finally, complete the characterization\
    \ by recording the frame loss\n      or timestamps (as reported by the test tool)\
    \ and calculating the\n      reset time (as defined in Section 1.3).\n      For\
    \ easier comparison with other testing, 15 seconds are removed\n      from the\
    \ reported reset time.\n   Reporting Format\n      The reporting format is defined\
    \ in Section 1.4.\n"
- title: 5.  Security Considerations
  contents:
  - "5.  Security Considerations\n   Benchmarking activities, as described in this\
    \ document, are limited\n   to technology characterization using controlled stimuli\
    \ in a\n   laboratory environment, with dedicated address space and the\n   constraints\
    \ specified in the sections above.\n   The benchmarking network topology will\
    \ be an independent test setup\n   and MUST NOT be connected to devices that may\
    \ forward the test\n   traffic into a production network or misroute traffic to\
    \ the test\n   management network.\n   Furthermore, benchmarking is performed\
    \ on a \"black-box\" basis,\n   relying solely on measurements observable externally\
    \ to the DUT/SUT.\n   Special capabilities SHOULD NOT exist in the DUT/SUT specifically\
    \ for\n   benchmarking purposes.  Any implications for network security arising\n\
    \   from the DUT/SUT SHOULD be identical in the lab and in production\n   networks.\n\
    \   There are no specific security considerations within the scope of\n   this\
    \ document.\n"
- title: 6.  Acknowledgments
  contents:
  - "6.  Acknowledgments\n   The authors would like to thank Ron Bonica, who motivated\
    \ us to write\n   this document.  The authors would also like to thank Al Morton,\n\
    \   Andrew Yourtchenko, David Newman, John E. Dawson, Timmons C. Player,\n   Jan\
    \ Novak, Steve Maxwell, Ilya Varlashkin, and Sarah Banks for\n   providing thorough\
    \ review, useful suggestions, and valuable input.\n"
- title: 7.  References
  contents:
  - '7.  References

    '
- title: 7.1.  Normative References
  contents:
  - "7.1.  Normative References\n   [RFC1242] Bradner, S., \"Benchmarking Terminology\
    \ for Network\n             Interconnection Devices\", RFC 1242, July 1991.\n\
    \   [RFC2119] Bradner, S., \"Key words for use in RFCs to Indicate\n         \
    \    Requirement Levels\", BCP 14, RFC 2119, March 1997.\n   [RFC2544] Bradner,\
    \ S. and J. McQuaid, \"Benchmarking Methodology for\n             Network Interconnect\
    \ Devices\", RFC 2544, March 1999.\n"
- title: 7.2.  Informative References
  contents:
  - "7.2.  Informative References\n   [IGPConv] Poretsky, S., Imhoff, B., and K. Michielsen,\
    \ \"Benchmarking\n             Methodology for Link-State IGP Data Plane Route\n\
    \             Convergence\", Work in Progress, February 2011.\n   [RFC5180] Popoviciu,\
    \ C., Hamza, A., Van de Velde, G., and D.\n             Dugatkin, \"IPv6 Benchmarking\
    \ Methodology for Network\n             Interconnect Devices\", RFC 5180, May\
    \ 2008.\n   [RFC5695] Akhter, A., Asati, R., and C. Pignataro, \"MPLS Forwarding\n\
    \             Benchmarking Methodology for IP Flows\", RFC 5695, November\n  \
    \           2009.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Rajiv Asati\n   Cisco Systems\n   7025-6 Kit Creek Road\n\
    \   Research Triangle Park, NC 27709\n   USA\n   EMail: rajiva@cisco.com\n   Carlos\
    \ Pignataro\n   Cisco Systems\n   7200-12 Kit Creek Road\n   Research Triangle\
    \ Park, NC 27709\n   USA\n   EMail: cpignata@cisco.com\n   Fernando Calabria\n\
    \   Cisco Systems\n   7200-12 Kit Creek Road\n   Research Triangle Park, NC 27709\n\
    \   USA\n   EMail: fcalabri@cisco.com\n   Cesar Olvera Morales\n   Consulintel\n\
    \   Joaquin Turina, 2\n   Pozuelo de Alarcon, Madrid, E-28224\n   Spain\n   EMail:\
    \ cesar.olvera@consulintel.es\n"
