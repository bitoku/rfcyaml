- title: __initial_text__
  contents:
  - "                            NASA Glenn Research Center/Sterling Software\n  \
    \                 Known TCP Implementation Problems\n"
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (1999).  All Rights Reserved.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  INTRODUCTION....................................................2\n\
    \   2.  KNOWN IMPLEMENTATION PROBLEMS...................................3\n  \
    \   2.1  No initial slow start........................................3\n    \
    \ 2.2  No slow start after retransmission timeout...................6\n     2.3\
    \  Uninitialized CWND...........................................9\n     2.4  Inconsistent\
    \ retransmission.................................11\n     2.5  Failure to retain\
    \ above-sequence data.......................13\n     2.6  Extra additive constant\
    \ in congestion avoidance.............17\n     2.7  Initial RTO too low.........................................23\n\
    \     2.8  Failure of window deflation after loss recovery.............26\n  \
    \   2.9  Excessively short keepalive connection timeout..............28\n    \
    \ 2.10 Failure to back off retransmission timeout..................31\n     2.11\
    \ Insufficient interval between keepalives....................34\n     2.12 Window\
    \ probe deadlock.......................................36\n     2.13 Stretch ACK\
    \ violation.......................................40\n     2.14 Retransmission\
    \ sends multiple packets.......................43\n     2.15 Failure to send FIN\
    \ notification promptly...................45\n     2.16 Failure to send a RST\
    \ after Half Duplex Close...............47\n     2.17 Failure to RST on close\
    \ with data pending...................50\n     2.18 Options missing from TCP MSS\
    \ calculation....................54\n   3.  SECURITY CONSIDERATIONS........................................56\n\
    \   4.  ACKNOWLEDGEMENTS...............................................56\n  \
    \ 5.  REFERENCES.....................................................57\n   6.\
    \  AUTHORS' ADDRESSES.............................................58\n   7.  FULL\
    \ COPYRIGHT STATEMENT.......................................60\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   This memo catalogs a number of known TCP implementation problems.\n\
    \   The goal in doing so is to improve conditions in the existing\n   Internet\
    \ by enhancing the quality of current TCP/IP implementations.\n   It is hoped\
    \ that both performance and correctness issues can be\n   resolved by making implementors\
    \ aware of the problems and their\n   solutions.  In the long term, it is hoped\
    \ that this will provide a\n   reduction in unnecessary traffic on the network,\
    \ the rate of\n   connection failures due to protocol errors, and load on network\n\
    \   servers due to time spent processing both unsuccessful connections\n   and\
    \ retransmitted data.  This will help to ensure the stability of\n   the global\
    \ Internet.\n   Each problem is defined as follows:\n   Name of Problem\n    \
    \  The name associated with the problem.  In this memo, the name is\n      given\
    \ as a subsection heading.\n   Classification\n      One or more problem categories\
    \ for which the problem is\n      classified:  \"congestion control\", \"performance\"\
    , \"reliability\",\n      \"resource management\".\n   Description\n      A definition\
    \ of the problem, succinct but including necessary\n      background material.\n\
    \   Significance\n      A brief summary of the sorts of environments for which\
    \ the problem\n      is significant.\n   Implications\n      Why the problem is\
    \ viewed as a problem.\n   Relevant RFCs\n      The RFCs defining the TCP specification\
    \ with which the problem\n      conflicts.  These RFCs often qualify behavior\
    \ using terms such as\n      MUST, SHOULD, MAY, and others written capitalized.\
    \  See RFC 2119\n      for the exact interpretation of these terms.\n   Trace\
    \ file demonstrating the problem\n      One or more ASCII trace files demonstrating\
    \ the problem, if\n      applicable.\n   Trace file demonstrating correct behavior\n\
    \      One or more examples of how correct behavior appears in a trace,\n    \
    \  if applicable.\n   References\n      References that further discuss the problem.\n\
    \   How to detect\n      How to test an implementation to see if it exhibits the\
    \ problem.\n      This discussion may include difficulties and subtleties associated\n\
    \      with causing the problem to manifest itself, and with interpreting\n  \
    \    traces to detect the presence of the problem (if applicable).\n   How to\
    \ fix\n      For known causes of the problem, how to correct the\n      implementation.\n"
- title: 2. Known implementation problems
  contents:
  - '2. Known implementation problems

    '
- title: 2.1.
  contents:
  - "2.1.\n   Name of Problem\n      No initial slow start\n   Classification\n  \
    \    Congestion control\n   Description\n      When a TCP begins transmitting\
    \ data, it is required by RFC 1122,\n      4.2.2.15, to engage in a \"slow start\"\
    \ by initializing its\n      congestion window, cwnd, to one packet (one segment\
    \ of the maximum\n      size).  (Note that an experimental change to TCP, documented\
    \ in\n      [RFC2414], allows an initial value somewhat larger than one\n    \
    \  packet.)  It subsequently increases cwnd by one packet for each\n      ACK\
    \ it receives for new data.  The minimum of cwnd and the\n      receiver's advertised\
    \ window bounds the highest sequence number\n      the TCP can transmit.  A TCP\
    \ that fails to initialize and\n      increment cwnd in this fashion exhibits\
    \ \"No initial slow start\".\n   Significance\n      In congested environments,\
    \ detrimental to the performance of other\n      connections, and possibly to\
    \ the connection itself.\n   Implications\n      A TCP failing to slow start when\
    \ beginning a connection results in\n      traffic bursts that can stress the\
    \ network, leading to excessive\n      queueing delays and packet loss.\n    \
    \  Implementations exhibiting this problem might do so because they\n      suffer\
    \ from the general problem of not including the required\n      congestion window.\
    \  These implementations will also suffer from\n      \"No slow start after retransmission\
    \ timeout\".\n      There are different shades of \"No initial slow start\". \
    \ From the\n      perspective of stressing the network, the worst is a connection\n\
    \      that simply always sends based on the receiver's advertised\n      window,\
    \ with no notion of a separate congestion window.  Another\n      form is described\
    \ in \"Uninitialized CWND\" below.\n   Relevant RFCs\n      RFC 1122 requires\
    \ use of slow start.  RFC 2001 gives the specifics\n      of slow start.\n   Trace\
    \ file demonstrating it\n      Made using tcpdump [Jacobson89] recording at the\
    \ connection\n      responder.  No losses reported by the packet filter.\n   10:40:42.244503\
    \ B > A: S 1168512000:1168512000(0) win 32768\n                           <mss\
    \ 1460,nop,wscale 0> (DF) [tos 0x8]\n   10:40:42.259908 A > B: S 3688169472:3688169472(0)\n\
    \                           ack 1168512001 win 32768 <mss 1460>\n   10:40:42.389992\
    \ B > A: . ack 1 win 33580 (DF) [tos 0x8]\n   10:40:42.664975 A > B: P 1:513(512)\
    \ ack 1 win 32768\n   10:40:42.700185 A > B: . 513:1973(1460) ack 1 win 32768\n\
    \   10:40:42.718017 A > B: . 1973:3433(1460) ack 1 win 32768\n   10:40:42.762945\
    \ A > B: . 3433:4893(1460) ack 1 win 32768\n   10:40:42.811273 A > B: . 4893:6353(1460)\
    \ ack 1 win 32768\n   10:40:42.829149 A > B: . 6353:7813(1460) ack 1 win 32768\n\
    \   10:40:42.853687 B > A: . ack 1973 win 33580 (DF) [tos 0x8]\n   10:40:42.864031\
    \ B > A: . ack 3433 win 33580 (DF) [tos 0x8]\n      After the third packet, the\
    \ connection is established.  A, the\n      connection responder, begins transmitting\
    \ to B, the connection\n      initiator.  Host A quickly sends 6 packets comprising\
    \ 7812 bytes,\n      even though the SYN exchange agreed upon an MSS of 1460 bytes\n\
    \      (implying an initial congestion window of 1 segment corresponds to\n  \
    \    1460 bytes), and so A should have sent at most 1460 bytes.\n      The ACKs\
    \ sent by B to A in the last two lines indicate that this\n      trace is not\
    \ a measurement error (slow start really occurring but\n      the corresponding\
    \ ACKs having been dropped by the packet filter).\n      A second trace confirmed\
    \ that the problem is repeatable.\n   Trace file demonstrating correct behavior\n\
    \      Made using tcpdump recording at the connection originator.  No\n      losses\
    \ reported by the packet filter.\n   12:35:31.914050 C > D: S 1448571845:1448571845(0)\n\
    \                            win 4380 <mss 1460>\n   12:35:32.068819 D > C: S\
    \ 1755712000:1755712000(0)\n                            ack 1448571846 win 4096\n\
    \   12:35:32.069341 C > D: . ack 1 win 4608\n   12:35:32.075213 C > D: P 1:513(512)\
    \ ack 1 win 4608\n   12:35:32.286073 D > C: . ack 513 win 4096\n   12:35:32.287032\
    \ C > D: . 513:1025(512) ack 1 win 4608\n   12:35:32.287506 C > D: . 1025:1537(512)\
    \ ack 1 win 4608\n   12:35:32.432712 D > C: . ack 1537 win 4096\n   12:35:32.433690\
    \ C > D: . 1537:2049(512) ack 1 win 4608\n   12:35:32.434481 C > D: . 2049:2561(512)\
    \ ack 1 win 4608\n   12:35:32.435032 C > D: . 2561:3073(512) ack 1 win 4608\n\
    \   12:35:32.594526 D > C: . ack 3073 win 4096\n   12:35:32.595465 C > D: . 3073:3585(512)\
    \ ack 1 win 4608\n   12:35:32.595947 C > D: . 3585:4097(512) ack 1 win 4608\n\
    \   12:35:32.596414 C > D: . 4097:4609(512) ack 1 win 4608\n   12:35:32.596888\
    \ C > D: . 4609:5121(512) ack 1 win 4608\n   12:35:32.733453 D > C: . ack 4097\
    \ win 4096\n   References\n      This problem is documented in [Paxson97].\n \
    \  How to detect\n      For implementations always manifesting this problem, it\
    \ shows up\n      immediately in a packet trace or a sequence plot, as illustrated\n\
    \      above.\n   How to fix\n      If the root problem is that the implementation\
    \ lacks a notion of a\n      congestion window, then unfortunately this requires\
    \ significant\n      work to fix.  However, doing so is important, as such\n \
    \     implementations also exhibit \"No slow start after retransmission\n    \
    \  timeout\".\n"
- title: 2.2.
  contents:
  - "2.2.\n   Name of Problem\n      No slow start after retransmission timeout\n\
    \   Classification\n      Congestion control\n   Description\n      When a TCP\
    \ experiences a retransmission timeout, it is required by\n      RFC 1122, 4.2.2.15,\
    \ to engage in \"slow start\" by initializing its\n      congestion window, cwnd,\
    \ to one packet (one segment of the maximum\n      size).  It subsequently increases\
    \ cwnd by one packet for each ACK\n      it receives for new data until it reaches\
    \ the \"congestion\n      avoidance\" threshold, ssthresh, at which point the\
    \ congestion\n      avoidance algorithm for updating the window takes over.  A\
    \ TCP\n      that fails to enter slow start upon a timeout exhibits \"No slow\n\
    \      start after retransmission timeout\".\n   Significance\n      In congested\
    \ environments, severely detrimental to the performance\n      of other connections,\
    \ and also the connection itself.\n   Implications\n      Entering slow start\
    \ upon timeout forms one of the cornerstones of\n      Internet congestion stability,\
    \ as outlined in [Jacobson88].  If\n      TCPs fail to do so, the network becomes\
    \ at risk of suffering\n      \"congestion collapse\" [RFC896].\n   Relevant RFCs\n\
    \      RFC 1122 requires use of slow start after loss.  RFC 2001 gives\n     \
    \ the specifics of how to implement slow start.  RFC 896 describes\n      congestion\
    \ collapse.\n      The retransmission timeout discussed here should not be confused\n\
    \      with the separate \"fast recovery\" retransmission mechanism\n      discussed\
    \ in RFC 2001.\n   Trace file demonstrating it\n      Made using tcpdump recording\
    \ at the sending TCP (A).  No losses\n      reported by the packet filter.\n \
    \  10:40:59.090612 B > A: . ack 357125 win 33580 (DF) [tos 0x8]\n   10:40:59.222025\
    \ A > B: . 357125:358585(1460) ack 1 win 32768\n   10:40:59.868871 A > B: . 357125:358585(1460)\
    \ ack 1 win 32768\n   10:41:00.016641 B > A: . ack 364425 win 33580 (DF) [tos\
    \ 0x8]\n   10:41:00.036709 A > B: . 364425:365885(1460) ack 1 win 32768\n   10:41:00.045231\
    \ A > B: . 365885:367345(1460) ack 1 win 32768\n   10:41:00.053785 A > B: . 367345:368805(1460)\
    \ ack 1 win 32768\n   10:41:00.062426 A > B: . 368805:370265(1460) ack 1 win 32768\n\
    \   10:41:00.071074 A > B: . 370265:371725(1460) ack 1 win 32768\n   10:41:00.079794\
    \ A > B: . 371725:373185(1460) ack 1 win 32768\n   10:41:00.089304 A > B: . 373185:374645(1460)\
    \ ack 1 win 32768\n   10:41:00.097738 A > B: . 374645:376105(1460) ack 1 win 32768\n\
    \   10:41:00.106409 A > B: . 376105:377565(1460) ack 1 win 32768\n   10:41:00.115024\
    \ A > B: . 377565:379025(1460) ack 1 win 32768\n   10:41:00.123576 A > B: . 379025:380485(1460)\
    \ ack 1 win 32768\n   10:41:00.132016 A > B: . 380485:381945(1460) ack 1 win 32768\n\
    \   10:41:00.141635 A > B: . 381945:383405(1460) ack 1 win 32768\n   10:41:00.150094\
    \ A > B: . 383405:384865(1460) ack 1 win 32768\n   10:41:00.158552 A > B: . 384865:386325(1460)\
    \ ack 1 win 32768\n   10:41:00.167053 A > B: . 386325:387785(1460) ack 1 win 32768\n\
    \   10:41:00.175518 A > B: . 387785:389245(1460) ack 1 win 32768\n   10:41:00.210835\
    \ A > B: . 389245:390705(1460) ack 1 win 32768\n   10:41:00.226108 A > B: . 390705:392165(1460)\
    \ ack 1 win 32768\n   10:41:00.241524 B > A: . ack 389245 win 8760 (DF) [tos 0x8]\n\
    \      The first packet indicates the ack point is 357125.  130 msec\n      after\
    \ receiving the ACK, A transmits the packet after the ACK\n      point, 357125:358585.\
    \  640 msec after this transmission, it\n      retransmits 357125:358585, in an\
    \ apparent retransmission timeout.\n      At this point, A's cwnd should be one\
    \ MSS, or 1460 bytes, as A\n      enters slow start.  The trace is consistent\
    \ with this possibility.\n      B replies with an ACK of 364425, indicating that\
    \ A has filled a\n      sequence hole.  At this point, A's cwnd should be 1460*2\
    \ = 2920\n      bytes, since in slow start receiving an ACK advances cwnd by MSS.\n\
    \      However, A then launches 19 consecutive packets, which is\n      inconsistent\
    \ with slow start.\n      A second trace confirmed that the problem is repeatable.\n\
    \   Trace file demonstrating correct behavior\n      Made using tcpdump recording\
    \ at the sending TCP (C).  No losses\n      reported by the packet filter.\n \
    \  12:35:48.442538 C > D: P 465409:465921(512) ack 1 win 4608\n   12:35:48.544483\
    \ D > C: . ack 461825 win 4096\n   12:35:48.703496 D > C: . ack 461825 win 4096\n\
    \   12:35:49.044613 C > D: . 461825:462337(512) ack 1 win 4608\n   12:35:49.192282\
    \ D > C: . ack 465921 win 2048\n   12:35:49.192538 D > C: . ack 465921 win 4096\n\
    \   12:35:49.193392 C > D: P 465921:466433(512) ack 1 win 4608\n   12:35:49.194726\
    \ C > D: P 466433:466945(512) ack 1 win 4608\n   12:35:49.350665 D > C: . ack\
    \ 466945 win 4096\n   12:35:49.351694 C > D: . 466945:467457(512) ack 1 win 4608\n\
    \   12:35:49.352168 C > D: . 467457:467969(512) ack 1 win 4608\n   12:35:49.352643\
    \ C > D: . 467969:468481(512) ack 1 win 4608\n   12:35:49.506000 D > C: . ack\
    \ 467969 win 3584\n      After C transmits the first packet shown to D, it takes\
    \ no action\n      in response to D's ACKs for 461825, because the first packet\n\
    \      already reached the advertised window limit of 4096 bytes above\n     \
    \ 461825.  600 msec after transmitting the first packet, C\n      retransmits\
    \ 461825:462337, presumably due to a timeout.  Its\n      congestion window is\
    \ now MSS (512 bytes).\n      D acks 465921, indicating that C's retransmission\
    \ filled a\n      sequence hole.  This ACK advances C's cwnd from 512 to 1024.\
    \  Very\n      shortly after, D acks 465921 again in order to update the offered\n\
    \      window from 2048 to 4096.  This ACK does not advance cwnd since it\n  \
    \    is not for new data.  Very shortly after, C responds to the newly\n     \
    \ enlarged window by transmitting two packets.  D acks both,\n      advancing\
    \ cwnd from 1024 to 1536.  C in turn transmits three\n      packets.\n   References\n\
    \      This problem is documented in [Paxson97].\n   How to detect\n      Packet\
    \ loss is common enough in the Internet that generally it is\n      not difficult\
    \ to find an Internet path that will force\n      retransmission due to packet\
    \ loss.\n      If the effective window prior to loss is large enough, however,\n\
    \      then the TCP may retransmit using the \"fast recovery\" mechanism\n   \
    \   described in RFC 2001.  In a packet trace, the signature of fast\n      recovery\
    \ is that the packet retransmission occurs in response to\n      the receipt of\
    \ three duplicate ACKs, and subsequent duplicate ACKs\n      may lead to the transmission\
    \ of new data, above both the ack point\n      and the highest sequence transmitted\
    \ so far.  An absence of three\n      duplicate ACKs prior to retransmission suffices\
    \ to distinguish\n      between timeout and fast recovery retransmissions.  In\
    \ the face of\n      only observing fast recovery retransmissions, generally it\
    \ is not\n      difficult to repeat the data transfer until observing a timeout\n\
    \      retransmission.\n      Once armed with a trace exhibiting a timeout retransmission,\n\
    \      determining whether the TCP follows slow start is done by\n      computing\
    \ the correct progression of cwnd and comparing it to the\n      amount of data\
    \ transmitted by the TCP subsequent to the timeout\n      retransmission.\n  \
    \ How to fix\n      If the root problem is that the implementation lacks a notion\
    \ of a\n      congestion window, then unfortunately this requires significant\n\
    \      work to fix.  However, doing so is critical, for reasons outlined\n   \
    \   above.\n"
- title: 2.3.
  contents:
  - "2.3.\n   Name of Problem\n      Uninitialized CWND\n   Classification\n     \
    \ Congestion control\n   Description\n      As described above for \"No initial\
    \ slow start\", when a TCP\n      connection begins cwnd is initialized to one\
    \ segment (or perhaps a\n      few segments, if experimenting with [RFC2414]).\
    \  One particular\n      form of \"No initial slow start\", worth separate mention\
    \ as the bug\n      is fairly widely deployed, is \"Uninitialized CWND\".  That\
    \ is,\n      while the TCP implements the proper slow start mechanism, it fails\n\
    \      to initialize cwnd properly, so slow start in fact fails to occur.\n  \
    \    One way the bug can occur is if, during the connection\n      establishment\
    \ handshake, the SYN ACK packet arrives without an MSS\n      option.  The faulty\
    \ implementation uses receipt of the MSS option\n      to initialize cwnd to one\
    \ segment; if the option fails to arrive,\n      then cwnd is instead initialized\
    \ to a very large value.\n   Significance\n      In congested environments, detrimental\
    \ to the performance of other\n      connections, and likely to the connection\
    \ itself.  The burst can\n      be so large (see below) that it has deleterious\
    \ effects even in\n      uncongested environments.\n   Implications\n      A TCP\
    \ exhibiting this behavior is stressing the network with a\n      large burst\
    \ of packets, which can cause loss in the network.\n   Relevant RFCs\n      RFC\
    \ 1122 requires use of slow start.  RFC 2001 gives the specifics\n      of slow\
    \ start.\n   Trace file demonstrating it\n      This trace was made using tcpdump\
    \ running on host A.  Host A is\n      the sender and host B is the receiver.\
    \  The advertised window and\n      timestamp options have been omitted for clarity,\
    \ except for the\n      first segment sent by host A.  Note that A sends an MSS\
    \ option in\n      its initial SYN but B does not include one in its reply.\n\
    \   16:56:02.226937 A > B: S 237585307:237585307(0) win 8192\n         <mss 536,nop,wscale\
    \ 0,nop,nop,timestamp[|tcp]>\n   16:56:02.557135 B > A: S 1617216000:1617216000(0)\n\
    \         ack 237585308 win 16384\n   16:56:02.557788 A > B: . ack 1 win 8192\n\
    \   16:56:02.566014 A > B: . 1:537(536) ack 1\n   16:56:02.566557 A > B: . 537:1073(536)\
    \ ack 1\n   16:56:02.567120 A > B: . 1073:1609(536) ack 1\n   16:56:02.567662\
    \ A > B: P 1609:2049(440) ack 1\n   16:56:02.568349 A > B: . 2049:2585(536) ack\
    \ 1\n   16:56:02.568909 A > B: . 2585:3121(536) ack 1\n      [54 additional burst\
    \ segments deleted for brevity]\n   16:56:02.936638 A > B: . 32065:32601(536)\
    \ ack 1\n   16:56:03.018685 B > A: . ack 1\n      After the three-way handshake,\
    \ host A bursts 61 segments into the\n      network, before duplicate ACKs on\
    \ the first segment cause a\n      retransmission to occur.  Since host A did\
    \ not wait for the ACK on\n      the first segment before sending additional segments,\
    \ it is\n      exhibiting \"Uninitialized CWND\"\n   Trace file demonstrating\
    \ correct behavior\n      See the example for \"No initial slow start\".\n   References\n\
    \      This problem is documented in [Paxson97].\n   How to detect\n      This\
    \ problem can be detected by examining a packet trace recorded\n      at either\
    \ the sender or the receiver.  However, the bug can be\n      difficult to induce\
    \ because it requires finding a remote TCP peer\n      that does not send an MSS\
    \ option in its SYN ACK.\n   How to fix\n      This problem can be fixed by ensuring\
    \ that cwnd is initialized\n      upon receipt of a SYN ACK, even if the SYN ACK\
    \ does not contain an\n      MSS option.\n"
- title: 2.4.
  contents:
  - "2.4.\n   Name of Problem\n      Inconsistent retransmission\n   Classification\n\
    \      Reliability\n   Description\n      If, for a given sequence number, a sending\
    \ TCP retransmits\n      different data than previously sent for that sequence\
    \ number, then\n      a strong possibility arises that the receiving TCP will\n\
    \      reconstruct a different byte stream than that sent by the sending\n   \
    \   application, depending on which instance of the sequence number it\n     \
    \ accepts.\n      Such a sending TCP exhibits \"Inconsistent retransmission\"\
    .\n   Significance\n      Critical for all environments.\n   Implications\n  \
    \    Reliable delivery of data is a fundamental property of TCP.\n   Relevant\
    \ RFCs\n      RFC 793, section 1.5, discusses the central role of reliability\
    \ in\n      TCP operation.\n   Trace file demonstrating it\n      Made using tcpdump\
    \ recording at the receiving TCP (B).  No losses\n      reported by the packet\
    \ filter.\n   12:35:53.145503 A > B: FP 90048435:90048461(26)\n              \
    \               ack 393464682 win 4096\n                                     \
    \   4500 0042 9644 0000\n                    3006 e4c2 86b1 0401 83f3 010a b2a4\
    \ 0015\n                    055e 07b3 1773 cb6a 5019 1000 68a9 0000\n   data starts\
    \ here>504f 5254 2031 3334 2c31 3737*2c34 2c31\n                    2c31 3738\
    \ 2c31 3635 0d0a\n   12:35:53.146479 B > A: R 393464682:393464682(0) win 8192\n\
    \   12:35:53.851714 A > B: FP 90048429:90048463(34)\n                        \
    \  ack 393464682 win 4096\n                                        4500 004a 965b\
    \ 0000\n                    3006 e4a3 86b1 0401 83f3 010a b2a4 0015\n        \
    \            055e 07ad 1773 cb6a 5019 1000 8bd3 0000\n   data starts here>5041\
    \ 5356 0d0a 504f 5254 2031 3334 2c31\n                    3737*2c31 3035 2c31\
    \ 3431 2c34 2c31 3539\n                    0d0a\n      The sequence numbers shown\
    \ in this trace are absolute and not\n      adjusted to reflect the ISN.  The\
    \ 4-digit hex values show a dump\n      of the packet's IP and TCP headers, as\
    \ well as payload.  A first\n      sends to B data for 90048435:90048461.  The\
    \ corresponding data\n      begins with hex words 504f, 5254, etc.\n      B responds\
    \ with a RST.  Since the recording location was local to\n      B, it is unknown\
    \ whether A received the RST.\n      A then sends 90048429:90048463, which includes\
    \ six sequence\n      positions below the earlier transmission, all 26 positions\
    \ of the\n      earlier transmission, and two additional sequence positions.\n\
    \      The retransmission disagrees starting just after sequence\n      90048447,\
    \ annotated above with a leading '*'.  These two bytes\n      were originally\
    \ transmitted as hex 2c34 but retransmitted as hex\n      2c31.  Subsequent positions\
    \ disagree as well.\n      This behavior has been observed in other traces involving\n\
    \      different hosts.  It is unknown how to repeat it.\n      In this instance,\
    \ no corruption would occur, since B has already\n      indicated it will not\
    \ accept further packets from A.\n      A second example illustrates a slightly\
    \ different instance of the\n      problem.  The tracing again was made with tcpdump\
    \ at the receiving\n      TCP (D).\n   22:23:58.645829 C > D: P 185:212(27) ack\
    \ 565 win 4096\n                                        4500 0043 90a3 0000\n\
    \                    3306 0734 cbf1 9eef 83f3 010a 0525 0015\n               \
    \     a3a2 faba 578c 70a4 5018 1000 9a53 0000\n   data starts here>504f 5254 2032\
    \ 3033 2c32 3431 2c31 3538\n                    2c32 3339 2c35 2c34 330d 0a\n\
    \   22:23:58.646805 D > C: . ack 184 win 8192\n                              \
    \          4500 0028 beeb 0000\n                    3e06 ce06 83f3 010a cbf1 9eef\
    \ 0015 0525\n                    578c 70a4 a3a2 fab9 5010 2000 342f 0000\n   22:31:36.532244\
    \ C > D: FP 186:213(27) ack 565 win 4096\n                                   \
    \     4500 0043 9435 0000\n                    3306 03a2 cbf1 9eef 83f3 010a 0525\
    \ 0015\n                    a3a2 fabb 578c 70a4 5019 1000 9a51 0000\n   data starts\
    \ here>504f 5254 2032 3033 2c32 3431 2c31 3538\n                    2c32 3339\
    \ 2c35 2c34 330d 0a\n      In this trace, sequence numbers are relative.  C sends\
    \ 185:212,\n      but D only sends an ACK for 184 (so sequence number 184 is\n\
    \      missing).  C then sends 186:213.  The packet payload is identical\n   \
    \   to the previous payload, but the base sequence number is one\n      higher,\
    \ resulting in an inconsistent retransmission.\n      Neither trace exhibits checksum\
    \ errors.\n   Trace file demonstrating correct behavior\n      (Omitted, as presumably\
    \ correct behavior is obvious.)\n   References\n      None known.\n   How to detect\n\
    \      This problem unfortunately can be very difficult to detect, since\n   \
    \   available experience indicates it is quite rare that it is\n      manifested.\
    \  No \"trigger\" has been identified that can be used to\n      reproduce the\
    \ problem.\n   How to fix\n      In the absence of a known \"trigger\", we cannot\
    \ always assess how\n      to fix the problem.\n      In one implementation (not\
    \ the one illustrated above), the problem\n      manifested itself when (1) the\
    \ sender received a zero window and\n      stalled; (2) eventually an ACK arrived\
    \ that offered a window\n      larger than that in effect at the time of the stall;\
    \ (3) the\n      sender transmitted out of the buffer of data it held at the time\n\
    \      of the stall, but (4) failed to limit this transfer to the buffer\n   \
    \   length, instead using the newly advertised (and larger) offered\n      window.\
    \  Consequently, in addition to the valid buffer contents,\n      it sent whatever\
    \ garbage values followed the end of the buffer.\n      If it then retransmitted\
    \ the corresponding sequence numbers, at\n      that point it sent the correct\
    \ data, resulting in an inconsistent\n      retransmission.  Note that this instance\
    \ of the problem reflects a\n      more general problem, that of initially transmitting\
    \ incorrect\n      data.\n"
- title: 2.5.
  contents:
  - "2.5.\n   Name of Problem\n      Failure to retain above-sequence data\n   Classification\n\
    \      Congestion control, performance\n   Description\n      When a TCP receives\
    \ an \"above sequence\" segment, meaning one with\n      a sequence number exceeding\
    \ RCV.NXT but below RCV.NXT+RCV.WND, it\n      SHOULD queue the segment for later\
    \ delivery (RFC 1122, 4.2.2.20).\n      (See RFC 793 for the definition of RCV.NXT\
    \ and RCV.WND.)  A TCP\n      that fails to do so is said to exhibit \"Failure\
    \ to retain above-\n      sequence data\".\n      It may sometimes be appropriate\
    \ for a TCP to discard above-\n      sequence data to reclaim memory.  If they\
    \ do so only rarely, then\n      we would not consider them to exhibit this problem.\
    \  Instead, the\n      particular concern is with TCPs that always discard above-sequence\n\
    \      data.\n   Significance\n      In environments prone to packet loss, detrimental\
    \ to the\n      performance of both other connections and the connection itself.\n\
    \   Implications\n      In times of congestion, a failure to retain above-sequence\
    \ data\n      will lead to numerous otherwise-unnecessary retransmissions,\n \
    \     aggravating the congestion and potentially reducing performance by\n   \
    \   a large factor.\n   Relevant RFCs\n      RFC 1122 revises RFC 793 by upgrading\
    \ the latter's MAY to a SHOULD\n      on this issue.\n   Trace file demonstrating\
    \ it\n      Made using tcpdump recording at the receiving TCP.  No losses\n  \
    \    reported by the packet filter.\n      B is the TCP sender, A the receiver.\
    \  A exhibits failure to retain\n      above sequence-data:\n   10:38:10.164860\
    \ B > A: . 221078:221614(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.170809 B\
    \ > A: . 221614:222150(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.177183 B >\
    \ A: . 222150:222686(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.225039 A > B:\
    \ . ack 222686 win 25800\n      Here B has sent up to (relative) sequence 222686\
    \ in-sequence, and\n      A accordingly acknowledges.\n   10:38:10.268131 B >\
    \ A: . 223222:223758(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.337995 B > A:\
    \ . 223758:224294(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.344065 B > A: .\
    \ 224294:224830(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.350169 B > A: . 224830:225366(536)\
    \ ack 1 win 33232 [tos 0x8]\n   10:38:10.356362 B > A: . 225366:225902(536) ack\
    \ 1 win 33232 [tos 0x8]\n   10:38:10.362445 B > A: . 225902:226438(536) ack 1\
    \ win 33232 [tos 0x8]\n   10:38:10.368579 B > A: . 226438:226974(536) ack 1 win\
    \ 33232 [tos 0x8]\n   10:38:10.374732 B > A: . 226974:227510(536) ack 1 win 33232\
    \ [tos 0x8]\n   10:38:10.380825 B > A: . 227510:228046(536) ack 1 win 33232 [tos\
    \ 0x8]\n   10:38:10.387027 B > A: . 228046:228582(536) ack 1 win 33232 [tos 0x8]\n\
    \   10:38:10.393053 B > A: . 228582:229118(536) ack 1 win 33232 [tos 0x8]\n  \
    \ 10:38:10.399193 B > A: . 229118:229654(536) ack 1 win 33232 [tos 0x8]\n   10:38:10.405356\
    \ B > A: . 229654:230190(536) ack 1 win 33232 [tos 0x8]\n      A now receives\
    \ 13 additional packets from B.  These are above-\n      sequence because 222686:223222\
    \ was dropped.  The packets do\n      however fit within the offered window of\
    \ 25800.  A does not\n      generate any duplicate ACKs for them.\n      The trace\
    \ contributor (V. Paxson) verified that these 13 packets\n      had valid IP and\
    \ TCP checksums.\n   10:38:11.917728 B > A: . 222686:223222(536) ack 1 win 33232\
    \ [tos 0x8]\n   10:38:11.930925 A > B: . ack 223222 win 32232\n      B times out\
    \ for 222686:223222 and retransmits it.  Upon receiving\n      it, A only acknowledges\
    \ 223222.  Had it retained the valid above-\n      sequence packets, it would\
    \ instead have ack'd 230190.\n   10:38:12.048438 B > A: . 223222:223758(536) ack\
    \ 1 win 33232 [tos 0x8]\n   10:38:12.054397 B > A: . 223758:224294(536) ack 1\
    \ win 33232 [tos 0x8]\n   10:38:12.068029 A > B: . ack 224294 win 31696\n    \
    \  B retransmits two more packets, and A only acknowledges them.\n      This pattern\
    \ continues as B retransmits the entire set of\n      previously-received packets.\n\
    \      A second trace confirmed that the problem is repeatable.\n   Trace file\
    \ demonstrating correct behavior\n      Made using tcpdump recording at the receiving\
    \ TCP (C).  No losses\n      reported by the packet filter.\n   09:11:25.790417\
    \ D > C: . 33793:34305(512) ack 1 win 61440\n   09:11:25.791393 D > C: . 34305:34817(512)\
    \ ack 1 win 61440\n   09:11:25.792369 D > C: . 34817:35329(512) ack 1 win 61440\n\
    \   09:11:25.792369 D > C: . 35329:35841(512) ack 1 win 61440\n   09:11:25.793345\
    \ D > C: . 36353:36865(512) ack 1 win 61440\n   09:11:25.794321 C > D: . ack 35841\
    \ win 59904\n      A sequence hole occurs because 35841:36353 has been dropped.\n\
    \   09:11:25.794321 D > C: . 36865:37377(512) ack 1 win 61440\n   09:11:25.794321\
    \ C > D: . ack 35841 win 59904\n   09:11:25.795297 D > C: . 37377:37889(512) ack\
    \ 1 win 61440\n   09:11:25.795297 C > D: . ack 35841 win 59904\n   09:11:25.796273\
    \ C > D: . ack 35841 win 61440\n   09:11:25.798225 D > C: . 37889:38401(512) ack\
    \ 1 win 61440\n   09:11:25.799201 C > D: . ack 35841 win 61440\n   09:11:25.807009\
    \ D > C: . 38401:38913(512) ack 1 win 61440\n   09:11:25.807009 C > D: . ack 35841\
    \ win 61440\n   (many additional lines omitted)\n   09:11:25.884113 D > C: . 52737:53249(512)\
    \ ack 1 win 61440\n   09:11:25.884113 C > D: . ack 35841 win 61440\n      Each\
    \ additional, above-sequence packet C receives from D elicits a\n      duplicate\
    \ ACK for 35841.\n      09:11:25.887041 D > C: . 35841:36353(512) ack 1 win 61440\n\
    \      09:11:25.887041 C > D: . ack 53249 win 44032\n      D retransmits 35841:36353\
    \ and C acknowledges receipt of data all\n      the way up to 53249.\n   References\n\
    \      This problem is documented in [Paxson97].\n   How to detect\n      Packet\
    \ loss is common enough in the Internet that generally it is\n      not difficult\
    \ to find an Internet path that will result in some\n      above-sequence packets\
    \ arriving.  A TCP that exhibits \"Failure to\n      retain ...\" may not generate\
    \ duplicate ACKs for these packets.\n      However, some TCPs that do retain above-sequence\
    \ data also do not\n      generate duplicate ACKs, so failure to do so does not\
    \ definitively\n      identify the problem.  Instead, the key observation is whether\n\
    \      upon retransmission of the dropped packet, data that was\n      previously\
    \ above-sequence is acknowledged.\n      Two considerations in detecting this\
    \ problem using a packet trace\n      are that it is easiest to do so with a trace\
    \ made at the TCP\n      receiver, in order to unambiguously determine which packets\n\
    \      arrived successfully, and that such packets may still be correctly\n  \
    \    discarded if they arrive with checksum errors.  The latter can be\n     \
    \ tested by capturing the entire packet contents and performing the\n      IP\
    \ and TCP checksum algorithms to verify their integrity; or by\n      confirming\
    \ that the packets arrive with the same checksum and\n      contents as that with\
    \ which they were sent, with a presumption\n      that the sending TCP correctly\
    \ calculates checksums for the\n      packets it transmits.\n      It is considerably\
    \ easier to verify that an implementation does\n      NOT exhibit this problem.\
    \  This can be done by recording a trace\n      at the data sender, and observing\
    \ that sometimes after a\n      retransmission the receiver acknowledges a higher\
    \ sequence number\n      than just that which was retransmitted.\n   How to fix\n\
    \      If the root problem is that the implementation lacks buffer, then\n   \
    \   then unfortunately this requires significant work to fix.\n      However,\
    \ doing so is important, for reasons outlined above.\n"
- title: 2.6.
  contents:
  - "2.6.\n   Name of Problem\n      Extra additive constant in congestion avoidance\n\
    \   Classification\n      Congestion control / performance\n   Description\n \
    \     RFC 1122 section 4.2.2.15 states that TCP MUST implement\n      Jacobson's\
    \ \"congestion avoidance\" algorithm [Jacobson88], which\n      calls for increasing\
    \ the congestion window, cwnd, by:\n           MSS * MSS / cwnd\n      for each\
    \ ACK received for new data [RFC2001].  This has the effect\n      of increasing\
    \ cwnd by approximately one segment in each round trip\n      time.\n      Some\
    \ TCP implementations add an additional fraction of a segment\n      (typically\
    \ MSS/8) to cwnd for each ACK received for new data\n      [Stevens94, Wright95]:\n\
    \           (MSS * MSS / cwnd) + MSS/8\n      These implementations exhibit \"\
    Extra additive constant in\n      congestion avoidance\".\n   Significance\n \
    \     May be detrimental to performance even in completely uncongested\n     \
    \ environments (see Implications).\n      In congested environments, may also\
    \ be detrimental to the\n      performance of other connections.\n   Implications\n\
    \      The extra additive term allows a TCP to more aggressively open its\n  \
    \    congestion window (quadratic rather than linear increase).  For\n      congested\
    \ networks, this can increase the loss rate experienced by\n      all connections\
    \ sharing a bottleneck with the aggressive TCP.\n      However, even for completely\
    \ uncongested networks, the extra\n      additive term can lead to diminished\
    \ performance, as follows.  In\n      congestion avoidance, a TCP sender probes\
    \ the network path to\n      determine its available capacity, which often equates\
    \ to the\n      number of buffers available at a bottleneck link.  With linear\n\
    \      congestion avoidance, the TCP only probes for sufficient capacity\n   \
    \   (buffer) to hold one extra packet per RTT.\n      Thus, when it exceeds the\
    \ available capacity, generally only one\n      packet will be lost (since on\
    \ the previous RTT it already found\n      that the path could sustain a window\
    \ with one less packet in\n      flight).  If the congestion window is sufficiently\
    \ large, then the\n      TCP will recover from this single loss using fast retransmission\n\
    \      and avoid an expensive (in terms of performance) retransmission\n     \
    \ timeout.\n      However, when the additional additive term is used, then cwnd\
    \ can\n      increase by more than one packet per RTT, in which case the TCP\n\
    \      probes more aggressively.  If in the previous RTT it had reached\n    \
    \  the available capacity of the path, then the excess due to the\n      extra\
    \ increase will again be lost, but now this will result in\n      multiple losses\
    \ from the flight instead of a single loss.  TCPs\n      that do not utilize SACK\
    \ [RFC2018] generally will not recover from\n      multiple losses without incurring\
    \ a retransmission timeout\n      [Fall96,Hoe96], significantly diminishing performance.\n\
    \   Relevant RFCs\n      RFC 1122 requires use of the \"congestion avoidance\"\
    \ algorithm.\n      RFC 2001 outlines the fast retransmit/fast recovery algorithms.\n\
    \      RFC 2018 discusses the SACK option.\n   Trace file demonstrating it\n \
    \     Recorded using tcpdump running on the same FDDI LAN as host A.\n      Host\
    \ A is the sender and host B is the receiver.  The connection\n      establishment\
    \ specified an MSS of 4,312 bytes and a window scale\n      factor of 4.  We omit\
    \ the establishment and the first 2.5 MB of\n      data transfer, as the problem\
    \ is best demonstrated when the window\n      has grown to a large value.  At\
    \ the beginning of the trace\n      excerpt, the congestion window is 31 packets.\
    \  The connection is\n      never receiver-window limited, so we omit window advertisements\n\
    \      from the trace for clarity.\n   11:42:07.697951 B > A: . ack 2383006\n\
    \   11:42:07.699388 A > B: . 2508054:2512366(4312)\n   11:42:07.699962 A > B:\
    \ . 2512366:2516678(4312)\n   11:42:07.700012 B > A: . ack 2391630\n   11:42:07.701081\
    \ A > B: . 2516678:2520990(4312)\n   11:42:07.701656 A > B: . 2520990:2525302(4312)\n\
    \   11:42:07.701739 B > A: . ack 2400254\n   11:42:07.702685 A > B: . 2525302:2529614(4312)\n\
    \   11:42:07.703257 A > B: . 2529614:2533926(4312)\n   11:42:07.703295 B > A:\
    \ . ack 2408878\n   11:42:07.704414 A > B: . 2533926:2538238(4312)\n   11:42:07.704989\
    \ A > B: . 2538238:2542550(4312)\n   11:42:07.705040 B > A: . ack 2417502\n  \
    \ 11:42:07.705935 A > B: . 2542550:2546862(4312)\n   11:42:07.706506 A > B: .\
    \ 2546862:2551174(4312)\n   11:42:07.706544 B > A: . ack 2426126\n   11:42:07.707480\
    \ A > B: . 2551174:2555486(4312)\n   11:42:07.708051 A > B: . 2555486:2559798(4312)\n\
    \   11:42:07.708088 B > A: . ack 2434750\n   11:42:07.709030 A > B: . 2559798:2564110(4312)\n\
    \   11:42:07.709604 A > B: . 2564110:2568422(4312)\n   11:42:07.710175 A > B:\
    \ . 2568422:2572734(4312) *\n   11:42:07.710215 B > A: . ack 2443374\n   11:42:07.710799\
    \ A > B: . 2572734:2577046(4312)\n   11:42:07.711368 A > B: . 2577046:2581358(4312)\n\
    \   11:42:07.711405 B > A: . ack 2451998\n   11:42:07.712323 A > B: . 2581358:2585670(4312)\n\
    \   11:42:07.712898 A > B: . 2585670:2589982(4312)\n   11:42:07.712938 B > A:\
    \ . ack 2460622\n   11:42:07.713926 A > B: . 2589982:2594294(4312)\n   11:42:07.714501\
    \ A > B: . 2594294:2598606(4312)\n   11:42:07.714547 B > A: . ack 2469246\n  \
    \ 11:42:07.715747 A > B: . 2598606:2602918(4312)\n   11:42:07.716287 A > B: .\
    \ 2602918:2607230(4312)\n   11:42:07.716328 B > A: . ack 2477870\n   11:42:07.717146\
    \ A > B: . 2607230:2611542(4312)\n   11:42:07.717717 A > B: . 2611542:2615854(4312)\n\
    \   11:42:07.717762 B > A: . ack 2486494\n   11:42:07.718754 A > B: . 2615854:2620166(4312)\n\
    \   11:42:07.719331 A > B: . 2620166:2624478(4312)\n   11:42:07.719906 A > B:\
    \ . 2624478:2628790(4312) **\n   11:42:07.719958 B > A: . ack 2495118\n   11:42:07.720500\
    \ A > B: . 2628790:2633102(4312)\n   11:42:07.721080 A > B: . 2633102:2637414(4312)\n\
    \   11:42:07.721739 B > A: . ack 2503742\n   11:42:07.722348 A > B: . 2637414:2641726(4312)\n\
    \   11:42:07.722918 A > B: . 2641726:2646038(4312)\n   11:42:07.769248 B > A:\
    \ . ack 2512366\n      The receiver's acknowledgment policy is one ACK per two\
    \ packets\n      received.  Thus, for each ACK arriving at host A, two new packets\n\
    \      are sent, except when cwnd increases due to congestion avoidance,\n   \
    \   in which case three new packets are sent.\n      With an ack-every-two-packets\
    \ policy, cwnd should only increase\n      one MSS per 2 RTT.  However, at the\
    \ point marked \"*\" the window\n      increases after 7 ACKs have arrived, and\
    \ then again at \"**\" after\n      6 more ACKs.\n      While we do not have space\
    \ to show the effect, this trace suffered\n      from repeated timeout retransmissions\
    \ due to multiple packet\n      losses during a single RTT.\n   Trace file demonstrating\
    \ correct behavior\n      Made using the same host and tracing setup as above,\
    \ except now\n      A's TCP has been modified to remove the MSS/8 additive constant.\n\
    \      Tcpdump reported 77 packet drops; the excerpt below is fully\n      self-consistent\
    \ so it is unlikely that any of these occurred\n      during the excerpt.\n  \
    \    We again begin when cwnd is 31 packets (this occurs significantly\n     \
    \ later in the trace, because the congestion avoidance is now less\n      aggressive\
    \ with opening the window).\n   14:22:21.236757 B > A: . ack 5194679\n   14:22:21.238192\
    \ A > B: . 5319727:5324039(4312)\n   14:22:21.238770 A > B: . 5324039:5328351(4312)\n\
    \   14:22:21.238821 B > A: . ack 5203303\n   14:22:21.240158 A > B: . 5328351:5332663(4312)\n\
    \   14:22:21.240738 A > B: . 5332663:5336975(4312)\n   14:22:21.270422 B > A:\
    \ . ack 5211927\n   14:22:21.271883 A > B: . 5336975:5341287(4312)\n   14:22:21.272458\
    \ A > B: . 5341287:5345599(4312)\n   14:22:21.279099 B > A: . ack 5220551\n  \
    \ 14:22:21.280539 A > B: . 5345599:5349911(4312)\n   14:22:21.281118 A > B: .\
    \ 5349911:5354223(4312)\n   14:22:21.281183 B > A: . ack 5229175\n   14:22:21.282348\
    \ A > B: . 5354223:5358535(4312)\n   14:22:21.283029 A > B: . 5358535:5362847(4312)\n\
    \   14:22:21.283089 B > A: . ack 5237799\n   14:22:21.284213 A > B: . 5362847:5367159(4312)\n\
    \   14:22:21.284779 A > B: . 5367159:5371471(4312)\n   14:22:21.285976 B > A:\
    \ . ack 5246423\n   14:22:21.287465 A > B: . 5371471:5375783(4312)\n   14:22:21.288036\
    \ A > B: . 5375783:5380095(4312)\n   14:22:21.288073 B > A: . ack 5255047\n  \
    \ 14:22:21.289155 A > B: . 5380095:5384407(4312)\n   14:22:21.289725 A > B: .\
    \ 5384407:5388719(4312)\n   14:22:21.289762 B > A: . ack 5263671\n   14:22:21.291090\
    \ A > B: . 5388719:5393031(4312)\n   14:22:21.291662 A > B: . 5393031:5397343(4312)\n\
    \   14:22:21.291701 B > A: . ack 5272295\n   14:22:21.292870 A > B: . 5397343:5401655(4312)\n\
    \   14:22:21.293441 A > B: . 5401655:5405967(4312)\n   14:22:21.293481 B > A:\
    \ . ack 5280919\n   14:22:21.294476 A > B: . 5405967:5410279(4312)\n   14:22:21.295053\
    \ A > B: . 5410279:5414591(4312)\n   14:22:21.295106 B > A: . ack 5289543\n  \
    \ 14:22:21.296306 A > B: . 5414591:5418903(4312)\n   14:22:21.296878 A > B: .\
    \ 5418903:5423215(4312)\n   14:22:21.296917 B > A: . ack 5298167\n   14:22:21.297716\
    \ A > B: . 5423215:5427527(4312)\n   14:22:21.298285 A > B: . 5427527:5431839(4312)\n\
    \   14:22:21.298324 B > A: . ack 5306791\n   14:22:21.299413 A > B: . 5431839:5436151(4312)\n\
    \   14:22:21.299986 A > B: . 5436151:5440463(4312)\n   14:22:21.303696 B > A:\
    \ . ack 5315415\n   14:22:21.305177 A > B: . 5440463:5444775(4312)\n   14:22:21.305755\
    \ A > B: . 5444775:5449087(4312)\n   14:22:21.308032 B > A: . ack 5324039\n  \
    \ 14:22:21.309525 A > B: . 5449087:5453399(4312)\n   14:22:21.310101 A > B: .\
    \ 5453399:5457711(4312)\n   14:22:21.310144 B > A: . ack 5332663           ***\n\
    \   14:22:21.311615 A > B: . 5457711:5462023(4312)\n   14:22:21.312198 A > B:\
    \ . 5462023:5466335(4312)\n   14:22:21.341876 B > A: . ack 5341287\n   14:22:21.343451\
    \ A > B: . 5466335:5470647(4312)\n   14:22:21.343985 A > B: . 5470647:5474959(4312)\n\
    \   14:22:21.350304 B > A: . ack 5349911\n   14:22:21.351852 A > B: . 5474959:5479271(4312)\n\
    \   14:22:21.352430 A > B: . 5479271:5483583(4312)\n   14:22:21.352484 B > A:\
    \ . ack 5358535\n   14:22:21.353574 A > B: . 5483583:5487895(4312)\n   14:22:21.354149\
    \ A > B: . 5487895:5492207(4312)\n   14:22:21.354205 B > A: . ack 5367159\n  \
    \ 14:22:21.355467 A > B: . 5492207:5496519(4312)\n   14:22:21.356039 A > B: .\
    \ 5496519:5500831(4312)\n   14:22:21.357361 B > A: . ack 5375783\n   14:22:21.358855\
    \ A > B: . 5500831:5505143(4312)\n   14:22:21.359424 A > B: . 5505143:5509455(4312)\n\
    \   14:22:21.359465 B > A: . ack 5384407\n   14:22:21.360605 A > B: . 5509455:5513767(4312)\n\
    \   14:22:21.361181 A > B: . 5513767:5518079(4312)\n   14:22:21.361225 B > A:\
    \ . ack 5393031\n   14:22:21.362485 A > B: . 5518079:5522391(4312)\n   14:22:21.363057\
    \ A > B: . 5522391:5526703(4312)\n   14:22:21.363096 B > A: . ack 5401655\n  \
    \ 14:22:21.364236 A > B: . 5526703:5531015(4312)\n   14:22:21.364810 A > B: .\
    \ 5531015:5535327(4312)\n   14:22:21.364867 B > A: . ack 5410279\n   14:22:21.365819\
    \ A > B: . 5535327:5539639(4312)\n   14:22:21.366386 A > B: . 5539639:5543951(4312)\n\
    \   14:22:21.366427 B > A: . ack 5418903\n   14:22:21.367586 A > B: . 5543951:5548263(4312)\n\
    \   14:22:21.368158 A > B: . 5548263:5552575(4312)\n   14:22:21.368199 B > A:\
    \ . ack 5427527\n   14:22:21.369189 A > B: . 5552575:5556887(4312)\n   14:22:21.369758\
    \ A > B: . 5556887:5561199(4312)\n   14:22:21.369803 B > A: . ack 5436151\n  \
    \ 14:22:21.370814 A > B: . 5561199:5565511(4312)\n   14:22:21.371398 A > B: .\
    \ 5565511:5569823(4312)\n   14:22:21.375159 B > A: . ack 5444775\n   14:22:21.376658\
    \ A > B: . 5569823:5574135(4312)\n   14:22:21.377235 A > B: . 5574135:5578447(4312)\n\
    \   14:22:21.379303 B > A: . ack 5453399\n   14:22:21.380802 A > B: . 5578447:5582759(4312)\n\
    \   14:22:21.381377 A > B: . 5582759:5587071(4312)\n   14:22:21.381947 A > B:\
    \ . 5587071:5591383(4312) ****\n      \"***\" marks the end of the first round\
    \ trip.  Note that cwnd did\n      not increase (as evidenced by each ACK eliciting\
    \ two new data\n      packets).  Only at \"****\", which comes near the end of\
    \ the second\n      round trip, does cwnd increase by one packet.\n      This\
    \ trace did not suffer any timeout retransmissions.  It\n      transferred the\
    \ same amount of data as the first trace in about\n      half as much time.  This\
    \ difference is repeatable between hosts A\n      and B.\n   References\n    \
    \  [Stevens94] and [Wright95] discuss this problem.  The problem of\n      Reno\
    \ TCP failing to recover from multiple losses except via a\n      retransmission\
    \ timeout is discussed in [Fall96,Hoe96].\n   How to detect\n      If source code\
    \ is available, that is generally the easiest way to\n      detect this problem.\
    \  Search for each modification to the cwnd\n      variable; (at least) one of\
    \ these will be for congestion\n      avoidance, and inspection of the related\
    \ code should immediately\n      identify the problem if present.\n      The problem\
    \ can also be detected by closely examining packet\n      traces taken near the\
    \ sender.  During congestion avoidance, cwnd\n      will increase by an additional\
    \ segment upon the receipt of\n      (typically) eight acknowledgements without\
    \ a loss.  This increase\n      is in addition to the one segment increase per\
    \ round trip time (or\n      two round trip times if the receiver is using delayed\
    \ ACKs).\n      Furthermore, graphs of the sequence number vs. time, taken from\n\
    \      packet traces, are normally linear during congestion avoidance.\n     \
    \ When viewing packet traces of transfers from senders exhibiting\n      this\
    \ problem, the graphs appear quadratic instead of linear.\n      Finally, the\
    \ traces will show that, with sufficiently large\n      windows, nearly every\
    \ loss event results in a timeout.\n   How to fix\n      This problem may be corrected\
    \ by removing the \"+ MSS/8\" term from\n      the congestion avoidance code that\
    \ increases cwnd each time an ACK\n      of new data is received.\n"
- title: 2.7.
  contents:
  - "2.7.\n   Name of Problem\n      Initial RTO too low\n   Classification\n    \
    \  Performance\n   Description\n      When a TCP first begins transmitting data,\
    \ it lacks the RTT\n      measurements necessary to have computed an adaptive\
    \ retransmission\n      timeout (RTO).  RFC 1122, 4.2.3.1, states that a TCP SHOULD\n\
    \      initialize RTO to 3 seconds.  A TCP that uses a lower value\n      exhibits\
    \ \"Initial RTO too low\".\n   Significance\n      In environments with large\
    \ RTTs (where \"large\" means any value\n      larger than the initial RTO), TCPs\
    \ will experience very poor\n      performance.\n   Implications\n      Whenever\
    \ RTO < RTT, very poor performance can result as packets\n      are unnecessarily\
    \ retransmitted (because RTO will expire before an\n      ACK for the packet can\
    \ arrive) and the connection enters slow\n      start and congestion avoidance.\
    \  Generally, the algorithms for\n      computing RTO avoid this problem by adding\
    \ a positive term to the\n      estimated RTT.  However, when a connection first\
    \ begins it must\n      use some estimate for RTO, and if it picks a value less\
    \ than RTT,\n      the above problems will arise.\n      Furthermore, when the\
    \ initial RTO < RTT, it can take a long time\n      for the TCP to correct the\
    \ problem by adapting the RTT estimate,\n      because the use of Karn's algorithm\
    \ (mandated by RFC 1122,\n      4.2.3.1) will discard many of the candidate RTT\
    \ measurements made\n      after the first timeout, since they will be measurements\
    \ of\n      retransmitted segments.\n   Relevant RFCs\n      RFC 1122 states that\
    \ TCPs SHOULD initialize RTO to 3 seconds and\n      MUST implement Karn's algorithm.\n\
    \   Trace file demonstrating it\n      The following trace file was taken using\
    \ tcpdump at host A, the\n      data sender.  The advertised window and SYN options\
    \ have been\n      omitted for clarity.\n   07:52:39.870301 A > B: S 2786333696:2786333696(0)\n\
    \   07:52:40.548170 B > A: S 130240000:130240000(0) ack 2786333697\n   07:52:40.561287\
    \ A > B: P 1:513(512) ack 1\n   07:52:40.753466 A > B: . 1:513(512) ack 1\n  \
    \ 07:52:41.133687 A > B: . 1:513(512) ack 1\n   07:52:41.458529 B > A: . ack 513\n\
    \   07:52:41.458686 A > B: . 513:1025(512) ack 1\n   07:52:41.458797 A > B: P\
    \ 1025:1537(512) ack 1\n   07:52:41.541633 B > A: . ack 513\n   07:52:41.703732\
    \ A > B: . 513:1025(512) ack 1\n   07:52:42.044875 B > A: . ack 513\n   07:52:42.173728\
    \ A > B: . 513:1025(512) ack 1\n   07:52:42.330861 B > A: . ack 1537\n   07:52:42.331129\
    \ A > B: . 1537:2049(512) ack 1\n   07:52:42.331262 A > B: P 2049:2561(512) ack\
    \ 1\n   07:52:42.623673 A > B: . 1537:2049(512) ack 1\n   07:52:42.683203 B >\
    \ A: . ack 1537\n   07:52:43.044029 B > A: . ack 1537\n   07:52:43.193812 A >\
    \ B: . 1537:2049(512) ack 1\n      Note from the SYN/SYN-ACK exchange, the RTT\
    \ is over 600 msec.\n      However, from the elapsed time between the third and\
    \ fourth lines\n      (the first packet being sent and then retransmitted), it\
    \ is\n      apparent the RTO was initialized to under 200 msec.  The next line\n\
    \      shows that this value has doubled to 400 msec (correct exponential\n  \
    \    backoff of RTO), but that still does not suffice to avoid an\n      unnecessary\
    \ retransmission.\n      Finally, an ACK from B arrives for the first segment.\
    \  Later two\n      more duplicate ACKs for 513 arrive, indicating that both the\n\
    \      original and the two retransmissions arrived at B.  (Indeed, a\n      concurrent\
    \ trace at B showed that no packets were lost during the\n      entire connection).\
    \  This ACK opens the congestion window to two\n      packets, which are sent\
    \ back-to-back, but at 07:52:41.703732 RTO\n      again expires after a little\
    \ over 200 msec, leading to an\n      unnecessary retransmission, and the pattern\
    \ repeats.  By the end\n      of the trace excerpt above, 1536 bytes have been\
    \ successfully\n      transmitted from A to B, over an interval of more than 2\
    \ seconds,\n      reflecting terrible performance.\n   Trace file demonstrating\
    \ correct behavior\n      The following trace file was taken using tcpdump at\
    \ host C, the\n      data sender.  The advertised window and SYN options have\
    \ been\n      omitted for clarity.\n   17:30:32.090299 C > D: S 2031744000:2031744000(0)\n\
    \   17:30:32.900325 D > C: S 262737964:262737964(0) ack 2031744001\n   17:30:32.900326\
    \ C > D: . ack 1\n   17:30:32.910326 C > D: . 1:513(512) ack 1\n   17:30:34.150355\
    \ D > C: . ack 513\n   17:30:34.150356 C > D: . 513:1025(512) ack 1\n   17:30:34.150357\
    \ C > D: . 1025:1537(512) ack 1\n   17:30:35.170384 D > C: . ack 1025\n   17:30:35.170385\
    \ C > D: . 1537:2049(512) ack 1\n   17:30:35.170386 C > D: . 2049:2561(512) ack\
    \ 1\n   17:30:35.320385 D > C: . ack 1537\n   17:30:35.320386 C > D: . 2561:3073(512)\
    \ ack 1\n   17:30:35.320387 C > D: . 3073:3585(512) ack 1\n   17:30:35.730384\
    \ D > C: . ack 2049\n      The initial SYN/SYN-ACK exchange shows that RTT is\
    \ more than 800\n      msec, and for some subsequent packets it rises above 1\
    \ second, but\n      C's retransmit timer does not ever expire.\n   References\n\
    \      This problem is documented in [Paxson97].\n   How to detect\n      This\
    \ problem is readily detected by inspecting a packet trace of\n      the startup\
    \ of a TCP connection made over a long-delay path.  It\n      can be diagnosed\
    \ from either a sender-side or receiver-side trace.\n      Long-delay paths can\
    \ often be found by locating remote sites on\n      other continents.\n   How\
    \ to fix\n      As this problem arises from a faulty initialization, one hopes\n\
    \      fixing it requires a one-line change to the TCP source code.\n"
- title: 2.8.
  contents:
  - "2.8.\n   Name of Problem\n      Failure of window deflation after loss recovery\n\
    \   Classification\n      Congestion control / performance\n   Description\n \
    \     The fast recovery algorithm allows TCP senders to continue to\n      transmit\
    \ new segments during loss recovery.  First, fast\n      retransmission is initiated\
    \ after a TCP sender receives three\n      duplicate ACKs.  At this point, a retransmission\
    \ is sent and cwnd\n      is halved.  The fast recovery algorithm then allows\
    \ additional\n      segments to be sent when sufficient additional duplicate ACKs\n\
    \      arrive.  Some implementations of fast recovery compute when to\n      send\
    \ additional segments by artificially incrementing cwnd, first\n      by three\
    \ segments to account for the three duplicate ACKs that\n      triggered fast\
    \ retransmission, and subsequently by 1 MSS for each\n      new duplicate ACK\
    \ that arrives.  When cwnd allows, the sender\n      transmits new data segments.\n\
    \      When an ACK arrives that covers new data, cwnd is to be reduced by\n  \
    \    the amount by which it was artificially increased.  However, some\n     \
    \ TCP implementations fail to \"deflate\" the window, causing an\n      inappropriate\
    \ amount of data to be sent into the network after\n      recovery.  One cause\
    \ of this problem is the \"header prediction\"\n      code, which is used to handle\
    \ incoming segments that require\n      little work.  In some implementations\
    \ of TCP, the header\n      prediction code does not check to make sure cwnd has\
    \ not been\n      artificially inflated, and therefore does not reduce the\n \
    \     artificially increased cwnd when appropriate.\n   Significance\n      TCP\
    \ senders that exhibit this problem will transmit a burst of\n      data immediately\
    \ after recovery, which can degrade performance, as\n      well as network stability.\
    \  Effectively, the sender does not\n      reduce the size of cwnd as much as\
    \ it should (to half its value\n      when loss was detected), if at all.  This\
    \ can harm the performance\n      of the TCP connection itself, as well as competing\
    \ TCP flows.\n   Implications\n      A TCP sender exhibiting this problem does\
    \ not reduce cwnd\n      appropriately in times of congestion, and therefore may\
    \ contribute\n      to congestive collapse.\n   Relevant RFCs\n      RFC 2001\
    \ outlines the fast retransmit/fast recovery algorithms.\n      [Brakmo95] outlines\
    \ this implementation problem and offers a fix.\n   Trace file demonstrating it\n\
    \      The following trace file was taken using tcpdump at host A, the\n     \
    \ data sender.  The advertised window (which never changed) has been\n      omitted\
    \ for clarity, except for the first packet sent by each\n      host.\n   08:22:56.825635\
    \ A.7505 > B.7505: . 29697:30209(512) ack 1 win 4608\n   08:22:57.038794 B.7505\
    \ > A.7505: . ack 27649 win 4096\n   08:22:57.039279 A.7505 > B.7505: . 30209:30721(512)\
    \ ack 1\n   08:22:57.321876 B.7505 > A.7505: . ack 28161\n   08:22:57.322356 A.7505\
    \ > B.7505: . 30721:31233(512) ack 1\n   08:22:57.347128 B.7505 > A.7505: . ack\
    \ 28673\n   08:22:57.347572 A.7505 > B.7505: . 31233:31745(512) ack 1\n   08:22:57.347782\
    \ A.7505 > B.7505: . 31745:32257(512) ack 1\n   08:22:57.936393 B.7505 > A.7505:\
    \ . ack 29185\n   08:22:57.936864 A.7505 > B.7505: . 32257:32769(512) ack 1\n\
    \   08:22:57.950802 B.7505 > A.7505: . ack 29697 win 4096\n   08:22:57.951246\
    \ A.7505 > B.7505: . 32769:33281(512) ack 1\n   08:22:58.169422 B.7505 > A.7505:\
    \ . ack 29697\n   08:22:58.638222 B.7505 > A.7505: . ack 29697\n   08:22:58.643312\
    \ B.7505 > A.7505: . ack 29697\n   08:22:58.643669 A.7505 > B.7505: . 29697:30209(512)\
    \ ack 1\n   08:22:58.936436 B.7505 > A.7505: . ack 29697\n   08:22:59.002614 B.7505\
    \ > A.7505: . ack 29697\n   08:22:59.003026 A.7505 > B.7505: . 33281:33793(512)\
    \ ack 1\n   08:22:59.682902 B.7505 > A.7505: . ack 33281\n   08:22:59.683391 A.7505\
    \ > B.7505: P 33793:34305(512) ack 1\n   08:22:59.683748 A.7505 > B.7505: P 34305:34817(512)\
    \ ack 1 ***\n   08:22:59.684043 A.7505 > B.7505: P 34817:35329(512) ack 1\n  \
    \ 08:22:59.684266 A.7505 > B.7505: P 35329:35841(512) ack 1\n   08:22:59.684567\
    \ A.7505 > B.7505: P 35841:36353(512) ack 1\n   08:22:59.684810 A.7505 > B.7505:\
    \ P 36353:36865(512) ack 1\n   08:22:59.685094 A.7505 > B.7505: P 36865:37377(512)\
    \ ack 1\n      The first 12 lines of the trace show incoming ACKs clocking out\
    \ a\n      window of data segments.  At this point in the transfer, cwnd is 7\n\
    \      segments.  The next 4 lines of the trace show 3 duplicate ACKs\n      arriving\
    \ from the receiver, followed by a retransmission from the\n      sender.  At\
    \ this point, cwnd is halved (to 3 segments) and\n      artificially incremented\
    \ by the three duplicate ACKs that have\n      arrived, making cwnd 6 segments.\
    \  The next two lines show 2 more\n      duplicate ACKs arriving, each of which\
    \ increases cwnd by 1\n      segment.  So, after these two duplicate ACKs arrive\
    \ the cwnd is 8\n      segments and the sender has permission to send 1 new segment\n\
    \      (since there are 7 segments outstanding).  The next line in the\n     \
    \ trace shows this new segment being transmitted.  The next packet\n      shown\
    \ in the trace is an ACK from host B that covers the first 7\n      outstanding\
    \ segments (all but the new segment sent during\n      recovery).  This should\
    \ cause cwnd to be reduced to 3 segments and\n      2 segments to be transmitted\
    \ (since there is already 1 outstanding\n      segment in the network).  However,\
    \ as shown by the last 7 lines of\n      the trace, cwnd is not reduced, causing\
    \ a line-rate burst of 7 new\n      segments.\n   Trace file demonstrating correct\
    \ behavior\n      The trace would appear identical to the one above, only it would\n\
    \      stop after the line marked \"***\", because at this point host A\n    \
    \  would correctly reduce cwnd after recovery, allowing only 2\n      segments\
    \ to be transmitted, rather than producing a burst of 7\n      segments.\n   References\n\
    \      This problem is documented and the performance implications\n      analyzed\
    \ in [Brakmo95].\n   How to detect\n      Failure of window deflation after loss\
    \ recovery can be found by\n      examining sender-side packet traces recorded\
    \ during periods of\n      moderate loss (so cwnd can grow large enough to allow\
    \ for fast\n      recovery when loss occurs).\n   How to fix\n      When this\
    \ bug is caused by incorrect header prediction, the fix is\n      to add a predicate\
    \ to the header prediction test that checks to\n      see whether cwnd is inflated;\
    \ if so, the header prediction test\n      fails and the usual ACK processing\
    \ occurs, which (in this case)\n      takes care to deflate the window.  See [Brakmo95]\
    \ for details.\n"
- title: 2.9.
  contents:
  - "2.9.\n   Name of Problem\n      Excessively short keepalive connection timeout\n\
    \   Classification\n      Reliability\n   Description\n      Keep-alive is a mechanism\
    \ for checking whether an idle connection\n      is still alive.  According to\
    \ RFC 1122, keepalive should only be\n      invoked in server applications that\
    \ might otherwise hang\n      indefinitely and consume resources unnecessarily\
    \ if a client\n      crashes or aborts a connection during a network failure.\n\
    \      RFC 1122 also specifies that if a keep-alive mechanism is\n      implemented\
    \ it MUST NOT interpret failure to respond to any\n      specific probe as a dead\
    \ connection.  The RFC does not specify a\n      particular mechanism for timing\
    \ out a connection when no response\n      is received for keepalive probes. \
    \ However, if the mechanism does\n      not allow ample time for recovery from\
    \ network congestion or\n      delay, connections may be timed out unnecessarily.\n\
    \   Significance\n      In congested networks, can lead to unwarranted termination\
    \ of\n      connections.\n   Implications\n      It is possible for the network\
    \ connection between two peer\n      machines to become congested or to exhibit\
    \ packet loss at the time\n      that a keep-alive probe is sent on a connection.\
    \  If the keep-\n      alive mechanism does not allow sufficient time before dropping\n\
    \      connections in the face of unacknowledged probes, connections may\n   \
    \   be dropped even when both peers of a connection are still alive.\n   Relevant\
    \ RFCs\n      RFC 1122 specifies that the keep-alive mechanism may be provided.\n\
    \      It does not specify a mechanism for determining dead connections\n    \
    \  when keepalive probes are not acknowledged.\n   Trace file demonstrating it\n\
    \      Made using the Orchestra tool at the peer of the machine using\n      keep-alive.\
    \  After connection establishment, incoming keep-alives\n      were dropped by\
    \ Orchestra to simulate a dead connection.\n   22:11:12.040000 A > B: 22666019:0\
    \ win 8192 datasz 4 SYN\n   22:11:12.060000 B > A: 2496001:22666020 win 4096 datasz\
    \ 4 SYN ACK\n   22:11:12.130000 A > B: 22666020:2496002 win 8760 datasz 0 ACK\n\
    \   (more than two hours elapse)\n   00:23:00.680000 A > B: 22666019:2496002 win\
    \ 8760 datasz 1 ACK\n   00:23:01.770000 A > B: 22666019:2496002 win 8760 datasz\
    \ 1 ACK\n   00:23:02.870000 A > B: 22666019:2496002 win 8760 datasz 1 ACK\n  \
    \ 00:23.03.970000 A > B: 22666019:2496002 win 8760 datasz 1 ACK\n   00:23.05.070000\
    \ A > B: 22666019:2496002 win 8760 datasz 1 ACK\n      The initial three packets\
    \ are the SYN exchange for connection\n      setup.  About two hours later, the\
    \ keepalive timer fires because\n      the connection has been idle.  Keepalive\
    \ probes are transmitted a\n      total of 5 times, with a 1 second spacing between\
    \ probes, after\n      which the connection is dropped.  This is problematic because\
    \ a 5\n      second network outage at the time of the first probe results in\n\
    \      the connection being killed.\n   Trace file demonstrating correct behavior\n\
    \      Made using the Orchestra tool at the peer of the machine using\n      keep-alive.\
    \  After connection establishment, incoming keep-alives\n      were dropped by\
    \ Orchestra to simulate a dead connection.\n   16:01:52.130000 A > B: 1804412929:0\
    \ win 4096 datasz 4 SYN\n   16:01:52.360000 B > A: 16512001:1804412930 win 4096\
    \ datasz 4 SYN ACK\n   16:01:52.410000 A > B: 1804412930:16512002 win 4096 datasz\
    \ 0 ACK\n   (two hours elapse)\n   18:01:57.170000 A > B: 1804412929:16512002\
    \ win 4096 datasz 0 ACK\n   18:03:12.220000 A > B: 1804412929:16512002 win 4096\
    \ datasz 0 ACK\n   18:04:27.270000 A > B: 1804412929:16512002 win 4096 datasz\
    \ 0 ACK\n   18:05:42.320000 A > B: 1804412929:16512002 win 4096 datasz 0 ACK\n\
    \   18:06:57.370000 A > B: 1804412929:16512002 win 4096 datasz 0 ACK\n   18:08:12.420000\
    \ A > B: 1804412929:16512002 win 4096 datasz 0 ACK\n   18:09:27.480000 A > B:\
    \ 1804412929:16512002 win 4096 datasz 0 ACK\n   18:10:43.290000 A > B: 1804412929:16512002\
    \ win 4096 datasz 0 ACK\n   18:11:57.580000 A > B: 1804412929:16512002 win 4096\
    \ datasz 0 ACK\n   18:13:12.630000 A > B: 1804412929:16512002 win 4096 datasz\
    \ 0 RST ACK\n      In this trace, when the keep-alive timer expires, 9 keepalive\n\
    \      probes are sent at 75 second intervals.  75 seconds after the last\n  \
    \    probe is sent, a final RST segment is sent indicating that the\n      connection\
    \ has been closed.  This implementation waits about 11\n      minutes before timing\
    \ out the connection, while the first\n      implementation shown allows only\
    \ 5 seconds.\n   References\n      This problem is documented in [Dawson97].\n\
    \   How to detect\n      For implementations manifesting this problem, it shows\
    \ up on a\n      packet trace after the keepalive timer fires if the peer machine\n\
    \      receiving the keepalive does not respond.  Usually the keepalive\n    \
    \  timer will fire at least two hours after keepalive is turned on,\n      but\
    \ it may be sooner if the timer value has been configured lower,\n      or if\
    \ the keepalive mechanism violates the specification (see\n      Insufficient\
    \ interval between keepalives problem).  In this\n      example, suppressing the\
    \ response of the peer to keepalive probes\n      was accomplished using the Orchestra\
    \ toolkit, which can be\n      configured to drop packets.  It could also have\
    \ been done by\n      creating a connection, turning on keepalive, and disconnecting\
    \ the\n      network connection at the receiver machine.\n   How to fix\n    \
    \  This problem can be fixed by using a different method for timing\n      out\
    \ keepalives that allows a longer period of time to elapse\n      before dropping\
    \ the connection.  For example, the algorithm for\n      timing out on dropped\
    \ data could be used.  Another possibility is\n      an algorithm such as the\
    \ one shown in the trace above, which sends\n      9 probes at 75 second intervals\
    \ and then waits an additional 75\n      seconds for a response before closing\
    \ the connection.\n"
- title: 2.10.
  contents:
  - "2.10.\n   Name of Problem\n      Failure to back off retransmission timeout\n\
    \   Classification\n      Congestion control / reliability\n   Description\n \
    \     The retransmission timeout is used to determine when a packet has\n    \
    \  been dropped in the network.  When this timeout has expired\n      without\
    \ the arrival of an ACK, the segment is retransmitted. Each\n      time a segment\
    \ is retransmitted, the timeout is adjusted according\n      to an exponential\
    \ backoff algorithm, doubling each time.  If a TCP\n      fails to receive an\
    \ ACK after numerous attempts at retransmitting\n      the same segment, it terminates\
    \ the connection.  A TCP that fails\n      to double its retransmission timeout\
    \ upon repeated timeouts is\n      said to exhibit \"Failure to back off retransmission\
    \ timeout\".\n   Significance\n      Backing off the retransmission timer is a\
    \ cornerstone of network\n      stability in the presence of congestion.  Consequently,\
    \ this bug\n      can have severe adverse affects in congested networks.  It also\n\
    \      affects TCP reliability in congested networks, as discussed in the\n  \
    \    next section.\n   Implications\n      It is possible for the network connection\
    \ between two TCP peers to\n      become congested or to exhibit packet loss at\
    \ the time that a\n      retransmission is sent on a connection.  If the retransmission\n\
    \      mechanism does not allow sufficient time before dropping\n      connections\
    \ in the face of unacknowledged segments, connections\n      may be dropped even\
    \ when, by waiting longer, the connection could\n      have continued.\n   Relevant\
    \ RFCs\n      RFC 1122 specifies mandatory exponential backoff of the\n      retransmission\
    \ timeout, and the termination of connections after\n      some period of time\
    \ (at least 100 seconds).\n   Trace file demonstrating it\n      Made using tcpdump\
    \ on an intermediate host:\n   16:51:12.671727 A > B: S 510878852:510878852(0)\
    \ win 16384\n   16:51:12.672479 B > A: S 2392143687:2392143687(0)\n          \
    \                  ack 510878853 win 16384\n   16:51:12.672581 A > B: . ack 1\
    \ win 16384\n   16:51:15.244171 A > B: P 1:3(2) ack 1 win 16384\n   16:51:15.244933\
    \ B > A: . ack 3 win 17518  (DF)\n   <receiving host disconnected>\n   16:51:19.381176\
    \ A > B: P 3:5(2) ack 1 win 16384\n   16:51:20.162016 A > B: P 3:5(2) ack 1 win\
    \ 16384\n   16:51:21.161936 A > B: P 3:5(2) ack 1 win 16384\n   16:51:22.161914\
    \ A > B: P 3:5(2) ack 1 win 16384\n   16:51:23.161914 A > B: P 3:5(2) ack 1 win\
    \ 16384\n   16:51:24.161879 A > B: P 3:5(2) ack 1 win 16384\n   16:51:25.161857\
    \ A > B: P 3:5(2) ack 1 win 16384\n   16:51:26.161836 A > B: P 3:5(2) ack 1 win\
    \ 16384\n   16:51:27.161814 A > B: P 3:5(2) ack 1 win 16384\n   16:51:28.161791\
    \ A > B: P 3:5(2) ack 1 win 16384\n   16:51:29.161769 A > B: P 3:5(2) ack 1 win\
    \ 16384\n   16:51:30.161750 A > B: P 3:5(2) ack 1 win 16384\n   16:51:31.161727\
    \ A > B: P 3:5(2) ack 1 win 16384\n   16:51:32.161701 A > B: R 5:5(0) ack 1 win\
    \ 16384\n      The initial three packets are the SYN exchange for connection\n\
    \      setup, then a single data packet, to verify that data can be\n      transferred.\
    \  Then the connection to the destination host was\n      disconnected, and more\
    \ data sent.  Retransmissions occur every\n      second for 12 seconds, and then\
    \ the connection is terminated with\n      a RST.  This is problematic because\
    \ a 12 second pause in\n      connectivity could result in the termination of\
    \ a connection.\n   Trace file demonstrating correct behavior\n      Again, a\
    \ tcpdump taken from a third host:\n   16:59:05.398301 A > B: S 2503324757:2503324757(0)\
    \ win 16384\n   16:59:05.399673 B > A: S 2492674648:2492674648(0)\n          \
    \                 ack 2503324758 win 16384\n   16:59:05.399866 A > B: . ack 1\
    \ win 17520\n   16:59:06.538107 A > B: P 1:3(2) ack 1 win 17520\n   16:59:06.540977\
    \ B > A: . ack 3 win 17518  (DF)\n   <receiving host disconnected>\n   16:59:13.121542\
    \ A > B: P 3:5(2) ack 1 win 17520\n   16:59:14.010928 A > B: P 3:5(2) ack 1 win\
    \ 17520\n   16:59:16.010979 A > B: P 3:5(2) ack 1 win 17520\n   16:59:20.011229\
    \ A > B: P 3:5(2) ack 1 win 17520\n   16:59:28.011896 A > B: P 3:5(2) ack 1 win\
    \ 17520\n   16:59:44.013200 A > B: P 3:5(2) ack 1 win 17520\n   17:00:16.015766\
    \ A > B: P 3:5(2) ack 1 win 17520\n   17:01:20.021308 A > B: P 3:5(2) ack 1 win\
    \ 17520\n   17:02:24.027752 A > B: P 3:5(2) ack 1 win 17520\n   17:03:28.034569\
    \ A > B: P 3:5(2) ack 1 win 17520\n   17:04:32.041567 A > B: P 3:5(2) ack 1 win\
    \ 17520\n   17:05:36.048264 A > B: P 3:5(2) ack 1 win 17520\n   17:06:40.054900\
    \ A > B: P 3:5(2) ack 1 win 17520\n   17:07:44.061306 A > B: R 5:5(0) ack 1 win\
    \ 17520\n      In this trace, when the retransmission timer expires, 12\n    \
    \  retransmissions are sent at exponentially-increasing intervals,\n      until\
    \ the interval value reaches 64 seconds, at which time the\n      interval stops\
    \ growing.  64 seconds after the last retransmission,\n      a final RST segment\
    \ is sent indicating that the connection has\n      been closed.  This implementation\
    \ waits about 9 minutes before\n      timing out the connection, while the first\
    \ implementation shown\n      allows only 12 seconds.\n   References\n      None\
    \ known.\n   How to detect\n      A simple transfer can be easily interrupted\
    \ by disconnecting the\n      receiving host from the network.  tcpdump or another\
    \ appropriate\n      tool should show the retransmissions being sent.  Several\
    \ trials\n      in a low-rtt environment may be required to demonstrate the bug.\n\
    \   How to fix\n      For one of the implementations studied, this problem seemed\
    \ to be\n      the result of an error introduced with the addition of the\n  \
    \    Brakmo-Peterson RTO algorithm [Brakmo95], which can return a value\n    \
    \  of zero where the older Jacobson algorithm always returns a\n      positive\
    \ value.  Brakmo and Peterson specified an additional step\n      of min(rtt +\
    \ 2, RTO) to avoid problems with this.  Unfortunately,\n      in the implementation\
    \ this step was omitted when calculating the\n      exponential backoff for the\
    \ RTO.  This results in an RTO of 0\n      seconds being multiplied by the backoff,\
    \ yielding again zero, and\n      then being subjected to a later MAX operation\
    \ that increases it to\n      1 second, regardless of the backoff factor.\n  \
    \    A similar TCP persist failure has the same cause.\n"
- title: 2.11.
  contents:
  - "2.11.\n   Name of Problem\n      Insufficient interval between keepalives\n \
    \  Classification\n      Reliability\n   Description\n      Keep-alive is a mechanism\
    \ for checking whether an idle connection\n      is still alive.  According to\
    \ RFC 1122, keep-alive may be included\n      in an implementation.  If it is\
    \ included, the interval between\n      keep-alive packets MUST be configurable,\
    \ and MUST default to no\n      less than two hours.\n   Significance\n      In\
    \ congested networks, can lead to unwarranted termination of\n      connections.\n\
    \   Implications\n      According to RFC 1122, keep-alive is not required of\n\
    \      implementations because it could: (1) cause perfectly good\n      connections\
    \ to break during transient Internet failures; (2)\n      consume unnecessary\
    \ bandwidth (\"if no one is using the connection,\n      who cares if it is still\
    \ good?\"); and (3) cost money for an\n      Internet path that charges for packets.\
    \  Regarding this last\n      point, we note that in addition the presence of\
    \ dial-on-demand\n      links in the route can greatly magnify the cost penalty\
    \ of excess\n      keepalives, potentially forcing a full-time connection on a\
    \ link\n      that would otherwise only be connected a few minutes a day.\n  \
    \    If keepalive is provided the RFC states that the required inter-\n      keepalive\
    \ distance MUST default to no less than two hours.  If it\n      does not, the\
    \ probability of connections breaking increases, the\n      bandwidth used due\
    \ to keepalives increases, and cost increases\n      over paths which charge per\
    \ packet.\n   Relevant RFCs\n      RFC 1122 specifies that the keep-alive mechanism\
    \ may be provided.\n      It also specifies the two hour minimum for the default\
    \ interval\n      between keepalive probes.\n   Trace file demonstrating it\n\
    \      Made using the Orchestra tool at the peer of the machine using\n      keep-alive.\
    \  Machine A was configured to use default settings for\n      the keepalive timer.\n\
    \   11:36:32.910000 A > B: 3288354305:0      win 28672 datasz 4 SYN\n   11:36:32.930000\
    \ B > A: 896001:3288354306 win 4096  datasz 4 SYN ACK\n   11:36:32.950000 A >\
    \ B: 3288354306:896002 win 28672 datasz 0 ACK\n   11:50:01.190000 A > B: 3288354305:896002\
    \ win 28672 datasz 0 ACK\n   11:50:01.210000 B > A: 896002:3288354306 win 4096\
    \  datasz 0 ACK\n   12:03:29.410000 A > B: 3288354305:896002 win 28672 datasz\
    \ 0 ACK\n   12:03:29.430000 B > A: 896002:3288354306 win 4096  datasz 0 ACK\n\
    \   12:16:57.630000 A > B: 3288354305:896002 win 28672 datasz 0 ACK\n   12:16:57.650000\
    \ B > A: 896002:3288354306 win 4096  datasz 0 ACK\n   12:30:25.850000 A > B: 3288354305:896002\
    \ win 28672 datasz 0 ACK\n   12:30:25.870000 B > A: 896002:3288354306 win 4096\
    \  datasz 0 ACK\n   12:43:54.070000 A > B: 3288354305:896002 win 28672 datasz\
    \ 0 ACK\n   12:43:54.090000 B > A: 896002:3288354306 win 4096  datasz 0 ACK\n\
    \      The initial three packets are the SYN exchange for connection\n      setup.\
    \  About 13 minutes later, the keepalive timer fires because\n      the connection\
    \ is idle.  The keepalive is acknowledged, and the\n      timer fires again in\
    \ about 13 more minutes.  This behavior\n      continues indefinitely until the\
    \ connection is closed, and is a\n      violation of the specification.\n   Trace\
    \ file demonstrating correct behavior\n      Made using the Orchestra tool at\
    \ the peer of the machine using\n      keep-alive.  Machine A was configured to\
    \ use default settings for\n      the keepalive timer.\n   17:37:20.500000 A >\
    \ B: 34155521:0       win 4096 datasz 4 SYN\n   17:37:20.520000 B > A: 6272001:34155522\
    \ win 4096 datasz 4 SYN ACK\n   17:37:20.540000 A > B: 34155522:6272002 win 4096\
    \ datasz 0 ACK\n   19:37:25.430000 A > B: 34155521:6272002 win 4096 datasz 0 ACK\n\
    \   19:37:25.450000 B > A: 6272002:34155522 win 4096 datasz 0 ACK\n   21:37:30.560000\
    \ A > B: 34155521:6272002 win 4096 datasz 0 ACK\n   21:37:30.570000 B > A: 6272002:34155522\
    \ win 4096 datasz 0 ACK\n   23:37:35.580000 A > B: 34155521:6272002 win 4096 datasz\
    \ 0 ACK\n   23:37:35.600000 B > A: 6272002:34155522 win 4096 datasz 0 ACK\n  \
    \ 01:37:40.620000 A > B: 34155521:6272002 win 4096 datasz 0 ACK\n   01:37:40.640000\
    \ B > A: 6272002:34155522 win 4096 datasz 0 ACK\n   03:37:45.590000 A > B: 34155521:6272002\
    \ win 4096 datasz 0 ACK\n   03:37:45.610000 B > A: 6272002:34155522 win 4096 datasz\
    \ 0 ACK\n      The initial three packets are the SYN exchange for connection\n\
    \      setup.  Just over two hours later, the keepalive timer fires\n      because\
    \ the connection is idle.  The keepalive is acknowledged,\n      and the timer\
    \ fires again just over two hours later.  This\n      behavior continues indefinitely\
    \ until the connection is closed.\n   References\n      This problem is documented\
    \ in [Dawson97].\n   How to detect\n      For implementations manifesting this\
    \ problem, it shows up on a\n      packet trace.  If the connection is left idle,\
    \ the keepalive\n      probes will arrive closer together than the two hour minimum.\n"
- title: 2.12.
  contents:
  - "2.12.\n   Name of Problem\n      Window probe deadlock\n   Classification\n \
    \     Reliability\n   Description\n      When an application reads a single byte\
    \ from a full window, the\n      window should not be updated, in order to avoid\
    \ Silly Window\n      Syndrome (SWS; see [RFC813]).  If the remote peer uses a\
    \ single\n      byte of data to probe the window, that byte can be accepted into\n\
    \      the buffer.  In some implementations, at this point a negative\n      argument\
    \ to a signed comparison causes all further new data to be\n      considered outside\
    \ the window; consequently, it is discarded\n      (after sending an ACK to resynchronize).\
    \  These discards include\n      the ACKs for the data packets sent by the local\
    \ TCP, so the TCP\n      will consider the data unacknowledged.\n      Consequently,\
    \ the application may be unable to complete sending\n      new data to the remote\
    \ peer, because it has exhausted the transmit\n      buffer available to its local\
    \ TCP, and buffer space is never being\n      freed because incoming ACKs that\
    \ would do so are being discarded.\n      If the application does not read any\
    \ more data, which may happen\n      due to its failure to complete such sends,\
    \ then deadlock results.\n   Significance\n      It's relatively rare for applications\
    \ to use TCP in a manner that\n      can exercise this problem.  Most applications\
    \ only transmit bulk\n      data if they know the other end is prepared to receive\
    \ the data.\n      However, if a client fails to consume data, putting the server\
    \ in\n      persist mode, and then consumes a small amount of data, it can\n \
    \     mistakenly compute a negative window.  At this point the client\n      will\
    \ discard all further packets from the server, including ACKs\n      of the client's\
    \ own data, since they are not inside the\n      (impossibly-sized) window.  If\
    \ subsequently the client consumes\n      enough data to then send a window update\
    \ to the server, the\n      situation will be rectified.  That is, this situation\
    \ can only\n      happen if the client consumes 1 < N < MSS bytes, so as not to\n\
    \      cause a window update, and then starts its own transmission\n      towards\
    \ the server of more than a window's worth of data.\n   Implications\n      TCP\
    \ connections will hang and eventually time out.\n   Relevant RFCs\n      RFC\
    \ 793 describes zero window probing.  RFC 813 describes Silly\n      Window Syndrome.\n\
    \   Trace file demonstrating it\n      Trace made from a version of tcpdump modified\
    \ to print out the\n      sequence number attached to an ACK even if it's dataless.\
    \  An\n      unmodified tcpdump would not print seq:seq(0); however, for this\n\
    \      bug, the sequence number in the ACK is important for unambiguously\n  \
    \    determining how the TCP is behaving.\n   [ Normal connection startup and\
    \ data transmission from B to A.\n     Options, including MSS of 16344 in both\
    \ directions, omitted\n     for clarity. ]\n   16:07:32.327616 A > B: S 65360807:65360807(0)\
    \ win 8192\n   16:07:32.327304 B > A: S 65488807:65488807(0) ack 65360808 win\
    \ 57344\n   16:07:32.327425 A > B: . 1:1(0) ack 1 win 57344\n   16:07:32.345732\
    \ B > A: P 1:2049(2048) ack 1 win 57344\n   16:07:32.347013 B > A: P 2049:16385(14336)\
    \ ack 1 win 57344\n   16:07:32.347550 B > A: P 16385:30721(14336) ack 1 win 57344\n\
    \   16:07:32.348683 B > A: P 30721:45057(14336) ack 1 win 57344\n   16:07:32.467286\
    \ A > B: . 1:1(0) ack 45057 win 12288\n   16:07:32.467854 B > A: P 45057:57345(12288)\
    \ ack 1 win 57344\n   [ B fills up A's offered window ]\n   16:07:32.667276 A\
    \ > B: . 1:1(0) ack 57345 win 0\n   [ B probes A's window with a single byte ]\n\
    \   16:07:37.467438 B > A: . 57345:57346(1) ack 1 win 57344\n   [ A resynchronizes\
    \ without accepting the byte ]\n   16:07:37.467678 A > B: . 1:1(0) ack 57345 win\
    \ 0\n   [ B probes A's window again ]\n   16:07:45.467438 B > A: . 57345:57346(1)\
    \ ack 1 win 57344\n   [ A resynchronizes and accepts the byte (per the ack field)\
    \ ]\n   16:07:45.667250 A > B: . 1:1(0) ack 57346 win 0\n   [ The application\
    \ on A has started generating data.  The first\n     packet A sends is small due\
    \ to a memory allocation bug. ]\n   16:07:51.358459 A > B: P 1:2049(2048) ack\
    \ 57346 win 0\n   [ B acks A's first packet ]\n   16:07:51.467239 B > A: . 57346:57346(0)\
    \ ack 2049 win 57344\n   [ This looks as though A accepted B's ACK and is sending\n\
    \     another packet in response to it.  In fact, A is trying\n     to resynchronize\
    \ with B, and happens to have data to send\n     and can send it because the first\
    \ small packet didn't use\n     up cwnd. ]\n   16:07:51.467698 A > B: . 2049:14337(12288)\
    \ ack 57346 win 0\n   [ B acks all of the data that A has sent ]\n   16:07:51.667283\
    \ B > A: . 57346:57346(0) ack 14337 win 57344\n   [ A tries to resynchronize.\
    \  Notice that by the packets\n     seen on the network, A and B *are* in fact\
    \ synchronized;\n     A only thinks that they aren't. ]\n   16:07:51.667477 A\
    \ > B: . 14337:14337(0) ack 57346 win 0\n   [ A's retransmit timer fires, and\
    \ B acks all of the data.\n     A once again tries to resynchronize. ]\n   16:07:52.467682\
    \ A > B: . 1:14337(14336) ack 57346 win 0\n   16:07:52.468166 B > A: . 57346:57346(0)\
    \ ack 14337 win 57344\n   16:07:52.468248 A > B: . 14337:14337(0) ack 57346 win\
    \ 0\n   [ A's retransmit timer fires again, and B acks all of the data.\n    \
    \ A once again tries to resynchronize. ]\n   16:07:55.467684 A > B: . 1:14337(14336)\
    \ ack 57346 win 0\n   16:07:55.468172 B > A: . 57346:57346(0) ack 14337 win 57344\n\
    \   16:07:55.468254 A > B: . 14337:14337(0) ack 57346 win 0\n   Trace file demonstrating\
    \ correct behavior\n      Made between the same two hosts after applying the bug\
    \ fix\n      mentioned below (and using the same modified tcpdump).\n   [ Connection\
    \ starts up with data transmission from B to A.\n     Note that due to a separate\
    \ bug (the fact that A and B\n     are communicating over a loopback driver),\
    \ B erroneously\n     skips slow start. ]\n   17:38:09.510854 A > B: S 3110066585:3110066585(0)\
    \ win 16384\n   17:38:09.510926 B > A: S 3110174850:3110174850(0)\n          \
    \                  ack 3110066586 win 57344\n   17:38:09.510953 A > B: . 1:1(0)\
    \ ack 1 win 57344\n   17:38:09.512956 B > A: P 1:2049(2048) ack 1 win 57344\n\
    \   17:38:09.513222 B > A: P 2049:16385(14336) ack 1 win 57344\n   17:38:09.513428\
    \ B > A: P 16385:30721(14336) ack 1 win 57344\n   17:38:09.513638 B > A: P 30721:45057(14336)\
    \ ack 1 win 57344\n   17:38:09.519531 A > B: . 1:1(0) ack 45057 win 12288\n  \
    \ 17:38:09.519638 B > A: P 45057:57345(12288) ack 1 win 57344\n   [ B fills up\
    \ A's offered window ]\n   17:38:09.719526 A > B: . 1:1(0) ack 57345 win 0\n \
    \  [ B probes A's window with a single byte.  A resynchronizes\n     without accepting\
    \ the byte ]\n   17:38:14.499661 B > A: . 57345:57346(1) ack 1 win 57344\n   17:38:14.499724\
    \ A > B: . 1:1(0) ack 57345 win 0\n   [ B probes A's window again.  A resynchronizes\
    \ and accepts\n     the byte, as indicated by the ack field ]\n   17:38:19.499764\
    \ B > A: . 57345:57346(1) ack 1 win 57344\n   17:38:19.519731 A > B: . 1:1(0)\
    \ ack 57346 win 0\n   [ B probes A's window with a single byte.  A resynchronizes\n\
    \     without accepting the byte ]\n   17:38:24.499865 B > A: . 57346:57347(1)\
    \ ack 1 win 57344\n   17:38:24.499934 A > B: . 1:1(0) ack 57346 win 0\n   [ The\
    \ application on A has started generating data.\n     B acks A's data and A accepts\
    \ the ACKs and the\n     data transfer continues ]\n   17:38:28.530265 A > B:\
    \ P 1:2049(2048) ack 57346 win 0\n   17:38:28.719914 B > A: . 57346:57346(0) ack\
    \ 2049 win 57344\n   17:38:28.720023 A > B: . 2049:16385(14336) ack 57346 win\
    \ 0\n   17:38:28.720089 A > B: . 16385:30721(14336) ack 57346 win 0\n   17:38:28.720370\
    \ B > A: . 57346:57346(0) ack 30721 win 57344\n   17:38:28.720462 A > B: . 30721:45057(14336)\
    \ ack 57346 win 0\n   17:38:28.720526 A > B: P 45057:59393(14336) ack 57346 win\
    \ 0\n   17:38:28.720824 A > B: P 59393:73729(14336) ack 57346 win 0\n   17:38:28.721124\
    \ B > A: . 57346:57346(0) ack 73729 win 47104\n   17:38:28.721198 A > B: P 73729:88065(14336)\
    \ ack 57346 win 0\n   17:38:28.721379 A > B: P 88065:102401(14336) ack 57346 win\
    \ 0\n   17:38:28.721557 A > B: P 102401:116737(14336) ack 57346 win 0\n   17:38:28.721863\
    \ B > A: . 57346:57346(0) ack 116737 win 36864\n   References\n      None known.\n\
    \   How to detect\n      Initiate a connection from a client to a server.  Have\
    \ the server\n      continuously send data until its buffers have been full for\
    \ long\n      enough to exhaust the window.  Next, have the client read 1 byte\n\
    \      and then delay for long enough that the server TCP sends a window\n   \
    \   probe.  Now have the client start sending data.  At this point, if\n     \
    \ it ignores the server's ACKs, then the client's TCP suffers from\n      the\
    \ problem.\n   How to fix\n      In one implementation known to exhibit the problem\
    \ (derived from\n      4.3-Reno), the problem was introduced when the macro MAX()\
    \ was\n      replaced by the function call max() for computing the amount of\n\
    \      space in the receive window:\n          tp->rcv_wnd = max(win, (int)(tp->rcv_adv\
    \ - tp->rcv_nxt));\n      When data has been received into a window beyond what\
    \ has been\n      advertised to the other side, rcv_nxt > rcv_adv, making this\n\
    \      negative.  It's clear from the (int) cast that this is intended,\n    \
    \  but the unsigned max() function sign-extends so the negative\n      number\
    \ is \"larger\".  The fix is to change max() to imax():\n          tp->rcv_wnd\
    \ = imax(win, (int)(tp->rcv_adv - tp->rcv_nxt));\n      4.3-Tahoe and before did\
    \ not have this bug, since it used the\n      macro MAX() for this calculation.\n"
- title: 2.13.
  contents:
  - "2.13.\n   Name of Problem\n      Stretch ACK violation\n   Classification\n \
    \     Congestion Control/Performance\n   Description\n      To improve efficiency\
    \ (both computer and network) a data receiver\n      may refrain from sending\
    \ an ACK for each incoming segment,\n      according to [RFC1122].  However, an\
    \ ACK should not be delayed an\n      inordinate amount of time.  Specifically,\
    \ ACKs SHOULD be sent for\n      every second full-sized segment that arrives.\
    \  If a second full-\n      sized segment does not arrive within a given timeout\
    \ (of no more\n      than 0.5 seconds), an ACK should be transmitted, according\
    \ to\n      [RFC1122].  A TCP receiver which does not generate an ACK for\n  \
    \    every second full-sized segment exhibits a \"Stretch ACK\n      Violation\"\
    .\n   Significance\n      TCP receivers exhibiting this behavior will cause TCP\
    \ senders to\n      generate burstier traffic, which can degrade performance in\n\
    \      congested environments.  In addition, generating fewer ACKs\n      increases\
    \ the amount of time needed by the slow start algorithm to\n      open the congestion\
    \ window to an appropriate point, which\n      diminishes performance in environments\
    \ with large bandwidth-delay\n      products.  Finally, generating fewer ACKs\
    \ may cause needless\n      retransmission timeouts in lossy environments, as\
    \ it increases the\n      possibility that an entire window of ACKs is lost, forcing\
    \ a\n      retransmission timeout.\n   Implications\n      When not in loss recovery,\
    \ every ACK received by a TCP sender\n      triggers the transmission of new data\
    \ segments.  The burst size is\n      determined by the number of previously unacknowledged\
    \ segments\n      each ACK covers.  Therefore, a TCP receiver ack'ing more than\
    \ 2\n      segments at a time causes the sending TCP to generate a larger\n  \
    \    burst of traffic upon receipt of the ACK.  This large burst of\n      traffic\
    \ can overwhelm an intervening gateway, leading to higher\n      drop rates for\
    \ both the connection and other connections passing\n      through the congested\
    \ gateway.\n      In addition, the TCP slow start algorithm increases the congestion\n\
    \      window by 1 segment for each ACK received.  Therefore, increasing\n   \
    \   the ACK interval (thus decreasing the rate at which ACKs are\n      transmitted)\
    \ increases the amount of time it takes slow start to\n      increase the congestion\
    \ window to an appropriate operating point,\n      and the connection consequently\
    \ suffers from reduced performance.\n      This is especially true for connections\
    \ using large windows.\n   Relevant RFCs\n      RFC 1122 outlines delayed ACKs\
    \ as a recommended mechanism.\n   Trace file demonstrating it\n      Trace file\
    \ taken using tcpdump at host B, the data receiver (and\n      ACK originator).\
    \  The advertised window (which never changed) and\n      timestamp options have\
    \ been omitted for clarity, except for the\n      first packet sent by A:\n  \
    \ 12:09:24.820187 A.1174 > B.3999: . 2049:3497(1448) ack 1\n       win 33580 <nop,nop,timestamp\
    \ 2249877 2249914> [tos 0x8]\n   12:09:24.824147 A.1174 > B.3999: . 3497:4945(1448)\
    \ ack 1\n   12:09:24.832034 A.1174 > B.3999: . 4945:6393(1448) ack 1\n   12:09:24.832222\
    \ B.3999 > A.1174: . ack 6393\n   12:09:24.934837 A.1174 > B.3999: . 6393:7841(1448)\
    \ ack 1\n   12:09:24.942721 A.1174 > B.3999: . 7841:9289(1448) ack 1\n   12:09:24.950605\
    \ A.1174 > B.3999: . 9289:10737(1448) ack 1\n   12:09:24.950797 B.3999 > A.1174:\
    \ . ack 10737\n   12:09:24.958488 A.1174 > B.3999: . 10737:12185(1448) ack 1\n\
    \   12:09:25.052330 A.1174 > B.3999: . 12185:13633(1448) ack 1\n   12:09:25.060216\
    \ A.1174 > B.3999: . 13633:15081(1448) ack 1\n   12:09:25.060405 B.3999 > A.1174:\
    \ . ack 15081\n      This portion of the trace clearly shows that the receiver\
    \ (host B)\n      sends an ACK for every third full sized packet received.  Further\n\
    \      investigation of this implementation found that the cause of the\n    \
    \  increased ACK interval was the TCP options being used.  The\n      implementation\
    \ sent an ACK after it was holding 2*MSS worth of\n      unacknowledged data.\
    \  In the above case, the MSS is 1460 bytes so\n      the receiver transmits an\
    \ ACK after it is holding at least 2920\n      bytes of unacknowledged data. \
    \ However, the length of the TCP\n      options being used [RFC1323] took 12 bytes\
    \ away from the data\n      portion of each packet.  This produced packets containing\
    \ 1448\n      bytes of data.  But the additional bytes used by the options in\n\
    \      the header were not taken into account when determining when to\n     \
    \ trigger an ACK.  Therefore, it took 3 data segments before the\n      data receiver\
    \ was holding enough unacknowledged data (>= 2*MSS, or\n      2920 bytes in the\
    \ above example) to transmit an ACK.\n   Trace file demonstrating correct behavior\n\
    \      Trace file taken using tcpdump at host B, the data receiver (and\n    \
    \  ACK originator), again with window and timestamp information\n      omitted\
    \ except for the first packet:\n   12:06:53.627320 A.1172 > B.3999: . 1449:2897(1448)\
    \ ack 1\n       win 33580 <nop,nop,timestamp 2249575 2249612> [tos 0x8]\n   12:06:53.634773\
    \ A.1172 > B.3999: . 2897:4345(1448) ack 1\n   12:06:53.634961 B.3999 > A.1172:\
    \ . ack 4345\n   12:06:53.737326 A.1172 > B.3999: . 4345:5793(1448) ack 1\n  \
    \ 12:06:53.744401 A.1172 > B.3999: . 5793:7241(1448) ack 1\n   12:06:53.744592\
    \ B.3999 > A.1172: . ack 7241\n   12:06:53.752287 A.1172 > B.3999: . 7241:8689(1448)\
    \ ack 1\n   12:06:53.847332 A.1172 > B.3999: . 8689:10137(1448) ack 1\n   12:06:53.847525\
    \ B.3999 > A.1172: . ack 10137\n      This trace shows the TCP receiver (host\
    \ B) ack'ing every second\n      full-sized packet, according to [RFC1122].  This\
    \ is the same\n      implementation shown above, with slight modifications that\
    \ allow\n      the receiver to take the length of the options into account when\n\
    \      deciding when to transmit an ACK.\n   References\n      This problem is\
    \ documented in [Allman97] and [Paxson97].\n   How to detect\n      Stretch ACK\
    \ violations show up immediately in receiver-side packet\n      traces of bulk\
    \ transfers, as shown above.  However, packet traces\n      made on the sender\
    \ side of the TCP connection may lead to\n      ambiguities when diagnosing this\
    \ problem due to the possibility of\n      lost ACKs.\n"
- title: 2.14.
  contents:
  - "2.14.\n   Name of Problem\n      Retransmission sends multiple packets\n   Classification\n\
    \      Congestion control\n   Description\n      When a TCP retransmits a segment\
    \ due to a timeout expiration or\n      beginning a fast retransmission sequence,\
    \ it should only transmit\n      a single segment.  A TCP that transmits more\
    \ than one segment\n      exhibits \"Retransmission Sends Multiple Packets\".\n\
    \      Instances of this problem have been known to occur due to\n      miscomputations\
    \ involving the use of TCP options.  TCP options\n      increase the TCP header\
    \ beyond its usual size of 20 bytes.  The\n      total size of header must be\
    \ taken into account when\n      retransmitting a packet.  If a TCP sender does\
    \ not account for the\n      length of the TCP options when determining how much\
    \ data to\n      retransmit, it will send too much data to fit into a single\n\
    \      packet.  In this case, the correct retransmission will be followed\n  \
    \    by a short segment (tinygram) containing data that may not need to\n    \
    \  be retransmitted.\n      A specific case is a TCP using the RFC 1323 timestamp\
    \ option,\n      which adds 12 bytes to the standard 20-byte TCP header.  On\n\
    \      retransmission of a packet, the 12 byte option is incorrectly\n      interpreted\
    \ as part of the data portion of the segment.  A\n      standard TCP header and\
    \ a new 12-byte option is added to the data,\n      which yields a transmission\
    \ of 12 bytes more data than contained\n      in the original segment.  This overflow\
    \ causes a smaller packet,\n      with 12 data bytes, to be transmitted.\n   Significance\n\
    \      This problem is somewhat serious for congested environments\n      because\
    \ the TCP implementation injects more packets into the\n      network than is\
    \ appropriate.  However, since a tinygram is only\n      sent in response to a\
    \ fast retransmit or a timeout, it does not\n      effect the sustained sending\
    \ rate.\n   Implications\n      A TCP exhibiting this behavior is stressing the\
    \ network with more\n      traffic than appropriate, and stressing routers by\
    \ increasing the\n      number of packets they must process.  The redundant tinygram\
    \ will\n      also elicit a duplicate ACK from the receiver, resulting in yet\n\
    \      another unnecessary transmission.\n   Relevant RFCs\n      RFC 1122 requires\
    \ use of slow start after loss; RFC 2001\n      explicates slow start; RFC 1323\
    \ describes the timestamp option\n      that has been observed to lead to some\
    \ implementations exhibiting\n      this problem.\n   Trace file demonstrating\
    \ it\n      Made using tcpdump recording at a machine on the same subnet as\n\
    \      Host A.  Host A is the sender and Host B is the receiver.  The\n      advertised\
    \ window and timestamp options have been omitted for\n      clarity, except for\
    \ the first segment sent by host A.  In\n      addition, portions of the trace\
    \ file not pertaining to the packet\n      in question have been removed (missing\
    \ packets are denoted by\n      \"[...]\" in the trace).\n   11:55:22.701668 A\
    \ > B: . 7361:7821(460) ack 1\n       win 49324 <nop,nop,timestamp 3485348 3485113>\n\
    \   11:55:22.702109 A > B: . 7821:8281(460) ack 1\n   [...]\n   11:55:23.112405\
    \ B > A: . ack 7821\n   11:55:23.113069 A > B: . 12421:12881(460) ack 1\n   11:55:23.113511\
    \ A > B: . 12881:13341(460) ack 1\n   11:55:23.333077 B > A: . ack 7821\n   11:55:23.336860\
    \ B > A: . ack 7821\n   11:55:23.340638 B > A: . ack 7821\n   11:55:23.341290\
    \ A > B: . 7821:8281(460) ack 1\n   11:55:23.341317 A > B: . 8281:8293(12) ack\
    \ 1\n   11:55:23.498242 B > A: . ack 7821\n   11:55:23.506850 B > A: . ack 7821\n\
    \   11:55:23.510630 B > A: . ack 7821\n   [...]\n   11:55:23.746649 B > A: . ack\
    \ 10581\n      The second line of the above trace shows the original transmission\n\
    \      of a segment which is later dropped.  After 3 duplicate ACKs, line\n  \
    \    9 of the trace shows the dropped packet (7821:8281), with a 460-\n      byte\
    \ payload, being retransmitted.  Immediately following this\n      retransmission,\
    \ a packet with a 12-byte payload is unnecessarily\n      sent.\n   Trace file\
    \ demonstrating correct behavior\n      The trace file would be identical to the\
    \ one above, with a single\n      line:\n      11:55:23.341317 A > B: . 8281:8293(12)\
    \ ack 1\n      omitted.\n   References\n      [Brakmo95]\n   How to detect\n \
    \     This problem can be detected by examining a packet trace of the\n      TCP\
    \ connections of a machine using TCP options, during which a\n      packet is\
    \ retransmitted.\n"
- title: 2.15.
  contents:
  - "2.15.\n   Name of Problem\n      Failure to send FIN notification promptly\n\
    \   Classification\n      Performance\n   Description\n      When an application\
    \ closes a connection, the corresponding TCP\n      should send the FIN notification\
    \ promptly to its peer (unless\n      prevented by the congestion window).  If\
    \ a TCP implementation\n      delays in sending the FIN notification, for example\
    \ due to waiting\n      until unacknowledged data has been acknowledged, then\
    \ it is said\n      to exhibit \"Failure to send FIN notification promptly\".\n\
    \      Also, while not strictly required, FIN segments should include the\n  \
    \    PSH flag to ensure expedited delivery of any pending data at the\n      receiver.\n\
    \   Significance\n      The greatest impact occurs for short-lived connections,\
    \ since for\n      these the additional time required to close the connection\n\
    \      introduces the greatest relative delay.\n      The additional time can\
    \ be significant in the common case of the\n      sender waiting for an ACK that\
    \ is delayed by the receiver.\n   Implications\n      Can diminish total throughput\
    \ as seen at the application layer,\n      because connection termination takes\
    \ longer to complete.\n   Relevant RFCs\n      RFC 793 indicates that a receiver\
    \ should treat an incoming FIN\n      flag as implying the push function.\n  \
    \ Trace file demonstrating it\n      Made using tcpdump (no losses reported by\
    \ the packet filter).\n   10:04:38.68 A > B: S 1031850376:1031850376(0) win 4096\n\
    \                   <mss 1460,wscale 0,eol> (DF)\n   10:04:38.71 B > A: S 596916473:596916473(0)\
    \ ack 1031850377\n                   win 8760 <mss 1460> (DF)\n   10:04:38.73\
    \ A > B: . ack 1 win 4096 (DF)\n   10:04:41.98 A > B: P 1:4(3) ack 1 win 4096\
    \ (DF)\n   10:04:42.15 B > A: . ack 4 win 8757 (DF)\n   10:04:42.23 A > B: P 4:7(3)\
    \ ack 1 win 4096 (DF)\n   10:04:42.25 B > A: P 1:11(10) ack 7 win 8754 (DF)\n\
    \   10:04:42.32 A > B: . ack 11 win 4096 (DF)\n   10:04:42.33 B > A: P 11:51(40)\
    \ ack 7 win 8754 (DF)\n   10:04:42.51 A > B: . ack 51 win 4096 (DF)\n   10:04:42.53\
    \ B > A: F 51:51(0) ack 7 win 8754 (DF)\n   10:04:42.56 A > B: FP 7:7(0) ack 52\
    \ win 4096 (DF)\n   10:04:42.58 B > A: . ack 8 win 8754 (DF)\n      Machine B\
    \ in the trace above does not send out a FIN notification\n      promptly if there\
    \ is any data outstanding.  It instead waits for\n      all unacknowledged data\
    \ to be acknowledged before sending the FIN\n      segment.  The connection was\
    \ closed at 10:04.42.33 after\n      requesting 40 bytes to be sent.  However,\
    \ the FIN notification\n      isn't sent until 10:04.42.51, after the (delayed)\
    \ acknowledgement\n      of the 40 bytes of data.\n   Trace file demonstrating\
    \ correct behavior\n      Made using tcpdump (no losses reported by the packet\
    \ filter).\n   10:27:53.85 C > D: S 419744533:419744533(0) win 4096\n        \
    \           <mss 1460,wscale 0,eol> (DF)\n   10:27:53.92 D > C: S 10082297:10082297(0)\
    \ ack 419744534\n                   win 8760 <mss 1460> (DF)\n   10:27:53.95 C\
    \ > D: . ack 1 win 4096 (DF)\n   10:27:54.42 C > D: P 1:4(3) ack 1 win 4096 (DF)\n\
    \   10:27:54.62 D > C: . ack 4 win 8757 (DF)\n   10:27:54.76 C > D: P 4:7(3) ack\
    \ 1 win 4096 (DF)\n   10:27:54.89 D > C: P 1:11(10) ack 7 win 8754 (DF)\n   10:27:54.90\
    \ D > C: FP 11:51(40) ack7 win 8754 (DF)\n   10:27:54.92 C > D: . ack 52 win 4096\
    \ (DF)\n   10:27:55.01 C > D: FP 7:7(0) ack 52 win 4096 (DF)\n   10:27:55.09 D\
    \ > C: . ack 8 win 8754 (DF)\n      Here, Machine D sends a FIN with 40 bytes\
    \ of data even before the\n      original 10 octets have been acknowledged. This\
    \ is correct\n      behavior as it provides for the highest performance.\n   References\n\
    \      This problem is documented in [Dawson97].\n   How to detect\n      For\
    \ implementations manifesting this problem, it shows up on a\n      packet trace.\n"
- title: 2.16.
  contents:
  - "2.16.\n   Name of Problem\n      Failure to send a RST after Half Duplex Close\n\
    \   Classification\n      Resource management\n   Description\n      RFC 1122\
    \ 4.2.2.13 states that a TCP SHOULD send a RST if data is\n      received after\
    \ \"half duplex close\", i.e. if it cannot be delivered\n      to the application.\
    \  A TCP that fails to do so is said to exhibit\n      \"Failure to send a RST\
    \ after Half Duplex Close\".\n   Significance\n      Potentially serious for TCP\
    \ endpoints that manage large numbers of\n      connections, due to exhaustion\
    \ of memory and/or process slots\n      available for managing connection state.\n\
    \   Implications\n      Failure to send the RST can lead to permanently hung TCP\n\
    \      connections.  This problem has been demonstrated when HTTP clients\n  \
    \    abort connections, common when users move on to a new page before\n     \
    \ the current page has finished downloading.  The HTTP client closes\n      by\
    \ transmitting a FIN while the server is transmitting images,\n      text, etc.\
    \  The server TCP receives the FIN,  but its application\n      does not close\
    \ the connection until all data has been queued for\n      transmission.  Since\
    \ the server will not transmit a FIN until all\n      the preceding data has been\
    \ transmitted, deadlock results if the\n      client TCP does not consume the\
    \ pending data or tear down the\n      connection: the window decreases to zero,\
    \ since the client cannot\n      pass the data to the application, and the server\
    \ sends probe\n      segments.  The client acknowledges the probe segments with\
    \ a zero\n      window. As mandated in RFC1122 4.2.2.17, the probe segments are\n\
    \      transmitted forever.  Server connection state remains in\n      CLOSE_WAIT,\
    \ and eventually server processes are exhausted.\n      Note that there are two\
    \ bugs.  First, probe segments should be\n      ignored if the window can never\
    \ subsequently increase.  Second, a\n      RST should be sent when data is received\
    \ after half duplex close.\n      Fixing the first bug, but not the second, results\
    \ in the probe\n      segments eventually timing out the connection, but the server\n\
    \      remains in CLOSE_WAIT for a significant and unnecessary period.\n   Relevant\
    \ RFCs\n      RFC 1122 sections 4.2.2.13 and 4.2.2.17.\n   Trace file demonstrating\
    \ it\n      Made using an unknown network analyzer.  No drop information\n   \
    \   available.\n   client.1391 > server.8080: S 0:1(0) ack: 0 win: 2000 <mss:\
    \ 5b4>\n   server.8080 > client.1391: SA 8c01:8c02(0) ack: 1 win: 8000 <mss:100>\n\
    \   client.1391 > server.8080: PA\n   client.1391 > server.8080: PA 1:1c2(1c1)\
    \ ack: 8c02 win: 2000\n   server.8080 > client.1391: [DF] PA 8c02:8cde(dc) ack:\
    \ 1c2 win: 8000\n   server.8080 > client.1391: [DF] A 8cde:9292(5b4) ack: 1c2\
    \ win: 8000\n   server.8080 > client.1391: [DF] A 9292:9846(5b4) ack: 1c2 win:\
    \ 8000\n   server.8080 > client.1391: [DF] A 9846:9dfa(5b4) ack: 1c2 win: 8000\n\
    \   client.1391 > server.8080: PA\n   server.8080 > client.1391: [DF] A 9dfa:a3ae(5b4)\
    \ ack: 1c2 win: 8000\n   server.8080 > client.1391: [DF] A a3ae:a962(5b4) ack:\
    \ 1c2 win: 8000\n   server.8080 > client.1391: [DF] A a962:af16(5b4) ack: 1c2\
    \ win: 8000\n   server.8080 > client.1391: [DF] A af16:b4ca(5b4) ack: 1c2 win:\
    \ 8000\n   client.1391 > server.8080: PA\n   server.8080 > client.1391: [DF] A\
    \ b4ca:ba7e(5b4) ack: 1c2 win: 8000\n   server.8080 > client.1391: [DF] A b4ca:ba7e(5b4)\
    \ ack: 1c2 win: 8000\n   client.1391 > server.8080: PA\n   server.8080 > client.1391:\
    \ [DF] A ba7e:bdfa(37c) ack: 1c2 win: 8000\n   client.1391 > server.8080: PA\n\
    \   server.8080 > client.1391: [DF] A bdfa:bdfb(1) ack: 1c2 win: 8000\n   client.1391\
    \ > server.8080: PA\n   [ HTTP client aborts and enters FIN_WAIT_1 ]\n   client.1391\
    \ > server.8080: FPA\n   [ server ACKs the FIN and enters CLOSE_WAIT ]\n   server.8080\
    \ > client.1391: [DF] A\n   [ client enters FIN_WAIT_2 ]\n   server.8080 > client.1391:\
    \ [DF] A bdfa:bdfb(1) ack: 1c3 win: 8000\n   [ server continues to try to send\
    \ its data ]\n   client.1391 > server.8080: PA < window = 0 >\n   server.8080\
    \ > client.1391: [DF] A bdfa:bdfb(1) ack: 1c3 win: 8000\n   client.1391 > server.8080:\
    \ PA < window = 0 >\n   server.8080 > client.1391: [DF] A bdfa:bdfb(1) ack: 1c3\
    \ win: 8000\n   client.1391 > server.8080: PA < window = 0 >\n   server.8080 >\
    \ client.1391: [DF] A bdfa:bdfb(1) ack: 1c3 win: 8000\n   client.1391 > server.8080:\
    \ PA < window = 0 >\n   server.8080 > client.1391: [DF] A bdfa:bdfb(1) ack: 1c3\
    \ win: 8000\n   client.1391 > server.8080: PA < window = 0 >\n   [ ... repeat\
    \ ad exhaustium ... ]\n   Trace file demonstrating correct behavior\n      Made\
    \ using an unknown network analyzer.  No drop information\n      available.\n\
    \   client > server D=80 S=59500 Syn Seq=337 Len=0 Win=8760\n   server > client\
    \ D=59500 S=80 Syn Ack=338 Seq=80153 Len=0 Win=8760\n   client > server D=80 S=59500\
    \ Ack=80154 Seq=338 Len=0 Win=8760\n   [ ... normal data omitted ... ]\n   client\
    \ > server D=80 S=59500 Ack=14559 Seq=596 Len=0 Win=8760\n   server > client D=59500\
    \ S=80 Ack=596 Seq=114559 Len=1460 Win=8760\n   [ client closes connection ]\n\
    \   client > server D=80 S=59500 Fin Seq=596 Len=0 Win=8760\n   server > client\
    \ D=59500 S=80 Ack=597 Seq=116019 Len=1460 Win=8760\n   [ client sends RST (RFC1122\
    \ 4.2.2.13) ]\n   client > server D=80 S=59500 Rst Seq=597 Len=0 Win=0\n   server\
    \ > client D=59500 S=80 Ack=597 Seq=117479 Len=1460 Win=8760\n   client > server\
    \ D=80 S=59500 Rst Seq=597 Len=0 Win=0\n   server > client D=59500 S=80 Ack=597\
    \ Seq=118939 Len=1460 Win=8760\n   client > server D=80 S=59500 Rst Seq=597 Len=0\
    \ Win=0\n   server > client D=59500 S=80 Ack=597 Seq=120399 Len=892 Win=8760\n\
    \   client > server D=80 S=59500 Rst Seq=597 Len=0 Win=0\n   server > client D=59500\
    \ S=80 Ack=597 Seq=121291 Len=1460 Win=8760\n   client > server D=80 S=59500 Rst\
    \ Seq=597 Len=0 Win=0\n      \"client\" sends a number of RSTs, one in response\
    \ to each incoming\n      packet from \"server\".  One might wonder why \"server\"\
    \ keeps sending\n      data packets after it has received a RST from \"client\"\
    ; the\n      explanation is that \"server\" had already transmitted all five of\n\
    \      the data packets before receiving the first RST from \"client\", so\n \
    \     it is too late to avoid transmitting them.\n   How to detect\n      The\
    \ problem can be detected by inspecting packet traces of a\n      large, interrupted\
    \ bulk transfer.\n"
- title: 2.17.
  contents:
  - "2.17.\n   Name of Problem\n      Failure to RST on close with data pending\n\
    \   Classification\n      Resource management\n   Description\n      When an application\
    \ closes a connection in such a way that it can\n      no longer read any received\
    \ data, the TCP SHOULD, per section\n      4.2.2.13 of RFC 1122, send a RST if\
    \ there is any unread received\n      data, or if any new data is received. A\
    \ TCP that fails to do so\n      exhibits \"Failure to RST on close with data\
    \ pending\".\n      Note that, for some TCPs, this situation can be caused by\
    \ an\n      application \"crashing\" while a peer is sending data.\n      We have\
    \ observed a number of TCPs that exhibit this problem.  The\n      problem is\
    \ less serious if any subsequent data sent to the now-\n      closed connection\
    \ endpoint elicits a RST (see illustration below).\n   Significance\n      This\
    \ problem is most significant for endpoints that engage in\n      large numbers\
    \ of connections, as their ability to do so will be\n      curtailed as they leak\
    \ away resources.\n   Implications\n      Failure to reset the connection can\
    \ lead to permanently hung\n      connections, in which the remote endpoint takes\
    \ no further action\n      to tear down the connection because it is waiting on\
    \ the local TCP\n      to first take some action.  This is particularly the case\
    \ if the\n      local TCP also allows the advertised window to go to zero, and\n\
    \      fails to tear down the connection when the remote TCP engages in\n    \
    \  \"persist\" probes (see example below).\n   Relevant RFCs\n      RFC 1122 section\
    \ 4.2.2.13.  Also, 4.2.2.17 for the zero-window\n      probing discussion below.\n\
    \   Trace file demonstrating it\n      Made using tcpdump.  No drop information\
    \ available.\n   13:11:46.04 A > B: S 458659166:458659166(0) win 4096\n      \
    \                 <mss 1460,wscale 0,eol> (DF)\n   13:11:46.04 B > A: S 792320000:792320000(0)\
    \ ack 458659167\n                       win 4096\n   13:11:46.04 A > B: . ack\
    \ 1 win 4096 (DF)\n   13:11.55.80 A > B: . 1:513(512) ack 1 win 4096 (DF)\n  \
    \ 13:11.55.80 A > B: . 513:1025(512) ack 1 win 4096 (DF)\n   13:11:55.83 B > A:\
    \ . ack 1025 win 3072\n   13:11.55.84 A > B: . 1025:1537(512) ack 1 win 4096 (DF)\n\
    \   13:11.55.84 A > B: . 1537:2049(512) ack 1 win 4096 (DF)\n   13:11.55.85 A\
    \ > B: . 2049:2561(512) ack 1 win 4096 (DF)\n   13:11:56.03 B > A: . ack 2561\
    \ win 1536\n   13:11.56.05 A > B: . 2561:3073(512) ack 1 win 4096 (DF)\n   13:11.56.06\
    \ A > B: . 3073:3585(512) ack 1 win 4096 (DF)\n   13:11.56.06 A > B: . 3585:4097(512)\
    \ ack 1 win 4096 (DF)\n   13:11:56.23 B > A: . ack 4097 win 0\n   13:11:58.16\
    \ A > B: . 4096:4097(1) ack 1 win 4096 (DF)\n   13:11:58.16 B > A: . ack 4097\
    \ win 0\n   13:12:00.16 A > B: . 4096:4097(1) ack 1 win 4096 (DF)\n   13:12:00.16\
    \ B > A: . ack 4097 win 0\n   13:12:02.16 A > B: . 4096:4097(1) ack 1 win 4096\
    \ (DF)\n   13:12:02.16 B > A: . ack 4097 win 0\n   13:12:05.37 A > B: . 4096:4097(1)\
    \ ack 1 win 4096 (DF)\n   13:12:05.37 B > A: . ack 4097 win 0\n   13:12:06.36\
    \ B > A: F 1:1(0) ack 4097 win 0\n   13:12:06.37 A > B: . ack 2 win 4096 (DF)\n\
    \   13:12:11.78 A > B: . 4096:4097(1) ack 2 win 4096 (DF)\n   13:12:11.78 B >\
    \ A: . ack 4097 win 0\n   13:12:24.59 A > B: . 4096:4097(1) ack 2 win 4096 (DF)\n\
    \   13:12:24.60 B > A: . ack 4097 win 0\n   13:12:50.22 A > B: . 4096:4097(1)\
    \ ack 2 win 4096 (DF)\n   13:12:50.22 B > A: . ack 4097 win 0\n      Machine B\
    \ in the trace above does not drop received data when the\n      socket is \"\
    closed\" by the application (in this case, the\n      application process was\
    \ terminated). This occurred at\n      approximately 13:12:06.36 and resulted\
    \ in the FIN being sent in\n      response to the close. However, because there\
    \ is no longer an\n      application to deliver the data to, the TCP should have\
    \ instead\n      sent a RST.\n      Note: Machine A's zero-window probing is also\
    \ broken.  It is\n      resending old data, rather than new data. Section 3.7\
    \ in RFC 793\n      and Section 4.2.2.17 in RFC 1122 discuss zero-window probing.\n\
    \   Trace file demonstrating better behavior\n      Made using tcpdump.  No drop\
    \ information available.\n      Better, but still not fully correct, behavior,\
    \ per the discussion\n      below.  We show this behavior because it has been\
    \ observed for a\n      number of different TCP implementations.\n   13:48:29.24\
    \ C > D: S 73445554:73445554(0) win 4096\n                       <mss 1460,wscale\
    \ 0,eol> (DF)\n   13:48:29.24 D > C: S 36050296:36050296(0) ack 73445555\n   \
    \                    win 4096 <mss 1460,wscale 0,eol> (DF)\n   13:48:29.25 C >\
    \ D: . ack 1 win 4096 (DF)\n   13:48:30.78 C > D: . 1:1461(1460) ack 1 win 4096\
    \ (DF)\n   13:48:30.79 C > D: . 1461:2921(1460) ack 1 win 4096 (DF)\n   13:48:30.80\
    \ D > C: . ack 2921 win 1176 (DF)\n   13:48:32.75 C > D: . 2921:4097(1176) ack\
    \ 1 win 4096 (DF)\n   13:48:32.82 D > C: . ack 4097 win 0 (DF)\n   13:48:34.76\
    \ C > D: . 4096:4097(1) ack 1 win 4096 (DF)\n   13:48:34.84 D > C: . ack 4097\
    \ win 0 (DF)\n   13:48:36.34 D > C: FP 1:1(0) ack 4097 win 4096 (DF)\n   13:48:36.34\
    \ C > D: . 4097:5557(1460) ack 2 win 4096 (DF)\n   13:48:36.34 D > C: R 36050298:36050298(0)\
    \ win 24576\n   13:48:36.34 C > D: . 5557:7017(1460) ack 2 win 4096 (DF)\n   13:48:36.34\
    \ D > C: R 36050298:36050298(0) win 24576\n      In this trace, the application\
    \ process is terminated on Machine D\n      at approximately 13:48:36.34.  Its\
    \ TCP sends the FIN with the\n      window opened again (since it discarded the\
    \ previously received\n      data).  Machine C promptly sends more data, causing\
    \ Machine D to\n      reset the connection since it cannot deliver the data to\
    \ the\n      application. Ideally, Machine D SHOULD send a RST instead of\n  \
    \    dropping the data and re-opening the receive window.\n      Note: Machine\
    \ C's zero-window probing is broken, the same as in\n      the example above.\n\
    \   Trace file demonstrating correct behavior\n      Made using tcpdump.  No losses\
    \ reported by the packet filter.\n   14:12:02.19 E > F: S 1143360000:1143360000(0)\
    \ win 4096\n   14:12:02.19 F > E: S 1002988443:1002988443(0) ack 1143360001\n\
    \                       win 4096 <mss 1460> (DF)\n   14:12:02.19 E > F: . ack\
    \ 1 win 4096\n   14:12:10.43 E > F: . 1:513(512) ack 1 win 4096\n   14:12:10.61\
    \ F > E: . ack 513 win 3584 (DF)\n   14:12:10.61 E > F: . 513:1025(512) ack 1\
    \ win 4096\n   14:12:10.61 E > F: . 1025:1537(512) ack 1 win 4096\n   14:12:10.81\
    \ F > E: . ack 1537 win 2560 (DF)\n   14:12:10.81 E > F: . 1537:2049(512) ack\
    \ 1 win 4096\n   14:12:10.81 E > F: . 2049:2561(512) ack 1 win 4096\n   14:12:10.81\
    \ E > F: . 2561:3073(512) ack 1 win 4096\n   14:12:11.01 F > E: . ack 3073 win\
    \ 1024 (DF)\n   14:12:11.01 E > F: . 3073:3585(512) ack 1 win 4096\n   14:12:11.01\
    \ E > F: . 3585:4097(512) ack 1 win 4096\n   14:12:11.21 F > E: . ack 4097 win\
    \ 0 (DF)\n   14:12:15.88 E > F: . 4097:4098(1) ack 1 win 4096\n   14:12:16.06\
    \ F > E: . ack 4097 win 0 (DF)\n   14:12:20.88 E > F: . 4097:4098(1) ack 1 win\
    \ 4096\n   14:12:20.91 F > E: . ack 4097 win 0 (DF)\n   14:12:21.94 F > E: R 1002988444:1002988444(0)\
    \ win 4096\n      When the application terminates at 14:12:21.94, F immediately\n\
    \      sends a RST.\n      Note: Machine E's zero-window probing is (finally)\
    \ correct.\n   How to detect\n      The problem can often be detected by inspecting\
    \ packet traces of a\n      transfer in which the receiving application terminates\
    \ abnormally.\n      When doing so, there can be an ambiguity (if only looking\
    \ at the\n      trace) as to whether the receiving TCP did indeed have unread\
    \ data\n      that it could now no longer deliver.  To provoke this to happen,\n\
    \      it may help to suspend the receiving application so that it fails\n   \
    \   to consume any data, eventually exhausting the advertised window.\n      At\
    \ this point, since the advertised window is zero, we know that\n      the receiving\
    \ TCP has undelivered data buffered up.  Terminating\n      the application process\
    \ then should suffice to test the\n      correctness of the TCP's behavior.\n"
- title: 2.18.
  contents:
  - "2.18.\n   Name of Problem\n      Options missing from TCP MSS calculation\n \
    \  Classification\n      Reliability / performance\n   Description\n      When\
    \ a TCP determines how much data to send per packet, it\n      calculates a segment\
    \ size based on the MTU of the path.  It must\n      then subtract from that MTU\
    \ the size of the IP and TCP headers in\n      the packet.  If IP options and\
    \ TCP options are not taken into\n      account correctly in this calculation,\
    \ the resulting segment size\n      may be too large.  TCPs that do so are said\
    \ to exhibit \"Options\n      missing from TCP MSS calculation\".\n   Significance\n\
    \      In some implementations, this causes the transmission of strangely\n  \
    \    fragmented packets.  In some implementations with Path MTU (PMTU)\n     \
    \ discovery [RFC1191], this problem can actually result in a total\n      failure\
    \ to transmit any data at all, regardless of the environment\n      (see below).\n\
    \      Arguably, especially since the wide deployment of firewalls, IP\n     \
    \ options appear only rarely in normal operations.\n   Implications\n      In\
    \ implementations using PMTU discovery, this problem can result\n      in packets\
    \ that are too large for the output interface, and that\n      have the DF (don't\
    \ fragment) bit set in the IP header.  Thus, the\n      IP layer on the local\
    \ machine is not allowed to fragment the\n      packet to send it out the interface.\
    \  It instead informs the TCP\n      layer of the correct MTU size of the interface;\
    \ the TCP layer\n      again miscomputes the MSS by failing to take into account\
    \ the size\n      of IP options; and the problem repeats, with no data flowing.\n\
    \   Relevant RFCs\n      RFC 1122 describes the calculation of the effective send\
    \ MSS.  RFC\n      1191 describes Path MTU discovery.\n   Trace file demonstrating\
    \ it\n      Trace file taking using tcpdump on host C.  The first trace\n    \
    \  demonstrates the fragmentation that occurs without path MTU\n      discovery:\n\
    \   13:55:25.488728 A.65528 > C.discard:\n           P 567833:569273(1440) ack\
    \ 1 win 17520\n           <nop,nop,timestamp 3839 1026342>\n           (frag 20828:1472@0+)\n\
    \           (ttl 62, optlen=8 LSRR{B#} NOP)\n   13:55:25.488943 A > C:\n     \
    \      (frag 20828:8@1472)\n           (ttl 62, optlen=8 LSRR{B#} NOP)\n   13:55:25.489052\
    \ C.discard > A.65528:\n           . ack 566385 win 60816\n           <nop,nop,timestamp\
    \ 1026345 3839> (DF)\n           (ttl 60, id 41266)\n      Host A repeatedly sends\
    \ 1440-octet data segments, but these hare\n      fragmented into two packets,\
    \ one with 1432 octets of data, and\n      another with 8 octets of data.\n  \
    \    The second trace demonstrates the failure to send any data\n      segments,\
    \ sometimes seen with hosts doing path MTU discovery:\n   13:55:44.332219 A.65527\
    \ > C.discard:\n           S 1018235390:1018235390(0) win 16384\n           <mss\
    \ 1460,nop,wscale 0,nop,nop,timestamp 3876 0> (DF)\n           (ttl 62, id 20912,\
    \ optlen=8 LSRR{B#} NOP)\n   13:55:44.333015 C.discard > A.65527:\n          \
    \ S 1271629000:1271629000(0) ack 1018235391 win 60816\n           <mss 1460,nop,wscale\
    \ 0,nop,nop,timestamp 1026383 3876> (DF)\n           (ttl 60, id 41427)\n   13:55:44.333206\
    \ C.discard > A.65527:\n           S 1271629000:1271629000(0) ack 1018235391 win\
    \ 60816\n           <mss 1460,nop,wscale 0,nop,nop,timestamp 1026383 3876> (DF)\n\
    \           (ttl 60, id 41427)\n      This is all of the activity seen on this\
    \ connection.  Eventually\n      host C will time out attempting to establish\
    \ the connection.\n   How to detect\n      The \"netcat\" utility [Hobbit96] is\
    \ useful for generating source\n      routed packets:\n      1% nc C discard\n\
    \      (interactive typing)\n      ^C\n      2% nc C discard < /dev/zero\n   \
    \   ^C\n      3% nc -g B C discard\n      (interactive typing)\n      ^C\n   \
    \   4% nc -g B C discard < /dev/zero\n      ^C\n      Lines 1 through 3 should\
    \ generate appropriate packets, which can\n      be verified using tcpdump.  If\
    \ the problem is present, line 4\n      should generate one of the two kinds of\
    \ packet traces shown.\n   How to fix\n      The implementation should ensure\
    \ that the effective send MSS\n      calculation includes a term for the IP and\
    \ TCP options, as\n      mandated by RFC 1122.\n"
- title: 3. Security Considerations
  contents:
  - "3. Security Considerations\n   This memo does not discuss any specific security-related\
    \ TCP\n   implementation problems, as the working group decided to pursue\n  \
    \ documenting those in a separate document.  Some of the implementation\n   problems\
    \ discussed here, however, can be used for denial-of-service\n   attacks.  Those\
    \ classified as congestion control present\n   opportunities to subvert TCPs used\
    \ for legitimate data transfer into\n   excessively loading network elements.\
    \  Those classified as\n   \"performance\", \"reliability\" and \"resource management\"\
    \ may be\n   exploitable for launching surreptitious denial-of-service attacks\n\
    \   against the user of the TCP.  Both of these types of attacks can be\n   extremely\
    \ difficult to detect because in most respects they look\n   identical to legitimate\
    \ network traffic.\n"
- title: 4. Acknowledgements
  contents:
  - "4. Acknowledgements\n   Thanks to numerous correspondents on the tcp-impl mailing\
    \ list for\n   their input:  Steve Alexander, Larry Backman, Jerry Chu, Alan Cox,\n\
    \   Kevin Fall, Richard Fox, Jim Gettys, Rick Jones, Allison Mankin, Neal\n  \
    \ McBurnett, Perry Metzger, der Mouse, Thomas Narten, Andras Olah,\n   Steve Parker,\
    \ Francesco Potorti`, Luigi Rizzo, Allyn Romanow, Al\n   Smith, Jerry Toporek,\
    \ Joe Touch, and Curtis Villamizar.\n   Thanks also to Josh Cohen for the traces\
    \ documenting the \"Failure to\n   send a RST after Half Duplex Close\" problem;\
    \ and to John Polstra, who\n   analyzed the \"Window probe deadlock\" problem.\n"
- title: 5. References
  contents:
  - "5. References\n   [Allman97]   M. Allman, \"Fixing Two BSD TCP Bugs,\" Technical\
    \ Report\n                CR-204151, NASA Lewis Research Center, Oct. 1997.\n\
    \                http://roland.grc.nasa.gov/~mallman/papers/bug.ps\n   [RFC2414]\
    \    Allman, M., Floyd, S. and C. Partridge, \"Increasing\n                TCP's\
    \ Initial Window\", RFC 2414, September 1998.\n   [RFC1122]    Braden, R., Editor,\
    \ \"Requirements for Internet Hosts --\n                Communication Layers\"\
    , STD 3, RFC 1122, October 1989.\n   [RFC2119]    Bradner, S., \"Key words for\
    \ use in RFCs to Indicate\n                Requirement Levels\", BCP 14, RFC 2119,\
    \ March 1997.\n   [Brakmo95]   L. Brakmo and L. Peterson, \"Performance Problems\
    \ in\n                BSD4.4 TCP,\" ACM Computer Communication Review,\n     \
    \           25(5):69-86, 1995.\n   [RFC813]     Clark, D., \"Window and Acknowledgement\
    \ Strategy in TCP,\"\n                RFC 813, July 1982.\n   [Dawson97]   S.\
    \ Dawson, F. Jahanian, and T. Mitton, \"Experiments on\n                Six Commercial\
    \ TCP Implementations Using a Software\n                Fault Injection Tool,\"\
    \ to appear in Software Practice &\n                Experience, 1997.  A technical\
    \ report version of this\n                paper can be obtained at\n         \
    \       ftp://rtcl.eecs.umich.edu/outgoing/sdawson/CSE-TR-298-\n             \
    \   96.ps.gz.\n   [Fall96]     K. Fall and S. Floyd, \"Simulation-based Comparisons\
    \ of\n                Tahoe, Reno, and SACK TCP,\" ACM Computer Communication\n\
    \                Review, 26(3):5-21, 1996.\n   [Hobbit96]   Hobbit, Avian Research,\
    \ netcat, available via anonymous\n                ftp to ftp.avian.org, 1996.\n\
    \   [Hoe96]      J. Hoe, \"Improving the Start-up Behavior of a Congestion\n \
    \               Control Scheme for TCP,\" Proc. SIGCOMM '96.\n   [Jacobson88]\
    \ V. Jacobson, \"Congestion Avoidance and Control,\" Proc.\n                SIGCOMM\
    \ '88.  ftp://ftp.ee.lbl.gov/papers/congavoid.ps.Z\n   [Jacobson89] V. Jacobson,\
    \ C. Leres, and S. McCanne, tcpdump,\n                available via anonymous\
    \ ftp to ftp.ee.lbl.gov, Jun.\n                1989.\n   [RFC2018]    Mathis,\
    \ M., Mahdavi, J., Floyd, S. and A. Romanow, \"TCP\n                Selective\
    \ Acknowledgement Options\", RFC 2018, October\n                1996.\n   [RFC1191]\
    \    Mogul, J. and S. Deering, \"Path MTU discovery\", RFC\n                1191,\
    \ November 1990.\n   [RFC896]     Nagle, J., \"Congestion Control in IP/TCP Internetworks\"\
    ,\n                RFC 896, January 1984.\n   [Paxson97]   V. Paxson, \"Automated\
    \ Packet Trace Analysis of TCP\n                Implementations,\" Proc. SIGCOMM\
    \ '97, available from\n                ftp://ftp.ee.lbl.gov/papers/vp-tcpanaly-sigcomm97.ps.Z.\n\
    \   [RFC793]     Postel, J., Editor, \"Transmission Control Protocol,\" STD\n\
    \                7, RFC 793, September 1981.\n   [RFC2001]    Stevens, W., \"\
    TCP Slow Start, Congestion Avoidance, Fast\n                Retransmit, and Fast\
    \ Recovery Algorithms\", RFC 2001,\n                January 1997.\n   [Stevens94]\
    \  W. Stevens, \"TCP/IP Illustrated, Volume 1\", Addison-\n                Wesley\
    \ Publishing Company, Reading, Massachusetts, 1994.\n   [Wright95]   G. Wright\
    \ and W. Stevens, \"TCP/IP Illustrated, Volume\n                2\", Addison-Wesley\
    \ Publishing Company, Reading\n                Massachusetts, 1995.\n"
- title: 6. Authors' Addresses
  contents:
  - "6. Authors' Addresses\n   Vern Paxson\n   ACIRI / ICSI\n   1947 Center Street\n\
    \   Suite 600\n   Berkeley, CA 94704-1198\n   Phone: +1 510/642-4274 x302\n  \
    \ EMail: vern@aciri.org\n   Mark Allman <mallman@grc.nasa.gov>\n   NASA Glenn\
    \ Research Center/Sterling Software\n   Lewis Field\n   21000 Brookpark Road\n\
    \   MS 54-2\n   Cleveland, OH 44135\n   USA\n   Phone: +1 216/433-6586\n   Email:\
    \ mallman@grc.nasa.gov\n   Scott Dawson\n   Real-Time Computing Laboratory\n \
    \  EECS Building\n   University of Michigan\n   Ann Arbor, MI  48109-2122\n  \
    \ USA\n   Phone: +1 313/763-5363\n   EMail: sdawson@eecs.umich.edu\n   William\
    \ C. Fenner\n   Xerox PARC\n   3333 Coyote Hill Road\n   Palo Alto, CA 94304\n\
    \   USA\n   Phone: +1 650/812-4816\n   EMail: fenner@parc.xerox.com\n   Jim Griner\
    \ <jgriner@grc.nasa.gov>\n   NASA Glenn Research Center\n   Lewis Field\n   21000\
    \ Brookpark Road\n   MS 54-2\n   Cleveland, OH 44135\n   USA\n   Phone: +1 216/433-5787\n\
    \   EMail: jgriner@grc.nasa.gov\n   Ian Heavens\n   Spider Software Ltd.\n   8\
    \ John's Place, Leith\n   Edinburgh EH6 7EL\n   UK\n   Phone: +44 131/475-7015\n\
    \   EMail: ian@spider.com\n   Kevin Lahey\n   NASA Ames Research Center/MRJ\n\
    \   MS 258-6\n   Moffett Field, CA 94035\n   USA\n   Phone: +1 650/604-4334\n\
    \   EMail: kml@nas.nasa.gov\n   Jeff Semke\n   Pittsburgh Supercomputing Center\n\
    \   4400 Fifth Ave\n   Pittsburgh, PA 15213\n   USA\n   Phone: +1 412/268-4960\n\
    \   EMail: semke@psc.edu\n   Bernie Volz\n   Process Software Corporation\n  \
    \ 959 Concord Street\n   Framingham, MA 01701\n   USA\n   Phone: +1 508/879-6994\n\
    \   EMail: volz@process.com\n"
- title: 7.  Full Copyright Statement
  contents:
  - "7.  Full Copyright Statement\n   Copyright (C) The Internet Society (1999). \
    \ All Rights Reserved.\n   This document and translations of it may be copied\
    \ and furnished to\n   others, and derivative works that comment on or otherwise\
    \ explain it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
