- title: __initial_text__
  contents:
  - '               Requirements for Telepresence Multistreams

    '
- title: Abstract
  contents:
  - "Abstract\n   This memo discusses the requirements for specifications that enable\n\
    \   telepresence interoperability by describing behaviors and protocols\n   for\
    \ Controlling Multiple Streams for Telepresence (CLUE).  In\n   addition, the\
    \ problem statement and related definitions are also\n   covered herein.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7262.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2014 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction  . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   2\n   2.  Terminology . . . . . . . . . . . . . . . . . . . . .\
    \ . . . .   3\n   3.  Definitions . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .   4\n   4.  Problem Statement . . . . . . . . . . . . . . . . . . . .\
    \ . .   5\n   5.  Requirements  . . . . . . . . . . . . . . . . . . . . . . .\
    \ .   6\n   6.  Acknowledgements  . . . . . . . . . . . . . . . . . . . . . .\
    \  10\n   7.  Security Considerations . . . . . . . . . . . . . . . . . . .  10\n\
    \   8.  Informative References  . . . . . . . . . . . . . . . . . . .  11\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Telepresence systems greatly improve collaboration.  In\
    \ a\n   telepresence conference (as used herein), the goal is to create an\n \
    \  environment that gives the users a feeling of (co-located) presence\n   --\
    \ the feeling that a local user is in the same room with other local\n   users\
    \ and remote parties.  Currently, systems from different vendors\n   often do\
    \ not interoperate because they do the same tasks differently,\n   as discussed\
    \ in the Problem Statement section below (see Section 4).\n   The approach taken\
    \ in this memo is to set requirements for a future\n   specification(s) that,\
    \ when fulfilled by an implementation of the\n   specification(s), provide for\
    \ interoperability between IETF protocol-\n   based telepresence systems.  It\
    \ is anticipated that a solution for\n   the requirements set out in this memo\
    \ likely involves the exchange of\n   adequate information about participating\
    \ sites; this information that\n   is currently not standardized by the IETF.\n\
    \   The purpose of this document is to describe the requirements for a\n   specification\
    \ that enables interworking between different SIP-based\n   [RFC3261] telepresence\
    \ systems, by exchanging and negotiating\n   appropriate information.  In the\
    \ context of the requirements in this\n   document and related solution documents,\
    \ this includes both point-to-\n   point SIP sessions as well as SIP-based conferences\
    \ as described in\n   the SIP conferencing framework [RFC4353] and the SIP-based\
    \ conference\n   control [RFC4579] specifications.  Non-IETF protocol-based systems,\n\
    \   such as those based on ITU-T Rec. H.323 [ITU.H323], are out of scope.\n  \
    \ These requirements are for the specification, they are not\n   requirements\
    \ on the telepresence systems implementing the solution/\n   protocol that will\
    \ be specified.\n   Today, telepresence systems of different vendors can follow\
    \ radically\n   different architectural approaches while offering a similar user\n\
    \   experience.  CLUE will not dictate telepresence architectural and\n   implementation\
    \ choices; however, it will describe a protocol\n   architecture for CLUE and\
    \ how it relates to other protocols.  CLUE\n   enables interoperability between\
    \ telepresence systems by exchanging\n   information about the systems' characteristics.\
    \  Systems can use this\n   information to control their behavior to allow for\
    \ interoperability\n   between those systems.\n   A telepresence session requires\
    \ at least one sending and one\n   receiving endpoint.  Multiparty telepresence\
    \ sessions include more\n   than 2 endpoints and centralized infrastructure such\
    \ as Multipoint\n   Control Units (MCUs) or equivalent.  CLUE specifies the syntax,\n\
    \   semantics, and control flow of information to enable the best\n   possible\
    \ user experience at those endpoints.\n   Sending endpoints, or MCUs, are not\
    \ mandated to use any of the CLUE\n   specifications that describe their capabilities,\
    \ attributes, or\n   behavior.  Similarly, it is not envisioned that endpoints\
    \ or MCUs\n   will ever have to take information received into account.  However,\n\
    \   by making available as much information as possible, and by taking\n   into\
    \ account as much information as has been received or exchanged,\n   MCUs and\
    \ endpoints are expected to select operation modes that enable\n   the best possible\
    \ user experience under their constraints.\n   The document structure is as follows:\
    \ definitions are set out,\n   followed by a description of the problem of telepresence\n\
    \   interoperability that led to this work.  Then the requirements for a\n   specification\
    \ addressing the current shortcomings are enumerated and\n   discussed.\n"
- title: 2.  Terminology
  contents:
  - "2.  Terminology\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\"\
    , \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and\
    \ \"OPTIONAL\" in this\n   document are to be interpreted as described in RFC\
    \ 2119 [RFC2119].\n"
- title: 3.  Definitions
  contents:
  - "3.  Definitions\n   The following terms are used throughout this document and\
    \ serve as a\n   reference for other documents.\n      Audio Mixing: refers to\
    \ the accumulation of scaled audio signals\n      to produce a single audio stream.\
    \  See \"RTP Topologies\" [RFC5117].\n      Conference: used as defined in \"\
    A Framework for Conferencing\n      within the Session Initiation Protocol (SIP)\"\
    \ [RFC4353].\n      Endpoint: The logical point of final termination through\n\
    \      receiving, decoding and rendering, and/or initiation through\n      capturing,\
    \ encoding, and sending of media streams.  An endpoint\n      consists of one\
    \ or more physical devices that source and sink\n      media streams, and exactly\
    \ one participant [RFC4353] (which, in\n      turn, includes exactly one SIP user\
    \ agent).  In contrast to an\n      endpoint, an MCU may also send and receive\
    \ media streams, but it\n      is not the initiator or the final terminator in\
    \ the sense that\n      media is captured or rendered.  Endpoints can be anything\
    \ from\n      multiscreen/multicamera rooms to handheld devices.\n      Endpoint\
    \ Characteristics: include placement of capture and\n      rendering devices,\
    \ capture/render angle, resolution of cameras and\n      screens, spatial location,\
    \ and mixing parameters of microphones.\n      Endpoint characteristics are not\
    \ specific to individual media\n      streams sent by the endpoint.\n      Layout:\
    \ How rendered media streams are spatially arranged with\n      respect to each\
    \ other on a telepresence endpoint with a single\n      screen and a single loudspeaker,\
    \ and how rendered media streams\n      are arranged with respect to each other\
    \ on a telepresence endpoint\n      with multiple screens or loudspeakers.  Note\
    \ that audio as well as\n      video are encompassed by the term layout -- in\
    \ other words,\n      included is the placement of audio streams on loudspeakers\
    \ as well\n      as video streams on video screens.\n      Local: Sender and/or\
    \ receiver physically co-located (\"local\") in\n      the context of the discussion.\n\
    \      MCU: Multipoint Control Unit (MCU) - a device that connects two or\n  \
    \    more endpoints together into one single multimedia conference\n      [RFC5117].\
    \  An MCU may include a mixer [RFC4353].\n      Media: Any data that, after suitable\
    \ encoding, can be conveyed\n      over RTP, including audio, video, or timed\
    \ text.\n      Model: a set of assumptions a telepresence system of a given\n\
    \      vendor adheres to and expects the remote telepresence system(s) to\n  \
    \    also adhere to.\n      Remote: Sender and/or receiver on the other side of\
    \ the\n      communication channel (depending on context); i.e., not local.  A\n\
    \      remote can be an endpoint or an MCU.\n      Render: the process of generating\
    \ a representation from a media,\n      such as displayed motion video or sound\
    \ emitted from loudspeakers.\n      Telepresence: an environment that gives non-co-located\
    \ users or\n      user groups a feeling of (co-located) presence -- the feeling\
    \ that\n      a local user is in the same room with other local users and the\n\
    \      remote parties.  The inclusion of Remote parties is achieved\n      through\
    \ multimedia communication including at least audio and\n      video signals of\
    \ high fidelity.\n"
- title: 4.  Problem Statement
  contents:
  - "4.  Problem Statement\n   In order to create a \"being there\" experience characteristic\
    \ of\n   telepresence, media inputs need to be transported, received, and\n  \
    \ coordinated between participating systems.  Different telepresence\n   systems\
    \ take diverse approaches in crafting a solution, or they\n   implement similar\
    \ solutions quite differently.\n   They use disparate techniques, and they describe,\
    \ control and\n   negotiate media in dissimilar fashions.  Such diversity creates\
    \ an\n   interoperability problem.  The same issues are solved in different\n\
    \   ways by different systems, so that they are not directly\n   interoperable.\
    \  This makes interworking difficult at best and\n   sometimes impossible.\n \
    \  Worse, even if those extensions are based on common standards such as\n   SIP,\
    \ many telepresence systems use proprietary protocol extensions to\n   solve telepresence-related\
    \ problems.\n   Some degree of interworking between systems from different vendors\
    \ is\n   possible through transcoding and translation.  This requires\n   additional\
    \ devices, which are expensive, are often not entirely\n   automatic, and sometimes\
    \ introduce unwelcome side effects, such as\n   additional delay or degraded performance.\
    \  Specialized knowledge is\n   currently required to operate a telepresence conference\
    \ with\n   endpoints from different vendors, for example to configure\n   transcoding\
    \ and translating devices.  Often such conferences do not\n   start as planned\
    \ or are interrupted by difficulties that arise.\n   The general problem that\
    \ needs to be solved can be described as\n   follows.  Today, each endpoint renders\
    \ the audio and video captures\n   it receives according to an implicitly assumed\
    \ model that stipulates\n   how to produce a realistic depiction of the remote\
    \ location.  If all\n   endpoints are manufactured by the same vendor, they all\
    \ share the\n   same implicit model and render the received captures correctly.\n\
    \   However, if the devices are from different vendors, the models used\n   for\
    \ rendering presence can and usually do differ.  The result can be\n   that the\
    \ telepresence systems actually connect, but the user\n   experience will suffer,\
    \ for example one system assumes that the first\n   video stream is captured from\
    \ the right camera, whereas the other\n   assumes the first video stream is captured\
    \ from the left camera.\n   If Alice and Bob are at different sites, Alice needs\
    \ to tell Bob\n   about the camera and sound equipment arrangement at her site\
    \ so that\n   Bob's receiver can create an accurate rendering of her site.  Alice\n\
    \   and Bob need to agree on what the salient characteristics are as well\n  \
    \ as how to represent and communicate them.  Characteristics may\n   include number,\
    \ placement, capture/render angle, resolution of\n   cameras and screens, spatial\
    \ location, and audio mixing parameters of\n   microphones.\n   The telepresence\
    \ multistream work seeks to describe the sender\n   situation in a way that allows\
    \ the receiver to render it\n   realistically even though it may have a different\
    \ rendering model\n   than the sender.\n"
- title: 5.  Requirements
  contents:
  - "5.  Requirements\n   Although some aspects of these requirements can be met by\
    \ existing\n   technology, such as the Session Description Protocol (SDP) [RFC4566],\n\
    \   they are stated here to have a complete record of the requirements\n   for\
    \ CLUE.  Determining whether a requirement needs new work or not\n   will be part\
    \ of the solution development, and is not discussed in\n   this document.  Note\
    \ that the term \"solution\" is used in these\n   requirements to mean the protocol\
    \ specifications, including\n   extensions to existing protocols as well as any\
    \ new protocols,\n   developed to support the use cases.  The solution might introduce\n\
    \   additional functionality that is not mapped directly to these\n   requirements;\
    \ e.g., the detailed information carried in the signaling\n   protocol(s).  In\
    \ cases where the requirements are directly relevant\n   to specific use cases\
    \ as described in [RFC7205], a reference to the\n   use case is provided.\n  \
    \ REQ-1:   The solution MUST support a description of the spatial\n          \
    \  arrangement of source video images sent in video streams\n            that\
    \ enables a satisfactory reproduction at the receiver of\n            the original\
    \ scene.  This applies to each site in a point-\n            to-point or a multipoint\
    \ meeting and refers to the spatial\n            ordering within a site, not to\
    \ the ordering of images\n            between sites.\n            This requirement\
    \ relates to all the use cases described in\n            [RFC7205].\n        \
    \    REQ-1a:  The solution MUST support a means of allowing the\n            \
    \         preservation of the order of images in the captured\n              \
    \       scene.  For example, if John is to Susan's right in\n                \
    \     the image capture, John is also to Susan's right in\n                  \
    \   the rendered image.\n            REQ-1b:  The solution MUST support a means\
    \ of allowing the\n                     preservation of order of images in the\
    \ scene in two\n                     dimensions - horizontal and vertical.\n \
    \           REQ-1c:  The solution MUST support a means to identify the\n     \
    \                relative location, within a scene, of the point of\n        \
    \             capture of individual video captures in three\n                \
    \     dimensions.\n            REQ-1d:  The solution MUST support a means to identify\
    \ the\n                     area of coverage, within a scene, of individual\n\
    \                     video captures in three dimensions.\n   REQ-2:   The solution\
    \ MUST support a description of the spatial\n            arrangement of captured\
    \ source audio sent in audio streams\n            that enables a satisfactory\
    \ reproduction at the receiver in\n            a spatially correct manner.  This\
    \ applies to each site in a\n            point to point or a multipoint meeting\
    \ and refers to the\n            spatial ordering within a site, not the ordering\
    \ of channels\n            between sites.\n            This requirement relates\
    \ to all the use cases described in\n            [RFC7205], but is particularly\
    \ important in the\n            Heterogeneous Systems use case.\n            REQ-2a:\
    \  The solution MUST support a means of preserving the\n                     spatial\
    \ order of audio in the captured scene.  For\n                     example, if\
    \ John sounds as if he is on Susan's\n                     right in the captured\
    \ audio, John voice is also\n                     placed on Susan's right in the\
    \ rendered image.\n            REQ-2b:  The solution MUST support a means to identify\
    \ the\n                     number and spatial arrangement of audio channels\n\
    \                     including monaural, stereophonic (2.0), and 3.0\n      \
    \               (left, center, right) audio channels.\n            REQ-2c:  The\
    \ solution MUST support a means to identify the\n                     point of\
    \ capture of individual audio captures in\n                     three dimensions.\n\
    \            REQ-2d:  The solution MUST support a means to identify the\n    \
    \                 area of coverage of individual audio captures in\n         \
    \            three dimensions.\n   REQ-3:   The solution MUST enable individual\
    \ audio streams to be\n            associated with one or more video image captures,\
    \ and\n            individual video image captures to be associated with one or\n\
    \            more audio captures, for the purpose of rendering proper\n      \
    \      position.\n            This requirement relates to all the use cases described\
    \ in\n            [RFC7205].\n   REQ-4:   The solution MUST enable interoperability\
    \ between endpoints\n            that have a different number of similar devices.\
    \  For\n            example, an endpoint may have 1 screen, 1 loudspeaker, 1\n\
    \            camera, 1 mic, and another endpoint may have 3 screens, 2\n     \
    \       loudspeakers, 3 cameras and 2 microphones.  Or, in a\n            multipoint\
    \ conference, an endpoint may have 1 screen,\n            another may have 2 screens,\
    \ and a third may have 3 screens.\n            This includes endpoints where the\
    \ number of devices of a\n            given type is zero.\n            This requirement\
    \ relates to the Point-to-Point Meeting:\n            Symmetric and Multipoint\
    \ Meeting use cases described in\n            [RFC7205].\n   REQ-5:   The solution\
    \ MUST support means of enabling interoperability\n            between telepresence\
    \ endpoints where cameras are of\n            different picture aspect ratios.\n\
    \   REQ-6:   The solution MUST provide scaling information that enables\n    \
    \        rendering of a video image at the actual size of the\n            captured\
    \ scene.\n   REQ-7:   The solution MUST support means of enabling interoperability\n\
    \            between telepresence endpoints where displays are of\n          \
    \  different resolutions.\n   REQ-8:   The solution MUST support methods for handling\
    \ different bit\n            rates in the same conference.\n   REQ-9:   The solution\
    \ MUST support means of enabling interoperability\n            between endpoints\
    \ that send and receive different numbers of\n            media streams.\n   \
    \         This requirement relates to the Heterogeneous Systems and\n        \
    \    Multipoint Meeting use cases.\n   REQ-10:  The solution MUST ensure that\
    \ endpoints that support\n            telepresence extensions can establish a\
    \ session with a SIP\n            endpoint that does not support the telepresence\
    \ extensions.\n            For example, in the case of a SIP endpoint that supports\
    \ a\n            single audio and a single video stream, an endpoint that\n  \
    \          supports the telepresence extensions would setup a session\n      \
    \      with a single audio and single video stream using existing\n          \
    \  SIP and SDP mechanisms.\n   REQ-11:  The solution MUST support a mechanism\
    \ for determining\n            whether or not an endpoint or MCU is capable of\
    \ telepresence\n            extensions.\n   REQ-12:  The solution MUST support\
    \ a means to enable more than two\n            endpoints to participate in a teleconference.\n\
    \            This requirement relates to the Multipoint Meeting use case.\n  \
    \ REQ-13:  The solution MUST support both transcoding and switching\n        \
    \    approaches for providing multipoint conferences.\n   REQ-14:  The solution\
    \ MUST support mechanisms to allow media from one\n            source endpoint\
    \ or/and multiple source endpoints to be sent\n            to a remote endpoint\
    \ at a particular point in time.  Which\n            media is sent at a point\
    \ in time may be based on local\n            policy.\n   REQ-15:  The solution\
    \ MUST provide mechanisms to support the\n            following:\n           \
    \ *  Presentations with different media sources\n            *  Presentations\
    \ for which the media streams are visible to\n               all endpoints\n \
    \           *  Multiple, simultaneous presentation media streams,\n          \
    \     including presentation media streams that are spatially\n              \
    \ related to each other.\n               The requirement relates to the Presentation\
    \ use case.\n   REQ-16:  The specification of any new protocols for the solution\
    \ MUST\n            provide extensibility mechanisms.\n   REQ-17:  The solution\
    \ MUST support a mechanism for allowing\n            information about media captures\
    \ to change during a\n            conference.\n   REQ-18:  The solution MUST provide\
    \ a mechanism for the secure\n            exchange of information about the media\
    \ captures.\n"
- title: 6.  Acknowledgements
  contents:
  - "6.  Acknowledgements\n   This document has benefited from all the comments on\
    \ the CLUE mailing\n   list and a number of discussions.  So many people contributed\
    \ that it\n   is not possible to list them all.  However, the comments provided\
    \ by\n   Roberta Presta, Christian Groves and Paul Coverdale during WGLC were\n\
    \   particularly helpful in completing the WG document.\n"
- title: 7.  Security Considerations
  contents:
  - "7.  Security Considerations\n   REQ-18 identifies the need to securely transport\
    \ the information\n   about media captures.  It is important to note that session\
    \ setup for\n   a telepresence session will use SIP for basic session setup and\n\
    \   either SIP or the Centralized Conferencing Manipulation Protocol\n   (CCMP)\
    \ [RFC6503] for a multiparty telepresence session.  Information\n   carried in\
    \ the SIP signaling can be secured by the SIP security\n   mechanisms as defined\
    \ in [RFC3261].  In the case of conference\n   control using CCMP, the security\
    \ model and mechanisms as defined in\n   the Centralized Conferencing (XCON) Framework\
    \ [RFC5239] and CCMP\n   [RFC6503] documents would meet the requirement.  Any\
    \ additional\n   signaling mechanism used to transport the information about media\n\
    \   captures needs to define the mechanisms by which the information is\n   secure.\
    \  The details for the mechanisms needs to be defined and\n   described in the\
    \ CLUE framework document and related solution\n   document(s).\n"
- title: 8.  Informative References
  contents:
  - "8.  Informative References\n   [RFC2119]  Bradner, S., \"Key words for use in\
    \ RFCs to Indicate\n              Requirement Levels\", BCP 14, RFC 2119, March\
    \ 1997.\n   [RFC3261]  Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston,\n\
    \              A., Peterson, J., Sparks, R., Handley, M., and E.\n           \
    \   Schooler, \"SIP: Session Initiation Protocol\", RFC 3261,\n              June\
    \ 2002.\n   [RFC4353]  Rosenberg, J., \"A Framework for Conferencing with the\n\
    \              Session Initiation Protocol (SIP)\", RFC 4353, February\n     \
    \         2006.\n   [RFC4566]  Handley, M., Jacobson, V., and C. Perkins, \"SDP:\
    \ Session\n              Description Protocol\", RFC 4566, July 2006.\n   [RFC4579]\
    \  Johnston, A. and O. Levin, \"Session Initiation Protocol\n              (SIP)\
    \ Call Control - Conferencing for User Agents\", BCP\n              119, RFC 4579,\
    \ August 2006.\n   [RFC5117]  Westerlund, M. and S. Wenger, \"RTP Topologies\"\
    , RFC 5117,\n              January 2008.\n   [RFC5239]  Barnes, M., Boulton, C.,\
    \ and O. Levin, \"A Framework for\n              Centralized Conferencing\", RFC\
    \ 5239, June 2008.\n   [RFC6503]  Barnes, M., Boulton, C., Romano, S., and H.\
    \ Schulzrinne,\n              \"Centralized Conferencing Manipulation Protocol\"\
    , RFC\n              6503, March 2012.\n   [RFC7205]  Romanow, A., Botzko, S.,\
    \ Duckworth, M., and R. Even, \"Use\n              Cases for Telepresence Multistreams\"\
    , RFC 7205, April\n              2014.\n   [ITU.H323] ITU-T, \"Packet-based Multimedia\
    \ Communications Systems\",\n              ITU-T Recommendation H.323, December\
    \ 2009.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Allyn Romanow\n   Cisco Systems\n   San Jose, CA  95134\n\
    \   USA\n   EMail: allyn@cisco.com\n   Stephen Botzko\n   Polycom\n   Andover,\
    \ MA  01810\n   USA\n   EMail: stephen.botzko@polycom.com\n   Mary Barnes\n  \
    \ MLB@Realtime Communications, LLC\n   EMail: mary.ietf.barnes@gmail.com\n"
