- title: __initial_text__
  contents:
  - '       Building Directories from DNS: Experiences from WWWSeeker

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (1999).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   There has been much discussion and several documents written about\n\
    \   the need for an Internet Directory.  Recently, this discussion has\n   focused\
    \ on ways to discover an organization's domain name without\n   relying on use\
    \ of DNS as a directory service.  This memo discusses\n   lessons that were learned\
    \ during InterNIC Directory and Database\n   Services' development and operation\
    \ of WWWSeeker, an application that\n   finds a web site given information about\
    \ the name and location of an\n   organization.  The back end database that drives\
    \ this application was\n   built from information obtained from domain registries\
    \ via WHOIS and\n   other protocols.  We present this information to help future\n\
    \   implementors avoid some of the blind alleys that we have already\n   explored.\
    \  This work builds on the Netfind system that was created by\n   Mike Schwartz\
    \ and his team at the University of Colorado at Boulder\n   [1].\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   Over time, there have been several RFCs [2, 3, 4] about approaches\n\
    \   for providing Internet Directories.  Many of the earlier documents\n   discussed\
    \ white pages directories that supply mappings from a\n   person's name to their\
    \ telephone number, email address, etc.\n   More recently, there has been discussion\
    \ of directories that map from\n   a company name to a domain name or web site.\
    \  Many people are using\n   DNS as a directory today to find this type of information\
    \ about a\n   given company.  Typically when DNS is used, users guess the domain\n\
    \   name of the company they are looking for and then prepend \"www.\".\n   This\
    \ makes it highly desirable for a company to have an easily\n   guessable name.\n\
    \   There are two major problems here.  As the number of assigned names\n   increases,\
    \ it becomes more difficult to get an easily guessable name.\n   Also, the TLD\
    \ must be guessed as well as the name.  While many users\n   just guess \".COM\"\
    \ as the \"default\" TLD today, there are many two-\n   letter country code top-level\
    \ domains in current use as well as other\n   gTLDs (.NET, .ORG, and possibly\
    \ .EDU) with the prospect of additional\n   gTLDs in the future.  As the number\
    \ of TLDs in general use increases,\n   guessing gets more difficult.\n   Between\
    \ July 1996 and our shutdown in March 1998, the InterNIC\n   Directory and Database\
    \ Services project maintained the Netfind search\n   engine [1] and the associated\
    \ database that maps organization\n   information to domain names. This database\
    \ thus acted as the type of\n   Internet directory that associates company names\
    \ with domain names.\n   We also built WWWSeeker, a system that used the Netfind\
    \ database to\n   find web sites associated with a given organization.  The experienced\n\
    \   gained from maintaining and growing this database provides valuable\n   insight\
    \ into the issues of providing a directory service.  We present\n   it here to\
    \ allow future implementors to avoid some of the blind\n   alleys that we have\
    \ already explored.\n"
- title: 2. Directory Population
  contents:
  - '2. Directory Population

    '
- title: 2.1 What to do?
  contents:
  - "2.1 What to do?\n   There are two issues in populating a directory: finding all\
    \ the\n   domain names (building the skeleton) and associating those domains\n\
    \   with entities (adding the meat).  These two issues are discussed\n   below.\n"
- title: 2.2 Building the skeleton
  contents:
  - "2.2 Building the skeleton\n   In \"building the skeleton\", it is popular to\
    \ suggest using a variant\n   of a \"tree walk\" to determine the domains that\
    \ need to be added to\n   the directory.  Our experience is that this is neither\
    \ a reasonable\n   nor an efficient proposal for maintaining such a directory.\
    \  Except\n   for some infrequent and long-standing DNS surveys [5], DNS \"tree\n\
    \   walks\" tend to be discouraged by the Internet community, especially\n   given\
    \ that the frequency of DNS changes would require a new tree walk\n   monthly\
    \ (if not more often).  Instead, our experience has shown that\n   data on allocated\
    \ DNS domains can usually be retrieved in bulk\n   fashion with FTP, HTTP, or\
    \ Gopher (we have used each of these for\n   particular TLDs).  This has the added\
    \ advantage of both \"building the\n   skeleton\" and \"adding the meat\" at the\
    \ same time.  Our favorite\n   method for finding a server that has allocated\
    \ DNS domain information\n   is to start with the list maintained at\n   http://www.alldomains.com/countryindex.html\
    \ and go from there.\n   Before this was available, it was necessary to hunt for\
    \ a registry\n   using trial and error.\n   When maintaining the database, existing\
    \ domains may be verified via\n   direct DNS lookups rather than a \"tree walk.\"\
    \ \"Tree walks\" should\n   therefore be the choice of last resort for directory\
    \ population, and\n   bulk retrieval should be used whenever possible.\n"
- title: 2.3 Adding the meat
  contents:
  - "2.3 Adding the meat\n   A possibility for populating a directory (\"adding the\
    \ meat\") is to\n   use an automated system that makes repeated queries using\
    \ the WHOIS\n   protocol to gather information about the organization that owns\
    \ a\n   domain.  The queries would be made against a WHOIS server located\n  \
    \ with the above method. At the conclusion of the InterNIC Directory\n   and Database\
    \ Services project, our backend database contained about\n   2.9 million records\
    \ built from data that could be retrieved via\n   WHOIS.  The entire database\
    \ contained 3.25 million records, with the\n   additional records coming from\
    \ sources other than WHOIS.\n   In our experience this information contains many\
    \ factual and\n   typographical errors and requires further examination and processing\n\
    \   to improve its quality.  Further, TLD registrars that support WHOIS\n   typically\
    \ only support WHOIS information for second level domains\n   (i.e. ne.us) as\
    \ opposed to lower level domains (i.e.\n   windrose.omaha.ne.us).  Also, there\
    \ are TLDs without registrars, TLDs\n   without WHOIS support, and still other\
    \ TLDs that use other methods\n   (HTTP, FTP, gopher) for providing organizational\
    \ information.  Based\n   on our experience, an implementor of an internet directory\
    \ needs to\n   support multiple protocols for directory population.  An automated\n\
    \   WHOIS search tool is necessary, but isn't enough.\n"
- title: '3. Directory Updating: Full Rebuilds vs Incremental Updates'
  contents:
  - "3. Directory Updating: Full Rebuilds vs Incremental Updates\n   Given the size\
    \ of our database in April 1998 when it was last\n   generated, a complete rebuild\
    \ of the database that is available from\n   WHOIS lookups would require between\
    \ 134.2 to 167.8 days just for\n   WHOIS lookups from a Sun SPARCstation 20. This\
    \ estimate does not\n   include other considerations (for example, inverting the\
    \ token tree\n   required about 24 hours processing time on a Sun SPARCstation\
    \ 20)\n   that would increase the amount of time to rebuild the entire\n   database.\n\
    \   Whether this is feasible depends on the frequency of database updates\n  \
    \ provided.  Because of the rate of growth of allocated domain names\n   (150K-200K\
    \ new allocated domains per month in early 1998), we\n   provided monthly updates\
    \ of the database. To rebuild the database\n   each month (based on the above\
    \ time estimate) would require between 3\n   and 5 machines to be dedicated full\
    \ time (independent of machine\n   architecture).  Instead, we checkpointed the\
    \ allocated domain list\n   and rebuild on an incremental basis during one weekend\
    \ of the month.\n   This allowed us to complete the update on between 1 and 4\
    \ machines (3\n   Sun SPARCstation 20s and a dual-processor Sparcserver 690) without\n\
    \   full dedication over a couple of days.  Further, by coupling\n   incremental\
    \ updates with periodic refresh of existing data (which can\n   be done during\
    \ another part of the month and doesn't require full\n   dedication of machine\
    \ hardware), older records would be periodically\n   updated when the underlying\
    \ information changes.  The tradeoff is\n   timeliness and accuracy of data (some\
    \ data in the database may be\n   old) against hardware and processing costs.\n"
- title: '4. Directory Presentation: Distributed vs Monolithic'
  contents:
  - "4. Directory Presentation: Distributed vs Monolithic\n   While a distributed\
    \ directory is a desirable goal, we maintained our\n   database as a monolithic\
    \ structure.  Given past growth, it is not\n   clear at what point migrating to\
    \ a distributed directory becomes\n   actually necessary to support customer queries.\
    \  Our last database\n   contained over 3.25 million records in a flat ASCII file.\
    \  Searching\n   was done via a PERL script of an inverted tree (also produced\
    \ by a\n   PERL script).  While admittedly primitive, this configuration\n   supported\
    \ over 200,000 database queries per month from our production\n   servers.\n \
    \  Increasing the database size only requires more disk space to hold\n   the\
    \ database and inverted tree. Of course, using database technology\n   would probably\
    \ improve performance and scalability, but we had not\n   reached the point where\
    \ this technology was required.\n"
- title: 5. Security Considerations
  contents:
  - "5. Security Considerations\n   The underlying data for the type of directory\
    \ discussed in this\n   document is already generally available through WHOIS,\
    \ DNS, and other\n   standard interfaces.  No new information is made available\
    \ by using\n   these techniques though many types of search become much easier.\
    \  To\n   the extent that easier access to this data makes it easier to find\n\
    \   specific sites or machines to attack, security may be decreased.\n   The protocols\
    \ discussed here do not have built-in security features.\n   If one source machine\
    \ is spoofed while the directory data is being\n   gathered, substantial amounts\
    \ of incorrect and misleading data could\n   be pulled in to the directory and\
    \ be spread to a wider audience.\n   In general, building a directory from registry\
    \ data will not open any\n   new security holes since the data is already available\
    \ to the public.\n   Existing security and accuracy problems with the data sources\
    \ are\n   likely to be amplified.\n"
- title: 6. Acknowledgments
  contents:
  - "6. Acknowledgments\n   This work described in this document was partially supported\
    \ by the\n   National Science Foundation under Cooperative Agreement NCR-9218179.\n"
- title: 7. References
  contents:
  - "7. References\n   [1] M. F. Schwartz, C. Pu.  \"Applying an Information\n   \
    \    Gathering Architecture to Netfind: A White Pages Tool for a\n       Changing\
    \ and Growing Internet\", University of Colorado Technical\n       Report CU-CS-656-93.\
    \  December 1993, revised July 1994.\n       URL:ftp://ftp.cs.colorado.edu/pub/cs/techreports/schwartz/Netfind\n\
    \   [2] Sollins, K., \"Plan for Internet Directory Services\", RFC 1107,\n   \
    \    July 1989.\n   [3] Hardcastle-Kille, S., Huizer, E., Cerf, V., Hobby, R.\
    \ and S.\n       Kent, \"A Strategic Plan for Deploying an Internet X.500 Directory\n\
    \       Service\", RFC 1430, February 1993.\n   [4] Postel, J. and  C. Anderson,\
    \ \"White Pages Meeting Report\", RFC\n       1588, February 1994.\n   [5] M.\
    \ Lottor, \"Network Wizards Internet Domain Survey\", available\n       from http://www.nw.com/zone/WWW/top.html\n"
- title: 8. Authors' Addresses
  contents:
  - "8. Authors' Addresses\n   Ryan Moats\n   AT&T\n   15621 Drexel Circle\n   Omaha,\
    \ NE 68135-2358\n   USA\n   EMail:  jayhawk@att.com\n   Rick Huber\n   AT&T\n\
    \   Room C3-3B30, 200 Laurel Ave. South\n   Middletown, NJ 07748\n   USA\n   EMail:\
    \ rvh@att.com\n"
- title: 9.  Full Copyright Statement
  contents:
  - "9.  Full Copyright Statement\n   Copyright (C) The Internet Society (1999). \
    \ All Rights Reserved.\n   This document and translations of it may be copied\
    \ and furnished to\n   others, and derivative works that comment on or otherwise\
    \ explain it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
