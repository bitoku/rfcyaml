- title: __initial_text__
  contents:
  - "           Forwarding and Control Element Separation (ForCES)\n             \
    \   Inter-FE Logical Functional Block (LFB)\n"
- title: Abstract
  contents:
  - "Abstract\n   This document describes how to extend the Forwarding and Control\n\
    \   Element Separation (ForCES) Logical Functional Block (LFB) topology\n   across\
    \ Forwarding Elements (FEs) by defining the inter-FE LFB class.\n   The inter-FE\
    \ LFB class provides the ability to pass data and metadata\n   across FEs without\
    \ needing any changes to the ForCES specification.\n   The document focuses on\
    \ Ethernet transport.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This is an Internet Standards Track document.\n   This\
    \ document is a product of the Internet Engineering Task Force\n   (IETF).  It\
    \ represents the consensus of the IETF community.  It has\n   received public\
    \ review and has been approved for publication by the\n   Internet Engineering\
    \ Steering Group (IESG).  Further information on\n   Internet Standards is available\
    \ in Section 2 of RFC 7841.\n   Information about the current status of this document,\
    \ any errata,\n   and how to provide feedback on it may be obtained at\n   http://www.rfc-editor.org/info/rfc8013.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2017 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction  . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   2\n   2.  Terminology and Conventions . . . . . . . . . . . . .\
    \ . . . .   3\n     2.1.  Requirements Language . . . . . . . . . . . . . . .\
    \ . . .   3\n     2.2.  Definitions . . . . . . . . . . . . . . . . . . . . .\
    \ . .   3\n   3.  Problem Scope and Use Cases . . . . . . . . . . . . . . . .\
    \ .   4\n     3.1.  Assumptions . . . . . . . . . . . . . . . . . . . . . . .\
    \   4\n     3.2.  Sample Use Cases  . . . . . . . . . . . . . . . . . . . .  \
    \ 4\n       3.2.1.  Basic IPv4 Router . . . . . . . . . . . . . . . . . .   4\n\
    \         3.2.1.1.  Distributing the Basic IPv4 Router  . . . . . . .   6\n  \
    \     3.2.2.  Arbitrary Network Function  . . . . . . . . . . . . .   7\n    \
    \     3.2.2.1.  Distributing the Arbitrary Network Function . . .   8\n   4. \
    \ Inter-FE LFB Overview . . . . . . . . . . . . . . . . . . . .   8\n     4.1.\
    \  Inserting the Inter-FE LFB  . . . . . . . . . . . . . . .   8\n   5.  Inter-FE\
    \ Ethernet Connectivity  . . . . . . . . . . . . . . .  10\n     5.1.  Inter-FE\
    \ Ethernet Connectivity Issues . . . . . . . . . .  10\n       5.1.1.  MTU Consideration\
    \ . . . . . . . . . . . . . . . . . .  10\n       5.1.2.  Quality-of-Service Considerations\
    \ . . . . . . . . . .  11\n       5.1.3.  Congestion Considerations . . . . .\
    \ . . . . . . . . .  11\n     5.2.  Inter-FE Ethernet Encapsulation . . . . .\
    \ . . . . . . . .  12\n   6.  Detailed Description of the Ethernet Inter-FE LFB\
    \ . . . . . .  13\n     6.1.  Data Handling . . . . . . . . . . . . . . . . .\
    \ . . . . .  13\n       6.1.1.  Egress Processing . . . . . . . . . . . . . .\
    \ . . . .  14\n       6.1.2.  Ingress Processing  . . . . . . . . . . . . . .\
    \ . . .  15\n     6.2.  Components  . . . . . . . . . . . . . . . . . . . . .\
    \ . .  16\n     6.3.  Inter-FE LFB XML Model  . . . . . . . . . . . . . . . .\
    \ .  17\n   7.  IANA Considerations . . . . . . . . . . . . . . . . . . . . .\
    \  21\n   8.  IEEE Assignment Considerations  . . . . . . . . . . . . . . .  21\n\
    \   9.  Security Considerations . . . . . . . . . . . . . . . . . . .  22\n  \
    \ 10. References  . . . . . . . . . . . . . . . . . . . . . . . . .  23\n    \
    \ 10.1.  Normative References . . . . . . . . . . . . . . . . . .  23\n     10.2.\
    \  Informative References . . . . . . . . . . . . . . . . .  24\n   Acknowledgements\
    \  . . . . . . . . . . . . . . . . . . . . . . . .  25\n   Authors' Addresses\
    \  . . . . . . . . . . . . . . . . . . . . . . .  25\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   In the ForCES architecture, a packet service can be modeled\
    \ by\n   composing a graph of one or more LFB instances.  The reader is\n   referred\
    \ to the details in the ForCES model [RFC5812].\n   The ForCES model describes\
    \ the processing within a single Forwarding\n   Element (FE) in terms of Logical\
    \ Functional Blocks (LFBs), including\n   provision for the Control Element (CE)\
    \ to establish and modify that\n   processing sequence, and the parameters of\
    \ the individual LFBs.\n   Under some circumstances, it would be beneficial to\
    \ be able to extend\n   this view and the resulting processing across more than\
    \ one FE.  This\n   may be in order to achieve scale by splitting the processing\
    \ across\n   elements or to utilize specialized hardware available on specific\n\
    \   FEs.\n   Given that the ForCES inter-LFB architecture calls for the ability\
    \ to\n   pass metadata between LFBs, it is imperative to define mechanisms to\n\
    \   extend that existing feature and allow passing the metadata between\n   LFBs\
    \ across FEs.\n   This document describes how to extend the LFB topology across\
    \ FEs,\n   i.e., inter-FE connectivity without needing any changes to the ForCES\n\
    \   definitions.  It focuses on using Ethernet as the interconnection\n   between\
    \ FEs.\n"
- title: 2.  Terminology and Conventions
  contents:
  - '2.  Terminology and Conventions

    '
- title: 2.1.  Requirements Language
  contents:
  - "2.1.  Requirements Language\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\"\
    , \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"\
    MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in [RFC2119].\n"
- title: 2.2.  Definitions
  contents:
  - "2.2.  Definitions\n   This document depends on the terms (below) defined in several\
    \ ForCES\n   documents: [RFC3746], [RFC5810], [RFC5811], [RFC5812], [RFC7391],\
    \ and\n   [RFC7408].\n      Control Element (CE)\n      Forwarding Element (FE)\n\
    \      FE Model\n      LFB (Logical Functional Block) Class (or type)\n      LFB\
    \ Instance\n      LFB Model\n      LFB Metadata\n      ForCES Component\n    \
    \  LFB Component\n      ForCES Protocol Layer (ForCES PL)\n      ForCES Protocol\
    \ Transport Mapping Layer (ForCES TML)\n"
- title: 3.  Problem Scope and Use Cases
  contents:
  - "3.  Problem Scope and Use Cases\n   The scope of this document is to solve the\
    \ challenge of passing\n   ForCES-defined metadata alongside packet data across\
    \ FEs (be they\n   physical or virtual) for the purpose of distributing the LFB\n\
    \   processing.\n"
- title: 3.1.  Assumptions
  contents:
  - "3.1.  Assumptions\n   o  The FEs involved in the inter-FE LFB belong to the same\
    \ Network\n      Element (NE) and are within a single administrative private\n\
    \      network that is in close proximity.\n   o  The FEs are already interconnected\
    \ using Ethernet.  We focus on\n      Ethernet because it is commonly used for\
    \ FE interconnection.\n      Other higher transports (such as UDP over IP) or\
    \ lower transports\n      could be defined to carry the data and metadata, but\
    \ these cases\n      are not addressed in this document.\n"
- title: 3.2.  Sample Use Cases
  contents:
  - "3.2.  Sample Use Cases\n   To illustrate the problem scope, we present two use\
    \ cases where we\n   start with a single FE running all the LFBs functionality\
    \ and then\n   split it into multiple FEs achieving the same end goals.\n"
- title: 3.2.1.  Basic IPv4 Router
  contents:
  - "3.2.1.  Basic IPv4 Router\n   A sample LFB topology depicted in Figure 1 demonstrates\
    \ a service\n   graph for delivering a basic IPv4-forwarding service within one\
    \ FE.\n   For the purpose of illustration, the diagram shows LFB classes as\n\
    \   graph nodes instead of multiple LFB class instances.\n   Since the purpose\
    \ of the illustration in Figure 1 is to showcase how\n   data and metadata are\
    \ sent down or upstream on a graph of LFB\n   instances, it abstracts out any\
    \ ports in both directions and talks\n   about a generic ingress and egress LFB.\
    \  Again, for illustration\n   purposes, the diagram does not show exception or\
    \ error paths.  Also\n   left out are details on Reverse Path Filtering, ECMP,\
    \ multicast\n   handling, etc.  In other words, this is not meant to be a complete\n\
    \   description of an IPv4-forwarding application; for a more complete\n   example,\
    \ please refer to the LFBLibrary document [RFC6956].\n   The output of the ingress\
    \ LFB(s) coming into the IPv4 Validator LFB\n   will have both the IPv4 packets\
    \ and, depending on the implementation,\n   a variety of ingress metadata such\
    \ as offsets into the different\n   headers, any classification metadata, physical\
    \ and virtual ports\n   encountered, tunneling information, etc.  These metadata\
    \ are lumped\n   together as \"ingress metadata\".\n   Once the IPv4 validator\
    \ vets the packet (for example, it ensures that\n   there is no expired TTL),\
    \ it feeds the packet and inherited metadata\n   into the IPv4 unicast LPM (Longest-Prefix-Matching)\
    \ LFB.\n                      +----+\n                      |    |\n         \
    \  IPv4 pkt   |    | IPv4 pkt     +-----+             +---+\n       +------------->|\
    \    +------------->|     |             |   |\n       |  + ingress   |    | +\
    \ ingress    |IPv4 |   IPv4 pkt  |   |\n       |   metadata   |    | metadata\
    \     |Ucast+------------>|   +--+\n       |              +----+             \
    \ |LPM  |  + ingress  |   |  |\n     +-+-+             IPv4               +-----+\
    \  + NHinfo   +---+  |\n     |   |             Validator                   metadata\
    \   IPv4   |\n     |   |             LFB                                    NextHop|\n\
    \     |   |                                                     LFB   |\n    \
    \ |   |                                                           |\n     |  \
    \ |                                                  IPv4 pkt |\n     |   |  \
    \                                             + {ingress  |\n     +---+      \
    \                                            + NHdetails}\n     Ingress      \
    \                                          metadata |\n      LFB             \
    \                   +--------+                  |\n                          \
    \               | Egress |                  |\n                              \
    \        <--+        |<-----------------+\n                                  \
    \       |  LFB   |\n                                         +--------+\n    \
    \         Figure 1: Basic IPv4 Packet Service LFB Topology\n   The IPv4 unicast\
    \ LPM LFB does an LPM lookup on the IPv4 FIB using the\n   destination IP address\
    \ as a search key.  The result is typically a\n   next-hop selector, which is\
    \ passed downstream as metadata.\n   The NextHop LFB receives the IPv4 packet\
    \ with associated next-hop\n   (NH) information metadata.  The NextHop LFB consumes\
    \ the NH\n   information metadata and derives a table index from it to look up\
    \ the\n   next-hop table in order to find the appropriate egress information.\n\
    \   The lookup result is used to build the next-hop details to be used\n   downstream\
    \ on the egress.  This information may include any source\n   and destination\
    \ information (for our purposes, which Media Access\n   Control (MAC) addresses\
    \ to use) as well as egress ports.  (Note: It\n   is also at this LFB where typically,\
    \ the forwarding TTL-decrementing\n   and IP checksum recalculation occurs.)\n\
    \   The details of the egress LFB are considered out of scope for this\n   discussion.\
    \  Suffice it to say that somewhere within or beyond the\n   Egress LFB, the IPv4\
    \ packet will be sent out a port (e.g., Ethernet,\n   virtual or physical).\n"
- title: 3.2.1.1.  Distributing the Basic IPv4 Router
  contents:
  - "3.2.1.1.  Distributing the Basic IPv4 Router\n   Figure 2 demonstrates one way\
    \ that the router LFB topology in\n   Figure 1 may be split across two FEs (e.g.,\
    \ two Application-Specific\n   Integrated Circuits (ASICs)).  Figure 2 shows the\
    \ LFB topology split\n   across FEs after the IPv4 unicast LPM LFB.\n      FE1\n\
    \    +-------------------------------------------------------------+\n    |  \
    \                          +----+                           |\n    | +----------+\
    \               |    |                           |\n    | | Ingress  |    IPv4\
    \ pkt   |    | IPv4 pkt     +-----+      |\n    | |  LFB     +-------------->|\
    \    +------------->|     |      |\n    | |          |  + ingress    |    | +\
    \ ingress    |IPv4 |      |\n    | +----------+    metadata   |    |   metadata\
    \   |Ucast|      |\n    |      ^                     +----+              |LPM\
    \  |      |\n    |      |                      IPv4               +--+--+    \
    \  |\n    |      |                     Validator              |         |\n  \
    \  |                             LFB                   |         |\n    +---------------------------------------------------|---------+\n\
    \                                                        |\n                 \
    \                                  IPv4 packet +\n                           \
    \                      {ingress + NHinfo}\n                                  \
    \                   metadata\n      FE2                                      \
    \         |\n    +---------------------------------------------------|---------+\n\
    \    |                                                   V         |\n    |  \
    \           +--------+                       +--------+     |\n    |         \
    \    | Egress |     IPv4 packet       | IPv4   |     |\n    |       <-----+  LFB\
    \   |<----------------------+NextHop |     |\n    |             |        |{ingress\
    \ + NHdetails}  | LFB    |     |\n    |             +--------+      metadata \
    \        +--------+     |\n    +-------------------------------------------------------------+\n\
    \             Figure 2: Split IPv4 Packet Service LFB Topology\n   Some proprietary\
    \ interconnections (for example, Broadcom HiGig over\n   XAUI [brcm-higig]) are\
    \ known to exist to carry both the IPv4 packet\n   and the related metadata between\
    \ the IPv4 Unicast LFB and IPv4NextHop\n   LFB across the two FEs.\n   This document\
    \ defines the inter-FE LFB, a standard mechanism for\n   encapsulating, generating,\
    \ receiving, and decapsulating packets and\n   associated metadata FEs over Ethernet.\n"
- title: 3.2.2.  Arbitrary Network Function
  contents:
  - "3.2.2.  Arbitrary Network Function\n   In this section, we show an example of\
    \ an arbitrary Network Function\n   that is more coarsely grained in terms of\
    \ functionality.  Each\n   Network Function may constitute more than one LFB.\n\
    \      FE1\n    +-------------------------------------------------------------+\n\
    \    |                            +----+                           |\n    | +----------+\
    \               |    |                           |\n    | | Network  |   pkt \
    \        |NF2 |    pkt       +-----+      |\n    | | Function +-------------->|\
    \    +------------->|     |      |\n    | |    1     |  + NF1        |    | +\
    \ NF1/2      |NF3  |      |\n    | +----------+    metadata   |    |   metadata\
    \   |     |      |\n    |      ^                     +----+              |   \
    \  |      |\n    |      |                                         +--+--+    \
    \  |\n    |      |                                            |         |\n  \
    \  |                                                   |         |\n    +---------------------------------------------------|---------+\n\
    \                                                        V\n         Figure 3:\
    \ A Network Function Service Chain within One FE\n   The setup in Figure 3 is\
    \ typical of most packet processing boxes\n   where we have functions like deep\
    \ packet inspection (DPI), NAT,\n   Routing, etc., connected in such a topology\
    \ to deliver a packet\n   processing service to flows.\n"
- title: 3.2.2.1.  Distributing the Arbitrary Network Function
  contents:
  - "3.2.2.1.  Distributing the Arbitrary Network Function\n   The setup in Figure\
    \ 3 can be split across three FEs instead of as\n   demonstrated in Figure 4.\
    \  This could be motivated by scale-out\n   reasons or because different vendors\
    \ provide different functionality,\n   which is plugged-in to provide such functionality.\
    \  The end result is\n   having the same packet service delivered to the different\
    \ flows\n   passing through.\n      FE1                        FE2\n      +----------+\
    \               +----+               FE3\n      | Network  |   pkt         |NF2\
    \ |    pkt       +-----+\n      | Function +-------------->|    +------------->|\
    \     |\n      |    1     |  + NF1        |    | + NF1/2      |NF3  |\n      +----------+\
    \    metadata   |    |   metadata   |     |\n           ^                    \
    \ +----+              |     |\n           |                                  \
    \       +--+--+\n                                                        |\n \
    \                                                       V\n       Figure 4: A\
    \ Network Function Service Chain Distributed across\n                        \
    \       Multiple FEs\n"
- title: 4.  Inter-FE LFB Overview
  contents:
  - "4.  Inter-FE LFB Overview\n   We address the inter-FE connectivity requirements\
    \ by defining the\n   inter-FE LFB class.  Using a standard LFB class definition\
    \ implies no\n   change to the basic ForCES architecture in the form of the core\
    \ LFBs\n   (FE Protocol or Object LFBs).  This design choice was made after\n\
    \   considering an alternative approach that would have required changes\n   to\
    \ both the FE Object capabilities (SupportedLFBs) and the\n   LFBTopology component\
    \ to describe the inter-FE connectivity\n   capabilities as well as the runtime\
    \ topology of the LFB instances.\n"
- title: 4.1.  Inserting the Inter-FE LFB ne 15
  contents:
  - "4.1.  Inserting the Inter-FE LFB ne 15\n   The distributed LFB topology described\
    \ in Figure 2 is re-illustrated\n   in Figure 5 to show the topology location\
    \ where the inter-FE LFB\n   would fit in.\n   As can be observed in Figure 5,\
    \ the same details passed between IPv4\n   unicast LPM LFB and the IPv4 NH LFB\
    \ are passed to the egress side of\n   the inter-FE LFB.  This information is\
    \ illustrated as multiplicity of\n   inputs into the egress inter-FE LFB instance.\
    \  Each input represents\n   a unique set of selection information.\n      FE1\n\
    \    +-------------------------------------------------------------+\n    | +----------+\
    \               +----+                           |\n    | | Ingress  |    IPv4\
    \ pkt   |    | IPv4 pkt     +-----+      |\n    | |  LFB     +-------------->|\
    \    +------------->|     |      |\n    | |          |  + ingress    |    | +\
    \ ingress    |IPv4 |      |\n    | +----------+    metadata   |    |   metadata\
    \   |Ucast|      |\n    |      ^                     +----+              |LPM\
    \  |      |\n    |      |                      IPv4               +--+--+    \
    \  |\n    |      |                     Validator              |         |\n  \
    \  |      |                      LFB                   |         |\n    |    \
    \  |                                  IPv4 pkt + metadata |\n    |      |    \
    \                               {ingress + NHinfo} |\n    |      |           \
    \                                 |         |\n    |      |                  \
    \                     +..--+..+      |\n    |      |                         \
    \              |..| |  |      |\n    |                                       \
    \     +-V--V-V--V-+    |\n    |                                            | \
    \  Egress  |    |\n    |                                            |  Inter-FE\
    \ |    |\n    |                                            |   LFB     |    |\n\
    \    |                                            +------+----+    |\n    +---------------------------------------------------|---------+\n\
    \                                                        |\n                 \
    \               Ethernet Frame with:    |\n                                IPv4\
    \ packet data and metadata\n                                {ingress + NHinfo\
    \ + Inter-FE info}\n     FE2                                                |\n\
    \    +---------------------------------------------------|---------+\n    |  \
    \                                              +..+.+..+    |\n    |         \
    \                                       |..|.|..|    |\n    |                \
    \                              +-V--V-V--V-+  |\n    |                       \
    \                       | Ingress   |  |\n    |                              \
    \                | Inter-FE  |  |\n    |                                     \
    \         |   LFB     |  |\n    |                                            \
    \  +----+------+  |\n    |                                                   |\
    \         |\n    |                                         IPv4 pkt + metadata\
    \ |\n    |                                          {ingress + NHinfo} |\n   \
    \ |                                                   |         |\n    |     \
    \        +--------+                       +----V---+     |\n    |            \
    \ | Egress |     IPv4 packet       | IPv4   |     |\n    |       <-----+  LFB\
    \   |<----------------------+NextHop |     |\n    |             |        |{ingress\
    \ + NHdetails}  | LFB    |     |\n    |             +--------+      metadata \
    \        +--------+     |\n    +-------------------------------------------------------------+\n\
    \         Figure 5: Split IPv4-Forwarding Service with Inter-FE LFB\n   The egress\
    \ of the inter-FE LFB uses the received packet and metadata\n   to select details\
    \ for encapsulation when sending messages towards the\n   selected neighboring\
    \ FE.  These details include what to communicate\n   as the source and destination\
    \ FEs (abstracted as MAC addresses as\n   described in Section 5.2); in addition,\
    \ the original metadata may be\n   passed along with the original IPv4 packet.\n\
    \   On the ingress side of the inter-FE LFB, the received packet and its\n   associated\
    \ metadata are used to decide the packet graph continuation.\n   This includes\
    \ which of the original metadata and on which next LFB\n   class instance to continue\
    \ processing.  In Figure 5, an IPv4NextHop\n   LFB instance is selected and the\
    \ appropriate metadata is passed to\n   it.\n   The ingress side of the inter-FE\
    \ LFB consumes some of the information\n   passed and passes it the IPv4 packet\
    \ alongside with the ingress and\n   NHinfo metadata to the IPv4NextHop LFB as\
    \ was done earlier in both\n   Figures 1 and 2.\n"
- title: 5.  Inter-FE Ethernet Connectivity
  contents:
  - "5.  Inter-FE Ethernet Connectivity\n   Section 5.1 describes some of the issues\
    \ related to using Ethernet as\n   the transport and how we mitigate them.\n \
    \  Section 5.2 defines a payload format that is to be used over\n   Ethernet.\
    \  An existing implementation of this specification that runs\n   on top of Linux\
    \ Traffic Control [linux-tc] is described in [tc-ife].\n"
- title: 5.1.  Inter-FE Ethernet Connectivity Issues
  contents:
  - "5.1.  Inter-FE Ethernet Connectivity Issues\n   There are several issues that\
    \ may occur due to using direct Ethernet\n   encapsulation that need consideration.\n"
- title: 5.1.1.  MTU Consideration
  contents:
  - "5.1.1.  MTU Consideration\n   Because we are adding data to existing Ethernet\
    \ frames, MTU issues\n   may arise.  We recommend:\n   o  Using large MTUs when\
    \ possible (example with jumbo frames).\n   o  Limiting the amount of metadata\
    \ that could be transmitted; our\n      definition allows for filtering of select\
    \ metadata to be\n      encapsulated in the frame as described in Section 6. \
    \ We recommend\n      sizing the egress port MTU so as to allow space for maximum\
    \ size\n      of the metadata total size to allow between FEs.  In such a setup,\n\
    \      the port is configured to \"lie\" to the upper layers by claiming to\n\
    \      have a lower MTU than it is capable of.  Setting the MTU can be\n     \
    \ achieved by ForCES control of the port LFB (or some other\n      configuration.\
    \  In essence, the control plane when explicitly\n      making a decision for\
    \ the MTU settings of the egress port is\n      implicitly deciding how much metadata\
    \ will be allowed.  Caution\n      needs to be exercised on how low the resulting\
    \ reported link MTU\n      could be: for IPv4 packets, the minimum size is 64\
    \ octets [RFC791]\n      and for IPv6 the minimum size is 1280 octets [RFC2460].\n"
- title: 5.1.2.  Quality-of-Service Considerations
  contents:
  - "5.1.2.  Quality-of-Service Considerations\n   A raw packet arriving at the inter-FE\
    \ LFB (from upstream LFB class\n   instances) may have Class-of-Service (CoS)\
    \ metadata indicating how it\n   should be treated from a Quality-of-Service perspective.\n\
    \   The resulting Ethernet frame will be eventually (preferentially)\n   treated\
    \ by a downstream LFB (typically a port LFB instance) and their\n   CoS marks\
    \ will be honored in terms of priority.  In other words, the\n   presence of the\
    \ inter-FE LFB does not change the CoS semantics.\n"
- title: 5.1.3.  Congestion Considerations
  contents:
  - "5.1.3.  Congestion Considerations\n   Most of the traffic passing through FEs\
    \ that utilize the inter-FE LFB\n   is expected to be IP based, which is generally\
    \ assumed to be\n   congestion controlled [UDP-GUIDE].  For example, if congestion\
    \ causes\n   a TCP packet annotated with additional ForCES metadata to be dropped\n\
    \   between FEs, the sending TCP can be expected to react in the same\n   fashion\
    \ as if that packet had been dropped at a different point on\n   its path where\
    \ ForCES is not involved.  For this reason, additional\n   inter-FE congestion-control\
    \ mechanisms are not specified.\n   However, the increased packet size due to\
    \ the addition of ForCES\n   metadata is likely to require additional bandwidth\
    \ on inter-FE links\n   in comparison to what would be required to carry the same\
    \ traffic\n   without ForCES metadata.  Therefore, traffic engineering SHOULD\
    \ be\n   done when deploying inter-FE encapsulation.\n   Furthermore, the inter-FE\
    \ LFB MUST only be deployed within a single\n   network (with a single network\
    \ operator) or networks of an adjacent\n   set of cooperating network operators\
    \ where traffic is managed to\n   avoid congestion.  These are Controlled Environments,\
    \ as defined by\n   Section 3.6 of [UDP-GUIDE].  Additional measures SHOULD be\
    \ imposed to\n   restrict the impact of inter-FE-encapsulated traffic on other\n\
    \   traffic; for example:\n   o  rate-limiting all inter-FE LFB traffic at an\
    \ upstream LFB\n   o  managing circuit breaking [circuit-b]\n   o  Isolating the\
    \ inter-FE traffic either via dedicated interfaces or\n      VLANs\n"
- title: 5.2.  Inter-FE Ethernet Encapsulation
  contents:
  - "5.2.  Inter-FE Ethernet Encapsulation\n   The Ethernet wire encapsulation is\
    \ illustrated in Figure 6.  The\n   process that leads to this encapsulation is\
    \ described in Section 6.\n   The resulting frame is 32-bit aligned.\n       0\
    \                   1                   2                   3\n       0 1 2 3\
    \ 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      | Destination MAC Address                                       |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |\
    \ Destination MAC Address       |   Source MAC Address          |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      | Source MAC Address                                            |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |\
    \ Inter-FE ethertype            | Metadata length               |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      | TLV encoded Metadata ~~~..............~~                      |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |\
    \ TLV encoded Metadata ~~~..............~~                      |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      | Original packet data ~~................~~                     |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      \
    \              Figure 6: Packet Format Definition\n   The Ethernet header (illustrated\
    \ in Figure 6) has the following\n   semantics:\n   o  The Destination MAC Address\
    \ is used to identify the Destination\n      FEID by the CE policy (as described\
    \ in Section 6).\n   o  The Source MAC Address is used to identify the Source\
    \ FEID by the\n      CE policy (as described in Section 6).\n   o  The ethertype\
    \ is used to identify the frame as inter-FE LFB type.\n      Ethertype ED3E (base\
    \ 16) is to be used.\n   o  The 16-bit metadata length is used to describe the\
    \ total encoded\n      metadata length (including the 16 bits used to encode the\
    \ metadata\n      length).\n   o  One or more 16-bit TLV-encoded metadatum follows\
    \ the Metadata\n      length field.  The TLV type identifies the metadata ID.\
    \  ForCES\n      metadata IDs that have been registered with IANA will be used.\n\
    \      All TLVs will be 32-bit-aligned.  We recognize that using a 16-bit\n  \
    \    TLV restricts the metadata ID to 16 bits instead of a ForCES-\n      defined\
    \ component ID space of 32 bits if an Index-Length-Value\n      (ILV) is used.\
    \  However, at the time of publication, we believe\n      this is sufficient to\
    \ carry all the information we need; the TLV\n      approach has been selected\
    \ because it saves us 4 bytes per\n      metadatum transferred as compared to\
    \ the ILV approach.\n   o  The original packet data payload is appended at the\
    \ end of the\n      metadata as shown.\n"
- title: 6.  Detailed Description of the Ethernet Inter-FE LFB
  contents:
  - "6.  Detailed Description of the Ethernet Inter-FE LFB\n   The Ethernet inter-FE\
    \ LFB has two LFB input port groups and three LFB\n   output ports as shown in\
    \ Figure 7.\n   The inter-FE LFB defines two components used in aiding processing\n\
    \   described in Section 6.1.\n                    +-----------------+\n     Inter-FE\
    \ LFB   |                 |\n     Encapsulated   |             OUT2+--> Decapsulated\
    \ Packet\n     -------------->|IngressInGroup   |       + metadata\n     Ethernet\
    \ Frame |                 |\n                    |                 |\n     raw\
    \ Packet +   |             OUT1+--> Encapsulated Ethernet\n     -------------->|EgressInGroup\
    \    |           Frame\n     Metadata       |                 |\n            \
    \        |    EXCEPTIONOUT +--> ExceptionID, packet\n                    |   \
    \              |           + metadata\n                    +-----------------+\n\
    \                          Figure 7: Inter-FE LFB\n"
- title: 6.1.  Data Handling
  contents:
  - "6.1.  Data Handling\n   The inter-FE LFB (instance) can be positioned at the\
    \ egress of a\n   source FE.  Figure 5 illustrates an example source FE in the\
    \ form of\n   FE1.  In such a case, an inter-FE LFB instance receives, via port\n\
    \   group EgressInGroup, a raw packet and associated metadata from the\n   preceding\
    \ LFB instances.  The input information is used to produce a\n   selection of\
    \ how to generate and encapsulate the new frame.  The set\n   of all selections\
    \ is stored in the LFB component IFETable described\n   further below.  The processed\
    \ encapsulated Ethernet frame will go out\n   on OUT1 to a downstream LFB instance\
    \ when processing succeeds or to\n   the EXCEPTIONOUT port in the case of failure.\n\
    \   The inter-FE LFB (instance) can be positioned at the ingress of a\n   receiving\
    \ FE.  Figure 5 illustrates an example destination FE in the\n   form of FE1.\
    \  In such a case, an inter-FE LFB receives, via an LFB\n   port in the IngressInGroup,\
    \ an encapsulated Ethernet frame.\n   Successful processing of the packet will\
    \ result in a raw packet with\n   associated metadata IDs going downstream to\
    \ an LFB connected on OUT2.\n   On failure, the data is sent out EXCEPTIONOUT.\n"
- title: 6.1.1.  Egress Processing
  contents:
  - "6.1.1.  Egress Processing\n   The egress inter-FE LFB receives packet data and\
    \ any accompanying\n   metadatum at an LFB port of the LFB instance's input port\
    \ group\n   labeled EgressInGroup.\n   The LFB implementation may use the incoming\
    \ LFB port (within the LFB\n   port group EgressInGroup) to map to a table index\
    \ used to look up the\n   IFETable table.\n   If the lookup is successful, a matched\
    \ table row that has the IFEInfo\n   details is retrieved with the tuple (optional\
    \ IFETYPE, optional\n   StatId, Destination MAC address (DSTFE), Source MAC address\
    \ (SRCFE),\n   and optional metafilters).  The metafilters lists define a whitelist\n\
    \   of which metadatum are to be passed to the neighboring FE.  The\n   inter-FE\
    \ LFB will perform the following actions using the resulting\n   tuple:\n   o\
    \  Increment statistics for packet and byte count observed at the\n      corresponding\
    \ IFEStats entry.\n   o  When the MetaFilterList is present, walk each received\
    \ metadatum\n      and apply it against the MetaFilterList.  If no legitimate\n\
    \      metadata is found that needs to be passed downstream, then the\n      processing\
    \ stops and the packet and metadata are sent out the\n      EXCEPTIONOUT port\
    \ with the exceptionID of EncapTableLookupFailed\n      [RFC6956].\n   o  Check\
    \ that the additional overhead of the Ethernet header and\n      encapsulated\
    \ metadata will not exceed MTU.  If it does, increment\n      the error-packet-count\
    \ statistics and send the packet and metadata\n      out the EXCEPTIONOUT port\
    \ with the exceptionID of FragRequired\n      [RFC6956].\n   o  Create the Ethernet\
    \ header.\n   o  Set the Destination MAC address of the Ethernet header with the\n\
    \      value found in the DSTFE field.\n   o  Set the Source MAC address of the\
    \ Ethernet header with the value\n      found in the SRCFE field.\n   o  If the\
    \ optional IFETYPE is present, set the ethertype to the value\n      found in\
    \ IFETYPE.  If IFETYPE is absent, then the standard inter-\n      FE LFB ethertype\
    \ ED3E (base 16) is used.\n   o  Encapsulate each allowed metadatum in a TLV.\
    \  Use the metaID as\n      the \"type\" field in the TLV header.  The TLV should\
    \ be aligned to\n      32 bits.  This means you may need to add a padding of zeroes\
    \ at\n      the end of the TLV to ensure alignment.\n   o  Update the metadata\
    \ length to the sum of each TLV's space plus 2\n      bytes (a 16-bit space for\
    \ the Metadata length field).\n   The resulting packet is sent to the next LFB\
    \ instance connected to\n   the OUT1 LFB-port, typically a port LFB.\n   In the\
    \ case of a failed lookup, the original packet and associated\n   metadata is\
    \ sent out the EXCEPTIONOUT port with the exceptionID of\n   EncapTableLookupFailed\
    \ [RFC6956].  Note that the EXCEPTIONOUT LFB\n   port is merely an abstraction\
    \ and implementation may in fact drop\n   packets as described above.\n"
- title: 6.1.2.  Ingress Processing
  contents:
  - "6.1.2.  Ingress Processing\n   An ingressing inter-FE LFB packet is recognized\
    \ by inspecting the\n   ethertype, and optionally the destination and source MAC\
    \ addresses.\n   A matching packet is mapped to an LFB instance port in the\n\
    \   IngressInGroup.  The IFETable table row entry matching the LFB\n   instance\
    \ port may have optionally programmed metadata filters.  In\n   such a case, the\
    \ ingress processing should use the metadata filters\n   as a whitelist of what\
    \ metadatum is to be allowed.\n   o  Increment statistics for packet and byte\
    \ count observed.\n   o  Look at the metadata length field and walk the packet\
    \ data,\n      extracting the metadata values from the TLVs.  For each metadatum\n\
    \      extracted, in the presence of metadata filters, the metaID is\n      compared\
    \ against the relevant IFETable row metafilter list.  If\n      the metadatum\
    \ is recognized and allowed by the filter, the\n      corresponding implementation\
    \ Metadatum field is set.  If an\n      unknown metadatum ID is encountered or\
    \ if the metaID is not in the\n      allowed filter list, then the implementation\
    \ is expected to ignore\n      it, increment the packet error statistic, and proceed\
    \ processing\n      other metadatum.\n   o  Upon completion of processing all\
    \ the metadata, the inter-FE LFB\n      instance resets the data point to the\
    \ original payload (i.e.,\n      skips the IFE header information).  At this point,\
    \ the original\n      packet that was passed to the egress inter-FE LFB at the\
    \ source FE\n      is reconstructed.  This data is then passed along with the\n\
    \      reconstructed metadata downstream to the next LFB instance in the\n   \
    \   graph.\n   In the case of a processing failure of either ingress or egress\n\
    \   positioning of the LFB, the packet and metadata are sent out the\n   EXCEPTIONOUT\
    \ LFB port with the appropriate error ID.  Note that the\n   EXCEPTIONOUT LFB\
    \ port is merely an abstraction and implementation may\n   in fact drop packets\
    \ as described above.\n"
- title: 6.2.  Components
  contents:
  - "6.2.  Components\n   There are two LFB components accessed by the CE.  The reader\
    \ is asked\n   to refer to the definitions in Figure 8.\n   The first component,\
    \ populated by the CE, is an array known as the\n   \"IFETable\" table.  The array\
    \ rows are made up of IFEInfo structure.\n   The IFEInfo structure constitutes\
    \ the optional IFETYPE, the\n   optionally present StatId, the Destination MAC\
    \ address (DSTFE), the\n   Source MAC address (SRCFE), and an optionally present\
    \ array of\n   allowed metaIDs (MetaFilterList).\n   The second component (ID\
    \ 2), populated by the FE and read by the CE,\n   is an indexed array known as\
    \ the \"IFEStats\" table.  Each IFEStats row\n   carries statistics information\
    \ in the structure bstats.\n   A note about the StatId relationship between the\
    \ IFETable table and\n   the IFEStats table -- an implementation may choose to\
    \ map between an\n   IFETable row and IFEStats table row using the StatId entry\
    \ in the\n   matching IFETable row.  In that case, the IFETable StatId must be\n\
    \   present.  An alternative implementation may map an IFETable row to an\n  \
    \ IFEStats table row at provisioning time.  Yet another alternative\n   implementation\
    \ may choose not to use the IFETable row StatId and\n   instead use the IFETable\
    \ row index as the IFEStats index.  For these\n   reasons, the StatId component\
    \ is optional.\n"
- title: 6.3.  Inter-FE LFB XML Model
  contents:
  - "6.3.  Inter-FE LFB XML Model\n  <LFBLibrary xmlns=\"urn:ietf:params:xml:ns:forces:lfbmodel:1.1\"\
    \n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         provides=\"\
    IFE\">\n    <frameDefs>\n       <frameDef>\n           <name>PacketAny</name>\n\
    \            <synopsis>Arbitrary Packet</synopsis>\n       </frameDef>\n     \
    \  <frameDef>\n           <name>InterFEFrame</name>\n           <synopsis>\n \
    \                  Ethernet frame with encapsulated IFE information\n        \
    \   </synopsis>\n       </frameDef>\n    </frameDefs>\n    <dataTypeDefs>\n  \
    \    <dataTypeDef>\n         <name>bstats</name>\n         <synopsis>Basic stats</synopsis>\n\
    \      <struct>\n          <component componentID=\"1\">\n           <name>bytes</name>\n\
    \           <synopsis>The total number of bytes seen</synopsis>\n           <typeRef>uint64</typeRef>\n\
    \          </component>\n          <component componentID=\"2\">\n           <name>packets</name>\n\
    \           <synopsis>The total number of packets seen</synopsis>\n          \
    \ <typeRef>uint32</typeRef>\n          </component>\n          <component componentID=\"\
    3\">\n           <name>errors</name>\n           <synopsis>The total number of\
    \ packets with errors</synopsis>\n           <typeRef>uint32</typeRef>\n     \
    \     </component>\n      </struct>\n     </dataTypeDef>\n       <dataTypeDef>\n\
    \          <name>IFEInfo</name>\n          <synopsis>Describing IFE table row\
    \ Information</synopsis>\n          <struct>\n             <component componentID=\"\
    1\">\n               <name>IFETYPE</name>\n               <synopsis>\n       \
    \            The ethertype to be used for outgoing IFE frame\n               </synopsis>\n\
    \               <optional/>\n               <typeRef>uint16</typeRef>\n      \
    \       </component>\n             <component componentID=\"2\">\n           \
    \    <name>StatId</name>\n               <synopsis>\n                   The Index\
    \ into the stats table\n               </synopsis>\n               <optional/>\n\
    \               <typeRef>uint32</typeRef>\n             </component>\n       \
    \      <component componentID=\"3\">\n               <name>DSTFE</name>\n    \
    \           <synopsis>\n                       The destination MAC address of\
    \ the destination FE\n               </synopsis>\n               <typeRef>byte[6]</typeRef>\n\
    \             </component>\n             <component componentID=\"4\">\n     \
    \          <name>SRCFE</name>\n               <synopsis>\n                   \
    \    The source MAC address used for the source FE\n               </synopsis>\n\
    \               <typeRef>byte[6]</typeRef>\n             </component>\n      \
    \       <component componentID=\"5\">\n               <name>MetaFilterList</name>\n\
    \               <synopsis>\n                       The allowed metadata filter\
    \ table\n               </synopsis>\n               <optional/>\n            \
    \   <array type=\"variable-size\">\n                 <typeRef>uint32</typeRef>\n\
    \               </array>\n              </component>\n          </struct>\n  \
    \     </dataTypeDef>\n    </dataTypeDefs>\n    <LFBClassDefs>\n      <LFBClassDef\
    \ LFBClassID=\"18\">\n        <name>IFE</name>\n        <synopsis>\n         \
    \  This LFB describes IFE connectivity parameterization\n        </synopsis>\n\
    \        <version>1.0</version>\n          <inputPorts>\n            <inputPort\
    \ group=\"true\">\n             <name>EgressInGroup</name>\n             <synopsis>\n\
    \                     The input port group of the egress side.\n             \
    \        It expects any type of Ethernet frame.\n             </synopsis>\n  \
    \           <expectation>\n                  <frameExpected>\n               \
    \   <ref>PacketAny</ref>\n                  </frameExpected>\n             </expectation>\n\
    \            </inputPort>\n            <inputPort  group=\"true\">\n         \
    \    <name>IngressInGroup</name>\n             <synopsis>\n                  \
    \   The input port group of the ingress side.\n                     It expects\
    \ an interFE-encapsulated Ethernet frame.\n              </synopsis>\n       \
    \      <expectation>\n                  <frameExpected>\n                  <ref>InterFEFrame</ref>\n\
    \                  </frameExpected>\n             </expectation>\n          </inputPort>\n\
    \         </inputPorts>\n         <outputPorts>\n           <outputPort>\n   \
    \          <name>OUT1</name>\n             <synopsis>\n                  The output\
    \ port of the egress side\n             </synopsis>\n             <product>\n\
    \                <frameProduced>\n                  <ref>InterFEFrame</ref>\n\
    \                </frameProduced>\n             </product>\n          </outputPort>\n\
    \          <outputPort>\n            <name>OUT2</name>\n            <synopsis>\n\
    \                The output port of the Ingress side\n            </synopsis>\n\
    \            <product>\n               <frameProduced>\n                 <ref>PacketAny</ref>\n\
    \               </frameProduced>\n            </product>\n         </outputPort>\n\
    \         <outputPort>\n           <name>EXCEPTIONOUT</name>\n           <synopsis>\n\
    \              The exception handling path\n           </synopsis>\n         \
    \  <product>\n              <frameProduced>\n                <ref>PacketAny</ref>\n\
    \              </frameProduced>\n              <metadataProduced>\n          \
    \      <ref>ExceptionID</ref>\n              </metadataProduced>\n           </product>\n\
    \        </outputPort>\n     </outputPorts>\n     <components>\n        <component\
    \ componentID=\"1\" access=\"read-write\">\n           <name>IFETable</name>\n\
    \           <synopsis>\n              The table of all inter-FE relations\n  \
    \         </synopsis>\n           <array type=\"variable-size\">\n           \
    \   <typeRef>IFEInfo</typeRef>\n           </array>\n        </component>\n  \
    \     <component componentID=\"2\" access=\"read-only\">\n         <name>IFEStats</name>\n\
    \         <synopsis>\n          The stats corresponding to the IFETable table\n\
    \         </synopsis>\n         <typeRef>bstats</typeRef>\n       </component>\n\
    \    </components>\n   </LFBClassDef>\n  </LFBClassDefs>\n  </LFBLibrary>\n  \
    \                      Figure 8: Inter-FE LFB XML\n"
- title: 7.  IANA Considerations
  contents:
  - "7.  IANA Considerations\n   IANA has registered the following LFB class name\
    \ in the \"Logical\n   Functional Block (LFB) Class Names and Class Identifiers\"\
    \ subregistry\n   of the \"Forwarding and Control Element Separation (ForCES)\"\
    \ registry\n   <https://www.iana.org/assignments/forces>.\n   +------------+--------+---------+-----------------------+-----------+\n\
    \   | LFB Class  |  LFB   |   LFB   |      Description      | Reference |\n  \
    \ | Identifier | Class  | Version |                       |           |\n   |\
    \            |  Name  |         |                       |           |\n   +------------+--------+---------+-----------------------+-----------+\n\
    \   |     18     |  IFE   |   1.0   |     An IFE LFB to     |    This   |\n  \
    \ |            |        |         |  standardize inter-FE |  document |\n   |\
    \            |        |         |     LFB for ForCES    |           |\n   |  \
    \          |        |         |    Network Elements   |           |\n   +------------+--------+---------+-----------------------+-----------+\n\
    \     Logical Functional Block (LFB) Class Names and Class Identifiers\n"
- title: 8.  IEEE Assignment Considerations
  contents:
  - "8.  IEEE Assignment Considerations\n   This memo includes a request for a new\
    \ Ethernet protocol type as\n   described in Section 5.2.\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   The FEs involved in the inter-FE LFB belong to\
    \ the same NE and are\n   within the scope of a single administrative Ethernet\
    \ LAN private\n   network.  While trust of policy in the control and its treatment\
    \ in\n   the datapath exists already, an inter-FE LFB implementation SHOULD\n\
    \   support security services provided by Media Access Control Security\n   (MACsec)\
    \ [ieee8021ae].  MACsec is not currently sufficiently widely\n   deployed in traditional\
    \ packet processing hardware although it is\n   present in newer versions of the\
    \ Linux kernel (which will be widely\n   deployed) [linux-macsec].  Over time,\
    \ we expect that most FEs will be\n   able to support MACsec.\n   MACsec provides\
    \ security services such as a message authentication\n   service and an optional\
    \ confidentiality service.  The services can be\n   configured manually or automatically\
    \ using the MACsec Key Agreement\n   (MKA) over the IEEE 802.1x [ieee8021x] Extensible\
    \ Authentication\n   Protocol (EAP) framework.  It is expected that FE implementations\
    \ are\n   going to start with shared keys configured from the control plane but\n\
    \   progress to automated key management.\n   The following are the MACsec security\
    \ mechanisms that need to be in\n   place for the inter-FE LFB:\n   o  Security\
    \ mechanisms are NE-wide for all FEs.  Once the security is\n      turned on,\
    \ depending upon the chosen security level (e.g.,\n      Authentication, Confidentiality),\
    \ it will be in effect for the\n      inter-FE LFB for the entire duration of\
    \ the session.\n   o  An operator SHOULD configure the same security policies\
    \ for all\n      participating FEs in the NE cluster.  This will ensure uniform\n\
    \      operations and avoid unnecessary complexity in policy\n      configuration.\
    \  In other words, the Security Association Keys\n      (SAKs) should be pre-shared.\
    \  When using MKA, FEs must identify\n      themselves with a shared Connectivity\
    \ Association Key (CAK) and\n      Connectivity Association Key Name (CKN).  EAP-TLS\
    \ SHOULD be used\n      as the EAP method.\n   o  An operator SHOULD configure\
    \ the strict validation mode, i.e., all\n      non-protected, invalid, or non-verifiable\
    \ frames MUST be dropped.\n   It should be noted that given the above choices,\
    \ if an FE is\n   compromised, an entity running on the FE would be able to fake\
    \ inter-\n   FE or modify its content, causing bad outcomes.\n"
- title: 10.  References
  contents:
  - '10.  References

    '
- title: 10.1.  Normative References
  contents:
  - "10.1.  Normative References\n   [ieee8021ae]\n              IEEE, \"IEEE Standard\
    \ for Local and metropolitan area\n              networks Media Access Control\
    \ (MAC) Security\", IEEE\n              802.1AE-2006, DOI 10.1109/IEEESTD.2006.245590,\n\
    \              <http://ieeexplore.ieee.org/document/1678345/>.\n   [ieee8021x]\n\
    \              IEEE, \"IEEE Standard for Local and metropolitan area\n       \
    \       networks - Port-Based Network Access Control.\", IEEE\n              802.1X-2010,\
    \ DOI 10.1109/IEEESTD.2010.5409813,\n              <http://ieeexplore.ieee.org/document/5409813/>.\n\
    \   [RFC2119]  Bradner, S., \"Key words for use in RFCs to Indicate\n        \
    \      Requirement Levels\", BCP 14, RFC 2119,\n              DOI 10.17487/RFC2119,\
    \ March 1997,\n              <http://www.rfc-editor.org/info/rfc2119>.\n   [RFC5810]\
    \  Doria, A., Ed., Hadi Salim, J., Ed., Haas, R., Ed.,\n              Khosravi,\
    \ H., Ed., Wang, W., Ed., Dong, L., Gopal, R., and\n              J. Halpern,\
    \ \"Forwarding and Control Element Separation\n              (ForCES) Protocol\
    \ Specification\", RFC 5810,\n              DOI 10.17487/RFC5810, March 2010,\n\
    \              <http://www.rfc-editor.org/info/rfc5810>.\n   [RFC5811]  Hadi Salim,\
    \ J. and K. Ogawa, \"SCTP-Based Transport Mapping\n              Layer (TML) for\
    \ the Forwarding and Control Element\n              Separation (ForCES) Protocol\"\
    , RFC 5811,\n              DOI 10.17487/RFC5811, March 2010,\n              <http://www.rfc-editor.org/info/rfc5811>.\n\
    \   [RFC5812]  Halpern, J. and J. Hadi Salim, \"Forwarding and Control\n     \
    \         Element Separation (ForCES) Forwarding Element Model\",\n          \
    \    RFC 5812, DOI 10.17487/RFC5812, March 2010,\n              <http://www.rfc-editor.org/info/rfc5812>.\n\
    \   [RFC7391]  Hadi Salim, J., \"Forwarding and Control Element Separation\n \
    \             (ForCES) Protocol Extensions\", RFC 7391,\n              DOI 10.17487/RFC7391,\
    \ October 2014,\n              <http://www.rfc-editor.org/info/rfc7391>.\n   [RFC7408]\
    \  Haleplidis, E., \"Forwarding and Control Element Separation\n             \
    \ (ForCES) Model Extension\", RFC 7408, DOI 10.17487/RFC7408,\n              November\
    \ 2014, <http://www.rfc-editor.org/info/rfc7408>.\n"
- title: 10.2.  Informative References
  contents:
  - "10.2.  Informative References\n   [brcm-higig]\n              Broadcom, \"HiGig\"\
    , <http://www.broadcom.com/products/\n              ethernet-communication-and-switching/switching/bcm56720>.\n\
    \   [circuit-b]\n              Fairhurst, G., \"Network Transport Circuit Breakers\"\
    , Work\n              in Progress, draft-ietf-tsvwg-circuit-breaker-15, April\n\
    \              2016.\n   [linux-macsec]\n              Dubroca, S., \"MACsec:\
    \ Encryption for the wired LAN\",\n              Netdev 11, Feb 2016.\n   [linux-tc]\
    \ Hadi Salim, J., \"Linux Traffic Control Classifier-Action\n              Subsystem\
    \ Architecture\", Netdev 01, Feb 2015.\n   [RFC791]   Postel, J., \"Internet Protocol\"\
    , STD 5, RFC 791,\n              DOI 10.17487/RFC0791, September 1981,\n     \
    \         <http://www.rfc-editor.org/info/rfc791>.\n   [RFC2460]  Deering, S.\
    \ and R. Hinden, \"Internet Protocol, Version 6\n              (IPv6) Specification\"\
    , RFC 2460, DOI 10.17487/RFC2460,\n              December 1998, <http://www.rfc-editor.org/info/rfc2460>.\n\
    \   [RFC3746]  Yang, L., Dantu, R., Anderson, T., and R. Gopal,\n            \
    \  \"Forwarding and Control Element Separation (ForCES)\n              Framework\"\
    , RFC 3746, DOI 10.17487/RFC3746, April 2004,\n              <http://www.rfc-editor.org/info/rfc3746>.\n\
    \   [RFC6956]  Wang, W., Haleplidis, E., Ogawa, K., Li, C., and J.\n         \
    \     Halpern, \"Forwarding and Control Element Separation\n              (ForCES)\
    \ Logical Function Block (LFB) Library\", RFC 6956,\n              DOI 10.17487/RFC6956,\
    \ June 2013,\n              <http://www.rfc-editor.org/info/rfc6956>.\n   [tc-ife]\
    \   Hadi Salim, J. and D. Joachimpillai, \"Distributing Linux\n              Traffic\
    \ Control Classifier-Action Subsystem\", Netdev 01,\n              Feb 2015.\n\
    \   [UDP-GUIDE]\n              Eggert, L., Fairhurst, G., and G. Shepherd, \"\
    UDP Usage\n              Guidelines\", Work in Progress, draft-ietf-tsvwg-\n \
    \             rfc5405bis-19, October 2016.\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   The authors would like to thank Joel Halpern and Dave Hood\
    \ for the\n   stimulating discussions.  Evangelos Haleplidis shepherded and\n\
    \   contributed to improving this document.  Alia Atlas was the AD\n   sponsor\
    \ of this document and did a tremendous job of critiquing it.\n   The authors\
    \ are grateful to Joel Halpern and Sue Hares in their roles\n   as the Routing\
    \ Area reviewers for shaping the content of this\n   document.  David Black put\
    \ in a lot of effort to make sure the\n   congestion-control considerations are\
    \ sane.  Russ Housley did the\n   Gen-ART review, Joe Touch did the TSV area review,\
    \ and Shucheng LIU\n   (Will) did the OPS review.  Suresh Krishnan helped us provide\
    \ clarity\n   during the IESG review.  The authors are appreciative of the efforts\n\
    \   Stephen Farrell put in to fixing the security section.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Damascane M. Joachimpillai\n   Verizon\n   60 Sylvan Rd\n\
    \   Waltham, MA  02451\n   United States of America\n   Email: damascene.joachimpillai@verizon.com\n\
    \   Jamal Hadi Salim\n   Mojatatu Networks\n   Suite 200, 15 Fitzgerald Rd.\n\
    \   Ottawa, Ontario  K2H 9G1\n   Canada\n   Email: hadi@mojatatu.com\n"
