- title: __initial_text__
  contents:
  - '             Source Directed Access Control on the Internet

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  This memo\n   does not specify an Internet standard of any kind.  Distribution\
    \ of\n   this memo is unlimited.\n"
- title: 1.  Abstract
  contents:
  - "1.  Abstract\n   This memo was developed from a deposition that I submitted as\
    \ part of\n   a challenge to the Communications Decency Act of 1996, part of the\n\
    \   Telecommunications Reform Act of 1996.  The Telecommunications Reform\n  \
    \ Act is a U.S. federal law substantially changing the regulatory\n   structure\
    \ in the United States in the telecommunications arena.  The\n   Communications\
    \ Decency Act (CDA) part of this law has as its aim the\n   desire to protect\
    \ minors from some of the material carried over\n   telecommunications networks.\
    \  In particular the law requires that the\n   sender of potentially offensive\
    \ material take \"effective action\" to\n   ensure that it is not presented to\
    \ minors.  A number of people have\n   requested that I publish the deposition\
    \ as an informational RFC since\n   some of the information in it may be useful\
    \ where descriptions of the\n   way the Internet and its applications work could\
    \ help clear up\n   confusion in the technical feasibility of proposed content\
    \ control\n   regulations.\n"
- title: 2.  Control and oversight over the Internet
  contents:
  - "2.  Control and oversight over the Internet\n   No organization or entity operates\
    \ or controls the Internet.  The\n   Internet consists of tens of thousands of\
    \ local networks linking\n   millions of computers, owned by governments, public\
    \ institutions,\n   non-profit organizations, and private companies around the\
    \ world.\n   These local networks are linked together by thousands of Internet\n\
    \   service providers which interconnect at dozens of points throughout\n   the\
    \ world.  None of these entities, however, controls the Internet;\n   each entity\
    \ only controls its own computers and computer networks,\n   and the links allowed\
    \ into those computers and computer networks.\n   Although no organizations control\
    \ the Internet, a limited number of\n   organizations are responsible for the\
    \ development of communications\n   and operational standards and protocols used\
    \ on the Internet.  These\n   standards and protocols are what allow the millions\
    \ of different (and\n   sometimes incompatible) computers worldwide to communicate\
    \ with each\n   other.  These standards and protocols are not imposed on any computer\n\
    \   or computer network, but any computer or computer network must follow\n  \
    \ at least some of the standards and protocols to be able to\n   communicate with\
    \ other computers over the Internet.\n   The most significant of the organizations\
    \ involved in defining these\n   standards include the Internet Society (ISOC),\
    \ the Internet\n   Architecture Board (IAB), Internet Engineering Steering Group\
    \ (IESG),\n   and the Internet Engineering Task Force (IETF).   The following\n\
    \   summary outlines the relationship of these four organizations:\n   The Internet\
    \ Society (ISOC) is a professional society that is\n   concerned with the growth\
    \ and evolution of the worldwide Internet,\n   with the way in which the Internet\
    \ is and can be used, and with the\n   social, political, and technical issues\
    \ which arise as a result.  The\n   ISOC Trustees are responsible for approving\
    \ appointments to the IAB\n   from among the nominees submitted by the IETF nominating\
    \ committee\n   and ratifying the IETF Standards Process.\n   The Internet Architecture\
    \ Board (IAB) is a technical advisory group\n   of the ISOC.  It is chartered\
    \ to provide oversight of the\n   architecture of the Internet and its protocols,\
    \ and to serve, in the\n   context of the Internet standards process, as a body\
    \ to which the\n   decisions of the IESG may be appealed.  The IAB is responsible\
    \ for\n   approving appointments to the IESG from among the nominees submitted\n\
    \   by the IETF nominations committee and advising the IESG on the\n   approval\
    \ of Working Group charters.\n   The Internet Engineering Steering Group (IESG)\
    \ is responsible for\n   technical management of IETF activities and the Internet\
    \ standards\n   process.  As a part of the ISOC, it administers the process according\n\
    \   to the rules and procedures which have been ratified by the ISOC\n   Trustees.\
    \  The IESG is directly responsible for the actions\n   associated with entry\
    \ into and movement along the Internet \"standards\n   track,\" including final\
    \ approval of specifications as Internet\n   Standards.\n   The Internet Engineering\
    \ Task Force (IETF) is a self-organized group\n   of people who make technical\
    \ and other contributions to the\n   engineering and evolution of the Internet\
    \ and its technologies.  It\n   is the principal body engaged in the development\
    \ of new Internet\n   standard specifications.  The IETF is divided into eight\
    \ functional\n   areas.  They are: Applications, Internet, IP: Next Generation,\n\
    \   Network Management, Operational Requirements, Routing, Security,\n   Transport\
    \ and User Services.  Each area has one or two area\n   directors.  These area\
    \ directors, along with the IETF/IESG Chair,\n   form the IESG.\n   In addition\
    \ to these organizations, there are a variety of other\n   formal and informal\
    \ groups that develop standards and agreements\n   about specialized or emerging\
    \ areas of the Internet.   For example,\n   the World Wide Web Consortium has\
    \ developed agreements and standards\n   for the Web.\n   None of these organizations\
    \ controls, governs, runs, or pays for the\n   Internet.  None of these organizations\
    \ controls the substantive\n   content available on the Internet.  None of these\
    \ organizations has\n   the power or authority to require content providers to\
    \ alter, screen,\n   or restrict access to content on the Internet other than\
    \ content that\n   they themselves create.\n   Beyond the standards setting process,\
    \ the only Internet functions\n   that are centralized are the allocation of numeric\
    \ addresses to\n   networks and the registration of \"domain names.\"  Three entities\n\
    \   around the world share responsibility for ensuring that each network\n   and\
    \ computer on the Internet has a unique 32-bit numeric \"IP\" address\n   (such\
    \ as 123.32.22.132), and for ensuring that all \"domain names\"\n   (such as \"\
    harvard.edu\") are unique.  InterNIC allocates IP addresses\n   for the Americas,\
    \ and has counterparts in Europe and Asia.  InterNIC\n   allocates large blocks\
    \ of IP addresses to major Internet providers,\n   who in turn allocate smaller\
    \ blocks to smaller Internet providers\n   (who in turn allocate even smaller\
    \ blocks to other providers or end\n   users).  InterNIC does not, however, reliably\
    \ receive information on\n   who receives each numeric IP address, and thus cannot\
    \ provide any\n   central database of computer addresses.  In addition, a growing\n\
    \   number of computers access the Internet indirectly through address\n   translating\
    \ devices such as application \"firewalls\".  With these\n   devices the IP address\
    \ used by a computer on the \"inside\" of the\n   firewall is translated to another\
    \ IP address for transmission over\n   the Internet.  The IP address used over\
    \ the Internet can be\n   dynamically assigned from a pool of available IP addresses\
    \ at the\n   time that a communication is initiated.  In this case the IP\n  \
    \ addresses used inside the firewall is not required to be globally\n   unique\
    \ and the IP addresses used over the Internet do not uniquely\n   identify a specific\
    \ computer.  Neither the InterNIC nor its\n   counterparts in Europe and Asia\
    \ control the substantive content\n   available on the Internet, nor do they have\
    \ the power or authority to\n   require content providers to alter, screen, or\
    \ restrict access to\n   content on the Internet.\n"
- title: 3.  Characteristics of Internet communications
  contents:
  - "3.  Characteristics of Internet communications\n   There are a wide variety of\
    \ methods of communications over the\n   Internet, including electronic mail,\
    \ mail exploders such as listserv,\n   USENET newsgroups, Internet Relay Chat,\
    \ gopher, FTP, and the World\n   Wide Web.  With each of these forms of communication,\
    \ the speaker has\n   little or no way to control or verify who receives the communication.\n\
    \   As detailed below, for each of these methods of communications, it is\n  \
    \ either impossible or very difficult for the speaker to restrict\n   access to\
    \ his or her communications \"by requiring use of a verified\n   credit card,\
    \ debit account, adult access code, or adult personal\n   identification number.\"\
    \ Similarly, for each of these methods of\n   communication, there are no feasible\
    \ actions that I know of that the\n   speaker can take that would be reasonably\
    \ effective to \"restrict or\n   prevent access by minors\" to the speaker's communications.\n\
    \   With each of these methods of communications, it is either\n   technologically\
    \ impossible or practically infeasible for the speaker\n   to ensure that the\
    \ speech is not \"available\" to a minor.  For most of\n   these methods--mail\
    \ exploders such as listserv, USENET newsgroups,\n   Internet Relay Chat, gopher,\
    \ FTP, and the World Wide Web--there are\n   technological obstacles to a speaker\
    \ knowing about or preventing\n   access by minors to a communication.  Yet even\
    \ for the basic point-\n   to-point communication of electronic mail, there are\
    \ practical and\n   informational obstacles to a speaker ensuring that minors\
    \ do not have\n   access to a communication that might be considered \"indecent\"\
    \ or\n   \"patently offensive\" in some communities.\n"
- title: 3.1 Point-to-Point Communications
  contents:
  - '3.1 Point-to-Point Communications

    '
- title: 3.1.1  Electronic Mail.
  contents:
  - "3.1.1  Electronic Mail.\n   Of all of the primary methods of communication on\
    \ the Internet, there\n   is the highest likelihood that the sender of electronic\
    \ mail will\n   personally know the intended recipient (and know the intended\n\
    \   recipient's true e-mail address), and thus the sender (i.e., the\n   speaker\
    \ or content provider) may be able to transmit potentially\n   \"indecent\" or\
    \ \"patently offensive\" content with relatively little\n   concern that the speech\
    \ might be \"available\" to minors.\n   There is significantly greater risk for\
    \ the e-mail speaker who does\n   not know the intended recipient.  As a hypothetical\
    \ example, if an\n   AIDS information organization receives from an unknown individual\
    \ a\n   request for information via electronic mail, the organization has no\n\
    \   practical or effective way to verify the identity or age of the e-\n   mail\
    \ requester.\n   An electronic mail address provides no authoritative information\n\
    \   about the addressee.  Addresses are often chosen by the addressees\n   themselves,\
    \ and may or may not be based on the addressees' real\n   names.  For millions\
    \ of people with e-mail addresses, no additional\n   information is available\
    \ over the Internet.  Where information is\n   available (via, for example, inquiry\
    \ tools such as \"finger\"), it is\n   usually provided by the addressee, and\
    \ thus may not be accurate\n   (especially in a case of a minor seeking to obtain\
    \ information the\n   government has restricted to adults).\n   There exists no\
    \ universal or even extensive \"white pages\" listing of\n   e-mail addresses\
    \ and corresponding names or telephone numbers.  Given\n   the rapidly expanding\
    \ and global nature of the Internet, any attempt\n   as such a listing likely\
    \ will be incomplete (and likely will not\n   contain information about the age\
    \ of the e-mail addressee).  Nor is\n   there any systematic, practical, and efficient\
    \ method to obtain the\n   identity of an e-mail address holder from the organization\
    \ or\n   institution operating the addressee's computer system.\n   Moreover,\
    \ it is relatively simple for someone to create an e-mail\n   \"alias\" to send\
    \ and receive mail under a different name.  Thus, a\n   given e-mail address may\
    \ not even be the true e-mail address of the\n   recipient.  On some systems,\
    \ for example, an individual seeking to\n   protect his or her anonymity could\
    \ easily create a temporary e-mail\n   address for the sole purpose of requesting\
    \ information from an AIDS\n   information resource.  In addition, there exist\
    \ \"anonymous remailers\"\n   which replace the original e-mail address on messages\
    \ with a randomly\n   chosen new one.  The remailer keeps a record of the relationship\n\
    \   between the original and the replacement name so that return mail\n   will\
    \ get forwarded to the right person.  These remailers are used\n   frequently\
    \ for discussion or support groups on sensitive or\n   controversial topics such\
    \ as AIDS.\n   Thus, there is no reasonably effective method by which one can\
    \ obtain\n   information from existing online information sources about an e-mail\n\
    \   address sufficient to ensure that a given address is used by an adult\n  \
    \ and not a minor.\n   Absent the ability to comply with the Communications Decency\
    \ Act\n   based on information from existing online information sources, an e-\n\
    \   mail speaker's only recourse is to interrogate the intended e-mail\n   recipient\
    \ in an attempt to verify that the intended recipient is an\n   adult.  Such verification\
    \ inherently and unavoidably imposes the\n   burden of an entirely separate exchange\
    \ of communications prior to\n   sending the e-mail itself, and is likely to be\
    \ unreliable if the\n   recipient intends to deceive the speaker.\n   This separate\
    \ preliminary communication is required because with\n   electronic mail, there\
    \ is a complete electronic and temporal\n   \"disconnect\" between the sender\
    \ and recipient.  Electronic mail can\n   be routed through numerous computers\
    \ between the sender and the\n   recipient, and the recipient may not \"log in\"\
    \ to retrieve mail until\n   days or even weeks after the sender sent the mail.\
    \  Thus, at no point\n   in time is there any direct or even indirect electronic\
    \ linkage\n   between sender and recipient that would allow the sender to\n  \
    \ interrogate the recipient prior to sending an e-mail.  Thus,\n   unavoidably,\
    \ the Communications Decency Act requires that the sender\n   incur the administrative\
    \ (and in some cases financial) cost of an\n   entirely separate exchange of communications\
    \ between sender and\n   recipient prior to the sender having sufficient information\
    \ to ensure\n   that the recipient is an adult.   Even if the sender were to\n\
    \   establish that an e-mail addressee is not a minor, the sender could\n   not\
    \ be sure that the addressee was not sharing their computer account\n   with someone\
    \ else, as is frequently done, who is a minor.\n   If an e-mail is part of a commercial\
    \ transaction of sufficient value\n   to justify the time and expense of obtaining\
    \ payment via credit card\n   from the e-mail addressee, an e-mail sender may\
    \ be able to utilize\n   the credit card or debit account options set out in the\n\
    \   Communications Decency Act.  At this time, however, one cannot verify\n  \
    \ a credit or debit transaction over the Internet, and thus an e-mail\n   speaker\
    \ would have to incur the expense of verifying the transaction\n   via telephone\
    \ or separate computer connection to the correct banking\n   entity.  Because\
    \ of current concerns about data security on the\n   Internet, such an e-mail\
    \ credit card transaction would likely also\n   require that the intended e-mail\
    \ recipient transmit the credit card\n   information to the e-mail sender via\
    \ telephone or the postal service.\n   Similarly, utilizing the \"adult access\
    \ code\" or \"adult personal\n   identification number\" options set out in the\
    \ statute would at this\n   time require the creation and maintenance of a database\
    \ of adult\n   codes.  While such a database would not be an insurmountable\n\
    \   technological problem, it would require a significant amount of human\n  \
    \ clerical time to create and maintain the information.  As with the\n   credit\
    \ or debit transactions, an adult code database would also\n   likely require\
    \ that information be transmitted by telephone or postal\n   mail.\n   Moreover,\
    \ such an adult access code would likely be very ineffective\n   at screening\
    \ access by minors.  For the adult access code concept to\n   work at all, any\
    \ such code would have to be transmitted over the\n   Internet, and thus would\
    \ be vulnerable to interception and\n   disclosure.  Any sort of \"information\
    \ based\" code--that is, a code\n   that consists of letters and numbers transmitted\
    \ in a message--could\n   be duplicated and circulated to other users on the Internet.\
    \  It is\n   highly likely that valid adult access codes would themselves become\n\
    \   widely distributed on the Internet, allowing industrious minors to\n   obtain\
    \ a valid code and thus obtain access the material sought to be\n   protected.\n\
    \   A somewhat more effective alternative to this type of \"information\n   based\"\
    \ access code would be to link such a code to the unique 32-bit\n   numeric \"\
    IP\" addresses of networks and computers on the Internet.\n   Under this approach,\
    \ \"adult\" information would only be transmitted to\n   the particular computer\
    \ with the \"approved\" IP address.  For tens of\n   millions of Internet users,\
    \ however, IP addresses for a given access\n   session are dynamically assigned\
    \ at the time of the access, and those\n   users will almost certainly utilize\
    \ different IP addresses in\n   succeeding sessions.  For example, users of the\
    \ major online services\n   such as America Online (AOL) are only allocated a\
    \ temporary IP\n   address at the time they link to the service, and the AOL user\
    \ will\n   not retain that IP address in later sessions.  Also, as discussed\n\
    \   above, the use of \"firewalls\" can dynamically alter the apparent IP\n  \
    \ address of computers accessing the Internet.  Thus, any sort of IP\n   address-based\
    \ screening system would exclude tens of millions of\n   potential recipients,\
    \ and thus would not be a viable screening\n   option.\n   At bottom, short of\
    \ incurring the time and expense of obtaining and\n   charging the e-mail recipient's\
    \ credit card, there are no reasonably\n   effective methods by which an e-mail\
    \ sender can verify the identity\n   or age of an intended e-mail recipient even\
    \ in a one-to-one\n   communication to a degree of confidence sufficient to ensure\n\
    \   compliance with the Communications Decency Act (and avoid the Act's\n   criminal\
    \ sanction).\n"
- title: 3.2 Point-to-Multipoint Communications
  contents:
  - "3.2 Point-to-Multipoint Communications\n   The difficulties described above for\
    \ point-to-point communications\n   are magnified many times over for point-to-multipoint\
    \ communications.\n   In addition, for almost all major types of point-to-multipoint\n\
    \   communications on the Internet, there is a technological obstacle\n   that\
    \ makes it impossible or virtually impossible for the speaker to\n   control who\
    \ receives his or her speech.  For these types of\n   communications over the\
    \ Internet, reasonably effective compliance\n   with the Communications Decency\
    \ Act is impossible.\n"
- title: 3.2.1 Mail Exploders
  contents:
  - "3.2.1 Mail Exploders\n   Essentially an extension of electronic mail allowing\
    \ someone to\n   communicate with many people by sending a single e-mail, \"mail\n\
    \   exploders\" are an important means by which the Internet user can\n   exchange\
    \ ideas and information on particular topics with others\n   interested in the\
    \ topic.  \"Mail exploders\" is a generic term covering\n   programs such as \"\
    listserv\" and \"Majordomo.\" These programs typically\n   receive electronic\
    \ mail messages from individual users, and\n   automatically retransmit the message\
    \ to all other users who have\n   asked to receive postings on the particular\
    \ list.  In addition to\n   listserv and Majordomo, many e-mail retrieval programs\
    \ contain the\n   option to receive messages and automatically forward the messages\
    \ to\n   other recipients on a local mailing list.\n   Mail exploder programs\
    \ are relatively simple to establish.  The\n   leading programs such as listserv\
    \ and Majordomo are available for\n   free, and once set up can generally run\
    \ unattended.  There is no\n   practical way to measure how many mailing lists\
    \ have been established\n   worldwide, but there are certainly tens of thousands\
    \ of such mailing\n   lists on a wide range of topics.\n   With the leading mail\
    \ exploder programs, users typically can add or\n   remove their names from the\
    \ mailing list automatically, with no\n   direct human involvement.  To subscribe\
    \ to a mailing list, a user\n   transmits an e-mail to the automated list program.\
    \  For example, to\n   subscribe to the \"Cyber-Rights\" mailing list (relating\
    \ to censorship\n   and other legal issues on the Internet) one sends e-mail addressed\
    \ to\n   \"listserv@cpsr.org\" and includes as the first line of the body of the\n\
    \   message the words \"subscribe cyber-rights name\" (inserting a person's\n\
    \   name in the appropriate place).  In this example, the listserv\n   program\
    \ operated on the cpsr.org computer would automatically add the\n   new subscriber's\
    \ e-mail address to the mailing list.  The name\n   inserted is under the control\
    \ of the person subscribing, and thus may\n   not be the actual name of the subscriber.\n\
    \   A speaker can post to a mailing list by transmitting an e-mail\n   message\
    \ to a particular address for the mailing list.  For example,\n   to post a message\
    \ to the \"Cyber-Rights\" mailing list, one sends the\n   message in an e-mail\
    \ addressed to \"cyber-rights@cpsr.org\".  Some\n   mailing lists are \"moderated,\"\
    \ and messages are forwarded to a human\n   moderator who, in turn, forwards messages\
    \ that moderator approves of\n   to the whole list.   Many mailing lists, however,\
    \ are unmoderated and\n   postings directed to the appropriate mail exploder programs\
    \ are\n   automatically distributed to all users on the mailing list.  Because\n\
    \   of the time required to review proposed postings and the large number\n  \
    \ of people posting messages, most mailing lists are not moderated.\n   An individual\
    \ speaker posting to a mail exploder mailing list cannot\n   control who has subscribed\
    \ to the particular list.  In many cases,\n   the poster cannot even find out\
    \ the e-mail address of who has\n   subscribed to the list.  A speaker posting\
    \ a message to a list thus\n   has no way to screen or control who receives the\
    \ message.  Even if\n   the mailing list is \"moderated,\" an individual posting\
    \ to the list\n   still cannot control who receives the posting.\n   Moreover,\
    \ the difficulty in knowing (and the impossibility of\n   controlling) who will\
    \ receive a posting to a mailing list is\n   compounded by the fact that it is\
    \ possible that mail exploder lists\n   can themselves be entered as a subscriber\
    \ to a mailing list.  Thus,\n   one of the \"subscribers\" to a mailing list may\
    \ in fact be another\n   mail exploder program that re-explodes any messages transmitted\
    \ using\n   the first mailing list.  Thus, a message sent to the first mailing\n\
    \   list may end up being distributed to many entirely separate mailing\n   lists\
    \ as well.\n   Based on the current operations and standards of the Internet,\
    \ it\n   would be impossible for someone posting to a listserv to screen\n   recipients\
    \ to ensure the recipients were over 17 years of age.  Short\n   of not speaking\
    \ at all, I know of no actions available to a speaker\n   today that would be\
    \ reasonably effective at preventing minors from\n   having access to messages\
    \ posted to mail exploder programs.\n   Requiring such screening for any messages\
    \ that might be \"indecent\" or\n   \"patently offensive\" to a minor would have\
    \ the effect of banning such\n   messages from this type of mailing list program.\n\
    \   Even if one could obtain a listing of the e-mail addresses that have\n   subscribed\
    \ to a mailing list, one would then be faced with the same\n   obstacles described\
    \ above that face a point-to-point e-mail sender.\n   Instead of obtaining a credit\
    \ card or adult access code from a single\n   intended recipient, however, a posted\
    \ to a mailing list may have to\n   obtain such codes from a thousand potential\
    \ recipients, including new\n   mailing list subscribers who may have only subscribed\
    \ moments before\n   the poster wants to post a message.  As noted above, complying\
    \ with\n   the Communications Decency Act for a single e-mail would be very\n\
    \   difficult.  Complying with the Act for a single mailing list posting\n   with\
    \ any reasonable level of effectiveness is impossible.\n"
- title: 3.2.2  USENET Newsgroups.
  contents:
  - "3.2.2  USENET Newsgroups.\n   One of the most popular forms of communication\
    \ on the Internet is the\n   USENET newsgroup.  USENET newsgroups are similar\
    \ in objective to mail\n   exploder mailing lists--to be able to communicate easily\
    \ with others\n   who share an interest in a particular topic--but messages are\n\
    \   conveyed across the Internet in a very different manner.\n   USENET newsgroups\
    \ are distributed message databases that allow\n   discussions and exchanges on\
    \ particular topics.   USENET newsgroups\n   are disseminated using ad hoc, peer-to-peer\
    \ connections between\n   200,000 or more computers (called USENET \"servers\"\
    ) around the world.\n   There are newsgroups on more than twenty thousand different\
    \ subjects.\n   Collectively, almost 100,000 new messages (or \"articles\") are\
    \ posted\n   to newsgroups each day.   Some newsgroups are \"moderated\" but most\n\
    \   are open access.\n   For unmoderated newsgroups, when an individual user with\
    \ access to a\n   USENET server posts a message to a newsgroup, the message is\n\
    \   automatically forwarded to adjacent USENET servers that furnish\n   access\
    \ to the newsgroup, and it is then propagated to the servers\n   adjacent to those\
    \ servers, etc.  The messages are temporarily stored\n   on each receiving server,\
    \ where they are available for review and\n   response by individual users.  The\
    \ messages are automatically and\n   periodically purged from each system after\
    \ a configurable amount of\n   time to make room for new messages.  Responses\
    \ to messages--like the\n   original messages--are automatically distributed to\
    \ all other\n   computers receiving the newsgroup.  The dissemination of messages\
    \ to\n   USENET servers around the world is an automated process that does not\n\
    \   require direct human intervention or review.\n   An individual who posts a\
    \ message to a newsgroup has no ability to\n   monitor or control who reads the\
    \ posted message.  When an individual\n   posts a message, she transmits it to\
    \ a particular newsgroup located\n   on her local USENET server.  The local service\
    \ then automatically\n   routes the message to other servers (or in some cases\
    \ to a\n   moderator), which in turn allow the users of those servers to read\n\
    \   the message.  The poster has no control over the handling of her\n   message\
    \ by the USENET servers worldwide that receive newsgroups.\n   Each individual\
    \ server is configured by its local manager to\n   determine which newsgroups\
    \ it will accept.   There is no mechanism to\n   permit distribution based on\
    \ characteristics of the individual\n   messages within a newsgroup.\n   The impossibility\
    \ of the speaker controlling the message distribution\n   is made even more clear\
    \ by the fact that new computers and computer\n   networks can join the USENET\
    \ news distribution system at any time.\n   To obtain newsgroups, the operator\
    \ of a new computer or computer\n   network need only reach agreement with a neighboring\
    \ computer that\n   already receives the newsgroups.  Speakers around the world\
    \ do not\n   learn that the new computer had joined the distribution system.\n\
    \   Thus, just as a speaker cannot know or control who receives a\n   message,\
    \ the speaker does not even know how many or which computers\n   might receive\
    \ a given newsgroup.\n   For moderated newsgroups, all messages to the newsgroup\
    \ are forwarded\n   to an individual who can screen them for relevance to the\
    \ topics\n   under discussion.  The screening process, however, does not increase\n\
    \   the ability of the original speaker to control who receives a given\n   message.\
    \  A newsgroup moderator has as little control as the original\n   speaker over\
    \ who receives a message posted to the newsgroup.\n   Based on the current operations\
    \ and standards of the Internet, it\n   would be impossible for someone posting\
    \ to a USENET newsgroup to\n   screen recipients to ensure that the recipients\
    \ were over 17 years of\n   age.  Short of not speaking at all, I know of no actions\
    \ available to\n   a speaker today that would be reasonably effective at preventing\n\
    \   minors from having access to USENET newsgroup messages.  Requiring\n   such\
    \ screening for any messages that might be \"indecent\" or \"patently\n   offensive\"\
    \ to a minor would have the effect of banning such messages\n   from USENET newsgroups.\n\
    \   A speaker also has no means by which he or she could require\n   listeners\
    \ to provide a credit card, debit account, adult access code,\n   or adult personal\
    \ identification number.  Each individual USENET\n   server controls access to\
    \ the newsgroups on that server, and a\n   speaker has no ability to force a server\
    \ operator to take any\n   particular action.  The message is out of the speaker's\
    \ hands from\n   the moment the message is posted.\n   Moreover, even if one hypothesized\
    \ a system under which a newsgroup\n   server would withhold access to a message\
    \ until the speaker received\n   a credit card, debit account, adult access code,\
    \ or adult personal\n   identification number from the listener, there would be\
    \ no feasible\n   way for the speaker to receive such a number.  Because a listener\
    \ may\n   retrieve a message from a newsgroup days after the speaker posted the\n\
    \   message, such a hypothetical system would require the speaker either\n   to\
    \ remain at his or her computer 24 hours a day for as many as ten\n   days after\
    \ posting the message, or to finance, develop, and maintain\n   an automated system\
    \ to receive and validate access numbers.  All of\n   this effort would be required\
    \ for the speaker to post even a single\n   potentially \"patently offensive\"\
    \ message to a single newsgroup.\n   Moreover, even if such a hypothetical system\
    \ did exist and a speaker\n   were willing to remain available 24 hours a day\
    \ (or operate a costly\n   automated system) in order to receive access numbers,\
    \ not all\n   computers that receive USENET newsgroups could reasonably transmit\n\
    \   such access numbers.  Some computers that receive newsgroups do so\n   only\
    \ by a once-a-day telephone connection to another newsgroup\n   server.  Some\
    \ of these computers do not have any other type of\n   Internet connection, and\
    \ indeed some computers that receive USENET\n   newsgroups do not even utilize\
    \ the TCP/IP communications protocol\n   that is required for direct or real time\
    \ communications on the\n   Internet.  These computers would have no means by\
    \ which a prospective\n   listener's access code could be communicated back to\
    \ a speaker.\n   It is my opinion that if this hypothetical access system ever\
    \ were\n   created, it would be so burdensome as to effectively ban from USENET\n\
    \   newsgroups messages that might be \"indecent\" or \"patently offensive.\"\n\
    \   Moreover, the communications standards and protocols that would allow\n  \
    \ such a hypothetical access system have not as of today been\n   developed, and\
    \ no Internet standards setting body of which I am aware\n   is currently developing\
    \ such standards and protocols.  Specifically,\n   such a hypothetical access\
    \ system is not part of the \"next\n   generation\" Internet Protocol that I helped\
    \ to develop.\n"
- title: 3.2.3  Internet Relay Chat.
  contents:
  - "3.2.3  Internet Relay Chat.\n   Another method of communication on the Internet\
    \ is called \"Internet\n   Relay Chat\" (or IRC).  IRC allows for real time communication\
    \ between\n   two or more Internet users.  IRC is analogous to a telephone party\n\
    \   line, using a computer and keyboard rather than a telephone.  With\n   IRC,\
    \ however, at anyone time there are thousands of different party\n   lines available,\
    \ in which collectively tens of thousands of users are\n   engaging in discussions,\
    \ debates, and conversations on a huge range\n   of subjects.  Moreover, an individual\
    \ can create a new party line to\n   discuss a different topic at any time.  While\
    \ many discussions on IRC\n   are little more than social conversations between\
    \ the participants,\n   there are often conversations on important issues and\
    \ topics.\n   Although I have not personally operated an IRC server in my career,\
    \ I\n   am familiar enough with the operations of IRC servers to be able to\n\
    \   identify the obstacles that a speaker would encounter attempting to\n   identify\
    \ other participants and to verify that those participants\n   were not minors.\n\
    \   There exists a network of dozens of IRC servers across the world.  To\n  \
    \ speak through IRC, a speaker connects to one of these servers and\n   selects\
    \ the topic the speaker wishes to \"join.\"  Within a particular\n   topic (once\
    \ a speaker joins a topic), all speakers on that topic can\n   see and read everything\
    \ that everyone else transmits.  As a practical\n   matter, there is no way for\
    \ each person who joins a discussion to\n   interrogate all other participants\
    \ (sometimes dozens of participants)\n   as to their identity and age.  Because\
    \ people join or drop out of\n   discussions on a rolling basis, the discussion\
    \ line would be\n   overwhelmed with messages attempting to verify the identity\
    \ of the\n   participants.\n   Also as a practical matter, there is no way that\
    \ an individual\n   speaker or an individual IRC server operator could enforce\
    \ an \"adults\n   only\" rule for a selection of the discussion topics.  Dozens\
    \ of IRC\n   servers are interconnected globally so that people across the world\n\
    \   can talk to each other.  Thus, a speaker connected to an IRC server\n   in\
    \ the United States can speak directly to a listener in Asia or\n   Europe.  There\
    \ is no practical way that a speaker in the United\n   States can be reasonably\
    \ certain that a given IRC discussion is in\n   fact \"adults only.\"\n   Nor\
    \ can a speaker, prior to or at the time of joining an IRC\n   discussion, ascertain\
    \ with any confidence the identity of the other\n   participants in the discussion.\
    \  Individual participants in an IRC\n   conversation are able to participate\
    \ anonymously by using a\n   pseudonym.  A new speaking joining the conversation\
    \ can see a list of\n   pseudonyms of other participants, but has no possibly\
    \ way of\n   determining the real identify (or even the real e-mail address) of\n\
    \   the individuals behind each pseudonym.\n   Based on the current operations\
    \ and standards of the Internet, it\n   would be impossible for someone participating\
    \ in a IRC discussion to\n   screen recipients with a level of certainty needed\
    \ to ensure the\n   recipients were over 17 years of age.  Short of not speaking\
    \ at all,\n   I know of no actions available to a speaker today that would be\n\
    \   reasonably effective at preventing minors from having access to\n   speech\
    \ in an IRC discussion.  Requiring such screening of recipients\n   by the speakers\
    \ for any IRC discussions that might be \"indecent\" or\n   \"patently offensive\"\
    \ to a minor would have the effect of banning such\n   discussions.\n"
- title: 4.0  Information Retrival Systems
  contents:
  - "4.0  Information Retrival Systems\n   With FTP (or File Transfer Protocol), gopher,\
    \ and the World Wide Web,\n   the Internet is a vast resource for information\
    \ made available to\n   users around the world.  All three methods (FTP, gopher,\
    \ and the Web)\n   are specifically geared toward allowing thousands or millions\
    \ of\n   users worldwide to access content on the Internet, and none are\n   specifically\
    \ designed to limit access based on criteria such as the\n   age of the Internet\
    \ user.  Currently much of this information is\n   offered for free access.\n"
- title: 4.1 Anonymous FTP
  contents:
  - "4.1 Anonymous FTP\n   \"Anonymous FTP\" is a basic method by which a content\
    \ provider can\n   make content available to users on the Internet.   FTP is a\
    \ protocol\n   that allows the efficient and error free transfer of files from\
    \ one\n   computer to another.  To make content available via FTP, a content\n\
    \   provider establishes an \"Anonymous FTP server\" capable of receiving\n  \
    \ FTP requests from remote users.   This approach is called \"anonymous\"\n  \
    \ because when a remote user connects to an FTP server, the remote user\n   enters\
    \ the word \"anonymous\" in response to the server's request for a\n   user name.\
    \   By convention, the remote user is requested to enter his\n   or her e-mail\
    \ address when prompted for a \"password.\"  The user is\n   then given access\
    \ to a restricted portion of the server disk and to\n   the files in that area.\
    \  Even though the user may have entered their\n   e-mail address in response\
    \ to the password prompt, there is no\n   effective validation or screening is\
    \ possible using the FTP server\n   software that is currently available.  Using\
    \ currently available FTP\n   software, a content provider has no way to screen\
    \ access by\n   \"anonymous\" users that may be minors.  Even if a content provider\n\
    \   could determine the age of a particular remote user, the currently\n   available\
    \ FTP software cannot be set to limit the user's access to\n   non-\"adult\" file\
    \ areas.\n   FTP server software can allow non-\"anonymous\" users to access the\
    \ FTP\n   server, and in that mode can require the users to have individual\n\
    \   passwords that are verified against a pre-existing list of passwords.\n  \
    \ There are two major problems, however, that prevent this type of\n   non-\"\
    anonymous\" FTP access from being used to allow broad access to\n   information\
    \ over the Internet (as anonymous FTP can allow).  First,\n   with current server\
    \ software each non-\"anonymous\" FTP user must be\n   given an account on the\
    \ server computer, creating a significant\n   administrative burden and resource\
    \ drain.  If more than a limited\n   number of users want access to the FTP system,\
    \ the requirement of\n   separate accounts would quickly overwhelm the capacity\
    \ of the server\n   to manage the accounts--the FTP server software was not designed\
    \ to\n   manage thousands or millions of different user/password combinations.\n\
    \   Second, under existing FTP server software, each of these named users\n  \
    \ would have complete access to the server file system, not a\n   restricted area\
    \ like the anonymous FTP function supports.  This would\n   create a significant\
    \ security problem.  For these two reasons, as a\n   practical matter FTP cannot\
    \ be used to give broad access to content\n   except via the anonymous FTP option\
    \ (which, as noted above, does not\n   allow for screening or blocking of minors).\n\
    \   As discussed below with regard to the World Wide Web, even if someone\n  \
    \ re-designed the currently available FTP server software to allow the\n   screening\
    \ of minors, the administrative burden of such screening\n   would in many cases\
    \ overwhelm the resources of the content provider.\n   Based on the current operations\
    \ and standards of the Internet, it is\n   not possible or practically feasible\
    \ for someone operating an\n   anonymous FTP file server to screen recipients\
    \ with a level of\n   certainty needed to ensure the recipients were over 17 years\
    \ of age.\n   Short of not operating an anonymous FTP server at all, I know of\
    \ no\n   actions available to a content provider today that would be\n   reasonably\
    \ effective at preventing minors from having access to\n   \"adult\" files on\
    \ the FTP server.  Requiring such screening by\n   anonymous FTP server operators\
    \ to prevent minors from accessing FTP\n   files that might be \"indecent\" or\
    \ \"patently offensive\" to a minor\n   would have the effect of banning such\
    \ anonymous FTP access.\n"
- title: 4.2  Gopher.
  contents:
  - "4.2  Gopher.\n   The gopher program is similar to FTP in that it allows for basic\n\
    \   transfer of files from one computer to another, but it is also a\n   precursor\
    \ to the World Wide Web in that it allows a user to\n   seamlessly jump from one\
    \ gopher file server to another in order to\n   locate the desired information.\
    \  The development of gopher and the\n   linking of gopher servers around the\
    \ worlds dramatically improved the\n   ability of Internet users to locate information\
    \ across the Internet.\n   Although in many ways an improvement over FTP, gopher\
    \ is simpler than\n   FTP in that users need not enter any username or password\
    \ to gain\n   access to files stored on the gopher server.   Under currently\n\
    \   available gopher server software, a content provider has no built-in\n   ability\
    \ to screen users.  Thus a content provider could not prevent\n   minors from\
    \ retrieving \"adult\" files.\n   As discussed below with regard to the World\
    \ Wide Web, even if the\n   gopher server software allowed the screening of minors,\
    \ the\n   administrative burden of such screening would in many cases overwhelm\n\
    \   the resources of the content provider.\n   Based on the current operations\
    \ and standards of the Internet, it is\n   not possible for someone operating\
    \ a gopher file server to screen\n   recipients with a level of certainty needed\
    \ to ensure the recipients\n   were over 17 years of age.  Short of not operating\
    \ a gopher server at\n   all, I know of no actions available to a content provider\
    \ today that\n   would be reasonably effective at preventing minors from having\
    \ access\n   to \"adult\" files on a gopher server.  Requiring such screening\
    \ of\n   users by gopher server operators to prevent minors from accessing\n \
    \  files that might be \"indecent\" or \"patently offensive\" to a minor\n   would\
    \ have the effect of banning gopher servers wherever there is any\n   such material.\n"
- title: 4.3  World Wide Web (WWW).
  contents:
  - "4.3  World Wide Web (WWW).\n   Fast becoming the most well known method of communicating\
    \ on the\n   Internet, the \"World Wide Web\" offers users the easy ability to\n\
    \   locate and view a vast array of content on the Internet.  The Web\n   uses\
    \ a \"hypertext\" formatting language called hypertext markup\n   language (HTML),\
    \ and Web \"browsers\" can display HTML documents\n   containing text, images,\
    \ and sound.  Any HTML document can include\n   links to other types of information\
    \ or resources anywhere in the\n   world, so that while viewing an HTML document\
    \ that, for example,\n   describes resources available on the Internet, an individual\
    \ can\n   \"click\" using a computer mouse on the description of the resource\
    \ and\n   be immediately connected to the resource itself.  Such \"hyperlinks\"\
    \n   allow information to be accessed and organized in very flexible ways,\n \
    \  and allow individuals to locate and efficiently view related\n   information\
    \ even if the information is stored on numerous computers\n   all around the world.\n\
    \   Unlike with USENET newsgroups, mail exploders, FTP, and gopher, an\n   operator\
    \ of a World Wide Web server does have some ability to\n   interrogate a user\
    \ of a Web site on the server, and thus has some\n   ability to screen out users.\
    \  An HTML document can include a fill-in-\n   the-blank \"form\" to request information\
    \ from a visitor to a Web site,\n   and this information can be transmitted back\
    \ to the Web server.  The\n   information received can then be processed by a\
    \ computer program\n   (usually a \"Common Gateway Interface,\" or \"CGI,\" script),\
    \ and based\n   on the results of that computer program the Web server could grant\
    \ or\n   deny access to a particular Web page.  Thus, it is possible for some\n\
    \   (but not all, as discussed below) World Wide Web sites to be designed\n  \
    \ to \"screen\" visitors to ensure that they are adults.\n   The primary barrier\
    \ to such screening is the administrative burden of\n   creating and maintaining\
    \ the screening system.  For an individual Web\n   site to create a software system\
    \ capable of screening thousands of\n   visitors a day, determining (to the extent\
    \ possible) whether a\n   visitor is an adult or a minor, and maintaining a database\
    \ to allow\n   subsequent access to the Web site would require a significant on-\n\
    \   going effort.  Moreover, as discussed above with regard to electronic\n  \
    \ mail, the task of actually establishing a Web visitor's identity or\n   \"verifying\"\
    \ a credit card would require a significant investment of\n   administrative and\
    \ clerical time.  As there is no effective method to\n   establish identity over\
    \ the Internet, nor is there currently a method\n   to verify credit card numbers\
    \ over the Internet (and given the\n   current cost of credit card verifications\
    \ done by other means), this\n   type of identification process is only practical\
    \ for a commercial\n   entity that is charging for access to the Web information.\n\
    \   Beyond the major administrative burden that would be required for a\n   Web\
    \ site host to comply with the Communications Decency Act, there\n   are two additional\
    \ problems presented by the Act.  First, many Web\n   publishers cannot utilize\
    \ computer programs such as CGI scripts to\n   process input from a Web visitor.\
    \  For example, I have been informed\n   that the major online services such as\
    \ America Online and Compuserve\n   do not allow their customers to run CGI scripts\
    \ or other processes\n   that could be a significant drain on the online services'\
    \ computers\n   as well as a potential security risk.  Thus, for this category\
    \ of Web\n   publisher, the Communications Decency Act works as a ban on any\n\
    \   arguably \"indecent\" or \"patently offensive\" speech.  It is impossible\n\
    \   for this category of Web publisher to control access to their Web\n   sites.\n\
    \   Moreover, even for Web publishers who can use CGI scripts to screen\n   access,\
    \ the existence of Web page caching on the Internet can make\n   such screening\
    \ ineffective.  \"Caching\" refers to a method to speed up\n   access to Internet\
    \ resources.  Caching is often used at one or both\n   ends of, for example, a\
    \ transatlantic or transpacific cable that\n   carries Internet communications.\
    \  An example of caching might occur\n   when a Internet user in Europe requests\
    \ access to a World Wide Web\n   page located in the United States.  The request\
    \ travels by\n   transatlantic cable to the United States, and the Web page is\n\
    \   transmitted back across the ocean to Europe (and ultimately to the\n   user\
    \ who requested access).  But, the operator of the transatlantic\n   cable will\
    \ place the Web page in a storage \"cache\" located on the\n   European side of\
    \ the cable.  Then, if a second Internet user in\n   Europe requests the same\
    \ Web page, the operator of the transatlantic\n   cable will intercept the request\
    \ and provide the page from its\n   \"cache\" (thereby reducing traffic on the\
    \ transatlantic cable).  This\n   type of caching typically occurs without the\
    \ awareness of the\n   requesting user.  Moreover, in this scenario, the original\
    \ content\n   provider is not even aware that the second user requested the Web\n\
    \   page--and the original content provider has no opportunity to screen\n   the\
    \ access by the second user.  Nevertheless, the original content\n   provider\
    \ risks prosecution if the content is \"adult\" content and the\n   second requester\
    \ is a minor.  The use of caching web servers is\n   rapidly increasing within\
    \ the United States (mostly to help moderate\n   the all too rapid growth in Internet\
    \ traffic), and thus can affect\n   entirely domestic communications.  For example,\
    \ a growing number of\n   universities use caching web servers to reduce the usage\
    \ of the link\n   to their Internet service provider.  In light of this type of\n\
    \   caching, efforts to screen access to Web pages can only at best be\n   partially\
    \ effective.\n   In light of the existence of Web page caching on the Internet,\
    \ it\n   would be extremely difficult if not impossible to for someone\n   operating\
    \ a World Wide Web server to ensure that no minors received\n   \"adult\" content.\n\
    \   Moreover, for those Web page publishers who lack access to CGI\n   scripts,\
    \ there is no possible way for them to screen recipients to\n   ensure that all\
    \ recipients are over 17 years of age.  For these\n   content providers, short\
    \ of not supporting World Wide Web access to\n   their materials, I know of no\
    \ actions available to them that would be\n   reasonably effective at preventing\
    \ minors from having access to\n   \"adult\" files on a World Wide Web server.\
    \  Requiring such screening\n   by these Web publishers to prevent minors from\
    \ accessing files that\n   might be \"indecent\" or \"patently offensive\" to\
    \ a minor would have the\n   effect of banning their speech on the World Wide\
    \ Web.\n   The Web page caching described above contributes to the difficulty\
    \ of\n   determining with specificity the number of visitors to a particular\n\
    \   Web site.  Some Web servers can count how many different Web clients,\n  \
    \ some of which could be caching Web servers, requested access to a Web\n   site.\
    \  Some Web servers can also count how many \"hits\"--or separate\n   file accesses--were\
    \ made on a particular Web site (a single access to\n   a Web page that contains\
    \ a images or graphic icons would likely be\n   registered as more than one \"\
    hit\").  With caching, the actual number\n   of users that retrieved information\
    \ that originated on a particular\n   Web server is likely to be greater than\
    \ the number of \"hits\" recorded\n   for the server.\n"
- title: 5.0  Client-end Blocking
  contents:
  - "5.0  Client-end Blocking\n   As detailed above, for many important methods of\
    \ communication on the\n   Internet, the senders--the content providers--have\
    \ no ability to\n   ensure that their messages are only available to adults. \
    \ It is also\n   not possible for a Internet service provider or large institutional\n\
    \   provider of access to the Internet (such as a university) to screen\n   out\
    \ all or even most content that could be deemed \"indecent\" or\n   \"patently\
    \ offensive\" (to the extent those terms can be understood at\n   all).  A large\
    \ institution could at least theoretically screen a\n   portion of the communications\
    \ over the Internet, scanning for example\n   for \"indecent\" words, but not\
    \ pictures.  Such a screening program\n   capable of screening a high volume of\
    \ Internet traffic at the point\n   of its entry into the institution would require\
    \ an investment of\n   computing resources of as much as one million dollars per\
    \ major\n   Internet information conduit.  In addition it would be quit difficult\n\
    \   to configure such a system to only control the content for those\n   users\
    \ that are under-age recipients, since in many cases the\n   information would\
    \ be going to a server within the university where\n   many users, under-age and\
    \ not, would have access to it.\n   Based on my experience and knowledge of the\
    \ Internet, I believe that\n   the most effective way to monitor, screen, or control\
    \ the full range\n   of information transmitted over the Internet to block undesired\n\
    \   content is at the client end--that is, by using software installed in\n  \
    \ the individual user's computer.  Such software could block certain\n   forms\
    \ of incoming transmissions by using content descriptive tags in\n   the messages,\
    \ or could use content ratings developed by third parties\n   to select what can\
    \ and cannot be retrieved for display on a user's\n   computer.\n"
- title: 6.0  Tagging Material
  contents:
  - "6.0  Tagging Material\n   I am informed that the government in this action may\
    \ advocate the use\n   of special tags or flags in electronic mail messages, USENET\n\
    \   newsgroup postings, and World Wide Web HTML documents to indicate\n   \"adult\"\
    \ material.  To my knowledge, no Internet access software or\n   World Wide Web\
    \ browsers are currently configurable to block material\n   with such tags.  Thus,\
    \ the headers and flags the government may\n   advocate is currently an ineffective\
    \ means to ensure the blocking of\n   access by minors to \"adult\" material.\
    \  Even in a predictable future\n   where there are defined standards for such\
    \ tags and there are\n   readably available browsers that are configurable to\
    \ make use of\n   those tags, a content provider--e.g., a listserv or Newsgroup\
    \ poster\n   or a Web page author--will have little power to ensure that the\n\
    \   client software used to receive the postings was in all cases\n   properly\
    \ configured to recognize these tags and to block access to\n   the posting when\
    \ required.  Thus I feel that the tagging that may be\n   proposed by the government\
    \ would in fact not be \"effective\" in\n   ensuring that the poster's speech\
    \ would not be \"available to a person\n   under 18 years of age,\" as the Communications\
    \ Decency Act requires.\n   Although I strongly support both voluntary self-rating\
    \ and third-\n   party rating (as described in the preceding paragraph), I do\
    \ not feel\n   that the use of tags of this type would satisfy the speaker's\n\
    \   obligation to take effective actions to ensure that \"patently\n   offensive\"\
    \ material would not be \"available\" to minors.  Furthermore,\n   since it is\
    \ impossible to embed such flags or headers in many of the\n   documents currently\
    \ made available by anonymous FTP, gopher and the\n   World Wide Web without rendering\
    \ the files useless (executable\n   programs for example), any government proposal\
    \ to require the use of\n   tags to indicate \"adult\" material would not allow\
    \ the continued use\n   of those methods of communication for speech that might\
    \ be deemed\n   \"indecent\" or \"patently offensive.\"\n   With the exception\
    \ of electronic mail and e-mail exploders all of the\n   methods of Internet communications\
    \ discussed above require an\n   affirmative action by the listener before the\
    \ communication takes\n   place.  A listener must take specific action to receive\n\
    \   communications from USENET newsgroups, Internet Relay Chat, gopher,\n   FTP,\
    \ and the World Wide Web.  In general this is also true for e-mail\n   exploders\
    \ except in the case where a third party subscribes the user\n   to the exploder\
    \ list.  These communications over the Internet do not\n   \"invade\" a person's\
    \ home or appear on a person's computer screen\n   unbidden.  Instead, a person\
    \ must almost always take specific\n   affirmative steps to receive information\
    \ over the Internet.\n"
- title: 7.0  Acknowledgment
  contents:
  - "7.0  Acknowledgment\n   I owe a great deal of thanks to John Morris of Jenner\
    \ and Block, one\n   of the law firms involved in the CDA challenge.  Without\
    \ his\n   extensive help this document would not exist, or if it did, it would\n\
    \   be even more scattered.\n"
- title: 8.0 Security Considerations
  contents:
  - "8.0 Security Considerations\n   To be actually able to do the type of content\
    \ access control that the\n   CDA envisions would require a secure Internet infrastructure\
    \ along\n   with secure ways to determine the minor status of potential\n   reciepiants\
    \ around the world.  Developing such a system is outside of\n   the scope of this\
    \ document.\n"
- title: 9.0 Author's Address
  contents:
  - "9.0 Author's Address\n   Scott Bradner\n   Harvard University\n   1350 Mass Ave.\n\
    \   Cambridge MA 02138 USA\n   Phone: +1 617 495 3864\n   EMail: sob@harvard.edu\n"
