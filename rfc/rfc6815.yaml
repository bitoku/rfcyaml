- title: __initial_text__
  contents:
  - "                 Applicability Statement for RFC 2544:\n             Use on Production\
    \ Networks Considered Harmful\n"
- title: Abstract
  contents:
  - "Abstract\n   The Benchmarking Methodology Working Group (BMWG) has been developing\n\
    \   key performance metrics and laboratory test methods since 1990, and\n   continues\
    \ this work at present.  The methods described in RFC 2544\n   are intended to\
    \ generate traffic that overloads network device\n   resources in order to assess\
    \ their capacity.  Overload of shared\n   resources would likely be harmful to\
    \ user traffic performance on a\n   production network, and there are further\
    \ negative consequences\n   identified with production application of the methods.\
    \  This memo\n   clarifies the scope of RFC 2544 and other IETF BMWG benchmarking\
    \ work\n   for isolated test environments only, and it encourages new standards\n\
    \   activity for measurement methods applicable outside that scope.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6815.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2012 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \      1.1. Requirements Language ......................................4\n  \
    \ 2. Scope and Goals .................................................4\n   3.\
    \ The Concept of an Isolated Test Environment .....................4\n   4. Why\
    \ the Methods of RFC 2544 Are Intended Only for ITE ...........4\n      4.1. Experimental\
    \ Control and Accuracy ..........................4\n      4.2. Containing Damage\
    \ ..........................................5\n   5. Advisory on RFC 2544 Methods\
    \ in Production Networks .............5\n   6. Considering Performance Testing\
    \ in Production Networks ..........6\n   7. Security Considerations .........................................7\n\
    \   8. Acknowledgements ................................................7\n  \
    \ 9. References ......................................................8\n    \
    \  9.1. Normative References .......................................8\n      9.2.\
    \ Informative References .....................................8\n   Appendix A.\
    \ Example of RFC 2544 Method Failure in Production\n               Network Measurement\
    \ ....................................9\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This memo clarifies the scope and use of IETF Benchmarking\n\
    \   Methodology Working Group (BMWG) tests including [RFC2544], which\n   discusses\
    \ and defines several tests that may be used to characterize\n   the performance\
    \ of a network interconnecting device.  All readers of\n   this memo must read\
    \ and fully understand [RFC2544].\n   Benchmarking methodologies (beginning with\
    \ [RFC2544]) have always\n   relied on test conditions that can only be produced\
    \ and replicated\n   reliably in the laboratory.  These methodologies are not\
    \ appropriate\n   for inclusion in wider specifications such as:\n   1.  Validation\
    \ of telecommunication service configuration, such as\n       the Committed Information\
    \ Rate (CIR).\n   2.  Validation of performance metrics in a telecommunication\
    \ Service\n       Level Agreement (SLA), such as frame loss and latency.\n   3.\
    \  Telecommunication service activation testing, where traffic that\n       shares\
    \ network resources with the test might be adversely\n       affected.\n   Above,\
    \ we distinguish \"telecommunication service\" (where a network\n   service provider\
    \ contracts with a customer to transfer information\n   between specified interfaces\
    \ at different geographic locations) from\n   the generic term \"service\".  Below,\
    \ we use the adjective \"production\"\n   to refer to networks carrying live user\
    \ traffic.  [RFC2544] used the\n   term \"real-world\" to refer to production\
    \ networks and to\n   differentiate them from test networks.\n   Although [RFC2544]\
    \ has been held up as the standard reference for the\n   testing listed above,\
    \ we believe that the actual methods used vary\n   from [RFC2544] in significant\
    \ ways.  Since the only citation is to\n   [RFC2544], the modifications are opaque\
    \ to the standards community\n   and to users in general.\n   Since applying the\
    \ test traffic and methods described in [RFC2544] on\n   a production network\
    \ risks causing overload in shared resources,\n   there is direct risk of harming\
    \ user traffic if the methods are\n   misused in this way.  Therefore, the IETF\
    \ BMWG developed this\n   Applicability Statement for [RFC2544] to directly address\
    \ the\n   situation.\n"
- title: 1.1.  Requirements Language
  contents:
  - "1.1.  Requirements Language\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\"\
    , \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"\
    MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in RFC 2119 [RFC2119].\n"
- title: 2.  Scope and Goals
  contents:
  - "2.  Scope and Goals\n   This memo clarifies the scope of [RFC2544] with the goal\
    \ of providing\n   guidance to the industry on its applicability, which is limited\
    \ to\n   laboratory testing.\n"
- title: 3.  The Concept of an Isolated Test Environment
  contents:
  - "3.  The Concept of an Isolated Test Environment\n   An Isolated Test Environment\
    \ (ITE) used with the methods of [RFC2544]\n   (as illustrated in Figures 1 through\
    \ 3 of [RFC2544]) has the ability\n   to:\n   o  contain the test streams to paths\
    \ within the desired setup\n   o  prevent non-test traffic from traversing the\
    \ test setup\n   These features allow unfettered experimentation, while at the\
    \ same\n   time protecting lab equipment management/control LANs and other\n \
    \  production networks from the unwanted effects of the test traffic.\n"
- title: 4.  Why the Methods of RFC 2544 Are Intended Only for ITE
  contents:
  - "4.  Why the Methods of RFC 2544 Are Intended Only for ITE\n   The following sections\
    \ discuss some of the reasons why [RFC2544]\n   methods are applicable only for\
    \ isolated laboratory use, and the\n   consequences of applying these methods\
    \ outside the lab environment.\n"
- title: 4.1.  Experimental Control and Accuracy
  contents:
  - "4.1.  Experimental Control and Accuracy\n   All of the tests described in RFC\
    \ 2544 require that the tester and\n   device under test are the only devices\
    \ on the networks that are\n   transmitting data.  The presence of other traffic\
    \ (unwanted on the\n   ITE network) would mean that the specified test conditions\
    \ have not\n   been achieved and flawed results are a likely consequence.\n  \
    \ If any other traffic appears and the amount varies over time, the\n   repeatability\
    \ of any test result will likely depend to some degree on\n   the amount and variation\
    \ of the other traffic.\n   The presence of other traffic makes accurate, repeatable,\
    \ and\n   consistent measurements of the performance of the device under test\n\
    \   very unlikely, since the complete details of test conditions will not\n  \
    \ be reported.\n   For example, the RFC 2544 Throughput Test attempts to characterize\
    \ a\n   maximum reliable load; thus, there will be testing above the maximum\n\
    \   that causes packet/frame loss.  Any other sources of traffic on the\n   network\
    \ will cause packet loss to occur at a tester data rate lower\n   than the rate\
    \ that would be achieved without the extra traffic.\n"
- title: 4.2.  Containing Damage
  contents:
  - "4.2.  Containing Damage\n   [RFC2544] methods, specifically to determine Throughput\
    \ as defined in\n   [RFC1242] and other benchmarks, may overload the resources\
    \ of the\n   device under test, and they may cause failure modes in the device\n\
    \   under test.  Since failures can become the root cause of more\n   widespread\
    \ failure, it is clearly desirable to contain all test\n   traffic within the\
    \ ITE.\n   In addition, such testing can have a negative effect on any traffic\n\
    \   that shares resources with the test stream(s) since, in most cases,\n   the\
    \ traffic load will be close to the capacity of the network links.\n   Appendix\
    \ C.2.2 of [RFC2544] (as adjusted by errata) gives the private\n   IPv4 address\
    \ range for testing:\n   \"...The network addresses 198.18.0.0 through 198.19.255.255\
    \ have been\n   assigned to the BMWG by the IANA for this purpose.  This assignment\n\
    \   was made to minimize the chance of conflict in case a testing device\n   were\
    \ to be accidentally connected to part of the Internet.  The\n   specific use\
    \ of the addresses is detailed below.\"\n   In other words, devices operating\
    \ on the Internet may be configured\n   to discard any traffic they observe in\
    \ this address range, as it is\n   intended for laboratory ITE use only.  Thus,\
    \ if testers using the\n   assigned testing address ranges are connected to the\
    \ Internet and\n   test packets are forwarded across the Internet, it is likely\
    \ that the\n   packets will be discarded and the test will not work.\n   We note\
    \ that a range of IPv6 addresses has been assigned to BMWG for\n   laboratory\
    \ test purposes, in [RFC5180] (as amended by errata).\n   See the Security Considerations\
    \ section below for further\n   considerations on containing damage.\n"
- title: 5.  Advisory on RFC 2544 Methods in Production Networks
  contents:
  - "5.  Advisory on RFC 2544 Methods in Production Networks\n   The tests in [RFC2544]\
    \ were designed to measure the performance of\n   network devices, not of networks,\
    \ and certainly not production\n   networks carrying user traffic on shared resources.\
    \  There will be\n   undesirable consequences when applying these methods outside\
    \ the\n   isolated test environment.\n   One negative consequence stems from reliance\
    \ on frame loss as an\n   indicator of resource exhaustion in [RFC2544] methods.\
    \  In practice,\n   link-layer and physical-layer errors prevent production networks\
    \ from\n   operating loss-free.  The [RFC2544] methods will not correctly assess\n\
    \   Throughput when loss from uncontrolled sources is present.  Frame\n   loss\
    \ occurring at the SLA levels of some networks could affect every\n   iteration\
    \ of Throughput testing (when each step includes sufficient\n   packets to experience\
    \ facility-related loss).  Flawed results waste\n   the time and resources of\
    \ the testing service user and of the service\n   provider when called to dispute\
    \ the measurement.  These are\n   additional examples of harm that compliance\
    \ with this advisory should\n   help to avoid.  See Appendix A for an example.\n\
    \   The methods described in [RFC2544] are intended to generate traffic\n   that\
    \ overloads network device resources in order to assess their\n   capacity.  Overload\
    \ of shared resources would likely be harmful to\n   user traffic performance\
    \ on a production network.  These tests MUST\n   NOT be used on production networks\
    \ and as discussed above.  The tests\n   will not produce a reliable or accurate\
    \ benchmarking result on a\n   production network.\n   [RFC2544] methods have\
    \ never been validated on a network path, even\n   when that path is not part\
    \ of a production network and carrying no\n   other traffic.  It is unknown whether\
    \ the tests can be used to\n   measure valid and reliable performance of a multi-device,\
    \ multi-\n   network path.  It is possible that some of the tests may prove valid\n\
    \   in some path scenarios, but that work has not been done or has not\n   been\
    \ shared with the IETF community.  Thus, such testing is\n   contraindicated by\
    \ the BMWG.\n"
- title: 6.  Considering Performance Testing in Production Networks
  contents:
  - "6.  Considering Performance Testing in Production Networks\n   The IETF has addressed\
    \ the problem of production network performance\n   measurement by chartering\
    \ a different working group: IP Performance\n   Metrics (IPPM).  This working\
    \ group has developed a set of standard\n   metrics to assess the quality, performance,\
    \ and reliability of\n   Internet packet transfer services.  These metrics can\
    \ be measured by\n   network operators, end users, or independent testing groups.\
    \  We note\n   that some IPPM metrics differ from RFC 2544 metrics with similar\n\
    \   names, and there is likely to be confusion if the details are\n   ignored.\n\
    \   IPPM has not yet standardized methods for raw capacity measurement of\n  \
    \ Internet paths.  Such testing needs to adequately consider the strong\n   possibility\
    \ for degradation to any other traffic that may be present\n   due to congestion.\
    \  There are no specific methods proposed for\n   activation of a packet transfer\
    \ service in IPPM at this time.  Thus,\n   individuals who need to conduct capacity\
    \ tests on production networks\n   should actively participate in standards development\
    \ to ensure their\n   methods receive appropriate industry review and agreement,\
    \ in the\n   IETF or in alternate standards development organizations.\n   Other\
    \ standards may help to fill gaps in telecommunication service\n   testing.  For\
    \ example, the IETF has many standards intended to assist\n   with network Operations,\
    \ Administration, and Maintenance (OAM).\n   ITU-T Study Group 12 has a Recommendation\
    \ on service activation test\n   methodology [Y.1564].\n   The world will not\
    \ spin off axis while waiting for appropriate and\n   standardized methods to\
    \ emerge from the consensus process.\n"
- title: 7.  Security Considerations
  contents:
  - "7.  Security Considerations\n   This Applicability Statement intends to help\
    \ preserve the security of\n   the Internet by clarifying that the scope of [RFC2544]\
    \ and other BMWG\n   memos are all limited to testing in a laboratory ITE, thus\
    \ avoiding\n   accidental Denial-of-Service attacks or congestion due to high\n\
    \   traffic volume test streams.\n   All benchmarking activities are limited to\
    \ technology\n   characterization using controlled stimuli in a laboratory\n \
    \  environment, with dedicated address space and the other constraints\n   [RFC2544].\n\
    \   The benchmarking network topology will be an independent test setup\n   and\
    \ MUST NOT be connected to devices that may forward the test\n   traffic into\
    \ a production network or misroute traffic to the test\n   management network.\n\
    \   Further, benchmarking is performed on a \"black-box\" basis, relying\n   solely\
    \ on measurements observable external to the device under test/\n   system under\
    \ test (DUT/SUT).\n   Special capabilities SHOULD NOT exist in the DUT/SUT specifically\
    \ for\n   benchmarking purposes.  Any implications for network security arising\n\
    \   from the DUT/SUT SHOULD be identical in the lab and in production\n   networks.\n"
- title: 8.  Acknowledgements
  contents:
  - "8.  Acknowledgements\n   Thanks to Matt Zekauskas, Bill Cerveny, Barry Constantine,\
    \ Curtis\n   Villamizar, David Newman, and Adrian Farrel for suggesting\n   improvements\
    \ to this memo.\n   Specifically, Al Morton would like to thank his coauthors,\
    \ who\n   constitute the complete set of Chairmen-Emeritus of the BMWG, for\n\
    \   returning from other pursuits to develop this statement and see it\n   through\
    \ to approval.  This has been a rare privilege; one that likely\n   will not be\
    \ matched in the IETF again:\n      Scott Bradner   served as Chairman from 1990\
    \ to 1993\n      Jim McQuaid     served as Chairman from 1993 to 1995\n      Kevin\
    \ Dubray    served as Chairman from 1995 to 2006\n   It's all about the band.\n"
- title: 9.  References
  contents:
  - '9.  References

    '
- title: 9.1.  Normative References
  contents:
  - "9.1.  Normative References\n   [RFC1242]  Bradner, S., \"Benchmarking terminology\
    \ for network\n              interconnection devices\", RFC 1242, July 1991.\n\
    \   [RFC2119]  Bradner, S., \"Key words for use in RFCs to Indicate\n        \
    \      Requirement Levels\", BCP 14, RFC 2119, March 1997.\n   [RFC2544]  Bradner,\
    \ S. and J. McQuaid, \"Benchmarking Methodology for\n              Network Interconnect\
    \ Devices\", RFC 2544, March 1999.\n   [RFC5180]  Popoviciu, C., Hamza, A., Van\
    \ de Velde, G., and D.\n              Dugatkin, \"IPv6 Benchmarking Methodology\
    \ for Network\n              Interconnect Devices\", RFC 5180, May 2008.\n"
- title: 9.2.  Informative References
  contents:
  - "9.2.  Informative References\n   [Bryant]   Bonica, R. and S. Bryant, \"RFC2544\
    \ Testing in Production\n              Network\", Work in Progress, October 2012.\n\
    \   [Y.1564]   ITU-T Recommendation Y.1564, \"Ethernet Service Activation\n  \
    \            Test Methodology\", March 2011.\n"
- title: Appendix A.  Example of RFC 2544 Method Failure in Production Network
  contents:
  - "Appendix A.  Example of RFC 2544 Method Failure in Production Network\n     \
    \        Measurement\n   This Appendix provides an example illustrating how [RFC2544]\
    \ methods\n   applied on production networks can easily produce a form of harm\
    \ from\n   flawed and misleading results.\n   The [RFC2544] Throughput benchmarking\
    \ method usually includes the\n   following steps:\n   a.  Set the offered traffic\
    \ level, less than max of the ingress\n       link(s).\n   b.  Send the test traffic\
    \ through the device under test (DUT) and\n       count all frames successfully\
    \ transferred.\n   c.  If all frames are received, increment traffic level and\
    \ repeat\n       step b.\n   d.  If one or more frames are lost, the level is\
    \ in the DUT-overload\n       region (step b may be repeated at a reduced traffic\
    \ level to more\n       exactly determine the maximum rate at which none of the\
    \ frames\n       are dropped by the DUT, defined as the Throughput [RFC1242]).\n\
    \   e.  Report the Throughput values, the x-y of graph of frame size and\n   \
    \    Throughput, and other information in accordance with [RFC2544].\n   In this\
    \ method, frame loss is the sole indicator of overload and\n   therefore the determining\
    \ factor in the measurement of Throughput\n   using the [RFC2544] methodology\
    \ (even though the results may not\n   report frame loss per se).\n   Frame loss\
    \ is subject to many factors in addition to operating above\n   the Throughput\
    \ traffic level.  These factors include optical\n   interference (which may be\
    \ due to dirty interfaces, crossover from\n   other signals, fiber bend and temperature,\
    \ etc.) and electrical\n   interference (caused by local sources of radio signals,\
    \ electrical\n   spikes, solar particles, etc.).  In the laboratory environment\
    \ many\n   of these issues can be carefully controlled through cleaning and\n\
    \   isolation.  Since [RFC2544] methodologies are primarily intended to\n   test\
    \ devices and not paths, the total length of path, the number of\n   interfaces,\
    \ and compound risk of random frame loss can be kept to a\n   minimum.\n   In\
    \ a production network, however, there will be many interfaces and\n   many kilometers\
    \ of path under test.  This considerably increases the\n   risk of random frame\
    \ loss.\n   The risk of frame loss caused by outside effects is significantly\n\
    \   higher in production networks, and significantly higher with long\n   paths\
    \ (both those with long physical path lengths, and those with\n   large numbers\
    \ of interfaces in the path).  Thus, the risk of falsely\n   low reported Throughput\
    \ using an [RFC2544] methodology test is\n   considerably increased in a production\
    \ network.\n   Therefore, to successfully conduct tests with similar objectives\
    \ to\n   those in [RFC2544] in a production network, it will be necessary to\n\
    \   develop modifications to the methodologies defined in [RFC2544] and\n   standards\
    \ to describe them.  See [Bryant] for an in-progress effort\n   and [Y.1564] for\
    \ an approved method adapted to production service\n   activation.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Scott Bradner\n   Harvard University\n   1350 Mass. Ave.,\
    \ Room 760\n   Cambridge, MA  02138\n   USA\n   Phone: +1 617 495 3864\n   EMail:\
    \ sob@harvard.edu\n   URI:   http://www.sobco.com\n   Kevin Dubray\n   Juniper\
    \ Networks\n   Jim McQuaid\n   Turnip Video\n   6 Cobbleridge Court\n   Durham,\
    \ North Carolina  27713\n   USA\n   Phone: +1 919-619-3220\n   EMail: jim@turnipvideo.com\n\
    \   URI:   www.turnipvideo.com\n   Al Morton\n   AT&T Labs\n   200 Laurel Avenue\
    \ South\n   Middletown,, NJ  07748\n   USA\n   Phone: +1 732 420 1571\n   Fax:\
    \   +1 732 368 1192\n   EMail: acmorton@att.com\n   URI:   http://home.comcast.net/~acmacm/\n"
