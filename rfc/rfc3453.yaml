- title: __initial_text__
  contents:
  - '    The Use of Forward Error Correction (FEC) in Reliable Multicast

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2002).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This memo describes the use of Forward Error Correction (FEC) codes\n\
    \   to efficiently provide and/or augment reliability for one-to-many\n   reliable\
    \ data transport using IP multicast.  One of the key\n   properties of FEC codes\
    \ in this context is the ability to use the\n   same packets containing FEC data\
    \ to simultaneously repair different\n   packet loss patterns at multiple receivers.\
    \  Different classes of FEC\n   codes and some of their basic properties are described\
    \ and\n   terminology relevant to implementing FEC in a reliable multicast\n \
    \  protocol is introduced.  Examples are provided of possible abstract\n   formats\
    \ for packets carrying FEC.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Rationale and Overview . . . . . . . . . . . . . . .\
    \ . . . . .   2\n     1.1. Application of FEC codes . . . . . . . . . . . . .\
    \ . . . .   5\n   2. FEC Codes. . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .   6\n     2.1. Simple codes . . . . . . . . . . . . . . . . . . . . .\
    \ . .   6\n     2.2. Small block FEC codes. . . . . . . . . . . . . . . . . .\
    \ .   8\n     2.3. Large block FEC codes. . . . . . . . . . . . . . . . . . .\
    \  10\n     2.4. Expandable FEC codes . . . . . . . . . . . . . . . . . . .  11\n\
    \     2.5. Source blocks with variable length source symbols. . . . .  13\n  \
    \ 3. Security Considerations. . . . . . . . . . . . . . . . . . . .  14\n   4.\
    \ Intellectual Property Disclosure . . . . . . . . . . . . . . .  14\n   5. Acknowledgments.\
    \ . . . . . . . . . . . . . . . . . . . . . . .  15\n   6. References . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . .  15\n   7. Authors' Addresses .\
    \ . . . . . . . . . . . . . . . . . . . . .  17\n   8. Full Copyright Statement\
    \ . . . . . . . . . . . . . . . . . . .  18\n"
- title: 1.  Rationale and Overview
  contents:
  - "1.  Rationale and Overview\n   There are many ways to provide reliability for\
    \ transmission\n   protocols.  A common method is to use ARQ, automatic request\
    \ for\n   retransmission.  With ARQ, receivers use a back channel to the sender\n\
    \   to send requests for retransmission of lost packets.  ARQ works well\n   for\
    \ one-to-one reliable protocols, as evidenced by the pervasive\n   success of\
    \ TCP/IP.  ARQ has also been an effective reliability tool\n   for one-to-many\
    \ reliability protocols, and in particular for some\n   reliable IP multicast\
    \ protocols.  However, for one-to-very-many\n   reliability protocols, ARQ has\
    \ limitations, including the feedback\n   implosion problem because many receivers\
    \ are transmitting back to the\n   sender, and the need for a back channel to\
    \ send these requests from\n   the receiver.  Another limitation is that receivers\
    \ may experience\n   different loss patterns of packets, and thus receivers may\
    \ be delayed\n   by retransmission of packets that other receivers have lost that\
    \ but\n   they have already received.  This may also cause wasteful use of\n \
    \  bandwidth used to retransmit packets that have already been received\n   by\
    \ many of the receivers.\n   In environments where ARQ is either costly or impossible\
    \ because\n   there is either a very limited capacity back channel or no back\n\
    \   channel at all, such as satellite transmission, a Data Carousel\n   approach\
    \ to reliability is sometimes used [1].  With a Data Carousel,\n   the sender\
    \ partitions the object into equal length pieces of data,\n   which we hereafter\
    \ call source symbols, places them into packets, and\n   then continually cycles\
    \ through and sends these packets.  Receivers\n   continually receive packets\
    \ until they have received a copy of each\n   packet.  Data Carousel has the advantage\
    \ that it requires no back\n   channel because there is no data that flows from\
    \ receivers to the\n   sender.  However, Data Carousel also has limitations. \
    \ For example,\n   if a receiver loses a packet in one round of transmission it\
    \ must\n   wait an entire round before it has a chance to receive that packet\n\
    \   again.  This may also cause wasteful use of bandwidth, as the sender\n   continually\
    \ cycles through and transmits the packets until no\n   receiver is missing a\
    \ packet.\n   Forward Error Correction (FEC) codes provide a reliability method\n\
    \   that can be used to augment or replace other reliability methods,\n   especially\
    \ for one-to-many reliability protocols such as reliable IP\n   multicast.  We\
    \ first briefly review some of the basic properties and\n   types of FEC codes\
    \ before reviewing their uses in the context of\n   reliable IP multicast.  Later,\
    \ we provide a more detailed description\n   of some of FEC codes.\n   In the\
    \ general literature, FEC refers to the ability to overcome both\n   erasures\
    \ (losses) and bit-level corruption.  However, in the case of\n   an IP multicast\
    \ protocol, the network layers will detect corrupted\n   packets and discard them\
    \ or the transport layers can use packet\n   authentication to discard corrupted\
    \ packets.  Therefore the primary\n   application of FEC codes to IP multicast\
    \ protocols is as an erasure\n   code.  The payloads are generated and processed\
    \ using an FEC erasure\n   encoder and objects are reassembled from reception\
    \ of packets\n   containing the generated encoding using the corresponding FEC\
    \ erasure\n   decoder.\n   The input to an FEC encoder is some number k of equal\
    \ length source\n   symbols.  The FEC encoder generates some number of encoding\
    \ symbols\n   that are of the same length as the source symbols.  The chosen length\n\
    \   of the symbols can vary upon each application of the FEC encoder, or\n   it\
    \ can be fixed.  These encoding symbols are placed into packets for\n   transmission.\
    \  The number of encoding symbols placed into each packet\n   can vary on a per\
    \ packet basis, or a fixed number of symbols (often\n   one) can be placed into\
    \ each packet.  Also, in each packet is placed\n   enough information to identify\
    \ the particular encoding symbols\n   carried in that packet.  Upon receipt of\
    \ packets containing encoding\n   symbols, the receiver feeds these encoding symbols\
    \ into the\n   corresponding FEC decoder to recreate an exact copy of the k source\n\
    \   symbols.  Ideally, the FEC decoder can recreate an exact copy from\n   any\
    \ k of the encoding symbols.\n   In a later section, we describe a technique for\
    \ using FEC codes as\n   described above to handle blocks with variable length\
    \ source symbols.\n   Block FEC codes work as follows.  The input to a block FEC\
    \ encoder is\n   k source symbols and a number n.  The encoder generates a total\
    \ of n\n   encoding symbols.  The encoder is systematic if it generates n-k\n\
    \   redundant symbols yielding an encoding block of n encoding symbols in\n  \
    \ total composed of the k source symbols and the n-k redundant symbols.\n   A\
    \ block FEC decoder has the property that any k of the n encoding\n   symbols\
    \ in the encoding block is sufficient to reconstruct the\n   original k source\
    \ symbols.\n   Expandable FEC codes work as follows.  An expandable FEC encoder\n\
    \   takes as input k source symbols and generates as many unique encoding\n  \
    \ symbols as requested on demand, where the amount of time for\n   generating\
    \ each encoding symbol is the same independent of how many\n   encoding symbols\
    \ are generated.  An expandable FEC decoder has the\n   property that any k of\
    \ the unique encoding symbols is sufficient to\n   reconstruct the original k\
    \ source symbols.\n   The above definitions explain the ideal situation when the\
    \ reception\n   of any k encoding symbols is sufficient to recover the k source\n\
    \   symbols, in which case the reception overhead is 0%.  For some\n   practical\
    \ FEC codes, slightly more than k encoding symbols are needed\n   to recover the\
    \ k source symbols.  If k*(1+ep) encoding symbols are\n   needed, we say the reception\
    \ overhead is ep*100%, e.g., if k*1.05\n   encoding symbols are needed then the\
    \ reception overhead is 5%.\n   Along a different dimension, we classify FEC codes\
    \ loosely as being\n   either small or large.  A small FEC code is efficient in\
    \ terms of\n   processing time requirements for encoding and decoding for small\n\
    \   values of k, and a large FEC code is efficient for encoding and\n   decoding\
    \ for much large values of k.  There are implementations of\n   block FEC codes\
    \ that have encoding times proportional to n-k times\n   the length of the k source\
    \ symbols, and decoding times proportional\n   to l times the length of the k\
    \ source symbols, where l is the number\n   of missing source symbols among the\
    \ k received encoding symbols and l\n   can be as large as k.  Because of the\
    \ growth rate of the encoding and\n   decoding times as a product of k and n-k,\
    \ these are typically\n   considered to be small block FEC codes.  There are block\
    \ FEC codes\n   with a small reception overhead that can generate n encoding symbols\n\
    \   and can decode the k source symbols in time proportional to the\n   length\
    \ of the n encoding symbols.  These codes are considered to be\n   large block\
    \ FEC codes.  There are expandable FEC codes with a small\n   reception overhead\
    \ that can generate each encoding symbol in time\n   roughly proportional to its\
    \ length, and can decode all k source\n   symbols in time roughly proportional\
    \ to their length.  These are\n   considered to be large expandable FEC codes.\
    \  We describe examples of\n   all of these types of codes later.\n   Ideally,\
    \ FEC codes in the context of IP multicast can be used to\n   generate encoding\
    \ symbols that are transmitted in packets in such a\n   way that each received\
    \ packet is fully useful to a receiver to\n   reassemble the object regardless\
    \ of previous packet reception\n   patterns.  Thus, if some packets are lost in\
    \ transit between the\n   sender and the receiver, instead of asking for specific\n\
    \   retransmission of the lost packets or waiting till the packets are\n   resent\
    \ using Data Carousel, the receiver can use any other subsequent\n   equal number\
    \ of packets that arrive to reassemble the object.  These\n   packets can either\
    \ be proactively transmitted or they can be\n   explicitly requested by receivers.\
    \  This implies that the same packet\n   is fully useful to all receivers to reassemble\
    \ the object, even\n   though the receivers may have previously experienced different\
    \ packet\n   loss patterns.  This property can reduce or even eliminate the\n\
    \   problems mentioned above associated with ARQ and Data Carousel and\n   thereby\
    \ dramatically increase the scalability of the protocol to\n   orders of magnitude\
    \ more receivers.\n"
- title: 1.1.  Application of FEC codes
  contents:
  - "1.1.  Application of FEC codes\n   For some reliable IP multicast protocols,\
    \ FEC codes are used in\n   conjunction with ARQ to provide reliability.  For\
    \ example, a large\n   object could be partitioned into a number of source blocks\
    \ consisting\n   of a small number of source symbols each, and in a first round\
    \ of\n   transmission all of the source symbols for all the source blocks\n  \
    \ could be transmitted.  Then, receivers could report back to the\n   sender the\
    \ number of source symbols they are missing from each source\n   block.  The sender\
    \ could then compute the maximum number of missing\n   source symbols from each\
    \ source block among all receivers.  Based on\n   this, a small block FEC encoder\
    \ could be used to generate for each\n   source block a number of redundant symbols\
    \ equal to the computed\n   maximum number of missing source symbols from the\
    \ block among all\n   receivers, as long as this maximum maximum for each block\
    \ does not\n   exceed the number of redundant symbols that can be generated\n\
    \   efficiently.  In a second round of transmission, the server would\n   then\
    \ send all of these redundant symbols for all blocks.  In this\n   example, if\
    \ there are no losses in the second round of transmission\n   then all receivers\
    \ will be able to recreate an exact copy of each\n   original block.  In this\
    \ case, even if different receivers are\n   missing different symbols in different\
    \ blocks, transmitted redundant\n   symbols for a given block are useful to all\
    \ receivers missing symbols\n   from that block in the second round.\n   For other\
    \ reliable IP multicast protocols, FEC codes are used in a\n   Data Carousel fashion\
    \ to provide reliability, which we call an FEC\n   Data Carousel.  For example,\
    \ an FEC Data Carousel using a large block\n   FEC code could work as follows.\
    \  The large block FEC encoder produces\n   n encoding symbols considering all\
    \ the k source symbols of an object\n   as one block.  The sender cycles through\
    \ and transmits the n encoding\n   symbols in packets in the same order in each\
    \ round.  An FEC Data\n   Carousel can have much better protection against packet\
    \ loss than a\n   Data Carousel.  For example, a receiver can join the transmission\
    \ at\n   any point in time, and, as long as the receiver receives at least k\n\
    \   encoding symbols during the transmission of the next n encoding\n   symbols,\
    \ the receiver can completely recover the object.  This is\n   true even if the\
    \ receiver starts receiving packets in the middle of a\n   pass through the encoding\
    \ symbols.  This method can also be used when\n   the object is partitioned into\
    \ blocks and a short block FEC code is\n   applied to each block separately. \
    \ In this case, as we explain in\n   more detail below, it is useful to interleave\
    \ the symbols from the\n   different blocks when they are transmitted.\n   Since\
    \ any number of encoding symbols can be generated using an\n   expandable FEC\
    \ encoder, reliable IP multicast protocols that use\n   expandable FEC codes generally\
    \ rely solely on these codes for\n   reliability.  For example, when an expandable\
    \ FEC code is used in a\n   FEC Data Carousel application, the encoding packets\
    \ never repeat, and\n   thus any k of the encoding symbols in the potentially\
    \ unbounded\n   number of encoding symbols are sufficient to recover the original\
    \ k\n   source symbols.\n   For additional reliable IP multicast protocols, the\
    \ method to obtain\n   reliability is to generate enough encoding symbols so that\
    \ each\n   encoding symbol is transmitted only once (at most).  For example, the\n\
    \   sender can decide a priori how many encoding symbols it will\n   transmit,\
    \ use an FEC code to generate that number of encoding symbols\n   from the object,\
    \ and then transmit the encoding symbols to all\n   receivers.  This method is\
    \ applicable to streaming protocols, for\n   example, where the stream is partitioned\
    \ into objects, the source\n   symbols for each object are encoded into encoding\
    \ symbols using an\n   FEC code, and then the sets of encoding symbols for each\
    \ object are\n   transmitted one after the other using IP multicast.\n"
- title: 2.  FEC Codes
  contents:
  - '2.  FEC Codes

    '
- title: 2.1.  Simple codes
  contents:
  - "2.1.  Simple codes\n   There are some very simple codes that are effective for\
    \ repairing\n   packet loss under very low loss conditions.  For example, to provide\n\
    \   protection from a single loss is to partition the object into fixed\n   size\
    \ source symbols and then add a redundant symbol that is the\n   parity (XOR)\
    \ of all the source symbols.  The size of a source symbol\n   is chosen so that\
    \ it fits perfectly into the payload of a packet,\n   i.e. if the packet payload\
    \ is 512 bytes then each source symbol is\n   512 bytes.  The header of each packet\
    \ contains enough information to\n   identify the payload.  This is an example\
    \ of encoding symbol ID.  The\n   encoding symbol IDs can consist of two parts\
    \ in this example.  The\n   first part is an encoding flag that is equal to 1\
    \ if the encoding\n   symbol is a source symbol and is equal to 0 if the encoding\
    \ symbol is\n   a redundant symbol.  The second part of the encoding symbol ID\
    \ is a\n   source symbol ID if the encoding flag is 1 and a redundant symbol ID\n\
    \   if the encoding flag is 0.  The source symbol IDs can be numbered\n   from\
    \ 0 to k-1 and the redundant symbol ID can be 0.  For example, if\n   the object\
    \ consists of four source symbols that have values a, b, c\n   and d, then the\
    \ value of the redundant symbol is e = a XOR b XOR c\n   XOR d.  Then, the packets\
    \ carrying these symbols look like:\n            (1, 0: a), (1, 1: b), (1, 2:\
    \ c), (1, 3: d), (0, 0: e).\n   In this example, the encoding symbol ID consists\
    \ of the first two\n   values, where the first value is the encoding flag and\
    \ the second\n   value is either a source symbol ID or the redundant symbol ID.\
    \  The\n   portion of the packet after the colon is the value of the encoding\n\
    \   symbol.  Any single source symbol of the object can be recovered as\n   the\
    \ parity of all the other symbols.  For example, if packets\n                \
    \  (1, 0: a), (1, 1: b), (1, 3: d), (0, 0: e)\n   are received then the missing\
    \ source symbol value with source symbol\n   ID = 2 can be recovered by computing\
    \ a XOR b XOR d XOR e = c.\n   Another way of forming the encoding symbol ID is\
    \ to let values\n   0,...,k-1 correspond to the k source symbols and value k correspond\n\
    \   to the redundant symbol that is the XOR of the k source symbols.\n   When\
    \ the number of source symbols in the object is large, a simple\n   block code\
    \ variant of the above can be used.  In this case, the\n   source symbols are\
    \ grouped together into source blocks of some number\n   k of consecutive symbols\
    \ each, where k may be different for different\n   blocks.  If a block consists\
    \ of k source symbols then a redundant\n   symbol is added to form an encoding\
    \ block consisting of k+1 encoding\n   symbols.  Then, a source block consisting\
    \ of k source symbols can be\n   recovered from any k of the k+1 encoding symbols\
    \ from the associated\n   encoding block.\n   Slightly more sophisticated ways\
    \ of adding redundant symbols using\n   parity can also be used.  For example,\
    \ one can group a block\n   consisting of k source symbols in an object into a\
    \ p x p square\n   matrix, where p = sqrt(k).  Then, for each row a redundant\
    \ symbol is\n   added that is the parity of all the source symbols in the row.\n\
    \   Similarly, for each column a redundant symbol is added that is the\n   parity\
    \ of all the source symbols in the column.  Then, any row of the\n   matrix can\
    \ be recovered from any p of the p+1 symbols in the row, and\n   similarly for\
    \ any column.  Higher dimensional product codes using\n   this technique can also\
    \ be used.  However, one must be wary of using\n   these constructions without\
    \ some thought towards the possible loss\n   patterns of symbols.  Ideally, the\
    \ property that one would like to\n   obtain is that if k source symbols are encoded\
    \ into n encoding\n   symbols (the encoding symbols consist of the source symbols\
    \ and the\n   redundant symbols) then the k source symbols can be recovered from\n\
    \   any k of the n encoding symbols.  Using the simple constructions\n   described\
    \ above does not yield codes that come close to obtaining\n   this ideal behavior.\n"
- title: 2.2.  Small block FEC codes
  contents:
  - "2.2.  Small block FEC codes\n   Reliable IP multicast protocols may use a block\
    \ (n, k) FEC code [2].\n   For such codes, k source symbols are encoded into n\
    \ > k encoding\n   symbols, such that any k of the encoding symbols can be used\
    \ to\n   reassemble the original k source symbols.  Thus, these codes have no\n\
    \   reception overhead when used to encode the entire object directly.\n   Block\
    \ codes are usually systematic, which means that the n encoding\n   symbols consist\
    \ of the k source symbols and n-k redundant symbols\n   generated from these k\
    \ source symbols, where the size of a redundant\n   symbol is the same as that\
    \ for a source symbol.  For example, the\n   first simple code (XOR) described\
    \ in the previous subsection is a\n   (k+1, k) code.  In general, the freedom\
    \ to choose n larger than k+1\n   is desirable, as this can provide much better\
    \ protection against\n   losses.  A popular example of these types of codes is\
    \ a class of\n   Reed-Solomon codes, which are based on algebraic methods using\
    \ finite\n   fields.  Implementations of (n, k) FEC erasure codes are efficient\n\
    \   enough to be used by personal computers [16].  For example, [15]\n   describes\
    \ an implementation where the encoding and decoding speeds\n   decay as C/j, where\
    \ the constant C is on the order of 10 to 80\n   Mbytes/second for Pentium class\
    \ machines of various vintages and j is\n   upper bounded by min(k, n-k).\n  \
    \ In practice, the values of k and n must be small (for example below\n   256)\
    \ for such FEC codes as large values make encoding and decoding\n   prohibitively\
    \ expensive.  As many objects are longer than k symbols\n   for reasonable values\
    \ of k and the symbol length (e.g. larger than 16\n   kilobyte for k = 16 using\
    \ 1 kilobyte symbols), they can be divided\n   into a number of source blocks.\
    \  Each source block consists of some\n   number k of source symbols, where k\
    \ may vary between different source\n   blocks.  The FEC encoder is used to encode\
    \ a k source symbol source\n   block into a n encoding symbol encoding block,\
    \ where the number n of\n   encoding symbols in the encoding block may vary for\
    \ each source\n   block.  For a receiver to completely recover the object, for\
    \ each\n   source block consisting of k source symbols, k distinct encoding\n\
    \   symbols (i.e., with different encoding symbol IDs) must be received\n   from\
    \ the corresponding encoding block.  For some encoding blocks,\n   more encoding\
    \ symbols may be received than there are source symbols\n   in the corresponding\
    \ source block, in which case the excess encoding\n   symbols are discarded. \
    \ An example encoding structure is shown in\n   Figure 1.\n       |   source symbol\
    \ IDs   |   source symbols IDs  |\n       |   of source block 0   |   of source\
    \ block 1   |\n                    |                          |\n            \
    \        v                          v\n       +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n\
    \       |0 |1 |2 |3 |4 |5 |6 |7 |0 |1 |2 |3 | 4|5 |6 |7 |\n       +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n\
    \                               |\n                           FEC encoder\n  \
    \                             |\n                               v\n   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n\
    \   |0 |1 |2 |3 | 4| 5| 6| 7| 8| 9| 0| 1| 2| 3| 4| 5| 6| 7| 8| 9|\n   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n\
    \                  ^                             ^\n                  |      \
    \                       |\n   |  encoding symbol IDs        | encoding symbol\
    \ IDs         |\n   |  of encoding block 0        | of encoding block 1      \
    \   |\n   Figure 1. The encoding structure for an object divided into two\n  \
    \ source blocks consisting of 8 source symbols each, and the FEC\n   encoder is\
    \ used to generate 2 additional redundant symbols (10\n   encoding symbols in\
    \ total) for each of the two source blocks.\n   In many cases, an object is partitioned\
    \ into equal length source\n   blocks each consisting of k contiguous source symbols\
    \ of the object,\n   i.e., block c consists of the range of source symbols [ck,\
    \ (c+1)k-1].\n   This ensures that the FEC encoder can be optimized to handle\
    \ a\n   particular number k of source symbols.  This also ensures that memory\n\
    \   references are local when the sender reads source symbols to encode,\n   and\
    \ when the receiver reads encoding symbols to decode.  Locality of\n   reference\
    \ is particularly important when the object is stored on\n   disk, as it reduces\
    \ the disk seeks required.  The block number and\n   the source symbol ID within\
    \ that block can be used to uniquely\n   specify a source symbol within the object.\
    \ If the size of the object\n   is not a multiple of k source symbols, then the\
    \ last source block\n   will contain less than k symbols.\n   The block numbers\
    \ can be numbered consecutively starting from zero.\n   Encoding symbols within\
    \ a block can be uniquely identified by an\n   encoding symbol ID.  One way of\
    \ identifying encoding symbols within a\n   block is to use the combination of\
    \ an encoding flag that identifies\n   the symbol as either a source symbol or\
    \ a redundant symbol together\n   with either a source symbol ID or a redundant\
    \ symbol ID.  For\n   example, an encoding flag value of 1 can indicate that the\
    \ encoding\n   symbol is a source symbol and 0 can indicate that it is a redundant\n\
    \   symbol.  The source symbol IDs can be numbered from 0 to k-1 and the\n   redundant\
    \ symbol IDs can be numbered from 0 to n-k-1.\n   For example, if the object consists\
    \ 10 source symbols with values a,\n   b, c, d, e, f, g, h, i, and j, and k =\
    \ 5 and n = 8, then there are\n   two source blocks consisting of 5 symbols each,\
    \ and there are two\n   encoding blocks consisting of 8 symbols each.  Let p,\
    \ q and r be the\n   values of the redundant symbols for the first encoding block,\
    \ and let\n   x, y and z be the values of the redundant symbols for the second\n\
    \   encoding block.  Then the encoding symbols together with their\n   identifiers\
    \ are\n   (0, 1, 0: a), (0, 1, 1: b), (0, 1, 2: c), (0, 1, 3: d), (0, 1, 4: e),\n\
    \   (0, 0, 0: p), (0, 0, 1: q), (0, 0, 2: r),\n   (1, 1, 0: f), (1, 1, 1: g),\
    \ (1, 1, 2: h), (1, 1, 3: i), (1, 1, 4: j),\n   (1, 0, 0: x), (1, 0, 1: y), (1,\
    \ 0, 2: z).\n   In this example, the first value identifies the block number and\
    \ the\n   second two values together identify the encoding symbol within the\n\
    \   block, i.e, the encoding symbol ID consists of the encoding flag\n   together\
    \ with either the source symbol ID or the redundant symbol ID\n   depending on\
    \ the value of the encoding flag.  The value of the\n   encoding symbol is written\
    \ after the colon.  Each block can be\n   recovered from any 5 of the 8 encoding\
    \ symbols associated with that\n   block.  For example, reception of\n    (0,\
    \ 1, 1: b), (0, 1, 2: c), (0, 1, 3: d), (0, 0, 0: p), (0, 0, 1: q)\n   is sufficient\
    \ to recover the first source block, and reception of\n    (1, 1, 0: f), (1, 1,\
    \ 1: g), (1, 0, 0: x), (1, 0, 1: y), (1, 0, 2: z)\n   is sufficient to recover\
    \ the second source block.\n   Another way of uniquely identifying encoding symbols\
    \ within a block\n   is to let the encoding symbol IDs for source symbols be 0,...,k-1\
    \ and\n   to let the encoding symbol IDs for redundant symbols be k,...,n-1.\n"
- title: 2.3.  Large block FEC codes
  contents:
  - "2.3.  Large block FEC codes\n   Tornado codes [12], [13], [10], [11], [9] are\
    \ large block FEC codes\n   that provide an alternative to small block FEC codes.\
    \  An (n, k)\n   Tornado code requires slightly more than k out of n encoding\
    \ symbols\n   to recover k source symbols, i.e., there is a small reception\n\
    \   overhead.  The benefit of the small cost of non-zero reception\n   overhead\
    \ is that the value of k may be on the order of tens of\n   thousands and still\
    \ the encoding and decoding are efficient.  Because\n   of memory considerations,\
    \ in practice the value of n is restricted to\n   be a small multiple of k, e.g.,\
    \ n = 2k.  For example, [4] describes\n   an implementation of Tornado codes where\
    \ the encoding and decoding\n   speeds are tens of megabytes per second for Pentium\
    \ class machines of\n   various vintages when k is in the tens of thousands and\
    \ n = 2k.  The\n   reception overhead for such values of k and n is in the 5-10%\
    \ range.\n   Tornado codes require a large amount of out of band information to\
    \ be\n   communicated to all senders and receivers for each different object\n\
    \   length, and require an amount of memory on the encoder and decoder\n   which\
    \ is proportional to the object length times 2n/k.\n   Tornado codes are designed\
    \ to have low reception overhead on average\n   with respect to reception of a\
    \ random portion of the encoding\n   packets.  Thus, to ensure that a receiver\
    \ can reassemble the object\n   with low reception overhead, the packets are permuted\
    \ into a random\n   order before transmission.\n"
- title: 2.4.  Expandable FEC codes
  contents:
  - "2.4.  Expandable FEC codes\n   All of the FEC codes described up to this point\
    \ are block codes.\n   There is a different type of FEC codes that we call expandable\
    \ FEC\n   codes.  Like block codes, an expandable FEC encoder operates on an\n\
    \   object of known size that is partitioned into equal length source\n   symbols.\
    \  Unlike block codes, there is no predetermined number of\n   encoding symbols\
    \ that can be generated for expandable FEC codes.\n   Instead, an expandable FEC\
    \ encoder can generate as few or as many\n   unique encoding symbols as required\
    \ on demand.\n   LT codes [6], [7], [8], [5] are an example of large expandable\
    \ FEC\n   codes with a small reception overhead.  An LT encoder uses\n   randomization\
    \ to generate each encoding symbol randomly and\n   independently of all other\
    \ encoding symbols.  Like Tornado codes, the\n   number of source symbols k may\
    \ be very large for LT codes, i.e., on\n   the order of tens to hundreds of thousands,\
    \ and the encoder and\n   decoder run efficiently in software.  For example the\
    \ encoding and\n   decoding speeds for LT codes are in the range 3-20 megabytes\
    \ per\n   second for Pentium class machines of various vintages when k is in\n\
    \   the high tens of thousands.  An LT encoder can generate as few or as\n   many\
    \ encoding symbols as required on demand.  When a new encoding\n   symbol is to\
    \ be generated by an LT encoder, it is based on a randomly\n   chosen encoding\
    \ symbol ID that uniquely describes how the encoding\n   symbol is to be generated\
    \ from the source symbols. In general, each\n   encoding symbol ID value corresponds\
    \ to a unique encoding symbol, and\n   thus the space of possible encoding symbols\
    \ is approximately four\n   billion if for example the encoding symbol ID is 4\
    \ bytes.  Thus, the\n   chance that a particular encoding symbol is the same as\
    \ any other\n   particular encoding symbol is inversely proportional to the number\
    \ of\n   possible encoding symbol IDs.  An LT decoder has the property that\n\
    \   with very high probability the receipt of any set of slightly more\n   than\
    \ k randomly and independently generated encoding symbols is\n   sufficient to\
    \ reassemble the k source symbols.  For example, when k\n   is on the order of\
    \ tens to hundreds of thousands the reception\n   overhead is less than 5% with\
    \ no failures in hundreds of millions of\n   trials under any loss conditions.\n\
    \   Because encoding symbols are randomly and independently generated by\n   choosing\
    \ random encoding symbol IDs, LT codes have the property that\n   encoding symbols\
    \ for the same k source symbols can be generated and\n   transmitted from multiple\
    \ senders and received by a receiver and the\n   reception overhead and the decoding\
    \ time is the same as if though all\n   the encoding symbols were generated by\
    \ a single sender.  The only\n   requirement is that the senders choose their\
    \ encoding symbol IDs\n   randomly and independently of one another.\n   There\
    \ is a weak tradeoff between the number of source symbols and the\n   reception\
    \ overhead for LT codes, and the larger the number of source\n   symbols the smaller\
    \ the reception overhead.  Thus, for shorter\n   objects, it is sometimes advantageous\
    \ to partition the object into\n   many short source symbols and include multiple\
    \ encoding symbols in\n   each packet.  In this case, a single encoding symbol\
    \ ID is used to\n   identify the multiple encoding symbols contained in a single\
    \ packet.\n   There are a couple of factors for choosing the appropriate symbol\n\
    \   length/ number of source symbols tradeoff. The primary consideration\n   is\
    \ that there is a fixed overhead per symbol in the overall\n   processing requirements\
    \ of the encoding and decoding, independent of\n   the number of source symbols.\
    \  Thus, using shorter symbols means that\n   this fixed overhead processing per\
    \ symbol will be a larger component\n   of the overall processing requirements,\
    \ leading to larger overall\n   processing requirements.  A second much less important\
    \ consideration\n   is that there is a component of the processing per symbol\
    \ that\n   depends logarithmically on the number of source symbols, and thus for\n\
    \   this reason there is a slight preference towards fewer source\n   symbols.\n\
    \   Like small block codes, there is a point when the object is large\n   enough\
    \ that it makes sense to partition it into blocks when using LT\n   codes.  Generally\
    \ the object is partitioned into blocks whenever the\n   number of source symbols\
    \ times the packet payload length is less than\n   the size of the object.  Thus,\
    \ if the packet payload is 1024 bytes\n   and the maximum number of source symbols\
    \ is 128,000 then any object\n   over 128 megabytes will be partitioned into more\
    \ than one block.  One\n   can choose the maximum number of source symbols to\
    \ use, depending on\n   the desired encoding and decoding speed versus reception\
    \ overhead\n   tradeoff desired.  Encoding symbols can be uniquely identified\
    \ by a\n   block number (when the object is large enough to be partitioned into\n\
    \   more than one block) and an encoding symbol ID.  The block numbers,\n   if\
    \ they are used, are generally numbered consecutively starting from\n   zero within\
    \ the object.  The block number and the encoding symbol ID\n   are both chosen\
    \ uniformly and randomly from their range when an\n   encoding symbol is to be\
    \ transmitted.  For example, suppose the\n   number of source symbols is 128,000\
    \ and the number of blocks is 2.\n   Then, each packet generated by the LT encoder\
    \ could be of the form\n   (b, x: y).  In this example, the first value identifies\
    \ the block\n   number and the second value identifies the encoding symbol within\
    \ the\n   block.  In this example, the block number b is either 0 or 1, and the\n\
    \   encoding symbol ID x might be a 32-bit value.  The value y after the\n   colon\
    \ is the value of the encoding symbol.\n"
- title: 2.5.  Source blocks with variable length source symbols
  contents:
  - "2.5.  Source blocks with variable length source symbols\n   For all the FEC codes\
    \ described above, all the source symbols in the\n   same source block are all\
    \ of the same length.  In this section, we\n   describe a general technique to\
    \ handle the case when it is desirable\n   to use source symbols of varying lengths\
    \ in a single source block.\n   This technique is applicable to block FEC codes.\n\
    \   Let l_1, l_2, ... , l_k be the lengths in bytes of k varying length\n   source\
    \ symbols to be considered part of the same source block.  Let\n   lmax be the\
    \ maximum over i = 1, ... , k of l_i.  To prepare the\n   source block for the\
    \ FEC encoder, pad each source symbol i out to\n   length lmax with a suffix of\
    \ lmax-l_i zeroes, and then prepend to the\n   beginning of this the value l_i.\
    \  Thus, each padded source symbol is\n   of length x+lmax, assuming that it takes\
    \ x bytes to store an integer\n   with possible values 0,...,lmax, where x is\
    \ a protocol constant known\n   to both the encoder and the decoder.  These padded\
    \ source symbols,\n   each of length x+lmax, are the input to the encoder, together\
    \ with\n   the value n.  The encoder then generates n-k redundant symbols, each\n\
    \   of length x+lmax.\n   The encoding symbols that are placed into packets consist\
    \ of the\n   original k varying length source symbols and n-k redundant symbols,\n\
    \   each of length x+lmax.  From any k of the received encoding symbols,\n   the\
    \ FEC decoder recreates the k original source symbols as follows.\n   If all k\
    \ original source symbols are received, then no decoding is\n   necessary.  Otherwise,\
    \ at least one redundant symbol is received,\n   from which the receiver can easily\
    \ determine if the block is composed\n   of variable- length source symbols: if\
    \ the redundant symbol(s) is\n   longer than the source symbols then the source\
    \ symbols are variable-\n   length.  Note that in a variable-length block the\
    \ redundant symbols\n   are always longer than the longest source symbol, due\
    \ to the presence\n   of the prepended symbol- length.  The receiver can determine\
    \ the\n   value of lmax by subtracting x from the length of a received\n   redundant\
    \ symbol.  For each of the received original source symbols,\n   the receiver\
    \ can generate the corresponding padded source symbol as\n   described above.\
    \  Then, the input to the FEC decoder is the set of\n   received redundant symbols,\
    \ together with the set of padded source\n   symbols constructed from the received\
    \ original symbols.  The FEC\n   decoder then produces the set of k padded source\
    \ symbols.  Once the k\n   padded source symbols have been recovered, the length\
    \ l_i of original\n   source symbol i can be recovered from the first x bytes\
    \ of the ith\n   padded source symbol, and then original source symbol i is obtained\n\
    \   by taking the next l_i bytes following the x bytes of the length\n   field.\n"
- title: 3.  Security Considerations
  contents:
  - "3.  Security Considerations\n   The use of FEC, in and of itself, imposes no\
    \ additional security\n   considerations versus sending the same information without\
    \ FEC.\n   However, just like for any transmission system, a malicious sender\n\
    \   may try to inject packets carrying corrupted encoding symbols.  If a\n   receiver\
    \ accepts one or more corrupted encoding symbol, in place of\n   authentic ones,\
    \ then such a receiver may reconstruct a corrupted\n   object.\n   Application-level\
    \ transmission object authentication can detect the\n   corrupted transfer, but\
    \ the receiver must discard the transferred\n   object.  By injecting corrupted\
    \ encoding symbols, they are accepted\n   as valid encoding symbols by a receiver,\
    \ which at the very least, is\n   an effective denial of service attack.\n   In\
    \ light of this possibility, FEC receivers may screen the source\n   address of\
    \ a received symbol against a list of authentic transmitter\n   addresses.  Since\
    \ source addresses may be spoofed, transport\n   protocols using FEC may provide\
    \ mechanisms for robust source\n   authentication of each encoding symbol.  Multicast\
    \ routers along the\n   path of a FEC transfer may provide the capability of discarding\n\
    \   multicast packets that originated on that subnet, and whose source IP\n  \
    \ address does not correspond with that subnet.\n   It is recommended that a packet\
    \ authentication scheme such as TESLA\n   [14] be used in conjunction with FEC\
    \ codes.  Then, packets that\n   cannot be authenticated can be discarded and\
    \ the object can be\n   reliably recovered from the received authenticated packets.\n"
- title: 4.  Intellectual Property Disclosure
  contents:
  - "4.  Intellectual Property Disclosure\n   The IETF has been notified of intellectual\
    \ property rights claimed in\n   regard to some or all of the specification contained\
    \ in this\n   document.  For more information consult the online list of claimed\n\
    \   rights.\n"
- title: 5.  Acknowledgments
  contents:
  - "5.  Acknowledgments\n   Thanks to Vincent Roca and Hayder Radha for their detailed\
    \ comments\n   on this document.\n"
- title: 6.  References
  contents:
  - "6.  References\n   [1]  Acharya, S., Franklin, M. and S. Zdonik, \"Dissemination\
    \ - Based\n        Data Delivery Using Broadcast Disks\", IEEE Personal\n    \
    \    Communications, pp.50-60, Dec 1995.\n   [2]  Blahut, R.E., \"Theory and Practice\
    \ of Error Control Codes\",\n        Addison Wesley, MA, 1984.\n   [3]  Bradner,\
    \ S., \"The Internet Standards Process -- Revision 3\", BCP\n        9, RFC 2026,\
    \ October 1996.\n   [4]  Byers, J.W., Luby, M., Mitzenmacher, M. and A. Rege,\
    \ \"A Digital\n        Fountain Approach to Reliable Distribution of Bulk Data\"\
    ,\n        Proceedings ACM SIGCOMM '98, Vancouver, Canada, Sept 1998.\n   [5]\
    \  Haken, A., Luby, M., Horn, G., Hernek, D., Byers, J. and M.\n        Mitzenmacher,\
    \ \"Generating high weight encoding symbols using a\n        basis\", U.S. Patent\
    \ No. 6,411,223, June 25, 2002.\n   [6]  Luby, M., \"Information Additive Code\
    \ Generator and Decoder for\n        Communication Systems\", U.S. Patent No.\
    \ 6,307,487, October 23,\n        2001.\n   [7]  Luby, M., \"Information Additive\
    \ Group Code Generator and Decoder\n        for Communication Systems\", U.S.\
    \ Patent No. 6,320,520, November\n        20, 2001.\n   [8]  Luby, M., \"Information\
    \ Additive Code Generator and Decoder for\n        Communication Systems\", U.S.\
    \ Patent No. 6,373,406, April 16,\n        2002.\n   [9]  Luby, M. and M. Mitzenmacher,\
    \ \"Loss resilient code with double\n        heavy tailed series of redundant\
    \ layers\", U.S. Patent No.\n        6,195,777, February 27, 2001.\n   [10] Luby,\
    \ M., Mitzenmacher, M., Shokrollahi, A., Spielman, D. and V.\n        Stemann,\
    \ \"Message encoding with irregular graphing\", U.S. Patent\n        No. 6,163,870,\
    \ December 19, 2000.\n   [11] Luby, M., Mitzenmacher, M., Shokrollahi, A. and\
    \ D. Spielman,\n        \"Efficient Erasure Correcting Codes\", IEEE Transactions\
    \ on\n        Information Theory, Special Issue: Codes on Graphs and Iterative\n\
    \        Algorithms, pp.  569-584, Vol. 47, No. 2, February 2001.\n   [12] Luby,\
    \ M., Shokrollahi, A., Stemann, V., Mitzenmacher, M. and D.\n        Spielman,\
    \ \"Loss resilient decoding technique\", U.S. Patent No.\n        6,073,250, June\
    \ 6, 2000.\n   [13] Luby, M., Shokrollahi, A., Stemann, V., Mitzenmacher, M. and\
    \ D.\n        Spielman, \"Irregularly graphed encoding technique\", U.S. Patent\n\
    \        No.  6,081,909, June 27, 2000.\n   [14] Perrig, A., Canetti, R., Song,\
    \ D. and J.D. Tygar, \"Efficient and\n        Secure Source Authentication for\
    \ Multicast\", Network and\n        Distributed System Security Symposium, NDSS\
    \ 2001, pp. 35-46,\n        February 2001.\n   [15] Rizzo, L., \"Effective Erasure\
    \ Codes for Reliable Computer\n        Communication Protocols\", ACM SIGCOMM\
    \ Computer Communication\n        Review, Vol.27, No.2, pp.24-36, Apr 1997.\n\
    \   [16] Rizzo, L., \"On the Feasibility of Software FEC\", DEIT Tech\n      \
    \  Report, http://www.iet.unipi.it/~luigi/softfec.ps, Jan 1997.\n"
- title: 7.  Authors' Addresses
  contents:
  - "7.  Authors' Addresses\n   Michael Luby\n   Digital Fountain\n   39141 Civic\
    \ Center Drive\n   Suite 300\n   Fremont, CA  94538\n   EMail: luby@digitalfountain.com\n\
    \   Lorenzo Vicisano\n   Cisco Systems, Inc.\n   170 West Tasman Dr.,\n   San\
    \ Jose, CA, USA, 95134\n   EMail: lorenzo@cisco.com\n   Jim Gemmell\n   Microsoft\
    \ Research\n   455 Market St. #1690\n   San Francisco, CA, 94105\n   EMail: jgemmell@microsoft.com\n\
    \   Luigi Rizzo\n   Dip. di Ing. dell'Informazione\n   Universita` di Pisa\n \
    \  via Diotisalvi 2, 56126 Pisa, Italy\n   EMail:luigi@iet.unipi.it\n   Mark Handley\n\
    \   ICSI Center for Internet Research\n   1947 Center St.\n   Berkeley CA, USA,\
    \ 94704\n   EMail: mjh@icir.org\n   Jon Crowcroft\n   Marconi Professor of Communications\
    \ Systems\n   University of Cambridge\n   Computer Laboratory\n   William Gates\
    \ Building\n   J J Thomson Avenue\n   Cambridge\n   CB3 0FD\n   EMail: Jon.Crowcroft@cl.cam.ac.uk\n"
- title: 8.  Full Copyright Statement
  contents:
  - "8.  Full Copyright Statement\n   Copyright (C) The Internet Society (2002). \
    \ All Rights Reserved.\n   This document and translations of it may be copied\
    \ and furnished to\n   others, and derivative works that comment on or otherwise\
    \ explain it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
