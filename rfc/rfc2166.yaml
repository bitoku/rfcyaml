- title: __initial_text__
  contents:
  - "                      APPN Implementer's Workshop\n                         Closed\
    \ Pages Document\n                         DLSw v2.0 Enhancements\n"
- title: Status of this Memo
  contents:
  - 'Status of this Memo

    '
- title: This memo provides information for the Internet community.  This memo
  contents:
  - 'This memo provides information for the Internet community.  This memo

    '
- title: does not specify an Internet standard of any kind.  Distribution of
  contents:
  - 'does not specify an Internet standard of any kind.  Distribution of

    '
- title: this memo is unlimited.
  contents:
  - 'this memo is unlimited.

    '
- title: Abstract
  contents:
  - "Abstract\n   This document specifies\n   - a set of extensions to RFC 1795 designed\
    \ to improve the scalability\n     of DLSw\n   - clarifications to RFC 1795 in\
    \ the light of the implementation\n     experience to-date.\n   It is assumed\
    \ that the reader is familiar with DLSw and RFC 1795.  No\n   effort has been\
    \ made to explain these existing protocols or\n   associated terminology.\n  \
    \ This document was developed in the DLSw Related Interest Group (RIG)\n   of\
    \ the APPN Implementers Workshop (AIW). If you would like to\n   participate in\
    \ future DLSw discussions, please subscribe to the DLSw\n   RIG mailing lists\
    \ by sending a mail to majordomo@raleigh.ibm.com\n   specifying 'subscribe aiw-dlsw'\
    \ as the body of the message.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. INTRODUCTION ................................................\
    \    3\n   2. HALT REASON CODES............................................  \
    \  3\n   3. SCOPE OF SCALABILITY ENHANCEMENTS............................    4\n\
    \   4. OVERVIEW OF SCALABILITY ENHANCEMENTS.........................    6\n  \
    \ 5. MULTICAST GROUPS AND ADDRESSING..............................    7\n   5.1\
    \ USING MULTICAST GROUPS......................................    8\n   5.2 DLSW\
    \ MULTICAST ADDRESSES....................................    8\n   6. DLSW MESSAGE\
    \ TRANSPORTS......................................    8\n   6.1 TCP/IP CONNECTIONS\
    \ ON DEMAND................................    9\n    6.1.1 TCP CONNECTIONS ON\
    \ DEMAND RACE CONDITIONS................    9\n   6.2 SINGLE SESSION TCP/IP CONNECTIONS...........................\
    \    9\n    6.2.1 EXPEDITED SINGLE SESSION TCP/IP CONNECTIONS..............  \
    \ 10\n     6.2.1.1 TCP PORT NUMBERS......................................   10\n\
    \     6.2.1.2 TCP CONNECTION SETUP..................................   10\n  \
    \   6.2.1.3 SINGLE SESSION SETUP RACE CONDITIONS..................   10\n    \
    \ 6.2.1.4 TCP CONNECTIONS WITH NON-MULTICAST CAPABLE DLSW PEERS.   11\n   6.3\
    \ UDP DATAGRAMS...............................................   12\n    6.3.1\
    \ VENDOR SPECIFIC FUNCTIONS OVER UDP.......................   12\n    6.3.2 UNICAST\
    \ UDP DATAGRAMS....................................   12\n    6.3.3 MULTICAST\
    \ UDP DATAGRAMS..................................   13\n   6.4 UNICAST UDP DATAGRAMS\
    \ IN LIEU OF IP MULTICAST...............   13\n   6.5 TCP TRANSPORT...............................................\
    \   14\n   7. MIGRATION SUPPORT............................................  \
    \ 14\n   7.1 CAPABILITIES EXCHANGE.......................................   14\n\
    \   7.2 CONNECTING TO NON-MULTICAST CAPABLE NODES...................   15\n  \
    \ 7.3 COMMUNICATING WITH MULTICAST CAPABLE NODES..................   15\n   8.\
    \ SNA SUPPORT..................................................   16\n   8.1 ADDRESS\
    \ RESOLUTION..........................................   16\n   8.2 EXPLORER FRAMES.............................................\
    \   16\n   8.3 CIRCUIT SETUP...............................................  \
    \ 17\n   8.4 EXAMPLE SNA SSP MESSAGE SEQUENCE............................   17\n\
    \   8.5 UDP RELIABILITY.............................................   19\n  \
    \  8.5.1 RETRIES..................................................   19\n   9.\
    \ NETBIOS......................................................   20\n   9.1 ADDRESS\
    \ RESOLUTION..........................................   21\n   9.2 EXPLORER FRAMES.............................................\
    \   21\n   9.3 CIRCUIT SETUP...............................................  \
    \ 21\n   9.4 EXAMPLE NETBIOS SSP MESSAGE SEQUENCE........................   22\n\
    \   9.5 MULTICAST RELIABILITY AND RETRIES...........................   24\n  \
    \ 10. SEQUENCING..................................................   24\n   11.\
    \ FRAME FORMATS...............................................   25\n   11.1 MULTICAST\
    \ CAPABILITIES CONTROL VECTOR......................   25\n    11.1.1 DLSW CAPABILITIES\
    \ NEGATIVE RESPONSE.....................   26\n   11.2 UDP PACKETS................................................\
    \   26\n   11.3 VENDOR SPECIFIC UDP PACKETS................................  \
    \ 27\n   12. COMPLIANCE STATEMENT........................................   28\n\
    \   13. SECURITY CONSIDERATIONS.....................................   29\n  \
    \ 14. ACKNOWLEDGEMENTS............................................   29\n   15.\
    \ AUTHORS' ADDRESSES..........................................   30\n   16. APPENDIX\
    \ - CLARIFICATIONS TO RFC 1795.......................   31\n   1. Introduction\n\
    \   This document defines v2.0 of Data Link Switching (DLSw) in the form\n   of\
    \ a set of enhancements to RFC 1795. These enhancements are designed\n   to be\
    \ fully backward compatible with existing RFC 1795\n   implementations. As a compatible\
    \ set of enhancements to RFC 1795,\n   this document does not replace or supersede\
    \ RFC 1795.\n   The bulk of these enhancements address scalability issues in DLSw\n\
    \   v1.0.  Reason codes have also been added to the HALT_DL and\n   HALT_DL_NOACK\
    \ SSP messages in order to improve the diagnostic\n   information available.\n\
    \   Finally, the appendix to this document lists a number of\n   clarifications\
    \ to RFC 1795 where the implementation experience to-\n   date has shown that\
    \ the original RFC was ambiguous or unclear. These\n   clarifications should be\
    \ read alongside RFC 1795 to obtain a full\n   specification of the base v1.0\
    \ DLSw standard.\n"
- title: 2. HALT Reason codes
  contents:
  - "2. HALT Reason codes\n   RFC 1795 provides no mechanism for a DLSw to communicate\
    \ to its peer\n   the reason for dropping a circuit.  DLSw v2.0 adds reason code\
    \ fields\n   to the HALT_DL and HALT_DL_NOACK SSP messages to carry this\n   information.\n\
    \   The reason code is carried as 6 bytes of data after the existing SSP\n   header.\
    \  The format of these bytes is as shown below.\n   Byte       Description\n \
    \  0-1        Generic HALT reason code in byte normal format\n   2-5        Vendor-specific\
    \ detailed reason code\n   The generic HALT reason code takes one of the following\
    \ decimal\n   values (which are chosen to match the disconnect reason codes\n\
    \   specified in the DLSw MIB).\n   1 - Unknown error\n   2 - Received DISC from\
    \ end-station\n   3 - Detected DLC error with end-station\n   4 - Circuit-level\
    \ protocol error (e.g., pacing)\n   5 - Operator-initiated (mgt station or local\
    \ console)\n   The vendor-specific detailed reason code may take any value.\n\
    \   All V2.0 DLSws must include this information on all HALT_DL and\n   HALT_DL_NOACK\
    \ messages sent to v2.0 DLSw peers.  For backwards\n   compatibility with RFC\
    \ 1795, DLSw V2.0 implementations must also\n   accept a HALT_DL or HALT_DL_NOACK\
    \ message received from a DLSw peer\n   that does not carry this information (i.e.\
    \ RFC 1795 format for these\n   SSP messages).\n"
- title: 3. Scope of Scalability Enhancements
  contents:
  - "3. Scope of Scalability Enhancements\n   The DLSw Scalability group of the AIW\
    \ identified a number of\n   scalability issues associated with existing DLSw\
    \ protocols as defined\n   in RFC 1795:\n   - Administration\n     RFC 1795 implies\
    \ the need to define the transport address of all\n     DLSw peers at each DLSw.\
    \  In highly meshed situations (such as\n     those often found in NetBIOS networks),\
    \ the resultant\n     administrative burden is undesirable.\n   - Address Resolution\n\
    \     RFC 1795 defines point to point TCP (or other reliable transport\n     protocol)\
    \ connections between DLSw peers.  When attempting to\n     discover the location\
    \ of an unknown resource, a DLSw sends an\n     address resolution packet to each\
    \ DLSw peer over these connections.\n     In highly meshed configurations, this\
    \ can result in a very large\n     number of packets in the transport network.\
    \  Although each packet\n     is sent individually to each DLSw peer, they are\
    \ each identical in\n     nature.  Thus the transport network is burdened with\
    \ excessive\n     numbers of identical packets.  Since the transport network is\
    \ most\n     commonly a wide area network, where bandwidth is considered a\n \
    \    precious resource, this packet duplication is undesirable.\n   - Broadcast\
    \ Packets\n     In addition to the address resolution packets described above,\
    \ RFC\n     1795 also propagates NetBIOS broadcast packets into the transport\n\
    \     network.  The UI frames of NetBIOS are sent as LAN broadcast\n     packets.\
    \  RFC 1795 propagates these packets over the point to point\n     transport connections\
    \ to each DLSw peer.  In the same manner as\n     above, this creates a large\
    \ number of identical packets in the\n     transport network, and hence is undesirable.\
    \  Since NetBIOS UI\n     frames can be sent by applications, it is difficult\
    \ to predict or\n     control the rate and quantity of such traffic.  This compounds\
    \ the\n     undesirability of the existing RFC 1795 propagation method for\n \
    \    these packets.\n   - TCP (transport connection) Overhead\n     As defined\
    \ in RFC 1795, each DLSw maintains a transport connection\n     to its DLSw peers.\
    \  Each transport connection guarantees in order\n     packet delivery.   This\
    \ is accomplished using acknowledgment and\n     sequencing algorithms which require\
    \ both CPU and memory at the DLSw\n     endpoints in direct proportion to the\
    \ number transport connections.\n     The DLSw Scalability group has identified\
    \ two scenarios where the\n     number of transport connections can become significant\
    \ resulting in\n     excessive overhead and corresponding equipment costs (memory\
    \ and\n     CPU).   The first scenario is found in highly meshed DLSw\n     configurations\
    \ where the number of transport connections\n     approximates n2 (where n is\
    \ the number of DLSw peers).  This is\n     typically found in DLSw networks supporting\
    \ NetBIOS.  The second\n     scenario is found  in networks  where many remote\
    \ locations\n     communicate to few central sites.  In this case, the central\
    \ sites\n     must support n transport connections  (where n is the number of\n\
    \     remote sites).    In both scenarios the resultant transport\n     connection\
    \ overhead is considered undesirable depending upon the\n     value of n.\n  \
    \ - LLC2 overhead\n     RFC 1795 specifies that each DLSw provides local termination\
    \ for\n     the LLC2 (SDLC or other SNA reliable data link  protocol) sessions\n\
    \     traversing the SSP.   Because these reliable data links provide\n     guaranteed\
    \ in order packet delivery, the memory and CPU overhead of\n     maintaining these\
    \ connections can also become significant.   This\n     is particularly undesirable\
    \ in the second scenario described above,\n     because the number of reliable\
    \ connections maintained at the\n     central site is the aggregate of the connections\
    \ maintained at each\n     remote site.\n   It is not the intent of this document\
    \ to address all the undesirable\n   scalability issues associated with RFC 1795.\
    \  This paper identifies\n   protocol enhancements to RFC 1795 using the inherent\
    \ multicast\n   capabilities of the underlying transport network to improve the\n\
    \   scalability of RFC 1795.  It is believed that the enhancements\n   defined,\
    \ herein, address many of the issues identified above, such as\n   administration,\
    \ address resolution, broadcast packets, and, to a\n   lesser extent, transport\
    \ overhead.  This paper does not address LLC2\n   overhead.  Subsequent efforts\
    \ by the AIW and/or DLSw Scalability\n   group may address the unresolved scalability\
    \ issues.\n   While it is the intent of this paper to accommodate all transport\n\
    \   protocols as best as is possible, it is recognized that the multicast\n  \
    \ capabilities of many protocols is not yet well defined, understood,\n   or implemented.\
    \ Since TCP is the most prevalent DLSw transport\n   protocol in use today, the\
    \ DLSw Scalability group has chosen to focus\n   its definition around IP based\
    \ multicast services. This document only\n   addresses the implementation detail\
    \ of IP based multicast services.\n   This proposal does not consider the impacts\
    \ of IPv6 as this was\n   considered too far from widespread use at the time of\
    \ writing.\n"
- title: 4. Overview of Scalability Enhancements
  contents:
  - "4. Overview of Scalability Enhancements\n   This paper describes the use of multicast\
    \ services within the\n   transport network to improve the scalability of DLSw\
    \ based\n   networking.  There are only a few main components of this proposal:\n\
    \   - Single session TCP connections\n     RFC 1795 defines a negotiation protocol\
    \ for DLSw peers to choose\n     either two unidirectional or one bi-directional\
    \ TCP connection.\n     DLSws implementing the enhancements described in this\
    \ document must\n     support and use(whenever required and possible)a single\
    \ bi-\n     directional TCP connection between DLSw peers. That is to say that\n\
    \     the single tunnel negotiation support of RFC 1795 is a prerequisite\n  \
    \   function to this set of enhancements. Use of two unidirectional TCP\n    \
    \ connections is only allowed (and required)for migration purposes\n     when\
    \ communicating with DLSw peers that do not implement these\n     enhancements.\n\
    \     This document also specifies a faster method for bringing up a\n     single\
    \ TCP connection between two DLSw peers than the negotiation\n     used in RFC\
    \ 1795.  This faster method, detailed in section 6.2.1,\n     must be used where\
    \ both peers are known to support DLSw v2.0.\n   - TCP connections on demand\n\
    \     Two DLSw peers using these enhancements will only establish a TCP\n    \
    \ connection when necessary.  SSP connections to DLSw peers which do\n     not\
    \ implement these enhancements are assumed to be established by\n     the means\
    \ defined in RFC 1795.  DLSws implementing v2.0 utilize UDP\n     based transport\
    \ services to send address resolution packets\n     (CANUREACH_ex, NETBIOS_NQ_ex,\
    \ etc.).  If a positive response is\n     received, then a TCP connection is only\
    \ established to the\n     associated DLSw peer if one does not already exist.\n\
    \     Correspondingly, TCP connections are brought down when there are no\n  \
    \   circuits to a DLSw peer for an implementation defined period of\n     time.\n\
    \   - Address resolution through UDP\n     The main thrust of this paper is to\
    \ utilize non-reliable transport\n     and the inherent efficiencies of multicast\
    \ protocols whenever\n     possible and applicable to reduce network overhead.\
    \  Accordingly,\n     the address resolution protocols of SNA and NetBIOS are\
    \ sent over\n     the non-reliable transport of IP, namely UDP.  In addition,\
    \ IP\n     multicast/unicast services are used whenever address resolution\n \
    \    packets must be sent to multiple destinations. This avoids the need\n   \
    \  to maintain TCP SSP connections between two DLSw peers when no\n     circuits\
    \ are active.  CANUREACH_ex and ICANREACH_ex packets can be\n     sent to all\
    \ the appropriate DLSw peers without the need for pre-\n     configured peers\
    \ or pre-established TCP/IP connections.  In\n     addition, most multicast services\
    \ (including TCP's MOSPF, DVMRP,\n     MIP, etc.) replicate and propagate messages\
    \ only as necessary to\n     deliver to all multicast members.   This avoids duplication\
    \ and\n     excessive bandwidth consumption in the transport network.\n     To\
    \ further optimize the use of WAN resources, address resolution\n     responses\
    \ are sent in a directed fashion (i.e., unicast) via UDP\n     transport whenever\
    \ possible.   This avoids the need to setup or\n     maintain TCP connections\
    \ when they are not required.  It also\n     avoids the bandwidth costs associated\
    \ with broadcasting.\n     Note: It is also permitted to send some address resolution\
    \ traffic\n     over existing TCP connections.  The conditions under which this\
    \ is\n     permitted are detailed in section 7.\n   - NetBIOS broadcasts over\
    \ UDP\n     In the same manner as above, NetBIOS broadcast packets are sent via\n\
    \     UDP (unicast and multicast) whenever possible and appropriate. This\n  \
    \   avoids the need to establish TCP connections between DLSw peers\n     when\
    \ there are no circuits required.   In addition, bandwidth in\n     the transport\
    \ network is conserved by utilizing the efficiencies\n     inherent to multicast\
    \ service implementation.  Details covering\n     identification of these packets\
    \ and proper propagation methods are\n     described in section 10.\n"
- title: 5. Multicast Groups and Addressing
  contents:
  - "5. Multicast Groups and Addressing\n   IP multicast services provides an unreliable\
    \ datagram oriented\n   delivery service to multiple parties. Communication is\
    \ accomplished\n   by sending and/or listening to specific 'multicast' addresses.\
    \  When\n   a given node sends a packet to a specific address (defined to be\n\
    \   within the multicast address range), the IP network (unreliably)\n   delivers\
    \ the packet to every node listening on that address.\n   Thus, DLSws can make\
    \ use of this service by simply sending and\n   receiving (i.e., listening for)\
    \ packets on the appropriate multicast\n   addresses. With careful planning and\
    \ implementation, networks can be\n   effectively partitioned and network overhead\
    \ controlled by sending\n   and listening on different addresses groups.  It is\
    \ not the intent of\n   this paper to define or describe the techniques by which\
    \ this can be\n   accomplished.  It is expected that the networking industry (vendors\n\
    \   and end users alike) will determine the most appropriate ways to make\n  \
    \ use of the functions provided by use of DLSw multicast transport\n   services.\n"
- title: 5.1 Using Multicast Groups
  contents:
  - "5.1 Using Multicast Groups\n   The multicast addressing as described above can\
    \ be effectively used\n   to limit the amount of broadcast/multicast traffic in\
    \ the network.\n   It is not the intent of this document to describe how individual\n\
    \   DLSw/SSP implementations would assign or choose group addresses.  The\n  \
    \ specifics of how this is done and exposed to the end user is an issue\n   for\
    \ the specific implementor.  In order to provide for multivendor\n   interoperability\
    \ and simplicity of configuration, however, this paper\n   defines a single IP\
    \ multicast address, 224.0.10.000, to be used as a\n   default DLSw multicast\
    \ address.  If a given implementation chooses to\n   provide a default multicast\
    \ address, it is recommended this address\n   be used.  In addition, this address\
    \ should be used for both\n   transmitting and receiving of multicast SSP messages.\
    \  Implementation\n   of a default multicast address is not, however, required.\n"
- title: 5.2 DLSw Multicast Addresses
  contents:
  - "5.2 DLSw Multicast Addresses\n   For the purpose of long term interoperability,\
    \ the AIW has secured a\n   block of IP multicast addresses to be used with DLSw.\
    \  These\n   addresses are listed below:\n   Address Range        Purpose\n  \
    \ --------------------------------------------------------------------\n   224.0.10.000\
    \         Default multicast address\n   224.0.10.001-191     User defined DLSw\
    \ multicast groups\n   224.0.10.192-255     Reserved for future use by the DLSw\
    \ RIG in DLSw\n                        enhancements\n"
- title: 6. DLSw Message Transports
  contents:
  - "6. DLSw Message Transports\n   With the introduction of DLSw Multicast Protocols,\
    \ SSP messages are\n   now sent over two distinct transport mechanisms: TCP/IP\
    \ connections\n   and UDP services.  Furthermore, the UDP datagrams can be sent\
    \ to two\n   different kinds of IP addresses: unique IP addresses (generally\n\
    \   associated with a specific DLSw), and multicast IP addresses\n   (generally\
    \ associated with a group of DLSw peers).\n"
- title: 6.1 TCP/IP Connections on Demand
  contents:
  - "6.1 TCP/IP Connections on Demand\n   As is the case in RFC 1795, TCP/IP connections\
    \ are established\n   between DLSw peers.  Unlike RFC 1795, however, TCP/IP connections\
    \ are\n   only established to carry reliable circuit data (i.e., LLC2 based\n\
    \   circuits).  Accordingly, a TCP/IP connection is only established to a\n  \
    \ given DLSw peer when the first circuit to that DLSw is required\n   (i.e., the\
    \ origin DLSw must send a CANUREACH_CS to a target DLSw peer\n   and there is\
    \ no existing TCP connection between the two).  In\n   addition, the TCP/IP connection\
    \ is brought down an implementation\n   defined amount of time after the last\
    \ active (not pending) circuit\n   has terminated.  In this way, the overhead\
    \ associated with\n   maintaining TCP connections is minimized.\n   With the advent\
    \ of TCP connections on demand, the activation and\n   deactivation of TCP connections\
    \ becomes a normal occurrence as\n   opposed to the exception event it constitutes\
    \ in RFC 1795.  For this\n   reason, it is recommended that implementations carefully\
    \ consider the\n   value of SNMP traps for this condition.\n"
- title: 6.1.1 TCP Connections on Demand Race Conditions
  contents:
  - "6.1.1 TCP Connections on Demand Race Conditions\n   Non-circuit based SSP packetsn\
    \ (e.g.,CANUREACH_ex, etc.) may still be\n   sent/received over TCP connections\
    \ after all circuits have been\n   terminated.  Taking this into account implementations\
    \ should still\n   gracefully terminate these TCP connections once the connection\
    \ is no\n   longer supporting circuits.  This may require an implementation to\n\
    \   retransmit request frames over UDP when no response to a TCP based\n   unicast\
    \ request is received and the TCP connection is brought down.\n   This is not\
    \ required in the case of multicast requests as these are\n   received over the\
    \ multicast transport mechanism.\n"
- title: 6.2 Single Session TCP/IP Connections
  contents:
  - "6.2 Single Session TCP/IP Connections\n   RFC 1795 defines the use of two unidirectional\
    \ TCP/IP sessions\n   between any pair of DLSw peers using read port number 2065\
    \ and write\n   port number 2067.  Additionally, RFC 1795 allows for implementations\n\
    \   to optionally use only one bi-directional TCP/IP session.  Using one\n   TCP/IP\
    \ session between DLSw peers is believed to significantly\n   improve the performance\
    \ and scalability of DLSw protocols.\n   Performance is improved because TCP/IP\
    \ acknowledgments are much more\n   likely to be piggy-backed on real data when\
    \ TCP/IP sessions are used\n   bi-directionally.  Scalability is improved because\
    \ fewer TCP control\n   blocks, state machines, and associated message buffers\
    \ are required.\n   For these reasons, the DLSw enhancements defined in this paper\n\
    \   REQUIRE the use of single session TCP/IP sessions.\n   Accordingly, DLSws\
    \ implementing these enhancements must carry the TCP\n   Connections Control Vector\
    \ in their Capabilities Exchange.  In\n   addition, the TCP Connections Control\
    \ Vector must indicate support\n   for 1 connection.\n"
- title: 6.2.1 Expedited Single Session TCP/IP Connections
  contents:
  - "6.2.1 Expedited Single Session TCP/IP Connections\n   In RFC 1795, single session\
    \ TCP/IP connections are accomplished by\n   first establishing two uni-directional\
    \ TCP connections, exchanging\n   capabilities, and then bringing down one of\
    \ the connections.  In\n   order to avoid the unnecessary flows and time delays\
    \ associated with\n   this process, a new single session bi-directional TCP/IP\
    \ connection\n   establishment algorithm is defined.\n"
- title: 6.2.1.1 TCP Port Numbers
  contents:
  - "6.2.1.1 TCP Port Numbers\n   DLSws implementing these enhancements will use a\
    \ TCP destination port\n   of 2067 (as opposed to RFC 1795 which uses 2065) for\
    \ single session\n   TCP connections.  The source port will be a random port number\
    \ using\n   the established TCP norms which exclude the possibility of either\n\
    \   2065 or 2067.\n"
- title: 6.2.1.2 TCP Connection Setup
  contents:
  - "6.2.1.2 TCP Connection Setup\n   DLSw peers implementing these enhancements will\
    \ establish a single\n   session TCP connection whenever the associated peer is\
    \ known to\n   support this capability.  To do this, the initiating DLSw simply\n\
    \   sends a TCP setup request to destination port 2067.  The receiving\n   DLSw\
    \ responds accordingly and the TCP three way handshake ensues.\n   Once this handshake\
    \ has completed, each DLSw is notified and the DLSw\n   capabilities exchange\
    \ ensues.  As in RFC 1795, no flows may take\n   place until the capabilities\
    \ exchange completes.\n"
- title: 6.2.1.3 Single Session Setup Race Conditions
  contents:
  - "6.2.1.3 Single Session Setup Race Conditions\n   The new expedited single session\
    \ setup procedure described above\n   opens up the possibility of a race condition\
    \ that occurs when two\n   DLSw peers attempt to setup single session TCP connections\
    \ to each\n   other at the same time.  To avoid the establishment of two TCP\n\
    \   connections, the following rules are applied when establishing\n   expedited\
    \ single session TCP connections:\n   1.If an inbound TCP connect indication is\
    \ received on port 2067 while\n     an outbound TCP connect request (on port 2067)\
    \ to the same DLSw (IP\n     address) is in process or outstanding, the DLSw with\
    \ the higher IP\n     address will close or reject the connection from the DLSw\
    \ with the\n     lower IP address.\n   2.To further expedite the process, the\
    \ DLSw with the lower IP address\n     may choose (implementation option) to close\
    \ its connection request\n     to the DLSw with the higher address when this condition\
    \ is\n     detected.\n   3.If the DLSw with the lower IP address has already sent\
    \ its\n     capabilities exchange request on its connection to the DLSw with\n\
    \     the higher IP address, it must resend its capabilities exchange\n     request\
    \ over the remaining TCP connection from its DLSw peer (with\n     the higher\
    \ IP address).\n   4.The DLSw with the higher IP address must ignore any capabilities\n\
    \     exchange request received over the TCP connection to be terminated\n   \
    \  (the one from the DLSw with the lower IP address).\n"
- title: 6.2.1.4 TCP Connections with Non-Multicast Capable DLSw peers
  contents:
  - "6.2.1.4 TCP Connections with Non-Multicast Capable DLSw peers\n   During periods\
    \ of migration, it is possible that TCP connections\n   between multicast capable\
    \ and non-multicast capable DLSw peers will\n   occur.  It is also possible that\
    \ multicast capable DLSws may attempt\n   to establish TCP connections with partners\
    \ of unknown capabilities\n   (e.g., statically defined peers).  To handle these\
    \ conditions the\n   following additional rules apply to expedited single session\
    \ TCP\n   connection setup:\n   1.If the capability of a DLSw peer is not known,\
    \ an implementation\n     may choose to send the initial TCP connect request to\
    \ either port\n     2067 (expedited single session setup) or port 2065 (standard\
    \ RFC\n     1795 TCP setup).\n   2.If a multicast capable DLSw receives an inbound\
    \ TCP connect request\n     on port 2065 while processing an outbound request\
    \ on 2067 to the\n     same DLSw, the sending DLSw will terminate its 2067 request\
    \ and\n     respond as defined in RFC 1795 with an outbound 2065 request\n   \
    \  (standard RFC 1795 TCP setup).\n   3.If a multicast capable DLSw receives an\
    \ indication that the DLSw\n     peer is not multicast capable (the port 2067\
    \ setup request times\n     out or a port not recognized rejection is received),\
    \ it will send\n     another connection request using port 2065 and the standard\
    \ RFC\n     1795 session setup protocol.\n"
- title: 6.3 UDP Datagrams
  contents:
  - "6.3 UDP Datagrams\n   As mentioned above, UDP datagrams can be sent two different\
    \ ways:\n   unicast (e.g., sent to a single unique IP address) or multicast\n\
    \   (i.e., sent to an IP multicast address).  Throughout this document,\n   the\
    \ term UDP datagram will be used to refer to SSP messages sent over\n   UDP, while\
    \ unicast and multicast SSP messages will refer to the\n   specific type/method\
    \ of UDP packet transport.  In either case,\n   standard UDP services are used\
    \ to transport these packets.  In order\n   to properly parse the inbound UDP\
    \ packets and deliver them to the SSP\n   state machines, all DLSw UDP packets\
    \ will use the destination port of\n   2067.\n   In addition, the checksum function\
    \ of UDP remains optional for DLSw\n   SSP messages.  It is believed that the\
    \ inherent CRC capabilities of\n   all data link transports will adequately protect\
    \ SSP packets during\n   transmission.  And the incremental exposure to intermediate\
    \ nodal\n   data corruption is negligible.  For further information on UDP packet\n\
    \   formats see the Frame Formats section.\n"
- title: 6.3.1 Vendor Specific Functions over UDP
  contents:
  - "6.3.1 Vendor Specific Functions over UDP\n   In order to accommodate vendor specific\
    \ capabilities over UDP\n   transport, a new SSP packet format has been defined.\
    \  This new packet\n   format is required because message traffic of this type\
    \ is not\n   necessarily preceded by a capabilities exchange.  Accordingly, DLSw's\n\
    \   wishing to invoke a vendor specific function may send out this new\n   SSP\
    \ packet format over UDP.\n   Because this packet can be sent over TCP connections\
    \ and non-\n   multicast capable nodes may not be able to recognize it,\n   implementations\
    \ may only send this packet over TCP to DLSw peers\n   known to understand this\
    \ packet format (i.e., multicast capable).  To\n   avoid this situation in the\
    \ future, DLSws implementing these\n   enhancements must ignore SSP packets with\
    \ an unrecognized DLSw\n   version number in the range of x'31' to x'3F'.  Further\
    \ information\n   and the precise format for this new packet type is described\
    \ below in\n   the Frame Formats section.\n"
- title: 6.3.2 Unicast UDP Datagrams
  contents:
  - "6.3.2 Unicast UDP Datagrams\n   Generically speaking, a unicast UDP datagram\
    \ is utilized whenever an\n   SSP message (not requiring reliable transport) must\
    \ be sent to a\n   unique set (not all) of DLSw peers.  This avoids the overhead\
    \ of\n   having to establish and maintain TCP connections when they are not\n\
    \   required for reliable data transport.\n   A typical example of when unicast\
    \ UDP might be used would be an\n   ICANREACH_ex response from a peer DLSw (with\
    \ which no TCP connection\n   currently exists).  In this case, the sending DLSw\
    \ knows the IP\n   address of the intended receiver and can simply send the response\
    \ via\n   unicast UDP.  In addition, there are a number of NetBIOS cases where\n\
    \   unicast UDP is used to handle UI frames directed to a specific DLSw\n   (e.g.,\
    \ NetBIOS STATUS_RESPONSE).  Further detail is provided in the\n   NetBIOS section\
    \ of this document.\n"
- title: 6.3.3 Multicast UDP Datagrams
  contents:
  - "6.3.3 Multicast UDP Datagrams\n   In a broad sense, multicast UDP datagrams are\
    \ used whenever a given\n   SSP message must be sent to multiple DLSw peers. \
    \ In the case of SNA,\n   this is primarily the CANUREACH_ex packets.  In the\
    \ case of NetBIOS,\n   multicast datagrams are used to send broadcast UI frames\
    \ such as\n   NetBIOS user datagrams and broadcast datagrams.\n   Note, however,\
    \ it is sometimes possible to avoid broadcasting certain\n   NetBIOS frames that\
    \ would otherwise be broadcast in the LAN\n   environment.  This is typically\
    \ accomplished using name caching\n   techniques not described in this paper.\
    \  In cases of this type when a\n   single destination DLSw can be determined,\
    \ unicast transport can be\n   used to send the 'broadcast' NetBIOS frame to a\
    \ single destination.\n   A more detailed listing of NetBIOS SSP packets and transport\
    \ methods\n   can be found in the NetBIOS section of this document.\n"
- title: 6.4 Unicast UDP Datagrams in Lieu of IP Multicast
  contents:
  - "6.4 Unicast UDP Datagrams in Lieu of IP Multicast\n   Because the use of IP multicast\
    \ services is actually a function of IP\n   itself and not DLSw proper, it is\
    \ possible for implementations to\n   simply make use of the UDP transport mechanisms\
    \ described in this\n   paper without making direct use of the IP multicast function.\
    \  While\n   this is not considered to be as efficient as using multicast\n  \
    \ transport mechanisms, this practice is not explicitly prohibited.\n   Implementations\
    \ which choose to make use of UDP transport in this\n   manner must first know\
    \ the IP address of all the potential target\n   DLSw peers and send individual\
    \ unicast packets to each.  How this\n   information is obtained and/or maintained\
    \ is outside the scope of\n   this paper.\n   As a matter of compliance, implementers\
    \ need not send SSP packets\n   outbound over UDP as there are some conditions\
    \ where this may not be\n   necessary or desirable.  It is, however, required\
    \ that implementers\n   provide an option to receive SSP packets over UDP.\n"
- title: 6.5 TCP Transport
  contents:
  - "6.5 TCP Transport\n   Despite the addition of UDP based packet transport, TCP\
    \ remains the\n   fundamental form of communications between DLSw peers.  In\n\
    \   particular, TCP is still used to carry all LLC2 based circuit data.\n   Throughout\
    \ this document wherever UDP unicast (not multicast) is\n   discussed, the reader\
    \ should be aware that TCP may be used instead.\n   Moreover, it is strongly recommended\
    \ that TCP be used in preference\n   to UDP whenever a TCP connection to the destination\
    \ already exists.\n   Implementations, however, should be prepared to receive\
    \ SSP packets\n   from either transport (TCP or UDP).\n"
- title: 7. Migration Support
  contents:
  - "7. Migration Support\n   It is anticipated that some networks will experience\
    \ a transition\n   stage where both RFC 1795 (referred to as 'non-multicast' DLSws)\
    \ and\n   It will be important for these two DLSw node types to interoperate\n\
    \   and thus the following accommodations for non-multicast DLSws are\n   required:\n"
- title: 7.1 Capabilities Exchange
  contents:
  - "7.1 Capabilities Exchange\n   In order to guarantee both backward and forward\
    \ capability, DLSws\n   which implement these multicast enhancements will carry\
    \ a Multicast\n   Capabilities Control Vector in their capabilities exchange (see\
    \ RFC\n   1795 for an explanation of capabilities exchange protocols).\n   Presence\
    \ of the Multicast Capabilities control vector indicates\n   support for the protocols\
    \ defined in this document on a per DLSw peer\n   basis.  Conversely, lack of\
    \ the Multicast Capabilities control vector\n   indicates no support for these\
    \ extensions on a per DLSw peer basis.\n   Additionally, nodes implementing these\
    \ enhancement will carry a\n   modified DLSw Version control vector (x'82') indicating\
    \ support for\n   version 2 release 0.\n   Lastly, presence of these control vectors\
    \ mandates a TCP Connections\n   Control Vector indicating support for 1 TCP connection\
    \ in the same\n   Capabilities exchange.\n   If a multicast capable DLSw receives\
    \ a Capabilities Exchange CV that\n   includes the Multicast Capabilites CV but\
    \ does not meet the above\n   criteria, it must reject the capabilities exchange\
    \ by sending a\n   negative response as described in section 11.1.1.\n"
- title: 7.2 Connecting to Non-Multicast Capable Nodes
  contents:
  - "7.2 Connecting to Non-Multicast Capable Nodes\n   It is assumed that TCP connections\
    \ to DLSw peers which do not support\n   multicast services are established by\
    \ some means outside the scope of\n   this paper (i.e., non-multicast partner\
    \ addresses are configured by\n   the customer).  TCP connections must be established\
    \ and maintained to\n   down level nodes in the exact same manner as RFC 1795\
    \ requires,\n   establishes, and maintains them.  And because non-multicast DLSw\n\
    \   peers will not indicate support for multicast services in their\n   capabilities\
    \ exchange, a multicast capable DLSw will know all its\n   non-multicast peers.\n"
- title: 7.3 Communicating with Multicast Capable Nodes
  contents:
  - "7.3 Communicating with Multicast Capable Nodes\n   Because non-multicast nodes\
    \ will not receive SSP frames via UDP\n   (unicast or multicast) transmission,\
    \ SSP messages to these DLSw peers\n   must be sent over TCP connections.  Therefore,\
    \ nodes which implement\n   the multicast protocol enhancements must keep track\
    \ of which DLSw\n   peers do not support multicast extensions (as indicated in\
    \ the\n   capabilities exchange).  When a given packet is sent out via\n   multicast\
    \ services, it must also be sent over multicast UDP(to reach\n   other multicast\
    \ capable DLSw peers) and over the TCP connection to\n   each non-multicast node.\
    \  And although the multicast service requires\n   periodic retransmissions (for\
    \ reliability reasons), this is not the\n   case with TCP connections to non-multicast\
    \ nodes. Therefore,\n   multicast capable DLSws should not resend SSP packets\
    \ over TCP\n   transport connection but rather, rely upon TCP to recover any lost\n\
    \   packets. Furthermore, communications with non-multicast nodes should\n   be\
    \ in exact compliance with RFC 1795 protocols.\n   When sending a unicast UDP\
    \ message, it is important to know that the\n   destination DLSw supports multicast\
    \ services.  This knowledge can be\n   obtained from previous TCP connections/capabilities\
    \ exchanges or\n   inferred from a previously received UDP message, but how this\n\
    \   information is obtained is outside the scope of this paper.  In the\n   latter\
    \ case, if the DLSw is non-multicast, then there would be a TCP\n   connection\
    \ to it and it would be known to be non-multicast.  If it is\n   multicast capable\
    \ and a TCP connection is in existence, then its\n   level is known (via the prior\
    \ capabilities exchange).  If its\n   capabilities are not known and there is\
    \ not an existing TCP\n   connection, then it can be implied to be multicast capable\
    \ by virtue\n   of a cached entry but no active TCP connection (e.g., TCP peer\
    \ on\n   demand support).  This inference, however, could be erroneous in\n  \
    \ cases where the TCP connection (to a non-multicast DLSw) has failed\n   for\
    \ some reason. But normal UDP based unicast verification mechanisms\n   will detect\
    \ no active path to the destination and circuit setup will\n   proceed correctly\
    \ (i.e., succeed or fail in accordance with true\n   connectivity).\n"
- title: 8. SNA Support
  contents:
  - "8. SNA Support\n   Note: This paper does not attempt to address the unique issues\n\
    \   presented by SNA/HPR and its non-ERP data links\n   In SNA protocols the generalized\
    \ packet sequence of interest is a\n   test frame exchange followed by an XID\
    \ exchange.  In all cases, DLSw\n   uses the CANUREACH_ex and ICANREACH_ex SSP\
    \ packets to complete\n   address resolution and circuit establishment.  The following\
    \ table\n   describes how these packets are transported via UDP between two\n\
    \   multicast capable DLSw peers.\n                                          \
    \    Transport\n     Message Event          Action            Mechanism      \
    \   Retry\n   --------------------------------------------------------------------\n\
    \   TEST                 SEND CANUREACH_ex    Multicast/Unicast   Yes\n   TEST\
    \ RESPONSE        SEND ICANREACH_ex       Unicast          No\n   The following\
    \ paragraphs provide more detail on how UDP transport and\n   multicast protocol\
    \ enhancements are used to establish SNA data links.\n"
- title: 8.1 Address Resolution
  contents:
  - "8.1 Address Resolution\n   When a DLSw receives an incoming test frame from an\
    \ attached data\n   link, the assumption is that this is an exploratory frame\
    \ in\n   preparation for an XID exchange and link activation.  The DLSw must\n\
    \   determine a correlation between the destination LSAP (mac and sap\n   pairing)\
    \ and some other DLSw in the transport network.  This paper\n   generically refers\
    \ to this process as address resolution.\n"
- title: 8.2 Explorer frames
  contents:
  - "8.2 Explorer frames\n   Address resolution messages may be sent over a TCP connection\
    \ to a\n   multicast capable DLSw peer if such a connection already exists in\n\
    \   order that they take advantage of the guaranteed delivery of TCP.\n   This\
    \ is particularly recommended for ICANREACH_ex frames.\n"
- title: 8.3 Circuit Setup
  contents:
  - "8.3 Circuit Setup\n   Circuit setup is accomplished in the same manner as described\
    \ in RFC\n   1795.  More specifically, CANUREACH_cs, ICANREACH_cs, REACH_ACK,\n\
    \   XIDFRAME, etc.  are all sent over the TCP connection to the\n   appropriate\
    \ DLSw.  This, of course, assumes the existence of a TCP\n   connection between\
    \ the DLSw peers.  If the sending DLSw (sending a\n   CANUREACH_cs ) detects no\
    \ active TCP connection to the DLSw peer,\n   then a TCP connection setup is initiated\
    \ and the packet sent.  All\n   other circuit setup (and takedown) related sequences\
    \ are now passed\n   over the TCP connection.\n"
- title: 8.4 Example SNA SSP Message Sequence
  contents:
  - "8.4 Example SNA SSP Message Sequence\n   The following diagram provides an example\
    \ sequence of flows\n   associated with an SNA LLC circuit setup.  All flows and\
    \ states\n   described below correspond precisely with those defined in RFC 1795.\n\
    \   The only exception is the addition of a TCP connection setup and DLSw\n  \
    \ capabilities exchange that occurs when the origin DLSw must send a\n   CANUREACH_CS\
    \ and no TCP connection yet exists to the target DLSw\n   peer.\n ======     \
    \                       ___                           ======\n |    |        ---------\
    \        __/   \\__       ---------        |    |\n |    |      __|  _|_  |__\
    \     /   IP    \\    __|  _|_  |__      |    |\n ======        |   |   |    \
    \  <  Network  >     |   |   |        ======\n"
- title: /______\       ---------       \__     __/      ---------       /______\
  contents:
  - "/______\\       ---------       \\__     __/      ---------       /______\\\n\
    \ Origin       Origin DLSw         \\___/        Target DLSw      Target\n Station\
    \        partner                          partner        Station\n           \
    \   disconnected                    disconnected\n"
- title: TEST_cmd      DLC_RESOLVE_C    CANUREACH_ex               TEST_cmd
  contents:
  - 'TEST_cmd      DLC_RESOLVE_C    CANUREACH_ex               TEST_cmd

    '
- title: '----------->  ----------->     ----------->               ---------->'
  contents:
  - "----------->  ----------->     ----------->               ---------->\n   TEST_rsp\
    \   DLC_RESOLVE_R    ICANREACH_ex                 TEST_rsp\n <---------    <-----------\
    \   <-----------                <----------\n"
- title: null XID      DLC_XID
  contents:
  - 'null XID      DLC_XID

    '
- title: '----------->  ----------->'
  contents:
  - "----------->  ----------->\n              circuit_start\n                   \
    \        TCP Connection Setup\n                             <------------->\n\
    \                            Capabilities Exch.\n                            \
    \ <------------->\n                             CANUREACH_cs    DLC_START_DL\n\
    \                             ----------->    ----------->\n                 \
    \                             resolve_pending\n                             ICANREACH_cs\
    \    DLC_DL_STARTED\n                             <-----------    <-------------\n\
    \           circuit_established                circuit_pending\n             \
    \                 REACH_ACK\n                              ----------->  circuit_established\n\
    \                               XIDFRAME         DLC_XID       null XID\n    \
    \                           ----------->     --------->    -------->\n       \
    \ XID        DLC_XID      XIDFRAME         DLC_XID          XID\n  <-------- \
    \  <-----------   <-----------    <-----------    <--------\n    XIDs        \
    \ DLC_XIDs      XIDFRAMEs        DLC_XIDs         XIDs\n"
- title: <---------->  <---------->   <------------>  <------------>  <--------->
  contents:
  - '<---------->  <---------->   <------------>  <------------>  <--------->

    '
- title: SABME         DLC_CONTACTED   CONTACT         DLC_CONTACT     SABME
  contents:
  - 'SABME         DLC_CONTACTED   CONTACT         DLC_CONTACT     SABME

    '
- title: '----------->  ----------->     ----------->    ----------->    -------->'
  contents:
  - "----------->  ----------->     ----------->    ----------->    -------->\n  \
    \            connect_pending                 contact_pending\n          UA   \
    \  DLC_CONTACT     CONTACTED    DLC_CONTACTED          UA\n  <---------   <-----------\
    \  <-----------    <-----------    <--------\n                  connected    \
    \                  connected\n"
- title: IFRAMEs       DLC_INFOs        IFRAMEs        DLC_INFOs       IFRAMEs
  contents:
  - 'IFRAMEs       DLC_INFOs        IFRAMEs        DLC_INFOs       IFRAMEs

    '
- title: <---------->  <----------->  <------------>  <------------>  <-------->
  contents:
  - '<---------->  <----------->  <------------>  <------------>  <-------->

    '
- title: 8.5 UDP Reliability
  contents:
  - "8.5 UDP Reliability\n   It is important to note, that UDP (unicast and multicast)transport\n\
    \   services do not provide a reliable means of delivery.  Existing RFC\n   1795\
    \ protocols guarantee the delivery (or failure notification) of\n   CANUREACH_ex\
    \ and ICANREACH_ex messages.  UDP will not provide the\n   same level of reliability.\
    \  It is, therefore, possible that these\n   messages may be lost in the network\
    \ and (CANUREACH_ex) retries will\n   be necessary.\n"
- title: 8.5.1 Retries
  contents:
  - "8.5.1 Retries\n   Test Frames are generally initiated by end stations every few\n\
    \   seconds.  Many existing RFC 1795 DLSw implementations take advantage\n   of\
    \ the reliable SSP TCP connections and filter out end station Test\n   frame retries\
    \ when a CANUREACH_ex is outstanding.  Given the\n   unreliable nature of UDP\
    \ transport for these messages, however, this\n   filtering technique may not\
    \ be advisable.  Neither RFC 1795 nor this\n   paper address this issue specifically.\
    \  It is simply noted that the\n   UDP transport mechanism is unreliable and implementations\
    \ should take\n   this into account when determining a scheme for Test frame filtering\n\
    \   and explorer retries.  Accordingly, the Retry section in the table\n   above\
    \ only serves as an indicator of situations where retries may be\n   desirable\
    \ and/or necessary, but does not imply any requirement to\n   implement retries.\
    \ Also note, that retry logic only applies to non-\n   response type packets.\
    \  It is not appropriate to retry response type\n   SSP packets (i.e., ICANREACH_ex)\
    \ as there is no way of knowing if the\n   original response was ever received\
    \ (and whether retry is necessary).\n   So in the case of SNA, CANUREACH_ex messages\
    \ may need retry logic and\n   ICANREACH_ex messages do not.\n"
- title: 9. NetBIOS
  contents:
  - "9. NetBIOS\n   With the introduction of DLSw Multicast transport, all multicast\n\
    \   NetBIOS UI frames are carried outside the TCP connections between\n   DLSw\
    \ peers (i.e., via UDP datagrams).  The following table defines\n   the various\
    \ NetBIOS UI frames and how they are transported via UDP\n   between multicast\
    \ capable DLSw peers:\n                                              Transport\n"
- title: Message Event            Action               Mechanism           Retry
  contents:
  - 'Message Event            Action               Mechanism           Retry

    '
- title: '---------------------------------------------------------------------------'
  contents:
  - '---------------------------------------------------------------------------

    '
- title: ADD_GROUP_NAME_QUERY     SEND DATAFRAME       Multicast            Yes
  contents:
  - 'ADD_GROUP_NAME_QUERY     SEND DATAFRAME       Multicast            Yes

    '
- title: ADD_NAME_QUERY           SEND NETBIOS_ANQ     Multicast            Yes
  contents:
  - 'ADD_NAME_QUERY           SEND NETBIOS_ANQ     Multicast            Yes

    '
- title: ADD_NAME_RESPONSE        SEND NETBIOS_ANR     Unicast1             No
  contents:
  - 'ADD_NAME_RESPONSE        SEND NETBIOS_ANR     Unicast1             No

    '
- title: NAME_IN_CONFLICT         SEND DATAFRAME       Multicast            No
  contents:
  - 'NAME_IN_CONFLICT         SEND DATAFRAME       Multicast            No

    '
- title: STATUS_QUERY             SEND DATAFRAME       Unicast/Multicast(2) Yes
  contents:
  - 'STATUS_QUERY             SEND DATAFRAME       Unicast/Multicast(2) Yes

    '
- title: STATUS_RESPONSE          SEND DATAFRAME       Multicast(5)         No
  contents:
  - 'STATUS_RESPONSE          SEND DATAFRAME       Multicast(5)         No

    '
- title: TERMINATE_TRACE (x'07')  SEND DATAFRAME       Multicast            No
  contents:
  - 'TERMINATE_TRACE (x''07'')  SEND DATAFRAME       Multicast            No

    '
- title: TERMINATE_TRACE (X'13')  SEND DATAFRAME       Multicast            No
  contents:
  - 'TERMINATE_TRACE (X''13'')  SEND DATAFRAME       Multicast            No

    '
- title: DATAGRAM                 SEND DATAFRAME(3)    Unicast/Multicast(2) No
  contents:
  - 'DATAGRAM                 SEND DATAFRAME(3)    Unicast/Multicast(2) No

    '
- title: DATAGRAM_BROADCAST       SEND DATAFRAME       Multicast            No
  contents:
  - 'DATAGRAM_BROADCAST       SEND DATAFRAME       Multicast            No

    '
- title: NAME_QUERY               SEND NETBIOS_NQ_ex   Unicast/Multicast(2) Yes
  contents:
  - 'NAME_QUERY               SEND NETBIOS_NQ_ex   Unicast/Multicast(2) Yes

    '
- title: NAME_RECOGNIZED          SEND NETBIOS_NR_ex   Unicast(4)           No
  contents:
  - "NAME_RECOGNIZED          SEND NETBIOS_NR_ex   Unicast(4)           No\n   Note\
    \ 1:\n   Upon receipt of an ADD_NAME_RESPONSE frame, a NETBIOS_ANR SSP message\n\
    \   is returned via unicast UDP to the originator of the NETBIOS_ANQ\n   message.\n\
    \   Note 2:\n   These frames may be sent either Unicast or Multicast UDP.  If\
    \ the\n   implementation has sufficient cached information to resolve the\n  \
    \ NetBIOS datagram destination to a single DLSw peer, then the SSP\n   message\
    \ can and should be sent via unicast.  If the cache does not\n   contain such\
    \ information then the resultant SSP message must be sent\n   via multicast UDP.\n\
    \   Note 3:\n   Note that this frame is sent as either a DATAFRAME or DGRMFRAME\n\
    \   according to the rules as specified in RFC 1795.\n   Note 4:\n   Upon receipt\
    \ of a NAME_RECOGNIZED frame, a NETBIOS_NR_ex SSP message\n   is returned via\
    \ unicast UDP to the originator of the NETBIOS_NQ_ex\n   frame.  Notice that although\
    \ the NAME_RECOGNIZED frame is sent as an\n   All Routes Explorer (source routing\
    \ LANs only) frame, the resultant\n   NETBIOS_NR_ex is sent as a unicast UDP directed\
    \ response to the DLSw\n   originating the NETBIOS_NQ_ex.  This is because there\
    \ is no value in\n   sending NETBIOS_NR_ex as a multicast packet in the transport\
    \ network.\n   The use of ARE transmission in the LAN environment is to accomplish\n\
    \   some form of load sharing in the source routed LAN environment.\n   Since\
    \ no analogous capability exists in the (TCP) transport network,\n   it is not\
    \ necessary to emulate this function there.  It is important\n   to note, however,\
    \ that when converting a received NETBIOS_NR_ex to a\n   NAME_RECOGNIZED frame,\
    \ the DLSw sends the NAME_RECOGNIZED frame onto\n   the LAN as an ARE (source\
    \ routing LANs only) frame.  This preserves\n   the source route load sharing\
    \ in the LAN environments on either side\n   of the DLSw transport network.\n\
    \   Note 5:\n   Although RFC 1795 does not attempt to optimize STATUS_RESPONSE\n\
    \   processing, it is possible to send a STATUS_RESPONSE as a unicast UDP\n  \
    \ response.  To do this, DLSws receiving an incoming SSP DATAFRAME\n   containing\
    \ a STATUS_QUERY must remember the originating DLSw's\n   address and STATUS_QUERY\
    \ correlator.  Then upon receipt of the\n   corresponding STATUS_RESPONSE, the\
    \ DLSw responds via unicast UDP to\n   the originating DLSw(using the remembered\
    \ originating DLSw address).\n   Note, however, that in order to determine whether\
    \ a frame is a\n   STATUS_QUERY, all multicast capable DLSw implementations will\
    \ need to\n   parse the contents of frames that would normally be sent as DATAFRAME\n\
    \   SSP messages.\n   All other multicast frames are sent into the transport network\
    \ using\n   the appropriate multicast group address.\n"
- title: 9.1 Address Resolution
  contents:
  - "9.1 Address Resolution\n   Typical NetBIOS circuit setup using multicast services\
    \ is essentially\n   the same as specified in RFC 1795.  The only significant\
    \ difference\n   is that NETBIOS_NQ_ex messages are sent via UDP to the appropriate\n\
    \   unicast/multicast IP address and the NETBIOS_NR_ex is sent via\n   unicast\
    \ UDP to the DLSw originating the NETBIOS_NQ_ex.\n"
- title: 9.2 Explorer Frames
  contents:
  - "9.2 Explorer Frames\n   Address resolution messages may be sent over a TCP connection\
    \ to a\n   multicast capable partner if such a connection already exists in\n\
    \   order that they take advantage of the guaranteed delivery of TCP.\n   This\
    \ is particularly recommended for NETBIOS_NR_ex frames.\n"
- title: 9.3 Circuit Setup
  contents:
  - "9.3 Circuit Setup\n   Following successful address resolution, a NetBIOS end\
    \ station\n   typically sends a SABME frame to initiate a formal LLC2 connection.\n\
    \   Receipt of this message results in normal circuit setup as described\n   in\
    \ RFC 1795 (and the SNA case described above).  That is to say that\n   the CANUREACH_cs\
    \ messages etc. are sent on a TCP connection to the\n   appropriate DLSw peer.\
    \  If no such TCP connection exists, one is\n   brought up.\n"
- title: 9.4 Example NetBIOS SSP Message Sequence
  contents:
  - "9.4 Example NetBIOS SSP Message Sequence\n   The following diagram provides an\
    \ example sequence of flows\n   associated with a NetBIOS circuit setup.  All\
    \ flows and states\n   described below correspond precisely with those defined\
    \ in RFC 1795.\n   The only exception is the addition of a TCP connection setup\
    \ and DLSw\n   capabilities exchange that occurs when the origin DLSw must send\
    \ a\n   CANUREACH_cs and no TCP connection yet exists to the target DLSw\n   peer.\n\
    \ ======                            ___                           ======\n | \
    \   |        ---------        __/   \\__       ---------        |    |\n |   \
    \ |      __|  _|_  |__     /   IP    \\    __|  _|_  |__      |    |\n ======\
    \        |   |   |      <  Network  >     |   |   |        ======\n"
- title: /______\       ---------       \__     __/      ---------       /______\
  contents:
  - "/______\\       ---------       \\__     __/      ---------       /______\\\n\
    \ Origin       Origin DLSw         \\___/        Target DLSw      Target\n Station\
    \        partner                          partner        Station\n           \
    \   disconnected                     disconnected\n"
- title: NAME_QUERY    DLC_DGRM        NETBIOS_NQ_ex   DLC_DGRM       NAME_QUERY
  contents:
  - 'NAME_QUERY    DLC_DGRM        NETBIOS_NQ_ex   DLC_DGRM       NAME_QUERY

    '
- title: '----------->  ----------->    ----------->    ----------->   --------->'
  contents:
  - "----------->  ----------->    ----------->    ----------->   --------->\n  NAME_RECOG\
    \    DLC_DGRM      NETBIOS_NR_ex     DLC_DGRM    NAME_RECOG\n"
- title: <-----------  <------------   <-----------    <-----------  <---------
  contents:
  - '<-----------  <------------   <-----------    <-----------  <---------

    '
- title: SABME         DLC_CONTACTED
  contents:
  - 'SABME         DLC_CONTACTED

    '
- title: '----------->  ----------->'
  contents:
  - "----------->  ----------->\n               circuit_start\n                  \
    \          TCP Connection Setup\n                              <------------->\n\
    \                            Capabilities Exch.\n                            \
    \  <------------->\n                              CANUREACH_cs    DLC_START_DL\n\
    \                              ----------->    ----------->\n                \
    \                             resolve_pending\n                              ICANREACH_cs\
    \    DLC_DL_STARTED\n                              <-----------    <-----------\n\
    \            circuit_established                circuit_pending\n            \
    \                  REACH_ACK\n                              ----------->   circuit_established\n\
    \                              CONTACT         DLC_CONTACT     SABME\n       \
    \                       ----------->    ----------->    --------->\n         \
    \    connect_pending                   contact_pending\n          UA   DLC_CONTACT\
    \       CONTACTED    DLC_CONTACTED           UA\n  <---------   <----------- \
    \  <-----------    <-----------    <---------\n                connected     \
    \                   connected\n   IFRAMEs       DLC_INFOs       IFRAMEs      \
    \  DLC_INFOs       IFRAMEs\n"
- title: <------------> <------------> <------------>  <------------>  <-------->
  contents:
  - '<------------> <------------> <------------>  <------------>  <-------->

    '
- title: 9.5 Multicast Reliability and Retries
  contents:
  - "9.5 Multicast Reliability and Retries\n   In the case of NetBIOS, many more packets\
    \ are being sent via UDP than\n   in the SNA case.  Therefore, the exposure to\
    \ the unreliability of\n   these services is greater than that of SNA. For address\
    \ resolution\n   frames, such as NAME_QUERY, etc., successful message delivery\
    \ is an\n   issue.  In addition, the retry interval for these types of frames\
    \ is\n   considerably shorter than SNA with the defaults being: retry interval\n\
    \   = 0.5 seconds and retry count = 6.  Once again, neither RFC 1795 nor\n   this\
    \ paper attempt to address the issue of LAN frame filtering\n   optimizations.\
    \ This issue is outside the scope of this paper.  But it\n   is important for\
    \ implementers to recognize the inherent unreliable\n   nature of UDP transport\
    \ services for frames of this type and to\n   implement retry schemes that are\
    \ appropriate to successful operation.\n   Again, it is only appropriate to consider\
    \ retry of non-response type\n   packets.  Specific NetBIOS messages where successful\
    \ message delivery\n   is considered important (and retries possibly necessary)\
    \ are\n   indicated in the table above with an Yes in the Retry column.\n"
- title: 10. Sequencing
  contents:
  - "10. Sequencing\n   It is important to note that UDP transport services do not\
    \ provide\n   guaranteed packet sequencing like TCP does for RFC 1795.  In a steady\n\
    \   state network, in order packet delivery can be generally assumed.\n   But\
    \ in the presence of network outages and topology changes, packets\n   may take\
    \ alternate routes to the destination and arrive out of\n   sequence with respect\
    \ to their original transmission order.  For SNA\n   address resolution this should\
    \ not be a problem given that there is\n   no inherent significance to the order\
    \ of packets being transmitted\n   via UDP.\n   In the case of NetBIOS, in order\
    \ delivery is not guaranteed in the\n   normal case (e.g., LANs).  This is because\
    \ LAN broadcasting\n   mechanisms suffer the same problems of packet sequencing\
    \ as do WAN\n   multicast mechanisms.  But one might argue the greater likelihood\
    \ of\n   topology related changes in the WAN environment and thus a greater\n\
    \   level of concern.  The vast majority of NetBIOS UI frames (being\n   handled\
    \ via UDP and Multicast) have correlator values and do not rely\n   upon packet\
    \ sequencing.\n   The only NetBIOS frames of special note would be: DATAGRAM,\n\
    \   DATAGRAM_BROADCAST, and STATUS_RESPONSE.  In the case of DATAGRAM and\n  \
    \ DATAGRAM_BROADCAST it is generally assumed that datagrams do not\n   provide\
    \ any guarantee of in order packet delivery.  Thus applications\n   utilizing\
    \ this NetBIOS service are assumed to have no dependency on\n   in order packet\
    \ delivery.  STATUS_RESPONSE can actually be sent as a\n   sequence of STATUS_RESPONSE\
    \ messages.  In cases where this occurs,\n   the STATUS_RESPONSE will be exposed\
    \ to potential out of sequence\n   delivery.\n"
- title: 11. Frame Formats
  contents:
  - '11. Frame Formats

    '
- title: 11.1 Multicast Capabilities Control Vector
  contents:
  - "11.1 Multicast Capabilities Control Vector\n   This control vector is carried\
    \ in the Capabilities Exchange Request.\n   When present, it must be accompanied\
    \ by a TCP Connections Control\n   Vector indicating support for 1 TCP/IP connection\
    \ and a DLSw version\n   CV indicating support for version 2 release 0.  Like\
    \ all control\n   vectors in this SSP message, it is an LT structure.  LT structures\n\
    \   consist of a 1 byte length field followed by a 1 byte type field.\n   The\
    \ length field includes itself as well as the type and data fields.\n   Byte Bit\
    \    Description\n   0   0-7    Length, in binary, of the Multicast Capabilities\
    \ control\n   vector (inclusive of this byte, always 3)\n   1   0-7    Type: \
    \ x'8C'\n   2   0-7    Multicast Version Number:\n               A binary numerical\
    \ representation of the level of\n               multicast services provided.\
    \  The protocols as identified\n               in this document constitute version\
    \ one.   Accordingly,\n               x'01' is encoded in this field.  Any subsequent\
    \ version\n               must provide the services of all previous versions.\n\
    \   The intended use of this CV for Multicast support is to detect when\n   the\
    \ multicast CANUREACH_ex flows will suffice between partners.  If\n   this CV\
    \ is present in a CAPEX from a partner, that partner is also\n   multicast capable\
    \ and therefore does not need to receive CANUREACH_ex\n   messages over the TCP\
    \ link that exists between them (and there must\n   be one or else the CAPEX would\
    \ not have flowed) because it will\n   receive the multicast copies.\n   A DLSw\
    \ includes this control vector on a peer-wise basis.  That is to\n   say, that\
    \ a DLSw implementation may support multicast services but\n   choose not to indicate\
    \ this in its capabilities exchange to all\n   partners. Therefore, a DLSw may\
    \ include this capabilities CV with\n   some DLSw peers and not with others. \
    \ Not including this vector can\n   be used to force TCP connections with other\
    \ multicast capable nodes\n   and degrade to normal RFC 1795 operations.  This\
    \ capability is\n   allowed to provide greater network design flexibility.\n \
    \  When sending this capabilities exchange control vector, the following\n   rules\
    \ apply:\n         Required                       Allowed @\n    ID   @ Startup\
    \  Length  Repeatable* Runtime  Order  Content\n   ====  =========  ======  ==========\
    \  =======  =====  ===============\n   0x8C     Y        0x03        N       \
    \  N       5+    Multicast\n                                                 \
    \        Capabilities\n"
- title: '*Note: "Repeatable" means a Control Vector is repeatable within a single'
  contents:
  - "*Note: \"Repeatable\" means a Control Vector is repeatable within a single\n\
    \   message.\n"
- title: 11.1.1 DLSw Capabilities Negative Response
  contents:
  - "11.1.1 DLSw Capabilities Negative Response\n   DLSws that implement these enhancements\
    \ must provide support for both\n   multicast version 1 and single TCP connections.\
    \  This means that the\n   capabilities exchange request must contain a DLSw Version\
    \ ID control\n   vector (x'82') indicating support for version 2 release 0, a\n\
    \   Multicast Capabilities control vector, and the TCP Connections\n   control\
    \ vector indicating support for 1 TCP connection within a given\n   capabilities\
    \ exchange. If a multicast capable DLSw receives a\n   capabilities exchange with\
    \ a Multicast Capabilities, but either a\n   missing or inappropriate TCP Connections\
    \ CV (i.e., connections not\n   equal to one)or DLSw Version control vector, then\
    \ the inbound\n   capabilities exchange should be rejected with a DLSw capabilities\n\
    \   exchange negative response (see RFC 1795) using the following new\n   reason\
    \ code:\n   x'000D'Inconsistent DLSw Version,  Multicast Capabilities, and TCP\n\
    \   Connections CV received on the inbound Capabilities exchange\n"
- title: 11.2 UDP Packets
  contents:
  - "11.2 UDP Packets\n   SSP frame formats are defined in RFC 1795.  Multicast protocol\n\
    \   enhancements do not change these formats in any way.  The multicast\n   protocol\
    \ enhancements, however, do introduce the notion of SSP packet\n   transport via\
    \ UDP.  In this case, standard UDP services and headers\n   are used to transport\
    \ SSP packets.\n   The following section describes the proper UDP header for DLSw\
    \ SSP\n   packets.\n   Byte       Description\n   0-1        Source Port address\n\
    \               In DLSw multicast protocols, this particular field is not\n  \
    \             relevant.  It may be set to any value.\n   2-3        Destination\
    \ Port address\n               Always set to 2067\n   4-5        Length\n   6-7\
    \        Checksum\n               The standard UDP checksum value.  Use of the\
    \ UDP checksum\n               function is optional.\n"
- title: 11.3 Vendor Specific UDP Packets
  contents:
  - "11.3 Vendor Specific UDP Packets\n   In order to accommodate the addition of\
    \ vendor specific functions\n   over UDP transport, a new SSP packet header has\
    \ been defined. As\n   described above, it is possible to receive these packets\
    \ over both\n   UDP and TCP (when a TCP connection already exists).\n   It is\
    \ important to note that the first 4 bytes of this packet match\n   the format\
    \ of existing RFC 1795 SSP packets.  This is done so that\n   implementations\
    \ in the future can expect that the DLSw Version\n   Number is found in byte one\
    \ and that the following bytes describe\n   the packet header and message length.\n\
    \   Furthermore, to assist DLSws in detecting 'out-of-sync' conditions\n   whereby\
    \ packet or parsing errors lead to improper length\n   interpretations in the\
    \ TCP datastream, valid DLSw version numbers\n   will be restricted to the range\
    \ of x'31' through x'3F' inclusive.\n   DLSw multicast Vendor Specific frame format\
    \ differs from existing RFC\n   1795 packets in the following ways:\n   1) The\
    \ Version Number field is set to x'32' (ASCII '2') and now\n   represents a packet\
    \ type more than a DLSw version number.  More\n   precisely, it is permitted and\
    \ expected that DLSw may send packets of\n   both types (x'31' and x'32').\n \
    \  2) The message length field is followed by a new 3 byte field that\n   contains\
    \ the specific vendor's IEEE Organizationally Unique\n   Identifier (OUI).\n \
    \  3) All fields following the new OUI field are arbitrary and defined\n   by\
    \ implementers.\n   The following section defines this new packet format:\n  \
    \ Byte       Description\n   0          DLSw packet type, Always set to x'32'\n\
    \   1          Header Length\n               Always 7 or higher\n   2-3      \
    \  Message Length\n               Number of bytes within the data field following\
    \ the\n               header.\n   4-6        Vendor specific OUI\n           \
    \    The IEEE Organizationally Unique Identifier (OUI)\n               associated\
    \ with the vendor specific function in\n               question.\n   7-n     \
    \   Defined by the OUI owner\n"
- title: 12. Compliance Statement
  contents:
  - "12. Compliance Statement\n   All DLSw v2.0 implementations must support\n   -\
    \ Halt reason codes\n   - the Multicast Capabilities control vector in the DLSw\n\
    \     capabilities exchanges messages.\n   The presence of the Multicast Capabilities\
    \ control vector in a\n   capabilities exchange message implies that the DLSw\
    \ that issued the\n   message supports all the scalability enhancements defined\
    \ in this\n   document.  These are:\n   - use of multicast IP (if it is available\
    \ in the underlying network)\n   - use of 2067 as the destination port for UDP\
    \ and TCP connections\n   - single tunnel bring-up of TCP connections to DLSw\
    \ peers\n   - peer-on-demand\n   - quiet ignore of all unrecognized vendor-specific\
    \ UDP/TCP packets.\n"
- title: 13. Security Considerations
  contents:
  - "13. Security Considerations\n   This document addresses only scalability problems\
    \ in RFC 1795.  No\n   attempt is made to define any additional security mechanisms.\
    \  Note\n   that, as in RFC 1795, a given implementation may still choose to\n\
    \   refuse TCP connections from DLSw peers that have not been configured\n   by\
    \ the user.  The mechanism by which the user configures this\n   behavior is not\
    \ specified in this document.\n"
- title: 14. Acknowledgements
  contents:
  - "14. Acknowledgements\n   This specification was developed in the DLSw Related\
    \ Interest Group\n   (RIG) of the APPN Implementers Workshop.  This RIG is chaired\
    \ by\n   Louise Herndon- Wells (lhwells@cup.portal.com) and edited by Paul\n \
    \  Brittain (pjb@datcon.co.uk).\n   Much of the work on the scalability enhancements\
    \ for v2.0 was\n   developed by Dave Bryant (3COM).\n   Other significant contributors\
    \ to this document include:\n   Frank Bordonaro (Cisco)\n   Jon Houghton (IBM)\n\
    \   Steve Klein (IBM)\n   Ravi Periasamy (Cisco)\n   Mike Redden (Proteon)\n \
    \  Doug Wolff (3COM)\n   Many thanks also to all those who participated in the\
    \ DLSw RIG\n   sessions and mail exploder discussions.\n   If you would like to\
    \ participate in future DLSw discussions, please\n   subscribe to the DLSw RIG\
    \ mailing lists by sending a mail to\n   majordomo@raleigh.ibm.com specifying\
    \ 'subscribe aiw-dlsw' as the body\n   of the message.\n   If you would like further\
    \ information on the activities of the AIW,\n   please refer to the AIW web site\
    \ at\n   http://www.raleigh.ibm.com/app/aiwhome.htm.\n"
- title: 15. Authors' Addresses
  contents:
  - "15. Authors' Addresses\n   The editor of this document is:\n         Paul Brittain\n\
    \         Data Connection Ltd\n         Windsor House\n         Pepper Street\n\
    \         Chester\n         CH1 1DF\n         UK\n         tel:   +44 1244 313440\n\
    \         email: pjb@datcon.co.uk\n   Much of the work on this document was created\
    \ by:\n         David Bryant\n         3Com Corporation\n         5400 Bayfront\
    \ Plaza MS 2418\n         Santa Clara, CA 95052\n         tel:   (408) 764-5272\n\
    \         email: David_Bryant@3mail.3com.com\n"
- title: 16. Appendix - Clarifications to RFC 1795
  contents:
  - "16. Appendix - Clarifications to RFC 1795\n   This appendix attempts to clarify\
    \ the areas of RFC 1795 that have\n   proven to be ambiguous or hard to understand\
    \ in the implementation\n   experience to- date.  These clarifications should\
    \ be read in\n   conjunction with RFC 1795 as this document does not reproduce\
    \ the\n   complete text of that RFC.\n   The clarifications are ordered by the\
    \ section number in RFC 1795 to\n   which they apply.  Where one point applies\
    \ to more than one place in\n   RFC 1795, it is listed below by the first relevant\
    \ section.\n   If any implementers encounter further difficulties in understanding\n\
    \   RFC 1795 or these clarifications, they are encouraged to query the\n   DLSw\
    \ mail exploder (see section 1.1) for assistance.\n   3. Send Port\n   It is not\
    \ permitted for a DLSw implementation to check that the send\n   port used by\
    \ a partner is 2067.  All implementations must accept\n   connections from partners\
    \ that do not use this port.\n   3   TCP Tunnel bringup\n   The paragraph below\
    \ the figure should read as follows:\n      Each Data Link Switch will maintain\
    \ a list of DLSw capable routers\n      and their status (active/inactive). Before\
    \ Data Link Switching can\n      occur between two routers, they must establish\
    \ two TCP connections\n      between them. These connections are treated as half\
    \ duplex data\n      pipes. A Data Link Switch will listen for incoming connections\
    \ on\n      its Read Port (2065), and initiate outgoing connections on its\n \
    \     Write Port (2067).  Each Switch is responsible for initiating one\n    \
    \  of the two TCP connections.  After the TCP connections are\n      established,\
    \ SSP messages are exchanged to establish the\n      capabilities of the two Data\
    \ Link Switches.  Once the exchange is\n      complete, the DLSw will employ SSP\
    \ control messages to establish\n      end-to-end circuits over the transport\
    \ connection.  Within the\n      transport connection, DLSw SSP messages are exchanged.\
    \  The\n      message formats and types for these SSP messages are documented\
    \ in\n      the following sections.\n   3.2 RII bit in SSP header MAC addresses\n\
    \   The RII bit in MAC addresses received from the LAN must be set to\n   zero\
    \ before forwarding in the source or destination address field in\n   a SSP message\
    \ header.  This requirement aims to avoid ambiguity of\n   circuit IDs.  It is\
    \ also recommended that all implementations ignore\n   this bit in received SSP\
    \ message headers.\n   3.3 Transport IDs\n   All implementations must allow for\
    \ the DLSw peer varying the\n   Transport ID up to and including when the ICR_cs\
    \ message flows, and\n   at all times reflect the most recent TID received from\
    \ the partner in\n   any SSP messages sent.  The TID cannot vary once the ICR_cs\
    \ message\n   has flowed.\n   3.4 LF bits\n   LF-bits should be propagated from\
    \ LAN to SSP to LAN (and back) as per\n   a bridge (i.e. they can only be revised\
    \ downwards at each step if\n   required).\n   3.5 KEEPALIVE messages\n   The\
    \ SSP KEEPALIVE message (x1D) uses the short (\"infoframe\") version\n   of the\
    \ SSP header.  All DLSw implementation must support receipt and\n   quiet ignore\
    \ of this message, but there is not requirement to send\n   it.  There is no response\
    \ to a KEEPALIVE message.\n   3.5 MAC header for Netbios SSP frames\n   The MAC\
    \ header is included in forwarded SSP Netbios frames in the\n   format described\
    \ below:\n        -    addresses are always in non-canonical format\n        -\
    \    src/dest addresses are as per the LLC frame\n        -    AC/FC bits may\
    \ be reset and must be ignored\n        -    SSAP, DSAP and command fields are\
    \ included\n        -    RII bit in src address is copied from the LLC frame\n\
    \        -    the RIF length is not extended to include padding\n        -   \
    \ all RIFs are padded to 18 bytes so that the data is\n             in a consistent\
    \ place.\n   3.5.7 Unrecognized control vectors\n   All implementations should\
    \ quietly ignore unrecognized control\n   vectors in any SSP messages.  In particular,\
    \ unrecognized SSP frames\n   or unrecognized fields in a CAPEX message should\
    \ be quietly ignored\n   without dropping the TCP connection.\n   5.4 Use of CUR-cs/CUR-ex\n\
    \   The SSAP and DSAP numbers in CUR_ex messages should reflect those\n   actually\
    \ used in the TEST (or equivalent) frame that caused the\n   CUR_ex message to\
    \ flow.  This would mean that the SAP numbers in a\n   'typical' CUR_ex frame\
    \ for SNA traffic switched from a LAN will be a\n   source SAP of x04 and a destination\
    \ SAP of x00.\n   The CUR_cs frame should only be sent when the DSAP is known.\n\
    \   Specifically, CUR_ex should be used when a NULL XID is received that\n   is\
    \ targeted at DSAP zero, and CUR_cs when a XID specifying the (non-\n   zero)\
    \ DSAP is received.\n   Note that this does not mean that an implementation can\
    \ assume that\n   the DSAP on a CUR_ex will always be zero.  The ICR_ex must always\n\
    \   reflect the SSAP and DSAP values sent on the CUR_ex.  This is still\n   true\
    \ even if an implementation always sends a TEST with DSAP = x00 on\n   its local\
    \ LAN(s) in response to a CUR_ex to any SAP.\n   An example of a situation where\
    \ the CUR_ex may flow with a non-zero\n   DSAP is when there is an APPN stack\
    \ local to the DLSw node.  The APPN\n   stack may then issue a connection request\
    \ specifying the DSAP as a\n   non-zero value.  This would then be passed on the\
    \ CUR_ex message.\n   7.6.1 Vendor IDs\n   The Vendor ID field in a CAPEX may\
    \ be zero.  However, a zero Vendor\n   Context ID is not permitted, which implies\
    \ that an implementation\n   that uses a zero ID cannot send any vendor-specific\
    \ CVs (other than\n   those specified by other vendors that do have a non-zero\
    \ ID)\n   7.6.3 Initial Pacing Window\n   The initial pacing window may be 1.\
    \  There is no requirement on an\n   implementation to use any minimum value for\
    \ the initial pacing\n   window.\n   7.6.7 TCP Tunnel bringup\n   The third paragraph\
    \ should read:\n      If TCP Connections CV values agree and the number of connections\n\
    \      is one, then the DLSw with the higher IP address must tear down\n     \
    \ the TCP connections on its local port 2065. This connection is\n      torn down\
    \ after a CAPEX response has been both sent and received.\n      After this point,\
    \ the remaining TCP connection is used to exchange\n      data in both directions.\n\
    \   7.7 CAPEX negative responses\n   If a DLSw does not support any of the options\
    \ specified on a CAPEX\n   received from a partner, or if it thinks the CAPEX\
    \ is malformed, it\n   must send a CAPEX negative response to the partner.  The\
    \ receiver of\n   a CAPEX negative response is then responsible for dropping the\n\
    \   connection.  It is not permitted to drop the link instead of sending\n   a\
    \ CAPEX negative response.\n   8.2 Flow Control ACKs\n   The first flow-control\
    \ ack (FCACK) does not have to be returned on\n   the REACH_ACK even if the ICR_cs\
    \ carried the FCIND bit.  However it\n   should be returned on the first SSP frame\
    \ flowing for that circuit\n   after the REACH_ACK.\n"
