- title: __initial_text__
  contents:
  - '     Inter-Domain Policy Routing Protocol Specification: Version 1

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This RFC specifies an IAB standards track protocol for\
    \ the Internet\n   community, and requests discussion and suggestions for improvements.\n\
    \   Please refer to the current edition of the \"IAB Official Protocol\n   Standards\"\
    \ for the standardization state and status of this protocol.\n   Distribution\
    \ of this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   We present the set of protocols and procedures that constitute\n\
    \   Inter-Domain Policy Routing (IDPR).  IDPR includes the virtual\n   gateway\
    \ protocol, the flooding protocol, the route server query\n   protocol, the route\
    \ generation procedure, the path control protocol,\n   and the data message forwarding\
    \ procedure.\n"
- title: Contributors
  contents:
  - "Contributors\n   The following people have contributed to the protocols and procedures\n\
    \   described in this document: Helen Bowns, Lee Breslau, Ken Carlberg,\n   Isidro\
    \ Castineyra, Deborah Estrin, Tony Li, Mike Little, Katia\n   Obraczka, Sam Resheff,\
    \ Martha Steenstrup, Gene Tsudik, and Robert\n   Woodburn.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction. . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . 3\n   1.1. Domain Elements . . . . . . . . . . . . . . . . . . .\
    \ . . . . 3\n   1.2. Policy. . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . 5\n   1.3. IDPR Functions. . . . . . . . . . . . . . . . . . . . . . . .\
    \ 5\n   1.3.1. IDPR Entities . . . . . . . . . . . . . . . . . . . . . . . 6\n\
    \   1.4. Policy Semantics. . . . . . . . . . . . . . . . . . . . . . . 7\n   1.4.1.\
    \ Source Policies . . . . . . . . . . . . . . . . . . . . . . 7\n   1.4.2. Transit\
    \ Policies. . . . . . . . . . . . . . . . . . . . . . 8\n   1.5. IDPR Message\
    \ Encapsulation. . . . . . . . . . . . . . . . . . 9\n   1.5.1. IDPR Data Message\
    \ Format. . . . . . . . . . . . . . . . . .11\n   1.6. Security. . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . .12\n   1.7. Timestamps and Clock Synchronization.\
    \ . . . . . . . . . . . .13\n   1.8. Network Management. . . . . . . . . . . .\
    \ . . . . . . . . . .14\n   1.8.1. Policy Gateway Configuration. . . . . . . .\
    \ . . . . . . . .17\n   1.8.2. Route Server Configuration. . . . . . . . . . .\
    \ . . . . . .18\n   2. Control Message Transport Protocol. . . . . . . . . . .\
    \ . . . .18\n   2.1. Message Transmission. . . . . . . . . . . . . . . . . . .\
    \ . .20\n   2.2. Message Reception . . . . . . . . . . . . . . . . . . . . . .22\n\
    \   2.3. Message Validation. . . . . . . . . . . . . . . . . . . . . .23\n   2.4.\
    \ CMTP Message Formats. . . . . . . . . . . . . . . . . . . . .24\n   3. Virtual\
    \ Gateway Protocol. . . . . . . . . . . . . . . . . . . .27\n   3.1. Message Scope\
    \ . . . . . . . . . . . . . . . . . . . . . . . .28\n   3.1.1. Pair-PG Messages.\
    \ . . . . . . . . . . . . . . . . . . . . .28\n   3.1.2. Intra-VG Messages . .\
    \ . . . . . . . . . . . . . . . . . . .29\n   3.1.3. Inter-VG Messages . . . .\
    \ . . . . . . . . . . . . . . . . .29\n   3.1.4. VG Representatives. . . . . .\
    \ . . . . . . . . . . . . . . .31\n   3.2. Up/Down Protocol. . . . . . . . . .\
    \ . . . . . . . . . . . . .31\n   3.3. Implementation. . . . . . . . . . . . .\
    \ . . . . . . . . . . .33\n   3.4. Policy Gateway Connectivity . . . . . . . .\
    \ . . . . . . . . .35\n   3.4.1. Within a Virtual Gateway. . . . . . . . . . .\
    \ . . . . . . .35\n   3.4.2. Between Virtual Gateways. . . . . . . . . . . . .\
    \ . . . . .37\n   3.4.3. Communication Complexity. . . . . . . . . . . . . . .\
    \ . . .40\n   3.5. VGP Message Formats . . . . . . . . . . . . . . . . . . . .\
    \ .41\n   3.5.1. UP/DOWN . . . . . . . . . . . . . . . . . . . . . . . . . .41\n\
    \   3.5.2. PG CONNECT. . . . . . . . . . . . . . . . . . . . . . . . .42\n   3.5.3.\
    \ PG POLICY . . . . . . . . . . . . . . . . . . . . . . . . .43\n   3.5.4. VG\
    \ CONNECT. . . . . . . . . . . . . . . . . . . . . . . . .44\n   3.5.5. VG POLICY\
    \ . . . . . . . . . . . . . . . . . . . . . . . . .45\n   3.5.6. Negative Acknowledgements\
    \ . . . . . . . . . . . . . . . . .46\n   4. Routing Information Distribution.\
    \ . . . . . . . . . . . . . . .47\n   4.1. AD Representatives. . . . . . . . .\
    \ . . . . . . . . . . . . .48\n   4.2. Flooding Protocol . . . . . . . . . . .\
    \ . . . . . . . . . . .48\n   4.2.1. Message Generation. . . . . . . . . . . .\
    \ . . . . . . . . .50\n   4.2.2. Sequence Numbers. . . . . . . . . . . . . . .\
    \ . . . . . . .52\n   4.2.3. Message Acceptance. . . . . . . . . . . . . . . .\
    \ . . . . .52\n   4.2.4. Message Incorporation . . . . . . . . . . . . . . . .\
    \ . . .54\n   4.2.5. Routing Information Database. . . . . . . . . . . . . . .\
    \ .56\n   4.3. Routing Information Message Formats . . . . . . . . . . . . .57\n\
    \   4.3.1. CONFIGURATION . . . . . . . . . . . . . . . . . . . . . . .57\n   4.3.2.\
    \ DYNAMIC . . . . . . . . . . . . . . . . . . . . . . . . . .62\n   4.3.3. Negative\
    \ Acknowledgements . . . . . . . . . . . . . . . . .63\n   5. Route Server Query\
    \ Protocol . . . . . . . . . . . . . . . . . .64\n   5.1. Message Exchange. .\
    \ . . . . . . . . . . . . . . . . . . . . .64\n   5.2. Remote Route Server Communication\
    \ . . . . . . . . . . . . . .65\n   5.3. Routing Information . . . . . . . . .\
    \ . . . . . . . . . . . .66\n   5.4. Routes. . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . .67\n   5.5. Route Server Message Formats. . . . . . . . .\
    \ . . . . . . . .67\n   5.5.1. ROUTING INFORMATION REQUEST . . . . . . . . . .\
    \ . . . . . .67\n   5.5.2. ROUTE REQUEST . . . . . . . . . . . . . . . . . . .\
    \ . . . .68\n   5.5.3. ROUTE RESPONSE. . . . . . . . . . . . . . . . . . . . .\
    \ . .71\n   5.5.4. Negative Acknowledgements . . . . . . . . . . . . . . . . .72\n\
    \   6. Route Generation. . . . . . . . . . . . . . . . . . . . . . . .73\n   6.1.\
    \ Searching . . . . . . . . . . . . . . . . . . . . . . . . . .74\n   6.1.1. Implementation.\
    \ . . . . . . . . . . . . . . . . . . . . . .75\n   6.2. Route Directionality.\
    \ . . . . . . . . . . . . . . . . . . . .78\n   6.3. Route Database. . . . . .\
    \ . . . . . . . . . . . . . . . . . .79\n   6.3.1. Cache Maintenance . . . . .\
    \ . . . . . . . . . . . . . . . .80\n   7. Path Control Protocol and Data Message\
    \ Forwarding Procedure . .80\n   7.1. An Example of Path Setup. . . . . . . .\
    \ . . . . . . . . . . .81\n   7.2. Path Identifiers. . . . . . . . . . . . . .\
    \ . . . . . . . . .84\n   7.3. Path Control Messages . . . . . . . . . . . . .\
    \ . . . . . . .85\n   7.4. Setting Up and Tearing Down a Path. . . . . . . . .\
    \ . . . . .87\n   7.4.1. Validating Path Identifiers . . . . . . . . . . . . .\
    \ . . .89\n   7.4.2. Path Consistency with Configured Transit Policies . . . .\
    \ .89\n   7.4.3. Path Consistency with Virtual Gateway Reachability. . . . .91\n\
    \   7.4.4. Obtaining Resources . . . . . . . . . . . . . . . . . . . .92\n   7.4.5.\
    \ Target Response . . . . . . . . . . . . . . . . . . . . . .93\n   7.4.6. Originator\
    \ Response . . . . . . . . . . . . . . . . . . . .93\n   7.4.7. Path Life . .\
    \ . . . . . . . . . . . . . . . . . . . . . .  94\n   7.5. Path Failure and Recovery\
    \ . . . . . . . . . . . . . . . . .  95\n   7.5.1. Handling Implicit Path Failures\
    \ . . . . . . . . . . . . .  96\n   7.5.2. Local Path Repair . . . . . . . . .\
    \ . . . . . . . . . . .  97\n   7.5.3. Repairing a Path. . . . . . . . . . . .\
    \ . . . . . . . . .  98\n   7.6. Path Control Message Formats. . . . . . . . .\
    \ . . . . . . . 100\n   7.6.1. SETUP . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . 101\n   7.6.2. ACCEPT. . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . 103\n   7.6.3. REFUSE. . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . 103\n   7.6.4. TEARDOWN. . . . . . . . . . . . . . . . . . . . . . . . . 104\n\
    \   7.6.5. ERROR . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n   7.6.6.\
    \ REPAIR. . . . . . . . . . . . . . . . . . . . . . . . . . 106\n   7.6.7. Negative\
    \ Acknowledgements . . . . . . . . . . . . . . . . 106\n   8. Security Considerations\
    \ . . . . . . . . . . . . . . . . . . . 106\n   9. Authors's Address . . . . .\
    \ . . . . . . . . . . . . . . . . . 107\n   References . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . 107\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   In this document, we specify the protocols and procedures\
    \ that\n   compose Inter-Domain Policy Routing (IDPR).  The objective of IDPR\
    \ is\n   to construct and maintain routes between source and destination\n   administrative\
    \ domains, that provide user traffic with the services\n   requested within the\
    \ constraints stipulated for the domains\n   transited.  IDPR supports link state\
    \ routing information distribution\n   and route generation in conjunction with\
    \ source specified message\n   forwarding.  Refer to [5] for a detailed justification\
    \ of our\n   approach to inter-domain policy routing.\n"
- title: 1.1.  Domain Elements
  contents:
  - "1.1.  Domain Elements\n   The IDPR architecture has been designed to accommodate\
    \ an\n   internetwork with tens of thousands of administrative domains\n   collectively\
    \ containing hundreds of thousands of local networks.\n   Inter-domain policy\
    \ routes are constructed using information about\n   the services offered by,\
    \ and the connectivity between, administrative\n   domains.  The intra-domain\
    \ details - gateways, networks, and links\n   traversed - of an inter-domain policy\
    \ route are the responsibility of\n   intra-domain routing and are thus outside\
    \ the scope of IDPR.\n   An \"administrative domain\" (AD) is a collection of\
    \ contiguous hosts,\n   gateways, networks, and links managed by a single administrative\n\
    \   authority.  The domain administrator defines service restrictions for\n  \
    \ transit traffic and service requirements for locally-generated\n   traffic,\
    \ and selects the addressing schemes and routing procedures\n   that apply within\
    \ the domain.  Within the Internet, each domain has a\n   unique numeric identifier\
    \ assigned by the Internet Assigned Numbers\n   Authority (IANA).\n   \"Virtual\
    \ gateways\" (VGs) are the only IDPR-recognized connecting\n   points between\
    \ adjacent domains.  Each virtual gateway is a\n   collection of directly-connected\
    \ \"policy gateways\" (see below) in two\n   adjoining domains, whose existence\
    \ has been sanctioned by the\n   administrators of both domains.  The domain administrators\
    \ may agree\n   to establish more than one virtual gateway between the two domains.\n\
    \   For each such virtual gateway, the two administrators together assign\n  \
    \ a local numeric identifier, unique within the set of virtual gateways\n   connecting\
    \ the two domains.  To produce a virtual gateway identifier\n   unique within\
    \ its domain, a domain administrator concatenates the\n   mutually assigned local\
    \ virtual gateway identifier together with the\n   adjacent domain's identifier.\n\
    \   Policy gateways (PGs) are the physical gateways within a virtual\n   gateway.\
    \  Each policy gateway enforces service restrictions on IDPR\n   transit traffic,\
    \ as stipulated by the domain administrator, and\n   forwards the traffic accordingly.\
    \  Within a domain, two policy\n   gateways are \"neighbors\" if they are in different\
    \ virtual gateways.\n   A single policy gateway may belong to multiple virtual\
    \ gateways.\n   Within a virtual gateway, two policy gateways are \"peers\" if\
    \ they are\n   in the same domain and are \"adjacent\" if they are in different\n\
    \   domains.  Adjacent policy gateways are \"directly connected\" if the\n   only\
    \ Internet-addressable entities attached to the connecting medium\n   are policy\
    \ gateways in the virtual gateways.  Note that this\n   definition implies that\
    \ not only point-to-point links but also\n   networks may serve as direct connections\
    \ between adjacent policy\n   gateways.  The domain administrator assigns to each\
    \ of its policy\n   gateways a numeric identifier, unique within that domain.\n\
    \   A \"domain component\" is a subset of a domain's entities such that all\n\
    \   entities within the subset are mutually reachable via intra-domain\n   routes,\
    \ but no entities outside the subset are reachable via intra-\n   domain routes\
    \ from entities within the subset.  Normally, a domain\n   consists of a single\
    \ component, namely itself; however, when\n   partitioned, a domain consists of\
    \ multiple components.  Each domain\n   component has an identifier, unique within\
    \ the Internet, composed of\n   the domain identifier together with the identifier\
    \ of the lowest-\n   numbered operational policy gateway within the component.\
    \  All\n   operational policy gateways within a domain component can discover\n\
    \   mutual reachability through intra-domain routing information.  Hence,\n  \
    \ all such policy gateways can consistently determine, without explicit\n   negotiation,\
    \ which of them has the lowest number.\n"
- title: 1.2.  Policy
  contents:
  - "1.2.  Policy\n   With IDPR, each domain administrator sets \"transit policies\"\
    \ that\n   dictate how and by whom the resources in its domain should be used.\n\
    \   Transit policies are usually public, and they specify offered\n   services\
    \ comprising:\n   -   Access restrictions: e.g., applied to traffic to or from\
    \ certain\n       domains or classes of users.\n   -   Quality: e.g., delay, throughput,\
    \ or error characteristics.\n   -   Monetary cost: e.g., charge per byte, message,\
    \ or unit time.\n   Each domain administrator also sets \"source policies\" for\
    \ traffic\n   originating in its domain.  Source policies are usually private,\
    \ and\n   they specify requested services comprising:\n   -   Access restrictions:\
    \ e.g., domains to favor or avoid in routes.\n   -   Quality: e.g., acceptable\
    \ delay, throughput, and reliability.\n   -   Monetary cost: e.g., acceptable\
    \ session cost.\n"
- title: 1.3.  IDPR Functions
  contents:
  - "1.3.  IDPR Functions\n   IDPR comprises the following functions:\n   -   Collecting\
    \ and distributing routing information including domain\n       transit policies\
    \ and inter-domain connectivity.\n   -   Generating and selecting policy routes\
    \ based on the routing\n       information distributed and on the source policies\
    \ configured or\n       requested.\n   -   Setting up paths across the Internet\
    \ using the policy routes\n       generated.\n   -   Forwarding messages across\
    \ and between domains along the\n       established paths.\n   -   Maintaining\
    \ databases of routing information, inter-domain policy\n       routes, forwarding\
    \ information, and configuration information.\n"
- title: 1.3.1.  IDPR Entities
  contents:
  - "1.3.1.  IDPR Entities\n   Several different entities are responsible for performing\
    \ the IDPR\n   functions.\n   Policy gateways, the only IDPR-recognized connecting\
    \ points between\n   adjacent domains, collect and distribute routing information,\n\
    \   participate in path setup, forward data messages along established\n   paths,\
    \ and maintain forwarding information databases.\n   \"Path agents\", resident\
    \ within policy gateways and within \"route\n   servers\" (see below), act on\
    \ behalf of hosts to select policy routes,\n   to set up and manage paths, and\
    \ to maintain forwarding information\n   databases.  Any Internet host can reap\
    \ the benefits of IDPR, as long\n   as there exists a path agent configured to\
    \ act on its behalf and a\n   means by which the host's messages can reach the\
    \ path agent.\n   Specifically, a path agent in one domain may be configured to\
    \ act on\n   behalf of hosts in another domain.  In this case, the path agent's\n\
    \   domain is an IDPR \"proxy\" for the hosts' domain.\n   Route servers maintain\
    \ both the routing information database and the\n   route database, and they generate\
    \ policy routes using the routing\n   information collected and the source policies\
    \ requested by the path\n   agents.  A route server may reside within a policy\
    \ gateway, or it may\n   exist as an autonomous entity.  Separating the route\
    \ server functions\n   from the policy gateways frees the policy gateways from\
    \ both the\n   memory intensive task of database (routing information and route)\n\
    \   maintenance and the computationally intensive task of route\n   generation.\
    \  Route servers, like policy gateways, each have a unique\n   numeric identifier\
    \ within their domain, assigned by the domain\n   administrator.\n   Given the\
    \ size of the current Internet, each policy gateway can\n   perform the route\
    \ server functions, in addition to its message\n   forwarding functions, with\
    \ little or no degradation in message\n   forwarding performance.  Aggregating\
    \ the routing functions into\n   policy gateways simplifies implementation; one\
    \ need only install IDPR\n   protocols in policy gateways.  Moreover, it simplifies\
    \ communication\n   between routing functions, as all functions reside within\
    \ each policy\n   gateway.  As the Internet grows, the memory and processing required\n\
    \   to perform the route server functions may become a burden for the\n   policy\
    \ gateways.  When this happens, each domain administrator should\n   separate\
    \ the route server functions from the policy gateways in its\n   domain.\n   \"\
    Mapping servers\" maintain the database of mappings that resolve\n   Internet\
    \ names and addresses to domain identifiers.  Each host is\n   contained within\
    \ a domain and is associated with a proxy domain which\n   may be identical with\
    \ the host's domain.  The mapping server function\n   will be integrated into\
    \ the existing DNS name service (see [6]) and\n   will provide mappings between\
    \ a host and its local and proxy domains.\n   \"Configuration servers\" maintain\
    \ the databases of configured\n   information that apply to IDPR entities within\
    \ their domains.\n   Configuration information for a given domain includes transit\n\
    \   policies (i.e., service offerings and restrictions), source policies\n   (i.e.,\
    \ service requirements), and mappings between local IDPR\n   entities and their\
    \ names and addresses.  The configuration server\n   function will be integrated\
    \ into a domain's existing network\n   management system (see [7]-[8]).\n"
- title: 1.4.  Policy Semantics
  contents:
  - "1.4.  Policy Semantics\n   The source and transit policies supported by IDPR\
    \ are intended to\n   accommodate a wide range of services available throughout\
    \ the\n   Internet.  We describe the semantics of these policies, concentrating\n\
    \   on the access restriction aspects.  To express these policies in this\n  \
    \ document, we have chosen to use a syntactic variant of Clark's policy\n   term\
    \ notation [1].  However, we provide a more succinct syntax (see\n   [7]) for\
    \ actually configuring source and transit policies.\n"
- title: 1.4.1.  Source Policies
  contents:
  - "1.4.1.  Source Policies\n   Each source policy takes the form of a collection\
    \ of sets as follows:\n   Applicable Sources and Destinations:\n      {((H(1,1),s(1,1)),...,(H(1,f1),s(1,f1))),...,((H(n,1),s(n,1)),...,\n\
    \      (H(n,fn),s(n,fn)))}: The set of groups of source/destination\n      traffic\
    \ flows to which the source policy applies.  Each traffic\n      flow group ((H(i,1),s(i,1)),...,(H(i,fi),s(i,fi)))\
    \ contains a set\n      of source hosts and corresponding destination hosts. \
    \ Here, H(i,j)\n      represents a host, and s(i,j), an element of {SOURCE,\n\
    \      DESTINATION}, represents an indicator of whether H(i,j) is to be\n    \
    \  considered as a source or as a destination.\n   Domain Preferences: {(AD(1),x(1)),...,(AD(m),x(m))}:\
    \ The set of\n      transit domains that the traffic flows should favor, avoid,\
    \ or\n      exclude.  Here, AD(i) represents a domain, and x(i), an element of\n\
    \      {FAVOR, AVOID, EXCLUDE}, represents an indicator of whether routes\n  \
    \    including AD(i) are to be favored, avoided if possible, or\n      unconditionally\
    \ excluded.\n   UCI: The source user class for the traffic flows listed.\n   RequestedServices:\
    \ The set of requested services not related to\n      access restrictions, i.e.,\
    \ service quality and monetary cost.\n   When selecting a route for a traffic\
    \ flow from a source host H(i,j)\n   to a destination host H(i,k), where 1 < or\
    \ = i < or = n and 1 < or =\n   j, k < or = fi, the path agent (see section 1.3.1)\
    \ must honor the\n   source policy such that:\n   - For each domain, AD(p), contained\
    \ in the route, AD(p) is not equal\n     to any AD(k), such that 1 < or = k <\
    \ or = m and x(k) = EXCLUDE.\n   - The route provides the services listed in the\
    \ set Requested\n     Services.\n"
- title: 1.4.2.  Transit Policies
  contents:
  - "1.4.2.  Transit Policies\n   Each transit policy takes the form of a collection\
    \ of sets as\n   follows:\n   Source/Destination Access Restrictions:\n      {((H(1,1),AD(1,1),s(1,1)),...,(H(1,f1),AD(1,f1),s(1,f1))),...,\n\
    \      ((H(n,1),AD(n,1),s(n,1)),...,(H(n,fn),AD(n,fn),s(n,fn)))}: The set\n  \
    \    of groups of source and destination hosts and domains to which the\n    \
    \  transit policy applies.  Each domain group\n      ((H(i,1),AD(i,1),s(i,1)),...,(H(i,fi),AD(i,fi),s(i,fi)))\
    \ contains\n      a set of source and destination hosts and domains such that\
    \ this\n      transit domain will carry traffic from each source listed to each\n\
    \      destination listed.  Here, H(i,j) represents a set of hosts,\n      AD(i,j)\
    \ represents a domain containing H(i,j), and s(i,j), a\n      subset of {SOURCE,\
    \ DESTINATION}, represents an indicator of\n      whether (H(i,j),AD(i,j)) is\
    \ to be considered as a set of sources,\n      destinations, or both.\n   Temporal\
    \ Access Restrictions: The set of time intervals during which\n      the transit\
    \ policy applies.\n   User Class Access Restrictions: The set of user classes\
    \ to which the\n      transit policy applies.\n   Offered Services: The set of\
    \ offered services not related to access\n      restrictions, i.e., service quality\
    \ and monetary cost.\n   Virtual Gateway Access Restrictions:\n      {((VG(1,1),e(1,1)),...,(VG(1,g1),e(1,g1))),...,((VG(m,1),e(m,1)),\n\
    \      gateways to which the transit policy applies.  Each virtual\n      gateway\
    \ group ((VG(i,1),e(i,1)),...,(VG(i,gi),e(i,gi))) contains a\n      set of domain\
    \ entry and exit points such that each entry virtual\n      gateway can reach\
    \ (barring an intra-domain routing failure) each\n      exit virtual gateway via\
    \ an intra-domain route supporting the\n      transit policy.  Here, VG(i,j) represents\
    \ a virtual gateway, and\n      e(i,j), a subset of {ENTRY, EXIT}, represents\
    \ an indicator of\n      whether VG(i,j) is to be considered as a domain entry\
    \ point, exit\n      point, or both.\n   The domain advertising such a transit\
    \ policy will carry traffic from\n   any host in the set H(i,j) in AD(i,j) to\
    \ any host in the set H(i,k)\n   in AD(i,k), where 1 < or = i < or = n and 1 <\
    \ or = j, k < or = fi,\n   provided that:\n   - SOURCE is an element of s(i,j).\n\
    \   - DESTINATION is an element of s(i,k).\n   - Traffic from H(i,j) enters the\
    \ domain during one of the intervals\n     in the set Temporal Access Restrictions.\n\
    \   - Traffic from H(i,j) carries one of the user class identifiers in\n     the\
    \ set User Class Access Restrictions.\n   - Traffic from H(i,j) enters via any\
    \ VG(u,v) such that ENTRY is an\n     element of e(u,v), where 1 < or = u < or\
    \ = m and 1 < or = v < or =\n     gu.\n   - Traffic to H(i,k) leaves via any VG(u,w)\
    \ such that EXIT is an\n     element of e(u,w), where 1 < or = w < or = gu.\n"
- title: 1.5.  IDPR Message Encapsulation
  contents:
  - "1.5.  IDPR Message Encapsulation\n   There are two kinds of IDPR messages:\n\
    \   - \"Data messages\" containing user data generated by hosts.\n   - \"Control\
    \ messages\" containing IDPR protocol-related control\n     information generated\
    \ by policy gateways and route servers.\n   Within an internetwork, only policy\
    \ gateways and route servers are\n   able to generate, recognize, and process\
    \ IDPR messages.  The\n   existence of IDPR is invisible to all other gateways\
    \ and hosts,\n   including mapping servers and configuration servers.  Mapping\
    \ servers\n   and configuration servers perform necessary but ancillary functions\n\
    \   for IDPR, and thus they are not required to handle IDPR messages.\n   An IDPR\
    \ entity places IDPR-specific information in each IDPR control\n   message it\
    \ originates; this information is significant only to\n   recipient IDPR entities.\
    \  Using \"encapsulation\" across each domain,\n   an IDPR message tunnels from\
    \ source to destination across an\n   internetwork through domains that may employ\
    \ disparate intra-domain\n   addressing schemes and routing procedures.\n   As\
    \ an alternative to encapsulation, we had considered embedding IDPR\n   in IP,\
    \ as a set of IP options.  However, this approach has the\n   following disadvantages:\n\
    \   - Only domains that support IP would be able to participate in IDPR;\n   \
    \  domains that do not support IP would be excluded.\n   - Each gateway, policy\
    \ or other, in a participating domain would at\n     least have to recognize the\
    \ IDPR option, even if it did not execute\n     the IDPR protocols.  However,\
    \ most commercial routers are not\n     optimized for IP options processing, and\
    \ so IDPR message handling\n     might require significant processing at each\
    \ gateway.\n   - For some IDPR protocols, in particular path control, the size\n\
    \     restrictions on IP options would preclude inclusion of all of the\n    \
    \ necessary protocol-related information.\n   For these reasons, we decided against\
    \ the IP option approach and in\n   favor of encapsulation.\n   An IDPR message\
    \ travels from source to destination between\n   consecutive policy gateways.\
    \  Each policy gateway encapsulates the\n   IDPR message with information, for\
    \ example an IP header, that will\n   enable the message to reach the next policy\
    \ gateway.  Note that the\n   encapsulating header and the IDPR-specific information\
    \ may increase\n   the message size beyond the MTU of the given domain.  However,\n\
    \   message fragmentation and reassembly is the responsibility of the\n   protocol,\
    \ for example IP, that encapsulates IDPR messages for\n   transport between successive\
    \ policy gateways; it is not currently the\n   responsibility of IDPR itself.\n\
    \   A policy gateway, when forwarding an IDPR message to a peer or a\n   neighbor\
    \ policy gateway, encapsulates the message in accordance with\n   the addressing\
    \ scheme and routing procedure of the given domain and\n   indicates in the protocol\
    \ field of the encapsulating header that the\n   message is indeed an IDPR message.\
    \  Intermediate gateways between the\n   two policy gateways forward the IDPR\
    \ message as they would any other\n   message, using the information in the encapsulating\
    \ header.  Only the\n   recipient policy gateway interprets the protocol field,\
    \ strips off\n   the encapsulating header, and processes the IDPR message.\n \
    \  A policy gateway, when forwarding an IDPR message to a directly-\n   connected\
    \ adjacent policy gateway, encapsulates the message in\n   accordance with the\
    \ addressing scheme of the entities within the\n   virtual gateway and indicates\
    \ in the protocol field of the\n   encapsulating header that the message is indeed\
    \ an IDPR message.  The\n   recipient policy gateway strips off the encapsulating\
    \ header and\n   processes the IDPR message.  We recommend that the recipient\
    \ policy\n   gateway perform the following validation check of the encapsulating\n\
    \   header, prior to stripping it off.  Specifically, the recipient\n   policy\
    \ gateway should verify that the source address and the\n   destination address\
    \ in the encapsulating header match the adjacent\n   policy gateway's address\
    \ and its own address, respectively.\n   Moreover, the recipient policy gateway\
    \ should verify that the message\n   arrived on the interface designated for the\
    \ direct connection to the\n   adjacent policy gateway.  These checks help to\
    \ ensure that IDPR\n   traffic that crosses domain boundaries does so only over\
    \ direct\n   connections between adjacent policy gateways.\n   Policy gateways\
    \ forward IDPR data messages according to a forwarding\n   information database\
    \ which maps \"path identifiers\", carried in the\n   data messages, into next\
    \ policy gateways.  Policy gateways forward\n   IDPR control messages according\
    \ to next policy gateways selected by\n   the particular IDPR control protocols\
    \ associated with the messages.\n   Distinguishing IDPR data messages and IDPR\
    \ control messages at the\n   encapsulating protocol level, instead of at the\
    \ IDPR protocol level,\n   eliminates an extra level of dispatching and hence\
    \ makes IDPR message\n   forwarding more efficient.  When encapsulated within\
    \ IP messages,\n   IDPR data messages and IDPR control messages carry the IP protocol\n\
    \   numbers 35 and 38, respectively.\n"
- title: 1.5.1.  IDPR Data Message Format
  contents:
  - "1.5.1.  IDPR Data Message Format\n   The path agents at a source domain determine\
    \ which data messages\n   generated by local hosts are to be handled by IDPR.\
    \  To each data\n   message selected for IDPR handling, a source path agent prepends\
    \ the\n   following header:\n    0                   1                   2   \
    \                3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6\
    \ 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |    VERSION    |     PROTO     |            LENGTH             |\n   +---------------+---------------+-------------------------------+\n\
    \   |                            PATH ID                            |\n   |  \
    \                                                             |\n   +---------------------------------------------------------------+\n\
    \   |                           TIMESTAMP                           |\n   +---------------------------------------------------------------+\n\
    \   |                            INT/AUTH                           |\n   |  \
    \                                                             |\n   +---------------------------------------------------------------+\n\
    \   VERSION (8 bits) Version number for IDPR data messages, currently\n   equal\
    \ to 1.\n   PROTO (8 bits) Numeric identifier for the protocol with which to\n\
    \   process the contents of the IDPR data message.  Only the path agent\n   at\
    \ the destination interprets and acts upon the contents of the PROTO\n   field.\n\
    \   LENGTH (16 bits) Length of the entire IDPR data message in bytes.\n   PATH\
    \ ID (64 bits) Path identifier assigned by the source's path agent\n   and consisting\
    \ of the numeric identifier for the path agent's domain\n   (16 bits), the numeric\
    \ identifier for the path agent's policy gateway\n   (16 bits), and the path agent's\
    \ local path identifier (32 bits) (see\n   section 7.2).\n   TIMESTAMP (32 bits)\
    \ Number of seconds elapsed since 1 January 1970\n   0:00 GMT.\n   INT/AUTH (variable)\
    \ Computed integrity/authentication value,\n   dependent on the type of integrity/authentication\
    \ requested during\n   path setup.\n   We describe the IDPR control message header\
    \ in section 2.4.\n"
- title: 1.6.  Security
  contents:
  - "1.6.  Security\n   IDPR contains mechanisms for verifying message integrity and\
    \ source\n   authenticity and for protecting against certain types of denial of\n\
    \   service attacks.  It is particularly important to keep IDPR control\n   messages\
    \ intact, because they carry control information critical to\n   the construction\
    \ and use of viable policy routes between domains.\n   All IDPR messages carry\
    \ a single piece of information, referred to as\n   the \"integrity/authentication\
    \ value\", which may be used not only to\n   detect message corruption but also\
    \ to verify the authenticity of the\n   message source.  In the Internet, the\
    \ IANA will sanction the set of\n   valid algorithms which may be used to compute\
    \ the\n   integrity/authentication values.  This set may include algorithms\n\
    \   that perform only message integrity checks such as n-bit cyclic\n   redundancy\
    \ checksums (CRCs), as well as algorithms that perform both\n   message integrity\
    \ and source authentication checks such as signed\n   hash functions of message\
    \ contents.\n   Each domain administrator is free to select any\n   integrity/authentication\
    \ algorithm, from the set specified by the\n   IANA, for computing the integrity/authentication\
    \ values contained in\n   its domain's messages.  However, we recommend that IDPR\
    \ entities in\n   each domain be capable of executing all of the valid algorithms\
    \ so\n   that an IDPR control message originating at an entity in one domain\n\
    \   can be properly checked by an entity in another domain.\n   Each IDPR control\
    \ message must carry a non-null\n   integrity/authentication value.  We recommend\
    \ that control message\n   integrity/authentication be based on a digital signature\
    \ algorithm\n   applied to a one-way hash function, such as RSA applied to MD5\
    \ [17],\n   which simultaneously verifies message integrity and source\n   authenticity.\
    \  The digital signature may be based on either public-\n   key or private-key\
    \ cryptography.  Our approach to digital signature\n   use in IDPR is based on\
    \ the privacy-enhanced Internet electronic mail\n   service [13]-[15], already\
    \ available in the Internet.\n   We do not require that IDPR data messages carry\
    \ a non-null\n   integrity/authentication value.  In fact, we recommend that a\
    \ higher\n   layer (end-to-end) procedure, and not IDPR, assume responsibility\
    \ for\n   checking the integrity and authenticity of data messages, because of\n\
    \   the amount of computation involved.\n"
- title: 1.7.  Timestamps and Clock Synchronization
  contents:
  - "1.7.  Timestamps and Clock Synchronization\n   Each IDPR message carries a timestamp\
    \ (expressed in seconds elapsed\n   since 1 January 1970 0:00 GMT, following the\
    \ UNIX precedent) supplied\n   by the source IDPR entity, which serves to indicate\
    \ the age of the\n   message.  IDPR entities use the absolute value of the timestamp\
    \ to\n   confirm that a message is current and use the relative difference\n \
    \  between timestamps to determine which message contains the more\n   recent\
    \ information.\n   All IDPR entities must possess internal clocks that are synchronized\n\
    \   to some degree, in order for the absolute value of a message\n   timestamp\
    \ to be meaningful.  The synchronization granularity required\n   by IDPR is on\
    \ the order of minutes and can be achieved manually.\n   Thus, a clock synchronization\
    \ protocol operating among all IDPR\n   entities in all domains, while useful,\
    \ is not necessary.\n   An IDPR entity can determine whether to accept or reject\
    \ a message\n   based on the discrepancy between the message's timestamp and the\n\
    \   entity's own internal clock time.  Any IDPR message whose timestamp\n   lies\
    \ outside of the acceptable range may contain stale or corrupted\n   information\
    \ or may have been issued by a source whose internal clock\n   has lost synchronization\
    \ with the message recipient's internal clock.\n   Timestamp checks are required\
    \ for control messages because of the\n   consequences of propagating and acting\
    \ upon incorrect control\n   information.  However, timestamp checks are discretionary\
    \ for data\n   messages but may be invoked during problem diagnosis, for example,\n\
    \   when checking for suspected message replays.\n   We note that none of the\
    \ IDPR protocols contain explicit provisions\n   for dealing with an exhausted\
    \ timestamp space.  As timestamp space\n   exhaustion will not occur until well\
    \ into the next century, we expect\n   timestamp space viability to outlast the\
    \ IDPR protocols.\n"
- title: 1.8.  Network Management
  contents:
  - "1.8.  Network Management\n   In this document, we do not describe how to configure\
    \ and manage\n   IDPR.  However, in this section, we do provide a list of the\
    \ types of\n   IDPR configuration information required.  Also, in later sections\n\
    \   describing the IDPR protocols, we briefly note the types of\n   exceptional\
    \ events that must be logged for network management.\n   Complete descriptions\
    \ of IDPR entity configuration and IDPR managed\n   objects appear in [7] and\
    \ [8] respectively.\n   To participate in inter-domain policy routing, policy\
    \ gateways and\n   route servers within a domain each require configuration information.\n\
    \   Some of the configuration information is specifically defined within\n   the\
    \ given domain, while some of the configuration information is\n   universally\
    \ defined throughout an internetwork.  A domain\n   administrator determines domain-specific\
    \ information, and in the\n   Internet, the IANA determines globally significant\
    \ information.\n   To produce valid domain configurations, the domain administrators\n\
    \   must receive the following global information from the IANA:\n   - For each\
    \ integrity/authentication type, the numeric\n     identifier, syntax, and semantics.\
    \  Available integrity and\n     authentication types include but are not limited\
    \ to:\n       o    public-key based signatures;\n       o    private-key based\
    \ signatures;\n       o    cyclic redundancy checksums;\n       o    no integrity/authentication.\n\
    \   - For each user class, the numeric identifier, syntax, and\n     semantics.\
    \  Available user classes include but are not limited to:\n       o    federal\
    \ (and if necessary, agency-specific such as NSF, DOD,\n            DOE, etc.);\n\
    \       o    research;\n       o    commercial;\n       o    support.\n   - For\
    \ each offered service that may be advertised in transit\n     policies, the numeric\
    \ identifier, syntax, and semantics.  Available\n     offered services include\
    \ but are not limited to:\n       o    average message delay;\n       o    message\
    \ delay variation;\n       o    average bandwidth available;\n       o    available\
    \ bandwidth variation;\n       o    maximum transfer unit (MTU);\n       o   \
    \ charge per byte;\n       o    charge per message;\n       o    charge per unit\
    \ time.\n   - For each access restriction that may be advertised in transit\n\
    \     policies, the numeric identifier, syntax, and semantics.  Available\n  \
    \   access restrictions include but are not limited to:\n       o    Source and\
    \ destination domains and host sets.\n       o    User classes.\n       o    Entry\
    \ and exit virtual gateways.\n       o    Time of day.\n   - For each requested\
    \ service that may appear within a path setup\n     message, the numeric identifier,\
    \ syntax, and semantics.  Available\n     requested services include but are not\
    \ limited to:\n       o    maximum path life in minutes, messages, or bytes;\n\
    \       o    integrity/authentication algorithms to be used on data\n        \
    \    messages sent over the path;\n       o    upper bound on path delay;\n  \
    \     o    minimum delay path;\n       o    upper bound on path delay variation;\n\
    \       o    minimum delay variation path;\n       o    lower bound on path bandwidth;\n\
    \       o    maximum bandwidth path;\n       o    upper bound on monetary cost;\n\
    \       o    minimum monetary cost path.\n   In an internetwork-wide implementation\
    \ of IDPR, the set of global\n   configuration parameters and their syntax and\
    \ semantics must be\n   consistent across all participating domains.  The IANA,\
    \ responsible\n   for establishing the full set of global configuration parameters\
    \ in\n   the Internet, relies on the cooperation of the administrators of all\n\
    \   participating domains to ensure that the global parameters are\n   consistent\
    \ with the desired transit policies and user service\n   requirements of each\
    \ domain.  Moreover, as the syntax and semantics\n   of the global parameters\
    \ affects the syntax and semantics of the\n   corresponding IDPR software, the\
    \ IANA must carefully define each\n   global parameter so that it is unlikely\
    \ to require future\n   modification.\n   The IANA provides configured global\
    \ information to configuration\n   servers in all domains participating in IDPR.\
    \  Each domain\n   administrator uses the configured global information maintained\
    \ by\n   its configuration servers to develop configurations for each IDPR\n \
    \  entity within its domain.  Each configuration server retains a copy\n   of\
    \ the configuration for each local IDPR entity and also distributes\n   the configuration\
    \ to that entity using, for example, SNMP.\n"
- title: 1.8.1.  Policy Gateway Configuration
  contents:
  - "1.8.1.  Policy Gateway Configuration\n   Each policy gateway must contain sufficient\
    \ configuration information\n   to perform its IDPR functions, which subsume those\
    \ of the path agent.\n   These include: validating IDPR control messages; generating\
    \ and\n   distributing virtual gateway connectivity and routing information\n\
    \   messages to peer, neighbor, and adjacent policy gateways;\n   distributing\
    \ routing information messages to route servers in its\n   domain; resolving destination\
    \ addresses; requesting policy routes\n   from route servers; selecting policy\
    \ routes and initiating path\n   setup; ensuring consistency of a path with its\
    \ domain's transit\n   policies; establishing path forwarding information; and\
    \ forwarding\n   IDPR data messages along existing paths.  The necessary configuration\n\
    \   information includes the following:\n   - For each integrity/authentication\
    \ type, the numeric identifier,\n     syntax, and semantics.\n   - For each policy\
    \ gateway and route server in the given domain, the\n     numeric identifier and\
    \ set of addresses or names.\n   - For each virtual gateway connected to the given\
    \ domain, the numeric\n     identifier, the numeric identifiers for the constituent\
    \ peer policy\n     gateways, and the numeric identifier for the adjacent domain.\n\
    \   - For each virtual gateway of which the given policy gateway is a\n     member,\
    \ the numeric identifiers and set of addresses for the\n     constituent adjacent\
    \ policy gateways.\n   - For each policy gateway directly-connected and adjacent\
    \ to the\n     given policy gateway, the local connecting interface.\n   - For\
    \ each local route server to which the given policy gateway\n     distributes\
    \ routing information, the numeric identifier.\n   - For each source policy applicable\
    \ to hosts within the given domain,\n     the syntax and semantics.\n   - For\
    \ each transit policy applicable to the domain, the numeric\n     identifier,\
    \ syntax, and semantics.\n   - For each requested service that may appear within\
    \ a path setup\n     message, the numeric identifier, syntax, and semantics.\n\
    \   - For each source user class, the numeric identifier, syntax, and\n     semantics.\n"
- title: 1.8.2.  Route Server Configuration
  contents:
  - "1.8.2.  Route Server Configuration\n   Each route server must contain sufficient\
    \ configuration information\n   to perform its IDPR functions, which subsume those\
    \ of the path agent.\n   These include: validating IDPR control messages; deciphering\
    \ and\n   storing the contents of routing information messages; exchanging\n \
    \  routing information with other route servers and policy gateways;\n   generating\
    \ policy routes that respect transit policy restrictions and\n   source service\
    \ requirements; distributing policy routes to path\n   agents in policy gateways;\
    \ resolving destination addresses; selecting\n   policy routes and initiating\
    \ path setup; establishing path forwarding\n   information; and forwarding IDPR\
    \ data messages along existing paths.\n   The necessary configuration information\
    \ includes the following:\n   - For each integrity/authentication type, the numeric\
    \ identifier,\n     syntax, and semantics.\n   - For each policy gateway and route\
    \ server in the given domain, the\n     numeric identifier and set of addresses\
    \ or names.\n   - For each source policy applicable to hosts within the given\
    \ domain,\n     the syntax and semantics.\n   - For access restriction that may\
    \ be advertised in transit\n     policies, the numeric identifier, syntax, and\
    \ semantics.\n   - For each offered service that may be advertised in transit\
    \ policies,\n     the numeric identifier, syntax, and semantics.\n   - For each\
    \ requested service that may appear within a path setup\n     message, the numeric\
    \ identifier, syntax, and semantics.\n   - For each source user class, the numeric\
    \ identifier, syntax, and\n     semantics.\n"
- title: 2.  Control Message Transport Protocol
  contents:
  - "2.  Control Message Transport Protocol\n   IDPR control messages convey routing-related\
    \ information that\n   directly affects the policy routes generated and the paths\
    \ set up\n   across the Internet.  Errors in IDPR control messages can have\n\
    \   widespread, deleterious effects on inter-domain policy routing, and\n   so\
    \ the IDPR protocols have been designed to minimize loss and\n   corruption of\
    \ control messages.  For every control message it\n   transmits, each IDPR protocol\
    \ expects to receive notification as to\n   whether the control message successfully\
    \ reached the intended IDPR\n   recipient.  Moreover, the IDPR recipient of a\
    \ control message first\n   verifies that the message appears to be well-formed,\
    \ before acting on\n   its contents.\n   All IDPR protocols use the Control Message\
    \ Transport Protocol (CMTP),\n   a connectionless, transaction-based transport\
    \ layer protocol, for\n   communication with intended recipients of control messages.\
    \  CMTP\n   retransmits unacknowledged control messages and applies integrity\
    \ and\n   authenticity checks to received control messages.\n   There are three\
    \ types of CMTP messages:\n   DATAGRAM:\n        Contains IDPR control messages.\n\
    \   ACK: Positive acknowledgement in response to a DATAGRAM message.\n   NAK:\
    \ Negative acknowledgement in response to a DATAGRAM message.\n   Each CMTP message\
    \ contains several pieces of information supplied by\n   the sender that allow\
    \ the recipient to test the integrity and\n   authenticity of the message.  The\
    \ set of integrity and authenticity\n   checks performed after CMTP message reception\
    \ are collectively\n   referred to as \"validation checks\" and are described\
    \ in section 2.3.\n   When we first designed the IDPR protocols, CMTP as a distinct\n\
    \   protocol did not exist.  Instead, CMTP-equivalent functionality was\n   embedded\
    \ in each IDPR protocol.  To provide a cleaner implementation,\n   we later decided\
    \ to provide a single transport protocol that could be\n   used by all IDPR protocols.\
    \  We originally considered using an\n   existing transport protocol, but rejected\
    \ this approach for the\n   following reasons:\n   - The existing reliable transport\
    \ protocols do not provide all of the\n     validation checks, in particular the\
    \ timestamp and authenticity\n     checks, required by the IDPR protocols.  Hence,\
    \ if we were to use\n     one of these protocols, we would still have to provide\
    \ a separate\n     protocol on top of the transport protocol to force retransmission\
    \ of\n     IDPR messages that failed to pass the required validation checks.\n\
    \   - Many of the existing reliable transport protocols are window-based\n   \
    \  and hence can result in increased message delay and resource use\n     when,\
    \ as is the case with IDPR, multiple independent messages use\n     the same transport\
    \ connection.  A single message experiencing\n     transmission problems and requiring\
    \ retransmission can prevent the\n     window from advancing, forcing all subsequent\
    \ messages to queue\n     behind it.  Moreover, many of the window-based protocols\
    \ do not\n     support selective retransmission of failed messages but instead\n\
    \     require retransmission of not only the failed message but also all\n   \
    \  preceding messages within the window.\n   For these reasons, we decided against\
    \ using an existing transport\n   protocol and in favor of developing CMTP.\n"
- title: 2.1.  Message Transmission
  contents:
  - "2.1.  Message Transmission\n   At the transmitting entity, when an IDPR protocol\
    \ is ready to issue a\n   control message, it passes a copy of the message to\
    \ CMTP; it also\n   passes a set of parameters to CMTP for inclusion in the CMTP\
    \ header\n   and for proper CMTP message handling.  In turn, CMTP converts the\n\
    \   control message and associated parameters into a DATAGRAM by\n   prepending\
    \ the appropriate header to the control message.  The CMTP\n   header contains\
    \ several pieces of information to aid the message\n   recipient in detecting\
    \ errors (see section 2.4).  Each IDPR protocol\n   can specify all of the following\
    \ CMTP parameters applicable to its\n   control message:\n   -   IDPR protocol\
    \ and message type.\n   -   Destination.\n   -   Integrity/authentication scheme.\n\
    \   -   Timestamp.\n   -   Maximum number of transmissions allotted.\n   -   Retransmission\
    \ interval in microseconds.\n   One of these parameters, the timestamp, can be\
    \ specified directly by\n   CMTP as the internal clock time at which the message\
    \ is transmitted.\n   However, two of the IDPR protocols, namely flooding and\
    \ path control,\n   themselves require message generation timestamps for proper\
    \ protocol\n   operation.  Thus, instead of requiring CMTP to pass back a timestamp\n\
    \   to an IDPR protocol, we simplify the service interface between CMTP\n   and\
    \ the IDPR protocols by allowing an IDPR protocol to specify the\n   timestamp\
    \ in the first place.\n   Using the control message and accompanying parameters\
    \ supplied by the\n   IDPR protocol, CMTP constructs a DATAGRAM, adding to the\
    \ header\n   CMTP-specific parameters.  In particular, CMTP assigns a \"transaction\n\
    \   identifier\" to each DATAGRAM generated, which it uses to associate\n   acknowledgements\
    \ with DATAGRAM messages.  Each DATAGRAM recipient\n   includes the received transaction\
    \ identifier in its returned ACK or\n   NAK, and each DATAGRAM sender uses the\
    \ transaction identifier to\n   match the received ACK or NAK with the original\
    \ DATAGRAM.\n   A single DATAGRAM, for example a routing information message or\
    \ a\n   path control message, may be handled by CMTP at many different policy\n\
    \   gateways.  Within a pair of consecutive IDPR entities, the DATAGRAM\n   sender\
    \ expects to receive an acknowledgement from the DATAGRAM\n   recipient.  However,\
    \ only the IDPR entity that actually generated the\n   original CMTP DATAGRAM\
    \ has control over the transaction identifier,\n   because that entity may supply\
    \ a digital signature that covers the\n   entire DATAGRAM.  The intermediate policy\
    \ gateways that transmit the\n   DATAGRAM do not change the transaction identifier.\
    \  Nevertheless, at\n   each DATAGRAM recipient, the transaction identifier must\
    \ uniquely\n   distinguish the DATAGRAM so that only one acknowledgement from\
    \ the\n   next DATAGRAM recipient matches the original DATAGRAM.  Therefore,\n\
    \   the transaction identifier must be globally unique.\n   The transaction identifier\
    \ consists of the numeric identifiers for\n   the domain and IDPR entity (policy\
    \ gateway or route server) issuing\n   the original DATAGRAM, together with a\
    \ 32-bit local identifier\n   assigned by CMTP operating within that IDPR entity.\
    \  We recommend\n   implementing the 32-bit local identifier either as a simple\
    \ counter\n   incremented for each DATAGRAM generated or as a fine granularity\n\
    \   clock.  The former always guarantees uniqueness of transaction\n   identifiers;\
    \ the latter guarantees uniqueness of transaction\n   identifiers, provided the\
    \ clock granularity is finer than the minimum\n   possible interval between DATAGRAM\
    \ generations and the clock wrapping\n   period is longer than the maximum round-trip\
    \ delay to and from any\n   internetwork destination.\n   Before transmitting\
    \ a DATAGRAM, CMTP computes the length of the\n   entire message, taking into\
    \ account the prescribed\n   integrity/authentication scheme, and then computes\
    \ the\n   integrity/authentication value over the whole message.  CMTP includes\n\
    \   both of these quantities, which are crucial for checking message\n   integrity\
    \ and authenticity at the recipient, in the DATAGRAM header.\n   After sending\
    \ a DATAGRAM, CMTP saves a copy and sets an associated\n   retransmission timer,\
    \ as directed by the IDPR protocol parameters.\n   If the retransmission timer\
    \ fires and CMTP has received neither an\n   ACK nor a NAK for the DATAGRAM, CMTP\
    \ then retransmits the DATAGRAM,\n   provided this retransmission does not exceed\
    \ the transmission\n   allotment.  Whenever a DATAGRAM exhausts its transmission\
    \ allotment,\n   CMTP discards the DATAGRAM, informs the IDPR protocol that the\n\
    \   control message transmission was not successful, and logs the event\n   for\
    \ network management.  In this case, the IDPR protocol may either\n   resubmit\
    \ its control message to CMTP, specifying an alternate\n   destination, or discard\
    \ the control message altogether.\n"
- title: 2.2.  Message Reception
  contents:
  - "2.2.  Message Reception\n   At the receiving entity, when CMTP obtains a DATAGRAM,\
    \ it takes one\n   of the following actions, depending upon the outcome of the\
    \ message\n   validation checks:\n   - The DATAGRAM passes the CMTP validation\
    \ checks.  CMTP then delivers\n     the DATAGRAM with enclosed IDPR control message,\
    \ to the appropriate\n     IDPR protocol, which in turn applies its own integrity\
    \ checks to\n     the control message before acting on the contents.  The recipient\n\
    \     IDPR protocol, except in one case, directs CMTP to generate an ACK\n   \
    \  and return the ACK to the sender.  That exception is the up/down\n     protocol\
    \ (see section 3.2) which determines reachability of\n     adjacent policy gateways\
    \ and does not use CMTP ACK messages to\n     notify the sender of message reception.\
    \  Instead, the up/down\n     protocol messages themselves carry implicit information\
    \ about\n     message reception at the adjacent policy gateway.  In the cases\n\
    \     where the recipient IDPR protocol directs CMTP to generate an ACK,\n   \
    \  it may pass control information to CMTP for inclusion in the ACK,\n     depending\
    \ on the contents of the original IDPR control message.\n     For example, a route\
    \ server unable to fill a request for routing\n     information may inform the\
    \ requesting IDPR entity, through an ACK\n     for the initial request, to place\
    \ its request elsewhere.\n   - The DATAGRAM fails at least one of the CMTP validation\
    \ checks.\n     CMTP then generates a NAK, returns the NAK to the sender, and\n\
    \     discards the DATAGRAM, regardless of the type of IDPR control\n     message\
    \ contained in the DATAGRAM.  The NAK indicates the nature of\n     the validation\
    \ failure and serves to help the sender establish\n     communication with the\
    \ recipient.  In particular, the CMTP NAK\n     provides a mechanism for negotiation\
    \ of IDPR version and\n     integrity/authentication scheme, two parameters crucial\
    \ for\n     establishing communication between IDPR entities.\n   Upon receiving\
    \ an ACK or a NAK, CMTP immediately discards the message\n   if at least one of\
    \ the validation checks fails or if it is unable to\n   locate the associated\
    \ DATAGRAM.  CMTP logs the latter event for\n   network management.  Otherwise,\
    \ if all of the validation checks pass\n   and if it is able to locate the associated\
    \ DATAGRAM, CMTP clears the\n   associated retransmission timer and then takes\
    \ one of the following\n   actions, depending upon the message type:\n   - The\
    \ message is an ACK.  CMTP discards the associated DATAGRAM and\n     delivers\
    \ the ACK, which may contain IDPR control information, to\n     the appropriate\
    \ IDPR protocol.\n   - The message is a NAK.  If the associated DATAGRAM has exhausted\
    \ its\n     transmission allotment, CMTP discards the DATAGRAM, informs the\n\
    \     appropriate IDPR protocol that the control message transmission was\n  \
    \   not successful, and logs the event for network management.\n     Otherwise,\
    \ if the associated DATAGRAM has not yet exhausted its\n     transmission allotment,\
    \ CMTP first checks its copy of the DATAGRAM\n     against the failure indication\
    \ contained in the NAK.  If its\n     DATAGRAM copy appears to be intact, CMTP\
    \ retransmits the DATAGRAM\n     and sets the associated retransmission timer.\
    \  However, if its\n     DATAGRAM copy appears to be corrupted, CMTP discards\
    \ the DATAGRAM,\n     informs the IDPR protocol that the control message transmission\
    \ was\n     not successful, and logs the event for network management.\n"
- title: 2.3.  Message Validation
  contents:
  - "2.3.  Message Validation\n   On every CMTP message received, CMTP performs a\
    \ set of validation\n   checks to test message integrity and authenticity.  The\
    \ order in\n   which these tests are executed is important.  CMTP must first\n\
    \   determine if it can parse enough of the message to compute the\n   integrity/authentication\
    \ value.  (Refer to section 2.4 for a\n   description of CMTP message formats.)\
    \  Then, CMTP must immediately\n   compute the integrity/authentication value\
    \ before checking other\n   header information.  An incorrect integrity/authentication\
    \ value\n   means that the message is corrupted, and so it is likely that CMTP\n\
    \   header information is incorrect.  Checking specific header fields\n   before\
    \ computing the integrity/authentication value not only may\n   waste time and\
    \ resources, but also may lead to incorrect diagnoses of\n   a validation failure.\n\
    \   The CMTP validation checks are as follows:\n   - CMTP verifies that it can\
    \ recognize both the control message\n     version type contained in the header.\
    \  Failure to recognize either\n     one of these values means that CMTP cannot\
    \ continue to parse the\n     message.\n   - CMTP verifies that it can recognize\
    \ and accept the\n     integrity/authentication type contained in the header;\
    \ no\n     integrity/authentication is not an acceptable type for CMTP.\n   -\
    \ CMTP computes the integrity/authentication value and verifies that\n     it\
    \ equals the integrity/authentication value contained in the\n     header.  For\
    \ key-based integrity/authentication schemes, CMTP may\n     use the source domain\
    \ identifier contained in the CMTP header to\n     index the correct key.  Failure\
    \ to index a key means that CMTP\n     cannot compute the integrity/authentication\
    \ value.\n   - CMTP computes the message length in bytes and verifies that it\n\
    \     equals the length value contained in the header.\n   - CMTP verifies that\
    \ the message timestamp is in the acceptable\n     range.  The message should\
    \ be no more recent than cmtp_new (300)\n     seconds ahead of the entity's current\
    \ internal clock time.  In this\n     document, when we present an IDPR system\
    \ configuration parameter,\n     such as cmtp_new, we usually follow it with a\
    \ recommended value in\n     parentheses.  The cmtp_new value allows some clock\
    \ drift between\n     IDPR entities.  Moreover, each IDPR protocol has its own\
    \ limit on\n     the maximum age of its control messages.  The message should\
    \ be no\n     less recent than a prescribed number of seconds behind the\n   \
    \  recipient entity's current internal clock time.  Hence, each IDPR\n     protocol\
    \ performs its own message timestamp check in addition to\n     that performed\
    \ by CMTP.\n   - CMTP verifies that it can recognize the IDPR protocol designated\n\
    \     for the enclosed control message.\n   Whenever CMTP encounters a failure\
    \ while performing any of these\n   validation checks, it logs the event for network\
    \ management.  If the\n   failure occurs on a DATAGRAM, CMTP immediately generates\
    \ a NAK\n   containing the reason for the failure, returns the NAK to the sender,\n\
    \   and discards the DATAGRAM message.  If the failure occurs on an ACK\n   or\
    \ a NAK, CMTP discards the ACK or NAK message.\n"
- title: 2.4.  CMTP Message Formats
  contents:
  - "2.4.  CMTP Message Formats\n   In designing the format of IDPR control messages,\
    \ we have attempted\n   to strike a balance between efficiency of link bandwidth\
    \ usage and\n   efficiency of message processing.  In general, we have chosen\
    \ compact\n   representations for IDPR information in order to minimize the link\n\
    \   bandwidth consumed by IDPR-specific information.  However, we have\n   also\
    \ organized IDPR information in order to speed message processing,\n   which does\
    \ not always result in minimum link bandwidth usage.\n   To limit link bandwidth\
    \ usage, we currently use fixed-length\n   identifier fields in IDPR messages;\
    \ domains, virtual gateways, policy\n   gateways, and route servers are all represented\
    \ by fixed-length\n   identifiers.  To simplify message processing, we currently\
    \ align\n   fields containing an even number of bytes on even-byte boundaries\n\
    \   within a message.  In the future, if the Internet adopts the use of\n   super\
    \ domains, we will offer hierarchical, variable-length identifier\n   fields in\
    \ an updated version of IDPR.\n   The header of each CMTP message contains the\
    \ following information:\n    0                   1                   2      \
    \             3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8\
    \ 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |    VERSION    |  PRT  |  MSG  |  DPR  |  DMS  |    I/A TYP    |\n   +---------------+-------+-------+-------+-------+---------------+\n\
    \   |           SOURCE AD           |           SOURCE ENT          |\n   +-------------------------------+-------------------------------+\n\
    \   |                           TRANS ID                            |\n   +---------------------------------------------------------------+\n\
    \   |                           TIMESTAMP                           |\n   +-------------------------------+-------------------------------+\n\
    \   |            LENGTH             |       message specific        |\n   +-------------------------------+-------------------------------+\n\
    \   |         DATAGRAM AD           |         DATAGRAM ENT          |\n   +-------------------------------+-------------------------------+\n\
    \   |                             INFORM                            |\n   +---------------------------------------------------------------+\n\
    \   |                            INT/AUTH                           |\n   |  \
    \                                                             |\n   +---------------------------------------------------------------+\n\
    \   VERSION\n        (8 bits) Version number for IDPR control messages, currently\n\
    \        equal to 1.\n   PRT (4 bits) Numeric identifier for the control message\
    \ transport\n        protocol, equal to 0 for CMTP.\n   MSG (4 bits) Numeric identifier\
    \ for the CMTP message type,equal to 0\n        for a DATAGRAM, 1 for an ACK,\
    \ and 2 for a NAK.\n   DPR (4 bits) Numeric identifier for the original DATAGRAM's\
    \ IDPR\n        protocol type.\n   DMS (4 bits) Numeric identifier for the original\
    \ DATAGRAM's IDPR\n        message type.\n   I/A TYP (8 bits) Numeric identifier\
    \ for the integrity/authentication\n        scheme used.  CMTP requires the use\
    \ of an\n        integrity/authentication scheme; this value must not be set\n\
    \        equal to 0, indicating no integrity/authentication in use.\n   SOURCE\
    \ AD (16 bits) Numeric identifier for the domain containing the\n        IDPR\
    \ entity that generated the message.\n   SOURCE ENT (16 bits) Numeric identifier\
    \ for the IDPR entity that\n        generated the message.\n   TRANSACTION ID\
    \ (32 bits) Local transaction identifier assigned by the\n        IDPR entity\
    \ that generated the original DATAGRAM.\n   TIMESTAMP (32 bits) Number of seconds\
    \ elapsed since 1 January 1970\n        0:00 GMT.\n   LENGTH (16 bits) Length\
    \ of the entire IDPR control message, including\n        the CMTP header, in bytes.\n\
    \   message specific (16 bits) Dependent upon CMTP message type.\n        For\
    \ DATAGRAM and ACK messages:\n             RESERVED\n                  (16 bits)\
    \ Reserved for future use and currently set\n                  equal to 0.\n \
    \       For NAK messages:\n             ERR TYP (8 bits) Numeric identifier for\
    \ the type of CMTP\n                  validation failure encountered.  Validation\
    \ failures\n                  include the following types:\n                 \
    \ 1.   Unrecognized IDPR control message version number.\n                  2.\
    \   Unrecognized CMTP message type.\n                  3.   Unrecognized integrity/authentication\
    \ scheme.\n                  4.   Unacceptable integrity/authentication scheme.\n\
    \                  5.   Unable to locate key using source domain.\n          \
    \        6.   Incorrect integrity/authentication value.\n                  7.\
    \   Incorrect message length.\n                  8.   Message timestamp out of\
    \ range.\n                  9.   Unrecognized IDPR protocol designated for the\n\
    \                  enclosed control message.\n             ERR INFO (8 bits) CMTP\
    \ supplies the following additional\n                  information for the designated\
    \ types of validation\n                  failures:\n                  Type 1:\n\
    \                      Acceptable IDPR control message version number.\n     \
    \             Types 3 and 4: Acceptable integrity/authentication\n           \
    \           type.\n   DATAGRAM AD\n        (16 bits) Numeric identifier for the\
    \ domain containing the IDPR\n        entity that generated the original DATAGRAM.\
    \  Present only in\n        ACK and NAK messages.\n   DATAGRAM ENT (16 bits) Numeric\
    \ identifier for the IDPR entity that\n        generated the original DATAGRAM.\
    \  Present only in ACK and NAK\n        messages.\n   INFORM (optional,variable)\
    \ Information to be interpreted by the IDPR\n        protocol that issued the\
    \ original DATAGRAM.  Present only in ACK\n        messages and dependent on the\
    \ original DATAGRAM's IDPR protocol\n        type.\n   INT/AUTH (variable) Computed\
    \ integrity/authentication value,\n        dependent on the type of integrity/authentication\
    \ scheme used.\n"
- title: 3.  Virtual Gateway Protocol
  contents:
  - "3.  Virtual Gateway Protocol\n   Every policy gateway within a domain participates\
    \ in gathering\n   information about connectivity within and between virtual gateways\
    \ of\n   which it is a member and in distributing this information to other\n\
    \   virtual gateways in its domain.  We refer to these functions\n   collectively\
    \ as the Virtual Gateway Protocol (VGP).\n   The information collected through\
    \ VGP has both local and global\n   significance for IDPR.  Virtual gateway connectivity\
    \ information,\n   distributed to policy gateways within a single domain, aids\
    \ those\n   policy gateways in selecting routes across and between virtual\n \
    \  gateways connecting their domain to adjacent domains.  Inter-domain\n   connectivity\
    \ information, distributed throughout an internetwork in\n   routing information\
    \ messages, aids route servers in constructing\n   feasible policy routes.\n \
    \  Provided that a domain contains simple virtual gateway and transit\n   policy\
    \ configurations, one need only implement a small subset of the\n   VGP functions.\
    \  The connectivity among policy gateways within a\n   virtual gateway and the\
    \ heterogeneity of transit policies within a\n   domain determine which VGP functions\
    \ must be implemented, as we\n   explain toward the end of this section.\n"
- title: 3.1.  Message Scope
  contents:
  - "3.1.  Message Scope\n   Policy gateways generate VGP messages containing information\
    \ about\n   perceived changes in virtual gateway connectivity and distribute\n\
    \   these messages to other policy gateways within the same domain and\n   within\
    \ the same virtual gateway.  We classify VGP messages into three\n   distinct\
    \ categories: \"pair-PG\", \"intra-VG\", and \"inter-VG\", depending\n   upon\
    \ the scope of message distribution.\n   Policy gateways use CMTP for reliable\
    \ transport of VGP messages.  The\n   issuing policy gateway must communicate\
    \ to CMTP the maximum number of\n   transmissions per VGP message, vgp_ret, and\
    \ the interval between VGP\n   message retransmissions, vgp_int microseconds.\
    \  The recipient policy\n   gateway must determine VGP message acceptability;\
    \ conditions of\n   acceptability depend on the type of VGP message, as we describe\n\
    \   below.\n   Policy gateways store, act upon, and in the case of inter-VG\n\
    \   messages, forward the information contained in acceptable VGP\n   messages.\
    \  VGP messages that pass the CMTP validation checks but fail\n   a specific VGP\
    \ message acceptability check are considered to be\n   unacceptable and are hence\
    \ discarded by recipient policy gateways.  A\n   policy gateway that receives\
    \ an unacceptable VGP message also logs\n   the event for network management.\n"
- title: 3.1.1.  Pair-PG Messages
  contents:
  - "3.1.1.  Pair-PG Messages\n   Pair-PG message communication occurs between the\
    \ two members of a\n   pair of adjacent, peer, or neighbor policy gateways.  With\
    \ IDPR, the\n   only pair-PG messages are those periodically generated by the\
    \ up/down\n   protocol and used to monitor mutual reachability between policy\n\
    \   gateways.\n   A pair-PG message is \"acceptable\" if:\n   - It passes the\
    \ CMTP validation checks.\n   - Its timestamp is less than vgp_old (300) seconds\
    \ behind the\n     recipient's internal clock time.\n   - Its destination policy\
    \ gateway identifier coincides with the\n     identifier of the recipient policy\
    \ gateway.\n   - Its source policy gateway identifier coincides with the identifier\n\
    \     of a policy gateway configured for the recipient's domain or\n     associated\
    \ virtual gateway.\n"
- title: 3.1.2.  Intra-VG Messages
  contents:
  - "3.1.2.  Intra-VG Messages\n   Intra-VG message communication occurs between one\
    \ policy gateway and\n   all of its peers.  Whenever a policy gateway discovers\
    \ that its\n   connectivity to an adjacent or neighbor policy gateway has changed,\n\
    \   it issues an intra-VG message indicating the connectivity change to\n   all\
    \ of its reachable peers.  Whenever a policy gateway detects that a\n   previously\
    \ unreachable peer is now reachable, it issues, to that\n   peer, intra-VG messages\
    \ indicating connectivity to adjacent and\n   neighbor policy gateways.  If the\
    \ issuing policy gateway fails to\n   receive an analogous intra-VG message from\
    \ the newly reachable peer\n   within twice the configured VGP retransmission\
    \ interval, vgp_int\n   microseconds, it actively requests the intra-VG message\
    \ from that\n   peer.  These message exchanges ensure that peers maintain a\n\
    \   consistent view of each others' connectivity to adjacent and neighbor\n  \
    \ policy gateways.\n   An intra-VG message is \"acceptable\" if:\n   - It passes\
    \ the CMTP validation checks.\n   - Its timestamp is less than vgp_old (300) seconds\
    \ behind the\n     recipient's internal clock time.\n   - Its virtual gateway\
    \ identifier coincides with that of a virtual\n     gateway configured for the\
    \ recipient's domain.\n"
- title: 3.1.3.  Inter-VG Messages
  contents:
  - "3.1.3.  Inter-VG Messages\n   Inter-VG message communication occurs between one\
    \ policy gateway and\n   all of its neighbors.  Whenever the lowest-numbered operational\n\
    \   policy gateway in a set of mutually reachable peers discovers that\n   its\
    \ virtual gateway's connectivity to the adjacent domain or to\n   another virtual\
    \ gateway has changed, it issues an inter-VG message\n   indicating the connectivity\
    \ change to all of its neighbors.\n   Specifically, the policy gateway distributes\
    \ an inter-VG message to a\n   \"VG representative\" policy gateway (see section\
    \ 3.1.4 below) in each\n   virtual gateway in the domain.  Each VG representative\
    \ in turn\n   propagates the inter-VG message to each of its peers.\n   Whenever\
    \ the lowest-numbered operational policy gateway in a set of\n   mutually peers\
    \ detects that one or more previously unreachable peers\n   are now reachable,\
    \ it issues, to the lowest-numbered operational\n   policy gateway in all other\
    \ virtual gateways, requests for inter-VG\n   information indicating connectivity\
    \ to adjacent domains and to other\n   virtual gateways.  The recipient policy\
    \ gateways return the requested\n   inter-VG messages to the issuing policy gateway,\
    \ which in turn\n   distributes the messages to the newly reachable peers.  These\
    \ message\n   exchanges ensure that virtual gateways maintain a consistent view\
    \ of\n   each others' connectivity, while consuming minimal domain resources\n\
    \   in distributing connectivity information.\n   An inter-VG message contains\
    \ information about the entire virtual\n   gateway, not just about the issuing\
    \ policy gateway.  Thus, when\n   virtual gateway connectivity changes happen\
    \ in rapid succession,\n   recipients of the resultant inter-VG messages should\
    \ be able to\n   determine the most recent message and that message must contain\
    \ the\n   current virtual gateway connectivity information.  To ensure that the\n\
    \   connectivity information distributed is consistent and unambiguous,\n   we\
    \ designate a single policy gateway, namely the lowest-numbered\n   operational\
    \ peer, for generating and distributing inter-VG messages.\n   It is a simple\
    \ procedure for a set of mutually reachable peers to\n   determine the lowest-numbered\
    \ member, as we describe in section 3.2\n   below.\n   To understand why a single\
    \ member of a virtual gateway must issue\n   inter-VG messages, consider the following\
    \ example.  Suppose that two\n   peers in a virtual gateway each detect a different\
    \ connectivity\n   change and generate separate inter-VG messages.  Recipients\
    \ of these\n   messages may not be able to determine which message is more recent\
    \ if\n   policy gateway internal clocks are not perfectly synchronized.\n   Moreover,\
    \ even if the clocks were perfectly synchronized, and hence\n   message recency\
    \ could be consistently determined, it is possible for\n   each peer to issue\
    \ its inter-VG message before receiving current\n   information from the other.\
    \  As a result, neither inter-VG message\n   contains the correct connectivity\
    \ from the perspective of the virtual\n   gateway.  However, these problems are\
    \ eliminated if all inter-VG\n   messages are generated by a single peer within\
    \ a virtual gateway, in\n   particular the lowest-numbered operational policy\
    \ gateway.\n   An inter-VG message is \"acceptable\" if:\n   - It passes the CMTP\
    \ validation checks.\n   - Its timestamp is less than vgp_old (300) seconds behind\
    \ the\n     recipient's internal clock time.\n   - Its virtual gateway identifier\
    \ coincides with that of a virtual\n     gateway configured for the recipient's\
    \ domain.\n   - Its source policy gateway identifier represents the lowest numbered\n\
    \     operational member of the issuing virtual gateway, reachable from\n    \
    \ the recipient.\n   Distribution of intra-VG messages among peers often triggers\n\
    \   generation and distribution of inter-VG messages among virtual\n   gateways.\
    \  Usually, the lowest-numbered operational policy gateway in\n   a virtual gateway\
    \ generates and distributes an inter-VG message\n   immediately after detecting\
    \ a change in virtual gateway connectivity,\n   through receipt or generation\
    \ of an intra-VG message.  However, if\n   this policy gateway is also waiting\
    \ for an intra-VG message from a\n   newly reachable peer, it does not immediately\
    \ generate and distribute\n   the inter-VG message.\n   Waiting for intra-VG messages\
    \ enables the lowest-numbered operational\n   policy gateway in a virtual gateway\
    \ to gather the most recent\n   connectivity information for inclusion in the\
    \ inter-VG message.\n   However, under unusual circumstances, the policy gateway\
    \ may fail to\n   receive an intra-VG message from a newly reachable peer, even\
    \ after\n   actively requesting such a message.  To accommodate this case, VGP\n\
    \   uses an upper bound of four times the configured retransmission\n   interval,\
    \ vgp_int microseconds, on the amount of time to wait before\n   generating and\
    \ distributing an inter-VG message, when receipt of an\n   intra-VG message is\
    \ pending.\n"
- title: 3.1.4.  VG Representatives
  contents:
  - "3.1.4.  VG Representatives\n   When distributing an inter-VG message, the issuing\
    \ policy gateway\n   selects as recipients one neighbor, the VG Representative,\
    \ from each\n   virtual gateway in the domain.  To be selected as a VG\n   representative,\
    \ a policy gateway must be reachable from the issuing\n   policy gateway via intra-domain\
    \ routing.  The issuing policy gateway\n   gives preference to neighbors that\
    \ are members of more than one\n   virtual gateway.  Such a neighbor acts as a\
    \ VG representative for all\n   virtual gateways of which it is a member and restricts\
    \ inter-VG\n   message distribution as follows: any policy gateway that is a peer\
    \ in\n   more than one of the represented virtual gateways receives at most\n\
    \   one copy of the inter-VG message.  This message distribution strategy\n  \
    \ minimizes the number of message copies required for disseminating\n   inter-VG\
    \ information.\n"
- title: 3.2.  Up/Down Protocol
  contents:
  - "3.2.  Up/Down Protocol\n   Directly-connected adjacent policy gateways execute\
    \ the Up/Down\n   Protocol to determine mutual reachability.  Pairs of peer or\
    \ neighbor\n   policy gateways can determine mutual reachability through information\n\
    \   provided by the intra-domain routing procedure or through execution\n   of\
    \ the up/down protocol.  In general, we do not recommend\n   implementing the\
    \ up/down protocol between each pair of policy\n   gateways in a domain, as it\
    \ results in O(n**2) (where n is the number\n   of policy gateways within the\
    \ domain) communications complexity.\n   However, if the intra-domain routing\
    \ procedure is slow to detect\n   connectivity changes or is unable to report\
    \ reachability at the IDPR\n   entity level, the reachability information obtained\
    \ through the\n   up/down protocol may well be worth the extra communications\
    \ cost.  In\n   the remainder of this section, we decribe the up/down protocol\
    \ from\n   the perspective of adjacent policy gateways, but we note that the\n\
    \   identical protocol can be applied to peer and neighbor policy\n   gateways\
    \ as well.\n   The up/down protocol determines whether the direct connection between\n\
    \   adjacent policy gateways is acceptable for data traffic transport.  A\n  \
    \ direct connection is presumed to be \"down\" (unacceptable for data\n   traffic\
    \ transport) until the up/down protocol declares it to be \"up\"\n   (acceptable\
    \ for data traffic transport).  We say that a virtual\n   gateway is \"up\" if\
    \ there exists at least one pair of adjacent policy\n   gateways whose direct\
    \ connection is acceptable for data traffic\n   transport, and that a virtual\
    \ gateway is \"down\" if there exists no\n   such pair of adjacent policy gateways.\n\
    \   When executing the up/down protocol, policy gateways exchange UP/DOWN\n  \
    \ messages every ud_per (1) second.  All policy gateways use the same\n   default\
    \ period of ud_per initially and then negotiate a preferred\n   period through\
    \ exchange of UP/DOWN messages.  A policy gateway\n   reports its desired value\
    \ for ud_per within its UP/DOWN messages.  It\n   then chooses the larger of its\
    \ desired value and that of the adjacent\n   policy gateway as the period for\
    \ exchanging subsequent UP/DOWN\n   messages.  Policy gateways also exchange,\
    \ in UP/DOWN messages,\n   information about the identity of their respective\
    \ domain components.\n   This information assists the policy gateways in selecting\
    \ routes\n   across virtual gateways to partitioned domains.\n   Each UP/DOWN\
    \ message is transported using CMTP and hence is covered\n   by the CMTP validation\
    \ checks.  However, unlike other IDPR control\n   messages, UP/DOWN messages do\
    \ not require reliable transport.\n   Specifically, the up/down protocol requires\
    \ only a single\n   transmission per UP/DOWN message and never directs CMTP to\
    \ return an\n   ACK.  As pair-PG messages, UP/DOWN messages are acceptable under\
    \ the\n   conditions described in section 3.1.1.\n   Each policy gateway assesses\
    \ the state of its direct connection, to\n   the adjacent policy gateway, by counting\
    \ the number of acceptable\n   UP/DOWN messages received within a set of consecutive\
    \ periods.  A\n   policy gateway communicates its perception of the state of the\
    \ direct\n   connection through its UP/DOWN messages.  Initially, a policy gateway\n\
    \   indicates the down state in each of its UP/DOWN messages.  Only when\n   the\
    \ direct connection appears to be up from its perspective does a\n   policy gateway\
    \ indicate the up state in its UP/DOWN messages.\n   A policy gateway can begin\
    \ to transport data traffic over a direct\n   connection only if both of the following\
    \ conditions are true:\n   - The policy gateway receives from the adjacent policy\
    \ gateway at\n     least j acceptable UP/DOWN messages within the last m consecutive\n\
    \     periods.  From the recipient policy gateway's perspective, this\n     event\
    \ up.  Hence, the recipient policy gateway indicates the up\n     state in its\
    \ subsequent UP/DOWN messages.\n   - The UP/DOWN message most recently received\
    \ from the adjacent policy\n     gateway indicates the up state, signifying that\
    \ the adjacent policy\n     gateway considers the direct connection to be up.\n\
    \   A policy gateway must cease to transport data traffic over a direct\n   connection\
    \ whenever either of the following conditions is true:\n   - The policy gateway\
    \ receives from the adjacent policy gateway at\n     most acceptable UP/DOWN messages\
    \ within the last n consecutive\n     periods.\n   - The UP/DOWN message most\
    \ recently received from the adjacent policy\n     gateway indicates the down\
    \ state, signifying that the adjacent\n     policy gateway considers the direct\
    \ connection to be down.\n   From the recipient policy gateway's perspective,\
    \ either of these\n   events constitutes a state transition of the direct connection\
    \ from\n   up to down.  Hence, the policy gateway indicates the down state in\n\
    \   its subsequent UP/DOWN messages.\n"
- title: 3.3.  Implementation
  contents:
  - "3.3.  Implementation\n   We recommend implementing the up/down protocol using\
    \ a sliding\n   window.  Each window slot indicates the UP/DOWN message activity\n\
    \   during a given period, containing either a \"hit\" for receipt of an\n   acceptable\
    \ UP/DOWN message or a \"miss\" for failure to receive an\n   acceptable UP/DOWN\
    \ message.  In addition to the sliding window, the\n   implementation should include\
    \ a tally of hits recorded during the\n   current period and a tally of misses\
    \ recorded over the current\n   window.\n   When the direct connection moves to\
    \ the down state, the initial\n   values of the up/down protocol parameters must\
    \ be set as follows:\n   -   The sliding window size is equal to m.\n   -   Each\
    \ window slot contains a miss.\n   -   The current period hit tally is equal to\
    \ 0.\n   -   The current window miss tally is equal to m.\n   When the direct\
    \ connection moves to the up state, the initial values\n   of the up/down protocol\
    \ parameters must be set as follows:\n   -   The sliding window size is equal\
    \ to n.\n   -   Each window slot contains a hit.\n   -   The current period hit\
    \ tally is equal to 0.\n   -   The current window miss tally is equal to 0.\n\
    \   At the conclusion of each period, a policy gateway computes the miss\n   tally\
    \ and determines whether there has been a state transition of the\n   direct connection\
    \ to the adjacent policy gateway.  In the down state,\n   a miss tally of no more\
    \ than m - j signals a transition to the up\n   state.  In the up state, a miss\
    \ tally of no less than n - k signals a\n   transition to the down state.\n  \
    \ Computing the correct miss tally involves several steps.  First, the\n   policy\
    \ gateway prepares to slide the window by one slot so that the\n   oldest slot\
    \ disappears, making room for the newest slot.  However,\n   before sliding the\
    \ window, the policy gateway checks the contents of\n   the oldest window slot.\
    \  If this slot contains a miss, the policy\n   gateway decrements the miss tally\
    \ by 1, as this slot is no longer\n   part of the current window.\n   After sliding\
    \ the window, the policy gateway determines the proper\n   contents.  If the hit\
    \ tally for the current period equals 0, the\n   policy gateway records a miss\
    \ for the newest slot and increments the\n   miss tally by 1.  Otherwise, if the\
    \ hit tally for the current period\n   is greater than 0, the policy gateway records\
    \ a hit for the newest\n   slot and decrements the hit tally by 1.  Moreover,\
    \ the policy gateway\n   applies any remaining hits to slots containing misses,\
    \ beginning with\n   the newest and progressing to the oldest such slot.  For\
    \ each such\n   slot containing a miss, the policy gateway records a hit in that\
    \ slot\n   and decrements both the hit and miss tallies by 1, as the hit cancels\n\
    \   out a miss.  The policy gateway continues to apply each remaining hit\n  \
    \ tallied to any slot containing a miss, until either all such hits are\n   exhausted\
    \ or all such slots are accounted for.  Before beginning the\n   next up/down\
    \ period, the policy gateway resets the hit tally to 0.\n   Although we expect\
    \ the hit tally, within any given period, to be no\n   greater than 1, we do anticipate\
    \ the occasional period in which a\n   policy gateway receives more than one UP/DOWN\
    \ message from an\n   adjacent policy gateway.  The most common reasons for this\
    \ occurrence\n   are message delay and clock drift.  When an UP/DOWN message is\n\
    \   delayed, the receiving policy gateway observes a miss in one period\n   followed\
    \ by two hits in the next period, one of which cancels the\n   previous miss.\
    \  However, excess hits remaining in the tally after\n   miss cancellation indicate\
    \ a problem, such as clock drift.  Thus,\n   whenever a policy gateway accumulates\
    \ excess hits, it logs the event\n   for network management.\n   When clock drift\
    \ occurs between two adjacent policy gateways, it\n   causes the period of one\
    \ policy gateway to grow with respect to the\n   period of the other policy gateway.\
    \  Let p(X) be the period for PG X,\n   let p(Y) be the period for PG Y, and let\
    \ g and h be the smallest\n   positive integers such that g * p(X) = h * p(Y).\
    \  Suppose that p(Y) >\n   p(X) because of clock drift.  In this case, PG X observes\
    \ g - h\n   misses in g consecutive periods, while PG Y observes g - h surplus\n\
    \   hits in h consecutive periods.  As long as (g - h)/g < (n - k)/n and\n   (g\
    \ - h)/g < or = (m - j)/m, the clock drift itself will not cause the\n   direct\
    \ connection to enter or remain in the down state.\n"
- title: 3.4.  Policy Gateway Connectivity
  contents:
  - "3.4.  Policy Gateway Connectivity\n   Policy gateways collect connectivity information\
    \ through the intra-\n   domain routing procedure and through VGP, and they distribute\n\
    \   connectivity changes through VGP in both intra-VG messages to peers\n   and\
    \ inter-VG messages to neighbors.  Locally, this connectivity\n   information\
    \ assists policy gateways in selecting routes, not only\n   across a virtual gateway\
    \ to an adjacent domain but also across a\n   domain between two virtual gateways.\
    \  Moreover, changes in\n   connectivity between domains are distributed, in routing\
    \ information\n   messages, to route servers throughout an internetwork.\n"
- title: 3.4.1.  Within a Virtual Gateway
  contents:
  - "3.4.1.  Within a Virtual Gateway\n   Each policy gateway within a virtual gateway\
    \ constantly monitors its\n   connectivity to all adjacent and to all peer policy\
    \ gateways.  To\n   determine the state of its direct connection to an adjacent\
    \ policy\n   gateway, a policy gateway uses reachability information supplied\
    \ by\n   the up/down protocol.  To determine the state of its intra-domain\n \
    \  routes to a peer policy gateway, a policy gateway uses reachability\n   information\
    \ supplied by either the intra-domain routing procedure or\n   the up/down protocol.\n\
    \   A policy gateway generates a PG CONNECT message whenever either of\n   the\
    \ following conditions is true:\n   -   The policy gateway detects a change, in\
    \ state or in adjacent\n       domain component, associated with its direct connection\
    \ to an\n       adjacent policy gateway.  In this case, the policy gateway\n \
    \      distributes a copy of the message to each peer reachable via\n       intra-domain\
    \ routing.\n   -   The policy gateway detects that a previously unreachable peer\
    \ is\n       now reachable.  In this case, the policy gateway distributes a\n\
    \       copy of the message to the newly reachable peer.\n   A PG CONNECT message\
    \ is an intra-VG message that includes information\n   about each adjacent policy\
    \ gateway directly connected to the issuing\n   policy gateway.  Specifically,\
    \ the PG CONNECT message contains the\n   adjacent policy gateway's identifier,\
    \ status (reachable or\n   unreachable), and domain component identifier.  If\
    \ a PG CONNECT\n   message contains a \"request\", each peer that receives the\
    \ message\n   responds to the sender with its own PG CONNECT message.\n   All\
    \ mutually reachable peers monitor policy gateway connectivity\n   within their\
    \ virtual gateway, through the up/down protocol, the\n   intra-domain routing\
    \ procedure, and the exchange of PG CONNECT\n   messages.  Within a given virtual\
    \ gateway, each constituent policy\n   gateway maintains the following information\
    \ about each configured\n   adjacent policy gateway:\n   - The identifier for\
    \ the adjacent policy gateway.\n   - The status of the adjacent policy gateway:\
    \ reachable/unreachable,\n     directly connected/not directly connected.\n  \
    \ - The local exit interfaces used to reach the adjacent policy\n     gateway,\
    \ provided it is reachable.\n   - The identifier for the adjacent policy gateway's\
    \ domain component.\n   - The set of peers to which the adjacent policy gateway\
    \ is\n     directly-connected.\n   Hence, all mutually reachable peers can detect\
    \ changes in\n   connectivity across the virtual gateway to adjacent domain\n\
    \   components.\n   When the lowest-numbered operational peer policy gateway within\
    \ a\n   virtual gateway detects a change in the set of adjacent domain\n   components\
    \ reachable through direct connections across the given\n   virtual gateway, it\
    \ generates a VGCONNECT message and distributes a\n   copy to a VG representative\
    \ in all other virtual gateways connected\n   to its domain.  A VG CONNECT message\
    \ is an inter-VG message that\n   includes information about each peer's connectivity\
    \ across the given\n   virtual gateway.  Specifically, the VG CONNECT message\
    \ contains, for\n   each peer, its identifier and the identifiers of the domain\n\
    \   components reachable through its direct connections to adjacent\n   policy\
    \ gateways.  Moreover, the VG CONNECT message gives each\n   recipient enough\
    \ information to determine the state, up or down, of\n   the issuing virtual gateway.\n\
    \   The issuing policy gateway, namely the lowest-numbered operational\n   peer,\
    \ may have to wait up to four times vgp_int microseconds after\n   detecting the\
    \ connectivity change, before generating and distributing\n   the VGCONNECT message,\
    \ as described in section 3.1.3.  Each recipient\n   VG representative in turn\
    \ distributes a copy of the VG CONNECT\n   message to each of its peers reachable\
    \ via intra-domain routing.  If\n   a VG CONNECT message contains a \"request\"\
    , then in each recipient\n   virtual gateway, the lowest-numbered operational\
    \ peer that receives\n   the message responds to the original sender with its\
    \ own VGCONNECT\n   message.\n"
- title: 3.4.2.  Between Virtual Gateways
  contents:
  - "3.4.2.  Between Virtual Gateways\n   At present, we expect transit policies to\
    \ be uniform over all intra-\n   domain routes between any pair of policy gateways\
    \ within a domain.\n   However, when tariffed qualities of service become prevalent\n\
    \   offerings for intra-domain routing, we can no longer expect\n   uniformity\
    \ of transit policies throughout a domain.  To monitor the\n   transit policies\
    \ supported on intra-domain routes between virtual\n   gateways requires both\
    \ a policy-sensitive intra-domain routing\n   procedure and a VGP exchange of\
    \ policy information between neighbor\n   policy gateways.\n   Each policy gateway\
    \ within a domain constantly monitors its\n   connectivity to all peer and neighbor\
    \ policy gateways, including the\n   transit policies supported on intra-domain\
    \ routes to these policy\n   gateways.  To determine the state of its intra-domain\
    \ connection to a\n   peer or neighbor policy gateway, a policy gateway uses reachability\n\
    \   information supplied by either the intra-domain routing procedure or\n   the\
    \ up/down protocol.  To determine the transit policies supported on\n   intra-domain\
    \ routes to a peer or neighbor policy gateway, a policy\n   gateway uses policy-sensitive\
    \ reachability information supplied by\n   the intra-domain routing procedure.\
    \  We note that when transit\n   policies are uniform over a domain, reachability\
    \ and policy-sensitive\n   reachability are equivalent.\n   Within a virtual gateway,\
    \ each constituent policy gateway maintains\n   the following information about\
    \ each configured peer and neighbor\n   policy gateway:\n   - The identifier for\
    \ the peer or neighbor policy gateway.\n   - The identifiers corresponding to\
    \ the transit policies configured to\n     be supported by intra-domain routes\
    \ to the peer or neighbor policy\n     gateway.\n   - According to each transit\
    \ policy, the status of the peer or\n     neighbor policy gateway: reachable/unreachable.\n\
    \   - For each transit policy, the local exit interfaces used to reach\n     the\
    \ peer or neighbor policy gateway, provided it is reachable.\n   - The identifiers\
    \ for the adjacent domain components reachable\n     through direct connections\
    \ from the peer or neighbor policy\n     gateway, obtained through VG CONNECT\
    \ messages.\n   Using this information, a policy gateway can detect changes in\
    \ its\n   connectivity to an adjoining domain component, with respect to a\n \
    \  given transit policy and through a given neighbor.  Moreover,\n   combining\
    \ the information obtained for all neighbors within a given\n   virtual gateway,\
    \ the policy gateway can detect changes in its\n   connectivity, with respect\
    \ to a given transit policy, to that virtual\n   gateway and to adjoining domain\
    \ components reachable through that\n   virtual gateway.\n   All policy gateways\
    \ mutually reachable via intra-domain routes\n   supporting a configured transit\
    \ policy need not exchange information\n   about perceived changes in connectivity,\
    \ with respect to the given\n   transit policy.  In this case, each policy gateway\
    \ can infer\n   another's policy-sensitive reachability to a third, through mutual\n\
    \   intra-domain reachability information provided by the intra-domain\n   routing\
    \ procedure.  However, whenever two or more policy gateways are\n   no longer\
    \ mutually reachable with respect to a given transit policy,\n   these policy\
    \ gateways can no longer infer each other's reachability\n   to other policy gateways,\
    \ with respect to that transit policy.  In\n   this case, these policy gateways\
    \ must exchange explicit information\n   about changes in connectivity to other\
    \ policy gateways, with respect\n   to that transit policy.\n   A policy gateway\
    \ generates a PG POLICY message whenever either of the\n   following conditions\
    \ is true:\n   - The policy gateway detects a change in its connectivity to another\n\
    \     virtual gateway, with respect to a configured transit policy, or to\n  \
    \   an adjoining domain component reachable through that virtual\n     gateway.\
    \  In this case, the policy gateway distributes a copy of\n     the message to\
    \ each peer reachable via intra-domain routing but not\n     currently reachable\
    \ via any intra-domain routes of the given\n     transit policy.\n   - The policy\
    \ gateway detects that a previously unreachable peer is\n     reachable.  In this\
    \ case, the policy gateway distributes a copy of\n     the message to the newly\
    \ reachable peer.\n   A PG POLICY message is an intra-VG message that includes\
    \ information\n   about each configured transit policy and each virtual gateway\n\
    \   configured to be reachable from the issuing policy gateway via\n   intra-domain\
    \ routes of the given transit policy.  Specifically, the\n   PGPOLICY message\
    \ contains, for each configured transit policy:\n   - The identifier for the transit\
    \ policy.\n   - The identifiers for the virtual gateways associated with the given\n\
    \     transit policy and currently reachable, with respect to that\n     transit\
    \ policy, from the issuing policy gateway.\n   - The identifiers for the domain\
    \ components reachable from and\n     adjacent to the members of the given virtual\
    \ gateways.\n   If a PG POLICY message contains a \"request\", each peer that\
    \ receives\n   the message responds to the original sender with its own PG POLICY\n\
    \   message.\n   In addition to connectivity between itself and its neighbors,\
    \ each\n   policy gateway also monitors the connectivity, between domain\n   components\
    \ adjacent to its virtual gateway and domain components\n   adjacent to other\
    \ virtual gateways, through its domain and with\n   respect to the configured\
    \ transit policies.  For each member of each\n   of its virtual gateways, a policy\
    \ gateway monitors:\n   -  The set of  adjacent domain components  currently reachable\n\
    \     through direct connections across the given virtual gateway.  The\n    \
    \ policy gateway obtains this information through PG CONNECT messages\n     from\
    \ reachable peers and through UP/DOWN messages from adjacent\n     policy gateways.\n\
    \   - For each configured transit policy, the set of virtual gateways\n     currently\
    \ reachable from the given virtual gateway with respect to\n     that transit\
    \ policy and the set of adjoining domain components\n     currently reachable\
    \ through direct connections across those virtual\n     gateways.  The policy\
    \ gateway obtains this information through PG\n     POLICY messages from peers,\
    \ VG CONNECT messages from neighbors, and\n     the intra-domain routing procedure.\
    \  Using this information, a\n     policy gateway can detect connectivity changes,\
    \ through its domain\n     and with respect to a given transit policy, between\
    \ adjoining\n     domain components.\n   When the lowest-numbered operational\
    \ policy gateway within a virtual\n   gateway detects a change in the connectivity\
    \ between a domain\n   component adjacent to its virtual gateway and a domain\
    \ component\n   adjacent to another virtual gateway in its domain, with respect\
    \ to a\n   configured transit policy, it generates a VG POLICY message and\n \
    \  distributes a copy to a VG representative in selected virtual\n   gateways\
    \ connected to its domain.  In particular, the lowest-numbered\n   operational\
    \ policy gateway distributes a VG POLICY message to a VG\n   representative in\
    \ every other virtual gateway containing a member\n   reachable via intra-domain\
    \ routing but not currently reachable via\n   any routes of the given transit\
    \ policy.  A VG POLICY message is an\n   inter-VG message that includes information\
    \ about the connectivity\n   between domain components adjacent to the issuing\
    \ virtual gateway and\n   domain components adjacent to the other virtual gateways\
    \ in the\n   domain, with respect to configured transit policies.  Specifically,\n\
    \   the VG POLICY message contains, for each transit policy:\n   - The identifier\
    \ for the transit policy.\n   - The identifiers for the virtual gateways associated\
    \ with the given\n     transit policy and currently reachable, with respect to\
    \ that\n     transit policy, from the issuing virtual gateway.\n   - The identifiers\
    \ for the domain components reachable from and\n     adjacent to the members of\
    \ the given virtual gateways.\n   The issuing policy gateway, namely the lowest-numbered\
    \ operational\n   peer, may have to wait up to four times vgp_int microseconds\
    \ after\n   detecting the connectivity change, before generating and distributing\n\
    \   the VG POLICY message, as described in section 3.1.3.  Each recipient\n  \
    \ VG representative in turn distributes a copy of the VG POLICY message\n   to\
    \ each of its peers reachable via intra-domain routing.  If a VG\n   POLICY message\
    \ contains a \"request\", then in each recipient virtual\n   gateway, the lowest-numbered\
    \ operational peer that receives the\n   message responds to the original sender\
    \ with its own VG POLICY\n   message.\n"
- title: 3.4.3.  Communication Complexity
  contents:
  - "3.4.3.  Communication Complexity\n   We offer an example, to provide an estimate\
    \ of the number of VGP\n   messages exchanged within a domain, AD X, after a detected\
    \ change in\n   policy gateway connectivity.  Suppose that an adjacent domain,\
    \ AD Y,\n   partitions such that the partition is detectable through the exchange\n\
    \   of UP/DOWN messages across a virtual gateway connecting AD X and AD\n   Y.\
    \  Let V be the number of virtual gateways in AD X.  Suppose each\n   virtual\
    \ gateway contains P peer policy gateways, and no policy\n   gateway is a member\
    \ of multiple virtual gateways.  Then, within AD X,\n   the detected partition\
    \ will result in the following VGP message\n   exchanges:\n   - P policy gateways\
    \ each receive at most P-1 PG CONNECT messages.\n     Each policy gateway detecting\
    \ the adjacent domain partition\n     generates a PG CONNECT message and distributes\
    \ it to each reachable\n     peer in the virtual gateway.\n   - P * (V-1) policy\
    \ gateways each receive at most one VG CONNECT\n     message.  The lowest-numbered\
    \ operational policy gateway in the\n     virtual gateway detecting the partition\
    \ of the adjacent domain\n     generates a VG CONNECT message and distributes\
    \ it to a VG\n     representative in all other virtual gateways connected to the\n\
    \     domain.  In turn, each VG representative distributes the VG CONNECT\n  \
    \   message to each reachable peer within its virtual gateway.\n   - P * (V-1)\
    \ policy gateways each receive at most P-1 PG POLICY\n     messages, and only\
    \ if the domain has more than a single uniform\n     transit policy.  Each policy\
    \ gateway in each virtual gateway\n     generates a PG POLICY message and distributes\
    \ it to all reachable\n     peers not currently reachable with respect to the\
    \ given transit\n     policy.\n   - P * V policy gateways each receive at most\
    \ V-1 VG POLICY messages,\n     only if the domain has more than a single uniform\
    \ transit policy.\n     The lowest-numbered operational policy gateway in each\
    \ virtual\n     gateway generates a VG POLICY message and distributes it to a\
    \ VG\n     representative in all other virtual gateways containing at least\n\
    \     one reachable member not currently reachable with respect to the\n     given\
    \ transit policy.  In turn, each VG representative distributes\n     a VG POLICY\
    \ message to each peer within its virtual gateway.\n"
- title: 3.5.  VGP Message Formats
  contents:
  - "3.5.  VGP Message Formats\n   The virtual gateway protocol number is equal to\
    \ 0.  We describe the\n   contents of each type of VGP message below.\n"
- title: 3.5.1.  UP/DOWN
  contents:
  - "3.5.1.  UP/DOWN\n   The UP/DOWN message type is equal to 0.\n    0          \
    \         1                   2                   3\n    0 1 2 3 4 5 6 7 8 9 0\
    \ 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            SRC CMP            |            DST AD             |\n   +-------------------------------+---------------+---------------+\n\
    \   |            DST PG             |    PERIOD     |     STATE     |\n   +-------------------------------+---------------+---------------+\n\
    \   SRC CMP\n        (16 bits) Numeric identifier for the domain component containing\n\
    \        the issuing policy gateway.\n   DST AD (16 bits) Numeric identifier for\
    \ the destination domain.\n   DST PG (16 bits) Numeric identifier for the destination\
    \ policy\n        gateway.\n   PERIOD (8 bits) Length of the UP/DOWN message generation\
    \ period, in\n        seconds.\n   STATE (8 bits) Perceived state (1 up, 0 down)\
    \ of the direct\n        connection from the perspective of the issuing policy\
    \ gateway,\n        contained in the right-most bit.\n"
- title: 3.5.2.  PG CONNECT
  contents:
  - "3.5.2.  PG CONNECT\n   The PG CONNECT message type is equal to 1.  PG CONNECT\
    \ messages are\n   not required for any virtual gateway containing exactly two\
    \ policy\n   gateways.\n    0                   1                   2        \
    \           3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\
    \ 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            ADJ AD             |      VG       |     RQST      |\n   +-------------------------------+---------------+---------------+\n\
    \   |            NUM RCH            |           NUM UNRCH           |\n   +-------------------------------+-------------------------------+\n\
    \   For each reachable adjacent policy gateway:\n   +-------------------------------+-------------------------------+\n\
    \   |            ADJ PG             |            ADJ CMP            |\n   +-------------------------------+-------------------------------+\n\
    \   For each unreachable adjacent policy gateway:\n   +-------------------------------+\n\
    \   |            ADJ PG             |\n   +-------------------------------+\n\
    \   ADJ AD\n        (16 bits) Numeric identifier for the adjacent domain.\n  \
    \ VG (8 bits) Numeric identifier for the virtual gateway.\n   RQST (8 bits) Request\
    \ for a PG CONNECT message (1 request, 0 no\n        request) from each recipient\
    \ peer, contained in the right-most\n        bit.\n   NUM RCH (16 bits) Number\
    \ of adjacent policy gateways within the\n        virtual gateway, which are directly-connected\
    \ to and currently\n        reachable from the issuing policy gateway.\n   NUM\
    \ UNRCH (16 bits) Number of adjacent policy gateways within the\n        virtual\
    \ gateway, which are directly-connected to but not\n        currently reachable\
    \ from the issuing policy gateway.\n   ADJ PG (16 bits) Numeric identifier for\
    \ a directly-connected adjacent\n        policy gateway.\n   ADJ CMP (16 bits)\
    \ Numeric identifier for the domain component\n        containing the reachable,\
    \ directly-connected adjacent policy\n        gateway.\n"
- title: 3.5.3.  PG POLICY
  contents:
  - "3.5.3.  PG POLICY\n   The PG POLICY message type is equal to 2.  PG POLICY messages\
    \ are not\n   required for any virtual gateway containing exactly two policy\n\
    \   gateways or for any domain with a single uniform transit policy.\n    0  \
    \                 1                   2                   3\n    0 1 2 3 4 5 6\
    \ 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            ADJ AD             |      VG       |     RQST      |\n   +-------------------------------+---------------+---------------+\n\
    \   |            NUM TP             |\n   +-------------------------------+\n\
    \   For each transit policy associated with the virtual gateway:\n   +-------------------------------+-------------------------------+\n\
    \   |              TP               |            NUM VG             |\n   +-------------------------------+-------------------------------+\n\
    \   For each virtual gateway reachable via the transit policy:\n   +-------------------------------+---------------+---------------+\n\
    \   |            ADJ AD             |      VG       |    UNUSED     |\n   +-------------------------------+---------------+---------------+\n\
    \   |            NUM CMP            |            ADJ CMP            |\n   +-------------------------------+-------------------------------+\n\
    \   ADJ AD\n        (16 bits) Numeric identifier for the adjacent domain.\n  \
    \ VG (8 bits) Numeric identifier for the virtual gateway.\n   RQST (8 bits) Request\
    \ for a PG POLICY message (1 request, 0 no\n        request) from each recipient\
    \ peer, contained in the right-most\n        bit.\n   NUM TP (8 bits) Number of\
    \ transit policies configured to include the\n        virtual gateway.\n   TP\
    \ (16 bits) Numeric identifier for a transit policy associated with\n        the\
    \ virtual gateway.\n   NUM VG (16 bits) Number of virtual gateways reachable from\
    \ the\n        issuing policy gateway, via intra-domain routes supporting the\n\
    \        transit policy.\n   UNUSED (8 bits) Not currently used; must be set equal\
    \ to 0.\n   NUM CMP (16 bits) Number of adjacent domain components reachable via\n\
    \        direct connections through the virtual gateway.\n   ADJ CMP (16 bits)\
    \ Numeric identifier for a reachable adjacent domain\n        component.\n"
- title: 3.5.4.  VG CONNECT
  contents:
  - "3.5.4.  VG CONNECT\n   The VG CONNECT message type is equal to 3.\n    0    \
    \               1                   2                   3\n    0 1 2 3 4 5 6 7\
    \ 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            ADJ AD             |      VG       |     RQST      |\n   +-------------------------------+---------------+---------------+\n\
    \   |            NUM PG             |\n   +-------------------------------+\n\
    \   For each reach policy gateway in the virtual gateway:\n   +-------------------------------+-------------------------------+\n\
    \   |              PG               |            NUM CMP            |\n   +-------------------------------+-------------------------------+\n\
    \   |            ADJ CMP            |\n   +-------------------------------+\n\
    \   ADJ AD\n        (16 bits) Numeric identifier for the adjacent domain.\n  \
    \ VG (8 bits) Numeric identifier for the virtual gateway.\n   RQST (8 bits) Request\
    \ for a VG CONNECT message (1 request, 0 no\n        request) from a recipient\
    \ in each virtual gateway, contained in\n        the right-most bit.\n   NUM PG\
    \ (16 bits) Number of mutually-reachable peer policy gateways in\n        the\
    \ virtual gateway.\n   PG (16 bits) Numeric identifier for a peer policy gateway.\n\
    \   NUM CMP (16 bits) Number of components of the adjacent domain\n        reachable\
    \ via direct connections from the policy gateway.\n   ADJ CMP (16 bits) Numeric\
    \ identifier for a reachable adjacent domain\n        component.\n"
- title: 3.5.5.  VG POLICY
  contents:
  - "3.5.5.  VG POLICY\n   The VG POLICY message type is equal to 4.  VG POLICY messages\
    \ are not\n   required for any domain with a single uniform transit policy.\n\
    \    0                   1                   2                   3\n    0 1 2\
    \ 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            ADJ AD             |      VG       |     RQST      |\n   +-------------------------------+---------------+---------------+\n\
    \   |            NUM TP             |\n   +-------------------------------+\n\
    \   For each transit policy associated with the virtual gateway:\n   +-------------------------------+-------------------------------+\n\
    \   |              TP               |            NUM GRP            |\n   +-------------------------------+-------------------------------+\n\
    \   For each virtual gateway group reachable via the transit policy:\n   +-------------------------------+-------------------------------+\n\
    \   |            NUM VG             |            ADJ AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |     VG        |    UNUSED     |            NUM CMP            |\n   +---------------+---------------+-------------------------------+\n\
    \   |            ADJ CMP            |\n   +-------------------------------+\n\
    \   ADJ AD\n        (16 bits) Numeric identifier for the adjacent domain.\n  \
    \ VG (8 bits) Numeric identifier for the virtual gateway.\n   RQST (8 bits) Request\
    \ for a VG POLICY message (1 request, 0 no\n        request) from a recipient\
    \ in each virtual gateway, contained in\n        the right-most bit.\n   NUM TP\
    \ (16 bits) Number of transit policies configured to include the\n        virtual\
    \ gateway.\n   TP (16 bits) Numeric identifier for a transit policy associated\
    \ with\n        the virtual gateway.\n   NUM GRP (16 bits) Number of groups of\
    \ virtual gateways, such that all\n        members in a group are reachable from\
    \ the issuing virtual\n        gateway via intra-domain routes supporting the\
    \ given transit\n        policy.\n   NUM VG (16 bits) Number of virtual gateways\
    \ in a virtual gateway\n        group.\n   UNUSED (8 bits) Not currently used;\
    \ must be set equal to 0.\n   NUM CMP (16 bits) Number of adjacent domain components\
    \ reachable via\n        direct connections through the virtual gateway.\n   ADJ\
    \ CMP (16 bits) Numeric identifier for a reachable adjacent domain\n        component.\n\
    \   Normally, each VG POLICY message will contain a single virtual\n   gateway\
    \ group.  However, if the issuing virtual gateway becomes\n   partitioned such\
    \ that peers are mutually reachable with respect to\n   some transit policies\
    \ but not others, virtual gateway groups may be\n   necessary.  For example, let\
    \ PG X and PG Y be two peers in VG A which\n   configured to support transit policies\
    \ 1 and 2.  Suppose that PG X\n   and PG Y are reachable with respect to transit\
    \ policy 1 but not with\n   respect to transit policy 2.  Furthermore, suppose\
    \ that PG X can\n   reach members of VG B via intra-domain routes of transit policy\
    \ 2 and\n   that PG Y can reach members of VG C via intra-domain routes of\n \
    \  transit policy 2.  Then the entry in the VG POLICY message issued by\n   VG\
    \ A will include, for transit policy 2, two groups of virtual\n   gateways, one\
    \ containing VG B and one containing VG C.\n"
- title: 3.5.6.  Negative Acknowledgements
  contents:
  - "3.5.6.  Negative Acknowledgements\n   When a policy gateway receives an unacceptable\
    \ VGP message that\n   passes the CMTP validation checks, it includes, in its\
    \ CMTP ACK, an\n   appropriate VGP negative acknowledgement.  This information\
    \ is placed\n   in the INFORM field of the CMTP ACK (described previously in section\n\
    \   2.4); the numeric identifier for each type of VGP negative\n   acknowledgement\
    \ is contained in the left-most 8 bits of the INFORM\n   field.  Negative acknowledgements\
    \ associated with VGP include the\n   following types:\n   1.  Unrecognized VGP\
    \ message type.  Numeric identifier for the\n       unrecognized message type\
    \ (8 bits).\n   2.  Out-of-date VGP message.\n   3.  Unrecognized virtual gateway\
    \ source.  Numeric identifier for the\n       unrecognized virtual gateway including\
    \ the adjacent domain\n       identifier (16 bits) and the local identifier (8\
    \ bits).\n"
- title: 4.  Routing Information Distribution
  contents:
  - "4.  Routing Information Distribution\n   Each domain participating in IDPR generates\
    \ and distributes its\n   routing information messages to route servers throughout\
    \ an\n   internetwork.  IDPR routing information messages contain information\n\
    \   about the transit policies in effect across the given domain and the\n   virtual\
    \ gateway connectivity to adjacent domains.  Route servers in\n   turn use IDPR\
    \ routing information to generate policy routes between\n   source and destination\
    \ domains.\n   There are three different procedures for distributing IDPR routing\n\
    \   information:\n   - The flooding protocol.  In this case, a representative\
    \ policy\n     gateway in each domain floods its routing information messages\
    \ to\n     route servers in all other domains.\n   - Remote route server communication.\
    \  In this case, a route server\n     distributes its domain's routing information\
    \ messages to route\n     servers in specific destination domains, by encapsulating\
    \ these\n     messages within IDPR data messages.  Thus, a domain administrator\n\
    \     may control the distribution of the domain's routing information by\n  \
    \   restricting routing information exchange with remote route servers.\n    \
    \ Currently, routing information distribution restrictions are not\n     included\
    \ in IDPR configuration information.\n   - The route server query protocol.  In\
    \ this case, a policy gateway or\n     route server requests routing information\
    \ from another route\n     server, which in turn responds with routing information\
    \ from its\n     database.  The route server query protocol may be used for quickly\n\
    \     updating the routing information maintained by a policy gateway\n     or\
    \ route server that has just been connected or reconnected to an\n     internetwork.\
    \  It may also be used to retrieve routing information\n     from domains that\
    \ restrict distribution of their routing\n     information.\n   In this section,\
    \ we describe the flooding protocol only.  In section\n   5, we describe the route\
    \ server query protocol, and in section 5.2,\n   we describe communication between\
    \ route servers in separate domains.\n   Policy gateways and route servers use\
    \ CMTP for reliable transport of\n   IDPR routing information messages flooded\
    \ between peer, neighbor, and\n   adjacent policy gateways and between those policy\
    \ gateways and route\n   servers.  The issuing policy gateway must communicate\
    \ to CMTP the\n   maximum number of transmissions per routing information message,\n\
    \   flood_ret, and the interval between routing information message\n   retransmissions,\
    \ flood_int microseconds.  The recipient policy\n   gateway or route server must\
    \ determine routing information message\n   acceptability, as we describe in section\
    \ 4.2.3 below.\n"
- title: 4.1.  AD Representatives
  contents:
  - "4.1.  AD Representatives\n   We designate a single policy gateway, the \"AD representative\"\
    , for\n   generating and distributing IDPR routing information about its\n   domain,\
    \ to ensure that the routing information distributed is\n   consistent and unambiguous\
    \ and to minimize the communication required\n   for routing information distribution.\
    \  There is usually only a single\n   AD representative per domain, namely the\
    \ lowest-numbered operational\n   policy gateway in the domain.  Within a domain,\
    \ policy gateways need\n   no explicit election procedure to determine the AD\
    \ representative.\n   Instead, all members of a set of policy gateways mutually\
    \ reachable\n   via intra-domain routes can agree on set membership and therefore\
    \ on\n   which member has the lowest number.\n   A partitioned domain has as many\
    \ AD representatives as it does domain\n   components.  In fact, the numeric identifier\
    \ for an AD representative\n   is identical to the numeric identifier for a domain\
    \ component.  One\n   cannot normally predict when and where a domain partition\
    \ will occur,\n   and thus any policy gateway within a domain may become an AD\n\
    \   representative at any time.  To prepare for the role of AD\n   representative\
    \ in the event of a domain partition, every policy\n   gateway must continually\
    \ monitor its domain's IDPR routing\n   information, through VGP and through the\
    \ intra-domain routing\n   procedure.\n"
- title: 4.2.  Flooding Protocol
  contents:
  - "4.2.  Flooding Protocol\n   An AD representative policy gateway uses unrestricted\
    \ flooding among\n   all domains to distribute its domain's IDPR routing information\n\
    \   messages to route servers in an internetwork.  There are two kinds of\n  \
    \ IDPR routing information messages issued by each AD representative:\n   CONFIGURATION\
    \ and DYNAMIC messages.  Each CONFIGURATION message\n   contains the transit policy\
    \ information configured by the domain\n   administrator, including for each transit\
    \ policy, its identifier, its\n   specification, and the sets of virtual gateways\
    \ configured as\n   mutually reachable via intra-domain routes supporting the\
    \ given\n   transit policy.  Each DYNAMIC message contains information about\n\
    \   current virtual gateway connectivity to adjacent domains and about\n   the\
    \ sets of virtual gateways currently mutually reachable via intra-\n   domain\
    \ routes supporting the configured transit policies.\n   The IDPR Flooding Protocol\
    \ is similar to the flooding procedures\n   described in [9]-[11].  Through flooding,\
    \ the AD representative\n   distributes its routing information messages to route\
    \ servers in its\n   own domain and in adjacent domains.  After generating a routing\n\
    \   information message, the AD representative distributes a copy to each\n  \
    \ of its peers and to a selected VG representative (see section 3.1.4)\n   in\
    \ all other virtual gateways connected to the domain.  Each VG\n   representative\
    \ in turn distributes a copy of the routing information\n   message to each of\
    \ its peers.  We note that distribution of routing\n   information messages among\
    \ virtual gateways and among peers within a\n   virtual gateway is identical to\
    \ distribution of inter-VG messages in\n   VGP, as described in section 3.1.3.\n\
    \   Within a virtual gateway, each policy gateway distributes a copy of\n   the\
    \ routing information message:\n   - To each route server in its configured set\
    \ of route servers.  A\n     domain administrator should ensure that each route\
    \ server not\n     contained within a policy gateway appears in the set of configured\n\
    \     route servers for at least two distinct policy gateways.  Hence,\n     such\
    \ a route server will continue to receive routing information\n     messages,\
    \ even when one of the policy gateways becomes unreachable.\n     However, the\
    \ route server will normally receive duplicate copies of\n     a routing information\
    \ message.\n   - To certain directly-connected adjacent policy gateways.  A policy\n\
    \     gateway distributes a routing information message to a\n     directly-connected\
    \ adjacent policy gateway in an adjacent domain\n     component, only when it\
    \ is the lowest-numbered operational peer\n     with a direct connection to the\
    \ given domain component.  We note\n     that each policy gateway knows, through\
    \ information provided by\n     VGP, which peers have direct connections to which\
    \ components of\n     the adjacent domain.  If the policy gateway has direct connections\n\
    \     to more than one adjacent policy gateway in that domain component,\n   \
    \  it selects the routing information message recipient according to\n     the\
    \ order in which the adjacent policy gateways appear in its\n     database, choosing\
    \ the first one encountered.  This selection\n     procedure ensures that a copy\
    \ of the routing information message\n     reaches each component of the adjacent\
    \ domain, while limiting the\n     number of copies distributed.\n   Once a routing\
    \ information message reaches an adjacent policy\n   gateway, that policy gateway\
    \ distributes copies of the message\n   throughout its domain.  The adjacent policy\
    \ gateway, acting as the\n   first recipient of the routing information message\
    \ in its domain,\n   follows the same message distribution procedure as the AD\n\
    \   representative in the source domain, as described above.  The\n   flooding\
    \ procedure terminates when all reachable route servers in an\n   internetwork\
    \ receive a copy of the routing information message.\n   Neighbor policy gateways\
    \ may receive copies of the same routing\n   information message from different\
    \ adjoining domains.  If two\n   neighbor policy gateways receive the message\
    \ copies simultaneously,\n   they will distribute them to VG representatives in\
    \ other virtual\n   gateways within their domain, resulting in duplicate message\n\
    \   distribution.  However, each policy gateway stops the spread of\n   duplicate\
    \ routing information messages as soon as it detects them, as\n   described in\
    \ section 4.2.3 below.  In the Internet, we expect\n   simultaneous message receptions\
    \ to be the exception rather than the\n   rule, given the hierarchical structure\
    \ of the current topology.\n"
- title: 4.2.1.  Message Generation
  contents:
  - "4.2.1.  Message Generation\n   An AD representative generates and distributes\
    \ a CONFIGURATION\n   message whenever there is a configuration change in a transit\
    \ policy\n   or virtual gateway associated with its domain.  This ensures that\n\
    \   route servers maintain an up-to-date view of a domain's configured\n   transit\
    \ policies and adjacencies.  An AD representative may also\n   distribute a CONFIGURATION\
    \ message at a configurable period of\n   conf_per (500) hours.  A CONFIGURATION\
    \ message contains, for each\n   configured transit policy, the identifier assigned\
    \ by the domain\n   administrator, the specification, and the set of associated\
    \ \"virtual\n   gateway groups\".  Each virtual gateway group comprises virtual\n\
    \   gateways configured to be mutually reachable via intra-domain routes\n   of\
    \ the given transit policy.  Accompanying each virtual gateway\n   listed is an\
    \ indication of whether the virtual gateway is configured\n   to be a domain entry\
    \ point, a domain exit point, or both according to\n   the given transit policy.\
    \  The CONFIGURATION message also contains\n   the set of local route servers\
    \ that the domain administrator has\n   configured to be available to IDPR clients\
    \ in other domains.\n   An AD representative generates and distributes a DYNAMIC\
    \ message\n   whenever there is a change in currently supported transit policies\
    \ or\n   in current virtual gateway connectivity associated with its domain.\n\
    \   This ensures that route servers maintain an up-to-date view of a\n   domain's\
    \ supported transit policies and existing adjacencies and how\n   they differ\
    \ from those configured for the domain.  Specifically, an\n   AD representative\
    \ generates a DYNAMIC message whenever there is a\n   change in the connectivity,\
    \ through the given domain and with respect\n   to a configured transit policy,\
    \ between two components of adjoining\n   domains.  An AD representative may also\
    \ distribute a DYNAMIC message\n   at a configurable period of dyn_per (24) hours.\
    \  A DYNAMIC message\n   contains, for each configured transit policy, its identifier,\n\
    \   associated virtual gateway groups, and domain components reachable\n   through\
    \ virtual gateways in each group.  Each DYNAMIC message also\n   contains the\
    \ set of currently \"unavailable\", either down or\n   unreachable, virtual gateways\
    \ in the domain.\n   We note that each virtual gateway group expressed in a DYNAMIC\n\
    \   message may be a proper subset of one of the corresponding virtual\n   gateway\
    \ groups expressed in a CONFIGURATION message.  For example,\n   suppose that,\
    \ for a given domain, the virtual gateway group (VG\n   A,...,VG E) were configured\
    \ for a transit policy such that each\n   virtual gateway was both a domain entry\
    \ and exit point.  Thus, all\n   virtual gateways in this group are configured\
    \ to be mutually\n   reachable via intra-domain routes of the given transit policy.\
    \  Now\n   suppose that VG E becomes unreachable because of a power failure and\n\
    \   furthermore that the remaining virtual gateways form two distinct\n   groups,\
    \ (VG A,VG B) and (VG C,VG D), such that although virtual\n   gateways in both\
    \ groups are still mutually reachable via some intra-\n   domain routes they are\
    \ no longer mutually reachable via any intra-\n   domain routes of the given transit\
    \ policy.  In this case, the virtual\n   gateway groups for the given transit\
    \ policy now become (VG A,VG B)\n   and (VG C,VG D); VG E is listed as an unavailable\
    \ virtual gateway.\n   A route server uses information about the set of unavailable\
    \ virtual\n   gateways to determine which of its routes are no longer viable,\
    \ and\n   it subsequently removes such routes from its route database.\n   Although\
    \ route servers could determine the set of unavailable virtual\n   gateways using\
    \ information about configured virtual gateways and\n   currently reachable virtual\
    \ gateways, the associated processing cost\n   is high.  In particular, a route\
    \ server would have to examine all\n   virtual gateway groups listed in a DYNAMIC\
    \ message to determine\n   whether there are any unavailable virtual gateways\
    \ in the given\n   domain.  To reduce the message processing at each route server,\
    \ we\n   have chosen to include the set of unavailable virtual gateways in\n \
    \  each DYNAMIC message.\n   In order to construct a DYNAMIC message, an AD representative\n\
    \   assembles information gathered from intra-domain routing and from\n   VGP.\
    \  Specifically, the AD representative uses the following\n   information:\n \
    \  - VG CONNECT and UP/DOWN messages to determine the state, up or down,\n   \
    \  of each of its domain's virtual gateways and the adjacent domain\n     components\
    \ reachable through a given virtual gateway.\n   - Intra-domain routing information\
    \ to determine, for each of its\n     domain's transit policies, whether a given\
    \ virtual gateway in the\n     domain is reachable with respect to that transit\
    \ policy.\n   - VG POLICY messages to determine the connectivity of adjoining\n\
    \     domain components, across the given domain and with respect to a\n     configured\
    \ transit policy, such that these components are adjacent\n     to virtual gateways\
    \ not currently reachable from the AD\n     representative's virtual gateway according\
    \ to the given transit\n     policy.\n"
- title: 4.2.2.  Sequence Numbers
  contents:
  - "4.2.2.  Sequence Numbers\n   Each IDPR routing information message carries a\
    \ sequence number\n   which, when used in conjunction with the timestamp carried\
    \ in the\n   CMTP message header, determines the recency of the message.  An AD\n\
    \   representative assigns a sequence number to each routing information\n   message\
    \ it generates, depending upon its internal clock time:\n   - The AD representative\
    \ sets the sequence number to 0, if its\n     internal clock time is greater than\
    \ the timestamp in its previously\n     generated routing information message.\n\
    \   - The AD representative sets the sequence number to 1 greater than\n     the\
    \ sequence number in its previously generated routing information\n     message,\
    \ if its internal clock time equals the timestamp for its\n     previously generated\
    \ routing information message and if the\n     previous sequence number is less\
    \ than the maximum value\n     (currently 2**16 - 1).  If the previous sequence\
    \ number equals the\n     maximum value, the AD representative waits until its\
    \ internal clock\n     time exceeds the timestamp in its previously generated\
    \ routing\n     information message and then sets the sequence number to 0.\n\
    \   In general, we do not expect generation of multiple distinct IDPR\n   routing\
    \ information messages carrying identical timestamps, and so\n   the sequence\
    \ number may seem superfluous.  However, the sequence\n   number may become necessary\
    \ during synchronization of an AD\n   representative's internal clock.  In particular,\
    \ the AD\n   representative may need to freeze the clock value during\n   synchronization,\
    \ and thus distinct sequence numbers serve to\n   distinguish routing information\
    \ messages generated during the clock\n   synchronization interval.\n"
- title: 4.2.3.  Message Acceptance
  contents:
  - "4.2.3.  Message Acceptance\n   Prior to a policy gateway forwarding a routing\
    \ information message or\n   a route server incorporating routing information\
    \ into its routing\n   information database, the policy gateway or route server\
    \ assesses\n   routing information message acceptability.  An IDPR routing\n \
    \  information message is \"acceptable\" if:\n   - It passes the CMTP validation\
    \ checks.\n   - Its timestamp is less than conf_old (530) hours behind the\n \
    \    recipient's internal clock time for CONFIGURATION messages and less\n   \
    \  than dyn_old (25) hours behind the recipient's internal clock time\n     for\
    \ DYNAMIC messages.\n   - Its timestamp and sequence number indicate that it is\
    \ more recent\n     than the currently-stored routing information from the given\n\
    \     domain.  If there is no routing information currently stored from\n    \
    \ the given domain, then the routing information message contains, by\n     default,\
    \ the more recent information.\n   Policy gateways acknowledge and forward acceptable\
    \ IDPR routing\n   information messages, according to the flooding protocol described\
    \ in\n   section 4.2 above.  Moreover, each policy gateway retains the\n   timestamp\
    \ and sequence number for the most recently accepted routing\n   information message\
    \ from each domain and uses these values to\n   determine acceptability of routing\
    \ information messages received in\n   the future.  Route servers acknowledge\
    \ the receipt of acceptable\n   routing information messages and incorporate the\
    \ contents of these\n   messages into their routing information databases, contingent\
    \ upon\n   criteria discussed in section 4.2.4 below; however, they do not\n \
    \  participate in the flooding protocol.  We note that when a policy\n   gateway\
    \ or route server first returns to service, it immediately\n   updates its routing\
    \ information database with routing information\n   obtained from another route\
    \ server, using the route server query\n   protocol described in section 5.\n\
    \   An AD representative takes special action upon receiving an\n   acceptable\
    \ routing information message, supposedly generated by\n   itself but originally\
    \ obtained from a policy gateway or route server\n   other than itself.  There\
    \ are at least three possible reasons for the\n   occurrence of this event:\n\
    \   - The routing information message has been corrupted in a way that is\n  \
    \   not detectable by the integrity/authentication value.\n   - The AD representative\
    \ has experienced a memory error.\n   - Some other entity is generating routing\
    \ information messages on\n     behalf of the AD representative.\n   In any case,\
    \ the AD representative logs the event for network\n   management.  Moreover,\
    \ the AD representative must reestablish its own\n   routing information messages\
    \ as the most recent for its domain.  To\n   do so, the AD representative waits\
    \ until its internal clock time\n   exceeds the value of the timestamp in the\
    \ received routing\n   information message and then generates a new routing information\n\
    \   message using the currently-stored domain routing information\n   supplied\
    \ by VGP and by the intra-domain routing procedure.  Note that\n   the length\
    \ of time the AD representative must wait to generate the\n   new message is at\
    \ most cmtp_new (300) seconds, the maximum CMTP-\n   tolerated difference between\
    \ the received message's timestamp and the\n   AD representative's internal clock\
    \ time.\n   IDPR routing information messages that pass the CMTP validity checks\n\
    \   but appear less recent than stored routing information are\n   unacceptable.\
    \  Policy gateways do not forward unacceptable routing\n   information messages,\
    \ and route servers do not incorporate the\n   contents of unacceptable routing\
    \ information messages into their\n   routing information databases.  Instead,\
    \ the recipient of an\n   unacceptable routing information message acknowledges\
    \ the message in\n   one of two ways:\n   - If the routing information message\
    \ timestamp and sequence number\n     equal to the timestamp and sequence number\
    \ associated with the\n     stored routing information for the given domain, the\
    \ recipient\n     assumes that the routing information message is a duplicate\
    \ and\n     acknowledges the message.\n   - If the routing information message\
    \ timestamp and sequence number\n     indicate that the message is less recent\
    \ than the stored routing\n     information for the domain, the recipient acknowledges\
    \ the message\n     with an indication that the routing information it contains\
    \ is\n     out-of-date.  Such a negative acknowledgement is a signal to the\n\
    \     sender of the routing information message to request more up-to-\n     date\
    \ routing information from a route server, using the route\n     server query\
    \ protocol.  Furthermore, if the recipient of the out-\n     of-date routing information\
    \ message is a route server, it\n     regenerates a routing information message\
    \ from its own routing\n     information database and forwards the message to\
    \ the sender.  The\n     sender may in turn propagate this more recent routing\
    \ information\n     message to other policy gateways and route servers.\n"
- title: 4.2.4.  Message Incorporation
  contents:
  - "4.2.4.  Message Incorporation\n   A route server usually stores the entire contents\
    \ of an acceptable\n   IDPR routing information message in its routing information\
    \ database,\n   so that it has access to all advertised transit policies when\n\
    \   generating a route and so that it can regenerate routing information\n   messages\
    \ at a later point in time if requested to do so by another\n   route server or\
    \ policy gateway.  However, a route server may elect\n   not to store all routing\
    \ information message contents.  In\n   particular, the route server need not\
    \ store any transit policy that\n   excludes the route server's domain as a source\
    \ or any routing\n   information from a domain that the route server's domain's\
    \ source\n   policies exclude for transit.  Selective storing of routing\n   information\
    \ message contents simplifies the route generation\n   procedure since it reduces\
    \ the search space of possible routes, and\n   it limits the amount of route server\
    \ memory devoted to routing\n   information.  However, selective storing of routing\
    \ information also\n   means that the route server cannot always regenerate the\
    \ original\n   routing information message, if requested to do so by another route\n\
    \   server or policy gateway.\n   An acceptable IDPR routing information message\
    \ may contain transit\n   policy information that is not well-defined according\
    \ to the route\n   server's perception.  A CONFIGURATION message may contain an\n\
    \   unrecognized domain, virtual gateway, or transit policy attribute,\n   such\
    \ as user class access restrictions or offered service.  In this\n   case, \"\
    unrecognized\" means that the value in the routing information\n   message is\
    \ not listed in the route server's configuration database,\n   as described previously\
    \ in section 1.8.2.  A DYNAMIC message may\n   contain an unrecognized transit\
    \ policy or virtual gateway.  In this\n   case, \"unrecognized\" means that the\
    \ transit policy or virtual gateway\n   was not listed in the most recent CONFIGURATION\
    \ message for the given\n   domain.\n   Each route server can always parse an\
    \ acceptable routing information\n   messsage, even if some of the information\
    \ is not well-defined, and\n   thus can always use the information that it does\
    \ recognize.\n   Therefore, a route server can store the contents of acceptable\n\
    \   routing information messages from domains in which it is interested,\n   regardless\
    \ of whether all contents appear to be well-defined at\n   present.  If a routing\
    \ message contains unrecognized information, the\n   route server may attempt\
    \ to obtain the additional information it\n   needs to decipher the unrecognized\
    \ information.  For a CONFIGURATION\n   message, the route server logs the event\
    \ for network management; for\n   a DYNAMIC message, the route server requests,\
    \ from another route\n   server, the most recent CONFIGURATION message for the\
    \ domain in\n   question.\n   When a domain is partitioned, each domain component\
    \ has its own AD\n   representative, which generates routing information messages\
    \ on\n   behalf of that component.  Discovery of a domain partition prompts\n\
    \   the AD representative for each domain component to generate and\n   distribute\
    \ a DYNAMIC message.  In this case, a route server receives\n   and stores more\
    \ than one routing information message at a time for\n   the given domain, namely\
    \ one for each domain component.\n   When the partition heals, the AD representative\
    \ for the entire domain\n   generates and distributes a DYNAMIC message.  In each\
    \ route server's\n   routing information database, the new DYNAMIC message does\
    \ not\n   automatically replace all of the currently-stored DYNAMIC messages\n\
    \   for the given domain.  Instead, the new message only replaces that\n   message\
    \ whose AD representative matches the AD representative for the\n   new message.\
    \  The other DYNAMIC messages, generated during the period\n   over which the\
    \ partition occurred, remain in the routing information\n   database until they\
    \ attain their maximum lifetime, as described in\n   section 4.2.5 below.  Such\
    \ stale information may lead to the\n   generation of routes that result in path\
    \ setup failures and hence the\n   selection of alternative routes.  To reduce\
    \ the chances of path setup\n   failures, we will investigate, for a future version\
    \ of IDPR,\n   mechanisms for removing partition-related DYNAMIC messages\n  \
    \ immediately after a partition disappears.\n"
- title: 4.2.5.  Routing Information Database
  contents:
  - "4.2.5.  Routing Information Database\n   We expect that most of the IDPR routing\
    \ information stored in a\n   routing information database will remain viable\
    \ for long periods of\n   time, perhaps until a domain reconfiguration occurs.\
    \  By \"viable\", we\n   mean that the information reflects the current state\
    \ of the domain\n   and hence may be used successfully for generating policy routes.\
    \  To\n   reduce the probability of retaining stale routing information, a\n \
    \  route server imposes a maximum lifetime on each database entry,\n   initialized\
    \ when it incorporates an accepted entry into its routing\n   information database.\
    \  The maximum lifetime should be longer than the\n   corresponding message generation\
    \ period, so that the database entry\n   is likely to be refreshed before it attains\
    \ its maximum lifetime.\n   Each CONFIGURATION message stored in the routing information\
    \ database\n   has a maximum lifetime of conf_old (530) hours; each DYNAMIC message\n\
    \   stored in the routing information database has a maximum lifetime of\n   dyn_old\
    \ (25) hours.  Periodic generation of routing information\n   messages makes it\
    \ unlikely that any routing information message will\n   remain in a routing information\
    \ database for its full lifetime.\n   However, a routing information message may\
    \ attain its maximum\n   lifetime in a route server that is separated from a internetwork\
    \ for\n   a long period of time.\n   When an IDPR routing information message\
    \ attains its maximum lifetime\n   in a routing information database, the route\
    \ server removes the\n   message contents from its database, so that it will not\
    \ generate new\n   routes with the outdated routing information nor distribute\
    \ old\n   routing information in response to requests from other route servers\n\
    \   or policy gateways.  Nevertheless, the route server continues to\n   dispense\
    \ routes previously generated with the old routing\n   information, as long as\
    \ path setup (see section 7) for these routes\n   succeeds.\n   The route server\
    \ treats routing information message lifetime\n   expiration differently, depending\
    \ on the type of routing information\n   message.  When a CONFIGURATION message\
    \ expires, the route server\n   requests, from another route server, the most\
    \ recent CONFIGURATION\n   message issued for the given domain.  When a DYNAMIC\
    \ message expires,\n   the route server does not initially attempt to obtain more\
    \ recent\n   routing information.  Instead, if route generation is necessary,\
    \ the\n   route server uses the routing information contained in the\n   corresponding\
    \ CONFIGURATION message for the given domain.  Only if\n   there is a path setup\
    \ failure (see section 7.4) involving the given\n   domain does the route server\
    \ request, from another route server, the\n   most recent DYNAMIC message issued\
    \ for the given domain.\n"
- title: 4.3.  Routing Information Message Formats
  contents:
  - "4.3.  Routing Information Message Formats\n   The flooding protocol number is\
    \ equal to 1.  We describe the contents\n   of each type of routing information\
    \ message below.\n"
- title: 4.3.1.  CONFIGURATION
  contents:
  - "4.3.1.  CONFIGURATION\n   The CONFIGURATION message type is equal to 0.\n   \
    \ 0                   1                   2                   3\n    0 1 2 3 4\
    \ 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            AD CMP             |              SEQ              |\n   +-------------------------------+-------------------------------+\n\
    \   |            NUM TP             |            NUM RS             |\n   +-------------------------------+-------------------------------+\n\
    \   |              RS               |\n   +-------------------------------+\n\
    \   For each transit policy configured for the domain:\n   +-------------------------------+-------------------------------+\n\
    \   |              TP               |            NUM ATR            |\n   +-------------------------------+-------------------------------+\n\
    \   For each attribute of the transit policy:\n   +-------------------------------+-------------------------------+\n\
    \   |            ATR TYP            |            ATR LEN            |\n   +-------------------------------+-------------------------------+\n\
    \   For the source/destination access restrictions attribute:\n   +-------------------------------+\n\
    \   |          NUM AD GRP           |\n   +-------------------------------+\n\
    \   For each domain group in the source/destination access restrictions:\n   +-------------------------------+-------------------------------+\n\
    \   |            NUM AD             |              AD               |\n   +---------------+---------------+-------------------------------+\n\
    \   |    AD FLGS    |    NUM HST    |            HST SET            |\n   +---------------+---------------+-------------------------------+\n\
    \   For the temporal access restrictions attribute:\n   +-------------------------------+\n\
    \   |            NUM TIM            |\n   +-------------------------------+\n\
    \   For each set of times in the temporal access restrictions:\n   +---------------+-----------------------------------------------+\n\
    \   |   TIM FLGS    |                   DURATION                    |\n   +---------------+-----------------------------------------------+\n\
    \   |                             START                             |\n   +-------------------------------+-------------------------------+\n\
    \   |            PERIOD             |            ACTIVE             |\n   +-------------------------------+-------------------------------+\n\
    \   For the user class access restrictions attribute:\n   +-------------------------------+\n\
    \   |            NUM UCI            |\n   +-------------------------------+\n\
    \   For each UCI in the user class access restrictions:\n   +---------------+\n\
    \   |      UCI      |\n   +---------------+\n   For each offered service attribute:\n\
    \   +---------------------------------------------------------------+\n   |  \
    \                          OFR SRV                            |\n   +---------------------------------------------------------------+\n\
    \   For the virtual gateway access restrictions attribute:\n   +-------------------------------+\n\
    \   |           NUM VG GRP          |\n   +-------------------------------+\n\
    \   For each virtual gateway group in the virtual gateway access\n   restrictions:\n\
    \   +-------------------------------+-------------------------------+\n   |  \
    \          NUM VG             |            ADJ AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |      VG       |    VG FLGS    |\n   +---------------+---------------+\n\
    \   AD CMP\n        (16 bits) Numeric identifier for the domain component containing\n\
    \        the AD representative policy gateway.\n   SEQ (16 bits) Routing information\
    \ message sequence number.\n   NUM TP (16 bits) Number of transit policy specifications\
    \ contained in\n        the routing information message.\n   NUM RS (16 bits)\
    \ Number of route servers advertised to serve clients\n        outside of the\
    \ domain.\n   RS (16 bits) Numeric identifier for a route server.\n   TP (16 bits)\
    \ Numeric identifier for a transit policy specification.\n   NUM ATR (16 bits)\
    \ Number of attributes associated with the transit\n        policy.\n   ATR TYP\
    \ (16 bits) Numeric identifier for a type of attribute.  Valid\n        attributes\
    \ include the following types:\n   - Set of  virtual  gateway access restrictions\
    \   (see  section 1.4.2)\n     associated with the transit policy (variable).\
    \  This attribute must\n     be included.\n   - Set of source/destination access\
    \ restrictions (see section 1.4.2)\n     associated with the transit policy (variable).\
    \  This attribute may\n     be omitted.  Absence of this attribute implies that\
    \ traffic from\n     any source to any destination is acceptable.\n   - Set of\
    \ temporal access restrictions (see section 1.4.2) associated\n     with the transit\
    \ policy (variable).  This attribute may be omitted.\n     Absence of this attribute\
    \ implies that the transit policy applies\n     at all times.\n   - Set of user\
    \ class access restrictions (see section 1.4.2)\n     associated with the transit\
    \ policy (variable).  This attribute may\n     be omitted.  Absence of this attribute\
    \ implies that traffic from\n     any user class is acceptable.\n   - Average\
    \ delay in milliseconds (16 bits).  This attribute may be\n     omitted.\n   -\
    \ Delay variation in milliseconds (16 bits).  This attribute may be\n     omitted.\n\
    \   - Average available bandwidth in bits per second (48 bits).  This\n     attribute\
    \ may be omitted.\n   - Available bandwidth variation in bits per second (48 bits).\
    \  This\n     attribute may be omitted.\n   - MTU in bytes (16 bits).  This attribute\
    \ may be omitted.\n   - Charge per byte in thousandths of a cent (16 bits). This\
    \ attribute\n     may be omitted.\n   - Charge per message in thousandths of a\
    \ cent (16 bits).  This\n     attribute may be omitted.\n   - Charge for session\
    \ time in thousandths of a cent per second (16\n     bits).  This attribute may\
    \ be omitted.  Absence of any charge\n     attribute implies that the domain provides\
    \ free transit service.\n   ATR LEN (16 bits) Length of an attribute in bytes,\
    \ beginning with the\n   subsequent field.\n   NUM AD GRP (16 bits) Number of\
    \ source/destination domain groups (see\n   section 1.4.2) associated with the\
    \ source/destination access\n   restrictions.\n   NUM AD (16 bits) Number of domains\
    \ or sets of domains in a domain\n   group.\n   AD (16 bits) Numeric identifier\
    \ for a domain or domain set.\n   AD FLGS (8 bits) Set of five flags indicating\
    \ how to interpret the AD\n   field, contained in the right-most bits.  Proceeding\
    \ left to right,\n   the first flag indicates whether the transit policy applies\
    \ to all\n   domains or to specific domains (1 all, 0 specific), and when set\
    \ to\n   1, causes the second and third flags to be ignored.  The second flag\n\
    \   indicates whether the domain identifier signifies a single domain or\n   a\
    \ domain set (1 single, 0 set).  The third flag indicates whether the\n   transit\
    \ policy applies to the given domain or domain set (1 applies,\n   0 does not\
    \ apply) and is used for representing complements of sets of\n   domains.  The\
    \ fourth flag indicates whether the domain is a source (1\n   source, 0 not source).\
    \  The fifth flag indicates whether the domain\n   is a destination (1 destination,\
    \ 0 not destination).  At least one of\n   the fourth and fifth flags must be\
    \ set to 1.\n   NUM HST (8 bits) Number of \"host sets\" (see section 1.4.2) associated\n\
    \   with a particular domain or domain set.  The value 0 indicates that\n   all\
    \ hosts in the given domain or domain set are acceptable sources or\n   destinations,\
    \ as specified by the fourth and fifth AD flags.\n   HST SET (16 bits) Numeric\
    \ identifier for a host set.\n   NUM TIM (16 bits) Number of time specifications\
    \ associated with the\n   temporal access restrictions.  Each time specification\
    \ is split into\n   a set of continguous identical periods, as we describe below.\n\
    \   TIM FLGS (8 bits) Set of two flags indicating how to combine the time\n  \
    \ specifications, contained in the right-most bits.  Proceeding left to\n   right,\
    \ the first flag indicates whether the transit policy applies\n   during the periods\
    \ specified in the time specification (1 applies, 0\n   does not apply) and is\
    \ used for representing complements of policy\n   applicability intervals.  The\
    \ second flag indicates whether the time\n   specification takes precedence over\
    \ the previous time specifications\n   listed (1 precedence, 0 no precedence).\
    \  Precedence is equivalent to\n   the boolean OR and AND operators, in the following\
    \ sense.  At any\n   given instant, a transit policy either applies or does not\
    \ apply,\n   according to a given time specification, and we can assign a boolean\n\
    \   value to the state of policy applicability according to a given time\n   specification.\
    \  If the second flag assumes the value 1 for a given\n   time specification,\
    \ that indicates the boolean operator OR should be\n   applied to the values of\
    \ policy applicability, according to the given\n   time specification and to all\
    \ previously listed time specifications.\n   If the second flag assumes the value\
    \ 0 for a given time\n   specification, that indicates the boolean operator AND\
    \ should be\n   applied to the values of policy applicability, according to the\
    \ given\n   time specification and to all previously listed time specifications.\n\
    \   DURATION (24 bits) Length of the time specification duration, in\n   minutes.\
    \  A value of 0 indicates an infinite duration.\n   START (32 bits) Time at which\
    \ the time specification first takes\n   effect, in seconds elapsed since 1 January\
    \ 1970 0:00 GMT.\n   PERIOD (16 bits) Length of each time period within the time\n\
    \   specification, in minutes.\n   ACTIVE (16 bits) Length of the policy applicable\
    \ interval during each\n   time period, in minutes from the beginning of the time\
    \ period.\n   NUM UCI (16 bits) Number of user classes associated with the user\n\
    \   class access restrictions.\n   UCI (8 bits) Numeric identifier for a user\
    \ class.\n   NUM VG GRP (16 bits) Number of virtual gateway groups (see section\n\
    \   1.4.2) associated with the virtual gateway access restrictions.\n   NUM VG\
    \ (16 bits) Number of virtual gateways in a virtual gateway\n   group.\n   ADJ\
    \ AD (16 bits) Numeric identifier for the adjacent domain to which\n   a virtual\
    \ gateway connects.\n   VG (8 bits) Numeric identifier for a virtual gateway.\n\
    \   VG FLGS (8 bits) Set of two flags indicating how to interpret the VG\n   field,\
    \ contained in the right-most bits.  Proceeding left to right,\n   the first flag\
    \ indicates whether the virtual gateway is a domain\n   entry point (1 entry,\
    \ 0 not entry).  The second flag indicates\n   whether the virtual gateway is\
    \ a domain exit point (1 exit, 0 not\n   exit).  At least one of the first and\
    \ second flags must be set to 1.\n"
- title: 4.3.2.  DYNAMIC
  contents:
  - "4.3.2.  DYNAMIC\n   The DYNAMIC message type is equal to 1.\n    0          \
    \         1                   2                   3\n    0 1 2 3 4 5 6 7 8 9 0\
    \ 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            AD CMP             |              SEQ              |\n   +-------------------------------+-------------------------------+\n\
    \   |           UNAVL VG            |            NUM PS             |\n   +-------------------------------+-------------------------------+\n\
    \   For each unavailable virtual gateway in the domain:\n   +-------------------------------+---------------+---------------+\n\
    \   |            ADJ AD             |      VG       |    UNUSED     |\n   +-------------------------------+---------------+---------------+\n\
    \   For each set of transit policies for the domain:\n   +-------------------------------+-------------------------------+\n\
    \   |            NUM TP             |          NUM VG GRP           |\n   +-------------------------------+-------------------------------+\n\
    \   |              TP               |\n   +-------------------------------+\n\
    \   For each virtual gateway group associated with the transit policy\n   set:\n\
    \   +-------------------------------+-------------------------------+\n   |  \
    \          NUM VG             |            ADJ AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |      VG       |    VG FLGS    |            NUM CMP            |\n   +---------------+---------------+-------------------------------+\n\
    \   |            ADJ CMP            |\n   +-------------------------------+\n\
    \   AD CMP\n        (16 bits) Numeric identifier for the domain component containing\n\
    \        the AD representative policy gateway.\n   SEQ (16 bits) Routing information\
    \ message sequence number.\n   UNAVL VG (16 bits) Number of virtual gateways in\
    \ the domain component\n        that are currently unavailable via any intra-domain\
    \ routes.\n   NUM PS (16 bits) Number of sets of transit policies listed.  Transit\n\
    \        policy sets provide a mechanism for reducing the size of DYNAMIC\n  \
    \      messages.  A single set of virtual gateway groups applies to all\n    \
    \    transit policies in a given set.\n   ADJ AD (16 bits) Numeric identifier\
    \ for the adjacent domain to which\n        a virtual gateway connects.\n   VG\
    \ (8 bits) Numeric identifier for a virtual gateway.\n   UNUSED (8 bits) Not currently\
    \ used; must be set equal to 0.\n   NUM TP (16 bits) Number of transit policies\
    \ in a set.\n   NUM VGGRP (16 bits) Number of virtual gateway groups currently\n\
    \        associated with the transit policy set.\n   TP (16 bits) Numeric identifier\
    \ for a transit policy.\n   NUM VG (16 bits) Number of virtual gateways in a virtual\
    \ gateway\n        group.\n   VG FLGS (8 bits) Set of two flags indicating how\
    \ to interpret the VG\n        field, contained in the right-most bits.  Proceeding\
    \ left to\n        right, the first flag indicates whether the virtual gateway\
    \ is a\n        domain entry point (1 entry, 0 not entry).  The second flag\n\
    \        indicates whether the virtual gateway is a domain exit point (1\n   \
    \     exit, 0 not exit).  At least one of the first and second flags\n       \
    \ must be set to 1.\n   NUM CMP (16 bits) Number of adjacent domain components\
    \ reachable via\n        direct connections through the virtual gateway.\n   ADJ\
    \ CMP (16 bits) Numeric identifier for a reachable adjacent domain\n        component.\n"
- title: 4.3.3.  Negative Acknowledgements
  contents:
  - "4.3.3.  Negative Acknowledgements\n   When a policy gateway or route server receives\
    \ an unacceptable IDPR\n   routing information message that passes the CMTP validation\
    \ checks,\n   it includes, in its CMTP ACK, an appropriate negative\n   acknowledgement.\
    \  This information is placed in the INFORM field of\n   the CMTP ACK (described\
    \ previously in section 2.4); the numeric\n   identifier for each type of routing\
    \ information message negative\n   acknowledgement is contained in the left-most\
    \ 8 bits of the INFORM\n   field.  Negative acknowledgements associated with routing\
    \ information\n   messages include the following types:\n   1.  Unrecognized IDPR\
    \ routing information message type.  Numeric\n       identifier for the unrecognized\
    \ message type (8 bits).\n   2.  Out-of-date IDPR routing information message.\
    \  This is a signal\n       to the sender that it may not have the most recent\
    \ routing\n       information for the given domain.\n"
- title: 5.  Route Server Query Protocol
  contents:
  - "5.  Route Server Query Protocol\n   Each route server is responsible for maintaining\
    \ both the routing\n   information database and the route database and for responding\
    \ to\n   database information requests from policy gateways and other route\n\
    \   servers.  These requests and their responses are the messages\n   exchanged\
    \ via the Route Server Query Protocol (RSQP).\n   Policy gateways and route servers\
    \ normally invoke RSQP to replace\n   absent, outdated, or corrupted information\
    \ in their own routing\n   information or route databases.  In section 4, we discussed\
    \ some of\n   the situations in which RSQP may be invoked; in this section and\
    \ in\n   section 7, we discuss other such situations.\n"
- title: 5.1.  Message Exchange
  contents:
  - "5.1.  Message Exchange\n   Policy gateways and route servers use CMTP for reliable\
    \ transport of\n   route server requests and responses.  RSQP must communicate\
    \ to CMTP\n   the maximum number of transmissions per request/response message,\n\
    \   rsqp_ret, and the interval between request/response message\n   retransmissions,\
    \ rsqp_int microseconds.  A route server\n   request/response message is \"acceptable\"\
    \ if:\n   - It passes the CMTP validation checks.\n   - Its timestamp is less\
    \ than rsqp_old (300) seconds behind the\n     recipient's internal clock time.\n\
    \   With RSQP, a requesting entity expects to receive an acknowledgement\n   from\
    \ the queried route server indicating whether the route server can\n   accommodate\
    \ the request.  The route server may fail to fill a given\n   request for either\
    \ of the following reasons:\n   - Its corresponding database contains no entry\
    \ or only a partial\n     entry for the requested information.\n   - It is governed\
    \ by special message distribution rules, imposed by\n     the domain administrator,\
    \ that preclude it from releasing the\n     requested information.  Currently,\
    \ such distribution rules are not\n     included in IDPR configuration information.\n\
    \   For all requests that it cannot fill, the route server responds with\n   a\
    \ negative acknowledgement message carried in a CMTP acknowledgement,\n   indicating\
    \ the set of unfulfilled requests (see section 5.5.4).\n   If the requesting entity\
    \ either receives a negative acknowledgement\n   or does not receive any acknowledgement\
    \ after rsqp_ret attempts\n   directed at the same route server, it queries a\
    \ different route\n   server, as long as the number of attempted requests to different\n\
    \   route servers does not exceed rsqp_try (3).  Specifically, the\n   requesting\
    \ entity proceeds in round-robin order through its list of\n   addressable route\
    \ servers.  However, if the requesting entity is\n   unsuccessful after rsqp_try\
    \ attempts, it abandons the request\n   altogether and logs the event for network\
    \ management.\n   A policy gateway or a route server can request information from\
    \ any\n   route server that it can address.  Addresses for local route servers\n\
    \   within a domain are part of the configuration for each IDPR entity\n   within\
    \ a domain; addresses for remote route servers in other domains\n   are obtained\
    \ through flooded CONFIGURATION messages, as described\n   previously in section\
    \ 4.2.1.  However, requesting entities always\n   query local route servers before\
    \ remote route servers, in order to\n   contain the costs associated with the\
    \ query and response.  If the\n   requesting entity and the queried route server\
    \ are in the same\n   domain, they can communicate over intra-domain routes, whereas\
    \ if the\n   requesting entity and the queried route server are in different\n\
    \   domains, they must obtain a policy route and establish a path before\n   they\
    \ can communicate, as we describe below.\n"
- title: 5.2.  Remote Route Server Communication
  contents:
  - "5.2.  Remote Route Server Communication\n   RSQP communication involving a remote\
    \ route server requires a policy\n   route and accompanying path setup (see section\
    \ 7) between the\n   requesting and queried entities, as these entities reside\
    \ in\n   different domains.  After generating a request message, the\n   requesting\
    \ entity hands to CMTP its request message along with the\n   remote route server's\
    \ entity and domain identifiers.  CMTP encloses\n   the request in a DATAGRAM\
    \ and hands the DATAGRAM and remote route\n   server information to the path agent.\
    \  Using the remote route server\n   information, the path agent obtains, and\
    \ if necessary sets up, a path\n   to the remote route server.  Once the path\
    \ to the remote route server\n   has been successfully established, the path agent\
    \ encapsulates the\n   DATAGRAM within an IDPR data message and forwards the data\
    \ message\n   along the designated path.\n   When the path agent in the remote\
    \ route server receives the IDPR data\n   message, it extracts the DATAGRAM and\
    \ hands it to CMTP.  In addition,\n   the path agent, using the requesting entity\
    \ and domain identifiers\n   contained in the path identifier, obtains, and if\
    \ necessary sets up,\n   a path back to the requesting entity.\n   If the DATAGRAM\
    \ fails any of the CMTP validation checks, CMTP returns\n   a NAK to the requesting\
    \ entity.  If the DATAGRAM passes all of the\n   CMTP validation checks, the remote\
    \ route server assesses the\n   acceptability of the request message.  Provided\
    \ the request message\n   is acceptable, the remote route server determines whether\
    \ it can\n   fulfill the request and directs CMTP to return an ACK to the\n  \
    \ requesting entity.  The ACK may contain a negative acknowledgement if\n   the\
    \ entire request cannot be fulfilled.\n   The remote route server generates responses\
    \ for all requests that it\n   can fulfill and returns the responses to the requesting\
    \ entity.\n   Specifically, the remote route server hands to CMTP its response\
    \ and\n   the requesting entity information.  CMTP in turn encloses the\n   response\
    \ in a DATAGRAM.\n   When returning an ACK, a NAK, or a response to the requesting\
    \ entity,\n   the remote route server hands the corresponding CMTP message and\n\
    \   requesting entity information to the path agent.  Using the\n   requesting\
    \ entity information, the path agent retrieves the path to\n   the requesting\
    \ entity, encapsulates the CMTP message within an IDPR\n   data message, and forwards\
    \ the data message along the designated\n   path.\n   When the path agent in the\
    \ requesting entity receives the IDPR data\n   message, it extracts the ACK, NAK,\
    \ or response to its request and\n   performs the CMTP validation checks for that\
    \ message.  In the case of\n   a response messsage, the requesting entity also\
    \ assesses message\n   acceptability before incorporating the contents into the\
    \ appropriate\n   database.\n"
- title: 5.3  Routing Information
  contents:
  - "5.3  Routing Information\n   Policy gateways and route servers request routing\
    \ information from\n   route servers, in order to update their routing information\n\
    \   databases.  To obtain routing information from a route server, the\n   requesting\
    \ entity issues a ROUTING INFORMATION REQUEST message\n   containing the type\
    \ of routing information requested - CONFIGURATION\n   messages, DYNAMIC messages,\
    \ or both - and the set of domains from\n   which the routing information is requested.\n\
    \   Upon receiving a ROUTING INFORMATION REQUEST message, a route server\n   first\
    \ assesses message acceptability before proceeding to act on the\n   contents.\
    \  If the ROUTING INFORMATION REQUEST message is deemed\n   acceptable, the route\
    \ server determines how much of the request it\n   can fulfill and then instructs\
    \ CMTP to generate an acknowledgement,\n   indicating its ability to fulfill the\
    \ request.  The route server\n   proceeds to fulfill as much of the request as\
    \ possible by\n   reconstructing individual routing information messages, one\
    \ per\n   requested message type and domain, from its routing information\n  \
    \ database.  We note that only a regenerated routing information\n   message whose\
    \ entire contents match that of the original routing\n   information message may\
    \ pass the CMTP integrity/authentication\n   checks.\n"
- title: 5.4.  Routes
  contents:
  - "5.4.  Routes\n   Path agents request routes from route servers when they require\n\
    \   policy routes for path setup.  To obtain routes from a route server,\n   the\
    \ requesting path agent issues a ROUTE REQUEST message containing\n   the destination\
    \ domain and applicable service requirements, the\n   maximum number of routes\
    \ requested, a directive indicating whether to\n   generate the routes or retrieve\
    \ them from the route database, and a\n   directive indicating whether to refresh\
    \ the routing information\n   database with the most recent CONFIGURATION or DYNAMIC\
    \ message from a\n   given domain, before generating the routes.  To refresh its\
    \ routing\n   information database, a route server must obtain routing information\n\
    \   from another route server.  The path agent usually issues routing\n   information\
    \ database refresh directives in response to a failed path\n   setup.  We discuss\
    \ the application of these directives in more detail\n   in section 7.4.\n   Upon\
    \ receiving a ROUTE REQUEST message, a route server first assesses\n   message\
    \ acceptability before proceeding to act on the contents.  If\n   the ROUTE REQUEST\
    \ message is deemed acceptable, the route server\n   determines whether it can\
    \ fulfill the request and then instructs CMTP\n   to generate an acknowledgement,\
    \ indicating its ability to fulfill the\n   request.  The route server proceeds\
    \ to fulfill the request with\n   policy routes, either retrieved from its route\
    \ database or generated\n   from its routing information database if necessary,\
    \ and returns these\n   routes in a ROUTE RESPONSE message.\n"
- title: 5.5.  Route Server Message Formats
  contents:
  - "5.5.  Route Server Message Formats\n   The route server query protocol number\
    \ is equal to 2.  We describe\n   the contents of each type of RSQP message below.\n"
- title: 5.5.1.  ROUTING INFORMATION REQUEST
  contents:
  - "5.5.1.  ROUTING INFORMATION REQUEST\n   The ROUTING INFORMATION REQUEST message\
    \ type is equal to 0.\n    0                   1                   2         \
    \          3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\
    \ 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            QRY AD             |            QRY RS             |\n   +-------------------------------+-------------------------------+\n\
    \   |            NUM AD             |              AD               |\n   +---------------+---------------+-------------------------------+\n\
    \   |   RIM FLGS    |    UNUSED     |\n   +---------------+---------------+\n\
    \   QRY AD\n        (16 bits) Numeric identifier for the domain containing the\n\
    \        queried route server.\n   QRY RS (16 bits) Numeric identifier for the\
    \ queried route server.\n   NUM AD (16 bits) Number of domains about which routing\
    \ information is\n        requested.  The value 0 indicates a request for routing\n\
    \        information from all domains.\n   AD (16 bits) Numeric identifier for\
    \ a domain.  This field is absent\n        when NUM AD equals 0.\n   RIM FLGS\
    \ (8 bits) Set of two flags indicating the type of routing\n        information\
    \ messages requested, contained in the right-most\n        bits.  Proceeding left\
    \ to right, the first flag indicates\n        whether the request is for a CONFIGURATION\
    \ message (1\n        CONFIGURATION, 0 no CONFIGURATION).  The second flag indicates\n\
    \        whether the request is for a DYNAMIC message (1 DYNAMIC, 0 no\n     \
    \   DYNAMIC).  At least one of the first and second flags must be\n        set\
    \ to 1.\n   UNUSED (8 bits) Not currently used; must be set equal to 0.\n"
- title: 5.5.2.  ROUTE REQUEST
  contents:
  - "5.5.2.  ROUTE REQUEST\n        The ROUTE REQUEST message type is equal to 1.\n\
    \    0                   1                   2                   3\n    0 1 2\
    \ 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |            QRY AD             |            QRY RS             |\n   +-------------------------------+-------------------------------+\n\
    \   |            SRC AD             |            HST SET            |\n   +---------------+---------------+-------------------------------+\n\
    \   |      UCI      |    UNUSED     |            NUM RQS            |\n   +---------------+---------------+-------------------------------+\n\
    \   |            DST AD             |            PRX AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |    NUM RTS    |   GEN FLGS    |            RFS AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |            NUM AD             |\n   +-------------------------------+\n\
    \   For each domain to be favored, avoided, or excluded:\n   +-------------------------------+---------------+---------------+\n\
    \   |              AD               |    AD FLGS    |    UNUSED     |\n   +-------------------------------+---------------+---------------+\n\
    \   For each requested service:\n   +-------------------------------+-------------------------------+\n\
    \   |            RQS TYP            |            RQS LEN            |\n   +-------------------------------+-------------------------------+\n\
    \   |                            RQS SRV                            |\n   +---------------------------------------------------------------+\n\
    \   QRY AD\n        (16 bits) Numeric identifier for the domain containing the\n\
    \        queried route server.\n   QRY RS (16 bits) Numeric identifier for the\
    \ queried route server.\n   SRC AD (16 bits) Numeric identifier for the route's\
    \ source domain.\n   HST SET (16 bits) Numeric identifier for the source's host\
    \ set.\n   UCI (8 bits) Numeric identifier for the source user class. The value\n\
    \        0 indicates that there is no particular source user class.\n   UNUSED\
    \ (8 bits) Not currently used; must be set equal to 0.\n   NUM RQS (16 bits) Number\
    \ of requested services.  The value 0\n        indicates that the source requests\
    \ no special services.\n   DST AD (16 bits) Numeric identifier for the route's\
    \ destination\n        domain.\n   PRX AD (16 bits) Numeric identifier for the\
    \ destination domain's\n        proxy (see section 1.3.1).  If the destination\
    \ domain provides\n        the path agent function for its hosts, then the destination\
    \ and\n        proxy domains are identical.  A route server constructs routes\n\
    \        between the source domain's proxy and the destination domain's\n    \
    \    proxy.  We note that the source domain's proxy is identical to\n        the\
    \ domain issuing the CMTP message containing the ROUTE REQUEST\n        message,\
    \ and hence available in the CMTP header.\n   NUM RTS (8 bits) Number of policy\
    \ routes requested.\n   GEN FLGS (8 bits) Set of three flags indicating how to\
    \ obtain the\n        requested routes, contained in the right-most bits.  Proceeding\n\
    \        left to right, the first flag indicates whether the route server\n  \
    \      should retrieve existing routes from its route database or\n        generate\
    \ new routes (1 retrieve, 0 generate).  The second flag\n        indicates whether\
    \ the route server should refresh its routing\n        information database before\
    \ generating the requested routes (1\n        refresh, 0 no refresh) and when\
    \ set to 1, causes the third flag\n        and the RFS AD field to become significant.\
    \  The third flag\n        indicates whether the routing information database\
    \ refresh\n        should include CONFIGURATION messages or DYNAMIC messages (1\n\
    \        configuration, 0 dynamic).\n   RFS AD (16 bits) Numeric identifier for\
    \ the domain for which routing\n        information should be refreshed.  This\
    \ field is meaningful only\n        if the second flag in the GEN FLGS field is\
    \ set to 1.\n   NUM AD (16 bits) Number of transit domains that are to be favored,\n\
    \        avoided, or excluded during route selection (see section 1.4.1).\n  \
    \ AD (16 bits) Numeric identifier for a transit domain to be favored,\n      \
    \  avoided, or excluded.\n   AD FLGS (8 bits) Three flags indicating how to interpret\
    \ the AD\n        field, contained in the right-most bits.  Proceeding left to\n\
    \        right, the first flag indicates whether the domain should be\n      \
    \  favored (1 favored, 0 not favored).  The second flag indicates\n        whether\
    \ the domain should be avoided (1 avoided, 0 not avoided).\n        The third\
    \ flag indicates whether the domain should be excluded\n        (1 excluded, 0\
    \ not excluded).  No more than one of the first,\n        second, and third flags\
    \ must set to 1.\n   RQS TYP (16 bits) Numeric identifier for a type of requested\
    \ service.\n        Valid requested services include the following types:\n  \
    \ 1.  Upper bound on delay, in milliseconds (16 bits).  This attribute\n     \
    \  may be omitted.\n   2.  Minimum delay route.  This attribute may be omitted.\n\
    \   3.  Upper bound on delay variation, in milliseconds (16 bits).  This\n   \
    \    attribute may be omitted.\n   4.  Minimum delay variation route.  This attribute\
    \ may be omitted.\n   5.  Lower bound on bandwidth, in bits per second (48 bits).\
    \  This\n       attribute may be omitted.\n   6.  Maximum bandwidth route.  This\
    \ attribute may be omitted.\n   7.  Upper bound on monetary cost, in cents (32\
    \ bits).  This attribute\n       may be omitted.\n   8.  Minimum monetary cost\
    \ route.  This attribute may be omitted.\n   9.  Path lifetime in minutes (16\
    \ bits). This attribute may be omitted\n       but must be present if types 7\
    \ or 8 are present. Route servers\n       use path lifetime information together\
    \ with domain charging\n       method to compute expected session monetary cost\
    \ over a given\n       domain.\n   10. Path lifetime in messages (16 bits).  This\
    \ attribute may be\n       omitted but must be present if types 7 or 8 are present.\n\
    \   11. Path lifetime in bytes (48 bits).  This attribute may be omitted\n   \
    \    but must be present if types 7 or 8 are present.\n   RQS LEN\n        (16\
    \ bits) Length of the requested service, in bytes, beginning\n        with the\
    \ next field.\n   RQS SRV\n        (variable) Description of the requested service.\n"
- title: 5.5.3.  ROUTE RESPONSE
  contents:
  - "5.5.3.  ROUTE RESPONSE\n   The ROUTE RESPONSE message type is equal to 2.\n \
    \   0                   1                   2                   3\n    0 1 2 3\
    \ 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |    NUM RTS    |\n   +---------------+\n   For each route provided:\n   +---------------+---------------+\n\
    \   |    NUM AD     |   RTE FLGS    |\n   +---------------+---------------+\n\
    \   For each domain in the route:\n   +---------------+---------------+-------------------------------+\n\
    \   |    AD LEN     |      VG       |            ADJ AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |            ADJ CMP            |            NUM TP             |\n   +-------------------------------+-------------------------------+\n\
    \   |              TP               |\n   +-------------------------------+\n\
    \   NUM RTS\n        (16 bits) Number of policy routes provided.\n   RTE FLGS\
    \ (8 bits) Set of two flags indicating the directions in which\n        a route\
    \ can be used, contained in the right-most bits.  Refer to\n        sections 6.2,\
    \ 7, and 7.2 for detailed discussions of path\n        directionality.  Proceeding\
    \ left to right, the first flag\n        indicates whether the route can be used\
    \ from source to\n        destination (1 from source, 0 not from source).  The\
    \ second flag\n        indicates whether the route can be used from destination\
    \ to\n        source (1 from destination, 0 not from destination).  At least\n\
    \        one of the first and second flags must be set to 1, if NUM RTS\n    \
    \    is greater than 0.\n   NUM AD (8 bits) Number of domains in the policy route,\
    \ not including\n        the first domain on the route.\n   AD LEN (8 bits) Length\
    \ of the information associated with a\n        particular domain, in bytes, beginning\
    \ with the next field.\n   VG (8 bits) Numeric identifier for an exit virtual\
    \ gateway.\n   ADJ AD (16 bits) Numeric identifier for the adjacent domain connected\n\
    \        to the virtual gateway.\n   ADJ CMP (16 bits) Numeric identifier for\
    \ the adjacent domain\n        component.  Used by policy gateways to select a\
    \ route across a\n        virtual gateway connecting to a partitioned domain.\n\
    \   NUM TP (16 bits) Number of transit policies that apply to the section\n  \
    \      of the route traversing the domain component.\n   TP (16 bits) Numeric\
    \ identifier for a transit policy.\n"
- title: 5.5.4.  Negative Acknowledgements
  contents:
  - "5.5.4.  Negative Acknowledgements\n   When a policy gateway receives an unacceptable\
    \ RSQP message that\n   passes the CMTP validation checks, it includes, in its\
    \ CMTP ACK, an\n   appropriate negative acknowledgement.  This information is\
    \ placed in\n   the INFORM field of the CMTP ACK (described previously in section\n\
    \   2.4); the numeric identifier for each type of RSQP negative\n   acknowledgement\
    \ is contained in the left-most 8 bits of the INFORM\n   field.  Negative acknowledgements\
    \ associated with RSQP include the\n   following types:\n   1.  Unrecognized RSQP\
    \ message type.  Numeric identifier for the\n       unrecognized message type\
    \ (8 bits).\n   2.  Out-of-date RSQP message.\n   3.  Unable to fill requests\
    \ for routing information from the\n       following domains.  Number of domains\
    \ for which requests cannot\n       be filled (16 bits); a value of 0 indicates\
    \ that the route\n       server cannot fill any of the requests.  Numeric identifier\
    \ for\n       each domain for which a request cannot be filled (16 bits).\n  \
    \ 4.  Unable to fill requests for routes to the following destination\n      \
    \ domain.  Numeric identifier for the destination domain (16 bits).\n"
- title: 6.  Route Generation
  contents:
  - "6.  Route Generation\n   Route generation is the most computationally complex\
    \ part of IDPR,\n   because of the number of domains and the number and heterogeneity\
    \ of\n   policies that it must accommodate.  Route servers must generate\n   policy\
    \ routes that satisfy the requested services of the source\n   domains and respect\
    \ the offered services of the transit domains.\n   We distinguish requested qualities\
    \ of service and route generation\n   with respect to them as follows:\n  - Requested\
    \ service limits include upper bounds on route delay, route\n    delay variation,\
    \ and session monetary cost and lower bounds on\n    available route bandwidth.\
    \  Generating a route that must satisfy\n    more than one quality of service\
    \ constraint, for example route delay\n    of no more than X seconds and available\
    \ route bandwidth of no less\n    than Y bits per second, is an NP-complete problem.\n\
    \  - Optimal requested  services  include  minimum  route delay, minimum\n   \
    \ route delay variation, minimum session monetary cost, and maximum\n    available\
    \ route bandwidth.  In the worst case, the computational\n    complexity of generating\
    \ a route that is optimal with respect to a\n    given requested service is O((N\
    \ + L) log N) for Dijkstra's shortest\n    path first (SPF) search and O(N + (L\
    \ * L)) for breadth-first (BF)\n    search, where N is the number of nodes and\
    \ L is the number of links\n    in the search graph.  Multi-criteria optimization,\
    \ for example\n    finding a route with minimal delay variation and minimal session\n\
    \    monetary cost, may be defined in several ways.  One approach to\n    multi-criteria\
    \ optimization is to assign each link a single value\n    equal to a weighted\
    \ sum of the values of the individual offered\n    qualities of service and generate\
    \ a route that is optimal with\n    respect to this new criterion.  However, selecting\
    \ the weights that\n    yield the desired route generation behavior is itself\
    \ an\n    optimization procedure and hence not trivial.\n"
- title: To help contain the combinatorial explosion of processing and memory
  contents:
  - 'To help contain the combinatorial explosion of processing and memory

    '
- title: costs associated with route generation, we supply the following
  contents:
  - 'costs associated with route generation, we supply the following

    '
- title: 'guidelines for generation of suitable policy routes:'
  contents:
  - "guidelines for generation of suitable policy routes:\n  - Each route server should\
    \ only generate policy routes from the\n    perspective of its own domain as source;\
    \ it need not generate policy\n    routes for arbitrary source/destination domain\
    \ pairs.  Thus, we can\n    distribute the computational burden over all route\
    \ servers.\n  - Route servers should precompute routes for which they anticipate\n\
    \    requests and should generate routes on demand only in order to\n    satisfy\
    \ unanticipated route requests.  Hence, a single route server\n    can distribute\
    \ its computational burden over time.\n  - Route servers should cache the results\
    \ of route generation, in order\n    to minimize the computation associated with\
    \ responding to future\n    route requests.\n  - To handle requested service limits,\
    \ a route server should always\n    select the first route generated that satisfies\
    \ all of the requested\n    service limits.\n  - To handle multi-criteria optimization\
    \ in route selection, a route\n    server should generate routes that are optimal\
    \ with respect to the\n    first optimal requested service listed in the ROUTE\
    \ REQUEST message.\n    The route server should resolve ties between otherwise\
    \ equivalent\n    routes by evaluating these routes according to the other optimal\n\
    \    requested services contained in the ROUTE REQUEST message, in the\n    order\
    \ in which they are listed.  With respect to the route server's\n    routing information\
    \ database, the selected route is optimal\n    according to the first optimal\
    \ requested service listed in the ROUTE\n    REQUEST message but is not necessarily\
    \ optimal according to any\n    other optimal requested service listed in the\
    \ ROUTE REQUEST message.\n    ti 2 - To handle a mixture of requested service\
    \ limits and optimal\n    requested services, a route server should generate routes\
    \ that\n    satisfy all of the requested service limits.  The route server\n \
    \   should resolve ties between otherwise equivalent routes by\n    evaluating\
    \ these routes as described in the multi-criteria\n    optimization case above.\n\
    \    ti 2 - All else being equal, a route server should always prefer\n    minimum-hop\
    \ routes, because they minimize the amount of network\n    resources consumed\
    \ by the routes.\n    ti 2 - A route server should generate at least one route\
    \ to each\n    component of a partitioned destination domain, because it may not\n\
    \    know in which domain component the destination host resides.  Hence,\n  \
    \  a route server can maximize the chances of providing a feasible\n    route\
    \ to a destination within a partitioned domain.\n"
- title: 6.1  Searching
  contents:
  - "6.1  Searching\n    All domains need not execute the identical route generation\n\
    \    procedure.  Each domain administrator is free to specify the IDPR\n    route\
    \ generation procedure for route servers in its own domain,\n    making the procedure\
    \ as simple or as complex as desired.\n    We offer an IDPR route generation procedure\
    \ as a model.  With slight\n    modification, this procedure can be made to search\
    \ in either BF or\n    SPF order.  The procedure can be used either to generate\
    \ a single\n    policy route from the source to a specified destination domain\
    \ or to\n    generate a set of policy routes from the source domain to all\n \
    \   destination domains.  If the source or destination domain has a\n    proxy,\
    \ then the source or destination endpoint of the policy route\n    is a proxy\
    \ domain and not the actual source or destination domain.\n    For high-bandwidth\
    \ traffic flows, BF search is the recommended\n    search technique, because it\
    \ produces minimum-hop routes.  For low-\n    bandwidth traffic flows, the route\
    \ server may use either BF search\n    or SPF search.  The computational complexity\
    \ of BF search is O(N +\n    L) and hence it is the search procedure of choice,\
    \ except when\n    generating routes with optimal requested services.  We recommend\n\
    \    using SPF search only for optimal requested services and never in\n    response\
    \ to a request for a maximum bandwidth route.\n"
- title: 6.1.1.  Implementation
  contents:
  - "6.1.1.  Implementation\n   Data Structures:\n   The routing information database\
    \ contains the graph of an\n   internetwork, in which virtual gateways are the\
    \ nodes and intra-\n   domain routes between virtual gateways are the links. \
    \ During route\n   generation, each route is represented as a sequence of virtual\n\
    \   gateways, domains, and relevant transit policies, together with a\n   list\
    \ of route characteristics, stored in a temporary array and\n   indexed by destination\
    \ domain.\n   - Execute the Policy Consistency routine, first with the source\n\
    \     domain the given domain and second with the destination domain as\n    \
    \ the given domain.  If any policy inconsistency precludes the\n     requested\
    \ traffic flow, go to Exit.\n   - For each domain, initialize a null route, set\
    \ the route bandwidth\n     to and set the following route characteristics to\
    \ infinity: route\n     delay, route delay variation, session monetary cost, and\
    \ route\n     length in hops.\n   - With each operational virtual gateway in the\
    \ source or source proxy\n     domain, associate the initial route characteristics.\n\
    \   - Initialize a next-node data structure which will contain, for each\n   \
    \  route in progress, the virtual gateway at the current endpoint of\n     the\
    \ route together with the associated route characteristics.  The\n     next-node\
    \ data structure determines the order in which routes get\n     expanded.\n  \
    \      BF:  A fifo queue.\n        SPF: A heap, ordered according to the first\
    \ optimal requested\n             service listed in the ROUTE REQUEST message.\n\
    \   Remove Next Node: These steps are performed for each virtual gateway\n   \
    \     in the next-node data structure.\n      - If there are no more virtual gateways\
    \ in the next-node data\n        structure, go to Exit.\n      - Extract a virtual\
    \ gateway and its associated route\n        characteristics from the next-node\
    \ data structure, obtain the\n        adjacent domain, and:\n             SPF:\
    \ Remake the heap.\n      - If there is a specific destination domain and if for\
    \ the primary\n        optimal service:\n             BF:  Route length in hops.\n\
    \             SPF: First optimal requested service listed in the ROUTE\n     \
    \        REQUEST message.\n        the extracted virtual gateway's associated\
    \ route characteristic\n        is no better than that of the destination domain,\
    \ go to Remove\n        Next Node.\n      - Execute the Policy Consistency routine\
    \ with the adjacent domain\n        as given domain.  If any policy inconsistency\
    \ precludes the\n        requested traffic flow, go to Remove Next Node.\n   \
    \   - Check that the source domain's transit policies do not preclude\n      \
    \  traffic generated by members of the source host set with the\n        specified\
    \ user class and requested services, from flowing to the\n        adjacent domain\
    \ as destination.  This check is necessary because\n        the route server caches\
    \ what it considers to be all feasible\n        routes, to intermediate destination\
    \ domains, generated during\n        the computation of the requested route. \
    \ If there are no policy\n        inconsistencies, associate the route and its\
    \ characteristics\n        with the adjacent domain as destination.\n      - If\
    \ there is a specific destination domain and if the adjacent\n        domain is\
    \ the destination or destination proxy domain, go to\n        Remove Next Node.\n\
    \      - Record the set of all exit virtual gateways in the adjacent\n       \
    \ domain which the adjacent domain's transit policies permit the\n        requested\
    \ traffic flow and which are currently reachable from\n        the entry virtual\
    \ gateway.\n   Next Node:\n        These steps are performed for all exit virtual\
    \ gateways in the\n        above set.\n      - If there are no exit virtual gateways\
    \ in the set, go to Remove\n        Next Node.\n      - Compute the characteristics\
    \ for the route to the exit virtual\n        gateway, and check that all of the\
    \ route characteristics are\n        within the requested service limits.  If\
    \ any of the route\n        characteristics are outside of these limits, go to\
    \ Next Node.\n      - Compare these route characteristics with those already\n\
    \        associated with the exit virtual gateway (there may be none, if\n   \
    \     this is the first time the exit virtual gateway has been visited\n     \
    \   in the search), according to the primary optimal service.\n      - Select\
    \ the route with the optimal value of the primary optimal\n        service, resolve\
    \ ties by considering optimality according to any\n        other optimal requested\
    \ services in the order in which they are\n        listed in the ROUTE REQUEST\
    \ message, and associate the selected\n        route and its characteristics with\
    \ the exit virtual gateway.\n      - Add the virtual gateway to the next-node\
    \ structure:\n             BF:  Add to the end of the fifo queue.\n          \
    \   SPF: Add to the heap.\n             and go to Next Node.\n   Exit:\n     \
    \   Return a response to the route request, consisting of either a\n        set\
    \ of candidate policy routes or an indication that the route\n        request\
    \ cannot be fulfilled.\n   Policy Consistency: Check policy consistency for the\
    \ given domain.\n      - Check that the given domain is not specified as an excluded\n\
    \        domain in the route request.\n      - Check that the given domain's transit\
    \ policies do not preclude\n        traffic generated by members of the source\
    \ host set with the\n        specified user class and requested services, from\
    \ flowing to the\n        destination domain.\n   During the computation of the\
    \ requested routes, a route server also\n   caches what it considers to be all\
    \ feasible routes to intermediate\n   destination domains, thus increasing the\
    \ chances of being able to\n   respond to a future route request without having\
    \ to generate a new\n   route.  The route server does perform some policy consistency\
    \ checks\n   on the routes, as they are generated, to intermediate destinations.\n\
    \   However, these routes may not in fact be feasible; the transit\n   domains\
    \ contained on the routes may not permit traffic between the\n   source and the\
    \ given intermediate destinations.  Hence, before\n   dispensing such a route\
    \ in response to a route request, a route\n   server must check that the transit\
    \ policies of the constituent\n   domains are consistent with the source and destination\
    \ of the traffic\n   flow.\n"
- title: 6.2.  Route Directionality
  contents:
  - "6.2.  Route Directionality\n   A path agent may wish to set up a bidirectional\
    \ path using a route\n   supplied by a route server.  (Refer to sections 7.2 and\
    \ 7.4 for\n   detailed discussions of path directionality.)  However, a route\n\
    \   server can only guarantee that the routes it supplies are feasible if\n  \
    \ used in the direction from source to destination.  The reason is that\n   the\
    \ route server, which resides in the source or source proxy domain,\n   does not\
    \ have access to, and thus cannot account for, the source\n   policies of the\
    \ destination domain.  Nevertheless, the route server\n   can provide the path\
    \ agent with an indication of its assessment of\n   route feasibility in the direction\
    \ from destination to source.\n   A necessary but insufficient condition for a\
    \ route to be feasible in\n   the direction from destination to source is as follows.\
    \  The route\n   must be consistent, in the direction from destination to source,\
    \ with\n   the transit policies of the domains that compose the route.  The\n\
    \   transit policy consistency checks performed by the route server\n   during\
    \ route generation account for the direction from source to\n   destination but\
    \ not for the direction from destination to source.\n   Only after a route server\
    \ generates a feasible route from source to\n   destination does it perform the\
    \ transit policy consistency checks for\n   the route in the direction from destination\
    \ to source.  Following\n   these checks, the route server includes in its ROUTE\
    \ RESPONSE message\n   to the path agent an indication of its assessment of route\n\
    \   feasibility in each direction.\n"
- title: 6.3.  Route Database
  contents:
  - "6.3.  Route Database\n   A policy route, as originally specified by a route server,\
    \ is an\n   ordered list of virtual gateways, domains, and transit policies: VG\
    \ 1\n   - AD 1 - TP 1 - ... - VG n - AD n - TP n. where VG i is the virtual\n\
    \   gateway that serves as exit from AD i-1 and entry to AD i, and TP i\n   is\
    \ the set of transit policies associated with AD i and relevant to\n   the particular\
    \ route.  Each route is indexed by source and\n   destination domain.  Route servers\
    \ and paths agents store policy\n   routes in route databases maintained as caches\
    \ whose entries must be\n   periodically flushed to avoid retention of stale policy\
    \ routes.  A\n   route server's route database is the set of all routes it has\n\
    \   generated on behalf of its domain as source or source proxy;\n   associated\
    \ with each route in the database are its route\n   characteristics.  A path agent's\
    \ route database is the set of all\n   routes it has requested and received from\
    \ route servers on behalf of\n   hosts for which it is configured to act.\n  \
    \ When attempting to locate a feasible route for a traffic flow, a path\n   agent\
    \ first consults its own route database before querying a route\n   server.  If\
    \ the path agent's route database contains one or more\n   routes between the\
    \ given source and destination domains and\n   accommodating the given host set\
    \ and UCI, then the path agent checks\n   each such route against the set of excluded\
    \ domains listed in the\n   source policy.  The path agent either selects the\
    \ first route\n   encountered that does not include the excluded domains, or,\
    \ if no\n   such route exists in its route database, requests a route from a\n\
    \   route server.\n   A path agent must query a route server for routes when it\
    \ is unable\n   to fulfill a route request from its own route database.  Moreover,\
    \ we\n   recommend that a path agent automatically forward to a route server,\n\
    \   all route requests with non-null requested services.  The reason is\n   that\
    \ the path agent retains no route characteristics in its route\n   database. \
    \ Hence, the path agent cannot determine whether an entry in\n   its route database\
    \ satisfies the requested services.\n   When responding to a path agent's request\
    \ for a policy route, a route\n   server first consults its route database, unless\
    \ the ROUTE REQUEST\n   message contains an explicit directive to generate a new\
    \ route.  If\n   its route database contains one or more routes between the given\n\
    \   source and destination domains and accommodating the given host set\n   and\
    \ UCI, the route server checks each such route against the set of\n   excluded\
    \ domains listed in the ROUTE REQUEST message.  The route\n   server either selects\
    \ all routes encountered that do not include the\n   excluded domains, or, if\
    \ no such route exists in its route database,\n   attempts to generate such a\
    \ route.  Once the route server selects a\n   set of routes, it then checks each\
    \ such route against the services\n   requested by the path agent and the services\
    \ offered by the domains\n   composing the route.  To obtain the offered services\
    \ information, the\n   route server consults its routing information database.\
    \  The route\n   server either selects the first route encountered that is consistent\n\
    \   with both the requested and offered services, or, if no such route\n   exists\
    \ in its route database, attempts to generate such a route.\n"
- title: 6.3.1.  Cache Maintenance
  contents:
  - "6.3.1.  Cache Maintenance\n   Each route stored in a route database has a maximum\
    \ cache lifetime\n   equal to rdb_rs minutes for a route server and rdb_ps minutes\
    \ for a\n   path agent.  Route servers and path agents reclaim cache space by\n\
    \   flushing entries that have attained their maximum lifetimes.\n   Moreover,\
    \ paths agents reclaim cache space for routes whose paths\n   have failed to be\
    \ set up successfully or have been torn down (see\n   section 7.4).\n   Nevertheless,\
    \ cache space may become scarce, even with reclamation of\n   entries.  If a cache\
    \ fills, the route server or path agent logs the\n   event for network management.\
    \  To obtain space in the cache when the\n   cache is full, the route server or\
    \ path agent deletes from the cache\n   the oldest entry.\n"
- title: 7.  Path Control Protocol and Data Message Forwarding Procedure
  contents:
  - "7.  Path Control Protocol and Data Message Forwarding Procedure\n   Two entities\
    \ in different domains may exchange IDPR data messages,\n   only if there exists\
    \ an IDPR path set up between the two domains.\n   Path setup requires cooperation\
    \ among path agents and intermediate\n   policy gateways.  Path agents locate\
    \ policy routes, initiate the Path\n   Control Protocol (PCP), and manage existing\
    \ paths between\n   administrative domains.  Intermediate policy gateways verify\
    \ that a\n   given policy route is consistent with their domains' transit\n  \
    \ policies, establish the forwarding information, and forward messages\n   along\
    \ existing paths.\n   Each policy gateway and each route server contains a path\
    \ agent.  The\n   path agent that initiates path setup in the source or source\
    \ proxy\n   domain is the \"originator\", and the path agent that handles the\n\
    \   originator's path setup message in the destination or destination\n   proxy\
    \ domain is the \"target\".  Every path has two possible directions\n   of traffic\
    \ flow: from originator to target and from target to\n   originator.  Path control\
    \ messages are free to travel in either\n   direction, but data messages may be\
    \ restricted to only one direction.\n   Once a path for a policy route is set\
    \ up, its physical realization is\n   a set of consecutive policy gateways, with\
    \ policy gateways or route\n   servers forming the endpoints.  Two successive\
    \ entities in this set\n   belong to either the same domain or the same virtual\
    \ gateway.  A\n   policy gateway or route server may, at any time, recover the\n\
    \   resources dedicated to a path that goes through it by tearing down\n   that\
    \ path.  For example, a policy gateway may decide to tear down a\n   path that\
    \ has not been used for some period of time.\n   PCP may build multiple paths\
    \ between source and destination domains,\n   but it is not responsible for managing\
    \ such paths as a group or for\n   eliminating redundant paths.\n"
- title: 7.1.  An Example of Path Setup
  contents:
  - "7.1.  An Example of Path Setup\n   We illustrate how path setup works by stepping\
    \ through an example.\n   Suppose host Hx in domain AD X wants to communicate\
    \ with host Hy in\n   domain AD Y and that both AD X and AD Y support IDPR.  Hx\
    \ need not\n   know the identity of its own domain or of Hy's domain in order\
    \ to\n   send messages to Hy.  Instead, Hx simply forwards a message bound for\n\
    \   Hy to one of the gateways on its local network, according to its\n   local\
    \ forwarding information only.  If the recipient gateway is a\n   policy gateway,\
    \ the resident path agent determines how to forward the\n   message outside of\
    \ the domain.  Otherwise, the recipient gateway\n   forwards the message to another\
    \ gateway in AD X, according to its\n   local forwading information.  Eventually,\
    \ the message will arrive at\n   a policy gateway in AD X, as policy gateways\
    \ are the only egress\n   points to other domains, in domains that support IDPR.\n\
    \   The path agent resident in the recipient policy gateway uses the\n   message\
    \ header, including source and destination addresses and any\n   requested service\
    \ information (for example, type of service), in\n   order to determine whether\
    \ it is an intra-domain or inter-domain\n   message, and if inter-domain, whether\
    \ it requires an IDPR policy\n   route.  Specifically, the path agent attempts\
    \ to locate a forwarding\n   information database entry for the given traffic\
    \ flow, from the\n   information contained in the message header.  In the future,\
    \ for IP\n   messages, the relevant header information may also include special\n\
    \   service-specific IP options or even information from higher layer\n   protocols.\n\
    \   Forwarding database entries exist for all of the following:\n   - All intra-domain\
    \ traffic flows.  Intra-domain forwarding\n     information is integrated into\
    \ the forwarding information database\n     as soon as it is received.\n   - Inter-domain\
    \ traffic flows that do not require IDPR policy routes.\n     Non-IDPR forwarding\
    \ information is integrated into the forwarding\n     database as soon as it is\
    \ received.\n   - IDPR inter-domain traffic flows for which a path has already\
    \ been\n     set up.  IDPR forwarding information is integrated into the\n   \
    \  forwarding database only during path setup.\n   The path agent uses the message\
    \ header contents to guide the search\n   for a forwarding information database\
    \ entry for a given traffic flow.\n   We recommend a radix search to locate such\
    \ an entry.  When the search\n   terminates, it produces either an entry, or,\
    \ in the case of a new\n   IDPR traffic flow, a directive to generate an entry.\
    \  If the search\n   terminates in an existing forwarding information database\
    \ entry, the\n   path agent forwards the message according to that entry.\n  \
    \ Suppose that the search terminates indicating that the traffic flow\n   from\
    \ Hx to Hy requires an IDPR policy route and that no entry in the\n   forwarding\
    \ information database yet exists for that traffic flow.  In\n   this case, the\
    \ path agent first determines the source and destination\n   domains associated\
    \ with the message's source and destination\n   addresses, before attempting to\
    \ obtain a policy route.  The path\n   agent relies on the mapping servers to\
    \ supply the domain information,\n   but it caches all mapping server responses\
    \ locally to limit the\n   number of future queries.  When attempting to resolve\
    \ an address to a\n   domain, the path agent always checks its local cache before\n\
    \   contacting a mapping server.\n   After obtaining the domain information, the\
    \ path agent attempts to\n   obtain a policy route to carry the traffic from Hx\
    \ to Hy.  The path\n   agent relies on route servers to supply policy routes,\
    \ but it caches\n   all route server responses locally to limit the number of\
    \ future\n   queries.  When attempting to locate a suitable policy route, the\
    \ path\n   agent usually consults its local cache before contacting a route\n\
    \   server, as described previously in section 6.3.\n   If no suitable cache entry\
    \ exists, the path agent queries the route\n   server, providing it with the source\
    \ and destination domains together\n   with source policy information carried\
    \ in the host message or\n   specified through configuration.  Upon receiving\
    \ a policy route\n   query, a route server consults its route database.  If it\
    \ cannot\n   locate a suitable route in its route database, the route server\n\
    \   attempts to generate at least one route to AD Y, consistent with the\n   requested\
    \ services for Hx.\n   The route server always returns a response to the path\
    \ agent,\n   regardless of whether it is successful in locating a suitable policy\n\
    \   route.  The response to a successful route query consists of a set of\n  \
    \ candidate routes, from which the path agent makes its selection.  We\n   expect\
    \ that a path agent will normally choose a single route from a\n   candidate set.\
    \  Nevertheless, IDPR does not preclude a path agent\n   from selecting multiple\
    \ routes from the candidate set.  A path agent\n   may desire multiple routes\
    \ to support features such as fault\n   tolerance or load balancing; however,\
    \ IDPR does not currently specify\n   how the path agent should use multiple routes.\n\
    \   If the policy route is a new route provided by the route server,\n   there\
    \ will be no existing path for the route, and thus the path agent\n   must set\
    \ up such a path.  However, if the policy route is an existing\n   route extracted\
    \ from the path agent's cache, there may well be an\n   existing path for the\
    \ route, set up to accommodate a host traffic\n   flow.  IDPR permits multiple\
    \ traffic flows to use the same path,\n   provided that all traffic flows sharing\
    \ the path travel between the\n   same endpoint domains and have the same service\
    \ requirements.\n   Nevertheless, IDPR does not preclude a path agent from setting\
    \ up\n   distinct paths along the same policy route to preserve the\n   distinction\
    \ between host traffic flows.\n   The path agent associates an identifier with\
    \ the path, which is\n   included in each message that travels down the path and\
    \ is used by\n   the policy gateways along the path in order to determine how\
    \ to\n   forward the message.  If the path already exists, the path agent uses\n\
    \   the preexisting identifier.  However, for new paths, the path agent\n   chooses\
    \ a path identifier that is different from those of all other\n   paths that it\
    \ manages.  The path agent also updates its forwarding\n   information database\
    \ to reference the path identifier and modifies\n   its search procedure to yield\
    \ the correct entry in the forwarding\n   information database given the data\
    \ message header.\n   For new paths, the path agent initiates path setup, communicating\
    \ the\n   policy route, in terms of requested services, constituent domains,\n\
    \   relevant transit policies, and the connecting virtual gateways, to\n   policy\
    \ gateways in intermediate domains.  Using this information, an\n   intermediate\
    \ policy gateway determines whether to accept or refuse\n   the path and to which\
    \ next policy gateway to forward the path setup\n   information.  The path setup\
    \ procedure allows policy gateways to set\n   up a path in both directions simultaneously.\
    \  Each intermediate\n   policy gateway, after path acceptance, updates its forwarding\n\
    \   information database to include an entry that associates the path\n   identifier\
    \ with the appropriate previous and next hop policy\n   gateways.\n   When a policy\
    \ gateway in AD Y accepts a path, it notifies the source\n   path agent in AD\
    \ X.  We expect that the source path agent will\n   normally wait until a path\
    \ has been successfully established before\n   using it to transport data traffic.\
    \  However, PCP does not preclude a\n   path agent from forwarding messages along\
    \ a path prior to\n   confirmation of successful path establishment.  Paths remain\
    \ in place\n   until they are torn down because of failure, expiration, or when\n\
    \   resources are scarce, preemption in favor of other paths.\n   We note that\
    \ data communication between Hx and Hy may occur over two\n   separate IDPR paths:\
    \ one from AD X to AD Y and one from AD Y to AD X.\n   The reasons are that within\
    \ a domain, hosts know nothing about path\n   agents nor IDPR paths, and path\
    \ agents know nothing about other path\n   agents' existing IDPR paths.  Thus,\
    \ in AD Y, the path agent that\n   terminates the path from AD X may not be the\
    \ same as the path agent\n   that receives traffic from Hy destined for Hx.  In\
    \ this case, receipt\n   of traffic from Hy forces the second path agent to set\
    \ up an\n   independent path from AD Y to AD X.\n"
- title: 7.2.  Path Identifiers
  contents:
  - "7.2.  Path Identifiers\n   Each path has an associated path identifier, unique\
    \ throughout an\n   internetwork.  Every IDPR data message travelling along that\
    \ path\n   includes the path identifier, used for message forwarding.  The path\n\
    \   identifier is the concatenation of three items: the identifier of the\n  \
    \ originator's domain, the identifier of the originator's policy\n   gateway or\
    \ route server, and a 32-bit local path identifier specified\n   by the originator.\
    \  The path identifier and the CMTP transaction\n   identifier have analogous\
    \ syntax and play analogous roles in their\n   respective protocols.\n   When\
    \ issuing a new path identifier, the originator always assigns a\n   local path\
    \ identifier that is different from that of any other active\n   or recently torn-down\
    \ path originally set up by that path agent.\n   This helps to distinguish new\
    \ paths from replays.  Hence, the\n   originator must keep a record of each extinct\
    \ path for long enough\n   that all policy gateways on the path will have eliminated\
    \ any\n   reference to it from their memories.  The right-most 30 bits of the\n\
    \   local identifier are the same for each path direction, as they are\n   assigned\
    \ by the originator.  The left-most 2 bits of the local\n   identifier indicate\
    \ the path direction.\n   At path setup time, the originator specifies which of\
    \ the path\n   directions to enable contingent upon the information received from\n\
    \   the route server in the ROUTE RESPONSE message.  By \"enable\", we mean\n\
    \   that each path agent and each intermediate policy gateway establishes\n  \
    \ an association between the path identifier and the previous and next\n   policy\
    \ gateways on the path, which it uses for forwarding data\n   messages along that\
    \ path.  IDPR data messages may travel in the\n   enabled path directions only,\
    \ but path control messages are always\n   free to travel in either path direction.\
    \  The originator may enable\n   neither path direction, if the entire data transaction\
    \ can be carried\n   in the path setup message itself.  In this case, the path\
    \ agents and\n   the intermediate policy gateways do not establish forwarding\n\
    \   associations for the path, but they do verify consistency of the\n   policy\
    \ information contained in the path setup message, with their\n   own transit\
    \ policies, before forwarding the setup message on to the\n   next policy gateway.\n\
    \   The path direction portion of the local path identifier has different\n  \
    \ interpretations, depending upon message type.  In an IDPR path setup\n   message,\
    \ the path direction indicates the directions in which the\n   path should be\
    \ enabled: the value 01 denotes originator to target,\n   the value 10 denotes\
    \ target to originator, the value 11 denotes both\n   directions, and the value\
    \ 00 denotes neither direction.  Each policy\n   gateway along the path interprets\
    \ the path direction in the setup\n   message and sets up the forwarding information\
    \ as directed.  In an\n   IDPR data message, the path direction indicates the\
    \ current direction\n   of traffic flow: either 01 for originator to target or\
    \ 10 for target\n   to originator.  Thus, if for example, an originator sets up\
    \ a path\n   enabling only the direction from target to originator, the target\n\
    \   sends data messages containing the path identifier selected by the\n   originator\
    \ together with the path direction set equal to 10.\n   Instead of using path\
    \ identifiers that are unique throughout an\n   internetwork, we could have used\
    \ path identifiers that are unique\n   only between a pair of consecutive policy\
    \ gateways and that change\n   from one policy gateway pair to the next.  The\
    \ advantage of locally\n   unique path identifiers is that they may be much shorter\
    \ than\n   globally unique identifiers and hence consume less transmission\n \
    \  bandwidth.  However, the disadvantage is that the path identifier\n   carried\
    \ in each IDPR data message must be modified at each policy\n   gateway, and hence\
    \ if the integrity/authentication information covers\n   the path identifier,\
    \ it must be recomputed at each policy gateway.\n   For security reasons, we have\
    \ chosen to include the path identifier\n   in the set of information covered\
    \ by the integrity/authentication\n   value, and moreover, we advocate public-key\
    \ based signatures for\n   authentication.  Thus, it is not possible for intermediate\
    \ policy\n   gateways to modify the path identifier and then recompute the correct\n\
    \   integrity/authentication value.  Therefore, we have decided in favor\n   of\
    \ path identifiers that do not change from hop to hop and hence must\n   be globally\
    \ unique.  To speed forwarding of IDPR data messages with\n   long path identifiers,\
    \ policy gateways should hash the path\n   identifiers in order to index IDPR\
    \ forwarding information.\n"
- title: 7.3.  Path Control Messages
  contents:
  - "7.3.  Path Control Messages\n   Messages exchanged by the path control protocol\
    \ are classified into\n   \"requests\": SETUP, TEARDOWN, REPAIR; and \"responses\"\
    : ACCEPT, REFUSE,\n   ERROR.  These messages have significance for intermediate\
    \ policy\n   gateways as well as for path agents.\n   SETUP:\n        Establishes\
    \ a path by linking together pairs of policy gateways.\n        The SETUP message\
    \ is generated by the originator and propagates\n        to the target.  In response\
    \ to a SETUP message, the originator\n        expects to receive an ACCEPT, REFUSE,\
    \ or ERROR message.  The\n        SETUP message carries all information necessary\
    \ to set up the\n        path including path identifier, requested services, transit\n\
    \        policy information relating to each domain traversed, and\n        optionally,\
    \ expedited data.\n   ACCEPT: Signals successful path establishment.  The ACCEPT\
    \ message is\n        generated by the target, in response to a SETUP message,\
    \ and\n        propagates back to the originator.  Reception of an ACCEPT\n  \
    \      message by the originator indicates that the originator can now\n     \
    \   safely proceed to send data along the path.  The ACCEPT message\n        contains\
    \ the path identifier and an optional reason for\n        conditional acceptance.\n\
    \   REFUSE: Signals that the path could not be successfully established,\n   \
    \     either because resources were not available or because there was\n     \
    \   an inconsistency between the services requested by the source\n        and\
    \ the services offered by a transit domain along the path.\n        The REFUSE\
    \ message is generated by the target or by any\n        intermediate policy gateway,\
    \ in response to a SETUP message, and\n        propagates back to the originator.\
    \  All recipients of a REFUSE\n        message recover the resources dedicated\
    \ to the given path.  The\n        REFUSE message contains the path identifier\
    \ and the reason for\n        path refusal.\n   TEARDOWN: Tears down a path, typically\
    \ when a non-recoverable failure\n        is detected.  The TEARDOWN message may\
    \ be generated by any path\n        agent or policy gateway in the path and usually\
    \ propagates in\n        both path directions.  All recipients of a TEARDOWN message\n\
    \        recover the resources dedicated to the given path.  The TEARDOWN\n  \
    \      message contains the path identifier and the reason for path\n        teardown.\n\
    \   REPAIR: Establishes a repaired path by linking together pairs of\n       \
    \ policy gateways.  The REPAIR message is generated by a policy\n        gateway\
    \ after detecting that the next policy gateway on one of\n        its existing\
    \ paths is unreachable.  A policy gateway that\n        generates a REPAIR message\
    \ propagates the message forward at\n        most one virtual gateway.  In response\
    \ to a REPAIR message, the\n        policy gateway expects to receive an ACCEPT,\
    \ REFUSE, TEARDOWN,\n        or ERROR message.  The REPAIR message carries the\
    \ original SETUP\n        message.\n   ERROR: Transports information about a path\
    \ error back to the\n        originator, when a PCP message contains unrecognized\n\
    \        information.  The ERROR message may be generated by the target\n    \
    \    or by any intermediate policy gateway and propagates back to the\n      \
    \  originator.  Most, but not all, ERROR messages are generated in\n        response\
    \ to errors encountered during path setup.  The ERROR\n        message includes\
    \ the path identifier and an explanation of the\n        error detected.\n   Policy\
    \ gateways use CMTP for reliable transport of PCP messages,\n   between path agents\
    \ and policy gateways and between consecutive\n   policy gateways on a path. \
    \ PCP must communicate to CMTP the maximum\n   number of transmissions per path\
    \ control message, pcp_ret, and the\n   interval between path contol message retransmissions,\
    \ pcp_int\n   microseconds.  All path control messages, except ERROR messages,\
    \ may\n   be transmitted up to pcp_ret times; ERROR messages are never\n   retransmitted.\
    \  A path control message is \"acceptable\" if:\n   - It passes the CMTP validation\
    \ checks.\n   - Its timestamp is less than pcp_old (300) seconds behind the\n\
    \     recipient's internal clock time.\n   - It carries a recognized path identifier,\
    \ provided it is not a SETUP\n     message.\n   An intermediate policy gateway\
    \ on a path forwards acceptable PCP\n   messages.  As we describe in section 7.4\
    \ below, SETUP messages must\n   undergo additional tests at each intermediate\
    \ policy gateway prior to\n   forwarding.  Moreover, receipt of an acceptable\
    \ ACCEPT, REFUSE,\n   TEARDOWN, or ERROR message at either path agent or at any\n\
    \   intermediate policy gateway indirectly cancels any active local CMTP\n   retransmissions\
    \ of the original SETUP message.  When a path agent or\n   intermediate policy\
    \ gateway receives an unacceptable path control\n   message, it discards the message\
    \ and logs the event for network\n   management.  The path control message age\
    \ limit reduces the\n   likelihood of denial of service attacks based on message\
    \ replay.\n"
- title: 7.4.  Setting Up and Tearing Down a Path
  contents:
  - "7.4.  Setting Up and Tearing Down a Path\n   Path setup begins when the originator\
    \ generates a SETUP message\n   containing:\n   - The path identifier, including\
    \ path directions to enable.\n   - An indication of whether the message includes\
    \ expedited data.\n   -   The source user class identifier.\n   - The requested\
    \ services (see section 5.5.2) and source-specific\n     information (see section\
    \ 7.6.1) for the path.\n   - For each domain on the path, the domain component,\
    \ applicable\n     transit policies, and entry and exit virtual gateways.\n  \
    \ The only mandatory requested service is the maximum path lifetime,\n   pth_lif,\
    \ and the only mandatory source-specific information is the\n   data message integrity/authentication\
    \ type.  If these are not\n   specified in the path setup message, each recipient\
    \ policy gateway\n   assigns them default values, (60) minutes for pth_lif and\
    \ no\n   authentication for integrity/authentication type.  Each path agent\n\
    \   and intermediate policy gateway tears down a path when the path\n   lifetime\
    \ is exceeded.  Hence, no single source can indefinitely\n   monopolize policy\
    \ gateway resources or still functioning parts of\n   partially broken paths.\n\
    \   After generating the SETUP message and establishing the proper local\n   forwarding\
    \ information, the originator selects the next policy\n   gateway on the path\
    \ and forwards the SETUP message to the selected\n   policy gateway.  The next\
    \ policy gateway selection procedure,\n   described below, applies when either\
    \ the originator or an\n   intermediate policy gateway is making the selection.\
    \  We have elected\n   to describe the procedure from the perspective of a selecting\n\
    \   intermediate policy gateway.\n   The policy gateway selects the next policy\
    \ gateway on a path, in\n   round-robin order from its list of policy gateways\
    \ contained in the\n   present or next virtual gateway, as explained below.  In\
    \ selecting\n   the next policy gateway, the policy gateway uses information\n\
    \   contained in the SETUP message and information provided by VGP and by\n  \
    \ the intra-domain routing procedure.\n   If the selecting policy gateway is a\
    \ domain entry point, the next\n   policy gateway must be:\n   - A member of the\
    \ next virtual gateway listed in the SETUP message.\n   - Reachable according\
    \ to intra-domain routes supporting the transit\n     policies listed in the SETUP\
    \ message.\n   - Able to reach, according to VGP, the next domain component listed\n\
    \     in the SETUP message.\n   In addition, the selecting policy gateway may\
    \ use quality of service\n   information supplied by intra-domain routing to resolve\
    \ ties between\n   otherwise equivalent next policy gateways in the same domain.\
    \  In\n   particular, the selecting policy gateway may select the next policy\n\
    \   gateway whose connecting intra-domain route is optimal according to\n   the\
    \ requested services listed in the SETUP message.\n   If the selecting policy\
    \ gateway is a domain exit point, the next\n   policy gateway must be:\n   - A\
    \ member of the current virtual gateway listed in the SETUP message\n     (which\
    \ is also the selecting policy gateway's virtual gateway).\n   - Reachable according\
    \ to VGP.\n   - A member of the next domain component listed in the SETUP message.\n\
    \   Once the originator or intermediate policy gateway selects a next\n   policy\
    \ gateway, it forwards the SETUP message to the selected policy\n   gateway. \
    \ Each recipient (policy gateway or target) of an acceptable\n   SETUP message\
    \ performs several checks on the contents of the message,\n   in order to determine\
    \ whether to establish or reject the path.  We\n   describe these checks in detail\
    \ below from the perspective of a\n   policy gateway as SETUP message recipient.\n"
- title: 7.4.1.  Validating Path Identifiers
  contents:
  - "7.4.1.  Validating Path Identifiers\n   The recipient of a SETUP message first\
    \ checks the path identifier, to\n   make sure that it does not correspond to\
    \ that of an already existing\n   or recently extinct path.  To detect replays,\
    \ malicious or otherwise,\n   path agents and policy gateways maintain a record\
    \ of each path that\n   they establish, for max{pth_lif, pcp_old} seconds.  If\
    \ the path\n   identifier and timestamp carried in the SETUP message match a stored\n\
    \   path identifier and timestamp, the policy gateway considers the\n   message\
    \ to be a retransmission and does not forward the message.  If\n   the path identifier\
    \ carried in the SETUP message matches a stored\n   path identifier but the two\
    \ timestamps do not agree, the policy\n   gateway abandons path setup, logs the\
    \ event for network management,\n   and returns an ERROR message to the originator\
    \ via the previous\n   policy gateway.\n"
- title: 7.4.2.  Path Consistency with Configured Transit Policies
  contents:
  - "7.4.2.  Path Consistency with Configured Transit Policies\n   Provided the path\
    \ identifier in the SETUP message appears to be new,\n   the policy gateway proceeds\
    \ to determine whether the information\n   contained within the SETUP message\
    \ is consistent with the transit\n   policies configured for its domain.  The\
    \ policy gateway must locate\n   the source and destination domains, the source\
    \ host set and user\n   class identifier, and the domain-specific information\
    \ for its own\n   domain, within the SETUP message, in order to evaluate path\n\
    \   consistency.  If the policy gateway fails to recognize the source\n   user\
    \ class (or one or more of the requested services), it logs the\n   event for\
    \ network management but continues with path setup.  If the\n   policy gateway\
    \ fails to locate its domain within the SETUP message,\n   it abandons path setup,\
    \ logs the event for network management, and\n   returns an ERROR message to the\
    \ originator via the previous policy\n   gateway.  The originator responds by\
    \ tearing down the path and\n   subsequently removing the route from its cache.\n\
    \   Once the policy gateway locates its domain-specific portion of the\n   SETUP\
    \ message, it may encounter the following problems with the\n   contents:\n  \
    \ - The domain-specific portion lists a transit policy not configured\n     for\
    \ the domain.\n   - The domain-specific portion lists a virtual gateway not configured\n\
    \     for the domain.\n   In each case, the policy gateway abandons path setup,\
    \ logs the event\n   for network management, and returns an ERROR message to the\n\
    \   originator via the previous policy gateway.  These types of ERROR\n   messages\
    \ indicate to the originator that the route may have been\n   generated using\
    \ information from an out-of-date CONFIGURATION\n   message.\n   The originator\
    \ reacts to the receipt of such an ERROR message as\n   follows.  First, it tears\
    \ down the path and removes the route from\n   its cache.  Then, it issues to\
    \ a route server a ROUTE REQUEST message\n   containing a directive to refresh\
    \ the routing information database,\n   with the most recent CONFIGURATION message\
    \ from the domain that\n   issued the ERROR message, before generating a new route.\n\
    \   Once it verifies that its domain-specific information in the SETUP\n   message\
    \ is recognizable, the policy gateway then checks that the\n   information contained\
    \ within the SETUP message is consistent with the\n   transit policies configured\
    \ for its domain.  A policy gateway at the\n   entry to a domain checks path consistency\
    \ in the direction from\n   originator to target, if the enabled path directions\
    \ include\n   originator to target.  A policy gateway at the exit to a domain\n\
    \   checks path consistency in the direction from target to originator,\n   if\
    \ the enabled path directions include target to originator.\n   When evaluating\
    \ the consistency of the path with the transit policies\n   configured for the\
    \ domain, the policy gateway may encounter any of\n   the following problems with\
    \ SETUP message contents:\n   - A transit policy does not apply in the given direction\
    \ between the\n     virtual gateways listed in the SETUP message.\n   - A transit\
    \ policy denies access to traffic from the given host set\n     between the source\
    \ and destination domains listed in the SETUP\n     message.\n   - A transit policy\
    \ denies access to traffic from the source user\n     class listed in the SETUP\
    \ message.\n   - A transit policy denies access to traffic at the current time.\n\
    \   In each case, the policy gateway abandons path setup, logs the event\n   for\
    \ network management, and returns a REFUSE message to the\n   originator via the\
    \ previous policy gateway.  These types of REFUSE\n   messages indicate to the\
    \ originator that the route may have been\n   generated using information from\
    \ an out-of-date CONFIGURATION\n   message.  The REFUSE message also serves to\
    \ teardown the path.\n   The originator reacts to the receipt of such a REFUSE\
    \ message as\n   follows. First, it removes the route from its cache.  Then, it\
    \ issues\n   to a route server a ROUTE REQUEST message containing a directive\
    \ to\n   refresh the routing information database, with the most recent\n   CONFIGURATION\
    \ message from the domain that issued the REFUSE message,\n   before generating\
    \ a new route.\n"
- title: 7.4.3.  Path Consistency with Virtual Gateway Reachability
  contents:
  - "7.4.3.  Path Consistency with Virtual Gateway Reachability\n   Provided the information\
    \ contained in the SETUP message is consistent\n   with the transit policies configured\
    \ for its domain, the policy\n   gateway proceeds to determine whether the path\
    \ is consistent with the\n   reachability of the virtual gateway containing the\
    \ potential next\n   hop.  To determine virtual gateway reachability, the policy\
    \ gateway\n   uses information provided by VGP and by the intra-domain routing\n\
    \   procedure.\n   When evaluating the consistency of the path with virtual gateway\n\
    \   reachability, the policy gateway may encounter any of the following\n   problems:\n\
    \   - The virtual gateway containing the potential next hop is down.\n   - The\
    \ virtual gateway containing the potential next hop is not\n     reachable via\
    \ any intra-domain routes supporting the transit\n     policies listed in the\
    \ SETUP message.\n   - The next domain component listed in the SETUP message is\
    \ not\n     reachable.\n   Each of these determinations is made from the perspective\
    \ of a single\n   policy gateway and may not reflect actual reachability.  In\
    \ each\n   case, the policy gateway encountering such a problem returns a REFUSE\n\
    \   message to the previous policy gateway which then selects a different\n  \
    \ next policy gateway, in round-robin order, as described in\n   previously. \
    \ If the policy gateway receives the same response from\n   all next policy gateways\
    \ selected, it abandons path setup, logs the\n   event for network management,\
    \ and returns the REFUSE message to the\n   originator via the previous policy\
    \ gateway.  These types of REFUSE\n   messages indicate to the originator that\
    \ the route may have been\n   generated using information from an out-of-date\
    \ DYNAMIC message.  The\n   REFUSE message also serves to teardown the path.\n\
    \   The originator reacts to the receipt of such a REFUSE message as\n   follows.\
    \  First, it removes the route from its cache.  Then, it\n   issues to a route\
    \ server a ROUTE REQUEST message containing a\n   directive to refresh the routing\
    \ information database, with the most\n   recent DYNAMIC message from the domain\
    \ that issued the REFUSE\n   message, before generating a new route.\n"
- title: 7.4.4.  Obtaining Resources
  contents:
  - "7.4.4.  Obtaining Resources\n   Once the policy gateway determines that the SETUP\
    \ message contents\n   are consistent with the transit policies and virtual gateway\n\
    \   reachability of its domain, it attempts to gain resources for the new\n  \
    \ path.  For this version of IDPR, path resources consist of memory in\n   the\
    \ local forwarding information database.  However, in the future,\n   path resources\
    \ may also include reserved link bandwidth.\n   If the policy gateway does not\
    \ have sufficient resources to establish\n   the new path, it uses the following\
    \ algorithm to determine whether to\n   generate a REFUSE message for the new\
    \ path or a TEARDOWN message for\n   an existing path in favor of the new path.\
    \  There are two cases:\n   - No paths have been idle for more than pcp_idle (300)\
    \ seconds.  In\n     this case, the policy gateway returns a REFUSE message to\
    \ the\n     previous policy gateway.  This policy gateway then tries to select\n\
    \     a different next policy gateway, as described previously, provided\n   \
    \  the policy gateway that issued the REFUSE message was not the\n     target.\
    \ If the REFUSE message was issued by the target or if there\n     is no available\
    \ next policy gateway, the policy gateway returns\n     the REFUSE message to\
    \ the originator via the previous policy\n     gateway and logs the event for\
    \ network management.  The REFUSE\n     message serves to tear down the path.\n\
    \   - At least one path has been idle for more than pcp_idle seconds.  In\n  \
    \   this case, the policy gateway tears down an older path in order to\n     accommodate\
    \ the newer path and logs the event for network\n     management.  Specifically,\
    \ the policy gateway tears down the least\n     recently used path among those\
    \ that have been idle for longer than\n     pcp_idle seconds, resolving ties by\
    \ choosing the oldest such path.\n   If the policy gateway has sufficient resources\
    \ to establish the path,\n   it attempts to update its local forwarding information\
    \ database with\n   information about the path identifier, previous and next policy\n\
    \   gateways on the path, and directions in which the path should be\n   enabled\
    \ for data traffic transport.\n"
- title: 7.4.5  Target Response
  contents:
  - "7.4.5  Target Response\n   When an acceptable SETUP message successfully reaches\
    \ an entry policy\n   gateway in the destination or destination proxy domain,\
    \ this policy\n   gateway performs all of the SETUP message checks described in\
    \ the\n   above sections.  The policy gateway's path agent then becomes the\n\
    \   target, provided no checks fail, unless there is an explicit target\n   specified\
    \ in the SETUP message.  For example, remote route servers\n   act as originator\
    \ and target during RSQP message exchanges (see\n   section 5.2).  If the recipient\
    \ policy gateway is not the target, it\n   attempts to forward the SETUP message\
    \ to the target along an intra-\n   domain route.  However, if the target is not\
    \ reachable via intra-\n   domain routing, the policy gateway abandons path setup,\
    \ logs the\n   event for network management, and returns a REFUSE message to the\n\
    \   originator via the previous policy gateway.  The REFUSE message\n   serves\
    \ to tear down the path.\n   Once the SETUP message reaches the target, the target\
    \ determines\n   whether it has sufficient path resources.  The target generates\
    \ an\n   ACCEPT message, provided it has sufficient resources to establish the\n\
    \   path.  Otherwise, it generates a REFUSE message.\n   The target may choose\
    \ to use the reverse path to transport data\n   traffic to the source domain,\
    \ if the enabled path directions include\n   10 or 11.  However, the target must\
    \ first verify the consistency of\n   the reverse path with its own domain's configured\
    \ transit policies,\n   before sending data traffic over that path.\n"
- title: 7.4.6.  Originator Response
  contents:
  - "7.4.6.  Originator Response\n   The originator expects to receive an ACCEPT,\
    \ REFUSE, or ERROR message\n   in response to a SETUP message and reacts as follows:\n\
    \   - The originator receives an ACCEPT message, confirming successful\n     path\
    \ establishment.  To expedite data delivery, the originator may\n     forward\
    \ data messages along the path prior to receiving an ACCEPT\n     message, with\
    \ the understanding that there is no guarantee that the\n     path actually exists.\n\
    \   - The originator receives a REFUSE message or an ERROR message,\n     implying\
    \ that the path could not be successfully established.  In\n     response, the\
    \ originator attempts to set up a different path to the\n     same destination,\
    \ as long as the number of selected different paths\n     does not exceed setup_try\
    \ (3).  If the originator is unsuccessful\n     after setup_try attempts, it abandons\
    \ path setup and logs the event\n     for network management.\n   - The originator\
    \ fails to receive any response to the SETUP message\n     within setup_int microseconds\
    \ after transmission.  In this case,\n     the originator attempts path setup\
    \ using the same policy route and\n     a new path identifier, as long as the\
    \ number of path setup attempts\n     using the same route does not exceed setup_ret\
    \ (2).  If the\n     originator fails to receive a response to a SETUP message\
    \ after\n     setup_ret attempts, it logs the event for network management and\n\
    \     then proceeds as though it received a negative response, namely a\n    \
    \ REFUSE or an ERROR, to the SETUP message.  Specifically, it\n     attempts to\
    \ set up a different path to the same destination, or it\n     abandons path setup\
    \ altogether, depending on the value of\n     setup_try.\n"
- title: 7.4.7.  Path Life
  contents:
  - "7.4.7.  Path Life\n   Once set up, a path does not live forever.  A path agent\
    \ or policy\n   gateway may tear down an existing path, provided any of the following\n\
    \   conditions are true:\n   - The maximum path lifetime (in minutes, bytes, or\
    \ messages) has been\n     exceeded at the originator, the target, or an intermediate\
    \ policy\n     gateway.  In each case, the IDPR entity detecting path expiration\n\
    \     logs the event for network management and generates a TEARDOWN\n     message\
    \ as follows:\n      o The originator path agent generates a TEARDOWN message\
    \ for\n        propagation toward the target.\n      o The target path agent generates\
    \ a TEARDOWN message for\n        propagation toward the originator.\n      o\
    \ An intermediate policy gateway generates two TEARDOWN messages,\n        one\
    \ for propagation toward the originator and one for\n        propagation toward\
    \ the target.\n   - The previous or next policy gateway becomes unreachable, across\
    \ a\n     virtual gateway or across a domain according to a given transit\n  \
    \   policy, and the path is not reparable.  In either case, the policy\n     gateway\
    \ detecting the reachability problem logs the event for\n     network management\
    \ and generates a TEARDOWN message as follows:\n      o If the previous policy\
    \ gateway is unreachable, an intermediate\n        policy gateway generates a\
    \ TEARDOWN message for propagation to\n        the target.\n      o If the next\
    \ policy gateway is unreachable, an intermediate\n        policy gateway generates\
    \ a TEARDOWN message for propagation to\n        the originator.\n   - All of\
    \ the policy gateway's path resources are in use at the\n     originator, the\
    \ target, or an intermediate policy gateway, a new\n     path requires resources,\
    \ and the given existing path is expendable,\n     according to the least recently\
    \ used criterion discussed in section\n     7.4.4 above.  In each case, the IDPR\
    \ entity initiating path\n     preemption logs the event for network management\
    \ and generates a\n     TEARDOWN message as follows:\n      o The originator path\
    \ agent generates a TEARDOWN message for\n        propagation toward the originator.\n\
    \      o The target path agent generates a TEARDOWN message for\n        propagation\
    \ toward the originator.\n      o An intermediate policy gateway generates two\
    \ TEARDOWN messages,\n        one for propagation toward the originator and one\
    \ for\n        propagation toward the target.\n   Path teardown at a path agent\
    \ or policy gateway, whether initiated by\n   one of the above events, by receipt\
    \ of a TEARDOWN message, or by\n   receipt of a REFUSE message during path setup\
    \ (as discussed in the\n   previous sections), results in the path agent or policy\
    \ gateway\n   releasing all resources devoted to both directions of the path.\n"
- title: 7.5.  Path Failure and Recovery
  contents:
  - "7.5.  Path Failure and Recovery\n   When a policy gateway fails, it may not be\
    \ able to save information\n   pertaining to its established paths.  Thus, when\
    \ the policy gateway\n   returns to service, it may have no recollection of the\
    \ paths set up\n   through it and hence may no longer be able to forward data\
    \ messages\n   along these paths.  We expect that when a policy gateway fails,\
    \ it\n   will usually be out of service for long enough that the up/down\n   protocol\
    \ and the intra-domain routing procedure can detect that the\n   particular policy\
    \ gateway is no longer reachable.  In this case,\n   adjacent or neighbor policy\
    \ gateways that have set up paths through\n   the failed policy gateway and that\
    \ have detected the failure, attempt\n   local path repair (see section 7.5.2\
    \ below), and if unsuccessful,\n   issue TEARDOWN messages for all affected paths.\n"
- title: 7.5.1.  Handling Implicit Path Failures
  contents:
  - "7.5.1.  Handling Implicit Path Failures\n   Nevertheless, policy gateways along\
    \ a path must be able to handle the\n   case in which a policy gateway fails and\
    \ subsequently returns to\n   service without either the up/down protocol or the\
    \ intra-domain\n   routing procedure detecting the failure; we do not expect this\
    \ event\n   to occur often.  If the policy gateway, prior to failure, contained\n\
    \   forwarding information for several established paths, it may now\n   receive\
    \ many IDPR data messages containing unrecognized path\n   identifiers.  The policy\
    \ gateway should alert the data sources that\n   their paths through it are no\
    \ longer viable.\n   Policy gateways that receive IDPR data messages with unrecognized\n\
    \   path identifiers take one of the following two actions, depending\n   upon\
    \ their past failure record:\n   - The policy gateway has not failed in the past\
    \ pg_up (24) hour\n     period.  In this case, there are at least four possible\
    \ reasons for\n     the unrecognized path identifier in the data message:\n  \
    \    o The data message path identifier has been corrupted in a way\n        that\
    \ is not detectable by the integrity/authentication value, if\n        one is\
    \ present.\n      o The policy gateway has experienced a memory error.\n     \
    \ o The policy gateway failed sometime during the life of the path\n        and\
    \ source sent no data on the path for a period of pg_up hours\n        following\
    \ the failure.  Although paths may persist for more than\n        pg_up hours,\
    \ we expect that they will also be used more\n        frequently than once every\
    \ pg_up hours.\n      o The path was not successfully established, and the originator\n\
    \        sent data messages down the path prior to receiving a response\n    \
    \    to its SETUP message.\n      In all cases, the policy gateway discards the\
    \ data message and\n      logs the event for network management.\n   - The policy\
    \ gateway has failed at least once in the past pg_up hour\n     period.  Thus,\
    \ the policy gateway assumes that the unrecognized\n     path identifier in the\
    \ data message may be attributed to its\n     failure.  In response to the data\
    \ message, the policy gateway\n     generates an ERROR message containing the\
    \ unrecognized path\n     identifier.  The policy gateway then sends the ERROR\
    \ message back\n     to the entity from which it received the data message, which\
    \ should\n     be equivalent to the previous policy gateway on the path.\n   When\
    \ the previous policy gateway receives such an ERROR message, it\n   decides whether\
    \ the message is acceptable.  If the policy gateway\n   does not recognize the\
    \ path identifier contained in the ERROR\n   message, it does not find the ERROR\
    \ message acceptable and\n   subsequently discards the message.  However, if the\
    \ policy gateway\n   does find the ERROR message acceptable, it then determines\
    \ whether it\n   has already received an ACCEPT message for the given path.  If\
    \ the\n   policy gateway has not received an ACCEPT message for that path, it\n\
    \   discards the ERROR message and takes no further action.\n   If the policy\
    \ gateway has received an ACCEPT message for that path,\n   it then attempts path\
    \ repair, as described in section 7.5.2 below.\n   Only if path repair is unsuccessful\
    \ does the previous policy gateway\n   generate a TEARDOWN message for the path\
    \ and return it to the\n   originator.  The TEARDOWN message includes the domain\
    \ and virtual\n   gateway containing the policy gateway that failed, which aids\
    \ the\n   originator in selecting a new path that does not include the domain\n\
    \   containing the failed policy gateway.  This mechanism ensures that\n   path\
    \ agents quickly discover and recover from disrupted paths, while\n   guarding\
    \ against unwarranted path teardown.\n"
- title: 7.5.2.  Local Path Repair
  contents:
  - "7.5.2.  Local Path Repair\n   Failure of one of more entities on a given path\
    \ may render the path\n   unusable.  If the failure is within a domain, IDPR relies\
    \ on the\n   intra-domain routing procedure to find an alternate route across\
    \ the\n   domain, which leaves the path unaffected.  If the failure is in a\n\
    \   virtual gateway, policy gateways must bear the responsibility of\n   repairing\
    \ the path.  Policy gateways nearest to the failure are the\n   first to recognize\
    \ its existence and hence can react most quickly to\n   repair the path.\n   Relinquishing\
    \ control over path repair to policy gateways in other\n   domains may be unacceptable\
    \ to some domain administrators.  The\n   reason is that these policy gateways\
    \ cannot guarantee construction of\n   a path that satisfies the source policies\
    \ of the source domain, as\n   they have no knowledge of other domains' source\
    \ policies.\n   Nevertheless, limited local path repair is feasible, without\n\
    \   distributing either source policy information throughout an\n   internetwork\
    \ or detailed path information among policy gateways in\n   the same domain or\
    \ in the same virtual gateway.  We say that a path\n   is \"locally reparable\"\
    \ if there exists an alternate route between two\n   policy gateways, separated\
    \ by at most one virtual gateway, on the\n   path.  This definition covers path\
    \ repair in the presence of failed\n   routes between consecutive policy gateways\
    \ as well as failed policy\n   gateways themselves.\n   An IDPR entity attempts\
    \ local repair of an established path, in the\n   direction from originator to\
    \ target, immediately after detecting that\n   the next policy gateway on the\
    \ path is no longer reachable.  To\n   prevent multiple path repairs in response\
    \ to the same failure, we\n   have stipulated that path repair can only be initiated\
    \ in the\n   direction from originator to target.  The IDPR entity initiating\n\
    \   local path repair attempts to find an alternate path to the policy\n   gateway\
    \ immediately following the unreachable policy gateway on the\n   path.\n   Local\
    \ path repair minimizes the disruption of data traffic flow\n   caused by certain\
    \ types of failures along an established path.\n   Specifically, local path repair\
    \ can accommodate an individual failed\n   policy gateway or failed direct connection\
    \ between two adjacent\n   policy gateways.  However, it can only be attempted\
    \ through virtual\n   gateways containing multiple peer policy gateways.  Local\
    \ path repair\n   is not designed to repair paths traversing failed virtual gateways\
    \ or\n   domain partitions.  Whenever local path repair is impossible, the\n \
    \  failing path must be torn down.\n"
- title: 7.5.3.  Repairing a Path
  contents:
  - "7.5.3.  Repairing a Path\n   When an IDPR entity detects through an ERROR message\
    \ that the next\n   policy gateway has no knowledge of a given path, it generates\
    \ a\n   REPAIR message and forwards it to the next policy gateway.  This\n   REPAIR\
    \ message will reestablish the path through the next policy\n   gateway.\n   When\
    \ an entity detects that the next policy gateway on a path is no\n   longer reachable,\
    \ it takes one of the following actions, depending\n   upon whether the entity\
    \ is a member of the next policy gateway's\n   virtual gateway.\n   - If the entity\
    \ is not a member of the next policy gateway's virtual\n     gateway, then one\
    \ of the following two conditions must be true:\n      o The next policy gateway\
    \ has a peer that is reachable via an\n        intra-domain route consistent with\
    \ the requested services.  In\n        this case, the entity generates a REPAIR\
    \ message containing the\n        original SETUP message and forwards it to the\
    \ next policy\n        gateway's peer.\n      o The next policy gateway has no\
    \ peers that are reachable via\n        intra-domain routes consistent with the\
    \ requested services.  In\n        this case, the entity tears down the path back\
    \ to the\n        originator.\n   - If the entity is a member of the next policy\
    \ gateway's virtual\n   gateway, then one of the following four conditions must\
    \ be true:\n      o The next policy gateway has a peer that belongs to the same\n\
    \        domain component and is directly-connected to and reachable from\n  \
    \      the entity.  In this case, the entity generates a REPAIR message\n    \
    \    and forwards it to the next policy gateway's peer.\n      o The next policy\
    \ gateway has a peer that belongs to the same\n        domain component, is not\
    \ directly-connected to the entity, but\n        is directly-connected to and\
    \ reachable from one of the entity's\n        peers, which in turn is reachable\
    \ from the entity via an intra-\n        domain route consistent with the requested\
    \ services.  In this\n        case, the entity generates a REPAIR message and\
    \ forwards it to\n        its peer.\n      o The next policy gateway has no operational\
    \ peers within its\n        domain component, but is directly-connected to and\
    \ reachable\n        from one of the entity's peers, which in turn is reachable\
    \ from\n        the entity via an intra-domain route consistent with the\n   \
    \     requested services.  In this case, the entity generates a REPAIR\n     \
    \   message and forwards it to its peer.\n      o The next policy gateway has\
    \ no operational peers within its\n        domain component, and the entity has\
    \ no operational peers which\n        are both reachable via intra-domain routes\
    \ consistent with the\n        requested services and directly-connected to and\
    \ reachable from\n        the next policy gateway.  In this case, the entity tears\
    \ down\n        the path back to the originator.\n   A recipient of a REPAIR message\
    \ takes the following steps, depending\n   upon its relationship to the entity\
    \ that issued the REPAIR message.\n   - The recipient and the issuing entity are\
    \ in the same domain or in\n     same virtual gateway.  In this case, the recipient\
    \ extracts the\n     SETUP message contained within the REPAIR message and treats\
    \ the\n     message as it would any other SETUP message.  Specifically, the\n\
    \     recipient checks consistency of the path with its domain's transit\n   \
    \  policies and virtual gateway reachability.  If there are\n     unrecognized\
    \ portions of the SETUP message, the recipient generates\n     an ERROR message,\
    \ and if there are path inconsistencies, the\n     recipient generates a REFUSE\
    \ message.  In either case, the\n     recipient returns the corresponding message\
    \ to the policy gateway\n     from which it received the REPAIR message.  Otherwise,\
    \ if the\n     recipient accepts the REPAIR message, it updates its local\n  \
    \   forwarding information database accordingly and forwards the REPAIR\n    \
    \ message to a potential next policy gateway, according to the\n     information\
    \ contained in the enclosed SETUP message.\n   - The recipient and the issuing\
    \ entity are in different domains and\n     different virtual gateways.  In this\
    \ case, the recipient extracts\n     the SETUP message from the REPAIR message\
    \ and determines whether\n     the associated path matches any of its established\
    \ paths.  If the\n     path does not match an established path, the recipient\
    \ generates a\n     REFUSE message and returns it to the policy gateway from which\
    \ it\n     received the REPAIR message.  In response to the receipt of a\n   \
    \  REFUSE message, the policy gateway tries a different next policy\n     gateway.\n\
    \   The path is reparable, if a path match is discovered.  In this case,\n   the\
    \ recipient updates the path entry in the local forwarding\n   information database\
    \ and issues an ACCEPT message to the policy\n   gateway from which it received\
    \ the REPAIR message, which in turn\n   returns the message to the entity that\
    \ issued the REPAIR message.\n   The path is irreparable if all potential next\
    \ policy gateways have\n   been exhausted and a path match has yet to be discovered.\
    \  In this\n   case, the policy gateway that fails to locate a next policy gateway\n\
    \   issues a TEARDOWN message to return to the originator.\n   An IDPR entity\
    \ expects to receive an ACCEPT, TEARDOWN, REFUSE, or\n   ERROR message in response\
    \ to a REPAIR message and reacts to these\n   responses differently as follows:\n\
    \   - The entity always returns a TEARDOWN message to the originator via\n   \
    \  previous policy gateway.\n   - The entity does not return an ACCEPT message\
    \ to the originator, but\n     receipt of such a message indicates that the path\
    \ has been\n     successfully repaired.\n   - The entity infers that the path\
    \ is irreparable and subsequently\n     tears down the path and logs the event\
    \ for network management, upon\n     receipt of a REFUSE or ERROR message or when\
    \ no response to the\n     REPAIR message arrives within setup_int microseconds.\n\
    \   When an entity detects that the previous policy gateway on a path\n   becomes\
    \ unreachable, it expects to receive a REPAIR message within\n   setup_wait microseconds.\
    \  If the entity does not receive a REPAIR\n   message for the path within that\
    \ time, it infers that the path is\n   irreparable and subsequently tears down\
    \ the path and logs the event\n   for network management.\n"
- title: 7.6.  Path Control Message Formats
  contents:
  - "7.6.  Path Control Message Formats\n   The path control protocol number is equal\
    \ to 3.  We describe the\n   contents of each type of PCP message below.\n"
- title: 7.6.1.  SETUP
  contents:
  - "7.6.1.  SETUP\n   The SETUP message type is equal to 0.\n    0              \
    \     1                   2                   3\n    0 1 2 3 4 5 6 7 8 9 0 1 2\
    \ 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |                            PATH ID                            |\n   |  \
    \                                                             |\n   +-------------------------------+-------------------------------+\n\
    \   |            SRC AD             |            HST SET            |\n   +---------------+---------------+-------------------------------+\n\
    \   |      UCI      |    UNUSED     |            NUM RQS            |\n   +---------------+---------------+-------------------------------+\n\
    \   |            DST AD             |            TGT ENT            |\n   +-------------------------------+-------------------------------+\n\
    \   |            AD PTR             |\n   +-------------------------------+\n\
    \   For each requested service for the path:\n   +-------------------------------+-------------------------------+\n\
    \   |            RQS TYP            |            RQS LEN            |\n   +-------------------------------+-------------------------------+\n\
    \   |                            RQS SRV                            |\n   +---------------------------------------------------------------+\n\
    \   For each domain contained in the path:\n   +---------------+---------------+-------------------------------+\n\
    \   |    AD LEN     |      VG       |            ADJ AD             |\n   +---------------+---------------+-------------------------------+\n\
    \   |            ADJ CMP            |            NUM TP             |\n   +-------------------------------+-------------------------------+\n\
    \   |              TP               |\n   +-------------------------------+\n\
    \   PATH ID\n        (64 bits) Path identifier consisting of the numeric identifier\n\
    \        for the originator's domain (16 bits), the numeric identifier\n     \
    \   for the originator policy gateway or route server (16 bits), the\n       \
    \ path direction (2 bits), and the local path identifier (30\n        bits).\n\
    \   SRC AD (16 bits) Numeric identifier for the source domain, which may\n   \
    \     be different from the originator domain if the originator domain\n     \
    \   is a proxy for the source.\n   HST SET (16 bits) Numeric identifier for the\
    \ source's host set.\n   UCI (8 bits) Numeric identifier for the source user class.\
    \  The value\n        0 indicates that there is no particular source user class.\n\
    \   UNUSED (8 bits) Not currently used; must be set equal to 0.\n   NUM RQS (16\
    \ bits) Number of requested services.\n   DST AD (16 bits) Numeric identifier\
    \ for the destination domain, which\n        may be different from the target\
    \ domain if the target domain is\n        a proxy for the destination.\n   TGT\
    \ ENT (16 bits) Numeric identifier for the target entity.  A value\n        of\
    \ 0 indicates that there is no specific target entity.\n   AD PTR (16 bits) Byte\
    \ offset from the beginning of the message\n        indicating the location of\
    \ the beginning of the domain-specific\n        information, contained in the\
    \ right-most 15 bits.  The left-most\n        bit indicates whether the message\
    \ includes expedited data (1\n        expedited data, 0 no expedited data).\n\
    \   RQS TYP (16 bits) Numeric identifier for a type of requested service\n   \
    \     or source-specific information.  Valid requested services are\n        described\
    \ in section 5.5.2.  Valid source source-specific\n        information includes\
    \ the following types:\n        12.  MD4/RSA data message authentication (see\
    \ [16]).\n        13.  MD5/RSA data message authentication (see [17]).\n     \
    \   14.  Billing address (variable).\n        15.  Charge number (variable).\n\
    \   RQS LEN (16 bits) Length of the requested service or source-specific\n   \
    \     information, in bytes, beginning with the next field.\n   RQS SRV (variable)\
    \ Description of the requested service or source-\n        specific information.\n\
    \   AD LEN (8 bits) Length of the information associated with a\n        particular\
    \ domain on the route, in bytes, beginning with the\n        next field.\n   VG\
    \ (8 bits) Numeric identifier for an exit virtual gateway.\n   ADJ AD (16 bits)\
    \ Numeric identifier for an adjacent domain.\n   ADJ CMP (16 bits) Numeric identifier\
    \ for a component of the adjacent\n        domain.  Used to aid a policy gateway\
    \ in routing across a\n        virtual gateway connected to a partitioned domain.\n\
    \   NUM TP (16 bits) Number of transit policies that apply to the section\n  \
    \      of the path traversing the given domain component.\n   TP (16 bits) Numeric\
    \ identifier for a transit policy.\n"
- title: 7.6.2.  ACCEPT
  contents:
  - "7.6.2.  ACCEPT\n   The ACCEPT message type is equal to 1.\n    0            \
    \       1                   2                   3\n    0 1 2 3 4 5 6 7 8 9 0 1\
    \ 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |                            PATH ID                            |\n   |  \
    \                                                             |\n   +---------------+-----------------------------------------------+\n\
    \   |    RSN TYP    |                    REASON                     |\n   +---------------+-----------------------------------------------+\n\
    \   PATH ID\n        (64 bits) Path identifier contained in the original SETUP\n\
    \        message.\n   RSN TYP (optional, 8 bits) Numeric identifier for the reason\
    \ for\n        conditional path acceptance.\n   REASON (optional, variable) Description\
    \ of the reason for conditional\n        path acceptance.  Currently, no reasons\
    \ have been defined.\n"
- title: 7.6.3  REFUSE
  contents:
  - "7.6.3  REFUSE\n   The REFUSE message type is equal to 2.\n    0             \
    \      1                   2                   3\n    0 1 2 3 4 5 6 7 8 9 0 1\
    \ 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |                            PATH ID                            |\n   |  \
    \                                                             |\n   +---------------+-----------------------------------------------+\n\
    \   |    RSN TYP    |                    REASON                     |\n   +---------------+-----------------------------------------------+\n\
    \   PATH ID\n        (64 bits) Path identifier contained in the original SETUP\n\
    \        message.\n   RSN TYP (8 bits) Numeric identifier for the reason for path\
    \ refusal.\n   REASON (variable) Description of the reason for path refusal. \
    \ Valid\n        reasons include the following types:\n        1.  Transit policy\
    \ does not apply between the virtual gateways in a\n            given direction.\
    \  Numeric identifier for the transit policy (16\n            bits).\n       \
    \ 2.  Transit policy denies access to traffic from the host set between\n    \
    \        the source and destination domains.  Numeric identifier for the\n   \
    \         transit policy (16 bits).\n        3.  Transit policy denies access\
    \ to traffic from the source user\n            class.  Numeric identifier for\
    \ the transit policy (16 bits).\n        4.  Transit policy denies access to traffic\
    \ at the current time.\n            Numeric identifier for the transit policy\
    \ (16 bits).\n        5.  Virtual gateway is down.  Numeric identifier for the\
    \ virtual\n            gateway (8 bits) and associated adjacent domain (16 bits).\n\
    \        6.  Virtual gateway is not reachable according to the given transit\n\
    \            policy.  Numeric identifier for the virtual gateway (8 bits),\n \
    \           associated adjacent domain (16 bits), and transit policy (16\n   \
    \         bits).\n        7.  Domain component is not reachable.  Numeric identifier\
    \ for the\n            domain (16 bits) and the component (16 bits).\n       \
    \ 8.  Insufficient resources to establish the path.\n        9.  Target is not\
    \ reachable via intra-domain routing.\n        10. No existing path with the given\
    \ path identifier, in response to\n            a REPAIR message only.\n"
- title: 7.6.4.  TEARDOWN
  contents:
  - "7.6.4.  TEARDOWN\n   The TEARDOWN message type is equal to 3.\n    0        \
    \           1                   2                   3\n    0 1 2 3 4 5 6 7 8 9\
    \ 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |                            PATH ID                            |\n   |  \
    \                                                             |\n   +---------------+-----------------------------------------------+\n\
    \   |    RSN TYP    |                    REASON                     |\n   +---------------+-----------------------------------------------+\n\
    \   PATH ID\n        (64 bits) Path identifier contained in the original SETUP\n\
    \        message.\n   RSN TYP (8 bits) Numeric identifier for the reason for path\
    \ teardown.\n   REASON (variable) Description of the reason for path teardown.\
    \ Valid\n        reasons include the following types:\n   1.  Virtual gateway\
    \ is down.  Numeric identifier for the virtual\n       gateway (8 bits) and associated\
    \ adjacent domain (16 bits).\n   2.  Virtual gateway is not reachable according\
    \ to the given transit\n       policy.  Numeric identifier for the virtual gateway\
    \ (8 bits),\n       associated adjacent domain (16 bits), and transit policy (16\n\
    \       bits).\n   3.  Domain component is not reachable.  Numeric identifier\
    \ for the\n       domain (16 bits) and the component (16 bits).\n   4.  Maximum\
    \ path lifetime exceeded.\n   5.  Preempted path.\n   6.  Unable to repair path.\n"
- title: 7.6.5.  ERROR
  contents:
  - "7.6.5.  ERROR\n   The ERROR message type is equal to 4.\n    0              \
    \     1                   2                   3\n    0 1 2 3 4 5 6 7 8 9 0 1 2\
    \ 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |                            PATH ID                            |\n   |  \
    \                                                             |\n   +---------------+---------------+-------------------------------+\n\
    \   |      MSG      |    RSN TYP    |            REASON             |\n   +---------------+---------------+-------------------------------+\n\
    \   PATH ID\n        (64 bits) Path identifier contained in the path control or\
    \ data\n        message in error.\n   MSG (8 bits) Numeric identifier for the\
    \ type of path control message\n        in error.  This field is ignored for error\
    \ type 5.\n   RSN TYP (8 bits) Numeric identifier for the reason for the PCP\n\
    \        message error.\n   REASON (variable) Description of the reason for the\
    \ PCP message\n        error.  Valid reasons include the following types:\n  \
    \ 1.   Path identifier is already currently active.\n   2.   Domain does not appear\
    \ in the SETUP message.\n   3.   Transit policy is not configured for the domain.\
    \  Numeric\n   identifer for\n        the transit policy (16 bits).\n   4.   Virtual\
    \ gateway not configured for the domain.  Numeric\n   identifier\n        for\
    \ the virtual gateway (8 bits) and associated adjacent domain\n   (16\n      \
    \  bits).\n   5.   Unrecognized path identifier in an IDPR data message.\n"
- title: 7.6.6.  REPAIR
  contents:
  - "7.6.6.  REPAIR\n   The REPAIR message type is equal to 5.  A REPAIR message contains\
    \ the\n   original SETUP message only.\n"
- title: 7.6.7.  Negative Acknowledgements
  contents:
  - "7.6.7.  Negative Acknowledgements\n   When a policy gateway receives an unacceptable\
    \ PCP message that\n   passes the CMTP validation checks, it includes, in its\
    \ CMTP ACK, an\n   appropriate negative acknowledgement.  This information is\
    \ placed in\n   the INFORM field of the CMTP ACK (described previously in section\n\
    \   2.4); the numeric identifier for each type of PCP negative\n   acknowledgement\
    \ is contained in the left-most 8 bits of the INFORM\n   field.  Negative acknowledgements\
    \ associated with PCP include the\n   following types:\n   1.  Unrecognized PCP\
    \ message type.  Numeric identifier for the\n       unrecognized message type\
    \ (8 bits).\n   2.  Out-of-date PCP message.\n   3.  Unrecognized path identifier\
    \ (for all PCP messages except SETUP).\n       Numeric identifier for the unrecognized\
    \ path (64 bits).\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   Refer to sections 1.6, 1.7, and 2.3 for details\
    \ on security in IDPR.\n"
- title: 9.  Author's Address
  contents:
  - "9.  Author's Address\n   Martha Steenstrup\n   BBN Systems and Technologies\n\
    \   10 Moulton Street\n   Cambridge, MA 02138\n   Phone: (617) 873-3192\n   Email:\
    \ msteenst@bbn.com\n"
- title: References
  contents:
  - "References\n   [1]  Clark, D., \"Policy Routing in Internet Protocols\", RFC\
    \ 1102, May\n        1989.\n   [2]  Estrin, D., \"Requirements for Policy Based\
    \ Routing in the\n        Research Internet\", RFC 1125, November 1989.\n   [3]\
    \  Little, M., \"Goals and Functional Requirements for Inter-\n        Autonomous\
    \ System Routing\", RFC 1126, July 1989.\n   [4]  Breslau, L. and Estrin, D.,\
    \ \"Design of Inter-Administrative\n        Domain Routing Protocols\", Proceedings\
    \ of the ACM SIGCOMM '90\n        Symposium, September 1990.\n   [5]  Steenstrup,\
    \ M., \"An Architecture for Inter-Domain Policy Rout-\n        ing\", RFC 1478,\
    \ July 1993.\n   [6]  Austein, R., \"DNS Support for IDPR\", Work in Progress,\
    \ March\n        1993.\n   [7]  Bowns, H. and Steenstrup, M., \"Inter-Domain Policy\
    \ Routing Con-\n        figuration and Usage\", Work in Progress, July 1991.\n\
    \   [8]  Woodburn, R., \"Definitions of Managed Objects for Inter-Domain\n   \
    \     Policy Routing (Version 1)\", Work in Progress, March 1993.\n   [9]  McQuillan,\
    \ J., Richer, I., Rosen, E., and Bertsekas, D.,\n        \"ARPANET Routing Algorithm\
    \ Improvements: Second Semiannual\n        Technical Report\", BBN Report No.\
    \ 3940, October 1978.\n   [10] Moy, J., \"The OSPF Specification\", RFC 1131,\
    \ October 1989.\n   [11] Oran, D. (editor), \"Intermediate System to Intermediate\
    \ System\n        Routeing Exchange Protocol for Use in Conjunction with the Pro-\n\
    \        tocol for Providing the Connectionless-mode Network Service (ISO\n  \
    \      8473)\", ISO/IEC JTC1/SC6/WG2, October 1989.\n   [12] Estrin, D., and Tsudik,\
    \ G., \"Secure Control of Transit Internet-\n        work Traffic, TR-89-15, Computer\
    \ Science Department, University\n        of Southern California.\n   [13] Linn,\
    \ J., \"Privacy Enhancement for Internet Electronic Mail:\n        Part I - Message\
    \ Encipherment and Authentication Procedures\",\n        RFC 1113, August 1989.\n\
    \   [14] Kent, S., and Linn, J., \"Privacy Enhancement for Internet Elec-\n  \
    \      tronic Mail: Part II - Certificate-based Key Management\", RFC\n      \
    \  1114, August 1989.\n   [15] Linn, J., \"Privacy Enhancement for Internet Electronic\
    \ Mail:\n        Part III - Algorithms, Modes, and Identifiers\", RFC 1115, August\n\
    \        1989.\n   [16] Rivest, R., \"The MD4 Message-Digest Algorithm\", RFC\
    \ 1320, April\n        1992.\n   [17] Rivest, R., \"The MD5 Message-Digest Algorithm\"\
    , RFC 1321, April\n        1992.\n"
