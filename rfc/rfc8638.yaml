- contents:
  - '    IPv4 Multicast over an IPv6 Multicast in Softwire Mesh Networks

    '
  title: __initial_text__
- contents:
  - "Abstract\n   During the transition to IPv6, there are scenarios where a backbone\n
    \  network internally running one IP address family (referred to as the\n   internal
    IP or I-IP family) connects client networks running another\n   IP address family
    (referred to as the external IP or E-IP family).\n   In such cases, the I-IP backbone
    needs to offer both unicast and\n   multicast transit services to the client E-IP
    networks.\n   This document describes a mechanism for supporting multicast across\n
    \  backbone networks where the I-IP and E-IP protocol families differ.\n   The
    document focuses on the IPv4-over-IPv6 scenario, due to lack of\n   real-world
    use cases for the IPv6-over-IPv4 scenario.\n"
  title: Abstract
- contents:
  - "Status of This Memo\n   This is an Internet Standards Track document.\n   This
    document is a product of the Internet Engineering Task Force\n   (IETF).  It represents
    the consensus of the IETF community.  It has\n   received public review and has
    been approved for publication by the\n   Internet Engineering Steering Group (IESG).
    \ Further information on\n   Internet Standards is available in Section 2 of RFC
    7841.\n   Information about the current status of this document, any errata,\n
    \  and how to provide feedback on it may be obtained at\n   https://www.rfc-editor.org/info/rfc8638.\n"
  title: Status of This Memo
- contents:
  - "Copyright Notice\n   Copyright (c) 2019 IETF Trust and the persons identified
    as the\n   document authors.  All rights reserved.\n   This document is subject
    to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n
    \  (https://trustee.ietf.org/license-info) in effect on the date of\n   publication
    of this document.  Please review these documents\n   carefully, as they describe
    your rights and restrictions with respect\n   to this document.  Code Components
    extracted from this document must\n   include Simplified BSD License text as described
    in Section 4.e of\n   the Trust Legal Provisions and are provided without warranty
    as\n   described in the Simplified BSD License.\n"
  title: Copyright Notice
- contents:
  - "Table of Contents\n   1.  Introduction  . . . . . . . . . . . . . . . . . . .
    . . . . .   3\n   2.  Requirements Language . . . . . . . . . . . . . . . . .
    . . .   5\n   3.  Terminology . . . . . . . . . . . . . . . . . . . . . . . .
    .   5\n   4.  Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . .   6\n
    \  5.  Mesh Multicast Mechanism  . . . . . . . . . . . . . . . . . .   7\n     5.1.
    \ Mechanism Overview  . . . . . . . . . . . . . . . . . . .   7\n     5.2.  Group
    Address Mapping . . . . . . . . . . . . . . . . . .   7\n     5.3.  Source Address
    Mapping  . . . . . . . . . . . . . . . . .   8\n     5.4.  Routing Mechanism .
    . . . . . . . . . . . . . . . . . . .   9\n   6.  Control-Plane Functions of AFBR
    . . . . . . . . . . . . . . .  10\n     6.1.  E-IP (*,G) and (S,G) State Maintenance
    \ . . . . . . . . .  10\n     6.2.  I-IP (S',G') State Maintenance  . . . . .
    . . . . . . . .  10\n     6.3.  E-IP (S,G,rpt) State Maintenance  . . . . . .
    . . . . . .  10\n     6.4.  Inter-AFBR Signaling  . . . . . . . . . . . . . .
    . . . .  10\n     6.5.  SPT Switchover  . . . . . . . . . . . . . . . . . . .
    . .  13\n     6.6.  Other PIM Message Types . . . . . . . . . . . . . . . . .
    \ 13\n     6.7.  Maintenance of Other PIM States . . . . . . . . . . . . .  13\n
    \  7.  Data-Plane Functions of the AFBR  . . . . . . . . . . . . . .  13\n     7.1.
    \ Process and Forward Multicast Data  . . . . . . . . . . .  13\n     7.2.  TTL
    or Hop Count  . . . . . . . . . . . . . . . . . . . .  14\n     7.3.  Fragmentation
    . . . . . . . . . . . . . . . . . . . . . .  14\n   8.  Packet Format and Translation
    . . . . . . . . . . . . . . . .  14\n   9.  Softwire Mesh Multicast Encapsulation
    . . . . . . . . . . . .  16\n   10. Security Considerations . . . . . . . . .
    . . . . . . . . . .  16\n   11. IANA Considerations . . . . . . . . . . . . .
    . . . . . . . .  16\n   12. Normative References  . . . . . . . . . . . . . .
    . . . . . .  16\n   Acknowledgements  . . . . . . . . . . . . . . . . . . . .
    . . . .  18\n   Authors' Addresses  . . . . . . . . . . . . . . . . . . . . .
    . .  18\n"
  title: Table of Contents
- contents:
  - "1.  Introduction\n   During the transition to IPv6, there are scenarios where
    a backbone\n   network internally running one IP address family (referred to as
    the\n   internal IP or I-IP family) connects client networks running another\n
    \  IP address family (referred to as the external IP or E-IP family).\n   One
    solution is to leverage the multicast functions inherent in the\n   I-IP backbone
    to efficiently forward client E-IP multicast packets\n   inside an I-IP core tree.
    \ The I-IP tree is rooted at one or more\n   ingress Address Family Border Routers
    (AFBRs) [RFC5565] and branches\n   out to one or more egress AFBRs.\n   [RFC4925]
    outlines the requirements for the softwire mesh scenario\n   and includes support
    for multicast traffic.  It is likely that client\n   E-IP multicast sources and
    receivers will reside in different client\n   E-IP networks connected to an I-IP
    backbone network.  This requires\n   the source-rooted or shared tree of the client
    E-IP to traverse the\n   I-IP backbone network.\n   This could be accomplished
    by reusing the multicast VPN (MVPN)\n   approach outlined in [RFC6513].  MVPN-like
    schemes can support the\n   softwire mesh scenario and achieve a \"many-to-one\"
    mapping between\n   the E-IP client multicast trees and the transit-core multicast
    trees.\n   The advantage of this approach is that the number of trees in the\n
    \  I-IP backbone network scales less than linearly with the number of\n   E-IP
    client trees.  Corporate enterprise networks, and by extension\n   multicast VPNs,
    have been known to run applications that create too\n   many (S,G) states, which
    are source-specific states related to a\n   specified multicast group [RFC7761]
    [RFC7899].  Aggregation at the\n   edge contains the (S,G) states for customers'
    VPNs and these need to\n   be maintained by the network operator.  The disadvantage
    of this\n   approach is the possibility of inefficient bandwidth and resource\n
    \  utilization when multicast packets are delivered to a receiving AFBR\n   with
    no attached E-IP receivers.\n   [RFC8114] provides a solution for delivering IPv4
    multicast services\n   over an IPv6 network, but it mainly focuses on the DS-Lite
    scenario\n   [RFC6333], where IPv4 addresses assigned by a broadband service\n
    \  provider are shared among customers.  This document describes a\n   detailed
    solution for the IPv4-over-IPv6 softwire mesh scenario,\n   where client networks
    run IPv4 and the backbone network runs IPv6.\n   Internet-style multicast is somewhat
    different from the scenario in\n   [RFC8114] in that the trees are source-rooted
    and relatively sparse.\n   The need for multicast aggregation at the edge (where
    many customer\n   multicast trees are mapped to one or more backbone multicast
    trees)\n   does not exist and to date has not been identified.  Thus, the need\n
    \  for alignment between the E-IP and I-IP multicast mechanisms emerges.\n   [RFC5565]
    describes the \"Softwire Mesh Framework\".  This document\n   provides a more
    detailed description of how one-to-one mapping\n   schemes ([RFC5565], Section
    11.1) for IPv4-over-IPv6 multicast can be\n   achieved.\n   Figure 1 shows an
    example of how a softwire mesh network can support\n   multicast traffic.  A multicast
    source S is located in one E-IP\n   client network, while candidate E-IP group
    receivers are located in\n   the same or different E-IP client networks that all
    share a common\n   I-IP transit network.  When E-IP sources and receivers are
    not local\n   to each other, they can only communicate with each other through
    the\n   I-IP core.  There may be several E-IP sources for a single multicast\n
    \  group residing in different client E-IP networks.  In the case of\n   shared
    trees, the E-IP sources, receivers, and rendezvous points\n   (RPs) might be located
    in different client E-IP networks.  In the\n   simplest case, a single operator
    manages the resources of the I-IP\n   core, although the inter-operator case is
    also possible and so not\n   precluded.\n                   +---------+          +---------+\n
    \                  |         |          |         |  +--------+\n                   |
    \ E-IP   |          |  E-IP   +--+Source S|\n                   | network |          |
    network |  +--------+\n                   +---+-----+          +--+------+\n                       |
    \                  |\n                     +-+--------+  +-------+--+\n                     |
    \         |  | upstream |\n                   +-|   AFBR   +--+   AFBR   |-+\n
    \                  | +----------+  +----------+ |\n                   |                            |
    \ E-IP multicast\n                   |      I-IP transit core     |  packets are
    forwarded\n                   |                            |  across the I-IP\n
    \                  | +----------+  +----------+ |  transit core\n                   +-|downstream|
    \ |downstream|-+\n                     |   AFBR   |--|   AFBR   |\n                     +--+-------+
    \ +--------+-+\n                        |                   |\n                    +---+----+
    \         +---+----+\n       +--------+   |        |          |        |  +--------+\n
    \      |Receiver+---+  E-IP  |          |  E-IP  +--+Receiver|\n       +--------+
    \  |network |          |network |  +--------+\n                    +--------+
    \         +--------+\n                Figure 1: Softwire Mesh Multicast Framework\n"
  title: 1.  Introduction
- contents:
  - "2.  Requirements Language\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\",
    \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"NOT
    RECOMMENDED\", \"MAY\", and\n   \"OPTIONAL\" in this document are to be interpreted
    as described in\n   BCP 14 [RFC2119] [RFC8174] when, and only when, they appear
    in all\n   capitals, as shown here.\n"
  title: 2.  Requirements Language
- contents:
  - "3.  Terminology\n   The following terminology is used in this document.\n   o
    \ Address Family Border Router (AFBR) - A router interconnecting two\n      or
    more networks using different IP address families.\n      Additionally, in the
    context of softwire mesh multicast, the AFBR\n      runs E-IP and I-IP control
    planes to maintain E-IP and I-IP\n      multicast states respectively and performs
    the appropriate\n      encapsulation/decapsulation of client E-IP multicast packets
    for\n      transport across the I-IP core.  An AFBR will act as a source and/\n
    \     or receiver in an I-IP multicast tree.\n   o  Upstream AFBR: An AFBR that
    is closer to the source of a multicast\n      data flow.\n   o  Downstream AFBR:
    An AFBR that is closer to a receiver of a\n      multicast data flow.\n   o  I-IP
    (Internal IP): This refers to the IP address family that is\n      supported by
    the core network.  In this document, the I-IP is\n      IPv6.\n   o  E-IP (External
    IP): This refers to the IP address family that is\n      supported by the client
    network(s) attached to the I-IP transit\n      core.  In this document, the E-IP
    is IPv4.\n   o  I-IP core tree: A distribution tree rooted at one or more AFBR\n
    \     source nodes and branched out to one or more AFBR leaf nodes.  An\n      I-IP
    core tree is built using standard IP or MPLS multicast\n      signaling protocols
    (in this document, we focus on IP multicast)\n      operating exclusively inside
    the I-IP core network.  An I-IP core\n      tree is used to forward E-IP multicast
    packets belonging to E-IP\n      trees across the I-IP core.  Another name for
    an I-IP core tree is\n      multicast or multipoint softwire.\n   o  E-IP client
    tree: A distribution tree rooted at one or more hosts\n      or routers located
    inside a client E-IP network and branched out\n      to one or more leaf nodes
    located in the same or different client\n      E-IP networks.\n   o  uPrefix64:
    The /96 unicast IPv6 prefix for constructing an\n      IPv4-embedded IPv6 unicast
    address [RFC8114].\n   o  mPrefix64: The /96 multicast IPv6 prefix for constructing
    an\n      IPv4-embedded IPv6 multicast address [RFC8114].\n   o  PIMv4, PIMv6:
    Refer to [RFC8114].\n   o  Inter-AFBR signaling: A mechanism used by downstream
    AFBRs to send\n      PIMv6 messages to the upstream AFBR.\n"
  title: 3.  Terminology
- contents:
  - "4.  Scope\n   This document focuses on the IPv4-over-IPv6 scenario, as shown
    in the\n   following diagram.\n                   +---------+        +---------+\n
    \                  |  IPv4   |        |  IPv4   |  +--------+\n                   |
    Client  |        | Client  |--+Source S|\n                   | Network |        |
    Network |  +--------+\n                   +----+----+        +----+----+\n                        |
    \                 |\n                     +--+-------+  +-------+--+\n                     |
    \         |  | Upstream |\n                   +-+   AFBR   +--+   AFBR   |-+\n
    \                  | +----------+  +----------+ |\n                   |                            |\n
    \                  |      IPv6 transit core     |\n                   |                            |\n
    \                  | +----------+  +----------+ |\n                   +-+Downstream+--+Downstream+-+\n
    \                    |   AFBR   |  |   AFBR   |\n                     +--+-------+
    \ +-------+--+\n                        |                  |\n                   +----+----+
    \       +----+----+\n       +--------+  |  IPv4   |        |  IPv4   |  +--------+\n
    \      |Receiver+--+ Client  |        | Client  +--+Receiver|\n       +--------+
    \ | Network |        | Network |  +--------+\n                   +---------+        +---------+\n
    \                    Figure 2: IPv4-over-IPv6 Scenario\n   In Figure 2, the E-IP
    client networks run IPv4, and the I-IP core\n   runs IPv6.\n   Because of the
    much larger IPv6 group address space, the client E-IP\n   tree can be mapped to
    a specific I-IP core tree.  This simplifies\n   operations on the AFBR because
    it becomes possible to algorithmically\n   map an IPv4 group/source address to
    an IPv6 group/source address and\n   vice versa.\n   The IPv4-over-IPv6 scenario
    is an emerging requirement as network\n   operators build out native IPv6 backbone
    networks.  These networks\n   support native IPv6 services and applications, but,
    in many cases,\n   support for legacy IPv4 unicast and multicast services will
    also need\n   to be accommodated.\n"
  title: 4.  Scope
- contents:
  - '5.  Mesh Multicast Mechanism

    '
  - contents:
    - "5.1.  Mechanism Overview\n   Routers in the client E-IP networks have routes
      to all other client\n   E-IP networks.  Through PIMv4 messages, E-IP hosts and
      routers have\n   discovered or learnt of IPv4 addresses that are in (S,G) or
      (*,G)\n   state [RFC7761].  Any I-IP multicast state instantiated in the core\n
      \  is referred to as (S',G') or (*,G') and is separated from E-IP\n   multicast
      state.\n   Suppose a downstream AFBR receives an E-IP PIM Join/Prune message\n
      \  from the E-IP network for either an (S,G) tree or a (*,G) tree.  The\n   AFBR
      translates the PIMv4 message into a PIMv6 message with the\n   latter being
      directed towards the I-IP IPv6 address of the upstream\n   AFBR.  When the PIMv6
      message arrives at the upstream AFBR, it is\n   translated back into a PIMv4
      message.  The result of these actions is\n   the construction of E-IP trees
      and a corresponding I-IP tree in the\n   I-IP network.  An example of the packet
      format and translation is\n   provided in Section 8.\n   In this case, it is
      incumbent upon the AFBRs to perform PIM message\n   conversions in the control
      plane and IP group address conversions or\n   mappings in the data plane.  The
      AFBRs perform an algorithmic, one-\n   to-one mapping of IPv4 to IPv6.\n"
    title: 5.1.  Mechanism Overview
  - contents:
    - "5.2.  Group Address Mapping\n   A simple algorithmic mapping between IPv4 multicast
      group addresses\n   and IPv6 group addresses is performed.  Figure 3 is provided
      as a\n   reminder of the format:\n   +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n
      \  | 0-------------32--40--48--56--64--72--80--88--96-----------127|\n   +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n
      \  |                    mPrefix64                  | group address |\n   +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n
      \          Figure 3: IPv4-Embedded IPv6 Multicast Address Format\n   An IPv6
      multicast prefix (mPrefix64) is provisioned on each AFBR.\n   AFBRs will prepend
      the prefix to an IPv4 multicast group address when\n   translating it to an
      IPv6 multicast group address.\n   The construction of the mPrefix64 for Source-Specific
      Multicast (SSM)\n   is the same as the construction of the mPrefix64 described
      in\n   Section 5 of [RFC8114].\n   With this scheme, each IPv4 multicast address
      can be mapped to an\n   IPv6 multicast address (with the assigned prefix), and
      each IPv6\n   multicast address with the assigned prefix can be mapped to an
      IPv4\n   multicast address.  The group address translation algorithm is\n   specified
      in Section 5.2 of [RFC8114].\n"
    title: 5.2.  Group Address Mapping
  - contents:
    - "5.3.  Source Address Mapping\n   There are two kinds of multicast: Any-Source
      Multicast (ASM) and SSM.\n   Considering that the I-IP network and E-IP network
      may support\n   different kinds of multicast, the source address translation
      rules\n   needed to support all possible scenarios may become very complex.\n
      \  But since SSM can be implemented with a strict subset of the PIM-SM\n   protocol
      mechanisms [RFC7761], we can treat the I-IP core as SSM-only\n   to make it
      as simple as possible.  There then remain only two\n   scenarios to be discussed
      in detail:\n   o  E-IP network supports SSM\n      One possible way to make
      sure that the translated PIMv6 message\n      reaches the upstream AFBR is to
      set S' to a virtual IPv6 address\n      that leads to the upstream AFBR.  The
      unicast address translation\n      should be achieved according to [RFC6052].\n
      \  o  E-IP network supports ASM\n      The (S,G) source list entry and the (*,G)
      source list entry differ\n      only in that the latter has both the WildCard
      (WC) and RPT bits of\n      the Encoded-Source-Address set, while with the former,
      the bits\n      are cleared.  (See Section 4.9.5.1 of [RFC7761].)  As a result,\n
      \     the source list entries in (*,G) messages can be translated into\n      source
      list entries in (S',G') messages by clearing both the WC\n      and RPT bits
      at downstream AFBRs, and vice versa for the reverse\n      translation at upstream
      AFBRs.\n"
    title: 5.3.  Source Address Mapping
  - contents:
    - "5.4.  Routing Mechanism\n   With mesh multicast, PIMv6 messages originating
      from a downstream\n   AFBR need to be propagated to the correct upstream AFBR,
      and every\n   AFBR needs the /96 prefix in the IPv4-embedded IPv6 source address\n
      \  format [RFC6052].\n   To achieve this, every AFBR MUST announce the address
      of one of its\n   E-IPv4 interfaces in the \"v4\" field [RFC6052] alongside
      the\n   corresponding uPrefix46.  The announcement MUST be sent to the other\n
      \  AFBRs through Multiprotocol BGP (MBGP) [RFC4760].  Every uPrefix64\n   that
      an AFBR announces MUST be unique.  \"uPrefix64\" is an IPv6\n   prefix, and
      the distribution mechanism is the same as the traditional\n   mesh unicast scenario.\n
      \  As the \"v4\" field is an E-IP address, and BGP messages are not\n   tunneled
      through softwires or any other mechanism specified in\n   [RFC5565], AFBRs MUST
      be able to transport and encode/decode BGP\n   messages that are carried over
      the I-IP, and whose Network Layer\n   Reachability Information (NLRI) and next
      hop (NH) are of the E-IP\n   address family.\n   In this way, when a downstream
      AFBR receives an E-IP PIM (S,G)\n   message, it can translate this message into
      (S',G') by looking up the\n   IP address of the corresponding AFBR's E-IP interface.
      \ Since the\n   uPrefix64 of S' is unique and is known to every router in the
      I-IP\n   network, the translated message will be forwarded to the\n   corresponding
      upstream AFBR, and the upstream AFBR can translate the\n   message back to (S,G).\n
      \  When a downstream AFBR receives an E-IP PIM (*,G) message, S' can be\n   generated
      with the \"source address\" field set to * (the wildcard\n   value).  The translated
      message will be forwarded to the\n   corresponding upstream AFBR.  Every PIM
      router within a PIM domain\n   MUST be able to map a particular multicast group
      address to the same\n   RP when the source address is set to the wildcard value.
      \ (See\n   Section 4.7 of [RFC7761].)  So, when the upstream AFBR checks the\n
      \  \"source address\" field of the message, it finds the IPv4 address of\n   the
      RP and ascertains that this was originally a (*,G) message.  This\n   is then
      translated back to the (*,G) message and processed.\n"
    title: 5.4.  Routing Mechanism
  title: 5.  Mesh Multicast Mechanism
- contents:
  - "6.  Control-Plane Functions of AFBR\n   AFBRs are responsible for the functions
    detailed in the subsections\n   that follow.\n"
  - contents:
    - "6.1.  E-IP (*,G) and (S,G) State Maintenance\n   E-IP (*,G) and (S,G) state
      maintenance for an AFBR is the same as\n   E-IP (*,G) and (S,G) state maintenance
      for a multicast AFTR (mAFTR)\n   described in Section 7.2 of [RFC8114].\n"
    title: 6.1.  E-IP (*,G) and (S,G) State Maintenance
  - contents:
    - "6.2.  I-IP (S',G') State Maintenance\n   It is possible that the I-IP transit
      core runs another, non-transit,\n   I-IP PIM-SSM instance.  Since the translated
      source address starts\n   with the unique \"Well-Known\" prefix or the ISP-defined
      prefix that\n   MUST NOT be used by another service provider, mesh multicast
      will not\n   influence non-transit PIM-SSM multicast at all.  When an AFBR\n
      \  receives an I-IP (S',G') message, it MUST check S'.  If S' starts\n   with
      the unique prefix, then the message is actually a translated\n   E-IP (S,G)
      or (*,G) message, and the AFBR translates this message\n   back to a PIMv4 message
      and processes it.\n"
    title: 6.2.  I-IP (S',G') State Maintenance
  - contents:
    - "6.3.  E-IP (S,G,rpt) State Maintenance\n   When an AFBR wishes to propagate
      a Join/Prune(S,G,rpt) message\n   [RFC7761] to an I-IP upstream router, the
      AFBR MUST operate as\n   specified in Sections 6.5 and 6.6.\n"
    title: 6.3.  E-IP (S,G,rpt) State Maintenance
  - contents:
    - "6.4.  Inter-AFBR Signaling\n   Assume that one downstream AFBR has joined an
      RPT of (*,G) and a\n   shortest path tree (SPT) of (S,G) and decided to perform
      an SPT\n   switchover.  (See Section 4.2.1 of [RFC7761].)  According to\n   [RFC7761],
      it should propagate a Prune(S,G,rpt) message along with\n   the periodic Join(*,G)
      message upstream towards the RP.  However,\n   routers in the I-IP transit core
      do not process (S,G,rpt) messages\n   since the I-IP transit core is treated
      as SSM only.  As a result, the\n   downstream AFBR is unable to prune S from
      this RPT, so it will\n   receive two copies of the same data for (S,G).  In
      order to solve\n   this problem, we introduce a new mechanism for downstream
      AFBRs to\n   inform upstream AFBRs of pruning any given S from an RPT.\n   When
      a downstream AFBR wishes to propagate an (S,G,rpt) message\n   upstream, it
      SHOULD encapsulate the (S,G,rpt) message, then send the\n   encapsulated unicast
      message to the corresponding upstream AFBR,\n   which we call \"RP'\".\n   When
      RP' receives this encapsulated message, it MUST decapsulate the\n   message
      as in the unicast scenario and retrieve the original\n   (S,G,rpt) message.
      \ The incoming interface of this message may be\n   different from the outgoing
      interface that propagates multicast data\n   to the corresponding downstream
      AFBR, and there may be other\n   downstream AFBRs that need to receive multicast
      data for (S,G) from\n   this incoming interface, so RP' should not simply process
      this\n   message as specified in [RFC7761] on the incoming interface.\n   To
      solve this problem, we introduce an \"interface agent\" to process\n   all the
      encapsulated (S,G,rpt) messages the upstream AFBR receives.\n   The interface
      agent's RP' should prune S from the RPT of group G when\n   no downstream AFBR
      is subscribed to receive multicast data for (S,G)\n   along the RPT.\n   In
      this way, we ensure that downstream AFBRs will not miss any\n   multicast data
      that they need.  The cost of this is that multicast\n   data for (S,G) will
      be duplicated along the RPT received by AFBRs\n   affected by the SPT switchover,
      if at least one downstream AFBR\n   exists that has not yet sent Prune(S,G,rpt)
      messages to the upstream\n   AFBR.\n   In certain deployment scenarios (e.g.,
      if there is only a single\n   downstream router), the interface agent function
      is not required.\n   The mechanism used to achieve this is left to the implementation.\n
      \  The following diagram provides one possible solution for an\n   \"interface
      agent\" implementation:\n          +----------------------------------------+\n
      \         |                                        |\n          |       +-----------+----------+
      \        |\n          |       |  PIM-SM   |    UDP   |         |\n          |
      \      +-----------+----------+         |\n          |          ^                |
      \           |\n          |          |                |            |\n          |
      \         |                v            |\n          |       +----------------------+
      \        |\n          |       |       I/F Agent      |         |\n          |
      \      +----------------------+         |\n          |   PIM    ^                |
      multicast  |\n          | messages |                |   data     |\n          |
      \         |  +-------------+---+        |\n          |       +--+--|-----------+
      \    |        |\n          |       |     v           |     v        |\n          |
      \    +--------- +     +----------+      |\n          |     | I-IP I/F |     |
      I-IP I/F |      |\n          |     +----------+     +----------+      |\n          |
      \       ^     |          ^     |        |\n          |        |     |          |
      \    |        |\n          +--------|-----|----------|-----|--------+\n                   |
      \    v          |     v\n             Figure 4: Interface Agent Implementation
      Example\n   Figure 4 shows an example of an interface agent implementation using\n
      \  UDP encapsulation.  The interface agent has two responsibilities: In\n   the
      control plane, it should work as a real interface that has joined\n   (*,G),
      representing all the I-IP interfaces that are outgoing\n   interfaces of the
      (*,G) state machine, and it should process the\n   (S,G,rpt) messages received
      from all the I-IP interfaces.\n   The interface agent maintains downstream (S,G,rpt)
      state machines for\n   every downstream AFBR, and it submits Prune(S,G,rpt)
      messages to the\n   PIM-SM module only when every (S,G,rpt) state machine is
      in the\n   Prune(P) or PruneTmp(P') state, which means that no downstream AFBR\n
      \  is subscribed to receive multicast data for (S,G) along the RPT of G.\n   Once
      a (S,G,rpt) state machine changes to NoInfo (NI) state, which\n   means that
      the corresponding downstream AFBR has switched to receive\n   multicast data
      for (S,G) along the RPT again, the interface agent\n   MUST send a Join(S,G,rpt)
      to the PIM-SM module immediately.\n   In the data plane, upon receiving a multicast
      data packet, the\n   interface agent MUST encapsulate it at first, then propagate
      the\n   encapsulated packet from every I-IP interface.\n   NOTICE: It is possible
      that an E-IP neighbor of RP' has joined the\n   RPT of G, so the per-interface
      state machine for receiving E-IP Join/\n   Prune(S,G,rpt) messages should be
      preserved.\n"
    title: 6.4.  Inter-AFBR Signaling
  - contents:
    - "6.5.  SPT Switchover\n   After a new AFBR requests the receipt of traffic destined
      for a\n   multicast group, it will receive all the data from the RPT at first.\n
      \  At this time, every downstream AFBR will receive multicast data from\n   any
      source from this RPT, in spite of whether they have switched over\n   to an
      SPT or not.\n   To minimize this redundancy, it is recommended that every AFBR's\n
      \  SwitchToSptDesired(S,G) function employs the \"switch on first packet\"\n
      \  policy.  In this way, the delay in switchover to SPT is kept as small\n   as
      possible, and after the moment that every AFBR has performed the\n   SPT switchover
      for every S of group G, no data will be forwarded in\n   the RPT of G, thus
      no more unnecessary duplication will be produced.\n"
    title: 6.5.  SPT Switchover
  - contents:
    - "6.6.  Other PIM Message Types\n   In addition to Join or Prune, other message
      types exist, including\n   Register, Register-Stop, Hello and Assert.  Register
      and Register-\n   Stop messages are sent by unicast, while Hello and Assert
      messages\n   are only used between directly linked routers to negotiate with
      each\n   other.  It is not necessary to translate these for forwarding, thus\n
      \  the processing of these messages is out of scope for this document.\n"
    title: 6.6.  Other PIM Message Types
  - contents:
    - "6.7.  Maintenance of Other PIM States\n   In addition to states mentioned above,
      other states exist, including\n   (*,*,RP) and I-IP (*,G') state.  Since we
      treat the I-IP core as SSM\n   only, the maintenance of these states is out
      of scope for this\n   document.\n"
    title: 6.7.  Maintenance of Other PIM States
  title: 6.  Control-Plane Functions of AFBR
- contents:
  - '7.  Data-Plane Functions of the AFBR

    '
  - contents:
    - "7.1.  Process and Forward Multicast Data\n   Refer to Section 7.4 of [RFC8114].
      \ If there is at least one outgoing\n   interface whose IP address family is
      different from the incoming\n   interface, the AFBR MUST encapsulate this packet
      with\n   mPrefix64-derived and uPrefix64-derived IPv6 addresses to form an\n
      \  IPv6 multicast packet.\n"
    title: 7.1.  Process and Forward Multicast Data
  - contents:
    - "7.2.  TTL or Hop Count\n   Upon encapsulation, the TTL and hop count in the
      outer header SHOULD\n   be set by policy.  Upon decapsulation, the TTL and hop
      count in the\n   inner header SHOULD be modified by policy; it MUST NOT be incremented\n
      \  and it MAY be decremented to reflect the cost of tunnel forwarding.\n   Besides,
      processing of TTL and hop count information in protocol\n   headers depends
      on the tunneling technology, which is out of scope of\n   this document.\n"
    title: 7.2.  TTL or Hop Count
  - contents:
    - "7.3.  Fragmentation\n   The encapsulation performed by an upstream AFBR will
      increase the\n   size of packets.  As a result, the outgoing I-IP link MTU may
      not\n   accommodate the larger packet size.  It is not always possible for\n
      \  core operators to increase the MTU of every link, thus source\n   fragmentation
      after encapsulation and reassembling of encapsulated\n   packets MUST be supported
      by AFBRs [RFC5565].  Path MTU Discovery\n   (PMTUD) [RFC8201] SHOULD be enabled,
      and ICMPv6 packets MUST NOT be\n   filtered in the I-IP network.  Fragmentation
      and tunnel configuration\n   considerations are provided in Section 8 of [RFC5565].
      \ The detailed\n   procedure can be referred in Section 7.2 of [RFC2473].\n"
    title: 7.3.  Fragmentation
  title: 7.  Data-Plane Functions of the AFBR
- contents:
  - "8.  Packet Format and Translation\n   Because the PIM-SM specification is independent
    of the underlying\n   unicast routing protocol, the packet format in Section 4.9
    of\n   [RFC7761] remains the same, except that the group address and source\n
    \  address MUST be translated when traversing an AFBR.\n   For example, Figure
    5 shows the register-stop message format in the\n   IPv4 and IPv6 address families.\n
    \      0                   1                   2                   3\n       0
    1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \     |PIM Ver| Type  |   Reserved    |           Checksum            |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \     |             IPv4 Group Address (Encoded-Group format)         |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \     |            IPv4 Source Address (Encoded-Unicast format)       |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \                   (a) IPv4 Register-Stop Message Format\n       0                   1
    \                  2                   3\n       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4
    5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \     |PIM Ver| Type  |   Reserved    |           Checksum            |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \     |             IPv6 Group Address (Encoded-Group format)         |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \     |            IPv6 Source Address (Encoded-Unicast format)       |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
    \                   (b) IPv6 Register-Stop Message Format\n                  Figure
    5: Register-Stop Message Format\n   In Figure 5, the semantics of fields \"PIM
    Ver\", \"Type\", \"Reserved\",\n   and \"Checksum\" are specified in Section 4.9
    of [RFC7761].\n   IPv4 Group Address (Encoded-Group format): The encoded-group
    format\n   of the IPv4 group address described in Section 4.9.1 of [RFC7761].\n
    \  IPv4 Source Address (Encoded-Group format): The encoded-unicast\n   format
    of the IPv4 source address described in Section 4.9.1 of\n   [RFC7761].\n   IPv6
    Group Address (Encoded-Group format): The encoded-group format\n   of the IPv6
    group address described in Section 5.2.\n   IPv6 Source Address (Encoded-Group
    format): The encoded-unicast\n   format of the IPv6 source address described in
    Section 5.3.\n"
  title: 8.  Packet Format and Translation
- contents:
  - "9.  Softwire Mesh Multicast Encapsulation\n   Softwire mesh multicast encapsulation
    does not require the use of any\n   one particular encapsulation mechanism.  Rather,
    it MUST accommodate\n   a variety of different encapsulation mechanisms and allow
    the use of\n   encapsulation mechanisms mentioned in [RFC4925].  Additionally,
    all\n   of the AFBRs attached to the I-IP network MUST implement the same\n   encapsulation
    mechanism and follow the requirements mentioned in\n   Section 8 of [RFC5565].\n"
  title: 9.  Softwire Mesh Multicast Encapsulation
- contents:
  - "10.  Security Considerations\n   The security concerns raised in [RFC4925] and
    [RFC7761] are\n   applicable here.\n   The additional workload associated with
    some schemes, such as\n   interface agents, could be exploited by an attacker
    to perform a DDoS\n   attack.\n   Compared with [RFC4925], the security concerns
    should be considered\n   more carefully: An attacker could potentially set up
    many multicast\n   trees in the edge networks, causing too many multicast states
    in the\n   core network.  To defend against these attacks, BGP policies SHOULD\n
    \  be carefully configured, e.g., AFBRs only accept Well-Known prefix\n   advertisements
    from trusted peers.  Besides, cryptographic methods\n   for authenticating BGP
    sessions [RFC7454] could be used.\n"
  title: 10.  Security Considerations
- contents:
  - "11.  IANA Considerations\n   This document has no IANA actions.\n"
  title: 11.  IANA Considerations
- contents:
  - "12.  Normative References\n   [RFC2119]  Bradner, S., \"Key words for use in
    RFCs to Indicate\n              Requirement Levels\", BCP 14, RFC 2119,\n              DOI
    10.17487/RFC2119, March 1997,\n              <https://www.rfc-editor.org/info/rfc2119>.\n
    \  [RFC2473]  Conta, A. and S. Deering, \"Generic Packet Tunneling in\n              IPv6
    Specification\", RFC 2473, DOI 10.17487/RFC2473,\n              December 1998,
    <https://www.rfc-editor.org/info/rfc2473>.\n   [RFC4760]  Bates, T., Chandra,
    R., Katz, D., and Y. Rekhter,\n              \"Multiprotocol Extensions for BGP-4\",
    RFC 4760,\n              DOI 10.17487/RFC4760, January 2007,\n              <https://www.rfc-editor.org/info/rfc4760>.\n
    \  [RFC4925]  Li, X., Ed., Dawkins, S., Ed., Ward, D., Ed., and A.\n              Durand,
    Ed., \"Softwire Problem Statement\", RFC 4925,\n              DOI 10.17487/RFC4925,
    July 2007,\n              <https://www.rfc-editor.org/info/rfc4925>.\n   [RFC5565]
    \ Wu, J., Cui, Y., Metz, C., and E. Rosen, \"Softwire Mesh\n              Framework\",
    RFC 5565, DOI 10.17487/RFC5565, June 2009,\n              <https://www.rfc-editor.org/info/rfc5565>.\n
    \  [RFC6052]  Bao, C., Huitema, C., Bagnulo, M., Boucadair, M., and X.\n              Li,
    \"IPv6 Addressing of IPv4/IPv6 Translators\", RFC 6052,\n              DOI 10.17487/RFC6052,
    October 2010,\n              <https://www.rfc-editor.org/info/rfc6052>.\n   [RFC6333]
    \ Durand, A., Droms, R., Woodyatt, J., and Y. Lee, \"Dual-\n              Stack
    Lite Broadband Deployments Following IPv4\n              Exhaustion\", RFC 6333,
    DOI 10.17487/RFC6333, August 2011,\n              <https://www.rfc-editor.org/info/rfc6333>.\n
    \  [RFC6513]  Rosen, E., Ed. and R. Aggarwal, Ed., \"Multicast in MPLS/\n              BGP
    IP VPNs\", RFC 6513, DOI 10.17487/RFC6513, February\n              2012, <https://www.rfc-editor.org/info/rfc6513>.\n
    \  [RFC7454]  Durand, J., Pepelnjak, I., and G. Doering, \"BGP Operations\n              and
    Security\", BCP 194, RFC 7454, DOI 10.17487/RFC7454,\n              February 2015,
    <https://www.rfc-editor.org/info/rfc7454>.\n   [RFC7761]  Fenner, B., Handley,
    M., Holbrook, H., Kouvelas, I.,\n              Parekh, R., Zhang, Z., and L. Zheng,
    \"Protocol Independent\n              Multicast - Sparse Mode (PIM-SM): Protocol
    Specification\n              (Revised)\", STD 83, RFC 7761, DOI 10.17487/RFC7761,
    March\n              2016, <https://www.rfc-editor.org/info/rfc7761>.\n   [RFC7899]
    \ Morin, T., Ed., Litkowski, S., Patel, K., Zhang, Z.,\n              Kebler,
    R., and J. Haas, \"Multicast VPN State Damping\",\n              RFC 7899, DOI
    10.17487/RFC7899, June 2016,\n              <https://www.rfc-editor.org/info/rfc7899>.\n
    \  [RFC8114]  Boucadair, M., Qin, C., Jacquenet, C., Lee, Y., and Q.\n              Wang,
    \"Delivery of IPv4 Multicast Services to IPv4 Clients\n              over an IPv6
    Multicast Network\", RFC 8114,\n              DOI 10.17487/RFC8114, March 2017,\n
    \             <https://www.rfc-editor.org/info/rfc8114>.\n   [RFC8174]  Leiba,
    B., \"Ambiguity of Uppercase vs Lowercase in RFC\n              2119 Key Words\",
    BCP 14, RFC 8174, DOI 10.17487/RFC8174,\n              May 2017, <https://www.rfc-editor.org/info/rfc8174>.\n
    \  [RFC8201]  McCann, J., Deering, S., Mogul, J., and R. Hinden, Ed.,\n              \"Path
    MTU Discovery for IP version 6\", STD 87, RFC 8201,\n              DOI 10.17487/RFC8201,
    July 2017,\n              <https://www.rfc-editor.org/info/rfc8201>.\n"
  title: 12.  Normative References
- contents:
  - "Acknowledgements\n   Wenlong Chen, Xuan Chen, Alain Durand, Yiu Lee, Jacni Qin,
    and Stig\n   Venaas provided useful input to this document.\n"
  title: Acknowledgements
- contents:
  - "Authors' Addresses\n   Mingwei Xu\n   Tsinghua University\n   Department of Computer
    Science\n   Beijing  100084\n   China\n   Phone: +86-10-6278-5822\n   Email: xumw@tsinghua.edu.cn\n
    \  Yong Cui\n   Tsinghua University\n   Department of Computer Science\n   Beijing
    \ 100084\n   China\n   Phone: +86-10-6278-5822\n   Email: cuiyong@tsinghua.edu.cn\n
    \  Jianping Wu\n   Tsinghua University\n   Department of Computer Science\n   Beijing
    \ 100084\n   China\n   Phone: +86-10-6278-5983\n   Email: jianping@cernet.edu.cn\n
    \  Shu Yang\n   Shenzhen University\n   South Campus\n   Shenzhen  518060\n   China\n
    \  Phone: +86-755-2653-4078\n   Email: yang.shu@szu.edu.cn\n   Chris Metz\n   Cisco
    Systems\n   170 West Tasman Drive\n   San Jose, CA  95134\n   United States of
    America\n   Phone: +1-408-525-3275\n   Email: chmetz@cisco.com\n"
  title: Authors' Addresses
