- title: __initial_text__
  contents:
  - '        Techniques for Managing Asynchronously Generated Alerts

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo defines common mechanisms for managing asynchronously\n\
    \   produced alerts in a manner consistent with current network\n   management\
    \ protocols.\n   This memo specifies an Experimental Protocol for the Internet\n\
    \   community.  Discussion and suggestions for improvement are requested.\n  \
    \ Please refer to the current edition of the \"IAB Official Protocol\n   Standards\"\
    \ for the standardization state and status of this protocol.\n   Distribution\
    \ of this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   This RFC explores mechanisms to prevent a remotely managed entity\n\
    \   from burdening a manager or network with an unexpected amount of\n   network\
    \ management information, and to ensure delivery of \"important\"\n   information.\
    \  The focus is on controlling the flow of asynchronously\n   generated information,\
    \ and not how the information is generated.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction...................................................\
    \  2\n   2. Problem Definition.............................................  3\n\
    \   2.1 Polling Advantages............................................  3\n  \
    \  (a) Reliable detection of failures...............................  3\n    (b)\
    \ Reduced protocol complexity on managed entity................  3\n    (c) Reduced\
    \ performance impact on managed entity.................  3\n    (d) Reduced configuration\
    \ requirements to manage remote entity...  4\n   2.2 Polling Disadvantages.........................................\
    \  4\n    (a) Response time for problem detection..........................  4\n\
    \    (b) Volume of network management traffic generated...............  4\n  \
    \ 2.3 Alert Advantages..............................................  5\n    (a)\
    \ Real-time knowledge of problems..............................  5\n    (b) Minimal\
    \ amount of network management traffic.................  5\n   2.4 Alert Disadvantages...........................................\
    \  5\n    (a) Potential loss of critical information.......................  5\n\
    \    (b) Potential to over-inform a manager...........................  5\n  \
    \ 3. Specific Goals of this Memo....................................  6\n   4.\
    \ Compatibility with Existing Network Management Protocols.......  6\n   5. Closed\
    \ Loop \"Feedback\" Alert Reporting with a \"Pin\" Sliding\n      Window Limit...................................................\
    \  6\n   5.1 Use of Feedback...............................................  7\n\
    \   5.1.1 Example.....................................................  8\n  \
    \ 5.2 Notes on Feedback/Pin usage...................................  8\n   6.\
    \ Polled, Logged Alerts..........................................  9\n   6.1 Use\
    \ of Polled, Logged Alerts.................................. 10\n   6.1.1 Example.....................................................\
    \ 12\n   6.2 Notes on Polled, Logged Alerts................................ 12\n\
    \   7. Compatibility with SNMP and CMOT .............................. 14\n  \
    \ 7.1 Closed Loop Feedback Alert Reporting.......................... 14\n   7.1.1\
    \ Use of Feedback with SNMP................................... 14\n   7.1.2 Use\
    \ of Feedback with CMOT................................... 14\n   7.2 Polled,\
    \ Logged Alerts......................................... 14\n   7.2.1 Use of Polled,\
    \ Logged Alerts with SNMP...................... 14\n   7.2.2 Use of Polled, Logged\
    \ Alerts with CMOT...................... 15\n   8. Notes on Multiple Manager Environments.........................\
    \ 15\n   9. Summary........................................................ 16\n\
    \   10. References.................................................... 16\n  \
    \ 11. Acknowledgements.............................................. 17\n   Appendix\
    \ A.  Example of polling costs............................. 17\n   Appendix B.\
    \  MIB object definitions............................... 19\n   Security Considerations...........................................\
    \ 22\n   Author's Address.................................................. 22\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This memo defines mechanisms to prevent a remotely managed\
    \ entity\n   from burdening a manager or network with an unexpected amount of\n\
    \   network management information, and to ensure delivery of \"important\"\n\
    \   information.  The focus is on controlling the flow of asynchronously\n   generated\
    \ information, and not how the information is generated.\n   Mechanisms for generating\
    \ and controlling the generation of\n   asynchronous information may involve protocol\
    \ specific issues.\n   There are two understood mechanisms for transferring network\n\
    \   management information from a managed entity to a manager: request-\n   response\
    \ driven polling, and the unsolicited sending of \"alerts\".\n   Alerts are defined\
    \ as any management information delivered to a\n   manager that is not the result\
    \ of a specific query.  Advantages and\n   disadvantages exist within each method.\
    \  They are detailed in section\n   2 below.\n   Alerts in a failing system can\
    \ be generated so rapidly that they\n   adversely impact functioning resources.\
    \  They may also fail to be\n   delivered, and critical information maybe lost.\
    \  Methods are needed\n   both to limit the volume of alert transmission and to\
    \ assist in\n   delivering a minimum amount of information to a manager.\n   It\
    \ is our belief that managed agents capable of asynchronously\n   generating alerts\
    \ should attempt to adopt mechanisms that fill both\n   of these needs.  For reasons\
    \ shown in section 2.4, it is necessary to\n   fulfill both alert-management requirements.\
    \  A complete alert-driven\n   system must ensure that alerts are delivered or\
    \ their loss detected\n   with a means to recreate the lost information, AND it\
    \ must not allow\n   itself to overburden its manager with an unreasonable amount\
    \ of\n   information.\n"
- title: 2.  Problem Definition
  contents:
  - "2.  Problem Definition\n   The following discusses the relative advantages and\
    \ disadvantages of\n   polled vs. alert driven management.\n"
- title: 2.1  Polling Advantages
  contents:
  - "2.1  Polling Advantages\n   (a) Reliable detection of failures.\n          A\
    \ manager that polls for all of its information can\n          more readily determine\
    \ machine and network failures;\n          a lack of a response to a query indicates\
    \ problems\n          with the machine or network.   A manager relying on\n  \
    \        notification of problems might assume that a faulty\n          system\
    \ is good, should the alert be unable to reach\n          its destination, or\
    \ the managed system be unable to\n          correctly generate the alert.  Examples\
    \ of this\n          include network failures (in which an isolated network\n\
    \          cannot deliver the alert), and power failures (in which\n         \
    \ a failing machine cannot generate an alert).  More\n          subtle forms of\
    \ failure in the managed entity might\n          produce an incorrectly generated\
    \ alert, or no alert at\n          all.\n   (b) Reduced protocol complexity on\
    \ managed entity\n          The use of a request-response based system is based\
    \ on\n          conservative assumptions about the underlying transport\n    \
    \      protocol.  Timeouts and retransmits (re-requests) can\n          be built\
    \ into the manager.  In addition, this allows\n          the manager to affect\
    \ the amount of network management\n          information flowing across the network\
    \ directly.\n   (c) Reduced performance impact on managed entity\n          In\
    \ a purely polled system, there is no danger of having\n          to often test\
    \ for an alert condition.  This testing\n          takes CPU cycles away from\
    \ the real mission of the\n          managed entity.  Clearly, testing a threshold\
    \ on each\n          packet received could have unwanted performance effects\n\
    \          on machines such as gateways.  Those who wish to use\n          thresholds\
    \ and alerts must choose the parameters to be\n          tested with great care,\
    \ and should be strongly\n          discouraged from updating statistics and checking\
    \ values\n          frequently.\n   (d) Reduced Configuration Requirements to\
    \ manage remote\n          entity\n          Remote, managed entities need not\
    \ be configured\n          with one or more destinations for reporting information.\n\
    \          Instead, the entity merely responds to whomever\n          makes a\
    \ specific request.  When changing the network\n          configuration, there\
    \ is never a need to reconfigure\n          all remote manageable systems.  In\
    \ addition, any number\n          of \"authorized\" managers (i.e., those passing\
    \ any\n          authentication tests imposed by the network management\n    \
    \      protocol) may obtain information from any managed entity.\n          This\
    \ occurs without reconfiguring the entity and\n          without reaching an entity-imposed\
    \ limit on the maximum\n          number of potential managers.\n"
- title: 2.2  Polling Disadvantages
  contents:
  - "2.2  Polling Disadvantages\n   (a) Response time for problem detection\n    \
    \      Having to poll many MIB [2] variables per machine on\n          a large\
    \ number of machines is itself a real\n          problem.  The ability of a manager\
    \ to monitor\n          such a system is limited; should a system fail\n     \
    \     shortly after being polled there may be a significant\n          delay before\
    \ it is polled again.  During this time,\n          the manager must assume that\
    \ a failing system is\n          acceptable.  See Appendix A for a hypothetical\n\
    \          example of such a system.\n          It is worthwhile to note that\
    \ while improving the mean\n          time to detect failures might not greatly\
    \ improve the\n          time to correct the failure, the problem will generally\n\
    \          not be repaired until it is detected.  In addition,\n          most\
    \ network managers would prefer to at least detect\n          faults before network\
    \ users start phoning in.\n   (b) Volume of network management traffic\n     \
    \     Polling many objects (MIB variables) on many machines\n          greatly\
    \ increases the amount of network management\n          traffic flowing across\
    \ the network (see Appendix A).\n          While it is possible to minimize this\
    \ through the use\n          of hierarchies (polling a machine for a general status\n\
    \          of all the machines it polls), this aggravates the\n          response\
    \ time problem previously discussed.\n"
- title: 2.3  Alert Advantages
  contents:
  - "2.3  Alert Advantages\n   (a) Real-time Knowledge of Problems\n          Allowing\
    \ the manager to be notified of problems\n          eliminates the delay imposed\
    \ by polling many objects/\n          systems in a loop.\n   (b) Minimal amount\
    \ of Network Management Traffic\n          Alerts are transmitted only due to\
    \ detected errors.\n          By removing the need to transfer large amounts of\
    \ status\n          information that merely demonstrate a healthy system,\n  \
    \        network and system (machine processor) resources may be\n          freed\
    \ to accomplish their primary mission.\n"
- title: 2.4  Alert Disadvantages
  contents:
  - "2.4  Alert Disadvantages\n   (a) Potential Loss of Critical Information\n   \
    \       Alerts are most likely not to be delivered when the\n          managed\
    \ entity fails (power supply fails) or the\n          network experiences problems\
    \ (saturated or isolated).\n          It is important to remember that failing\
    \ machines and\n          networks cannot be trusted to inform a manager that\n\
    \          they are failing.\n   (b) Potential to Over-inform the Manager\n  \
    \        An \"open loop\" system in which the flow of alerts to\n          a manager\
    \ is fully asynchronous can result in an excess\n          of alerts being delivered\
    \ (e.g., link up/down messages\n          when lines vacillate).  This information\
    \ places an extra\n          burden on a strained network, and could prevent the\n\
    \          manager from disabling the mechanism generating the\n          alerts;\
    \ all available network bandwidth into the manager\n          could be saturated\
    \ with incoming alerts.\n   Most major network management systems strive to use\
    \ an optimal\n   combination of alerts and polling.  Doing so preserves the advantages\n\
    \   of each while eliminating the disadvantages of pure polling.\n"
- title: 3.  Specific Goals of this Memo
  contents:
  - "3.  Specific Goals of this Memo\n   This memo suggests mechanisms to minimize\
    \ the disadvantages of alert\n   usage.  An optimal system recognizes the potential\
    \ problems\n   associated with sending too many alerts in which a manager becomes\n\
    \   ineffective at managing, and not adequately using alerts (especially\n   given\
    \ the volumes of data that must be actively monitored with poor\n   scaling).\
    \  It is the author's belief that this is best done by\n   allowing alert mechanisms\
    \ that \"close down\" automatically when over-\n   delivering asynchronous (unexpected)\
    \ alerts, and that also allow a\n   flow of synchronous alert information through\
    \ a polled log.  The use\n   of \"feedback\" (with a sliding window \"pin\") discussed\
    \ in section 5\n   addresses the former need, while the discussion in section\
    \ 6 on\n   \"polled, logged alerts\" does the latter.\n   This memo does not attempt\
    \ to define mechanisms for controlling the\n   asynchronous generation of alerts,\
    \ as such matters deal with\n   specifics of the management protocol.  In addition,\
    \ no attempt is\n   made to define what the content of an alert should be.  The\
    \ feedback\n   mechanism does require the addition of a single alert type, but\
    \ this\n   is not meant to impact or influence the techniques for generating any\n\
    \   other alert (and can itself be generated from a MIB object or the\n   management\
    \ protocol).  To make any effective use of the alert\n   mechanisms described\
    \ in this memo, implementation of several MIB\n   objects is required in the relevant\
    \ managed systems.  The location of\n   these objects in the MIB is under an experimental\
    \ subtree delegated\n   to the Alert-Man working group of the Internet Engineering\
    \ Task Force\n   (IETF) and published in the \"Assigned Numbers\" RFC [5].  Currently,\n\
    \   this subtree is defined as\n         alertMan ::= { experimental 24 }.\n"
- title: 4.  Compatibility With Existing Network Management Protocols
  contents:
  - "4.  Compatibility With Existing Network Management Protocols\n   It is the intent\
    \ of this document to suggest mechanisms that violate\n   neither the letter nor\
    \ the spirit of the protocols expressed in CMOT\n   [3] and SNMP [4].  To achieve\
    \ this goal, each mechanism described\n   will give an example of its conformant\
    \ use with both SNMP and CMOT.\n"
- title: 5.  Closed Loop "Feedback" Alert Reporting with a "Pin" Sliding
  contents:
  - "5.  Closed Loop \"Feedback\" Alert Reporting with a \"Pin\" Sliding\n    Window\
    \ Limit\n   One technique for preventing an excess of alerts from being delivered\n\
    \   involves required feedback to the managed agent.  The name \"feedback\"\n\
    \   describes a required positive response from a potentially \"over-\n   reported\"\
    \ manager, before a remote agent may continue transmitting\n   alerts at a high\
    \ rate.  A sliding window \"pin\" threshold (so named\n   for the metal on the\
    \ end of a meter) is established as a part of a\n   user-defined SNMP trap, or\
    \ as a managed CMOT event.  This threshold\n   defines the maximum allowable number\
    \ of alerts (\"maxAlertsPerTime\")\n   that may be transmitted by the agent, and\
    \ the \"windowTime\" in seconds\n   that alerts are tested against.  Note that\
    \ \"maxAlertsPerTime\"\n   represents the sum total of all alerts generated by\
    \ the agent, and is\n   not duplicated for each type of alert that an agent might\
    \ generate.\n   Both \"maxAlertsPerTime\" and \"windowTime\" are required MIB\
    \ objects of\n   SMI [1] type INTEGER, must be readable, and may be writable should\n\
    \   the implementation permit it.\n   Two other items are required for the feedback\
    \ technique.  The first\n   is a Boolean MIB object (SMI type is INTEGER, but\
    \ it is treated as a\n   Boolean whose only value is zero, i.e., \"FALSE\") named\n\
    \   \"alertsEnabled\", which must have read and write access.  The second\n  \
    \ is a user defined alert named \"alertsDisabled\".  Please see Appendix\n   B\
    \ for their complete definitions.\n"
- title: 5.1  Use of Feedback
  contents:
  - "5.1  Use of Feedback\n   When an excess of alerts is being generated, as determined\
    \ by the\n   total number of alerts exceeding \"maxAlertsPerTime\" within\n  \
    \ \"windowTime\" seconds, the agent sets the Boolean value of\n   \"alertsEnabled\"\
    \ to \"FALSE\" and sends a single alert of type\n   \"alertsDisabled\".\n   Again,\
    \ the pin mechanism operates on the sum total of all alerts\n   generated by the\
    \ remote system.  Feedback is implemented once per\n   agent and not separately\
    \ for each type of alert in each agent.  While\n   it is also possible to implement\
    \ the Feedback/Pin technique on a per\n   alert-type basis, such a discussion\
    \ belongs in a document dealing\n   with controlling the generation of individual\
    \ alerts.\n   The typical use of feedback is detailed in the following steps:\n\
    \      (a)  Upon initialization of the agent, the value of\n           \"alertsEnabled\"\
    \ is set to \"TRUE\".\n      (b)  Each time an alert is generated, the value of\n\
    \           \"alertsEnabled\" is tested.  Should the value be \"FALSE\",\n   \
    \        no alert is sent.  If the value is \"TRUE\", the alert is\n         \
    \  sent and the current time is stored locally.\n      (c)  If at least \"maxAlertsPerTime\"\
    \ have been generated, the\n           agent calculates the difference of time\
    \ stored for the\n           new alert from the time associated with alert generated\n\
    \           \"maxAlertsPerTime\" previously.  Should this amount be\n        \
    \   less than \"windowTime\", a single alert of the type\n           \"alertsDisabled\"\
    \ is sent to the manager and the value of\n           \"alertsEnabled\" is then\
    \ set to \"FALSE\".\n      (d)  When a manager receives an alert of the type \"\
    Alerts-\n           Disabled\", it is expected to set \"alertsEnabled\" back\n\
    \           to \"TRUE\" to continue to receive alert reports.\n"
- title: 5.1.1  Example
  contents:
  - "5.1.1  Example\n   In a sample system, the maximum number of alerts any single\
    \ managed\n   entity may send the manager is 10 in any 3 second interval.  A\n\
    \   circular buffer with a maximum depth of 10 time of day elements is\n   defined\
    \ to accommodate statistics keeping.\n   After the first 10 alerts have been sent,\
    \ the managed entity tests\n   the time difference between its oldest and newest\
    \ alerts.  By testing\n   the time for a fixed number of alerts, the system will\
    \ never disable\n   itself merely because a few alerts were transmitted back to\
    \ back.\n   The mechanism will disable reporting only after at least 10 alerts\n\
    \   have been sent, and the only if the last 10 all occurred within a 3\n   second\
    \ interval.  As alerts are sent over time, the list maintains\n   data on the\
    \ last 10 alerts only.\n"
- title: 5.2  Notes on Feedback/Pin Usage
  contents:
  - "5.2  Notes on Feedback/Pin Usage\n   A manager may periodically poll \"alertsEnabled\"\
    \ in case an\n   \"alertsDisabled\" alert is not delivered by the network.  Some\n\
    \   implementers may also choose to add COUNTER MIB objects to show the\n   total\
    \ number of alerts transmitted and dropped by \"alertsEnabled\"\n   being FALSE.\
    \  While these may yield some indication of the number of\n   lost alerts, the\
    \ use of \"Polled, Logged Alerts\" offers a superset of\n   this function.\n \
    \  Testing the alert frequency need not begin until a minimum number of\n   alerts\
    \ have been sent (the circular buffer is full).  Even then, the\n   actual test\
    \ is the elapsed time to get a fixed number of alerts and\n   not the number of\
    \ alerts in a given time period.  This eliminates the\n   need for complex averaging\
    \ schemes (keeping current alerts per second\n   as a frequency and redetermining\
    \ the current value based on the\n   previous value and the time of a new alert).\
    \  Also eliminated is the\n   problem of two back to back alerts; they may indeed\
    \ appear to be a\n   large number of alerts per second, but the fact remains that\
    \ there\n   are only two alerts.  This situation is unlikely to cause a problem\n\
    \   for any manager, and should not trigger the mechanism.\n   Since alerts are\
    \ supposed to be generated infrequently, maintaining\n   the pin and testing the\
    \ threshold should not impact normal\n   performance of the agent (managed entity).\
    \  While repeated testing\n   may affect performance when an excess of alerts\
    \ are being\n   transmitted, this effect would be minor compared to the cost of\n\
    \   generating and sending so many alerts.  Long before the cost of\n   testing\
    \ (in CPU cycles) becomes relatively high, the feedback\n   mechanism should disable\
    \ alert sending and affect savings both in\n   alert sending and its own testing\
    \ (note that the list maintenance and\n   testing mechanisms disable themselves\
    \ when they disable alert\n   reporting).  In addition, testing the value of \"\
    alertsEnabled\" can\n   limit the CPU burden of building alerts that do not need\
    \ to be sent.\n   It is advised that the implementer consider allowing write access\
    \ to\n   both the window size and the number of alerts allowed in a window's\n\
    \   time.  In doing so, a management station has the option of varying\n   these\
    \ parameters remotely before setting \"alertsEnabled\" to \"TRUE\".\n   Should\
    \ either of these objects be set to 0, a conformant system will\n   disable the\
    \ pin and feedback mechanisms and allow the agent to send\n   all of the alerts\
    \ it generates.\n   While the feedback mechanism is not high in CPU utilization\
    \ costs,\n   those implementing alerts of any kind are again cautioned to exercise\n\
    \   care that the alerts tested do not occur so frequently as to impact\n   the\
    \ performance of the agent's primary function.\n   The user may prefer to send\
    \ alerts via TCP to help ensure delivery of\n   the \"alerts disabled\" message,\
    \ if available.\n   The feedback technique is effective for preventing the over-reporting\n\
    \   of alerts to a manager.  It does not assist with the problem of\n   \"under-reporting\"\
    \ (see \"polled, logged alerts\" for this).\n   It is possible to lose alerts\
    \ while \"alertsEnabled\" is \"FALSE\".\n   Ideally, the threshold of \"maxAlertsPerTime\"\
    \ should be set\n   sufficiently high that \"alertsEnabled\" is only set to \"\
    FALSE\" during\n   \"over-reporting\" situations.  To help prevent alerts from\
    \ possibly\n   being lost when the threshold is exceeded, this method can be\n\
    \   combined with \"polled, logged alerts\" (see below).\n"
- title: 6.  Polled, Logged Alerts
  contents:
  - "6.  Polled, Logged Alerts\n   A simple system that combines the request-response\
    \ advantages of\n   polling while minimizing the disadvantages is \"Polled, Logged\n\
    \   Alerts\".  Through the addition of several MIB objects, one gains a\n   system\
    \ that minimizes network management traffic, lends itself to\n   scaling, eliminates\
    \ the reliance on delivery, and imposes no\n   potential over-reporting problems\
    \ inherent in pure alert driven\n   architectures.  Minimizing network management\
    \ traffic is affected by\n   reducing multiple requests to a single request. \
    \ This technique does\n   not eliminate the need for polling, but reduces the\
    \ amount of data\n   transferred and ensures the manager either alert delivery\
    \ or\n   notification of an unreachable node.  Note again, the goal is to\n  \
    \ address the needs of information (alert) flow and not to control the\n   local\
    \ generation of alerts.\n"
- title: 6.1  Use of Polled, Logged Alerts
  contents:
  - "6.1  Use of Polled, Logged Alerts\n   As alerts are generated by a remote managed\
    \ entity, they are logged\n   locally in a table.  The manager may then poll a\
    \ single MIB object to\n   determine if any number of alerts have been generated.\
    \  Each poll\n   request returns a copy of an \"unacknowledged\" alert from the\
    \ alert\n   log, or an indication that the table is empty.  Upon receipt, the\n\
    \   manager might \"acknowledge\" any alert to remove it from the log.\n   Entries\
    \ in the table must be readable, and can optionally allow the\n   user to remove\
    \ them by writing to or deleting them.\n   This technique requires several additional\
    \ MIB objects.  The\n   alert_log is a SEQUENCE OF logTable entries that must\
    \ be readable,\n   and can optionally have a mechanism to remove entries (e.g.,\
    \ SNMP set\n   or CMOT delete).  An optional read-only MIB object of type INTEGER,\n\
    \   \"maxLogTableEntries\" gives the maximum number of log entries the\n   system\
    \ will support.  Please see Appendix B for their complete\n   definitions.\n \
    \  The typical use of Polled, Logged Alerts is detailed below.\n      (a)  Upon\
    \ initialization, the agent builds a pointer to a log\n           table.  The\
    \ table is empty (a sequence of zero entries).\n      (b)  Each time a local alert\
    \ is generated, a logTable entry\n           is built with the following information:\n\
    \      SEQUENCE {\n                 alertId          INTEGER,\n              \
    \   alertData        OPAQUE\n           }\n           (1) alertId number of type\
    \ INTEGER, set to 1 greater\n               than the previously generated alertId.\
    \  If this is\n               the first alert generated, the value is initialized\n\
    \               to 1.  This value should wrap (reset) to 1 when it\n         \
    \      reaches 2**32.  Note that the maximum log depth\n               cannot\
    \ exceed (2**32)-1 entries.\n           (2) a copy of the alert encapsulated in\
    \ an OPAQUE.\n      (c)  The new log element is added to the table.  Should\n\
    \           addition of the element exceed the defined maximum log\n         \
    \  table size, the oldest element in the table (having the\n           lowest\
    \ alertId) is replaced by the new element.\n      (d)  A manager may poll the\
    \ managed agent for either the next\n           alert in the alert_table, or for\
    \ a copy of the alert\n           associated with a specific alertId.  A poll\
    \ request must\n           indicate a specific alertId. The mechanism for obtaining\n\
    \           this information from a table is protocol specific, and\n        \
    \   might use an SNMP GET or GET NEXT (with GET NEXT\n           following an\
    \ instance of zero returning the first table\n           entry's alert) or CMOT's\
    \ GET with scoping and filtering\n           to get alertData entries associated\
    \ with alertId's\n           greater or less than a given instance.\n      (e)\
    \  An alertData GET request from a manager must always be\n           responded\
    \ to with a reply of the entire OPAQUE alert\n           (SNMP TRAP, CMOT EVENT,\
    \ etc.) or a protocol specific\n           reply indicating that the get request\
    \ failed.\n           Note that the actual contents of the alert string, and\n\
    \           the format of those contents, are protocol specific.\n      (f)  Once\
    \ an alert is logged in the local log, it is up to\n           the individual\
    \ architecture and implementation whether\n           or not to also send a copy\
    \ asynchronously to the\n           manager.  Doing so could be used to redirect\
    \ the focus\n           of the polling (rather than waiting an average of 1/2\n\
    \           the poll cycle to learn of a problem), but does not\n           result\
    \ in significant problems should the alert fail to\n           be delivered.\n\
    \      (g)  Should a manager request an alert with alertId of 0,\n           the\
    \ reply shall be the appropriate protocol specific\n           error response.\n\
    \      (h)  If a manager requests the alert immediately following\n          \
    \ the alert with alertId equal to 0, the reply will be the\n           first alert\
    \ (or alerts, depending on the protocol used)\n           in the alert log.\n\
    \      (i)  A manager may remove a specific alert from the alert log\n       \
    \    by naming the alertId of that alert and issuing a\n           protocol specific\
    \ command (SET or DELETE).  If no such\n           alert exists, the operation\
    \ is said to have failed and\n           such failure is reported to the manager\
    \ in a protocol\n           specific manner.\n"
- title: 6.1.1  Example
  contents:
  - "6.1.1  Example\n   In a sample system (based on the example in Appendix A), a\
    \ manager\n   must monitor 40 remote agents, each having between 2 and 15\n  \
    \ parameters which indicate the relative health of the agent and the\n   network.\
    \  During normal monitoring, the manager is concerned only\n   with fault detection.\
    \  With an average poll request-response time of\n   5 seconds, the manager polls\
    \ one MIB variable on each node.  This\n   involves one request and one reply\
    \ packet of the format specified in\n   the XYZ network management protocol. \
    \ Each packet requires 120 bytes\n   \"on the wire\" (requesting a single object,\
    \ ASN.1 encoded, IP and UDP\n   enveloped, and placed in an ethernet packet).\
    \  This results in a\n   serial poll cycle time of 3.3 minutes (40 nodes at 5\
    \ seconds each is\n   200 seconds), and a mean time to detect alert of slightly\
    \ over 1.5\n   minutes.  The total amount of data transferred during a 3.3 minute\n\
    \   poll cycle is 9600 bytes (120 requests and 120 replies for each of 40\n  \
    \ nodes).  With such a small amount of network management traffic per\n   minute,\
    \ the poll rate might reasonably be doubled (assuming the\n   network performance\
    \ permits it).  The result is 19200 bytes\n   transferred per cycle, and a mean\
    \ time to detect failure of under 1\n   minute.  Parallel polling obviously yields\
    \ similar improvements.\n   Should an alert be returned by a remote agent's log,\
    \ the manager\n   notifies the operator and removes the element from the alert\
    \ log by\n   setting it with SNMP or deleting it with CMOT.  Normal alert\n  \
    \ detection procedures are then followed.  Those SNMP implementers who\n   prefer\
    \ to not use SNMP SET for table entry deletes may always define\n   their log\
    \ as \"read only\".  The fact that the manager made a single\n   query (to the\
    \ log) and was able to determine which, if any, objects\n   merited special attention\
    \ essentially means that the status of all\n   alert capable objects was monitored\
    \ with a single request.\n   Continuing the above example, should a remote entity\
    \ fail to respond\n   to two successive poll attempts, the operator is notified\
    \ that the\n   agent is not reachable.  The operator may then choose (if so\n\
    \   equipped) to contact the agent through an alternate path (such as\n   serial\
    \ line IP over a dial up modem).  Upon establishing such a\n   connection, the\
    \ manager may then retrieve the contents of the alert\n   log for a chronological\
    \ map of the failure's alerts.  Alerts\n   undelivered because of conditions that\
    \ may no longer be present are\n   still available for analysis.\n"
- title: 6.2  Notes on Polled, Logged Alerts
  contents:
  - "6.2  Notes on Polled, Logged Alerts\n   Polled, logged alert techniques allow\
    \ the tracking of many alerts\n   while actually monitoring only a single MIB\
    \ object.  This\n   dramatically decreases the amount of network management data\
    \ that\n   must flow across the network to determine the status.  By reducing\n\
    \   the number of requests needed to track multiple objects (to one), the\n  \
    \ poll cycle time is greatly improved.  This allows a faster poll cycle\n   (mean\
    \ time to detect alert) with less overhead than would be caused\n   by pure polling.\n\
    \   In addition, this technique scales well to large networks, as the\n   concept\
    \ of polling a single object to learn the status of many lends\n   itself well\
    \ to hierarchies.  A proxy manager may be polled to learn\n   if he has found\
    \ any alerts in the logs of the agents he polls.  Of\n   course, this scaling\
    \ does not save on the mean time to learn of an\n   alert (the cycle times of\
    \ the manager and the proxy manager must be\n   considered), but the amount of\
    \ network management polling traffic is\n   concentrated at lower levels.  Only\
    \ a small amount of such traffic\n   need be passed over the network's \"backbone\"\
    ; that is the traffic\n   generated by the request-response from the manager to\
    \ the proxy\n   managers.\n   Note that it is best to return the oldest logged\
    \ alert as the first\n   table entry.  This is the object most likely to be overwritten,\
    \ and\n   every attempt should be made ensure that the manager has seen it.  In\n\
    \   a system where log entries may be removed by the manager, the manager\n  \
    \ will probably wish to attempt to keep all remote alert logs empty to\n   reduce\
    \ the number of alerts dropped or overwritten.  In any case, the\n   order in\
    \ which table entries are returned is a function of the table\n   mechanism, and\
    \ is implementation and/or protocol specific.\n   \"Polled, logged alerts\" offers\
    \ all of the advantages inherent in\n   polling (reliable detection of failures,\
    \ reduced agent complexity\n   with UDP, etc.), while minimizing the typical polling\
    \ problems\n   (potentially shorter poll cycle time and reduced network management\n\
    \   traffic).\n   Finally, alerts are not lost when an agent is isolated from\
    \ its\n   manager.  When a connection is reestablished, a history of conditions\n\
    \   that may no longer be in effect is available to the manager.  While\n   not\
    \ a part of this document, it is worthwhile to note that this same\n   log architecture\
    \ can be employed to archive alert and other\n   information on remote hosts.\
    \  However, such non-local storage is not\n   sufficient to meet the reliability\
    \ requirements of \"polled, logged\n   alerts\".\n"
- title: 7.  Compatibility with SNMP [4] and CMOT [3]
  contents:
  - '7.  Compatibility with SNMP [4] and CMOT [3]

    '
- title: 7.1  Closed Loop (Feedback) Alert Reporting
  contents:
  - '7.1  Closed Loop (Feedback) Alert Reporting

    '
- title: 7.1.1  Use of Feedback with SNMP
  contents:
  - "7.1.1  Use of Feedback with SNMP\n   At configuration time, an SNMP agent supporting\
    \ Feedback/Pin is\n   loaded with default values of \"windowTime\" and \"maxAlerts-PerTime\"\
    ,\n   and \"alertsEnabled\" is set to TRUE.  The manager issues an SNMP GET\n\
    \   to determine \"maxAlertsPerTime\" and \"windowTime\", and to verify the\n\
    \   state of \"alertsEnabled\".  Should the agent support setting Pin\n   objects,\
    \ the manager may choose to alter these values (via an SNMP\n   SET).  The new\
    \ values are calculated based upon known network\n   resource limitations (e.g.,\
    \ the amount of packets the manager's\n   gateway can support) and the number\
    \ of agents potentially reporting\n   to this manager.\n   Upon receipt of an\
    \ \"alertsDisabled\" trap, a manager whose state and\n   network are not overutilized\
    \ immediately issues an SNMP SET to make\n   \"alertsEnabled\" TRUE.  Should an\
    \ excessive number of \"alertsDisabled\"\n   traps regularly occur, the manager\
    \ might revisit the values chosen\n   for implementing the Pin mechanism.  Note\
    \ that an overutilized system\n   expects its manager to delay the resetting of\
    \ \"alertsEnabled\".\n   As a part of each regular polling cycle, the manager\
    \ includes a GET\n   REQUEST for the value of \"alertsEnabled\".  If this value\
    \ is FALSE, it\n   is SET to TRUE, and the potential loss of traps (while it was\
    \ FALSE)\n   is noted.\n"
- title: 7.1.2  Use of Feedback with CMOT
  contents:
  - "7.1.2  Use of Feedback with CMOT\n   The use of CMOT in implementing Feedback/Pin\
    \ is essentially identical\n   to the use of SNMP.  CMOT GET, SET, and EVENT replace\
    \ their SNMP\n   counterparts.\n"
- title: 7.2  Polled, Logged Alerts
  contents:
  - '7.2  Polled, Logged Alerts

    '
- title: 7.2.1  Use of Polled, Logged alerts with SNMP
  contents:
  - "7.2.1  Use of Polled, Logged alerts with SNMP\n   As a part of regular polling,\
    \ an SNMP manager using Polled, logged\n   alerts may issue a GET_NEXT Request\
    \ naming\n   { alertLog logTableEntry(1) alertId(1) 0 }.  Returned is either the\n\
    \   alertId of the first table entry or, if the table is empty, an SNMP\n   reply\
    \ whose object is the \"lexicographical successor\" to the alert\n   log.\n  \
    \ Should an \"alertId\" be returned, the manager issues an SNMP GET\n   naming\
    \ { alertLog logTableEntry(1) alertData(2) value } where \"value\"\n   is the\
    \ alertId integer obtained from the previously described GET\n   NEXT.  This returns\
    \ the SNMP TRAP encapsulated within an OPAQUE.\n   If the agent supports the deletion\
    \ of table entries through SNMP\n   SETS, the manager may then issue a SET of\
    \ { alertLog logTableEntry(1)\n   alertId(1) value } to remove the entry from\
    \ the log.  Otherwise, the\n   next GET NEXT poll of this agent should request\
    \ the first \"alertId\"\n   following the instance of \"value\" rather than an\
    \ instance of \"0\".\n"
- title: 7.2.2  Use of Polled, Logged Alerts with CMOT
  contents:
  - "7.2.2  Use of Polled, Logged Alerts with CMOT\n   Using polled, logged alerts\
    \ with CMOT is similar to using them with\n   SNMP.  In order to test for table\
    \ entries, one uses a CMOT GET and\n   specifies scoping to the alertLog.  The\
    \ request is for all table\n   entries that have an alertId value greater than\
    \ the last known\n   alertId, or greater than zero if the table is normally kept\
    \ empty by\n   the manager.  Should the agent support it, entries are removed\
    \ with a\n   CMOT DELETE, an object of alertLog.entry, and a distinguishing\n\
    \   attribute of the alertId to remove.\n"
- title: 8.  Multiple Manager Environments
  contents:
  - "8.  Multiple Manager Environments\n   The conflicts between multiple managers\
    \ with overlapping\n   administrative domains (generally found in larger networks)\
    \ tend to\n   be resolved in protocol specific manners.  This document has not\n\
    \   addressed them.  However, real world demands require alert management\n  \
    \ techniques to function in such environments.\n   Complex agents can clearly\
    \ respond to different managers (or managers\n   in different \"communities\"\
    ) with different reply values.  This allows\n   feedback and polled, logged alerts\
    \ to appear completely independent\n   to differing autonomous regions (each region\
    \ sees its own value).\n   Differing feedback thresholds might exist, and feedback\
    \ can be\n   actively blocking alerts to one manager even after another manager\n\
    \   has reenabled its own alert reporting.  All of this is transparent to\n  \
    \ an SNMP user if based on communities, or each manager can work with a\n   different\
    \ copy of the relevant MIB objects.  Those implementing CMOT\n   might view these\
    \ as multiple instances of the same feedback objects\n   (and allow one manager\
    \ to query the state of another's feedback\n   mechanism).\n   The same holds\
    \ true for polled, logged alerts.  One manager (or\n   manager in a single community/region)\
    \ can delete an alert from its\n   view without affecting the view of another\
    \ region's managers.\n   Those preferring less complex agents will recognize the\
    \ opportunity\n   to instrument proxy management.  Alerts might be distributed\
    \ from a\n   manager based alert exploder which effectively implements feedback\n\
    \   and polled, logged alerts for its subscribers.  Feedback parameters\n   are\
    \ set on each agent to the highest rate of any subscriber, and\n   limited by\
    \ the distributor.  Logged alerts are deleted from the view\n   at the proxy manager,\
    \ and truly deleted at the agent only when all\n   subscribers have so requested,\
    \ or immediately deleted at the agent\n   with the first proxy request, and maintained\
    \ as virtual entries by\n   the proxy manager for the benefit of other subscribers.\n"
- title: 9.  Summary
  contents:
  - "9.  Summary\n   While \"polled, logged alerts\" may be useful, they still have\
    \ a\n   limitation: the mean time to detect failures and alerts increases\n  \
    \ linearly as networks grow in size (hierarchies offer shorten\n   individual\
    \ poll cycle times, but the mean detection time is the sum\n   of 1/2 of each\
    \ cycle time).  For this reason, it may be necessary to\n   supplement asynchronous\
    \ generation of alerts (and \"polled, logged\n   alerts\") with unrequested transmission\
    \ of the alerts on very large\n   networks.\n   Whenever systems generate and\
    \ asynchronously transmit alerts, the\n   potential to overburden (over-inform)\
    \ a management station exists.\n   Mechanisms to protect a manager, such as the\
    \ \"Feedback/Pin\"\n   technique, risk losing potentially important information.\
    \  Failure to\n   implement asynchronous alerts increases the time for the manager\
    \ to\n   detect and react to a problem.  Over-reporting may appear less\n   critical\
    \ (and likely) a problem than under-informing, but the\n   potential for harm\
    \ exists with unbounded alert generation.\n   An ideal management system will\
    \ generate alerts to notify its\n   management station (or stations) of error\
    \ conditions.  However, these\n   alerts must be self limiting with required positive\
    \ feedback.  In\n   addition, the manager should periodically poll to ensure connectivity\n\
    \   to remote stations, and to retrieve copies of any alerts that were\n   not\
    \ delivered by the network.\n"
- title: 10.  References
  contents:
  - "10.  References\n   [1] Rose, M., and K. McCloghrie, \"Structure and Identification\
    \ of\n       Management Information for TCP/IP-based Internets\", RFC 1155,\n\
    \       Performance Systems International and Hughes LAN Systems, May\n      \
    \ 1990.\n   [2] McCloghrie, K., and M. Rose, \"Management Information Base for\n\
    \       Network Management of TCP/IP-based internets\", RFC 1213, Hughes\n   \
    \    LAN Systems, Inc., Performance Systems International, March 1991.\n   [3]\
    \ Warrier, U., Besaw, L., LaBarre, L., and B. Handspicker, \"Common\n       Management\
    \ Information Services and Protocols for the Internet\n       (CMOT) and (CMIP)\"\
    , RFC 1189, Netlabs, Hewlett-Packard, The Mitre\n       Corporation, Digital Equipment\
    \ Corporation, October 1990.\n   [4] Case, J., Fedor, M., Schoffstall, M., and\
    \ C. Davin, \"Simple\n       Network Management Protocol\" RFC 1157, SNMP Research,\
    \ Performance\n       Systems International, Performance Systems International,\
    \ MIT\n       Laboratory for Computer Science, May 1990.\n   [5] Reynolds, J.,\
    \ and J. Postel, \"Assigned Numbers\", RFC 1060,\n       USC/Information Sciences\
    \ Institute, March 1990.\n"
- title: 11.  Acknowledgements
  contents:
  - "11.  Acknowledgements\n   This memo is the product of work by the members of\
    \ the IETF Alert-Man\n   Working Group and other interested parties, whose efforts\
    \ are\n   gratefully acknowledged here:\n      Amatzia Ben-Artzi          Synoptics\
    \ Communications\n      Neal Bierbaum              Vitalink Corp.\n      Jeff\
    \ Case                  University of Tennessee at Knoxville\n      John Cook\
    \                  Chipcom Corp.\n      James Davin                MIT\n     \
    \ Mark Fedor                 Performance Systems International, Inc.\n      Steven\
    \ Hunter              Lawrence Livermore National Labs\n      Frank Kastenholz\
    \           Clearpoint Research\n      Lee LaBarre                Mitre Corp.\n\
    \      Bruce Laird                BBN, Inc\n      Gary Malkin                FTP\
    \ Software, Inc.\n      Keith McCloghrie           Hughes Lan Systems\n      David\
    \ Niemi                Contel Federal Systems\n      Lee Oattes              \
    \   University of Toronto\n      Joel Replogle              NCSA\n      Jim Sheridan\
    \               IBM Corp.\n      Steve Waldbusser           Carnegie-Mellon University\n\
    \      Dan Wintringham            Ohio Supercomputer Center\n      Rich Woundy\
    \                IBM Corp.\n"
- title: Appendix A
  contents:
  - "Appendix A\n   Example of polling costs\n      The following example is completely\
    \ hypothetical, and arbitrary.\n      It assumes that a network manager has made\
    \ decisions as to which\n      systems, and which objects on each system, must\
    \ be continuously\n      monitored to determine the operational state of a network.\
    \  It\n      does not attempt to discuss how such decisions are made, and\n  \
    \    assumes that they were arrived at with the full understanding that\n    \
    \  the costs of polling many objects must be weighed against the\n      level\
    \ of information required.\n      Consider a manager that must monitor 40 gateways\
    \ and hosts on a\n      single network.  Further assume that the average managed\
    \ entity\n      has 10 MIB objects that must be watched to determine the device's\n\
    \      and network's overall \"health\".  Under the XYZ network management\n \
    \     protocol, the manager may get the values of up to 4 MIB objects\n      with\
    \ a single request (so that 3 requests must be made to\n      determine the status\
    \ of a single entity).  An average response\n      time of 5 seconds is assumed,\
    \ and a lack of response within 30\n      seconds is considered no reply.  Two\
    \ such \"no replies\" are needed\n      to declare the managed entity \"unreachable\"\
    , as a single packet\n      may occasionally be dropped in a UDP system (those\
    \ preferring to\n      use TCP for automated retransmits should assume a longer\
    \ timeout\n      value before declaring the entity \"unreachable\" which we will\n\
    \      define as 60 seconds).\n      We begin with the case of \"sequential polling\"\
    .  This is defined\n      as awaiting a response to an outstanding request before\
    \ issuing\n      any further requests.  In this example, the average XYZ network\n\
    \      management protocol packet size is 300 bytes \"on the wire\"\n      (requesting\
    \ multiple objects, ASN.1 encoded, IP and UDP enveloped,\n      and placed in\
    \ an ethernet packet).  120 request packets are sent\n      each cycle (3 for\
    \ each of 40 nodes), and 120 response packets are\n      expected.  72000 bytes\
    \ (240 packets at 300 bytes each) must be\n      transferred during each poll\
    \ cycle, merely to determine that the\n      network is fine.\n      At five seconds\
    \ per transaction, it could take up to 10 minutes to\n      determine the state\
    \ of a failing machine (40 systems x 3 requests\n      each x 5 seconds per request).\
    \  The mean time to detect a system\n      with errors is 1/2 of the poll cycle\
    \ time, or 5 minutes.  In a\n      failing network, dropped packets (that must\
    \ be timed out and\n      resent) greatly increase the mean and worst case times\
    \ to detect\n      problems.\n      Note that the traffic costs could be substantially\
    \ reduced by\n      combining each set of three request/response packets in a\
    \ single\n      request/response transaction (see section 6.1.1 \"Example\").\n\
    \      While the bandwidth use is spread over 10 minutes (giving a usage\n   \
    \   of 120 bytes/second), this rapidly deteriorates should the manager\n     \
    \ decrease his poll cycle time to accommodate more machines or\n      improve\
    \ his mean time to fault detection.  Conversely, increasing\n      his delay between\
    \ polls reduces traffic flow, but does so at the\n      expense of time to detect\
    \ problems.\n      Many network managers allow multiple poll requests to be \"\
    pending\"\n      at any given time.  It is assumed that such managers would not\n\
    \      normally poll every machine without any delays.  Allowing\n      \"parallel\
    \ polling\" and initiating a new request immediately\n      following any response\
    \ would tend to generate larger amounts of\n      traffic; \"parallel polling\"\
    \ here produces 40 times the amount of\n      network traffic generated in the\
    \ simplistic case of \"sequential\n      polling\" (40 packets are sent and 40\
    \ replies received every 5\n      seconds, giving 80 packets x 300 bytes each\
    \ per 5 seconds, or 4800\n      bytes/second).  Mean time to detect errors drops,\
    \ but at the cost\n      of increased bandwidth.  This does not improve the timeout\
    \ value\n      of over 2 minutes to detect that a node is not responding.\n  \
    \    Even with parallel polling, increasing the device count (systems\n      to\
    \ manage) not only results in more traffic, but can degrade\n      performance.\
    \  On large networks the manager becomes bounded by the\n      number of queries\
    \ that can be built, tracked, responses parsed,\n      and reacted to per second.\
    \  The continuous volume requires the\n      timeout value to be increased to\
    \ accommodate responses that are\n      still in transit or have been received\
    \ and are queued awaiting\n      processing.  The only alternative is to reduce\
    \ the poll cycle.\n      Either of these actions increase both mean time to detect\
    \ failure\n      and worst case time to detect problems.\n      If alerts are\
    \ sent in place of polling, mean time to fault\n      detection drops from over\
    \ a minute to as little as 2.5 seconds\n      (1/2 the time for a single request-response\
    \ transaction).  This\n      time may be increased slightly, depending on the\
    \ nature of the\n      problem.  Typical network utilization is zero (assuming\
    \ a\n      \"typical\" case of a non-failing system).\n"
- title: Appendix B
  contents:
  - "Appendix B\n              All defined MIB objects used in this document reside\n\
    \              under the mib subtree:\n              alertMan ::= { iso(1) org(3)\
    \ dod(6) internet(1)\n                    experimental(3) alertMan(24) ver1(1)\
    \ }\n              as defined in the Internet SMI [1] and the latest \"Assigned\n\
    \              Numbers\" RFC [5]. Objects under this branch are assigned\n   \
    \           as follows:\n              RFC 1224-MIB DEFINITIONS ::= BEGIN\n  \
    \            alertMan        OBJECT IDENTIFIER ::= { experimental 24 }\n     \
    \         ver1            OBJECT IDENTIFIER ::= { alertMan 1 }\n             \
    \ feedback        OBJECT IDENTIFIER ::= { ver1 1 }\n              polledLogged\
    \    OBJECT IDENTIFIER ::= { ver1 2 }\n              END\n              1) Feedback\
    \ Objects\n                 OBJECT:\n                 ------\n               \
    \  maxAlertsPerTime { feedback 1 }\n                 Syntax:\n               \
    \     Integer\n                 Access:\n                    read-write\n    \
    \             Status:\n                    mandatory\n                 OBJECT:\n\
    \                 ------\n                 windowTime { feedback 2 }\n       \
    \          Syntax:\n                    Integer\n                 Access:\n  \
    \                  read-write\n                 Status:\n                    mandatory\n\
    \                 OBJECT:\n                 ------\n                 alertsEnabled\
    \ { feedback 3 }\n                 Syntax:\n                    Integer\n    \
    \             Access:\n                    read-write\n                 Status:\n\
    \                    mandatory\n              2) Polled, Logged Objects\n    \
    \             OBJECT:\n                 ------\n                 alertLog { polledLogged\
    \ 1 }\n                 Syntax:\n                    SEQUENCE OF logTableEntry\n\
    \                 Access:\n                    read-write\n                 Status:\n\
    \                    mandatory\n                 OBJECT:\n                 ------\n\
    \                 logTableEntry { alertLog 1 }\n                 Syntax:\n   \
    \                 logTableEntry ::= SEQUENCE {\n                       alertId\n\
    \                          INTEGER,\n                       alertData\n      \
    \                    OPAQUE\n                    }\n                 Access:\n\
    \                    read-write\n                 Status:\n                  \
    \  mandatory\n                 OBJECT:\n                 ------\n            \
    \     alertId { logTableEntry 1 }\n                 Syntax:\n                \
    \    Integer\n                 Access:\n                    read-write\n     \
    \            Status:\n                    mandatory\n                 OBJECT:\n\
    \                 ------\n                 alertData { logTableEntry 2 }\n   \
    \              Syntax:\n                    Opaque\n                 Access:\n\
    \                    read-only\n                 Status:\n                   \
    \ mandatory\n                 OBJECT:\n                 ------\n             \
    \    maxLogTableEntries { polledLogged 2 }\n                 Syntax:\n       \
    \             Integer\n                 Access:\n                    read-only\n\
    \                 Status:\n                    optional\n"
- title: Security Considerations
  contents:
  - "Security Considerations\n   Security issues are not discussed in this memo.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Lou Steinberg\n   IBM NSFNET Software Development\n   472\
    \ Wheelers Farms Rd, m/s 91\n   Milford, Ct. 06460\n   Phone:     203-783-7175\n\
    \   EMail:     LOUISS@IBM.COM\n"
