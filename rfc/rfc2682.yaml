- title: __initial_text__
  contents:
  - '            Performance Issues in VC-Merge Capable ATM LSRs

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (1999).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   VC merging allows many routes to be mapped to the same VC label,\n\
    \   thereby providing a scalable mapping method that can support\n   thousands\
    \ of edge routers. VC merging requires reassembly buffers so\n   that cells belonging\
    \ to different packets intended for the same\n   destination do not interleave\
    \ with each other.  This document\n   investigates the impact of VC merging on\
    \ the additional buffer\n   required for the reassembly buffers and other buffers.\
    \  The main\n   result indicates that VC merging incurs a minimal overhead compared\n\
    \   to non-VC merging in terms of additional buffering. Moreover, the\n   overhead\
    \ decreases as utilization increases, or as the traffic\n   becomes more bursty.\n"
- title: 1.0 Introduction
  contents:
  - "1.0 Introduction\n   Recently some radical proposals to overhaul the legacy router\n\
    \   architectures have been presented by several organizations, notably\n   the\
    \ Ipsilon's IP switching [1], Cisco's Tag switching [2], Toshiba's\n   CSR [3],\
    \ IBM's ARIS [4], and IETF's MPLS [5].  Although the details\n   of their implementations\
    \ vary, there is one fundamental concept that\n   is shared by all these proposals:\
    \ map the route information to short\n   fixed-length labels so that next-hop\
    \ routers can be determined by\n   direct indexing.\n   Although any layer 2 switching\
    \ mechanism can in principle be applied,\n   the use of ATM switches in the backbone\
    \ network is believed to be a\n   very attractive solution since ATM hardware\
    \ switches have been\n   extensively studied and are widely available in many\
    \ different\n   architectures.  In this document, we will assume that layer 2\n\
    \   switching uses ATM technology. In this case, each IP packet may be\n   segmented\
    \ to multiple 53-byte cells before being switched.\n   Traditionally, AAL 5 has\
    \ been used as the encapsulation method in\n   data communications since it is\
    \ simple, efficient, and has a powerful\n   error detection mechanism.  For the\
    \ ATM switch to forward incoming\n   cells to the correct outputs, the IP route\
    \ information needs to be\n   mapped to ATM labels which are kept in the VPI or/and\
    \ VCI fields.\n   The relevant route information that is stored semi-permanently\
    \ in the\n   IP routing table contains the tuple (destination, next-hop router).\n\
    \   The route information changes when the network state changes and this\n  \
    \ typically occurs slowly, except during transient cases.  The word\n   \"destination\"\
    \ typically refers to the destination network (or CIDR\n   prefix), but can be\
    \ readily generalized to (destination network,\n   QoS), (destination host, QoS),\
    \ or many other granularities. In this\n   document, the destination can mean\
    \ any of the above or other possible\n   granularities.\n   Several methods of\
    \ mapping the route information to ATM labels exist.\n   In the simplest form,\
    \ each source-destination pair is mapped to a\n   unique VC value at a switch.\
    \ This method, called the non-VC merging\n   case, allows the receiver to easily\
    \ reassemble cells into respective\n   packets since the VC values can be used\
    \ to distinguish the senders.\n   However, if there are n sources and destinations,\
    \ each switch is\n   potentially required to manage O(n^2) VC labels for full-meshed\n\
    \   connectivity.  For example, if there are 1,000 sources/destinations,\n   then\
    \ the size of the VC routing table is on the order of 1,000,000\n   entries. \
    \ Clearly, this method is not scalable to large networks.  In\n   the second method\
    \ called  VP merging, the VP labels of cells that are\n   intended for the same\
    \ destination would be translated to the same\n   outgoing VP value, thereby reducing\
    \ VP consumption downstream.  For\n   each VP, the VC value is used to identify\
    \ the sender so that the\n   receiver can reconstruct packets even though cells\
    \ from different\n   packets are allowed to interleave.  Each switch is now required\
    \ to\n   manage O(n) VP labels - a considerable saving from O(n^2).  Although\n\
    \   the number of label entries is considerably reduced, VP merging  is\n   limited\
    \ to only 4,096 entries at the network-to-network interface.\n   Moreover, VP\
    \ merging requires coordination of the VC values for a\n   given VP, which introduces\
    \ more complexity.  A third method, called\n   VC merging, maps incoming VC labels\
    \ for the same destination to the\n   same outgoing VC label. This method is scalable\
    \ and does not have the\n   space constraint problem as in VP merging. With VC\
    \ merging, cells for\n   the same destination is indistinguishable at the output\
    \ of a switch.\n   Therefore, cells belonging to different packets for the same\n\
    \   destination cannot interleave with each other, or else the receiver\n   will\
    \ not be able to reassemble the packets.  With VC merging, the\n   boundary between\
    \ two adjacent packets are identified by the \"End-of-\n   Packet\" (EOP) marker\
    \ used by AAL 5.\n   It is worthy to mention that cell interleaving may be allowed\
    \ if we\n   use the AAL 3/4 Message Identifier (MID) field to identify the sender\n\
    \   uniquely. However, this method has some serious drawbacks as:  1) the\n  \
    \ MID size may not be sufficient to identify all senders, 2) the\n   encapsulation\
    \ method is not efficient, 3) the CRC capability is not\n   as powerful as in\
    \ AAL 5, and 4) AAL 3/4 is not as widely supported as\n   AAL 5 in data communications.\n\
    \   Before VC merging with no cell interleaving can be qualified as the\n   most\
    \ promising approach, two main issues need to be addressed.\n   First, the feasibility\
    \ of an ATM switch that is capable of merging\n   VCs needs to be investigated.\
    \ Second, there is widespread concern\n   that the additional amount of buffering\
    \ required to implement VC\n   merging is excessive and thus making the VC-merging\
    \ method\n   impractical.  Through analysis and simulation, we will dispel these\n\
    \   concerns in this document by showing that the additional buffer\n   requirement\
    \ for VC merging is minimal for most practical purposes.\n   Other performance\
    \ related issues such as additional delay due to VC\n   merging will also be discussed.\n"
- title: 2.0 A VC-Merge Capable MPLS Switch Architecture
  contents:
  - "2.0 A VC-Merge Capable MPLS Switch Architecture\n   In principle, the reassembly\
    \ buffers can be placed at the input or\n   output side of a switch. If they are\
    \ located at the input, then the\n   switch fabric has to transfer all cells belonging\
    \ to a given packet\n   in an atomic manner since cells are not allowed to interleave.\
    \  This\n   requires the fabric to perform frame switching which is not flexible\n\
    \   nor desirable when multiple QoSs need to be supported.  On the other\n   hand,\
    \ if the reassembly buffers are located at the output, the switch\n   fabric can\
    \ forward each cell independently as in normal ATM\n   switching.  Placing the\
    \ reassembly buffers at the output makes an\n   output-buffered ATM switch a natural\
    \ choice.\n   We consider a generic output-buffered VC-merge capable MPLS switch\n\
    \   with VCI translation performed at the output. Other possible\n   architectures\
    \ may also be adopted.  The switch consists of a non-\n   blocking cell switch\
    \ fabric and multiple output modules (OMs), each\n   is associated with an output\
    \ port.  Each arriving ATM cell is\n   appended with two fields containing an\
    \ output port number and an\n   input port number.  Based on the output port number,\
    \ the switch\n   fabric forwards each cell to the correct output port, just as\
    \ in\n   normal ATM switches.  If VC merging is not implemented, then the OM\n\
    \   consists of an output buffer.  If VC merging is implemented, the OM\n   contains\
    \ a number of reassembly buffers (RBs), followed by a merging\n   unit, and an\
    \ output buffer. Each RB typically corresponds to an\n   incoming VC value. It\
    \ is important to note that each buffer is a\n   logical buffer, and it is envisioned\
    \ that there is a common pool of\n   memory for the reassembly buffers and the\
    \ output buffer.\n   The purpose of the RB is to ensure that cells for a given\
    \ packet do\n   not interleave with other cells that are merged to the same VC.\
    \  This\n   mechanism (called store-and-forward at the packet level) can be\n\
    \   accomplished by storing each incoming cell for a given packet at the\n   RB\
    \ until the last cell of the packet arrives.  When the last cell\n   arrives,\
    \ all cells in the packet are transferred in an atomic manner\n   to the output\
    \ buffer for transmission to the next hop. It is worth\n   pointing out that performing\
    \ a cut-through mode at the RB is not\n   recommended since it would result in\
    \ wastage of bandwidth if the\n   subsequent cells are delayed.  During the transfer\
    \ of a packet to the\n   output buffer, the incoming VCI is translated to the\
    \ outgoing VCI by\n   the merging unit.  To save VC translation table space, different\n\
    \   incoming VCIs are merged to the same outgoing VCI during the\n   translation\
    \ process if the cells are intended for the same\n   destination.  If all traffic\
    \ is best-effort, full-merging where all\n   incoming VCs destined for the same\
    \ destination network are mapped to\n   the same outgoing VC, can be implemented.\
    \  However, if the traffic is\n   composed of multiple classes, it is desirable\
    \ to implement partial\n   merging, where incoming VCs destined for the same (destination\n\
    \   network, QoS) are mapped to the same outgoing VC.\n   Regardless of whether\
    \ full merging or partial merging is implemented,\n   the output buffer may consist\
    \ of a single FIFO buffer or multiple\n   buffers each corresponding to a destination\
    \ network or (destination\n   network, QoS).  If a single output buffer is used,\
    \ then the switch\n   essentially tries to emulate frame switching.  If multiple\
    \ output\n   buffers are used, VC merging is different from frame switching since\n\
    \   cells of a given packet are not bound to be transmitted back-to-back.\n  \
    \ In fact, fair queueing can be implemented so that cells from their\n   respective\
    \ output buffers are served according to some QoS\n   requirements. Note that\
    \ cell-by-cell scheduling can be implemented\n   with VC merging, whereas only\
    \ packet-by-packet scheduling can be\n   implemented with frame switching.  In\
    \ summary, VC merging is more\n   flexible than frame switching and supports better\
    \ QoS control.\n"
- title: 3.0 Performance Investigation of VC Merging
  contents:
  - "3.0 Performance Investigation of VC Merging\n   This section compares the VC-merging\
    \ switch and the non-VC merging\n   switch. The non-VC merging switch is analogous\
    \ to the traditional\n   output-buffered ATM switch, whereby cells of any packets\
    \ are allowed\n   to interleave.  Since each cell is a distinct unit of information,\n\
    \   the non-VC merging switch is a work-conserving system at the cell\n   level.\
    \  On the other hand, the VC-merging switch is non-work\n   conserving so its\
    \ performance is always lower than that of the non-VC\n   merging switch.  The\
    \ main objective here is to study the effect of VC\n   merging on performance\
    \ implications of MPLS switches such as\n   additional delay, additional buffer,\
    \ etc., subject to different\n   traffic conditions.\n   In the simulation, the\
    \ arrival process to each reassembly buffer is\n   an independent ON-OFF process.\
    \ Cells within an ON period form a\n   single packet. During an OFF periof, the\
    \ slots are idle.  Note that\n   the ON-OFF process is a general process that\
    \ can model any traffic\n   process.\n"
- title: 3.1 Effect of Utilization on Additional Buffer Requirement
  contents:
  - "3.1 Effect of Utilization on Additional Buffer Requirement\n   We first investigate\
    \ the effect of switch utilization on the\n   additional buffer requirement for\
    \ a given overflow probability.  To\n   carry the comparison, we analyze the VC-merging\
    \ and non-VC merging\n   case when the average packet size is equal to 10 cells,\
    \ using\n   geometrically distributed packet sizes and packet interarrival times,\n\
    \   with cells of a packet arriving contiguously (later, we consider\n   other\
    \ distributions).  The results show, as expected, the VC-merging\n   switch requires\
    \ more buffers than the non-VC merging switch. When the\n   utilization is low,\
    \ there may be relatively many incomplete packets\n   in the reassembly buffers\
    \ at any given time, thus wasting storage\n   resource.  For example, when the\
    \ utilization is 0.3, VC merging\n   requires an additional storage of about 45\
    \ cells to achieve the same\n   overflow probability.  However, as the utilization\
    \ increases to 0.9,\n   the additional storage to achieve the same overflow probability\
    \ drops\n   to about 30 cells.  The reason is that when traffic intensity\n  \
    \ increases, the VC-merging system becomes more work-conserving.\n   It is important\
    \ to note that ATM switches must be dimensioned at high\n   utilization value\
    \ (in the range of 0.8-0.9) to withstand harsh\n   traffic conditions.  At the\
    \ utilization of 0.9, a VC-merge ATM switch\n   requires a buffer of size 976\
    \ cells to provide an overflow\n   probability of 10^{-5}, whereas an non-VC merge\
    \ ATM switch requires a\n   buffer of size 946.  These numbers translate the additional\
    \ buffer\n   requirement for VC merging to about 3% - hardly an additional\n \
    \  buffering cost.\n"
- title: 3.2 Effect of Packet Size on Additional Buffer Requirement
  contents:
  - "3.2 Effect of Packet Size on Additional Buffer Requirement\n   We now vary the\
    \ average packet size to see the impact on the buffer\n   requirement.  We fix\
    \ the utilization to 0.5 and use two different\n   average packet sizes; that\
    \ is, B=10 and B=30. To achieve the same\n   overflow probability, VC merging\
    \ requires an additional buffer of\n   about 40 cells (or 4 packets) compared\
    \ to non-VC merging when B=10.\n   When B=30, the additional buffer requirement\
    \ is about 90 cells (or 3\n   packets).  As expected, the additional buffer requirement\
    \ in terms of\n   cells increases as the packet size increases. However, the additional\n\
    \   buffer requirement is roughly constant in terms of packets.\n"
- title: 3.3 Additional Buffer Overhead Due to Packet Reassembly
  contents:
  - "3.3 Additional Buffer Overhead Due to Packet Reassembly\n   There may be some\
    \ concern that VC merging may require too much\n   buffering when the number of\
    \ reassembly buffers increases, which\n   would happen if the switch size is increased\
    \ or if cells for packets\n   going to different destinations are allowed to interleave.\
    \  We will\n   show that the concern is unfounded since buffer sharing becomes\
    \ more\n   efficient as the number of reassembly buffers increases.\n   To demonstrate\
    \ our argument, we consider the overflow probability for\n   VC merging for several\
    \ values of reassembly buffers (N); i.e., N=4,\n   8, 16, 32, 64, and 128.  The\
    \ utilization is fixed to 0.8 for each\n   case, and the average packet size is\
    \ chosen to be 10.  For a given\n   overflow probability, the increase in buffer\
    \ requirement becomes less\n   pronounced as N increases.  Beyond a certain value\
    \ (N=32), the\n   increase in buffer requirement becomes insignificant.  The reason\
    \ is\n   that as N increases, the traffic gets thinned and eventually\n   approaches\
    \ a limiting process.\n"
- title: 3.4 Effect of Interarrival time Distribution on Additional Buffer
  contents:
  - "3.4 Effect of Interarrival time Distribution on Additional Buffer\n   We now\
    \ turn our attention to different traffic processes.  First, we\n   use the same\
    \ ON period distribution and change the OFF period\n   distribution from geometric\
    \ to hypergeometric which has a larger\n   Square Coefficient of Variation (SCV),\
    \ defined to be the ratio of the\n   variance to the square of the mean.  Here\
    \ we fix the utilization at\n   0.5.  As expected, the switch performance degrades\
    \ as the SCV\n   increases in both the VC-merging and non-VC merging cases.  To\n\
    \   achieve a buffer overflow probability of 10^{-4}, the additional\n   buffer\
    \ required is about 40 cells when SCV=1, 26 cells when SCV=1.5,\n   and 24 cells\
    \ when SCV=2.6.  The result shows that VC merging becomes\n   more work-conserving\
    \ as SCV increases.  In summary, as the\n   interarrival time between packets\
    \ becomes more bursty, the additional\n   buffer requirement for VC merging diminishes.\n"
- title: 3.5 Effect of Internet Packets on Additional Buffer Requirement
  contents:
  - "3.5 Effect of Internet Packets on Additional Buffer Requirement\n   Up to now,\
    \ the packet size has been modeled as a geometric\n   distribution with a certain\
    \ parameter.  We modify the packet size\n   distribution to a more realistic one\
    \ for the rest of this document.\n   Since the initial deployment of VC-merge\
    \ capable ATM switches is\n   likely to be in the core network, it is more realistic\
    \ to consider\n   the packet size distribution in the Wide Area Network.  To this\
    \ end,\n   we refer to the data given in [6].  The data collected on Feb 10,\n\
    \   1996, in FIX-West network, is in the form of probability mass\n   function\
    \ versus packet size in bytes.  Data collected at other dates\n   closely resemble\
    \ this one.\n   The distribution appears bi-modal with two big masses at 40 bytes\n\
    \   (about a third) due to TCP acknowledgment packets, and 552 bytes\n   (about\
    \ 22 percent) due to Maximum Transmission Unit (MTU) limitations\n   in many routers.\
    \ Other prominent packet sizes include 72 bytes (about\n   4.1 percent), 576 bytes\
    \ (about 3.6 percent), 44 bytes (about 3\n   percent), 185 bytes (about 2.7 percent),\
    \ and 1500 bytes (about 1.5\n   percent) due to Ethernet MTU. The mean packet\
    \ size is  257 bytes, and\n   the variance is 84,287 bytes^2. Thus, the SCV for\
    \ the Internet packet\n   size is about 1.1.\n   To convert the IP packet size\
    \ in bytes to ATM cells, we assume AAL 5\n   using null encapsulation where the\
    \ additional overhead in AAL 5 is 8\n   bytes long [7].  Using the null encapsulation\
    \ technique, the average\n   packet size is about 6.2 ATM cells.\n   We examine\
    \ the buffer overflow probability against the buffer size\n   using the Internet\
    \ packet size distribution. The OFF period is\n   assumed to have a geometric\
    \ distribution.  Again, we find that the\n   same behavior as before, except that\
    \ the buffer requirement drops\n   with Internet packets due to smaller average\
    \ packet size.\n"
- title: 3.6 Effect of Correlated Interarrival Times on Additional Buffer
  contents:
  - "3.6 Effect of Correlated Interarrival Times on Additional Buffer\n    Requirement\n\
    \   To model correlated interarrival times, we use the DAR(p) process\n   (discrete\
    \ autoregressive process of order p) [8], which has been used\n   to accurately\
    \ model video traffic (Star Wars movie) in [9].  The\n   DAR(p) process is a p-th\
    \ order (lag-p) discrete-time Markov chain.\n   The state of the process at time\
    \ n depends explicitly on the states\n   at times (n-1), ...,  (n-p).\n   We examine\
    \ the overflow probability for the case where the\n   interarrival time between\
    \ packets is geometric and independent, and\n   the case where the interarrival\
    \ time is geometric and correlated to\n   the previous one with coefficient of\
    \ correlation equal to 0.9. The\n   empirical distribution of the Internet packet\
    \ size from the last\n   section is used. The utilization is fixed to 0.5 in each\
    \ case.\n   Although, the overflow probability increases as p increases, the\n\
    \   additional amount of buffering actually decreases for VC merging as\n   p,\
    \ or equivalently the correlation, increases.  One can easily\n   conclude that\
    \ higher-order correlation or long-range dependence,\n   which occurs in self-similar\
    \ traffic, will result in similar\n   qualitative performance.\n"
- title: 3.7 Slow Sources
  contents:
  - "3.7 Slow Sources\n   The discussions up to now have assumed that cells within\
    \ a packet\n   arrive back-to-back. When traffic shaping is implemented, adjacent\n\
    \   cells within the same packet would typically be spaced by idle slots.\n  \
    \ We call such sources as \"slow sources\".  Adjacent cells within the\n   same\
    \ packet may also be perturbed and spaced as these cells travel\n   downstream\
    \ due to the merging and splitting of cells at preceding\n   nodes.\n   Here,\
    \ we assume that each source transmits at the rate of r_s (0 <\n   r_s < 1), in\
    \ units of link speed, to the ATM switch.  To capture the\n   merging and splitting\
    \ of cells as they travel in the network, we will\n   also assume that the cell\
    \ interarrival time within a packet is ran-\n   domly perturbed.  To model this\
    \ perturbation, we stretch the original\n   ON period by 1/r_s, and  flip a Bernoulli\
    \ coin with parameter r_s\n   during the stretched ON period. In other words,\
    \ a slot would contain\n   a cell with probability r_s, and would be idle with\
    \ probability 1-r_s\n   during the ON period. By doing so, the average packet\
    \ size remains\n   the same as r_s is varied.  We simulated slow sources on the\
    \ VC-merge\n   ATM switch using the Internet packet size distribution with r_s=1\
    \ and\n   r_s=0.2.  The packet interarrival time is assumed to be geometrically\n\
    \   distributed.  Reducing the source rate in general reduces the\n   stresses\
    \ on the ATM switches since the traffic becomes smoother.\n   With VC merging,\
    \ slow sources also have the effect of increasing the\n   reassembly time. At\
    \ utilization of 0.5, the reassembly time is more\n   dominant and causes the\
    \ slow source (with r_s=0.2) to require more\n   buffering than the fast source\
    \ (with r_s=1).  At utilization of 0.8,\n   the smoother traffic is more dominant\
    \ and causes the slow source\n   (with r_s=0.2) to require less buffering than\
    \ the fast source (with\n   r_s=1).  This result again has practical consequences\
    \ in ATM switch\n   design where buffer dimensioning is performed at reasonably\
    \ high\n   utilization. In this situation, slow sources only help.\n"
- title: 3.8 Packet Delay
  contents:
  - "3.8 Packet Delay\n   It is of interest to see the impact of cell reassembly on\
    \ packet\n   delay. Here we consider the delay at one node only; end-to-end delays\n\
    \   are subject of ongoing work.  We define the delay of a packet as the\n   time\
    \ between the arrival of the first cell of a packet at the switch\n   and the\
    \ departure of the last cell of the same packet.  We study the\n   average packet\
    \ delay as a function of utilization for both VC-merging\n   and non-VC merging\
    \ switches for the case r_s=1 (back-to-back cells in\n   a packet).  Again, the\
    \ Internet packet size distribution is used to\n   adopt the more realistic scenario.\
    \ The interarrival time of packets\n   is geometrically distributed.  Although\
    \ the difference in the worst-\n   case delay between VC-merging and non-VC merging\
    \ can be theoretically\n   very large, we consistently observe that the difference\
    \ in average\n   delays of the two systems to be consistently about one average\
    \ packet\n   time for a wide range of utilization. The difference is due to the\n\
    \   average time needed to reassemble a packet.\n   To see the effect of cell\
    \ spacing in a packet, we again simulate the\n   average packet delay for r_s=0.2.\
    \ We observe that the difference in\n   average delays of VC merging and non-VC\
    \ merging increases to a few\n   packet times (approximately 20 cells at high\
    \ utilization).  It should\n   be noted that when a VC-merge capable ATM switch\
    \ reassembles packets,\n   in effect it performs the task that the receiver has\
    \ to do otherwise.\n   From practical point-of-view, an increase in 20 cells translates\
    \ to\n   about 60 micro seconds at OC-3 link speed.  This additional delay\n \
    \  should be insignificant for most applications.\n"
- title: 4.0 Security Considerations
  contents:
  - "4.0 Security Considerations\n   There are no security considerations directly\
    \ related to this\n   document since the document is concerned with the performance\n\
    \   implications of VC merging. There are also no known security\n   considerations\
    \ as a result of the proposed modification of a legacy\n   ATM LSR to incorporate\
    \ VC merging.\n"
- title: 5.0 Discussion
  contents:
  - "5.0 Discussion\n   This document has investigated the impacts of VC merging on\
    \ the\n   performance of an ATM LSR.  We experimented with various traffic\n \
    \  processes to understand the detailed behavior of VC-merge capable ATM\n   LSRs.\
    \  Our main finding indicates that VC merging incurs a minimal\n   overhead compared\
    \ to non-VC merging in terms of additional buffering.\n   Moreover, the overhead\
    \ decreases as utilization increases, or as the\n   traffic becomes more bursty.\
    \  This fact has important practical\n   consequences since switches are dimensioned\
    \ for high utilization and\n   stressful traffic conditions.  We have considered\
    \ the case where the\n   output buffer uses a FIFO scheduling. However, based\
    \ on our\n   investigation on slow sources, we believe that fair queueing will\
    \ not\n   introduce a significant impact on the additional amount of buffering.\n\
    \   Others may wish to investigate this further.\n"
- title: 6.0 Acknowledgement
  contents:
  - "6.0 Acknowledgement\n   The authors thank Debasis Mitra for his penetrating questions\
    \ during\n   the internal talks and discussions.\n"
- title: 7.0 References
  contents:
  - "7.0 References\n   [1] P. Newman, Tom Lyon and G. Minshall, \"Flow Labelled IP:\n\
    \       Connectionless ATM Under IP\", in Proceedings of INFOCOM'96, San-\n  \
    \     Francisco, April 1996.\n   [2] Rekhter,Y., Davie, B., Katz, D., Rosen, E.\
    \ and G. Swallow, \"Cisco\n       Systems' Tag Switching Architecture Overview\"\
    , RFC 2105, February\n       1997.\n   [3] Katsube, Y., Nagami, K. and H. Esaki,\
    \ \"Toshiba's Router\n       Architecture Extensions for ATM: Overview\", RFC\
    \ 2098, February\n       1997.\n   [4] A. Viswanathan, N. Feldman, R. Boivie and\
    \ R. Woundy, \"ARIS:\n       Aggregate Route-Based IP Switching\", Work in Progress.\n\
    \   [5] R. Callon, P. Doolan, N. Feldman, A. Fredette, G. Swallow and A.\n   \
    \    Viswanathan, \"A Framework for Multiprotocol Label Switching\",\n       Work\
    \ in Progress.\n   [6] WAN Packet Size Distribution,\n       http://www.nlanr.net/NA/Learn/packetsizes.html.\n\
    \   [7] Heinanen, J., \"Multiprotocol Encapsulation over ATM Adaptation\n    \
    \   Layer 5\", RFC 1483, July 1993.\n   [8] P. Jacobs and P. Lewis, \"Discrete\
    \ Time Series Generated by\n       Mixtures III:  Autoregressive Processes (DAR(p))\"\
    , Technical\n       Report NPS55-78-022, Naval Postgraduate School, 1978.\n  \
    \ [9] B.K. Ryu and A. Elwalid, \"The Importance of Long-Range Dependence\n   \
    \    of VBR Video Traffic in ATM Traffic Engineering\", ACM SigComm'96,\n    \
    \   Stanford, CA, pp. 3-14, August 1996.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Indra Widjaja\n   Fujitsu Network Communications\n   Two\
    \ Blue Hill Plaza\n   Pearl River, NY 10965, USA\n   Phone: 914 731-2244\n   EMail:\
    \ indra.widjaja@fnc.fujitsu.com\n   Anwar Elwalid\n   Bell Labs, Lucent Technologies\n\
    \   600 Mountain Ave, Rm 2C-324\n   Murray Hill, NJ 07974, USA\n   Phone: 908\
    \ 582-7589\n   EMail: anwar@lucent.com\n"
- title: 9.  Full Copyright Statement
  contents:
  - "9.  Full Copyright Statement\n   Copyright (C) The Internet Society (1999). \
    \ All Rights Reserved.\n   This document and translations of it may be copied\
    \ and furnished to\n   others, and derivative works that comment on or otherwise\
    \ explain it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
