- title: __initial_text__
  contents:
  - ''
- title: Internet Architecture Board (IAB)                              R. Barnes
  contents:
  - "Internet Architecture Board (IAB)                              R. Barnes\n  \
    \       Confidentiality in the Face of Pervasive Surveillance:\n             \
    \     A Threat Model and Problem Statement\n"
- title: Abstract
  contents:
  - "Abstract\n   Since the initial revelations of pervasive surveillance in 2013,\n\
    \   several classes of attacks on Internet communications have been\n   discovered.\
    \  In this document, we develop a threat model that\n   describes these attacks\
    \ on Internet confidentiality.  We assume an\n   attacker that is interested in\
    \ undetected, indiscriminate\n   eavesdropping.  The threat model is based on\
    \ published, verified\n   attacks.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Architecture Board (IAB)\n   and represents information that\
    \ the IAB has deemed valuable to\n   provide for permanent record.  It represents\
    \ the consensus of the\n   Internet Architecture Board (IAB).  Documents approved\
    \ for\n   publication by the IAB are not a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7624.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2015 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction  . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   3\n   2.  Terminology . . . . . . . . . . . . . . . . . . . . .\
    \ . . . .   3\n   3.  An Idealized Passive Pervasive Attacker . . . . . . . .\
    \ . . .   5\n     3.1.  Information Subject to Direct Observation . . . . . .\
    \ . .   6\n     3.2.  Information Useful for Inference  . . . . . . . . . . .\
    \ .   6\n     3.3.  An Illustration of an Ideal Passive Pervasive Attack  . .\
    \   7\n       3.3.1.  Analysis of IP Headers  . . . . . . . . . . . . . . .  \
    \ 7\n       3.3.2.  Correlation of IP Addresses to User Identities  . . .   8\n\
    \       3.3.3.  Monitoring Messaging Clients for IP Address\n               Correlation\
    \ . . . . . . . . . . . . . . . . . . . . .   9\n       3.3.4.  Retrieving IP\
    \ Addresses from Mail Headers . . . . . .   9\n       3.3.5.  Tracking Address\
    \ Usage with Web Cookies . . . . . . .  10\n       3.3.6.  Graph-Based Approaches\
    \ to Address Correlation . . . .  10\n       3.3.7.  Tracking of Link-Layer Identifiers\
    \  . . . . . . . . .  10\n   4.  Reported Instances of Large-Scale Attacks . .\
    \ . . . . . . . .  11\n   5.  Threat Model  . . . . . . . . . . . . . . . . .\
    \ . . . . . . .  13\n     5.1.  Attacker Capabilities . . . . . . . . . . . .\
    \ . . . . . .  14\n     5.2.  Attacker Costs  . . . . . . . . . . . . . . . .\
    \ . . . . .  17\n   6.  Security Considerations . . . . . . . . . . . . . . .\
    \ . . . .  19\n   7.  References  . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .  20\n     7.1.  Normative References  . . . . . . . . . . . . . . . .\
    \ . .  20\n     7.2.  Informative References  . . . . . . . . . . . . . . . .\
    \ .  20\n   IAB Members at the Time of Approval . . . . . . . . . . . . . . .\
    \  23\n   Acknowledgements  . . . . . . . . . . . . . . . . . . . . . . . .  24\n\
    \   Authors' Addresses  . . . . . . . . . . . . . . . . . . . . . . .  24\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Starting in June 2013, documents released to the press by\
    \ Edward\n   Snowden have revealed several operations undertaken by intelligence\n\
    \   agencies to exploit Internet communications for intelligence\n   purposes.\
    \  These attacks were largely based on protocol\n   vulnerabilities that were\
    \ already known to exist.  The attacks were\n   nonetheless striking in their\
    \ pervasive nature, in terms of both the\n   volume of Internet traffic targeted\
    \ and the diversity of attack\n   techniques employed.\n   To ensure that the\
    \ Internet can be trusted by users, it is necessary\n   for the Internet technical\
    \ community to address the vulnerabilities\n   exploited in these attacks [RFC7258].\
    \  The goal of this document is\n   to describe more precisely the threats posed\
    \ by these pervasive\n   attacks, and based on those threats, lay out the problems\
    \ that need\n   to be solved in order to secure the Internet in the face of those\n\
    \   threats.\n   The remainder of this document is structured as follows.  In\n\
    \   Section 3, we describe an idealized passive pervasive attacker, one\n   which\
    \ could completely undetectably compromise communications at\n   Internet scale.\
    \  In Section 4, we provide a brief summary of some\n   attacks that have been\
    \ disclosed, and use these to expand the assumed\n   capabilities of our idealized\
    \ attacker.  Note that we do not attempt\n   to describe all possible attacks,\
    \ but focus on those that result in\n   undetected eavesdropping.  Section 5 describes\
    \ a threat model based\n   on these attacks, focusing on classes of attack that\
    \ have not been a\n   focus of Internet engineering to date.\n"
- title: 2.  Terminology
  contents:
  - "2.  Terminology\n   This document makes extensive use of standard security and\
    \ privacy\n   terminology; see [RFC4949] and [RFC6973].  Terms used from [RFC6973]\n\
    \   include Eavesdropper, Observer, Initiator, Intermediary, Recipient,\n   Attack\
    \ (in a privacy context), Correlation, Fingerprint, Traffic\n   Analysis, and\
    \ Identifiability (and related terms).  In addition, we\n   use a few terms that\
    \ are specific to the attacks discussed in this\n   document.  Note especially\
    \ that \"passive\" and \"active\" below do not\n   refer to the effort used to\
    \ mount the attack; a \"passive attack\" is\n   any attack that accesses a flow\
    \ but does not modify it, while an\n   \"active attack\" is any attack that modifies\
    \ a flow.  Some passive\n   attacks involve active interception and modifications\
    \ of devices,\n   rather than simple access to the medium.  The introduced terms\
    \ are:\n   Pervasive Attack:  An attack on Internet communications that makes\n\
    \      use of access at a large number of points in the network, or\n      otherwise\
    \ provides the attacker with access to a large amount of\n      Internet traffic;\
    \ see [RFC7258].\n   Passive Pervasive Attack:  An eavesdropping attack undertaken\
    \ by a\n      pervasive attacker, in which the packets in a traffic stream\n \
    \     between two endpoints are intercepted, but in which the attacker\n     \
    \ does not modify the packets in the traffic stream between two\n      endpoints,\
    \ modify the treatment of packets in the traffic stream\n      (e.g., delay, routing),\
    \ or add or remove packets in the traffic\n      stream.  Passive pervasive attacks\
    \ are undetectable from the\n      endpoints.  Equivalent to passive wiretapping\
    \ as defined in\n      [RFC4949]; we use an alternate term here since the methods\n\
    \      employed are wider than those implied by the word \"wiretapping\",\n  \
    \    including the active compromise of intermediate systems.\n   Active Pervasive\
    \ Attack:  An attack that is undertaken by a pervasive\n      attacker and, in\
    \ addition to the elements of a passive pervasive\n      attack, also includes\
    \ modification, addition, or removal of\n      packets in a traffic stream, or\
    \ modification of treatment of\n      packets in the traffic stream.  Active pervasive\
    \ attacks provide\n      more capabilities to the attacker at the risk of possible\n\
    \      detection at the endpoints.  Equivalent to active wiretapping as\n    \
    \  defined in [RFC4949].\n   Observation:  Information collected directly from\
    \ communications by\n      an eavesdropper or observer.  For example, the knowledge\
    \ that\n      <alice@example.com> sent a message to <bob@example.com> via SMTP\n\
    \      taken from the headers of an observed SMTP message would be an\n      observation.\n\
    \   Inference:  Information derived from analysis of information\n      collected\
    \ directly from communications by an eavesdropper or\n      observer.  For example,\
    \ the knowledge that a given web page was\n      accessed by a given IP address,\
    \ by comparing the size in octets of\n      measured network flow records to fingerprints\
    \ derived from known\n      sizes of linked resources on the web servers involved,\
    \ would be an\n      inference.\n   Collaborator:  An entity that is a legitimate\
    \ participant in a\n      communication, and provides information about that communication\n\
    \      to an attacker.  Collaborators may either deliberately or\n      unwittingly\
    \ cooperate with the attacker, in the latter case\n      because the attacker\
    \ has subverted the collaborator through\n      technical, social, or other means.\n\
    \   Key Exfiltration:  The transmission of cryptographic keying material\n   \
    \   for an encrypted communication from a collaborator, deliberately\n      or\
    \ unwittingly, to an attacker.\n   Content Exfiltration:  The transmission of\
    \ the content of a\n      communication from a collaborator, deliberately or unwittingly,\
    \ to\n      an attacker\n"
- title: 3.  An Idealized Passive Pervasive Attacker
  contents:
  - "3.  An Idealized Passive Pervasive Attacker\n   In considering the threat posed\
    \ by pervasive surveillance, we begin\n   by defining an idealized passive pervasive\
    \ attacker.  While this\n   attacker is less capable than those that we now know\
    \ to have\n   compromised the Internet from press reports, as elaborated in\n\
    \   Section 4, it does set a lower bound on the capabilities of an\n   attacker\
    \ interested in indiscriminate passive surveillance while\n   interested in remaining\
    \ undetectable.  We note that, prior to the\n   Snowden revelations in 2013, the\
    \ assumptions of attacker capability\n   presented here would be considered on\
    \ the border of paranoia outside\n   the network security community.\n   Our idealized\
    \ attacker is an indiscriminate eavesdropper that is on\n   an Internet-attached\
    \ computer network and:\n   o  can observe every packet of all communications\
    \ at any hop in any\n      network path between an initiator and a recipient;\n\
    \   o  can observe data at rest in any intermediate system between the\n     \
    \ endpoints controlled by the initiator and recipient; and\n   o  can share information\
    \ with other such attackers; but\n   o  takes no other action with respect to\
    \ these communications (i.e.,\n      blocking, modification, injection, etc.).\n\
    \   The techniques available to our ideal attacker are direct observation\n  \
    \ and inference.  Direct observation involves taking information\n   directly\
    \ from eavesdropped communications, such as URLs identifying\n   content or email\
    \ addresses identifying individuals from application-\n   layer headers.  Inference,\
    \ on the other hand, involves analyzing\n   observed information to derive new\
    \ information, such as searching for\n   application or behavioral fingerprints\
    \ in observed traffic to derive\n   information about the observed individual.\
    \  The use of encryption is\n   generally sufficient to provide confidentiality\
    \ by preventing direct\n   observation of content, assuming of course, uncompromised\
    \ encryption\n   implementations and cryptographic keying material.  However,\n\
    \   encryption provides less complete protection against inference,\n   especially\
    \ inferences based only on plaintext portions of\n   communications, such as IP\
    \ and TCP headers for TLS-protected traffic\n   [RFC5246].\n"
- title: 3.1.  Information Subject to Direct Observation
  contents:
  - "3.1.  Information Subject to Direct Observation\n   Protocols that do not encrypt\
    \ their payload make the entire content\n   of the communication available to\
    \ the idealized attacker along their\n   path.  Following the advice in [RFC3365],\
    \ most such protocols have a\n   secure variant that encrypts the payload for\
    \ confidentiality, and\n   these secure variants are seeing ever-wider deployment.\
    \  A noteworthy\n   exception is DNS [RFC1035], as DNSSEC [RFC4033] does not have\n\
    \   confidentiality as a requirement.\n   This implies that, in the absence of\
    \ changes to the protocol as\n   presently under development in the IETF's DNS\
    \ Private Exchange\n   (DPRIVE) working group [DPRIVE], all DNS queries and answers\n\
    \   generated by the activities of any protocol are available to the\n   attacker.\n\
    \   When store-and-forward protocols are used (e.g., SMTP [RFC5321]),\n   intermediaries\
    \ leave this data subject to observation by an attacker\n   that has compromised\
    \ these intermediaries, unless the data is\n   encrypted end-to-end by the application-layer\
    \ protocol or the\n   implementation uses an encrypted store for this data.\n"
- title: 3.2.  Information Useful for Inference
  contents:
  - "3.2.  Information Useful for Inference\n   Inference is information extracted\
    \ from later analysis of an observed\n   or eavesdropped communication, and/or\
    \ correlation of observed or\n   eavesdropped information with information available\
    \ from other\n   sources.  Indeed, most useful inference performed by the attacker\n\
    \   falls under the rubric of correlation.  The simplest example of this\n   is\
    \ the observation of DNS queries and answers from and to a source\n   and correlating\
    \ those with IP addresses with which that source\n   communicates.  This can give\
    \ access to information otherwise not\n   available from encrypted application\
    \ payloads (e.g., the \"Host:\"\n   HTTP/1.1 request header when HTTP is used\
    \ with TLS).\n   Protocols that encrypt their payload using an application- or\n\
    \   transport-layer encryption scheme (e.g., TLS) still expose all the\n   information\
    \ in their network- and transport-layer headers to the\n   attacker, including\
    \ source and destination addresses and ports.\n   IPsec Encapsulating Security\
    \ Payload (ESP) [RFC4303] further encrypts\n   the transport-layer headers but\
    \ still leaves IP address information\n   unencrypted; in tunnel mode, these addresses\
    \ correspond to the tunnel\n   endpoints.  Features of the security protocols\
    \ themselves, e.g., the\n   TLS session identifier, may leak information that\
    \ can be used for\n   correlation and inference.  While this information is much\
    \ less\n   semantically rich than the application payload, it can still be\n \
    \  useful for inferring an individual's activities.\n   Inference can also leverage\
    \ information obtained from sources other\n   than direct traffic observation.\
    \  Geolocation databases, for example,\n   have been developed that map IP addresses\
    \ to a location, in order to\n   provide location-aware services such as targeted\
    \ advertising.  This\n   location information is often of sufficient resolution\
    \ that it can be\n   used to draw further inferences toward identifying or profiling\
    \ an\n   individual.\n   Social media provide another source of more or less publicly\n\
    \   accessible information.  This information can be extremely\n   semantically\
    \ rich, including information about an individual's\n   location, associations\
    \ with other individuals and groups, and\n   activities.  Further, this information\
    \ is generally contributed and\n   curated voluntarily by the individuals themselves:\
    \ it represents\n   information that the individuals are not necessarily interested\
    \ in\n   protecting for privacy reasons.  However, correlation of this social\n\
    \   networking data with information available from direct observation of\n  \
    \ network traffic allows the creation of a much richer picture of an\n   individual's\
    \ activities than either alone.\n   We note with some alarm that there is little\
    \ that can be done at\n   protocol design time to limit such correlation by the\
    \ attacker, and\n   that the existence of such data sources in many cases greatly\n\
    \   complicates the problem of protecting privacy by hardening protocols\n   alone.\n"
- title: 3.3.  An Illustration of an Ideal Passive Pervasive Attack
  contents:
  - "3.3.  An Illustration of an Ideal Passive Pervasive Attack\n   To illustrate\
    \ how capable the idealized attacker is even given its\n   limitations, we explore\
    \ the non-anonymity of encrypted IP traffic in\n   this section.  Here, we examine\
    \ in detail some inference techniques\n   for associating a set of addresses with\
    \ an individual, in order to\n   illustrate the difficulty of defending communications\
    \ against our\n   idealized attacker.  Here, the basic problem is that information\n\
    \   radiated even from protocols that have no obvious connection with\n   personal\
    \ data can be correlated with other information that can paint\n   a very rich\
    \ behavioral picture; it only takes one unprotected link in\n   the chain to associate\
    \ with an identity.\n"
- title: 3.3.1.  Analysis of IP Headers
  contents:
  - "3.3.1.  Analysis of IP Headers\n   Internet traffic can be monitored by tapping\
    \ Internet links or by\n   installing monitoring tools in Internet routers.  Of\
    \ course, a single\n   link or a single router only provides access to a fraction\
    \ of the\n   global Internet traffic.  However, monitoring a number of high-\n\
    \   capacity links or a set of routers placed at strategic locations\n   provides\
    \ access to a good sampling of Internet traffic.\n   Tools like the IP Flow Information\
    \ Export (IPFIX) Protocol [RFC7011]\n   allow administrators to acquire statistics\
    \ about sequences of packets\n   with some common properties that pass through\
    \ a network device.  The\n   most common set of properties used in flow measurement\
    \ is the \"five-\n   tuple\" of source and destination addresses, protocol type,\
    \ and source\n   and destination ports.  These statistics are commonly used for\n\
    \   network engineering but could certainly be used for other purposes.\n   Let's\
    \ assume for a moment that IP addresses can be correlated to\n   specific services\
    \ or specific users.  Analysis of the sequences of\n   packets will quickly reveal\
    \ which users use what services, and also\n   which users engage in peer-to-peer\
    \ connections with other users.\n   Analysis of traffic variations over time can\
    \ be used to detect\n   increased activity by particular users or, in the case\
    \ of peer-to-\n   peer connections, increased activity within groups of users.\n"
- title: 3.3.2.  Correlation of IP Addresses to User Identities
  contents:
  - "3.3.2.  Correlation of IP Addresses to User Identities\n   The correlation of\
    \ IP addresses with specific users can be done in\n   various ways.  For example,\
    \ tools like reverse DNS lookup can be used\n   to retrieve the DNS names of servers.\
    \  Since the addresses of servers\n   tend to be quite stable and since servers\
    \ are relatively less\n   numerous than users, an attacker could easily maintain\
    \ its own copy\n   of the DNS for well-known or popular servers to accelerate\
    \ such\n   lookups.\n   On the other hand, the reverse lookup of IP addresses\
    \ of users is\n   generally less informative.  For example, a lookup of the address\n\
    \   currently used by one author's home network returns a name of the\n   form\
    \ \"c-192-000-002-033.hsd1.wa.comcast.net\".  This particular type\n   of reverse\
    \ DNS lookup generally reveals only coarse-grained location\n   or provider information,\
    \ equivalent to that available from\n   geolocation databases.\n   In many jurisdictions,\
    \ Internet Service Providers (ISPs) are required\n   to provide identification\
    \ on a case-by-case basis of the \"owner\" of a\n   specific IP address for law\
    \ enforcement purposes.  This is a\n   reasonably expedient process for targeted\
    \ investigations, but\n   pervasive surveillance requires something more efficient.\
    \  This\n   provides an incentive for the attacker to secure the cooperation of\n\
    \   the ISP in order to automate this correlation.\n"
- title: 3.3.3.  Monitoring Messaging Clients for IP Address Correlation
  contents:
  - "3.3.3.  Monitoring Messaging Clients for IP Address Correlation\n   Even if the\
    \ ISP does not cooperate, user identity can often be\n   obtained via inference.\
    \  POP3 [RFC1939] and IMAP [RFC3501] are used\n   to retrieve mail from mail servers,\
    \ while a variant of SMTP is used\n   to submit messages through mail servers.\
    \  IMAP connections originate\n   from the client, and typically start with an\
    \ authentication exchange\n   in which the client proves its identity by answering\
    \ a password\n   challenge.  The same holds for the SIP protocol [RFC3261] and\
    \ many\n   instant messaging services operating over the Internet using\n   proprietary\
    \ protocols.\n   The username is directly observable if any of these protocols\
    \ operate\n   in cleartext; the username can then be directly associated with\
    \ the\n   source address.\n"
- title: 3.3.4.  Retrieving IP Addresses from Mail Headers
  contents:
  - "3.3.4.  Retrieving IP Addresses from Mail Headers\n   SMTP [RFC5321] requires\
    \ that each successive SMTP relay adds a\n   \"Received\" header to the mail headers.\
    \  The purpose of these headers\n   is to enable audit of mail transmission, and\
    \ perhaps to distinguish\n   between regular mail and spam.  Here is an extract\
    \ from the headers\n   of a message recently received from the perpass mailing\
    \ list:\n   Received: from 192-000-002-044.zone13.example.org (HELO\n   ?192.168.1.100?)\
    \ (xxx.xxx.xxx.xxx) by lvps192-000-002-219.example.net\n   with ESMTPSA (DHE-RSA-AES256-SHA\
    \ encrypted, authenticated); 27 Oct\n   2013 21:47:14 +0100 Message-ID: <526D7BD2.7070908@example.org>\
    \ Date:\n   Sun, 27 Oct 2013 20:47:14 +0000 From: Some One <some.one@example.org>\n\
    \   This is the first \"Received\" header attached to the message by the\n   first\
    \ SMTP relay; for privacy reasons, the field values have been\n   anonymized.\
    \  We learn here that the message was submitted by \"Some\n   One\" on October\
    \ 27, from a host behind a NAT (192.168.1.100)\n   [RFC1918] that used the IP\
    \ address 192.0.2.44.  The information\n   remained in the message and is accessible\
    \ by all recipients of the\n   perpass mailing list, or indeed by any attacker\
    \ that sees at least\n   one copy of the message.\n   An attacker that can observe\
    \ sufficient email traffic can regularly\n   update the mapping between public\
    \ IP addresses and individual email\n   identities.  Even if the SMTP traffic\
    \ was encrypted on submission and\n   relaying, the attacker can still receive\
    \ a copy of public mailing\n   lists like perpass.\n"
- title: 3.3.5.  Tracking Address Usage with Web Cookies
  contents:
  - "3.3.5.  Tracking Address Usage with Web Cookies\n   Many web sites only encrypt\
    \ a small fraction of their transactions.\n   A popular pattern is to use HTTPS\
    \ for the login information, and then\n   use a \"cookie\" to associate following\
    \ cleartext transactions with the\n   user's identity.  Cookies are also used\
    \ by various advertisement\n   services to quickly identify the users and serve\
    \ them with\n   \"personalized\" advertisements.  Such cookies are particularly\
    \ useful\n   if the advertisement services want to keep tracking the user across\n\
    \   multiple sessions that may use different IP addresses.\n   As cookies are\
    \ sent in cleartext, an attacker can build a database\n   that associates cookies\
    \ to IP addresses for non-HTTPS traffic.  If\n   the IP address is already identified,\
    \ the cookie can be linked to the\n   user identify.  After that, if the same\
    \ cookie appears on a new IP\n   address, the new IP address can be immediately\
    \ associated with the\n   predetermined identity.\n"
- title: 3.3.6.  Graph-Based Approaches to Address Correlation
  contents:
  - "3.3.6.  Graph-Based Approaches to Address Correlation\n   An attacker can track\
    \ traffic from an IP address not yet associated\n   with an individual to various\
    \ public services (e.g., web sites, mail\n   servers, game servers) and exploit\
    \ patterns in the observed traffic\n   to correlate this address with other addresses\
    \ that show similar\n   patterns.  For example, any two addresses that show connections\
    \ to\n   the same IMAP or webmail services, the same set of favorite web\n   sites,\
    \ and game servers at similar times of day may be associated\n   with the same\
    \ individual.  Correlated addresses can then be tied to\n   an individual through\
    \ one of the techniques above, walking the\n   \"network graph\" to expand the\
    \ set of attributable traffic.\n"
- title: 3.3.7.  Tracking of Link-Layer Identifiers
  contents:
  - "3.3.7.  Tracking of Link-Layer Identifiers\n   Moving back down the stack, technologies\
    \ like Ethernet or Wi-Fi use\n   MAC (Media Access Control) addresses to identify\
    \ link-level\n   destinations.  MAC addresses assigned according to IEEE 802 standards\n\
    \   are globally unique identifiers for the device.  If the link is\n   publicly\
    \ accessible, an attacker can eavesdrop and perform tracking.\n   For example,\
    \ the attacker can track the wireless traffic at publicly\n   accessible Wi-Fi\
    \ networks.  Simple devices can monitor the traffic\n   and reveal which MAC addresses\
    \ are present.  Also, devices do not\n   need to be connected to a network to\
    \ expose link-layer identifiers.\n   Active service discovery always discloses\
    \ the MAC address of the\n   user, and sometimes the Service Set Identifiers (SSIDs)\
    \ of previously\n   visited networks.  For instance, certain techniques such as\
    \ the use\n   of \"hidden SSIDs\" require the mobile device to broadcast the network\n\
    \   identifier together with the device identifier.  This combination can\n  \
    \ further expose the user to inference attacks, as more information can\n   be\
    \ derived from the combination of MAC address, SSID being probed,\n   time, and\
    \ current location.  For example, a user actively probing for\n   a semi-unique\
    \ SSID on a flight out of a certain city can imply that\n   the user is no longer\
    \ at the physical location of the corresponding\n   AP.  Given that large-scale\
    \ databases of the MAC addresses of\n   wireless access points for geolocation\
    \ purposes have been known to\n   exist for some time, the attacker could easily\
    \ build a database that\n   maps link-layer identifiers and time with device or\
    \ user identities,\n   and use it to track the movement of devices and of their\
    \ owners.  On\n   the other hand, if the network does not use some form of Wi-Fi\n\
    \   encryption, or if the attacker can access the decrypted traffic, the\n   analysis\
    \ will also provide the correlation between link-layer\n   identifiers such as\
    \ MAC addresses and IP addresses.  Additional\n   monitoring using techniques\
    \ exposed in the previous sections will\n   reveal the correlation between MAC\
    \ addresses, IP addresses, and user\n   identity.  For instance, similarly to\
    \ the use of web cookies, MAC\n   addresses provide identity information that\
    \ can be used to associate\n   a user to different IP addresses.\n"
- title: 4.  Reported Instances of Large-Scale Attacks
  contents:
  - "4.  Reported Instances of Large-Scale Attacks\n   The situation in reality is\
    \ more bleak than that suggested by an\n   analysis of our idealized attacker.\
    \  Through revelations of sensitive\n   documents in several media outlets, the\
    \ Internet community has been\n   made aware of several intelligence activities\
    \ conducted by US and UK\n   national intelligence agencies, particularly the\
    \ US National Security\n   Agency (NSA) and the UK Government Communications Headquarters\n\
    \   (GCHQ).  These documents have revealed methods that these agencies\n   use\
    \ to attack Internet applications and obtain sensitive user\n   information. \
    \ There is little reason to suppose that only the US or\n   UK governments are\
    \ involved in these sorts of activities; the\n   examples are just ones that were\
    \ disclosed.  We note that these\n   reports are primarily useful as an illustration\
    \ of the types of\n   capabilities fielded by pervasive attackers as of the date\
    \ of the\n   Snowden leaks in 2013.\n   First, they confirm the deployment of\
    \ large-scale passive collection\n   of Internet traffic, which confirms the existence\
    \ of pervasive\n   passive attackers with at least the capabilities of our idealized\n\
    \   attacker.  For example, as described in [pass1], [pass2], [pass3],\n   and\
    \ [pass4]:\n   o  NSA's XKEYSCORE system accesses data from multiple access points\n\
    \      and searches for \"selectors\" such as email addresses, at the scale\n\
    \      of tens of terabytes of data per day.\n   o  GCHQ's Tempora system appears\
    \ to have access to around 1,500 major\n      cables passing through the UK.\n\
    \   o  NSA's MUSCULAR program has tapped cables between data centers\n      belonging\
    \ to major service providers.\n   o  Several programs appear to perform wide-scale\
    \ collection of\n      cookies in web traffic and location data from location-aware\n\
    \      portable devices such as smartphones.\n   However, the capabilities described\
    \ by these reports go beyond those\n   of our idealized attacker.  They include\
    \ the compromise of\n   cryptographic protocols, including decryption of TLS-protected\n\
    \   Internet sessions [dec1] [dec2] [dec3].  For example, the NSA BULLRUN\n  \
    \ project worked to undermine encryption through multiple approaches,\n   including\
    \ covert modifications to cryptographic software on end\n   systems.\n   Reported\
    \ capabilities include the direct compromise of intermediate\n   systems and arrangements\
    \ with service providers for bulk data and\n   metadata access [dir1] [dir2] [dir3],\
    \ bypassing the need to capture\n   traffic on the wire.  For example, the NSA\
    \ PRISM program provides the\n   agency with access to many types of user data\
    \ (e.g., email, chat,\n   VoIP).\n   The reported capabilities also include elements\
    \ of active pervasive\n   attack, including:\n   o  Insertion of devices as a\
    \ man-in-the-middle of Internet\n      transactions [TOR1] [TOR2].  For example,\
    \ NSA's QUANTUM system\n      appears to use several different techniques to hijack\
    \ HTTP\n      connections, ranging from DNS response injection to HTTP 302\n \
    \     redirects.\n   o  Use of implants on end systems to undermine security and\
    \ anonymity\n      features [dec2] [TOR1] [TOR2].  For example, QUANTUM is used\
    \ to\n      direct users to a FOXACID server, which in turn delivers an\n    \
    \  implant to compromise browsers of Tor users.\n   o  Use of implants on network\
    \ elements from many major equipment\n      providers, including Cisco, Juniper,\
    \ Huawei, Dell, and HP, as\n      provided by the NSA's Advanced Network Technology\
    \ group\n      [spiegel1].\n   o  Use of botnet-scale collections of compromised\
    \ hosts [spiegel2].\n   The scale of the compromise extends beyond the network\
    \ to include\n   subversion of the technical standards process itself.  For example,\n\
    \   there is suspicion that NSA modifications to the DUAL_EC_DRBG random\n   number\
    \ generator (RNG) were made to ensure that keys generated using\n   that generator\
    \ could be predicted by NSA.  This RNG was made part of\n   NIST's SP 800-90A,\
    \ for which NIST acknowledges the NSA's assistance.\n   There have also been reports\
    \ that the NSA paid RSA Security for a\n   related contract with the result that\
    \ the curve became the default in\n   the RSA BSAFE product line.\n   We use the\
    \ term \"pervasive attack\" [RFC7258] to collectively describe\n   these operations.\
    \  The term \"pervasive\" is used because the attacks\n   are designed to indiscriminately\
    \ gather as much data as possible and\n   to apply selective analysis on targets\
    \ after the fact.  This means\n   that all, or nearly all, Internet communications\
    \ are targets for\n   these attacks.  To achieve this scale, the attacks are physically\n\
    \   pervasive; they affect a large number of Internet communications.\n   They\
    \ are pervasive in content, consuming and exploiting any\n   information revealed\
    \ by the protocol.  And they are pervasive in\n   technology, exploiting many\
    \ different vulnerabilities in many\n   different protocols.\n   Again, it's important\
    \ to note that, although the attacks mentioned\n   above were executed by the\
    \ NSA and GCHQ, there are many other\n   organizations that can mount pervasive\
    \ surveillance attacks.  Because\n   of the resources required to achieve pervasive\
    \ scale, these attacks\n   are most commonly undertaken by nation-state actors.\
    \  For example,\n   the Chinese Internet filtering system known as the \"Great\
    \ Firewall of\n   China\" uses several techniques that are similar to the QUANTUM\n\
    \   program and that have a high degree of pervasiveness with regard to\n   the\
    \ Internet in China.  Therefore, legal restrictions in any one\n   jurisdiction\
    \ on pervasive monitoring activities cannot eliminate the\n   risk of pervasive\
    \ attack to the Internet as a whole.\n"
- title: 5.  Threat Model
  contents:
  - "5.  Threat Model\n   Given these disclosures, we must consider a broader threat\
    \ model.\n   Pervasive surveillance aims to collect information across a large\n\
    \   number of Internet communications, analyzing the collected\n   communications\
    \ to identify information of interest within individual\n   communications, or\
    \ inferring information from correlated\n   communications.  This analysis sometimes\
    \ benefits from decryption of\n   encrypted communications and deanonymization\
    \ of anonymized\n   communications.  As a result, these attackers desire both\
    \ access to\n   the bulk of Internet traffic and to the keying material required\
    \ to\n   decrypt any traffic that has been encrypted.  Even if keys are not\n\
    \   available, note that the presence of a communication and the fact\n   that\
    \ it is encrypted may both be inputs to an analysis, even if the\n   attacker\
    \ cannot decrypt the communication.\n   The attacks listed above highlight new\
    \ avenues both for access to\n   traffic and for access to relevant encryption\
    \ keys.  They further\n   indicate that the scale of surveillance is sufficient\
    \ to provide a\n   general capability to cross-correlate communications, a threat\
    \ not\n   previously thought to be relevant at the scale of the Internet.\n"
- title: 5.1.  Attacker Capabilities
  contents:
  - "5.1.  Attacker Capabilities\n    +--------------------------+-------------------------------------+\n\
    \    | Attack Class             | Capability                          |\n    +--------------------------+-------------------------------------+\n\
    \    | Passive observation      | Directly capture data in transit    |\n    |\
    \                          |                                     |\n    | Passive\
    \ inference        | Infer from reduced/encrypted data   |\n    |            \
    \              |                                     |\n    | Active         \
    \          | Manipulate / inject data in transit |\n    |                    \
    \      |                                     |\n    | Static key exfiltration\
    \  | Obtain key material once / rarely   |\n    |                          | \
    \                                    |\n    | Dynamic key exfiltration | Obtain\
    \ per-session key material     |\n    |                          |           \
    \                          |\n    | Content exfiltration     | Access data at\
    \ rest                 |\n    +--------------------------+-------------------------------------+\n\
    \   Security analyses of Internet protocols commonly consider two classes\n  \
    \ of attacker: passive pervasive attackers, who can simply listen in on\n   communications\
    \ as they transit the network, and active pervasive\n   attackers, who can modify\
    \ or delete packets in addition to simply\n   collecting them.\n   In the context\
    \ of pervasive passive surveillance, these attacks take\n   on an even greater\
    \ significance.  In the past, these attackers were\n   often assumed to operate\
    \ near the edge of the network, where attacks\n   can be simpler.  For example,\
    \ in some LANs, it is simple for any node\n   to engage in passive listening to\
    \ other nodes' traffic or inject\n   packets to accomplish active pervasive attacks.\
    \  However, as we now\n   know, both passive and active pervasive attacks are\
    \ undertaken by\n   pervasive attackers closer to the core of the network, greatly\n\
    \   expanding the scope and capability of the attacker.\n   Eavesdropping and\
    \ observation at a larger scale make passive\n   inference attacks easier to carry\
    \ out: a passive pervasive attacker\n   with access to a large portion of the\
    \ Internet can analyze collected\n   traffic to create a much more detailed view\
    \ of individual behavior\n   than an attacker that collects at a single point.\
    \  Even the usual\n   claim that encryption defeats passive pervasive attackers\
    \ is\n   weakened, since a pervasive flow access attacker can infer\n   relationships\
    \ from correlations over large numbers of sessions, e.g.,\n   pairing encrypted\
    \ sessions with unencrypted sessions from the same\n   host, or performing traffic\
    \ fingerprinting between known and unknown\n   encrypted sessions.  Reports on\
    \ the NSA XKEYSCORE system would\n   indicate it is an example of such an attacker.\n\
    \   An active pervasive attacker likewise has capabilities beyond those\n   of\
    \ a localized active attacker.  Flow modification attacks are often\n   limited\
    \ by network topology, for example, by a requirement that the\n   attacker be\
    \ able to see a targeted session as well as inject packets\n   into it.  A pervasive\
    \ flow modification attacker with access at\n   multiple points within the core\
    \ of the Internet is able to overcome\n   these topological limitations and perform\
    \ attacks over a much broader\n   scope.  Being positioned in the core of the\
    \ network rather than the\n   edge can also enable an active pervasive attacker\
    \ to reroute targeted\n   traffic, amplifying the ability to perform both eavesdropping\
    \ and\n   traffic injection.  Active pervasive attackers can also benefit from\n\
    \   passive pervasive collection to identify vulnerable hosts.\n   While not directly\
    \ related to pervasiveness, attackers that are in a\n   position to mount an active\
    \ pervasive attack are also often in a\n   position to subvert authentication,\
    \ a traditional protection against\n   such attacks.  Authentication in the Internet\
    \ is often achieved via\n   trusted third-party authorities such as the Certificate\
    \ Authorities\n   (CAs) that provide web sites with authentication credentials.\
    \  An\n   attacker with sufficient resources may also be able to induce an\n \
    \  authority to grant credentials for an identity of the attacker's\n   choosing.\
    \  If the parties to a communication will trust multiple\n   authorities to certify\
    \ a specific identity, this attack may be\n   mounted by suborning any one of\
    \ the authorities (the proverbial\n   \"weakest link\").  Subversion of authorities\
    \ in this way can allow an\n   active attack to succeed in spite of an authentication\
    \ check.\n   Beyond these three classes (observation, inference, and active),\n\
    \   reports on the BULLRUN effort to defeat encryption and the PRISM\n   effort\
    \ to obtain data from service providers suggest three more\n   classes of attack:\n\
    \   o  Static key exfiltration\n   o  Dynamic key exfiltration\n   o  Content\
    \ exfiltration\n   These attacks all rely on a collaborator providing the attacker\
    \ with\n   some information, either keys or data.  These attacks have not\n  \
    \ traditionally been considered in scope for the Security\n   Considerations sections\
    \ of IETF protocols, as they occur outside the\n   protocol.\n   The term \"key\
    \ exfiltration\" refers to the transfer of keying material\n   for an encrypted\
    \ communication from the collaborator to the attacker.\n   By \"static\", we mean\
    \ that the transfer of keys happens once or rarely\n   and that the transferred\
    \ key is typically long-lived.  For example,\n   this case would cover a web site\
    \ operator that provides the private\n   key corresponding to its HTTPS certificate\
    \ to an intelligence agency.\n   \"Dynamic\" key exfiltration, by contrast, refers\
    \ to attacks in which\n   the collaborator delivers keying material to the attacker\
    \ frequently,\n   e.g., on a per-session basis.  This does not necessarily imply\n\
    \   frequent communications with the attacker; the transfer of keying\n   material\
    \ may be virtual.  For example, if an endpoint were modified\n   in such a way\
    \ that the attacker could predict the state of its\n   pseudorandom number generator,\
    \ then the attacker would be able to\n   derive per-session keys even without\
    \ per-session communications.\n   Finally, content exfiltration is the attack\
    \ in which the collaborator\n   simply provides the attacker with the desired\
    \ data or metadata.\n   Unlike the key exfiltration cases, this attack does not\
    \ require the\n   attacker to capture the desired data as it flows through the\
    \ network.\n   The exfiltration is of data at rest, rather than data in transit.\n\
    \   This increases the scope of data that the attacker can obtain, since\n   the\
    \ attacker can access historical data -- the attacker does not have\n   to be\
    \ listening at the time the communication happens.\n   Exfiltration attacks can\
    \ be accomplished via attacks against one of\n   the parties to a communication,\
    \ i.e., by the attacker stealing the\n   keys or content rather than the party\
    \ providing them willingly.  In\n   these cases, the party may not be aware, at\
    \ least at a human level,\n   that they are collaborating.  Rather, the subverted\
    \ technical assets\n   are \"collaborating\" with the attacker (by providing keys/content)\n\
    \   without their owner's knowledge or consent.\n   Any party that has access\
    \ to encryption keys or unencrypted data can\n   be a collaborator.  While collaborators\
    \ are typically the endpoints\n   of a communication (with encryption securing\
    \ the links),\n   intermediaries in an unencrypted communication can also facilitate\n\
    \   content exfiltration attacks as collaborators by providing the\n   attacker\
    \ access to those communications.  For example, documents\n   describing the NSA\
    \ PRISM program claim that NSA is able to access\n   user data directly from servers,\
    \ where it is stored unencrypted.  In\n   these cases, the operator of the server\
    \ would be a collaborator, if\n   an unwitting one.  By contrast, in the NSA MUSCULAR\
    \ program, a set of\n   collaborators enabled attackers to access the cables connecting\
    \ data\n   centers used by service providers such as Google and Yahoo.  Because\n\
    \   communications among these data centers were not encrypted, the\n   collaboration\
    \ by an intermediate entity allowed the NSA to collect\n   unencrypted user data.\n"
- title: 5.2.  Attacker Costs
  contents:
  - "5.2.  Attacker Costs\n     +--------------------------+-----------------------------------+\n\
    \     | Attack Class             | Cost / Risk to Attacker           |\n     +--------------------------+-----------------------------------+\n\
    \     | Passive observation      | Passive data access               |\n     |\
    \                          |                                   |\n     | Passive\
    \ inference        | Passive data access + processing  |\n     |             \
    \             |                                   |\n     | Active           \
    \        | Active data access + processing   |\n     |                       \
    \   |                                   |\n     | Static key exfiltration  | One-time\
    \ interaction              |\n     |                          |              \
    \                     |\n     | Dynamic key exfiltration | Ongoing interaction\
    \ / code change |\n     |                          |                         \
    \          |\n     | Content exfiltration     | Ongoing, bulk interaction    \
    \     |\n     +--------------------------+-----------------------------------+\n\
    \   Each of the attack types discussed in the previous section entails\n   certain\
    \ costs and risks.  These costs differ by attack and can be\n   helpful in guiding\
    \ response to pervasive attack.\n   Depending on the attack, the attacker may\
    \ be exposed to several types\n   of risk, ranging from simply losing access to\
    \ arrest or prosecution.\n   In order for any of these negative consequences to\
    \ occur, however,\n   the attacker must first be discovered and identified.  So,\
    \ the\n   primary risk we focus on here is the risk of discovery and\n   attribution.\n\
    \   A passive pervasive attack is the simplest to mount in some ways.\n   The\
    \ base requirement is that the attacker obtain physical access to a\n   communications\
    \ medium and extract communications from it.  For\n   example, the attacker might\
    \ tap a fiber-optic cable, acquire a mirror\n   port on a switch, or listen to\
    \ a wireless signal.  The need for these\n   taps to have physical access or proximity\
    \ to a link exposes the\n   attacker to the risk that the taps will be discovered.\
    \  For example,\n   a fiber tap or mirror port might be discovered by network\
    \ operators\n   noticing increased attenuation in the fiber or a change in switch\n\
    \   configuration.  Of course, passive pervasive attacks may be\n   accomplished\
    \ with the cooperation of the network operator, in which\n   case there is a risk\
    \ that the attacker's interactions with the\n   network operator will be exposed.\n\
    \   In many ways, the costs and risks for an active pervasive attack are\n   similar\
    \ to those for a passive pervasive attack, with a few\n   additions.  An active\
    \ attacker requires more robust network access\n   than a passive attacker, since,\
    \ for example, they will often need to\n   transmit data as well as receive it.\
    \  In the wireless example above,\n   the attacker would need to act as a transmitter\
    \ as well as a\n   receiver, greatly increasing the probability the attacker will\
    \ be\n   discovered (e.g., using direction-finding technology).  Active\n   attacks\
    \ are also much more observable at higher layers of the\n   network.  For example,\
    \ an active attacker that attempts to use a mis-\n   issued certificate could\
    \ be detected via Certificate Transparency\n   [RFC6962].\n   In terms of raw\
    \ implementation complexity, passive pervasive attacks\n   require only enough\
    \ processing to extract information from the\n   network and store it.  Active\
    \ pervasive attacks, by contrast, often\n   depend on winning race conditions\
    \ to inject packets into active\n   connections.  So, active pervasive attacks\
    \ in the core of the network\n   require processing hardware that can operate\
    \ at line speed (roughly\n   100 Gbps to 1 Tbps in the core) to identify opportunities\
    \ for attack\n   and insert attack traffic in high-volume traffic.  Key exfiltration\n\
    \   attacks rely on passive pervasive attack for access to encrypted\n   data,\
    \ with the collaborator providing keys to decrypt the data.  So,\n   the attacker\
    \ undertakes the cost and risk of a passive pervasive\n   attack, as well as additional\
    \ risk of discovery via the interactions\n   that the attacker has with the collaborator.\n\
    \   Some active attacks are more expensive than others.  For example,\n   active\
    \ man-in-the-middle (MITM) attacks require access to one or more\n   points on\
    \ a communication's network path that allow visibility of the\n   entire session\
    \ and the ability to modify or drop legitimate packets\n   in favor of the attacker's\
    \ packets.  A similar but weaker form of\n   attack, called an active man-on-the-side\
    \ (MOTS), requires access to\n   only part of the session.  In an active MOTS\
    \ attack, the attacker\n   need only be able to inject or modify traffic on the\
    \ network element\n   the attacker has access to.  While this may not allow for\
    \ full\n   control of a communication session (as in an MITM attack), the\n  \
    \ attacker can perform a number of powerful attacks, including but not\n   limited\
    \ to: injecting packets that could terminate the session (e.g.,\n   TCP RST packets),\
    \ sending a fake DNS reply to redirect ensuing TCP\n   connections to an address\
    \ of the attacker's choice (i.e., winning a\n   \"DNS response race\"), and mounting\
    \ an HTTP redirect attack by\n   observing a TCP/HTTP connection to a target address\
    \ and injecting a\n   TCP data packet containing an HTTP redirect.  For example,\
    \ the system\n   dubbed by researchers as China's \"Great Cannon\" [great-cannon]\
    \ can\n   operate in full MITM mode to accomplish very complex attacks that can\n\
    \   modify content in transit, while the well-known Great Firewall of\n   China\
    \ is a MOTS system that focuses on blocking access to certain\n   kinds of traffic\
    \ and destinations via TCP RST packet injection.\n   In this sense, static exfiltration\
    \ has a lower risk profile than\n   dynamic.  In the static case, the attacker\
    \ need only interact with\n   the collaborator a small number of times, possibly\
    \ only once -- say,\n   to exchange a private key.  In the dynamic case, the attacker\
    \ must\n   have continuing interactions with the collaborator.  As noted above,\n\
    \   these interactions may be real, such as in-person meetings, or\n   virtual,\
    \ such as software modifications that render keys available to\n   the attacker.\
    \  Both of these types of interactions introduce a risk\n   that they will be\
    \ discovered, e.g., by employees of the collaborator\n   organization noticing\
    \ suspicious meetings or suspicious code changes.\n   Content exfiltration has\
    \ a similar risk profile to dynamic key\n   exfiltration.  In a content exfiltration\
    \ attack, the attacker saves\n   the cost and risk of conducting a passive pervasive\
    \ attack.  The risk\n   of discovery through interactions with the collaborator,\
    \ however, is\n   still present, and may be higher.  The content of a communication\
    \ is\n   obviously larger than the key used to encrypt it, often by several\n\
    \   orders of magnitude.  So, in the content exfiltration case, the\n   interactions\
    \ between the collaborator and the attacker need to be\n   much higher bandwidth\
    \ than in the key exfiltration cases, with a\n   corresponding increase in the\
    \ risk that this high-bandwidth channel\n   will be discovered.\n   It should\
    \ also be noted that in these latter three exfiltration\n   cases, the collaborator\
    \ also undertakes a risk that his collaboration\n   with the attacker will be\
    \ discovered.  Thus, the attacker may have to\n   incur additional cost in order\
    \ to convince the collaborator to\n   participate in the attack.  Likewise, the\
    \ scope of these attacks is\n   limited to cases where the attacker can convince\
    \ a collaborator to\n   participate.  If the attacker is a national government,\
    \ for example,\n   it may be able to compel participation within its borders,\
    \ but have a\n   much more difficult time recruiting foreign collaborators.\n\
    \   As noted above, the collaborator in an exfiltration attack can be\n   unwitting;\
    \ the attacker can steal keys or data to enable the attack.\n   In some ways,\
    \ the risks of this approach are similar to the case of\n   an active collaborator.\
    \  In the static case, the attacker needs to\n   steal information from the collaborator\
    \ once; in the dynamic case,\n   the attacker needs continued presence inside\
    \ the collaborators'\n   systems.  The main difference is that the risk in this\
    \ case is of\n   automated discovery (e.g., by intrusion detection systems) rather\n\
    \   than discovery by humans.\n"
- title: 6.  Security Considerations
  contents:
  - "6.  Security Considerations\n   This document describes a threat model for pervasive\
    \ surveillance\n   attacks.  Mitigations are to be given in a future document.\n"
- title: 7.  References
  contents:
  - '7.  References

    '
- title: 7.1.  Normative References
  contents:
  - "7.1.  Normative References\n   [RFC6973]  Cooper, A., Tschofenig, H., Aboba,\
    \ B., Peterson, J.,\n              Morris, J., Hansen, M., and R. Smith, \"Privacy\n\
    \              Considerations for Internet Protocols\", RFC 6973,\n          \
    \    DOI 10.17487/RFC6973, July 2013,\n              <http://www.rfc-editor.org/info/rfc6973>.\n"
- title: 7.2.  Informative References
  contents:
  - "7.2.  Informative References\n   [dec1]     Perlroth, N., Larson, J., and S.\
    \ Shane, \"N.S.A. Able to\n              Foil Basic Safeguards of Privacy on Web\"\
    , The New York\n              Times, September 2013,\n              <http://www.nytimes.com/2013/09/06/us/\n\
    \              nsa-foils-much-internet-encryption.html>.\n   [dec2]     The Guardian,\
    \ \"Project Bullrun -- classification guide to\n              the NSA's decryption\
    \ program\", September 2013,\n              <http://www.theguardian.com/world/interactive/2013/sep/05/\n\
    \              nsa-project-bullrun-classification-guide>.\n   [dec3]     Ball,\
    \ J., Borger, J., and G. Greenwald, \"Revealed: how US\n              and UK spy\
    \ agencies defeat internet privacy and security\",\n              The Guardian,\
    \ September 2013,\n              <http://www.theguardian.com/world/2013/sep/05/\n\
    \              nsa-gchq-encryption-codes-security>.\n   [dir1]     Greenwald,\
    \ G., \"NSA collecting phone records of millions\n              of Verizon customers\
    \ daily\", The Guardian, June 2013,\n              <http://www.theguardian.com/world/2013/jun/06/\n\
    \              nsa-phone-records-verizon-court-order>.\n   [dir2]     Greenwald,\
    \ G. and E. MacAskill, \"NSA Prism program taps in\n              to user data\
    \ of Apple, Google and others\", The Guardian,\n              June 2013, <http://www.theguardian.com/world/2013/jun/06/\n\
    \              us-tech-giants-nsa-data>.\n   [dir3]     The Guardian, \"Sigint\
    \ -- how the NSA collaborates with\n              technology companies\", September\
    \ 2013,\n              <http://www.theguardian.com/world/interactive/2013/sep/05/\n\
    \              sigint-nsa-collaborates-technology-companies>.\n   [DPRIVE]   Bortzmeyer,\
    \ S., \"DNS privacy considerations\", Work in\n              Progress, draft-ietf-dprive-problem-statement-06,\
    \ June\n              2015.\n   [great-cannon]\n              Marczak, B., Weaver,\
    \ N., Dalek, J., Ensafi, R., Fifield,\n              D., McKune, S., Rey, A.,\
    \ Scott-Railton, J., Deibert, R.,\n              and V. Paxson, \"China's Great\
    \ Cannon\", The Citizen Lab,\n              University of Toronto, 2015,\n   \
    \           <https://citizenlab.org/2015/04/chinas-great-cannon/>.\n   [pass1]\
    \    Greenwald, G. and S. Ackerman, \"How the NSA is still\n              harvesting\
    \ your online data\", The Guardian, June 2013,\n              <http://www.theguardian.com/world/2013/jun/27/\n\
    \              nsa-online-metadata-collection>.\n   [pass2]    Ball, J., \"NSA's\
    \ Prism surveillance program: how it works\n              and what it can do\"\
    , The Guardian, June 2013,\n              <http://www.theguardian.com/world/2013/jun/08/\n\
    \              nsa-prism-server-collection-facebook-google>.\n   [pass3]    Greenwald,\
    \ G., \"XKeyscore: NSA tool collects 'nearly\n              everything a user\
    \ does on the internet'\", The Guardian,\n              July 2013, <http://www.theguardian.com/world/2013/jul/31/\n\
    \              nsa-top-secret-program-online-data>.\n   [pass4]    MacAskill,\
    \ E., Borger, J., Hopkins, N., Davies, N., and J.\n              Ball, \"How does\
    \ GCHQ's internet surveillance work?\", The\n              Guardian, June 2013,\n\
    \              <http://www.theguardian.com/uk/2013/jun/21/\n              how-does-gchq-internet-surveillance-work>.\n\
    \   [RFC1035]  Mockapetris, P., \"Domain names - implementation and\n        \
    \      specification\", STD 13, RFC 1035, DOI 10.17487/RFC1035,\n            \
    \  November 1987, <http://www.rfc-editor.org/info/rfc1035>.\n   [RFC1918]  Rekhter,\
    \ Y., Moskowitz, B., Karrenberg, D., de Groot, G.,\n              and E. Lear,\
    \ \"Address Allocation for Private Internets\",\n              BCP 5, RFC 1918,\
    \ DOI 10.17487/RFC1918, February 1996,\n              <http://www.rfc-editor.org/info/rfc1918>.\n\
    \   [RFC1939]  Myers, J. and M. Rose, \"Post Office Protocol - Version 3\",\n\
    \              STD 53, RFC 1939, DOI 10.17487/RFC1939, May 1996,\n           \
    \   <http://www.rfc-editor.org/info/rfc1939>.\n   [RFC3261]  Rosenberg, J., Schulzrinne,\
    \ H., Camarillo, G., Johnston,\n              A., Peterson, J., Sparks, R., Handley,\
    \ M., and E.\n              Schooler, \"SIP: Session Initiation Protocol\", RFC\
    \ 3261,\n              DOI 10.17487/RFC3261, June 2002,\n              <http://www.rfc-editor.org/info/rfc3261>.\n\
    \   [RFC3365]  Schiller, J., \"Strong Security Requirements for Internet\n   \
    \           Engineering Task Force Standard Protocols\", BCP 61,\n           \
    \   RFC 3365, DOI 10.17487/RFC3365, August 2002,\n              <http://www.rfc-editor.org/info/rfc3365>.\n\
    \   [RFC3501]  Crispin, M., \"INTERNET MESSAGE ACCESS PROTOCOL - VERSION\n   \
    \           4rev1\", RFC 3501, DOI 10.17487/RFC3501, March 2003,\n           \
    \   <http://www.rfc-editor.org/info/rfc3501>.\n   [RFC4033]  Arends, R., Austein,\
    \ R., Larson, M., Massey, D., and S.\n              Rose, \"DNS Security Introduction\
    \ and Requirements\",\n              RFC 4033, DOI 10.17487/RFC4033, March 2005,\n\
    \              <http://www.rfc-editor.org/info/rfc4033>.\n   [RFC4303]  Kent,\
    \ S., \"IP Encapsulating Security Payload (ESP)\",\n              RFC 4303, DOI\
    \ 10.17487/RFC4303, December 2005,\n              <http://www.rfc-editor.org/info/rfc4303>.\n\
    \   [RFC4949]  Shirey, R., \"Internet Security Glossary, Version 2\",\n      \
    \        FYI 36, RFC 4949, DOI 10.17487/RFC4949, August 2007,\n              <http://www.rfc-editor.org/info/rfc4949>.\n\
    \   [RFC5246]  Dierks, T. and E. Rescorla, \"The Transport Layer Security\n  \
    \            (TLS) Protocol Version 1.2\", RFC 5246,\n              DOI 10.17487/RFC5246,\
    \ August 2008,\n              <http://www.rfc-editor.org/info/rfc5246>.\n   [RFC5321]\
    \  Klensin, J., \"Simple Mail Transfer Protocol\", RFC 5321,\n              DOI\
    \ 10.17487/RFC5321, October 2008,\n              <http://www.rfc-editor.org/info/rfc5321>.\n\
    \   [RFC6962]  Laurie, B., Langley, A., and E. Kasper, \"Certificate\n       \
    \       Transparency\", RFC 6962, DOI 10.17487/RFC6962, June 2013,\n         \
    \     <http://www.rfc-editor.org/info/rfc6962>.\n   [RFC7011]  Claise, B., Ed.,\
    \ Trammell, B., Ed., and P. Aitken,\n              \"Specification of the IP Flow\
    \ Information Export (IPFIX)\n              Protocol for the Exchange of Flow\
    \ Information\", STD 77,\n              RFC 7011, DOI 10.17487/RFC7011, September\
    \ 2013,\n              <http://www.rfc-editor.org/info/rfc7011>.\n   [RFC7258]\
    \  Farrell, S. and H. Tschofenig, \"Pervasive Monitoring Is an\n             \
    \ Attack\", BCP 188, RFC 7258, DOI 10.17487/RFC7258, May\n              2014,\
    \ <http://www.rfc-editor.org/info/rfc7258>.\n   [spiegel1] Appelbaum, J., Horchert,\
    \ J., Reissmann, O., Rosenbach, M.,\n              Schindler, J., and C. Stocker,\
    \ \"NSA's Secret Toolbox: Unit\n              Offers Spy Gadgets for Every Need\"\
    , Spiegel Online,\n              December 2013, <http://www.spiegel.de/international/world/\n\
    \              nsa-secret-toolbox-ant-unit-offers-spy-gadgets-for-every-\n   \
    \           need-a-941006.html>.\n   [spiegel2] Appelbaum, J., Gibson, A., Guarnieri,\
    \ C., Muller-Maguhn,\n              A., Poitras, L., Rosenbach, M., Schmundt,\
    \ H., and M.\n              Sontheimer, \"The Digital Arms Race: NSA Preps America\
    \ for\n              Future Battle\", Spiegel Online, January 2015,\n        \
    \      <http://www.spiegel.de/international/world/new-snowden-\n             \
    \ docs-indicate-scope-of-nsa-preparations-for-cyber-battle-\n              a-1013409.html>.\n\
    \   [TOR1]     Schneier, B., \"How the NSA Attacks Tor/Firefox Users With\n  \
    \            QUANTUM and FOXACID\", Schneier on Security, October 2013,\n    \
    \          <https://www.schneier.com/blog/archives/2013/10/\n              how_the_nsa_att.html>.\n\
    \   [TOR2]     The Guardian, \"'Tor Stinks' presentation -- read the full\n  \
    \            document\", October 2013,\n              <http://www.theguardian.com/world/interactive/2013/oct/04/\n\
    \              tor-stinks-nsa-presentation-document>.\n"
- title: IAB Members at the Time of Approval
  contents:
  - "IAB Members at the Time of Approval\n   Jari Arkko (IETF Chair)\n   Mary Barnes\n\
    \   Marc Blanchet\n   Ralph Droms\n   Ted Hardie\n   Joe Hildebrand\n   Russ Housley\n\
    \   Erik Nordmark\n   Robert Sparks\n   Andrew Sullivan\n   Dave Thaler\n   Brian\
    \ Trammell\n   Suzanne Woolf\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   Thanks to Dave Thaler for the list of attacks and taxonomy;\
    \ to\n   Security Area Directors Stephen Farrell, Sean Turner, and Kathleen\n\
    \   Moriarty for starting and managing the IETF's discussion on pervasive\n  \
    \ attack; and to Stephan Neuhaus, Mark Townsley, Chris Inacio,\n   Evangelos Halepilidis,\
    \ Bjoern Hoehrmann, Aziz Mohaisen, Russ Housley,\n   Joe Hall, Andrew Sullivan,\
    \ the IEEE 802 Privacy Executive Committee\n   SG, and the IAB Privacy and Security\
    \ Program for their input.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Richard Barnes\n   Email: rlb@ipv.sx\n   Bruce Schneier\n\
    \   Email: schneier@schneier.com\n   Cullen Jennings\n   Email: fluffy@cisco.com\n\
    \   Ted Hardie\n   Email: ted.ietf@gmail.com\n   Brian Trammell\n   Email: ietf@trammell.ch\n\
    \   Christian Huitema\n   Email: huitema@huitema.net\n   Daniel Borkmann\n   Email:\
    \ dborkman@iogearbox.net\n"
