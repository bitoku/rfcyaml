- title: __initial_text__
  contents:
  - '            Network Hierarchy and Multilayer Survivability

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2002).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document presents a proposal of the near-term and practical\n\
    \   requirements for network survivability and hierarchy in current\n   service\
    \ provider environments.\n"
- title: Conventions used in this document
  contents:
  - "Conventions used in this document\n   The key words \"MUST\", \"MUST NOT\", \"\
    REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in BCP 14, RFC 2119 [2].\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction..............................................2\n\
    \   2. Terminology and Concepts..................................5\n   2.1 Hierarchy................................................6\n\
    \   2.1.1 Vertical Hierarchy.....................................5\n   2.1.2 Horizontal\
    \ Hierarchy...................................6\n   2.2 Survivability Terminology................................6\n\
    \   2.2.1 Survivability..........................................7\n   2.2.2 Generic\
    \ Operations.....................................7\n   2.2.3 Survivability Techniques...............................8\n\
    \   2.2.4 Survivability Performance..............................9\n   2.3 Survivability\
    \ Mechanisms: Comparison....................10\n   3. Survivability............................................11\n\
    \   3.1 Scope...................................................11\n   3.2 Required\
    \ initial set of survivability mechanisms........12\n   3.2.1 1:1 Path Protection\
    \ with Pre-Established Capacity.....12\n   3.2.2 1:1 Path Protection with Pre-Planned\
    \ Capacity.........13\n   3.2.3 Local Restoration.....................................13\n\
    \   3.2.4 Path Restoration......................................14\n   3.3 Applications\
    \ Supported..................................14\n   3.4 Timing Bounds for Survivability\
    \ Mechanisms..............15\n   3.5 Coordination Among Layers...............................16\n\
    \   3.6 Evolution Toward IP Over Optical........................17\n   4. Hierarchy\
    \ Requirements...................................17\n   4.1 Historical Context......................................17\n\
    \   4.2 Applications for Horizontal Hierarchy...................18\n   4.3 Horizontal\
    \ Hierarchy Requirements.......................19\n   5. Survivability and Hierarchy..............................19\n\
    \   6. Security Considerations..................................20\n   7. References...............................................21\n\
    \   8. Acknowledgments..........................................22\n   9. Contributing\
    \ Authors.....................................22\n   Appendix A: Questions used\
    \ to help develop requirements.....23\n   Editors' Addresses..........................................26\n\
    \   Full Copyright Statement....................................27\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   This document is the result of the Network Hierarchy and\n\
    \   Survivability Techniques Design Team established within the Traffic\n   Engineering\
    \ Working Group.  This team collected and documented\n   current and near term\
    \ requirements for survivability and hierarchy in\n   service provider environments.\
    \  For clarity, an expanded set of\n   definitions is included.  The team determined\
    \ that there appears to\n   be a need to define a small set of interoperable survivability\n\
    \   approaches in packet and non-packet networks.  Suggested approaches\n   include\
    \ path-based as well as one that repairs connections in\n   proximity to the network\
    \ fault.  They operate primarily at a single\n   network layer.  For hierarchy,\
    \ there did not appear to be a driving\n   near-term need for work on \"vertical\
    \ hierarchy,\" defined as\n   communication between network layers such as Time\
    \ Division\n   Multiplexed (TDM)/optical and Multi-Protocol Label Switching (MPLS).\n\
    \   In particular, instead of direct exchange of signaling and routing\n   between\
    \ vertical layers, some looser form of coordination and\n   communication, such\
    \ as the specification of hold-off timers, is a\n   nearer term need.  For \"\
    horizontal hierarchy\" in data networks, there\n   are several pressing needs.\
    \  The requirement is to be able to set up\n   many Label Switched Paths (LSPs)\
    \ in a service provider network with\n   hierarchical Interior Gateway Protocol\
    \ (IGP).  This is necessary to\n   support layer 2 and layer 3 Virtual Private\
    \ Network (VPN) services\n   that require edge-to-edge signaling across a core\
    \ network.\n   This document presents a proposal of the near-term and practical\n\
    \   requirements for network survivability and hierarchy in current\n   service\
    \ provider environments.  With feedback from the working group\n   solicited,\
    \ the objective is to help focus the work that is being\n   addressed in the TEWG\
    \ (Traffic Engineering Working Group), CCAMP\n   (Common Control and Measurement\
    \ Plane Working Group), and other\n   working groups.  A main goal of this work\
    \ is to provide some\n   expedience for required functionality in multi-vendor\
    \ service\n   provider networks.  The initial focus is primarily on intra-domain\n\
    \   operations.  However, to maintain consistency in the provision of\n   end-to-end\
    \ service in a multi-provider environment, rules governing\n   the operations\
    \ of survivability mechanisms at domain boundaries must\n   also be specified.\
    \  While such issues are raised and discussed, where\n   appropriate, they will\
    \ not be treated in depth in the initial release\n   of this document.\n   The\
    \ document first develops a set of definitions to be used later in\n   this document\
    \ and potentially in other documents as well.  It then\n   addresses the requirements\
    \ and issues associated with service\n   restoration, hierarchy, and finally a\
    \ short discussion of\n   survivability in hierarchical context.\n   Here is a\
    \ summary of the findings:\n   A. Survivability Requirements\n   o  need to define\
    \ a small set of interoperable survivability\n      approaches in packet and non-packet\
    \ networks\n   o  suggested survivability mechanisms include\n      -  1:1 path\
    \ protection with pre-established backup capacity (non-\n         shared)\n  \
    \    -  1:1 path protection with pre-planned backup capacity (shared)\n      -\
    \  local restoration with repairs in proximity to the network\n         fault\n\
    \      -  path restoration through source-based rerouting\n   o  timing bounds\
    \ for service restoration to support voice call cutoff\n      (140 msec to 2 sec),\
    \ protocol timer requirements in premium data\n      services, and mission critical\
    \ applications\n   o  use of restoration priority for service differentiation\n\
    \   B. Hierarchy Requirements\n   B.1. Horizontally Oriented Hierarchy (Intra-Domain)\n\
    \   o  ability to set up many LSPs in a service provider network with\n      hierarchical\
    \ IGP, for the support of layer 2 and layer 3 VPN\n      services\n   o  requirements\
    \ for multi-area traffic engineering need to be\n      developed to provide guidance\
    \ for any necessary protocol\n      extensions\n   B.2. Vertically Oriented Hierarchy\n\
    \   The following functionality for survivability is common on most\n   routing\
    \ equipment today.\n   o  near-term need is some loose form of coordination and\n\
    \      communication based on the use of nested hold-off timers, instead\n   \
    \   of direct exchange of signaling and routing between vertical\n      layers\n\
    \   o  means for an upper layer to immediately begin recovery actions in\n   \
    \   the event that a lower layer is not configured to perform recovery\n   C.\
    \ Survivability Requirements in Horizontal Hierarchy\n   o  protection of end-to-end\
    \ connection is based on a concatenated set\n      of connections, each protected\
    \ within their area\n   o  mechanisms for connection routing may include (1) a\
    \ network\n      element that participates on both sides of a boundary (e.g.,\
    \ OSPF\n      ABR) - note that this is a common point of failure; (2) a route\n\
    \      server\n   o  need for inter-area signaling of survivability information\
    \ (1) to\n      enable a \"least common denominator\" survivability mechanism\
    \ at the\n      boundary; (2) to convey the success or failure of the service\n\
    \      restoration action; e.g., if a part of a \"connection\" is down on\n  \
    \    one side of a boundary, there is no need for the other side to\n      recover\
    \ from failures\n"
- title: 2. Terminology and Concepts
  contents:
  - '2. Terminology and Concepts

    '
- title: 2.1 Hierarchy
  contents:
  - "2.1 Hierarchy\n   Hierarchy is a technique used to build scalable complex systems.\
    \  It\n   is based on an abstraction, at each level, of what is most\n   significant\
    \ from the details and internal structures of the levels\n   further away. This\
    \ approach makes use of a general property of all\n   hierarchical systems composed\
    \ of related subsystems that interactions\n   between subsystems decrease as the\
    \ level of communication between\n   subsystems decreases.\n   Network hierarchy\
    \ is an abstraction of part of a network's topology,\n   routing and signaling\
    \ mechanisms.  Abstraction may be used as a\n   mechanism to build large networks\
    \ or as a technique for enforcing\n   administrative, topological, or geographic\
    \ boundaries.  For example,\n   network hierarchy might be used to separate the\
    \ metropolitan and\n   long-haul regions of a network, or to separate the regional\
    \ and\n   backbone sections of a network, or to interconnect service provider\n\
    \   networks (with BGP which reduces a network to an Autonomous System).\n   In\
    \ this document, network hierarchy is considered from two\n   perspectives:\n\
    \   (1) Vertically oriented: between two network technology layers.\n   (2) Horizontally\
    \ oriented: between two areas or administrative\n       subdivisions within the\
    \ same network technology layer.\n"
- title: 2.1.1 Vertical Hierarchy
  contents:
  - "2.1.1 Vertical Hierarchy\n   Vertical hierarchy is the abstraction, or reduction\
    \ in information,\n   which would be of benefit when communicating information\
    \ across\n   network technology layers, as in propagating information between\n\
    \   optical and router networks.\n   In the vertical hierarchy, the total network\
    \ functions are\n   partitioned into a series of functional or technological layers\
    \ with\n   clear logical, and maybe even physical, separation between adjacent\n\
    \   layers. Survivability mechanisms either currently exist or are being\n   developed\
    \ at multiple layers in networks [3].  The optical layer is\n   now becoming capable\
    \ of providing dynamic ring and mesh restoration\n   functionality, in addition\
    \ to traditional 1+1 or 1:1 protection.  The\n   Synchronous Digital Hierarchy\
    \ (SDH)/Synchronous Optical NETwork\n   (SONET) layer provides survivability capability\
    \ with automatic\n   protection switching (APS), as well as self-healing ring\
    \ and mesh\n   restoration architectures.  Similar functionality has been defined\
    \ in\n   the Asynchronous Transfer Mode (ATM) Layer, with work ongoing to also\n\
    \   provide such functionality using MPLS [4].  At the IP layer,\n   rerouting\
    \ is used to restore service continuity following link and\n   node outages. \
    \ Rerouting at the IP layer, however, occurs after a\n   period of routing convergence,\
    \ which may require a few seconds to\n   several minutes to complete [5].\n"
- title: 2.1.2 Horizontal Hierarchy
  contents:
  - "2.1.2 Horizontal Hierarchy\n   Horizontal hierarchy is the abstraction that allows\
    \ a network at one\n   technology layer, for instance a packet network, to scale.\
    \  Examples\n   of horizontal hierarchy include BGP confederations, separate\n\
    \   Autonomous Systems, and multi-area OSPF.\n   In the horizontal hierarchy,\
    \ a large network is partitioned into\n   multiple smaller, non-overlapping sub-networks.\
    \  The partitioning\n   criteria can be based on topology, network function, administrative\n\
    \   policy, or service domain demarcation.  Two networks at the *same*\n   hierarchical\
    \ level, e.g., two Autonomous Systems in BGP, may share a\n   peer relation with\
    \ each other through some loose form of coupling.\n   On the other hand, for routing\
    \ in large networks using multi-area\n   OSPF, abstraction through the aggregation\
    \ of routing information is\n   achieved through a hierarchical partitioning of\
    \ the network.\n"
- title: 2.2 Survivability Terminology
  contents:
  - "2.2 Survivability Terminology\n   In alphabetical order, the following terms\
    \ are defined in this\n   section:\n   backup entity, same as protection entity\
    \ (section 2.2.2)\n   extra traffic (section 2.2.2)\n   non-revertive mode (section\
    \ 2.2.2)\n   normalization (section 2.2.2)\n   preemptable traffic, same as extra\
    \ traffic (section 2.2.2)\n   preemption priority (section 2.2.4)\n   protection\
    \ (section 2.2.3)\n   protection entity (section 2.2.2)\n   protection switching\
    \ (section 2.2.3)\n   protection switch time (section 2.2.4)\n   recovery (section\
    \ 2.2.2)\n   recovery by rerouting, same as restoration (section 2.2.3)\n   recovery\
    \ entity, same as protection entity (section 2.2.2)\n   restoration (section 2.2.3)\n\
    \   restoration priority (section 2.2.4)\n   restoration time (section 2.2.4)\n\
    \   revertive mode (section 2.2.2)\n   shared risk group (SRG) (section 2.2.2)\n\
    \   survivability (section 2.2.1)\n   working entity (section 2.2.2)\n"
- title: 2.2.1 Survivability
  contents:
  - "2.2.1 Survivability\n   Survivability is the capability of a network to maintain\
    \ service\n   continuity in the presence of faults within the network [6].\n \
    \  Survivability mechanisms such as protection and restoration are\n   implemented\
    \ either on a per-link basis, on a per-path basis, or\n   throughout an entire\
    \ network to alleviate service disruption at\n   affordable costs.  The degree\
    \ of survivability is determined by the\n   network's capability to survive single\
    \ failures, multiple failures,\n   and equipment failures.\n"
- title: 2.2.2 Generic Operations
  contents:
  - "2.2.2 Generic Operations\n   This document does not discuss the sequence of events\
    \ of how network\n   failures are monitored, detected, and mitigated.  For more\
    \ detail of\n   this aspect, see [4].  Also, the repair process following a failure\n\
    \   is out of the scope here.\n   A working entity is the entity that is used\
    \ to carry traffic in\n   normal operation mode.  Depending upon the context,\
    \ an entity can be\n   a channel or a transmission link in the physical layer,\
    \ an Label\n   Switched Path (LSP) in MPLS, or a logical bundle of one or more\
    \ LSPs.\n   A protection entity, also called backup entity or recovery entity,\
    \ is\n   the entity that is used to carry protected traffic in recovery\n   operation\
    \ mode, i.e., when the working entity is in error or has\n   failed.\n   Extra\
    \ traffic, also referred to as preemptable traffic, is the\n   traffic carried\
    \ over the protection entity while the working entity\n   is active.  Extra traffic\
    \ is not protected, i.e., when the protection\n   entity is required to protect\
    \ the traffic that is being carried over\n   the working entity, the extra traffic\
    \ is preempted.\n   A shared risk group (SRG) is a set of network elements that\
    \ are\n   collectively impacted by a specific fault or fault type.  For\n   example,\
    \ a shared risk link group (SRLG) is the union of all the\n   links on those fibers\
    \ that are routed in the same physical conduit in\n   a fiber-span network.  This\
    \ concept includes, besides shared conduit,\n   other types of compromise such\
    \ as shared fiber cable, shared right of\n   way, shared optical ring, shared\
    \ office without power sharing, etc.\n   The span of an SRG, such as the length\
    \ of the sharing for compromised\n   outside plant, needs to be considered on\
    \ a per fault basis.  The\n   concept of SRG can be extended to represent a \"\
    risk domain\" and its\n   associated capabilities and summarization for traffic\
    \ engineering\n   purposes.  See [7] for further discussion.\n   Normalization\
    \ is the sequence of events and actions taken by a\n   network that returns the\
    \ network to the preferred state upon\n   completing repair of a failure.  This\
    \ could include the switching or\n   rerouting of affected traffic to the original\
    \ repaired working\n   entities or new routes.  Revertive mode refers to the case\
    \ where\n   traffic is automatically returned to a repaired working entity (also\n\
    \   called switch back).\n   Recovery is the sequence of events and actions taken\
    \ by a network\n   after the detection of a failure to maintain the required performance\n\
    \   level for existing services (e.g., according to service level\n   agreements)\
    \ and to allow normalization of the network.  The actions\n   include notification\
    \ of the failure followed by two parallel\n   processes: (1) a repair process\
    \ with fault isolation and repair of\n   the failed components, and (2) a reconfiguration\
    \ process using\n   survivability mechanisms to maintain service continuity. \
    \ In\n   protection, reconfiguration involves switching the affected traffic\n\
    \   from a working entity to a protection entity.  In restoration,\n   reconfiguration\
    \ involves path selection and rerouting for the\n   affected traffic.\n   Revertive\
    \ mode is a procedure in which revertive action, i.e., switch\n   back from the\
    \ protection entity to the working entity, is taken once\n   the failed working\
    \ entity has been repaired.  In non-revertive mode,\n   such action is not taken.\
    \  To minimize service interruption, switch-\n   back in revertive mode should\
    \ be performed at a time when there is\n   the least impact on the traffic concerned,\
    \ or by using the make-\n   before-break concept.\n   Non-revertive mode is the\
    \ case where there is no preferred path or it\n   may be desirable to minimize\
    \ further disruption of the service\n   brought on by a revertive switching operation.\
    \  A switch-back to the\n   original working path is not desired or not possible\
    \ since the\n   original path may no longer exist after the occurrence of a fault\
    \ on\n   that path.\n"
- title: 2.2.3 Survivability Techniques
  contents:
  - "2.2.3 Survivability Techniques\n   Protection, also called protection switching,\
    \ is a survivability\n   technique based on predetermined failure recovery: as\
    \ the working\n   entity is established, a protection entity is also established.\n\
    \   Protection techniques can be implemented by several architectures:\n   1+1,\
    \ 1:1, 1:n, and m:n. In the context of SDH/SONET, they are\n   referred to as\
    \ Automatic Protection Switching (APS).\n   In the 1+1 protection architecture,\
    \ a protection entity is dedicated\n   to each working entity.  The dual-feed\
    \ mechanism is used whereby the\n   working entity is permanently bridged onto\
    \ the protection entity at\n   the source of the protected domain.  In normal\
    \ operation mode,\n   identical traffic is transmitted simultaneously on both\
    \ the working\n   and protection entities.  At the other end (sink) of the protected\n\
    \   domain, both feeds are monitored for alarms and maintenance signals.\n   A\
    \ selection between the working and protection entity is made based\n   on some\
    \ predetermined criteria, such as the transmission performance\n   requirements\
    \ or defect indication.\n   In the 1:1 protection architecture, a protection entity\
    \ is also\n   dedicated to each working entity.  The protected traffic is normally\n\
    \   transmitted by the working entity.  When the working entity fails,\n   the\
    \ protected traffic is switched to the protection entity.  The two\n   ends of\
    \ the protected domain must signal detection of the fault and\n   initiate the\
    \ switchover.\n   In the 1:n protection architecture, a dedicated protection entity\
    \ is\n   shared by n working entities.  In this case, not all of the affected\n\
    \   traffic may be protected.\n   The m:n architecture is a generalization of\
    \ the 1:n architecture.\n   Typically m <= n, where m dedicated protection entities\
    \ are shared by\n   n working entities.\n   Restoration, also referred to as recovery\
    \ by rerouting [4], is a\n   survivability technique that establishes new paths\
    \ or path segments\n   on demand, for restoring affected traffic after the occurrence\
    \ of a\n   fault.  The resources in these alternate paths are the currently\n\
    \   unassigned (unreserved) resources in the same layer.  Preemption of\n   extra\
    \ traffic may also be used if spare resources are not available\n   to carry the\
    \ higher-priority protected traffic.  As initiated by\n   detection of a fault\
    \ on the working path, the selection of a recovery\n   path may be based on preplanned\
    \ configurations, network routing\n   policies, or current network status such\
    \ as network topology and\n   fault information. Signaling is used for establishing\
    \ the new paths\n   to bypass the fault.  Thus, restoration involves a path selection\n\
    \   process followed by rerouting of the affected traffic from the\n   working\
    \ entity to the recovery entity.\n"
- title: 2.2.4 Survivability Performance
  contents:
  - "2.2.4 Survivability Performance\n   Protection switch time is the time interval\
    \ from the occurrence of a\n   network fault until the completion of the protection-switching\n\
    \   operations.  It includes the detection time necessary to initiate the\n  \
    \ protection switch, any hold-off time to allow for the interworking of\n   protection\
    \ schemes, and the switch completion time.\n   Restoration time is the time interval\
    \ from the occurrence of a\n   network fault to the instant when the affected\
    \ traffic is either\n   completely restored, or until spare resources are exhausted,\
    \ and/or\n   no more extra traffic exists that can be preempted to make room.\n\
    \   Restoration priority is a method of giving preference to protect\n   higher-priority\
    \ traffic ahead of lower-priority traffic.  Its use is\n   to help determine the\
    \ order of restoring traffic after a failure has\n   occurred.  The purpose is\
    \ to differentiate service restoration time\n   as well as to control access to\
    \ available spare capacity for\n   different classes of traffic.\n   Preemption\
    \ priority is a method of determining which traffic can be\n   disconnected in\
    \ the event that not all traffic with a higher\n   restoration priority is restored\
    \ after the occurrence of a failure.\n"
- title: '2.3 Survivability Mechanisms: Comparison'
  contents:
  - "2.3 Survivability Mechanisms: Comparison\n   In a survivable network design,\
    \ spare capacity and diversity must be\n   built into the network from the beginning\
    \ to support some degree of\n   self-healing whenever failures occur.  A common\
    \ strategy is to\n   associate each working entity with a protection entity having\
    \ either\n   dedicated resources or shared resources that are pre-reserved or\n\
    \   reserved-on-demand.  According to the methods of setting up a\n   protection\
    \ entity, different approaches to providing survivability\n   can be classified.\
    \  Generally, protection techniques are based on\n   having a dedicated protection\
    \ entity set up prior to failure.  Such\n   is not the case in restoration techniques,\
    \ which mainly rely on the\n   use of spare capacity in the network.  Hence, in\
    \ terms of trade-offs,\n   protection techniques usually offer fast recovery from\
    \ failure with\n   enhanced availability, while restoration techniques usually\
    \ achieve\n   better resource utilization.\n   A 1+1 protection architecture is\
    \ rather expensive since resource\n   duplication is required for the working\
    \ and protection entities.  It\n   is generally used for specific services that\
    \ need a very high\n   availability.\n   A 1:1 architecture is inherently slower\
    \ in recovering from failure\n   than a 1+1 architecture since communication between\
    \ both ends of the\n   protection domain is required to perform the switch-over\
    \ operation.\n   An advantage is that the protection entity can optionally be\
    \ used to\n   carry low-priority extra traffic in normal operation, if traffic\n\
    \   preemption is allowed.  Packet networks can pre-establish a\n   protection\
    \ path for later use with pre-planned but not pre-reserved\n   capacity.  That\
    \ is, if no packets are sent onto a protection path,\n   then no bandwidth is\
    \ consumed.  This is not the case in transmission\n   networks like optical or\
    \ TDM where path establishment and resource\n   reservation cannot be decoupled.\n\
    \   In the 1:n protection architecture, traffic is normally sent on the\n   working\
    \ entities.  When multiple working entities have failed\n   simultaneously, only\
    \ one of them can be restored by the common\n   protection entity.  This contention\
    \ could be resolved by assigning a\n   different preemptive priority to each working\
    \ entity.  As in the 1:1\n   case, the protection entity can optionally be used\
    \ to carry\n   preemptable traffic in normal operation.\n   While the m:n architecture\
    \ can improve system availability with small\n   cost increases, it has rarely\
    \ been implemented or standardized.\n   When compared with protection mechanisms,\
    \ restoration mechanisms are\n   generally more frugal as no resources are committed\
    \ until after the\n   fault occurs and the location of the fault is known.  However,\n\
    \   restoration mechanisms are inherently slower, since more must be done\n  \
    \ following the detection of a fault.  Also, the time it takes for the\n   dynamic\
    \ selection and establishment of alternate paths may vary,\n   depending on the\
    \ amount of traffic and connections to be restored,\n   and is influenced by the\
    \ network topology, technology employed, and\n   the type and severity of the\
    \ fault.  As a result, restoration time\n   tends to be more variable than the\
    \ protection switch time needed with\n   pre-selected protection entities.  Hence,\
    \ in using restoration\n   mechanisms, it is essential to use restoration priority\
    \ to ensure\n   that service objectives are met cost-effectively.\n   Once the\
    \ network routing algorithms have converged after a fault, it\n   may be preferable\
    \ in some cases, to reoptimize the network by\n   performing a reroute based on\
    \ the current state of the network and\n   network policies.\n"
- title: 3. Survivability
  contents:
  - '3. Survivability

    '
- title: 3.1 Scope
  contents:
  - "3.1 Scope\n   Interoperable approaches to network survivability were determined\
    \ to\n   be an immediate requirement in packet networks as well as in\n   SDH/SONET\
    \ framed TDM networks.  Not as pressing at this time were\n   techniques that\
    \ would cover all-optical networks (e.g., where framing\n   is unknown), as the\
    \ control of these networks in a multi-vendor\n   environment appeared to have\
    \ some other hurdles to first deal with.\n   Also, not of immediate interest were\
    \ approaches to coordinate or\n   explicitly communicate survivability mechanisms\
    \ across network layers\n   (such as from a TDM or optical network to/from an\
    \ IP network).\n   However, a capability should be provided for a network operator\
    \ to\n   perform fault notification and to control the operation of\n   survivability\
    \ mechanisms among different layers.  This may require\n   the development of\
    \ corresponding OAM functionality. However, such\n   issues and those related\
    \ to OAM are currently outside the scope of\n   this document.  (For proposed\
    \ MPLS OAM requirements, see [8, 9]).\n   The initial scope is to address only\
    \ \"backhoe failures\" in the\n   inter-office connections of a service provider\
    \ network.  A link\n   connection in the router layer is typically comprised of\
    \ multiple\n   spans in the lower layers.  Therefore, the types of network failures\n\
    \   that cause a recovery to be performed include link/span failures.\n   However,\
    \ linecard and node failures may not need to be treated any\n   differently than\
    \ their respective link/span failures, as a router\n   failure may be represented\
    \ as a set of simultaneous link failures.\n   Depending on the actual network\
    \ configuration, drop-side interface\n   (e.g., between a customer and an access\
    \ router, or between a router\n   and an optical cross-connect) may be considered\
    \ either inter-domain\n   or inter-layer.  Another inter-domain scenario is the\
    \ use of intra-\n   office links for interconnecting a metro network and a core\
    \ network,\n   with both networks being administered by the same service provider.\n\
    \   Failures at such interfaces may be similarly protected by the\n   mechanisms\
    \ of this section.\n   Other more complex failure mechanisms such as systematic\
    \ control-\n   plane failure, configuration error, or breach of security are not\n\
    \   within the scope of the survivability mechanisms discussed in this\n   document.\
    \  Network impairment such as congestion that results in\n   lower throughput\
    \ are also not covered.\n"
- title: 3.2 Required initial set of survivability mechanisms
  contents:
  - '3.2 Required initial set of survivability mechanisms

    '
- title: 3.2.1   1:1 Path Protection with Pre-Established Capacity
  contents:
  - "3.2.1   1:1 Path Protection with Pre-Established Capacity\n   In this protection\
    \ mode, the head end of a working connection\n   establishes a protection connection\
    \ to the destination.  There should\n   be the ability to maintain relative restoration\
    \ priorities between\n   working and protection connections, as well as between\
    \ different\n   classes of protection connections.\n   In normal operation, traffic\
    \ is only sent on the working connection,\n   though the ability to signal that\
    \ traffic will be sent on both\n   connections (1+1 Path for signaling purposes)\
    \ would be valuable in\n   non-packet networks.  Some distinction between working\
    \ and protection\n   connections is likely, either through explicit objects, or\
    \ preferably\n   through implicit methods such as general classes or priorities.\
    \  Head\n   ends need the ability to create connections that are as failure\n\
    \   disjoint as possible from each other.  This requires SRG information\n   that\
    \ can be generally assigned to either nodes or links and\n   propagated through\
    \ the control or management plane.  In this\n   mechanism, capacity in the protection\
    \ connection is pre-established,\n   however it should be capable of carrying\
    \ preemptable extra traffic in\n   non-packet networks.  When protection capacity\
    \ is called into service\n   during recovery, there should be the ability to promote\
    \ the\n   protection connection to working status (for non-revertive mode\n  \
    \ operation) with some form of make-before-break capability.\n"
- title: 3.2.2   1:1 Path Protection with Pre-Planned Capacity
  contents:
  - "3.2.2   1:1 Path Protection with Pre-Planned Capacity\n   Similar to the above\
    \ 1:1 protection with pre-established capacity,\n   the protection connection\
    \ in this case is also pre-signaled.  The\n   difference is in the way protection\
    \ capacity is assigned.  With pre-\n   planned capacity, the mechanism supports\
    \ the ability for the\n   protection capacity to be shared, or \"double-booked\"\
    .  Operators need\n   the ability to provision different amounts of protection\
    \ capacity\n   according to expected failure modes and service level agreements.\n\
    \   Thus, an operator may wish to provision sufficient restoration\n   capacity\
    \ to handle a single failure affecting all connections in an\n   SRG, or may wish\
    \ to provision less or more restoration capacity.\n   Mechanisms should be provided\
    \ to allow restoration capacity on each\n   link to be shared by SRG-disjoint\
    \ failures.  In a sense, this is 1:1\n   from a path perspective; however, the\
    \ protection capacity in the\n   network (on a link by link basis) is shared in\
    \ a 1:n fashion, e.g.,\n   see the proposals in [10, 11].  If capacity is planned\
    \ but not\n   allocated, some form of signaling could be required before traffic\n\
    \   may be sent on protection connections, especially in TDM networks.\n   The\
    \ use of this approach improves network resource utilization, but\n   may require\
    \ more careful planning.  So, initial deployment might be\n   based on 1:1 path\
    \ protection with pre-established capacity and the\n   local restoration mechanism\
    \ to be described next.\n"
- title: 3.2.3   Local Restoration
  contents:
  - "3.2.3   Local Restoration\n   Due to the time impact of signal propagation, dynamic\
    \ recovery of an\n   entire path may not meet the service requirements of some\
    \ networks.\n   The solution to this is to restore connectivity of the link or\
    \ span\n   in immediate proximity to the fault, e.g., see the proposals in [12,\n\
    \   13].  At a minimum, this approach should be able to protect against\n   connectivity-type\
    \ SRGs, though protecting against node-based SRGs\n   might be worthwhile.  Also,\
    \ this approach is applicable to support\n   restoration on the inter-domain and\
    \ inter-layer interconnection\n   scenarios using intra-office links as described\
    \ in the Scope Section.\n   Head end systems must have some control as to whether\
    \ their\n   connections are candidates for or excluded from local restoration.\n\
    \   For example, best-effort and preemptable traffic may be excluded from\n  \
    \ local restoration; they only get restored if there is bandwidth\n   available.\
    \  This type of control may require the definition of an\n   object in signaling.\n\
    \   Since local restoration may be suboptimal, a means for head end\n   systems\
    \ to later perform path-level re-grooming must be supported for\n   this approach.\n"
- title: 3.2.4   Path Restoration
  contents:
  - "3.2.4   Path Restoration\n   In this approach, connections that are impacted\
    \ by a fault are\n   rerouted by the originating network element upon notification\
    \ of\n   connection failure.  Such a source-based approach is efficient for\n\
    \   network resources, but typically takes longer to accomplish\n   restoration.\
    \  It does not involve any new mechanisms.  It merely is a\n   mention of another\
    \ common approach to protecting against faults in a\n   network.\n"
- title: 3.3 Applications Supported
  contents:
  - "3.3 Applications Supported\n   With service continuity under failure as a goal,\
    \ a network is\n   \"survivable\" if, in the face of a network failure, connectivity\
    \ is\n   interrupted for a \"brief\" period and then recovered before the\n  \
    \ network failure ends.  The length of this interrupted period is\n   dependent\
    \ upon the application supported.  Here are some typical\n   applications and\
    \ considerations that drive the requirements for an\n   acceptable protection\
    \ switch time or restoration time:\n   - Best-effort data: recovery of network\
    \ connectivity by rerouting at\n     the IP layer would be sufficient\n   - Premium\
    \ data service: need to meet TCP timeout or application\n     protocol timer requirements\n\
    \   - Voice: call cutoff is in the range of 140 msec to 2 sec (the time\n    \
    \ that a person waits after interruption of the speech path before\n     hanging\
    \ up or the time that a telephone switch will disconnect a\n     call)\n   - Other\
    \ real-time service (e.g., streaming, fax) where an\n     interruption would cause\
    \ the session to terminate\n   - Mission-critical applications that cannot tolerate\
    \ even brief\n     interruptions, for example, real-time financial transactions\n"
- title: 3.4 Timing Bounds for Survivability Mechanisms
  contents:
  - "3.4 Timing Bounds for Survivability Mechanisms\n   The approach to picking the\
    \ types of survivability mechanisms\n   recommended was to consider a spectrum\
    \ of mechanisms that can be used\n   to protect traffic with varying characteristics\
    \ of survivability and\n   speed of protection/restoration, and then attempt to\
    \ select a few\n   general points that provide some coverage across that spectrum.\
    \  The\n   focus of this work is to provide requirements to which a small set\
    \ of\n   detailed proposals may be developed, allowing the operator some\n   (limited)\
    \ flexibility in approaches to meeting their design goals in\n   engineering multi-vendor\
    \ networks.  Requirements of different\n   applications as listed in the previous\
    \ sub-section were discussed\n   generally, however none on the team would likely\
    \ attest to the\n   scientific merit of the ability of the timing bounds below\
    \ to meet\n   any specific application's needs.  A few assumptions include:\n\
    \   1. Approaches in which protection switch without propagation of\n      information\
    \ are likely to be faster than those that do require\n      some form of fault\
    \ notification to some or all elements in a\n      network.\n   2. Approaches\
    \ that require some form of signaling after a fault will\n      also likely suffer\
    \ some timing impact.\n   Proposed timing bounds for different survivability mechanisms\
    \ are as\n   follows (all bounds are exclusive of signal propagation):\n   1:1\
    \ path protection with pre-established capacity:  100-500 ms\n   1:1 path protection\
    \ with pre-planned capacity:      100-750 ms\n   Local restoration:          \
    \                        50 ms\n   Path restoration:                         \
    \          1-5 seconds\n   To ensure that the service requirements for different\
    \ applications\n   can be met within the above timing bounds, restoration priority\
    \ must\n   be implemented to determine the order in which connections are\n  \
    \ restored (to minimize service restoration time as well as to gain\n   access\
    \ to available spare capacity on the best paths).  For example,\n   mission critical\
    \ applications may require high restoration priority.\n   At the fiber layer,\
    \ instead of specific applications, it may be\n   possible that priority be given\
    \ to certain classifications of\n   customers with their traffic types enclosed\
    \ within the customer\n   aggregate.  Preemption priority should only be used\
    \ in the event that\n   not all connections can be restored, in which case connections\
    \ with\n   lower preemption priority should be released. Depending on a service\n\
    \   provider's strategy in provisioning network resources for backup,\n   preemption\
    \ may or may not be needed in the network.\n"
- title: 3.5 Coordination Among Layers
  contents:
  - "3.5 Coordination Among Layers\n   A common design goal for networks with multiple\
    \ technological layers\n   is to provide the desired level of service in the most\
    \ cost-effective\n   manner.  Multilayer survivability may allow the optimization\
    \ of spare\n   resources through the improvement of resource utilization by sharing\n\
    \   spare capacity across different layers, though further investigations\n  \
    \ are needed.  Coordination during recovery among different network\n   layers\
    \ (e.g., IP, SDH/SONET, optical layer) might necessitate\n   development of vertical\
    \ hierarchy.  The benefits of providing\n   survivability mechanisms at multiple\
    \ layers, and the optimization of\n   the overall approach, must be weighed with\
    \ the associated cost and\n   service impacts.\n   A default coordination mechanism\
    \ for inter-layer interaction could be\n   the use of nested timers and current\
    \ SDH/SONET fault monitoring, as\n   has been done traditionally for backward\
    \ compatibility.  Thus, when\n   lower-layer recovery happens in a longer time\
    \ period than higher-\n   layer recovery, a hold-off timer is utilized to avoid\
    \ contention\n   between the different single-layer survivability schemes.  In\
    \ other\n   words, multilayer interaction is addressed by having successively\n\
    \   higher multiplexing levels operate at a protection/restoration time\n   scale\
    \ greater than the next lowest layer.  This can impact the\n   overall time to\
    \ recover service.  For example, if SDH/SONET\n   protection switching is used,\
    \ MPLS recovery timers must wait until\n   SDH/SONET has had time to switch. \
    \ Setting such timers involves a\n   tradeoff between rapid recovery and creation\
    \ of a race condition\n   where multiple layers are responding to the same fault,\
    \ potentially\n   allocating resources in an inefficient manner.\n   In other\
    \ configurations where the lower layer does not have a\n   restoration capability\
    \ or is not expected to protect, say an\n   unprotected SDH/SONET linear circuit,\
    \ then there must be a mechanism\n   for the lower layer to trigger the higher\
    \ layer to take recovery\n   actions immediately.  This difference in network\
    \ configuration means\n   that implementations must allow for adjustment of hold-off\
    \ timer\n   values and/or a means for a lower layer to immediately indicate to\
    \ a\n   higher layer that a fault has occurred so that the higher layer can\n\
    \   take restoration or protection actions.\n   Furthermore, faults at higher\
    \ layers should not trigger restoration\n   or protection actions at lower layers\
    \ [3, 4].\n   It was felt that the current approach to coordination of\n   survivability\
    \ approaches currently did not have significant\n   operational shortfalls.  These\
    \ approaches include protecting traffic\n   solely at one layer (e.g., at the\
    \ IP layer over linear WDM, or at the\n   SDH/SONET layer).  Where survivability\
    \ mechanisms might be deployed\n   at several layers, such as when a routed network\
    \ rides a SDH/SONET\n   protected network, it was felt that current coordination\
    \ approaches\n   were sufficient in many cases.  One exception is the hold-off\
    \ of MPLS\n   recovery until the completion of SDH/SONET protection switching\
    \ as\n   described above.  This limits the recovery time of fast MPLS\n   restoration.\
    \  Also, by design, the operations and mechanisms within a\n   given layer tend\
    \ to be invisible to other layers.\n"
- title: 3.6 Evolution Toward IP Over Optical
  contents:
  - "3.6 Evolution Toward IP Over Optical\n   As more pressing requirements for survivability\
    \ and horizontal\n   hierarchy for edge-to-edge signaling are met with technical\n\
    \   proposals, it is believed that the benefits of merging (in some\n   manner)\
    \ the control planes of multiple layers will be outlined.  When\n   these benefits\
    \ are self-evident, it would then seem to be the right\n   time to review whether\
    \ vertical hierarchy mechanisms are needed, and\n   what the requirements might\
    \ be.  For example, a future requirement\n   might be to provide a better match\
    \ between the recovery requirements\n   of IP networks with the recovery capability\
    \ of optical transport.\n   One such proposal is described in [14].\n"
- title: 4. Hierarchy Requirements
  contents:
  - "4. Hierarchy Requirements\n   Efforts in the area of network hierarchy should\
    \ focus on mechanisms\n   that would allow more scalable edge-to-edge signaling,\
    \ or signaling\n   across networks with existing network hierarchy (such as multi-area\n\
    \   OSPF).  This appears to be a more urgent need than mechanisms that\n   might\
    \ be needed to interconnect networks at different layers.\n"
- title: 4.1 Historical Context
  contents:
  - "4.1 Historical Context\n   One reason for horizontal hierarchy is functionality\
    \ (e.g., metro\n   versus backbone).  Geographic \"islands\" or partitions reduce\
    \ the need\n   for interoperability and make administration and operations less\n\
    \   complex.  Using a simpler, more interoperable, survivability scheme\n   at\
    \ metro/backbone boundaries is natural for many provider network\n   architectures.\
    \  In transmission networks, creating geographic islands\n   of different vendor\
    \ equipment has been done for a long time because\n   multi-vendor interoperability\
    \ has been difficult to achieve.\n   Traditionally, providers have to coordinate\
    \ the equipment on either\n   end of a \"connection,\" and making this interoperable\
    \ reduces\n   complexity.  A provider should be able to concatenate survivability\n\
    \   mechanisms in order to provide a \"protected link\" to the next higher\n \
    \  level.  Think of SDH/SONET rings connecting to TDM DXCs with 1+1\n   line-layer\
    \ protection between the ADM and the DXC port.  The TDM\n   connection, e.g.,\
    \ a DS3, is protected but usually all equipment on\n   each SDH/SONET ring is\
    \ from a single vendor.  The DXC cross\n   connections are controlled by the provider\
    \ and the ports are\n   physically protected resulting in a highly available design.\
    \  Thus,\n   concatenation of survivability approaches can be used to cascade\n\
    \   across a horizontal hierarchy.  While not perfect, it is workable in\n   the\
    \ near to mid-term until multi-vendor interoperability is achieved.\n   While\
    \ the problems associated with multi-vendor interoperability may\n   necessitate\
    \ horizontal hierarchy as a practical matter in the near to\n   mid-term (at least\
    \ this has been the case in TDM networks), there\n   should not be a technical\
    \ reason for it in the standards developed by\n   the IETF for core networks,\
    \ or even most access networks.\n   Establishing interoperability of survivability\
    \ mechanisms between\n   multi-vendor equipment in core IP networks is urgently\
    \ required to\n   enable adoption of IP as a viable core transport technology\
    \ and to\n   facilitate the traffic engineering of future multi-service IP\n \
    \  networks [3].\n   Some of the largest service provider networks currently run\
    \ a single\n   area/level IGP.  Some service providers, as well as many large\n\
    \   enterprise networks, run multi-area Open Shortest Path First (OSPF)\n   to\
    \ gain increases in scalability.  Often, this was from an original\n   design,\
    \ so it is difficult to say if the network truly required the\n   hierarchy to\
    \ reach its current size.\n   Some proposals on improved mechanisms to address\
    \ network hierarchy\n   have been suggested [15, 16, 17, 18, 19].  This document\
    \ aims to\n   provide the concrete requirements so that these and other proposals\n\
    \   can first aim to meet some limited objectives.\n"
- title: 4.2 Applications for Horizontal Hierarchy
  contents:
  - "4.2 Applications for Horizontal Hierarchy\n   A primary driver for intra-domain\
    \ horizontal hierarchy is signaling\n   capabilities in the context of edge-to-edge\
    \ VPNs, potentially across\n   traffic-engineered data networks.  There are a\
    \ number of different\n   approaches to layer 2 and layer 3 VPNs and they are\
    \ currently being\n   addressed by different emerging protocols in the provider-provisioned\n\
    \   VPNs (e.g., virtual routers) and Pseudo Wire Edge-to-Edge Emulation\n   (PWE3)\
    \ efforts based on either MPLS and/or IP tunnels.  These may or\n   may not need\
    \ explicit signaling from edge to edge, but it is a common\n   perception that\
    \ in order to meet SLAs, some form of edge-to-edge\n   signaling may be required.\n\
    \   With a large number of edges (N), scalability is concerned with\n   avoiding\
    \ the O(N^2) properties of edge-to-edge signaling.  However,\n   the main issue\
    \ here is not with the scalability of large amounts of\n   signaling, such as\
    \ in O(N^2) meshes with a \"connection\" between every\n   edge-pair.  This is\
    \ because, even if establishing and maintaining\n   connections is feasible in\
    \ a large network, there might be an impact\n   on core survivability mechanisms\
    \ which would cause\n   protection/restoration times to grow with N^2, which would\
    \ be\n   undesirable.  While some value of N may be inevitable, approaches to\n\
    \   reduce N (e.g. to pull in from the edge to aggregation points) might\n   be\
    \ of value.\n   Thus, most service providers feel that O(N^2) meshes are not\n\
    \   necessary for VPNs, and that the number of tunnels to support VPNs\n   would\
    \ be within the scalability bounds of current protocols and\n   implementations.\
    \  That may be the case, as there is currently a lack\n   of ability to signal\
    \ MPLS tunnels from edge to edge across IGP\n   hierarchy, such as OSPF areas.\
    \  This may require the development of\n   signaling standards that support dynamic\
    \ establishment and\n   potentially the restoration of LSPs across a 2-level IGP\
    \ hierarchy.\n   For routing scalability, especially in data applications, a major\n\
    \   concern is the amount of processing/state that is required in the\n   variety\
    \ of network elements.  If some nodes might not be able to\n   communicate and\
    \ process the state of every other node, it might be\n   preferable to limit the\
    \ information.  There is one school of thought\n   that says that the amount of\
    \ information contained by a horizontal\n   barrier should be significant, and\
    \ that impacts this might have on\n   optimality in route selection and ability\
    \ to provide global\n   survivability are accepted tradeoffs.\n"
- title: 4.3 Horizontal Hierarchy Requirements
  contents:
  - "4.3 Horizontal Hierarchy Requirements\n   Mechanisms are required to allow for\
    \ edge-to-edge signaling of\n   connections through a network.  One network scenario\
    \ includes medium\n   to large networks that currently have hierarchical interior\
    \ routing\n   such as multi-area OSPF or multi-level Intermediate System to\n\
    \   Intermediate System (IS-IS).  The primary context of this is edge-\n   to-edge\
    \ signaling, which is thought to be required to assure the SLAs\n   for the layer\
    \ 2 and layer 3 VPNs that are being carried across the\n   network.  Another possible\
    \ context would be edge-to-edge signaling in\n   TDM SDH/SONET networks with IP\
    \ control, where metro and core networks\n   again might be in a hierarchical\
    \ interior routing domain.\n   To support edge-to-edge signaling in the above\
    \ network scenarios\n   within the framework of existing horizontal hierarchies,\
    \ current\n   traffic engineering (TE) methods [20, 6] may need to be extended.\n\
    \   Requirements for multi-area TE need to be developed to provide\n   guidance\
    \ for any necessary protocol extensions.\n"
- title: 5. Survivability and Hierarchy
  contents:
  - "5. Survivability and Hierarchy\n   When horizontal hierarchy exists in a network\
    \ technology layer, a\n   question arises as to how survivability can be provided\
    \ along a\n   connection that crosses hierarchical boundaries.\n   In designing\
    \ protocols to meet the requirements of hierarchy, an\n   approach to consider\
    \ is that boundaries are either clean, or are of\n   minimal value.  However,\
    \ the concept of network elements that\n   participate on both sides of a boundary\
    \ might be a consideration\n   (e.g., OSPF ABRs).  That would allow for devices\
    \ on either side to\n   take an intra-area approach within their region of knowledge,\
    \ and for\n   the ABR to do this in both areas, and splice the two protected\n\
    \   connections together at a common point (granted it is a common point\n   of\
    \ failure now).  If the limitations of this approach start to appear\n   in operational\
    \ settings, then perhaps it would be time to start\n   thinking about route-servers\
    \ and signaling propagated directives.\n   However, one initial approach might\
    \ be to signal through a common\n   border router, and to consider the service\
    \ as protected as it\n   consists of a concatenated set of connections which are\
    \ each\n   protected within their area.  Another approach might be to have a\n\
    \   least common denominator mechanism at the boundary, e.g., 1+1 port\n   protection.\
    \  There should also be some standardized means for a\n   survivability scheme\
    \ on one side of such a boundary to communicate\n   with the scheme on the other\
    \ side regarding the success or failure of\n   the recovery action.  For example,\
    \ if a part of a \"connection\" is\n   down on one side of such a boundary, there\
    \ is no need for the other\n   side to recover from failures.\n   In summary,\
    \ at this time, approaches as described above that allow\n   concatenation of\
    \ survivability schemes across hierarchical boundaries\n   seem sufficient.\n"
- title: 6. Security Considerations
  contents:
  - "6. Security Considerations\n   The set of SRGs that are defined for a network\
    \ under a common\n   administrative control and the corresponding assignment of\
    \ these SRGs\n   to nodes and links within the administrative control is sensitive\n\
    \   information and needs to be protected.  An SRG is an acknowledgement\n   that\
    \ nodes and links that belong to an SRG are susceptible to a\n   common threat.\
    \  An adversary with access to information contained in\n   an SRG could use that\
    \ information to design an attack, determine the\n   scope of damage caused by\
    \ the attack and, therefore, be used to\n   maximize the effect of an attack.\n\
    \   The label used to refer to a particular SRG must allow for an\n   encoding\
    \ such that sensitive information such as physical location,\n   function, purpose,\
    \ customer, fault type, etc. is not readily\n   discernable by unauthorized users.\n\
    \   SRG information that is propagated through the control and management\n  \
    \ plane should allow for an encryption mechanism.  An example of an\n   approach\
    \ would be to use IPSEC [21] on all packets carrying SRG\n   information.\n"
- title: 7. References
  contents:
  - "7. References\n   [1]  Bradner, S., \"The Internet Standards Process -- Revision\
    \ 3\", BCP\n        9, RFC 2026, October 1996.\n   [2]  Bradner, S., \"Key words\
    \ for use in RFCs to Indicate Requirement\n        Levels\", BCP 14, RFC 2119,\
    \ March 1997.\n   [3]  K. Owens, V. Sharma, and M. Oommen, \"Network Survivability\n\
    \        Considerations for Traffic Engineered IP Networks\", Work in\n      \
    \  Progress.\n   [4]  V. Sharma, B. Crane, S. Makam, K. Owens, C. Huang, F.\n\
    \        Hellstrand, J. Weil, L. Andersson, B. Jamoussi, B. Cain, S.\n       \
    \ Civanlar, and A. Chiu, \"Framework for MPLS-based Recovery\", Work\n       \
    \ in Progress.\n   [5]  M. Thorup, \"Fortifying OSPF/ISIS Against Link Failure\"\
    ,\n        http://www.research.att.com/~mthorup/PAPERS/lf_ospf.ps\n   [6]  Awduche,\
    \ D., Chiu, A., Elwalid, A., Widjaja, I. and X. Xiao,\n        \"Overview and\
    \ Principles of Internet Traffic Engineering\", RFC\n        3272, May 2002.\n\
    \   [7]  S. Dharanikota, R. Jain, D. Papadimitriou, R. Hartani, G.\n        Bernstein,\
    \ V. Sharma, C. Brownmiller, Y. Xue, and J. Strand,\n        \"Inter-domain routing\
    \ with Shared Risk Groups\", Work in\n        Progress.\n   [8]  N. Harrison,\
    \ P. Willis, S. Davari, E. Cuevas, B. Mack-Crane, E.\n        Franze, H. Ohta,\
    \ T. So, S. Goldfless, and F. Chen, \"Requirements\n        for OAM in MPLS Networks,\"\
    \ Work in Progress.\n   [9]  D. Allan and M. Azad, \"A Framework for MPLS User\
    \ Plane OAM,\"\n        Work in Progress.\n   [10] S. Kini, M. Kodialam, T.V.\
    \ Lakshman, S. Sengupta, and C.\n        Villamizar, \"Shared Backup Label Switched\
    \ Path Restoration,\"\n        Work in Progress.\n   [11] G. Li, C. Kalmanek,\
    \ J. Yates, G. Bernstein, F. Liaw, and V.\n        Sharma, \"RSVP-TE Extensions\
    \ For Shared-Mesh Restoration in\n        Transport Networks\", Work in Progress.\n\
    \   [12] P. Pan (Editor), D.H. Gan, G. Swallow, J. Vasseur, D. Cooper, A.\n  \
    \      Atlas, and M. Jork, \"Fast Reroute Extensions to RSVP-TE for LSP\n    \
    \    Tunnels\", Work in Progress.\n   [13] A. Atlas, C. Villamizar, and C. Litvanyi,\
    \ \"MPLS RSVP-TE\n        Interoperability for Local Protection/Fast Reroute\"\
    , Work in\n        Progress.\n   [14] A. Chiu and J. Strand, \"Joint IP/Optical\
    \ Layer Restoration after\n        a Router Failure\", Proc. OFC'2001, Anaheim,\
    \ CA, March 2001.\n   [15] K. Kompella and Y. Rekhter, \"Multi-area MPLS Traffic\n\
    \        Engineering\", Work in Progress.\n   [16] G. Ash, et. al., \"Requirements\
    \ for Multi-Area TE\", Work in\n        Progress.\n   [17] A. Iwata, N. Fujita,\
    \ G.R. Ash, and A. Farrel, \"Crankback Routing\n        Extensions for MPLS Signaling\"\
    , Work in Progress.\n   [18] C-Y Lee, A. Celer, N. Gammage, S. Ghanti, G. Ash,\
    \ \"Distributed\n        Route Exchangers\", Work in Progress.\n   [19] C-Y Lee\
    \ and S. Ghanti, \"Path Request and Path Reply Message\",\n        Work in Progress.\n\
    \   [20] Awduche, D., Malcolm, J., Agogbua, J., O'Dell, M. and J.\n        McManus,\
    \ \"Requirements for Traffic Engineering Over MPLS\", RFC\n        2702, September\
    \ 1999.\n   [21] Kent, S. and R. Atkinson, \"Security Architecture for the\n \
    \       Internet Protocol\", RFC 2401, November 1998.\n"
- title: 8. Acknowledgments
  contents:
  - "8. Acknowledgments\n   A lot of the direction taken in this document, and by\
    \ the team in its\n   initial effort was steered by the insightful questions provided\
    \ by\n   Bala Rajagoplan, Greg Bernstein, Yangguang Xu, and Avri Doria.  The\n\
    \   set of questions is attached as Appendix A in this document.\n   After the\
    \ release of the first draft, a number of comments were\n   received.  Thanks\
    \ to the inputs from Jerry Ash, Sudheer Dharanikota,\n   Chuck Kalmanek, Dan Koller,\
    \ Lyndon Ong, Steve Plote, and Yong Xue.\n"
- title: 9. Contributing Authors
  contents:
  - "9. Contributing Authors\n   Jim Boyle (PDNets), Rob Coltun (Movaz), Tim Griffin\
    \ (AT&T), Ed Kern,\n   Tom Reddington (Lucent) and Malin Carlzon.\n"
- title: 'Appendix A: Questions used to help develop requirements'
  contents:
  - "Appendix A: Questions used to help develop requirements\n   A. Definitions\n\
    \   1. In determining the specific requirements, the design team should\n    \
    \  precisely define the concepts \"survivability\", \"restoration\",\n      \"\
    protection\", \"protection switching\", \"recovery\", \"re-routing\"\n      etc.\
    \ and their relations.  This would enable the requirements doc\n      to describe\
    \ precisely which of these will be addressed. In the\n      following, the term\
    \ \"restoration\" is used to indicate the broad\n      set of policies and mechanisms\
    \ used to ensure survivability.\n   B. Network types and protection modes\n  \
    \ 1. What is the scope of the requirements with regard to the types of\n     \
    \ networks covered?  Specifically, are the following in scope:\n      Restoration\
    \ of connections in mesh optical networks (opaque or\n      transparent)\n   \
    \   Restoration of connections in hybrid mesh-ring networks\n      Restoration\
    \ of LSPs in MPLS networks (composed of LSRs overlaid on\n      a transport network,\
    \ e.g., optical)\n      Any other types of networks?\n      Is commonality of\
    \ approach, or optimization of approach more\n      important?\n   2. What are\
    \ the requirements with regard to the protection modes to\n      be supported\
    \ in each network type covered? (Examples of protection\n      modes include 1+1,\
    \ M:N, shared mesh, UPSR, BLSR, newly defined\n      modes such as P-cycles, etc.)\n\
    \   3. What are the requirements on local span (i.e., link by link)\n      protection\
    \ and end-to-end protection, and the interaction between\n      them?  E.g.: what\
    \ should be the granularity of connections for\n      each type (single connection,\
    \ bundle of connections, etc).\n   C. Hierarchy\n   1. Vertical (between two network\
    \ layers):\n      What are the requirements for the interaction between restoration\n\
    \      procedures across two network layers, when these features are\n      offered\
    \ in both layers?  (Example, MPLS network realized over pt-\n      to-pt optical\
    \ connections.)  Under such a case,\n      (a) Are there any criteria to choose\
    \ which layer should provide\n          protection?\n      (b) If both layers\
    \ provide survivability features, what are the\n          requirements to coordinate\
    \ these mechanisms?\n      (c) How is lack of current functionality of cross-layer\n\
    \          coordination currently hampering operations?\n      (d) Would the benefits\
    \ be worth additional complexity associated\n          with routing isolation\
    \ (e.g. VPN, areas), security, address\n          isolation and policy / authentication\
    \ processes?\n   2. Horizontal (between two areas or administrative subdivisions\n\
    \      within the same network layer):\n      (a) What are the criteria that trigger\
    \ the creation of protocol or\n          administrative boundaries pertaining\
    \ to restoration? (e.g.,\n          scalability?  multi-vendor interoperability?\
    \  what are the\n          practical issues?)  multi-provider?  Should multi-vendor\n\
    \          necessitate hierarchical separation?\n      When such boundaries are\
    \ defined:\n      (b) What are the requirements on how protection/restoration\
    \ is\n          performed end-to-end across such boundaries?\n      (c) If different\
    \ restoration mechanisms are implemented on two\n          sides of a boundary,\
    \ what are the requirements on their\n          interaction?\n      What is the\
    \ primary driver of horizontal hierarchy? (select one)\n          - functionality\
    \ (e.g. metro -v- backbone)\n          - routing scalability\n          - signaling\
    \ scalability\n          - current network architecture, trying to layer on TE\
    \ on top\n            of an already hierarchical network architecture\n      \
    \    - routing and signalling\n      For signalling scalability, is it\n     \
    \     - manageability\n          - processing/state of network\n          - edge-to-edge\
    \ N^2 type issue\n      For routing scalability, is it\n          - processing/state\
    \ of network\n          - are you flat and want to go hierarchical\n         \
    \ - or already hierarchical?\n          - data or TDM application?\n   D. Policy\n\
    \   1. What are the requirements for policy support during\n      protection/restoration,\
    \ e.g., restoration priority, preemption,\n      etc.\n   E. Signaling Mechanisms\n\
    \   1. What are the requirements on the signaling transport mechanism\n      (e.g.,\
    \ in-band over SDH/SONET overhead bytes, out-of-band over an\n      IP network,\
    \ etc.) used to communicate restoration protocol\n      messages between network\
    \ elements?  What are the bandwidth and\n      other requirements on the signaling\
    \ channels?\n   2. What are the requirements on fault detection/localization\n\
    \      mechanisms (which is the prelude to performing restoration\n      procedures)\
    \ in the case of opaque and transparent optical\n      networks? What are the\
    \ requirements in the case of MPLS\n      restoration?\n   3. What are the requirements\
    \ on signaling protocols to be used in\n      restoration procedures (e.g., high\
    \ priority processing, security,\n      etc)?\n   4. Are there any requirements\
    \ on the operation of restoration\n      protocols?\n   F. Quantitative\n   1.\
    \ What are the quantitative requirements (e.g., latency) for\n      completing\
    \ restoration under different protection modes (for both\n      local and end-to-end\
    \ protection)?\n   G. Management\n   1. What information should be measured/maintained\
    \ by the control\n      plane at each network element pertaining to restoration\
    \ events?\n   2. What are the requirements for the correlation between control\n\
    \      plane and data plane failures from the restoration point of view?\n"
- title: Editors' Addresses
  contents:
  - "Editors' Addresses\n   Wai Sum Lai\n   AT&T\n   200 Laurel Avenue\n   Middletown,\
    \ NJ 07748, USA\n   Phone: +1 732-420-3712\n   EMail: wlai@att.com\n   Dave McDysan\n\
    \   WorldCom\n   22001 Loudoun County Pkwy\n   Ashburn, VA 20147, USA\n   EMail:\
    \ dave.mcdysan@wcom.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2002).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
