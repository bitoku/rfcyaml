- title: __initial_text__
  contents:
  - "               Determining Strengths For Public Keys Used\n                 \
    \    For Exchanging Symmetric Keys\n"
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This document specifies an Internet Best Current Practices\
    \ for the\n   Internet Community, and requests discussion and suggestions for\n\
    \   improvements.  Distribution of this memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2004).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   Implementors of systems that use public key cryptography to exchange\n\
    \   symmetric keys need to make the public keys resistant to some\n   predetermined\
    \ level of attack.  That level of attack resistance is\n   the strength of the\
    \ system, and the symmetric keys that are exchanged\n   must be at least as strong\
    \ as the system strength requirements.  The\n   three quantities, system strength,\
    \ symmetric key strength, and public\n   key strength, must be consistently matched\
    \ for any network protocol\n   usage.\n   While it is fairly easy to express the\
    \ system strength requirements\n   in terms of a symmetric key length and to choose\
    \ a cipher that has a\n   key length equal to or exceeding that requirement, it\
    \ is harder to\n   choose a public key that has a cryptographic strength meeting\
    \ a\n   symmetric key strength requirement.  This document explains how to\n \
    \  determine the length of an asymmetric key as a function of a\n   symmetric\
    \ key strength requirement.  Some rules of thumb for\n   estimating equivalent\
    \ resistance to large-scale attacks on various\n   algorithms are given.  The\
    \ document also addresses how changing the\n   sizes of the underlying large integers\
    \ (moduli, group sizes,\n   exponents, and so on) changes the time to use the\
    \ algorithms for key\n   exchange.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Model of Protecting Symmetric Keys with Public Keys.\
    \ . . . . .  2\n       1.1. The key exchange algorithms . . . . . . . . . . .\
    \ . . . .  4\n   2.  Determining the Effort to Factor . . . . . . . . . . . .\
    \ . . .  5\n       2.1. Choosing parameters for the equation. . . . . . . . .\
    \ . .  6\n       2.2. Choosing k from empirical reports . . . . . . . . . . .\
    \ .  7\n       2.3. Pollard's rho method. . . . . . . . . . . . . . . . . . .\
    \  7\n       2.4. Limits of large memory and many machines. . . . . . . . .  8\n\
    \       2.5. Special purpose machines. . . . . . . . . . . . . . . . .  9\n  \
    \ 3.  Compute Time for the Algorithms. . . . . . . . . . . . . . . . 10\n    \
    \   3.1. Diffie-Hellman Key Exchange . . . . . . . . . . . . . . . 10\n      \
    \      3.1.1. Diffie-Hellman with elliptic curve groups. . . . . 11\n       3.2.\
    \ RSA encryption and decryption . . . . . . . . . . . . . . 11\n       3.3. Real-world\
    \ examples . . . . . . . . . . . . . . . . . . . 12\n   4.  Equivalences of Key\
    \ Sizes. . . . . . . . . . . . . . . . . . . 13\n       4.1. Key equivalence against\
    \ special purpose brute force\n            hardware. . . . . . . . . . . . . .\
    \ . . . . . . . . . . . 15\n       4.2. Key equivalence against conventional CPU\
    \ brute force\n            attack. . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . 15\n       4.3. A One Year Attack: 80 bits of strength. . . . . . . .\
    \ . . 16\n       4.4. Key equivalence for other ciphers . . . . . . . . . . .\
    \ . 16\n       4.5. Hash functions for deriving symmetric keys from public\n \
    \           key algorithms. . . . . . . . . . . . . . . . . . . . . . 17\n   \
    \    4.6. Importance of randomness. . . . . . . . . . . . . . . . . 19\n   5.\
    \  Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n       5.1.\
    \ TWIRL Correction. . . . . . . . . . . . . . . . . . . . . 20\n   6.  Security\
    \ Considerations. . . . . . . . . . . . . . . . . . . . 20\n   7.  References\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n       7.1. Informational\
    \ References. . . . . . . . . . . . . . . . . 20\n   8.  Authors' Addresses .\
    \ . . . . . . . . . . . . . . . . . . . . . 22\n   9.  Full Copyright Statement\
    \ . . . . . . . . . . . . . . . . . . . 23\n"
- title: 1.  Model of Protecting Symmetric Keys with Public Keys
  contents:
  - "1.  Model of Protecting Symmetric Keys with Public Keys\n   Many books on cryptography\
    \ and security explain the need to exchange\n   symmetric keys in public as well\
    \ as the many algorithms that are used\n   for this purpose.  However, few of\
    \ these discussions explain how the\n   strengths of the public keys and the symmetric\
    \ keys are related.\n   To understand this, picture a house with a strong lock\
    \ on the front\n   door.  Next to the front door is a small lockbox that contains\
    \ the\n   key to the front door.  A would-be burglar who wants to break into\n\
    \   the house through the front door has two options: attack the lock on\n   the\
    \ front door, or attack the lock on the lockbox in order to\n   retrieve the key.\
    \  Clearly, the burglar is better off attacking the\n   weaker of the two locks.\
    \  The homeowner in this situation must make\n   sure that adding the second entry\
    \ option (the lockbox containing the\n   front door key) is at least as strong\
    \ as the lock on the front door,\n   in order not to make the burglar's job easier.\n\
    \   An implementor designing a system for exchanging symmetric keys using\n  \
    \ public key cryptography must make a similar decision.  Assume that an\n   attacker\
    \ wants to learn the contents of a message that is encrypted\n   with a symmetric\
    \ key, and that the symmetric key was exchanged\n   between the sender and recipient\
    \ using public key cryptography.  The\n   attacker has two options to recover\
    \ the message: a brute-force\n   attempt to determine the symmetric key by repeated\
    \ guessing, or\n   mathematical determination of the private key used as the key\n\
    \   exchange key.  A smart attacker will work on the easier of these two\n   problems.\n\
    \   A simple-minded answer to the implementor's problem is to be sure\n   that\
    \ the key exchange system is always significantly stronger than\n   the symmetric\
    \ key; this can be done by choosing a very long public\n   key.  Such a design\
    \ is usually not a good idea because the key\n   exchanges become much more expensive\
    \ in terms of processing time as\n   the length of the public keys go up.  Thus,\
    \ the implementor is faced\n   with the task of trying to match the difficulty\
    \ of an attack on the\n   symmetric key with the difficulty of an attack on the\
    \ public key\n   encryption.  This analysis is not necessary if the key exchange\
    \ can\n   be performed with extreme security for almost no cost in terms of\n\
    \   elapsed time or CPU effort; unfortunately, this is not the case for\n   public\
    \ key methods today.\n   A third consideration is the minimum security requirement\
    \ of the\n   user.  Assume the user is encrypting with CAST-128 and requires a\n\
    \   symmetric key with a resistance time against brute-force attack of 20\n  \
    \ years.  He might start off by choosing a key with 86 random bits, and\n   then\
    \ use a one-way function such as SHA-1 to \"boost\" that to a block\n   of 160\
    \ bits, and then take 128 of those bits as the key for CAST-128.\n   In such a\
    \ case, the key exchange algorithm need only match the\n   difficulty of 86 bits,\
    \ not 128 bits.\n   The selection procedure is:\n   1. Determine the attack resistance\
    \ necessary to satisfy the security\n      requirements of the application.  Do\
    \ this by estimating the\n      minimum number of computer operations that the\
    \ attacker will be\n      forced to do in order to compromise the security of\
    \ the system and\n      then take the logarithm base two of that number.  Call\
    \ that\n      logarithm value \"n\".\n      A 1996 report recommended 90 bits\
    \ as a good all-around choice for\n      system security.  The 90 bit number should\
    \ be increased by about\n      2/3 bit/year, or about 96 bits in 2005.\n   2.\
    \ Choose a symmetric cipher that has a key with at least n bits and\n      at\
    \ least that much cryptanalytic strength.\n   3. Choose a key exchange algorithm\
    \ with a resistance to attack of at\n      least n bits.\n   A fourth consideration\
    \ might be the public key authentication method\n   used to establish the identity\
    \ of a user.  This might be an RSA\n   digital signature or a DSA digital signature.\
    \  If the modulus for the\n   authentication method isn't large enough, then the\
    \ entire basis for\n   trusting the communication might fall apart.  The following\
    \ step is\n   thus added:\n   4. Choose an authentication algorithm with a resistance\
    \ to attack of\n      at least n bits.  This ensures that a similar key exchanged\
    \ cannot\n      be forged between the two parties during the secrecy lifetime\
    \ of\n      the encrypted material.  This may not be strictly necessary if the\n\
    \      authentication keys are changed frequently and they have a well-\n    \
    \  understood usage lifetime, but in lieu of this, the n bit guidance\n      is\
    \ sound.\n"
- title: 1.1.  The key exchange algorithms
  contents:
  - "1.1.  The key exchange algorithms\n   The Diffie-Hellman method uses a group,\
    \ a generator, and exponents.\n   In today's Internet standards, the group operation\
    \ is based on\n   modular multiplication.  Here, the group is defined by the\n\
    \   multiplicative group of an integer, typically a prime p = 2q + 1,\n   where\
    \ q is a prime, and the arithmetic is done modulo p; the\n   generator (which\
    \ is often simply 2) is denoted by g.\n   In Diffie-Hellman, Alice and Bob first\
    \ agree (in public or in\n   private) on the values for g and p.  Alice chooses\
    \ a secret large\n   random integer (a), and Bob chooses a secret random large\
    \ integer\n   (b).  Alice sends Bob A, which is g^a mod p; Bob sends Alice B,\
    \ which\n   is g^b mod p.  Next, Alice computes B^a mod p, and Bob computes A^b\n\
    \   mod p.  These two numbers are equal, and the participants use a\n   simple\
    \ function of this number as the symmetric key k.\n   Note that Diffie-Hellman\
    \ key exchange can be done over different\n   kinds of group representations.\
    \  For instance, elliptic curves\n   defined over finite fields are a particularly\
    \ efficient way to\n   compute the key exchange [SCH95].\n   For RSA key exchange,\
    \ assume that Bob has a public key (m) which is\n   equal to p*q, where p and\
    \ q are two secret prime numbers, and an\n   encryption exponent e, and a decryption\
    \ exponent d.  For the key\n   exchange, Alice sends Bob E = k^e mod m, where\
    \ k is the secret\n   symmetric key being exchanged.  Bob recovers k by computing\
    \ E^d mod\n   m, and the two parties use k as their symmetric key.  While Bob's\n\
    \   encryption exponent e can be quite small (e.g., 17 bits), his\n   decryption\
    \ exponent d will have as many bits in it as m does.\n"
- title: 2.  Determining the Effort to Factor
  contents:
  - "2.  Determining the Effort to Factor\n   The RSA public key encryption method\
    \ is immune to brute force\n   guessing attacks because the modulus (and thus,\
    \ the secret exponent\n   d) will have at least 512 bits, and that is too many\
    \ possibilities to\n   guess.  The Diffie-Hellman exchange is also secure against\
    \ guessing\n   because the exponents will have at least twice as many bits as\
    \ the\n   symmetric keys that will be derived from them.  However, both methods\n\
    \   are susceptible to mathematical attacks that determine the structure\n   of\
    \ the public keys.\n   Factoring an RSA modulus will result in complete compromise\
    \ of the\n   security of the private key.  Solving the discrete logarithm problem\n\
    \   for a Diffie-Hellman modular exponentiation system will similarly\n   destroy\
    \ the security of all key exchanges using the particular\n   modulus.  This document\
    \ assumes that the difficulty of solving the\n   discrete logarithm problem is\
    \ equivalent to the difficulty of\n   factoring numbers that are the same size\
    \ as the modulus.  In fact, it\n   is slightly harder because it requires more\
    \ operations; based on\n   empirical evidence so far, the ratio of difficulty\
    \ is at least 20,\n   possibly as high as 64.  Solving either problem requires\
    \ a great deal\n   of memory for the last stage of the algorithm, the matrix reduction\n\
    \   step.  Whether or not this memory requirement will continue to be the\n  \
    \ limiting factor in solving larger integer problems remains to be\n   seen. \
    \ At the current time it is not, and there is active research\n   into parallel\
    \ matrix algorithms that might mitigate the memory\n   requirements for this problem.\n\
    \   The number field sieve (NFS) [GOR93] [LEN93] is the best method today\n  \
    \ for solving the discrete logarithm problem.  The formula for\n   estimating\
    \ the number of simple arithmetic operations needed to\n   factor an integer,\
    \ n, using the NFS method is:\n      L(n) = k * e^((1.92 + o(1)) * cubrt(ln(n)\
    \ * (ln(ln(n)))^2))\n   Many people prefer to discuss the number of MIPS years\
    \ (MYs) that are\n   needed for large operations such as the number field sieve.\
    \  For such\n   an estimation, an operation in the L(n) formula is one computer\n\
    \   instruction.  Empirical evidence indicates that 4 or 5 instructions\n   might\
    \ be a closer match, but this is a minor factor and this document\n   sticks with\
    \ one operation/one instruction for this discussion.\n"
- title: 2.1.  Choosing parameters for the equation
  contents:
  - "2.1.  Choosing parameters for the equation\n   The expression above has two parameters\
    \ that can be estimated by\n   empirical means: k and o(1).  For the range of\
    \ numbers we are\n   interested in, there is little distinction between them.\n\
    \   One could assume that k is 1 and o(1) is 0.  This is reasonably valid\n  \
    \ if the expression is only used for estimating relative effort\n   (instead of\
    \ actual effort) and one assumes that the o(1) term is very\n   small over the\
    \ range of the numbers that are to be factored.\n   Or, one could assume that\
    \ o(1) is small and roughly constant and thus\n   its value can be folded into\
    \ k; then estimate k from reported amounts\n   of effort spent factoring large\
    \ integers in tests.\n   This document uses the second approach in order to get\
    \ an estimate of\n   the significance of the factor.  It appears to be minor,\
    \ based on the\n   following calculations.\n   Sample values from recent work\
    \ with the number field sieve include:\n      Test name   Number of   Number of\
    \   MYs of effort\n                    decimal      bits\n                   \
    \ digits\n      RSA130         130         430            500\n      RSA140  \
    \       140         460           2000\n      RSA155         155         512 \
    \          8000\n      RSA160         160         528           3000\n   There\
    \ are few precise measurements of the amount of time used for\n   these factorizations.\
    \  In most factorization tests, hundreds or\n   thousands of computers are used\
    \ over a period of several months, but\n   the number of their cycles were used\
    \ for the factoring project, the\n   precise distribution of processor types,\
    \ speeds, and so on are not\n   usually reported.  However, in all the above cases,\
    \ the amount of\n   effort used was far less than the L(n) formula would predict\
    \ if k was\n   1 and o(1) was 0.\n   A similar estimate of effort, done in 1995,\
    \ is in [ODL95].\n   Results indicating that for the Number Field Sieve factoring\
    \ method,\n   the actual number of operations is less than expected, are found\
    \ in\n   [DL].\n"
- title: 2.2.  Choosing k from empirical reports
  contents:
  - "2.2.  Choosing k from empirical reports\n   By solving for k from the empirical\
    \ reports, it appears that k is\n   approximately 0.02.  This means that the \"\
    effective key strength\" of\n   the RSA algorithm is about 5 or 6 bits less than\
    \ is implied by the\n   naive application of equation L(n) (that is, setting k\
    \ to 1 and o(1)\n   to 0). These estimates of k are fairly stable over the numbers\n\
    \   reported in the table.  The estimate is limited to a single\n   significant\
    \ digit of k because it expresses real uncertainties;\n   however, the effect\
    \ of additional digits would have make only tiny\n   changes to the recommended\
    \ key sizes.\n   The factorers of RSA130 used about 1700 MYs, but they felt that\
    \ this\n   was unrealistically high for prediction purposes; by using more\n \
    \  memory on their machines, they could have easily reduced the time to\n   500\
    \ MYs.  Thus, the value used in preparing the table above was 500.\n   This story\
    \ does, however, underscore the difficulty in getting an\n   accurate measure\
    \ of effort.  This document takes the reported effort\n   for factoring RSA155\
    \ as being the most accurate measure.\n   As a result of examining the empirical\
    \ data, it appears that the L(n)\n   formula can be used with the o(1) term set\
    \ to 0 and with k set to\n   0.02 when talking about factoring numbers in the\
    \ range of 100 to 200\n   decimal digits.  The equation becomes:\n      L(n) =\
    \  0.02 * e^(1.92 * cubrt(ln(n) * (ln(ln(n)))^2))\n   To convert L(n) from simple\
    \ math instructions to MYs, divide by\n   3*10^13.  The equation for the number\
    \ of MYs needed to factor an\n   integer n then reduces to:\n      MYs = 6 * 10^(-16)\
    \ * e^(1.92 * cubrt(ln(n) * (ln(ln(n)))^2))\n   With what confidence can this\
    \ formula be used for predicting the\n   difficulty of factoring slightly larger\
    \ numbers?  The answer is that\n   it should be a close upper bound, but each\
    \ factorization effort is\n   usually marked by some improvement in the algorithms\
    \ or their\n   implementations that makes the running time somewhat shorter than\
    \ the\n   formula would indicate.\n"
- title: 2.3.  Pollard's rho method
  contents:
  - "2.3.  Pollard's rho method\n   In Diffie-Hellman exchanges, there is a second\
    \ attack, Pollard's rho\n   method [POL78].  The algorithm relies on finding collisions\
    \ between\n   values computed in a large number space; its success rate is\n \
    \  proportional to the square root of the size of the space.  Because of\n   Pollard's\
    \ rho method, the search space in a DH key exchange for the\n   key (the exponent\
    \ in a g^a term), must be twice as large as the\n   symmetric key.  Therefore,\
    \ to securely derive a key of K bits, an\n   implementation must use an exponent\
    \ with at least 2*K bits.  See\n   [ODL99] for more detail.\n   When the Diffie-Hellman\
    \ key exchange is done using an elliptic curve\n   method, the NFS methods are\
    \ of no avail.  However, the collision\n   method is still effective, and the\
    \ need for an exponent (called a\n   multiplier in EC's) with 2*K bits remains.\
    \  The modulus used for the\n   computation can also be 2*K bits, and this will\
    \ be substantially\n   smaller than the modulus needed for modular exponentiation\
    \ methods as\n   the desired security level increases past 64 bits of brute-force\n\
    \   attack resistance.\n   One might ask, how can you compare the number of computer\n\
    \   instructions really needed for a discrete logarithm attack to the\n   number\
    \ needed to search the keyspace of a cipher? In comparing the\n   efforts, one\
    \ should consider what a \"basic operation\" is.  For brute\n   force search of\
    \ the keyspace of a symmetric encryption algorithm like\n   DES, the basic operation\
    \ is the time to do a key setup and the time\n   to do one encryption.  For discrete\
    \ logs, the basic operation is a\n   modular squaring.  The log of the ratio of\
    \ these two operations can\n   be used as a \"normalizing factor\" between the\
    \ two kinds of\n   computations.  However, even for very large moduli (16K bits),\
    \ this\n   factor amounts to only a few bits of extra effort.\n"
- title: 2.4.  Limits of large memory and many machines
  contents:
  - "2.4.  Limits of large memory and many machines\n   Robert Silverman has examined\
    \ the question of when it will be\n   practical to factor RSA moduli larger than\
    \ 512 bits.  His analysis is\n   based not only on the theoretical number of operations,\
    \ but it also\n   includes expectations about the availability of actual machines\
    \ for\n   performing the work (this document is based only on theoretical\n  \
    \ number of operations).  He examines the question of whether or not we\n   can\
    \ expect there be enough machines, memory, and communication to\n   factor a very\
    \ large number.\n   The best factoring methods need a lot of random access memory\
    \ for\n   collecting data relations (sieving) and a critical final step that\n\
    \   does a row reduction on a large matrix.  The memory requirements are\n   related\
    \ to the size of the number being factored (or subjected to\n   discrete logarithm\
    \ solution).  Silverman [SILIEEE99] [SIL00] has\n   argued that there is a practical\
    \ limit to the number of machines and\n   the amount of RAM that can be brought\
    \ to bear on a single problem in\n   the foreseeable future.  He sees two problems\
    \ in attacking a 1024-bit\n   RSA modulus: the machines doing the sieving will\
    \ need 64-bit address\n   spaces and the matrix row reduction machine will need\
    \ several\n   terabytes of memory. Silverman notes that very few 64-bit machines\n\
    \   that have the 170 gigabytes of memory needed for sieving have been\n   sold.\
    \  Nearly a billion such machines are necessary for the sieving\n   in a reasonable\
    \ amount of time (a year or two).\n   Silverman's conclusion, based on the history\
    \ of factoring efforts and\n   Moore's Law, is that 1024-bit RSA moduli will not\
    \ be factored until\n   about 2037.  This implies a much longer lifetime to RSA\
    \ keys than the\n   theoretical analysis indicates.  He argues that predictions\
    \ about how\n   many machines and memory modules will be available can be with\
    \ great\n   confidence, based on Moore's Law extrapolations and the recent\n \
    \  history of factoring efforts.\n   One should give the practical considerations\
    \ a great deal of weight,\n   but in a risk analysis, the physical world is less\
    \ predictable than\n   trend graphs would indicate.  In considering how much trust\
    \ to put\n   into the inability of the computer industry to satisfy the voracious\n\
    \   needs of factorers, one must have some insight into economic\n   considerations\
    \ that are more complicated than the mathematics of\n   factoring.  The demand\
    \ for computer memory is hard to predict because\n   it is based on applications:\
    \  a \"killer app\" might come along any day\n   and send the memory industry\
    \ into a frenzy of sales.  The number of\n   processors available on desktops\
    \ may be limited by the number of\n   desks, but very capable embedded systems\
    \ account for more processor\n   sales than desktops.  As embedded systems absorb\
    \ networking\n   functions, it is not unimaginable that millions of 64-bit processors\n\
    \   with at least gigabytes of memory will pervade our environment.\n   The bottom\
    \ line on this is that the key length recommendations\n   predicted by theory\
    \ may be overly conservative, but they are what we\n   have used for this document.\
    \  This question of machine availability\n   is one that should be reconsidered\
    \ in light of current technology on\n   a regular basis.\n"
- title: 2.5.  Special purpose machines
  contents:
  - "2.5.  Special purpose machines\n   In August of 2003, a design for a special-purpose\
    \ \"sieving machine\"\n   (TWIRL) surfaced [Shamir2003], and it substantially\
    \ changed the cost\n   estimates for factoring numbers up to 1024 bits in size.\
    \  By applying\n   many high-speed VLSI components in parallel, such a machine\
    \ might be\n   able to carry out the sieving of 512-bit numbers in 10 minutes\
    \ at a\n   cost of $10K for the hardware.  A larger version could sieve a 1024-\n\
    \   bit number in one year for a cost of $10M.  The work cites some\n   advances\
    \ in approaches to the row reduction step in concluding that\n   the security\
    \ of 1024-bit RSA moduli is doubtful.\n   The estimates for the time and cost\
    \ for factoring 512-bit and 1024-\n   bit numbers correspond to a speed-up factor\
    \ of about 2 million over\n   what can be achieved with commodity processors of\
    \ a few years ago.\n"
- title: 3.  Compute Time for the Algorithms
  contents:
  - "3.  Compute Time for the Algorithms\n   This section describes how long it takes\
    \ to use the algorithms to\n   perform key exchanges.  Again, it is important\
    \ to consider the\n   increased time it takes to exchange symmetric keys when\
    \ increasing\n   the length of public keys.  It is important to avoid choosing\n\
    \   unfeasibly long public keys.\n"
- title: 3.1.  Diffie-Hellman Key Exchange
  contents:
  - "3.1.  Diffie-Hellman Key Exchange\n   A Diffie-Hellman key exchange is done with\
    \ a finite cyclic group G\n   with a generator g and an exponent x.  As noted\
    \ in the Pollard's rho\n   method section, the exponent has twice as many bits\
    \ as are needed for\n   the final key.  Let the size of the group G be p, let\
    \ the number of\n   bits in the base 2 representation of p be j, and let the number\
    \ of\n   bits in the exponent be K.\n   In doing the operations that result in\
    \ a shared key, a generator is\n   raised to a power.  The most efficient way\
    \ to do this involves\n   squaring a number K times and multiplying it several\
    \ times along the\n   way.  Each of the numbers has j/w computer words in it,\
    \ where w is\n   the number of bits in a computer word (today that will be 32\
    \ or 64\n   bits).  A naive assumption is that you will need to do j squarings\n\
    \   and j/2 multiplies; fortunately, an efficient implementation will\n   need\
    \ fewer (NB: for the remainder of this section, n represents j/w).\n   A squaring\
    \ operation does not need to use quite as many operations as\n   a multiplication;\
    \ a reasonable estimate is that squaring takes .6 the\n   number of machine instructions\
    \ of a multiply.  If one prepares a\n   table ahead of time with several values\
    \ of small integer powers of\n   the generator g, then only about one fifth as\
    \ many multiplies are\n   needed as the naive formula suggests.  Therefore, one\
    \ needs to do the\n   work of approximately .8*K multiplies of n-by-n word numbers.\n\
    \   Further, each multiply and squaring must be followed by a modular\n   reduction,\
    \ and a good assumption is that it is as hard to do a\n   modular reduction as\
    \ it is to do an n-by-n word multiply.  Thus, it\n   takes K reductions for the\
    \ squarings and .2*K reductions for the\n   multiplies.  Summing this, the total\
    \ effort for a Diffie-Hellman key\n   exchange with K bit exponents and a modulus\
    \ of n words is\n   approximately 2*K n-by-n-word multiplies.\n   For 32-bit processors,\
    \ integers that use less than about 30 computer\n   words in their representation\
    \ require at least n^2 instructions for\n   an n-by-n-word multiply.  Larger numbers\
    \ will use less time, using\n   Karatsuba multiplications, and they will scale\
    \ as about n^(1.58) for\n   larger n, but that is ignored for the current discussion.\
    \  Note that\n   64-bit processors push the \"Karatsuba cross-over\" number out\
    \ to even\n   more bits.\n   The basic result is: if you double the size of the\
    \ Diffie-Hellman\n   modular exponentiation group, you quadruple the number of\
    \ operations\n   needed for the computation.\n"
- title: 3.1.1.  Diffie-Hellman with elliptic curve groups
  contents:
  - "3.1.1.  Diffie-Hellman with elliptic curve groups\n   Note that the ratios for\
    \ computation effort as a function of modulus\n   size hold even if you are using\
    \ an elliptic curve (EC) group for\n   Diffie-Hellman.  However, for equivalent\
    \ security, one can use\n   smaller numbers in the case of elliptic curves.  Assume\
    \ that someone\n   has chosen an modular exponentiation group with an 2048 bit\
    \ modulus\n   as being an appropriate security measure for a Diffie-Hellman\n\
    \   application and wants to determine what advantage there would be to\n   using\
    \ an EC group instead.  The calculation is relatively\n   straightforward, if\
    \ you assume that on the average, it is about 20\n   times more effort to do a\
    \ squaring or multiplication in an EC group\n   than in a modular exponentiation\
    \ group.  A rough estimate is that an\n   EC group with equivalent security has\
    \ about 200 bits in its\n   representation.  Then, assuming that the time is dominated\
    \ by n-by-n-\n   word operations, the relative time is computed as:\n      ((2048/200)^2)/20\
    \ ~= 5\n   showing that an elliptic curve implementation should be five times\
    \ as\n   fast as a modular exponentiation implementation.\n"
- title: 3.2.  RSA encryption and decryption
  contents:
  - "3.2.  RSA encryption and decryption\n   Assume that an RSA public key uses a\
    \ modulus with j bits; its factors\n   are two numbers of about j/2 bits each.\
    \  The expected computation\n   time for encryption and decryption are different.\
    \  As before, we\n   denote the number of words in the machine representation\
    \ of the\n   modulus by the symbol n.\n   Most implementations of RSA use a small\
    \ exponent for encryption.  An\n   encryption may involve as few as 16 squarings\
    \ and one multiplication,\n   using n-by-n-word operations.  Each operation must\
    \ be followed by a\n   modular reduction, and therefore the time complexity is\
    \ about 16*(.6\n   + 1) + 1 + 1 ~= 28 n-by-n-word multiplies.\n   RSA decryption\
    \ must use an exponent that has as many bits as the\n   modulus, j.  However,\
    \ the Chinese Remainder Theorem applies, and all\n   the computations can be done\
    \ with a modulus of only n/2 words and an\n   exponent of only j/2 bits.  The\
    \ computation must be done twice, once\n   for each factor.  The effort is equivalent\
    \ to  2*(j/2) (n/2 by n/2)-\n   word multiplies.  Because multiplying numbers\
    \ with n/2 words is only\n   1/4 as difficult as multiplying numbers with n words,\
    \ the equivalent\n   effort for RSA decryption is j/4 n-by-n-word multiplies.\n\
    \   If you double the size of the modulus for RSA, the n-by-n multiplies\n   will\
    \ take four times as long.  Further, the decryption time doubles\n   because the\
    \ exponent is larger.  The overall scaling cost is a factor\n   of 4 for encryption,\
    \ a factor of 8 for decryption.\n"
- title: 3.3.  Real-world examples
  contents:
  - "3.3.  Real-world examples\n   To make these numbers more real, here are a few\
    \ examples of software\n   implementations run on hardware that was current as\
    \ of a few years\n   before the publication of this document.  The examples are\
    \ included\n   to show rough estimates of reasonable implementations; they are\
    \ not\n   benchmarks.  As with all software, the performance will depend on the\n\
    \   exact details of specialization of the code to the problem and the\n   specific\
    \ hardware.\n   The best time informally reported for a 1024-bit modular\n   exponentiation\
    \ (the decryption side of 2048-bit RSA), is 0.9 ms\n   (about 450,000 CPU cycles)\
    \ on a 500 MHz Itanium processor.  This\n   shows that newer processors are not\
    \ losing ground on big number\n   operations; the number of instructions is less\
    \ than a 32-bit\n   processor uses for a 256-bit modular exponentiation.\n   For\
    \ less advanced processors timing, the following two tables\n   (computed by Tero\
    \ Monenen at SSH Communications) for modular\n   exponentiation, such as would\
    \ be done in a Diffie-Hellman key\n   exchange.\n   Celeron 400 MHz; compiled\
    \ with GNU C compiler, optimized, some\n   platform specific coding optimizations:\n\
    \      group  modulus   exponent    time\n      type    size       size\n    \
    \   mod    768       ~150       18 msec\n       mod   1024       ~160       32\
    \ msec\n       mod   1536       ~180       82 msec\n       ecn    155       ~150\
    \       35 msec\n       ecn    185       ~200       56 msec\n   The group type\
    \ is from [RFC2409] and is either modular exponentiation\n   (\"mod\") or elliptic\
    \ curve (\"ecn\").  All sizes here and in subsequent\n   tables are in bits.\n\
    \   Alpha 500 MHz compiled with Digital's C compiler, optimized, no\n   platform\
    \ specific code:\n      group  modulus    exponent       time\n      type    size\
    \       size\n       mod    768       ~150          12 msec\n       mod   1024\
    \       ~160          24 msec\n       mod   1536       ~180          59 msec\n\
    \       ecn    155       ~150          20 msec\n       ecn    185       ~200 \
    \         27 msec\n   The following two tables (computed by Eric Young) were originally\
    \ for\n   RSA signing operations, using the Chinese Remainder representation.\n\
    \   For ease of understanding, the parameters are presented here to show\n   the\
    \ interior calculations, i.e., the size of the modulus and exponent\n   used by\
    \ the software.\n   Dual Pentium II-350:\n       equiv      equiv         equiv\n\
    \      modulus    exponent       time\n       size        size\n        256  \
    \      256         1.5 ms\n        512        512         8.6 ms\n       1024\
    \       1024        55.4 ms\n       2048       2048       387   ms\n   Alpha 264\
    \ 600mhz:\n       equiv       equiv        equiv\n      modulus     exponent \
    \     time\n       size        size\n       512         512         1.4 ms\n \
    \  Recent chips that accelerate exponentiation can perform 1024-bit\n   exponentiations\
    \ (1024 bit modulus, 1024 bit exponent) in about 3\n   milliseconds or less.\n"
- title: 4.  Equivalences of Key Sizes
  contents:
  - "4.  Equivalences of Key Sizes\n   In order to determine how strong a public key\
    \ is needed to protect a\n   particular symmetric key, you first need to determine\
    \ how much effort\n   is needed to break the symmetric key.  Many Internet security\n\
    \   protocols require the use of TripleDES for strong symmetric\n   encryption,\
    \ and it is expected that the Advanced Encryption Standard\n   (AES) will be adopted\
    \ on the Internet in the coming years.\n   Therefore, these two algorithms are\
    \ discussed here.  In this section,\n   for illustrative purposes, we will implicitly\
    \ assume that the system\n   security requirement is 112 bits; this doesn't mean\
    \ that 112 bits is\n   recommended.  In fact, 112 bits is arguably too strong\
    \ for any\n   practical purpose.  It is used for illustration simply because that\n\
    \   is the upper bound on the strength of TripleDES.\n   If one could simply determine\
    \ the number of MYs it takes to break\n   TripleDES, the task of computing the\
    \ public key size of equivalent\n   strength would be easy.  Unfortunately, that\
    \ isn't the case here\n   because there are many examples of DES-specific hardware\
    \ that encrypt\n   faster than DES in software on a standard CPU.  Instead, one\
    \ must\n   determine the equivalent cost for a system to break TripleDES and a\n\
    \   system to break the public key protecting a TripleDES key.\n   In 1998, the\
    \ Electronic Frontier Foundation (EFF) built a DES-\n   cracking machine [GIL98]\
    \ for US$130,000 that could test about 1e11\n   DES keys per second (additional\
    \ money was spent on the machine's\n   design).  The machine's builders fully\
    \ admit that the machine is not\n   well optimized, and it is estimated that ten\
    \ times the amount of\n   money could probably create a machine about 50 times\
    \ as fast.\n   Assuming more optimization by guessing that a system to test\n\
    \   TripleDES keys runs about as fast as a system to test DES keys, so\n   approximately\
    \ US$1 million might test 5e12 TripleDES keys per second.\n   In case your adversaries\
    \ are much richer than EFF, you may want to\n   assume that they have US$1 trillion,\
    \ enough to test 5e18 keys per\n   second.  An exhaustive search of the effective\
    \ TripleDES space of\n   2^112 keys with this quite expensive system would take\
    \ about 1e15\n   seconds or about 33 million years.  (Note that such a system\
    \ would\n   also need 2^60 bytes of RAM [MH81], which is considered free in this\n\
    \   calculation).  This seems a needlessly conservative value.  However,\n   if\
    \ computer logic speeds continue to increase in accordance with\n   Moore's Law\
    \ (doubling in speed every 1.5 years), then one might\n   expect that in about\
    \ 50 years, the computation could be completed in\n   only one year.  For the\
    \ purposes of illustration, this 50 year\n   resistance against a trillionaire\
    \ is assumed to be the minimum\n   security requirement for a set of applications.\n\
    \   If 112 bits of attack resistance is the system security requirement,\n   then\
    \ the key exchange system for TripleDES should have equivalent\n   difficulty;\
    \ that is to say, if the attacker has US$1 trillion, you\n   want him to spend\
    \ all his money to buy hardware today and to know\n   that he will \"crack\" the\
    \ key exchange in not less than 33 million\n   years.  (Obviously, a rational\
    \ attacker would wait for about 45 years\n   before actually spending the money,\
    \ because he could then get much\n   better hardware, but all attackers benefit\
    \ from this sort of wait\n   equally.)\n   It is estimated that a typical PC CPU\
    \ of just a few years ago can\n   generate over 500 MIPs and could be purchased\
    \ for about US$100 in\n   quantity; thus you get more than 5 MIPs/US$.  Again,\
    \ this number\n   doubles about every 18 months.  For one trillion US dollars,\
    \ an\n   attacker can get 5e12 MIP years of computer instructions on that\n  \
    \ recent-vintage hardware.  This figure is used in the following\n   estimates\
    \ of equivalent costs for breaking key exchange systems.\n"
- title: 4.1.  Key equivalence against special purpose brute force hardware
  contents:
  - "4.1.  Key equivalence against special purpose brute force hardware\n   If the\
    \ trillionaire attacker is to use conventional CPU's to \"crack\"\n   a key exchange\
    \ for a 112 bit key in the same time that the special\n   purpose machine is spending\
    \ on brute force search for the symmetric\n   key, the key exchange system must\
    \ use an appropriately large modulus.\n   Assume that the trillionaire performs\
    \ 5e12 MIPs of instructions per\n   year.  Use the following equation to estimate\
    \ the modulus size to use\n   with RSA encryption or DH key exchange:\n      5*10^33\
    \ = (6*10^-16)*e^(1.92*cubrt(ln(n)*(ln(ln(n)))^2))\n   Solving this approximately\
    \ for n yields:\n      n = 10^(625) = 2^(2077)\n   Thus, assuming similar logic\
    \ speeds and the current efficiency of the\n   number field sieve, moduli with\
    \ about 2100 bits will have about the\n   same resistance against attack as an\
    \ 112-bit TripleDES key.  This\n   indicates that RSA public key encryption should\
    \ use a modulus with\n   around 2100 bits; for a Diffie-Hellman key exchange,\
    \ one could use a\n   slightly smaller modulus, but it is not a significant difference.\n"
- title: 4.2 Key equivalence against conventional CPU brute force attack
  contents:
  - "4.2 Key equivalence against conventional CPU brute force attack\n   An alternative\
    \ way of estimating this assumes that the attacker has a\n   less challenging\
    \ requirement: he must only \"crack\" the key exchange\n   in less time than a\
    \ brute force key search against the symmetric key\n   would take with general\
    \ purpose computers.  This is an \"apples-to-\n   apples\" comparison, because\
    \ it assumes that the attacker needs only\n   to have computation donated to his\
    \ effort, not built from a personal\n   or national fortune.  The public key modulus\
    \ will be larger than the\n   one in 4.1, because the symmetric key is going to\
    \ be viable for a\n   longer period of time.\n   Assume that the number of CPU\
    \ instructions to encrypt a block of\n   material using TripleDES is 300.  The\
    \ estimated number of computer\n   instructions to break 112 bit TripleDES key:\n\
    \      300 * 2^112\n      = 1.6 * 10^(36)\n      = .02*e^(1.92*cubrt(ln(n)*(ln(ln(n)))^2))\n\
    \   Solving this approximately for n yields:\n      n = 10^(734) = 2^(2439)\n\
    \   Thus, for general purpose CPU attacks, you can assume that moduli\n   with\
    \ about 2400 bits will have about the same strength against attack\n   as an 112-bit\
    \ TripleDES key.  This indicates that RSA public key\n   encryption should use\
    \ a modulus with around 2400 bits; for a Diffie-\n   Hellman key exchange, one\
    \ could use a slightly smaller modulus, but\n   it not a significant difference.\n\
    \   Note that some authors assume that the algorithms underlying the\n   number\
    \ field sieve will continue to get better over time.  These\n   authors recommend\
    \ an even larger modulus, over 4000 bits, for\n   protecting a 112-bit symmetric\
    \ key for 50 years.  This points out the\n   difficulty of long-term cryptographic\
    \ security: it is all but\n   impossible to predict progress in mathematics and\
    \ physics over such a\n   long period of time.\n"
- title: '4.3.  A One Year Attack: 80 bits of strength'
  contents:
  - "4.3.  A One Year Attack: 80 bits of strength\n   Assuming a trillionaire spends\
    \ his money today to buy hardware, what\n   size key exchange numbers could he\
    \ \"crack\" in one year?  He can\n   perform 5*e12 MYs of instructions, or\n \
    \     3*10^13 * 5*10^12 = .02*e^(1.92*cubrt(ln(n)*(ln(ln(n)))^2))\n   Solving\
    \ for an approximation of n yields\n      n = 10^(360) = 2^(1195)\n   This is\
    \ about as many operations as it would take to crack an 80-bit\n   symmetric key\
    \ by brute force.\n   Thus, for protecting data that has a secrecy requirement\
    \ of one year\n   against an incredibly rich attacker, a key exchange modulus\
    \ with\n   about 1200 bits protecting an 80-bit symmetric key is safe even\n \
    \  against a nation's resources.\n"
- title: 4.4.  Key equivalence for other ciphers
  contents:
  - "4.4.  Key equivalence for other ciphers\n   Extending this logic to the AES is\
    \ straightforward.  For purposes of\n   estimation for key searching, one can\
    \ think of the 128-bit AES as\n   being at least 16 bits stronger than TripleDES\
    \ but about three times\n   as fast.  The time and cost for a brute force attack\
    \ is approximately\n   2^(16) more than for TripleDES, and thus, under the assumption\
    \ that\n   128 bits of strength is the desired security goal, the recommended\n\
    \   key exchange modulus size is about 700 bits longer.\n   If it is possible\
    \ to design hardware for AES cracking that is\n   considerably more efficient\
    \ than hardware for DES cracking, then\n   (again under the assumption that the\
    \ key exchange strength must match\n   the brute force effort) the moduli for\
    \ protecting the key exchange\n   can be made smaller.  However, the existence\
    \ of such designs is only\n   a matter of speculation at this early moment in\
    \ the AES lifetime.\n   The AES ciphers have key sizes of 128 bits up to 256 bits.\
    \  Should a\n   prudent minimum security requirement, and thus the key exchange\n\
    \   moduli, have similar strengths? The answer to this depends on whether\n  \
    \ or not one expect Moore's Law to continue unabated.  If it continues,\n   one\
    \ would expect 128 bit keys to be safe for about 60 years, and 256\n   bit keys\
    \ would be safe for another 400 years beyond that, far beyond\n   any imaginable\
    \ security requirement.  But such progress is difficult\n   to predict, as it\
    \ exceeds the physical capabilities of today's\n   devices and would imply the\
    \ existence of logic technologies that are\n   unknown or infeasible today.  Quantum\
    \ computing is a candidate, but\n   too little is known today to make confident\
    \ predictions about its\n   applicability to cryptography (which itself might\
    \ change over the\n   next 100 years!).\n   If Moore's Law does not continue to\
    \ hold, if no new computational\n   paradigms emerge, then keys of over 100 bits\
    \ in length might well be\n   safe \"forever\".  Note, however that others have\
    \ come up with\n   estimates based on assumptions of new computational paradigms\n\
    \   emerging.  For example, Lenstra and Verheul's web-based paper\n   \"Selecting\
    \ Cryptographic Key Sizes\" chooses a more conservative\n   analysis than the\
    \ one in this document.\n"
- title: 4.5.  Hash functions for deriving symmetric keys from public key
  contents:
  - "4.5.  Hash functions for deriving symmetric keys from public key\n      algorithms\n\
    \   The Diffie-Hellman algorithm results in a key that is hundreds or\n   thousands\
    \ of bits long, but ciphers need far fewer bits than that.\n   How can one distill\
    \ a long key down to a short one without losing\n   strength?\n   Cryptographic\
    \ one-way hash functions are the building blocks for\n   this, and so long as\
    \ they use all of the Diffie-Hellman key to derive\n   each block of the symmetric\
    \ key, they produce keys with sufficient\n   strength.\n   The usual recommendation\
    \ is to use a good one-way hash function\n   applied to he base material (the\
    \ result of the key exchange) and to\n   use a subset of the hash function output\
    \ for the key.  However, if\n   the desired key length is greater than the output\
    \ of the hash\n   function, one might wonder how to reconcile the two.\n   The\
    \ step of deriving extra key bits must satisfy these requirements:\n   -  The\
    \ bits must not reveal any information about the key exchange\n      secret\n\
    \   -  The bits must not be correlated with each other\n   -  The bits must depend\
    \ on all the bits of the key exchange secret\n   Any good cryptographic hash function\
    \ satisfies these three\n   requirements.  Note that the number of bits of output\
    \ of the hash\n   function is not specified.  That is because even a hash function\
    \ with\n   a very short output can be iterated to produce more uncorrelated bits\n\
    \   with just a little bit of care.\n   For example, SHA-1 has 160 bits of output.\
    \  For deriving a key of\n   attack resistance of 160 bits or less, SHA(DHkey)\
    \ produces a good\n   symmetric key.\n   Suppose one wants a key with attack resistance\
    \ of 160 bits, but it is\n   to be used with a cipher that uses 192 bit keys.\
    \  One can iterate\n   SHA-1 as follows:\n      Bits 1-160   of the symmetric\
    \ key = K1 = SHA(DHkey | 0x00)\n                   (that is, concatenate a single\
    \ octet of value 0x00 to\n                   the right side of the DHkey, and\
    \ then hash)\n      Bits 161-192 of the symmetric key = K2 =\n               \
    \    select_32_bits(SHA(K1 | 0x01))\n   But what if one wants 192 bits of strength\
    \ for the cipher?  Then the\n   appropriate calculation is\n      Bits 1-160 \
    \  of the symmetric key = SHA(0x00 | DHkey)\n      Bits 161-192 of the symmetric\
    \ key =\n                   select_32_bits(SHA(0x01 | DHkey))\n   (Note that in\
    \ the description above, instead of concatenating a full\n   octet, concatenating\
    \ a single bit would also be sufficient.)\n   The important distinction is that\
    \ in the second case, the DH key is\n   used for each part of the symmetric key.\
    \  This assures that entropy\n   of the DH key is not lost by iteration of the\
    \ hash function over the\n   same bits.\n   From an efficiency point of view,\
    \ if the symmetric key must have a\n   great deal of entropy, it is probably best\
    \ to use a cryptographic\n   hash function with a large output block (192 bits\
    \ or more), rather\n   than iterating a smaller one.\n   Newer hash algorithms\
    \ with longer output (such as SHA-256, SHA-384,\n   and SHA-512) can be used with\
    \ the same level of security as the\n   stretching algorithm described above.\n"
- title: 4.6.  Importance of randomness
  contents:
  - "4.6.  Importance of randomness\n   Some of the calculations described in this\
    \ document require random\n   inputs; for example, the secret Diffie-Hellman exponents\
    \ must be\n   chosen based on n truly random bits (where n is the system security\n\
    \   requirement).  The number of truly random bits is extremely important\n  \
    \ to determining the strength of the output of the calculations.  Using\n   truly\
    \ random numbers is often overlooked, and many security\n   applications have\
    \ been significantly weakened by using insufficient\n   random inputs.  A much\
    \ more complete description of the importance of\n   random numbers can be found\
    \ in [ECS].\n"
- title: 5.  Conclusion
  contents:
  - "5.  Conclusion\n   In this table it is assumed that attackers use general purpose\n\
    \   computers, that the hardware is purchased in the year 2000, and that\n   mathematical\
    \ knowledge relevant to the problem remains the same as\n   today.  This is an\
    \ pure \"apples-to-apples\" comparison demonstrating\n   how the time for a key\
    \ exchange scales with respect to the strength\n   requirement.  The subgroup\
    \ size for DSA is included, if that is being\n   used for supporting authentication\
    \ as part of the protocol; the DSA\n   modulus must be as long as the DH modulus,\
    \ but the size of the \"q\"\n   subgroup is also relevant.\n   +-------------+-----------+--------------+--------------+\n\
    \   | System      |           |              |              |\n   | requirement\
    \ | Symmetric | RSA or DH    | DSA subgroup |\n   | for attack  | key size  |\
    \ modulus size | size         |\n   | resistance  | (bits)    | (bits)       |\
    \ (bits)       |\n   | (bits)      |           |              |              |\n\
    \   +-------------+-----------+--------------+--------------+\n   |     70   \
    \   |     70    |      947     |     129      |\n   |     80      |     80   \
    \ |     1228     |     148      |\n   |     90      |     90    |     1553   \
    \  |     167      |\n   |    100      |    100    |     1926     |     186   \
    \   |\n   |    150      |    150    |     4575     |     284      |\n   |    200\
    \      |    200    |     8719     |     383      |\n   |    250      |    250\
    \    |    14596     |     482      |\n   +-------------+-----------+--------------+--------------+\n"
- title: 5.1.  TWIRL Correction
  contents:
  - "5.1.  TWIRL Correction\n   If the TWIRL machine becomes a reality, and if there\
    \ are advances in\n   parallelism for row reduction in factoring, then conservative\n\
    \   estimates would subtract about 11 bits from the system security\n   column\
    \ of the table.  Thus, in order to get 89 bits of security, one\n   would need\
    \ an RSA modulus of about 1900 bits.\n"
- title: 6.  Security Considerations
  contents:
  - "6.  Security Considerations\n   The equations and values given in this document\
    \ are meant to be as\n   accurate as possible, based on the state of the art in\
    \ general\n   purpose computers at the time that this document is being written.\n\
    \   No predictions can be completely accurate, and the formulas given\n   here\
    \ are not meant to be definitive statements of fact about\n   cryptographic strengths.\
    \  For example, some of the empirical results\n   used in calibrating the formulas\
    \ in this document are probably not\n   completely accurate, and this inaccuracy\
    \ affects the estimates.  It\n   is the authors' hope that the numbers presented\
    \ here vary from real\n   world experience as little as possible.\n"
- title: 7.  References
  contents:
  - '7.  References

    '
- title: 7.1.  Informational References
  contents:
  - "7.1.  Informational References\n   [DL]        Dodson, B. and A. K. Lenstra,\
    \ NFS with four large primes:\n               an explosive experiment, Proceedings\
    \ Crypto 95, Lecture\n               Notes in Comput. Sci. 963, (1995) 372-385.\n\
    \   [ECS]       Eastlake, D., Crocker, S. and J. Schiller, \"Randomness\n    \
    \           Recommendations for Security\", RFC 1750, December 1994.\n   [GIL98]\
    \     Cracking DES: Secrets of Encryption Research, Wiretap\n               Politics\
    \ & Chip Design , Electronic Frontier Foundation,\n               John Gilmore\
    \ (Ed.), 272 pages, May 1998, O'Reilly &\n               Associates; ISBN: 1565925203\n\
    \   [GOR93]     Gordon, D., \"Discrete logarithms in GF(p) using the\n       \
    \        number field sieve\", SIAM Journal on Discrete\n               Mathematics,\
    \ 6 (1993), 124-138.\n   [LEN93]     Lenstra, A. K. and H. W. Lenstra, Jr. (eds),\
    \ The\n               development of the number field sieve, Lecture Notes in\n\
    \               Math, 1554, Springer Verlag, Berlin, 1993.\n   [MH81]      Merkle,\
    \ R.C., and Hellman, M., \"On the Security of\n               Multiple Encryption\"\
    , Communications of the ACM, v. 24 n.\n               7, 1981, pp. 465-467.\n\
    \   [ODL95]     RSA Labs Cryptobytes, Volume 1, No. 2 - Summer 1995; The\n   \
    \            Future of Integer Factorization, A. M. Odlyzko\n   [ODL99]     A.\
    \ M. Odlyzko, Discrete logarithms: The past and the\n               future, Designs,\
    \ Codes, and Cryptography (1999).\n   [POL78]     J. Pollard, \"Monte Carlo methods\
    \ for index computation\n               mod p\", Mathematics of Computation, 32\
    \ (1978), 918-924.\n   [RFC2409]   Harkins, D. and D. Carrel, \"The Internet Key\
    \ Exchange\n               (IKE)\", RFC 2409, November 1998.\n   [SCH95]     R.\
    \ Schroeppel, et al., Fast Key Exchange With Elliptic\n               Curve Systems,\
    \ In Don Coppersmith, editor, Advances in\n               Cryptology -- CRYPTO\
    \ 31 August 1995. Springer-Verlag\n   [SHAMIR03]  Shamir, Adi and Eran Tromer,\
    \ \"Factoring Large Numbers\n               with the TWIRL Device\", Advances\
    \ in Cryptology - CRYPTO\n               2003, Springer, Lecture Notes in Computer\
    \ Science 2729.\n   [SIL00]     R. D. Silverman, RSA Laboratories Bulletin, Number\
    \ 13 -\n               April 2000, A Cost-Based Security Analysis of Symmetric\n\
    \               and Asymmetric Key Lengths\n   [SILIEEE99] R. D. Silverman, \"\
    The Mythical MIPS Year\", IEEE Computer,\n               August 1999.\n"
- title: 8. Authors' Addresses
  contents:
  - "8. Authors' Addresses\n   Hilarie Orman\n   Purple Streak Development\n   500\
    \ S. Maple Dr.\n   Salem, UT 84653\n   EMail: hilarie@purplestreak.com and ho@alum.mit.edu\n\
    \   Paul Hoffman\n   VPN Consortium\n   127 Segre Place\n   Santa Cruz, CA  95060\
    \ USA\n   EMail: paul.hoffman@vpnc.org\n"
- title: 9.  Full Copyright Statement
  contents:
  - "9.  Full Copyright Statement\n   Copyright (C) The Internet Society (2004). \
    \ This document is subject\n   to the rights, licenses and restrictions contained\
    \ in BCP 78, and\n   except as set forth therein, the authors retain all their\
    \ rights.\n   This document and the information contained herein are provided\
    \ on an\n   \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE\n   REPRESENTS\
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE\n   INTERNET ENGINEERING\
    \ TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR\n   IMPLIED, INCLUDING BUT NOT\
    \ LIMITED TO ANY WARRANTY THAT THE USE OF\n   THE INFORMATION HEREIN WILL NOT\
    \ INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS\
    \ FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed\n   to pertain to the implementation or use of the technology\n   described\
    \ in this document or the extent to which any license\n   under such rights might\
    \ or might not be available; nor does it\n   represent that it has made any independent\
    \ effort to identify any\n   such rights.  Information on the procedures with\
    \ respect to\n   rights in RFC documents can be found in BCP 78 and BCP 79.\n\
    \   Copies of IPR disclosures made to the IETF Secretariat and any\n   assurances\
    \ of licenses to be made available, or the result of an\n   attempt made to obtain\
    \ a general license or permission for the use\n   of such proprietary rights by\
    \ implementers or users of this\n   specification can be obtained from the IETF\
    \ on-line IPR repository\n   at http://www.ietf.org/ipr.\n   The IETF invites\
    \ any interested party to bring to its attention\n   any copyrights, patents or\
    \ patent applications, or other\n   proprietary rights that may cover technology\
    \ that may be required\n   to implement this standard.  Please address the information\
    \ to the\n   IETF at ietf-ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
