- title: __initial_text__
  contents:
  - '      Considerations When Using Basic OSPF Convergence Benchmarks

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2005).\n"
- title: Abstract
  contents:
  - "Abstract\n   This document discusses the applicability of various tests for\n\
    \   measuring single router control plane convergence, specifically in\n   regard\
    \ to the Open Shortest First (OSPF) protocol.  There are two\n   general sections\
    \ in this document, the first discusses advantages and\n   limitations of specific\
    \ OSPF convergence tests, and the second\n   discusses more general pitfalls to\
    \ be considered when routing\n   protocol convergence is tested.\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   There is a growing interest in testing single router control\
    \ plane\n   convergence for routing protocols, and many people are looking at\n\
    \   testing methodologies that can provide information on how long it\n   takes\
    \ for a network to converge after various network events occur.\n   It is important\
    \ to consider the framework within which any given\n   convergence test is executed\
    \ when one attempts to apply the results\n   of the testing, since the framework\
    \ can have a major impact on the\n   results.  For instance, determining when\
    \ a network is converged, what\n   parts of the router's operation are considered\
    \ within the testing,\n   and other such things will have a major impact on the\
    \ apparent\n   performance that routing protocols provide.\n   This document describes\
    \ in detail various benefits and pitfalls of\n   tests described in [BENCHMARK].\
    \  It also explains how such\n   measurements can be useful for providers and\
    \ the research community.\n   NOTE: In this document, the word \"convergence\"\
    \ refers to single\n   router control plane convergence [TERM].\n"
- title: 2.  Advantages of Such Measurement
  contents:
  - "2.  Advantages of Such Measurement\n   o    To be able to compare the iterations\
    \ of a protocol\n        implementation.  It is often useful to be able to compare\
    \ the\n        performance of two iterations of a given implementation of a\n\
    \        protocol in order to determine where improvements have been made\n  \
    \      and where further improvements can be made.\n   o    To understand, given\
    \ a set of parameters (network conditions),\n        how a particular implementation\
    \ on a particular device will\n        perform.  For instance, if you were trying\
    \ to decide the\n        processing power (size of device) required in a certain\
    \ location\n        within a network, you could emulate the conditions that will\n\
    \        exist at that point in the network and use the test described to\n  \
    \      measure the performance of several different routers.  The\n        results\
    \ of these tests can provide one possible data point for\n        an intelligent\
    \ decision.\n        If the device being tested is to be deployed in a running\n\
    \        network, using routes taken from the network where the equipment\n  \
    \      is to be deployed rather than some generated topology in these\n      \
    \  tests will yield results that are closer to the real performance\n        of\
    \ the device.  Care should be taken to emulate or take routes\n        from the\
    \ actual location in the network where the device will be\n        (or would be)\
    \ deployed.  For instance, one set of routes may be\n        taken from an ABR,\
    \ one set from an area 0 only router, various\n        sets from stub area, another\
    \ set from various normal areas, etc.\n   o    To measure the performance of an\
    \ OSPF implementation in a wide\n        variety of scenarios.\n   o    To be\
    \ used as parameters in OSPF simulations by researchers.  It\n        may sometimes\
    \ be required for certain kinds of research to\n        measure the individual\
    \ delays of each parameter within an OSPF\n        implementation.  These delays\
    \ can be measured using the methods\n        defined in [BENCHMARK].\n   o   \
    \ To help optimize certain configurable parameters.  It may\n        sometimes\
    \ be helpful for operators to know the delay required\n        for individual\
    \ tasks in order to optimize the resource usage in\n        the network.  For\
    \ example, if the processing time on a router is\n        found to be x seconds,\
    \ determining the rate at which to flood\n        LSAs to that router would be\
    \ helpful so as not to overload the\n        network.\n"
- title: 3.  Assumptions Made and Limitations of Such Measurements
  contents:
  - "3.  Assumptions Made and Limitations of Such Measurements\n   o    The interactions\
    \ of convergence and forwarding; testing is\n        restricted to events occurring\
    \ within the control plane.\n        Forwarding performance is the primary focus\
    \ in [INTERCONNECT],\n        and it is expected to be dealt with in work that\
    \ ensues from\n        [FIB-TERM].\n   o    Duplicate LSAs are Acknowledged Immediately.\
    \  A few tests rely\n        on the property that duplicate LSA Acknowledgements\
    \ are not\n        delayed but are done immediately.  However, if an implementation\n\
    \        does not acknowledge duplicate LSAs immediately on receipt, the\n   \
    \     testing methods presented in [BENCHMARK] could give inaccurate\n       \
    \ measurements.\n   o    It is assumed that SPF is non-preemptive.  If SPF is\
    \ implemented\n        so that it can (and will be) preempted, the SPF measurements\n\
    \        taken in [BENCHMARK] would include the times that the SPF\n        process\
    \ is not running, thus giving inaccurate measurements.\n        ([BENCHMARK] measures\
    \ the total time taken for SPF to run, not\n        the amount of time that SPF\
    \ actually spends on the device's\n        processor.)\n   o    Some implementations\
    \ may be multithreaded or use a\n        multiprocess/multirouter model of OSPF.\
    \  If because of this any\n        of the assumptions made during measurement\
    \ are violated in such\n        a model, measurements could be inaccurate.\n \
    \  o    The measurements resulting from the tests in [BENCHMARK] may not\n   \
    \     provide the information required to deploy a device in a large-\n      \
    \  scale network.  The tests described focus on individual\n        components\
    \ of an OSPF implementation's performance, and it may\n        be difficult to\
    \ combine the measurements in a way that\n        accurately depicts a device's\
    \ performance in a large-scale\n        network.  Further research is required\
    \ in this area.\n   o    The measurements described in [BENCHMARK] should be used\
    \ with\n        great care when comparing two different implementations of OSPF\n\
    \        from two different vendors.  For instance, there are many other\n   \
    \     factors than convergence speed that need to be taken into\n        consideration\
    \ when comparing different vendors' products.  One\n        difficulty is aligning\
    \ the resources available on one device to\n        the resources available on\
    \ another.\n"
- title: 4.  Observations on the Tests Described in [BENCHMARK]
  contents:
  - "4.  Observations on the Tests Described in [BENCHMARK]\n   Some observations\
    \ recorded while implementing the tests described in\n   [BENCHMARK] are noted\
    \ in this section.\n"
- title: 4.1.  Measuring the SPF Processing Time Externally
  contents:
  - "4.1.  Measuring the SPF Processing Time Externally\n   The most difficult test\
    \ to perform is the external measurement of the\n   time required to perform an\
    \ SPF calculation because the amount of\n   time between the first LSA that indicates\
    \ a topology change and the\n   duplicate LSA is critical.  If the duplicate LSA\
    \ is sent too quickly,\n   it may be received before the device being tested actually\
    \ begins\n   running SPF on the network change information.  If the delay between\n\
    \   the two LSAs is too long, the device may finish SPF processing before\n  \
    \ receiving the duplicate LSA.  It is important to closely investigate\n   any\
    \ delays between the receipt of an LSA and the beginning of an SPF\n   calculation\
    \ in the tested device; multiple tests with various delays\n   might be required\
    \ to determine what delay needs to be used to measure\n   the SPF calculation\
    \ time accurately.\n   Some implementations may force two intervals, the SPF hold\
    \ time and\n   the SPF delay, between successive SPF calculations.  If an SPF\
    \ hold\n   time exists, it should be subtracted from the total SPF execution\n\
    \   time.  If an SPF delay exists, it should be noted in the test\n   results.\n"
- title: 4.2.  Noise in the Measurement Device
  contents:
  - "4.2.  Noise in the Measurement Device\n   The device on which measurements are\
    \ taken (not the device being\n   tested) also adds noise to the test results,\
    \ primarily in the form of\n   delay in packet processing and measurement output.\
    \  The largest\n   source of noise is generally the delay between the receipt\
    \ of packets\n   by the measuring device and the receipt of information about\
    \ the\n   packet by the device's output, where the event can be measured.  The\n\
    \   following steps may be taken to reduce this sampling noise:\n   o    Increasing\
    \ the number of samples taken will generally improve\n        the tester's ability\
    \ to determine what is noise, and to remove\n        it from the results.  This\
    \ applies to the DUT as well.\n   o    Try to take time-stamp for a packet as\
    \ early as possible.\n        Depending on the operating system being used on\
    \ the box, one can\n        instrument the kernel to take the time-stamp when\
    \ the interrupt\n        is processed.  This does not eliminate the noise completely,\
    \ but\n        at least reduces it.\n   o    Keep the measurement box as lightly\
    \ loaded as possible.  This\n        applies to the DUT as well.\n   o    Having\
    \ an estimate of noise can also be useful.\n   The DUT also adds noise to the\
    \ measurement.\n"
- title: 4.3.  Gaining an Understanding of the Implementation Improves
  contents:
  - "4.3.  Gaining an Understanding of the Implementation Improves\n      Measurements\n\
    \   Although the tester will (generally) not have access to internal\n   information\
    \ about the OSPF implementation being tested using\n   [BENCHMARK], the more thorough\
    \ the tester's knowledge of the\n   implementation is, the more accurate the results\
    \ of the tests will\n   be.  For instance, in some implementations, the installation\
    \ of\n   routes in local routing tables may occur while the SPF is being\n   calculated,\
    \ dramatically impacting the time required to calculate the\n   SPF.\n"
- title: 4.4.  Gaining an Understanding of the Tests Improves Measurements
  contents:
  - "4.4.  Gaining an Understanding of the Tests Improves Measurements\n   One method\
    \ that can be used to become familiar with the tests\n   described in [BENCHMARK]\
    \ is to perform the tests on an OSPF\n   implementation for which all the internal\
    \ details are available.\n   Although there is no assurance that any two implementations\
    \ will be\n   similar, this will provide a better understanding of the tests\n\
    \   themselves.\n"
- title: 5.  LSA and Destination Mix
  contents:
  - "5.  LSA and Destination Mix\n   In many OSPF benchmark tests, a generator injecting\
    \ a number of LSAs\n   is called for.  There are several areas in which injected\
    \ LSAs can be\n   varied in testing:\n   o    The number of destinations represented\
    \ by the injected LSAs\n        Each destination represents a single reachable\
    \ IP network; these\n        will be leaf nodes on the shortest path tree.  The\
    \ primary\n        impact to performance should be the time required to insert\n\
    \        destinations in the local routing table and handling the memory\n   \
    \     required to store the data.\n   o    The types of LSAs injected\n      \
    \  There are several types of LSAs that would be acceptable under\n        different\
    \ situations; within an area, for instance, types 1, 2,\n        3, 4, and 5 are\
    \ likely to be received by a router.  Within a\n        not-so-stubby area, however,\
    \ type-7 LSAs would replace the\n        type-5 LSAs received.  These sorts of\
    \ characterizations are\n        important to note in any test results.\n   o\
    \    The number of LSAs injected\n        Within any injected set of information,\
    \ the number of each type\n        of LSA injected is also important.  This will\
    \ impact the\n        shortest path algorithm's ability to handle large numbers\
    \ of\n        nodes, large shortest path first trees, etc.\n   o    The order\
    \ of LSA injection\n        The order in which LSAs are injected should not favor\
    \ any given\n        data structure used for storing the LSA database on the device\n\
    \        being tested.  For instance, AS-External LSAs have AS wide\n        flooding\
    \ scope; any type-5 LSA originated is immediately flooded\n        to all neighbors.\
    \  However, the type-4 LSA, which announces the\n        ASBR as a border router,\
    \ is originated in an area at SPF time\n        (by ABRs on the edge of the area\
    \ in which the ASBR is).  If SPF\n        isn't scheduled immediately on the ABRs\
    \ originating the type-4\n        LSA, the type-4 LSA is sent after the type-5\
    \ LSA's reach a\n        router in the adjacent area.  Therefore, routes to the\
    \ external\n        destinations aren't immediately added to the routers in the\n\
    \        other areas.  When the routers that already have the type 5s\n      \
    \  receive the type-4 LSA, all the external routes are added to the\n        tree\
    \ at the same time.  This timing could produce different\n        results than\
    \ a router receiving a type 4 indicating the presence\n        of a border router,\
    \ followed by the type 5s originated by that\n        border router.\n       \
    \ The ordering can be changed in various tests to provide insight\n        into\
    \ the efficiency of storage within the DUT.  Any such changes\n        in ordering\
    \ should be noted in test results.\n"
- title: 6.  Tree Shape and the SPF Algorithm
  contents:
  - "6.  Tree Shape and the SPF Algorithm\n   The complexity of Dijkstra's algorithm\
    \ depends on the data structure\n   used for storing vertices with their current\
    \ minimum distances from\n   the source; the simplest structure is a list of vertices\
    \ currently\n   reachable from the source.  In a simple list of vertices, finding\
    \ the\n   minimum cost vertex would then take O(size of the list).  There will\n\
    \   be O(n) such operations if we assume that all the vertices are\n   ultimately\
    \ reachable from the source.  Moreover, after the vertex\n   with minimum cost\
    \ is found, the algorithm iterates through all the\n   edges of the vertex and\
    \ updates the cost of other vertices.  With an\n   adjacency list representation,\
    \ this step, when iterated over all the\n   vertices, would take O(E) time, with\
    \ E being the number of edges in\n   the graph.  Thus, the overall running time\
    \ is:\n   O(sum(i:1, n)(size(list at level i) + E).\n   So everything boils down\
    \ to the size(list at level i).\n   If the graph is linear,\n      root\n    \
    \   |\n       1\n       |\n       2\n       |\n       3\n       |\n       4\n\
    \       |\n       5\n       |\n       6\n   and source is a vertex on the end,\
    \ then size(list at level i) = 1 for\n   all i.  Moreover, E = n - 1.  Therefore,\
    \ running time is O(n).\n   If the graph is a balanced binary tree,\n       root\n\
    \      /    \\\n     1      2\n    / \\    / \\\n   3   4  5   6\n   size(list\
    \ at level i) is a little complicated.  First, it increases\n   by 1 at each level\
    \ up to a certain number, and then it goes down by\n   1.  If we assume that the\
    \ tree is a complete tree (as shown above)\n   with k levels (1 to k), then size(list)\
    \ goes on like this: 1, 2, 3,\n   Then the number of edges E is still n - 1. \
    \ It then turns out that\n   the run-time is O(n^2) for such a tree.\n   If the\
    \ graph is a complete graph (fully-connected mesh), then\n   size(list at level\
    \ i) = n - i.  Number of edges E = O(n^2).\n   Therefore, run-time is O(n^2).\n\
    \   Therefore, the performance of the shortest path first algorithm used\n   to\
    \ compute the best paths through the network is dependent on the\n   construction\
    \ of the tree.  The best practice would be to try to make\n   any emulated network\
    \ look as much like a real network as possible,\n   especially in the area of\
    \ the tree depth, the meshiness of the\n   network, the number of stub links versus\
    \ transit links, and the\n   number of connections and nodes to process at each\
    \ level within the\n   original tree.\n"
- title: 7.  Topology Generation
  contents:
  - "7.  Topology Generation\n   As the size of networks grows, it becomes more and\
    \ more difficult to\n   actually create a large-scale network on which to test\
    \ the properties\n   of routing protocols and their implementations.  In general,\
    \ network\n   emulators are used to provide emulated topologies that can be\n\
    \   advertised to a device with varying conditions.  Route generators\n   tend\
    \ to be either a specialized device, a piece of software which\n   runs on a router,\
    \ or a process that runs on another operating system,\n   such as Linux or another\
    \ variant of Unix.\n   Some of the characteristics of this device should be as\
    \ follows:\n   o    The ability to connect to several devices using both point-to-\n\
    \        point and broadcast high-speed media.  Point-to-point links can\n   \
    \     be emulated with high-speed Ethernet as long as there is no hub\n      \
    \  or other device between the DUT and the route generator, and the\n        link\
    \ is configured as a point-to-point link within OSPF\n        [BROADCAST-P2P].\n\
    \   o    The ability to create a set of LSAs that appear to be a logical,\n  \
    \      realistic topology.  For instance, the generator should be able\n     \
    \   to mix the number of point-to-point and broadcast links within\n        the\
    \ emulated topology and to inject varying numbers of\n        externally reachable\
    \ destinations.\n   o    The ability to withdraw and add routing information into\
    \ and\n        from the emulated topology to emulate flapping links.\n   o   \
    \ The ability to randomly order the LSAs representing the emulated\n        topology\
    \ as they are advertised.\n   o    The ability to log or otherwise measure the\
    \ time between packets\n        transmitted and received.\n   o    The ability\
    \ to change the rate at which OSPF LSAs are\n        transmitted.\n   o    The\
    \ generator and the collector should be fast enough that they\n        are not\
    \ bottlenecks.  The devices should also have a degree of\n        granularity\
    \ of measurement at least as small as is desired from\n        the test results.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   This document does not modify the underlying\
    \ security considerations\n   in [OSPF].\n"
- title: 9.  Acknowledgements
  contents:
  - "9.  Acknowledgements\n   Thanks to Howard Berkowitz (hcb@clark.net) and the rest\
    \ of the BGP\n   benchmarking team for their support and to Kevin Dubray\n   (kdubray@juniper.net),\
    \ who realized the need for this document.\n"
- title: 10.  Normative References
  contents:
  - "10.  Normative References\n   [BENCHMARK]     Manral, V., White, R., and A. Shaikh,\
    \ \"Benchmarking\n                   Basic OSPF Single Router Control Plane Convergence\"\
    ,\n                   RFC 4061, April 2005.\n   [TERM]          Manral, V., White,\
    \ R., and A. Shaikh, \"OSPF\n                   Benchmarking Terminology and Concepts\"\
    , RFC 4062,\n                   April 2005.\n   [OSPF]          Moy, J., \"OSPF\
    \ Version 2\", STD 54, RFC 2328, April\n                   1998.\n"
- title: 11.  Informative References
  contents:
  - "11.  Informative References\n   [INTERCONNECT]  Bradner, S. and J. McQuaid, \"\
    Benchmarking Methodology\n                   for Network Interconnect Devices\"\
    , RFC 2544, March\n                   1999.\n   [FIB-TERM]      Trotter, G., \"\
    Terminology for Forwarding Information\n                   Base (FIB) based Router\
    \ Performance\", RFC 3222,\n                   December 2001.\n   [BROADCAST-P2P]\
    \ Shen, Naiming, et al., \"Point-to-point operation over\n                   LAN\
    \ in link-state routing protocols\", Work in\n                   Progress, August,\
    \ 2003.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Vishwas Manral\n   SiNett Corp,\n   Ground Floor,\n  \
    \ Embassy Icon Annexe,\n   2/1, Infantry Road,\n   Bangalore, India\n   EMail:\
    \ vishwas@sinett.com\n   Russ White\n   Cisco Systems, Inc.\n   7025 Kit Creek\
    \ Rd.\n   Research Triangle Park, NC 27709\n   EMail: riw@cisco.com\n   Aman Shaikh\n\
    \   AT&T Labs (Research)\n   180 Park Av, PO Box 971\n   Florham Park, NJ 07932\n\
    \   EMail: ashaikh@research.att.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2005).\n   This\
    \ document is subject to the rights, licenses and restrictions\n   contained in\
    \ BCP 78, and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET\n   ENGINEERING\
    \ TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT\
    \ LIMITED TO ANY WARRANTY THAT THE USE OF THE\n   INFORMATION HEREIN WILL NOT\
    \ INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS\
    \ FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at ietf-\n   ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
