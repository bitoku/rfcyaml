- title: __initial_text__
  contents:
  - "            The Architecture of Direct Data Placement (DDP)\n      and Remote\
    \ Direct Memory Access (RDMA) on Internet Protocols\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2005).\n"
- title: Abstract
  contents:
  - "Abstract\n   This document defines an abstract architecture for Direct Data\n\
    \   Placement (DDP) and Remote Direct Memory Access (RDMA) protocols to\n   run\
    \ on Internet Protocol-suite transports.  This architecture does\n   not necessarily\
    \ reflect the proper way to implement such protocols,\n   but is, rather, a descriptive\
    \ tool for defining and understanding the\n   protocols.  DDP allows the efficient\
    \ placement of data into buffers\n   designated by Upper Layer Protocols (e.g.,\
    \ RDMA).  RDMA provides the\n   semantics to enable Remote Direct Memory Access\
    \ between peers in a\n   way consistent with application requirements.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................2\n\
    \      1.1. Terminology ................................................2\n  \
    \    1.2. DDP and RDMA Protocols .....................................3\n   2.\
    \ Architecture ....................................................4\n      2.1.\
    \ Direct Data Placement (DDP) Protocol Architecture ..........4\n           2.1.1.\
    \ Transport Operations ................................6\n           2.1.2. DDP\
    \ Operations ......................................7\n           2.1.3. Transport\
    \ Characteristics in DDP ...................10\n      2.2. Remote Direct Memory\
    \ Access (RDMA) Protocol Architecture ..12\n           2.2.1. RDMA Operations\
    \ ....................................14\n           2.2.2. Transport Characteristics\
    \ in RDMA ..................16\n   3. Security Considerations ........................................17\n\
    \      3.1. Security Services .........................................18\n  \
    \    3.2. Error Considerations ......................................19\n   4.\
    \ Acknowledgements ...............................................19\n   5. Informative\
    \ References .........................................20\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document defines an abstract architecture for Direct\
    \ Data\n   Placement (DDP) and Remote Direct Memory Access (RDMA) protocols to\n\
    \   run on Internet Protocol-suite transports.  This architecture does\n   not\
    \ necessarily reflect the proper way to implement such protocols,\n   but is,\
    \ rather, a descriptive tool for defining and understanding the\n   protocols.\
    \  This document uses C language notation as a shorthand to\n   describe the architectural\
    \ elements of DDP and RDMA protocols.  The\n   choice of C notation is not intended\
    \ to describe concrete protocols\n   or programming interfaces.\n   The first\
    \ part of the document describes the architecture of DDP\n   protocols, including\
    \ what assumptions are made about the transports\n   on which DDP is built.  The\
    \ second part describes the architecture of\n   RDMA protocols layered on top\
    \ of DDP.\n"
- title: 1.1.  Terminology
  contents:
  - "1.1.  Terminology\n   Before introducing the protocols, certain definitions will\
    \ be useful\n   to guide discussion:\n   o    Placement - writing to a data buffer.\n\
    \   o    Operation - a protocol message, or sequence of messages, which\n    \
    \    provide an architectural semantic, such as reading or writing of\n      \
    \  a data buffer.\n   o    Delivery - informing any Upper Layer or application\
    \ that a\n        particular message is available for use.  Therefore, delivery\n\
    \        may be viewed as the \"control\" signal associated with a unit of\n \
    \       data.  Note that the order of delivery is defined more strictly\n    \
    \    than it is for placement.\n   o    Completion - informing any Upper Layer\
    \ or application that a\n        particular operation has finished.  A completion,\
    \ for instance,\n        may require the delivery of several messages, or it may\
    \ also\n        reflect that some local processing has finished.\n   o    Data\
    \ Sink - the peer on which any placement occurs.\n   o    Data Source - the peer\
    \ from which the placed data originates.\n   o    Steering Tag - a \"handle\"\
    \ used to identify the buffer that is\n        the target of placement.  A \"\
    tagged\" message is one that\n        references such a handle.\n   o    RDMA\
    \ Write - an Operation that places data from a local data\n        buffer to a\
    \ remote data buffer specified by a Steering Tag.\n   o    RDMA Read - an Operation\
    \ that places data to a local data buffer\n        specified by a Steering Tag\
    \ from a remote data buffer specified\n        by another Steering Tag.\n   o\
    \    Send - an Operation that places data from a local data buffer to\n      \
    \  a remote data buffer of the data sink's choice.  Therefore,\n        sends\
    \ are \"untagged\".\n"
- title: 1.2.  DDP and RDMA Protocols
  contents:
  - "1.2.  DDP and RDMA Protocols\n   The goal of the DDP protocol is to allow the\
    \ efficient placement of\n   data into buffers designated by protocols layered\
    \ above DDP (e.g.,\n   RDMA).  This is described in detail in [ROM].  Efficiency\
    \ may be\n   characterized by the minimization of the number of transfers of the\n\
    \   data over the receiver's system buses.\n   The goal of the RDMA protocol is\
    \ to provide the semantics to enable\n   Remote Direct Memory Access between peers\
    \ in a way consistent with\n   application requirements.  The RDMA protocol provides\
    \ facilities\n   immediately useful to existing and future networking, storage,\
    \ and\n   other application protocols.  [FCVI, IB, MYR, SDP, SRVNET, VI]\n   The\
    \ DDP and RDMA protocols work together to achieve their respective\n   goals.\
    \  DDP provides facilities to safely steer payloads to specific\n   buffers at\
    \ the Data Sink.  RDMA provides facilities to Upper Layers\n   for identifying\
    \ these buffers, controlling the transfer of data\n   between peers' buffers,\
    \ supporting authorized bidirectional transfer\n   between buffers, and signalling\
    \ completion.  Upper Layer Protocols\n   that do not require the features of RDMA\
    \ may be layered directly on\n   top of DDP.\n   The DDP and RDMA protocols are\
    \ transport independent.  The following\n   figure shows the relationship between\
    \ RDMA, DDP, Upper Layer\n   Protocols, and Transport.\n          +--------------------------------------------------+\n\
    \          |               Upper Layer Protocol               |\n          +---------+------------+---------------------------+\n\
    \          |         |            |           RDMA            |\n          | \
    \        |            +---------------------------+\n          |         |   \
    \                DDP                  |\n          |         +----------------------------------------+\n\
    \          |                    Transport                     |\n          +--------------------------------------------------+\n"
- title: 2.  Architecture
  contents:
  - "2.  Architecture\n   The Architecture section is presented in two parts:  Direct\
    \ Data\n   Placement Protocol architecture and Remote Direct Memory Access\n \
    \  Protocol architecture.\n"
- title: 2.1.  Direct Data Placement (DDP) Protocol Architecture
  contents:
  - "2.1.  Direct Data Placement (DDP) Protocol Architecture\n   The central idea\
    \ of general-purpose DDP is that a data sender will\n   supplement the data it\
    \ sends with placement information that allows\n   the receiver's network interface\
    \ to place the data directly at its\n   final destination without any copying.\
    \  DDP can be used to steer\n   received data to its final destination, without\
    \ requiring layer-\n   specific behavior for each different layer.  Data sent\
    \ with such DDP\n   information is said to be `tagged'.\n   The central components\
    \ of the DDP architecture are the `buffer',\n   which is an object with beginning\
    \ and ending addresses, and a method\n   (set()), which sets the value of an octet\
    \ at an address.  In many\n   cases, a buffer corresponds directly to a portion\
    \ of host user\n   memory.  However, DDP does not depend on this; a buffer could\
    \ be a\n   disk file, or anything else that can be viewed as an addressable\n\
    \   collection of octets.  Abstractly, a buffer provides the interface:\n    \
    \    typedef struct {\n          const address_t start;\n          const address_t\
    \ end;\n          void            set(address_t a, data_t v);\n        } ddp_buffer_t;\n\
    \   address_t\n        a reference to local memory\n   data_t\n        an octet\
    \ data value.\n   The protocol layering and in-line data flow of DDP is:\n   \
    \                      DDP Client Protocol\n                  (e.g., RDMA or Upper\
    \ Layer Protocol)\n                                |  ^\n              untagged\
    \ messages |  | untagged message delivery\n                tagged messages | \
    \ | tagged message delivery\n                                v  |\n          \
    \                      DDP+---> data placement\n                             \
    \    ^\n                                 | transport messages\n              \
    \                   v\n                             Transport\n              \
    \      (e.g., SCTP, DCCP, framed TCP)\n                                 ^\n  \
    \                               | IP datagrams\n                             \
    \    v\n                               . . .\n   In addition to in-line data flow,\
    \ the client protocol registers\n   buffers with DDP, and DDP performs buffer\
    \ update (set()) operations\n   as a result of receiving tagged messages.\n  \
    \ DDP messages may be split into multiple, smaller DDP messages, each\n   in a\
    \ separate transport message.  However, if the transport is\n   unreliable or\
    \ unordered, messages split across transport messages may\n   or may not provide\
    \ useful behavior, in the same way as splitting\n   arbitrary Upper Layer messages\
    \ across unreliable or unordered\n   transport messages may or may not provide\
    \ useful behavior.  In other\n   words, the same considerations apply to building\
    \ client protocols on\n   different types of transports with or without the use\
    \ of DDP.\n   A DDP message split across transport messages looks like:\n   DDP\
    \ message:                Transport messages:\n     stag=s, offset=o,        \
    \  message 1:\n     notify=y, id=i               |type=ddp  |\n     message= \
    \                    |stag=s    |\n       |aabbccddee|-------.       |offset=o\
    \  |\n       ~   ...    ~----.   \\      |notify=n  |\n       |vvwwxxyyzz|-. \
    \  \\   \\     |id=?      |\n                    |    \\   `--->|aabbccddee|\n\
    \                    |     \\       ~    ...   ~\n                    |      +----->|iijjkkllmm|\n\
    \                    |      |\n                    +      |    message 2:\n  \
    \                   \\     |      |type=ddp  |\n                      \\    |\
    \      |stag=s    |\n                       \\   +      |offset=o+n|\n       \
    \                 \\   \\     |notify=y  |\n                         \\   \\ \
    \   |id=i      |\n                          \\   `-->|nnooppqqrr|\n          \
    \                 \\      ~    ...   ~\n                            `---->|vvwwxxyyzz|\n\
    \   Although this picture suggests that DDP information is carried in-\n   line\
    \ with the message payload, components of the DDP information may\n   also be\
    \ in transport-specific fields, or derived from transport-\n   specific control\
    \ information if the transport permits.\n"
- title: 2.1.1.  Transport Operations
  contents:
  - "2.1.1.  Transport Operations\n   For the purposes of this architecture, the transport\
    \ provides:\n        void      xpt_send(socket_t s, message_t m);\n        message_t\
    \ xpt_recv(socket_t s);\n        msize_t   xpt_max_msize(socket_t s);\n   socket_t\n\
    \        a transport address, including IP addresses, ports and other\n      \
    \  transport-specific identifiers.\n   message_t\n        a string of octets.\n\
    \   msize_t (scalar)\n        a message size.\n   xpt_send(socket_t s, message_t\
    \ m)\n        send a transport message.\n   xpt_recv(socket_t s)\n        receive\
    \ a transport message.\n   xpt_max_msize(socket_t s)\n        get the current\
    \ maximum transport message size.  Corresponds,\n        roughly, to the current\
    \ path Maximum Transfer Unit (PMTU),\n        adjusted by underlying protocol\
    \ overheads.\n   Real implementations of xpt_send() and xpt_recv() typically return\n\
    \   error indications, but that is not relevant to this architecture.\n"
- title: 2.1.2.  DDP Operations
  contents:
  - "2.1.2.  DDP Operations\n   The DDP layer provides:\n        void       ddp_send(socket_t\
    \ s, message_t m);\n        void       ddp_send_ddp(socket_t s, message_t m, ddp_addr_t\
    \ d,\n                                ddp_notify_t n);\n        void       ddp_post_recv(socket_t\
    \ s, bdesc_t b);\n        ddp_ind_t  ddp_recv(socket_t s);\n        bdesc_t  \
    \  ddp_register(socket_t s, ddp_buffer_t b);\n        void       ddp_deregister(bhand_t\
    \ bh);\n        msizes_t   ddp_max_msizes(socket_t s);\n   ddp_addr_t\n      \
    \  the buffer address portion of a tagged message:\n                typedef struct\
    \ {\n                  stag_t stag;\n                  address_t offset;\n   \
    \             } ddp_addr_t;\n   stag_t (scalar)\n        a Steering Tag.  A stag_t\
    \ identifies the destination buffer for\n        tagged messages.  stag_ts are\
    \ generated when the buffer is\n        registered, communicated to the sender\
    \ by some client protocol\n        convention and inserted in DDP messages.  stag_t\
    \ values in this\n        DDP architecture are assumed to be completely opaque\
    \ to the\n        client protocol, and implementation-dependent.  However,\n \
    \       particular implementations, such as DDP on a multicast transport\n   \
    \     (see below), may provide the buffer holder some control in\n        selecting\
    \ stag_ts.\n   ddp_notify_t\n        the notification portion of a DDP message,\
    \ used to signal\n        that the message represents the final fragment of a\n\
    \        multi-segmented DDP message:\n                typedef struct {\n    \
    \              boolean_t notify;\n                  ddp_msg_id_t i;\n        \
    \        } ddp_notify_t;\n   ddp_msg_id_t (scalar)\n        a DDP message identifier.\
    \  msg_id_ts are chosen by the DDP\n        message receiver (buffer holder),\
    \ communicated to the sender by\n        some client protocol convention and inserted\
    \ in DDP messages.\n        Whether a message reception indication is requested\
    \ for a DDP\n        message is a matter of client protocol convention.  Unlike\n\
    \        stag_ts, the structure of msg_id_ts is opaque to DDP, and\n        therefore,\
    \ it is completely in the hands of the client protocol.\n   bdesc_t\n        a\
    \ description of a registered buffer:\n                typedef struct {\n    \
    \              bhand_t bh;\n                  ddp_addr_t a;\n                }\
    \ bdesc_t;\n        `a.offset' is the starting offset of the registered buffer,\n\
    \        which may have no relationship to the `start' or `end' addresses\n  \
    \      of that buffer.  However, particular implementations, such as\n       \
    \ DDP on a multicast transport (see below), may allow some client\n        protocol\
    \ control over the starting offset.\n   bhand_t\n        an opaque buffer handle\
    \ used to deregister a buffer.\n   recv_message_t\n        a description of a\
    \ completed untagged receive buffer:\n                typedef struct {\n     \
    \             bdesc_t b;\n                  length_t l;\n                } recv_message_t;\n\
    \   ddp_ind_t\n        an untagged message, a tagged message reception indication,\
    \ or a\n        tagged message reception error:\n                typedef union\
    \ {\n                  recv_message_t m;\n                  ddp_msg_id_t i;\n\
    \                  ddp_err_t e;\n                } ddp_ind_t;\n   ddp_err_t\n\
    \        indicates an error while receiving a tagged message, typically\n    \
    \    `offset' out of bounds, or `stag' is not registered to the\n        socket.\n\
    \   msizes_t\n        The maximum untagged and tagged messages that fit in a single\n\
    \        transport message:\n                typedef struct {\n              \
    \    msize_t max_untagged;\n                  msize_t max_tagged;\n          \
    \      } msizes_t;\n   ddp_send(socket_t s, message_t m)\n        send an untagged\
    \ message.\n   ddp_send_ddp(socket_t s, message_t m, ddp_addr_t d, ddp_notify_t\
    \ n)\n        send a tagged message to remote buffer address d.\n   ddp_post_recv(socket_t\
    \ s, bdesc_t b)\n        post a registered buffer to accept a single received\
    \ untagged\n        message.  Each buffer is returned to the caller in a ddp_recv()\n\
    \        untagged message reception indication, in the order in which it\n   \
    \     was posted.  The same buffer may be enabled on multiple sockets;\n     \
    \   receipt of an untagged message into the buffer from any of these\n       \
    \ sockets unposts the buffer from all sockets.\n   ddp_recv(socket_t s)\n    \
    \    get the next received untagged message, tagged message reception\n      \
    \  indication, or tagged message error.\n   ddp_register(socket_t s, ddp_buffer_t\
    \ b)\n        register a buffer for DDP on a socket.  The same buffer may be\n\
    \        registered multiple times on the same or different sockets.  The\n  \
    \      same buffer registered on different sockets may result in a\n        common\
    \ registration.  Different buffers may also refer to\n        portions of the\
    \ same underlying addressable object (buffer\n        aliasing).\n   ddp_deregister(bhand_t\
    \ bh)\n        remove a registration from a buffer.\n   ddp_max_msizes(socket_t\
    \ s)\n        get the current maximum untagged and tagged message sizes that\n\
    \        will fit in a single transport message.\n"
- title: 2.1.3.  Transport Characteristics in DDP
  contents:
  - "2.1.3.  Transport Characteristics in DDP\n   Certain characteristics of the transport\
    \ on which DDP is mapped\n   determine the nature of the service provided to client\
    \ protocols.\n   Fundamentally, the characteristics of the transport will not\
    \ be\n   changed by the presence of DDP.  The choice of transport is therefore\n\
    \   driven not by DDP, but by the requirements of the Upper Layer, and\n   employing\
    \ the DDP service.\n   Specifically, transports are:\n     o    reliable or unreliable,\n\
    \     o    ordered or unordered,\n     o    single source or multisource,\n  \
    \   o    single destination or multidestination (multicast or anycast).\n   Some\
    \ transports support several combinations of these\n   characteristics.  For example,\
    \ SCTP [SCTP] is reliable, single\n   source, single destination (point-to-point)\
    \ and supports both ordered\n   and unordered modes.\n   DDP messages carried\
    \ by transport are framed for processing by the\n   receiver, and may be further\
    \ protected for integrity or privacy in\n   accordance with the transport capabilities.\
    \  DDP does not provide\n   such functions.\n   In general, transport characteristics\
    \ equally affect transport and\n   DDP message delivery.  However, there are several\
    \ issues specific to\n   DDP messages.\n   A key component of DDP is how the following\
    \ operations on the\n   receiving side are ordered among themselves, and how they\
    \ relate to\n   corresponding operations on the sending side:\n          o   \
    \ set()s,\n          o    untagged message reception indications, and\n      \
    \    o    tagged message reception indications.\n   These relationships depend\
    \ upon the characteristics of the underlying\n   transport in a way that is defined\
    \ by the DDP protocol.  For example,\n   if the transport is unreliable and unordered,\
    \ the DDP protocol might\n   specify that the client protocol is subject to the\
    \ consequences of\n   transport messages being lost or duplicated, rather than\
    \ requiring\n   that different characteristics be presented to the client protocol.\n\
    \   Buffer access must be implemented consistently across endpoint IP\n   addresses\
    \ on transports allowing multiple IP addresses per endpoint,\n   for example,\
    \ SCTP.  In particular, the Steering Tag must be\n   consistently scoped and must\
    \ address the same buffer across all IP\n   address associations belonging to\
    \ the endpoint.  Additionally,\n   operation ordering relationships across IP\
    \ addresses within an\n   association (set(), get(), etc.) depend on the underlying\
    \ transport.\n   If the above consistency relationships cannot be maintained by\
    \ a\n   transport endpoint, then the endpoint is unsuitable for a DDP\n   connection.\n\
    \   Multidestination data delivery is a transport characteristic that may\n  \
    \ require specific consideration in a DDP protocol.  As mentioned\n   above, the\
    \ basic DDP model assumes that buffer address values\n   returned by ddp_register()\
    \ are opaque to the client protocol, and can\n   be implementation dependent.\
    \  The most natural way to map DDP to a\n   multidestination transport is to require\
    \ that all receivers produce\n   the same buffer address when registering a multidestination\n\
    \   destination buffer.  Restriction of the DDP model to accommodate\n   multiple\
    \ destinations involves engineering tradeoffs comparable to\n   those of providing\
    \ non-DDP multidestination transport capability.\n   A registered buffer is identified\
    \ within DDP by its stag_t, which in\n   turn is associated with a socket.  Therefore,\
    \ this registration\n   grants a capability to the DDP peer, and the socket (using\
    \ the\n   underlying properties of its chosen transport and possible security)\n\
    \   identifies the peer and authenticates the stag_t.\n   The same buffer may\
    \ be enabled by ddp_post_recv() on multiple\n   sockets.  In this case any ddp_recv()\
    \ untagged message reception\n   indication may be provided on a different socket\
    \ from that on which\n   the buffer was posted.  Such indications are not ordered\
    \ among\n   multiple DDP sockets.\n   When multiple sockets reference an untagged\
    \ message reception buffer,\n   local interfaces are responsible for managing\
    \ the mechanisms of\n   allocating posted buffers to received untagged messages,\
    \ the handling\n   of received untagged messages when no buffer is available,\
    \ and of\n   resource management among multiple sockets.  Where underprovisioning\n\
    \   of buffers on multiple sockets is allowed, mechanisms should be\n   provided\
    \ to manage buffer consumption on a per-socket or group of\n   related sockets\
    \ basis.\n   Architecturally, therefore, DDP is a flexible and general paradigm\n\
    \   that may be applied to any variety of transports.  Implementations of\n  \
    \ DDP may, however, adapt themselves to these differences in ways\n   appropriate\
    \ to each transport.  In all cases, the layering of DDP\n   must continue to express\
    \ the transport's underlying characteristics.\n"
- title: 2.2.  Remote Direct Memory Access (RDMA) Protocol Architecture
  contents:
  - "2.2.  Remote Direct Memory Access (RDMA) Protocol Architecture\n   Remote Direct\
    \ Memory Access (RDMA) extends the capabilities of DDP\n   with two primary functions.\n\
    \   First, it adds the ability to read from buffers registered to a\n   socket\
    \ (RDMA Read).  This allows a client protocol to perform\n   arbitrary, bidirectional\
    \ data movement without involving the remote\n   client.  When RDMA is implemented\
    \ in hardware, arbitrary data\n   movement can be performed without involving\
    \ the remote host CPU at\n   all.\n   In addition, RDMA specifies a transport-independent\
    \ untagged message\n   service (Send) with characteristics that are both very\
    \ efficient to\n   implement in hardware, and convenient for client protocols.\n\
    \   The RDMA architecture is patterned after the traditional model for\n   device\
    \ programming, where the client requests an operation using\n   Send-like actions\
    \ (programmed I/O), the server performs the necessary\n   data transfers for the\
    \ operation (DMA reads and writes), and notifies\n   the client of completion.\
    \  The programmed I/O+DMA model efficiently\n   supports a high degree of concurrency\
    \ and flexibility for both the\n   client and server, even when operations have\
    \ a wide range of\n   intrinsic latencies.\n   RDMA is layered as a client protocol\
    \ on top of DDP:\n                      Client Protocol\n                    \
    \       |  ^\n                     Sends |  | Send reception indications\n   \
    \     RDMA Read Requests |  | RDMA Read Completion indications\n             \
    \  RDMA Writes |  | RDMA Write Completion indications\n                      \
    \     v  |\n                           RDMA\n                           |  ^\n\
    \         untagged messages |  | untagged message delivery\n           tagged\
    \ messages |  | tagged message delivery\n                           v  |\n   \
    \                        DDP+---> data placement\n                           \
    \ ^\n                            | transport messages\n                      \
    \      v\n                          . . .\n   In addition to in-line data flow,\
    \ read (get()) and update (set())\n   operations are performed on buffers registered\
    \ with RDMA as a result\n   of RDMA Read Requests and RDMA Writes, respectively.\n\
    \   An RDMA `buffer' extends a DDP buffer with a get() operation that\n   retrieves\
    \ the value of the octet at address `a':\n           typedef struct {\n      \
    \       const address_t start;\n             const address_t end;\n          \
    \   void            set(address_t a, data_t v);\n             data_t         \
    \ get(address_t a);\n           } rdma_buffer_t;\n"
- title: 2.2.1.  RDMA Operations
  contents:
  - "2.2.1.  RDMA Operations\n   The RDMA layer provides:\n        void        rdma_send(socket_t\
    \ s, message_t m);\n        void        rdma_write(socket_t s, message_t m, ddp_addr_t\
    \ d,\n                               rdma_notify_t n);\n        void        rdma_read(socket_t\
    \ s, ddp_addr_t s, ddp_addr_t d);\n        void        rdma_post_recv(socket_t\
    \ s, bdesc_t b);\n        rdma_ind_t  rdma_recv(socket_t s);\n        bdesc_t\
    \     rdma_register(socket_t s, rdma_buffer_t b,\n                           \
    \    bmode_t mode);\n        void        rdma_deregister(bhand_t bh);\n      \
    \  msizes_t    rdma_max_msizes(socket_t s);\n   Although, for clarity, these data\
    \ transfer interfaces are\n   synchronous, rdma_read() and possibly rdma_send()\
    \ (in the presence of\n   Send flow control) can require an arbitrary amount of\
    \ time to\n   complete.  To express the full concurrency and interleaving of RDMA\n\
    \   data transfer, these interfaces should also be reentrant.  For\n   example,\
    \ a client protocol may perform an rdma_send(), while an\n   rdma_read() operation\
    \ is in progress.\n   rdma_notify_t\n        RDMA Write notification information,\
    \ used to signal that the\n        message represents the final fragment of a\
    \ multi-segmented RDMA\n        message:\n                typedef struct {\n \
    \                 boolean_t notify;\n                  rdma_write_id_t i;\n  \
    \              } rdma_notify_t;\n        identical in function to ddp_notify_t,\
    \ except that the type\n        rdma_write_id_t may not be equivalent to ddp_msg_id_t.\n\
    \   rdma_write_id_t (scalar)\n        an RDMA Write identifier.\n   rdma_ind_t\n\
    \        a Send message, or an RDMA error:\n                typedef union {\n\
    \                  recv_message_t m;\n                  rdma_err_t e;\n      \
    \          } rdma_ind_t;\n   rdma_err_t\n        an RDMA protocol error indication.\
    \  RDMA errors include buffer\n        addressing errors corresponding to ddp_err_ts,\
    \ and buffer\n        protection violations (e.g., RDMA Writing a buffer only\n\
    \        registered for reading).\n   bmode_t\n        buffer registration mode\
    \ (permissions).  Any combination of\n        permitting RDMA Read (BMODE_READ)\
    \ and RDMA Write (BMODE_WRITE)\n        operations.\n   rdma_send(socket_t s,\
    \ message_t m)\n        send a message, delivering it to the next untagged RDMA\
    \ buffer\n        at the remote peer.\n   rdma_write(socket_t s, message_t m,\
    \ ddp_addr_t d, rdma_notify_t n)\n        RDMA Write to remote buffer address\
    \ d.\n   rdma_read(socket_t s, ddp_addr_t s, length_t l, ddp_addr_t d)\n     \
    \   RDMA Read l octets from remote buffer address s to local buffer\n        address\
    \ d.\n   rdma_post_recv(socket_t s, bdesc_t b)\n        post a registered buffer\
    \ to accept a single Send message, to be\n        filled and returned in-order\
    \ to a subsequent caller of\n        rdma_recv().  As with DDP, buffers may be\
    \ enabled on multiple\n        sockets, in which case ordering guarantees are\
    \ relaxed.  Also as\n        with DDP, local interfaces must manage the mechanisms\
    \ of\n        allocation and management of buffers posted to multiple sockets.\n\
    \   rdma_recv(socket_t s);\n        get the next received Send message, RDMA Write\
    \ completion\n        identifier, or RDMA error.\n   rdma_register(socket_t s,\
    \ rdma_buffer_t b, bmode_t mode)\n        register a buffer for RDMA on a socket\
    \ (for read access, write\n        access or both).  As with DDP, the same buffer\
    \ may be registered\n        multiple times on the same or different sockets,\
    \ and different\n        buffers may refer to portions of the same underlying\
    \ addressable\n        object.\n   rdma_deregister(bhand_t bh)\n        remove\
    \ a registration from a buffer.\n   rdma_max_msizes(socket_t s)\n        get the\
    \ current maximum Send (max_untagged) and RDMA Read or\n        Write (max_tagged)\
    \ operations that will fit in a single\n        transport message.  The values\
    \ returned by rdma_max_msizes() are\n        closely related to the values returned\
    \ by ddp_max_msizes(), but\n        may not be equal.\n"
- title: 2.2.2.  Transport Characteristics in RDMA
  contents:
  - "2.2.2.  Transport Characteristics in RDMA\n   As with DDP, RDMA can be used on\
    \ transports with a variety of\n   different characteristics that manifest themselves\
    \ directly in the\n   service provided by RDMA.  Also, as with DDP, the fundamental\n\
    \   characteristics of the transport will not be changed by the presence\n   of\
    \ RDMA.\n   Like DDP, an RDMA protocol must specify how:\n          o    set()s,\n\
    \          o    get()s,\n          o    Send messages, and\n          o    RDMA\
    \ Read completions\n   are ordered among themselves and how they relate to corresponding\n\
    \   operations on the remote peer(s).  These relationships are likely to\n   be\
    \ a function of the underlying transport characteristics.\n   There are some additional\
    \ characteristics of RDMA that may translate\n   poorly to unreliable or multipoint\
    \ transports due to attendant\n   complexities in managing endpoint state:\n \
    \    o    Send flow control\n     o    RDMA Read\n   These difficulties can be\
    \ overcome by placing restrictions on the\n   service provided by RDMA.  However,\
    \ many RDMA clients, especially\n   those that separate data transfer and application\
    \ logic concerns, are\n   likely to depend upon capabilities only provided by\
    \ RDMA on a point-\n   to-point, reliable transport.  In other words, many potential\
    \ Upper\n   Layers, which might avail themselves of RDMA services, are naturally\n\
    \   already biased toward these transport classes.\n"
- title: 3.  Security Considerations
  contents:
  - "3.  Security Considerations\n   Fundamentally, the DDP and RDMA protocols themselves\
    \ should not\n   introduce additional vulnerabilities.  They are intermediate\n\
    \   protocols and so should not perform or require functions such as\n   authorization,\
    \ which are the domain of Upper Layers.  However, the\n   DDP and RDMA protocols\
    \ should allow mapping by strict Upper Layers\n   that are not permissive of new\
    \ vulnerabilities; DDP and RDMAP\n   implementations should be prohibited from\
    \ `cutting corners' that\n   create new vulnerabilities.  Implementations must\
    \ ensure that only\n   `supplied' resources (i.e., buffers) can be manipulated\
    \ by DDP or\n   RDMAP messages.\n   System integrity must be maintained in any\
    \ RDMA solution.  Mechanisms\n   must be specified to prevent RDMA or DDP operations\
    \ from impairing\n   system integrity.  For example, threats can include potential\
    \ buffer\n   reuse or buffer overflow, and are not merely a security issue.  Even\n\
    \   trusted peers must not be allowed to damage local integrity.  Any DDP\n  \
    \ and RDMA protocol must address the issue of giving end-systems and\n   applications\
    \ the capabilities to offer protection from such\n   compromises.\n   Because\
    \ a Steering Tag exports access to a buffer, one critical\n   aspect of security\
    \ is the scope of this access.  It must be possible\n   to individually control\
    \ specific attributes of the access provided by\n   a Steering Tag on the endpoint\
    \ (socket) on which it was registered,\n   including remote read access, remote\
    \ write access, and others that\n   might be identified.  DDP and RDMA specifications\
    \ must provide both\n   implementation requirements relevant to this issue, and\
    \ guidelines to\n   assist implementors in making the appropriate design decisions.\n\
    \   For example, it must not be possible for DDP to enable evasion of\n   buffer\
    \ consistency checks at the recipient.  The DDP and RDMA\n   specifications must\
    \ allow the recipient to rely on its consistent\n   buffer contents by explicitly\
    \ controlling peer access to buffer\n   regions at appropriate times.\n   The\
    \ use of DDP and RDMA on a transport connection may interact with\n   any security\
    \ mechanism, and vice-versa.  For example, if the security\n   mechanism is implemented\
    \ above the transport layer, the DDP and RDMA\n   headers may not be protected.\
    \  Therefore, such a layering may be\n   inappropriate, depending on requirements.\n"
- title: 3.1.  Security Services
  contents:
  - "3.1.  Security Services\n   The following end-to-end security services protect\
    \ DDP and RDMAP\n   operation streams:\n     o    Authentication of the data source,\
    \ to protect against peer\n          impersonation, stream hijacking, and man-in-the-middle\
    \ attacks\n          exploiting capabilities offered by the RDMA implementation.\n\
    \          Peer connections that do not pass authentication and\n          authorization\
    \ checks must not be permitted to begin processing\n          in RDMA mode with\
    \ an inappropriate endpoint.  Once associated,\n          peer accesses to buffer\
    \ regions must be authenticated and made\n          subject to authorization checks\
    \ in the context of the\n          association and endpoint (socket) on which\
    \ they are to be\n          performed, prior to any transfer operation or data\
    \ being\n          accessed.  The RDMA protocols must ensure that these region\n\
    \          protections be under strict application control.\n     o    Integrity,\
    \ to protect against modification of the control\n          content and buffer\
    \ content.\n          While integrity is of concern to any transport, it is\n\
    \          important for the DDP and RDMAP protocols that the RDMA\n         \
    \ control information carried in each operation be protected, in\n          order\
    \ to direct the payloads appropriately.\n     o    Sequencing, to protect against\
    \ replay attacks (a special case\n          of the above modifications).\n   \
    \  o    Confidentiality, to protect the stream from eavesdropping.\n   IPsec,\
    \ operating to secure the connection on a packet-by-packet\n   basis, is a natural\
    \ fit to securing RDMA placement, which operates in\n   conjunction with transport.\
    \  Because RDMA enables an implementation\n   to avoid buffering, it is preferable\
    \ to perform all applicable\n   security protection prior to processing of each\
    \ segment by the\n   transport and RDMA layers.  Such a layering enables the most\n\
    \   efficient secure RDMA implementation.\n   The TLS record protocol, on the\
    \ other hand, is layered on top of\n   reliable transports and cannot provide\
    \ such security assurance until\n   an entire record is available, which may require\
    \ the buffering and/or\n   assembly of several distinct messages prior to TLS\
    \ processing.  This\n   defers RDMA processing and introduces overheads that RDMA\
    \ is designed\n   to avoid.  In addition, TLS length restrictions on records themselves\n\
    \   impose additional buffering and processing for long operations that\n   must\
    \ span multiple records.  TLS therefore is viewed as potentially a\n   less natural\
    \ fit for protecting the RDMA protocols.\n   Any DDP and RDMAP specification must\
    \ provide the means to satisfy the\n   above security service requirements.\n\
    \   IPsec is sufficient to provide the required security services to the\n   DDP\
    \ and RDMAP protocols, while enabling efficient implementations.\n"
- title: 3.2.  Error Considerations
  contents:
  - "3.2.  Error Considerations\n   Resource issues leading to denial-of-service attacks,\
    \ overwrites and\n   other concurrent operations, the ordering of completions\
    \ as required\n   by the RDMA protocol, and the granularity of transfer are all\
    \ within\n   the required scope of any security analysis of RDMA and DDP.\n  \
    \ The RDMA operations require checking of what is essentially user\n   information,\
    \ explicitly including addressing information and\n   operation type (read or\
    \ write), and implicitly including protection\n   and attributes.  The semantics\
    \ associated with each class of error\n   resulting from possible failure of such\
    \ checks must be clearly\n   defined, and the expected action to be taken by the\
    \ protocols in each\n   case must be specified.\n   In some cases, this will result\
    \ in a catastrophic error on the RDMA\n   association; however, in others, a local\
    \ or remote error may be\n   signalled.  Certain of these errors may require consideration\
    \ of\n   abstract local semantics.  The result of the error on the RDMA\n   association\
    \ must be carefully specified so as to provide useful\n   behavior, while not\
    \ constraining the implementation.\n"
- title: 4.  Acknowledgements
  contents:
  - "4.  Acknowledgements\n   The authors wish to acknowledge the valuable contributions\
    \ of Caitlin\n   Bestler, David Black, Jeff Mogul, and Allyn Romanow.\n"
- title: 5.  Informative References
  contents:
  - "5.  Informative References\n   [FCVI]   ANSI Technical Committee T11, \"Fibre\
    \ Channel Standard\n            Virtual Interface Architecture Mapping\", ANSI/NCITS\
    \ 357-\n            2001, March 2001, available from\n            http://www.t11.org/t11/stat.nsf/fcproj.\n\
    \   [IB]     InfiniBand Trade Association, \"InfiniBand Architecture\n       \
    \     Specification Volumes 1 and 2\", Release 1.1, November 2002,\n         \
    \   available from http://www.infinibandta.org/specs.\n   [MYR]    VMEbus International\
    \ Trade Association, \"Myrinet on VME\n            Protocol Specification\", ANSI/VITA\
    \ 26-1998, August 1998,\n            available from http://www.myri.com/open-specs.\n\
    \   [ROM]    Romanow, A., Mogul, J., Talpey, T., and S. Bailey, \"Remote\n   \
    \         Direct Memory Access (RDMA) over IP Problem Statement\", RFC\n     \
    \       4297, December 2005.\n   [SCTP]   Stewart, R., Xie, Q., Morneault, K.,\
    \ Sharp, C.,\n            Schwarzbauer, H., Taylor, T., Rytina, I., Kalla, M.,\
    \ Zhang,\n            L., and V. Paxson, \"Stream Control Transmission Protocol\"\
    ,\n            RFC 2960, October 2000.\n   [SDP]    InfiniBand Trade Association,\
    \ \"Sockets Direct Protocol\n            v1.0\", Annex A of InfiniBand Architecture\
    \ Specification\n            Volume 1, Release 1.1, November 2002, available from\n\
    \            http://www.infinibandta.org/specs.\n   [SRVNET] R. Horst, \"TNet:\
    \ A reliable system area network\", IEEE\n            Micro, pp. 37-45, February\
    \ 1995.\n   [VI]     D. Cameron and G. Regnier, \"The Virtual Interface\n    \
    \        Architecture\", ISBN 0971288704, Intel Press, April 2002,\n         \
    \   more info at http://www.intel.com/intelpress/via/.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Stephen Bailey\n   Sandburst Corporation\n   600 Federal\
    \ Street\n   Andover, MA  01810 USA\n   USA\n   Phone: +1 978 689 1614\n   EMail:\
    \ steph@sandburst.com\n   Tom Talpey\n   Network Appliance\n   1601 Trapelo Road\n\
    \   Waltham, MA  02451 USA\n   Phone: +1 781 768 5329\n   EMail: thomas.talpey@netapp.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2005).\n   This\
    \ document is subject to the rights, licenses and restrictions\n   contained in\
    \ BCP 78, and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET\n   ENGINEERING\
    \ TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT\
    \ LIMITED TO ANY WARRANTY THAT THE USE OF THE\n   INFORMATION HEREIN WILL NOT\
    \ INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS\
    \ FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at ietf-\n   ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
