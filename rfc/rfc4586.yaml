- title: __initial_text__
  contents:
  - "                        Extended RTP Profile for\n      Real-time Transport Control\
    \ Protocol (RTCP)-Based Feedback:\n                Results of the Timing Rule\
    \ Simulations\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2006).\n"
- title: Abstract
  contents:
  - "Abstract\n   This document describes the results achieved when simulating the\n\
    \   timing rules of the Extended RTP Profile for Real-time Transport\n   Control\
    \ Protocol (RTCP)-Based Feedback, denoted AVPF.  Unicast and\n   multicast topologies\
    \ are considered as well as several protocol and\n   environment configurations.\
    \  The results show that the timing rules\n   result in better performance regarding\
    \ feedback delay and still\n   preserve the well-accepted RTP rules regarding\
    \ allowed bit rates for\n   control traffic.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Timing Rules of the Extended RTP Profile for RTCP-Based\n      Feedback\
    \ ........................................................4\n   3. Simulation\
    \ Environment ..........................................5\n      3.1. Network\
    \ Simulator Version 2 ................................5\n      3.2. RTP Agent\
    \ ..................................................5\n      3.3. Scenarios ..................................................5\n\
    \      3.4. Topologies .................................................6\n  \
    \ 4. RTCP Bit Rate Measurements ......................................6\n    \
    \  4.1. Unicast ....................................................7\n      4.2.\
    \ Multicast .................................................10\n      4.3. Summary\
    \ of the RTCP Bit Rate Measurements .................10\n   5. Feedback Measurements\
    \ ..........................................11\n      5.1. Unicast ...................................................11\n\
    \      5.2. Multicast .................................................12\n  \
    \         5.2.1. Shared Losses vs. Distributed Losses ...............13\n   6.\
    \ Investigations on \"l\" ..........................................14\n     \
    \ 6.1. Feedback Suppression Performance ..........................16\n      6.2.\
    \ Loss Report Delay .........................................18\n      6.3. Summary\
    \ of \"l\" Investigations .............................18\n   7. Applications\
    \ Using AVPF ........................................19\n      7.1. NEWPRED Implementation\
    \ in NS2 .............................19\n      7.2. Simulation ................................................21\n\
    \           7.2.1. Simulation A - Constant Packet Loss Rate ...........21\n  \
    \         7.2.2. Simulation B - Packet Loss Due to Congestion .......23\n    \
    \  7.3. Summary of Application Simulations ........................24\n   8. Summary\
    \ ........................................................24\n   9. Security Considerations\
    \ ........................................25\n   10. Normative References ..........................................26\n\
    \   11. Informative References ........................................26\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The Real-time Transport Protocol (RTP) is widely used for\
    \ the\n   transmission of real-time or near real-time media data over the\n  \
    \ Internet.  While it was originally designed to work well for\n   multicast groups\
    \ in very large scales, its scope is not limited to\n   that.  More and more applications\
    \ use RTP for small multicast groups\n   (e.g., video conferences) or even unicast\
    \ (e.g., IP telephony and\n   media streaming applications).\n   RTP comes together\
    \ with its companion protocol Real-time Transport\n   Control Protocol (RTCP),\
    \ which is used to monitor the transmission of\n   the media data and provide\
    \ feedback of the reception quality.\n   Furthermore, it can be used for loose\
    \ session control.  Having the\n   scope of large multicast groups in mind, the\
    \ rules regarding when to\n   send feedback were carefully restricted to avoid\
    \ feedback explosion\n   or feedback-related congestion in the network.  RTP and\
    \ RTCP have\n   proven to work well in the Internet, especially in large multicast\n\
    \   groups, which is shown by their widespread usage today.\n   However, the applications\
    \ that transmit the media data only to small\n   multicast groups or unicast may\
    \ benefit from more frequent feedback.\n   The source of the packets may be able\
    \ to react to changes in the\n   reception quality, which may be due to varying\
    \ network utilization\n   (e.g., congestion) or other changes.  Possible reactions\
    \ include\n   transmission rate adaptation according to a congestion control\n\
    \   algorithm or the invocation of error resilience features for the\n   media\
    \ stream (e.g., retransmissions, reference picture selection,\n   NEWPRED, etc.).\n\
    \   As mentioned before, more frequent feedback may be desirable to\n   increase\
    \ the reception quality, but RTP restricts the use of RTCP\n   feedback.  Hence\
    \ it was decided to create a new extended RTP profile,\n   which redefines some\
    \ of the RTCP timing rules, but keeps most of the\n   algorithms for RTP and RTCP,\
    \ which have proven to work well.  The new\n   rules should scale from unicast\
    \ to multicast, where unicast or small\n   multicast applications have the most\
    \ gain from it.  A detailed\n   description of the new profile and its timing\
    \ rules can be found in\n   [1].\n   This document investigates the new algorithms\
    \ by the means of\n   simulations.  We show that the new timing rules scale well\
    \ and behave\n   in a network-friendly manner.  Firstly, the key features of the\
    \ new\n   RTP profile that are important for our simulations are roughly\n   described\
    \ in Section 2.  After that, we describe in Section 3 the\n   environment that\
    \ is used to conduct the simulations.  Section 4\n   describes simulation results\
    \ that show the backwards compatibility to\n   RTP and that the new profile is\
    \ network-friendly in terms of used\n   bandwidth for RTCP traffic.  In Section\
    \ 5, we show the benefit that\n   applications could get from implementing the\
    \ new profile.  In Section\n   6, we investigated the effect of the parameter\
    \ \"l\" (used to calculate\n   the T_dither_max value) upon the algorithm performance,\
    \ and finally,\n   in Section 7, we show the performance gain we could get for\
    \ a special\n   application, namely, NEWPRED in [6] and [7].\n"
- title: 2.  Timing Rules of the Extended RTP Profile for RTCP-Based Feedback
  contents:
  - "2.  Timing Rules of the Extended RTP Profile for RTCP-Based Feedback\n   As said\
    \ above, RTP restricts the usage of RTCP feedback.  The main\n   restrictions\
    \ on RTCP are as follows:\n   - RTCP messages are sent in compound packets, i.e.,\
    \ every RTCP packet\n     contains at least one sender report (SR) or receiver\
    \ report (RR)\n     message and a source description (SDES) message.\n   - The\
    \ RTCP compound packets are sent in time intervals (T_rr), which\n     are computed\
    \ as a function of the average packet size, the number\n     of senders and receivers\
    \ in the group, and the session bandwidth\n     (5% of the session bandwidth is\
    \ used for RTCP messages; this\n     bandwidth is shared between all session members,\
    \ where the senders\n     may get a larger share than the receivers.)\n   - The\
    \ average minimum interval between two RTCP packets from the same\n     source\
    \ is 5 seconds.\n   We see that these rules prevent feedback explosion and scale\
    \ well to\n   large multicast groups.  However, they do not allow timely feedback\n\
    \   at all.  While the second rule scales also to small groups or unicast\n  \
    \ (in this cases the interval might be as small as a few milliseconds),\n   the\
    \ third rule may prevent the receivers from sending feedback\n   timely.\n   The\
    \ timing rules to send RTCP feedback from the new RTP profile [1]\n   consist\
    \ of two key components.  First, the minimum interval of 5\n   seconds is abolished.\
    \  Second, receivers get one chance during every\n   other of their (now quite\
    \ small) RTCP intervals to send an RTCP\n   packet \"early\", i.e., not according\
    \ to the calculated interval, but\n   virtually immediately.  It is important\
    \ to note that the RTCP\n   interval calculation is still inherited from the original\
    \ RTP\n   specification.\n   The specification and all the details of the extended\
    \ timing rules\n   can be found in [1].  Rather than describing the algorithms\
    \ here, we\n   reference the original specification [1].  Therefore, we use also\
    \ the\n   same variable names and abbreviations as in [1].\n"
- title: 3.  Simulation Environment
  contents:
  - "3.  Simulation Environment\n   This section describes the simulation testbed\
    \ that was used for the\n   investigations and its key features.  The extensions\
    \ to the simulator\n   that were necessary are roughly described in the following\
    \ sections.\n"
- title: 3.1.  Network Simulator Version 2
  contents:
  - "3.1.  Network Simulator Version 2\n   The simulations were conducted using the\
    \ network simulator version 2\n   (ns2).  ns2 is an open source project, written\
    \ in a combination of\n   Tool Command Language (TCL) and C++.  The scenarios\
    \ are set up using\n   TCL.  Using the scripts, it is possible to specify the\
    \ topologies\n   (nodes and links, bandwidths, queue sizes, or error rates for\
    \ links)\n   and the parameters of the \"agents\", i.e., protocol configurations.\n\
    \   The protocols themselves are implemented in C++ in the agents, which\n   are\
    \ connected to the nodes.  The documentation for ns2 and the newest\n   version\
    \ can be found in [4].\n"
- title: 3.2.  RTP Agent
  contents:
  - "3.2.  RTP Agent\n   We implemented a new agent, based on RTP/RTCP.  RTP packets\
    \ are sent\n   at a constant packet rate with the correct header sizes.  RTCP\n\
    \   packets are sent according to the timing rules of [2] and [3], and\n   also\
    \ its algorithms for group membership maintenance are implemented.\n   Sender\
    \ and receiver reports are sent.\n   Further, we extended the agent to support\
    \ the extended profile [1].\n   The use of the new timing rules can be turned\
    \ on and off via\n   parameter settings in TCL.\n"
- title: 3.3.  Scenarios
  contents:
  - "3.3.  Scenarios\n   The scenarios that are simulated are defined in TCL scripts.\
    \  We set\n   up several different topologies, ranging from unicast with two\n\
    \   session members to multicast with up to 25 session members.\n   Depending\
    \ on the sending rates used and the corresponding link\n   bandwidths, congestion\
    \ losses may occur.  In some scenarios, bit\n   errors are inserted on certain\
    \ links.  We simulated groups with\n   RTP/AVP agents, RTP/AVPF agents, and mixed\
    \ groups.\n   The feedback messages are generally NACK messages as defined in\
    \ [1]\n   and are triggered by packet loss.\n"
- title: 3.4.  Topologies
  contents:
  - "3.4.  Topologies\n   Mainly, four different topologies are simulated to show\
    \ the key\n   features of the extended profile.  However, for some specific\n\
    \   simulations we used different topologies.  This is then indicated in\n   the\
    \ description of the simulation results.  The main four topologies\n   are named\
    \ after the number of participating RTP agents, i.e., T-2,\n   T-4, T-8, and T-16,\
    \ where T-2 is a unicast scenario, T-4 contains\n   four agents, etc.  Figure\
    \ 1 below illustrates the main topologies.\n                                 \
    \                  A5\n                                     A5            |  \
    \ A6\n                                    /              |  /\n              \
    \                     /               | /--A7\n                              \
    \    /                |/\n                    A2          A2-----A6          A2--A8\n\
    \                   /           /                  /        A9\n             \
    \     /           /                  /        /\n                 /          \
    \ /                  /        /---A10\n   A1-----A2   A1-----A3   A1-----A3-----A7\
    \   A1------A3<\n                 \\           \\                  \\        \\\
    ---A11\n                  \\           \\                  \\        \\\n    \
    \               \\           \\                  \\        A12\n             \
    \       A4          A4-----A8          A4--A13\n                             \
    \                      |\\\n                                                 \
    \  | \\--A14\n                                                   |  \\\n     \
    \                                              |  A15\n                      \
    \                            A16\n       T-2         T-4            T-8      \
    \         T-16\n                      Figure 1: Simulated topologies\n"
- title: 4.  RTCP Bit Rate Measurements
  contents:
  - "4.  RTCP Bit Rate Measurements\n   The new timing rules allow more frequent RTCP\
    \ feedback for small\n   multicast groups.  In large groups, the algorithm behaves\
    \ similarly\n   to the normal RTCP timing rules.  While it is generally good to\n\
    \   have more frequent feedback, it cannot be allowed at all to\n   increase the\
    \ bit rate used for RTCP above a fixed limit, i.e., 5%\n   of the total RTP bandwidth\
    \ according to RTP.  This section shows\n   that the new timing rules keep RTCP\
    \ bandwidth usage under the 5%\n   limit for all investigated scenarios, topologies,\
    \ and group sizes.\n   Furthermore, we show that mixed groups (some members using\n\
    \   AVP, some AVPF) can be allowed and that each session member behaves\n   fairly\
    \ according to its corresponding specification.  Note that\n   other values for\
    \ the RTCP bandwidth limit may be specified using\n   the RTCP bandwidth modifiers\
    \ as in [10].\n"
- title: 4.1.  Unicast
  contents:
  - "4.1.  Unicast\n   First we measured the RTCP bandwidth share in the unicast topology\n\
    \   T-2.  Even for a fixed topology and group size, there are several\n   protocol\
    \ parameters that are varied to simulate a large range of\n   different scenarios.\
    \  We varied the configurations of the agents\n   in the sense that the agents\
    \ may use AVP or AVPF.  Thereby it\n   is possible that one agent uses AVP and\
    \ the other AVPF in one RTP\n   session.  This is done to test the backwards compatibility\
    \ of the\n   AVPF profile.\n   Next, we consider scenarios where no losses occur.\
    \  In this case,\n   both RTP session members transmit the RTCP compound packets\
    \ at\n   regular intervals, calculated as T_rr, if they use AVPF, and\n   use\
    \ a minimum interval of 5 seconds (on average) if they implement\n   AVP.  No\
    \ early packets are sent, because the need to send early\n   feedback is not given.\
    \  Still it is important to see that not more\n   than 5% of the session bandwidth\
    \ is used for RTCP and that AVP and\n   AVPF members can coexist without interference.\
    \  The results can\n   be found in Table 1.\n       |         |      |      |\
    \      |      | Used RTCP Bit Rate |\n       | Session | Send | Rec. | AVP  |\
    \ AVPF | (% of session bw)  |\n       |Bandwidth|Agents|Agents|Agents|Agents|\
    \  A1  |  A2  | sum  |\n       +---------+------+------+------+------+------+------+------+\n\
    \       |  2 Mbps |  1   |  2   |  -   | 1,2  | 2.42 | 2.56 | 4.98 |\n       |\
    \  2 Mbps | 1,2  |  -   |  -   | 1,2  | 2.49 | 2.49 | 4.98 |\n       |  2 Mbps\
    \ |  1   |  2   |  1   |  2   | 0.01 | 2.49 | 2.50 |\n       |  2 Mbps | 1,2 \
    \ |  -   |  1   |  2   | 0.01 | 2.48 | 2.49 |\n       |  2 Mbps |  1   |  2  \
    \ | 1,2  |  -   | 0.01 | 0.01 | 0.02 |\n       |  2 Mbps | 1,2  |  -   | 1,2 \
    \ |  -   | 0.01 | 0.01 | 0.02 |\n       |200 kbps |  1   |  2   |  -   | 1,2 \
    \ | 2.42 | 2.56 | 4.98 |\n       |200 kbps | 1,2  |  -   |  -   | 1,2  | 2.49\
    \ | 2.49 | 4.98 |\n       |200 kbps |  1   |  2   |  1   |  2   | 0.06 | 2.49\
    \ | 2.55 |\n       |200 kbps | 1,2  |  -   |  1   |  2   | 0.08 | 2.50 | 2.58\
    \ |\n       |200 kbps |  1   |  2   | 1,2  |  -   | 0.06 | 0.06 | 0.12 |\n   \
    \    |200 kbps | 1,2  |  -   | 1,2  |  -   | 0.08 | 0.08 | 0.16 |\n       | 20\
    \ kbps |  1   |  2   |  -   | 1,2  | 2.44 | 2.54 | 4.98 |\n       | 20 kbps |\
    \ 1,2  |  -   |  -   | 1,2  | 2.50 | 2.51 | 5.01 |\n       | 20 kbps |  1   |\
    \  2   |  1   |  2   | 0.58 | 2.48 | 3.06 |\n       | 20 kbps | 1,2  |  -   |\
    \  1   |  2   | 0.77 | 2.51 | 3.28 |\n       | 20 kbps |  1   |  2   | 1,2  |\
    \  -   | 0.58 | 0.61 | 1.19 |\n       | 20 kbps | 1,2  |  -   | 1,2  |  -   |\
    \ 0.77 | 0.79 | 1.58 |\n             Table 1: Unicast simulations without packet\
    \ loss\n   We can see that in configurations where both agents use the new\n \
    \  timing rules each of them uses, at most, about 2.5% of the session\n   bandwidth\
    \ for RTP, which sums up to 5% of the session bandwidth for\n   both.  This is\
    \ achieved regardless of the agent being a sender or a\n   receiver.  In the cases\
    \ where agent A1 uses AVP and agent A2 AVPF,\n   the total RTCP session bandwidth\
    \ decreases.  This is because agent A1\n   can send RTCP packets only with an\
    \ average minimum interval of 5\n   seconds.  Thus, only a small fraction of the\
    \ session bandwidth is\n   used for its RTCP packets.  For a high-bit-rate session\
    \ (session\n   bandwidth = 2 Mbps), the fraction of the RTCP packets from agent\
    \ A1\n   is as small as 0.01%.  For smaller session bandwidths, the fraction\n\
    \   increases because the same amount of RTCP data is sent.  The\n   bandwidth\
    \ share that is used by RTCP packets from agent A2 is not\n   different from what\
    \ was used, when both agents implemented the AVPF.\n   Thus, the interaction of\
    \ AVP and AVPF agents is not problematic in\n   these scenarios at all.\n   In\
    \ our second unicast experiment, we show that the allowed RTCP\n   bandwidth share\
    \ is not exceeded, even if packet loss occurs.  We\n   simulated a constant byte\
    \ error rate (BYER) on the link.  The byte\n   errors are inserted randomly according\
    \ to a uniform distribution.\n   Packets with byte errors are discarded on the\
    \ link; hence the\n   receiving agents will not see the loss immediately.  The\
    \ agents\n   detect packet loss by a gap in the sequence number.\n   When an AVPF\
    \ agent detects a packet loss, the early feedback\n   procedure is started.  As\
    \ described in AVPF [1], in unicast\n   T_dither_max is always zero, hence an\
    \ early packet can be sent\n   immediately if allow_early is true.  If the last\
    \ packet was already\n   an early one (i.e., allow_early = false), the feedback\
    \ might be\n   appended to the next regularly scheduled receiver report.  The\n\
    \   max_feedback_delay parameter (which we set to 1 second in our\n   simulations)\
    \ determines if that is allowed.\n   The results are shown in Table 2, where we\
    \ can see that there is no\n   difference in the RTCP bandwidth share, whether\
    \ or not losses occur.\n   This is what we expected, because even though the RTCP\
    \ packet size\n   grows and early packets are sent, the interval between the packets\n\
    \   increases and thus the RTCP bandwidth stays the same.  Only the RTCP\n   bandwidth\
    \ of the agents that use the AVP increases slightly.  This is\n   because the\
    \ interval between the packets is still 5 seconds (in\n   average), but the packet\
    \ size increased because of the feedback that\n   is appended.\n       |     \
    \    |      |      |      |      | Used RTCP Bit Rate |\n       | Session | Send\
    \ | Rec. | AVP  | AVPF | (% of session bw)  |\n       |Bandwidth|Agents|Agents|Agents|Agents|\
    \  A1  |  A2  | sum  |\n       +---------+------+------+------+------+------+------+------+\n\
    \       |  2 Mbps |  1   |  2   |  -   | 1,2  | 2.42 | 2.56 | 4.98 |\n       |\
    \  2 Mbps | 1,2  |  -   |  -   | 1,2  | 2.49 | 2.49 | 4.98 |\n       |  2 Mbps\
    \ |  1   |  2   |  1   |  2   | 0.01 | 2.49 | 2.50 |\n       |  2 Mbps | 1,2 \
    \ |  -   |  1   |  2   | 0.01 | 2.48 | 2.49 |\n       |  2 Mbps |  1   |  2  \
    \ | 1,2  |  -   | 0.01 | 0.02 | 0.03 |\n       |  2 Mbps | 1,2  |  -   | 1,2 \
    \ |  -   | 0.01 | 0.01 | 0.02 |\n       |200 kbps |  1   |  2   |  -   | 1,2 \
    \ | 2.42 | 2.56 | 4.98 |\n       |200 kbps | 1,2  |  -   |  -   | 1,2  | 2.50\
    \ | 2.49 | 4.99 |\n       |200 kbps |  1   |  2   |  1   |  2   | 0.06 | 2.50\
    \ | 2.56 |\n       |200 kbps | 1,2  |  -   |  1   |  2   | 0.08 | 2.49 | 2.57\
    \ |\n       |200 kbps |  1   |  2   | 1,2  |  -   | 0.06 | 0.07 | 0.13 |\n   \
    \    |200 kbps | 1,2  |  -   | 1,2  |  -   | 0.09 | 0.08 | 0.17 |\n       | 20\
    \ kbps |  1   |  2   |  -   | 1,2  | 2.42 | 2.57 | 4.99 |\n       | 20 kbps |\
    \ 1,2  |  -   |  -   | 1,2  | 2.52 | 2.51 | 5.03 |\n       | 20 kbps |  1   |\
    \  2   |  1   |  2   | 0.58 | 2.54 | 3.12 |\n       | 20 kbps | 1,2  |  -   |\
    \  1   |  2   | 0.83 | 2.43 | 3.26 |\n       | 20 kbps |  1   |  2   | 1,2  |\
    \  -   | 0.58 | 0.73 | 1.31 |\n       | 20 kbps | 1,2  |  -   | 1,2  |  -   |\
    \ 0.86 | 0.84 | 1.70 |\n               Table 2: Unicast simulations with packet\
    \ loss\n"
- title: 4.2.  Multicast
  contents:
  - "4.2.  Multicast\n   Next, we investigated the RTCP bandwidth share in multicast\n\
    \   scenarios; i.e., we simulated the topologies T-4, T-8, and T-16 and\n   measured\
    \ the fraction of the session bandwidth that was used for RTCP\n   packets.  Again\
    \ we considered different situations and protocol\n   configurations (e.g., with\
    \ or without bit errors, groups with AVP\n   and/or AVPF agents, etc.).  For reasons\
    \ of readability, we present\n   only selected results.  For a documentation of\
    \ all results, see [5].\n   The simulations of the different topologies in scenarios\
    \ where no\n   losses occur (neither through bit errors nor through congestion)\
    \ show\n   a similar behavior as in the unicast case.  For all group sizes, the\n\
    \   maximum RTCP bit rate share used is 5.06% of the session bandwidth in\n  \
    \ a simulation of 16 session members in a low-bit-rate scenario\n   (session bandwidth\
    \ = 20 kbps) with several senders.  In all other\n   scenarios without losses,\
    \ the RTCP bit rate share used is below that.\n   Thus, the requirement that not\
    \ more than 5% of the session bit rate\n   should be used for RTCP is fulfilled\
    \ with reasonable accuracy.\n   Simulations where bit errors are randomly inserted\
    \ in RTP and RTCP\n   packets and the corrupted packets are discarded give the\
    \ same\n   results.  The 5% rule is kept (at maximum 5.07% of the session\n  \
    \ bandwidth is used for RTCP).\n   Finally, we conducted simulations where we\
    \ reduced the link bandwidth\n   and thereby caused congestion-related losses.\
    \  These simulations are\n   different from the previous bit error simulations,\
    \ in that the losses\n   occur more in bursts and are more correlated, also between\
    \ different\n   agents.  The correlation and \"burstiness\" of the packet loss\
    \ is due\n   to the queuing discipline in the routers we simulated; we used simple\n\
    \   FIFO queues with a drop-tail strategy to handle congestion.  Random\n   Early\
    \ Detection (RED) queues may enhance the performance, because the\n   burstiness\
    \ of the packet loss might be reduced; however, this is not\n   the subject of\
    \ our investigations, but is left for future study.  The\n   delay between the\
    \ agents, which also influences RTP and RTCP packets,\n   is much more variable\
    \ because of the added queuing delay.  Still the\n   RTCP bit rate share used\
    \ does not increase beyond 5.09% of the\n   session bandwidth.  Thus, also for\
    \ these special cases the\n   requirement is fulfilled.\n"
- title: 4.3.  Summary of the RTCP Bit Rate Measurements
  contents:
  - "4.3.  Summary of the RTCP Bit Rate Measurements\n   We have shown that for unicast\
    \ and reasonable multicast scenarios,\n   feedback implosion does not happen.\
    \  The requirement that at maximum\n   5% of the session bandwidth is used for\
    \ RTCP is fulfilled for all\n   investigated scenarios.\n"
- title: 5.  Feedback Measurements
  contents:
  - "5.  Feedback Measurements\n   In this section we describe the results of feedback\
    \ delay\n   measurements, which we conducted in the simulations.  Therefore, we\n\
    \   use two metrics for measuring the performance of the algorithms;\n   these\
    \ are the \"mean waiting time\" (MWT) and the number of feedback\n   packets that\
    \ are sent, suppressed, or not allowed.  The waiting time\n   is the time, measured\
    \ at a certain agent, between the detection of a\n   packet loss event and the\
    \ time when the corresponding feedback is\n   sent.  Assuming that the value of\
    \ the feedback decreases with its\n   delay, we think that the mean waiting time\
    \ is a good metric to\n   measure the performance gain we could get by using AVPF\
    \ instead of\n   AVP.\n   The feedback an RTP/AVPF agent wants to send can be\
    \ either sent or\n   not sent.  If it was not sent, this could be due to feedback\n\
    \   suppression (i.e., another receiver already sent the same feedback)\n   or\
    \ because the feedback was not allowed (i.e., the max_feedback_delay\n   was exceeded).\
    \  We traced for every detected loss, if the agent sent\n   the corresponding\
    \ feedback or not and if not, why.  The more feedback\n   was not allowed, the\
    \ worse the performance of the algorithm.\n   Together with the waiting times,\
    \ this gives us a good hint of the\n   overall performance of the scheme.\n"
- title: 5.1.  Unicast
  contents:
  - "5.1.  Unicast\n   In the unicast case, the maximum dithering interval T_dither_max\
    \ is\n   fixed and set to zero.  This is because it does not make sense for a\n\
    \   unicast receiver to wait for other receivers if they have the same\n   feedback\
    \ to send.  But still feedback can be delayed or might not be\n   permitted to\
    \ be sent at all.  The regularly scheduled packets are\n   spaced according to\
    \ T_rr, which depends in the unicast case mainly on\n   the session bandwidth.\n\
    \   Table 3 shows the mean waiting times (MWTs) measured in seconds for\n   some\
    \ configurations of the unicast topology T-2.  The number of\n   feedback packets\
    \ that are sent or discarded is listed also (feedback\n   sent (sent) or feedback\
    \ discarded (disc)).  We do not list suppressed\n   packets, because for the unicast\
    \ case feedback suppression does not\n   apply.  In the simulations, agent A1\
    \ was a sender and agent A2 was a\n   pure receiver.\n       |         |     \
    \  |          Feedback Statistics          |\n       | Session |       |     \
    \  AVP         |       AVPF        |\n       |Bandwidth|  PLR  | sent |disc| MWT\
    \   | sent |disc| MWT   |\n       +---------+-------+------+----+-------+------+----+-------+\n\
    \       |  2 Mbps | 0.001 |  781 |  0 | 2.604 |  756 |  0 | 0.015 |\n       |\
    \  2 Mbps | 0.01  | 7480 |  0 | 2.591 | 7548 |  2 | 0.006 |\n       |  2 Mbps\
    \ | cong. |   25 |  0 | 2.557 | 1741 |  0 | 0.001 |\n       | 20 kbps | 0.001\
    \ |   79 |  0 | 2.472 |   74 |  2 | 0.034 |\n       | 20 kbps | 0.01  |  780 |\
    \  0 | 2.605 |  709 | 64 | 0.163 |\n       | 20 kbps | cong. |  780 |  0 | 2.590\
    \ |  687 | 70 | 0.162 |\n         Table 3: Feedback statistics for the unicast\
    \ simulations\n   From the table above we see that the mean waiting time can be\n\
    \   decreased dramatically by using AVPF instead of AVP.  While the\n   waiting\
    \ times for agents using AVP is always around 2.5 seconds (half\n   the minimum\
    \ interval average), it can be decreased to a few ms for\n   most of the AVPF\
    \ configurations.\n   In the configurations with high session bandwidth, normally\
    \ all\n   triggered feedback is sent.  This is because more RTCP bandwidth is\n\
    \   available.  There are only very few exceptions, which are probably\n   due\
    \ to more than one packet loss within one RTCP interval, where the\n   first loss\
    \ was by chance sent quite early.  In this case, it might be\n   possible that\
    \ the second feedback is triggered after the early packet\n   was sent, but possibly\
    \ too early to append it to the next regularly\n   scheduled report, because of\
    \ the limitation of the\n   max_feedback_delay.  This is different for the cases\
    \ with a small\n   session bandwidth, where the RTCP bandwidth share is quite\
    \ low and\n   T_rr thus larger.  After an early packet was sent, the time to the\n\
    \   next regularly scheduled packet can be very high.  We saw that in\n   some\
    \ cases the time was larger than the max_feedback_delay, and in\n   these cases\
    \ the feedback is not allowed to be sent at all.\n   With a different setting\
    \ of max_feedback_delay, it is possible to\n   have either more feedback that\
    \ is not allowed and a decreased mean\n   waiting time or more feedback that is\
    \ sent but an increased waiting\n   time.  Thus, the parameter should be set with\
    \ care according to the\n   application's needs.\n"
- title: 5.2.  Multicast
  contents:
  - "5.2.  Multicast\n   In this section, we describe some measurements of feedback\
    \ statistics\n   in the multicast simulations.  We picked out certain characteristic\n\
    \   and representative results.  We considered the topology T-16.\n   Different\
    \ scenarios and applications are simulated for this topology.\n   The parameters\
    \ of the different links are set as follows.  The agents\n   A2, A3, and A4 are\
    \ connected to the middle node of the multicast\n   tree, i.e., agent A1, via\
    \ high bandwidth and low-delay links.  The\n   other agents are connected to the\
    \ nodes 2, 3, and 4 via different\n   link characteristics.  The agents connected\
    \ to node 2 represent\n   mobile users.  They suffer in certain configurations\
    \ from a certain\n   byte error rate on their access links and the delays are\
    \ high.  The\n   agents that are connected to node 3 have low-bandwidth access\
    \ links,\n   but do not suffer from bit errors.  The last agents, which are\n\
    \   connected to node 4, have high bandwidth and low delay.\n"
- title: 5.2.1.  Shared Losses vs. Distributed Losses
  contents:
  - "5.2.1.  Shared Losses vs. Distributed Losses\n   In our first investigation,\
    \ we wanted to see the effect of the loss\n   characteristic on the algorithm's\
    \ performance.  We investigate the\n   cases where packet loss occurs for several\
    \ users simultaneously\n   (shared losses) or totally independently (distributed\
    \ losses).  We\n   first define agent A1 to be the sender.  In the case of shared\n\
    \   losses, we inserted a constant byte error rate on one of the middle\n   links,\
    \ i.e., the link between A1 and A2.  In the case of distributed\n   losses, we\
    \ inserted the same byte error rate on all links downstream\n   of A2.\n   These\
    \ scenarios are especially interesting because of the feedback\n   suppression\
    \ algorithm.  When all receivers share the same loss, it is\n   only necessary\
    \ for one of them to send the loss report.  Hence if a\n   member receives feedback\
    \ with the same content that it has scheduled\n   to be sent, it suppresses the\
    \ scheduled feedback.  Of course, this\n   suppressed feedback does not contribute\
    \ to the mean waiting times.\n   So we expect reduced waiting times for shared\
    \ losses, because the\n   probability is high that one of the receivers can send\
    \ the feedback\n   more or less immediately.  The results are shown in the following\n\
    \   table.\n       |     |                Feedback Statistics                |\n\
    \       |     |  Shared Losses          |  Distributed Losses     |\n       |Agent|sent|fbsp|disc|sum\
    \ | MWT |sent|fbsp|disc|sum | MWT |\n       +-----+----+----+----+----+-----+----+----+----+----+-----+\n\
    \       |  A2 | 274| 351|  25| 650|0.267|   -|   -|   -|   -|    -|\n       |\
    \  A5 | 231| 408|  11| 650|0.243| 619|   2|  32| 653|0.663|\n       |  A6 | 234|\
    \ 407|   9| 650|0.235| 587|   2|  32| 621|0.701|\n       |  A7 | 223| 414|  13|\
    \ 650|0.253| 594|   6|  41| 641|0.658|\n       |  A8 | 188| 443|  19| 650|0.235|\
    \ 596|   1|  32| 629|0.677|\n          Table 4: Feedback statistics for multicast\
    \ simulations\n   Table 4 shows the feedback statistics for the simulation of\
    \ a large\n   group size.  All 16 agents of topology T-16 joined the RTP session.\n\
    \   However, only agent A1 acts as an RTP sender; the other agents are\n   pure\
    \ receivers.  Only 4 or 5 agents suffer from packet loss, i.e.,\n   A2, A5, A6,\
    \ A7, and A8 for the case of shared losses and A5, A6, A7,\n   and A8 in the case\
    \ of distributed losses.  Since the number of\n   session members is the same\
    \ for both cases, T_rr is also the same on\n   the average.  Still the mean waiting\
    \ times are reduced by more than\n   50% in the case of shared losses.  This proves\
    \ our assumption that\n   shared losses enhance the performance of the algorithm,\
    \ regardless of\n   the loss characteristic.\n   The feedback suppression mechanism\
    \ seems to be working quite well.\n   Even though some feedback is sent from different\
    \ receivers (i.e.,\n   1150 loss reports are sent in total and only 650 packets\
    \ were lost,\n   resulting in loss reports being received on the average 1.8 times),\n\
    \   most of the redundant feedback was suppressed.  That is, 2023 loss\n   reports\
    \ were suppressed from 3250 individual detected losses, which\n   means that more\
    \ than 60% of the feedback was actually suppressed.\n"
- title: 6.  Investigations on "l"
  contents:
  - "6.  Investigations on \"l\"\n   In this section, we want to investigate the effect\
    \ of the parameter\n   \"l\" on the T_dither_max calculation in RTP/AVPF agents.\
    \  We\n   investigate the feedback suppression performance as well as the\n  \
    \ report delay for three sample scenarios.\n   For all receivers, the T_dither_max\
    \ value is calculated as\n   T_dither_max = l * T_rr, with l = 0.5.  The rationale\
    \ for this is\n   that, in general, if the receiver has no round-trip time (RTT)\n\
    \   estimation, it does not know how long it should wait for other\n   receivers\
    \ to send feedback.  The feedback suppression algorithm would\n   certainly fail\
    \ if the time selected is too short.  However, the\n   waiting time is increased\
    \ unnecessarily (and thus the value of the\n   feedback is decreased) in case\
    \ the chosen value is too large.\n   Ideally, the optimum time value could be\
    \ found for each case, but\n   this is not always feasible.  On the other hand,\
    \ it is not dangerous\n   if the optimum time is not used.  A decreased feedback\
    \ value and a\n   failure of the feedback suppression mechanism do not hurt the\
    \ network\n   stability.  We have shown for the cases of distributed losses that\n\
    \   the overall bandwidth constraints are kept in any case and thus we\n   could\
    \ only lose some performance by choosing the wrong time value.\n   On the other\
    \ hand, a good measure for T_dither_max is the RTCP\n   interval T_rr.  This value\
    \ increases with the number of session\n   members.  Also, we know that we can\
    \ send feedback at least every\n   T_rr.  Thus, increasing T_dither max beyond\
    \ T_rr would certainly make\n   no sense.  So by choosing T_rr/2, we guarantee\
    \ that at least\n   sometimes (i.e., when a loss is detected in the first half\
    \ of the\n   interval between two regularly scheduled RTCP packets) we are allowed\n\
    \   to send early packets.  Because of the randomness of T_dither, we\n   still\
    \ have a good chance of sending the early packet in time.\n   The AVPF profile\
    \ specifies that the calculation of T_dither_max, as\n   given above, is common\
    \ to session members having an RTT estimation\n   and to those not having it.\
    \  If this were not so, participants using\n   different calculations for T_dither_max\
    \ might also have very\n   different mean waiting times before sending feedback,\
    \ which\n   translates into different reporting priorities.  For example, in a\n\
    \   scenario where T_rr = 1 s and the RTT = 100 ms, receivers using the\n   RTT\
    \ estimation would, on average, send more feedback than those not\n   using it.\
    \  This might partially cancel out the feedback suppression\n   mechanism and\
    \ even cause feedback implosion.  Also note that, in a\n   general case where\
    \ the losses are shared, the feedback suppression\n   mechanism works if the feedback\
    \ packets from each receiver have\n   enough time to reach each of the other ones\
    \ before the calculated\n   T_dither_max seconds.  Therefore, in scenarios of\
    \ very high bandwidth\n   (small T_rr), the calculated T_dither_max could be much\
    \ smaller than\n   the propagation delay between receivers, which would translate\
    \ into a\n   failure of the feedback suppression mechanism.  In these cases, one\n\
    \   solution could be to limit the bandwidth available to receivers (see\n   [10])\
    \ such that this does not happen.  Another solution could be to\n   develop a\
    \ mechanism for feedback suppression based on the RTT\n   estimation between senders.\
    \  This will not be discussed here and may\n   be the subject of another document.\
    \  Note, however, that a really\n   high bandwidth media stream is not that likely\
    \ to rely on this kind\n   of error repair in the first place.\n   In the following,\
    \ we define three representative sample scenarios.\n   We use the topology from\
    \ the previous section, T-16.  Most of the\n   agents contribute only little to\
    \ the simulations, because we\n   introduced an error rate only on the link between\
    \ the sender A1 and\n   the agent A2.\n   The first scenario represents those\
    \ cases, where losses are shared\n   between two agents.  One agent is located\
    \ upstream on the path\n   between the other agent and the sender.  Therefore,\
    \ agent A2 and\n   agent A5 see the same losses that are introduced on the link\
    \ between\n   the sender and agent A2.  Agents A6, A7, and A8 do not join the\
    \ RTP\n   session.  From the other agents, only agents A3 and A9 join.  All\n\
    \   agents are pure receivers, except A1, which is the sender.\n   The second\
    \ scenario also represents cases where losses are shared\n   between two agents,\
    \ but this time the agents are located on different\n   branches of the multicast\
    \ tree.  The delays to the sender are roughly\n   of the same magnitude.  Agents\
    \ A5 and A6 share the same losses.\n   Agents A3 and A9 join the RTP session,\
    \ but are pure receivers and do\n   not see any losses.\n   Finally, in the third\
    \ scenario, the losses are shared between two\n   agents, A5 and A6.  The same\
    \ agents as in the second scenario are\n   active.  However, the delays of the\
    \ links are different.  The delay\n   of the link between agents A2 and A5 is\
    \ reduced to 20 ms and between\n   A2 and A6 to 40 ms.\n   All agents beside agent\
    \ A1 are pure RTP receivers.  Thus, these\n   agents do not have an RTT estimation\
    \ to the source.  T_dither_max is\n   calculated with the above given formula,\
    \ depending only on T_rr and\n   l, which means that all agents should calculate\
    \ roughly the same\n   T_dither_max.\n"
- title: 6.1.  Feedback Suppression Performance
  contents:
  - "6.1.  Feedback Suppression Performance\n   The feedback suppression rate for\
    \ an agent is defined as the ratio of\n   the total number of feedback packets\
    \ not sent out of the total number\n   of feedback packets the agent intended\
    \ to send (i.e., the sum of sent\n   and not sent).  The reasons for not sending\
    \ a packet include: the\n   receiver already saw the same loss reported in a receiver\
    \ report\n   coming from another session member or the max_feedback_delay\n  \
    \ (application-specific) was surpassed.\n   The results for the feedback suppression\
    \ rate of the agent Af that is\n   further away from the sender are depicted in\
    \ Table 5.  In general, it\n   can be seen that the feedback suppression rate\
    \ increases as l\n   increases.  However there is a threshold, depending on the\n\
    \   environment, from which the additional gain is not significant\n   anymore.\n\
    \                  |      |  Feedback Suppression Rate  |\n                  |\
    \  l   | Scen. 1 | Scen. 2 | Scen. 3 |\n                  +------+---------+---------+---------+\n\
    \                  | 0.10 |  0.671  |  0.051  |  0.089  |\n                  |\
    \ 0.25 |  0.582  |  0.060  |  0.210  |\n                  | 0.50 |  0.524  | \
    \ 0.114  |  0.361  |\n                  | 0.75 |  0.523  |  0.180  |  0.370  |\n\
    \                  | 1.00 |  0.523  |  0.204  |  0.369  |\n                  |\
    \ 1.25 |  0.506  |  0.187  |  0.372  |\n                  | 1.50 |  0.536  | \
    \ 0.213  |  0.414  |\n                  | 1.75 |  0.526  |  0.215  |  0.424  |\n\
    \                  | 2.00 |  0.535  |  0.216  |  0.400  |\n                  |\
    \ 3.00 |  0.522  |  0.220  |  0.405  |\n                  | 4.00 |  0.522  | \
    \ 0.220  |  0.405  |\n    Table 5: Fraction of feedback that was suppressed at\
    \ agent (Af) of\n      the total number of feedback messages the agent wanted\
    \ to send\n   Similar results can be seen in Table 6 for the agent An that is\n\
    \   nearer to the sender.\n                  |      |  Feedback Suppression Rate\
    \  |\n                  |  l   | Scen. 1 | Scen. 2 | Scen. 3 |\n             \
    \     +------+---------+---------+---------+\n                  | 0.10 |  0.056\
    \  |  0.056  |  0.090  |\n                  | 0.25 |  0.063  |  0.055  |  0.166\
    \  |\n                  | 0.50 |  0.116  |  0.099  |  0.255  |\n             \
    \     | 0.75 |  0.141  |  0.141  |  0.312  |\n                  | 1.00 |  0.179\
    \  |  0.175  |  0.352  |\n                  | 1.25 |  0.206  |  0.176  |  0.361\
    \  |\n                  | 1.50 |  0.193  |  0.193  |  0.337  |\n             \
    \     | 1.75 |  0.197  |  0.204  |  0.341  |\n                  | 2.00 |  0.207\
    \  |  0.207  |  0.368  |\n                  | 3.00 |  0.196  |  0.203  |  0.359\
    \  |\n                  | 4.00 |  0.196  |  0.203  |  0.359  |\n    Table 6: Fraction\
    \ of feedback that was suppressed at agent (An) of\n      the total number of\
    \ feedback messages the agent wanted to send\n   The rate of feedback suppression\
    \ failure is depicted in Table 7.  The\n   trend of additional performance increase\
    \ is not significant beyond a\n   certain threshold.  Dependence on the scenario\
    \ is noticeable here as\n   well.\n                  |      |Feedback Suppr. Failure\
    \ Rate |\n                  |  l   | Scen. 1 | Scen. 2 | Scen. 3 |\n         \
    \         +------+---------+---------+---------+\n                  | 0.10 | \
    \ 0.273  |  0.893  |  0.822  |\n                  | 0.25 |  0.355  |  0.885  |\
    \  0.624  |\n                  | 0.50 |  0.364  |  0.787  |  0.385  |\n      \
    \            | 0.75 |  0.334  |  0.679  |  0.318  |\n                  | 1.00\
    \ |  0.298  |  0.621  |  0.279  |\n                  | 1.25 |  0.289  |  0.637\
    \  |  0.267  |\n                  | 1.50 |  0.274  |  0.595  |  0.249  |\n   \
    \               | 1.75 |  0.274  |  0.580  |  0.235  |\n                  | 2.00\
    \ |  0.258  |  0.577  |  0.233  |\n                  | 3.00 |  0.282  |  0.577\
    \  |  0.236  |\n                  | 4.00 |  0.282  |  0.577  |  0.236  |\n   \
    \        Table 7: The ratio of feedback suppression failures.\n   Summarizing\
    \ the feedback suppression results, it can be said that in\n   general the feedback\
    \ suppression performance increases as l\n   increases.  However, beyond a certain\
    \ threshold, depending on\n   environment parameters such as propagation delays\
    \ or session\n   bandwidth, the additional increase is not significant anymore.\
    \  This\n   threshold is not uniform across all scenarios; a value of l=0.5 seems\n\
    \   to produce reasonable results with acceptable (though not optimal)\n   overhead.\n"
- title: 6.2.  Loss Report Delay
  contents:
  - "6.2.  Loss Report Delay\n   In this section, we show the results for the measured\
    \ report delay\n   during the simulations of the three sample scenarios.  This\n\
    \   measurement is a metric of the performance of the algorithms, because\n  \
    \ the value of the feedback for the sender typically decreases with the\n   delay\
    \ of its reception.  The loss report delay is measured as the\n   time at the\
    \ sender between sending a packet and receiving the first\n   corresponding loss\
    \ report.\n                  |      |   Mean Loss Report Delay    |\n        \
    \          |  l   | Scen. 1 | Scen. 2 | Scen. 3 |\n                  +------+---------+---------+---------+\n\
    \                  | 0.10 |  0.124  |  0.282  |  0.210  |\n                  |\
    \ 0.25 |  0.168  |  0.266  |  0.234  |\n                  | 0.50 |  0.243  | \
    \ 0.264  |  0.284  |\n                  | 0.75 |  0.285  |  0.286  |  0.325  |\n\
    \                  | 1.00 |  0.329  |  0.305  |  0.350  |\n                  |\
    \ 1.25 |  0.351  |  0.329  |  0.370  |\n                  | 1.50 |  0.361  | \
    \ 0.363  |  0.388  |\n                  | 1.75 |  0.360  |  0.387  |  0.392  |\n\
    \                  | 2.00 |  0.367  |  0.412  |  0.400  |\n                  |\
    \ 3.00 |  0.368  |  0.507  |  0.398  |\n                  | 4.00 |  0.368  | \
    \ 0.568  |  0.398  |\n       Table 8: The mean loss report delay, measured at\
    \ the sender.\n   As can be seen from Table 8, the delay increases, in general,\
    \ as l\n   increases.  Also, a similar effect as for the feedback suppression\n\
    \   performance is present: beyond a certain threshold, the additional\n   increase\
    \ in delay is not significant anymore.  The threshold is\n   environment dependent\
    \ and seems to be related to the threshold, where\n   the feedback suppression\
    \ gain would not increase anymore.\n"
- title: 6.3.  Summary of "l" Investigations
  contents:
  - "6.3.  Summary of \"l\" Investigations\n   We have shown experimentally that the\
    \ performance of the feedback\n   suppression mechanisms increases as l increases.\
    \  The same applies\n   for the report delay, which also increases as l increases.\
    \  This\n   leads to a threshold where both the performance and the delay do not\n\
    \   increase any further.  The threshold is dependent upon the\n   environment.\n\
    \   So finding an optimum value of l is not possible because it is always\n  \
    \ a trade-off between delay and feedback suppression performance.  With\n   l=0.5,\
    \ we think that a trade-off was found that is acceptable for\n   typical applications\
    \ and environments.\n"
- title: 7.  Applications Using AVPF
  contents:
  - "7.  Applications Using AVPF\n   NEWPRED is one of the error resilience tools,\
    \ which is defined in\n   both ISO/IEC MPEG-4 visual part and ITU-T H.263.  NEWPRED\
    \ achieves\n   fast error recovery using feedback messages.  We simulated the\n\
    \   behavior of NEWPRED in the network simulator environment as described\n  \
    \ above and measured the waiting time statistics, in order to verify\n   that\
    \ the extended RTP profile for RTCP-based feedback (AVPF) [1] is\n   appropriate\
    \ for the NEWPRED feedback messages.  Simulation results,\n   which are presented\
    \ in the following sections, show that the waiting\n   time is small enough to\
    \ get the expected performance of NEWPRED.\n"
- title: 7.1.  NEWPRED Implementation in NS2
  contents:
  - "7.1.  NEWPRED Implementation in NS2\n   The agent that performs the NEWPRED functionality,\
    \ called NEWPRED\n   agent, is different from the RTP agent we described above.\
    \  Some of\n   the added features and functionalities are described in the following\n\
    \   points:\n   Application Feedback\n      The \"Application Layer Feedback Messages\"\
    \ format is used to\n      transmit the NEWPRED feedback messages.  Thereby the\
    \ NEWPRED\n      functionality is added to the RTP agent.  The NEWPRED agent\n\
    \      creates one NACK message for each lost segment of a video frame,\n    \
    \  and then assembles multiple NACK messages corresponding to the\n      segments\
    \ in the same video frame into one Application Layer\n      Feedback Message.\
    \  Although there are two modes, namely, NACK mode\n      and ACK mode, in NEWPRED\
    \ [6][7], only NACK mode is used in these\n      simulations.  In this simulation,\
    \ the RTP layer doesn't generate\n      feedback messages.  Instead, the decoder\
    \ (NEWPRED) generates a\n      NACK message when the segment cannot be decoded\
    \ because the data\n      hasn't arrived or loss of reference picture has occurred.\
    \  Those\n      conditions are detected in the decoder with frame number, segment\n\
    \      number, and existence of reference pictures in the decoder.\n   The parameters\
    \ of NEWPRED agent are as follows:\n        f: Frame Rate(frames/sec)\n      seg:\
    \ Number of segments in one video frame\n       bw: RTP session bandwidth(kbps)\n\
    \   Generation of NEWPRED's NACK Messages\n      The NEWPRED agent generates NACK\
    \ messages when segments are lost.\n      a. The NEWPRED agent generates multiple\
    \ NACK messages per one\n         video frame when multiple segments are lost.\
    \  These are\n         assembled into one Feedback Control Information (FCI) message\n\
    \         per video frame.  If there is no lost segment, no message is\n     \
    \    generated and sent.\n      b. The length of one NACK message is 4 bytes.\
    \  Let num be the\n         number of NACK messages in one video frame (1 <= num\
    \ <= seg).\n         Thus, 12+4*num bytes is the size of the low-delay RTCP feedback\n\
    \         message in a compound RTCP packet.\n   Measurements\n      We defined\
    \ two values to be measured:\n      - Recovery time\n        The recovery time\
    \ is measured as the time between the detection\n        of a lost segment and\
    \ reception of a recovered segment.  We\n        measured this \"recovery time\"\
    \ for each lost segment.\n      - Waiting time\n        The waiting time is the\
    \ additional delay due to the feedback\n        limitation of RTP.\n   Figure\
    \ 2 depicts the behavior of a NEWPRED agent when a loss occurs.\n   The recovery\
    \ time is approximated as follows:\n      (Recovery time) = (Waiting time) +\n\
    \                        (Transmission time for feedback message) +\n        \
    \                (Transmission time for media data)\n   Therefore, the waiting\
    \ time is derived as follows:\n      (Waiting time) = (Recovery time) - (Round-trip\
    \ delay), where\n      (Round-trip delay ) = (Transmission time for feedback message)\
    \ +\n                            (Transmission time for media data)\n        Picture\
    \ Reference                            |: Picture Segment\n                 ____________________\
    \                %: Lost Segment\n                /_    _    _    _    \\\n  \
    \             v/ \\  / \\  / \\  / \\    \\\n               v   \\v   \\v   \\\
    v   \\    \\\n   Sender   ---|----|----|----|----|----|---|------------->\n  \
    \                  \\    \\                 ^ \\\n                     \\    \\\
    \               /   \\\n                      \\    \\             /     \\\n\
    \                       \\    v           /       \\\n                       \
    \ \\    x         /         \\\n                         \\   Lost     /     \
    \      \\\n                          \\    x     /             \\\n   _____\n\
    \                           v    x   / NACK          v\n   Receiver ---------------|----%===-%----%----%----|----->\n\
    \                                |-a-|               |\n                     \
    \           |-------  b  -------|\n                          a: Waiting time\n\
    \                          b: Recover time (%: Video segments are lost)\n   Figure\
    \ 2: Relation between the measured values at the NEWPRED agent\n"
- title: 7.2.  Simulation
  contents:
  - "7.2.  Simulation\n   We conducted two simulations (Simulation A and Simulation\
    \ B).  In\n   Simulation A, the packets are dropped with a fixed packet loss rate\n\
    \   on a link between two NEWPRED agents.  In Simulation B, packet loss\n   occurs\
    \ due to congestion from other traffic sources, i.e., ftp\n   sessions.\n"
- title: 7.2.1.  Simulation A - Constant Packet Loss Rate
  contents:
  - "7.2.1.  Simulation A - Constant Packet Loss Rate\n   The network topology used\
    \ for this simulation is shown in Figure 3.\n                  Link 1        \
    \ Link 2        Link 3\n        +--------+      +------+       +------+      +--------+\n\
    \        | Sender |------|Router|-------|Router|------|Receiver|\n        +--------+\
    \      +------+       +------+      +--------+\n                 10(msec)    \
    \   x(msec)       10(msec)\n         Figure 3: Network topology that is used for\
    \ Simulation A\n   Link1 and link3 are error free, and each link delay is 10 msec.\n\
    \   Packets may get dropped on link2.  The packet loss rates (Plr) and\n   link\
    \ delay (D) are as follows:\n      D [ms] = {10, 50, 100, 200, 500}\n      Plr\
    \    = {0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2}\n   Session bandwidth, frame\
    \ rate, and the number of segments are shown\n   in Table 9.\n               +------------+----------+-------------+-----+\n\
    \               |Parameter ID| bw(kbps) |f (frame/sec)| seg |\n              \
    \ +------------+----------+-------------+-----+\n               | 32k-4-3    |\
    \     32   |      4      |  3  |\n               | 32k-5-3    |     32   |   \
    \   5      |  3  |\n               | 64k-5-3    |     64   |      5      |  3\
    \  |\n               | 64k-10-3   |     64   |     10      |  3  |\n         \
    \      | 128k-10-6  |    128   |     10      |  6  |\n               | 128k-15-6\
    \  |    128   |     15      |  6  |\n               | 384k-15-6  |    384   |\
    \     15      |  6  |\n               | 384k-30-6  |    384   |     30      |\
    \  6  |\n               | 512k-30-6  |    512   |     30      |  6  |\n      \
    \         | 1000k-30-9 |   1000   |     30      |  9  |\n               | 2000k-30-9\
    \ |   2000   |     30      |  9  |\n               +------------+----------+-------------+-----+\n\
    \              Table 9: Parameter sets of the NEWPRED agents\n   Figure 4 shows\
    \ the key values of the result (packet loss rate vs.\n   mean of waiting time).\n\
    \   When the packet loss rate is 5% and the session bandwidth is 32 kbps,\n  \
    \ the waiting time is around 400 msec, which is just allowable for\n   reasonable\
    \ NEWPRED performance.\n   When the packet loss rate is less than 1%, the waiting\
    \ time is less\n   than 200 msec.  In such a case, the NEWPRED allows as much\
    \ as\n   200-msec additional link delay.\n   When the packet loss rate is less\
    \ than 5% and the session bandwidth\n   is 64 kbps, the waiting time is also less\
    \ than 200 msec.\n   In 128-kbps cases, the result shows that when the packet\
    \ loss rate is\n   20%, the waiting time is around 200 msec.  In cases with more\
    \ than\n   512-kbps session bandwidth, there is no significant delay.  This\n\
    \   means that the waiting time due to the feedback limitation of RTCP is\n  \
    \ negligible for the NEWPRED performance.\n      +------------------------------------------------------------+\n\
    \      |           | Packet Loss Rate =                             |\n      |\
    \ Bandwidth | 0.005| 0.01 | 0.02 | 0.03 | 0.05 |0.10  |0.20  |\n      |-----------+------+------+------+------+------+------+------|\n\
    \      |       32k |130-  |200-  |230-  |280-  |350-  |470-  |560-  |\n      |\
    \           |   180|   250|   320|   390|   430|   610|   780|\n      |      \
    \ 64k | 80-  |100-  |120-  |150-  |180-  |210-  |290-  |\n      |           |\
    \   130|   150|   180|   190|   210|   300|   400|\n      |      128k | 60-  |\
    \ 70-  | 90-  |110-  |130-  |170-  |190-  |\n      |           |    70|    80|\
    \   100|   120|   140|   190|   240|\n      |      384k | 30-  | 30-  | 30-  |\
    \ 40-  | 50-  | 50-  | 50-  |\n      |           |    50|    50|    50|    50|\
    \    60|    70|    90|\n      |      512k | < 50 | < 50 | < 50 | < 50 | < 50 |\
    \ < 50 | < 60 |\n      |           |      |      |      |      |      |      |\
    \      |\n      |     1000k | < 50 | < 50 | < 50 | < 50 | < 50 | < 50 | < 55 |\n\
    \      |           |      |      |      |      |      |      |      |\n      |\
    \     2000k | < 30 | < 30 | < 30 | < 30 | < 30 | < 35 | < 35 |\n      +------------------+------+------+------+------+------+------+\n\
    \                   Figure 4: The result of simulation A\n"
- title: 7.2.2.  Simulation B - Packet Loss Due to Congestion
  contents:
  - "7.2.2.  Simulation B - Packet Loss Due to Congestion\n   The configurations of\
    \ link1, link2, and link3 are the same as in\n   Simulation A except that link2\
    \ is also error-free, regarding bit\n   errors.  However, in addition, some FTP\
    \ agents are deployed to\n   overload link2.  See Figure 5 for the simulation\
    \ topology.\n                   Link1         Link2          Link3\n        +--------+\
    \      +------+       +------+      +--------+\n        | Sender |------|Router|-------|Router|------|Receiver|\n\
    \        +--------+    /|+------+       +------+|\\    +--------+\n          \
    \      +---+/ |                       | \\+---+\n              +-|FTP|+---+  \
    \                 +---+|FTP|-+\n              | +---+|FTP| ...               |FTP|+---+\
    \ | ...\n              +---+  +---+                   +---+  +---+\n         \
    \      FTP Agents                      FTP Agents\n                Figure 5: Network\
    \ Topology of Simulation B\n   The parameters are defined as for Simulation A\
    \ with the following\n   values assigned:\n      D[ms] ={10, 50, 100, 200, 500}\
    \ 32 FTP agents are deployed at each\n      edge, for a total of 64 FTP agents\
    \ active.\n   The sets of session bandwidth, frame rate, and the number of segments\n\
    \   are the same as in Simulation A (Table 9).\n   We provide the results for\
    \ the cases with 64 FTP agents, because\n   these are the cases where packet losses\
    \ could be detected to be\n   stable.  The results are similar to those for Simulation\
    \ A except for\n   a constant additional offset of 50..100 ms.  This is due to\
    \ the delay\n   incurred by the routers' buffers.\n"
- title: 7.3.  Summary of Application Simulations
  contents:
  - "7.3.  Summary of Application Simulations\n   We have shown that the limitations\
    \ of RTP AVPF profile do not\n   generate such high delay in the feedback messages\
    \ that the\n   performance of NEWPRED is degraded for sessions from 32 kbps to\
    \ 2\n   Mbps.  We could see that the waiting time increases with a decreasing\n\
    \   session bandwidth and/or an increasing packet loss rate.  The cause\n   of\
    \ the packet loss is not significant; congestion and constant packet\n   loss\
    \ rates behave similarly.  Still we see that for reasonable\n   conditions and\
    \ parameters the AVPF is well suited to support the\n   feedback needed for NEWPRED.\
    \  For more information about NEWPRED, see\n   [8] and [9].\n"
- title: 8.  Summary
  contents:
  - "8.  Summary\n   The new RTP profile AVPF was investigated regarding performance\
    \ and\n   potential risks to the network stability.  Simulations were conducted\n\
    \   using the network simulator ns2, simulating unicast and several\n   differently\
    \ sized multicast topologies.  The results were shown in\n   this document.\n\
    \   Regarding the network stability, it was important to show that the\n   new\
    \ profile does not lead to any feedback implosion or use more\n   bandwidth than\
    \ it is allowed.  We measured the bandwidth that was\n   used for RTCP in relation\
    \ to the RTP session bandwidth.  We have\n   shown that, more or less exactly,\
    \ 5% of the session bandwidth is used\n   for RTCP, in all considered scenarios.\
    \  Other RTCP bandwidth values\n   could be set using the RTCP bandwidth modifiers\
    \ [10].  The scenarios\n   included unicast with and without errors, differently\
    \ sized multicast\n   groups, with and without errors or congestion on the links.\
    \  Thus, we\n   can say that the new profile behaves in a network-friendly manner\
    \ in\n   the sense that it uses only the allowed RTCP bandwidth, as defined by\n\
    \   RTP.\n   Secondly, we have shown that receivers using the new profile\n  \
    \ experience a performance gain.  This was measured by capturing the\n   delay\
    \ that the sender sees for the received feedback.  Using the new\n   profile,\
    \ this delay can be decreased by orders of magnitude.\n   In the third place,\
    \ we investigated the effect of the parameter \"l\"\n   on the new algorithms.\
    \  We have shown that there does not exist an\n   optimum value for it but only\
    \ a trade-off can be achieved.  The\n   influence of this parameter is highly\
    \ environment-specific and a\n   trade-off between performance of the feedback\
    \ suppression algorithm\n   and the experienced delay has to be met.  The recommended\
    \ value of\n   l=0.5 given in this document seems to be reasonable for most\n\
    \   applications and environments.\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   This document describes the simulation work carried\
    \ out to verify the\n   correct working of the RTCP timing rules specified in\
    \ the AVPF\n   profile [1].  Consequently, security considerations concerning\
    \ these\n   timing rules are described in that document.\n"
- title: 10.  Normative References
  contents:
  - "10.  Normative References\n   [1]  Ott, J., Wenger, S., Sato, N., Burmeister,\
    \ C., and J. Rey,\n        \"Extended RTP Profile for Real-time Transport Control\
    \ Protocol\n        (RTCP)-Based Feedback (RTP/AVPF)\", RFC 4585, July 2006.\n"
- title: 11.  Informative References
  contents:
  - "11.  Informative References\n   [2]  Schulzrinne, H., Casner, S., Frederick,\
    \ R., and V. Jacobson,\n        \"RTP: A Transport Protocol for Real-Time Applications\"\
    , STD 64,\n        RFC 3550, July 2003.\n   [3]  Schulzrinne, H. and S. Casner,\
    \ \"RTP Profile for Audio and Video\n        Conferences with Minimal Control\"\
    , STD 65, RFC 3551, July 2003.\n   [4]  Network Simulator Version 2 - ns-2, available\
    \ from\n        http://www.isi.edu/nsnam/ns.\n   [5]  C. Burmeister, T. Klinner,\
    \ \"Low Delay Feedback RTCP - Timing\n        Rules Simulation Results\".  Technical\
    \ Report of the Panasonic\n        European Laboratories, September 2001, available\
    \ from:\n        http://www.informatik.uni-bremen.de/~jo/misc/\n        SimulationResults-A.pdf.\n\
    \   [6]  ISO/IEC 14496-2:1999/Amd.1:2000, \"Information technology -\n       \
    \ Coding of audio-visual objects - Part2: Visual\", July 2000.\n   [7]  ITU-T\
    \ Recommendation, H.263.  Video encoding for low bitrate\n        communication.\
    \  1998.\n   [8]  S. Fukunaga, T. Nakai, and H. Inoue, \"Error Resilient Video\n\
    \        Coding by Dynamic Replacing of Reference Pictures\", IEEE Global\n  \
    \      Telecommunications Conference (GLOBECOM), pp.1503-1508, 1996.\n   [9] \
    \ H. Kimata, Y. Tomita, H. Yamaguchi, S. Ichinose, T. Ichikawa,\n        \"Receiver-Oriented\
    \ Real-Time Error Resilient Video Communication\n        System: Adaptive Recovery\
    \ from Error Propagation in Accordance\n        with Memory Size at Receiver\"\
    , Electronics and Communications in\n        Japan, Part 1, vol. 84, no. 2, pp.8-17,\
    \ 2001.\n   [10] Casner, S., \"Session Description Protocol (SDP) Bandwidth\n\
    \        Modifiers for RTP Control Protocol (RTCP) Bandwidth\", RFC 3556,\n  \
    \      July 2003.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Carsten Burmeister\n   Panasonic R&D Center Germany GmbH\n\
    \   Monzastr. 4c\n   D-63225 Langen, Germany\n   EMail: carsten.burmeister@eu.panasonic.com\n\
    \   Rolf Hakenberg\n   Panasonic R&D Center Germany GmbH\n   Monzastr. 4c\n  \
    \ D-63225 Langen, Germany\n   EMail: rolf.hakenberg@eu.panasonic.com\n   Akihiro\
    \ Miyazaki\n   Matsushita Electric Industrial Co., Ltd\n   1006, Kadoma, Kadoma\
    \ City, Osaka, Japan\n   EMail: miyazaki.akihiro@jp.panasonic.com\n   Joerg Ott\n\
    \   Helsinki University of Technology, Networking Laboratory\n   PO Box 3000,\
    \ 02015 TKK, Finland\n   EMail: jo@acm.org\n   Noriyuki Sato\n   Oki Electric\
    \ Industry Co., Ltd.\n   1-16-8 Chuo, Warabi, Saitama 335-8510 Japan\n   EMail:\
    \ sato652@oki.com\n   Shigeru Fukunaga\n   Oki Electric Industry Co., Ltd.\n \
    \  2-5-7 Hommachi, Chuo-ku, Osaka 541-0053 Japan\n   EMail: fukunaga444@oki.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2006).\n   This\
    \ document is subject to the rights, licenses and restrictions\n   contained in\
    \ BCP 78, and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET\n   ENGINEERING\
    \ TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT\
    \ LIMITED TO ANY WARRANTY THAT THE USE OF THE\n   INFORMATION HEREIN WILL NOT\
    \ INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS\
    \ FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at\n   ietf-ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is provided by the IETF\n\
    \   Administrative Support Activity (IASA).\n"
