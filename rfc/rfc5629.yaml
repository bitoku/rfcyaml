- title: __initial_text__
  contents:
  - "                A Framework for Application Interaction\n                in the\
    \ Session Initiation Protocol (SIP)\n"
- title: Abstract
  contents:
  - "Abstract\n   This document describes a framework for the interaction between\
    \ users\n   and Session Initiation Protocol (SIP) based applications.  By\n  \
    \ interacting with applications, users can guide the way in which they\n   operate.\
    \  The focus of this framework is stimulus signaling, which\n   allows a user\
    \ agent (UA) to interact with an application without\n   knowledge of the semantics\
    \ of that application.  Stimulus signaling\n   can occur to a user interface running\
    \ locally with the client, or to\n   a remote user interface, through media streams.\
    \  Stimulus signaling\n   encompasses a wide range of mechanisms, ranging from\
    \ clicking on\n   hyperlinks, to pressing buttons, to traditional Dual-Tone Multi-\n\
    \   Frequency (DTMF) input.  In all cases, stimulus signaling is\n   supported\
    \ through the use of markup languages, which play a key role\n   in this framework.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document specifies an Internet standards track protocol\
    \ for the\n   Internet community, and requests discussion and suggestions for\n\
    \   improvements.  Please refer to the current edition of the \"Internet\n   Official\
    \ Protocol Standards\" (STD 1) for the standardization state\n   and status of\
    \ this protocol.  Distribution of this memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2009 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the BSD License.\n   This document may\
    \ contain material from IETF Documents or IETF\n   Contributions published or\
    \ made publicly available before November\n   10, 2008.  The person(s) controlling\
    \ the copyright in some of this\n   material may not have granted the IETF Trust\
    \ the right to allow\n   modifications of such material outside the IETF Standards\
    \ Process.\n   Without obtaining an adequate license from the person(s) controlling\n\
    \   the copyright in such materials, this document may not be modified\n   outside\
    \ the IETF Standards Process, and derivative works of it may\n   not be created\
    \ outside the IETF Standards Process, except to format\n   it for publication\
    \ as an RFC or to translate it into languages other\n   than English.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction . . . . . . . . . . . . . . . . . . .\
    \ . . . . . .  4\n   2.  Conventions Used in This Document  . . . . . . . . .\
    \ . . . . .  4\n   3.  Definitions  . . . . . . . . . . . . . . . . . . . . .\
    \ . . . .  4\n   4.  A Model for Application Interaction  . . . . . . . . . .\
    \ . . .  7\n     4.1.  Functional vs. Stimulus  . . . . . . . . . . . . . . .\
    \ . .  9\n     4.2.  Real-Time vs. Non-Real-Time  . . . . . . . . . . . . . .\
    \ . 10\n     4.3.  Client-Local vs. Client-Remote . . . . . . . . . . . . . .\
    \ 10\n     4.4.  Presentation-Capable vs. Presentation-Free . . . . . . . . 11\n\
    \   5.  Interaction Scenarios on Telephones  . . . . . . . . . . . . . 11\n  \
    \   5.1.  Client Remote  . . . . . . . . . . . . . . . . . . . . . . 12\n    \
    \ 5.2.  Client Local . . . . . . . . . . . . . . . . . . . . . . . 12\n     5.3.\
    \  Flip-Flop  . . . . . . . . . . . . . . . . . . . . . . . . 13\n   6.  Framework\
    \ Overview . . . . . . . . . . . . . . . . . . . . . . 13\n   7.  Deployment Topologies\
    \  . . . . . . . . . . . . . . . . . . . . 16\n     7.1.  Third-Party Application\
    \  . . . . . . . . . . . . . . . . . 16\n     7.2.  Co-Resident Application  .\
    \ . . . . . . . . . . . . . . . . 17\n     7.3.  Third-Party Application and User\
    \ Device Proxy  . . . . . . 18\n     7.4.  Proxy Application  . . . . . . . .\
    \ . . . . . . . . . . . . 19\n   8.  Application Behavior . . . . . . . . . .\
    \ . . . . . . . . . . . 19\n     8.1.  Client-Local Interfaces  . . . . . . .\
    \ . . . . . . . . . . 20\n       8.1.1.  Discovering Capabilities . . . . . .\
    \ . . . . . . . . . 20\n       8.1.2.  Pushing an Initial Interface Component\
    \ . . . . . . . . 20\n       8.1.3.  Updating an Interface Component  . . . .\
    \ . . . . . . . 22\n       8.1.4.  Terminating an Interface Component . . . .\
    \ . . . . . . 22\n     8.2.  Client-Remote Interfaces . . . . . . . . . . . .\
    \ . . . . . 23\n       8.2.1.  Originating and Terminating Applications . . .\
    \ . . . . 23\n       8.2.2.  Intermediary Applications  . . . . . . . . . . .\
    \ . . . 24\n   9.  User Agent Behavior  . . . . . . . . . . . . . . . . . . .\
    \ . . 24\n     9.1.  Advertising Capabilities . . . . . . . . . . . . . . . .\
    \ . 24\n     9.2.  Receiving User Interface Components  . . . . . . . . . . .\
    \ 25\n     9.3.  Mapping User Input to User Interface Components  . . . . . 26\n\
    \     9.4.  Receiving Updates to User Interface Components . . . . . . 27\n  \
    \   9.5.  Terminating a User Interface Component . . . . . . . . . . 27\n   10.\
    \ Inter-Application Feature Interaction  . . . . . . . . . . . . 27\n     10.1.\
    \ Client-Local UI  . . . . . . . . . . . . . . . . . . . . . 28\n     10.2. Client-Remote\
    \ UI . . . . . . . . . . . . . . . . . . . . . 29\n   11. Intra Application Feature\
    \ Interaction  . . . . . . . . . . . . 29\n   12. Example Call Flow  . . . . .\
    \ . . . . . . . . . . . . . . . . . 30\n   13. Security Considerations  . . .\
    \ . . . . . . . . . . . . . . . . 36\n   14. Contributors . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . 36\n   15. Acknowledgements . . . . . . . . .\
    \ . . . . . . . . . . . . . . 36\n   16. References . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . 36\n     16.1. Normative References . . . . . . .\
    \ . . . . . . . . . . . . 36\n     16.2. Informative References . . . . . . .\
    \ . . . . . . . . . . . 37\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The Session Initiation Protocol (SIP) [2] provides the ability\
    \ for\n   users to initiate, manage, and terminate communications sessions.\n\
    \   Frequently, these sessions will involve a SIP application.  A SIP\n   application\
    \ is defined as a program running on a SIP-based element\n   (such as a proxy\
    \ or user agent) that provides some value-added\n   function to a user or system\
    \ administrator.  Examples of SIP\n   applications include prepaid calling card\
    \ calls, conferencing, and\n   presence-based [12] call routing.\n   In order\
    \ for most applications to properly function, they need input\n   from the user\
    \ to guide their operation.  As an example, a prepaid\n   calling card application\
    \ requires the user to input their calling\n   card number, their PIN code, and\
    \ the destination number they wish to\n   reach.  The process by which a user\
    \ provides input to an application\n   is called \"application interaction\".\n\
    \   Application interaction can be either functional or stimulus.\n   Functional\
    \ interaction requires the user device to understand the\n   semantics of the\
    \ application, whereas stimulus interaction does not.\n   Stimulus signaling allows\
    \ for applications to be built without\n   requiring modifications to the user\
    \ device.  Stimulus interaction is\n   the subject of this framework.  The framework\
    \ provides a model for\n   how users interact with applications through user interfaces,\
    \ and how\n   user interfaces and applications can be distributed throughout a\n\
    \   network.  This model is then used to describe how applications can\n   instantiate\
    \ and manage user interfaces.\n"
- title: 2.  Conventions Used in This Document
  contents:
  - "2.  Conventions Used in This Document\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in [1]\n"
- title: 3.  Definitions
  contents:
  - "3.  Definitions\n   SIP Application:  A SIP application is defined as a program\
    \ running\n      on a SIP-based element (such as a proxy or user agent) that\n\
    \      provides some value-added function to a user or system\n      administrator.\
    \  Examples of SIP applications include prepaid\n      calling card calls, conferencing,\
    \ and presence-based [12] call\n      routing.\n   Application Interaction:  The\
    \ process by which a user provides input\n      to an application.\n   Real-Time\
    \ Application Interaction:  Application interaction that\n      takes place while\
    \ an application instance is executing.  For\n      example, when a user enters\
    \ their PIN number into a prepaid\n      calling card application, this is real-time\
    \ application\n      interaction.\n   Non-Real-Time Application Interaction: \
    \ Application interaction that\n      takes place asynchronously with the execution\
    \ of the application.\n      Generally, non-real-time application interaction\
    \ is accomplished\n      through provisioning.\n   Functional Application Interaction:\
    \  Application interaction is\n      functional when the user device has an understanding\
    \ of the\n      semantics of the interaction with the application.\n   Stimulus\
    \ Application Interaction:  Application interaction is\n      stimulus when the\
    \ user device has no understanding of the\n      semantics of the interaction\
    \ with the application.\n   User Interface (UI):  The user interface provides\
    \ the user with\n      context to make decisions about what they want.  The user\n\
    \      interacts with the device, which conveys the user input to the\n      user\
    \ interface.  The user interface interprets the information and\n      passes\
    \ it to the application.\n   User Interface Component:  A piece of user interface\
    \ that operates\n      independently of other pieces of the user interface.  For\
    \ example,\n      a user might have two separate web interfaces to a prepaid calling\n\
    \      card application: one for hanging up and making another call, and\n   \
    \   another for entering the username and PIN.\n   User Device:  The software\
    \ or hardware system that the user directly\n      interacts with to communicate\
    \ with the application.  An example of\n      a user device is a telephone.  Another\
    \ example is a PC with a web\n      browser.\n   User Device Proxy:  A software\
    \ or hardware system that a user\n      indirectly interacts through to communicate\
    \ with the application.\n      This indirection can be through a network.  An\
    \ example is a\n      gateway from IP to the Public Switched Telephone Network\
    \ (PSTN).\n      It acts as a user device proxy, acting on behalf of the user\
    \ on\n      the circuit network.\n   User Input:  The \"raw\" information passed\
    \ from a user to a user\n      interface.  Examples of user input include a spoken\
    \ word or a\n      click on a hyperlink.\n   Client-Local User Interface:  A user\
    \ interface that is co-resident\n      with the user device.\n   Client-Remote\
    \ User Interface:  A user interface that executes\n      remotely from the user\
    \ device.  In this case, a standardized\n      interface is needed between the\
    \ user device and the user\n      interface.  Typically, this is done through\
    \ media sessions: audio,\n      video, or application sharing.\n   Markup Language:\
    \  A markup language describes a logical flow of\n      presentation of information\
    \ to the user, collection of information\n      from the user, and transmission\
    \ of that information to an\n      application.\n   Media Interaction:  A means\
    \ of separating a user and a user interface\n      by connecting them with media\
    \ streams.\n   Interactive Voice Response (IVR):  An IVR is a type of user interface\n\
    \      that allows users to speak commands to the application, and hear\n    \
    \  responses to those commands prompting for more information.\n   Prompt-and-Collect:\
    \  The basic primitive of an IVR user interface.\n      The user is presented\
    \ with a voice option, and the user speaks\n      their choice.\n   Barge-In:\
    \  The act of entering information into an IVR user interface\n      prior to\
    \ the completion of a prompt requesting that information.\n   Focus:  A user interface\
    \ component has focus when user input is\n      provided to it, as opposed to\
    \ any other user interface components.\n      This is not to be confused with\
    \ the term \"focus\" within the SIP\n      conferencing framework, which refers\
    \ to the center user agent in a\n      conference [14].\n   Focus Determination:\
    \  The process by which the user device determines\n      which user interface\
    \ component will receive the user input.\n   Focusless Device:  A user device\
    \ that has no ability to perform focus\n      determination.  An example of a\
    \ focusless device is a telephone\n      with a keypad.\n   Presentation-Capable\
    \ UI:  A user interface that can prompt the user\n      with input, collect results,\
    \ and then prompt the user with new\n      information based on those results.\n\
    \   Presentation-Free UI:  A user interface that cannot prompt the user\n    \
    \  with information.\n   Feature Interaction:  A class of problems that result\
    \ when multiple\n      applications or application components are trying to provide\n\
    \      services to a user at the same time.\n   Inter-Application Feature Interaction:\
    \  Feature interactions that\n      occur between applications.\n   DTMF:  Dual-Tone\
    \ Multi-Frequency.  DTMF refers to a class of tones\n      generated by circuit-switched\
    \ telephony devices when the user\n      presses a key on the keypad.  As a result,\
    \ DTMF and keypad input\n      are often used synonymously, when in fact one of\
    \ them (DTMF) is\n      merely a means of conveying the other (the keypad input)\
    \ to a\n      client-remote user interface (the switch, for example).\n   Application\
    \ Instance:  A single execution path of a SIP application.\n   Originating Application:\
    \  A SIP application that acts as a User Agent\n      Client (UAC), making a call\
    \ on behalf of the user.\n   Terminating Application:  A SIP application that\
    \ acts as a User Agent\n      Server (UAS), answering a call generated by a user.\
    \  IVR\n      applications are terminating applications.\n   Intermediary Application:\
    \  A SIP application that is neither the\n      caller or callee, but rather a\
    \ third party involved in a call.\n"
- title: 4.  A Model for Application Interaction
  contents:
  - "4.  A Model for Application Interaction\n         +---+            +---+    \
    \        +---+             +---+\n         |   |            |   |            |\
    \   |             |   |\n         |   |            | U |            | U |    \
    \         | A |\n         |   |   Input    | s |   Input    | s |   Results  \
    \ | p |\n         |   | ---------> | e | ---------> | e | ----------> | p |\n\
    \         | U |            | r |            | r |             | l |\n        \
    \ | s |            |   |            |   |             | i |\n         | e |  \
    \          | D |            | I |             | c |\n         | r |   Output \
    \  | e |   Output   | f |   Update    | a |\n         |   | <--------- | v | <---------\
    \ | a | <.......... | t |\n         |   |            | i |            | c |  \
    \           | i |\n         |   |            | c |            | e |          \
    \   | o |\n         |   |            | e |            |   |             | n |\n\
    \         |   |            |   |            |   |             |   |\n        \
    \ +---+            +---+            +---+             +---+\n                Figure\
    \ 1: Model for Real-Time Interactions\n   Figure 1 presents a general model for\
    \ how users interact with\n   applications.  Generally, users interact with a\
    \ user interface\n   through a user device.  A user device can be a telephone,\
    \ or it can\n   be a PC with a web browser.  Its role is to pass the user input\
    \ from\n   the user to the user interface.  The user interface provides the user\n\
    \   with context in order to make decisions about what they want.  The\n   user\
    \ interacts with the device, causing information to be passed from\n   the device\
    \ to the user interface.  The user interface interprets the\n   information, and\
    \ passes it as a user interface event to the\n   application.  The application\
    \ may be able to modify the user\n   interface based on this event.  Whether or\
    \ not this is possible\n   depends on the type of user interface.\n   User interfaces\
    \ are fundamentally about rendering and interpretation.\n   Rendering refers to\
    \ the way in which the user is provided context.\n   This can be through hyperlinks,\
    \ images, sounds, videos, text, and so\n   on.  Interpretation refers to the way\
    \ in which the user interface\n   takes the \"raw\" data provided by the user,\
    \ and returns the result to\n   the application as a meaningful event, abstracted\
    \ from the\n   particulars of the user interface.  As an example, consider a prepaid\n\
    \   calling card application.  The user interface worries about details\n   such\
    \ as what prompt the user is provided, whether the voice is male\n   or female,\
    \ and so on.  It is concerned with recognizing the speech\n   that the user provides,\
    \ in order to obtain the desired information.\n   In this case, the desired information\
    \ is the calling card number, the\n   PIN code, and the destination number.  The\
    \ application needs that\n   data, and it doesn't matter to the application whether\
    \ it was\n   collected using a male prompt or a female one.\n   User interfaces\
    \ generally have real-time requirements towards the\n   user.  That is, when a\
    \ user interacts with the user interface, the\n   user interface needs to react\
    \ quickly, and that change needs to be\n   propagated to the user right away.\
    \  However, the interface between\n   the user interface and the application need\
    \ not be that fast.  Faster\n   is better, but the user interface itself can frequently\
    \ compensate\n   for long latencies between the user interface and the application.\n\
    \   In the case of a prepaid calling card application, when the user is\n   prompted\
    \ to enter their PIN, the prompt should generally stop\n   immediately once the\
    \ first digit of the PIN is entered.  This is\n   referred to as \"barge-in\"\
    .  After the user interface collects the\n   rest of the PIN, it can tell the\
    \ user to \"please wait while\n   processing\".  The PIN can then be gradually\
    \ transmitted to the\n   application.  In this example, the user interface has\
    \ compensated for\n   a slow UI to application interface by asking the user to\
    \ wait.\n   The separation between user interface and application is absolutely\n\
    \   fundamental to the entire framework provided in this document.  Its\n   importance\
    \ cannot be overstated.\n   With this basic model, we can begin to taxonomize\
    \ the types of\n   systems that can be built.\n"
- title: 4.1.  Functional vs. Stimulus
  contents:
  - "4.1.  Functional vs. Stimulus\n   The first way to taxonomize the system is to\
    \ consider the interface\n   between the UI and the application.  There are two\
    \ fundamentally\n   different models for this interface.  In a functional interface,\
    \ the\n   user interface has detailed knowledge about the application and is,\n\
    \   in fact, specific to the application.  The interface between the two\n   components\
    \ is through a functional protocol, capable of representing\n   the semantics\
    \ that can be exposed through the user interface.\n   Because the user interface\
    \ has knowledge of the application, it can\n   be optimally designed for that\
    \ application.  As a result, functional\n   user interfaces are almost always\
    \ the most user friendly, the\n   fastest, and the most responsive.  However,\
    \ in order to allow\n   interoperability between user devices and applications,\
    \ the details\n   of the functional protocols need to be specified in standards.\
    \  This\n   slows down innovation and limits the scope of applications that can\n\
    \   be built.\n   An alternative is a stimulus interface.  In a stimulus interface,\
    \ the\n   user interface is generic -- that is, totally ignorant of the details\n\
    \   of the application.  Indeed, the application may pass instructions to\n  \
    \ the user interface describing how it should operate.  The user\n   interface\
    \ translates user input into \"stimulus\", which are data\n   understood only\
    \ by the application, and not by the user interface.\n   Because they are generic,\
    \ and because they require communications\n   with the application in order to\
    \ change the way in which they render\n   information to the user, stimulus user\
    \ interfaces are usually slower,\n   less user friendly, and less responsive than\
    \ a functional\n   counterpart.  However, they allow for substantial innovation\
    \ in\n   applications, since no standardization activity is needed to build a\n\
    \   new application, as long as it can interact with the user within the\n   confines\
    \ of the user interface mechanism.  The web is an example of a\n   stimulus user\
    \ interface to applications.\n   In SIP systems, functional interfaces are provided\
    \ by extending the\n   SIP protocol to provide the needed functionality.  For\
    \ example, the\n   SIP caller preferences specification [15] provides a functional\n\
    \   interface that allows a user to request applications to route the\n   call\
    \ to specific types of user agents.  Functional interfaces are\n   important,\
    \ but are not the subject of this framework.  The primary\n   goal of this framework\
    \ is to address the role of stimulus interfaces\n   to SIP applications.\n"
- title: 4.2.  Real-Time vs. Non-Real-Time
  contents:
  - "4.2.  Real-Time vs. Non-Real-Time\n   Application interaction systems can also\
    \ be real-time or non-real-\n   time.  Non-real-time interaction allows the user\
    \ to enter information\n   about application operation asynchronously with its\
    \ invocation.\n   Frequently, this is done through provisioning systems.  As an\n\
    \   example, a user can set up the forwarding number for a call-forward\n   on\
    \ no-answer application using a web page.  Real-time interaction\n   requires\
    \ the user to interact with the application at the time of its\n   invocation.\n"
- title: 4.3.  Client-Local vs. Client-Remote
  contents:
  - "4.3.  Client-Local vs. Client-Remote\n   Another axis in the taxonomization is\
    \ whether the user interface is\n   co-resident with the user device (which we\
    \ refer to as a client-local\n   user interface), or the user interface runs in\
    \ a host separated from\n   the client (which we refer to as a client-remote user\
    \ interface).  In\n   a client-remote user interface, there exists some kind of\
    \ protocol\n   between the client device and the UI that allows the client to\n\
    \   interact with the user interface over a network.\n   The most important way\
    \ to separate the UI and the client device is\n   through media interaction. \
    \ In media interaction, the interface\n   between the user and the user interface\
    \ is through media: audio,\n   video, messaging, and so on.  This is the classic\
    \ mode of operation\n   for VoiceXML [5], where the user interface (also referred\
    \ to as the\n   voice browser) runs on a platform in the network.  Users communicate\n\
    \   with the voice browser through the telephone network (or using a SIP\n   session).\
    \  The voice browser interacts with the application using\n   HTTP to convey the\
    \ information collected from the user.\n   In the case of a client-local user\
    \ interface, the user interface runs\n   co-located with the user device.  The\
    \ interface between them is\n   through the software that interprets the user's\
    \ input and passes it\n   to the user interface.  The classic example of this\
    \ is the Web.  In\n   the Web, the user interface is a web browser, and the interface\
    \ is\n   defined by the HTML document that it's rendering.  The user interacts\n\
    \   directly with the user interface running in the browser.  The results\n  \
    \ of that user interface are sent to the application (running on the\n   web server)\
    \ using HTTP.\n   It is important to note that whether or not the user interface\
    \ is\n   local or remote (in the case of media interaction) is not a property\n\
    \   of the modality of the interface, but rather a property of the\n   system.\
    \  As an example, it is possible for a Web-based user interface\n   to be provided\
    \ with a client-remote user interface.  In such a\n   scenario, video- and application-sharing\
    \ media sessions can be used\n   between the user and the user interface.  The\
    \ user interface, still\n   guided by HTML, now runs \"in the network\", remote\
    \ from the client.\n   Similarly, a VoiceXML document can be interpreted locally\
    \ by a client\n   device, with no media streams at all.  Indeed, the VoiceXML\
    \ document\n   can be rendered using text, rather than media, with no impact on\
    \ the\n   interface between the user interface and the application.\n   It is\
    \ also important to note that systems can be hybrid.  In a hybrid\n   user interface,\
    \ some aspects of it (usually those associated with a\n   particular modality)\
    \ run locally, and others run remotely.\n"
- title: 4.4.  Presentation-Capable vs. Presentation-Free
  contents:
  - "4.4.  Presentation-Capable vs. Presentation-Free\n   A user interface can be\
    \ capable of presenting information to the user\n   (a presentation-capable UI),\
    \ or it can be capable only of collecting\n   user input (a presentation-free\
    \ UI).  These are very different types\n   of user interfaces.  A presentation-capable\
    \ UI can provide the user\n   with feedback after every input, providing the context\
    \ for collecting\n   the next input.  As a result, presentation-capable user interfaces\n\
    \   require an update to the information provided to the user after each\n   input.\
    \  The Web is a classic example of this.  After every input\n   (i.e., a click),\
    \ the browser provides the input to the application\n   and fetches the next page\
    \ to render.  In a presentation-free user\n   interface, this is not the case.\
    \  Since the user is not provided with\n   feedback, these user interfaces tend\
    \ to merely collect information as\n   it's entered, and pass it to the application.\n\
    \   Another difference is that a presentation-free user interface cannot\n   easily\
    \ support the concept of a focus.  Selection of a focus usually\n   requires a\
    \ means for informing the user of the available\n   applications, allowing the\
    \ user to choose, and then informing them\n   about which one they have chosen.\
    \  Without the first and third steps\n   (which a presentation-free UI cannot\
    \ provide), focus selection is\n   very difficult.  Without a selected focus,\
    \ the input provided to\n   applications through presentation-free user interfaces\
    \ is more of a\n   broadcast or notification operation.\n"
- title: 5.  Interaction Scenarios on Telephones
  contents:
  - "5.  Interaction Scenarios on Telephones\n   In this section, we apply the model\
    \ of Section 4 to telephones.\n   In a traditional telephone, the user interface\
    \ consists of a 12-key\n   keypad, a speaker, and a microphone.  Indeed, from\
    \ here forward, the\n   term \"telephone\" is used to represent any device that\
    \ meets, at a\n   minimum, the characteristics described in the previous sentence.\n\
    \   Circuit-switched telephony applications are almost universally\n   client-remote\
    \ user interfaces.  In the Public Switched Telephone\n   Network (PSTN), there\
    \ is usually a circuit interface between the user\n   and the user interface.\
    \  The user input from the keypad is conveyed\n   using Dual-Tone Multi-Frequency\
    \ (DTMF), and the microphone input as\n   Pulse Code Modulated (PCM) encoded voice.\n\
    \   In an IP-based system, there is more variability in how the system\n   can\
    \ be instantiated.  Both client-remote and client-local user\n   interfaces to\
    \ a telephone can be provided.\n   In this framework, a PSTN gateway can be considered\
    \ a User Device\n   Proxy.  It is a proxy for the user because it can provide,\
    \ to a user\n   interface on an IP network, input taken from a user on a circuit-\n\
    \   switched telephone.  The gateway may be able to run a client-local\n   user\
    \ interface, just as an IP telephone might.\n"
- title: 5.1.  Client Remote
  contents:
  - "5.1.  Client Remote\n   The most obvious instantiation is the \"classic\" circuit-switched\n\
    \   telephony model.  In that model, the user interface runs remotely\n   from\
    \ the client.  The interface between the user and the user\n   interface is through\
    \ media, which is set up by SIP and carried over\n   the Real Time Transport Protocol\
    \ (RTP) [18].  The microphone input\n   can be carried using any suitable voice-encoding\
    \ algorithm.  The\n   keypad input can be conveyed in one of two ways.  The first\
    \ is to\n   convert the keypad input to DTMF, and then convey that DTMF using\
    \ a\n   suitable encoding algorithm (such as PCMU).  An alternative, and\n   generally\
    \ the preferred approach, is to transmit the keypad input\n   using RFC 4733 [19],\
    \ which provides an encoding mechanism for\n   carrying keypad input within RTP.\n\
    \   In this classic model, the user interface would run on a server in\n   the\
    \ IP network.  It would perform speech recognition and DTMF\n   recognition to\
    \ derive the user intent, feed them through the user\n   interface, and provide\
    \ the result to an application.\n"
- title: 5.2.  Client Local
  contents:
  - "5.2.  Client Local\n   An alternative model is for the entire user interface\
    \ to reside on\n   the telephone.  The user interface can be a VoiceXML browser,\
    \ running\n   speech recognition on the microphone input, and feeding the keypad\n\
    \   input directly into the script.  As discussed above, the VoiceXML\n   script\
    \ could be rendered using text instead of voice, if the\n   telephone has a textual\
    \ display.\n   For simpler phones without a display, the user interface can be\n\
    \   described by a Keypad Markup Language request document [8].  As the\n   user\
    \ enters digits in the keypad, they are passed to the user\n   interface, which\
    \ generates user interface events that can be\n   transported to the application.\n"
- title: 5.3.  Flip-Flop
  contents:
  - "5.3.  Flip-Flop\n   A middle-ground approach is to flip back and forth between\
    \ a client-\n   local and client-remote user interface.  Many voice applications\
    \ are\n   of the type that listen to the media stream and wait for some\n   specific\
    \ trigger that kicks off a more complex user interaction.  The\n   long pound\
    \ in a prepaid calling card application is one example.\n   Another example is\
    \ a conference recording application, where the user\n   can press a key at some\
    \ point in the call to begin recording.  When\n   the key is pressed, the user\
    \ hears a whisper to inform them that\n   recording has started.\n   The ideal\
    \ way to support such an application is to install a client-\n   local user interface\
    \ component that waits for the trigger to kick off\n   the real interaction. \
    \ Once the trigger is received, the application\n   connects the user to a client-remote\
    \ user interface that can play\n   announcements, collect more information, and\
    \ so on.\n   The benefit of flip-flopping between a client-local and client-remote\n\
    \   user interface is cost.  The client-local user interface will\n   eliminate\
    \ the need to send media streams into the network just to\n   wait for the user\
    \ to press the pound key on the keypad.\n   The Keypad Markup Language (KPML)\
    \ was designed to support exactly\n   this kind of need [8].  It models the keypad\
    \ on a phone and allows an\n   application to be informed when any sequence of\
    \ keys has been\n   pressed.  However, KPML has no presentation component.  Since\
    \ user\n   interfaces generally require a response to user input, the\n   presentation\
    \ will need to be done using a client-remote user\n   interface that gets instantiated\
    \ as a result of the trigger.\n   It is tempting to use a hybrid model, where\
    \ a prompt-and-collect\n   application is implemented by using a client-remote\
    \ user interface\n   that plays the prompts, and a client-local user interface,\
    \ described\n   by KPML, that collects digits.  However, this only complicates\
    \ the\n   application.  Firstly, the keypad input will be sent to both the\n \
    \  media stream and the KPML user interface.  This requires the\n   application\
    \ to sort out which user inputs are duplicates, a process\n   that is very complicated.\
    \  Secondly, the primary benefit of KPML is\n   to avoid having a media stream\
    \ towards a user interface.  However,\n   there is already a media stream for\
    \ the prompting, so there is no\n   real savings.\n"
- title: 6.  Framework Overview
  contents:
  - "6.  Framework Overview\n   In this framework, we use the term \"SIP application\"\
    \ to refer to a\n   broad set of functionality.  A SIP application is a program\
    \ running\n   on a SIP-based element (such as a proxy or user agent) that provides\n\
    \   some value-added function to a user or system administrator.  SIP\n   applications\
    \ can execute on behalf of a caller, a called party, or a\n   multitude of users\
    \ at once.\n   Each application has a number of instances that are executing at\
    \ any\n   given time.  An instance represents a single execution path for an\n\
    \   application.  It is established as a result of some event.  That\n   event\
    \ can be a SIP event, such as the reception of a SIP INVITE\n   request, or it\
    \ can be a non-SIP event, such as a web form post or\n   even a timer.  Application\
    \ instances also have an end time.  Some\n   instances have a lifetime that is\
    \ coupled with a SIP transaction or\n   dialog.  For example, a proxy application\
    \ might begin when an INVITE\n   arrives, and terminate when the call is answered.\
    \  Other applications\n   have a lifetime that spans multiple dialogs or transactions.\
    \  For\n   example, a conferencing application instance may exist so long as\n\
    \   there are dialogs connected to it.  When the last dialog terminates,\n   the\
    \ application instance terminates.  Other applications have a\n   lifetime that\
    \ is completely decoupled from SIP events.\n   It is fundamental to the framework\
    \ described here that multiple\n   application instances may interact with a user\
    \ during a single SIP\n   transaction or dialog.  Each instance may be for the\
    \ same\n   application, or different applications.  Each of the applications may\n\
    \   be completely independent, in that each may be owned by a different\n   provider,\
    \ and may not be aware of each other's existence.  Similarly,\n   there may be\
    \ application instances interacting with the caller, and\n   instances interacting\
    \ with the callee, both within the same\n   transaction or dialog.\n   The first\
    \ step in the interaction with the user is to instantiate one\n   or more user\
    \ interface components for the application instance.  A\n   user interface component\
    \ is a single piece of the user interface that\n   is defined by a logical flow\
    \ that is not synchronously coupled with\n   any other component.  In other words,\
    \ each component runs\n   independently.\n   A user interface component can be\
    \ instantiated in one of the user\n   agents in a dialog (for a client-local user\
    \ interface), or within a\n   network element (for a client-remote user interface).\
    \  If a client-\n   local user interface is to be used, the application needs\
    \ to\n   determine whether or not the user agent is capable of supporting a\n\
    \   client-local user interface, and in what format.  In this framework,\n   all\
    \ client-local user interface components are described by a markup\n   language.\
    \  A markup language describes a logical flow of presentation\n   of information\
    \ to the user, a collection of information from the\n   user, and a transmission\
    \ of that information to an application.\n   Examples of markup languages include\
    \ HTML, Wireless Markup Language\n   (WML), VoiceXML, and the Keypad Markup Language\
    \ (KPML) [8].\n   Unlike an application instance, which has a very flexible lifetime,\
    \ a\n   user interface component has a very fixed lifetime.  A user interface\n\
    \   component is always associated with a dialog.  The user interface\n   component\
    \ can be created at any point after the dialog (or early\n   dialog) is created.\
    \  However, the user interface component terminates\n   when the dialog terminates.\
    \  The user interface component can be\n   terminated earlier by the user agent,\
    \ and possibly by the\n   application, but its lifetime never exceeds that of\
    \ its associated\n   dialog.\n   There are two ways to create a client-local interface\
    \ component.  For\n   interface components that are presentation capable, the\
    \ application\n   sends a REFER [7] request to the user agent.  The Refer-To header\n\
    \   field contains an HTTP URI that points to the markup for the user\n   interface,\
    \ and the REFER contains a Target-Dialog header field [10]\n   which identifies\
    \ the dialog associated with the user interface\n   component.  For user interface\
    \ components that are presentation free\n   (such as those defined by KPML), the\
    \ application sends a SUBSCRIBE\n   request to the user agent.  The body of the\
    \ SUBSCRIBE request\n   contains a filter, which, in this case, is the markup\
    \ that defines\n   when information is to be sent to the application in a NOTIFY.\
    \  The\n   SUBSCRIBE does not contain the Target-Dialog header field, since\n\
    \   equivalent information is conveyed in the Event header field.\n   If a user\
    \ interface component is to be instantiated in the network,\n   there is no need\
    \ to determine the capabilities of the device on which\n   the user interface\
    \ is instantiated.  Presumably, it is on a device on\n   which the application\
    \ knows a UI can be created.  However, the\n   application does need to connect\
    \ the user device to the user\n   interface.  This will require manipulation of\
    \ media streams in order\n   to establish that connection.\n   The interface between\
    \ the user interface component and the\n   application depends on the type of\
    \ user interface.  For presentation-\n   capable user interfaces, such as those\
    \ described by HTML and\n   VoiceXML, HTTP form POST operations are used.  For\
    \ presentation-free\n   user interfaces, a SIP NOTIFY is used.  The differing\
    \ needs and\n   capabilities of these two user interfaces, as described in\n \
    \  Section 4.4, are what drives the different choices for the\n   interactions.\
    \  Since presentation-capable user interfaces require an\n   update to the presentation\
    \ every time user data is entered, they are\n   a good match for HTTP.  Since\
    \ presentation-free user interfaces\n   merely transmit user input to the application,\
    \ a NOTIFY is more\n   appropriate.\n   Indeed, for presentation-free user interfaces,\
    \ there are two\n   different modalities of operation.  The first is called \"\
    one shot\".\n   In the one-shot role, the markup waits for a user to enter some\n\
    \   information and, when they do, reports this event to the application.\n  \
    \ The application then does something, and the markup is no longer\n   used. \
    \ In the other modality, called \"monitor\", the markup stays\n   permanently\
    \ resident, and reports information back to an application\n   until termination\
    \ of the associated dialog.\n"
- title: 7.  Deployment Topologies
  contents:
  - "7.  Deployment Topologies\n   This section presents some of the network topologies\
    \ in which this\n   framework can be instantiated.\n"
- title: 7.1.  Third-Party Application
  contents:
  - "7.1.  Third-Party Application\n                    +-------------+\n        \
    \        /---| Application |\n               /    +-------------+\n          \
    \    /\n       SUB/  / REFER/\n       NOT  /  HTTP\n           /\n      +--------+\
    \    SIP (INVITE)    +-----+\n      |   UI   A--------------------X     |\n  \
    \    |........|                    | SIP |\n      |  User  |        RTP      \
    \   | UA  |\n      | Device B--------------------Y     |\n      +--------+   \
    \                 +-----+\n                      Figure 2: Third-Party Topology\n\
    \   In this topology, the application that is interested in interacting\n   with\
    \ the users exists outside of the SIP dialog between the user\n   agents.  In\
    \ that case, the application learns about the initiation\n   and termination of\
    \ the dialog, along with the dialog identifiers,\n   through some out-of-band\
    \ means.  One such possibility is the dialog\n   event package [16].  Dialog information\
    \ is only revealed to trusted\n   parties, so the application would need to be\
    \ trusted by one of the\n   users in order to obtain this information.\n   At\
    \ any point during the dialog, the application can instantiate user\n   interface\
    \ components on the user device of the caller or callee.  It\n   can do this using\
    \ either SUBSCRIBE or REFER, depending on the type of\n   user interface (presentation\
    \ capable or presentation free).\n"
- title: 7.2.  Co-Resident Application
  contents:
  - "7.2.  Co-Resident Application\n      +--------+    SIP (INVITE)    +-----+\n\
    \      |  User  A--------------------X SIP |\n      | Device |        RTP    \
    \     | UA  |\n      |........B--------------------Y     |\n      |        | \
    \   SUB/NOT         | App)|\n      |  UI    A'-------------------X'    |\n   \
    \   +--------+    REFER/HTTP      +-----+\n                      Figure 3: Co-Resident\
    \ Topology\n   In this deployment topology, the application is co-resident with\
    \ one\n   of the user agents (the one on the right in the picture above).  This\n\
    \   application can install client-local user interface components on the\n  \
    \ other user agent, which is acting as the user device.  These\n   components\
    \ can be installed using either SUBSCRIBE, for presentation-\n   free user interfaces,\
    \ or REFER, for presentation-capable ones.  This\n   situation typically arises\
    \ when the application wishes to install UI\n   components on a presentation-capable\
    \ user interface.  If the only\n   user input is via keypad input, the framework\
    \ is not needed per se,\n   because the UA/application will receive the input\
    \ via RFC 4733 in the\n   RTP stream.\n   If the application resides in the called\
    \ party, it is called a\n   \"terminating application\".  If it resides in the\
    \ calling party, it is\n   called an \"originating application\".\n   This kind\
    \ of topology is common in protocol converter and gateway\n   applications.\n"
- title: 7.3.  Third-Party Application and User Device Proxy
  contents:
  - "7.3.  Third-Party Application and User Device Proxy\n                       \
    \                        +-------------+\n                                   \
    \        /---| Application |\n                                          /    +-------------+\n\
    \                                         /\n                                \
    \   SUB/ /  REFER/\n                                   NOT /   HTTP\n        \
    \                              /\n      +-----+        SIP         +---M----+\
    \        SIP         +-----+\n      |     V--------------------C        A--------------------X\
    \     |\n      | SIP |                    |   UI   |                    | SIP\
    \ |\n      | UAa |        RTP         |        |        RTP         | UAb |\n\
    \      |     W--------------------D        B--------------------Y     |\n    \
    \  +-----+                    +--------+                    +-----+\n       User\
    \                         User\n       Device                      Device\n  \
    \                                 Proxy\n                   Figure 4: User Device\
    \ Proxy Topology\n   In this deployment topology, there is a third-party application\
    \ as in\n   Section 7.1.  However, instead of installing a user interface\n  \
    \ component on the end user device, the component is installed in an\n   intermediate\
    \ device, known as a User Device Proxy.  From the\n   perspective of the actual\
    \ user device (on the left), the User Device\n   Proxy is a client remote user\
    \ interface.  As such, media, typically\n   transported using RTP (including RFC\
    \ 4733 for carrying user input),\n   is sent from the user device to the client\
    \ remote user interface on\n   the User Device Proxy.  As far as the application\
    \ is concerned, it is\n   installing what it thinks is a client-local user interface\
    \ on the\n   user device, but it happens to be on a user device proxy that looks\n\
    \   like the user device to the application.\n   The user device proxy will need\
    \ to terminate and re-originate both\n   signaling (SIP) and media traffic towards\
    \ the actual peer in the\n   conversation.  The User Device Proxy is a media relay\
    \ in the\n   terminology of RFC 3550 [18].  The User Device Proxy will need to\n\
    \   monitor the media streams associated with each dialog, in order to\n   convert\
    \ user input received in the media stream to events reported to\n   the user interface.\
    \  This can pose a challenge in multi-media\n   systems, where it may be unclear\
    \ on which media stream the user input\n   is being sent.  As discussed in RFC\
    \ 3264 [20], if a user agent has a\n   single media source and is supporting multiple\
    \ streams, it is\n   supposed to send that source to all streams.  In cases where\
    \ there\n   are multiple sources, the mapping is a matter of local policy.  In\n\
    \   the absence of a way to explicitly identify or request which sources\n   map\
    \ to which streams, the user device proxy will need to do the best\n   job it\
    \ can.  This specification RECOMMENDS that the User Device Proxy\n   monitor the\
    \ first stream (defined in terms of ordering of media\n   sessions within a session\
    \ description).  As such, user agents SHOULD\n   send their user input on the\
    \ first stream, absent a policy to direct\n   it otherwise.\n"
- title: 7.4.  Proxy Application
  contents:
  - "7.4.  Proxy Application\n                             +----------+\n        \
    \       SUB/NOT       |   App    |      SUB/NOT\n            +--------------->|\
    \          |<-----------------+\n            |  REFER/HTTP    |..........|   \
    \  REFER/HTTP   |\n            |                |   SIP    |                 \
    \ |\n            |                |  Proxy   |                  |\n          \
    \  |                +----------+                  |\n            V           \
    \      ^        |                   V\n      +----------+            |       \
    \ |             +----------+\n      |   UI     |   INVITE   |        |    INVITE\
    \   |   UI     |\n      |          |------------+        +------------>|     \
    \     |\n      |......... |                                   |..........|\n \
    \     |   SIP    |...................................|   SIP    |\n      |   UA\
    \     |                                   |   UA     |\n      +----------+   \
    \            RTP                 +----------+\n        User Device           \
    \                         User Device\n                   Figure 5: Proxy Application\
    \ Topology\n   In this topology, the application is co-resident with a transaction\n\
    \   stateful, record-routing proxy server on the call path between two\n   user\
    \ devices.  The application uses SUBSCRIBE or REFER to install\n   user interface\
    \ components on one or both user devices.\n   This topology is common in routing\
    \ applications, such as a web-\n   assisted call-routing application.\n"
- title: 8.  Application Behavior
  contents:
  - "8.  Application Behavior\n   The behavior of an application within this framework\
    \ depends on\n   whether it seeks to use a client-local or client-remote user\n\
    \   interface.\n"
- title: 8.1.  Client-Local Interfaces
  contents:
  - "8.1.  Client-Local Interfaces\n   One key component of this framework is support\
    \ for client-local user\n   interfaces.\n"
- title: 8.1.1.  Discovering Capabilities
  contents:
  - "8.1.1.  Discovering Capabilities\n   A client-local user interface can only be\
    \ instantiated on a user\n   agent if the user agent supports that type of user\
    \ interface\n   component.  Support for client-local user interface components\
    \ is\n   declared by both the UAC and UAS in their Allow, Accept, Supported,\n\
    \   and Allow-Event header fields of dialog-initiating requests and\n   responses.\
    \  If the Allow header field indicates support for the SIP\n   SUBSCRIBE method,\
    \ and the Allow-Event header field indicates support\n   for the KPML package\
    \ [8], and the Supported header field indicates\n   support for the Globally Routable\
    \ UA URI (GRUU) [9] specification\n   (which, in turn, means that the Contact\
    \ header field contains a\n   GRUU), it means that the UA can instantiate presentation-free\
    \ user\n   interface components.  In this case, the application can push\n   presentation-free\
    \ user interface components according to the rules of\n   Section 8.1.2.  The\
    \ specific markup languages that can be supported\n   are indicated in the Accept\
    \ header field.\n   If the Allow header field indicates support for the SIP REFER\
    \ method,\n   and the Supported header field indicates support for the Target-\n\
    \   Dialog header field [10], and the Contact header field contains UA\n   capabilities\
    \ [6] that indicate support for the HTTP URI scheme, it\n   means that the UA\
    \ supports presentation-capable user interface\n   components.  In this case,\
    \ the application can push presentation-\n   capable user interface components\
    \ to the client according to the\n   rules of Section 8.1.2.  The specific markups\
    \ that are supported are\n   indicated in the Accept header field.\n   A third-party\
    \ application that is not present on the call path will\n   not be privy to these\
    \ header fields in the dialog-initiating requests\n   that pass by.  As such,\
    \ it will need to obtain this capability\n   information in other ways.  One way\
    \ is through the registration event\n   package [21], which can contain user agent\
    \ capability information\n   provided in REGISTER requests [6].\n"
- title: 8.1.2.  Pushing an Initial Interface Component
  contents:
  - "8.1.2.  Pushing an Initial Interface Component\n   Generally, we anticipate that\
    \ interface components will need to be\n   created at various different points\
    \ in a SIP session.  Clearly, they\n   will need to be pushed during session setup,\
    \ or after the session is\n   established.  A user interface component is always\
    \ associated with a\n   specific dialog, however.\n   An application MUST NOT\
    \ attempt to push a user interface component to\n   a user agent until it has\
    \ determined that the user agent has the\n   necessary capabilities and a dialog\
    \ has been created.  In the case of\n   a UAC, this means that an application\
    \ MUST NOT push a user interface\n   component for an INVITE-initiated dialog\
    \ until the application has\n   seen a request confirming the receipt of a dialog-creating\
    \ response.\n   This could be an ACK for a 200 OK, or a PRACK for a provisional\n\
    \   response [3].  For SUBSCRIBE-initiated dialogs, the application MUST\n   NOT\
    \ push a user interface component until the application has seen a\n   200 OK\
    \ to the NOTIFY request.  For a user interface component on a\n   UAS, the application\
    \ MUST NOT push a user interface component for an\n   INVITE-initiated dialog\
    \ until it has seen a dialog-creating response\n   from the UAS.  For a SUBSCRIBE-initiated\
    \ dialog, it MUST NOT push a\n   user interface component until it has seen a\
    \ NOTIFY request from the\n   notifier.\n   To create a presentation-capable UI\
    \ component on the UA, the\n   application sends a REFER request to the UA.  This\
    \ REFER MUST be sent\n   to the GRUU [9] advertised by that UA in the Contact\
    \ header field of\n   the dialog-initiating request or response sent by that UA.\
    \  Note that\n   this REFER request creates a separate dialog between the application\n\
    \   and the UA.  The Refer-To header field of the REFER request MUST\n   contain\
    \ an HTTP URI that references the markup document to be\n   fetched.\n   Furthermore,\
    \ it is essential for the REFER request to be correlated\n   with the dialog to\
    \ which the user interface component will be\n   associated.  This is necessary\
    \ for authorization and for terminating\n   the user interface components when\
    \ the dialog terminates.  To provide\n   this context, the REFER request MUST\
    \ contain a Target-Dialog header\n   field identifying the dialog with which the\
    \ user interface component\n   is associated.  As discussed in [10], this request\
    \ will also contain\n   a Require header field with the tdialog option tag.\n\
    \   To create a presentation-free user interface component, the\n   application\
    \ sends a SUBSCRIBE request to the UA.  The SUBSCRIBE MUST\n   be sent to the\
    \ GRUU advertised by the UA.  This SUBSCRIBE request\n   creates a separate dialog.\
    \  The SUBSCRIBE request MUST use the KPML\n   [8] event package.  The body of\
    \ the SUBSCRIBE request contains the\n   markup document that defines the conditions\
    \ under which the\n   application wishes to be notified of user input.\n   In\
    \ both cases, the REFER or SUBSCRIBE request SHOULD include a\n   display name\
    \ in the From header field that identifies the name of the\n   application.  For\
    \ example, a prepaid calling card might include a\n   From header field that looks\
    \ like:\n   From: \"Prepaid Calling Card\" <sip:prepaid@example.com>\n   Any of\
    \ the SIP identity assertion mechanisms that have been defined,\n   such as [11]\
    \ and [13], are applicable to these requests as well.\n"
- title: 8.1.3.  Updating an Interface Component
  contents:
  - "8.1.3.  Updating an Interface Component\n   Once a user interface component has\
    \ been created on a client, it can\n   be updated.  The means for updating it\
    \ depends on the type of UI\n   component.\n   Presentation-capable UI components\
    \ are updated using techniques\n   already in place for those markups.  In particular,\
    \ user input will\n   cause an HTTP POST operation to push the user input to the\n\
    \   application.  The result of the POST operation is a new markup that\n   the\
    \ UI is supposed to use.  This allows the UI to be updated in\n   response to\
    \ user action.  Some markups, such as HTML, provide the\n   ability to force a\
    \ refresh after a certain period of time, so that\n   the UI can be updated without\
    \ user input.  Those mechanisms can be\n   used here as well.  However, there\
    \ is no support for an asynchronous\n   push of an updated UI component from the\
    \ application to the user\n   agent.  A new REFER request to the same GRUU would\
    \ create a new UI\n   component rather than update any components already in place.\n\
    \   For presentation-free UI, the story is different.  The application\n   MAY\
    \ update the filter at any time by generating a SUBSCRIBE refresh\n   with the\
    \ new filter.  The UA will immediately begin using this new\n   filter.\n"
- title: 8.1.4.  Terminating an Interface Component
  contents:
  - "8.1.4.  Terminating an Interface Component\n   User interface components have\
    \ a well-defined lifetime.  They are\n   created when the component is first pushed\
    \ to the client.  User\n   interface components are always associated with the\
    \ SIP dialog on\n   which they were pushed.  As such, their lifetime is bound\
    \ by the\n   lifetime of the dialog.  When the dialog ends, so does the interface\n\
    \   component.\n   However, there are some cases where the application would like\
    \ to\n   terminate the user interface component before its natural termination\n\
    \   point.  For presentation-capable user interfaces, this is not\n   possible.\
    \  For presentation-free user interfaces, the application MAY\n   terminate the\
    \ component by sending a SUBSCRIBE with Expires equal to\n   zero.  This terminates\
    \ the subscription, which removes the UI\n   component.\n   A client can remove\
    \ a UI component at any time.  For presentation-\n   capable UI, this is analogous\
    \ to the user dismissing the web form\n   window.  There is no mechanism provided\
    \ for reporting this kind of\n   event to the application.  The application MUST\
    \ be prepared to time\n   out and never receive input from a user.  The duration\
    \ of this\n   timeout is application dependent.  For presentation-free user\n\
    \   interfaces, the UA can explicitly terminate the subscription.  This\n   will\
    \ result in the generation of a NOTIFY with a Subscription-State\n   header field\
    \ equal to \"terminated\".\n"
- title: 8.2.  Client-Remote Interfaces
  contents:
  - "8.2.  Client-Remote Interfaces\n   As an alternative to, or in conjunction with\
    \ client-local user\n   interfaces, an application can make use of client-remote\
    \ user\n   interfaces.  These user interfaces can execute co-resident with the\n\
    \   application itself (in which case no standardized interfaces between\n   the\
    \ UI and the application need to be used), or they can run\n   separately.  This\
    \ framework assumes that the user interface runs on a\n   host that has a sufficient\
    \ trust relationship with the application.\n   As such, the means for instantiating\
    \ the user interface is not\n   considered here.\n   The primary issue is to connect\
    \ the user device to the remote user\n   interface.  Doing so requires the manipulation\
    \ of media streams\n   between the client and the user interface.  Such manipulation\
    \ can\n   only be done by user agents.  There are two types of user agent\n  \
    \ applications within this framework: originating/terminating\n   applications,\
    \ and intermediary applications.\n"
- title: 8.2.1.  Originating and Terminating Applications
  contents:
  - "8.2.1.  Originating and Terminating Applications\n   Originating and terminating\
    \ applications are applications that are\n   themselves the originator or the\
    \ final recipient of a SIP invitation.\n   They are \"pure\" user agent applications,\
    \ not back-to-back user\n   agents.  The classic example of such an application\
    \ is an interactive\n   voice response (IVR) application, which is typically a\
    \ terminating\n   application.  It is a terminating application because the user\n\
    \   explicitly calls it; i.e., it is the actual called party.  An example\n  \
    \ of an originating application is a wakeup call application, which\n   calls\
    \ a user at a specified time in order to wake them up.\n   Because originating\
    \ and terminating applications are a natural\n   termination point of the dialog,\
    \ manipulation of the media session by\n   the application is trivial.  Traditional\
    \ SIP techniques for adding\n   and removing media streams, modifying codecs,\
    \ and changing the\n   address of the recipient of the media streams can be applied.\n"
- title: 8.2.2.  Intermediary Applications
  contents:
  - "8.2.2.  Intermediary Applications\n   Intermediary applications are, at the same\
    \ time, more common than\n   originating/terminating applications and more complex.\
    \  Intermediary\n   applications are applications that are neither the actual\
    \ caller nor\n   the called party.  Rather, they represent a \"third party\" that\
    \ wishes\n   to interact with the user.  The classic example is the ubiquitous\n\
    \   prepaid calling card application.\n   In order for the intermediary application\
    \ to add a client-remote user\n   interface, it needs to manipulate the media\
    \ streams of the user agent\n   to terminate on that user interface.  This also\
    \ introduces a\n   fundamental feature interaction issue.  Since the intermediary\n\
    \   application is not an actual participant in the call, the user will\n   need\
    \ to interact with both the intermediary application and its peer\n   in the dialog.\
    \  Doing both at the same time is complicated and is\n   discussed in more detail\
    \ in Section 10.\n"
- title: 9.  User Agent Behavior
  contents:
  - '9.  User Agent Behavior

    '
- title: 9.1.  Advertising Capabilities
  contents:
  - "9.1.  Advertising Capabilities\n   In order to participate in applications that\
    \ make use of stimulus\n   interfaces, a user agent needs to advertise its interaction\n\
    \   capabilities.\n   If a user agent supports presentation-capable user interfaces,\
    \ it\n   MUST support the REFER method.  It MUST include, in all dialog-\n   initiating\
    \ requests and responses, an Allow header field that\n   includes the REFER method.\
    \  The user agent MUST support the target\n   dialog specification [10], and MUST\
    \ include the \"tdialog\" option tag\n   in the Supported header field of dialog-forming\
    \ requests and\n   responses.  Furthermore, the UA MUST support the SIP user agent\n\
    \   capabilities specification [6].  The UA MUST be capable of being\n   REFERed\
    \ to an HTTP URI.  It MUST include, in the Contact header field\n   of its dialog-initiating\
    \ requests and responses, a \"schemes\" Contact\n   header field parameter that\
    \ includes the HTTP URI scheme.  The UA\n   MUST include, in all dialog-initiating\
    \ requests and responses, an\n   Accept header field listing all of those markups\
    \ supported by the UA.\n   It is RECOMMENDED that all user agents that support\
    \ presentation-\n   capable user interfaces support HTML.\n   If a user agent\
    \ supports presentation-free user interfaces, it MUST\n   support the SUBSCRIBE\
    \ [4] method.  It MUST support the KPML [8] event\n   package.  It MUST include,\
    \ in all dialog-initiating requests and\n   responses, an Allow header field that\
    \ includes the SUBSCRIBE method.\n   It MUST include, in all dialog-initiating\
    \ requests and responses, an\n   Allow-Events header field that lists the KPML\
    \ event package.  The UA\n   MUST include, in all dialog-initiating requests and\
    \ responses, an\n   Accept header field listing those event filters it supports.\
    \  At a\n   minimum, a UA MUST support the \"application/kpml-request+xml\" MIME\n\
    \   type.\n   For either presentation-free or presentation-capable user interfaces,\n\
    \   the user agent MUST support the GRUU [9] specification.  The Contact\n   header\
    \ field in all dialog-initiating requests and responses MUST\n   contain a GRUU.\
    \  The UA MUST include a Supported header field that\n   contains the \"gruu\"\
    \ option tag and the \"tdialog\" option tag.\n   Because these headers are examined\
    \ by proxies that may be executing\n   applications, a UA that wishes to support\
    \ client-local user\n   interfaces should not encrypt them.\n"
- title: 9.2.  Receiving User Interface Components
  contents:
  - "9.2.  Receiving User Interface Components\n   Once the UA has created a dialog\
    \ (in either the early or confirmed\n   states), it MUST be prepared to receive\
    \ a SUBSCRIBE or REFER request\n   against its GRUU.  If the UA receives such\
    \ a request prior to the\n   establishment of a dialog, the UA MUST reject the\
    \ request.\n   A user agent SHOULD attempt to authenticate the sender of the\n\
    \   request.  The sender will generally be an application; therefore, the\n  \
    \ user agent is unlikely to ever have a shared secret with it, making\n   digest\
    \ authentication useless.  However, authenticated identities can\n   be obtained\
    \ through other means, such as the Identity mechanism [11].\n   A user agent MAY\
    \ have pre-defined authorization policies that permit\n   applications which have\
    \ authenticated themselves with a particular\n   identity to push user interface\
    \ components.  If such a set of\n   policies is present, it is checked first.\
    \  If the application is\n   authorized, processing proceeds.\n   If the application\
    \ has authenticated itself but is not explicitly\n   authorized or blocked, this\
    \ specification RECOMMENDS that the\n   application be automatically authorized\
    \ if it can prove that it was\n   either on the call path, or is trusted by one\
    \ of the elements on the\n   call path.  An application proves this to the user\
    \ agent by\n   demonstrating that it knows the dialog identifiers.  That occurs\
    \ by\n   including them in a Target-Dialog header field for REFER requests, or\n\
    \   in the Event header field parameters of the KPML SUBSCRIBE request.\n   Because\
    \ the dialog identifiers serve as a tool for authorization, a\n   user agent compliant\
    \ to this framework SHOULD use dialog identifiers\n   that are cryptographically\
    \ random, with at least 128 bits of\n   randomness.  It is recommended that this\
    \ randomness be split between\n   the Call-ID and From header field tags in the\
    \ case of a UAC.\n   Furthermore, to ensure that only applications resident in\
    \ or trusted\n   by on-path elements can instantiate a user interface component,\
    \ a\n   user agent compliant to this specification SHOULD use the Session\n  \
    \ Initiation Protocol Secure (SIPS) URI scheme for all dialogs it\n   initiates.\
    \  This will guarantee secure links between all the elements\n   on the signaling\
    \ path.\n   If the dialog was not established with a SIPS URI, or the user agent\n\
    \   did not choose cryptographically random dialog identifiers, then the\n   application\
    \ MUST NOT automatically be authorized, even if it\n   presented valid dialog\
    \ identifiers.  A user agent MAY apply any other\n   policies in addition to (but\
    \ not instead of) the ones specified here\n   in order to authorize the creation\
    \ of the user interface component.\n   One such mechanism would be to prompt the\
    \ user, informing them of the\n   identity of the application and the dialog it\
    \ is associated with.  If\n   an authorization policy requires user interaction,\
    \ the user agent\n   SHOULD respond to the SUBSCRIBE or REFER request with a 202.\
    \  In the\n   case of SUBSCRIBE, if authorization is not granted, the user agent\n\
    \   SHOULD generate a NOTIFY to terminate the subscription.  In the case\n   of\
    \ REFER, the user agent MUST NOT act upon the URI in the Refer-To\n   header field\
    \ until user authorization is obtained.\n   If an application does not present\
    \ a valid dialog identifier in its\n   REFER or SUBSCRIBE request, the user agent\
    \ MUST reject the request\n   with a 403 response.\n   If a REFER request to an\
    \ HTTP URI is authorized, the UA executes the\n   URI and fetches the content\
    \ to be rendered to the user.  This\n   instantiates a presentation-capable user\
    \ interface component.  If a\n   SUBSCRIBE was authorized, a presentation-free\
    \ user interface\n   component is instantiated.\n"
- title: 9.3.  Mapping User Input to User Interface Components
  contents:
  - "9.3.  Mapping User Input to User Interface Components\n   Once the user interface\
    \ components are instantiated, the user agent\n   must direct user input to the\
    \ appropriate component.  In the case of\n   presentation-capable user interfaces,\
    \ this process is known as focus\n   selection.  It is done by means that are\
    \ specific to the user\n   interface on the device.  In the case of a PC, for\
    \ example, the\n   window manager would allow the user to select the appropriate\
    \ user\n   interface component to which their input is directed.\n   For presentation-free\
    \ user interfaces, the situation is more\n   complicated.  In some cases, the\
    \ device may support a mechanism that\n   allows the user to select a \"line\"\
    , and thus the associated dialog.\n   Any user input on the keypad while this\
    \ line is selected are fed to\n   the user interface components associated with\
    \ that dialog.\n   Otherwise, for client-local user interfaces, the user input\
    \ is\n   assumed to be associated with all user interface components.  For\n \
    \  client-remote user interfaces, the user device converts the user\n   input\
    \ to media, typically conveyed using RFC 4733, and sends this to\n   the client-remote\
    \ user interface.  This user interface then needs to\n   map user input from potentially\
    \ many media streams into user\n   interface events.  The process for doing this\
    \ is described in\n   Section 7.3.\n"
- title: 9.4.  Receiving Updates to User Interface Components
  contents:
  - "9.4.  Receiving Updates to User Interface Components\n   For presentation-capable\
    \ user interfaces, updates to the user\n   interface occur in ways specific to\
    \ that user interface component.\n   In the case of HTML, for example, the document\
    \ can tell the client to\n   fetch a new document periodically.  However, this\
    \ framework does not\n   provide any additional machinery to asynchronously push\
    \ a new user\n   interface component to the client.\n   For presentation-free\
    \ user interfaces, an application can push an\n   update to a component by sending\
    \ a SUBSCRIBE refresh with a new\n   filter.  The user agent will process these\
    \ according to the rules of\n   the event package.\n"
- title: 9.5.  Terminating a User Interface Component
  contents:
  - "9.5.  Terminating a User Interface Component\n   Termination of a presentation-capable\
    \ user interface component is a\n   trivial procedure.  The user agent merely\
    \ dismisses the window (or\n   its equivalent).  The fact that the component is\
    \ dismissed is not\n   communicated to the application.  As such, it is purely\
    \ a local\n   matter.\n   In the case of a presentation-free user interface, the\
    \ user might\n   wish to cease interacting with the application.  However, most\n\
    \   presentation-free user interfaces will not have a way for the user to\n  \
    \ signal this through the device.  If such a mechanism did exist, the\n   UA SHOULD\
    \ generate a NOTIFY request with a Subscription-State header\n   field equal to\
    \ \"terminated\" and a reason of \"rejected\".  This tells\n   the application\
    \ that the component has been removed and that it\n   should not attempt to re-subscribe.\n"
- title: 10.  Inter-Application Feature Interaction
  contents:
  - "10.  Inter-Application Feature Interaction\n   The inter-application feature\
    \ interaction problem is inherent to\n   stimulus signaling.  Whenever there are\
    \ multiple applications, there\n   are multiple user interfaces.  The system has\
    \ to determine to which\n   user interface any particular input is destined. \
    \ That question is\n   the essence of the inter-application feature interaction\
    \ problem.\n   Inter-application feature interaction is not an easy problem to\n\
    \   resolve.  For now, we consider separately the issues for client-local\n  \
    \ and client-remote user interface components.\n"
- title: 10.1.  Client-Local UI
  contents:
  - "10.1.  Client-Local UI\n   When the user interface itself resides locally on\
    \ the client device,\n   the feature interaction problem is actually much simpler.\
    \  The end\n   device knows explicitly about each application, and therefore can\n\
    \   present the user with each one separately.  When the user provides\n   input,\
    \ the client device can determine to which user interface the\n   input is destined.\
    \  The user interface to which input is destined is\n   referred to as the \"\
    application in focus\", and the means by which the\n   focused application is\
    \ selected is called \"focus determination\".\n   Generally speaking, focus determination\
    \ is purely a local operation.\n   In the PC universe, focus determination is\
    \ provided by window\n   managers.  Each application does not know about focus;\
    \ it merely\n   receives the user input that has been targeted to it when it's\
    \ in\n   focus.  This basic concept applies to SIP-based applications as well.\n\
    \   Focus determination will frequently be trivial, depending on the user\n  \
    \ interface type.  Consider a user that makes a call from a PC.  The\n   call\
    \ passes through a prepaid calling card application and a call-\n   recording\
    \ application.  Both of these wish to interact with the user.\n   Both push an\
    \ HTML-based user interface to the user.  On the PC, each\n   user interface would\
    \ appear as a separate window.  The user interacts\n   with the call-recording\
    \ application by selecting its window, and with\n   the prepaid calling card application\
    \ by selecting its window.  Focus\n   determination is literally provided by the\
    \ PC window manager.  It is\n   clear to which application the user input is targeted.\n\
    \   As another example, consider the same two applications, but on a\n   \"smart\
    \ phone\" that has a set of buttons, and next to each button,\n   there is an\
    \ LCD display that can provide the user with an option.\n   This user interface\
    \ can be represented using the Wireless Markup\n   Language (WML), for example.\n\
    \   The phone would allocate some number of buttons to each application.\n   The\
    \ prepaid calling card would get one button for its \"hangup\"\n   command, and\
    \ the recording application would get one for its \"start/\n   stop\" command.\
    \  The user can easily determine which application to\n   interact with by pressing\
    \ the appropriate button.  Pressing a button\n   determines focus and provides\
    \ user input, both at the same time.\n   Unfortunately, not all devices will have\
    \ these advanced displays.  A\n   PSTN gateway, or a basic IP telephone, may only\
    \ have a 12-key keypad.\n   The user interfaces for these devices are provided\
    \ through the Keypad\n   Markup Language (KPML).  Considering once again the feature\n\
    \   interaction case above, the prepaid calling card application and the\n   call-recording\
    \ application would both pass a KPML document to the\n   device.  When the user\
    \ presses a button on the keypad, to which\n   document does the input apply?\
    \  The device does not allow the user to\n   select.  A device where the user\
    \ cannot provide focus is called a\n   \"focusless device\".  This is quite a\
    \ hard problem to solve.  This\n   framework does not make any explicit normative\
    \ recommendation, but it\n   concludes that the best option is to send the input\
    \ to both user\n   interfaces unless the markup in one interface has indicated\
    \ that it\n   should be suppressed from others.  This is a sensible choice by\n\
    \   analogy -- it's exactly what the existing circuit-switched telephone\n   network\
    \ will do.  It is an explicit non-goal to provide a better\n   mechanism for feature\
    \ interaction resolution than the PSTN on devices\n   that have the same user\
    \ interface as they do on the PSTN.  Devices\n   with better displays, such as\
    \ PCs or screen phones, can benefit from\n   the capabilities of this framework,\
    \ allowing the user to determine\n   which application they are interacting with.\n\
    \   Indeed, when a user provides input on a focusless device, the input\n   must\
    \ be passed to all client-local user interfaces AND all client-\n   remote user\
    \ interfaces, unless the markup tells the UI to suppress\n   the media.  In the\
    \ case of KPML, key events are passed to remote user\n   interfaces by encoding\
    \ them as described in RFC 4733 [19].  Of\n   course, since a client cannot determine\
    \ whether or not a media stream\n   terminates in a remote user interface, these\
    \ key events are passed in\n   all audio media streams unless the KPML request\
    \ document is used to\n   suppress them.\n"
- title: 10.2.  Client-Remote UI
  contents:
  - "10.2.  Client-Remote UI\n   When the user interfaces run remotely, the determination\
    \ of focus can\n   be much, much harder.  There are many architectures that can\
    \ be\n   deployed to handle the interaction.  None are ideal.  However, all\n\
    \   are beyond the scope of this specification.\n"
- title: 11.  Intra Application Feature Interaction
  contents:
  - "11.  Intra Application Feature Interaction\n   An application can instantiate\
    \ a multiplicity of user interface\n   components.  For example, a single application\
    \ can instantiate two\n   separate HTML components and one WML component.  Furthermore,\
    \ an\n   application can instantiate both client-local and client-remote user\n\
    \   interfaces.\n   The feature interaction issues between these components within\
    \ the\n   same application are less severe.  If an application has multiple\n\
    \   client user interface components, their interaction is resolved\n   identically\
    \ to the inter-application case -- through focus\n   determination.  However,\
    \ the problems in focusless user devices (such\n   as a keypad on a telephone)\
    \ generally won't exist, since the\n   application can generate user interfaces\
    \ that do not overlap in their\n   usage of an input.\n   The real issue is that\
    \ the optimal user experience frequently\n   requires some kind of coupling between\
    \ the differing user interface\n   components.  This is a classic problem in multi-modal\
    \ user\n   interfaces, such as those described by Speech Application Language\n\
    \   Tags (SALT).  As an example, consider a user interface where a user\n   can\
    \ either press a labeled button to make a selection, or listen to a\n   prompt,\
    \ and speak the desired selection.  Ideally, when the user\n   presses the button,\
    \ the prompt should cease immediately, since both\n   of them were targeted at\
    \ collecting the same information in parallel.\n   Such interactions are best\
    \ handled by markups that natively support\n   such interactions, such as SALT,\
    \ and thus require no explicit support\n   from this framework.\n"
- title: 12.  Example Call Flow
  contents:
  - "12.  Example Call Flow\n   This section shows the operation of a call-recording\
    \ application.\n   This application allows a user to record the media in their\
    \ call by\n   clicking on a button in a web form.  The application uses a\n  \
    \ presentation-capable user interface component that is pushed to the\n   caller.\
    \  The conventions of [17] are used to describe representation\n   of long message\
    \ lines.\n             A                  Recording App                  B\n \
    \            |(1) INVITE              |                        |\n           \
    \  |----------------------->|                        |\n             |       \
    \                 |(2) INVITE              |\n             |                 \
    \       |----------------------->|\n             |                        |(3)\
    \ 200 OK              |\n             |                        |<-----------------------|\n\
    \             |(4) 200 OK              |                        |\n          \
    \   |<-----------------------|                        |\n             |(5) ACK\
    \                 |                        |\n             |----------------------->|\
    \                        |\n             |                        |(6) ACK   \
    \              |\n             |                        |----------------------->|\n\
    \             |(7) REFER               |                        |\n          \
    \   |<-----------------------|                        |\n             |(8) 200\
    \ OK              |                        |\n             |----------------------->|\
    \                        |\n             |(9) NOTIFY              |          \
    \              |\n             |----------------------->|                    \
    \    |\n             |(10) 200 OK             |                        |\n   \
    \          |<-----------------------|                        |\n             |(11)\
    \ HTTP GET           |                        |\n             |----------------------->|\
    \                        |\n             |(12) 200 OK             |          \
    \              |\n             |<-----------------------|                    \
    \    |\n             |(13) NOTIFY             |                        |\n   \
    \          |----------------------->|                        |\n             |(14)\
    \ 200 OK             |                        |\n             |<-----------------------|\
    \                        |\n             |(15) HTTP POST          |          \
    \              |\n             |----------------------->|                    \
    \    |\n             |(16) 200 OK             |                        |\n   \
    \          |<-----------------------|                        |\n             \
    \                    Figure 6\n   First, the caller, A, sends an INVITE to set\
    \ up a call (message 1).\n   Since the caller supports the framework and can handle\
    \ presentation-\n   capable user interface components, it includes the Supported\
    \ header\n   field indicating that the GRUU extension and the Target-Dialog header\n\
    \   field are understood, the Allow header field indicating that REFER is\n  \
    \ understood, and the Contact header field that includes the \"schemes\"\n   header\
    \ field parameter.\n   INVITE sip:B@example.com SIP/2.0\n   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9zz8\n\
    \   From: Caller <sip:A@example.com>;tag=kkaz-\n   To: Callee <sip:B@example.org>\n\
    \   Call-ID: fa77as7dad8-sd98ajzz@host.example.com\n   CSeq: 1 INVITE\n   Max-Forwards:\
    \ 70\n   Supported: gruu, tdialog\n   Allow: INVITE, OPTIONS, BYE, CANCEL, ACK,\
    \ REFER\n   Accept: application/sdp, text/html\n   <allOneLine>\n   Contact: <sip:A@example.com;gr=urn:uuid:f81d4fae\n\
    \   -7dec-11d0-a765-00a0c91e6bf6>;schemes=\"http,sip\"\n   </allOneLine>\n   Content-Length:\
    \ ...\n   Content-Type: application/sdp\n   --SDP not shown--\n   The proxy acts\
    \ as a recording server, and forwards the INVITE to the\n   called party (message\
    \ 2).  It strips the Record-Route it would\n   normally insert due to the presence\
    \ of the GRUU in the INVITE:\n   INVITE sip:B@pc.example.com SIP/2.0\n   Via:\
    \ SIP/2.0/TLS app.example.com;branch=z9hG4bK97sh\n   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9zz8\n\
    \   From: Caller <sip:A@example.com>;tag=kkaz-\n   To: Callee <sip:B@example.org>\n\
    \   Call-ID: fa77as7dad8-sd98ajzz@host.example.com\n   CSeq: 1 INVITE\n   Max-Forwards:\
    \ 70\n   Supported: gruu, tdialog\n   Allow: INVITE, OPTIONS, BYE, CANCEL, ACK,\
    \ REFER\n   Accept: application/sdp, text/html\n   <allOneLine>\n   Contact: <sip:A@example.com;gr=urn:uuid:f81d4fae\n\
    \   -7dec-11d0-a765-00a0c91e6bf6>;schemes=\"http,sip\"\n   </allOneLine>\n   Content-Length:\
    \ ...\n   Content-Type: application/sdp\n   --SDP not shown--\n   B accepts the\
    \ call with a 200 OK (message 3).  It does not support\n   the framework, so the\
    \ various header fields are not present.\n   SIP/2.0 200 OK\n   Via: SIP/2.0/TLS\
    \ app.example.com;branch=z9hG4bK97sh\n   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9zz8\n\
    \   From: Caller <sip:A@example.com>;tag=kkaz-\n   To: Callee <sip:B@example.com>;tag=7777\n\
    \   Call-ID: fa77as7dad8-sd98ajzz@host.example.com\n   CSeq: 1 INVITE\n   Contact:\
    \ <sip:B@pc.example.com>\n   Content-Length: ...\n   Content-Type: application/sdp\n\
    \   --SDP not shown--\n   This 200 OK is passed back to the caller (message 4):\n\
    \   SIP/2.0 200 OK\n   Record-Route: <sip:app.example.com;lr>\n   Via: SIP/2.0/TLS\
    \ host.example.com;branch=z9hG4bK9zz8\n   From: Caller <sip:A@example.com>;tag=kkaz-\n\
    \   To: Callee <sip:B@example.com>;tag=7777\n   Call-ID: fa77as7dad8-sd98ajzz@host.example.com\n\
    \   CSeq: 1 INVITE\n   Contact: <sip:B@pc.example.com>\n   Content-Length: ...\n\
    \   Content-Type: application/sdp\n   --SDP not shown--\n   The caller generates\
    \ an ACK (message 5).\n   ACK sip:B@pc.example.com\n   Route: <sip:app.example.com;lr>\n\
    \   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9zz9\n   From: Caller <sip:A@example.com>;tag=kkaz-\n\
    \   To: Callee <sip:B@example.com>;tag=7777\n   Call-ID: fa77as7dad8-sd98ajzz@host.example.com\n\
    \   CSeq: 1 ACK\n   The ACK is forwarded to the called party (message 6).\n  \
    \ ACK sip:B@pc.example.com\n   Via: SIP/2.0/TLS app.example.com;branch=z9hG4bKh7s\n\
    \   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9zz9\n   From: Caller <sip:A@example.com>;tag=kkaz-\n\
    \   To: Callee <sip:B@example.com>;tag=7777\n   Call-ID: fa77as7dad8-sd98ajzz@host.example.com\n\
    \   CSeq: 1 ACK\n   Now, the application decides to push a user interface component\
    \ to\n   user A.  So, it sends it a REFER request (message 7):\n   <allOneLine>\n\
    \   REFER sip:A@example.com;gr=urn:uuid:f81d4fae\n   -7dec-11d0-a765-00a0c91e6bf6\
    \ SIP/2.0\n   </allOneLine>\n   Refer-To: https://app.example.com/script.pl\n\
    \   Target-Dialog: fa77as7dad8-sd98ajzz@host.example.com\n     ;remote-tag=7777;local-tag=kkaz-\n\
    \   Require: tdialog\n   Via: SIP/2.0/TLS app.example.com;branch=z9hG4bK9zh6\n\
    \   Max-Forwards: 70\n   From: Recorder Application <sip:app.example.com>;tag=jhgf\n\
    \   <allOneLine>\n   To: Caller <sip:A@example.com;gr=urn:uuid:f81d4fae\n   -7dec-11d0-a765-00a0c91e6bf6>\n\
    \   </allOneLine>\n   Require: tdialog\n   Allow: INVITE, OPTIONS, BYE, CANCEL,\
    \ ACK, REFER\n   Call-ID: 66676776767@app.example.com\n   CSeq: 1 REFER\n   Event:\
    \ refer\n   Contact: <sip:app.example.com>\n   Since the recording application\
    \ is the same as the authoritative\n   proxy for the domain, it resolves the Request\
    \ URI to the registered\n   contact of A, and then sent there.  The REFER is answered\
    \ by a 200 OK\n   (message 8).\n   SIP/2.0 200 OK\n   Via: SIP/2.0/TLS app.example.com;branch=z9hG4bK9zh6\n\
    \   From: Recorder Application <sip:app.example.com>;tag=jhgf\n   To: Caller <sip:A@example.com>;tag=pqoew\n\
    \   Call-ID: 66676776767@app.example.com\n   Supported: gruu, tdialog\n   Allow:\
    \ INVITE, OPTIONS, BYE, CANCEL, ACK, REFER\n   <allOneLine>\n   Contact: <sip:A@example.com;gr=urn:uuid:f81d4fae\n\
    \   -7dec-11d0-a765-00a0c91e6bf6>;schemes=\"http,sip\"\n   </allOneLine>\n   CSeq:\
    \ 1 REFER\n   User A sends a NOTIFY (message 9):\n   NOTIFY sip:app.example.com\
    \ SIP/2.0\n   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9320394238995\n\
    \   To: Recorder Application <sip:app.example.com>;tag=jhgf\n   From: Caller <sip:A@example.com>;tag=pqoew\n\
    \   Call-ID: 66676776767@app.example.com\n   CSeq: 1 NOTIFY\n   Max-Forwards:\
    \ 70\n   <allOneLine>\n   Contact: <sip:A@example.com;gr=urn:uuid:f81d4fae\n \
    \  -7dec-11d0-a765-00a0c91e6bf6>;schemes=\"http,sip\"\n   </allOneLine>\n   Event:\
    \ refer;id=93809824\n   Subscription-State: active;expires=3600\n   Content-Type:\
    \ message/sipfrag;version=2.0\n   Content-Length: 20\n   SIP/2.0 100 Trying\n\
    \   And the recording server responds with a 200 OK (message 10).\n   SIP/2.0\
    \ 200 OK\n   Via: SIP/2.0/TLS host.example.com;branch=z9hG4bK9320394238995\n \
    \  To: Recorder Application <sip:app.example.com>;tag=jhgf\n   From: Caller <sip:A@example.com>;tag=pqoew\n\
    \   Call-ID: 66676776767@app.example.com\n   CSeq: 1 NOTIFY\n   The REFER request\
    \ contained a Target-Dialog header field parameter\n   with a valid dialog identifier.\
    \  Furthermore, all of the signaling\n   was over TLS and the dialog identifiers\
    \ contain sufficient\n   randomness.  As such, the caller, A, automatically authorizes\
    \ the\n   application.  It then acts on the Refer-To URI, fetching the script\n\
    \   from app.example.com (message 11).  The response, message 12,\n   contains\
    \ a web application that the user can click on to enable\n   recording.  Because\
    \ the client executed the URL in the Refer-To, it\n   generates another NOTIFY\
    \ to the application, informing it of the\n   successful response (message 13).\
    \  This is answered with a 200 OK\n   (message 14).  When the user clicks on the\
    \ link (message 15), the\n   results are posted to the server, and an updated\
    \ display is provided\n   (message 16).\n"
- title: 13.  Security Considerations
  contents:
  - "13.  Security Considerations\n   There are many security considerations associated\
    \ with this\n   framework.  It allows applications in the network to instantiate\
    \ user\n   interface components on a client device.  Such instantiations need\
    \ to\n   be from authenticated applications, and also need to be authorized to\n\
    \   place a UI into the client.  Indeed, the stronger requirement is\n   authorization.\
    \  It is not as important to know the name of the\n   provider of the application,\
    \ as it is to know that the provider is\n   authorized to instantiate components.\n\
    \   This specification defines specific authorization techniques and\n   requirements.\
    \  Automatic authorization is granted if the application\n   can prove that it\
    \ is on the call path, or is trusted by an element on\n   the call path.  As documented\
    \ above, this can be accomplished by the\n   use of cryptographically random dialog\
    \ identifiers and the usage of\n   SIPS for message confidentiality.  It is RECOMMENDED\
    \ that SIPS be\n   implemented by user agents compliant to this specification.\
    \  This\n   does not represent a change from the requirements in RFC 3261.\n"
- title: 14.  Contributors
  contents:
  - "14.  Contributors\n   This document was produced as a result of discussions amongst\
    \ the\n   application interaction design team.  All members of this team\n   contributed\
    \ significantly to the ideas embodied in this document.\n   The members of this\
    \ team were:\n   Eric Burger\n   Cullen Jennings\n   Robert Fairlie-Cuninghame\n"
- title: 15.  Acknowledgements
  contents:
  - "15.  Acknowledgements\n   The authors would like to thank Martin Dolly and Rohan\
    \ Mahy for their\n   input and comments.  Thanks to Allison Mankin for her support\
    \ of this\n   work.\n"
- title: 16.  References
  contents:
  - '16.  References

    '
- title: 16.1.  Normative References
  contents:
  - "16.1.  Normative References\n   [1]   Bradner, S., \"Key words for use in RFCs\
    \ to Indicate Requirement\n         Levels\", BCP 14, RFC 2119, March 1997.\n\
    \   [2]   Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A.,\n     \
    \    Peterson, J., Sparks, R., Handley, M., and E. Schooler, \"SIP:\n        \
    \ Session Initiation Protocol\", RFC 3261, June 2002.\n   [3]   Rosenberg, J.\
    \ and H. Schulzrinne, \"Reliability of Provisional\n         Responses in Session\
    \ Initiation Protocol (SIP)\", RFC 3262,\n         June 2002.\n   [4]   Roach,\
    \ A., \"Session Initiation Protocol (SIP)-Specific Event\n         Notification\"\
    , RFC 3265, June 2002.\n   [5]   McGlashan, S., Lucas, B., Porter, B., Rehor,\
    \ K., Burnett, D.,\n         Carter, J., Ferrans, J., and A. Hunt, \"Voice Extensible\
    \ Markup\n         Language (VoiceXML) Version 2.0\", W3C CR CR-voicexml20-\n\
    \         20030220, February 2003.\n   [6]   Rosenberg, J., Schulzrinne, H., and\
    \ P. Kyzivat, \"Indicating\n         User Agent Capabilities in the Session Initiation\
    \ Protocol\n         (SIP)\", RFC 3840, August 2004.\n   [7]   Sparks, R., \"\
    The Session Initiation Protocol (SIP) Refer\n         Method\", RFC 3515, April\
    \ 2003.\n   [8]   Burger, E. and M. Dolly, \"A Session Initiation Protocol (SIP)\n\
    \         Event Package for Key Press Stimulus (KPML)\", RFC 4730,\n         November\
    \ 2006.\n   [9]   Rosenberg, J., \"Obtaining and Using Globally Routable User\n\
    \         Agent URIs (GRUUs) in the Session Initiation Protocol (SIP)\",\n   \
    \      RFC 5627, October 2009.\n   [10]  Rosenberg, J., \"Request Authorization\
    \ through Dialog\n         Identification in the Session Initiation Protocol (SIP)\"\
    ,\n         RFC 4538, June 2006.\n"
- title: 16.2.  Informative References
  contents:
  - "16.2.  Informative References\n   [11]  Peterson, J. and C. Jennings, \"Enhancements\
    \ for Authenticated\n         Identity Management in the Session Initiation Protocol\
    \ (SIP)\",\n         RFC 4474, August 2006.\n   [12]  Day, M., Rosenberg, J.,\
    \ and H. Sugano, \"A Model for Presence\n         and Instant Messaging\", RFC\
    \ 2778, February 2000.\n   [13]  Jennings, C., Peterson, J., and M. Watson, \"\
    Private Extensions\n         to the Session Initiation Protocol (SIP) for Asserted\
    \ Identity\n         within Trusted Networks\", RFC 3325, November 2002.\n   [14]\
    \  Rosenberg, J., \"A Framework for Conferencing with the Session\n         Initiation\
    \ Protocol (SIP)\", RFC 4353, February 2006.\n   [15]  Rosenberg, J., Schulzrinne,\
    \ H., and P. Kyzivat, \"Caller\n         Preferences for the Session Initiation\
    \ Protocol (SIP)\",\n         RFC 3841, August 2004.\n   [16]  Rosenberg, J.,\
    \ Schulzrinne, H., and R. Mahy, \"An INVITE-\n         Initiated Dialog Event\
    \ Package for the Session Initiation\n         Protocol (SIP)\", RFC 4235, November\
    \ 2005.\n   [17]  Sparks, R., Hawrylyshen, A., Johnston, A., Rosenberg, J., and\n\
    \         H. Schulzrinne, \"Session Initiation Protocol (SIP) Torture Test\n \
    \        Messages\", RFC 4475, May 2006.\n   [18]  Schulzrinne, H., Casner, S.,\
    \ Frederick, R., and V. Jacobson,\n         \"RTP: A Transport Protocol for Real-Time\
    \ Applications\", STD 64,\n         RFC 3550, July 2003.\n   [19]  Schulzrinne,\
    \ H. and T. Taylor, \"RTP Payload for DTMF Digits,\n         Telephony Tones,\
    \ and Telephony Signals\", RFC 4733, December\n         2006.\n   [20]  Rosenberg,\
    \ J. and H. Schulzrinne, \"An Offer/Answer Model with\n         Session Description\
    \ Protocol (SDP)\", RFC 3264, June 2002.\n   [21]  Rosenberg, J., \"A Session\
    \ Initiation Protocol (SIP) Event\n         Package for Registrations\", RFC 3680,\
    \ March 2004.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Jonathan Rosenberg\n   Cisco Systems\n   600 Lanidex Plaza\n\
    \   Parsippany, NJ  07054\n   US\n   Phone: +1 973 952-5000\n   EMail: jdrosen@cisco.com\n\
    \   URI:   http://www.jdrosen.net\n"
