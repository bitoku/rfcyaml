- title: __initial_text__
  contents:
  - '                    TCP Congestion Window Validation

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo defines an Experimental Protocol for the Internet\n\
    \   community.  It does not specify an Internet standard of any kind.\n   Discussion\
    \ and suggestions for improvement are requested.\n   Distribution of this memo\
    \ is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2000).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   TCP's congestion window controls the number of packets a TCP flow\
    \ may\n   have in the network at any time.  However, long periods when the\n \
    \  sender is idle or application-limited can lead to the invalidation of\n   the\
    \ congestion window, in that the congestion window no longer\n   reflects current\
    \ information about the state of the network.  This\n   document describes a simple\
    \ modification to TCP's congestion control\n   algorithms to decay the congestion\
    \ window cwnd after the transition\n   from a sufficiently-long application-limited\
    \ period, while using the\n   slow-start threshold ssthresh to save information\
    \ about the previous\n   value of the congestion window.\n   An invalid congestion\
    \ window also results when the congestion window\n   is increased (i.e., in TCP's\
    \ slow-start or congestion avoidance\n   phases) during application-limited periods,\
    \ when the previous value\n   of the congestion window might never have been fully\
    \ utilized.  We\n   propose that the TCP sender should not increase the congestion\
    \ window\n   when the TCP sender has been application-limited (and therefore has\n\
    \   not fully used the current congestion window).  We have explored\n   these\
    \ algorithms both with simulations and with experiments from an\n   implementation\
    \ in FreeBSD.\n"
- title: 1.  Conventions and Acronyms
  contents:
  - "1.  Conventions and Acronyms\n   The keywords MUST, MUST NOT, REQUIRED, SHALL,\
    \ SHALL NOT, SHOULD,\n   SHOULD NOT, RECOMMENDED, MAY, and OPTIONAL, when they\
    \ appear in this\n   document, are to be interpreted as described in [B97].\n"
- title: 2. Introduction
  contents:
  - "2. Introduction\n   TCP's congestion window controls the number of packets a\
    \ TCP flow may\n   have in the network at any time.  The congestion window is\
    \ set using\n   an Additive-Increase, Multiplicative-Decrease (AIMD) mechanism\
    \ that\n   probes for available bandwidth, dynamically adapting to changing\n\
    \   network conditions.  This AIMD mechanism works well when the sender\n   continually\
    \ has data to send, as is typically the case for TCP used\n   for bulk-data transfer.\
    \  In contrast, for TCP used with telnet\n   applications, the data sender often\
    \ has little or no data to send,\n   and the sending rate is often determined\
    \ by the rate at which data is\n   generated by the user.  With the advent of\
    \ the web, including\n   developments such as TCP senders with dynamically-created\
    \ data and\n   HTTP 1.1 with persistent-connection TCP, the interaction between\n\
    \   application-limited periods (when the sender sends less than is\n   allowed\
    \ by the congestion or receiver windows) and network-limited\n   periods (when\
    \ the sender is limited by the TCP window) becomes\n   increasingly important.\
    \  More precisely, we define a network-limited\n   period as any period when the\
    \ sender is sending a full window of\n   data.\n   Long periods when the sender\
    \ is application-limited can lead to the\n   invalidation of the congestion window.\
    \  During periods when the TCP\n   sender is network-limited, the value of the\
    \ congestion window is\n   repeatedly \"revalidated\" by the successful transmission\
    \ of a window\n   of data without loss.  When the TCP sender is network-limited,\
    \ there\n   is an incoming stream of acknowledgements that \"clocks out\" new\
    \ data,\n   giving concrete evidence of recent available bandwidth in the\n  \
    \ network.  In contrast, during periods when the TCP sender is\n   application-limited,\
    \ the estimate of available capacity represented\n   by the congestion window\
    \ may become steadily less accurate over time.\n   In particular, capacity that\
    \ had once been used by the network-\n   limited connection might now be used\
    \ by other traffic.\n   Current TCP implementations have a range of behaviors\
    \ for starting up\n   after an idle period.  Some current TCP implementations\
    \ slow-start\n   after an idle period longer than the RTO estimate, as suggested\
    \ in\n   [RFC2581] and in the appendix of [VJ88], while other implementations\n\
    \   don't reduce their congestion window after an idle period.  RFC 2581\n   [RFC2581]\
    \ recommends the following: \"a TCP SHOULD set cwnd to no more\n   than RW [the\
    \ initial window] before beginning transmission if the TCP\n   has not sent data\
    \ in an interval exceeding the retransmission\n   timeout.\"  A proposal for TCP's\
    \ slow-start after idle has also been\n   discussed in [HTH98].  The issue of\
    \ validation of congestion\n   information during idle periods has also been addressed\
    \ in contexts\n   other than TCP and IP, for example in \"Use-it or Lose-it\"\
    \ mechanisms\n   for ATM networks [J96,J95].\n   To address the revalidation of\
    \ the congestion window after a\n   application-limited period, we propose a simple\
    \ modification to TCP's\n   congestion control algorithms to decay the congestion\
    \ window cwnd\n   after the transition from a sufficiently-long application-limited\n\
    \   period (i.e., at least one roundtrip time) to a network-limited\n   period.\
    \  In particular, we propose that after an idle period, the TCP\n   sender should\
    \ reduce its congestion window by half for every RTT that\n   the flow has remained\
    \ idle.\n   When the congestion window is reduced, the slow-start threshold\n\
    \   ssthresh remains as \"memory\" of the recent congestion window.\n   Specifically,\
    \ ssthresh is never decreased when cwnd is reduced after\n   an application-limited\
    \ period; before cwnd is reduced, ssthresh is\n   set to the maximum of its current\
    \ value, and half-way between the old\n   and the new values of cwnd.  This use\
    \ of ssthresh allows a TCP sender\n   increasing its sending rate after an application-limited\
    \ period to\n   quickly slow-start to recover most of the previous value of the\n\
    \   congestion window.  To be more precise, if ssthresh is less than 3/4\n   cwnd\
    \ when the congestion window is reduced after an application-\n   limited period,\
    \ then ssthresh is increased to 3/4 cwnd before the\n   reduction of the congestion\
    \ window.\n   An invalid congestion window also results when the congestion window\n\
    \   is increased (i.e., in TCP's slow-start or congestion avoidance\n   phases)\
    \ during application-limited periods, when the previous value\n   of the congestion\
    \ window might never have been fully utilized.  As\n   far as we know, all current\
    \ TCP implementations increase the\n   congestion window when an acknowledgement\
    \ arrives, if allowed by the\n   receiver's advertised window and the slow-start\
    \ or congestion\n   avoidance window increase algorithm, without checking to see\
    \ if the\n   previous value of the congestion window has in fact been used.  This\n\
    \   document proposes that the window increase algorithm not be invoked\n   during\
    \ application-limited periods [MSML99].  In particular, the TCP\n   sender should\
    \ not increase the congestion window when the TCP sender\n   has been application-limited\
    \ (and therefore has not fully used the\n   current congestion window).  This\
    \ restriction prevents the congestion\n   window from growing arbitrarily large,\
    \ in the absence of evidence\n   that the congestion window can be supported by\
    \ the network.  From\n   [MSML99, Section 5.2]: \"This restriction assures that\
    \ [cwnd] only\n   grows as long as TCP actually succeeds in injecting enough data\
    \ into\n   the network to test the path.\"\n   A somewhat-orthogonal problem associated\
    \ with maintaining a large\n   congestion window after an application-limited\
    \ period is that the\n   sender, with a sudden large amount of data to send after\
    \ a quiescent\n   period, might immediately send a full congestion window of back-to-\n\
    \   back packets.  This problem of sending large bursts of packets back-\n   to-back\
    \ can be effectively handled using rate-based pacing (RBP,\n   [VH97]), or using\
    \ a maximum burst size control [FF96].  We would\n   contend that, even with mechanisms\
    \ for limiting the sending of back-\n   to-back packets or pacing packets out\
    \ over the period of a roundtrip\n   time, an old congestion window that has not\
    \ been fully used for some\n   time can not be trusted as an indication of the\
    \ bandwidth currently\n   available for that flow.  We would contend that the\
    \ mechanisms to\n   pace out packets allowed by the congestion window are largely\n\
    \   orthogonal to the algorithms used to determine the appropriate size\n   of\
    \ the congestion window.\n"
- title: 3. Description
  contents:
  - "3. Description\n   When a TCP sender has sufficient data available to fill the\
    \ available\n   network capacity for that flow, cwnd and ssthresh get set to\n\
    \   appropriate values for the network conditions.  When a TCP sender\n   stops\
    \ sending, the flow stops sampling the network conditions, and so\n   the value\
    \ of the congestion window may become inaccurate.  We believe\n   the correct\
    \ conservative behavior under these circumstances is to\n   decay the congestion\
    \ window by half for every RTT that the flow\n   remains inactive.  The value\
    \ of half is a very conservative figure\n   based on how quickly multiplicative\
    \ decrease would have decayed the\n   window in the presence of loss.\n   Another\
    \ possibility is that the sender may not stop sending, but may\n   become application-limited\
    \ rather than network-limited, and offer\n   less data to the network than the\
    \ congestion window allows to be\n   sent.  In this case the TCP flow is still\
    \ sampling network\n   conditions, but is not offering sufficient traffic to be\
    \ sure that\n   there is still sufficient capacity in the network for that flow\
    \ to\n   send a full congestion window.  Under these circumstances we believe\n\
    \   the correct conservative behavior is for the sender to keep track of\n   the\
    \ maximum amount of the congestion window used during each RTT, and\n   to decay\
    \ the congestion window each RTT to midway between the current\n   cwnd value\
    \ and the maximum value used.\n   Before the congestion window is reduced, ssthresh\
    \ is set to the\n   maximum of its current value and 3/4 cwnd.  If the sender\
    \ then has\n   more data to send than the decayed cwnd allows, the TCP will slow-\n\
    \   start (perform exponential increase) at least half-way back up to the\n  \
    \ old value of cwnd.\n   The justification for this value of \"3/4 cwnd\" is that\
    \ 3/4 cwnd is a\n   conservative estimate of the recent average value of the congestion\n\
    \   window, and the TCP should safely be able to slow-start at least up\n   to\
    \ this point.  For a TCP in steady-state that has been reducing its\n   congestion\
    \ window each time the congestion window reached some\n   maximum value `maxwin',\
    \ the average congestion window has been 3/4\n   maxwin.  On average, when the\
    \ connection becomes application-limited,\n   cwnd will be 3/4 maxwin, and in\
    \ this case cwnd itself represents the\n   average value of the congestion window.\
    \  However, if the connection\n   happens to become application-limited when cwnd\
    \ equals maxwin, then\n   the average value of the congestion window is given\
    \ by 3/4 cwnd.\n   An alternate possibility would be to set ssthresh to the maximum\
    \ of\n   the current value of ssthresh, and the old value of cwnd, allowing\n\
    \   TCP to slow-start all of the way back up to the old value of cwnd.\n   Further\
    \ experimentation can be used to evaluate these two options for\n   setting ssthresh.\n\
    \   For the separate issue of the increase of the congestion window in\n   response\
    \ to an acknowledgement, we believe the correct behavior is\n   for the sender\
    \ to increase the congestion window only if the window\n   was full when the acknowledgment\
    \ arrived.\n   We term this set of modifications to TCP Congestion Window Validation\n\
    \   (CWV) because they are related to ensuring the congestion window is\n   always\
    \ a valid reflection of the current network state as probed by\n   the connection.\n"
- title: 3.1. The basic algorithm for reducing the congestion window
  contents:
  - "3.1. The basic algorithm for reducing the congestion window\n   A key issue in\
    \ the CWV algorithm is to determine how to apply the\n   guideline of reducing\
    \ the congestion window once for every roundtrip\n   time that the flow is application-limited.\
    \  We use TCP's\n   retransmission timer (RTO) as a reasonable upper bound on\
    \ the\n   roundtrip time, and reduce the congestion window roughly once per\n\
    \   RTO.\n   This basic algorithm could be implemented in TCP as follows: When\
    \ TCP\n   sends a new packet it checks to see if more than RTO seconds have\n\
    \   elapsed since the previous packet was sent.  If RTO has elapsed,\n   ssthresh\
    \ is set to the maximum of 3/4 cwnd and the current value of\n   ssthresh, and\
    \ then the congestion window is halved for every RTO that\n   elapsed since the\
    \ previous packet was sent.  In addition, T_prev is\n   set to the current time,\
    \ and W_used is reset to zero.  T_prev will be\n   used to determine the elapsed\
    \ time since the sender last was network-\n   limited or had reduced cwnd after\
    \ an idle period.  When the sender is\n   application-limited, W_used holds the\
    \ maximum congestion window\n   actually used since the sender was last network-limited.\n\
    \   The mechanism for determining the number of RTOs in the most recent\n   idle\
    \ period could also be implemented by using a timer that expires\n   every RTO\
    \ after the last packet was sent instead of a check per\n   packet - efficiency\
    \ constraints on different operating systems may\n   dictate which is more efficient\
    \ to implement.\n   After TCP sends a packet, it also checks to see if that packet\
    \ filled\n   the congestion window.  If so, the sender is network-limited, and\n\
    \   sets the variable T_prev to the current TCP clock time, and the\n   variable\
    \ W_used to zero.\n   When TCP sends a packet that does not fill the congestion\
    \ window, and\n   the TCP send queue is empty, then the sender is application-limited.\n\
    \   The sender checks to see if the amount of unacknowledged data is\n   greater\
    \ than W_used; if so, W_used is set to the amount of\n   unacknowledged data.\
    \  In addition TCP checks to see if the elapsed\n   time since T_prev is greater\
    \ than RTO.  If so, then the TCP has not\n   just reduced its congestion window\
    \ following an idle period.  The TCP\n   has been application-limited rather than\
    \ network-limited for at least\n   an entire RTO interval, but for less than two\
    \ RTO intervals.  In this\n   case, TCP sets ssthresh to the maximum of 3/4 cwnd\
    \ and the current\n   value of ssthresh, and reduces its congestion window to\n\
    \   (cwnd+W_used)/2.  W_used is then set to zero, and T_prev is set to\n   the\
    \ current time, so a further reduction will not take place until at\n   least\
    \ another RTO period has elapsed.  Thus, during an application-\n   limited period\
    \ the CWV algorithm reduces the congestion window once\n   per RTO.\n"
- title: 3.2.  Pseudo-code for reducing the congestion window
  contents:
  - "3.2.  Pseudo-code for reducing the congestion window\n   Initially:\n       T_last\
    \ = tcpnow, T_prev = tcpnow, W_used = 0\n   After sending a data segment:\n  \
    \     If tcpnow - T_last >= RTO\n           (The sender has been idle.)\n    \
    \       ssthresh =  max(ssthresh, 3*cwnd/4)\n           For i=1  To (tcpnow -\
    \ T_last)/RTO\n               win =  min(cwnd, receiver's declared max window)\n\
    \               cwnd =  max(win/2, MSS)\n           T_prev = tcpnow\n        \
    \   W_used = 0\n       T_last = tcpnow\n       If window is full\n           T_prev\
    \ = tcpnow\n           W_used = 0\n       Else\n           If no more data is\
    \ available to send\n               W_used =  max(W_used, amount of unacknowledged\
    \ data)\n               If tcpnow - T_prev >= RTO\n                   (The sender\
    \ has been application-limited.)\n                   ssthresh =  max(ssthresh,\
    \ 3*cwnd/4)\n                   win =  min(cwnd, receiver's declared max window)\n\
    \                   cwnd = (win + W_used)/2\n                   T_prev = tcpnow\n\
    \                   W_used = 0\n"
- title: 4. Simulations
  contents:
  - "4. Simulations\n   The CWV proposal has been implemented as an option in the\
    \ network\n   simulator NS [NS].  The simulations in the validation test suite\
    \ for\n   CWV can be run with the command \"./test-all-tcp\" in the directory\n\
    \   \"tcl/test\".  The simulations show the use of CWV to reduce the\n   congestion\
    \ window after a period when the TCP connection was\n   application-limited, and\
    \ to limit the increase in the congestion\n   window when a transfer is application-limited.\
    \  As the simulations\n   illustrate, the use of ssthresh to maintain connection\
    \ history is a\n   critical part of the Congestion Window Validation algorithm.\
    \  [HPF99]\n   discusses these simulations in more detail.\n"
- title: 5. Experiments
  contents:
  - "5. Experiments\n   We have implemented the CWV mechanism in the TCP implementation\
    \ in\n   FreeBSD 3.2.  [HPF99] discusses these experiments in more detail.\n \
    \  The first experiment examines the effects of the Congestion Window\n   Validation\
    \ mechanisms for limiting cwnd increases during\n   application-limited periods.\
    \  The experiment used a real ssh\n   connection through a modem link emulated\
    \ using Dummynet [Dummynet].\n   The link speed is 30Kb/s and the link has five\
    \ packet buffers\n   available.  Today most modem banks have more buffering available\
    \ than\n   this, but the more buffer-limited situation sometimes occurs with\n\
    \   older modems.  In the first half of the transfer, the user is typing\n   away\
    \ over the connection.  About half way through the time, the user\n   lists a\
    \ moderately large file, which causes a large burst of traffic\n   to be transmitted.\n\
    \   For the unmodified TCP, every returning ACK during the first part of\n   the\
    \ transfer results in an increase in cwnd.  As a result, the large\n   burst of\
    \ data arriving from the application to the transport layer is\n   sent as many\
    \ back-to-back packets, most of which get lost and\n   subsequently retransmitted.\n\
    \   For the modified TCP with Congestion Window Validation, the\n   congestion\
    \ window is not increased when the window is not full, and\n   has been decreased\
    \ during application-limited periods closer to what\n   the user actually used.\
    \  The burst of traffic is now constrained by\n   the congestion window, resulting\
    \ in a better-behaved flow with\n   minimal loss.  The end result is that the\
    \ transfer happens\n   approximately 30% faster than the transfer without CWV,\
    \ due to\n   avoiding retransmission timeouts.\n   The second experiment uses\
    \ a real ssh connection over a real dialup\n   ppp connection, where the modem\
    \ bank has much more buffering.  For\n   the unmodified TCP, the initial burst\
    \ from the large file does not\n   cause loss, but does cause the RTT to increase\
    \ to approximately 5\n   seconds, where the connection becomes bounded by the\
    \ receiver's\n   window.\n   For the modified TCP with Congestion Window Validation,\
    \ the flow is\n   much better behaved, and produces no large burst of traffic.\
    \  In this\n   case the linear increase for cwnd results in a slow increase in\
    \ the\n   RTT as the buffer slowly fills.\n   For the second experiment, both\
    \ the modified and the unmodified TCP\n   finish delivering the data at precisely\
    \ the same time.  This is\n   because the link has been fully utilized in both\
    \ cases due to the\n   modem buffer being larger than the receiver window.  Clearly\
    \ a modem\n   buffer of this size is undesirable due to its effect on the RTT\
    \ of\n   competing flows, but it is necessary with current TCP implementations\n\
    \   that produce bursts similar to those shown in the top graph.\n"
- title: 6. Conclusions
  contents:
  - "6. Conclusions\n   This document has presented several TCP algorithms for Congestion\n\
    \   Window Validation, to be employed after an idle period or a period in\n  \
    \ which the sender was application-limited, and before an increase of\n   the\
    \ congestion window.  The goal of these algorithms is for TCP's\n   congestion\
    \ window to reflect recent knowledge of the TCP connection\n   about the state\
    \ of the network path, while at the same time keeping\n   some memory (i.e., in\
    \ ssthresh) about the earlier state of the path.\n   We believe that these modifications\
    \ will be of benefit to both the\n   network and to the TCP flows themselves,\
    \ by preventing unnecessary\n   packet drops due to the TCP sender's failure to\
    \ update its\n   information (or lack of information) about current network\n\
    \   conditions.  Future work will document and investigate the benefit\n   provided\
    \ by these algorithms, using both simulations and experiments.\n   Additional\
    \ future work will describe a more complex version of the\n   CWV algorithm for\
    \ TCP implementations where the sender does not have\n   an accurate estimate\
    \ of the TCP roundtrip time.\n"
- title: 7. References
  contents:
  - "7. References\n   [FF96]     Fall, K., and Floyd, S., Simulation-based Comparisons\
    \ of\n              Tahoe, Reno, and SACK TCP, Computer Communication Review,\n\
    \              V. 26 N. 3, July 1996, pp. 5-21.  URL\n              \"http://www.aciri.org/floyd/papers.html\"\
    .\n   [HPF99]    Mark Handley, Jitendra Padhye, Sally Floyd, TCP Congestion\n\
    \              Window Validation, UMass CMPSCI Technical Report 99-77,\n     \
    \         September 1999.  URL \"ftp://www-\n              net.cs.umass.edu/pub/Handley99-tcpq-tr-99-77.ps.gz\"\
    .\n   [HTH98]    Amy Hughes, Joe Touch, John Heidemann, \"Issues in TCP\n    \
    \          Slow-Start Restart After Idle\", Work in Progress.\n   [J88]      Jacobson,\
    \ V., Congestion Avoidance and Control, Originally\n              from Proceedings\
    \ of SIGCOMM '88 (Palo Alto, CA, Aug.\n              1988), and revised in 1992.\
    \  URL \"http://www-\n              nrg.ee.lbl.gov/nrg-papers.html\".\n   [JKBFL96]\
    \  Raj Jain, Shiv Kalyanaraman, Rohit Goyal, Sonia Fahmy, and\n              Fang\
    \ Lu, Comments on \"Use-it or Lose-it\", ATM Forum\n              Document Number:\
    \  ATM Forum/96-0178, URL\n              \"http://www.netlab.ohio-\n         \
    \     state.edu/~jain/atmf/af_rl5b2.htm\".\n   [JKGFL95]  R. Jain, S. Kalyanaraman,\
    \ R. Goyal, S. Fahmy, and F. Lu, A\n              Fix for Source End System Rule\
    \ 5, AF-TM 95-1660, December\n              1995, URL \"http://www.netlab.ohio-\n\
    \              state.edu/~jain/atmf/af_rl52.htm\".\n   [MSML99]   Matt Mathis,\
    \ Jeff Semke, Jamshid Mahdavi, and Kevin Lahey,\n              The Rate-Halving\
    \ Algorithm for TCP Congestion Control,\n              June 1999.  URL\n     \
    \         \"http://www.psc.edu/networking/ftp/papers/draft-\n              ratehalving.txt\"\
    .\n   [NS]       NS, the UCB/LBNL/VINT Network Simulator.  URL\n             \
    \ \"http://www-mash.cs.berkeley.edu/ns/\".\n   [RFC2581]  Allman, M., Paxson,\
    \ V. and W. Stevens, TCP Congestion\n              Control, RFC 2581, April 1999.\n\
    \   [VH97]     Vikram Visweswaraiah and John Heidemann. Improving Restart\n  \
    \            of Idle TCP Connections, Technical Report 97-661,\n             \
    \ University of Southern California, November, 1997.\n   [Dummynet] Luigi Rizzo,\
    \ \"Dummynet and Forward Error Correction\",\n              Freenix 98, June 1998,\
    \ New Orleans.  URL\n              \"http://info.iet.unipi.it/~luigi/ip_dummynet/\"\
    .\n"
- title: 8. Security Considerations
  contents:
  - "8. Security Considerations\n   General security considerations concerning TCP\
    \ congestion control are\n   discussed in RFC 2581.  This document describes a\
    \ algorithm for one\n   aspect of those congestion control procedures, and so\
    \ the\n   considerations described in RFC 2581 apply to this algorithm also.\n\
    \   There are no known additional security concerns for this specific\n   algorithm.\n"
- title: 9. Authors' Addresses
  contents:
  - "9. Authors' Addresses\n   Mark Handley\n   AT&T Center for Internet Research\
    \ at ICSI (ACIRI)\n   Phone: +1 510 666 2946\n   EMail: mjh@aciri.org\n   URL:\
    \ http://www.aciri.org/mjh/\n   Jitendra Padhye\n   AT&T Center for Internet Research\
    \ at ICSI (ACIRI)\n   Phone: +1 510 666 2887\n   EMail: padhye@aciri.org\n   URL:\
    \ http://www-net.cs.umass.edu/~jitu/\n   Sally Floyd\n   AT&T Center for Internet\
    \ Research at ICSI (ACIRI)\n   Phone: +1 510 666 2989\n   EMail: floyd@aciri.org\n\
    \   URL:  http://www.aciri.org/floyd/\n"
- title: 10. Full Copyright Statement
  contents:
  - "10. Full Copyright Statement\n   Copyright (C) The Internet Society (2000). \
    \ All Rights Reserved.\n   This document and translations of it may be copied\
    \ and furnished to\n   others, and derivative works that comment on or otherwise\
    \ explain it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
