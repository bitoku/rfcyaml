- title: __initial_text__
  contents:
  - '            An Overview of Reliable Server Pooling Protocols

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   The Reliable Server Pooling effort (abbreviated \"RSerPool\") provides\n\
    \   an application-independent set of services and protocols for building\n  \
    \ fault-tolerant and highly available client/server applications.  This\n   document\
    \ provides an overview of the protocols and mechanisms in the\n   Reliable Server\
    \ Pooling suite.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Aggregate Server Access Protocol (ASAP) Overview ................6\n  \
    \    2.1. Pool Initialization ........................................6\n    \
    \  2.2. Pool Entity Registration ...................................6\n      2.3.\
    \ Pool Entity Selection ......................................7\n      2.4. Endpoint\
    \ Keep-Alive ........................................7\n      2.5. Failover Services\
    \ ..........................................7\n           2.5.1. Cookie Mechanism\
    \ ....................................7\n           2.5.2. Business Card Mechanism\
    \ .............................8\n   3. Endpoint Handlespace Redundancy Protocol\
    \ (ENRP) Overview ........8\n      3.1. Initialization .............................................8\n\
    \      3.2. Server Discovery and Home Server Selection .................8\n  \
    \    3.3. Failure Detection, Handlespace Audit, and Synchronization ..9\n    \
    \  3.4. Server Takeover ............................................9\n   4. Example\
    \ Scenarios ...............................................9\n      4.1. Example\
    \ Scenario Using RSerPool Resolution Service .........9\n      4.2. Example Scenario\
    \ Using RSerPool Session Services ..........11\n   5. Reference Implementation\
    \ .......................................12\n   6. Security Considerations ........................................12\n\
    \   7. IANA Considerations ............................................12\n  \
    \ 8. Acknowledgements ...............................................12\n   9.\
    \ References .....................................................13\n      9.1.\
    \ Normative References ......................................13\n      9.2. Informative\
    \ References ....................................13\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The Reliable Server Pooling (RSerPool) protocol suite is\
    \ designed to\n   provide client applications (\"pool users\") with the ability\
    \ to select\n   a server (a \"pool element\") from among a group of servers providing\n\
    \   equivalent service (a \"pool\").  The protocols are currently targeted\n \
    \  for Experimental Track.\n   The RSerPool architecture supports high availability\
    \ and load\n   balancing by enabling a pool user to identify the most appropriate\n\
    \   server from the server pool at a given time.  The architecture is\n   defined\
    \ to support a set of basic goals:\n   o  application-independent protocol mechanisms\n\
    \   o  separation of server naming from IP addressing\n   o  use of the end-to-end\
    \ principle to avoid dependencies on\n      intermediate equipment\n   o  separation\
    \ of session availability/failover functionality from the\n      application itself\n\
    \   o  facilitation of different server selection policies\n   o  facilitation\
    \ of a set of application-independent failover\n      capabilities\n   o  peer-to-peer\
    \ structure\n   The basic components of the RSerPool architecture are shown in\n\
    \   Figure 1 below:\n                                           .......................\n\
    \         ______          ______            .      +-------+      .\n        /\
    \ ENRP \\        / ENRP \\           .      |       |      .\n        |Server|\
    \ <----> |Server|<----------.----->|  PE 1 |      .\n        \\______/  ENRP \
    \ \\______/  ASAP(1)  .      |       |      .\n                           ^  \
    \             .      +-------+      .\n                           |          \
    \     .                     .\n                           | ASAP(2)       .  \
    \   Server Pool     .\n                           V               .          \
    \           .\n                      +-------+            .      +-------+   \
    \   .\n                      |       |            .      |       |      .\n  \
    \                    |  PU   |<---------->.      |  PE 2 |      .\n          \
    \            |       |  PU to PE  .      |       |      .\n                  \
    \    +-------+            .      +-------+      .\n                          \
    \                 .                     .\n                                  \
    \         .      +-------+      .\n                                          \
    \ .      |       |      .\n                                           .      |\
    \  PE 3 |      .\n                                           .      |       |\
    \      .\n                                           .      +-------+      .\n\
    \                                           .......................\n        \
    \                         Figure 1\n   A server pool is defined as a set of one\
    \ or more servers providing\n   the same application functionality.  The servers\
    \ are called Pool\n   Elements (PEs).  Multiple PEs in a server pool can be used\
    \ to provide\n   fault tolerance or load sharing, for example.  The PEs register\
    \ into\n   and de-register out of the pool at an entity called the Endpoint\n\
    \   haNdlespace Redundancy Protocol (ENRP) server, using the Aggregate\n   Server\
    \ Access Protocol (ASAP) [RFC5352] (this association is labeled\n   ASAP(1) in\
    \ the figure).\n   Each server pool is identified by a unique byte string called\
    \ the\n   pool handle (PH).  The pool handle allows a mapping from the pool to\n\
    \   a specific PE located by its IP address (both IPv4 and IPv6 PE\n   addresses\
    \ are supported) and port number.  The pool handle is what is\n   specified by\
    \ the Pool User (PU) when it attempts to access a server\n   in the pool.  To\
    \ resolve the pool handle to the address necessary to\n   access a PE, the PU\
    \ consults an ENRP server using ASAP (this\n   association is labeled ASAP(2)\
    \ in the figure).  The space of pool\n   handles is assumed to be a flat space\
    \ with limited operational scope\n   (see RFC 3237 [RFC3237]).  Administration\
    \ of pool handles is not\n   addressed by the RSerPool protocol documents at this\
    \ time.  The\n   protocols used between the PU and PE are application-specific.\
    \  It is\n   assumed that the PU and PE are configured to support a common set\
    \ of\n   protocols for application layer communication, independent of the\n \
    \  RSerPool mechanisms.\n   RSerPool provides a number of tools to aid client\
    \ migration between\n   servers on server failure: it allows the client to identify\n\
    \   alternative servers, either on initial discovery or in real time; it\n   also\
    \ allows the original server to provide a state cookie to the\n   client that\
    \ can be forwarded to an alternative server to provide\n   application-specific\
    \ state information.  This information is\n   exchanged between the PE and PU\
    \ directly, over the association\n   labeled PU to PE in the figure.\n   It is\
    \ envisioned that ENRP servers provide a fully distributed and\n   fault-tolerant\
    \ registry service.  They use ENRP [RFC5353] to maintain\n   synchronization of\
    \ data concerning the pool handle mapping space.\n   For PUs and PEs, the ENRP\
    \ servers are functionally equal.  Due to the\n   synchronization provided by\
    \ ENRP, they can contact an arbitrary one\n   for registration/de-registration\
    \ (PE) or PH resolution (PU).  An\n   illustration containing 3 ENRP servers is\
    \ provided in Figure 2 below:\n                          ______          _____\n\
    \            ...          / ENRP \\        / ENRP \\          ...\n          PEs/PUs\
    \  <---->|Server| <----> |Server|<---->  PEs/PUs\n            ...     ASAP \\\
    ______/  ENRP  \\______/ ASAP     ...\n                           ^          \
    \        ^\n                           |                  |\n                \
    \           |     / ENRP \\     |\n                           +---->|Server|<----+\n\
    \                            ENRP \\______/ ENRP\n                           \
    \         ^\n                                    | ASAP\n                    \
    \                v\n                                   ...\n                 \
    \                PEs/PUs\n                                   ...\n           \
    \                         Figure 2\n         The requirements for the Reliable\
    \ Server Pooling framework are\n         defined in RFC 3237 [RFC3237].  It is\
    \ worth noting that the\n         requirements on RSerPool in the area of load\
    \ balancing\n         partially overlap with grid computing/high-performance\n\
    \         computing.  However, the scope of both areas is completely\n       \
    \  different: grid and high-performance computing also cover\n         topics\
    \ like managing different administrative domains, data\n         locking and synchronization,\
    \ inter-session communication, and\n         resource accounting for powerful\
    \ computation services, but the\n         intention of RSerPool is simply a lightweight\
    \ realization of\n         load distribution and session management.  In particular,\
    \ these\n         functionalities are intended to be used on\n         systems\
    \ with small memory and CPU resources only.  Any further\n         functionality\
    \ is not in the scope of RSerPool and can -- if\n         necessary -- be provided\
    \ by the application itself.\n         This document provides an overview of the\
    \ RSerPool protocol\n         suite, specifically the Aggregate Server Access\
    \ Protocol (ASAP)\n         [RFC5352] and the Endpoint Handlespace Redundancy\
    \ Protocol\n         (ENRP) [RFC5353].  In addition to the protocol specifications,\n\
    \         there is a common parameter format specification [RFC5354] for\n   \
    \      both protocols, a definition of server selection rules (pool\n        \
    \ policies) [RFC5356], as well as a security threat analysis\n         [RFC5355].\n"
- title: 2.  Aggregate Server Access Protocol (ASAP) Overview
  contents:
  - "2.  Aggregate Server Access Protocol (ASAP) Overview\n   ASAP defines a straightforward\
    \ set of mechanisms necessary to support\n   the creation and maintenance of pools\
    \ of redundant servers.  These\n   mechanisms include:\n   o  registration of\
    \ a new server into a server pool\n   o  de-registration of an existing server\
    \ from a pool\n   o  resolution of a pool handle to a server or list of servers\n\
    \   o  liveness detection for servers in a pool\n   o  failover mechanisms for\
    \ handling a server failure\n"
- title: 2.1.  Pool Initialization
  contents:
  - "2.1.  Pool Initialization\n   Pools come into existence when a PE registers the\
    \ first instance of\n   the pool name with an ENRP server.  They disappear when\
    \ the last PE\n   de-registers.  In other words, the starting of the first PE\
    \ on some\n   machine causes the creation of the pool when the registration reaches\n\
    \   the ENRP server.\n   It is assumed that information needed for RSerPool, such\
    \ as the\n   address of an ENRP server to contact, is configured into the PE\n\
    \   beforehand.  Methods of automating this configuration process are not\n  \
    \ addressed at this time.\n"
- title: 2.2.  Pool Entity Registration
  contents:
  - "2.2.  Pool Entity Registration\n   A new server joins an existing pool by sending\
    \ a Registration message\n   via ASAP to an ENRP server, indicating the pool handle\
    \ of the pool\n   that it wishes to join, a PE identifier for itself (chosen randomly),\n\
    \   information about its lifetime in the pool, and what transport\n   protocols\
    \ and selection policy it supports.  The ENRP server that it\n   first contacts\
    \ is called its Home ENRP server, and maintains a list\n   of subscriptions by\
    \ the PE as well as performs periodic audits to\n   confirm that the PE is still\
    \ responsive.\n   Similar procedures are applied to de-register itself from the\
    \ server\n   pool (or, alternatively, the server may simply let the lifetime that\n\
    \   it previously registered with expire, after which it is gracefully\n   removed\
    \ from the pool).\n"
- title: 2.3.  Pool Entity Selection
  contents:
  - "2.3.  Pool Entity Selection\n   When an endpoint wishes to be connected to a\
    \ server in the pool, it\n   generates an ASAP Handle Resolution message and sends\
    \ this to its\n   Home ENRP server.  The ENRP server resolves the handle based\
    \ on its\n   knowledge of pool servers and returns a Handle Resolution Response\n\
    \   message via ASAP.  The response contains a list of the IP addresses\n   of\
    \ one or more servers in the pool that can be contacted.  The\n   process by which\
    \ the list of servers is created may involve a number\n   of policies for server\
    \ selection.  The RSerPool protocol suite\n   defines a few basic policies and\
    \ allows the use of external server\n   selection input for more complex policies.\n"
- title: 2.4.  Endpoint Keep-Alive
  contents:
  - "2.4.  Endpoint Keep-Alive\n   ENRP servers monitor the status of pool elements\
    \ using the ASAP\n   Endpoint Keep-Alive message.  A PE responds to the ASAP Keep-Alive\n\
    \   message with an Endpoint Keep-Alive Ack response.\n   In addition, a PU can\
    \ notify its Home ENRP server that the PE it used\n   has become unresponsive\
    \ by sending an ASAP Endpoint Unreachable\n   message to the ENRP server.\n"
- title: 2.5.  Failover Services
  contents:
  - "2.5.  Failover Services\n   While maintaining application-independence, the RSerPool\
    \ protocol\n   suite provides some simple hooks for supporting failover of an\n\
    \   individual session with a pool element.  Generally, mechanisms for\n   failover\
    \ that rely on application state or transaction status cannot\n   be defined without\
    \ more specific knowledge of the application being\n   supported.  However, some\
    \ simple mechanisms supported by RSerPool\n   allow some level of failover that\
    \ any application can use.\n"
- title: 2.5.1.  Cookie Mechanism
  contents:
  - "2.5.1.  Cookie Mechanism\n   Cookies may optionally be generated by the ASAP\
    \ layer and\n   periodically sent from the PE to the PU.  The PU only stores the\
    \ last\n   received cookie.  In case of failover, the PU sends this last\n   received\
    \ cookie to the new PE.  This method provides a simple way of\n   state sharing\
    \ between the PEs.  Please note that the old PE should\n   sign the cookie, and\
    \ the receiving PE should verify that signature.\n   For the PU, the cookie has\
    \ no structure and is only stored and\n   transmitted to the new PE.\n"
- title: 2.5.2.  Business Card Mechanism
  contents:
  - "2.5.2.  Business Card Mechanism\n   A PE can send a business card to its peer\
    \ (PE or PU) containing its\n   pool handle and guidance concerning which other\
    \ PEs the peer should\n   use for failover.  This gives a PE a means of telling\
    \ a PU what it\n   identifies as the \"next best\" PE to use in case of failure,\
    \ which may\n   be based on pool considerations, such as load balancing, or user\n\
    \   considerations, such as PEs that have the most up-to-date state\n   information.\n"
- title: 3.  Endpoint Handlespace Redundancy Protocol (ENRP) Overview
  contents:
  - "3.  Endpoint Handlespace Redundancy Protocol (ENRP) Overview\n   A set of server\
    \ pools, which is denoted as a handlespace, is managed\n   by ENRP servers.  Pools\
    \ are not valid in the whole Internet but only\n   in smaller domains, called\
    \ the operational scope.  The ENRP servers\n   use the ENRP protocol in order\
    \ to maintain a distributed, fault-\n   tolerant, real-time registry service.\
    \  ENRP servers communicate with\n   each other for information exchange, such\
    \ as pool membership changes,\n   handlespace data synchronization, etc.\n"
- title: 3.1.  Initialization
  contents:
  - "3.1.  Initialization\n   Each ENRP server initially generates a 32-bit server\
    \ ID that it uses\n   in subsequent messaging and remains unchanged over the lifetime\
    \ of\n   the server.  It then attempts to learn all of the other ENRP servers\n\
    \   within the scope of the server pool, either by using a pre-defined\n   Mentor\
    \ server or by sending out Presence messages on a well-known\n   multicast channel\
    \ in order to determine other ENRP servers from the\n   responses and select one\
    \ as Mentor.  A Mentor can be any peer ENRP\n   server.  The most current handlespace\
    \ data is requested by Handle\n   Table Requests from the Mentor.  The received\
    \ answer in the form of\n   Handle Table Response messages is unpacked into the\
    \ local database.\n   After that, the ENRP server is ready to provide ENRP services.\n"
- title: 3.2.  Server Discovery and Home Server Selection
  contents:
  - "3.2.  Server Discovery and Home Server Selection\n   PEs can now register their\
    \ presence with the newly functioning ENRP\n   server by using ASAP messages.\
    \  They discover the new ENRP server\n   after the server sends out an ASAP Server\
    \ Announce message on the\n   well-known ASAP multicast channel.  PEs only have\
    \ to register with\n   one ENRP server, as other ENRP servers supporting the pool\
    \ will\n   synchronize their knowledge about pool elements using the ENRP\n  \
    \ protocol.\n   The PE may have a configured list of ENRP servers to talk to,\
    \ in the\n   form of a list of IP addresses, in which case it will start to set\
    \ up\n   associations with some number of them and assign the first one that\n\
    \   responds to it as its Home ENRP server.\n   Alternatively, it can listen on\
    \ the multicast channel for a set\n   period, and when it hears an ENRP server,\
    \ start an association.  The\n   first server it gets up can then become its Home\
    \ ENRP server.\n"
- title: 3.3.  Failure Detection, Handlespace Audit, and Synchronization
  contents:
  - "3.3.  Failure Detection, Handlespace Audit, and Synchronization\n   ENRP servers\
    \ send ENRP Presence messages to all of their peers in\n   order to show their\
    \ liveness.  These Presence messages also include a\n   checksum computed over\
    \ all PE identities for which the ENRP server is\n   in the role of a Home ENRP\
    \ server.  Each ENRP server maintains an up-\n   to-date list of its peers and\
    \ can also compute the checksum expected\n   from a certain peer, according to\
    \ its local handlespace database.  By\n   comparing the expected sum and the sum\
    \ reported by a peer (denoted as\n   handlespace audit), an inconsistency can\
    \ be detected.  In such a\n   case, the handlespace -- restricted to the PEs owned\
    \ by that peer --\n   can be requested for synchronization, analogously to Section\
    \ 3.2.\n"
- title: 3.4.  Server Takeover
  contents:
  - "3.4.  Server Takeover\n   If the unresponsiveness of an ENRP server is detected,\
    \ the remaining\n   ENRP servers negotiate which other server takes over the Home\
    \ ENRP\n   role for the PEs of the failed peer.  After reaching a consensus on\n\
    \   the takeover, the ENRP server taking over these PEs sends a\n   notification\
    \ to its peers (via ENRP) as well as to the PEs taken over\n   (via ASAP).\n"
- title: 4.  Example Scenarios
  contents:
  - '4.  Example Scenarios

    '
- title: 4.1.  Example Scenario Using RSerPool Resolution Service
  contents:
  - "4.1.  Example Scenario Using RSerPool Resolution Service\n   RSerPool can be\
    \ used in a 'standalone' manner, where the application\n   uses RSerPool to determine\
    \ the address of a primary server in the\n   pool, and then interacts directly\
    \ with that server without further\n   use of RSerPool services.  If the initial\
    \ server fails, the\n   application uses RSerPool again to find the next server\
    \ in the pool.\n   For pool user (\"client\") applications, if an ASAP implementation\
    \ is\n   available on the client system, there are typically only three\n   modifications\
    \ required to the application source code:\n   1.  Instead of specifying the hostnames\
    \ of primary, secondary,\n       tertiary servers, etc., the application user\
    \ specifies a pool\n       handle.\n   2.  Instead of using a DNS-based service\
    \ (e.g., the Unix library\n       function getaddrinfo()) to translate from a\
    \ hostname to an IP\n       address, the application will invoke an RSerPool service\n\
    \       primitive provisionally named GETPRIMARYSERVER that takes a pool\n   \
    \    handle as input, and returns the IP address of the primary\n       server.\
    \  The application then uses that IP address just as it\n       would have used\
    \ the IP address returned by the DNS in the\n       previous scenario.\n   3.\
    \  Without the use of additional RSerPool services, failure\n       detection\
    \ and failover procedures must be designed into each\n       application.  However,\
    \ when failure is detected on the primary\n       server, instead of invoking\
    \ DNS translation again on the hostname\n       of a secondary server, the application\
    \ invokes a service\n       primitive provisionally named GETNEXTSERVER, which\
    \ performs two\n       functions in a single operation.\n       1.  First, it\
    \ indicates to the RSerPool layer the failure of the\n           server returned\
    \ by a previous GETPRIMARYSERVER or\n           GETNEXTSERVER call.\n       2.\
    \  Second, it provides the IP address of the next server that\n           should\
    \ be contacted, according to the best information\n           available to the\
    \ RSerPool layer at the present time (e.g.,\n           set of available pool\
    \ elements, pool element policy in effect\n           for the pool, etc.).\n \
    \  Note: at the time of this document, a full API for use with RSerPool\n   protocols\
    \ has not yet been defined.\n   For pool element (\"server\") applications where\
    \ an ASAP implementation\n   is available, two changes are required to the application\
    \ source\n   code:\n   1.  The server should invoke the REGISTER service primitive\
    \ upon\n       startup to add itself into the server pool using an appropriate\n\
    \       pool handle.  This also includes the address(es) protocol or\n       mapping\
    \ id, port (if required by the mapping), and pooling policy\n       (or policies).\n\
    \   2.  The server should invoke the DEREGISTER service primitive to\n       remove\
    \ itself from the server pool when shutting down.\n   When using these RSerPool\
    \ services, RSerPool provides benefits that\n   are limited (as compared to utilizing\
    \ all services), but nevertheless\n   quite useful as compared to not using RSerPool\
    \ at all.  First, the\n   client user need only supply a single string, i.e.,\
    \ the pool handle,\n   rather than a list of servers.  Second, the decision as\
    \ to which\n   server is to be used can be determined dynamically by the server\n\
    \   selection mechanism (i.e., a \"pool policy\" performed by ASAP; see\n   ASAP\
    \ [RFC5352]).  Finally, when failures occur, these are reported to\n   the pool\
    \ via signaling present in ASAP [RFC5352] and ENRP [RFC5353];\n   other clients\
    \ will eventually know (once this failure is confirmed by\n   other elements of\
    \ the RSerPool architecture) that this server has\n   failed.\n"
- title: 4.2.  Example Scenario Using RSerPool Session Services
  contents:
  - "4.2.  Example Scenario Using RSerPool Session Services\n   When the full suite\
    \ of RSerPool services is used, all communication\n   between the pool user and\
    \ the pool element is mediated by the\n   RSerPool framework, including session\
    \ establishment and teardown, and\n   the sending and receiving of data.  Accordingly,\
    \ it is necessary to\n   modify the application to use the service primitives\
    \ (i.e., the API)\n   provided by RSerPool, rather than the transport layer primitives\n\
    \   provided by TCP, Stream Control Transmission Protocol (SCTP), or\n   whatever\
    \ transport protocol is being used.\n   As in the previous case, sessions (rather\
    \ than connections or\n   associations) are established, and the destination endpoint\
    \ is\n   specified as a pool handle rather than as a list of IP addresses with\n\
    \   a port number.  However, failover from one pool element to another is\n  \
    \ fully automatic, and can be transparent to the application (so long\n   as the\
    \ application has saved enough state in a state cookie):\n      The RSerPool framework\
    \ control channel provides maintenance\n      functions to keep pool element lists,\
    \ policies, etc. current.\n      Since the application data (e.g., data channel)\
    \ is managed by the\n      RSerPool framework, unsent data (data not yet submitted\
    \ by\n      RSerPool to the underlying transport protocol) is automatically\n\
    \      redirected to the newly selected pool element upon failover.  If\n    \
    \  the underlying transport layer supports retrieval of unsent data\n      (as\
    \ in SCTP), retrieved unsent data can also be automatically\n      re-sent to\
    \ the newly selected pool element.\n      An application server (pool element)\
    \ can provide a state cookie\n      (described in Section 2.5.1) that is automatically\
    \ passed on to\n      another pool element (by the ASAP layer at the pool user)\
    \ in the\n      event of a failover.  This state cookie can be used to assist\
    \ the\n      application at the new pool element in recreating whatever state\n\
    \      is needed to continue a session or transaction that was\n      interrupted\
    \ by a failure in the communication between a pool user\n      and the original\
    \ pool element.\n      The application client (pool user) can provide a callback\
    \ function\n      that is invoked on the pool user side in the case of a failover.\n\
    \      This callback function can execute any application-specific\n      failover\
    \ code, such as generating a special message (or sequence\n      of messages)\
    \ that helps the new pool element construct any state\n      needed to continue\
    \ an in-process session.\n      Suppose in a particular peer-to-peer application,\
    \ PU A is\n      communicating with PE B, and it so happens that PU A is also\
    \ a PE\n      in pool X.  PU A can pass a \"business card\" to PE B identifying\
    \ it\n      as a member of pool X.  In the event of a failure at A, or a\n   \
    \   failure in the communication link between A and B, PE B can use\n      the\
    \ information in the business card to contact an equivalent PE\n      to PU A\
    \ from pool X.\n      Additionally, if the application at PU A is aware of some\n\
    \      particular PEs of pool X that would be preferred for B to contact\n   \
    \   in the event that A becomes unreachable from B, PU A can provide\n      that\
    \ list to the ASAP layer, and it will be included in A's\n      business card\
    \ (see Section 2.5.2).\n"
- title: 5.  Reference Implementation
  contents:
  - "5.  Reference Implementation\n   A reference implementation of RSerPool is available\
    \ at [RSerPoolPage]\n   and described in [Dre2006].\n"
- title: 6.  Security Considerations
  contents:
  - "6.  Security Considerations\n   This document does not identify security requirements\
    \ beyond those\n   already documented in the ENRP and ASAP protocol specifications.\
    \  A\n   security threat analysis of RSerPool is provided in THREATS\n   [RFC5355].\n"
- title: 7.  IANA Considerations
  contents:
  - "7.  IANA Considerations\n   This document does not require additional IANA actions\
    \ beyond those\n   already identified in the ENRP [RFC5353] and ASAP [RFC5352]\
    \ protocol\n   specifications.\n"
- title: 8.  Acknowledgements
  contents:
  - "8.  Acknowledgements\n   The authors wish to thank Maureen Stillman, Qiaobing\
    \ Xie, Randall\n   Stewart, Scott Bradner, and many others for their invaluable\n\
    \   comments.\n"
- title: 9.  References
  contents:
  - '9.  References

    '
- title: 9.1.  Normative References
  contents:
  - "9.1.  Normative References\n   [RFC3237]       Tuexen, M., Xie, Q., Stewart,\
    \ R., Shore, M., Ong, L.,\n                   Loughney, J., and M. Stillman, \"\
    Requirements for\n                   Reliable Server Pooling\", RFC 3237, January\
    \ 2002.\n   [RFC5352]       Stewart, R., Xie, Q., Stillman, M., and M. Tuexen,\n\
    \                   \"Aggregate Server Access Protocol (ASAP)\", RFC 5352,\n \
    \                  September 2008.\n   [RFC5353]       Xie, Q., Stewart, R., Stillman,\
    \ M., Tuexen, M., and\n                   A. Silverton, \"Endpoint Handlespace\
    \ Redundancy\n                   Protocol (ENRP)\", RFC 5353, September 2008.\n\
    \   [RFC5354]       Stewart, R., Xie, Q., Stillman, M., and M. Tuexen,\n     \
    \              \"Aggregate Server Access Protocol (ASAP) and Endpoint\n      \
    \             Handlespace Redundancy Protocol (ENRP) Parameters\",\n         \
    \          RFC 5354, September 2008.\n   [RFC5355]       Stillman, M., Ed., Gopal,\
    \ R., Guttman, E., Holdrege,\n                   M., and S. Sengodan, \"Threats\
    \ Introduced by Reliable\n                   Server Pooling (RSerPool) and Requirements\
    \ for\n                   Security in Response to Threats\", RFC 5355,\n     \
    \              September 2008.\n   [RFC5356]       Dreibholz, T. and M. Tuexen,\
    \ \"Reliable Server Pooling\n                   Policies\", RFC 5356, September\
    \ 2008.\n"
- title: 9.2.  Informative References
  contents:
  - "9.2.  Informative References\n   [RSerPoolPage]  Dreibholz, T., \"Thomas Dreibholz's\
    \ RSerPool Page\",\n                   <http://tdrwww.iem.uni-due.de/dreibholz/rserpool/>.\n\
    \   [Dre2006]       Dreibholz, T., \"Reliable Server Pooling --\n            \
    \       Evaluation, Optimization and Extension of a Novel\n                  \
    \ IETF Architecture\", Ph.D. Thesis University of\n                   Duisburg-Essen,\
    \ Faculty of Economics, Institute for\n                   Computer Science and\
    \ Business Information Systems,\n                   March 2007, <http://duepublico.uni-duisburg-essen.de/\n\
    \                   servlets/DerivateServlet/Derivate-16326/\n               \
    \    Dre2006-final.pdf>.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Peter Lei\n   Cisco Systems, Inc.\n   955 Happfield Dr.\n\
    \   Arlington Heights, IL  60004\n   US\n   Phone: +1 773 695-8201\n   EMail:\
    \ peterlei@cisco.com\n   Lyndon Ong\n   Ciena Corporation\n   PO Box 308\n   Cupertino,\
    \ CA  95015\n   US\n   EMail: Lyong@Ciena.com\n   Michael Tuexen\n   Muenster\
    \ Univ. of Applied Sciences\n   Stegerwaldstr. 39\n   48565 Steinfurt\n   Germany\n\
    \   EMail: tuexen@fh-muenster.de\n   Thomas Dreibholz\n   University of Duisburg-Essen,\
    \ Institute for Experimental Mathematics\n   Ellernstrasse 29\n   45326 Essen,\
    \ Nordrhein-Westfalen\n   Germany\n   Phone: +49 201 183-7637\n   Fax:   +49 201\
    \ 183-7673\n   EMail: dreibh@iem.uni-due.de\n   URI:   http://www.iem.uni-due.de/~dreibh/\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The IETF Trust (2008).\n   This document\
    \ is subject to the rights, licenses and restrictions\n   contained in BCP 78,\
    \ and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY, THE IETF TRUST AND\n   THE\
    \ INTERNET ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS\n   OR IMPLIED,\
    \ INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF\n   THE INFORMATION\
    \ HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY\
    \ OR FITNESS FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at\n   ietf-ipr@ietf.org.\n"
