- title: __initial_text__
  contents:
  - "     Recommendations on Queue Management and Congestion Avoidance\n         \
    \                   in the Internet\n"
- title: Status of Memo
  contents:
  - "Status of Memo\n      This memo provides information for the Internet community.\
    \  It\n      does not specify an Internet standard of any kind.  Distribution\n\
    \      of this memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n      Copyright (C) The Internet Society (1998).  All Rights\
    \ Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n      This memo presents two recommendations to the Internet community\n\
    \      concerning measures to improve and preserve Internet performance.\n   \
    \   It presents a strong recommendation for testing, standardization,\n      and\
    \ widespread deployment of active queue management in routers,\n      to improve\
    \ the performance of today's Internet.  It also urges a\n      concerted effort\
    \ of research, measurement, and ultimate deployment\n      of router mechanisms\
    \ to protect the Internet from flows that are\n      not sufficiently responsive\
    \ to congestion notification.\n"
- title: 1. INTRODUCTION
  contents:
  - "1. INTRODUCTION\n   The Internet protocol architecture is based on a connectionless\
    \ end-\n   to-end packet service using the IP protocol.  The advantages of its\n\
    \   connectionless design, flexibility and robustness, have been amply\n   demonstrated.\
    \  However, these advantages are not without cost:\n   careful design is required\
    \ to provide good service under heavy load.\n   In fact, lack of attention to\
    \ the dynamics of packet forwarding can\n   result in severe service degradation\
    \ or \"Internet meltdown\".  This\n   phenomenon was first observed during the\
    \ early growth phase of the\n   Internet of the mid 1980s [Nagle84], and is technically\
    \ called\n   \"congestion collapse\".\n   The original fix for Internet meltdown\
    \ was provided by Van Jacobson.\n   Beginning in 1986, Jacobson developed the\
    \ congestion avoidance\n   mechanisms that are now required in TCP implementations\
    \ [Jacobson88,\n   HostReq89].  These mechanisms operate in the hosts to cause\
    \ TCP\n   connections to \"back off\" during congestion.  We say that TCP flows\n\
    \   are \"responsive\" to congestion signals (i.e., dropped packets) from\n  \
    \ the network.  It is primarily these TCP congestion avoidance\n   algorithms\
    \ that prevent the congestion collapse of today's Internet.\n   However, that\
    \ is not the end of the story.  Considerable research has\n   been done on Internet\
    \ dynamics since 1988, and the Internet has\n   grown.  It has become clear that\
    \ the TCP congestion avoidance\n   mechanisms [RFC2001], while necessary and powerful,\
    \ are not\n   sufficient to provide good service in all circumstances.  Basically,\n\
    \   there is a limit to how much control can be accomplished from the\n   edges\
    \ of the network.  Some mechanisms are needed in the routers to\n   complement\
    \ the endpoint congestion avoidance mechanisms.\n   It is useful to distinguish\
    \ between two classes of router algorithms\n   related to congestion control:\
    \ \"queue management\" versus \"scheduling\"\n   algorithms.  To a rough approximation,\
    \ queue management algorithms\n   manage the length of packet queues by dropping\
    \ packets when necessary\n   or appropriate, while scheduling algorithms determine\
    \ which packet to\n   send next and are used primarily to manage the allocation\
    \ of\n   bandwidth among flows.  While these two router mechanisms are closely\n\
    \   related, they address rather different performance issues.\n   This memo highlights\
    \ two router performance issues.  The first issue\n   is the need for an advanced\
    \ form of router queue management that we\n   call \"active queue management.\"\
    \  Section 2 summarizes the benefits\n   that active queue management can bring.\
    \  Section 3 describes a\n   recommended active queue management mechanism, called\
    \ Random Early\n   Detection or \"RED\".  We expect that the RED algorithm can\
    \ be used\n   with a wide variety of scheduling algorithms, can be implemented\n\
    \   relatively efficiently, and will provide significant Internet\n   performance\
    \ improvement.\n   The second issue, discussed in Section 4 of this memo, is the\n\
    \   potential for future congestion collapse of the Internet due to flows\n  \
    \ that are unresponsive, or not sufficiently responsive, to congestion\n   indications.\
    \  Unfortunately, there is no consensus solution to\n   controlling congestion\
    \ caused by such aggressive flows; significant\n   research and engineering will\
    \ be required before any solution will be\n   available.  It is imperative that\
    \ this work be energetically pursued,\n   to ensure the future stability of the\
    \ Internet.\n   Section 5 concludes the memo with a set of recommendations to\
    \ the\n   IETF concerning these topics.\n   The discussion in this memo applies\
    \ to \"best-effort\" traffic.  The\n   Internet integrated services architecture,\
    \ which provides a mechanism\n   for protecting individual flows from congestion,\
    \ introduces its own\n   queue management and scheduling algorithms [Shenker96,\
    \ Wroclawski96].\n   Similarly, the discussion of queue management and congestion\
    \ control\n   requirements for differential services is a separate issue.  However,\n\
    \   we do not expect the deployment of integrated services and\n   differential\
    \ services to significantly diminish the importance of the\n   best-effort traffic\
    \ issues discussed in this memo.\n   Preparation of this memo resulted from past\
    \ discussions of end-to-end\n   performance, Internet congestion, and RED in the\
    \ End-to-End Research\n   Group of the Internet Research Task Force (IRTF).\n"
- title: 2. THE NEED FOR ACTIVE QUEUE MANAGEMENT
  contents:
  - "2. THE NEED FOR ACTIVE QUEUE MANAGEMENT\n   The traditional technique for managing\
    \ router queue lengths is to set\n   a maximum length (in terms of packets) for\
    \ each queue, accept packets\n   for the queue until the maximum length is reached,\
    \ then reject (drop)\n   subsequent incoming packets until the queue decreases\
    \ because a\n   packet from the queue has been transmitted.  This technique is\
    \ known\n   as \"tail drop\", since the packet that arrived most recently (i.e.,\n\
    \   the one on the tail of the queue) is dropped when the queue is full.\n   This\
    \ method has served the Internet well for years, but it has two\n   important\
    \ drawbacks.\n   1.   Lock-Out\n        In some situations tail drop allows a\
    \ single connection or a few\n        flows to monopolize queue space, preventing\
    \ other connections\n        from getting room in the queue.  This \"lock-out\"\
    \ phenomenon is\n        often the result of synchronization or other timing effects.\n\
    \   2.   Full Queues\n        The tail drop discipline allows queues to maintain\
    \ a full (or,\n        almost full) status for long periods of time, since tail\
    \ drop\n        signals congestion (via a packet drop) only when the queue has\n\
    \        become full.  It is important to reduce the steady-state queue\n    \
    \    size, and this is perhaps queue management's most important\n        goal.\n\
    \        The naive assumption might be that there is a simple tradeoff\n     \
    \   between delay and throughput, and that the recommendation that\n        queues\
    \ be maintained in a \"non-full\" state essentially\n        translates to a recommendation\
    \ that low end-to-end delay is more\n        important than high throughput. \
    \ However, this does not take\n        into account the critical role that packet\
    \ bursts play in\n        Internet performance.  Even though TCP constrains a\
    \ flow's\n        window size, packets often arrive at routers in bursts\n   \
    \     [Leland94].  If the queue is full or almost full, an arriving\n        burst\
    \ will cause multiple packets to be dropped.  This can\n        result in a global\
    \ synchronization of flows throttling back,\n        followed by a sustained period\
    \ of lowered link utilization,\n        reducing overall throughput.\n       \
    \ The point of buffering in the network is to absorb data bursts\n        and\
    \ to transmit them during the (hopefully) ensuing bursts of\n        silence.\
    \  This is essential to permit the transmission of bursty\n        data.  It should\
    \ be clear why we would like to have normally-\n        small queues in routers:\
    \ we want to have queue capacity to\n        absorb the bursts.  The counter-intuitive\
    \ result is that\n        maintaining normally-small queues can result in higher\n\
    \        throughput as well as lower end-to-end delay.  In short, queue\n    \
    \    limits should not reflect the steady state queues we want\n        maintained\
    \ in the network; instead, they should reflect the size\n        of bursts we\
    \ need to absorb.\n   Besides tail drop, two alternative queue disciplines that\
    \ can be\n   applied when the queue becomes full are \"random drop on full\" or\n\
    \   \"drop front on full\".  Under the random drop on full discipline, a\n   router\
    \ drops a randomly selected packet from the queue (which can be\n   an expensive\
    \ operation, since it naively requires an O(N) walk\n   through the packet queue)\
    \ when the queue is full and a new packet\n   arrives.  Under the \"drop front\
    \ on full\" discipline [Lakshman96], the\n   router drops the packet at the front\
    \ of the queue when the queue is\n   full and a new packet arrives.  Both of these\
    \ solve the lock-out\n   problem, but neither solves the full-queues problem described\
    \ above.\n   We know in general how to solve the full-queues problem for\n   \"\
    responsive\" flows, i.e., those flows that throttle back in response\n   to congestion\
    \ notification.  In the current Internet, dropped packets\n   serve as a critical\
    \ mechanism of congestion notification to end\n   nodes.  The solution to the\
    \ full-queues problem is for routers to\n   drop packets before a queue becomes\
    \ full, so that end nodes can\n   respond to congestion before buffers overflow.\
    \  We call such a\n   proactive approach \"active queue management\".  By dropping\
    \ packets\n   before buffers overflow, active queue management allows routers\
    \ to\n   control when and how many packets to drop.  The next section\n   introduces\
    \ RED, an active queue management mechanism that solves both\n   problems listed\
    \ above (given responsive flows).\n   In summary, an active queue management mechanism\
    \ can provide the\n   following advantages for responsive flows.\n   1.   Reduce\
    \ number of packets dropped in routers\n        Packet bursts are an unavoidable\
    \ aspect of packet networks\n        [Willinger95].  If all the queue space in\
    \ a router is already\n        committed to \"steady state\" traffic or if the\
    \ buffer space is\n        inadequate, then the router will have no ability to\
    \ buffer\n        bursts.  By keeping the average queue size small, active queue\n\
    \        management will provide greater capacity to absorb naturally-\n     \
    \   occurring bursts without dropping packets.\n        Furthermore, without active\
    \ queue management, more packets will\n        be dropped when a queue does overflow.\
    \  This is undesirable for\n        several reasons.  First, with a shared queue\
    \ and the tail drop\n        discipline, an unnecessary global synchronization\
    \ of flows\n        cutting back can result in lowered average link utilization,\
    \ and\n        hence lowered network throughput.  Second, TCP recovers with\n\
    \        more difficulty from a burst of packet drops than from a single\n   \
    \     packet drop.  Third, unnecessary packet drops represent a\n        possible\
    \ waste of bandwidth on the way to the drop point.\n        We note that while\
    \ RED can manage queue lengths and reduce end-\n        to-end latency even in\
    \ the absence of end-to-end congestion\n        control, RED will be able to reduce\
    \ packet dropping only in an\n        environment that continues to be dominated\
    \ by end-to-end\n        congestion control.\n   2.   Provide lower-delay interactive\
    \ service\n        By keeping the average queue size small, queue management will\n\
    \        reduce the delays seen by flows.  This is particularly important\n  \
    \      for interactive applications such as short Web transfers, Telnet\n    \
    \    traffic, or interactive audio-video sessions, whose subjective\n        (and\
    \ objective) performance is better when the end-to-end delay\n        is low.\n\
    \   3.   Avoid lock-out behavior\n        Active queue management can prevent\
    \ lock-out behavior by\n        ensuring that there will almost always be a buffer\
    \ available for\n        an incoming packet.  For the same reason, active queue\n\
    \        management can prevent a router bias against low bandwidth but\n    \
    \    highly bursty flows.\n        It is clear that lock-out is undesirable because\
    \ it constitutes\n        a gross unfairness among groups of flows.  However,\
    \ we stop\n        short of calling this benefit \"increased fairness\", because\n\
    \        general fairness among flows requires per-flow state, which is\n    \
    \    not provided by queue management.  For example, in a router\n        using\
    \ queue management but only FIFO scheduling, two TCP flows\n        may receive\
    \ very different bandwidths simply because they have\n        different round-trip\
    \ times [Floyd91], and a flow that does not\n        use congestion control may\
    \ receive more bandwidth than a flow\n        that does.  Per-flow state to achieve\
    \ general fairness might be\n        maintained by a per-flow scheduling algorithm\
    \ such as Fair\n        Queueing (FQ) [Demers90], or a class-based scheduling\
    \ algorithm\n        such as CBQ [Floyd95], for example.\n        On the other\
    \ hand, active queue management is needed even for\n        routers that use per-flow\
    \ scheduling algorithms such as FQ or\n        class-based scheduling algorithms\
    \ such as CBQ.  This is because\n        per-flow scheduling algorithms by themselves\
    \ do nothing to\n        control the overall queue size or the size of individual\
    \ queues.\n        Active queue management is needed to control the overall average\n\
    \        queue sizes, so that arriving bursts can be accommodated without\n  \
    \      dropping packets.  In addition, active queue management should\n      \
    \  be used to control the queue size for each individual flow or\n        class,\
    \ so that they do not experience unnecessarily high delays.\n        Therefore,\
    \ active queue management should be applied across the\n        classes or flows\
    \ as well as within each class or flow.\n        In short, scheduling algorithms\
    \ and queue management should be\n        seen as complementary, not as replacements\
    \ for each other.  In\n        particular, there have been implementations of\
    \ queue management\n        added to FQ, and work is in progress to add RED queue\
    \ management\n        to CBQ.\n"
- title: 3. THE QUEUE MANAGEMENT ALGORITHM "RED"
  contents:
  - "3. THE QUEUE MANAGEMENT ALGORITHM \"RED\"\n   Random Early Detection, or RED,\
    \ is an active queue management\n   algorithm for routers that will provide the\
    \ Internet performance\n   advantages cited in the previous section [RED93]. \
    \ In contrast to\n   traditional queue management algorithms, which drop packets\
    \ only when\n   the buffer is full, the RED algorithm drops arriving packets\n\
    \   probabilistically.  The probability of drop increases as the\n   estimated\
    \ average queue size grows.  Note that RED responds to a\n   time-averaged queue\
    \ length, not an instantaneous one.  Thus, if the\n   queue has been mostly empty\
    \ in the \"recent past\", RED won't tend to\n   drop packets (unless the queue\
    \ overflows, of course!). On the other\n   hand, if the queue has recently been\
    \ relatively full, indicating\n   persistent congestion, newly arriving packets\
    \ are more likely to be\n   dropped.\n   The RED algorithm itself consists of\
    \ two main parts: estimation of\n   the average queue size and the decision of\
    \ whether or not to drop an\n   incoming packet.\n   (a) Estimation of Average\
    \ Queue Size\n        RED estimates the average queue size, either in the forwarding\n\
    \        path using a simple exponentially weighted moving average (such\n   \
    \     as presented in Appendix A of [Jacobson88]), or in the\n        background\
    \ (i.e., not in the forwarding path) using a similar\n        mechanism.\n   \
    \        Note: The queue size can be measured either in units of\n           packets\
    \ or of bytes.  This issue is discussed briefly in\n           [RED93] in the\
    \ \"Future Work\" section.\n           Note: when the average queue size is computed\
    \ in the\n           forwarding path, there is a special case when a packet\n\
    \           arrives and the queue is empty.  In this case, the\n           computation\
    \ of the average queue size must take into account\n           how much time has\
    \ passed since the queue went empty.  This is\n           discussed further in\
    \ [RED93].\n   (b) Packet Drop Decision\n        In the second portion of the\
    \ algorithm, RED decides whether or\n        not to drop an incoming packet. \
    \ It is RED's particular\n        algorithm for dropping that results in performance\
    \ improvement\n        for responsive flows.  Two RED parameters, minth (minimum\n\
    \        threshold) and maxth (maximum threshold), figure prominently in\n   \
    \     this decision process.  Minth specifies the average queue size\n       \
    \ *below which* no packets will be dropped, while maxth specifies\n        the\
    \ average queue size *above which* all packets will be\n        dropped.  As the\
    \ average queue size varies from minth to maxth,\n        packets will be dropped\
    \ with a probability that varies linearly\n        from 0 to maxp.\n         \
    \  Note: a simplistic method of implementing this would be to\n           calculate\
    \ a new random number at each packet arrival, then\n           compare that number\
    \ with the above probability which varies\n           from 0 to maxp.  A more\
    \ efficient implementation, described\n           in [RED93], computes a random\
    \ number *once* for each dropped\n           packet.\n           Note: the decision\
    \ whether or not to drop an incoming packet\n           can be made in \"packet\
    \ mode\", ignoring packet sizes, or in\n           \"byte mode\", taking into\
    \ account the size of the incoming\n           packet.  The performance implications\
    \ of the choice between\n           packet mode or byte mode is discussed further\
    \ in [Floyd97].\n   RED effectively controls the average queue size while still\n\
    \   accommodating bursts of packets without loss.  RED's use of\n   randomness\
    \ breaks up synchronized processes that lead to lock-out\n   phenomena.\n   There\
    \ have been several implementations of RED in routers, and papers\n   have been\
    \ published reporting on experience with these\n   implementations ([Villamizar94],\
    \ [Gaynor96]).  Additional reports of\n   implementation experience would be welcome,\
    \ and will be posted on the\n   RED web page [REDWWW].\n   All available empirical\
    \ evidence shows that the deployment of active\n   queue management mechanisms\
    \ in the Internet would have substantial\n   performance benefits.  There are\
    \ seemingly no disadvantages to using\n   the RED algorithm, and numerous advantages.\
    \  Consequently, we believe\n   that the RED active queue management algorithm\
    \ should be widely\n   deployed.\n   We should note that there are some extreme\
    \ scenarios for which RED\n   will not be a cure, although it won't hurt and may\
    \ still help.  An\n   example of such a scenario would be a very large number\
    \ of flows,\n   each so tiny that its fair share would be less than a single packet\n\
    \   per RTT.\n"
- title: 4. MANAGING AGGRESSIVE FLOWS
  contents:
  - "4. MANAGING AGGRESSIVE FLOWS\n   One of the keys to the success of the Internet\
    \ has been the\n   congestion avoidance mechanisms of TCP.  Because TCP \"backs\
    \ off\"\n   during congestion, a large number of TCP connections can share a\n\
    \   single, congested link in such a way that bandwidth is shared\n   reasonably\
    \ equitably among similarly situated flows.  The equitable\n   sharing of bandwidth\
    \ among flows depends on the fact that all flows\n   are running basically the\
    \ same congestion avoidance algorithms,\n   conformant with the current TCP specification\
    \ [HostReq89].\n   We introduce the term \"TCP-compatible\" for a flow that behaves\
    \ under\n   congestion like a flow produced by a conformant TCP.  A TCP-\n   compatible\
    \ flow is responsive to congestion notification, and in\n   steady-state it uses\
    \ no more bandwidth than a conformant TCP running\n   under comparable conditions\
    \ (drop rate, RTT, MTU, etc.)\n   It is convenient to divide flows into three\
    \ classes: (1) TCP-\n   compatible flows, (2) unresponsive flows, i.e., flows\
    \ that do not\n   slow down when congestion occurs, and (3) flows that are responsive\n\
    \   but are not TCP-compatible.  The last two classes contain more\n   aggressive\
    \ flows that pose significant threats to Internet\n   performance, as we will\
    \ now discuss.\n   o    Non-Responsive Flows\n        There is a growing set of\
    \ UDP-based applications whose\n        congestion avoidance algorithms are inadequate\
    \ or nonexistent\n        (i.e, the flow does not throttle back upon receipt of\
    \ congestion\n        notification).  Such UDP applications include streaming\n\
    \        applications like packet voice and video, and also multicast\n      \
    \  bulk data transport [SRM96].  If no action is taken, such\n        unresponsive\
    \ flows could lead to a new congestion collapse.\n        In general, all UDP-based\
    \ streaming applications should\n        incorporate effective congestion avoidance\
    \ mechanisms.  For\n        example, recent research has shown the possibility\
    \ of\n        incorporating congestion avoidance mechanisms such as Receiver-\n\
    \        driven Layered Multicast (RLM) within UDP-based streaming\n        applications\
    \ such as packet video [McCanne96; Bolot94]. Further\n        research and development\
    \ on ways to accomplish congestion\n        avoidance for streaming applications\
    \ will be very important.\n        However, it will also be important for the\
    \ network to be able to\n        protect itself against unresponsive flows, and\
    \ mechanisms to\n        accomplish this must be developed and deployed.  Deployment\
    \ of\n        such mechanisms would provide incentive for every streaming\n  \
    \      application to become responsive by incorporating its own\n        congestion\
    \ control.\n   o    Non-TCP-Compatible Transport Protocols\n        The second\
    \ threat is posed by transport protocol implementations\n        that are responsive\
    \ to congestion notification but, either\n        deliberately or through faulty\
    \ implementations, are not TCP-\n        compatible.  Such applications can grab\
    \ an unfair share of the\n        network bandwidth.\n        For example, the\
    \ popularity of the Internet has caused a\n        proliferation in the number\
    \ of TCP implementations.  Some of\n        these may fail to implement the TCP\
    \ congestion avoidance\n        mechanisms correctly because of poor implementation.\
    \  Others may\n        deliberately be implemented with congestion avoidance algorithms\n\
    \        that are more aggressive in their use of bandwidth than other\n     \
    \   TCP implementations; this would allow a vendor to claim to have\n        a\
    \ \"faster TCP\".  The logical consequence of such implementations\n        would\
    \ be a spiral of increasingly aggressive TCP\n        implementations, leading\
    \ back to the point where there is\n        effectively no congestion avoidance\
    \ and the Internet is\n        chronically congested.\n        Note that there\
    \ is a well-known way to achieve more aggressive\n        TCP performance without\
    \ even changing TCP: open multiple\n        connections to the same place, as\
    \ has been done in some Web\n        browsers.\n   The projected increase in more\
    \ aggressive flows of both these\n   classes, as a fraction of total Internet\
    \ traffic, clearly poses a\n   threat to the future Internet.  There is an urgent\
    \ need for\n   measurements of current conditions and for further research into\
    \ the\n   various ways of managing such flows.  There are many difficult issues\n\
    \   in identifying and isolating unresponsive or non-TCP-compatible flows\n  \
    \ at an acceptable router overhead cost.  Finally, there is little\n   measurement\
    \ or simulation evidence available about the rate at which\n   these threats are\
    \ likely to be realized, or about the expected\n   benefit of router algorithms\
    \ for managing such flows.\n   There is an issue about the appropriate granularity\
    \ of a \"flow\".\n   There are a few \"natural\" answers: 1) a TCP or UDP connection\
    \ (source\n   address/port, destination address/port); 2) a source/destination\
    \ host\n   pair; 3) a given source host or a given destination host.  We would\n\
    \   guess that the source/destination host pair gives the most\n   appropriate\
    \ granularity in many circumstances.  However, it is\n   possible that different\
    \ vendors/providers could set different\n   granularities for defining a flow\
    \ (as a way of \"distinguishing\"\n   themselves from one another), or that different\
    \ granularities could\n   be chosen for different places in the network.  It may\
    \ be the case\n   that the granularity is less important than the fact that we\
    \ are\n   dealing with more unresponsive flows at *some* granularity.  The\n \
    \  granularity of flows for congestion management is, at least in part,\n   a\
    \ policy question that needs to be addressed in the wider IETF\n   community.\n"
- title: 5. CONCLUSIONS AND RECOMMENDATIONS
  contents:
  - "5. CONCLUSIONS AND RECOMMENDATIONS\n   This discussion leads us to make the following\
    \ recommendations to the\n   IETF and to the Internet community as a whole.\n\
    \   o    RECOMMENDATION 1:\n        Internet routers should implement some active\
    \ queue management\n        mechanism to manage queue lengths, reduce end-to-end\
    \ latency,\n        reduce packet dropping, and avoid lock-out phenomena within\
    \ the\n        Internet.\n        The default mechanism for managing queue lengths\
    \ to meet these\n        goals in FIFO queues is Random Early Detection (RED)\
    \ [RED93].\n        Unless a developer has reasons to provide another equivalent\n\
    \        mechanism, we recommend that RED be used.\n   o    RECOMMENDATION 2:\n\
    \        It is urgent to begin or continue research, engineering, and\n      \
    \  measurement efforts contributing to the design of mechanisms to\n        deal\
    \ with flows that are unresponsive to congestion notification\n        or are\
    \ responsive but more aggressive than TCP.\n   Although there has already been\
    \ some limited deployment of RED in the\n   Internet, we may expect that widespread\
    \ implementation and deployment\n   of RED in accordance with Recommendation 1\
    \ will expose a number of\n   engineering issues.  For example, such issues may\
    \ include:\n   implementation questions for Gigabit routers, the use of RED in\
    \ layer\n   2 switches, and the possible use of additional considerations, such\n\
    \   as priority, in deciding which packets to drop.\n   We again emphasize that\
    \ the widespread implementation and deployment\n   of RED would not, in and of\
    \ itself, achieve the goals of\n   Recommendation 2.\n   Widespread implementation\
    \ and deployment of RED will also enable the\n   introduction of other new functionality\
    \ into the Internet.  One\n   example of an enabled functionality would be the\
    \ addition of explicit\n   congestion notification [Ramakrishnan97] to the Internet\n\
    \   architecture, as a mechanism for congestion notification in addition\n   to\
    \ packet drops.  A second example of new functionality would be\n   implementation\
    \ of queues with packets of different drop priorities;\n   packets would be transmitted\
    \ in the order in which they arrived, but\n   during times of congestion packets\
    \ of the lower drop priority would\n   be preferentially dropped.\n"
- title: 6. References
  contents:
  - "6. References\n   [Bolot94] Bolot, J.-C., Turletti, T., and Wakeman, I., Scalable\n\
    \   Feedback Control for Multicast Video Distribution in the Internet,\n   ACM\
    \ SIGCOMM '94, Sept. 1994.\n   [Demers90] Demers, A., Keshav, S., and Shenker,\
    \ S., Analysis and\n   Simulation of a Fair Queueing Algorithm, Internetworking:\
    \ Research\n   and Experience, Vol. 1, 1990, pp. 3-26.\n   [Floyd91] Floyd, S.,\
    \ Connections with Multiple Congested Gateways in\n   Packet-Switched Networks\
    \ Part 1: One-way Traffic.  Computer\n   Communications Review, Vol.21, No.5,\
    \ October 1991, pp.  30-47.  URL\n   http://ftp.ee.lbl.gov/floyd/.\n   [Floyd95]\
    \ Floyd, S., and Jacobson, V., Link-sharing and Resource\n   Management Models\
    \ for Packet Networks. IEEE/ACM Transactions on\n   Networking, Vol. 3 No. 4,\
    \ pp. 365-386, August 1995.\n   [Floyd97] Floyd, S., RED: Discussions of Byte\
    \ and Packet Modes, March\n   1997 email, http://www-nrg.ee.lbl.gov/floyd/REDaveraging.txt.\n\
    \   [Gaynor96] Gaynor, M., Proactive Packet Dropping Methods for TCP\n   Gateways,\
    \ October 1996, URL http://www.eecs.harvard.edu/~gaynor/\n   final.ps.\n   [HostReq89]\
    \ Braden, R., Ed., \"Requirements for Internet Hosts --\n   Communication Layers\"\
    , STD 3, RFC 1122, October 1989.\n   [Jacobson88] V. Jacobson, Congestion Avoidance\
    \ and Control, ACM\n   SIGCOMM '88, August 1988.\n   [Lakshman96] T. V. Lakshman,\
    \ Arnie Neidhardt, Teunis Ott, The Drop\n   From Front Strategy in TCP Over ATM\
    \ and Its Interworking with Other\n   Control Features, Infocom 96, MA28.1.\n\
    \   [Leland94] W. Leland, M. Taqqu, W. Willinger, and D. Wilson, On the\n   Self-Similar\
    \ Nature of Ethernet Traffic (Extended Version), IEEE/ACM\n   Transactions on\
    \ Networking, 2(1), pp. 1-15, February 1994.\n   [McCanne96] McCanne, S., Jacobson,\
    \ V., and M. Vetterli, Receiver-\n   driven Layered Multicast, ACM SIGCOMM\n \
    \  [Nagle84] Nagle, J., \"Congestion Control in IP/TCP\", RFC 896, January\n \
    \  1984.\n   [Ramakrishnan97] Ramakrishnan, K. K., and S. Floyd, \"A Proposal\
    \ to\n   add Explicit Congestion Notification (ECN) to IPv6 and to TCP\", Work\n\
    \   in Progress.\n   [RED93] Floyd, S., and Jacobson, V., Random Early Detection\
    \ gateways\n   for Congestion Avoidance, IEEE/ACM Transactions on Networking,\
    \ V.1\n   N.4, August 1993, pp. 397-413.  Also available from\n   http://ftp.ee.lbl.gov/floyd/red.html.\n\
    \   [REDWWW] Floyd, S., The RED Web Page, 1997, URL\n   http://ftp.ee.lbl.gov/floyd/red.html.\n\
    \   [RFC 2001] Stevens, W., \"TCP Slow Start, Congestion Avoidance, Fast\n   Retransmit,\
    \ and Fast Recovery Algorithms\", RFC 2001, January 1997.\n   [Shenker96] Shenker,\
    \ S., Partridge, C., and R. Guerin, \"Specification\n   of Guaranteed Quality\
    \ of Service\", Work in Progress.\n   [SRM96] Floyd. S., Jacobson, V., McCanne,\
    \ S., Liu, C., and L. Zhang,\n   A Reliable Multicast Framework for Light-weight\
    \ Sessions and\n   Application Level Framing.  ACM SIGCOMM '96, pp 342-355.\n\
    \   [Villamizar94] Villamizar, C., and Song, C., High Performance TCP in\n   ANSNET.\
    \ Computer Communications Review, V. 24 N. 5, October 1994, pp.\n   45-60.  URL\
    \ http://ftp.ans.net/pub/papers/tcp-performance.ps.\n   [Willinger95] W. Willinger,\
    \ M. S. Taqqu, R. Sherman, D. V.  Wilson,\n   Self-Similarity Through High-Variability:\
    \  Statistical Analysis of\n   Ethernet LAN Traffic at the Source Level, ACM SIGCOMM\
    \ '95, pp.  100-\n   113, August 1995.\n   [Wroclawski96] Wroclawski, J., \"Specification\
    \ of the Controlled-Load\n   Network Element Service\", Work in Progress.\n"
- title: Security Considerations
  contents:
  - "Security Considerations\n   While security is a very important issue, it is largely\
    \ orthogonal to\n   the performance issues discussed in this memo.  We note, however,\n\
    \   that denial-of-service attacks may create unresponsive traffic flows\n   that\
    \ are indistinguishable from flows from normal high-bandwidth\n   isochronous\
    \ applications, and the mechanism suggested in\n   Recommendation 2 will be equally\
    \ applicable to such attacks.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Bob Braden\n   USC Information Sciences Institute\n  \
    \ 4676 Admiralty Way\n   Marina del Rey, CA 90292\n   Phone: 310-822-1511\n  \
    \ EMail: Braden@ISI.EDU\n   David D. Clark\n   MIT Laboratory for Computer Science\n\
    \   545 Technology Sq.\n   Cambridge, MA  02139\n   Phone: 617-253-6003\n   EMail:\
    \ DDC@lcs.mit.edu\n   Jon Crowcroft\n   University College London\n   Department\
    \ of Computer Science\n   Gower Street\n   London, WC1E 6BT\n   ENGLAND\n   Phone:\
    \ +44 171 380 7296\n   EMail: Jon.Crowcroft@cs.ucl.ac.uk\n   Bruce Davie\n   Cisco\
    \ Systems, Inc.\n   250 Apollo Drive\n   Chelmsford, MA 01824\n   Phone:\n   EMail:\
    \ bdavie@cisco.com\n   Steve Deering\n   Cisco Systems, Inc.\n   170 West Tasman\
    \ Drive\n   San Jose, CA 95134-1706\n   Phone: 408-527-8213\n   EMail: deering@cisco.com\n\
    \   Deborah Estrin\n   USC Information Sciences Institute\n   4676 Admiralty Way\n\
    \   Marina del Rey, CA 90292\n   Phone: 310-822-1511\n   EMail: Estrin@usc.edu\n\
    \   Sally Floyd\n   Lawrence Berkeley National Laboratory,\n   MS 50B-2239,\n\
    \   One Cyclotron Road,\n   Berkeley CA 94720\n   Phone:  510-486-7518\n   EMail:\
    \ Floyd@ee.lbl.gov\n   Van Jacobson\n   Lawrence Berkeley National Laboratory,\n\
    \   MS 46A,\n   One Cyclotron Road,\n   Berkeley CA 94720\n   Phone: 510-486-7519\n\
    \   EMail: Van@ee.lbl.gov\n   Greg Minshall\n   Fiberlane Communications\n   1399\
    \ Charleston Road\n   Mountain View, CA  94043\n   Phone:  +1 650 237 3164\n \
    \  EMail:  Minshall@fiberlane.com\n   Craig Partridge\n   BBN Technologies\n \
    \  10 Moulton St.\n   Cambridge MA 02138\n   Phone: 510-558-8675\n   EMail: craig@bbn.com\n\
    \   Larry Peterson\n   Department of Computer Science\n   University of Arizona\n\
    \   Tucson, AZ 85721\n   Phone: 520-621-4231\n   EMail: LLP@cs.arizona.edu\n \
    \  K. K. Ramakrishnan\n   AT&T Labs. Research\n   Rm. A155\n   180 Park Avenue\n\
    \   Florham Park, N.J. 07932\n   Phone: 973-360-8766\n   EMail: KKRama@research.att.com\n\
    \   Scott Shenker\n   Xerox PARC\n   3333 Coyote Hill Road\n   Palo Alto, CA 94304\n\
    \   Phone: 415-812-4840\n   EMail: Shenker@parc.xerox.com\n   John Wroclawski\n\
    \   MIT Laboratory for Computer Science\n   545 Technology Sq.\n   Cambridge,\
    \ MA  02139\n   Phone: 617-253-7885\n   EMail: JTW@lcs.mit.edu\n   Lixia Zhang\n\
    \   UCLA\n   4531G Boelter Hall\n   Los Angeles, CA 90024\n   Phone: 310-825-2695\n\
    \   EMail: Lixia@cs.ucla.edu\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (1998).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
