- title: __initial_text__
  contents:
  - '       Guidelines for Writing RFC Text on Security Considerations

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This document specifies an Internet Best Current Practices\
    \ for the\n   Internet Community, and requests discussion and suggestions for\n\
    \   improvements.  Distribution of this memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2003).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   All RFCs are required to have a Security Considerations section.\n\
    \   Historically, such sections have been relatively weak.  This document\n  \
    \ provides guidelines to RFC authors on how to write a good Security\n   Considerations\
    \ section.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction . . . . . . . . . . . . . . . . . . . .\
    \ . . .   3\n      1.1. Requirements. . . . . . . . . . . . . . . . . . . . .\
    \   3\n   2. The Goals of Security. . . . . . . . . . . . . . . . . . .   3\n\
    \      2.1. Communication Security. . . . . . . . . . . . . . . .   3\n      \
    \     2.1.1. Confidentiality. . . . . . . . . . . . . . . .   4\n           2.1.2.\
    \ Data Integrity . . . . . . . . . . . . . . . .   4\n           2.1.3. Peer Entity\
    \ authentication . . . . . . . . . .   4\n      2.2. Non-Repudiation . . . . .\
    \ . . . . . . . . . . . . . .   5\n      2.3. Systems Security. . . . . . . .\
    \ . . . . . . . . . . .   5\n           2.3.1. Unauthorized Usage . . . . . .\
    \ . . . . . . . .   6\n           2.3.2. Inappropriate Usage. . . . . . . . .\
    \ . . . . .   6\n           2.3.3. Denial of Service. . . . . . . . . . . . .\
    \ . .   6\n   3. The Internet Threat Model. . . . . . . . . . . . . . . . .  \
    \ 6\n      3.1. Limited Threat Models . . . . . . . . . . . . . . . .   7\n  \
    \    3.2. Passive Attacks . . . . . . . . . . . . . . . . . . .   7\n        \
    \   3.2.1. Confidentiality Violations . . . . . . . . . .   8\n           3.2.2.\
    \ Password Sniffing. . . . . . . . . . . . . . .   8\n           3.2.3. Offline\
    \ Cryptographic Attacks. . . . . . . . .   9\n      3.3. Active Attacks. . . .\
    \ . . . . . . . . . . . . . . . .   9\n           3.3.1. Replay Attacks . . .\
    \ . . . . . . . . . . . . .  10\n           3.3.2. Message Insertion. . . . .\
    \ . . . . . . . . . .  10\n           3.3.3. Message Deletion . . . . . . . .\
    \ . . . . . . .  11\n           3.3.4. Message Modification . . . . . . . . .\
    \ . . . .  11\n           3.3.5. Man-In-The-Middle. . . . . . . . . . . . . .\
    \ .  12\n      3.4. Topological Issues. . . . . . . . . . . . . . . . . .  12\n\
    \      3.5. On-path versus off-path . . . . . . . . . . . . . . .  13\n      3.6.\
    \ Link-local. . . . . . . . . . . . . . . . . . . . . .  13\n   4. Common Issues.\
    \ . . . . . . . . . . . . . . . . . . . . . .  13\n      4.1. User Authentication\
    \ . . . . . . . . . . . . . . . . .  14\n           4.1.1. Username/Password.\
    \ . . . . . . . . . . . . . .  14\n           4.1.2. Challenge Response and One\
    \ Time Passwords. . .  14\n           4.1.3. Shared Keys. . . . . . . . . . .\
    \ . . . . . . .  15\n           4.1.4. Key Distribution Centers . . . . . . .\
    \ . . . .  15\n           4.1.5. Certificates . . . . . . . . . . . . . . . .\
    \ .  15\n           4.1.6. Some Uncommon Systems. . . . . . . . . . . . .  15\n\
    \           4.1.7. Host Authentication. . . . . . . . . . . . . .  16\n      4.2.\
    \ Generic Security Frameworks . . . . . . . . . . . . .  16\n      4.3. Non-repudiation\
    \ . . . . . . . . . . . . . . . . . . .  17\n      4.4. Authorization vs. Authentication.\
    \ . . . . . . . . . .  18\n           4.4.1. Access Control Lists . . . . . .\
    \ . . . . . . .  18\n           4.4.2. Certificate Based Systems. . . . . . .\
    \ . . . .  18\n      4.5. Providing Traffic Security. . . . . . . . . . . . .\
    \ .  19\n           4.5.1. IPsec. . . . . . . . . . . . . . . . . . . . .  19\n\
    \           4.5.2. SSL/TLS. . . . . . . . . . . . . . . . . . . .  20\n      \
    \     4.5.3. Remote Login . . . . . . . . . . . . . . . . .  22\n      4.6. Denial\
    \ of Service Attacks and Countermeasures . . . .  22\n           4.6.1. Blind\
    \ Denial of Service. . . . . . . . . . . .  23\n           4.6.2. Distributed\
    \ Denial of Service. . . . . . . . .  23\n           4.6.3. Avoiding Denial of\
    \ Service . . . . . . . . . .  24\n           4.6.4. Example: TCP SYN Floods.\
    \ . . . . . . . . . . .  24\n           4.6.5. Example: Photuris. . . . . . .\
    \ . . . . . . . .  25\n      4.7. Object vs. Channel Security . . . . . . . .\
    \ . . . . .  25\n      4.8. Firewalls and Network Topology. . . . . . . . . .\
    \ . .  26\n   5. Writing Security Considerations Sections . . . . . . . . .  26\n\
    \   6. Examples . . . . . . . . . . . . . . . . . . . . . . . . .  28\n      6.1.\
    \ SMTP. . . . . . . . . . . . . . . . . . . . . . . . .  29\n           6.1.1.\
    \ Security Considerations. . . . . . . . . . . .  29\n           6.1.2. Communications\
    \ security issues . . . . . . . .  34\n           6.1.3. Denial of Service. .\
    \ . . . . . . . . . . . . .  36\n      6.2. VRRP. . . . . . . . . . . . . . .\
    \ . . . . . . . . . . .36\n           6.2.1. Security Considerations. . . . .\
    \ . . . . . . .  36\n   7. Acknowledgments. . . . . . . . . . . . . . . . . .\
    \ . . . .  38\n   8. Normative References . . . . . . . . . . . . . . . . . .\
    \ .  39\n   9. Informative References . . . . . . . . . . . . . . . . . .  41\n\
    \   10.Security Considerations. . . . . . . . . . . . . . . . . .  42\n   Appendix\
    \ A. . . . . . . . . . . . . . . . . . . . . . . . . .  43\n   Authors' Addresses.\
    \ . . . . . . . . . . . . . . . . . . . . .  43\n   Full Copyright Statement.\
    \ . . . . . . . . . . . . . . . . . .  44\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   All RFCs are required by RFC 2223 to contain a Security\n\
    \   Considerations section.  The purpose of this is both to encourage\n   document\
    \ authors to consider security in their designs and to inform\n   the reader of\
    \ relevant security issues.  This memo is intended to\n   provide guidance to\
    \ RFC authors in service of both ends.\n   This document is structured in three\
    \ parts.  The first is a\n   combination security tutorial and definition of common\
    \ terms; the\n   second is a series of guidelines for writing Security Considerations;\n\
    \   the third is a series of examples.\n"
- title: 1.1. Requirements
  contents:
  - "1.1. Requirements\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"\
    SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\"\
    , and \"OPTIONAL\" in this\n   document are to be interpreted as described in\
    \ BCP 14, RFC 2119\n   [KEYWORDS].\n"
- title: 2. The Goals of Security
  contents:
  - "2. The Goals of Security\n   Most people speak of security as if it were a single\
    \ monolithic\n   property of a protocol or system, however, upon reflection, one\n\
    \   realizes that it is clearly not true.  Rather, security is a series\n   of\
    \ related but somewhat independent properties.  Not all of these\n   properties\
    \ are required for every application.\n   We can loosely divide security goals\
    \ into those related to protecting\n   communications (COMMUNICATION SECURITY,\
    \ also known as COMSEC) and\n   those relating to protecting systems (ADMINISTRATIVE\
    \ SECURITY or\n   SYSTEM SECURITY).  Since communications are carried out by systems\n\
    \   and access to systems is through communications channels, these goals\n  \
    \ obviously interlock, but they can also be independently provided.\n"
- title: 2.1. Communication Security
  contents:
  - "2.1. Communication Security\n   Different authors partition the goals of communication\
    \ security\n   differently.  The partitioning we've found most useful is to divide\n\
    \   them into three major categories: CONFIDENTIALITY, DATA INTEGRITY and\n  \
    \ PEER ENTITY AUTHENTICATION.\n"
- title: 2.1.1. Confidentiality
  contents:
  - "2.1.1. Confidentiality\n   When most people think of security, they think of\
    \ CONFIDENTIALITY.\n   Confidentiality means that your data is kept secret from\
    \ unintended\n   listeners.  Usually, these listeners are simply eavesdroppers.\
    \  When\n   an adversary taps your phone, it poses a risk to your\n   confidentiality.\n\
    \   Obviously, if you have secrets, then you are probably concerned about\n  \
    \ others discovering them.  Thus, at the very least, you want to\n   maintain\
    \ confidentiality.  When you see spies in the movies go into\n   the bathroom\
    \ and turn on all the water to foil bugging, the property\n   they're looking\
    \ for is confidentiality.\n"
- title: 2.1.2. Data Integrity
  contents:
  - "2.1.2. Data Integrity\n   The second primary goal is DATA INTEGRITY.  The basic\
    \ idea here is\n   that we want to make sure that the data we receive is the same\
    \ data\n   that the sender has sent.  In paper-based systems, some data\n   integrity\
    \ comes automatically.  When you receive a letter written in\n   pen you can be\
    \ fairly certain that no words have been removed by an\n   attacker because pen\
    \ marks are difficult to remove from paper.\n   However, an attacker could have\
    \ easily added some marks to the paper\n   and completely changed the meaning\
    \ of the message.  Similarly, it's\n   easy to shorten the page to truncate the\
    \ message.\n   On the other hand, in the electronic world, since all bits look\n\
    \   alike, it's trivial to tamper with messages in transit.  You simply\n   remove\
    \ the message from the wire, copy out the parts you like, add\n   whatever data\
    \ you want, and generate a new message of your choosing,\n   and the recipient\
    \ is no wiser.  This is the moral equivalent of the\n   attacker taking a letter\
    \ you wrote, buying some new paper and\n   recopying the message, changing it\
    \ as he does it.  It's just a lot\n   easier to do electronically since all bits\
    \ look alike.\n"
- title: 2.1.3. Peer Entity authentication
  contents:
  - "2.1.3. Peer Entity authentication\n   The third property we're concerned with\
    \ is PEER ENTITY\n   AUTHENTICATION.  What we mean by this is that we know that\
    \ one of the\n   endpoints in the communication is the one we intended.  Without\
    \ peer\n   entity authentication, it's very difficult to provide either\n   confidentiality\
    \ or data integrity.  For instance, if we receive a\n   message from Alice, the\
    \ property of data integrity doesn't do us much\n   good unless we know that it\
    \ was in fact sent by Alice and not the\n   attacker.  Similarly, if we want to\
    \ send a confidential message to\n   Bob, it's not of much value to us if we're\
    \ actually sending a\n   confidential message to the attacker.\n   Note that peer\
    \ entity authentication can be provided asymmetrically.\n   When you call someone\
    \ on the phone, you can be fairly certain that\n   you have the right person --\
    \ or at least that you got a person who's\n   actually at the phone number you\
    \ called.  On the other hand, if they\n   don't have caller ID, then the receiver\
    \ of a phone call has no idea\n   who's calling them.  Calling someone on the\
    \ phone is an example of\n   recipient authentication, since you know who the\
    \ recipient of the\n   call is, but they don't know anything about the sender.\n\
    \   In messaging situations, you often wish to use peer entity\n   authentication\
    \ to establish the identity of the sender of a certain\n   message.  In such contexts,\
    \ this property is called DATA ORIGIN\n   AUTHENTICATION.\n"
- title: 2.2. Non-Repudiation
  contents:
  - "2.2. Non-Repudiation\n   A system that provides endpoint authentication allows\
    \ one party to be\n   certain of the identity of someone with whom he is communicating.\n\
    \   When the system provides data integrity a receiver can be sure of\n   both\
    \ the sender's identity and that he is receiving the data that\n   that sender\
    \ meant to send.  However, he cannot necessarily\n   demonstrate this fact to\
    \ a third party.  The ability to make this\n   demonstration is called NON-REPUDIATION.\n\
    \   There are many situations in which non-repudiation is desirable.\n   Consider\
    \ the situation in which two parties have signed a contract\n   which one party\
    \ wishes to unilaterally abrogate.  He might simply\n   claim that he had never\
    \ signed it in the first place.  Non-\n   repudiation prevents him from doing\
    \ so, thus protecting the\n   counterparty.\n   Unfortunately, non-repudiation\
    \ can be very difficult to achieve in\n   practice and naive approaches are generally\
    \ inadequate.  Section 4.3\n   describes some of the difficulties, which generally\
    \ stem from the\n   fact that the interests of the two parties are not aligned\
    \ -- one\n   party wishes to prove something that the other party wishes to deny.\n"
- title: 2.3. Systems Security
  contents:
  - "2.3. Systems Security\n   In general, systems security is concerned with protecting\
    \ one's\n   machines and data.  The intent is that machines should be used only\n\
    \   by authorized users and for the purposes that the owners intend.\n   Furthermore,\
    \ they should be available for those purposes.  Attackers\n   should not be able\
    \ to deprive legitimate users of resources.\n"
- title: 2.3.1. Unauthorized Usage
  contents:
  - "2.3.1. Unauthorized Usage\n   Most systems are not intended to be completely\
    \ accessible to the\n   public.  Rather, they are intended to be used only by\
    \ certain\n   authorized individuals.  Although many Internet services are\n \
    \  available to all Internet users, even those servers generally offer a\n   larger\
    \ subset of services to specific users.  For instance, Web\n   Servers often will\
    \ serve data to any user, but restrict the ability\n   to modify pages to specific\
    \ users.  Such modifications by the general\n   public would be UNAUTHORIZED USAGE.\n"
- title: 2.3.2. Inappropriate Usage
  contents:
  - "2.3.2. Inappropriate Usage\n   Being an authorized user does not mean that you\
    \ have free run of the\n   system.  As we said above, some activities are restricted\
    \ to\n   authorized users, some to specific users, and some activities are\n \
    \  generally forbidden to all but administrators.  Moreover, even\n   activities\
    \ which are in general permitted might be forbidden in some\n   cases.  For instance,\
    \ users may be permitted to send email but\n   forbidden from sending files above\
    \ a certain size, or files which\n   contain viruses.  These are examples of INAPPROPRIATE\
    \ USAGE.\n"
- title: 2.3.3. Denial of Service
  contents:
  - "2.3.3. Denial of Service\n   Recall that our third goal was that the system should\
    \ be available to\n   legitimate users.  A broad variety of attacks are possible\
    \ which\n   threaten such usage.  Such attacks are collectively referred to as\n\
    \   DENIAL OF SERVICE attacks.  Denial of service attacks are often very\n   easy\
    \ to mount and difficult to stop.  Many such attacks are designed\n   to consume\
    \ machine resources, making it difficult or impossible to\n   serve legitimate\
    \ users.  Other attacks cause the target machine to\n   crash, completely denying\
    \ service to users.\n"
- title: 3. The Internet Threat Model
  contents:
  - "3. The Internet Threat Model\n   A THREAT MODEL describes the capabilities that\
    \ an attacker is assumed\n   to be able to deploy against a resource.  It should\
    \ contain such\n   information as the resources available to an attacker in terms\
    \ of\n   information, computing capability, and control of the system.  The\n\
    \   purpose of a threat model is twofold.  First, we wish to identify the\n  \
    \ threats we are concerned with.  Second, we wish to rule some threats\n   explicitly\
    \ out of scope.  Nearly every security system is vulnerable\n   to a sufficiently\
    \ dedicated and resourceful attacker.\n   The Internet environment has a fairly\
    \ well understood threat model.\n   In general, we assume that the end-systems\
    \ engaging in a protocol\n   exchange have not themselves been compromised.  Protecting\
    \ against an\n   attack when one of the end-systems has been compromised is\n\
    \   extraordinarily difficult.  It is, however, possible to design\n   protocols\
    \ which minimize the extent of the damage done under these\n   circumstances.\n\
    \   By contrast, we assume that the attacker has nearly complete control\n   of\
    \ the communications channel over which the end-systems communicate.\n   This\
    \ means that the attacker can read any PDU (Protocol Data Unit) on\n   the network\
    \ and undetectably remove, change, or inject forged packets\n   onto the wire.\
    \  This includes being able to generate packets that\n   appear to be from a trusted\
    \ machine.  Thus, even if the end-system\n   with which you wish to communicate\
    \ is itself secure, the Internet\n   environment provides no assurance that packets\
    \ which claim to be from\n   that system in fact are.\n   It's important to realize\
    \ that the meaning of a PDU is different at\n   different levels.  At the IP level,\
    \ a PDU means an IP packet.  At the\n   TCP level, it means a TCP segment.  At\
    \ the application layer, it\n   means some kind of application PDU.  For instance,\
    \ at the level of\n   email, it might either mean an RFC-822 message or a single\
    \ SMTP\n   command.  At the HTTP level, it might mean a request or response.\n"
- title: 3.1. Limited Threat Models
  contents:
  - "3.1. Limited Threat Models\n   As we've said, a resourceful and dedicated attacker\
    \ can control the\n   entire communications channel.  However, a large number\
    \ of attacks\n   can be mounted by an attacker with fewer resources.  A number\
    \ of\n   currently known attacks can be mounted by an attacker with limited\n\
    \   control of the network.  For instance, password sniffing attacks can\n   be\
    \ mounted by an attacker who can only read arbitrary packets.  This\n   is generally\
    \ referred to as a PASSIVE ATTACK [INTAUTH].\n   By contrast, Morris' sequence\
    \ number guessing attack [SEQNUM] can be\n   mounted by an attacker who can write\
    \ but not read arbitrary packets.\n   Any attack which requires the attacker to\
    \ write to the network is\n   known as an ACTIVE ATTACK.\n   Thus, a useful way\
    \ of organizing attacks is to divide them based on\n   the capabilities required\
    \ to mount the attack.  The rest of this\n   section describes these categories\
    \ and provides some examples of each\n   category.\n"
- title: 3.2. Passive Attacks
  contents:
  - "3.2. Passive Attacks\n   In a passive attack, the attacker reads packets off\
    \ the network but\n   does not write them.  The simplest way to mount such an\
    \ attack is to\n   simply be on the same LAN as the victim.  On most common LAN\n\
    \   configurations, including Ethernet, 802.3, and FDDI, any machine on\n   the\
    \ wire can read all traffic destined for any other machine on the\n   same LAN.\
    \  Note that switching hubs make this sort of sniffing\n   substantially more\
    \ difficult, since traffic destined for a machine\n   only goes to the network\
    \ segment which that machine is on.\n   Similarly, an attacker who has control\
    \ of a host in the\n   communications path between two victim machines is able\
    \ to mount a\n   passive attack on their communications.  It is also possible\
    \ to\n   compromise the routing infrastructure to specifically arrange that\n\
    \   traffic passes through a compromised machine.  This might involve an\n   active\
    \ attack on the routing infrastructure to facilitate a passive\n   attack on a\
    \ victim machine.\n   Wireless communications channels deserve special consideration,\n\
    \   especially with the recent and growing popularity of wireless-based\n   LANs,\
    \ such as those using 802.11.  Since the data is simply broadcast\n   on well\
    \ known radio frequencies, an attacker simply needs to be able\n   to receive\
    \ those transmissions.  Such channels are especially\n   vulnerable to passive\
    \ attacks.  Although many such channels include\n   cryptographic protection,\
    \ it is often of such poor quality as to be\n   nearly useless [WEP].\n   In general,\
    \ the goal of a passive attack is to obtain information\n   which the sender and\
    \ receiver would prefer to remain private.  This\n   private information may include\
    \ credentials useful in the electronic\n   world and/or passwords or credentials\
    \ useful in the outside world,\n   such as confidential business information.\n"
- title: 3.2.1. Confidentiality Violations
  contents:
  - "3.2.1. Confidentiality Violations\n   The classic example of passive attack is\
    \ sniffing some inherently\n   private data off of the wire.  For instance, despite\
    \ the wide\n   availability of SSL, many credit card transactions still traverse\
    \ the\n   Internet in the clear.  An attacker could sniff such a message and\n\
    \   recover the credit card number, which can then be used to make\n   fraudulent\
    \ transactions.  Moreover, confidential business information\n   is routinely\
    \ transmitted over the network in the clear in email.\n"
- title: 3.2.2. Password Sniffing
  contents:
  - "3.2.2. Password Sniffing\n   Another example of a passive attack is PASSWORD\
    \ SNIFFING.  Password\n   sniffing is directed towards obtaining unauthorized\
    \ use of resources.\n   Many protocols, including [TELNET], [POP], and [NNTP]\
    \ use a shared\n   password to authenticate the client to the server.  Frequently,\
    \ this\n   password is transmitted from the client to the server in the clear\n\
    \   over the communications channel.  An attacker who can read this\n   traffic\
    \ can therefore capture the password and REPLAY it.  In other\n   words, the attacker\
    \ can initiate a connection to the server and pose\n   as the client and login\
    \ using the captured password.\n   Note that although the login phase of the attack\
    \ is active, the\n   actual password capture phase is passive.  Moreover, unless\
    \ the\n   server checks the originating address of connections, the login phase\n\
    \   does not require any special control of the network.\n"
- title: 3.2.3. Offline Cryptographic Attacks
  contents:
  - "3.2.3. Offline Cryptographic Attacks\n   Many cryptographic protocols are subject\
    \ to OFFLINE ATTACKS.  In such\n   a protocol, the attacker recovers data which\
    \ has been processed using\n   the victim's secret key and then mounts a cryptanalytic\
    \ attack on\n   that key.  Passwords make a particularly vulnerable target because\n\
    \   they are typically low entropy.  A number of popular password-based\n   challenge\
    \ response protocols are vulnerable to DICTIONARY ATTACK.\n   The attacker captures\
    \ a challenge-response pair and then proceeds to\n   try entries from a list of\
    \ common words (such as a dictionary file)\n   until he finds a password that\
    \ produces the right response.\n   A similar such attack can be mounted on a local\
    \ network when NIS is\n   used.  The Unix password is crypted using a one-way\
    \ function, but\n   tools exist to break such crypted passwords [KLEIN].  When\
    \ NIS is\n   used, the crypted password is transmitted over the local network\
    \ and\n   an attacker can thus sniff the password and attack it.\n   Historically,\
    \ it has also been possible to exploit small operating\n   system security holes\
    \ to recover the password file using an active\n   attack.  These holes can then\
    \ be bootstrapped into an actual account\n   by using the aforementioned offline\
    \ password recovery techniques.\n   Thus we combine a low-level active attack\
    \ with an offline passive\n   attack.\n"
- title: 3.3. Active Attacks
  contents:
  - "3.3. Active Attacks\n   When an attack involves writing data to the network,\
    \ we refer to this\n   as an ACTIVE ATTACK.  When IP is used without IPsec, there\
    \ is no\n   authentication for the sender address.  As a consequence, it's\n \
    \  straightforward for an attacker to create a packet with a source\n   address\
    \ of his choosing.  We'll refer to this as a SPOOFING ATTACK.\n   Under certain\
    \ circumstances, such a packet may be screened out by the\n   network.  For instance,\
    \ many packet filtering firewalls screen out\n   all packets with source addresses\
    \ on the INTERNAL network that arrive\n   on the EXTERNAL interface.  Note, however,\
    \ that this provides no\n   protection against an attacker who is inside the firewall.\
    \  In\n   general, designers should assume that attackers can forge packets.\n\
    \   However, the ability to forge packets does not go hand in hand with\n   the\
    \ ability to receive arbitrary packets.  In fact, there are active\n   attacks\
    \ that involve being able to send forged packets but not\n   receive the responses.\
    \  We'll refer to these as BLIND ATTACKS.\n   Note that not all active attacks\
    \ require forging addresses.  For\n   instance, the TCP SYN denial of service\
    \ attack [TCPSYN] can be\n   mounted successfully without disguising the sender's\
    \ address.\n   However, it is common practice to disguise one's address in order\
    \ to\n   conceal one's identity if an attack is discovered.\n   Each protocol\
    \ is susceptible to specific active attacks, but\n   experience shows that a number\
    \ of common patterns of attack can be\n   adapted to any given protocol.  The\
    \ next sections describe a number\n   of these patterns and give specific examples\
    \ of them as applied to\n   known protocols.\n"
- title: 3.3.1. Replay Attacks
  contents:
  - "3.3.1. Replay Attacks\n   In a REPLAY ATTACK, the attacker records a sequence\
    \ of messages off\n   of the wire and plays them back to the party which originally\n\
    \   received them.  Note that the attacker does not need to be able to\n   understand\
    \ the messages.  He merely needs to capture and retransmit\n   them.\n   For example,\
    \ consider the case where an S/MIME message is being used\n   to request some\
    \ service, such as a credit card purchase or a stock\n   trade.  An attacker might\
    \ wish to have the service executed twice, if\n   only to inconvenience the victim.\
    \  He could capture the message and\n   replay it, even though he can't read it,\
    \ causing the transaction to\n   be executed twice.\n"
- title: 3.3.2. Message Insertion
  contents:
  - "3.3.2. Message Insertion\n   In a MESSAGE INSERTION attack, the attacker forges\
    \ a message with\n   some chosen set of properties and injects it into the network.\
    \  Often\n   this message will have a forged source address in order to disguise\n\
    \   the identity of the attacker.\n   For example, a denial-of-service attack\
    \ can be mounted by inserting a\n   series of spurious TCP SYN packets directed\
    \ towards the target host.\n   The target host responds with its own SYN and allocates\
    \ kernel data\n   structures for the new connection.  The attacker never completes\
    \ the\n   3-way handshake, so the allocated connection endpoints just sit there\n\
    \   taking up kernel memory.  Typical TCP stack implementations only\n   allow\
    \ some limited number of connections in this \"half-open\" state\n   and when\
    \ this limit is reached, no more connections can be initiated,\n   even from legitimate\
    \ hosts.  Note that this attack is a blind attack,\n   since the attacker does\
    \ not need to process the victim's SYNs.\n"
- title: 3.3.3. Message Deletion
  contents:
  - "3.3.3. Message Deletion\n   In a MESSAGE DELETION attack, the attacker removes\
    \ a message from the\n   wire.  Morris' sequence number guessing attack [SEQNUM]\
    \ often\n   requires a message deletion attack to be performed successfully. \
    \ In\n   this blind attack, the host whose address is being forged will\n   receive\
    \ a spurious TCP SYN packet from the host being attacked.\n   Receipt of this\
    \ SYN packet generates a RST, which would tear the\n   illegitimate connection\
    \ down.  In order to prevent this host from\n   sending a RST so that the attack\
    \ can be carried out successfully,\n   Morris describes flooding this host to\
    \ create queue overflows such\n   that the SYN packet is lost and thus never responded\
    \ to.\n"
- title: 3.3.4. Message Modification
  contents:
  - "3.3.4. Message Modification\n   In a MESSAGE MODIFICATION attack, the attacker\
    \ removes a message from\n   the wire, modifies it, and reinjects it into the\
    \ network.  This sort\n   of attack is particularly useful if the attacker wants\
    \ to send some\n   of the data in the message but also wants to change some of\
    \ it.\n   Consider the case where the attacker wants to attack an order for\n\
    \   goods placed over the Internet.  He doesn't have the victim's credit\n   card\
    \ number so he waits for the victim to place the order and then\n   replaces the\
    \ delivery address (and possibly the goods description)\n   with his own.  Note\
    \ that this particular attack is known as a CUT-\n   AND-PASTE attack since the\
    \ attacker cuts the credit card number out\n   of the original message and pastes\
    \ it into the new message.\n   Another interesting example of a cut-and-paste\
    \ attack is provided by\n   [IPSPPROB].  If IPsec ESP is used without any MAC\
    \ then it is possible\n   for the attacker to read traffic encrypted for a victim\
    \ on the same\n   machine.  The attacker attaches an IP header corresponding to\
    \ a port\n   he controls onto the encrypted IP packet.  When the packet is\n \
    \  received by the host it will automatically be decrypted and forwarded\n   to\
    \ the attacker's port.  Similar techniques can be used to mount a\n   session\
    \ hijacking attack.  Both of these attacks can be avoided by\n   always using\
    \ message authentication when you use encryption.  Note\n   that this attack only\
    \ works if (1) no MAC check is being used, since\n   this attack generates damaged\
    \ packets (2) a host-to-host SA is being\n   used, since a user-to-user SA will\
    \ result in an inconsistency between\n   the port associated with the SA and the\
    \ target port.  If the\n   receiving machine is single-user than this attack is\
    \ infeasible.\n"
- title: 3.3.5. Man-In-The-Middle
  contents:
  - "3.3.5. Man-In-The-Middle\n   A MAN-IN-THE-MIDDLE attack combines the above techniques\
    \ in a special\n   form: The attacker subverts the communication stream in order\
    \ to pose\n   as the sender to receiver and the receiver to the sender:\n    \
    \  What Alice and Bob think:\n      Alice  <---------------------------------------------->\
    \  Bob\n      What's happening:\n      Alice  <---------------->  Attacker  <---------------->\
    \  Bob\n   This differs fundamentally from the above forms of attack because it\n\
    \   attacks the identity of the communicating parties, rather than the\n   data\
    \ stream itself.  Consequently, many techniques which provide\n   integrity of\
    \ the communications stream are insufficient to protect\n   against man-in-the-middle\
    \ attacks.\n   Man-in-the-middle attacks are possible whenever a protocol lacks\
    \ PEER\n   ENTITY AUTHENTICATION.  For instance, if an attacker can hijack the\n\
    \   client TCP connection during the TCP handshake (perhaps by responding\n  \
    \ to the client's SYN before the server does), then the attacker can\n   open\
    \ another connection to the server and begin a man-in-the-middle\n   attack. \
    \ It is also trivial to mount man-in-the-middle attacks on\n   local networks\
    \ via ARP spoofing -- the attacker forges an ARP with\n   the victim's IP address\
    \ and his own MAC address.  Tools to mount this\n   sort of attack are readily\
    \ available.\n   Note that it is only necessary to authenticate one side of the\n\
    \   transaction in order to prevent man-in-the-middle attacks.  In such a\n  \
    \ situation the the peers can establish an association in which only\n   one peer\
    \ is authenticated.  In such a system, an attacker can\n   initiate an association\
    \ posing as the unauthenticated peer but cannot\n   transmit or access data being\
    \ sent on a legitimate connection.  This\n   is an acceptable situation in contexts\
    \ such as Web e-commerce where\n   only the server needs to be authenticated (or\
    \ the client is\n   independently authenticated via some non-cryptographic mechanism\
    \ such\n   as a credit card number).\n"
- title: 3.4. Topological Issues
  contents:
  - "3.4. Topological Issues\n   In practice, the assumption that it's equally easy\
    \ for an attacker to\n   read and generate all packets is false, since the Internet\
    \ is not\n   fully connected.  This has two primary implications.\n"
- title: 3.5. On-path versus off-path
  contents:
  - "3.5. On-path versus off-path\n   In order for a datagram to be transmitted from\
    \ one host to another,\n   it generally must traverse some set of intermediate\
    \ links and\n   gateways.  Such gateways are naturally able to read, modify, or\n\
    \   remove any datagram transmitted along that path.  This makes it much\n   easier\
    \ to mount a wide variety of attacks if you are on-path.\n   Off-path hosts can,\
    \ of course, transmit arbitrary datagrams that\n   appear to come from any hosts\
    \ but cannot necessarily receive\n   datagrams intended for other hosts.  Thus,\
    \ if an attack depends on\n   being able to receive data, off-path hosts must\
    \ first subvert the\n   topology in order to place themselves on-path.  This is\
    \ by no means\n   impossible but is not necessarily trivial.\n   Applications\
    \ protocol designers MUST NOT assume that all attackers\n   will be off-path.\
    \  Where possible, protocols SHOULD be designed to\n   resist attacks from attackers\
    \ who have complete control of the\n   network.  However, designers are expected\
    \ to give more weight to\n   attacks which can be mounted by off-path attackers\
    \ as well as on-path\n   ones.\n"
- title: 3.6. Link-local
  contents:
  - "3.6. Link-local\n   One specialized case of on-path is being on the same link.\
    \  In some\n   situations, it's desirable to distinguish between hosts who are\
    \ on\n   the local network and those who are not.  The standard technique for\n\
    \   this is verifying the IP TTL value [IP].  Since the TTL must be\n   decremented\
    \ by each forwarder, a protocol can demand that TTL be set\n   to 255 and that\
    \ all receivers verify the TTL.  A receiver then has\n   some reason to believe\
    \ that conforming packets are from the same\n   link.  Note that this technique\
    \ must be used with care in the\n   presence of tunneling systems, since such\
    \ systems may pass packets\n   without decrementing TTL.\n"
- title: 4. Common Issues
  contents:
  - "4. Common Issues\n   Although each system's security requirements are unique,\
    \ certain\n   common requirements appear in a number of protocols.  Often, when\n\
    \   naive protocol designers are faced with these requirements, they\n   choose\
    \ an obvious but insecure solution even though better solutions\n   are available.\
    \  This section describes a number of issues seen in\n   many protocols and the\
    \ common pieces of security technology that may\n   be useful in addressing them.\n"
- title: 4.1. User Authentication
  contents:
  - "4.1. User Authentication\n   Essentially every system which wants to control\
    \ access to its\n   resources needs some way to authenticate users.  A nearly\
    \ uncountable\n   number of such mechanisms have been designed for this purpose.\
    \  The\n   next several sections describe some of these techniques.\n"
- title: 4.1.1. Username/Password
  contents:
  - "4.1.1. Username/Password\n   The most common access control mechanism is simple\
    \ USERNAME/PASSWORD\n   The user provides a username and a reusable password to\
    \ the host\n   which he wishes to use.  This system is vulnerable to a simple\n\
    \   passive attack where the attacker sniffs the password off the wire\n   and\
    \ then initiates a new session, presenting the password.  This\n   threat can\
    \ be mitigated by hosting the protocol over an encrypted\n   connection such as\
    \ TLS or IPSEC.  Unprotected (plaintext)\n   username/password systems are not\
    \ acceptable in IETF standards.\n"
- title: 4.1.2. Challenge Response and One Time Passwords
  contents:
  - "4.1.2. Challenge Response and One Time Passwords\n   Systems which desire greater\
    \ security than USERNAME/PASSWORD often\n   employ either a ONE TIME PASSWORD\
    \ [OTP] scheme or a CHALLENGE-\n   RESPONSE.  In a one time password scheme, the\
    \ user is provided with a\n   list of passwords, which must be used in sequence,\
    \ one time each.\n   (Often these passwords are generated from some secret key\
    \ so the user\n   can simply compute the next password in the sequence.)  SecureID\
    \ and\n   DES Gold are variants of this scheme.  In a challenge-response\n   scheme,\
    \ the host and the user share some secret (which often is\n   represented as a\
    \ password).  In order to authenticate the user, the\n   host presents the user\
    \ with a (randomly generated) challenge.  The\n   user computes some function\
    \ based on the challenge and the secret and\n   provides that to the host, which\
    \ verifies it.  Often this computation\n   is performed in a handheld device,\
    \ such as a DES Gold card.\n   Both types of scheme provide protection against\
    \ replay attack, but\n   often still vulnerable to an OFFLINE KEYSEARCH ATTACK\
    \ (a form of\n   passive attack): As previously mentioned, often the one-time\
    \ password\n   or response is computed from a shared secret.  If the attacker\
    \ knows\n   the function being used, he can simply try all possible shared\n \
    \  secrets until he finds one that produces the right output.  This is\n   made\
    \ easier if the shared secret is a password, in which case he can\n   mount a\
    \ DICTIONARY ATTACK -- meaning that he tries a list of common\n   words (or strings)\
    \ rather than just random strings.\n   These systems are also often vulnerable\
    \ to an active attack.  Unless\n   communication security is provided for the\
    \ entire session, the\n   attacker can simply wait until authentication has been\
    \ performed and\n   hijack the connection.\n"
- title: 4.1.3. Shared Keys
  contents:
  - "4.1.3. Shared Keys\n   CHALLENGE-RESPONSE type systems can be made secure against\
    \ dictionary\n   attack by using randomly generated shared keys instead of user-\n\
    \   generated passwords.  If the keys are sufficiently large then\n   keysearch\
    \ attacks become impractical.  This approach works best when\n   the keys are\
    \ configured into the end nodes rather than memorized and\n   typed in by users,\
    \ since users have trouble remembering sufficiently\n   long keys.\n   Like password-based\
    \ systems, shared key systems suffer from\n   management problems.  Each pair\
    \ of communicating parties must have\n   their own agreed-upon key, which leads\
    \ to there being a lot of keys.\n"
- title: 4.1.4. Key Distribution Centers
  contents:
  - "4.1.4. Key Distribution Centers\n   One approach to solving the large number\
    \ of keys problem is to use an\n   online \"trusted third party\" that mediates\
    \ between the authenticating\n   parties.  The trusted third party (generally\
    \ called a a KEY\n   DISTRIBUTION CENTER (KDC)) shares a symmetric key or password\
    \ with\n   each party in the system.  It first contacts the KDC which gives it\
    \ a\n   TICKET containing a randomly generated symmetric key encrypted under\n\
    \   both peer's keys.  Since only the proper peers can decrypt the\n   symmetric\
    \ key the ticket can be used to establish a trusted\n   association.  By far the\
    \ most popular KDC system is Kerberos\n   [KERBEROS].\n"
- title: 4.1.5. Certificates
  contents:
  - "4.1.5. Certificates\n   A simple approach is to have all users have CERTIFICATES\
    \ [PKIX] which\n   they then use to authenticate in some protocol-specific way,\
    \ as in\n   [TLS] or [S/MIME].  A certificate is a signed credential binding an\n\
    \   entity's identity to its public key.  The signer of a certificate is\n   a\
    \ CERTIFICATE AUTHORITY (CA), whose certificate may itself be signed\n   by some\
    \ superior CA.  In order for this system to work, trust in one\n   or more CAs\
    \ must be established in an out-of-band fashion.  Such CAs\n   are referred to\
    \ as TRUSTED ROOTS or ROOT CAS.  The primary obstacle\n   to this approach in\
    \ client-server type systems is that it requires\n   clients to have certificates,\
    \ which can be a deployment problem.\n"
- title: 4.1.6. Some Uncommon Systems
  contents:
  - "4.1.6. Some Uncommon Systems\n   There are ways to do a better job than the schemes\
    \ mentioned above,\n   but they typically don't add much security unless communications\n\
    \   security (at least message integrity) will be employed to secure the\n   connection,\
    \ because otherwise the attacker can merely hijack the\n   connection after authentication\
    \ has been performed.  A number of\n   protocols ([EKE], [SPEKE], [SRP]) allow\
    \ one to securely bootstrap a\n   user's password into a shared key which can\
    \ be used as input to a\n   cryptographic protocol.  One major obstacle to the\
    \ deployment of\n   these protocols has been that their Intellectual Property\
    \ status is\n   extremely unclear.  Similarly, the user can authenticate using\
    \ public\n   key certificates (e.g., S-HTTP client authentication).  Typically\n\
    \   these methods are used as part of a more complete security protocol.\n"
- title: 4.1.7. Host Authentication
  contents:
  - "4.1.7. Host Authentication\n   Host authentication presents a special problem.\
    \  Quite commonly, the\n   addresses of services are presented using a DNS hostname,\
    \ for\n   instance as a URL [URL].  When requesting such a service, one has to\n\
    \   ensure that the entity that one is talking to not only has a\n   certificate\
    \ but that that certificate corresponds to the expected\n   identity of the server.\
    \  The important thing to have is a secure\n   binding between the certificate\
    \ and the expected hostname.\n   For instance, it is usually not acceptable for\
    \ the certificate to\n   contain an identity in the form of an IP address if the\
    \ request was\n   for a given hostname.  This does not provide end-to-end security\n\
    \   because the hostname-IP mapping is not secure unless secure name\n   resolution\
    \ [DNSSEC] is being used.  This is a particular problem when\n   the hostname\
    \ is presented at the application layer but the\n   authentication is performed\
    \ at some lower layer.\n"
- title: 4.2. Generic Security Frameworks
  contents:
  - "4.2. Generic Security Frameworks\n   Providing security functionality in a protocol\
    \ can be difficult.  In\n   addition to the problem of choosing authentication\
    \ and key\n   establishment mechanisms, one needs to integrate it into a protocol.\n\
    \   One response to this problem (embodied in IPsec and TLS) is to create\n  \
    \ a lower-level security protocol and then insist that new protocols be\n   run\
    \ over that protocol.  Another approach that has recently become\n   popular is\
    \ to design generic application layer security frameworks.\n   The idea is that\
    \ you design a protocol that allows you to negotiate\n   various security mechanisms\
    \ in a pluggable fashion.  Application\n   protocol designers then arrange to\
    \ carry the security protocol PDUs\n   in their application protocol.  Examples\
    \ of such frameworks include\n   GSS-API [GSS] and SASL [SASL].\n   The generic\
    \ framework approach has a number of problems.  First, it\n   is highly susceptible\
    \ to DOWNGRADE ATTACKS.  In a downgrade attack,\n   an active attacker tampers\
    \ with the negotiation in order to force the\n   parties to negotiate weaker protection\
    \ than they otherwise would.\n   It's possible to include an integrity check after\
    \ the negotiation and\n   key establishment have both completed, but the strength\
    \ of this\n   integrity check is necessarily limited to the weakest common\n \
    \  algorithm.  This problem exists with any negotiation approach, but\n   generic\
    \ frameworks exacerbate it by encouraging the application\n   protocol author\
    \ to just specify the framework rather than think hard\n   about the appropriate\
    \ underlying mechanisms, particularly since the\n   mechanisms can very widely\
    \ in the degree of security offered.\n   Another problem is that it's not always\
    \ obvious how the various\n   security features in the framework interact with\
    \ the application\n   layer protocol.  For instance, SASL can be used merely as\
    \ an\n   authentication framework -- in which case the SASL exchange occurs\n\
    \   but the rest of the connection is unprotected, but can also negotiate\n  \
    \ traffic protection, such as via GSS, as a mechanism.  Knowing under\n   what\
    \ circumstances traffic protection is optional and which it is\n   required requires\
    \ thinking about the threat model.\n   In general, authentication frameworks are\
    \ most useful in situations\n   where new protocols are being added to systems\
    \ with pre-existing\n   legacy authentication systems.  A framework allows new\
    \ installations\n   to provide better authentication while not forcing existing\
    \ sites\n   completely redo their legacy authentication systems.  When the\n \
    \  security requirements of a system can be clearly identified and only\n   a\
    \ few forms of authentication are used, choosing a single security\n   mechanism\
    \ leads to greater simplicity and predictability.  In\n   situations where a framework\
    \ is to be used, designers SHOULD\n   carefully examine the framework's options\
    \ and specify only the\n   mechanisms that are appropriate for their particular\
    \ threat model.\n   If a framework is necessary, designers SHOULD choose one of\
    \ the\n   established ones instead of designing their own.\n"
- title: 4.3. Non-repudiation
  contents:
  - "4.3. Non-repudiation\n   The naive approach to non-repudiation is simply to use\
    \ public-key\n   digital signatures over the content.  The party who wishes to\
    \ be\n   bound (the SIGNING PARTY) digitally signs the message in question.\n\
    \   The counterparty (the RELYING PARTY) can later point to the digital\n   signature\
    \ as proof that the signing party at one point agreed to the\n   disputed message.\
    \  Unfortunately, this approach is insufficient.\n   The easiest way for the signing\
    \ party to repudiate the message is by\n   claiming that his private key has been\
    \ compromised and that some\n   attacker (though not necessarily the relying party)\
    \ signed the\n   disputed message.  In order to defend against this attack the\
    \ relying\n   party needs to demonstrate that the signing party's key had not\
    \ been\n   compromised at the time of the signature.  This requires substantial\n\
    \   infrastructure, including archival storage of certificate revocation\n   information\
    \ and timestamp servers to establish the time that the\n   message was signed.\n\
    \   Additionally, the relying party might attempt to trick the signing\n   party\
    \ into signing one message while thinking he's signing another.\n   This problem\
    \ is particularly severe when the relying party controls\n   the infrastructure\
    \ that the signing party uses for signing, such as\n   in kiosk situations.  In\
    \ many such situations the signing party's key\n   is kept on a smartcard but\
    \ the message to be signed is displayed by\n   the relying party.\n   All of these\
    \ complications make non-repudiation a difficult service\n   to deploy in practice.\n"
- title: 4.4. Authorization vs. Authentication
  contents:
  - "4.4. Authorization vs. Authentication\n   AUTHORIZATION is the process by which\
    \ one determines whether an\n   authenticated party has permission to access a\
    \ particular resource or\n   service.  Although tightly bound, it is important\
    \ to realize that\n   authentication and authorization are two separate mechanisms.\n\
    \   Perhaps because of this tight coupling, authentication is sometimes\n   mistakenly\
    \ thought to imply authorization.  Authentication simply\n   identifies a party,\
    \ authorization defines whether they can perform a\n   certain action.\n   Authorization\
    \ necessarily relies on authentication, but\n   authentication alone does not\
    \ imply authorization.  Rather, before\n   granting permission to perform an action,\
    \ the authorization mechanism\n   must be consulted to determine whether that\
    \ action is permitted.\n"
- title: 4.4.1. Access Control Lists
  contents:
  - "4.4.1. Access Control Lists\n   One common form of authorization mechanism is\
    \ an access control list\n   (ACL), which lists users that are permitted access\
    \ to a resource.\n   Since assigning individual authorization permissions to each\
    \ resource\n   is tedious, resources are often hierarchically arranged so that\
    \ the\n   parent resource's ACL is inherited by child resources.  This allows\n\
    \   administrators to set top level policies and override them when\n   necessary.\n"
- title: 4.4.2. Certificate Based Systems
  contents:
  - "4.4.2. Certificate Based Systems\n   While the distinction between authentication\
    \ and authorization is\n   intuitive when using simple authentication mechanisms\
    \ such as\n   username and password (i.e., everyone understands the difference\n\
    \   between the administrator account and a user account), with more\n   complex\
    \ authentication mechanisms the distinction is sometimes lost.\n   With certificates,\
    \ for instance, presenting a valid signature does\n   not imply authorization.\
    \  The signature must be backed by a\n   certificate chain that contains a trusted\
    \ root, and that root must be\n   trusted in the given context.  For instance,\
    \ users who possess\n   certificates issued by the Acme MIS CA may have different\
    \ web access\n   privileges than users who possess certificates issued by the\
    \ Acme\n   Accounting CA, even though both of these CAs are \"trusted\" by the\n\
    \   Acme web server.\n   Mechanisms for enforcing these more complicated properties\
    \ have not\n   yet been completely explored.  One approach is simply to attach\n\
    \   policies to ACLs describing what sorts of certificates are trusted.\n   Another\
    \ approach is to carry that information with the certificate,\n   either as a\
    \ certificate extension/attribute [PKIX, SPKI] or as a\n   separate \"Attribute\
    \ Certificate\".\n"
- title: 4.5. Providing Traffic Security
  contents:
  - "4.5. Providing Traffic Security\n   Securely designed protocols should provide\
    \ some mechanism for\n   securing (meaning integrity protecting, authenticating,\
    \ and possibly\n   encrypting) all sensitive traffic.  One approach is to secure\
    \ the\n   protocol itself, as in [DNSSEC], [S/MIME] or [S-HTTP].  Although this\n\
    \   provides security which is most fitted to the protocol, it also\n   requires\
    \ considerable effort to get right.\n   Many protocols can be adequately secured\
    \ using one of the available\n   channel security systems.  We'll discuss the\
    \ two most common, IPsec\n   [AH, ESP] and [TLS].\n"
- title: 4.5.1. IPsec
  contents:
  - "4.5.1. IPsec\n   The IPsec protocols (specifically, AH and ESP) can provide\n\
    \   transmission security for all traffic between two hosts.  The IPsec\n   protocols\
    \ support varying granularities of user identification,\n   including for example\
    \ \"IP Subnet\", \"IP Address\", \"Fully Qualified\n   Domain Name\", and individual\
    \ user (\"Mailbox name\").  These varying\n   levels of identification are employed\
    \ as inputs to access control\n   facilities that are an intrinsic part of IPsec.\
    \  However, a given\n   IPsec implementation might not support all identity types.\
    \  In\n   particular, security gateways may not provide user-to-user\n   authentication\
    \ or have mechanisms to provide that authentication\n   information to applications.\n\
    \   When AH or ESP is used, the application programmer might not need to\n   do\
    \ anything (if AH or ESP has been enabled system-wide) or might need\n   to make\
    \ specific software changes (e.g., adding specific setsockopt()\n   calls) --\
    \ depending on the AH or ESP implementation being used.\n   Unfortunately, APIs\
    \ for controlling IPsec implementations are not yet\n   standardized.\n   The\
    \ primary obstacle to using IPsec to secure other protocols is\n   deployment.\
    \  The major use of IPsec at present is for VPN\n   applications, especially for\
    \ remote network access.  Without\n   extremely tight coordination between security\
    \ administrators and\n   application developers, VPN usage is not well suited\
    \ to providing\n   security services for individual applications since it is difficult\n\
    \   for such applications to determine what security services have in\n   fact\
    \ been provided.\n   IPsec deployment in host-to-host environments has been slow.\
    \  Unlike\n   application security systems such as TLS, adding IPsec to a non-IPsec\n\
    \   system generally involves changing the operating system, either by\n   modifying\
    \ with the kernel or installing new drivers.  This is a\n   substantially greater\
    \ undertaking than simply installing a new\n   application.  However, recent versions\
    \ of a number of commodity\n   operating systems include IPsec stacks, so deployment\
    \ is becoming\n   easier.\n   In environments where IPsec is sure to be available,\
    \ it represents a\n   viable option for protecting application communications\
    \ traffic.  If\n   the traffic to be protected is UDP, IPsec and application-specific\n\
    \   object security are the only options.  However, designers MUST NOT\n   assume\
    \ that IPsec will be available.  A security policy for a generic\n   application\
    \ layer protocol SHOULD NOT simply state that IPsec must be\n   used, unless there\
    \ is some reason to believe that IPsec will be\n   available in the intended deployment\
    \ environment.  In environments\n   where IPsec may not be available and the traffic\
    \ is solely TCP, TLS\n   is the method of choice, since the application developer\
    \ can easily\n   ensure its presence by including a TLS implementation in his\
    \ package.\n   In the special-case of IPv6, both AH and ESP are mandatory to\n\
    \   implement.  Hence, it is reasonable to assume that AH/ESP are already\n  \
    \ available for IPv6-only protocols or IPv6-only deployments.  However,\n   automatic\
    \ key management (IKE) is not required to implement so\n   protocol designers\
    \ SHOULD not assume it will be present.  [USEIPSEC]\n   provides quite a bit of\
    \ guidance on when IPsec is a good choice.\n"
- title: 4.5.2. SSL/TLS
  contents:
  - "4.5.2. SSL/TLS\n   Currently, the most common approach is to use SSL or its successor\n\
    \   TLS.  They provide channel security for a TCP connection at the\n   application\
    \ level.  That is, they run over TCP.  SSL implementations\n   typically provide\
    \ a Berkeley Sockets-like interface for easy\n   programming.  The primary issue\
    \ when designing a protocol solution\n   around TLS is to differentiate between\
    \ connections protected using\n   TLS and those which are not.\n   The two primary\
    \ approaches used have a separate well-known port for\n   TLS connections (e.g.,\
    \ the HTTP over TLS port is 443) [HTTPTLS] or to\n   have a mechanism for negotiating\
    \ upward from the base protocol to TLS\n   as in [UPGRADE] or [STARTTLS].  When\
    \ an upward negotiation strategy\n   is used, care must be taken to ensure that\
    \ an attacker can not force\n   a clear connection when both parties wish to use\
    \ TLS.\n   Note that TLS depends upon a reliable protocol such as TCP or SCTP.\n\
    \   This produces two notable difficulties.  First, it cannot be used to\n   secure\
    \ datagram protocols that use UDP.  Second, TLS is susceptible\n   to IP layer\
    \ attacks that IPsec is not.  Typically, these attacks take\n   some form of denial\
    \ of service or connection assassination.  For\n   instance, an attacker might\
    \ forge a TCP RST to shut down SSL\n   connections.  TLS has mechanisms to detect\
    \ truncation attacks but\n   these merely allow the victim to know he is being\
    \ attacked and do not\n   provide connection survivability in the face of such\
    \ attacks.  By\n   contrast, if IPsec were being used, such a forged RST could\
    \ be\n   rejected without affecting the TCP connection.  If forged RSTs or\n \
    \  other such attacks on the TCP connection are a concern, then AH/ESP\n   or\
    \ the TCP MD5 option [TCPMD5] are the preferred choices.\n"
- title: 4.5.2.1. Virtual Hosts
  contents:
  - "4.5.2.1. Virtual Hosts\n   If the \"separate ports\" approach to TLS is used,\
    \ then TLS will be\n   negotiated before any application-layer traffic is sent.\
    \  This can\n   cause a problem with protocols that use virtual hosts, such as\n\
    \   [HTTP], since the server does not know which certificate to offer the\n  \
    \ client during the TLS handshake.  The TLS hostname extension [TLSEXT]\n   can\
    \ be used to solve this problem, although it is too new to have\n   seen wide\
    \ deployment.\n"
- title: 4.5.2.2. Remote Authentication and TLS
  contents:
  - "4.5.2.2. Remote Authentication and TLS\n   One difficulty with using TLS is that\
    \ the server is authenticated via\n   a certificate.  This can be inconvenient\
    \ in environments where\n   previously the only form of authentication was a password\
    \ shared\n   between client and server.  It's tempting to use TLS without an\n\
    \   authenticated server (i.e., with anonymous DH or a self-signed RSA\n   certificate)\
    \ and then authenticate via some challenge-response\n   mechanism such as SASL\
    \ with CRAM-MD5.\n   Unfortunately, this composition of SASL and TLS is less strong\
    \ than\n   one would expect.  It's easy for an active attacker to hijack this\n\
    \   connection.  The client man-in-the-middles the SSL connection\n   (remember\
    \ we're not authenticating the server, which is what\n   ordinarily prevents this\
    \ attack) and then simply proxies the SASL\n   handshake.  From then on, it's\
    \ as if the connection were in the\n   clear, at least as far as that attacker\
    \ is concerned.  In order to\n   prevent this attack, the client needs to verify\
    \ the server's\n   certificate.\n   However, if the server is authenticated, challenge-response\
    \ becomes\n   less desirable.  If you already have a hardened channel then simple\n\
    \   passwords are fine.  In fact, they're arguably superior to\n   challenge-response\
    \ since they do not require that the password be\n   stored in the clear on the\
    \ server.  Thus, compromise of the key file\n   with challenge-response systems\
    \ is more serious than if simple\n   passwords were used.\n   Note that if the\
    \ client has a certificate than SSL-based client\n   authentication can be used.\
    \  To make this easier, SASL provides the\n   EXTERNAL mechanism, whereby the\
    \ SASL client can tell the server\n   \"examine the outer channel for my identity\"\
    .  Obviously, this is not\n   subject to the layering attacks described above.\n"
- title: 4.5.3. Remote Login
  contents:
  - "4.5.3. Remote Login\n   In some special cases it may be worth providing channel-level\n\
    \   security directly in the application rather than using IPSEC or\n   SSL/TLS.\
    \  One such case is remote terminal security.  Characters are\n   typically delivered\
    \ from client to server one character at a time.\n   Since SSL/TLS and AH/ESP\
    \ authenticate and encrypt every packet, this\n   can mean a data expansion of\
    \ 20-fold.  The telnet encryption option\n   [ENCOPT] prevents this expansion\
    \ by foregoing message integrity.\n   When using remote terminal service, it's\
    \ often desirable to securely\n   perform other sorts of communications services.\
    \  In addition to\n   providing remote login, SSH [SSH] also provides secure port\n\
    \   forwarding for arbitrary TCP ports, thus allowing users run arbitrary\n  \
    \ TCP-based applications over the SSH channel.  Note that SSH Port\n   Forwarding\
    \ can be security issue if it is used improperly to\n   circumvent firewall and\
    \ improperly expose insecure internal\n   applications to the outside world.\n"
- title: 4.6. Denial of Service Attacks and Countermeasures
  contents:
  - "4.6. Denial of Service Attacks and Countermeasures\n   Denial of service attacks\
    \ are all too frequently viewed as an fact of\n   life.  One problem is that an\
    \ attacker can often choose from one of\n   many denial of service attacks to\
    \ inflict upon a victim, and because\n   most of these attacks cannot be thwarted,\
    \ common wisdom frequently\n   assumes that there is no point protecting against\
    \ one kind of denial\n   of service attack when there are many other denial of\
    \ service attacks\n   that are possible but that cannot be prevented.\n   However,\
    \ not all denial of service attacks are equal and more\n   importantly, it is\
    \ possible to design protocols so that denial of\n   service attacks are made\
    \ more difficult, if not impractical.  Recent\n   SYN flood attacks [TCPSYN] demonstrate\
    \ both of these properties: SYN\n   flood attacks are so easy, anonymous, and\
    \ effective that they are\n   more attractive to attackers than other attacks;\
    \ and because the\n   design of TCP enables this attack.\n   Because complete\
    \ DoS protection is so difficult, security against DoS\n   must be dealt with\
    \ pragmatically.  In particular, some attacks which\n   would be desirable to\
    \ defend against cannot be defended against\n   economically.  The goal should\
    \ be to manage risk by defending against\n   attacks with sufficiently high ratios\
    \ of severity to cost of defense.\n   Both severity of attack and cost of defense\
    \ change as technology\n   changes and therefore so does the set of attacks which\
    \ should be\n   defended against.\n   Authors of internet standards MUST describe\
    \ which denial of service\n   attacks their protocol is susceptible to.  This\
    \ description MUST\n   include the reasons it was either unreasonable or out of\
    \ scope to\n   attempt to avoid these denial of service attacks.\n"
- title: 4.6.1. Blind Denial of Service
  contents:
  - "4.6.1. Blind Denial of Service\n   BLIND denial of service attacks are particularly\
    \ pernicious.  With a\n   blind attack the attacker has a significant advantage.\
    \  If the\n   attacker must be able to receive traffic from the victim, then he\n\
    \   must either subvert the routing fabric or use his own IP address.\n   Either\
    \ provides an opportunity for the victim to track the attacker\n   and/or filter\
    \ out his traffic.  With a blind attack the attacker can\n   use forged IP addresses,\
    \ making it extremely difficult for the victim\n   to filter out his packets.\
    \  The TCP SYN flood attack is an example of\n   a blind attack.  Designers should\
    \ make every attempt possible to\n   prevent blind denial of service attacks.\n"
- title: 4.6.2. Distributed Denial of Service
  contents:
  - "4.6.2. Distributed Denial of Service\n   Even more dangerous are DISTRIBUTED\
    \ denial of service attacks (DDoS)\n   [DDOS].  In a DDoS the attacker arranges\
    \ for a number of machines to\n   attack the target machine simultaneously.  Usually\
    \ this is\n   accomplished by infecting a large number of machines with a program\n\
    \   that allows remote initiation of attacks.  The machines actually\n   performing\
    \ the attack are called ZOMBIEs and are likely owned by\n   unsuspecting third\
    \ parties in an entirely different location from the\n   true attacker.  DDoS\
    \ attacks can be very hard to counter because the\n   zombies often appear to\
    \ be making legitimate protocol requests and\n   simply crowd out the real users.\
    \  DDoS attacks can be difficult to\n   thwart, but protocol designers are expected\
    \ to be cognizant of these\n   forms of attack while designing protocols.\n"
- title: 4.6.3. Avoiding Denial of Service
  contents:
  - "4.6.3. Avoiding Denial of Service\n   There are two common approaches to making\
    \ denial of service attacks\n   more difficult:\n"
- title: 4.6.3.1. Make your attacker do more work than you do
  contents:
  - "4.6.3.1. Make your attacker do more work than you do\n   If an attacker consumes\
    \ more of his resources than yours when\n   launching an attack, attackers with\
    \ fewer resources than you will be\n   unable to launch effective attacks.  One\
    \ common technique is to\n   require the attacker perform a time-intensive operation,\
    \ such as a\n   cryptographic operation.  Note that an attacker can still mount\
    \ a\n   denial of service attack if he can muster substantially sufficient\n \
    \  CPU power.  For instance, this technique would not stop the\n   distributed\
    \ attacks described in [TCPSYN].\n"
- title: 4.6.3.2. Make your attacker prove they can receive data from you
  contents:
  - "4.6.3.2. Make your attacker prove they can receive data from you\n   A blind\
    \ attack can be subverted by forcing the attacker to prove that\n   they can can\
    \ receive data from the victim.  A common technique is to\n   require that the\
    \ attacker reply using information that was gained\n   earlier in the message\
    \ exchange.  If this countermeasure is used, the\n   attacker must either use\
    \ his own address (making him easy to track)\n   or to forge an address which\
    \ will be routed back along a path that\n   traverses the host from which the\
    \ attack is being launched.\n   Hosts on small subnets are thus useless to the\
    \ attacker (at least in\n   the context of a spoofing attack) because the attack\
    \ can be traced\n   back to a subnet (which should be sufficient for locating\
    \ the\n   attacker) so that anti-attack measures can be put into place (for\n\
    \   instance, a boundary router can be configured to drop all traffic\n   from\
    \ that subnet).  A common technique is to require that the\n   attacker reply\
    \ using information that was gained earlier in the\n   message exchange.\n"
- title: '4.6.4. Example: TCP SYN Floods'
  contents:
  - "4.6.4. Example: TCP SYN Floods\n   TCP/IP is vulnerable to SYN flood attacks\
    \ (which are described in\n   section 3.3.2) because of the design of the 3-way\
    \ handshake.  First,\n   an attacker can force a victim to consume significant\
    \ resources (in\n   this case, memory) by sending a single packet.  Second, because\
    \ the\n   attacker can perform this action without ever having received data\n\
    \   from the victim, the attack can be performed anonymously (and\n   therefore\
    \ using a large number of forged source addresses).\n"
- title: '4.6.5. Example: Photuris'
  contents:
  - "4.6.5. Example: Photuris\n   [PHOTURIS] specifies an anti-clogging mechanism\
    \ that prevents attacks\n   on Photuris that resemble the SYN flood attack.  Photuris\
    \ employs a\n   time-variant secret to generate a \"cookie\" which is returned\
    \ to the\n   attacker.  This cookie must be returned in subsequent messages for\n\
    \   the exchange to progress.  The interesting feature is that this\n   cookie\
    \ can be regenerated by the victim later in the exchange, and\n   thus no state\
    \ need be retained by the victim until after the attacker\n   has proven that\
    \ he can receive packets from the victim.\n"
- title: 4.7. Object vs. Channel Security
  contents:
  - "4.7. Object vs. Channel Security\n   It's useful to make the conceptual distinction\
    \ between object\n   security and channel security.  Object security refers to\
    \ security\n   measures which apply to entire data objects.  Channel security\n\
    \   measures provide a secure channel over which objects may be carried\n   transparently\
    \ but the channel has no special knowledge about object\n   boundaries.\n   Consider\
    \ the case of an email message.  When it's carried over an\n   IPSEC or TLS secured\
    \ connection, the message is protected during\n   transmission.  However, it is\
    \ unprotected in the receiver's mailbox,\n   and in intermediate spool files along\
    \ the way.  Moreover, since mail\n   servers generally run as a daemon, not a\
    \ user, authentication of\n   messages generally merely means authentication of\
    \ the daemon not the\n   user.  Finally, since mail transport is hop-by-hop, even\
    \ if the user\n   authenticates to the first hop relay the authentication can't\
    \ be\n   safely verified by the receiver.\n   By contrast, when an email message\
    \ is protected with S/MIME or\n   OpenPGP, the entire message is encrypted and\
    \ integrity protected\n   until it is examined and decrypted by the recipient.\
    \  It also\n   provides strong authentication of the actual sender, as opposed\
    \ to\n   the machine the message came from.  This is object security.\n   Moreover,\
    \ the receiver can prove the signed message's authenticity to\n   a third party.\n\
    \   Note that the difference between object and channel security is a\n   matter\
    \ of perspective.  Object security at one layer of the protocol\n   stack often\
    \ looks like channel security at the next layer up.  So,\n   from the perspective\
    \ of the IP layer, each packet looks like an\n   individually secured object.\
    \  But from the perspective of a web\n   client, IPSEC just provides a secure\
    \ channel.\n   The distinction isn't always clear-cut.  For example, S-HTTP provides\n\
    \   object level security for a single HTTP transaction, but a web page\n   typically\
    \ consists of multiple HTTP transactions (the base page and\n   numerous inline\
    \ images).  Thus, from the perspective of the total web\n   page, this looks rather\
    \ more like channel security.  Object security\n   for a web page would consist\
    \ of security for the transitive closure\n   of the page and all its embedded\
    \ content as a single unit.\n"
- title: 4.8. Firewalls and Network Topology
  contents:
  - "4.8. Firewalls and Network Topology\n   It's common security practice in modern\
    \ networks to partition the\n   network into external and internal networks using\
    \ a firewall.  The\n   internal network is then assumed to be secure and only\
    \ limited\n   security measures are used there.  The internal portion of such\
    \ a\n   network is often called a WALLED GARDEN.\n   Internet protocol designers\
    \ cannot safely assume that their protocols\n   will be deployed in such an environment,\
    \ for three reasons.  First,\n   protocols which were originally designed to be\
    \ deployed in closed\n   environments often are later deployed on the Internet,\
    \ thus creating\n   serious vulnerabilities.\n   Second, networks which appear\
    \ to be topologically disconnected may\n   not be.  One reason may be that the\
    \ network has been reconfigured to\n   allow access by the outside world.  Moreover,\
    \ firewalls are\n   increasingly passing generic application layer protocols such\
    \ as\n   [SOAP] or [HTTP].  Network protocols which are based on these generic\n\
    \   protocols cannot in general assume that a firewall will protect them.\n  \
    \ Finally, one of the most serious security threats to systems is from\n   insiders,\
    \ not outsiders.  Since insiders by definition have access to\n   the internal\
    \ network, topological protections such as firewalls will\n   not protect them.\n"
- title: 5. Writing Security Considerations Sections
  contents:
  - "5. Writing Security Considerations Sections\n   While it is not a requirement\
    \ that any given protocol or system be\n   immune to all forms of attack, it is\
    \ still necessary for authors to\n   consider as many forms as possible.  Part\
    \ of the purpose of the\n   Security Considerations section is to explain what\
    \ attacks are out of\n   scope and what countermeasures can be applied to defend\
    \ against them.\n   In\n   There should be a clear description of the kinds of\
    \ threats on the\n   described protocol or technology.  This should be approached\
    \ as an\n   effort to perform \"due diligence\" in describing all known or\n \
    \  foreseeable risks and threats to potential implementers and users.\n   Authors\
    \ MUST describe\n      1.   which attacks are out of scope (and why!)\n      2.\
    \   which attacks are in-scope\n      2.1  and the protocol is susceptible to\n\
    \      2.2  and the protocol protects against\n   At least the following forms\
    \ of attack MUST be considered:\n   eavesdropping, replay, message insertion,\
    \ deletion, modification, and\n   man-in-the-middle.  Potential denial of service\
    \ attacks MUST be\n   identified as well.  If the protocol incorporates cryptographic\n\
    \   protection mechanisms, it should be clearly indicated which portions\n   of\
    \ the data are protected and what the protections are (i.e.,\n   integrity only,\
    \ confidentiality, and/or endpoint authentication,\n   etc.).  Some indication\
    \ should also be given to what sorts of attacks\n   the cryptographic protection\
    \ is susceptible.  Data which should be\n   held secret (keying material, random\
    \ seeds, etc.) should be clearly\n   labeled.\n   If the technology involves authentication,\
    \ particularly user-host\n   authentication, the security of the authentication\
    \ method MUST be\n   clearly specified.  That is, authors MUST document the assumptions\n\
    \   that the security of this authentication method is predicated upon.\n   For\
    \ instance, in the case of the UNIX username/password login method,\n   a statement\
    \ to the effect of:\n      Authentication in the system is secure only to the\
    \ extent that it\n      is difficult to guess or obtain a ASCII password that\
    \ is a maximum\n      of 8 characters long.  These passwords can be obtained by\
    \ sniffing\n      telnet sessions or by running the 'crack' program using the\n\
    \      contents of the /etc/passwd file.  Attempts to protect against\n      on-line\
    \ password guessing by (1) disconnecting after several\n      unsuccessful login\
    \ attempts and (2) waiting between successive\n      password prompts is effective\
    \ only to the extent that attackers\n      are impatient.\n      Because the /etc/passwd\
    \ file maps usernames to user ids, groups,\n      etc. it must be world readable.\
    \  In order to permit this usage but\n      make running crack more difficult,\
    \ the file is often split into\n      /etc/passwd and a 'shadow' password file.\
    \  The shadow file is not\n      world readable and contains the encrypted password.\
    \  The regular\n      /etc/passwd file contains a dummy password in its place.\n\
    \   It is insufficient to simply state that one's protocol should be run\n   over\
    \ some lower layer security protocol.  If a system relies upon\n   lower layer\
    \ security services for security, the protections those\n   services are expected\
    \ to provide MUST be clearly specified.  In\n   addition, the resultant properties\
    \ of the combined system need to be\n   specified.\n   Note: In general, the IESG\
    \ will not approve standards track protocols\n   which do not provide for strong\
    \ authentication, either internal to\n   the protocol or through tight binding\
    \ to a lower layer security\n   protocol.\n   The threat environment addressed\
    \ by the Security Considerations\n   section MUST at a minimum include deployment\
    \ across the global\n   Internet across multiple administrative boundaries without\
    \ assuming\n   that firewalls are in place, even if only to provide justification\n\
    \   for why such consideration is out of scope for the protocol.  It is\n   not\
    \ acceptable to only discuss threats applicable to LANs and ignore\n   the broader\
    \ threat environment.  All IETF standards-track protocols\n   are considered likely\
    \ to have deployment in the global Internet.  In\n   some cases, there might be\
    \ an Applicability Statement discouraging\n   use of a technology or protocol\
    \ in a particular environment.\n   Nonetheless, the security issues of broader\
    \ deployment should be\n   discussed in the document.\n   There should be a clear\
    \ description of the residual risk to the user\n   or operator of that protocol\
    \ after threat mitigation has been\n   deployed.  Such risks might arise from\
    \ compromise in a related\n   protocol (e.g., IPsec is useless if key management\
    \ has been\n   compromised), from incorrect implementation, compromise of the\n\
    \   security technology used for risk reduction (e.g., a cipher with a\n   40-bit\
    \ key), or there might be risks that are not addressed by the\n   protocol specification\
    \ (e.g., denial of service attacks on an\n   underlying link protocol).  Particular\
    \ care should be taken in\n   situations where the compromise of a single system\
    \ would compromise\n   an entire protocol.  For instance, in general protocol\
    \ designers\n   assume that end-systems are inviolate and don't worry about physical\n\
    \   attack.  However, in cases (such as a certificate authority) where\n   compromise\
    \ of a single system could lead to widespread compromises,\n   it is appropriate\
    \ to consider systems and physical security as well.\n   There should also be\
    \ some discussion of potential security risks\n   arising from potential misapplications\
    \ of the protocol or technology\n   described in the RFC.  This might be coupled\
    \ with an Applicability\n   Statement for that RFC.\n"
- title: 6. Examples
  contents:
  - "6. Examples\n   This section consists of some example security considerations\n\
    \   sections, intended to give the reader a flavor of what's intended by\n   this\
    \ document.\n   The first example is a 'retrospective' example, applying the criteria\n\
    \   of this document to an existing widely deployed protocol, SMTP.  The\n   second\
    \ example is a good security considerations section clipped from\n   a current\
    \ protocol.\n"
- title: 6.1. SMTP
  contents:
  - "6.1. SMTP\n   When RFC 821 was written, Security Considerations sections were\
    \ not\n   required in RFCs, and none is contained in that document.  [RFC 2821]\n\
    \   updated RFC 821 and added a detailed security considerations section.\n  \
    \ We reproduce here the Security Considerations section from that\n   document\
    \ (with new section numbers).  Our comments are indented and\n   prefaced with\
    \ 'NOTE:'.  We also add a number of new sections to cover\n   topics we consider\
    \ important.  Those sections are marked with [NEW]\n   in the section header.\n"
- title: 6.1.1. Security Considerations
  contents:
  - '6.1.1. Security Considerations

    '
- title: 6.1.1.1. Mail Security and Spoofing
  contents:
  - "6.1.1.1. Mail Security and Spoofing\n   SMTP mail is inherently insecure in that\
    \ it is feasible for even\n   fairly casual users to negotiate directly with receiving\
    \ and relaying\n   SMTP servers and create messages that will trick a naive recipient\n\
    \   into believing that they came from somewhere else.  Constructing such\n  \
    \ a message so that the \"spoofed\" behavior cannot be detected by an\n   expert\
    \ is somewhat more difficult, but not sufficiently so as to be a\n   deterrent\
    \ to someone who is determined and knowledgeable.\n   Consequently, as knowledge\
    \ of Internet mail increases, so does the\n   knowledge that SMTP mail inherently\
    \ cannot be authenticated, or\n   integrity checks provided, at the transport\
    \ level.  Real mail\n   security lies only in end-to-end methods involving the\
    \ message\n   bodies, such as those which use digital signatures (see [14] and,\n\
    \   e.g., PGP [4] or S/MIME [31]).\n      NOTE: One bad approach to sender authentication\
    \ is [IDENT] in\n      which the receiving mail server contacts the alleged sender\
    \ and\n      asks for the username of the sender.  This is a bad idea for a\n\
    \      number of reasons, including but not limited to relaying, TCP\n      connection\
    \ hijacking, and simple lying by the origin server.\n      Aside from the fact\
    \ that IDENT is of low security value, use of\n      IDENT by receiving sites\
    \ can lead to operational problems.  Many\n      sending sites blackhole IDENT\
    \ requests, thus causing mail to be\n      held until the receiving server's IDENT\
    \ request times out.\n   Various protocol extensions and configuration options\
    \ that provide\n   authentication at the transport level (e.g., from an SMTP client\
    \ to\n   an SMTP server) improve somewhat on the traditional situation\n   described\
    \ above.  However, unless they are accompanied by careful\n   handoffs of responsibility\
    \ in a carefully-designed trust environment,\n   they remain inherently weaker\
    \ than end-to-end mechanisms which use\n   digitally signed messages rather than\
    \ depending on the integrity of\n   the transport system.\n   Efforts to make\
    \ it more difficult for users to set envelope return\n   path and header \"From\"\
    \ fields to point to valid addresses other than\n   their own are largely misguided:\
    \ they frustrate legitimate\n   applications in which mail is sent by one user\
    \ on behalf of another\n   or in which error (or normal) replies should be directed\
    \ to a special\n   address.  (Systems that provide convenient ways for users to\
    \ alter\n   these fields on a per-message basis should attempt to establish a\n\
    \   primary and permanent mailbox address for the user so that Sender\n   fields\
    \ within the message data can be generated sensibly.)\n   This specification does\
    \ not further address the authentication issues\n   associated with SMTP other\
    \ than to advocate that useful functionality\n   not be disabled in the hope of\
    \ providing some small margin of\n   protection against an ignorant user who is\
    \ trying to fake mail.\n      NOTE: We have added additional material on communications\
    \ security\n      and SMTP in Section 6.1.2 In a final specification, the above\
    \ text\n      would be edited somewhat to reflect that fact.\n"
- title: 6.1.1.2. Blind Copies
  contents:
  - "6.1.1.2. Blind Copies\n   Addresses that do not appear in the message headers\
    \ may appear in the\n   RCPT commands to an SMTP server for a number of reasons.\
    \  The two\n   most common involve the use of a mailing address as a \"list exploder\"\
    \n   (a single address that resolves into multiple addresses) and the\n   appearance\
    \ of \"blind copies\".  Especially when more than one RCPT\n   command is present,\
    \ and in order to avoid defeating some of the\n   purpose of these mechanisms,\
    \ SMTP clients and servers SHOULD NOT copy\n   the full set of RCPT command arguments\
    \ into the headers, either as\n   part of trace headers or as informational or\
    \ private-extension\n   headers.  Since this rule is often violated in practice,\
    \ and cannot\n   be enforced, sending SMTP systems that are aware of \"bcc\" use\
    \ MAY\n   find it helpful to send each blind copy as a separate message\n   transaction\
    \ containing only a single RCPT command.\n   There is no inherent relationship\
    \ between either \"reverse\" (from\n   MAIL, SAML, etc., commands) or \"forward\"\
    \ (RCPT) addresses in the SMTP\n   transaction (\"envelope\") and the addresses\
    \ in the headers.  Receiving\n   systems SHOULD NOT attempt to deduce such relationships\
    \ and use them\n   to alter the headers of the message for delivery.  The popular\n\
    \   \"Apparently-to\" header is a violation of this principle as well as a\n \
    \  common source of unintended information disclosure and SHOULD NOT be\n   used.\n"
- title: 6.1.1.3. VRFY, EXPN, and Security
  contents:
  - "6.1.1.3. VRFY, EXPN, and Security\n   As discussed in section 3.5, individual\
    \ sites may want to disable\n   either or both of VRFY or EXPN for security reasons.\
    \  As a corollary\n   to the above, implementations that permit this MUST NOT\
    \ appear to\n   have verified addresses that are not, in fact, verified.  If a\
    \ site\n   disables these commands for security reasons, the SMTP server MUST\n\
    \   return a 252 response, rather than a code that could be confused with\n  \
    \ successful or unsuccessful verification.\n   Returning a 250 reply code with\
    \ the address listed in the VRFY\n   command after having checked it only for\
    \ syntax violates this rule.\n   Of course, an implementation that \"supports\"\
    \ VRFY by always returning\n   550 whether or not the address is valid is equally\
    \ not in\n   conformance.\n   Within the last few years, the contents of mailing\
    \ lists have become\n   popular as an address information source for so-called\
    \ \"spammers.\"\n   The use of EXPN to \"harvest\" addresses has increased as\
    \ list\n   administrators have installed protections against inappropriate uses\n\
    \   of the lists themselves.  Implementations SHOULD still provide\n   support\
    \ for EXPN, but sites SHOULD carefully evaluate the tradeoffs.\n   As authentication\
    \ mechanisms are introduced into SMTP, some sites may\n   choose to make EXPN\
    \ available only to authenticated requesters.\n      NOTE: It's not clear that\
    \ disabling VRFY adds much protection,\n      since it's often possible to discover\
    \ whether an address is valid\n      using RCPT TO.\n"
- title: 6.1.1.4. Information Disclosure in Announcements
  contents:
  - "6.1.1.4. Information Disclosure in Announcements\n   There has been an ongoing\
    \ debate about the tradeoffs between the\n   debugging advantages of announcing\
    \ server type and version (and,\n   sometimes, even server domain name) in the\
    \ greeting response or in\n   response to the HELP command and the disadvantages\
    \ of exposing\n   information that might be useful in a potential hostile attack.\
    \  The\n   utility of the debugging information is beyond doubt.  Those who\n\
    \   argue for making it available point out that it is far better to\n   actually\
    \ secure an SMTP server rather than hope that trying to\n   conceal known vulnerabilities\
    \ by hiding the server's precise identity\n   will provide more protection.  Sites\
    \ are encouraged to evaluate the\n   tradeoff with that issue in mind; implementations\
    \ are strongly\n   encouraged to minimally provide for making type and version\n\
    \   information available in some way to other network hosts.\n"
- title: 6.1.1.5. Information Disclosure in Trace Fields
  contents:
  - "6.1.1.5. Information Disclosure in Trace Fields\n   In some circumstances, such\
    \ as when mail originates from within a LAN\n   whose hosts are not directly on\
    \ the public Internet, trace\n   (\"Received\") fields produced in conformance\
    \ with this specification\n   may disclose host names and similar information\
    \ that would not\n   normally be available.  This ordinarily does not pose a problem,\
    \ but\n   sites with special concerns about name disclosure should be aware of\n\
    \   it.  Also, the optional FOR clause should be supplied with caution or\n  \
    \ not at all when multiple recipients are involved lest it\n   inadvertently disclose\
    \ the identities of \"blind copy\" recipients to\n   others.\n"
- title: 6.1.1.6. Information Disclosure in Message Forwarding
  contents:
  - "6.1.1.6. Information Disclosure in Message Forwarding\n   As discussed in section\
    \ 3.4, use of the 251 or 551 reply codes to\n   identify the replacement address\
    \ associated with a mailbox may\n   inadvertently disclose sensitive information.\
    \  Sites that are\n   concerned about those issues should ensure that they select\
    \ and\n   configure servers appropriately.\n"
- title: 6.1.1.7. Scope of Operation of SMTP Servers
  contents:
  - "6.1.1.7. Scope of Operation of SMTP Servers\n   It is a well-established principle\
    \ that an SMTP server may refuse to\n   accept mail for any operational or technical\
    \ reason that makes sense\n   to the site providing the server.  However, cooperation\
    \ among sites\n   and installations makes the Internet possible.  If sites take\n\
    \   excessive advantage of the right to reject traffic, the ubiquity of\n   email\
    \ availability (one of the strengths of the Internet) will be\n   threatened;\
    \ considerable care should be taken and balance maintained\n   if a site decides\
    \ to be selective about the traffic it will accept\n   and process.\n   In recent\
    \ years, use of the relay function through arbitrary sites\n   has been used as\
    \ part of hostile efforts to hide the actual origins\n   of mail.  Some sites\
    \ have decided to limit the use of the relay\n   function to known or identifiable\
    \ sources, and implementations SHOULD\n   provide the capability to perform this\
    \ type of filtering.  When mail\n   is rejected for these or other policy reasons,\
    \ a 550 code SHOULD be\n   used in response to EHLO, MAIL, or RCPT as appropriate.\n"
- title: 6.1.1.8. Inappropriate Usage [NEW]
  contents:
  - "6.1.1.8. Inappropriate Usage [NEW]\n   SMTP itself provides no protection is\
    \ provided against unsolicited\n   commercial mass e-mail (aka spam).  It is extremely\
    \ difficult to tell\n   a priori whether a given message is spam or not.  From\
    \ a protocol\n   perspective, spam is indistinguishable from other e-mail -- the\n\
    \   distinction is almost entirely social and often quite subtle.  (For\n   instance,\
    \ is a message from a merchant from whom you've purchased\n   items before advertising\
    \ similar items spam?) SMTP spam-suppression\n   mechanisms are generally limited\
    \ to identifying known spam senders\n   and either refusing to service them or\
    \ target them for\n   punishment/disconnection.  [RFC-2505] provides extensive\
    \ guidance on\n   making SMTP servers spam-resistant.  We provide a brief discussion\
    \ of\n   the topic here.\n   The primary tool for refusal to service spammers\
    \ is the blacklist.\n   Some authority such as [MAPS] collects and publishes a\
    \ list of known\n   spammers.  Individual SMTP servers then block the blacklisted\n\
    \   offenders (generally by IP address).\n   In order to avoid being blacklisted\
    \ or otherwise identified, spammers\n   often attempt to obscure their identity,\
    \ either simply by sending a\n   false SMTP identity or by forwarding their mail\
    \ through an Open Relay\n   -- an SMTP server which will perform mail relaying\
    \ for any sender.\n   As a consequence, there are now blacklists [ORBS] of open\
    \ relays as\n   well.\n"
- title: 6.1.1.8.1. Closed Relaying [NEW]
  contents:
  - "6.1.1.8.1. Closed Relaying [NEW]\n   To avoid being used for spam forwarding,\
    \ many SMTP servers operate as\n   closed relays, providing relaying service only\
    \ for clients who they\n   can identify.  Such relays should generally insist\
    \ that senders\n   advertise a sending address consistent with their known identity.\
    \  If\n   the relay is providing service for an identifiable network (such as\
    \ a\n   corporate network or an ISP's network) then it is sufficient to block\n\
    \   all other IP addresses).  In other cases, explicit authentication\n   must\
    \ be used.  The two standard choices for this are TLS [STARTTLS]\n   and SASL\
    \ [SASLSMTP].\n"
- title: 6.1.1.8.2. Endpoints [NEW]
  contents:
  - "6.1.1.8.2. Endpoints [NEW]\n   Realistically, SMTP endpoints cannot refuse to\
    \ deny service to\n   unauthenticated senders.  Since the vast majority of senders\
    \ are\n   unauthenticated, this would break Internet mail interoperability.\n\
    \   The exception to this is when the endpoint server should only be\n   receiving\
    \ mail from some other server which can itself receive\n   unauthenticated messages.\
    \  For instance, a company might operate a\n   public gateway but configure its\
    \ internal servers to only talk to the\n   gateway.\n"
- title: 6.1.2. Communications security issues [NEW]
  contents:
  - "6.1.2. Communications security issues [NEW]\n   SMTP itself provides no communications\
    \ security, and therefore a\n   large number of attacks are possible.  A passive\
    \ attack is sufficient\n   to recover the text of messages transmitted with SMTP.\
    \  No endpoint\n   authentication is provided by the protocol.  Sender spoofing\
    \ is\n   trivial, and therefore forging email messages is trivial.  Some\n   implementations\
    \ do add header lines with hostnames derived through\n   reverse name resolution\
    \ (which is only secure to the extent that it\n   is difficult to spoof DNS --\
    \ not very), although these header lines\n   are normally not displayed to users.\
    \  Receiver spoofing is also\n   fairly straight-forward, either using TCP connection\
    \ hijacking or DNS\n   spoofing.  Moreover, since email messages often pass through\
    \ SMTP\n   gateways, all intermediate gateways must be trusted, a condition\n\
    \   nearly impossible on the global Internet.\n   Several approaches are available\
    \ for alleviating these threats.  In\n   order of increasingly high level in the\
    \ protocol stack, we have:\n      SMTP over IPSEC\n      SMTP/TLS\n      S/MIME\
    \ and PGP/MIME\n"
- title: 6.1.2.1. SMTP over IPSEC [NEW]
  contents:
  - "6.1.2.1. SMTP over IPSEC [NEW]\n   An SMTP connection run over IPSEC can provide\
    \ confidentiality for the\n   message between the sender and the first hop SMTP\
    \ gateway, or between\n   any pair of connected SMTP gateways.  That is to say,\
    \ it provides\n   channel security for the SMTP connections.  In a situation where\
    \ the\n   message goes directly from the client to the receiver's gateway, this\n\
    \   may provide substantial security (though the receiver must still\n   trust\
    \ the gateway).  Protection is provided against replay attacks,\n   since the\
    \ data itself is protected and the packets cannot be\n   replayed.\n   Endpoint\
    \ identification is a problem, however, unless the receiver's\n   address can\
    \ be directly cryptographically authenticated.  Sender\n   identification is not\
    \ generally available, since generally only the\n   sender's machine is authenticated,\
    \ not the sender himself.\n   Furthermore, the identity of the sender simply appears\
    \ in the From\n   header of the message, so it is easily spoofable by the sender.\n\
    \   Finally, unless the security policy is set extremely strictly, there\n   is\
    \ also an active downgrade to cleartext attack.\n   Another problem with IPsec\
    \ as a security solution for SMTP is the\n   lack of a standard IPsec API.  In\
    \ order to take advantage of IPsec,\n   applications in general need to be able\
    \ to instruct the IPsec\n   implementation about their security policies and discover\
    \ what\n   protection has been applied to their connections.  Without a standard\n\
    \   API this is very difficult to do portably.\n   Implementors of SMTP servers\
    \ or SMTP administrators MUST NOT assume\n   that IPsec will be available unless\
    \ they have reason to believe that\n   it will be (such as the existence of preexisting\
    \ association between\n   two machines).  However, it may be a reasonable procedure\
    \ to attempt\n   to create an IPsec association opportunistically to a peer server\n\
    \   when mail is delivered.  Note that in cases where IPsec is used to\n   provide\
    \ a VPN tunnel between two sites, this is of substantial\n   security value, particularly\
    \ to the extent that confidentiality is\n   provided, subject to the caveats mentioned\
    \ above.  Also see\n   [USEIPSEC] for general guidance on the applicability of\
    \ IPsec.\n"
- title: 6.1.2.2. SMTP/TLS [NEW]
  contents:
  - "6.1.2.2. SMTP/TLS [NEW]\n   SMTP can be combined with TLS as described in [STARTTLS].\
    \  This\n   provides similar protection to that provided when using IPSEC.  Since\n\
    \   TLS certificates typically contain the server's host name, recipient\n   authentication\
    \ may be slightly more obvious, but is still susceptible\n   to DNS spoofing attacks.\
    \  Notably, common implementations of TLS\n   contain a US exportable (and hence\
    \ low security) mode.  Applications\n   desiring high security should ensure that\
    \ this mode is disabled.\n   Protection is provided against replay attacks, since\
    \ the data itself\n   is protected and the packets cannot be replayed.  [Note:\
    \  The\n   Security Considerations section of the SMTP over TLS document is\n\
    \   quite good and bears reading as an example of how to do things.]\n"
- title: 6.1.2.3. S/MIME and PGP/MIME [NEW]
  contents:
  - "6.1.2.3. S/MIME and PGP/MIME [NEW]\n   S/MIME and PGP/MIME are both message oriented\
    \ security protocols.\n   They provide object security for individual messages.\
    \  With various\n   settings, sender and recipient authentication and confidentiality\
    \ may\n   be provided.  More importantly, the identification is not of the\n \
    \  sending and receiving machines, but rather of the sender and\n   recipient\
    \ themselves.  (Or, at least, of cryptographic keys\n   corresponding to the sender\
    \ and recipient.)  Consequently, end-to-end\n   security may be obtained.  Note,\
    \ however, that no protection is\n   provided against replay attacks.  Note also\
    \ that S/MIME and PGP/MIME\n   generally provide identifying marks for both sender\
    \ and receiver.\n   Thus even when confidentiality is provided, traffic analysis\
    \ is still\n   possible.\n"
- title: 6.1.3. Denial of Service [NEW]
  contents:
  - "6.1.3. Denial of Service [NEW]\n   None of these security measures provides any\
    \ real protection against\n   denial of service.  SMTP connections can easily\
    \ be used to tie up\n   system resources in a number of ways, including excessive\
    \ port\n   consumption, excessive disk usage (email is typically delivered to\n\
    \   disk files), and excessive memory consumption (sendmail, for\n   instance,\
    \ is fairly large, and typically forks a new process to deal\n   with each message.)\n\
    \   If transport- or application-layer security is used for SMTP\n   connections,\
    \ it is possible to mount a variety of attacks on\n   individual connections using\
    \ forged RSTs or other kinds of packet\n   injection.\n"
- title: 6.2. VRRP
  contents:
  - "6.2. VRRP\n   The second example is from VRRP, the Virtual Router Redundance\n\
    \   Protocol ([VRRP]).  We reproduce here the Security Considerations\n   section\
    \ from that document (with new section numbers).  Our comments\n   are indented\
    \ and prefaced with 'NOTE:'.\n"
- title: 6.2.1. Security Considerations
  contents:
  - "6.2.1. Security Considerations\n   VRRP is designed for a range of internetworking\
    \ environments that may\n   employ different security policies.  The protocol\
    \ includes several\n   authentication methods ranging from no authentication,\
    \ simple clear\n   text passwords, and strong authentication using IP Authentication\n\
    \   with MD5 HMAC.  The details on each approach including possible\n   attacks\
    \ and recommended environments follows.\n   Independent of any authentication\
    \ type VRRP includes a mechanism\n   (setting TTL=255, checking on receipt) that\
    \ protects against VRRP\n   packets being injected from another remote network.\
    \  This limits most\n   vulnerabilities to local attacks.\n      NOTE: The security\
    \ measures discussed in the following sections\n      only provide various kinds\
    \ of authentication.  No confidentiality\n      is provided at all.  This should\
    \ be explicitly described as\n      outside the scope.\n"
- title: 6.2.1.1. No Authentication
  contents:
  - "6.2.1.1. No Authentication\n   The use of this authentication type means that\
    \ VRRP protocol\n   exchanges are not authenticated.  This type of authentication\
    \ SHOULD\n   only be used in environments were there is minimal security risk\
    \ and\n   little chance for configuration errors (e.g., two VRRP routers on a\n\
    \   LAN).\n"
- title: 6.2.1.2. Simple Text Password
  contents:
  - "6.2.1.2. Simple Text Password\n   The use of this authentication type means that\
    \ VRRP protocol\n   exchanges are authenticated by a simple clear text password.\n\
    \   This type of authentication is useful to protect against accidental\n   misconfiguration\
    \ of routers on a LAN.  It protects against routers\n   inadvertently backing\
    \ up another router.  A new router must first be\n   configured with the correct\
    \ password before it can run VRRP with\n   another router.  This type of authentication\
    \ does not protect against\n   hostile attacks where the password can be learned\
    \ by a node snooping\n   VRRP packets on the LAN.  The Simple Text Authentication\
    \ combined\n   with the TTL check makes it difficult for a VRRP packet to be sent\n\
    \   from another LAN to disrupt VRRP operation.\n   This type of authentication\
    \ is RECOMMENDED when there is minimal risk\n   of nodes on a LAN actively disrupting\
    \ VRRP operation.  If this type\n   of authentication is used the user should\
    \ be aware that this clear\n   text password is sent frequently, and therefore\
    \ should not be the\n   same as any security significant password.\n      NOTE:\
    \ This section should be clearer.  The basic point is that no\n      authentication\
    \ and Simple Text are only useful for a very limited\n      threat model, namely\
    \ that none of the nodes on the local LAN are\n      hostile.  The TTL check prevents\
    \ hostile nodes off-LAN from posing\n      as valid nodes, but nothing stops hostile\
    \ nodes on-LAN from\n      impersonating authorized nodes.  This is not a particularly\n\
    \      realistic threat model in many situations.  In particular, it's\n     \
    \ extremely brittle: the compromise of any node the LAN allows\n      reconfiguration\
    \ of the VRRP nodes.\n"
- title: 6.2.1.3. IP Authentication Header
  contents:
  - "6.2.1.3. IP Authentication Header\n   The use of this authentication type means\
    \ the VRRP protocol exchanges\n   are authenticated using the mechanisms defined\
    \ by the IP\n   Authentication Header [AH] using [HMAC].  This provides strong\n\
    \   protection against configuration errors, replay attacks, and packet\n   corruption/modification.\n\
    \   This type of authentication is RECOMMENDED when there is limited\n   control\
    \ over the administration of nodes on a LAN.  While this type\n   of authentication\
    \ does protect the operation of VRRP, there are other\n   types of attacks that\
    \ may be employed on shared media links (e.g.,\n   generation of bogus ARP replies)\
    \ which are independent from VRRP and\n   are not protected.\n      NOTE: It's\
    \ a mistake to have AH be a RECOMMENDED in this context.\n      Since AH is the\
    \ only mechanism that protects VRRP against attack\n      from other nodes on\
    \ the same LAN, it should be a MUST for cases\n      where there are untrusted\
    \ nodes on the same network.  In any case,\n      AH should be a MUST implement.\n\
    \      NOTE: There's an important piece of security analysis that's only\n   \
    \   hinted at in this document, namely the cost/benefit tradeoff of\n      VRRP\
    \ authentication.\n   [The rest of this section is NEW material]\n   The threat\
    \ that VRRP authentication is intended to prevent is an\n   attacker arranging\
    \ to be the VRRP master.  This would be done by\n   joining the group (probably\
    \ multiple times), gagging the master and\n   then electing oneself master.  Such\
    \ a node could then direct traffic\n   in arbitrary undesirable ways.\n   However,\
    \ it is not necessary for an attacker to be the VRRP master to\n   do this.  An\
    \ attacker can do similar kinds of damage to the network\n   by forging ARP packets\
    \ or (on switched networks) fooling the switch\n   VRRP authentication offers\
    \ no real protection against these attacks.\n   Unfortunately, authentication\
    \ makes VRRP networks very brittle in the\n   face of misconfiguration.  Consider\
    \ what happens if two nodes are\n   configured with different passwords.  Each\
    \ will reject messages from\n   the other and therefore both will attempt to be\
    \ master.  This creates\n   substantial network instability.\n   This set of cost/benefit\
    \ tradeoffs suggests that VRRP authentication\n   is a bad idea, since the incremental\
    \ security benefit is marginal but\n   the incremental risk is high.  This judgment\
    \ should be revisited if\n   the current set of non-VRRP threats are removed.\n"
- title: 7. Acknowledgments
  contents:
  - "7. Acknowledgments\n   This document is heavily based on a note written by Ran\
    \ Atkinson in\n   1997.  That note was written after the IAB Security Workshop\
    \ held in\n   early 1997, based on input from everyone at that workshop.  Some\
    \ of\n   the specific text above was taken from Ran's original document, and\n\
    \   some of that text was taken from an email message written by Fred\n   Baker.\
    \  The other primary source for this document is specific\n   comments received\
    \ from Steve Bellovin.  Early review of this document\n   was done by Lisa Dusseault\
    \ and Mark Schertler.  Other useful comments\n   were received from Bill Fenner,\
    \ Ned Freed, Lawrence Greenfield, Steve\n   Kent, Allison Mankin and Kurt Zeilenga.\n"
- title: 8. Normative References
  contents:
  - "8. Normative References\n   [AH]       Kent, S. and R. Atkinson, \"IP Authentication\
    \ Header\", RFC\n              2402, November 1998.\n   [DNSSEC]   Eastlake, D.,\
    \ \"Domain Name System Security Extensions\",\n              RFC 2535, March 1999.\n\
    \   [ENCOPT]   Tso, T., \"Telnet Data Encryption Option\", RFC 2946,\n       \
    \       September, 2000.\n   [ESP]      Kent, S. and R. Atkinson, \"IP Encapsulating\
    \ Security\n              Payload (ESP)\", RFC 2406, November 1998.\n   [GSS]\
    \      Linn, J., \"Generic Security Services Application Program\n           \
    \   Interface Version 2, Update 1\", RFC 2743, January 2000.\n   [HTTP]     Fielding,\
    \ R., Gettys, J., Mogul, J., Frystyk, H.,\n              Masinter, L., Leach,\
    \ P. and T. Berners-Lee, \"HyperText\n              Transfer Protocol\", RFC 2616,\
    \ June 1999.\n   [HTTPTLS]  Rescorla, E., \"HTTP over TLS\", RFC 2818, May 2000.\n\
    \   [HMAC]     Madson, C. and R. Glenn, \"The Use of HMAC-MD5-96 within\n    \
    \          ESP and AH\", RFC 2403, November 1998.\n   KERBEROS]  Kohl, J. and\
    \ C. Neuman, \"The Kerberos Network\n              Authentication Service (V5)\"\
    , RFC 1510, September 1993.\n   [KEYWORDS] Bradner, S., \"Key words for use in\
    \ RFCs to Indicate\n              Requirement Levels\", BCP 14, RFC 2119, March\
    \ 1997.\n   [OTP]      Haller, N., Metz, C., Nesser, P. and M. Straw, \"A One-Time\n\
    \              Password System\", STD 61, RFC 2289, February 1998.\n   [PHOTURIS]\
    \ Karn, P. and W. Simpson, \"Photuris: Session-Key Management\n              Protocol\"\
    , RFC 2522, March 1999.\n   [PKIX]     Housley, R., Polk, W., Ford, W. and D.\
    \ Solo, \"Internet\n              X.509 \"Public Key Infrastructure Certificate\
    \ and\n              Certificate Restoration List (CRL) Profile\", RFC 3280,\n\
    \              April 2002.\n   [RFC-2223] Postel J. and J. Reynolds, \"Instructions\
    \ to RFC Authors\",\n              RFC 2223, October 1997.\n   [RFC-2505] Lindberg,\
    \ G., \"Anti-Spam Recommendations for SMTP MTAs\",\n              BCP 30, RFC\
    \ 2505, February 1999.\n   [RFC-2821] Klensin, J., \"Simple Mail Transfer Protocol\"\
    , RFC 2821,\n              April 2001.\n   [SASL]     Myers, J., \"Simple Authentication\
    \ and Security Layer\n              (SASL)\", RFC 2222, October 1997.\n   [SPKI]\
    \     Ellison, C., Frantz, B., Lampson, B., Rivest, R., Thomas,\n            \
    \  B. and T. Ylonen, \"SPKI Certificate Theory\",  RFC 2693,\n              September\
    \ 1999.\n   [SSH]      Ylonen, T., \"SSH - Secure Login Connections Over the\n\
    \              Internet\", 6th USENIX Security Symposium, p. 37-42, July\n   \
    \           1996.\n   [SASLSMTP] Myers, J., \"SMTP Service Extension for Authentication\"\
    ,\n              RFC 2554, March 1999.\n   [STARTTLS] Hoffman, P., \"SMTP Service\
    \ Extension for Secure SMTP over\n              Transport Layer Security\", RFC\
    \ 3207, February 2002.\n   [S-HTTP]   Rescorla, E. and A. Schiffman, \"The Secure\
    \ HyperText\n              Transfer Protocol\", RFC 2660, August 1999.\n   [S/MIME]\
    \   Ramsdell, B., Editor, \"S/MIME Version 3 Message\n              Specification\"\
    , RFC 2633, June 1999.\n   [TELNET]   Postel, J. and J. Reynolds, \"Telnet Protocol\n\
    \              Specification\", STD 8, RFC 854, May 1983.\n   [TLS]      Dierks,\
    \ T. and C. Allen, \"The TLS Protocol Version 1.0\",\n              RFC 2246,\
    \ January 1999.\n   [TLSEXT]   Blake-Wilson, S., Nystrom, M., Hopwood, D. and\
    \ J.\n              Mikkelsen, \"Transport Layer Security (TLS) Extensions\",\n\
    \              RFC 3546, May 2003.\n   [TCPSYN]   \"TCP SYN Flooding and IP Spoofing\
    \ Attacks\", CERT Advisory\n              CA-1996-21, 19 September 1996, CERT.\n\
    \              http://www.cert.org/advisories/CA-1996-21.html\n   [UPGRADE]  Khare,\
    \ R. and S. Lawrence, \"Upgrading to TLS Within\n              HTTP/1.1\", RFC\
    \ 2817, May 2000.\n   [URL]      Berners-Lee, T., Masinter, M. and M. McCahill,\
    \ \"Uniform\n              Resource Locators (URL)\", RFC 1738, December 1994.\n\
    \   [VRRP]     Knight, S., Weaver, D., Whipple, D., Hinden, R., Mitzel,\n    \
    \          D., Hunt, P., Higginson, P., Shand, M. and A. Lindemn,\n          \
    \    \"Virtual Router Redundancy Protocol\", RFC 2338, April\n              1998.\n"
- title: 9. Informative References
  contents:
  - "9. Informative References\n   [DDOS]     \"Denial-Of-Service Tools\" CERT Advisory\
    \ CA-1999-17, 28\n              December 1999, CERT http://www.cert.org/advisories/CA-\n\
    \              1999-17.html\n   [EKE]      Bellovin, S., Merritt, M., \"Encrypted\
    \ Key Exchange:\n              Password-based protocols secure against dictionary\n\
    \              attacks\", Proceedings of the IEEE Symposium on Research in\n \
    \             Security and Privacy, May 1992.\n   [IDENT]    St. Johns, M. and\
    \ M. Rose, \"Identification Protocol\", RFC\n              1414, February 1993.\n\
    \   [INTAUTH]  Haller, N. and R. Atkinson, \"On Internet Authentication\",\n \
    \             RFC 1704, October 1994.\n   [IPSPPROB] Bellovin, S. M., \"Problem\
    \ Areas for the IP Security\n              Protocols\", Proceedings of the Sixth\
    \ Usenix UNIX Security\n              Symposium, July 1996.\n   [KLEIN]    Klein,\
    \ D.V., \"Foiling the Cracker: A Survey of and\n              Improvements to\
    \ Password Security\",  1990.\n   [NNTP]     Kantor, B. and P. Lapsley, \"Network\
    \ News Transfer\n              Protocol\", RFC 977, February 1986.\n   [POP] \
    \     Myers, J. and M. Rose, \"Post Office Protocol - Version 3\",\n         \
    \     STD 53, RFC 1939, May 1996.\n   [SEQNUM]   Morris, R.T., \"A Weakness in\
    \ the 4.2 BSD UNIX TCP/IP\n              Software\", AT&T Bell Laboratories, CSTR\
    \ 117, 1985.\n   [SOAP]     Box, D., Ehnebuske, D., Kakivaya, G., Layman, A.,\n\
    \              Mendelsoh, N., Nielsen, H., Thatte, S., Winer, D., \"Simple\n \
    \             Object Access Protocol (SOAP) 1.1\", May 2000.\n   [SPEKE]    Jablon,\
    \ D., \"Strong Password-Only Authenticated Key\n              Exchange\", Computer\
    \ Communication Review, ACM SIGCOMM,\n              vol. 26, no. 5, pp. 5-26,\
    \ October 1996.\n   [SRP]      Wu T., \"The Secure Remote Password Protocol\"\
    , ISOC NDSS\n              Symposium, 1998.\n   [USEIPSEC] Bellovin, S., \"Guidelines\
    \ for Mandating the Use of IPsec\",\n              Work in Progress.\n   [WEP]\
    \      Borisov, N., Goldberg, I., Wagner, D., \"Intercepting\n              Mobile\
    \ Communications: The Insecurity of 802.11\",\n              http://www.isaac.cs.berkeley.edu/isaac/wep-draft.pdf\n"
- title: 10. Security Considerations
  contents:
  - "10. Security Considerations\n   This entire document is about security considerations.\n"
- title: Appendix A.
  contents:
  - "Appendix A.\n   IAB Members at the time of this writing\n   Harald Alvestrand\n\
    \   Ran Atkinson\n   Rob Austein\n   Fred Baker\n   Leslie Daigle\n   Steve Deering\n\
    \   Sally Floyd\n   Ted Hardie\n   Geoff Huston\n   Charlie Kaufman\n   James\
    \ Kempf\n   Eric Rescorla\n   Mike St. Johns\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Eric Rescorla\n   RTFM, Inc.\n   2439 Alvin Drive\n  \
    \ Mountain View, CA 94043\n   Phone: (650)-320-8549\n   EMail: ekr@rtfm.com\n\
    \   Brian Korver\n   Xythos Software, Inc.\n   77 Maiden Lane, 6th Floor\n   San\
    \ Francisco, CA, 94108\n   Phone: (415)-248-3800\n   EMail: briank@xythos.com\n\
    \   Internet Architecture Board\n   IAB\n   EMail: iab@iab.org\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2003).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
