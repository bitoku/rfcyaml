- title: __initial_text__
  contents:
  - '                         Site Security Handbook

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This handbook is the product of the Site Security Policy\
    \ Handbook\n   Working Group (SSPHWG), a combined effort of the Security Area\
    \ and\n   User Services Area of the Internet Engineering Task Force (IETF).\n\
    \   This FYI RFC provides information for the Internet community.  It\n   does\
    \ not specify an Internet standard.  Distribution of this memo is\n   unlimited.\n"
- title: Contributing Authors
  contents:
  - "Contributing Authors\n   The following are the authors of the Site Security Handbook.\
    \  Without\n   their dedication, this handbook would not have been possible.\n\
    \   Dave Curry (Purdue University), Sean Kirkpatrick (Unisys), Tom\n   Longstaff\
    \ (LLNL), Greg Hollingsworth (Johns Hopkins University),\n   Jeffrey Carpenter\
    \ (University of Pittsburgh), Barbara Fraser (CERT),\n   Fred Ostapik (SRI NISC),\
    \ Allen Sturtevant (LLNL), Dan Long (BBN), Jim\n   Duncan (Pennsylvania State\
    \ University), and Frank Byrum (DEC).\n"
- title: Editors' Note
  contents:
  - "Editors' Note\n   This FYI RFC is a first attempt at providing Internet users\
    \ guidance\n   on how to deal with security issues in the Internet.  As such,\
    \ this\n   document is necessarily incomplete.  There are some clear shortfalls;\n\
    \   for example, this document focuses mostly on resources available in\n   the\
    \ United States.  In the spirit of the Internet's \"Request for\n   Comments\"\
    \ series of notes, we encourage feedback from users of this\n   handbook.  In\
    \ particular, those who utilize this document to craft\n   their own policies\
    \ and procedures.\n   This handbook is meant to be a starting place for further\
    \ research\n   and should be viewed as a useful resource, but not the final\n\
    \   authority.  Different organizations and jurisdictions will have\n   different\
    \ resources and rules.  Talk to your local organizations,\n   consult an informed\
    \ lawyer, or consult with local and national law\n   enforcement.  These groups\
    \ can help fill in the gaps that this\n   document cannot hope to cover.\n   Finally,\
    \ we intend for this FYI RFC to grow and evolve.  Please send\n   comments and\
    \ suggestions to: ssphwg@cert.sei.cmu.edu.\n"
- title: Table of Contents
  contents:
  - 'Table of Contents

    '
- title: 1.  Introduction.....................................................  3
  contents:
  - '1.  Introduction.....................................................  3

    '
- title: 1.1  Purpose of this Work............................................  3
  contents:
  - '1.1  Purpose of this Work............................................  3

    '
- title: 1.2  Audience........................................................  3
  contents:
  - '1.2  Audience........................................................  3

    '
- title: 1.3  Definitions.....................................................  4
  contents:
  - '1.3  Definitions.....................................................  4

    '
- title: 1.4  Related Work....................................................  4
  contents:
  - '1.4  Related Work....................................................  4

    '
- title: 1.5  Scope...........................................................  4
  contents:
  - '1.5  Scope...........................................................  4

    '
- title: 1.6  Why Do We Need Security Policies and Procedures?................  5
  contents:
  - '1.6  Why Do We Need Security Policies and Procedures?................  5

    '
- title: 1.7  Basic Approach..................................................  7
  contents:
  - '1.7  Basic Approach..................................................  7

    '
- title: 1.8  Organization of this Document...................................  7
  contents:
  - '1.8  Organization of this Document...................................  7

    '
- title: 2.  Establishing Official Site Policy on Computer Security...........  9
  contents:
  - '2.  Establishing Official Site Policy on Computer Security...........  9

    '
- title: 2.1  Brief Overview..................................................  9
  contents:
  - '2.1  Brief Overview..................................................  9

    '
- title: 2.2  Risk Assessment................................................. 10
  contents:
  - '2.2  Risk Assessment................................................. 10

    '
- title: 2.3  Policy Issues................................................... 13
  contents:
  - '2.3  Policy Issues................................................... 13

    '
- title: 2.4  What Happens When the Policy Is Violated........................ 19
  contents:
  - '2.4  What Happens When the Policy Is Violated........................ 19

    '
- title: 2.5  Locking In or Out............................................... 21
  contents:
  - '2.5  Locking In or Out............................................... 21

    '
- title: 2.6  Interpreting the Policy......................................... 23
  contents:
  - '2.6  Interpreting the Policy......................................... 23

    '
- title: 2.7  Publicizing the Policy.......................................... 23
  contents:
  - '2.7  Publicizing the Policy.......................................... 23

    '
- title: 3.  Establishing Procedures to Prevent Security Problems............. 24
  contents:
  - '3.  Establishing Procedures to Prevent Security Problems............. 24

    '
- title: 3.1  Security Policy Defines What Needs to be Protected.............. 24
  contents:
  - '3.1  Security Policy Defines What Needs to be Protected.............. 24

    '
- title: 3.2  Identifing Possible Problems.................................... 24
  contents:
  - '3.2  Identifing Possible Problems.................................... 24

    '
- title: 3.3  Choose Controls to Protect Assets in a Cost-Effective Way....... 26
  contents:
  - '3.3  Choose Controls to Protect Assets in a Cost-Effective Way....... 26

    '
- title: 3.4  Use Multiple Strategies to Protect Assets....................... 26
  contents:
  - '3.4  Use Multiple Strategies to Protect Assets....................... 26

    '
- title: 3.5  Physical Security............................................... 27
  contents:
  - '3.5  Physical Security............................................... 27

    '
- title: 3.6  Procedures to Recognize Unauthorized Activity................... 27
  contents:
  - '3.6  Procedures to Recognize Unauthorized Activity................... 27

    '
- title: 3.7  Define Actions to Take When Unauthorized Activity is Suspected.. 29
  contents:
  - '3.7  Define Actions to Take When Unauthorized Activity is Suspected.. 29

    '
- title: 3.8  Communicating Security Policy................................... 30
  contents:
  - '3.8  Communicating Security Policy................................... 30

    '
- title: 3.9  Resources to Prevent Security Breaches.......................... 34
  contents:
  - '3.9  Resources to Prevent Security Breaches.......................... 34

    '
- title: 4.  Types of Security Procedures..................................... 56
  contents:
  - '4.  Types of Security Procedures..................................... 56

    '
- title: 4.1  System Security Audits.......................................... 56
  contents:
  - '4.1  System Security Audits.......................................... 56

    '
- title: 4.2  Account Management Procedures................................... 57
  contents:
  - '4.2  Account Management Procedures................................... 57

    '
- title: 4.3  Password Management Procedures.................................. 57
  contents:
  - '4.3  Password Management Procedures.................................. 57

    '
- title: 4.4  Configuration Management Procedures............................. 60
  contents:
  - '4.4  Configuration Management Procedures............................. 60

    '
- title: 5.  Incident Handling................................................ 61
  contents:
  - '5.  Incident Handling................................................ 61

    '
- title: 5.1  Overview........................................................ 61
  contents:
  - '5.1  Overview........................................................ 61

    '
- title: 5.2  Evaluation...................................................... 65
  contents:
  - '5.2  Evaluation...................................................... 65

    '
- title: 5.3  Possible Types of Notification.................................. 67
  contents:
  - '5.3  Possible Types of Notification.................................. 67

    '
- title: 5.4  Response........................................................ 71
  contents:
  - '5.4  Response........................................................ 71

    '
- title: 5.5  Legal/Investigative............................................. 73
  contents:
  - '5.5  Legal/Investigative............................................. 73

    '
- title: 5.6  Documentation Logs.............................................. 77
  contents:
  - '5.6  Documentation Logs.............................................. 77

    '
- title: 6.  Establishing Post-Incident Procedures............................ 78
  contents:
  - '6.  Establishing Post-Incident Procedures............................ 78

    '
- title: 6.1  Overview........................................................ 78
  contents:
  - '6.1  Overview........................................................ 78

    '
- title: 6.2  Removing Vulnerabilities........................................ 78
  contents:
  - '6.2  Removing Vulnerabilities........................................ 78

    '
- title: 6.3  Capturing Lessons Learned....................................... 80
  contents:
  - '6.3  Capturing Lessons Learned....................................... 80

    '
- title: 6.4  Upgrading Policies and Procedures............................... 81
  contents:
  - '6.4  Upgrading Policies and Procedures............................... 81

    '
- title: 7.  References....................................................... 81
  contents:
  - '7.  References....................................................... 81

    '
- title: 8.  Annotated Bibliography........................................... 83
  contents:
  - '8.  Annotated Bibliography........................................... 83

    '
- title: 8.1  Computer Law.................................................... 84
  contents:
  - '8.1  Computer Law.................................................... 84

    '
- title: 8.2  Computer Security............................................... 85
  contents:
  - '8.2  Computer Security............................................... 85

    '
- title: 8.3  Ethics.......................................................... 91
  contents:
  - '8.3  Ethics.......................................................... 91

    '
- title: 8.4  The Internet Worm............................................... 93
  contents:
  - '8.4  The Internet Worm............................................... 93

    '
- title: 8.5  National Computer Security Center (NCSC)........................ 95
  contents:
  - '8.5  National Computer Security Center (NCSC)........................ 95

    '
- title: 8.6  Security Checklists............................................. 99
  contents:
  - '8.6  Security Checklists............................................. 99

    '
- title: 8.7  Additional Publications......................................... 99
  contents:
  - '8.7  Additional Publications......................................... 99

    '
- title: 9.  Acknlowledgements................................................101
  contents:
  - '9.  Acknlowledgements................................................101

    '
- title: 10.  Security Considerations.........................................101
  contents:
  - '10.  Security Considerations.........................................101

    '
- title: 11.  Authors' Addresses..............................................101
  contents:
  - '11.  Authors'' Addresses..............................................101

    '
- title: 1.  Introduction
  contents:
  - '1.  Introduction

    '
- title: 1.1  Purpose of this Work
  contents:
  - "1.1  Purpose of this Work\n   This handbook is a guide to setting computer security\
    \ policies and\n   procedures for sites that have systems on the Internet.  This\
    \ guide\n   lists issues and factors that a site must consider when setting their\n\
    \   own policies.  It makes some recommendations and gives discussions of\n  \
    \ relevant areas.\n   This guide is only a framework for setting security policies\
    \ and\n   procedures.  In order to have an effective set of policies and\n   procedures,\
    \ a site will have to make many decisions, gain agreement,\n   and then communicate\
    \ and implement the policies.\n"
- title: 1.2  Audience
  contents:
  - "1.2  Audience\n   The audience for this work are system administrators and decision\n\
    \   makers (who are more traditionally called \"administrators\" or \"middle\n\
    \   management\") at sites.  This document is not directed at programmers\n  \
    \ or those trying to create secure programs or systems.  The focus of\n   this\
    \ document is on the policies and procedures that need to be in\n   place to support\
    \ any technical security features that a site may be\n   implementing.\n   The\
    \ primary audience for this work are sites that are members of the\n   Internet\
    \ community.  However, this document should be useful to any\n   site that allows\
    \ communication with other sites.  As a general guide\n   to security policies,\
    \ this document may also be useful to sites with\n   isolated systems.\n"
- title: 1.3  Definitions
  contents:
  - "1.3  Definitions\n   For the purposes of this guide, a \"site\" is any organization\
    \ that\n   owns computers or network-related resources.  These resources may\n\
    \   include host computers that users use, routers, terminal servers,\n   PC's\
    \ or other devices that have access to the Internet.  A site may\n   be a end\
    \ user of Internet services or a service provider such as a\n   regional network.\
    \  However, most of the focus of this guide is on\n   those end users of Internet\
    \ services.\n   We assume that the site has the ability to set policies and\n\
    \   procedures for itself with the concurrence and support from those who\n  \
    \ actually own the resources.\n   The \"Internet\" is those set of networks and\
    \ machines that use the\n   TCP/IP protocol suite, connected through gateways,\
    \ and sharing a\n   common name and address spaces [1].\n   The term \"system\
    \ administrator\" is used to cover all those who are\n   responsible for the day-to-day\
    \ operation of resources.  This may be a\n   number of individuals or an organization.\n\
    \   The term \"decision maker\" refers to those people at a site who set or\n\
    \   approve policy.  These are often (but not always) the people who own\n   the\
    \ resources.\n"
- title: 1.4  Related Work
  contents:
  - "1.4  Related Work\n   The IETF Security Policy Working Group (SPWG) is working\
    \ on a set of\n   recommended security policy guidelines for the Internet [23].\
    \  These\n   guidelines may be adopted as policy by regional networks or owners\
    \ of\n   other resources.  This handbook should be a useful tool to help sites\n\
    \   implement those policies as desired or required.  However, even\n   implementing\
    \ the proposed policies isn't enough to secure a site.\n   The proposed Internet\
    \ policies deal only with network access\n   security.  It says nothing about\
    \ how sites should deal with local\n   security issues.\n"
- title: 1.5  Scope
  contents:
  - "1.5  Scope\n   This document covers issues about what a computer security policy\n\
    \   should contain, what kinds of procedures are need to enforce\n   security,\
    \ and some recommendations about how to deal with the\n   problem.  When developing\
    \ a security policy, close attention should\n   be made not only on the security\
    \ needs and requirements of the local\n   network, but also the security needs\
    \ and requirements of the other\n   interconnected networks.\n   This is not a\
    \ cookbook for computer security.  Each site has\n   different needs; the security\
    \ needs of a corporation might well be\n   different than the security needs of\
    \ an academic institution.  Any\n   security plan has to conform to the needs\
    \ and culture of the site.\n   This handbook does not cover details of how to\
    \ do risk assessment,\n   contingency planning, or physical security.  These things\
    \ are\n   essential in setting and implementing effective security policy, but\n\
    \   this document leaves treatment of those issues to other documents.\n   We\
    \ will try to provide some pointers in that direction.\n   This document also\
    \ doesn't talk about how to design or implement\n   secure systems or programs.\n"
- title: 1.6  Why Do We Need Security Policies and Procedures?
  contents:
  - "1.6  Why Do We Need Security Policies and Procedures?\n   For most sites, the\
    \ interest in computer security is proportional to\n   the perception of risk\
    \ and threats.\n   The world of computers has changed dramatically over the past\n\
    \   twenty-five years.  Twenty-five years ago, most computers were\n   centralized\
    \ and managed by data centers.  Computers were kept in\n   locked rooms and staffs\
    \ of people made sure they were carefully\n   managed and physically secured.\
    \  Links outside a site were unusual.\n   Computer security threats were rare,\
    \ and were basically concerned\n   with insiders: authorized users misusing accounts,\
    \ theft and\n   vandalism, and so forth.  These threats were well understood and\n\
    \   dealt with using standard techniques: computers behind locked doors,\n   and\
    \ accounting for all resources.\n   Computing in the 1990's is radically different.\
    \  Many systems are in\n   private offices and labs, often managed by individuals\
    \ or persons\n   employed outside a computer center.  Many systems are connected\
    \ into\n   the Internet, and from there around the world: the United States,\n\
    \   Europe, Asia, and Australia are all connected together.\n   Security threats\
    \ are different today.  The time honored advice says\n   \"don't write your password\
    \ down and put it in your desk\" lest someone\n   find it.  With world-wide Internet\
    \ connections, someone could get\n   into your system from the other side of the\
    \ world and steal your\n   password in the middle of the night when your building\
    \ is locked up.\n   Viruses and worms can be passed from machine to machine. \
    \ The\n   Internet allows the electronic equivalent of the thief who looks for\n\
    \   open windows and doors; now a person can check hundreds of machines\n   for\
    \ vulnerabilities in a few hours.\n   System administrators and decision makers\
    \ have to understand the\n   security threats that exist, what the risk and cost\
    \ of a problem\n   would be, and what kind of action they want to take (if any)\
    \ to\n   prevent and respond to security threats.\n   As an illustration of some\
    \ of the issues that need to be dealt with\n   in security problems, consider\
    \ the following scenarios (thanks to\n   Russell Brand [2, BRAND] for these):\n\
    \      - A system programmer gets a call reporting that a\n        major underground\
    \ cracker newsletter is being\n        distributed from the administrative machine\
    \ at his\n        center to five thousand sites in the US and\n        Western\
    \ Europe.\n        Eight weeks later, the authorities call to inform\n       \
    \ you the information in one of these newsletters\n        was used to disable\
    \ \"911\" in a major city for\n        five hours.\n      - A user calls in to\
    \ report that he can't login to his\n        account at 3 o'clock in the morning\
    \ on a Saturday.  The\n        system staffer can't login either.  After rebooting\
    \ to\n        single user mode, he finds that password file is empty.\n      \
    \  By Monday morning, your staff determines that a number\n        of privileged\
    \ file transfers took place between this\n        machine and a local university.\n\
    \        Tuesday morning a copy of the deleted password file is\n        found\
    \ on the university machine along with password\n        files for a dozen other\
    \ machines.\n        A week later you find that your system initialization\n \
    \       files had been altered in a hostile fashion.\n      - You receive a call\
    \ saying that a breakin to a government\n        lab occurred from one of your\
    \ center's machines.  You\n        are requested to provide accounting files to\
    \ help\n        trackdown the attacker.\n        A week later you are given a\
    \ list of machines at your\n        site that have been broken into.\n       -\
    \ A reporter calls up asking about the breakin at your\n         center.  You\
    \ haven't heard of any such breakin.\n        Three days later, you learn that\
    \ there was a breakin.\n        The center director had his wife's name as a password.\n\
    \      - A change in system binaries is detected.\n        The day that it is\
    \ corrected, they again are changed.\n        This repeats itself for some weeks.\n\
    \      - If an intruder is found on your system, should you\n        leave the\
    \ system open to monitor the situation or should\n        you close down the holes\
    \ and open them up again later?\n      - If an intruder is using your site, should\
    \ you call law\n        enforcement?  Who makes that decision?  If law enforcement\
    \ asks\n        you to leave your site open, who makes that decision?\n      -\
    \ What steps should be taken if another site calls you and says\n        they\
    \ see activity coming from an account on your system?  What\n        if the account\
    \ is owned by a local manager?\n"
- title: 1.7  Basic Approach
  contents:
  - "1.7  Basic Approach\n   Setting security policies and procedures really means\
    \ developing a\n   plan for how to deal with computer security.  One way to approach\n\
    \   this task is suggested by Fites, et. al. [3, FITES]:\n      -  Look at what\
    \ you are trying to protect.\n      -  Look at what you need to protect it from.\n\
    \      -  Determine how likely the threats are.\n      -  Implement measures which\
    \ will protect your assets in a\n         cost-effective manner.\n      -  Review\
    \ the process continuously, and improve things every time\n         a weakness\
    \ is found.\n   This handbook will concentrate mostly on the last two steps, but\
    \ the\n   first three are critically important to making effective decisions\n\
    \   about security.  One old truism in security is that the cost of\n   protecting\
    \ yourself against a threat should be less than the cost\n   recovering if the\
    \ threat were to strike you.  Without reasonable\n   knowledge of what you are\
    \ protecting and what the likely threats are,\n   following this rule could be\
    \ difficult.\n"
- title: 1.8  Organization of this Document
  contents:
  - "1.8  Organization of this Document\n   This document is organized into seven\
    \ parts in addition to this\n   introduction.\n   The basic form of each section\
    \ is to discuss issues that a site might\n   want to consider in creating a computer\
    \ security policy and setting\n   procedures to implement that policy.  In some\
    \ cases, possible options\n   are discussed along with the some of the ramifications\
    \ of those\n   choices.  As far as possible, this document tries not to dictate\
    \ the\n   choices a site should make, since these depend on local\n   circumstances.\
    \  Some of the issues brought up may not apply to all\n   sites.  Nonetheless,\
    \ all sites should at least consider the issues\n   brought up here to ensure\
    \ that they do not miss some important area.\n   The overall flow of the document\
    \ is to discuss policy issues followed\n   by the issues that come up in creating\
    \ procedures to implement the\n   policies.\n   Section 2 discusses setting official\
    \ site policies for access to\n   computing resources.  It also goes into the\
    \ issue of what happens\n   when the policy is violated.  The policies will drive\
    \ the procedures\n   that need to be created, so decision makers will need to\
    \ make choices\n   about policies before many of the procedural issues in following\n\
    \   sections can be dealt with.  A key part of creating policies is doing\n  \
    \ some kind of risk assessment to decide what really needs to be\n   protected\
    \ and the level of resources that should be applied to\n   protect them.\n   Once\
    \ policies are in place, procedures to prevent future security\n   problems should\
    \ be established.  Section 3 defines and suggests\n   actions to take when unauthorized\
    \ activity is suspected.  Resources\n   to prevent secruity breaches are also\
    \ discussed.\n   Section 4 discusses types of procedures to prevent security problems.\n\
    \   Prevention is a key to security; as an example, the Computer\n   Emergency\
    \ Response Team/Coordination Center (CERT/CC) at Carnegie-\n   Mellon University\
    \ (CMU) estimates that 80% or more of the problems\n   they see have to do with\
    \ poorly chosen passwords.\n   Section 5 discusses incident handling: what kinds\
    \ of issues does a\n   site face when someone violates the security policy.  Many\
    \ decisions\n   will have to made on the spot as the incident occurs, but many\
    \ of the\n   options and issues can be discussed in advance.  At very least,\n\
    \   responsibilities and methods of communication can be established\n   before\
    \ an incident.  Again, the choices here are influenced by the\n   policies discussed\
    \ in section 2.\n   Section 6 deals with what happens after a security violation\
    \ has been\n   dealt with.  Security planning is an on-going cycle; just after\
    \ an\n   incident has occurred is an excellent opportunity to improve policies\n\
    \   and procedures.\n   The rest of the document provides references and an annotated\n\
    \   bibliography.\n"
- title: 2.  Establishing Official Site Policy on Computer Security
  contents:
  - '2.  Establishing Official Site Policy on Computer Security

    '
- title: 2.1  Brief Overview
  contents:
  - "2.1  Brief Overview\n   2.1.1  Organization Issues\n      The goal in developing\
    \ an official site policy on computer\n      security is to define the organization's\
    \ expectations of proper\n      computer and network use and to define procedures\
    \ to prevent and\n      respond to security incidents.  In order to do this, aspects\
    \ of\n      the particular organization must be considered.\n      First, the\
    \ goals and direction of the organization should be\n      considered.  For example,\
    \ a military base may have very different\n      security concerns from a those\
    \ of a university.\n      Second, the site security policy developed must conform\
    \ to\n      existing policies, rules, regulations and laws that the\n      organization\
    \ is subject to.  Therefore it will be necessary to\n      identify these and\
    \ take them into consideration while developing\n      the policy.\n      Third,\
    \ unless the local network is completely isolated and\n      standalone, it is\
    \ necessary to consider security implications in a\n      more global context.\
    \  The policy should address the issues when\n      local security problems develop\
    \ as a result of a remote site as\n      well as when problems occur on remote\
    \ systems as a result of a\n      local host or user.\n   2.1.2  Who Makes the\
    \ Policy?\n      Policy creation must be a joint effort by technical personnel,\
    \ who\n      understand the full ramifications of the proposed policy and the\n\
    \      implementation of the policy, and by decision makers who have the\n   \
    \   power to enforce the policy.  A policy which is neither\n      implementable\
    \ nor enforceable is useless.\n      Since a computer security policy can affect\
    \ everyone in an\n      organization, it is worth taking some care to make sure\
    \ you have\n      the right level of authority in on the policy decisions.  Though\
    \ a\n      particular group (such as a campus information services group) may\n\
    \      have responsibility for enforcing a policy, an even higher group\n    \
    \  may have to support and approve the policy.\n   2.1.3  Who is Involved?\n \
    \     Establishing a site policy has the potential for involving every\n     \
    \ computer user at the site in a variety of ways.  Computer users\n      may be\
    \ responsible for personal password administration.  Systems\n      managers are\
    \ obligated to fix security holes and to oversee the\n      system.\n      It\
    \ is critical to get the right set of people involved at the\n      start of the\
    \ process.  There may already be groups concerned with\n      security who would\
    \ consider a computer security policy to be their\n      area.  Some of the types\
    \ of groups that might be involved include\n      auditing/control, organizations\
    \ that deal with physical security,\n      campus information systems groups,\
    \ and so forth.  Asking these\n      types of groups to \"buy in\" from the start\
    \ can help facilitate the\n      acceptance of the policy.\n   2.1.4  Responsibilities\n\
    \      A key element of a computer security policy is making sure\n      everyone\
    \ knows their own responsibility for maintaining security.\n      A computer security\
    \ policy cannot anticipate all possibilities;\n      however, it can ensure that\
    \ each kind of problem does have someone\n      assigned to deal with it.\n  \
    \    There may be levels of responsibility associated with a policy on\n     \
    \ computer security.  At one level, each user of a computing\n      resource may\
    \ have a responsibility to protect his account.  A user\n      who allows his\
    \ account to be compromised increases the chances of\n      compromising other\
    \ accounts or resources.\n      System managers may form another responsibility\
    \ level: they must\n      help to ensure the security of the computer system.\
    \  Network\n      managers may reside at yet another level.\n"
- title: 2.2  Risk Assessment
  contents:
  - "2.2  Risk Assessment\n   2.2.1  General Discussion\n      One of the most important\
    \ reasons for creating a computer security\n      policy is to ensure that efforts\
    \ spent on security yield cost\n      effective benefits.  Although this may seem\
    \ obvious, it is\n      possible to be mislead about where the effort is needed.\
    \  As an\n      example, there is a great deal of publicity about intruders on\n\
    \      computers systems; yet most surveys of computer security show that\n  \
    \    for most organizations, the actual loss from \"insiders\" is much\n     \
    \ greater.\n      Risk analysis involves determining what you need to protect,\
    \ what\n      you need to protect it from, and how to protect it.  Is is the\n\
    \      process of examining all of your risks, and ranking those risks by\n  \
    \    level of severity.  This process involves making cost-effective\n      decisions\
    \ on what you want to protect.  The old security adage\n      says that you should\
    \ not spend more to protect something than it\n      is actually worth.\n    \
    \  A full treatment of risk analysis is outside the scope of this\n      document.\
    \  [3, FITES] and [16, PFLEEGER] provide introductions to\n      this topic. \
    \ However, there are two elements of a risk analysis\n      that will be briefly\
    \ covered in the next two sections:\n         1. Identifying the assets\n    \
    \     2. Identifying the threats\n      For each asset, the basic goals of security\
    \ are availability,\n      confidentiality, and integrity.  Each threat should\
    \ be examined\n      with an eye to how the threat could affect these areas.\n\
    \   2.2.2  Identifying the Assets\n      One step in a risk analysis is to identify\
    \ all the things that\n      need to be protected.  Some things are obvious, like\
    \ all the\n      various pieces of hardware, but some are overlooked, such as\
    \ the\n      people who actually use the systems. The essential point is to\n\
    \      list all things that could be affected by a security problem.\n      One\
    \ list of categories is suggested by Pfleeger [16, PFLEEGER,\n      page 459];\
    \ this list is adapted from that source:\n         1. Hardware: cpus, boards,\
    \ keyboards, terminals,\n            workstations, personal computers, printers,\
    \ disk\n            drives, communication lines, terminal servers, routers.\n\
    \         2. Software: source programs, object programs,\n            utilities,\
    \ diagnostic programs, operating systems,\n            communication programs.\n\
    \         3. Data: during execution, stored on-line, archived off-line,\n    \
    \        backups, audit logs, databases, in transit over\n            communication\
    \ media.\n         4. People: users, people needed to run systems.\n         5.\
    \ Documentation: on programs, hardware, systems, local\n            administrative\
    \ procedures.\n         6. Supplies: paper, forms, ribbons, magnetic media.\n\
    \   2.2.3  Identifying the Threats\n      Once the assets requiring protection\
    \ are identified, it is\n      necessary to identify threats to those assests.\
    \  The threats can\n      then be examined to determine what potential for loss\
    \ exists.  It\n      helps to consider from what threats you are trying to protect\
    \ your\n      assets.\n      The following sections describe a few of the possible\
    \ threats.\n      2.2.3.1  Unauthorized Access\n         A common threat that\
    \ concerns many sites is unauthorized access\n         to computing facilities.\
    \  Unauthorized access takes many forms.\n         One means of unauthorized access\
    \ is the use of another user's\n         account to gain access to a system. \
    \ The use of any computer\n         resource without prior permission may be considered\n\
    \         unauthorized access to computing facilities.\n         The seriousness\
    \ of an unauthorized access will vary from site\n         to site.  For some sites,\
    \ the mere act of granting access to an\n         unauthorized user may cause\
    \ irreparable harm by negative media\n         coverage.  For other sites, an\
    \ unauthorized access opens the\n         door to other security threats.  In\
    \ addition, some sites may be\n         more frequent targets than others; hence\
    \ the risk from\n         unauthorized access will vary from site to site.  The\
    \ Computer\n         Emergency Response Team (CERT - see section 3.9.7.3.1) has\n\
    \         observed that well-known universities, government sites, and\n     \
    \    military sites seem to attract more intruders.\n      2.2.3.2  Disclosure\
    \ of Information\n         Another common threat is disclosure of information.\
    \  Determine\n         the value or sensitivity of the information stored on your\n\
    \         computers.  Disclosure of a password file might allow for\n        \
    \ future unauthorized accesses.  A glimpse of a proposal may give\n         a\
    \ competitor an unfair advantage.  A technical paper may\n         contain years\
    \ of valuable research.\n      2.2.3.3  Denial of Service\n         Computers\
    \ and networks provide valuable services to their\n         users.  Many people\
    \ rely on these services in order to perform\n         their jobs efficiently.\
    \  When these services are not available\n         when called upon, a loss in\
    \ productivity results.\n         Denial of service comes in many forms and might\
    \ affect users in\n         a number of ways.  A network may be rendered unusable\
    \ by a\n         rogue packet, jamming, or by a disabled network component.  A\n\
    \         virus might slow down or cripple a computer system.  Each site\n   \
    \      should determine which services are essential, and for each of\n      \
    \   these services determine the affect to the site if that service\n        \
    \ were to become disabled.\n"
- title: 2.3  Policy Issues
  contents:
  - "2.3  Policy Issues\n   There are a number of issues that must be addressed when\
    \ developing a\n   security policy.  These are:\n      1.  Who is allowed to use\
    \ the resources?\n      2.  What is the proper use of the resources?\n      3.\
    \  Who is authorized to grant access and approve usage?\n      4.  Who may have\
    \ system administration privileges?\n      5.  What are the user's rights and\
    \ responsibilities?\n      6.  What are the rights and responsibilities of the\n\
    \          system administrator vs. those of the user?\n      7.  What do you\
    \ do with sensitive information?\n   These issues will be discussed below.  In\
    \ addition you may wish to\n   include a section in your policy concerning ethical\
    \ use of computing\n   resources.  Parker, Swope and Baker [17, PARKER90] and\
    \ Forester and\n   Morrison [18, FORESTER] are two useful references that address\n\
    \   ethical issues.\n   2.3.1  Who is Allowed to use the Resources?\n      One\
    \ step you must take in developing your security policy is\n      defining who\
    \ is allowed to use your system and services.  The\n      policy should explicitly\
    \ state who is authorized to use what\n      resources.\n   2.3.2  What is the\
    \ Proper Use of the Resources?\n      After determining who is allowed access\
    \ to system resources it is\n      necessary to provide guidelines for the acceptable\
    \ use of the\n      resources.  You may have different guidelines for different\
    \ types\n      of users (i.e., students, faculty, external users).  The policy\n\
    \      should state what is acceptable use as well as unacceptable use.\n    \
    \  It should also include types of use that may be restricted.\n      Define limits\
    \ to access and authority.  You will need to consider\n      the level of access\
    \ various users will have and what resources\n      will be available or restricted\
    \ to various groups of people.\n      Your acceptable use policy should clearly\
    \ state that individual\n      users are responsible for their actions.  Their\
    \ responsibility\n      exists regardless of the security mechanisms that are\
    \ in place.\n      It should be clearly stated that breaking into accounts or\n\
    \      bypassing security is not permitted.\n      The following points should\
    \ be covered when developing an\n      acceptable use policy:\n         o Is breaking\
    \ into accounts permitted?\n         o Is cracking passwords permitted?\n    \
    \     o Is disrupting service permitted?\n         o Should users assume that\
    \ a file being world-readable\n           grants them the authorization to read\
    \ it?\n         o Should users be permitted to modify files that are\n       \
    \    not their own even if they happen to have write\n           permission?\n\
    \         o Should users share accounts?\n      The answer to most of these questions\
    \ will be \"no\".\n      You may wish to incorporate a statement in your policies\n\
    \      concerning copyrighted and licensed software.  Licensing\n      agreements\
    \ with vendors may require some sort of effort on your\n      part to ensure that\
    \ the license is not violated.  In addition, you\n      may wish to inform users\
    \ that the copying of copyrighted software\n      may be a violation of the copyright\
    \ laws, and is not permitted.\n      Specifically concerning copyrighted and/or\
    \ licensed software, you\n      may wish to include the following information:\n\
    \         o Copyrighted and licensed software may not be duplicated\n        \
    \   unless it is explicitly stated that you may do so.\n         o Methods of\
    \ conveying information on the\n           copyright/licensed status of software.\n\
    \         o When in doubt, DON'T COPY.\n      Your acceptable use policy is very\
    \ important.  A policy which does\n      not clearly state what is not permitted\
    \ may leave you unable to\n      prove that a user violated policy.\n      There\
    \ are exception cases like tiger teams and users or\n      administrators wishing\
    \ for \"licenses to hack\" -- you may face the\n      situation where users will\
    \ want to \"hack\" on your services for\n      security research purposes.  You\
    \ should develop a policy that will\n      determine whether you will permit this\
    \ type of research on your\n      services and if so, what your guidelines for\
    \ such research will\n      be.\n      Points you may wish to cover in this area:\n\
    \         o Whether it is permitted at all.\n         o What type of activity\
    \ is permitted: breaking in, releasing\n           worms, releasing viruses, etc..\n\
    \         o What type of controls must be in place to ensure that it\n       \
    \    does not get out of control (e.g., separate a segment of\n           your\
    \ network for these tests).\n         o How you will protect other users from\
    \ being victims of\n           these activities, including external users and\
    \ networks.\n         o The process for obtaining permission to conduct these\n\
    \           tests.\n      In cases where you do permit these activities, you should\
    \ isolate\n      the portions of the network that are being tested from your main\n\
    \      network.  Worms and viruses should never be released on a live\n      network.\n\
    \      You may also wish to employ, contract, or otherwise solicit one or\n  \
    \    more people or organizations to evaluate the security of your\n      services,\
    \ of which may include \"hacking\".  You may wish to provide\n      for this in\
    \ your policy.\n   2.3.3  Who Is Authorized to Grant Access and Approve Usage?\n\
    \      Your policy should state who is authorized to grant access to your\n  \
    \    services.  Further, it must be determined what type of access they\n    \
    \  are permitted to give.  If you do not have control over who is\n      granted\
    \ access to your system, you will not have control over who\n      is using your\
    \ system.  Controlling who has the authorization to\n      grant access will also\
    \ enable you to know who was or was not\n      granting access if problems develop\
    \ later.\n      There are many schemes that can be developed to control the\n\
    \      distribution of access to your services.  The following are the\n     \
    \ factors that you must consider when determining who will\n      distribute access\
    \ to your services:\n         o Will you be distributing access from a centralized\n\
    \           point or at various points?\n      You can have a centralized distribution\
    \ point to a distributed\n      system where various sites or departments independently\
    \ authorize\n      access.  The trade off is between security and convenience.\
    \  The\n      more centralized, the easier to secure.\n         o What methods\
    \ will you use for creating accounts and\n           terminating access?\n   \
    \   From a security standpoint, you need to examine the mechanism that\n     \
    \ you will be using to create accounts.  In the least restrictive\n      case,\
    \ the people who are authorized to grant access would be able\n      to go into\
    \ the system directly and create an account by hand or\n      through vendor supplied\
    \ mechanisms.  Generally, these mechanisms\n      place a great deal of trust\
    \ in the person running them, and the\n      person running them usually has a\
    \ large amount of privileges.  If\n      this is the choice you make, you need\
    \ to select someone who is\n      trustworthy to perform this task.  The opposite\
    \ solution is to\n      have an integrated system that the people authorized to\
    \ create\n      accounts run, or the users themselves may actually run.  Be aware\n\
    \      that even in the restrictive case of having a mechanized facility\n   \
    \   to create accounts does not remove the potential for abuse.\n      You should\
    \ have specific procedures developed for the creation of\n      accounts.  These\
    \ procedures should be well documented to prevent\n      confusion and reduce\
    \ mistakes.  A security vulnerability in the\n      account authorization process\
    \ is not only possible through abuse,\n      but is also possible if a mistake\
    \ is made.  Having clear and well\n      documented procedure will help ensure\
    \ that these mistakes won't\n      happen.  You should also be sure that the people\
    \ who will be\n      following these procedures understand them.\n      The granting\
    \ of access to users is one of the most vulnerable of\n      times.  You should\
    \ ensure that the selection of an initial\n      password cannot be easily guessed.\
    \  You should avoid using an\n      initial password that is a function of the\
    \ username, is part of\n      the user's name, or some algorithmically generated\
    \ password that\n      can easily be guessed.  In addition, you should not permit\
    \ users\n      to continue to use the initial password indefinitely.  If\n   \
    \   possible, you should force users to change the initial password\n      the\
    \ first time they login.  Consider that some users may never\n      even login,\
    \ leaving their password vulnerable indefinitely.  Some\n      sites choose to\
    \ disable accounts that have never been accessed,\n      and force the owner to\
    \ reauthorize opening the account.\n   2.3.4  Who May Have System Administration\
    \ Privileges?\n      One security decision that needs to be made very carefully\
    \ is who\n      will have access to system administrator privileges and passwords\n\
    \      for your services.  Obviously, the system administrators will need\n  \
    \    access, but inevitably other users will request special\n      privileges.\
    \  The policy should address this issue.  Restricting\n      privileges is one\
    \ way to deal with threats from local users.  The\n      challenge is to balance\
    \ restricting access to these to protect\n      security with giving people who\
    \ need these privileges access so\n      that they can perform their tasks.  One\
    \ approach that can be taken\n      is to grant only enough privilege to accomplish\
    \ the necessary\n      tasks.\n      Additionally, people holding special privileges\
    \ should be\n      accountable to some authority and this should also be identified\n\
    \      within the site's security policy.  If the people you grant\n      privileges\
    \ to are not accountable, you run the risk of losing\n      control of your system\
    \ and will have difficulty managing a\n      compromise in security.\n   2.3.5\
    \  What Are The Users' Rights and Responsibilities?\n      The policy should incorporate\
    \ a statement on the users' rights and\n      responsibilities concerning the\
    \ use of the site's computer systems\n      and services.  It should be clearly\
    \ stated that users are\n      responsible for understanding and respecting the\
    \ security rules of\n      the systems they are using.  The following is a list\
    \ of topics\n      that you may wish to cover in this area of the policy:\n  \
    \       o What guidelines you have regarding resource consumption\n          \
    \ (whether users are restricted, and if so, what the\n           restrictions\
    \ are).\n         o What might constitute abuse in terms of system performance.\n\
    \         o Whether users are permitted to share accounts or let others\n    \
    \       use their accounts.\n         o How \"secret\" users should keep their\
    \ passwords.\n         o How often users should change their passwords and any\
    \ other\n           password restrictions or requirements.\n         o Whether\
    \ you provide backups or expect the users to create\n           their own.\n \
    \        o Disclosure of information that may be proprietary.\n         o Statement\
    \ on Electronic Mail Privacy (Electronic\n           Communications Privacy Act).\n\
    \         o Your policy concerning controversial mail or postings to\n       \
    \    mailing lists or discussion groups (obscenity, harassment,\n           etc.).\n\
    \         o Policy on electronic communications: mail forging, etc.\n      The\
    \ Electronic Mail Association sponsored a white paper on the\n      privacy of\
    \ electronic mail in companies [4].  Their basic\n      recommendation is that\
    \ every site should have a policy on the\n      protection of employee privacy.\
    \  They also recommend that\n      organizations establish privacy policies that\
    \ deal with all media,\n      rather than singling out electronic mail.\n    \
    \  They suggest five criteria for evaluating any policy:\n         1. Does the\
    \ policy comply with law and with duties to\n            third parties?\n    \
    \     2. Does the policy unnecessarily compromise the interest of\n          \
    \  the employee, the employer or third parties?\n         3. Is the policy workable\
    \ as a practical matter and likely to\n            be enforced?\n         4. Does\
    \ the policy deal appropriately with all different\n            forms of communications\
    \ and record keeping with the office?\n         5. Has the policy been announced\
    \ in advance and agreed to by\n            all concerned?\n   2.3.6  What Are\
    \ The Rights and Responsibilities of System\n          Administrators Versus Rights\
    \ of Users\n      There is a tradeoff between a user's right to absolute privacy\
    \ and\n      the need of system administrators to gather sufficient information\n\
    \      to diagnose problems.  There is also a distinction between a\n      system\
    \ administrator's need to gather information to diagnose\n      problems and investigating\
    \ security violations.  The policy should\n      specify to what degree system\
    \ administrators can examine user\n      files to diagnose problems or for other\
    \ purposes, and what rights\n      you grant to the users.  You may also wish\
    \ to make a statement\n      concerning system administrators' obligation to maintaining\
    \ the\n      privacy of information viewed under these circumstances.  A few\n\
    \      questions that should be answered are:\n         o Can an administrator\
    \ monitor or read a user's files\n           for any reason?\n         o What\
    \ are the liabilities?\n         o Do network administrators have the right to\
    \ examine\n           network or host traffic?\n   2.3.7  What To Do With Sensitive\
    \ Information\n      Before granting users access to your services, you need to\n\
    \      determine at what level you will provide for the security of data\n   \
    \   on your systems.  By determining this, you are determining the\n      level\
    \ of sensitivity of data that users should store on your\n      systems.  You\
    \ do not want users to store very sensitive\n      information on a system that\
    \ you are not going to secure very\n      well.  You need to tell users who might\
    \ store sensitive\n      information what services, if any, are appropriate for\
    \ the storage\n      of sensitive information.  This part should include storing\
    \ of\n      data in different ways (disk, magnetic tape, file servers, etc.).\n\
    \      Your policy in this area needs to be coordinated with the policy\n    \
    \  concerning the rights of system administrators versus users (see\n      section\
    \ 2.3.6).\n"
- title: 2.4  What Happens When the Policy is Violated
  contents:
  - "2.4  What Happens When the Policy is Violated\n   It is obvious that when any\
    \ type of official policy is defined, be it\n   related to computer security or\
    \ not, it will eventually be broken.\n   The violation may occur due to an individual's\
    \ negligence, accidental\n   mistake, having not been properly informed of the\
    \ current policy, or\n   not understanding the current policy.  It is equally\
    \ possible that an\n   individual (or group of individuals) may knowingly perform\
    \ an act\n   that is in direct violation of the defined policy.\n   When a policy\
    \ violation has been detected, the immediate course of\n   action should be pre-defined\
    \ to ensure prompt and proper enforcement.\n   An investigation should be performed\
    \ to determine how and why the\n   violation occurred.  Then the appropriate corrective\
    \ action should be\n   executed.  The type and severity of action taken varies\
    \ depending on\n   the type of violation that occurred.\n   2.4.1  Determining\
    \ the Response to Policy Violations\n      Violations to policy may be committed\
    \ by a wide variety of users.\n      Some may be local users and others may be\
    \ from outside the local\n      environment.  Sites may find it helpful to define\
    \ what it\n      considers \"insiders\" and \"outsiders\" based upon administrative,\n\
    \      legal or political boundaries.  These boundaries imply what type\n    \
    \  of action must be taken to correct the offending party; from a\n      written\
    \ reprimand to pressing legal charges.  So, not only do you\n      need to define\
    \ actions based on the type of violation, you also\n      need to have a clearly\
    \ defined series of actions based on the kind\n      of user violating your computer\
    \ security policy.  This all seems\n      rather complicated, but should be addressed\
    \ long before it becomes\n      necessary as the result of a violation.\n    \
    \  One point to remember about your policy is that proper education\n      is\
    \ your best defense.  For the outsiders who are using your\n      computer legally,\
    \ it is your responsibility to verify that these\n      individuals are aware\
    \ of the policies that you have set forth.\n      Having this proof may assist\
    \ you in the future if legal action\n      becomes necessary.\n      As for users\
    \ who are using your computer illegally, the problem is\n      basically the same.\
    \  What type of user violated the policy and how\n      and why did they do it?\
    \  Depending on the results of your\n      investigation, you may just prefer\
    \ to \"plug\" the hole in your\n      computer security and chalk it up to experience.\
    \  Or if a\n      significant amount of loss was incurred, you may wish to take\
    \ more\n      drastic action.\n   2.4.2  What to do When Local Users Violate the\
    \ Policy of a Remote\n          Site\n      In the event that a local user violates\
    \ the security policy of a\n      remote site, the local site should have a clearly\
    \ defined set of\n      administrative actions to take concerning that local user.\
    \  The\n      site should also be prepared to protect itself against possible\n\
    \      actions by the remote site.  These situations involve legal issues\n  \
    \    which should be addressed when forming the security policy.\n   2.4.3  Defining\
    \ Contacts and Responsibilities to Outside\n          Organizations\n      The\
    \ local security policy should include procedures for\n      interaction with\
    \ outside organizations.  These include law\n      enforcement agencies, other\
    \ sites, external response team\n      organizations (e.g., the CERT, CIAC) and\
    \ various press agencies.\n      The procedure should state who is authorized\
    \ to make such contact\n      and how it should be handled.  Some questions to\
    \ be answered\n      include:\n         o Who may talk to the press?\n       \
    \  o When do you contact law enforcement and investigative agencies?\n       \
    \  o If a connection is made from a remote site, is the\n           system manager\
    \ authorized to contact that site?\n         o Can data be released?  What kind?\n\
    \      Detailed contact information should be readily available along\n      with\
    \ clearly defined procedures to follow.\n   2.4.4  What are the Responsibilities\
    \ to our Neighbors and Other\n          Internet Sites?\n      The Security Policy\
    \ Working Group within the IETF is working on a\n      document entitled, \"Policy\
    \ Guidelines for the Secure Operation of\n      the Internet\" [23].  It addresses\
    \ the issue that the Internet is a\n      cooperative venture and that sites are\
    \ expected to provide mutual\n      security assistance.  This should be addressed\
    \ when developing a\n      site's policy.  The major issue to be determined is\
    \ how much\n      information should be released.  This will vary from site to\
    \ site\n      according to the type of site (e.g., military, education,\n    \
    \  commercial) as well as the type of security violation that\n      occurred.\n\
    \   2.4.5  Issues for Incident Handling Procedures\n      Along with statements\
    \ of policy, the document being prepared\n      should include procedures for\
    \ incident handling.  This is covered\n      in detail in the next chapter.  There\
    \ should be procedures\n      available that cover all facets of policy violation.\n"
- title: 2.5  Locking In or Out
  contents:
  - "2.5  Locking In or Out\n   Whenever a site suffers an incident which may compromise\
    \ computer\n   security, the strategies for reacting may be influenced by two\n\
    \   opposing pressures.\n   If management fears that the site is sufficiently\
    \ vulnerable, it may\n   choose a \"Protect and Proceed\" strategy.  This approach\
    \ will have as\n   its primary goal the protection and preservation of the site\n\
    \   facilities and to provide for normalcy for its users as quickly as\n   possible.\
    \  Attempts will be made to actively interfere with the\n   intruder's processes,\
    \ prevent further access and begin immediate\n   damage assessment and recovery.\
    \  This process may involve shutting\n   down the facilities, closing off access\
    \ to the network, or other\n   drastic measures.  The drawback is that unless\
    \ the intruder is\n   identified directly, they may come back into the site via\
    \ a different\n   path, or may attack another site.\n   The alternate approach,\
    \ \"Pursue and Prosecute\", adopts the opposite\n   philosophy and goals.  The\
    \ primary goal is to allow intruders to\n   continue their activities at the site\
    \ until the site can identify the\n   responsible persons.  This approach is endorsed\
    \ by law enforcement\n   agencies and prosecutors.  The drawback is that the agencies\
    \ cannot\n   exempt a site from possible user lawsuits if damage is done to their\n\
    \   systems and data.\n   Prosecution is not the only outcome possible if the\
    \ intruder is\n   identified.  If the culprit is an employee or a student, the\n\
    \   organization may choose to take disciplinary actions.  The computer\n   security\
    \ policy needs to spell out the choices and how they will be\n   selected if an\
    \ intruder is caught.\n   Careful consideration must be made by site management\
    \ regarding their\n   approach to this issue before the problem occurs.  The strategy\n\
    \   adopted might depend upon each circumstance.  Or there may be a\n   global\
    \ policy which mandates one approach in all circumstances.  The\n   pros and cons\
    \ must be examined thoroughly and the users of the\n   facilities must be made\
    \ aware of the policy so that they understand\n   their vulnerabilities no matter\
    \ which approach is taken.\n   The following are checklists to help a site determine\
    \ which strategy\n   to adopt: \"Protect and Proceed\" or \"Pursue and Prosecute\"\
    .\n   Protect and Proceed\n      1. If assets are not well protected.\n      2.\
    \ If continued penetration could result in great\n         financial risk.\n \
    \     3. If the possibility or willingness to prosecute\n         is not present.\n\
    \      4. If user base is unknown.\n      5. If users are unsophisticated and\
    \ their work is\n         vulnerable.\n      6. If the site is vulnerable to lawsuits\
    \ from users, e.g.,\n         if their resources are undermined.\n   Pursue and\
    \ Prosecute\n      1. If assets and systems are well protected.\n      2. If good\
    \ backups are available.\n      3. If the risk to the assets is outweighed by\
    \ the\n         disruption caused by the present and possibly future\n       \
    \  penetrations.\n      4. If this is a concentrated attack occurring with great\n\
    \         frequency and intensity.\n      5. If the site has a natural attraction\
    \ to intruders, and\n         consequently regularly attracts intruders.\n   \
    \   6. If the site is willing to incur the financial (or other)\n         risk\
    \ to assets by allowing the penetrator continue.\n      7. If intruder access\
    \ can be controlled.\n      8. If the monitoring tools are sufficiently well-developed\n\
    \         to make the pursuit worthwhile.\n      9. If the support staff is sufficiently\
    \ clever and knowledgable\n         about the operating system, related utilities,\
    \ and systems\n         to make the pursuit worthwhile.\n      10. If there is\
    \ willingness on the part of management to\n          prosecute.\n      11. If\
    \ the system adminitrators know in general what kind of\n          evidence would\
    \ lead to prosecution.\n      12. If there is established contact with knowledgeable\
    \ law\n          enforcement.\n      13. If there is a site representative versed\
    \ in the relevant\n          legal issues.\n      14. If the site is prepared\
    \ for possible legal action from\n          its own users if their data or systems\
    \ become compromised\n          during the pursuit.\n"
- title: 2.6  Interpreting the Policy
  contents:
  - "2.6  Interpreting the Policy\n   It is important to define who will interpret\
    \ the policy.  This could\n   be an individual or a committee.  No matter how\
    \ well written, the\n   policy will require interpretation from time to time and\
    \ this body\n   would serve to review, interpret, and revise the policy as needed.\n"
- title: 2.7  Publicizing the Policy
  contents:
  - "2.7  Publicizing the Policy\n   Once the site security policy has been written\
    \ and established, a\n   vigorous process should be engaged to ensure that the\
    \ policy\n   statement is widely and thoroughly disseminated and discussed.  A\n\
    \   mailing of the policy should not be considered sufficient.  A period\n   for\
    \ comments should be allowed before the policy becomes effective to\n   ensure\
    \ that all affected users have a chance to state their reactions\n   and discuss\
    \ any unforeseen ramifications.  Ideally, the policy should\n   strike a balance\
    \ between protection and productivity.\n   Meetings should be held to elicit these\
    \ comments, and also to ensure\n   that the policy is correctly understood.  (Policy\
    \ promulgators are\n   not necessarily noted for their skill with the language.)\
    \  These\n   meetings should involve higher management as well as line employees.\n\
    \   Security is a collective effort.\n   In addition to the initial efforts to\
    \ publicize the policy, it is\n   essential for the site to maintain a continual\
    \ awareness of its\n   computer security policy.  Current users may need periodic\
    \ reminders\n   New users should have the policy included as part of their site\n\
    \   introduction packet.  As a condition for using the site facilities,\n   it\
    \ may be advisable to have them sign a statement that they have read\n   and understood\
    \ the policy.  Should any of these users require legal\n   action for serious\
    \ policy violations, this signed statement might\n   prove to be a valuable aid.\n"
- title: 3.  Establishing Procedures to Prevent Security Problems
  contents:
  - "3.  Establishing Procedures to Prevent Security Problems\n   The security policy\
    \ defines what needs to be protected.  This section\n   discusses security procedures\
    \ which specify what steps will be used\n   to carry out the security policy.\n"
- title: 3.1  Security Policy Defines What Needs to be Protected
  contents:
  - "3.1  Security Policy Defines What Needs to be Protected\n   The security policy\
    \ defines the WHAT's: what needs to be protected,\n   what is most important,\
    \ what the priorities are, and what the general\n   approach to dealing with security\
    \ problems should be.\n   The security policy by itself doesn't say HOW things\
    \ are protected.\n   That is the role of security procedures, which this section\n\
    \   discusses.  The security policy should be a high level document,\n   giving\
    \ general strategy.  The security procedures need to set out, in\n   detail, the\
    \ precise steps your site will take to protect itself.\n   The security policy\
    \ should include a general risk assessment of the\n   types of threats a site\
    \ is mostly likely to face and the consequences\n   of those threats (see section\
    \ 2.2).  Part of doing a risk assessment\n   will include creating a general list\
    \ of assets that should be\n   protected (section 2.2.2).  This information is\
    \ critical in devising\n   cost-effective procedures.\n   It is often tempting\
    \ to start creating security procedures by\n   deciding on different mechanisms\
    \ first: \"our site should have logging\n   on all hosts, call-back modems, and\
    \ smart cards for all users.\"  This\n   approach could lead to some areas that\
    \ have too much protection for\n   the risk they face, and other areas that aren't\
    \ protected enough.\n   Starting with the security policy and the risks it outlines\
    \ should\n   ensure that the procedures provide the right level of protect for\
    \ all\n   assets.\n"
- title: 3.2  Identifing Possible Problems
  contents:
  - "3.2  Identifing Possible Problems\n   To determine risk, vulnerabilities must\
    \ be identified.  Part of the\n   purpose of the policy is to aid in shoring up\
    \ the vulnerabilities and\n   thus to decrease the risk in as many areas as possible.\
    \  Several of\n   the more popular problem areas are presented in sections below.\
    \  This\n   list is by no means complete.  In addition, each site is likely to\n\
    \   have a few unique vulnerabilities.\n   3.2.1  Access Points\n      Access\
    \ points are typically used for entry by unauthorized users.\n      Having many\
    \ access points increases the risk of access to an\n      organization's computer\
    \ and network facilities.\n      Network links to networks outside the organization\
    \ allow access\n      into the organization for all others connected to that external\n\
    \      network.  A network link typically provides access to a large\n      number\
    \ of network services, and each service has a potential to be\n      compromised.\n\
    \      Dialup lines, depending on their configuration, may provide access\n  \
    \    merely to a login port of a single system.  If connected to a\n      terminal\
    \ server, the dialup line may give access to the entire\n      network.\n    \
    \  Terminal servers themselves can be a source of problem.  Many\n      terminal\
    \ servers do not require any kind of authentication.\n      Intruders often use\
    \ terminal servers to disguise their actions,\n      dialing in on a local phone\
    \ and then using the terminal server to\n      go out to the local network.  Some\
    \ terminal servers are configured\n      so that intruders can TELNET [19] in\
    \ from outside the network, and\n      then TELNET back out again, again serving\
    \ to make it difficult to\n      trace them.\n   3.2.2  Misconfigured Systems\n\
    \      Misconfigured systems form a large percentage of security holes.\n    \
    \  Today's operating systems and their associated software have\n      become\
    \ so complex that understanding how the system works has\n      become a full-time\
    \ job.  Often, systems managers will be non-\n      specialists chosen from the\
    \ current organization's staff.\n      Vendors are also partly responsible for\
    \ misconfigured systems. To\n      make the system installation process easier,\
    \ vendors occasionally\n      choose initial configurations that are not secure\
    \ in all\n      environments.\n   3.2.3  Software Bugs\n      Software will never\
    \ be bug free.  Publicly known security bugs are\n      common methods of unauthorized\
    \ entry.  Part of the solution to\n      this problem is to be aware of the security\
    \ problems and to update\n      the software when problems are detected.  When\
    \ bugs are found,\n      they should be reported to the vendor so that a solution\
    \ to the\n      problem can be implemented and distributed.\n   3.2.4  \"Insider\"\
    \ Threats\n      An insider to the organization may be a considerable threat to\
    \ the\n      security of the computer systems.  Insiders often have direct\n \
    \     access to the computer and network hardware components.  The\n      ability\
    \ to access the components of a system makes most systems\n      easier to compromise.\
    \  Most desktop workstations can be easily\n      manipulated so that they grant\
    \ privileged access.  Access to a\n      local area network provides the ability\
    \ to view possibly sensitive\n      data traversing the network.\n"
- title: 3.3  Choose Controls to Protect Assets in a Cost-Effective Way
  contents:
  - "3.3  Choose Controls to Protect Assets in a Cost-Effective Way\n   After establishing\
    \ what is to be protected, and assessing the risks\n   these assets face, it is\
    \ necessary to decide how to implement the\n   controls which protect these assets.\
    \  The controls and protection\n   mechanisms should be selected in a way so as\
    \ to adequately counter\n   the threats found during risk assessment, and to implement\
    \ those\n   controls in a cost effective manner.  It makes little sense to spend\n\
    \   an exorbitant sum of money and overly constrict the user base if the\n   risk\
    \ of exposure is very small.\n   3.3.1  Choose the Right Set of Controls\n   \
    \   The controls that are selected represent the physical embodiment\n      of\
    \ your security policy.  They are the first and primary line of\n      defense\
    \ in the protection of your assets.  It is therefore most\n      important to\
    \ ensure that the controls that you select are the\n      right set of controls.\
    \  If the major threat to your system is\n      outside penetrators, it probably\
    \ doesn't make much sense to use\n      biometric devices to authenticate your\
    \ regular system users.  On\n      the other hand, if the major threat is unauthorized\
    \ use of\n      computing resources by regular system users, you'll probably want\n\
    \      to establish very rigorous automated accounting procedures.\n   3.3.2 \
    \ Use Common Sense\n      Common sense is the most appropriate tool that can be\
    \ used to\n      establish your security policy.  Elaborate security schemes and\n\
    \      mechanisms are impressive, and they do have their place, yet there\n  \
    \    is little point in investing money and time on an elaborate\n      implementation\
    \ scheme if the simple controls are forgotten.  For\n      example, no matter\
    \ how elaborate a system you put into place on\n      top of existing security\
    \ controls, a single user with a poor\n      password can still leave your system\
    \ open to attack.\n"
- title: 3.4  Use Multiple Strategies to Protect Assets
  contents:
  - "3.4  Use Multiple Strategies to Protect Assets\n   Another method of protecting\
    \ assets is to use multiple strategies.\n   In this way, if one strategy fails\
    \ or is circumvented, another\n   strategy comes into play to continue protecting\
    \ the asset.  By using\n   several simpler strategies, a system can often be made\
    \ more secure\n   than if one very sophisticated method were used in its place.\
    \  For\n   example, dial-back modems can be used in conjunction with traditional\n\
    \   logon mechanisms.  Many similar approaches could be devised that\n   provide\
    \ several levels of protection for assets.  However, it's very\n   easy to go\
    \ overboard with extra mechanisms.  One must keep in mind\n   exactly what it\
    \ is that needs to be protected.\n"
- title: 3.5  Physical Security
  contents:
  - "3.5  Physical Security\n   It is a given in computer security if the system itself\
    \ is not\n   physically secure, nothing else about the system can be considered\n\
    \   secure.  With physical access to a machine, an intruder can halt the\n   machine,\
    \ bring it back up in privileged mode, replace or alter the\n   disk, plant Trojan\
    \ horse programs (see section 2.13.9.2), or take any\n   number of other undesirable\
    \ (and hard to prevent) actions.\n   Critical communications links, important\
    \ servers, and other key\n   machines should be located in physically secure areas.\
    \  Some security\n   systems (such as Kerberos) require that the machine be physically\n\
    \   secure.\n   If you cannot physically secure machines, care should be taken\
    \ about\n   trusting those machines.  Sites should consider limiting access from\n\
    \   non-secure machines to more secure machines.  In particular, allowing\n  \
    \ trusted access (e.g., the BSD Unix remote commands such as rsh) from\n   these\
    \ kinds of hosts is particularly risky.\n   For machines that seem or are intended\
    \ to be physically secure, care\n   should be taken about who has access to the\
    \ machines.  Remember that\n   custodial and maintenance staff often have keys\
    \ to rooms.\n"
- title: 3.6   Procedures to Recognize Unauthorized Activity
  contents:
  - "3.6   Procedures to Recognize Unauthorized Activity\n   Several simple procedures\
    \ can be used to detect most unauthorized\n   uses of a computer system.  These\
    \ procedures use tools provided with\n   the operating system by the vendor, or\
    \ tools publicly available from\n   other sources.\n   3.6.1  Monitoring System\
    \ Use\n      System monitoring can be done either by a system administrator, or\n\
    \      by software written for the purpose.  Monitoring a system involves\n  \
    \    looking at several parts of the system and searching for anything\n     \
    \ unusual.  Some of the easier ways to do this are described in this\n      section.\n\
    \      The most important thing about monitoring system use is that it be\n  \
    \    done on a regular basis.  Picking one day out of the month to\n      monitor\
    \ the system is pointless, since a security breach can be\n      isolated to a\
    \ matter of hours.  Only by maintaining a constant\n      vigil can you expect\
    \ to detect security violations in time to\n      react to them.\n   3.6.2  Tools\
    \ for Monitoring the System\n      This section describes tools and methods for\
    \ monitoring a system\n      against unauthorized access and use.\n      3.6.2.1\
    \  Logging\n         Most operating systems store numerous bits of information\
    \ in\n         log files.  Examination of these log files on a regular basis\n\
    \         is often the first line of defense in detecting unauthorized\n     \
    \    use of the system.\n            - Compare lists of currently logged in users\
    \ and past\n              login histories.  Most users typically log in and out\n\
    \              at roughly the same time each day.  An account logged\n       \
    \       in outside the \"normal\" time for the account may be in\n           \
    \   use by an intruder.\n            - Many systems maintain accounting records\
    \ for billing\n              purposes.  These records can also be used to determine\n\
    \              usage patterns for the system; unusual accounting records\n   \
    \           may indicate unauthorized use of the system.\n            - System\
    \ logging facilities, such as the UNIX \"syslog\"\n              utility, should\
    \ be checked for unusual error messages\n              from system software. \
    \ For example, a large number of\n              failed login attempts in a short\
    \ period of time may\n              indicate someone trying to guess passwords.\n\
    \            - Operating system commands which list currently executing\n    \
    \          processes can be used to detect users running programs\n          \
    \    they are not authorized to use, as well as to detect\n              unauthorized\
    \ programs which have been started by an\n              intruder.\n      3.6.2.2\
    \  Monitoring Software\n         Other monitoring tools can easily be constructed\
    \ using standard\n         operating system software, by using several, often\
    \ unrelated,\n         programs together.  For example, checklists of file ownerships\n\
    \         and permission settings can be constructed (for example, with\n    \
    \     \"ls\" and \"find\" on UNIX) and stored off-line.  These lists can\n   \
    \      then be reconstructed periodically and compared against the\n         master\
    \ checklist (on UNIX, by using the \"diff\" utility).\n         Differences may\
    \ indicate that unauthorized modifications have\n         been made to the system.\n\
    \         Still other tools are available from third-party vendors and\n     \
    \    public software distribution sites.  Section 3.9.9 lists\n         several\
    \ sources from which you can learn what tools are\n         available and how\
    \ to get them.\n      3.6.2.3  Other Tools\n         Other tools can also be used\
    \ to monitor systems for security\n         violations, although this is not their\
    \ primary purpose.  For\n         example, network monitors can be used to detect\
    \ and log\n         connections from unknown sites.\n   3.6.3  Vary the Monitoring\
    \ Schedule\n      The task of system monitoring is not as daunting as it may seem.\n\
    \      System administrators can execute many of the commands used for\n     \
    \ monitoring periodically throughout the day during idle moments\n      (e.g.,\
    \ while talking on the telephone), rather than spending fixed\n      periods of\
    \ each day monitoring the system.  By executing the\n      commands frequently,\
    \ you will rapidly become used to seeing\n      \"normal\" output, and will easily\
    \ spot things which are out of the\n      ordinary.  In addition, by running various\
    \ monitoring commands at\n      different times throughout the day, you make it\
    \ hard for an\n      intruder to predict your actions.  For example, if an intruder\n\
    \      knows that each day at 5:00 p.m. the system is checked to see that\n  \
    \    everyone has logged off, he will simply wait until after the check\n    \
    \  has completed before logging in.  But the intruder cannot guess\n      when\
    \ a system administrator might type a command to display all\n      logged-in\
    \ users, and thus he runs a much greater risk of\n      detection.\n      Despite\
    \ the advantages that regular system monitoring provides,\n      some intruders\
    \ will be aware of the standard logging mechanisms in\n      use on systems they\
    \ are attacking.  They will actively pursue and\n      attempt to disable monitoring\
    \ mechanisms.  Regular monitoring\n      therefore is useful in detecting intruders,\
    \ but does not provide\n      any guarantee that your system is secure, nor should\
    \ monitoring be\n      considered an infallible method of detecting unauthorized\
    \ use.\n"
- title: 3.7  Define Actions to Take When Unauthorized Activity is Suspected
  contents:
  - "3.7  Define Actions to Take When Unauthorized Activity is Suspected\n      Sections\
    \ 2.4 and 2.5 discussed the course of action a site should\n      take when it\
    \ suspects its systems are being abused.  The computer\n      security policy\
    \ should state the general approach towards dealing\n      with these problems.\n\
    \      The procedures for dealing with these types of problems should be\n   \
    \   written down.  Who has authority to decide what actions will be\n      taken?\
    \  Should law enforcement be involved?  Should your\n      organization cooperate\
    \ with other sites in trying to track down an\n      intruder?  Answers to all\
    \ the questions in section 2.4 should be\n      part of the incident handling\
    \ procedures.\n      Whether you decide to lock out or pursue intruders, you should\n\
    \      have tools and procedures ready to apply.  It is best to work up\n    \
    \  these tools and procedures before you need them.  Don't wait until\n      an\
    \ intruder is on your system to figure out how to track the\n      intruder's\
    \ actions; you will be busy enough if an intruder\n      strikes.\n"
- title: 3.8  Communicating Security Policy
  contents:
  - "3.8  Communicating Security Policy\n   Security policies, in order to be effective,\
    \ must be communicated to\n   both the users of the system and the system maintainers.\
    \  This\n   section describes what these people should be told, and how to tell\n\
    \   them.\n   3.8.1  Educating the Users\n      Users should be made aware of\
    \ how the computer systems are\n      expected to be used, and how to protect\
    \ themselves from\n      unauthorized users.\n      3.8.1.1  Proper Account/Workstation\
    \ Use\n         All users should be informed about what is considered the\n  \
    \       \"proper\" use of their account or workstation (\"proper\" use is\n  \
    \       discussed in section 2.3.2).  This can most easily be done at\n      \
    \   the time a user receives their account, by giving them a policy\n        \
    \ statement.  Proper use policies typically dictate things such\n         as whether\
    \ or not the account or workstation may be used for\n         personal activities\
    \ (such as checkbook balancing or letter\n         writing), whether profit-making\
    \ activities are allowed, whether\n         game playing is permitted, and so\
    \ on.  These policy statements\n         may also be used to summarize how the\
    \ computer facility is\n         licensed and what software licenses are held\
    \ by the\n         institution; for example, many universities have educational\n\
    \         licenses which explicitly prohibit commercial uses of the\n        \
    \ system.  A more complete list of items to consider when writing\n         a\
    \ policy statement is given in section 2.3.\n      3.8.1.2  Account/Workstation\
    \ Management Procedures\n         Each user should be told how to properly manage\
    \ their account\n         and workstation.  This includes explaining how to protect\
    \ files\n         stored on the system, how to log out or lock the terminal or\n\
    \         workstation, and so on.  Much of this information is typically\n   \
    \      covered in the \"beginning user\" documentation provided by the\n     \
    \    operating system vendor, although many sites elect to\n         supplement\
    \ this material with local information.\n         If your site offers dial-up\
    \ modem access to the computer\n         systems, special care must be taken to\
    \ inform users of the\n         security problems inherent in providing this access.\
    \  Issues\n         such as making sure to log out before hanging up the modem\n\
    \         should be covered when the user is initially given dial-up\n       \
    \  access.\n         Likewise, access to the systems via local and wide-area\n\
    \         networks presents its own set of security problems which users\n   \
    \      should be made aware of.  Files which grant \"trusted host\" or\n     \
    \    \"trusted user\" status to remote systems and users should be\n         carefully\
    \ explained.\n      3.8.1.3  Determining Account Misuse\n         Users should\
    \ be told how to detect unauthorized access to their\n         account.  If the\
    \ system prints the last login time when a user\n         logs in, he or she should\
    \ be told to check that time and note\n         whether or not it agrees with\
    \ the last time he or she actually\n         logged in.\n         Command interpreters\
    \ on some systems (e.g., the UNIX C shell)\n         maintain histories of the\
    \ last several commands executed.\n         Users should check these histories\
    \ to be sure someone has not\n         executed other commands with their account.\n\
    \      3.8.1.4  Problem Reporting Procedures\n         A procedure should be developed\
    \ to enable users to report\n         suspected misuse of their accounts or other\
    \ misuse they may\n         have noticed.  This can be done either by providing\
    \ the name\n         and telephone number of a system administrator who manages\n\
    \         security of the computer system, or by creating an electronic\n    \
    \     mail address (e.g., \"security\") to which users can address\n         their\
    \ problems.\n   3.8.2  Educating the Host Administrators\n      In many organizations,\
    \ computer systems are administered by a wide\n      variety of people.  These\
    \ administrators must know how to protect\n      their own systems from attack\
    \ and unauthorized use, as well as how\n      to communicate successful penetration\
    \ of their systems to other\n      administrators as a warning.\n      3.8.2.1\
    \  Account Management Procedures\n         Care must be taken when installing\
    \ accounts on the system in\n         order to make them secure.  When installing\
    \ a system from\n         distribution media, the password file should be examined\
    \ for\n         \"standard\" accounts provided by the vendor.  Many vendors\n\
    \         provide accounts for use by system services or field service\n     \
    \    personnel.  These accounts typically have either no password or\n       \
    \  one which is common knowledge.  These accounts should be given\n         new\
    \ passwords if they are needed, or disabled or deleted from\n         the system\
    \ if they are not.\n         Accounts without passwords are generally very dangerous\
    \ since\n         they allow anyone to access the system.  Even accounts which\
    \ do\n         not execute a command interpreter (e.g., accounts which exist\n\
    \         only to see who is logged in to the system) can be compromised\n   \
    \      if set up incorrectly.  A related concept, that of \"anonymous\"\n    \
    \     file transfer (FTP) [20], allows users from all over the\n         network\
    \ to access your system to retrieve files from (usually)\n         a protected\
    \ disk area.  You should carefully weigh the benefits\n         that an account\
    \ without a password provides against the\n         security risks of providing\
    \ such access to your system.\n         If the operating system provides a \"\
    shadow\" password facility\n         which stores passwords in a separate file\
    \ accessible only to\n         privileged users, this facility should be used.\
    \  System V UNIX,\n         SunOS 4.0 and above, and versions of Berkeley UNIX\
    \ after 4.3BSD\n         Tahoe, as well as others, provide this feature.  It protects\n\
    \         passwords by hiding their encrypted values from unprivileged\n     \
    \    users.  This prevents an attacker from copying your password\n         file\
    \ to his or her machine and then attempting to break the\n         passwords at\
    \ his or her leisure.\n         Keep track of who has access to privileged user\
    \ accounts (e.g.,\n         \"root\" on UNIX or \"MAINT\" on VMS).  Whenever a\
    \ privileged user\n         leaves the organization or no longer has need of the\
    \ privileged\n         account, the passwords on all privileged accounts should\
    \ be\n         changed.\n      3.8.2.2  Configuration Management Procedures\n\
    \         When installing a system from the distribution media or when\n     \
    \    installing third-party software, it is important to check the\n         installation\
    \ carefully.  Many installation procedures assume a\n         \"trusted\" site,\
    \ and hence will install files with world write\n         permission enabled,\
    \ or otherwise compromise the security of\n         files.\n         Network services\
    \ should also be examined carefully when first\n         installed.  Many vendors\
    \ provide default network permission\n         files which imply that all outside\
    \ hosts are to be \"trusted\",\n         which is rarely the case when connected\
    \ to wide-area networks\n         such as the Internet.\n         Many intruders\
    \ collect information on the vulnerabilities of\n         particular system versions.\
    \  The older a system, the more\n         likely it is that there are security\
    \ problems in that version\n         which have since been fixed by the vendor\
    \ in a later release.\n         For this reason, it is important to weigh the\
    \ risks of not\n         upgrading to a new operating system release (thus leaving\n\
    \         security holes unplugged) against the cost of upgrading to the\n   \
    \      new software (possibly breaking third-party software, etc.).\n        \
    \ Bug fixes from the vendor should be weighed in a similar\n         fashion,\
    \ with the added note that \"security\" fixes from a\n         vendor usually\
    \ address fairly serious security problems.\n         Other bug fixes, received\
    \ via network mailing lists and the\n         like, should usually be installed,\
    \ but not without careful\n         examination.  Never install a bug fix unless\
    \ you're sure you\n         know what the consequences of the fix are - there's\
    \ always the\n         possibility that an intruder has suggested a \"fix\" which\n\
    \         actually gives him or her access to your system.\n      3.8.2.3  Recovery\
    \ Procedures - Backups\n         It is impossible to overemphasize the need for\
    \ a good backup\n         strategy.  File system backups not only protect you\
    \ in the\n         event of hardware failure or accidental deletions, but they\n\
    \         also protect you against unauthorized changes made by an\n         intruder.\
    \  Without a copy of your data the way it's \"supposed\"\n         to be, it can\
    \ be difficult to undo something an attacker has\n         done.\n         Backups,\
    \ especially if run daily, can also be useful in\n         providing a history\
    \ of an intruder's activities.  Looking\n         through old backups can establish\
    \ when your system was first\n         penetrated.  Intruders may leave files\
    \ around which, although\n         deleted later, are captured on the backup tapes.\
    \  Backups can\n         also be used to document an intruder's activities to\
    \ law\n         enforcement agencies if necessary.\n         A good backup strategy\
    \ will dump the entire system to tape at\n         least once a month.  Partial\
    \ (or \"incremental\") dumps should be\n         done at least twice a week, and\
    \ ideally they should be done\n         daily.  Commands specifically designed\
    \ for performing file\n         system backups (e.g., UNIX \"dump\" or VMS \"\
    BACKUP\") should be\n         used in preference to other file copying commands,\
    \ since these\n         tools are designed with the express intent of restoring\
    \ a\n         system to a known state.\n      3.8.2.4  Problem Reporting Procedures\n\
    \         As with users, system administrators should have a defined\n       \
    \  procedure for reporting security problems.  In large\n         installations,\
    \ this is often done by creating an electronic\n         mail alias which contains\
    \ the names of all system\n         administrators in the organization.  Other\
    \ methods include\n         setting up some sort of response team similar to the\
    \ CERT, or\n         establishing a \"hotline\" serviced by an existing support\
    \ group.\n"
- title: 3.9  Resources to Prevent Security Breaches
  contents:
  - "3.9  Resources to Prevent Security Breaches\n   This section discusses software,\
    \ hardware, and procedural resources\n   that can be used to support your site\
    \ security policy.\n   3.9.1  Network Connections and Firewalls\n      A \"firewall\"\
    \ is put in place in a building to provide a point of\n      resistance to the\
    \ entry of flames into another area.  Similarly, a\n      secretary's desk and\
    \ reception area provides a point of\n      controlling access to other office\
    \ spaces.  This same technique\n      can be applied to a computer site, particularly\
    \ as it pertains to\n      network connections.\n      Some sites will be connected\
    \ only to other sites within the same\n      organization and will not have the\
    \ ability to connect to other\n      networks.  Sites such as these are less susceptible\
    \ to threats\n      from outside their own organization, although intrusions may\
    \ still\n      occur via paths such as dial-up modems.  On the other hand, many\n\
    \      other organizations will be connected to other sites via much\n      larger\
    \ networks, such as the Internet.  These sites are\n      susceptible to the entire\
    \ range of threats associated with a\n      networked environment.\n      The\
    \ risks of connecting to outside networks must be weighed\n      against the benefits.\
    \  It may be desirable to limit connection to\n      outside networks to those\
    \ hosts which do not store sensitive\n      material, keeping \"vital\" machines\
    \ (such as those which maintain\n      company payroll or inventory systems) isolated.\
    \  If there is a\n      need to participate in a Wide Area Network (WAN), consider\n\
    \      restricting all access to your local network through a single\n      system.\
    \  That is, all access to or from your own local network\n      must be made through\
    \ a single host computer that acts as a\n      firewall between you and the outside\
    \ world.  This firewall system\n      should be rigorously controlled and password\
    \ protected, and\n      external users accessing it should also be constrained\
    \ by\n      restricting the functionality available to remote users.  By using\n\
    \      this approach, your site could relax some of the internal security\n  \
    \    controls on your local net, but still be afforded the protection\n      of\
    \ a rigorously controlled host front end.\n      Note that even with a firewall\
    \ system, compromise of the firewall\n      could result in compromise of the\
    \ network behind the firewall.\n      Work has been done in some areas to construct\
    \ a firewall which\n      even when compromised, still protects the local network\
    \ [6,\n      CHESWICK].\n   3.9.2  Confidentiality\n      Confidentiality, the\
    \ act of keeping things hidden or secret, is\n      one of the primary goals of\
    \ computer security practitioners.\n      Several mechanisms are provided by most\
    \ modern operating systems\n      to enable users to control the dissemination\
    \ of information.\n      Depending upon where you work, you may have a site where\n\
    \      everything is protected, or a site where all information is\n      usually\
    \ regarded as public, or something in-between.  Most sites\n      lean toward\
    \ the in-between, at least until some penetration has\n      occurred.\n     \
    \ Generally, there are three instances in which information is\n      vulnerable\
    \ to disclosure: when the information is stored on a\n      computer system, when\
    \ the information is in transit to another\n      system (on the network), and\
    \ when the information is stored on\n      backup tapes.\n      The first of these\
    \ cases is controlled by file permissions, access\n      control lists, and other\
    \ similar mechanisms.  The last can be\n      controlled by restricting access\
    \ to the backup tapes (by locking\n      them in a safe, for example).  All three\
    \ cases can be helped by\n      using encryption mechanisms.\n      3.9.2.1  Encryption\
    \ (hardware and software)\n         Encryption is the process of taking information\
    \ that exists in\n         some readable form and converting it into a non-readable\
    \ form.\n         There are several types of commercially available encryption\n\
    \         packages in both hardware and software forms.  Hardware\n         encryption\
    \ engines have the advantage that they are much faster\n         than the software\
    \ equivalent, yet because they are faster, they\n         are of greater potential\
    \ benefit to an attacker who wants to\n         execute a brute-force attack on\
    \ your encrypted information.\n         The advantage of using encryption is that,\
    \ even if other access\n         control mechanisms (passwords, file permissions,\
    \ etc.) are\n         compromised by an intruder, the data is still unusable.\n\
    \         Naturally, encryption keys and the like should be protected at\n   \
    \      least as well as account passwords.\n         Information in transit (over\
    \ a network) may be vulnerable to\n         interception as well.  Several solutions\
    \ to this exist, ranging\n         from simply encrypting files before transferring\
    \ them (end-to-\n         end encryption) to special network hardware which encrypts\n\
    \         everything it sends without user intervention (secure links).\n    \
    \     The Internet as a whole does not use secure links, thus end-\n         to-end\
    \ encryption must be used if encryption is desired across\n         the Internet.\n\
    \         3.9.2.1.1  Data Encryption Standard (DES)\n            DES is perhaps\
    \ the most widely used data encryption\n            mechanism today.  Many hardware\
    \ and software implementations\n            exist, and some commercial computers\
    \ are provided with a\n            software version.  DES transforms plain text\
    \ information\n            into encrypted data (or ciphertext) by means of a special\n\
    \            algorithm and \"seed\" value called a key.  So long as the key\n\
    \            is retained (or remembered) by the original user, the\n         \
    \   ciphertext can be restored to the original plain text.\n            One of\
    \ the pitfalls of all encryption systems is the need to\n            remember\
    \ the key under which a thing was encrypted (this is\n            not unlike the\
    \ password problem discussed elsewhere in this\n            document).  If the\
    \ key is written down, it becomes less\n            secure.  If forgotten, there\
    \ is little (if any) hope of\n            recovering the original data.\n    \
    \        Most UNIX systems provide a DES command that enables a user\n       \
    \     to encrypt data using the DES algorithm.\n         3.9.2.1.2  Crypt\n  \
    \          Similar to the DES command, the UNIX \"crypt\" command allows\n   \
    \         a user to encrypt data.  Unfortunately, the algorithm used\n       \
    \     by \"crypt\" is very insecure (based on the World War II\n            \"\
    Enigma\" device), and files encrypted with this command can\n            be decrypted\
    \ easily in a matter of a few hours.  Generally,\n            use of the \"crypt\"\
    \ command should be avoided for any but the\n            most trivial encryption\
    \ tasks.\n      3.9.2.2  Privacy Enhanced Mail\n         Electronic mail normally\
    \ transits the network in the clear\n         (i.e., anyone can read it).  This\
    \ is obviously not the optimal\n         solution.  Privacy enhanced mail provides\
    \ a means to\n         automatically encrypt electronic mail messages so that\
    \ a person\n         eavesdropping at a mail distribution node is not (easily)\n\
    \         capable of reading them.  Several privacy enhanced mail\n         packages\
    \ are currently being developed and deployed on the\n         Internet.\n    \
    \     The Internet Activities Board Privacy Task Force has defined a\n       \
    \  draft standard, elective protocol for use in implementing\n         privacy\
    \ enhanced mail.  This protocol is defined in RFCs 1113,\n         1114, and 1115\
    \ [7,8,9].  Please refer to the current edition of\n         the \"IAB Official\
    \ Protocol Standards\" (currently, RFC 1200\n         [21]) for the standardization\
    \ state and status of these\n         protocols.\n   3.9.3  Origin Authentication\n\
    \      We mostly take it on faith that the header of an electronic mail\n    \
    \  message truly indicates the originator of a message.  However, it\n      iseasy\
    \ to \"spoof\", or forge the source of a mail message.  Origin\n      authentication\
    \ provides a means to be certain of the originator of\n      a message or other\
    \ object in the same way that a Notary Public\n      assures a signature on a\
    \ legal document.  This is done by means of\n      a \"Public Key\" cryptosystem.\n\
    \      A public key cryptosystem differs from a private key cryptosystem\n   \
    \   in several ways.  First, a public key system uses two keys, a\n      Public\
    \ Key that anyone can use (hence the name) and a Private Key\n      that only\
    \ the originator of a message uses.  The originator uses\n      the private key\
    \ to encrypt the message (as in DES).  The receiver,\n      who has obtained the\
    \ public key for the originator, may then\n      decrypt the message.\n      In\
    \ this scheme, the public key is used to authenticate the\n      originator's\
    \ use of his or her private key, and hence the identity\n      of the originator\
    \ is more rigorously proven.  The most widely\n      known implementation of a\
    \ public key cryptosystem is the RSA\n      system [26].  The Internet standard\
    \ for privacy enhanced mail\n      makes use of the RSA system.\n   3.9.4  Information\
    \ Integrity\n      Information integrity refers to the state of information such\
    \ that\n      it is complete, correct, and unchanged from the last time in which\n\
    \      it was verified to be in an \"integral\" state.  The value of\n      information\
    \ integrity to a site will vary.  For example, it is\n      more important for\
    \ military and government installations to\n      prevent the \"disclosure\" of\
    \ classified information, whether it is\n      right or wrong.  A bank, on the\
    \ other hand, is far more concerned\n      with whether the account information\
    \ maintained for its customers\n      is complete and accurate.\n      Numerous\
    \ computer system mechanisms, as well as procedural\n      controls, have an influence\
    \ on the integrity of system\n      information.  Traditional access control mechanisms\
    \ maintain\n      controls over who can access system information.  These mechanisms\n\
    \      alone are not sufficient in some cases to provide the degree of\n     \
    \ integrity required.  Some other mechanisms are briefly discussed\n      below.\n\
    \      It should be noted that there are other aspects to maintaining\n      system\
    \ integrity besides these mechanisms, such as two-person\n      controls, and\
    \ integrity validation procedures.  These are beyond\n      the scope of this\
    \ document.\n      3.9.4.1  Checksums\n         Easily the simplest mechanism,\
    \ a simple checksum routine can\n         compute a value for a system file and\
    \ compare it with the last\n         known value.  If the two are equal, the file\
    \ is probably\n         unchanged.  If not, the file has been changed by some\
    \ unknown\n         means.\n         Though it is the easiest to implement, the\
    \ checksum scheme\n         suffers from a serious failing in that it is not very\n\
    \         sophisticated and a determined attacker could easily add enough\n  \
    \       characters to the file to eventually obtain the correct value.\n     \
    \    A specific type of checksum, called a CRC checksum, is\n         considerably\
    \ more robust than a simple checksum.  It is only\n         slightly more difficult\
    \ to implement and provides a better\n         degree of catching errors.  It\
    \ too, however, suffers from the\n         possibility of compromise by an attacker.\n\
    \         Checksums may be used to detect the altering of information.\n     \
    \    However, they do not actively guard against changes being made.\n       \
    \  For this, other mechanisms such as access controls and\n         encryption\
    \ should be used.\n      3.9.4.2  Cryptographic Checksums\n         Cryptographic\
    \ checksums (also called cryptosealing) involve\n         breaking a file up into\
    \ smaller chunks, calculating a (CRC)\n         checksum for each chunk, and adding\
    \ the CRCs together.\n         Depending upon the exact algorithm used, this can\
    \ result in a\n         nearly unbreakable method of determining whether a file\
    \ has\n         been changed.  This mechanism suffers from the fact that it is\n\
    \         sometimes computationally intensive and may be prohibitive\n       \
    \  except in cases where the utmost integrity protection is\n         desired.\n\
    \         Another related mechanism, called a one-way hash function (or a\n  \
    \       Manipulation Detection Code (MDC)) can also be used to uniquely\n    \
    \     identify a file.  The idea behind these functions is that no\n         two\
    \ inputs can produce the same output, thus a modified file\n         will not\
    \ have the same hash value.  One-way hash functions can\n         be implemented\
    \ efficiently on a wide variety of systems, making\n         unbreakable integrity\
    \ checks possible.  (Snefru, a one-way hash\n         function available via USENET\
    \ as well as the Internet is just\n         one example of an efficient one-way\
    \ hash function.) [10]\n   3.9.5  Limiting Network Access\n      The dominant\
    \ network protocols in use on the Internet, IP (RFC\n      791) [11], TCP (RFC\
    \ 793) [12], and UDP (RFC 768) [13], carry\n      certain control information\
    \ which can be used to restrict access\n      to certain hosts or networks within\
    \ an organization.\n      The IP packet header contains the network addresses\
    \ of both the\n      sender and recipient of the packet.  Further, the TCP and\
    \ UDP\n      protocols provide the notion of a \"port\", which identifies the\n\
    \      endpoint (usually a network server) of a communications path.  In\n   \
    \   some instances, it may be desirable to deny access to a specific\n      TCP\
    \ or UDP port, or even to certain hosts and networks altogether.\n      3.9.5.1\
    \  Gateway Routing Tables\n         One of the simplest approaches to preventing\
    \ unwanted network\n         connections is to simply remove certain networks\
    \ from a\n         gateway's routing tables.  This makes it \"impossible\" for\
    \ a\n         host to send packets to these networks.  (Most protocols\n     \
    \    require bidirectional packet flow even for unidirectional data\n        \
    \ flow, thus breaking one side of the route is usually\n         sufficient.)\n\
    \         This approach is commonly taken in \"firewall\" systems by\n       \
    \  preventing the firewall from advertising local routes to the\n         outside\
    \ world.  The approach is deficient in that it often\n         prevents \"too\
    \ much\" (e.g., in order to prevent access to one\n         system on the network,\
    \ access to all systems on the network is\n         disabled).\n      3.9.5.2\
    \  Router Packet Filtering\n         Many commercially available gateway systems\
    \ (more correctly\n         called routers) provide the ability to filter packets\
    \ based not\n         only on sources or destinations, but also on source-destination\n\
    \         combinations.  This mechanism can be used to deny access to a\n    \
    \     specific host, network, or subnet from any other host, network,\n      \
    \   or subnet.\n         Gateway systems from some vendors (e.g., cisco Systems)\
    \ support\n         an even more complex scheme, allowing finer control over source\n\
    \         and destination addresses.  Via the use of address masks, one\n    \
    \     can deny access to all but one host on a particular network.\n         The\
    \ cisco Systems also allow packet screening based on IP\n         protocol type\
    \ and TCP or UDP port numbers [14].\n         This can also be circumvented by\
    \ \"source routing\" packets\n         destined for the \"secret\" network.  Source\
    \ routed packets may\n         be filtered out by gateways, but this may restrict\
    \ other\n         legitimate activities, such as diagnosing routing problems.\n\
    \   3.9.6  Authentication Systems\n      Authentication refers to the process\
    \ of proving a claimed identity\n      to the satisfaction of some permission-granting\
    \ authority.\n      Authentication systems are hardware, software, or procedural\n\
    \      mechanisms that enable a user to obtain access to computing\n      resources.\
    \  At the simplest level, the system administrator who\n      adds new user accounts\
    \ to the system is part of the system\n      authentication mechanism.  At the\
    \ other end of the spectrum,\n      fingerprint readers or retinal scanners provide\
    \ a very high-tech\n      solution to establishing a potential user's identity.\
    \  Without\n      establishing and proving a user's identity prior to establishing\
    \ a\n      session, your site's computers are vulnerable to any sort of\n    \
    \  attack.\n      Typically, a user authenticates himself or herself to the system\n\
    \      by entering a password in response to a prompt.\n      Challenge/Response\
    \ mechanisms improve upon passwords by prompting\n      the user for some piece\
    \ of information shared by both the computer\n      and the user (such as mother's\
    \ maiden name, etc.).\n      3.9.6.1  Kerberos\n         Kerberos, named after\
    \ the dog who in mythology is said to stand\n         at the gates of Hades, is\
    \ a collection of software used in a\n         large network to establish a user's\
    \ claimed identity.\n         Developed at the Massachusetts Institute of Technology\
    \ (MIT),\n         it uses a combination of encryption and distributed databases\n\
    \         so that a user at a campus facility can login and start a\n        \
    \ session from any computer located on the campus.  This has\n         clear advantages\
    \ in certain environments where there are a\n         large number of potential\
    \ users who may establish a connection\n         from any one of a large number\
    \ of workstations.  Some vendors\n         are now incorporating Kerberos into\
    \ their systems.\n         It should be noted that while Kerberos makes several\
    \ advances\n         in the area of authentication, some security weaknesses in\
    \ the\n         protocol still remain [15].\n      3.9.6.2  Smart Cards\n    \
    \     Several systems use \"smart cards\" (a small calculator-like\n         device)\
    \ to help authenticate users.  These systems depend on\n         the user having\
    \ an object in their possession.  One such system\n         involves a new password\
    \ procedure that require a user to enter\n         a value obtained from a \"\
    smart card\" when asked for a password\n         by the computer.  Typically,\
    \ the host machine will give the\n         user some piece of information that\
    \ is entered into the\n         keyboard of the smart card.  The smart card will\
    \ display a\n         response which must then be entered into the computer before\n\
    \         the session will be established.  Another such system involves\n   \
    \      a smart card which displays a number which changes over time,\n       \
    \  but which is synchronized with the authentication software on\n         the\
    \ computer.\n         This is a better way of dealing with authentication than\
    \ with\n         the traditional password approach.  On the other hand, some say\n\
    \         it's inconvenient to carry the smart card.  Start-up costs are\n   \
    \      likely to be high as well.\n   3.9.7  Books, Lists, and Informational Sources\n\
    \      There are many good sources for information regarding computer\n      security.\
    \  The annotated bibliography at the end of this document\n      can provide you\
    \ with a good start.  In addition, information can\n      be obtained from a variety\
    \ of other sources, some of which are\n      described in this section.\n    \
    \  3.9.7.1  Security Mailing Lists\n         The UNIX Security mailing list exists\
    \ to notify system\n         administrators of security problems before they become\
    \ common\n         knowledge, and to provide security enhancement information.\
    \  It\n         is a restricted-access list, open only to people who can be\n\
    \         verified as being principal systems people at a site.  Requests\n  \
    \       to join the list must be sent by either the site contact listed\n    \
    \     in the Defense Data Network's Network Information Center's (DDN\n      \
    \   NIC) WHOIS database, or from the \"root\" account on one of the\n        \
    \ major site machines.  You must include the destination address\n         you\
    \ want on the list, an indication of whether you want to be\n         on the mail\
    \ reflector list or receive weekly digests, the\n         electronic mail address\
    \ and voice telephone number of the site\n         contact if it isn't you, and\
    \ the name, address, and telephone\n         number of your organization.  This\
    \ information should be sent\n         to SECURITY-REQUEST@CPD.COM.\n        \
    \ The RISKS digest is a component of the ACM Committee on\n         Computers\
    \ and Public Policy, moderated by Peter G. Neumann.  It\n         is a discussion\
    \ forum on risks to the public in computers and\n         related systems, and\
    \ along with discussing computer security\n         and privacy issues, has discussed\
    \ such subjects as the Stark\n         incident, the shooting down of the Iranian\
    \ airliner in the\n         Persian Gulf (as it relates to the computerized weapons\n\
    \         systems), problems in air and railroad traffic control systems,\n  \
    \       software engineering, and so on.  To join the mailing list,\n        \
    \ send a message to RISKS-REQUEST@CSL.SRI.COM.  This list is also\n         available\
    \ in the USENET newsgroup \"comp.risks\".\n         The VIRUS-L list is a forum\
    \ for the discussion of computer\n         virus experiences, protection software,\
    \ and related topics.\n         The list is open to the public, and is implemented\
    \ as a\n         moderated digest.  Most of the information is related to\n  \
    \       personal computers, although some of it may be applicable to\n       \
    \  larger systems.  To subscribe, send the line:\n            SUB VIRUS-L your\
    \ full name\n         to the address LISTSERV%LEHIIBM1.BITNET@MITVMA.MIT.EDU.\
    \  This\n         list is also available via the USENET newsgroup \"comp.virus\"\
    .\n         The Computer Underground Digest \"is an open forum dedicated to\n\
    \         sharing information among computerists and to the presentation\n   \
    \      and debate of diverse views.\"  While not directly a security\n       \
    \  list, it does contain discussions about privacy and other\n         security\
    \ related topics.  The list can be read on USENET as\n         alt.society.cu-digest,\
    \ or to join the mailing list, send mail\n         to Gordon Myer (TK0JUT2%NIU.bitnet@mitvma.mit.edu).\n\
    \         Submissions may be mailed to: cud@chinacat.unicom.com.\n      3.9.7.2\
    \  Networking Mailing Lists\n         The TCP-IP mailing list is intended to act\
    \ as a discussion\n         forum for developers and maintainers of implementations\
    \ of the\n         TCP/IP protocol suite.  It also discusses network-related\n\
    \         security problems when they involve programs providing network\n   \
    \      services, such as \"Sendmail\".  To join the TCP-IP list, send a\n    \
    \     message to TCP-IP-REQUEST@NISC.SRI.COM.  This list is also\n         available\
    \ in the USENET newsgroup \"comp.protocols.tcp-ip\".\n         SUN-NETS is a discussion\
    \ list for items pertaining to\n         networking on Sun systems.  Much of the\
    \ discussion is related\n         to NFS, NIS (formally Yellow Pages), and name\
    \ servers.  To\n         subscribe, send a message to SUN-NETS-REQUEST@UMIACS.UMD.EDU.\n\
    \         The USENET groups misc.security and alt.security also discuss\n    \
    \     security issues.  misc.security is a moderated group and also\n        \
    \ includes discussions of physical security and locks.\n         alt.security\
    \ is unmoderated.\n      3.9.7.3  Response Teams\n         Several organizations\
    \ have formed special groups of people to\n         deal with computer security\
    \ problems.  These teams collect\n         information about possible security\
    \ holes and disseminate it to\n         the proper people, track intruders, and\
    \ assist in recovery from\n         security violations.  The teams typically\
    \ have both electronic\n         mail distribution lists as well as a special\
    \ telephone number\n         which can be called for information or to report\
    \ a problem.\n         Many of these teams are members of the CERT System, which\
    \ is\n         coordinated by the National Institute of Standards and\n      \
    \   Technology (NIST), and exists to facilitate the exchange of\n         information\
    \ between the various teams.\n         3.9.7.3.1  DARPA Computer Emergency Response\
    \ Team\n            The Computer Emergency Response Team/Coordination Center\n\
    \            (CERT/CC) was established in December 1988 by the Defense\n     \
    \       Advanced Research Projects Agency (DARPA) to address\n            computer\
    \ security concerns of research users of the\n            Internet.  It is operated\
    \ by the Software Engineering\n            Institute (SEI) at Carnegie-Mellon\
    \ University (CMU).  The\n            CERT can immediately confer with experts\
    \ to diagnose and\n            solve security problems, and also establish and\
    \ maintain\n            communications with the affected computer users and\n\
    \            government authorities as appropriate.\n            The CERT/CC serves\
    \ as a clearing house for the\n            identification and repair of security\
    \ vulnerabilities,\n            informal assessments of existing systems, improvement\
    \ of\n            emergency response capability, and both vendor and user\n  \
    \          security awareness.  In addition, the team works with\n           \
    \ vendors of various systems in order to coordinate the fixes\n            for\
    \ security problems.\n            The CERT/CC sends out security advisories to\
    \ the CERT-\n            ADVISORY mailing list whenever appropriate.  They also\n\
    \            operate a 24-hour hotline that can be called to report\n        \
    \    security problems (e.g., someone breaking into your system),\n          \
    \  as well as to obtain current (and accurate) information\n            about\
    \ rumored security problems.\n            To join the CERT-ADVISORY mailing list,\
    \ send a message to\n            CERT@CERT.SEI.CMU.EDU and ask to be added to\
    \ the mailing\n            list.  The material sent to this list also appears\
    \ in the\n            USENET newsgroup \"comp.security.announce\".  Past advisories\n\
    \            are available for anonymous FTP from the host\n            CERT.SEI.CMU.EDU.\
    \  The 24-hour hotline number is (412) 268-\n            7090.\n            The\
    \ CERT/CC also maintains a CERT-TOOLS list to encourage\n            the exchange\
    \ of information on tools and techniques that\n            increase the secure\
    \ operation of Internet systems.  The\n            CERT/CC does not review or\
    \ endorse the tools described on\n            the list.  To subscribe, send a\
    \ message to CERT-TOOLS-\n            REQUEST@CERT.SEI.CMU.EDU and ask to be added\
    \ to the mailing\n            list.\n            The CERT/CC maintains other generally\
    \ useful security\n            information for anonymous FTP from CERT.SEI.CMU.EDU.\
    \  Get\n            the README file for a list of what is available.\n       \
    \     For more information, contact:\n               CERT\n               Software\
    \ Engineering Institute\n               Carnegie Mellon University\n         \
    \      Pittsburgh, PA  15213-3890\n               (412) 268-7090\n           \
    \    cert@cert.sei.cmu.edu.\n         3.9.7.3.2  DDN Security Coordination Center\n\
    \            For DDN users, the Security Coordination Center (SCC) serves\n  \
    \          a function similar to CERT.  The SCC is the DDN's clearing-\n     \
    \       house for host/user security problems and fixes, and works\n         \
    \   with the DDN Network Security Officer.  The SCC also\n            distributes\
    \ the DDN Security Bulletin, which communicates\n            information on network\
    \ and host security exposures, fixes,\n            and concerns to security and\
    \ management personnel at DDN\n            facilities.  It is available online,\
    \ via kermit or anonymous\n            FTP, from the host NIC.DDN.MIL, in SCC:DDN-SECURITY-yy-\n\
    \            nn.TXT (where \"yy\" is the year and \"nn\" is the bulletin\n   \
    \         number).  The SCC provides immediate assistance with DDN-\n        \
    \    related host security problems; call (800) 235-3155 (6:00\n            a.m.\
    \ to 5:00 p.m. Pacific Time) or send email to\n            SCC@NIC.DDN.MIL.  For\
    \ 24 hour coverage, call the MILNET\n            Trouble Desk (800) 451-7413 or\
    \ AUTOVON 231-1713.\n         3.9.7.3.3  NIST Computer Security Resource and Response\
    \ Center\n            The National Institute of Standards and Technology (NIST)\n\
    \            has responsibility within the U.S. Federal Government for\n     \
    \       computer science and technology activities.  NIST has played\n       \
    \     a strong role in organizing the CERT System and is now\n            serving\
    \ as the CERT System Secretariat.  NIST also operates\n            a Computer\
    \ Security Resource and Response Center (CSRC) to\n            provide help and\
    \ information regarding computer security\n            events and incidents, as\
    \ well as to raise awareness about\n            computer security vulnerabilities.\n\
    \            The CSRC team operates a 24-hour hotline, at (301) 975-5200.\n  \
    \          For individuals with access to the Internet, on-line\n            publications\
    \ and computer security information can be\n            obtained via anonymous\
    \ FTP from the host CSRC.NCSL.NIST.GOV\n            (129.6.48.87).  NIST also\
    \ operates a personal computer\n            bulletin board that contains information\
    \ regarding computer\n            viruses as well as other aspects of computer\
    \ security.  To\n            access this board, set your modem to 300/1200/2400\
    \ BPS, 1\n            stop bit, no parity, and 8-bit characters, and call (301)\n\
    \            948-5717.  All users are given full access to the board\n       \
    \     immediately upon registering.\n            NIST has produced several special\
    \ publications related to\n            computer security and computer viruses\
    \ in particular; some\n            of these publications are downloadable.  For\
    \ further\n            information, contact NIST at the following address:\n \
    \              Computer Security Resource and Response Center\n              \
    \ A-216 Technology\n               Gaithersburg, MD 20899\n               Telephone:\
    \ (301) 975-3359\n               Electronic Mail: CSRC@nist.gov\n         3.9.7.3.4\
    \  DOE Computer Incident Advisory Capability (CIAC)\n            CIAC is the Department\
    \ of Energy's (DOE's) Computer Incident\n            Advisory Capability.  CIAC\
    \ is a four-person team of computer\n            scientists from Lawrence Livermore\
    \ National Laboratory\n            (LLNL) charged with the primary responsibility\
    \ of assisting\n            DOE sites faced with computer security incidents (e.g.,\n\
    \            intruder attacks, virus infections, worm attacks, etc.).\n      \
    \      This capability is available to DOE sites on a 24-hour-a-day\n        \
    \    basis.\n            CIAC was formed to provide a centralized response capability\n\
    \            (including technical assistance), to keep sites informed of\n   \
    \         current events, to deal proactively with computer security\n       \
    \     issues, and to maintain liaisons with other response teams\n           \
    \ and agencies.  CIAC's charter is to assist sites (through\n            direct\
    \ technical assistance, providing information, or\n            referring inquiries\
    \ to other technical experts), serve as a\n            clearinghouse for information\
    \ about threats/known\n            incidents/vulnerabilities, develop guidelines\
    \ for incident\n            handling, develop software for responding to\n   \
    \         events/incidents, analyze events and trends, conduct\n            training\
    \ and awareness activities, and alert and advise\n            sites about vulnerabilities\
    \ and potential attacks.\n            CIAC's business hours phone number is (415)\
    \ 422-8193 or FTS\n            532-8193.  CIAC's e-mail address is CIAC@TIGER.LLNL.GOV.\n\
    \         3.9.7.3.5  NASA Ames Computer Network Security Response Team\n     \
    \       The Computer Network Security Response Team (CNSRT) is NASA\n        \
    \    Ames Research Center's local version of the DARPA CERT.\n            Formed\
    \ in August of 1989, the team has a constituency that\n            is primarily\
    \ Ames users, but it is also involved in\n            assisting other NASA Centers\
    \ and federal agencies.  CNSRT\n            maintains liaisons with the DOE's\
    \ CIAC team and the DARPA\n            CERT.  It is also a charter member of the\
    \ CERT System.  The\n            team may be reached by 24 hour pager at (415)\
    \ 694-0571, or\n            by electronic mail to CNSRT@AMES.ARC.NASA.GOV.\n \
    \     3.9.7.4  DDN Management Bulletins\n         The DDN Management Bulletin\
    \ is distributed electronically by\n         the DDN NIC under contract to the\
    \ Defense Communications Agency\n         (DCA).  It is a means of communicating\
    \ official policy,\n         procedures, and other information of concern to management\n\
    \         personnel at DDN facilities.\n         The DDN Security Bulletin is\
    \ distributed electronically by the\n         DDN SCC, also under contract to\
    \ DCA, as a means of\n         communicating information on network and host security\n\
    \         exposures, fixes, and concerns to security and management\n        \
    \ personnel at DDN facilities.\n         Anyone may join the mailing lists for\
    \ these two bulletins by\n         sending a message to NIC@NIC.DDN.MIL and asking\
    \ to be placed on\n         the mailing lists.  These messages are also posted\
    \ to the\n         USENET newsgroup \"ddn.mgt-bulletin\".  For additional\n  \
    \       information, see section 8.7.\n      3.9.7.5  System Administration List\n\
    \         The SYSADM-LIST is a list pertaining exclusively to UNIX system\n  \
    \       administration.  Mail requests to be added to the list to\n         SYSADM-LIST-REQUEST@SYSADMIN.COM.\n\
    \      3.9.7.6  Vendor Specific System Lists\n         The SUN-SPOTS and SUN-MANAGERS\
    \ lists are discussion groups for\n         users and administrators of systems\
    \ supplied by Sun\n         Microsystems.  SUN-SPOTS is a fairly general list,\
    \ discussing\n         everything from hardware configurations to simple UNIX\n\
    \         questions.  To subscribe, send a message to SUN-SPOTS-\n         REQUEST@RICE.EDU.\
    \  This list is also available in the USENET\n         newsgroup \"comp.sys.sun\"\
    .  SUN-MANAGERS is a discussion list\n         for Sun system administrators and\
    \ covers all aspects of Sun\n         system administration.  To subscribe, send\
    \ a message to SUN-\n         MANAGERS-REQUEST@EECS.NWU.EDU.\n         The APOLLO\
    \ list discusses the HP/Apollo system and its\n         software.  To subscribe,\
    \ send a message to APOLLO-\n         REQUEST@UMIX.CC.UMICH.EDU.  APOLLO-L is\
    \ a similar list which\n         can be subscribed to by sending\n           \
    \ SUB APOLLO-L your full name\n         to LISTSERV%UMRVMB.BITNET@VM1.NODAK.EDU.\n\
    \         HPMINI-L pertains to the Hewlett-Packard 9000 series and HP/UX\n   \
    \      operating system.  To subscribe, send\n            SUB HPMINI-L your full\
    \ name\n         to LISTSERV%UAFSYSB.BITNET@VM1.NODAK.EDU.\n         INFO-IBMPC\
    \ discusses IBM PCs and compatibles, as well as MS-\n         DOS.  To subscribe,\
    \ send a note to INFO-IBMPC-REQUEST@WSMR-\n         SIMTEL20.ARMY.MIL.\n     \
    \    There are numerous other mailing lists for nearly every popular\n       \
    \  computer or workstation in use today.  For a complete list,\n         obtain\
    \ the file \"netinfo/interest-groups\" via anonymous FTP\n         from the host\
    \ FTP.NISC.SRI.COM.\n      3.9.7.7  Professional Societies and Journals\n    \
    \     The IEEE Technical Committee on Security & Privacy publishes a\n       \
    \  quarterly magazine, \"CIPHER\".\n            IEEE Computer Society,\n     \
    \       1730 Massachusetts Ave. N.W.\n            Washington, DC  2036-1903\n\
    \         The ACM SigSAC (Special Interest Group on Security, Audit, and\n   \
    \      Controls) publishes a quarterly magazine, \"SIGSAC Review\".\n        \
    \    Association for Computing Machinery\n            11 West 42nd St.\n     \
    \       New York, N.Y.  10036\n         The Information Systems Security Association\
    \ publishes a\n         quarterly magazine called \"ISSA Access\".\n         \
    \   Information Systems Security Association\n            P.O. Box 9457\n    \
    \        Newport Beach, CA  92658\n         \"Computers and Security\" is an \"\
    international journal for the\n         professional involved with computer security,\
    \ audit and\n         control, and data integrity.\"\n            $266/year, 8\
    \ issues (1990)\n            Elsevier Advanced Technology\n            Journal\
    \ Information Center\n            655 Avenue of the Americas\n            New\
    \ York, NY 10010\n         The \"Data Security Letter\" is published \"to help\
    \ data security\n         professionals by providing inside information and knowledgable\n\
    \         analysis of developments in computer and communications\n         security.\"\
    \n            $690/year, 9 issues (1990)\n            Data Security Letter\n \
    \           P.O. Box 1593\n            Palo Alto, CA 94302\n   3.9.8  Problem\
    \ Reporting Tools\n      3.9.8.1  Auditing\n         Auditing is an important\
    \ tool that can be used to enhance the\n         security of your installation.\
    \  Not only does it give you a\n         means of identifying who has accessed\
    \ your system (and may have\n         done something to it) but it also gives\
    \ you an indication of\n         how your system is being used (or abused) by\
    \ authorized users\n         and attackers alike.  In addition, the audit trail\n\
    \         traditionally kept by computer systems can become an invaluable\n  \
    \       piece of evidence should your system be penetrated.\n         3.9.8.1.1\
    \  Verify Security\n            An audit trail shows how the system is being used\
    \ from day\n            to day.  Depending upon how your site audit log is\n \
    \           configured, your log files should show a range of access\n       \
    \     attempts that can show what normal system usage should look\n          \
    \  like.  Deviation from that normal usage could be the result\n            of\
    \ penetration from an outside source using an old or stale\n            user account.\
    \  Observing a deviation in logins, for example,\n            could be your first\
    \ indication that something unusual is\n            happening.\n         3.9.8.1.2\
    \  Verify Software Configurations\n            One of the ruses used by attackers\
    \ to gain access to a\n            system is by the insertion of a so-called Trojan\
    \ Horse\n            program.  A Trojan Horse program can be a program that does\n\
    \            something useful, or merely something interesting.  It\n        \
    \    always does something unexpected, like steal passwords or\n            copy\
    \ files without your knowledge [25].  Imagine a Trojan\n            login program\
    \ that prompts for username and password in the\n            usual way, but also\
    \ writes that information to a special\n            file that the attacker can\
    \ come back and read at will.\n            Imagine a Trojan Editor program that,\
    \ despite the file\n            permissions you have given your files, makes copies\
    \ of\n            everything in your directory space without you knowing about\n\
    \            it.\n            This points out the need for configuration management\
    \ of the\n            software that runs on a system, not as it is being\n   \
    \         developed, but as it is in actual operation.  Techniques for\n     \
    \       doing this range from checking each command every time it is\n       \
    \     executed against some criterion (such as a cryptoseal,\n            described\
    \ above) or merely checking the date and time stamp\n            of the executable.\
    \  Another technique might be to check each\n            command in batch mode\
    \ at midnight.\n      3.9.8.2  Tools\n         COPS is a security tool for system\
    \ administrators that checks\n         for numerous common security problems on\
    \ UNIX systems [27].\n         COPS is a collection of shell scripts and C programs\
    \ that can\n         easily be run on almost any UNIX variant.  Among other things,\n\
    \         it checks the following items and sends the results to the\n       \
    \  system administrator:\n            - Checks \"/dev/kmem\" and other devices\
    \ for world\n              read/writability.\n            - Checks special or\
    \ important files and directories for\n              \"bad\" modes (world writable,\
    \ etc.).\n            - Checks for easily-guessed passwords.\n            - Checks\
    \ for duplicate user ids, invalid fields in the\n              password file,\
    \ etc..\n            - Checks for duplicate group ids, invalid fields in the\n\
    \              group file, etc..\n            - Checks all users' home directories\
    \ and their \".cshrc\",\n              \".login\", \".profile\", and \".rhosts\"\
    \ files for security\n              problems.\n            - Checks all commands\
    \ in the \"/etc/rc\" files and \"cron\"\n              files for world writability.\n\
    \            - Checks for bad \"root\" paths, NFS file systems exported\n    \
    \          to the world, etc..\n            - Includes an expert system that checks\
    \ to see if a given\n              user (usually \"root\") can be compromised,\
    \ given that\n              certain rules are true.\n            - Checks for\
    \ changes in the setuid status of programs on the\n              system.\n   \
    \      The COPS package is available from the \"comp.sources.unix\"\n        \
    \ archive on \"ftp.uu.net\", and also from the UNIX-SW repository\n         on\
    \ the MILNET host \"wsmr-simtel20.army.mil\".\n   3.9.9  Communication Among Administrators\n\
    \      3.9.9.1  Secure Operating Systems\n         The following list of products\
    \ and vendors is adapted from the\n         National Computer Security Center's\
    \ (NCSC) Evaluated Products\n         List.  They represent those companies who\
    \ have either received\n         an evaluation from the NCSC or are in the process\
    \ of a product\n         evaluation.  This list is not complete, but it is\n \
    \        representative of those operating systems and add on components\n   \
    \      available in the commercial marketplace.\n         For a more detailed\
    \ listing of the current products appearing\n         in the NCSC EPL, contact\
    \ the NCSC at:\n            National Computer Security Center\n            9800\
    \ Savage Road\n            Fort George G. Meade, MD  20755-6000\n            (301)\
    \ 859-4458\n                                                  Version    Evaluation\n"
- title: Evaluated Product               Vendor            Evaluated  Class
  contents:
  - 'Evaluated Product               Vendor            Evaluated  Class

    '
- title: '-----------------------------------------------------------------------'
  contents:
  - '-----------------------------------------------------------------------

    '
- title: Secure Communications           Honeywell Information    2.1         A1
  contents:
  - 'Secure Communications           Honeywell Information    2.1         A1

    '
- title: Processor (SCOMP)               Systems, Inc.
  contents:
  - 'Processor (SCOMP)               Systems, Inc.

    '
- title: Multics                         Honeywell Information    MR11.0      B2
  contents:
  - "Multics                         Honeywell Information    MR11.0      B2\n   \
    \                             Systems, Inc.\n"
- title: System V/MLS 1.1.2 on UNIX      AT&T                     1.1.2       B1
  contents:
  - 'System V/MLS 1.1.2 on UNIX      AT&T                     1.1.2       B1

    '
- title: System V 3.1.1 on AT&T 3B2/500and 3B2/600
  contents:
  - 'System V 3.1.1 on AT&T 3B2/500and 3B2/600

    '
- title: OS 1100                         Unisys Corp.             Security    B1
  contents:
  - "OS 1100                         Unisys Corp.             Security    B1\n   \
    \                                                      Release 1\n"
- title: MPE V/E                         Hewlett-Packard Computer G.03.04     C2
  contents:
  - "MPE V/E                         Hewlett-Packard Computer G.03.04     C2\n   \
    \                             Systems Division\n"
- title: AOS/VS on MV/ECLIPSE series     Data General Corp.        7.60       C2
  contents:
  - 'AOS/VS on MV/ECLIPSE series     Data General Corp.        7.60       C2

    '
- title: VM/SP or VM/SP HPO with CMS,    IBM Corp.                    5       C2
  contents:
  - 'VM/SP or VM/SP HPO with CMS,    IBM Corp.                    5       C2

    '
- title: RACF, DIRMAINT, VMTAPE-MS,
  contents:
  - 'RACF, DIRMAINT, VMTAPE-MS,

    '
- title: ISPF
  contents:
  - 'ISPF

    '
- title: MVS/XA with RACF                IBM Corp.                 2.2,2.3    C2
  contents:
  - 'MVS/XA with RACF                IBM Corp.                 2.2,2.3    C2

    '
- title: AX/VMS                          Digital Equipment Corp.      4.3     C2
  contents:
  - 'AX/VMS                          Digital Equipment Corp.      4.3     C2

    '
- title: NOS                             Control Data Corp.         NOS
  contents:
  - "NOS                             Control Data Corp.         NOS\n            \
    \                                               Security  C2\n               \
    \                                        Eval Product\n"
- title: TOP SECRET                      CGA Software Products       3.0/163  C2
  contents:
  - "TOP SECRET                      CGA Software Products       3.0/163  C2\n   \
    \                             Group, Inc.\n"
- title: Access Control Facility 2       SKK, Inc.                    3.1.3   C2
  contents:
  - 'Access Control Facility 2       SKK, Inc.                    3.1.3   C2

    '
- title: UTX/32S                         Gould, Inc. Computer          1.0    C2
  contents:
  - "UTX/32S                         Gould, Inc. Computer          1.0    C2\n   \
    \                             Systems Division\n"
- title: A Series MCP/AS with            Unisys Corp.                  3.7    C2
  contents:
  - 'A Series MCP/AS with            Unisys Corp.                  3.7    C2

    '
- title: InfoGuard Security
  contents:
  - 'InfoGuard Security

    '
- title: Enhancements
  contents:
  - 'Enhancements

    '
- title: Primos                          Prime Computer, Inc.    21.0.1DODC2A C2
  contents:
  - 'Primos                          Prime Computer, Inc.    21.0.1DODC2A C2

    '
- title: Resource Access Control         IBM Corp.                     1.5    C1
  contents:
  - 'Resource Access Control         IBM Corp.                     1.5    C1

    '
- title: Facility (RACF)
  contents:
  - "Facility (RACF)\n                                                  Version  \
    \    Candidate\n"
- title: Candidate Product            Vendor               Evaluated    Class
  contents:
  - 'Candidate Product            Vendor               Evaluated    Class

    '
- title: '-----------------------------------------------------------------------'
  contents:
  - '-----------------------------------------------------------------------

    '
- title: Boeing MLS LAN                  Boeing Aerospace                  A1 M1
  contents:
  - 'Boeing MLS LAN                  Boeing Aerospace                  A1 M1

    '
- title: Trusted XENIX                   Trusted Information
  contents:
  - "Trusted XENIX                   Trusted Information\n                       \
    \         Systems, Inc.                     B2\n"
- title: VSLAN                           VERDIX Corp.                      B2
  contents:
  - 'VSLAN                           VERDIX Corp.                      B2

    '
- title: System V/MLS                    AT&T                              B1
  contents:
  - 'System V/MLS                    AT&T                              B1

    '
- title: VM/SP with RACF                 IBM Corp.              5/1.8.2    C2
  contents:
  - 'VM/SP with RACF                 IBM Corp.              5/1.8.2    C2

    '
- title: Wang SVS/OS with CAP            Wang Laboratories, Inc.  1.0      C2
  contents:
  - "Wang SVS/OS with CAP            Wang Laboratories, Inc.  1.0      C2\n      3.9.9.2\
    \  Obtaining Fixes for Known Problems\n         It goes without saying that computer\
    \ systems have bugs.  Even\n         operating systems, upon which we depend for\
    \ protection of our\n         data, have bugs.  And since there are bugs, things\
    \ can be\n         broken, both maliciously and accidentally.  It is important\n\
    \         that whenever bugs are discovered, a should fix be identified\n    \
    \     and implemented as soon as possible.  This should minimize any\n       \
    \  exposure caused by the bug in the first place.\n         A corollary to the\
    \ bug problem is: from whom do I obtain the\n         fixes?  Most systems have\
    \ some support from the manufacturer or\n         supplier.  Fixes coming from\
    \ that source tend to be implemented\n         quickly after receipt.  Fixes for\
    \ some problems are often\n         posted on the network and are left to the\
    \ system administrators\n         to incorporate as they can.  The problem is\
    \ that one wants to\n         have faith that the fix will close the hole and\
    \ not introduce\n         any others.  We will tend to trust that the manufacturer's\n\
    \         fixes are better than those that are posted on the net.\n      3.9.9.3\
    \  Sun Customer Warning System\n         Sun Microsystems has established a Customer\
    \ Warning System\n         (CWS) for handling security incidents.  This is a formal\n\
    \         process which includes:\n            - Having a well advertised point\
    \ of contact in Sun\n              for reporting security problems.\n        \
    \    - Pro-actively alerting customers of worms, viruses,\n              or other\
    \ security holes that could affect their systems.\n            - Distributing\
    \ the patch (or work-around) as quickly\n              as possible.\n        \
    \ They have created an electronic mail address, SECURITY-\n         ALERT@SUN.COM,\
    \ which will enable customers to report security\n         problems.  A voice-mail\
    \ backup is available at (415) 688-9081.\n         A \"Security Contact\" can\
    \ be designated by each customer site;\n         this person will be contacted\
    \ by Sun in case of any new\n         security problems.  For more information,\
    \ contact your Sun\n         representative.\n      3.9.9.4  Trusted Archive Servers\n\
    \         Several sites on the Internet maintain large repositories of\n     \
    \    public-domain and freely distributable software, and make this\n        \
    \ material available for anonymous FTP.  This section describes\n         some\
    \ of the larger repositories.  Note that none of these\n         servers implements\
    \ secure checksums or anything else\n         guaranteeing the integrity of their\
    \ data.  Thus, the notion of\n         \"trust\" should be taken as a somewhat\
    \ limited definition.\n         3.9.9.4.1  Sun Fixes on UUNET\n            Sun\
    \ Microsystems has contracted with UUNET Communications\n            Services,\
    \ Inc., to make fixes for bugs in Sun software\n            available via anonymous\
    \ FTP.  You can access these fixes by\n            using the \"ftp\" command to\
    \ connect to the host FTP.UU.NET.\n            Then change into the directory\
    \ \"sun-dist/security\", and\n            obtain a directory listing.  The file\
    \ \"README\" contains a\n            brief description of what each file in this\
    \ directory\n            contains, and what is required to install the fix.\n\
    \         3.9.9.4.2  Berkeley Fixes\n            The University of California\
    \ at Berkeley also makes fixes\n            available via anonymous FTP; these\
    \ fixes pertain primarily\n            to the current release of BSD UNIX (currently,\
    \ release 4.3).\n            However, even if you are not running their software,\
    \ these\n            fixes are still important, since many vendors (Sun, DEC,\n\
    \            Sequent, etc.) base their software on the Berkeley releases.\n  \
    \          The Berkeley fixes are available for anonymous FTP from the\n     \
    \       host UCBARPA.BERKELEY.EDU in the directory \"4.3/ucb-fixes\".\n      \
    \      The file \"INDEX\" in this directory describes what each file\n       \
    \     contains.  They are also available from UUNET (see section\n           \
    \ 3.9.9.4.3).\n            Berkeley also distributes new versions of \"sendmail\"\
    \ and\n            \"named\" from this machine.  New versions of these commands\n\
    \            are stored in the \"4.3\" directory, usually in the files\n     \
    \       \"sendmail.tar.Z\" and \"bind.tar.Z\", respectively.\n         3.9.9.4.3\
    \  Simtel-20 and UUNET\n            The two largest general-purpose software repositories\
    \ on the\n            Internet are the hosts WSMR-SIMTEL20.ARMY.MIL and\n    \
    \        FTP.UU.NET.\n            WSMR-SIMTEL20.ARMY.MIL is a TOPS-20 machine\
    \ operated by the\n            U.S. Army at White Sands Missile Range (WSMR),\
    \ New Mexico.\n            The directory \"pd2:<unix-c>\" contains a large amount\
    \ of UNIX\n            software, primarily taken from the \"comp.sources\"\n \
    \           newsgroups.  The directories \"pd1:<msdos>\" and\n            \"pd2:<msdos2>\"\
    \ contains software for IBM PC systems, and\n            \"pd3:<macintosh>\" contains\
    \ software for the Apple Macintosh.\n            FTP.UU.NET is operated by UUNET\
    \ Communications Services,\n            Inc. in Falls Church, Virginia.  This\
    \ company sells Internet\n            and USENET access to sites all over the\
    \ country (and\n            internationally).  The software posted to the following\n\
    \            USENET source newsgroups is stored here, in directories of\n    \
    \        the same name:\n               comp.sources.games\n               comp.sources.misc\n\
    \               comp.sources.sun\n               comp.sources.unix\n         \
    \      comp.sources.x\n            Numerous other distributions, such as all the\
    \ freely\n            distributable Berkeley UNIX source code, Internet Request\n\
    \            for Comments (RFCs), and so on are also stored on this\n        \
    \    system.\n         3.9.9.4.4  Vendors\n            Many vendors make fixes\
    \ for bugs in their software available\n            electronically, either via\
    \ mailing lists or via anonymous\n            FTP.  You should contact your vendor\
    \ to find out if they\n            offer this service, and if so, how to access\
    \ it.  Some\n            vendors that offer these services include Sun Microsystems\n\
    \            (see above), Digital Equipment Corporation (DEC), the\n         \
    \   University of California at Berkeley (see above), and Apple\n            Computer\
    \ [5, CURRY].\n"
- title: 4.  Types of Security Procedures
  contents:
  - '4.  Types of Security Procedures

    '
- title: 4.1  System Security Audits
  contents:
  - "4.1  System Security Audits\n   Most businesses undergo some sort of annual financial\
    \ auditing as a\n   regular part of their business life.  Security audits are\
    \ an\n   important part of running any computing environment.  Part of the\n \
    \  security audit should be a review of any policies that concern system\n   security,\
    \ as well as the mechanisms that are put in place to enforce\n   them.\n   4.1.1\
    \   Organize Scheduled Drills\n      Although not something that would be done\
    \ each day or week,\n      scheduled drills may be conducted to determine if the\
    \ procedures\n      defined are adequate for the threat to be countered.  If your\n\
    \      major threat is one of natural disaster, then a drill would be\n      conducted\
    \ to verify your backup and recovery mechanisms.  On the\n      other hand, if\
    \ your greatest threat is from external intruders\n      attempting to penetrate\
    \ your system, a drill might be conducted to\n      actually try a penetration\
    \ to observe the effect of the policies.\n      Drills are a valuable way to test\
    \ that your policies and\n      procedures are effective.  On the other hand,\
    \ drills can be time-\n      consuming and disruptive to normal operations.  It\
    \ is important to\n      weigh the benefits of the drills against the possible\
    \ time loss\n      which may be associated with them.\n   4.1.2  Test Procedures\n\
    \      If the choice is made to not to use scheduled drills to examine\n     \
    \ your entire security procedure at one time, it is important to\n      test individual\
    \ procedures frequently.  Examine your backup\n      procedure to make sure you\
    \ can recover data from the tapes.  Check\n      log files to be sure that information\
    \ which is supposed to be\n      logged to them is being logged to them, etc..\n\
    \      When a security audit is mandated, great care should be used in\n     \
    \ devising tests of the security policy.  It is important to clearly\n      identify\
    \ what is being tested, how the test will be conducted, and\n      results expected\
    \ from the test.  This should all be documented and\n      included in or as an\
    \ adjunct to the security policy document\n      itself.\n      It is important\
    \ to test all aspects of the security policy, both\n      procedural and automated,\
    \ with a particular emphasis on the\n      automated mechanisms used to enforce\
    \ the policy.  Tests should be\n      defined to ensure a comprehensive examination\
    \ of policy features,\n      that is, if a test is defined to examine the user\
    \ logon process,\n      it should be explicitly stated that both valid and invalid\
    \ user\n      names and passwords will be used to demonstrate proper operation\n\
    \      of the logon program.\n      Keep in mind that there is a limit to the\
    \ reasonableness of tests.\n      The purpose of testing is to ensure confidence\
    \ that the security\n      policy is being correctly enforced, and not to \"prove\"\
    \ the\n      absoluteness of the system or policy.  The goal should be to\n  \
    \    obtain some assurance that the reasonable and credible controls\n      imposed\
    \ by your security policy are adequate.\n"
- title: 4.2  Account Management Procedures
  contents:
  - "4.2  Account Management Procedures\n   Procedures to manage accounts are important\
    \ in preventing\n   unauthorized access to your system.  It is necessary to decide\n\
    \   several things: Who may have an account on the system?  How long may\n   someone\
    \ have an account without renewing his or her request?  How do\n   old accounts\
    \ get removed from the system?  The answers to all these\n   questions should\
    \ be explicitly set out in the policy.\n   In addition to deciding who may use\
    \ a system, it may be important to\n   determine what each user may use the system\
    \ for (is personal use\n   allowed, for example).  If you are connected to an\
    \ outside network,\n   your site or the network management may have rules about\
    \ what the\n   network may be used for.  Therefore, it is important for any security\n\
    \   policy to define an adequate account management procedure for both\n   administrators\
    \ and users.  Typically, the system administrator would\n   be responsible for\
    \ creating and deleting user accounts and generally\n   maintaining overall control\
    \ of system use.  To some degree, account\n   management is also the responsibility\
    \ of each system user in the\n   sense that the user should observe any system\
    \ messages and events\n   that may be indicative of a policy violation.  For example,\
    \ a message\n   at logon that indicates the date and time of the last logon should\
    \ be\n   reported by the user if it indicates an unreasonable time of last\n \
    \  logon.\n"
- title: 4.3  Password Management Procedures
  contents:
  - "4.3  Password Management Procedures\n   A policy on password management may be\
    \ important if your site wishes\n   to enforce secure passwords.  These procedures\
    \ may range from asking\n   or forcing users to change their passwords occasionally\
    \ to actively\n   attempting to break users' passwords and then informing the\
    \ user of\n   how easy it was to do.  Another part of password management policy\n\
    \   covers who may distribute passwords - can users give their passwords\n   to\
    \ other users?\n   Section 2.3 discusses some of the policy issues that need to\
    \ be\n   decided for proper password management.  Regardless of the policies,\n\
    \   password management procedures need to be carefully setup to avoid\n   disclosing\
    \ passwords.  The choice of initial passwords for accounts\n   is critical.  In\
    \ some cases, users may never login to activate an\n   account; thus, the choice\
    \ of the initial password should not be\n   easily guessed.  Default passwords\
    \ should never be assigned to\n   accounts: always create new passwords for each\
    \ user.  If there are\n   any printed lists of passwords, these should be kept\
    \ off-line in\n   secure locations; better yet, don't list passwords.\n   4.3.1\
    \  Password Selection\n      Perhaps the most vulnerable part of any computer\
    \ system is the\n      account password.  Any computer system, no matter how secure\
    \ it is\n      from network or dial-up attack, Trojan horse programs, and so on,\n\
    \      can be fully exploited by an intruder if he or she can gain access\n  \
    \    via a poorly chosen password.  It is important to define a good\n      set\
    \ of rules for password selection, and distribute these rules to\n      all users.\
    \  If possible, the software which sets user passwords\n      should be modified\
    \ to enforce as many of the rules as possible.\n      A sample set of guidelines\
    \ for password selection is shown below:\n         - DON'T use your login name\
    \ in any form (as-is,\n           reversed, capitalized, doubled, etc.).\n   \
    \      - DON'T use your first, middle, or last name in any form.\n         - DON'T\
    \ use your spouse's or child's name.\n         - DON'T use other information easily\
    \ obtained about you.\n           This includes license plate numbers, telephone\
    \ numbers,\n           social security numbers, the make of your automobile,\n\
    \           the name of the street you live on, etc..\n         - DON'T use a\
    \ password of all digits, or all the same\n           letter.\n         - DON'T\
    \ use a word contained in English or foreign\n           language dictionaries,\
    \ spelling lists, or other\n           lists of words.\n         - DON'T use a\
    \ password shorter than six characters.\n         - DO use a password with mixed-case\
    \ alphabetics.\n         - DO use a password with non-alphabetic characters (digits\n\
    \           or punctuation).\n         - DO use a password that is easy to remember,\
    \ so you don't\n           have to write it down.\n         - DO use a password\
    \ that you can type quickly, without\n           having to look at the keyboard.\n\
    \      Methods of selecting a password which adheres to these guidelines\n   \
    \   include:\n         - Choose a line or two from a song or poem, and use the\n\
    \           first letter of each word.\n         - Alternate between one consonant\
    \ and one or two vowels, up\n           to seven or eight characters.  This provides\
    \ nonsense\n           words which are usually pronounceable, and thus easily\n\
    \           remembered.\n         - Choose two short words and concatenate them\
    \ together with\n           a punctuation character between them.\n      Users\
    \ should also be told to change their password periodically,\n      usually every\
    \ three to six months.  This makes sure that an\n      intruder who has guessed\
    \ a password will eventually lose access,\n      as well as invalidating any list\
    \ of passwords he/she may have\n      obtained.  Many systems enable the system\
    \ administrator to force\n      users to change their passwords after an expiration\
    \ period; this\n      software should be enabled if your system supports it [5,\
    \ CURRY].\n      Some systems provide software which forces users to change their\n\
    \      passwords on a regular basis.  Many of these systems also include\n   \
    \   password generators which provide the user with a set of passwords\n     \
    \ to choose from.  The user is not permitted to make up his or her\n      own\
    \ password.  There are arguments both for and against systems\n      such as these.\
    \  On the one hand, by using generated passwords,\n      users are prevented from\
    \ selecting insecure passwords.  On the\n      other hand, unless the generator\
    \ is good at making up easy to\n      remember passwords, users will begin writing\
    \ them down in order to\n      remember them.\n   4.3.2  Procedures for Changing\
    \ Passwords\n      How password changes are handled is important to keeping passwords\n\
    \      secure.  Ideally, users should be able to change their own\n      passwords\
    \ on-line.  (Note that password changing programs are a\n      favorite target\
    \ of intruders.  See section 4.4 on configuration\n      management for further\
    \ information.)\n      However, there are exception cases which must be handled\n\
    \      carefully.  Users may forget passwords and not be able to get onto\n  \
    \    the system.  The standard procedure is to assign the user a new\n      password.\
    \  Care should be taken to make sure that the real person\n      is requesting\
    \ the change and gets the new password.  One common\n      trick used by intruders\
    \ is to call or message to a system\n      administrator and request a new password.\
    \ Some external form of\n      verification should be used before the password\
    \ is assigned.  At\n      some sites, users are required to show up in person\
    \ with ID.\n      There may also be times when many passwords need to be changed.\n\
    \      If a system is compromised by an intruder, the intruder may be\n      able\
    \ to steal a password file and take it off the system.  Under\n      these circumstances,\
    \ one course of action is to change all\n      passwords on the system.  Your\
    \ site should have procedures for how\n      this can be done quickly and efficiently.\
    \  What course you choose\n      may depend on the urgency of the problem.  In\
    \ the case of a known\n      attack with damage, you may choose to forcibly disable\
    \ all\n      accounts and assign users new passwords before they come back onto\n\
    \      the system.  In some places, users are sent a message telling them\n  \
    \    that they should change their passwords, perhaps within a certain\n     \
    \ time period.  If the password isn't changed before the time period\n      expires,\
    \ the account is locked.\n      Users should be aware of what the standard procedure\
    \ is for\n      passwords when a security event has occurred.  One well-known\n\
    \      spoof reported by the Computer Emergency Response Team (CERT)\n      involved\
    \ messages sent to users, supposedly from local system\n      administrators,\
    \ requesting them to immediately change their\n      password to a new value provided\
    \ in the message [24].  These\n      messages were not from the administrators,\
    \ but from intruders\n      trying to steal accounts.  Users should be warned\
    \ to immediately\n      report any suspicious requests such as this to site\n\
    \      administrators.\n"
- title: 4.4  Configuration Management Procedures
  contents:
  - "4.4  Configuration Management Procedures\n   Configuration management is generally\
    \ applied to the software\n   development process.  However, it is certainly applicable\
    \ in a\n   operational sense as well.  Consider that the since many of the\n \
    \  system level programs are intended to enforce the security policy, it\n   is\
    \ important that these be \"known\" as correct.  That is, one should\n   not allow\
    \ system level programs (such as the operating system, etc.)\n   to be changed\
    \ arbitrarily.  At very least, the procedures should\n   state who is authorized\
    \ to make changes to systems, under what\n   circumstances, and how the changes\
    \ should be documented.\n   In some environments, configuration management is\
    \ also desirable as\n   applied to physical configuration of equipment.  Maintaining\
    \ valid\n   and authorized hardware configuration should be given due\n   consideration\
    \ in your security policy.\n   4.4.1  Non-Standard Configurations\n      Occasionally,\
    \ it may be beneficial to have a slightly non-standard\n      configuration in\
    \ order to thwart the \"standard\" attacks used by\n      some intruders.  The\
    \ non-standard parts of the configuration might\n      include different password\
    \ encryption algorithms, different\n      configuration file locations, and rewritten\
    \ or functionally\n      limited system commands.\n      Non-standard configurations,\
    \ however, also have their drawbacks.\n      By changing the \"standard\" system,\
    \ these modifications make\n      software maintenance more difficult by requiring\
    \ extra\n      documentation to be written, software modification after operating\n\
    \      system upgrades, and, usually, someone with special knowledge of\n    \
    \  the changes.\n      Because of the drawbacks of non-standard configurations,\
    \ they are\n      often only used in environments with a \"firewall\" machine\
    \ (see\n      section 3.9.1).  The firewall machine is modified in non-standard\n\
    \      ways since it is susceptible to attack, while internal systems\n      behind\
    \ the firewall are left in their standard configurations.\n"
- title: 5.  Incident Handling
  contents:
  - '5.  Incident Handling

    '
- title: 5.1  Overview
  contents:
  - "5.1  Overview\n   This section of the document will supply some guidance to be\
    \ applied\n   when a computer security event is in progress on a machine, network,\n\
    \   site, or multi-site environment.  The operative philosophy in the\n   event\
    \ of a breach of computer security, whether it be an external\n   intruder attack\
    \ or a disgruntled employee, is to plan for adverse\n   events in advance.  There\
    \ is no substitute for creating contingency\n   plans for the types of events\
    \ described above.\n   Traditional computer security, while quite important in\
    \ the overall\n   site security plan, usually falls heavily on protecting systems\
    \ from\n   attack, and perhaps monitoring systems to detect attacks.  Little\n\
    \   attention is usually paid for how to actually handle the attack when\n   it\
    \ occurs.  The result is that when an attack is in progress, many\n   decisions\
    \ are made in haste and can be damaging to tracking down the\n   source of the\
    \ incident, collecting evidence to be used in prosecution\n   efforts, preparing\
    \ for the recovery of the system, and protecting the\n   valuable data contained\
    \ on the system.\n   5.1.1  Have a Plan to Follow in Case of an Incident\n   \
    \   Part of handling an incident is being prepared to respond before\n      the\
    \ incident occurs.  This includes establishing a suitable level\n      of protections,\
    \ so that if the incident becomes severe, the damage\n      which can occur is\
    \ limited.  Protection includes preparing\n      incident handling guidelines\
    \ or a contingency response plan for\n      your organization or site.  Having\
    \ written plans eliminates much\n      of the ambiguity which occurs during an\
    \ incident, and will lead to\n      a more appropriate and thorough set of responses.\
    \  Second, part of\n      protection is preparing a method of notification, so\
    \ you will know\n      who to call and the relevant phone numbers.  It is important,\
    \ for\n      example, to conduct \"dry runs,\" in which your computer security\n\
    \      personnel, system administrators, and managers simulate handling\n    \
    \  an incident.\n      Learning to respond efficiently to an incident is important\
    \ for\n      numerous reasons.  The most important benefit is directly to human\n\
    \      beings--preventing loss of human life.  Some computing systems are\n  \
    \    life critical systems, systems on which human life depends (e.g.,\n     \
    \ by controlling some aspect of life-support in a hospital or\n      assisting\
    \ air traffic controllers).\n      An important but often overlooked benefit is\
    \ an economic one.\n      Having both technical and managerial personnel respond\
    \ to an\n      incident requires considerable resources, resources which could\
    \ be\n      utilized more profitably if an incident did not require their\n  \
    \    services.  If these personnel are trained to handle an incident\n      efficiently,\
    \ less of their time is required to deal with that\n      incident.\n      A third\
    \ benefit is protecting classified, sensitive, or\n      proprietary information.\
    \  One of the major dangers of a computer\n      security incident is that information\
    \ may be irrecoverable.\n      Efficient incident handling minimizes this danger.\
    \  When\n      classified information is involved, other government regulations\n\
    \      may apply and must be integrated into any plan for incident\n      handling.\n\
    \      A fourth benefit is related to public relations.  News about\n      computer\
    \ security incidents tends to be damaging to an\n      organization's stature\
    \ among current or potential clients.\n      Efficient incident handling minimizes\
    \ the potential for negative\n      exposure.\n      A final benefit of efficient\
    \ incident handling is related to legal\n      issues.  It is possible that in\
    \ the near future organizations may\n      be sued because one of their nodes\
    \ was used to launch a network\n      attack.  In a similar vein, people who develop\
    \ patches or\n      workarounds may be sued if the patches or workarounds are\n\
    \      ineffective, resulting in damage to systems, or if the patches or\n   \
    \   workarounds themselves damage systems.  Knowing about operating\n      system\
    \ vulnerabilities and patterns of attacks and then taking\n      appropriate measures\
    \ is critical to circumventing possible legal\n      problems.\n   5.1.2  Order\
    \ of Discussion in this Session Suggests an Order for\n          a Plan\n    \
    \  This chapter is arranged such that a list may be generated from\n      the\
    \ Table of Contents to provide a starting point for creating a\n      policy for\
    \ handling ongoing incidents.  The main points to be\n      included in a policy\
    \ for handling incidents are:\n         o Overview (what are the goals and objectives\
    \ in handling the\n           incident).\n         o Evaluation (how serious is\
    \ the incident).\n         o Notification (who should be notified about the incident).\n\
    \         o Response (what should the response to the incident be).\n        \
    \ o Legal/Investigative (what are the legal and prosecutorial\n           implications\
    \ of the incident).\n         o Documentation Logs (what records should be kept\
    \ from before,\n           during, and after the incident).\n      Each of these\
    \ points is important in an overall plan for handling\n      incidents.  The remainder\
    \ of this chapter will detail the issues\n      involved in each of these topics,\
    \ and provide some guidance as to\n      what should be included in a site policy\
    \ for handling incidents.\n      5.1.3  Possible Goals and Incentives for Efficient\
    \ Incident\n             Handling\n      As in any set of pre-planned procedures,\
    \ attention must be placed\n      on a set of goals to be obtained in handling\
    \ an incident.  These\n      goals will be placed in order of importance depending\
    \ on the site,\n      but one such set of goals might be:\n         Assure integrity\
    \ of (life) critical systems.\n         Maintain and restore data.\n         Maintain\
    \ and restore service.\n         Figure out how it happened.\n         Avoid escalation\
    \ and further incidents.\n         Avoid negative publicity.\n         Find out\
    \ who did it.\n         Punish the attackers.\n      It is important to prioritize\
    \ actions to be taken during an\n      incident well in advance of the time an\
    \ incident occurs.\n      Sometimes an incident may be so complex that it is impossible\
    \ to\n      do everything at once to respond to it; priorities are essential.\n\
    \      Although priorities will vary from institution-to-institution, the\n  \
    \    following suggested priorities serve as a starting point for\n      defining\
    \ an organization's response:\n         o Priority one -- protect human life and\
    \ people's\n           safety; human life always has precedence over all\n   \
    \        other considerations.\n         o Priority two -- protect classified\
    \ and/or sensitive\n           data (as regulated by your site or by government\n\
    \           regulations).\n         o Priority three -- protect other data, including\n\
    \           proprietary, scientific, managerial and other data,\n           because\
    \ loss of data is costly in terms of resources.\n         o Priority four -- prevent\
    \ damage to systems (e.g., loss\n           or alteration of system files, damage\
    \ to disk drives,\n           etc.); damage to systems can result in costly down\n\
    \           time and recovery.\n         o Priority five -- minimize disruption\
    \ of computing\n           resources; it is better in many cases to shut a system\n\
    \           down or disconnect from a network than to risk damage\n          \
    \ to data or systems.\n      An important implication for defining priorities\
    \ is that once\n      human life and national security considerations have been\n\
    \      addressed, it is generally more important to save data than system\n  \
    \    software and hardware.  Although it is undesirable to have any\n      damage\
    \ or loss during an incident, systems can be replaced; the\n      loss or compromise\
    \ of data (especially classified data), however,\n      is usually not an acceptable\
    \ outcome under any circumstances.\n      Part of handling an incident is being\
    \ prepared to respond before\n      the incident occurs.  This includes establishing\
    \ a suitable level\n      of protections so that if the incident becomes severe,\
    \ the damage\n      which can occur is limited.  Protection includes preparing\n\
    \      incident handling guidelines or a contingency response plan for\n     \
    \ your organization or site.  Written plans eliminate much of the\n      ambiguity\
    \ which occurs during an incident, and will lead to a more\n      appropriate\
    \ and thorough set of responses.  Second, part of\n      protection is preparing\
    \ a method of notification so you will know\n      who to call and how to contact\
    \ them.  For example, every member of\n      the Department of Energy's CIAC Team\
    \ carries a card with every\n      other team member's work and home phone numbers,\
    \ as well as pager\n      numbers.  Third, your organization or site should establish\
    \ backup\n      procedures for every machine and system.  Having backups\n   \
    \   eliminates much of the threat of even a severe incident, since\n      backups\
    \ preclude serious data loss.  Fourth, you should set up\n      secure systems.\
    \  This involves eliminating vulnerabilities,\n      establishing an effective\
    \ password policy, and other procedures,\n      all of which will be explained\
    \ later in this document.  Finally,\n      conducting training activities is part\
    \ of protection.  It is\n      important, for example, to conduct \"dry runs,\"\
    \ in which your\n      computer security personnel, system administrators, and\
    \ managers\n      simulate handling an incident.\n   5.1.4  Local Policies and\
    \ Regulations Providing Guidance\n      Any plan for responding to security incidents\
    \ should be guided by\n      local policies and regulations.  Government and private\
    \ sites that\n      deal with classified material have specific rules that they\
    \ must\n      follow.\n      The policies your site makes about how it responds\
    \ to incidents\n      (as discussed in sections 2.4 and 2.5) will shape your response.\n\
    \      For example, it may make little sense to create mechanisms to\n      monitor\
    \ and trace intruders if your site does not plan to take\n      action against\
    \ the intruders if they are caught.  Other\n      organizations may have policies\
    \ that affect your plans.  Telephone\n      companies often release information\
    \ about telephone traces only to\n      law enforcement agencies.\n      Section\
    \ 5.5 also notes that if any legal action is planned, there\n      are specific\
    \ guidelines that must be followed to make sure that\n      any information collected\
    \ can be used as evidence.\n"
- title: 5.2  Evaluation
  contents:
  - "5.2  Evaluation\n   5.2.1  Is It Real?\n      This stage involves determining\
    \ the exact problem.  Of course\n      many, if not most, signs often associated\
    \ with virus infections,\n      system intrusions, etc., are simply anomalies\
    \ such as hardware\n      failures.  To assist in identifying whether there really\
    \ is an\n      incident, it is usually helpful to obtain and use any detection\n\
    \      software which may be available.  For example, widely available\n     \
    \ software packages can greatly assist someone who thinks there may\n      be\
    \ a virus in a Macintosh computer.  Audit information is also\n      extremely\
    \ useful, especially in determining whether there is a\n      network attack.\
    \  It is extremely important to obtain a system\n      snapshot as soon as one\
    \ suspects that something is wrong.  Many\n      incidents cause a dynamic chain\
    \ of events to occur, and an initial\n      system snapshot may do more good in\
    \ identifying the problem and\n      any source of attack than most other actions\
    \ which can be taken at\n      this stage.  Finally, it is important to start\
    \ a log book.\n      Recording system events, telephone conversations, time stamps,\n\
    \      etc., can lead to a more rapid and systematic identification of\n     \
    \ the problem, and is the basis for subsequent stages of incident\n      handling.\n\
    \      There are certain indications or \"symptoms\" of an incident which\n  \
    \    deserve special attention:\n         o System crashes.\n         o New user\
    \ accounts (e.g., the account RUMPLESTILTSKIN\n           has unexplainedly been\
    \ created), or high activity on\n           an account that has had virtually\
    \ no activity for\n           months.\n         o New files (usually with novel\
    \ or strange file names,\n           such as data.xx or k).\n         o Accounting\
    \ discrepancies (e.g., in a UNIX system you\n           might notice that the\
    \ accounting file called\n           /usr/admin/lastlog has shrunk, something\
    \ that should\n           make you very suspicious that there may be an\n    \
    \       intruder).\n         o Changes in file lengths or dates (e.g., a user\
    \ should\n           be suspicious if he/she observes that the .EXE files in\n\
    \           an MS DOS computer have unexplainedly grown\n           by over 1800\
    \ bytes).\n         o Attempts to write to system (e.g., a system manager\n  \
    \         notices that a privileged user in a VMS system is\n           attempting\
    \ to alter RIGHTSLIST.DAT).\n         o Data modification or deletion (e.g., files\
    \ start to\n           disappear).\n         o Denial of service (e.g., a system\
    \ manager and all\n           other users become locked out of a UNIX system,\
    \ which\n           has been changed to single user mode).\n         o Unexplained,\
    \ poor system performance (e.g., system\n           response time becomes unusually\
    \ slow).\n         o Anomalies (e.g., \"GOTCHA\" is displayed on a display\n \
    \          terminal or there are frequent unexplained \"beeps\").\n         o\
    \ Suspicious probes (e.g., there are numerous\n           unsuccessful login attempts\
    \ from another node).\n         o Suspicious browsing (e.g., someone becomes a\
    \ root user\n           on a UNIX system and accesses file after file in one\n\
    \           user's account, then another's).\n      None of these indications\
    \ is absolute \"proof\" that an incident is\n      occurring, nor are all of these\
    \ indications normally observed when\n      an incident occurs.  If you observe\
    \ any of these indications,\n      however, it is important to suspect that an\
    \ incident might be\n      occurring, and act accordingly.  There is no formula\
    \ for\n      determining with 100 percent accuracy that an incident is\n     \
    \ occurring (possible exception: when a virus detection package\n      indicates\
    \ that your machine has the nVIR virus and you confirm\n      this by examining\
    \ contents of the nVIR resource in your Macintosh\n      computer, you can be\
    \ very certain that your machine is infected).\n      It is best at this point\
    \ to collaborate with other technical and\n      computer security personnel to\
    \ make a decision as a group about\n      whether an incident is occurring.\n\
    \   5.2.2  Scope\n      Along with the identification of the incident is the evaluation\
    \ of\n      the scope and impact of the problem.  It is important to correctly\n\
    \      identify the boundaries of the incident in order to effectively\n     \
    \ deal with it.  In addition, the impact of an incident will\n      determine\
    \ its priority in allocating resources to deal with the\n      event.  Without\
    \ an indication of the scope and impact of the\n      event, it is difficult to\
    \ determine a correct response.\n      In order to identify the scope and impact,\
    \ a set of criteria\n      should be defined which is appropriate to the site\
    \ and to the type\n      of connections available.  Some of the issues are:\n\
    \         o Is this a multi-site incident?\n         o Are many computers at your\
    \ site effected by this\n           incident?\n         o Is sensitive information\
    \ involved?\n         o What is the entry point of the incident (network,\n  \
    \         phone line, local terminal, etc.)?\n         o Is the press involved?\n\
    \         o What is the potential damage of the incident?\n         o What is\
    \ the estimated time to close out the incident?\n         o What resources could\
    \ be required\n           to handle the incident?\n"
- title: 5.3  Possible Types of Notification
  contents:
  - "5.3  Possible Types of Notification\n   When you have confirmed that an incident\
    \ is occurring, the\n   appropriate personnel must be notified.  Who and how this\n\
    \   notification is achieved is very important in keeping the event under\n  \
    \ control both from a technical and emotional standpoint.\n   5.3.1  Explicit\n\
    \      First of all, any notification to either local or off-site\n      personnel\
    \ must be explicit.  This requires that any statement (be\n      it an electronic\
    \ mail message, phone call, or fax) provides\n      information about the incident\
    \ that is clear, concise, and fully\n      qualified.  When you are notifying\
    \ others that will help you to\n      handle an event, a \"smoke screen\" will\
    \ only divide the effort and\n      create confusion.  If a division of labor\
    \ is suggested, it is\n      helpful to provide information to each section about\
    \ what is being\n      accomplished in other efforts.  This will not only reduce\n\
    \      duplication of effort, but allow people working on parts of the\n     \
    \ problem to know where to obtain other information that would help\n      them\
    \ resolve a part of the incident.\n   5.3.2  Factual\n      Another important\
    \ consideration when communicating about the\n      incident is to be factual.\
    \  Attempting to hide aspects of the\n      incident by providing false or incomplete\
    \ information may not only\n      prevent a successful resolution to the incident,\
    \ but may even\n      worsen the situation.  This is especially true when the\
    \ press is\n      involved.  When an incident severe enough to gain press attention\n\
    \      is ongoing, it is likely that any false information you provide\n     \
    \ will not be substantiated by other sources.  This will reflect\n      badly\
    \ on the site and may create enough ill-will between the site\n      and the press\
    \ to damage the site's public relations.\n   5.3.3  Choice of Language\n     \
    \ The choice of language used when notifying people about the\n      incident\
    \ can have a profound effect on the way that information is\n      received. \
    \ When you use emotional or inflammatory terms, you raise\n      the expectations\
    \ of damage and negative outcomes of the incident.\n      It is important to remain\
    \ calm both in written and spoken\n      notifications.\n      Another issue associated\
    \ with the choice of language is the\n      notification to non-technical or off-site\
    \ personnel.  It is\n      important to accurately describe the incident without\
    \ undue alarm\n      or confusing messages.  While it is more difficult to describe\
    \ the\n      incident to a non-technical audience, it is often more important.\n\
    \      A non-technical description may be required for upper-level\n      management,\
    \ the press, or law enforcement liaisons.  The\n      importance of these notifications\
    \ cannot be underestimated and may\n      make the difference between handling\
    \ the incident properly and\n      escalating to some higher level of damage.\n\
    \   5.3.4  Notification of Individuals\n         o Point of Contact (POC) people\
    \ (Technical, Administrative,\n           Response Teams, Investigative, Legal,\
    \ Vendors, Service\n           providers), and which POCs are visible to whom.\n\
    \         o Wider community (users).\n         o Other sites that might be affected.\n\
    \      Finally, there is the question of who should be notified during\n     \
    \ and after the incident.  There are several classes of individuals\n      that\
    \ need to be considered for notification.  These are the\n      technical personnel,\
    \ administration, appropriate response teams\n      (such as CERT or CIAC), law\
    \ enforcement, vendors, and other\n      service providers.  These issues are\
    \ important for the central\n      point of contact, since that is the person\
    \ responsible for the\n      actual notification of others (see section 5.3.6\
    \ for further\n      information).  A list of people in each of these categories\
    \ is an\n      important time saver for the POC during an incident.  It is much\n\
    \      more difficult to find an appropriate person during an incident\n     \
    \ when many urgent events are ongoing.\n      In addition to the people responsible\
    \ for handling part of the\n      incident, there may be other sites affected\
    \ by the incident (or\n      perhaps simply at risk from the incident).  A wider\
    \ community of\n      users may also benefit from knowledge of the incident. \
    \ Often, a\n      report of the incident once it is closed out is appropriate\
    \ for\n      publication to the wider user community.\n   5.3.5  Public Relations\
    \ - Press Releases\n      One of the most important issues to consider is when,\
    \ who, and how\n      much to release to the general public through the press.\
    \  There\n      are many issues to consider when deciding this particular issue.\n\
    \      First and foremost, if a public relations office exists for the\n     \
    \ site, it is important to use this office as liaison to the press.\n      The\
    \ public relations office is trained in the type and wording of\n      information\
    \ released, and will help to assure that the image of\n      the site is protected\
    \ during and after the incident (if possible).\n      A public relations office\
    \ has the advantage that you can\n      communicate candidly with them, and provide\
    \ a buffer between the\n      constant press attention and the need of the POC\
    \ to maintain\n      control over the incident.\n      If a public relations office\
    \ is not available, the information\n      released to the press must be carefully\
    \ considered.  If the\n      information is sensitive, it may be advantageous\
    \ to provide only\n      minimal or overview information to the press.  It is\
    \ quite\n      possible that any information provided to the press will be\n \
    \     quickly reviewed by the perpetrator of the incident.  As a\n      contrast\
    \ to this consideration, it was discussed above that\n      misleading the press\
    \ can often backfire and cause more damage than\n      releasing sensitive information.\n\
    \      While it is difficult to determine in advance what level of detail\n  \
    \    to provide to the press, some guidelines to keep in mind are:\n         o\
    \ Keep the technical level of detail low.  Detailed\n           information about\
    \ the incident may provide enough\n           information for copy-cat events\
    \ or even damage the\n           site's ability to prosecute once the event is\
    \ over.\n         o Keep the speculation out of press statements.\n          \
    \ Speculation of who is causing the incident or the\n           motives are very\
    \ likely to be in error and may cause\n           an inflamed view of the incident.\n\
    \         o Work with law enforcement professionals to assure that\n         \
    \  evidence is protected.  If prosecution is involved,\n           assure that\
    \ the evidence collected is not divulged to\n           the press.\n         o\
    \ Try not to be forced into a press interview before you are\n           prepared.\
    \  The popular press is famous for the \"2am\"\n           interview, where the\
    \ hope is to catch the interviewee off\n           guard and obtain information\
    \ otherwise not available.\n         o Do not allow the press attention to detract\
    \ from the\n           handling of the event.  Always remember that the successful\n\
    \           closure of an incident is of primary importance.\n   5.3.6  Who Needs\
    \ to Get Involved?\n      There now exists a number of incident response teams\
    \ (IRTs) such\n      as the CERT and the CIAC. (See sections 3.9.7.3.1 and 3.9.7.3.4.)\n\
    \      Teams exists for many major government agencies and large\n      corporations.\
    \  If such a team is available for your site, the\n      notification of this\
    \ team should be of primary importance during\n      the early stages of an incident.\
    \  These teams are responsible for\n      coordinating computer security incidents\
    \ over a range of sites and\n      larger entities.  Even if the incident is believed\
    \ to be contained\n      to a single site, it is possible that the information\
    \ available\n      through a response team could help in closing out the incident.\n\
    \      In setting up a site policy for incident handling, it may be\n      desirable\
    \ to create an incident handling team (IHT), much like\n      those teams that\
    \ already exist, that will be responsible for\n      handling computer security\
    \ incidents for the site (or\n      organization).  If such a team is created,\
    \ it is essential that\n      communication lines be opened between this team\
    \ and other IHTs.\n      Once an incident is under way, it is difficult to open\
    \ a trusted\n      dialogue between other IHTs if none has existed before.\n"
- title: 5.4  Response
  contents:
  - "5.4  Response\n   A major topic still untouched here is how to actually respond\
    \ to an\n   event.  The response to an event will fall into the general\n   categories\
    \ of containment, eradication, recovery, and follow-up.\n   Containment\n    \
    \  The purpose of containment is to limit the extent of an attack.\n      For\
    \ example, it is important to limit the spread of a worm attack\n      on a network\
    \ as quickly as possible.  An essential part of\n      containment is decision\
    \ making (i.e., determining whether to shut\n      a system down, to disconnect\
    \ from a network, to monitor system or\n      network activity, to set traps,\
    \ to disable functions such as\n      remote file transfer on a UNIX system, etc.).\
    \  Sometimes this\n      decision is trivial; shut the system down if the system\
    \ is\n      classified or sensitive, or if proprietary information is at risk!\n\
    \      In other cases, it is worthwhile to risk having some damage to the\n  \
    \    system if keeping the system up might enable you to identify an\n      intruder.\n\
    \      The third stage, containment, should involve carrying out\n      predetermined\
    \ procedures.  Your organization or site should, for\n      example, define acceptable\
    \ risks in dealing with an incident, and\n      should prescribe specific actions\
    \ and strategies accordingly.\n      Finally, notification of cognizant authorities\
    \ should occur during\n      this stage.\n   Eradication\n      Once an incident\
    \ has been detected, it is important to first think\n      about containing the\
    \ incident.  Once the incident has been\n      contained, it is now time to eradicate\
    \ the cause.  Software may be\n      available to help you in this effort.  For\
    \ example, eradication\n      software is available to eliminate most viruses\
    \ which infect small\n      systems.  If any bogus files have been created, it\
    \ is time to\n      delete them at this point.  In the case of virus infections,\
    \ it is\n      important to clean and reformat any disks containing infected\n\
    \      files.  Finally, ensure that all backups are clean.  Many systems\n   \
    \   infected with viruses become periodically reinfected simply\n      because\
    \ people do not systematically eradicate the virus from\n      backups.\n   Recovery\n\
    \      Once the cause of an incident has been eradicated, the recovery\n     \
    \ phase defines the next stage of action.  The goal of recovery is\n      to return\
    \ the system to normal.  In the case of a network-based\n      attack, it is important\
    \ to install patches for any operating\n      system vulnerability which was exploited.\n\
    \   Follow-up\n      One of the most important stages of responding to incidents\
    \ is\n      also the most often omitted---the follow-up stage.  This stage is\n\
    \      important because it helps those involved in handling the incident\n  \
    \    develop a set of \"lessons learned\" (see section 6.3) to improve\n     \
    \ future performance in such situations.  This stage also provides\n      information\
    \ which justifies an organization's computer security\n      effort to management,\
    \ and yields information which may be\n      essential in legal proceedings.\n\
    \      The most important element of the follow-up stage is performing a\n   \
    \   postmortem analysis.  Exactly what happened, and at what times?\n      How\
    \ well did the staff involved with the incident perform?  What\n      kind of\
    \ information did the staff need quickly, and how could they\n      have gotten\
    \ that information as soon as possible?  What would the\n      staff do differently\
    \ next time?  A follow-up report is valuable\n      because it provides a reference\
    \ to be used in case of other\n      similar incidents.  Creating a formal chronology\
    \ of events\n      (including time stamps) is also important for legal reasons.\n\
    \      Similarly, it is also important to as quickly obtain a monetary\n     \
    \ estimate of the amount of damage the incident caused in terms of\n      any\
    \ loss of software and files, hardware damage, and manpower\n      costs to restore\
    \ altered files, reconfigure affected systems, and\n      so forth.  This estimate\
    \ may become the basis for subsequent\n      prosecution activity by the FBI,\
    \ the U.S. Attorney General's\n      Office, etc..\n   5.4.1  What Will You Do?\n\
    \      o Restore control.\n      o Relation to policy.\n      o Which level of\
    \ service is needed?\n      o Monitor activity.\n      o Constrain or shut down\
    \ system.\n   5.4.2  Consider Designating a \"Single Point of Contact\"\n    \
    \  When an incident is under way, a major issue is deciding who is in\n      charge\
    \ of coordinating the activity of the multitude of players.\n      A major mistake\
    \ that can be made is to have a number of \"points of\n      contact\" (POC) that\
    \ are not pulling their efforts together.  This\n      will only add to the confusion\
    \ of the event, and will probably\n      lead to additional confusion and wasted\
    \ or ineffective effort.\n      The single point of contact may or may not be\
    \ the person \"in\n      charge\" of the incident.  There are two distinct rolls\
    \ to fill\n      when deciding who shall be the point of contact and the person\
    \ in\n      charge of the incident.  The person in charge will make decisions\n\
    \      as to the interpretation of policy applied to the event.  The\n      responsibility\
    \ for the handling of the event falls onto this\n      person.  In contrast, the\
    \ point of contact must coordinate the\n      effort of all the parties involved\
    \ with handling the event.\n      The point of contact must be a person with the\
    \ technical expertise\n      to successfully coordinate the effort of the system\
    \ managers and\n      users involved in monitoring and reacting to the attack.\
    \  Often\n      the management structure of a site is such that the administrator\n\
    \      of a set of resources is not a technically competent person with\n    \
    \  regard to handling the details of the operations of the computers,\n      but\
    \ is ultimately responsible for the use of these resources.\n      Another important\
    \ function of the POC is to maintain contact with\n      law enforcement and other\
    \ external agencies (such as the CIA, DoD,\n      U.S.  Army, or others) to assure\
    \ that multi-agency involvement\n      occurs.\n      Finally, if legal action\
    \ in the form of prosecution is involved,\n      the POC may be able to speak\
    \ for the site in court.  The\n      alternative is to have multiple witnesses\
    \ that will be hard to\n      coordinate in a legal sense, and will weaken any\
    \ case against the\n      attackers.  A single POC may also be the single person\
    \ in charge\n      of evidence collected, which will keep the number of people\n\
    \      accounting for evidence to a minimum.  As a rule of thumb, the\n      more\
    \ people that touch a potential piece of evidence, the greater\n      the possibility\
    \ that it will be inadmissible in court.  The\n      section below (Legal/Investigative)\
    \ will provide more details for\n      consideration on this topic.\n"
- title: 5.5  Legal/Investigative
  contents:
  - "5.5  Legal/Investigative\n   5.5.1  Establishing Contacts with Investigative\
    \ Agencies\n      It is important to establish contacts with personnel from\n\
    \      investigative agencies such as the FBI and Secret Service as soon\n   \
    \   as possible, for several reasons.  Local law enforcement and local\n     \
    \ security offices or campus police organizations should also be\n      informed\
    \ when appropriate.  A primary reason is that once a major\n      attack is in\
    \ progress, there is little time to call various\n      personnel in these agencies\
    \ to determine exactly who the correct\n      point of contact is.  Another reason\
    \ is that it is important to\n      cooperate with these agencies in a manner\
    \ that will foster a good\n      working relationship, and that will be in accordance\
    \ with the\n      working procedures of these agencies.  Knowing the working\n\
    \      procedures in advance and the expectations of your point of\n      contact\
    \ is a big step in this direction.  For example, it is\n      important to gather\
    \ evidence that will be admissible in a court of\n      law.  If you don't know\
    \ in advance how to gather admissible\n      evidence, your efforts to collect\
    \ evidence during an incident are\n      likely to be of no value to the investigative\
    \ agency with which\n      you deal.  A final reason for establishing contacts\
    \ as soon as\n      possible is that it is impossible to know the particular agency\n\
    \      that will assume jurisdiction in any given incident.  Making\n      contacts\
    \ and finding the proper channels early will make\n      responding to an incident\
    \ go considerably more smoothly.\n      If your organization or site has a legal\
    \ counsel, you need to\n      notify this office soon after you learn that an\
    \ incident is in\n      progress.  At a minimum, your legal counsel needs to be\
    \ involved\n      to protect the legal and financial interests of your site or\n\
    \      organization.  There are many legal and practical issues, a few of\n  \
    \    which are:\n         1. Whether your site or organization is willing to risk\n\
    \            negative publicity or exposure to cooperate with legal\n        \
    \    prosecution efforts.\n         2. Downstream liability--if you leave a compromised\
    \ system\n            as is so it can be monitored and another computer is damaged\n\
    \            because the attack originated from your system, your site or\n  \
    \          organization may be liable for damages incurred.\n         3. Distribution\
    \ of information--if your site or organization\n            distributes information\
    \ about an attack in which another\n            site or organization may be involved\
    \ or the vulnerability\n            in a product that may affect ability to market\
    \ that\n            product, your site or organization may again be liable\n \
    \           for any damages (including damage of reputation).\n         4. Liabilities\
    \ due to monitoring--your site or organization\n            may be sued if users\
    \ at your site or elsewhere discover\n            that your site is monitoring\
    \ account activity without\n            informing users.\n      Unfortunately,\
    \ there are no clear precedents yet on the\n      liabilities or responsibilities\
    \ of organizations involved in a\n      security incident or who might be involved\
    \ in supporting an\n      investigative effort.  Investigators will often encourage\n\
    \      organizations to help trace and monitor intruders -- indeed, most\n   \
    \   investigators cannot pursue computer intrusions without extensive\n      support\
    \ from the organizations involved.  However, investigators\n      cannot provide\
    \ protection from liability claims, and these kinds\n      of efforts may drag\
    \ out for months and may take lots of effort.\n      On the other side, an organization's\
    \ legal council may advise\n      extreme caution and suggest that tracing activities\
    \ be halted and\n      an intruder shut out of the system.  This in itself may\
    \ not\n      provide protection from liability, and may prevent investigators\n\
    \      from identifying anyone.\n      The balance between supporting investigative\
    \ activity and limiting\n      liability is tricky; you'll need to consider the\
    \ advice of your\n      council and the damage the intruder is causing (if any)\
    \ in making\n      your decision about what to do during any particular incident.\n\
    \      Your legal counsel should also be involved in any decision to\n      contact\
    \ investigative agencies when an incident occurs at your\n      site.  The decision\
    \ to coordinate efforts with investigative\n      agencies is most properly that\
    \ of your site or organization.\n      Involving your legal counsel will also\
    \ foster the multi-level\n      coordination between your site and the particular\
    \ investigative\n      agency involved which in turn results in an efficient division\
    \ of\n      labor.  Another result is that you are likely to obtain guidance\n\
    \      that will help you avoid future legal mistakes.\n      Finally, your legal\
    \ counsel should evaluate your site's written\n      procedures for responding\
    \ to incidents.  It is essential to obtain\n      a \"clean bill of health\" from\
    \ a legal perspective before you\n      actually carry out these procedures.\n\
    \   5.5.2  Formal and Informal Legal Procedures\n      One of the most important\
    \ considerations in dealing with\n      investigative agencies is verifying that\
    \ the person who calls\n      asking for information is a legitimate representative\
    \ from the\n      agency in question.  Unfortunately, many well intentioned people\n\
    \      have unknowingly leaked sensitive information about incidents,\n      allowed\
    \ unauthorized people into their systems, etc., because a\n      caller has masqueraded\
    \ as an FBI or Secret Service agent.  A\n      similar consideration is using\
    \ a secure means of communication.\n      Because many network attackers can easily\
    \ reroute electronic mail,\n      avoid using electronic mail to communicate with\
    \ other agencies (as\n      well as others dealing with the incident at hand).\
    \  Non-secured\n      phone lines (e.g., the phones normally used in the business\
    \ world)\n      are also frequent targets for tapping by network intruders, so\
    \ be\n      careful!\n      There is no established set of rules for responding\
    \ to an incident\n      when the U.S. Federal Government becomes involved.  Except\
    \ by\n      court order, no agency can force you to monitor, to disconnect\n \
    \     from the network, to avoid telephone contact with the suspected\n      attackers,\
    \ etc..  As discussed in section 5.5.1, you should\n      consult the matter with\
    \ your legal counsel, especially before\n      taking an action that your organization\
    \ has never taken.  The\n      particular agency involved may ask you to leave\
    \ an attacked\n      machine on and to monitor activity on this machine, for example.\n\
    \      Your complying with this request will ensure continued cooperation\n  \
    \    of the agency--usually the best route towards finding the source\n      of\
    \ the network attacks and, ultimately, terminating these attacks.\n      Additionally,\
    \ you may need some information or a favor from the\n      agency involved in\
    \ the incident.  You are likely to get what you\n      need only if you have been\
    \ cooperative.  Of particular importance\n      is avoiding unnecessary or unauthorized\
    \ disclosure of information\n      about the incident, including any information\
    \ furnished by the\n      agency involved.  The trust between your site and the\
    \ agency\n      hinges upon your ability to avoid compromising the case the agency\n\
    \      will build; keeping \"tight lipped\" is imperative.\n      Sometimes your\
    \ needs and the needs of an investigative agency will\n      differ.  Your site\
    \ may want to get back to normal business by\n      closing an attack route, but\
    \ the investigative agency may want you\n      to keep this route open.  Similarly,\
    \ your site may want to close a\n      compromised system down to avoid the possibility\
    \ of negative\n      publicity, but again the investigative agency may want you\
    \ to\n      continue monitoring.  When there is such a conflict, there may be\n\
    \      a complex set of tradeoffs (e.g., interests of your site's\n      management,\
    \ amount of resources you can devote to the problem,\n      jurisdictional boundaries,\
    \ etc.).  An important guiding principle\n      is related to what might be called\
    \ \"Internet citizenship\" [22,\n      IAB89, 23] and its responsibilities.  Your\
    \ site can shut a system\n      down, and this will relieve you of the stress,\
    \ resource demands,\n      and danger of negative exposure.  The attacker, however,\
    \ is likely\n      to simply move on to another system, temporarily leaving others\n\
    \      blind to the attacker's intention and actions until another path\n    \
    \  of attack can be detected.  Providing that there is no damage to\n      your\
    \ systems and others, the most responsible course of action is\n      to cooperate\
    \ with the participating agency by leaving your\n      compromised system on.\
    \  This will allow monitoring (and,\n      ultimately, the possibility of terminating\
    \ the source of the\n      threat to systems just like yours).  On the other hand,\
    \ if there\n      is damage to computers illegally accessed through your system,\
    \ the\n      choice is more complicated: shutting down the intruder may prevent\n\
    \      further damage to systems, but might make it impossible to track\n    \
    \  down the intruder.  If there has been damage, the decision about\n      whether\
    \ it is important to leave systems up to catch the intruder\n      should involve\
    \ all the organizations effected.  Further\n      complicating the issue of network\
    \ responsibility is the\n      consideration that if you do not cooperate with\
    \ the agency\n      involved, you will be less likely to receive help from that\
    \ agency\n      in the future.\n"
- title: 5.6  Documentation Logs
  contents:
  - "5.6  Documentation Logs\n   When you respond to an incident, document all details\
    \ related to the\n   incident.  This will provide valuable information to yourself\
    \ and\n   others as you try to unravel the course of events.  Documenting all\n\
    \   details will ultimately save you time.  If you don't document every\n   relevant\
    \ phone call, for example, you are likely to forget a good\n   portion of information\
    \ you obtain, requiring you to contact the\n   source of information once again.\
    \  This wastes yours and others'\n   time, something you can ill afford.  At the\
    \ same time, recording\n   details will provide evidence for prosecution efforts,\
    \ providing the\n   case moves in this direction.  Documenting an incident also\
    \ will help\n   you perform a final assessment of damage (something your management\n\
    \   as well as law enforcement officers will want to know), and will\n   provide\
    \ the basis for a follow-up analysis in which you can engage in\n   a valuable\
    \ \"lessons learned\" exercise.\n   During the initial stages of an incident,\
    \ it is often infeasible to\n   determine whether prosecution is viable, so you\
    \ should document as if\n   you are gathering evidence for a court case.  At a\
    \ minimum, you\n   should record:\n      o All system events (audit records).\n\
    \      o All actions you take (time tagged).\n      o All phone conversations\
    \ (including the person with whom\n        you talked, the date and time, and\
    \ the content of the\n        conversation).\n   The most straightforward way\
    \ to maintain documentation is keeping a\n   log book.  This allows you to go\
    \ to a centralized, chronological\n   source of information when you need it,\
    \ instead of requiring you to\n   page through individual sheets of paper.  Much\
    \ of this information is\n   potential evidence in a court of law.  Thus, when\
    \ you initially\n   suspect that an incident will result in prosecution or when\
    \ an\n   investigative agency becomes involved, you need to regularly (e.g.,\n\
    \   every day) turn in photocopied, signed copies of your logbook (as\n   well\
    \ as media you use to record system events) to a document\n   custodian who can\
    \ store these copied pages in a secure place (e.g., a\n   safe).  When you submit\
    \ information for storage, you should in return\n   receive a signed, dated receipt\
    \ from the document custodian.  Failure\n   to observe these procedures can result\
    \ in invalidation of any\n   evidence you obtain in a court of law.\n"
- title: 6.  Establishing Post-Incident Procedures
  contents:
  - '6.  Establishing Post-Incident Procedures

    '
- title: 6.1  Overview
  contents:
  - "6.1  Overview\n   In the wake of an incident, several actions should take place.\
    \  These\n   actions can be summarized as follows:\n      1. An inventory should\
    \ be taken of the systems' assets,\n         i.e., a careful examination should\
    \ determine how the\n         system was affected by the incident,\n      2. The\
    \ lessons learned as a result of the incident\n         should be included in\
    \ revised security plan to\n         prevent the incident from re-occurring,\n\
    \      3. A new risk analysis should be developed in light of the\n         incident,\n\
    \      4. An investigation and prosecution of the individuals\n         who caused\
    \ the incident should commence, if it is\n         deemed desirable.\n   All four\
    \ steps should provide feedback to the site security policy\n   committee, leading\
    \ to prompt re-evaluation and amendment of the\n   current policy.\n"
- title: 6.2  Removing Vulnerabilities
  contents:
  - "6.2  Removing Vulnerabilities\n   Removing all vulnerabilities once an incident\
    \ has occurred is\n   difficult.  The key to removing vulnerabilities is knowledge\
    \ and\n   understanding of the breach.  In some cases, it is prudent to remove\n\
    \   all access or functionality as soon as possible, and then restore\n   normal\
    \ operation in limited stages.  Bear in mind that removing all\n   access while\
    \ an incident is in progress will obviously notify all\n   users, including the\
    \ alleged problem users, that the administrators\n   are aware of a problem; this\
    \ may have a deleterious effect on an\n   investigation.  However, allowing an\
    \ incident to continue may also\n   open the likelihood of greater damage, loss,\
    \ aggravation, or\n   liability (civil or criminal).\n   If it is determined that\
    \ the breach occurred due to a flaw in the\n   systems' hardware or software,\
    \ the vendor (or supplier) and the CERT\n   should be notified as soon as possible.\
    \  Including relevant telephone\n   numbers (also electronic mail addresses and\
    \ fax numbers) in the site\n   security policy is strongly recommended.  To aid\
    \ prompt\n   acknowledgment and understanding of the problem, the flaw should\
    \ be\n   described in as much detail as possible, including details about how\n\
    \   to exploit the flaw.\n   As soon as the breach has occurred, the entire system\
    \ and all its\n   components should be considered suspect.  System software is\
    \ the most\n   probable target.  Preparation is key to recovering from a possibly\n\
    \   tainted system.  This includes checksumming all tapes from the vendor\n  \
    \ using a checksum algorithm which (hopefully) is resistant to\n   tampering [10].\
    \  (See sections 3.9.4.1, 3.9.4.2.)  Assuming original\n   vendor distribution\
    \ tapes are available, an analysis of all system\n   files should commence, and\
    \ any irregularities should be noted and\n   referred to all parties involved\
    \ in handling the incident.  It can be\n   very difficult, in some cases, to decide\
    \ which backup tapes to\n   recover from; consider that the incident may have\
    \ continued for\n   months or years before discovery, and that the suspect may\
    \ be an\n   employee of the site, or otherwise have intimate knowledge or access\n\
    \   to the systems.  In all cases, the pre-incident preparation will\n   determine\
    \ what recovery is possible.  At worst-case, restoration from\n   the original\
    \ manufactures' media and a re-installation of the systems\n   will be the most\
    \ prudent solution.\n   Review the lessons learned from the incident and always\
    \ update the\n   policy and procedures to reflect changes necessitated by the\n\
    \   incident.\n   6.2.1  Assessing Damage\n      Before cleanup can begin, the\
    \ actual system damage must be\n      discerned.  This can be quite time consuming,\
    \ but should lead into\n      some of the insight as to the nature of the incident,\
    \ and aid\n      investigation and prosecution.  It is best to compare previous\n\
    \      backups or original tapes when possible; advance preparation is\n     \
    \ the key.  If the system supports centralized logging (most do), go\n      back\
    \ over the logs and look for abnormalities.  If process\n      accounting and\
    \ connect time accounting is enabled, look for\n      patterns of system usage.\
    \  To a lesser extent, disk usage may shed\n      light on the incident.  Accounting\
    \ can provide much helpful\n      information in an analysis of an incident and\
    \ subsequent\n      prosecution.\n   6.2.2  Cleanup\n      Once the damage has\
    \ been assessed, it is necessary to develop a\n      plan for system cleanup.\
    \  In general, bringing up services in the\n      order of demand to allow a minimum\
    \ of user inconvenience is the\n      best practice.  Understand that the proper\
    \ recovery procedures for\n      the system are extremely important and should\
    \ be specific to the\n      site.\n      It may be necessary to go back to the\
    \ original distributed tapes\n      and recustomize the system.  To facilitate\
    \ this worst case\n      scenario, a record of the original systems setup and\
    \ each\n      customization change should be kept current with each change to\n\
    \      the system.\n   6.2.3  Follow up\n      Once you believe that a system\
    \ has been restored to a \"safe\"\n      state, it is still possible that holes\
    \ and even traps could be\n      lurking in the system.  In the follow-up stage,\
    \ the system should\n      be monitored for items that may have been missed during\
    \ the\n      cleanup stage.  It would be prudent to utilize some of the tools\n\
    \      mentioned in section 3.9.8.2 (e.g., COPS) as a start.  Remember,\n    \
    \  these tools don't replace continual system monitoring and good\n      systems\
    \ administration procedures.\n   6.2.4  Keep a Security Log\n      As discussed\
    \ in section 5.6, a security log can be most valuable\n      during this phase\
    \ of removing vulnerabilities.  There are two\n      considerations here; the\
    \ first is to keep logs of the procedures\n      that have been used to make the\
    \ system secure again.  This should\n      include command procedures (e.g., shell\
    \ scripts) that can be run\n      on a periodic basis to recheck the security.\
    \  Second, keep logs of\n      important system events.  These can be referenced\
    \ when trying to\n      determine the extent of the damage of a given incident.\n"
- title: 6.3  Capturing Lessons Learned
  contents:
  - "6.3  Capturing Lessons Learned\n   6.3.1  Understand the Lesson\n      After\
    \ an incident, it is prudent to write a report describing the\n      incident,\
    \ method of discovery, correction procedure, monitoring\n      procedure, and\
    \ a summary of lesson learned.  This will aid in the\n      clear understanding\
    \ of the problem.  Remember, it is difficult to\n      learn from an incident\
    \ if you don't understand the source.\n   6.3.2  Resources\n      6.3.2.1  Other\
    \ Security Devices, Methods\n         Security is a dynamic, not static process.\
    \  Sites are dependent\n         on the nature of security available at each site,\
    \ and the array\n         of devices and methods that will help promote security.\n\
    \         Keeping up with the security area of the computer industry and\n   \
    \      their methods will assure a security manager of taking\n         advantage\
    \ of the latest technology.\n      6.3.2.2  Repository of Books, Lists, Information\
    \ Sources\n         Keep an on site collection of books, lists, information\n\
    \         sources, etc., as guides and references for securing the\n         system.\
    \  Keep this collection up to date.  Remember, as systems\n         change, so\
    \ do security methods and problems.\n      6.3.2.3  Form a Subgroup\n        \
    \ Form a subgroup of system administration personnel that will be\n         the\
    \ core security staff.  This will allow discussions of\n         security problems\
    \ and multiple views of the site's security\n         issues.  This subgroup can\
    \ also act to develop the site\n         security policy and make suggested changes\
    \ as necessary to\n         ensure site security.\n"
- title: 6.4  Upgrading Policies and Procedures
  contents:
  - "6.4  Upgrading Policies and Procedures\n   6.4.1  Establish Mechanisms for Updating\
    \ Policies, Procedures,\n          and Tools\n      If an incident is based on\
    \ poor policy, and unless the policy is\n      changed, then one is doomed to\
    \ repeat the past.  Once a site has\n      recovered from and incident, site policy\
    \ and procedures should be\n      reviewed to encompass changes to prevent similar\
    \ incidents.  Even\n      without an incident, it would be prudent to review policies\
    \ and\n      procedures on a regular basis.  Reviews are imperative due to\n \
    \     today's changing computing environments.\n   6.4.2  Problem Reporting Procedures\n\
    \      A problem reporting procedure should be implemented to describe,\n    \
    \  in detail, the incident and the solutions to the incident.  Each\n      incident\
    \ should be reviewed by the site security subgroup to allow\n      understanding\
    \ of the incident with possible suggestions to the\n      site policy and procedures.\n"
- title: 7.  References
  contents:
  - "7.  References\n   [1] Quarterman, J., \"The Matrix: Computer Networks and Conferencing\n\
    \       Systems Worldwide\", Pg. 278, Digital Press, Bedford, MA, 1990.\n   [2]\
    \ Brand, R., \"Coping with the Threat of Computer Security\n       Incidents:\
    \ A Primer from Prevention through Recovery\", R. Brand,\n       available on-line\
    \ from: cert.sei.cmu.edu:/pub/info/primer, 8 June\n       1990.\n   [3] Fites,\
    \ M., Kratz, P. and A. Brebner, \"Control and Security of\n       Computer Information\
    \ Systems\", Computer Science Press, 1989.\n   [4] Johnson, D., and J. Podesta,\
    \ \"Formulating a Company Policy on\n       Access to and Use and Disclosure of\
    \ Electronic Mail on Company\n       Computer Systems\", Available from: The Electronic\
    \ Mail\n       Association (EMA) 1555 Wilson Blvd, Suite 555, Arlington VA\n \
    \      22209, (703) 522-7111, 22 October 1990.\n   [5] Curry, D., \"Improving\
    \ the Security of Your UNIX System\", SRI\n       International Report ITSTD-721-FR-90-21,\
    \ April 1990.\n   [6] Cheswick, B., \"The Design of a Secure Internet Gateway\"\
    ,\n       Proceedings of the Summer Usenix Conference, Anaheim, CA, June\n   \
    \    1990.\n   [7] Linn, J., \"Privacy Enhancement for Internet Electronic Mail:\
    \ Part\n       I -- Message Encipherment and Authentication Procedures\", RFC\n\
    \       1113, IAB Privacy Task Force, August 1989.\n   [8] Kent, S., and J. Linn,\
    \ \"Privacy Enhancement for Internet\n       Electronic Mail: Part II -- Certificate-Based\
    \ Key Management\",\n       RFC 1114, IAB Privacy Task Force, August 1989.\n \
    \  [9] Linn, J., \"Privacy Enhancement for Internet Electronic Mail: Part\n  \
    \     III -- Algorithms, Modes, and Identifiers\", RFC 1115, IAB Privacy\n   \
    \    Task Force, August 1989.\n  [10] Merkle, R., \"A Fast Software One Way Hash\
    \ Function\", Journal of\n       Cryptology, Vol. 3, No. 1.\n  [11] Postel, J.,\
    \ \"Internet Protocol - DARPA Internet Program Protocol\n       Specification\"\
    , RFC 791, DARPA, September 1981.\n  [12] Postel, J., \"Transmission Control Protocol\
    \ - DARPA Internet\n       Program Protocol Specification\", RFC 793, DARPA, September\
    \ 1981.\n  [13] Postel, J., \"User Datagram Protocol\", RFC 768, USC/Information\n\
    \       Sciences Institute, 28 August 1980.\n  [14] Mogul, J., \"Simple and Flexible\
    \ Datagram Access Controls for\n       UNIX-based Gateways\", Digital Western\
    \ Research Laboratory\n       Research Report 89/4, March 1989.\n  [15] Bellovin,\
    \ S., and M. Merritt, \"Limitations of the Kerberos\n       Authentication System\"\
    , Computer Communications Review, October\n       1990.\n  [16] Pfleeger, C.,\
    \ \"Security in Computing\", Prentice-Hall, Englewood\n       Cliffs, N.J., 1989.\n\
    \  [17] Parker, D., Swope, S., and B. Baker, \"Ethical Conflicts:\n       Information\
    \ and Computer Science, Technology and Business\", QED\n       Information Sciences,\
    \ Inc., Wellesley, MA.\n  [18] Forester, T., and P. Morrison, \"Computer Ethics:\
    \ Tales and\n       Ethical Dilemmas in Computing\", MIT Press, Cambridge, MA,\
    \ 1990.\n  [19] Postel, J., and J. Reynolds, \"Telnet Protocol Specification\"\
    , RFC\n       854, USC/Information Sciences Institute, May 1983.\n  [20] Postel,\
    \ J., and J. Reynolds, \"File Transfer Protocol\", RFC 959,\n       USC/Information\
    \ Sciences Institute, October 1985.\n  [21] Postel, J., Editor, \"IAB Official\
    \ Protocol Standards\", RFC 1200,\n       IAB, April 1991.\n  [22] Internet Activities\
    \ Board, \"Ethics and the Internet\", RFC 1087,\n       Internet Activities Board,\
    \ January 1989.\n  [23] Pethia, R., Crocker, S., and B. Fraser, \"Policy Guidelines\
    \ for\n       the Secure Operation of the Internet\", CERT, TIS, CERT, RFC in\n\
    \       preparation.\n  [24] Computer Emergency Response Team (CERT/CC), \"Unauthorized\n\
    \       Password Change Requests\", CERT Advisory CA-91:03, April 1991.\n  [25]\
    \ Computer Emergency Response Team (CERT/CC), \"TELNET Breakin\n       Warning\"\
    , CERT Advisory CA-89:03, August 1989.\n  [26] CCITT, Recommendation X.509, \"\
    The Directory: Authentication\n       Framework\", Annex C.\n  [27] Farmer, D.,\
    \ and E. Spafford, \"The COPS Security Checker System\",\n       Proceedings of\
    \ the Summer 1990 USENIX Conference, Anaheim, CA,\n       Pgs. 165-170, June 1990.\n"
- title: 8.  Annotated Bibliography
  contents:
  - "8.  Annotated Bibliography\n   The intent of this annotated bibliography is to\
    \ offer a\n   representative collection of resources of information that will\
    \ help\n   the user of this handbook.  It is meant provide a starting point for\n\
    \   further research in the security area.  Included are references to\n   other\
    \ sources of information for those who wish to pursue issues of\n   the computer\
    \ security environment.\n"
- title: 8.1  Computer Law
  contents:
  - "8.1  Computer Law\n   [ABA89]\n           American Bar Association, Section of\
    \ Science and\n           Technology, \"Guide to the Prosecution of Telecommunication\n\
    \           Fraud by the Use of Computer Crime Statutes\", American Bar\n    \
    \       Association, 1989.\n   [BENDER]\n           Bender, D., \"Computer Law:\
    \ Evidence and Procedure\",\n           M. Bender, New York, NY, 1978-present.\n\
    \           Kept up to date with supplements.\n           Years covering 1978-1984\
    \ focuses on: Computer law,\n           evidence and procedures.  The years 1984\
    \ to the current\n           focus on general computer law.  Bibliographical\n\
    \           references and index included.\n   [BLOOMBECKER]\n           Bloombecker,\
    \ B., \"Spectacular Computer Crimes\", Dow Jones-\n           Irwin, Homewood,\
    \ IL. 1990.\n   [CCH]\n           Commerce Clearing House, \"Guide to Computer\
    \ Law\", (Topical\n           Law Reports), Chicago, IL., 1989.\n           Court\
    \ cases and decisions rendered by federal and state\n           courts throughout\
    \ the United States on federal and state\n           computer law.  Includes Case\
    \ Table and Topical Index.\n   [CONLY]\n           Conly, C., \"Organizing for\
    \ Computer Crime Investigation and\n           Prosecution\", U.S. Dept. of Justice,\
    \ Office of Justice\n           Programs, Under Contract  Number OJP-86-C-002,\
    \ National\n           Institute of Justice, Washington, DC, July 1989.\n   [FENWICK]\n\
    \           Fenwick, W., Chair, \"Computer Litigation, 1985: Trial\n         \
    \  Tactics and Techniques\", Litigation Course Handbook\n           Series No.\
    \ 280, Prepared for distribution at the\n           Computer Litigation, 1985:\
    \ Trial Tactics and\n           Techniques Program, February-March 1985.\n   [GEMIGNANI]\n\
    \           Gemignani, M., \"Viruses and Criminal Law\", Communications\n    \
    \       of the ACM, Vol. 32, No. 6, Pgs. 669-671, June 1989.\n   [HUBAND]\n  \
    \         Huband, F., and R. Shelton, Editors, \"Protection of\n           Computer\
    \ Systems and Software: New Approaches for Combating\n           Theft of Software\
    \ and Unauthorized Intrusion\", Papers\n           presented at a workshop sponsored\
    \ by the National Science\n           Foundation, 1986.\n   [MCEWEN]\n       \
    \    McEwen, J., \"Dedicated Computer Crime Units\", Report\n           Contributors:\
    \ D. Fester and H. Nugent, Prepared for the\n           National Institute of\
    \ Justice, U.S. Department of Justice,\n           by Institute for Law and Justice,\
    \ Inc., under contract number\n           OJP-85-C-006, Washington, DC, 1989.\n\
    \   [PARKER]\n           Parker, D., \"Computer Crime: Criminal Justice Resource\n\
    \           Manual\", U.S. Dept. of Justice, National Institute of Justice,\n\
    \           Office of Justice Programs, Under Contract Number\n           OJP-86-C-002,\
    \ Washington, D.C., August 1989.\n   [SHAW]\n           Shaw, E., Jr., \"Computer\
    \ Fraud and Abuse Act of 1986,\n           Congressional Record (3 June 1986),\
    \ Washington, D.C.,\n           3 June 1986.\n   [TRIBLE]\n           Trible,\
    \ P., \"The Computer Fraud and Abuse Act of 1986\",\n           U.S. Senate Committee\
    \ on the Judiciary, 1986.\n"
- title: 8.2  Computer Security
  contents:
  - "8.2  Computer Security\n   [CAELLI]\n           Caelli, W., Editor, \"Computer\
    \ Security in the Age of\n           Information\", Proceedings of the Fifth IFIP\
    \ International\n           Conference on Computer Security, IFIP/Sec '88.\n \
    \  [CARROLL]\n           Carroll, J., \"Computer Security\", 2nd Edition, Butterworth\n\
    \           Publishers, Stoneham, MA, 1987.\n   [COOPER]\n           Cooper, J.,\
    \ \"Computer and Communications Security:\n           Strategies for the 1990s\"\
    , McGraw-Hill, 1989.\n   [BRAND]\n           Brand, R., \"Coping with the Threat\
    \ of Computer Security\n           Incidents: A Primer from Prevention through\
    \ Recovery\",\n           R. Brand, 8 June 1990.\n           As computer security\
    \ becomes a more important issue in\n           modern society, it begins to warrant\
    \ a systematic approach.\n           The vast majority of the computer security\
    \ problems and the\n           costs associated with them can be prevented with\
    \ simple\n           inexpensive measures.  The most important and cost\n    \
    \       effective of these measures are available in the prevention\n        \
    \   and planning phases.  These methods are presented in this\n           paper,\
    \ followed by a simplified guide to incident\n           handling and recovery.\
    \  Available on-line from:\n           cert.sei.cmu.edu:/pub/info/primer.\n  \
    \ [CHESWICK]\n           Cheswick, B., \"The Design of a Secure Internet Gateway\"\
    ,\n           Proceedings of the Summer Usenix Conference, Anaheim, CA,\n    \
    \       June 1990.\n           Brief abstract (slight paraphrase from the original\n\
    \           abstract): AT&T maintains a large internal Internet that\n       \
    \    needs to be protected from outside attacks, while\n           providing useful\
    \ services between the two.\n           This paper describes AT&T's Internet gateway.\
    \  This\n           gateway passes mail and many of the common Internet\n    \
    \       services between AT&T internal machines and the Internet.\n          \
    \ This is accomplished without IP connectivity using a pair\n           of machines:\
    \ a trusted internal machine and an untrusted\n           external gateway.  These\
    \ are connected by a private link.\n           The internal machine provides a\
    \ few carefully-guarded\n           services to the external gateway.  This configuration\n\
    \           helps protect the internal internet even if the external\n       \
    \    machine is fully compromised.\n           This is a very useful and interesting\
    \ design.  Most\n           firewall gateway systems rely on a system that, if\n\
    \           compromised, could allow access to the machines behind\n         \
    \  the firewall.  Also, most firewall systems require users\n           who want\
    \ access to Internet services to have accounts on\n           the firewall machine.\
    \  AT&T's design allows AT&T internal\n           internet users access to the\
    \ standard services of TELNET and\n           FTP from their own workstations\
    \ without accounts on\n           the firewall machine.  A very useful paper that\
    \ shows\n           how to maintain some of the benefits of Internet\n       \
    \    connectivity while still maintaining strong\n           security.\n   [CURRY]\n\
    \           Curry, D., \"Improving the Security of Your UNIX System\",\n     \
    \      SRI International Report ITSTD-721-FR-90-21, April 1990.\n           This\
    \ paper describes measures that you, as a system\n           administrator can\
    \ take to make your UNIX system(s) more\n           secure.  Oriented primarily\
    \ at SunOS 4.x, most of the\n           information covered applies equally well\
    \ to any Berkeley\n           UNIX system with or without NFS and/or Yellow Pages\
    \ (NIS).\n           Some of the information can also be applied to System V,\n\
    \           although this is not a primary focus of the paper.  A very\n     \
    \      useful reference, this is also available on the Internet in\n         \
    \  various locations, including the directory\n           cert.sei.cmu.edu:/pub/info.\n\
    \   [FITES]\n           Fites, M., Kratz, P. and A. Brebner, \"Control and\n \
    \          Security of Computer Information Systems\", Computer Science\n    \
    \       Press, 1989.\n           This book serves as a good guide to the issues\
    \ encountered\n           in forming computer security policies and procedures.\
    \  The\n           book is designed as a textbook for an introductory course\n\
    \           in information systems security.\n           The book is divided into\
    \ five sections: Risk Management (I),\n           Safeguards: security and control\
    \ measures, organizational\n           and administrative (II), Safeguards: Security\
    \ and Control\n           Measures, Technical (III), Legal Environment and\n \
    \          Professionalism (IV), and CICA Computer Control Guidelines\n      \
    \     (V).\n           The book is particularly notable for its straight-forward\n\
    \           approach to security, emphasizing that common sense is the\n     \
    \      first consideration in designing a security program.  The\n           authors\
    \ note that there is a tendency to look to more\n           technical solutions\
    \ to security problems while overlooking\n           organizational controls which\
    \ are often cheaper and much\n           more effective.  298 pages, including\
    \ references and index.\n   [GARFINKEL]\n           Garfinkel, S, and E. Spafford,\
    \ \"Practical Unix Security\",\n           O'Reilly & Associates, ISBN 0-937175-72-2,\
    \ May 1991.\n           Approx 450 pages, $29.95.  Orders: 1-800-338-6887\n  \
    \         (US & Canada), 1-707-829-0515 (Europe), email: nuts@ora.com\n      \
    \     This is one of the most useful books available on Unix\n           security.\
    \  The first part of the book covers standard Unix\n           and Unix security\
    \ basics, with particular emphasis on\n           passwords.  The second section\
    \ covers enforcing security on\n           the system.  Of particular interest\
    \ to the Internet user are\n           the sections on network security, which\
    \ address many\n           of the common security problems that afflict Internet\
    \ Unix\n           users.  Four chapters deal with handling security incidents,\n\
    \           and the book concludes with discussions of encryption,\n         \
    \  physical security, and useful checklists and lists of\n           resources.\
    \  The book lives up to its name; it is filled with\n           specific references\
    \ to possible security holes, files to\n           check, and things to do to\
    \ improve security.  This\n           book is an excellent complement to this\
    \ handbook.\n   [GREENIA90]\n           Greenia, M., \"Computer Security Information\
    \ Sourcebook\",\n           Lexikon Services, Sacramento, CA, 1989.\n        \
    \   A manager's guide to computer security.  Contains a\n           sourcebook\
    \ of key reference materials including\n           access control and computer\
    \ crimes bibliographies.\n   [HOFFMAN]\n           Hoffman, L., \"Rogue Programs:\
    \ Viruses, Worms, and\n           Trojan Horses\", Van Nostrand Reinhold, NY,\
    \ 1990.\n           (384 pages, includes bibliographical references and index.)\n\
    \   [JOHNSON]\n           Johnson, D., and J. Podesta, \"Formulating A Company\
    \ Policy\n           on Access to and Use and Disclosure of Electronic Mail on\n\
    \           Company Computer Systems\".\n           A white paper prepared for\
    \ the EMA, written by two experts\n           in privacy law.  Gives background\
    \ on the issues, and presents\n           some policy options.\n           Available\
    \ from: The Electronic Mail Association (EMA)\n           1555 Wilson Blvd, Suite\
    \ 555, Arlington, VA, 22209.\n           (703) 522-7111.\n   [KENT]\n        \
    \   Kent, Stephen, \"E-Mail Privacy for the Internet: New Software\n         \
    \  and Strict Registration Procedures will be Implemented this\n           Year\"\
    , Business Communications Review, Vol. 20, No. 1,\n           Pg. 55, 1 January\
    \ 1990.\n   [LU]\n           Lu, W., and M. Sundareshan, \"Secure Communication\
    \ in\n           Internet Environments: A Hierachical Key Management Scheme\n\
    \           for End-to-End Encryption\", IEEE Transactions on\n           Communications,\
    \ Vol. 37, No. 10, Pg. 1014, 1 October 1989.\n   [LU1]\n           Lu, W., and\
    \ M. Sundareshan, \"A Model for Multilevel Security\n           in Computer Networks\"\
    , IEEE Transactions on Software\n           Engineering, Vol. 16, No. 6, Page\
    \ 647, 1 June 1990.\n   [NSA]\n           National Security Agency, \"Information\
    \ Systems Security\n           Products and Services Catalog\", NSA, Quarterly\
    \ Publication.\n           NSA's catalogue contains chapter on: Endorsed Cryptographic\n\
    \           Products List; NSA Endorsed Data Encryption Standard (DES)\n     \
    \      Products List; Protected Services List; Evaluated Products\n          \
    \ List; Preferred Products List; and Endorsed Tools List.\n           The catalogue\
    \ is available from the Superintendent of\n           Documents, U.S. Government\
    \ Printing Office, Washington,\n           D.C.  One may place telephone orders\
    \ by calling:\n           (202) 783-3238.\n   [OTA]\n           United States\
    \ Congress, Office of Technology Assessment,\n           \"Defending Secrets,\
    \ Sharing Data: New Locks and Keys for\n           Electronic Information\", OTA-CIT-310,\
    \ October 1987.\n           This report, prepared for congressional committee\
    \ considering\n           Federal policy on the protection of electronic information,\
    \ is\n           interesting because of the issues it raises regarding the\n \
    \          impact of technology used to protect information.  It also\n      \
    \     serves as a reasonable introduction to the various encryption\n        \
    \   and information protection mechanisms.  185 pages.  Available\n          \
    \ from the U.S. Government Printing Office.\n   [PALMER]\n           Palmer, I.,\
    \ and G. Potter, \"Computer Security Risk\n           Management\", Van Nostrand\
    \ Reinhold, NY, 1989.\n   [PFLEEGER]\n           Pfleeger, C., \"Security in Computing\"\
    , Prentice-Hall,\n           Englewood Cliffs, NJ, 1989.\n           A general\
    \ textbook in computer security, this book provides an\n           excellent and\
    \ very readable introduction to classic computer\n           security problems\
    \ and solutions, with a particular emphasis on\n           encryption.  The encryption\
    \ coverage serves as a good\n           introduction to the subject.  Other topics\
    \ covered include\n           building secure programs and systems, security of\
    \ database,\n           personal computer security, network and communications\n\
    \           security, physical security, risk analysis and security\n        \
    \   planning, and legal and ethical issues.  538 pages including\n           index\
    \ and bibliography.\n   [SHIREY]\n           Shirey, R., \"Defense Data Network\
    \ Security Architecture\",\n           Computer Communication Review, Vol. 20,\
    \ No. 2, Page 66,\n           1 April 1990.\n   [SPAFFORD]\n           Spafford,\
    \ E., Heaphy, K., and D. Ferbrache, \"Computer\n           Viruses: Dealing with\
    \ Electronic Vandalism and Programmed\n           Threats\", ADAPSO, 1989. (109\
    \ pages.)\n           This is a good general reference on computer viruses and\n\
    \           related concerns.  In addition to describing viruses in\n        \
    \   some detail, it also covers more general security issues,\n           legal\
    \ recourse in case of security problems, and includes\n           lists of laws,\
    \ journals focused on computers security,\n           and other security-related\
    \ resources.\n           Available from: ADAPSO, 1300 N. 17th St, Suite 300,\n\
    \           Arlington VA 22209.  (703) 522-5055.\n   [STOLL88]\n           Stoll,\
    \ C., \"Stalking the Wily Hacker\", Communications\n           of the ACM, Vol.\
    \ 31, No. 5, Pgs. 484-497, ACM,\n           New York, NY, May 1988.\n        \
    \   This article describes some of the technical means used\n           to trace\
    \ the intruder that was later chronicled in\n           \"Cuckoo's Egg\" (see\
    \ below).\n   [STOLL89]\n           Stoll, C., \"The Cuckoo's Egg\", ISBN 00385-24946-2,\n\
    \           Doubleday, 1989.\n           Clifford Stoll, an astronomer turned\
    \ UNIX System\n           Administrator, recounts an exciting, true story of how\
    \ he\n           tracked a computer intruder through the maze of American\n  \
    \         military and research networks.  This book is easy to\n           understand\
    \ and can serve as an interesting introduction to\n           the world of networking.\
    \  Jon Postel says in a book review,\n           \"[this book] ... is absolutely\
    \ essential reading for anyone\n           that uses or operates any computer\
    \ connected to the Internet\n           or any other computer network.\"\n   [VALLA]\n\
    \           Vallabhaneni, S., \"Auditing Computer Security: A Manual with\n  \
    \         Case Studies\", Wiley, New York, NY, 1989.\n"
- title: 8.3  Ethics
  contents:
  - "8.3  Ethics\n   [CPSR89]\n           Computer Professionals for Social Responsibility,\
    \ \"CPSR\n           Statement on the Computer Virus\", CPSR, Communications of\
    \ the\n           ACM, Vol. 32, No. 6, Pg. 699, June 1989.\n           This memo\
    \ is a statement on the Internet Computer Virus\n           by the Computer Professionals\
    \ for Social Responsibility\n           (CPSR).\n   [DENNING]\n           Denning,\
    \ Peter J., Editor, \"Computers Under Attack:\n           Intruders, Worms, and\
    \ Viruses\",  ACM Press, 1990.\n           A collection of 40 pieces divided into\
    \ six sections: the\n           emergence of worldwide computer networks, electronic\
    \ breakins,\n           worms, viruses, counterculture (articles examining the\
    \ world\n           of the \"hacker\"), and finally a section discussing social,\n\
    \           legal, and ethical considerations.\n           A thoughtful collection\
    \ that addresses the phenomenon of\n           attacks on computers.  This includes\
    \ a number of previously\n           published articles and some new ones.  The\
    \ previously\n           published ones are well chosen, and include some references\n\
    \           that might be otherwise hard to obtain.  This book is a key\n    \
    \       reference to computer security threats that have generated\n         \
    \  much of the concern over computer security in recent years.\n   [ERMANN]\n\
    \           Ermann, D., Williams, M., and C. Gutierrez, Editors,\n           \"\
    Computers, Ethics, and Society\", Oxford University Press,\n           NY, 1990.\
    \  (376 pages, includes bibliographical references).\n   [FORESTER]\n        \
    \   Forester, T., and P. Morrison, \"Computer Ethics: Tales and\n           Ethical\
    \ Dilemmas in Computing\", MIT Press, Cambridge, MA,\n           1990.  (192 pages\
    \ including index.)\n           From the preface: \"The aim of this book is two-fold:\
    \ (1) to\n           describe some of the problems created by society by computers,\n\
    \           and (2) to show how these problems present ethical dilemmas\n    \
    \       for computers professionals and computer users.\n           The problems\
    \ created by computers arise, in turn, from two\n           main sources: from\
    \ hardware and software malfunctions and\n           from misuse by human beings.\
    \  We argue that computer systems\n           by their very nature are insecure,\
    \ unreliable, and\n           unpredictable -- and that society has yet to come\
    \ to terms\n           with the consequences.  We also seek to show how society\n\
    \           has become newly vulnerable to human misuse of computers in\n    \
    \       the form of computer crime, software theft, hacking, the\n           creation\
    \ of viruses, invasions of privacy, and so on.\"\n           The eight chapters\
    \ include \"Computer Crime\", \"Software\n           Theft\", \"Hacking and Viruses\"\
    , \"Unreliable Computers\",\n           \"The Invasion of Privacy\", \"AI and\
    \ Expert Systems\",\n           and \"Computerizing the Workplace.\"  Includes\
    \ extensive\n           notes on sources and an index.\n   [GOULD]\n         \
    \  Gould, C., Editor, \"The Information Web: Ethical and Social\n           Implications\
    \ of Computer Networking\", Westview Press,\n           Boulder, CO, 1989.\n \
    \  [IAB89]\n           Internet Activities Board, \"Ethics and the Internet\"\
    ,\n           RFC 1087, IAB, January 1989.  Also appears in the\n           Communications\
    \ of the ACM, Vol. 32, No. 6, Pg. 710,\n           June 1989.\n           This\
    \ memo is a statement of policy by the Internet\n           Activities Board (IAB)\
    \ concerning the proper use of\n           the resources of the Internet.  Available\
    \ on-line on\n           host ftp.nisc.sri.com, directory rfc, filename rfc1087.txt.\n\
    \           Also available on host nis.nsf.net, directory RFC,\n           filename\
    \ RFC1087.TXT-1.\n   [MARTIN]\n           Martin, M., and R. Schinzinger, \"Ethics\
    \ in Engineering\",\n           McGraw Hill, 2nd Edition, 1989.\n   [MIT89]\n\
    \           Massachusetts Institute of Technology, \"Teaching Students\n     \
    \      About Responsible Use of Computers\", MIT, 1985-1986.  Also\n         \
    \  reprinted in the Communications of the ACM, Vol. 32, No. 6,\n           Pg.\
    \ 704, Athena Project, MIT, June 1989.\n           This memo is a statement of\
    \ policy by the Massachusetts\n           Institute of Technology (MIT) on the\
    \ responsible use\n           of computers.\n   [NIST]\n           National Institute\
    \ of Standards and Technology, \"Computer\n           Viruses and Related Threats:\
    \ A Management Guide\", NIST\n           Special Publication 500-166, August 1989.\n\
    \   [NSF88]\n           National Science Foundation, \"NSF Poses Code of Networking\n\
    \           Ethics\", Communications of the ACM, Vol. 32, No. 6, Pg. 688,\n  \
    \         June 1989.  Also appears in the minutes of the regular\n           meeting\
    \ of the Division Advisory Panel for Networking and\n           Communications\
    \ Research and Infrastructure, Dave Farber,\n           Chair, November 29-30,\
    \ 1988.\n           This memo is a statement of policy by the National Science\n\
    \           Foundation (NSF) concerning the ethical use of the Internet.\n   [PARKER90]\n\
    \           Parker, D., Swope, S., and B. Baker, \"Ethical Conflicts:\n      \
    \     Information and Computer Science, Technology and Business\",\n         \
    \  QED Information Sciences, Inc., Wellesley, MA. (245 pages).\n   Additional\
    \ publications on Ethics:\n   The University of New Mexico (UNM)\n      The UNM\
    \ has a collection of ethics documents.  Included are\n      legislation from\
    \ several states and policies from many\n      institutions.\n         Access\
    \ is via FTP, IP address ariel.umn.edu.  Look in the\n         directory /ethics.\n"
- title: 8.4  The Internet Worm
  contents:
  - "8.4  The Internet Worm\n   [BROCK]\n           Brock, J., \"November 1988 Internet\
    \ Computer Virus and the\n           Vulnerability of National Telecommunications\
    \ Networks to\n           Computer Viruses\", GAO/T-IMTEC-89-10, Washington, DC,\n\
    \           20 July 1989.\n           Testimonial statement of Jack L. Brock,\
    \ Director, U. S.\n           Government Information before the Subcommittee on\n\
    \           Telecommunications and Finance, Committee on Energy and\n        \
    \   Commerce, House of Representatives.\n   [EICHIN89]\n           Eichin, M.,\
    \ and J. Rochlis, \"With Microscope and Tweezers:\n           An Analysis of the\
    \ Internet Virus of November 1988\",\n           Massachusetts Institute of Technology,\
    \ February 1989.\n           Provides a detailed dissection of the worm program.\
    \  The\n           paper discusses the major points of the worm program then\n\
    \           reviews strategies, chronology, lessons and open issues,\n       \
    \    Acknowledgments; also included are a detailed appendix\n           on the\
    \ worm program subroutine by subroutine, an\n           appendix on the cast of\
    \ characters, and a reference section.\n   [EISENBERG89]\n           Eisenberg,\
    \ T., D. Gries, J. Hartmanis, D. Holcomb,\n           M. Lynn, and T. Santoro,\
    \ \"The Computer Worm\", Cornell\n           University, 6 February 1989.\n  \
    \         A Cornell University Report presented to the Provost of the\n      \
    \     University on 6 February 1989 on the Internet Worm.\n   [GAO]\n        \
    \   U.S. General Accounting Office, \"Computer Security - Virus\n           Highlights\
    \ Need for Improved Internet Management\", United\n           States General Accounting\
    \ Office, Washington, DC, 1989.\n           This 36 page report (GAO/IMTEC-89-57),\
    \ by the U.S.\n           Government Accounting Office, describes the Internet\
    \ worm\n           and its effects.  It gives a good overview of the various\n\
    \           U.S. agencies involved in the Internet today and their\n         \
    \  concerns vis-a-vis computer security and networking.\n           Available\
    \ on-line on host nnsc.nsf.net, directory\n           pub, filename GAO_RPT; and\
    \ on nis.nsf.net, directory nsfnet,\n           filename GAO_RPT.TXT.\n   [REYNOLDS89]\n\
    \           The Helminthiasis of the Internet, RFC 1135,\n           USC/Information\
    \ Sciences Institute, Marina del Rey,\n           CA, December 1989.\n       \
    \    This report looks back at the helminthiasis (infestation\n           with,\
    \ or disease caused by parasitic worms) of the\n           Internet that was unleashed\
    \ the evening of 2 November 1988.\n           This document provides a glimpse\
    \ at the infection,its\n           festering, and cure.  The impact of the worm\
    \ on the Internet\n           community, ethics statements, the role of the news\
    \ media,\n           crime in the computer world, and future prevention is\n \
    \          discussed.  A documentation review presents four publications\n   \
    \        that describe in detail this particular parasitic computer\n        \
    \   program.  Reference and bibliography sections are also\n           included.\
    \  Available on-line on host ftp.nisc.sri.com\n           directory rfc, filename\
    \ rfc1135.txt.  Also available on\n           host nis.nsf.net, directory RFC,\
    \ filename RFC1135.TXT-1.\n   [SEELEY89]\n           Seeley, D., \"A Tour of the\
    \ Worm\", Proceedings of 1989\n           Winter USENIX Conference, Usenix Association,\
    \ San Diego, CA,\n           February 1989.\n           Details are presented\
    \ as a \"walk thru\" of this particular\n           worm program.  The paper opened\
    \ with an abstract,\n           introduction, detailed chronology of events upon\
    \ the\n           discovery of the worm, an overview, the internals of the\n \
    \          worm, personal opinions, and conclusion.\n   [SPAFFORD88]\n       \
    \    Spafford, E., \"The Internet Worm Program: An\n           Analysis\", Computer\
    \ Communication Review, Vol. 19,\n           No. 1, ACM SIGCOM, January 1989.\
    \  Also issued as Purdue\n           CS Technical Report CSD-TR-823, 28 November\
    \ 1988.\n           Describes the infection of the Internet as a worm\n      \
    \     program that exploited flaws in utility programs in\n           UNIX based\
    \ systems.  The report gives a detailed\n           description of the components\
    \ of the worm program:\n           data and functions.  Spafford focuses his study\
    \ on two\n           completely independent reverse-compilations of the\n    \
    \       worm and a version disassembled to VAX assembly language.\n   [SPAFFORD89]\n\
    \           Spafford, G., \"An Analysis of the Internet Worm\",\n           Proceedings\
    \ of the European Software Engineering\n           Conference 1989, Warwick England,\
    \ September 1989.\n           Proceedings published by Springer-Verlag as: Lecture\n\
    \           Notes in Computer Science #387.  Also issued\n           as Purdue\
    \ Technical Report #CSD-TR-933.\n"
- title: 8.5  National Computer Security Center (NCSC)
  contents:
  - "8.5  National Computer Security Center (NCSC)\n   All NCSC publications, approved\
    \ for public release, are available\n   from the NCSC Superintendent of Documents.\n\
    \           NCSC = National Computer Security Center\n           9800 Savage Road\n\
    \           Ft Meade, MD 20755-6000\n           CSC = Computer Security Center:\n\
    \           an older name for the NCSC\n           NTISS = National Telecommunications\
    \ and\n           Information Systems Security\n           NTISS Committee, National\
    \ Security Agency\n           Ft Meade, MD 20755-6000\n   [CSC]\n           Department\
    \ of Defense, \"Password Management Guideline\",\n           CSC-STD-002-85, 12\
    \ April 1985, 31 pages.\n           The security provided by a password system\
    \ depends on\n           the passwords being kept secret at all times.  Thus,\
    \ a\n           password is vulnerable to compromise whenever it is used,\n  \
    \         stored, or even known.  In a password-based authentication\n       \
    \    mechanism implemented on an ADP system, passwords are\n           vulnerable\
    \ to compromise due to five essential aspects\n           of the password system:\
    \ 1) a password must be initially\n           assigned to a user when enrolled\
    \ on the ADP system;\n           2) a user's password must be changed periodically;\n\
    \           3) the ADP system must maintain a 'password\n           database';\
    \ 4) users must remember their passwords; and\n           5) users must enter\
    \ their passwords into the ADP system at\n           authentication time.  This\
    \ guideline prescribes steps to be\n           taken to minimize the vulnerability\
    \ of passwords in each of\n           these circumstances.\n   [NCSC1]\n     \
    \      NCSC, \"A Guide to Understanding AUDIT in Trusted Systems\",\n        \
    \   NCSC-TG-001, Version-2, 1 June 1988, 25 pages.\n           Audit trails are\
    \ used to detect and deter penetration of\n           a computer system and to\
    \ reveal usage that identifies\n           misuse.  At the discretion of the auditor,\
    \ audit trails\n           may be limited to specific events or may encompass\
    \ all of\n           the activities on a system.  Although not required by\n \
    \          the criteria, it should be possible for the target of the\n       \
    \    audit mechanism to be either a subject or an object.  That\n           is\
    \ to say, the audit mechanism should be capable of\n           monitoring every\
    \ time John accessed the system as well as\n           every time the nuclear\
    \ reactor file was accessed; and\n           likewise every time John accessed\
    \ the nuclear reactor\n           file.\n   [NCSC2]\n           NCSC, \"A Guide\
    \ to Understanding DISCRETIONARY ACCESS CONTROL\n           in Trusted Systems\"\
    , NCSC-TG-003, Version-1, 30 September\n           1987, 29 pages.\n         \
    \  Discretionary control is the most common type of access\n           control\
    \ mechanism implemented in computer systems today.\n           The basis of this\
    \ kind of security is that an individual\n           user, or program operating\
    \ on the user's behalf, is\n           allowed to specify explicitly the types\
    \ of access other\n           users (or programs executing on their behalf) may\
    \ have to\n           information under the user's control.  [...]  Discretionary\n\
    \           controls are not a replacement for mandatory controls.  In\n     \
    \      any environment in which information is protected,\n           discretionary\
    \ security provides for a finer granularity of\n           control within the\
    \ overall constraints of the mandatory\n           policy.\n   [NCSC3]\n     \
    \      NCSC, \"A Guide to Understanding CONFIGURATION MANAGEMENT\n           in\
    \ Trusted Systems\", NCSC-TG-006, Version-1, 28 March 1988,\n           31 pages.\n\
    \           Configuration management consists of four separate tasks:\n      \
    \     identification, control, status accounting, and auditing.\n           For\
    \ every change that is made to an automated data\n           processing (ADP)\
    \ system, the design and requirements of the\n           changed version of the\
    \ system should be identified.  The\n           control task of configuration\
    \ management is performed\n           by subjecting every change to documentation,\
    \ hardware, and\n           software/firmware to review and approval by an authorized\n\
    \           authority.  Configuration status accounting is responsible\n     \
    \      for recording and reporting on the configuration of the\n           product\
    \ throughout the change.  Finally, though the process\n           of a configuration\
    \ audit, the completed change can be\n           verified to be functionally correct,\
    \ and for trusted\n           systems, consistent with the security policy of\
    \ the system.\n   [NTISS]\n           NTISS, \"Advisory Memorandum on Office Automation\
    \ Security\n           Guideline\", NTISSAM CONPUSEC/1-87, 16 January 1987,\n\
    \           58 pages.\n           This document provides guidance to users, managers,\
    \ security\n           officers, and procurement officers of Office Automation\n\
    \           Systems.  Areas addressed include: physical security,\n          \
    \ personnel security, procedural security, hardware/software\n           security,\
    \ emanations security (TEMPEST), and communications\n           security for stand-alone\
    \ OA Systems, OA Systems\n           used as terminals connected to mainframe\
    \ computer systems,\n           and OA Systems used as hosts in a Local Area Network\
    \ (LAN).\n           Differentiation is made between those Office Automation\n\
    \           Systems equipped with removable storage media only (e.g.,\n      \
    \     floppy disks, cassette tapes, removable hard disks) and\n           those\
    \ Office Automation Systems equipped with fixed media\n           (e.g., Winchester\
    \ disks).\n"
- title: 'Additional NCSC Publications:'
  contents:
  - "Additional NCSC Publications:\n   [NCSC4]\n           National Computer Security\
    \ Center, \"Glossary of Computer\n           Security Terms\", NCSC-TG-004, NCSC,\
    \ 21 October 1988.\n   [NCSC5]\n           National Computer Security Center,\
    \ \"Trusted\n           Computer System Evaluation Criteria\", DoD 5200.28-STD,\n\
    \           CSC-STD-001-83, NCSC, December 1985.\n   [NCSC7]\n           National\
    \ Computer Security Center, \"Guidance for\n           Applying the Department\
    \ of Defense Trusted Computer System\n           Evaluation Criteria in Specific\
    \ Environments\",\n           CSC-STD-003-85, NCSC, 25 June 1985.\n   [NCSC8]\n\
    \           National Computer Security Center, \"Technical Rationale\n       \
    \    Behind CSC-STD-003-85: Computer Security Requirements\",\n           CSC-STD-004-85,\
    \ NCSC, 25 June 85.\n   [NCSC9]\n           National Computer Security Center,\
    \ \"Magnetic Remanence\n           Security Guideline\", CSC-STD-005-85, NCSC,\
    \ 15 November 1985.\n           This guideline is tagged as a \"For Official Use\
    \ Only\"\n           exemption under Section 6, Public Law 86-36 (50 U.S. Code\n\
    \           402).  Distribution authorized of U.S. Government agencies\n     \
    \      and their contractors to protect unclassified technical,\n           operational,\
    \ or administrative data relating to operations\n           of the National Security\
    \ Agency.\n   [NCSC10]\n           National Computer Security Center, \"Guidelines\
    \ for Formal\n           Verification Systems\", Shipping list no.: 89-660-P,\
    \ The\n           Center, Fort George G. Meade, MD, 1 April 1990.\n   [NCSC11]\n\
    \           National Computer Security Center, \"Glossary of Computer\n      \
    \     Security Terms\", Shipping list no.: 89-254-P, The Center,\n           Fort\
    \ George G. Meade, MD, 21 October 1988.\n   [NCSC12]\n           National Computer\
    \ Security Center, \"Trusted UNIX Working\n           Group (TRUSIX) rationale\
    \ for selecting access control\n           list features for the UNIX system\"\
    , Shipping list no.:\n           90-076-P, The Center, Fort George G. Meade, MD,\
    \ 1990.\n   [NCSC13]\n           National Computer Security Center, \"Trusted\
    \ Network\n           Interpretation\", NCSC-TG-005, NCSC, 31 July 1987.\n   [NCSC14]\n\
    \           Tinto, M., \"Computer Viruses: Prevention, Detection, and\n      \
    \     Treatment\", National Computer Security Center C1\n           Technical\
    \ Report C1-001-89, June 1989.\n   [NCSC15]\n           National Computer Security\
    \ Conference, \"12th National\n           Computer Security Conference: Baltimore\
    \ Convention Center,\n           Baltimore, MD, 10-13 October, 1989: Information\
    \ Systems\n           Security, Solutions for Today - Concepts for Tomorrow\"\
    ,\n           National Institute of Standards and National Computer\n        \
    \   Security Center, 1989.\n"
- title: 8.6  Security Checklists
  contents:
  - "8.6  Security Checklists\n   [AUCOIN]\n           Aucoin, R., \"Computer Viruses:\
    \ Checklist for Recovery\",\n           Computers in  Libraries, Vol. 9, No. 2,\
    \ Pg. 4,\n           1 February 1989.\n   [WOOD]\n           Wood, C., Banks,\
    \ W., Guarro, S., Garcia, A., Hampel, V.,\n           and H. Sartorio, \"Computer\
    \ Security:  A Comprehensive Controls\n           Checklist\", John Wiley and\
    \ Sons, Interscience Publication,\n           1987.\n"
- title: 8.7  Additional Publications
  contents:
  - "8.7  Additional Publications\n   Defense Data Network's Network Information Center\
    \ (DDN NIC)\n      The DDN NIC maintains DDN Security bulletins and DDN Management\n\
    \      bulletins online on the machine: NIC.DDN.MIL.  They are available\n   \
    \   via anonymous FTP.  The DDN Security bulletins are in the\n      directory:\
    \ SCC, and the DDN Management bulletins are in the\n      directory: DDN-NEWS.\n\
    \      For additional information, you may send a message to:\n      NIC@NIC.DDN.MIL,\
    \ or call the DDN NIC at: 1-800-235-3155.\n   [DDN88]\n           Defense Data\
    \ Network, \"BSD 4.2 and 4.3 Software Problem\n           Resolution\", DDN MGT\
    \ Bulletin #43, DDN Network Information\n           Center, 3 November 1988.\n\
    \           A Defense Data Network Management Bulletin announcement\n        \
    \   on the 4.2bsd and 4.3bsd software fixes to the Internet\n           worm.\n\
    \   [DDN89]\n           DCA DDN Defense Communications System, \"DDN Security\n\
    \           Bulletin 03\", DDN Security Coordination Center,\n           17 October\
    \ 1989.\n   IEEE Proceedings\n   [IEEE]\n           \"Proceedings of the IEEE\
    \ Symposium on Security\n           and Privacy\", published annually.\n     \
    \ IEEE Proceedings are available from:\n              Computer Society of the\
    \ IEEE\n              P.O. Box 80452\n              Worldway Postal Center\n \
    \             Los Angeles, CA  90080\n   Other Publications:\n      Computer Law\
    \ and Tax Report\n      Computers and Security\n      Security Management Magazine\n\
    \      Journal of Information Systems Management\n      Data Processing & Communications\
    \ Security\n      SIG Security, Audit & Control Review\n"
- title: 9.  Acknowledgments
  contents:
  - "9.  Acknowledgments\n   Thanks to the SSPHWG's illustrious \"Outline Squad\"\
    , who assembled at\n   USC/Information Sciences Institute on 12-June-90: Ray Bates\
    \ (ISI),\n   Frank Byrum (DEC), Michael A. Contino (PSU), Dave Dalva (Trusted\n\
    \   Information Systems, Inc.), Jim Duncan (Penn State Math Department),\n   Bruce\
    \ Hamilton (Xerox), Sean Kirkpatrick (Unisys), Tom Longstaff\n   (CIAC/LLNL),\
    \ Fred Ostapik (SRI/NIC), Keith Pilotti (SAIC), and Bjorn\n   Satdeva (/sys/admin,\
    \ inc.).\n   Many thanks to Rich Pethia and the Computer Emergency Response Team\n\
    \   (CERT); much of the work by Paul Holbrook was done while he was\n   working\
    \ for CERT.  Rich also provided a very thorough review of this\n   document. \
    \ Thanks also to Jon Postel and USC/Information Sciences\n   Institute for contributing\
    \ facilities and moral support to this\n   effort.\n   Last, but NOT least, we\
    \ would like to thank members of the SSPHWG and\n   Friends for their additional\
    \ contributions: Vint Cerf (CNRI),\n   Dave Grisham (UNM), Nancy Lee Kirkpatrick\
    \ (Typist Extraordinaire),\n   Chris McDonald (WSMR), H. Craig McKee (Mitre),\
    \ Gene Spafford (Purdue),\n   and Aileen Yuan (Mitre).\n"
- title: 10.  Security Considerations
  contents:
  - "10.  Security Considerations\n   If security considerations had not been so widely\
    \ ignored in the\n   Internet, this memo would not have been possible.\n"
- title: 11.  Authors' Addresses
  contents:
  - "11.  Authors' Addresses\n   J. Paul Holbrook\n   CICNet, Inc.\n   2901 Hubbard\n\
    \   Ann Arbor, MI 48105\n   Phone: (313) 998-7680\n   EMail: holbrook@cic.net\n\
    \   Joyce K. Reynolds\n   University of Southern California\n   Information Sciences\
    \ Institute\n   4676 Admiralty Way\n   Marina del Rey, CA 90292\n   Phone: (213)\
    \ 822-1511\n   EMail: JKREY@ISI.EDU\n"
