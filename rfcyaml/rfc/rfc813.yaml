- title: __initial_text__
  contents:
  - "                WINDOW AND ACKNOWLEDGEMENT STRATEGY IN TCP\n                \
    \             David D. Clark\n                  MIT Laboratory for Computer Science\n\
    \               Computer Systems and Communications Group\n                  \
    \             July, 1982\n     1.  Introduction\n     This  document describes\
    \ implementation strategies to deal with two\nmechanisms in TCP, the window and\
    \ the acknowledgement.  These mechanisms\nare described in the specification document,\
    \ but it is  possible,  while\ncomplying with the specification, to produce implementations\
    \ which yield\nvery  bad  performance.    Happily,  the pitfalls possible in window\
    \ and\nacknowledgement strategies are very easy to avoid.\n     It is a much more\
    \ difficult exercise to verify the performance of a\nspecification than the correctness.\
    \  Certainly, we have less  experience\nin  this  area,  and  we  certainly  lack\
    \  any  useful formal technique.\nNonetheless, it is important to attempt a specification\
    \  in  this  area,\nbecause  different  implementors  might  otherwise  choose\
    \ superficially\nreasonable algorithms  which  interact  poorly  with  each  other.\
    \  This\ndocument  presents  a  particular  set of algorithms which have received\n\
    testing in the field, and which appear to work properly with each other.\n2. \
    \ The Mechanisms\n     The acknowledgement mechanism is at the heart of TCP. \
    \ Very simply,\nwhen  data  arrives at the recipient, the protocol requires that\
    \ it send\nback an acknowledgement of this data.  The protocol specifies  that\
    \  the\nbytes  of  data  are  sequentially  numbered,  so that the recipient can\n\
    acknowledge data by naming the highest numbered  byte  of  data  it  has\nreceived,\
    \  which  also  acknowledges  the  previous  bytes (actually, it\nidentifies the\
    \ first byte of data which it has  not  yet  received,  but\nthis is a small detail).\
    \  The protocol contains only a general assertion\nthat  data  should  be acknowledged\
    \ promptly, but gives no more specific\nindication as to how quickly an acknowledgement\
    \ must  be  sent,  or  how\nmuch data should be acknowledged in each separate\
    \ acknowledgement.\n     The window mechanism is a flow control tool.  Whenever\
    \ appropriate,\nthe  recipient of data returns to the sender a number, which is\
    \ (more or\nless) the size of the buffer which the receiver currently has  available\n\
    for  additional  data.   This number of bytes, called the window, is the\nmaximum\
    \ which the sender is permitted to  transmit  until  the  receiver\nreturns  some\
    \  additional  window.  Sometimes, the receiver will have no\nbuffer space available,\
    \ and will return a window value of zero.    Under\nthese  circumstances,the \
    \ protocol  requires  the sender to send a small\nsegment to the receiver now\
    \ and then, to see if more data  is  accepted.\nIf  the  window  remains closed\
    \ at zero for some substantial period, and\nthe sender can obtain  no  response\
    \  from  the  receiver,  the  protocol\ninformation  in  the  specification, describing\
    \ under what circumstances\nthe window should be increased, and how the  sender\
    \  should  respond  to\nsuch revised information.\n     A  bad implementation\
    \ of the window algorithm can lead to extremely\npoor performance overall.  The\
    \ degradations which  occur  in  throughput\nand  CPU  utilizations  can easily\
    \ be several factors of ten, not just a\nfractional increase.  This particular\
    \ phenomenon is specific enough that\nit has been given the name of Silly Window\
    \ Syndrome, or  SWS.    Happily\nSWS  is  easy  to  avoid  if  a few simple rules\
    \ are observed.  The most\nimportant function of this memo is to describe SWS,\
    \ so that implementors\nwill understand the general nature  of  the  problem,\
    \  and  to  describe\nalgorithms  which  will  prevent  its  occurrence.    This\
    \ document also\ndescribes   performance   enhancing   algorithms   which    relate\
    \    to\nacknowledgement,  and  discusses  the  way  acknowledgement  and  window\n\
    algorithms interact as part of SWS.\n     3.  SILLY WINDOW SYNDROME\n     In order\
    \ to understand SWS, we must first  define  two  new  terms.\nSuperficially, \
    \ the window mechanism is very simple:  there is a number,\ncalled \"the window\"\
    , which is returned from the receiver to the  sender.\nHowever,  we  must have\
    \ a more detailed way of talking about the meaning\nof this number.  The receiver\
    \ of data computes a  value  which  we  will\ncall  the  \"offered  window\".\
    \    In  a  simple  case, the offered window\ncorresponds to the amount of buffer\
    \ space  available  in  the  receiver.\nactually  transmitted  back from the receiver\
    \ to the sender.  The sender\nuses the offered window  to  compute  a  different\
    \  value,  the  \"usable\nwindow\",  which  is  the  offered window minus the\
    \ amount of outstanding\nunacknowledged data.  The usable window is less than\
    \  or  equal  to  the\noffered window, and can be much smaller.\n     Consider\
    \  the  following  simple  example.   The receiver initially\nprovides an offered\
    \ window of 1,000.  The sender uses up this window  by\nsending  five  segments\
    \  of 200 bytes each.  The receiver, on processing\nthe first of these  segments,\
    \  returns  an  acknowledgement  which  also\ncontains  an  updated  window value.\
    \  Let us assume that the receiver of\nthe data has removed the first 200 bytes\
    \ from the buffer,  so  that  the\nreceiver once again has 1,000 bytes of available\
    \ buffer.  Therefore, the\nreceiver would return, as before, an offered window\
    \ of 1,000 bytes.  The\nsender,  on  receipt  of  this  first  acknowledgement,\
    \ now computes the\nadditional number of bytes which may be sent.  In  fact, \
    \ of  the  1,000\nbytes  which  the recipient is prepared to receive at this time,\
    \ 800 are\nalready in transit, having been sent in response to the previous offered\n\
    window.  In this case, the usable window is only 200 bytes.\n     Let us now consider\
    \ how SWS  arises.    To  continue  the  previous\nexample,  assume  that at some\
    \ point, when the sender computes a useable\nwindow of 200 bytes, it has only\
    \ 50 bytes to send  until  it  reaches  a\n\"push\"  point.   It thus sends 50\
    \ bytes in one segment, and 150 bytes in\nthe next segment. Sometime later, this\
    \ 50-byte segment  will  arrive  at\ncompute  that there are 950 bytes in transit\
    \ in the network, so that the\nuseable window is now only 50 bytes.  Thus, the\
    \ sender will  once  again\nsend  a  50  byte  segment,  even  though  there \
    \ is no longer a natural\nboundary to force it.\n     In fact, whenever the acknowledgement\
    \  of  a  small  segment  comes\nback, the useable window associated with that\
    \ acknowledgement will cause\nanother  segment  of  the  same  small  size  to\
    \  be  sent,  until  some\nabnormality breaks the pattern.  It is easy to see\
    \  how  small  segments\narise,  because  natural  boundaries  in the data occasionally\
    \ cause the\nsender to take a computed useable window and divide it  up  between\
    \  two\nsegments.   Once that division has occurred, there is no natural way for\n\
    those useable window allocations to be recombined; thus the breaking  up\nof the\
    \ useable window into small pieces will persist.\n     Thus,  SWS  is a degeneration\
    \ in the throughput which develops over\ntime, during a long data transfer.  If\
    \ the sender  ever  stops,  as  for\nexample  when  it runs out of data to send,\
    \ the receiver will eventually\nacknowledge all  the  outstanding  data,  so \
    \ that  the  useable  window\ncomputed  by  the  sender  will  equal  the  full\
    \  offered window of the\nreceiver.  At this point the situation will  have  healed,\
    \  and  further\ndata  transmission  over  the  link will occur efficiently. \
    \ However, in\nlarge file transfers, which occur without interruption,  SWS  can\
    \  cause\nappalling  performance.  The network between the sender and the receiver\n\
    becomes clogged with  many  small  segments,  and  an  equal  number  of\naverage\
    \  segment  size was one-tenth of the size the sender and receiver\nwere prepared\
    \ to deal with, and the average number of retransmission per\nsuccessful segments\
    \ sent was five.\n     Happily, SWS is trivial to avoid.  The following sections\
    \  describe\ntwo  algorithms,  one  executed  by the sender, and one by the receiver,\n\
    which appear to eliminate SWS completely.  Actually, either algorithm by\nitself\
    \ is sufficient to prevent SWS, and thus  protect  a  host  from  a\nforeign \
    \ implementation  which  has  failed  to  deal properly with this\nproblem.  The\
    \  two  algorithms  taken  together  produce  an  additional\nreduction  in  CPU\
    \  consumption, observed in practice to be as high as a\nfactor of four.\n   \
    \  4.  Improved Window Algorithms\n     The receiver of data can take a very simple\
    \ step to eliminate  SWS.\nWhen  it  disposes of a small amount of data, it can\
    \ artificially reduce\nthe offered window in subsequent acknowledgements, so that\
    \  the  useable\nwindow computed by the sender does not permit the sending of\
    \ any further\ndata.     At  some  later  time,  when  the  receiver  has  processed\
    \  a\nsubstantially larger amount of incoming data, the artificial  limitation\n\
    on  the  offered  window  can be removed all at once, so that the sender\ncomputes\
    \ a sudden large jump rather than a sequence of  small  jumps  in\nthe useable\
    \ window.\n     At  this  level,  the  algorithm  is  quite simple, but in order\
    \ to\nDepending  on whether the window is held artificially closed for a short\n\
    or long time, two problems will  develop.    The  one  we  have  already\ndiscussed\
    \  -- never closing the window artificially -- will lead to SWS.\nOn the other\
    \ hand, if  the  window  is  only  opened  infrequently,  the\npipeline  of data\
    \ in the network between the sender and the receiver may\nhave emptied out while\
    \ the sender was being held off, so that a delay is\nintroduced before additional\
    \ data arrives from the sender.   This  delay\ndoes reduce throughput, but it\
    \ does not consume network resources or CPU\nresources  in  the  process, as does\
    \ SWS.  Thus, it is in this direction\nthat one ought to overcompensate.  For\
    \ a simple implementation,  a  rule\nof  thumb  that  seems to work in practice\
    \ is to artificially reduce the\noffered window until the reduction constitutes\
    \ one half of the available\nspace, at which point increase the window to advertise\
    \ the entire  space\nagain.  In any event, one ought to make the chunk by which\
    \ the window is\nopened  at  least permit one reasonably large segment.  (If the\
    \ receiver\nis so short of buffers that it can never advertise a large enough\
    \ buffer\nto permit at least one large segment, it is hopeless to expect any \
    \ sort\nof high throughput.)\n     There  is  an algorithm that the sender can\
    \ use to achieve the same\neffect described above:  a very simple and elegant\
    \ rule first  described\nby  Michael  Greenwald  at MIT.  The sender of the data\
    \ uses the offered\nwindow to compute a useable window, and then compares the\
    \ useable window\nto the offered window, and refrains from sending anything if\
    \  the  ratio\nof  useable to offered is less than a certain fraction.  Clearly,\
    \ if the\nin  the  pipeline  from  the sender to the receiver, which in turn means\n\
    that the sender can count on being granted a larger  useable  window  in\nthe\
    \  future.    Until  the  useable window reaches a certain amount, the\nsender\
    \ should simply refuse to send anything.\n     Simple experiments suggest that\
    \ the exact value of the ratio is not\nvery important, but that a value of about\
    \ 25 percent  is  sufficient  to\navoid  SWS  and  achieve reasonable throughput,\
    \ even for machines with a\nsmall offered window.    An  additional  enhancement\
    \  which  might  help\nthroughput  would be to attempt to hold off sending until\
    \ one can send a\nmaximum size segment.  Another enhancement would be to send\
    \ anyway, even\nif the ratio is small, if the useable window is sufficient to\
    \  hold  the\ndata available up to the next \"push point\".\n     This algorithm\
    \ at the sender end is very simple.  Notice that it is\nnot  necessary  to  set\
    \  a timer to protect against protocol lockup when\npostponing the  send  operation.\
    \    Further  acknowledgements,  as  they\narrive,  will  inevitably change the\
    \ ratio of offered to useable window.\n(To see this, note that when all the data\
    \ in the  catanet  pipeline  has\narrived  at  the  receiver,  the resulting acknowledgement\
    \ must yield an\noffered window and  useable  window  that  equal  each  other.)\
    \  If  the\nexpected  acknowledgements  do  not arrive, the retransmission mechanism\n\
    will come into play to assure that something finally happens.  Thus,  to\nadd\
    \  this  algorithm  to an existing TCP implementation usually requires\none line\
    \ of code.  As part of the send algorithm it is already necessary\npercent,  sets\
    \  the  useable  window to zero.  The results of SWS are so\ndevastating that\
    \ no sender  should  be  without  this  simple  piece  of\ninsurance.\n     5.\
    \  Improved Acknowledgement Algorithms\n     In the beginning of this paper, an\
    \ overly simplistic implementation\nof  TCP  was described, which led to SWS.\
    \  One of the characteristics of\nthis implementation was that the  recipient\
    \  of  data  sent  a  separate\nacknowledgement  for  every  segment  that it\
    \ received.  This compulsive\nacknowledgement  was  one  of  the   causes   of\
    \   SWS,   because   each\nacknowledgement provided some new useable window, but\
    \ even if one of the\nalgorithms  described  above  is  used to eliminate SWS,\
    \ overly frequent\nacknowledgement still has  a  substantial  problem,  which\
    \  is  that  it\ngreatly  increases the processing time at the sender's end. \
    \ Measurement\nof TCP implementations, especially on large operating systems,\
    \  indicate\nthat  most  of  the  overhead  of  dealing  with a segment is not\
    \ in the\nprocessing at the TCP or IP level, but simply in the scheduling  of\
    \  the\nhandler which is required to deal with the segment.  A steady dribble\
    \ of\nacknowledgements  causes a high overhead in scheduling, with very little\n\
    to show for it.  This waste is to be avoided if possible.\n     There are two\
    \ reasons  for  prompt  acknowledgement.    One  is  to\nprevent  retransmission.\
    \  We will discuss later how to determine whether\nunnecessary  retransmission\
    \  is  occurring.    The  other   reason   one\nacknowledges  promptly  is  to\
    \ permit further data to be sent.  However,\nit.    Therefore,  one  can  state\
    \  a  general  rule  that  under normal\noperation, the receiver of data need\
    \ not,  and  for  efficiency  reasons\nshould  not,  acknowledge  the data unless\
    \ either the acknowledgement is\nintended to produce an increased useable window,\
    \ is necessary  in  order\nto  prevent  retransmission  or  is  being  sent  as\
    \  part  of a reverse\ndirection segment being sent for some other reason.  We\
    \ will consider an\nalgorithm to achieve these goals.\n     Only the recipient\
    \ of  the  data  can  control  the  generation  of\nacknowledgements.    Once\
    \  an  acknowledgement  has  been  sent from the\nreceiver back to the sender,\
    \ the sender must process it.   Although  the\nextra overhead is incurred at the\
    \ sender's end, it is entirely under the\nreceiver's  control.  Therefore, we\
    \ must now describe an algorithm which\noccurs at the receiver's end.  Obviously,\
    \ the algorithm  must  have  the\nfollowing  general form; sometimes the receiver\
    \ of data, upon processing\na segment, decides not to send an acknowledgement\
    \ now, but  to  postpone\nthe  acknowledgement until some time in the future,\
    \ perhaps by setting a\ntimer.  The peril of this approach  is  that  on  many\
    \  large  operating\nsystems  it  is  extremely costly to respond to a timer event,\
    \ almost as\ncostly as to respond to an incoming segment.  Clearly, if  the  receiver\n\
    of  the data, in order to avoid extra overhead at the sender end, spends\na great\
    \ deal of time responding to timer interrupts, no overall  benefit\nhas been achieved,\
    \ for efficiency at the sender end is achieved by great\nthrashing  at  the  receiver\
    \ end.  We must find an algorithm that avoids\nboth of these perils.\nwill   refrain\
    \   from   sending   an   acknowledgement   under   certain\ncircumstances, in\
    \ which case it must set a timer which  will  cause  the\nacknowledgement  to\
    \ be sent later.  However, the receiver should do this\nonly where it is a reasonable\
    \ guess that some other event will intervene\nand prevent the necessity of the\
    \ timer  interrupt.    The  most  obvious\nevent  on  which  to depend is the\
    \ arrival of another segment.  So, if a\nsegment arrives, postpone sending an\
    \  acknowledgement  if  both  of  the\nfollowing  conditions  hold.    First,\
    \  the  push  bit is not set in the\nsegment, since it is a reasonable assumption\
    \ that  there  is  more  data\ncoming  in  a  subsequent  segment.   Second, there\
    \ is no revised window\ninformation to be sent back.\n     This algorithm will\
    \ insure that the timer, although set, is  seldom\nused.    The  interval  of\
    \  the  timer is related to the expected inter-\nsegment delay, which is in turn\
    \ a function  of  the  particular  network\nthrough  which  the  data  is  flowing.\
    \    For the Arpanet, a reasonable\ninterval seems to be 200 to 300 milliseconds.\
    \  Appendix A  describes  an\nadaptive algorithm for measuring this delay.\n \
    \    The section on improved window algorithms described both a receiver\nalgorithm\
    \  and  a  sender  algorithm,  and suggested that both should be\nused.  The reason\
    \ for this is now clear.  While the sender algorithm  is\nextremely  simple, \
    \ and  useful  as insurance, the receiver algorithm is\nrequired in order that\
    \ this improved acknowledgement strategy work.   If\nthe  receipt  of every segment\
    \ causes a new window value to be returned,\nreceiver  determines  to artificially\
    \ reduce the offered window, that is\nprecisely the circumstance under which an\
    \ acknowledgement  need  not  be\nsent.      When   the   receiver   window  algorithm\
    \  and  the  receiver\nacknowledgement algorithm are  used  together,  it  will\
    \  be  seen  that\nsending  an  acknowledgement  will  be triggered by one of\
    \ the following\nevents.  First, a push bit has been received.  Second, a temporary\
    \ pause\nin the data stream is detected.  Third,  the  offered  window  has  been\n\
    artificially reduced to one-half its actual value.\n     In the beginning of this\
    \ section, it was pointed out that there are\ntwo  reasons  why  one must acknowledge\
    \ data.  Our consideration at this\npoint has been concerned only with the first,\
    \  that  an  acknowledgement\nmust  be  returned as part of triggering the sending\
    \ of new data.  It is\nalso necessary to acknowledge  whenever  the  failure \
    \ to  do  so  would\ntrigger retransmission by the sender.  Since the retransmission\
    \ interval\nis  selected  by  the  sender,  the  receiver  of the data cannot\
    \ make a\nprecise  determination  of  when  the  acknowledgement  must  be   sent.\n\
    However,   there   is   a  rough  rule  the  sender  can  use  to  avoid\nretransmission,\
    \ provided that the receiver is reasonably well behaved.\n     We will assume\
    \ that sender of the data uses the optional  algorithm\ndescribed  in  the  TCP\
    \  specification,  in which the roundtrip delay is\nmeasured using an exponential\
    \ decay smoothing algorithm.  Retransmission\nof a segment occurs if the measured\
    \ delay for that segment  exceeds  the\nsmoothed  average  by  some  factor. \
    \ To see how retransmission might be\na  number of segments in close sequence,\
    \ and receive one acknowledgement\nfor the whole burst.  The  acknowledgement\
    \  will  be  generated  by  the\nreceiver  at  the time that the last segment\
    \ in the burst arrives at the\nreceiver.  (To ensure the prompt  return  of  the\
    \  acknowledgement,  the\nsender  could  turn on the \"push\" bit in the last\
    \ segment of the burst.)\nThe delay observed at the sender between the initial\
    \ transmission  of  a\nsegment  and  the  receipt  of the acknowledgement will\
    \ include both the\nnetwork transit time, plus the  holding  time  at  the  receiver.\
    \    The\nholding  time  will be greatest for the first segments in the burst,\
    \ and\nsmallest for the last segments  in  the  burst.    Thus,  the  smoothing\n\
    algorithm  will  measure  a  delay  which is roughly proportional to the\naverage\
    \ roundtrip delay for all the segments in  the  burst.    Problems\nwill  arise\
    \  if  the  average  delay  is  substantially smaller than the\nmaximum delay\
    \  and  the  smoothing  algorithm  used  has  a  very  small\nthreshold  for \
    \ triggering retransmission.  The widest variation between\naverage and maximum\
    \ delay  will  occur  when  network  transit  time  is\nnegligible, and all delay\
    \ is processing time.  In this case, the maximum\nwill  be  twice  the  average\
    \  (by simple algebra) so the threshold that\ncontrols retransmission should be\
    \ somewhat more than a factor of two.\n     In practice, retransmission of the\
    \ first segments of  a  burst  has\nnot  been  a  problem because the delay measured\
    \ consists of the network\nroundtrip  delay,  as  well  as  the  delay  due  to\
    \   withholding   the\nacknowledgement,  and the roundtrip tends to dominate except\
    \ in very low\nroundtrip time situations (such as when sending to one's self \
    \ for  test\npurposes).    This low roundtrip situation can be covered very simply\
    \ by\n     In  our  experiments  with  this  algorithm,  retransmission due to\n\
    faulty calculation of the roundtrip delay occurred only once,  when  the\nparameters\
    \  of  the exponential smoothing algorithm had been misadjusted\nso that they\
    \ were only  taking  into  account  the  last  two  or  three\nsegments  sent.\
    \   Clearly, this will cause trouble since the last two or\nthree segments of\
    \ any burst are the  ones  whose  holding  time  at  the\nreceiver is minimal,\
    \ so the resulting total estimate was much lower than\nappropriate.   Once the\
    \ parameters of the algorithm had been adjusted so\nthat the number of segments\
    \ taken into account was  approximately  twice\nthe  number  of  segments  in\
    \  a burst of average size, with a threshold\nfactor of 1.5, no further retransmission\
    \ has ever been identified due to\nthis problem, including when sending to ourself\
    \ and  when  sending  over\nhigh delay nets.\n     6.  Conservative Vs. Optimistic\
    \ Windows\n     According  to the TCP specification, the offered window is presumed\n\
    to have some relationship to the amount of data which  the  receiver  is\nactually\
    \  prepared  to receive.  However, it is not necessarily an exact\ncorrespondence.\
    \  We will use the term \"conservative window\" to  describe\nthe case where the\
    \ offered window is precisely no larger than the actual\nbuffering  available.\
    \  The drawback to conservative window algorithms is\nthat they can produce very\
    \ low throughput in long delay situations.   It\nis easy to see that the maximum\
    \ input of a conservative window algorithm\nis  one  bufferfull  every  roundtrip\
    \  delay  in the net, since the next\n     In  certain  cases,  it  may  be  possible\
    \  to increase the overall\nthroughput of the transmission by increasing the offered\
    \ window over the\nactual buffer available at the receiver.  Such a strategy we\
    \  will  call\nan  \"optimistic  window\" strategy.  The optimistic strategy works\
    \ if the\nnetwork delivers the data to the recipient sufficiently slowly  that\
    \  it\ncan  process  the  data fast enough to keep the buffer from overflowing.\n\
    If the receiver is faster than the sender, one could, with luck,  permit\nan infinitely\
    \ optimistic window, in which the sender is simply permitted\nto send full-speed.\
    \  If the sender is faster than the receiver, however,\nand the window is too\
    \ optimistic, then some segments will cause a buffer\noverflow,  and  will  be\
    \  discarded.  Therefore, the correct strategy to\nimplement an optimistic window\
    \ is to  increase  the  window  size  until\nsegments  start to be lost.  This\
    \ only works if it is possible to detect\nthat the segment has been lost.  In\
    \  some  cases,  it  is  easy  to  do,\nbecause  the  segment  is  partially processed\
    \ inside the receiving host\nbefore it is thrown away.  In other cases, overflows\
    \ may actually  cause\nthe network interface to be clogged, which will cause the\
    \ segments to be\nlost  elsewhere  in the net.  It is inadvisable to attempt an\
    \ optimistic\nwindow strategy unless one is certain that the algorithm can detect\
    \  the\nresulting  lost  segments.  However, the increase in throughput which\
    \ is\npossible from optimistic windows is quite substantial.  Any systems with\n\
    small buffer space should seriously consider  the  merit  of  optimistic\nwindows.\n\
    \     The  selection  of an appropriate window algorithm is actually more\nincorporated\
    \  in  current  implementations of TCP, but as background for\nthe sophisticated\
    \ designer who is attempting to understand how  his  TCP\nwill  respond  to  a\
    \ variety of networks, with different speed and delay\ncharacteristics.  The particular\
    \ pattern of windows and acknowledgements\nsent from receiver to sender influences\
    \ two characteristics of the  data\nbeing  sent.    First, they control the average\
    \ data rate.  Clearly, the\naverage rate of the  sender  cannot  exceed  the \
    \ average  rate  of  the\nreceiver,  or  long-term  buffer  overflow  will  occur.\
    \    Second, they\ninfluence the burstiness of the data coming from the sender.\
    \  Burstiness\nhas both advantages and disadvantages.  The advantage of  burstiness\
    \  is\nthat  it  reduces  the  CPU processing necessary to send the data.  This\n\
    follows from the observed fact, especially on large machines, that  most\nof \
    \ the  cost  of sending a segment is not the TCP or IP processing, but\nthe scheduling\
    \ overhead of getting started.\n     On the other hand, the disadvantage of burstiness\
    \ is  that  it  may\ncause  buffers  to overflow, either in the eventual recipient,\
    \ which was\ndiscussed above, or in an intermediate gateway,  a  problem  ignored\
    \  in\nthis paper.  The algorithms described above attempts to strike a balance\n\
    between  excessive  burstiness,  which  in  the  extreme cases can cause\ndelays\
    \ because a burst is  not  requested  soon  enough,  and  excessive\nfragmentation\
    \   of  the  data  stream  into  small  segments,  which  we\nidentified as Silly\
    \ Window Syndrome.\n     Under conditions of extreme delay  in  the  network,\
    \  none  of  the\nwhich  is one windowfull per roundtrip delay.  Attempts to solve\
    \ this by\noptimistic window strategies may  cause  buffer  overflows  due  to\
    \  the\nbursty  nature  of the arriving data.  A very sophisticated way to solve\n\
    this is for the receiver, having measured by some  means  the  roundtrip\ndelay\
    \  and  intersegment  arrival rate of the actual connection, to open\nhis window,\
    \ not in one optimistic increment of gigantic proportion,  but\nin  a number of\
    \ smaller optimistic increments, which have been carefully\nspaced using a timer\
    \ so that the resulting smaller bursts  which  arrive\nare each sufficiently small\
    \ to fit into the existing buffers.  One could\nvisualize this as a number of\
    \ requests flowing backwards through the net\nwhich trigger in return a number\
    \ of bursts which flow back spaced evenly\nfrom  the  sender  to  the  receiver.\
    \    The  overall result is that the\nreceiver uses the window mechanism to  control\
    \  the  burstiness  of  the\narrivals, and the average rate.\n     To  my knowledge,\
    \ no such strategy has been implemented in any TCP.\nFirst, we do not normally\
    \ have delays high enough to require  this  kind\nof  treatment.    Second,  the\
    \  strategy described above is probably not\nstable unless it is very carefully\
    \ balanced.  Just as buses on a  single\nbus  route tend to bunch up, bursts which\
    \ start out equally spaced could\nwell end up piling into each other, and forming\
    \ the single  large  burst\nwhich  the  receiver was hoping to avoid.  It is important\
    \ to understand\nthis extreme case, however, in order to  understand  the  limits\
    \  beyond\nwhich  TCP,  as normally implemented, with either conservative or simple\n\
    \     7.  Conclusions\n     This  paper  describes  three  simple  algorithms\
    \  for  performance\nenhancement in TCP, one at the sender end and two at the\
    \ receiver.   The\nsender  algorithm  is  to  refrain from sending if the useable\
    \ window is\nsmaller than 25 percent of the offered window.  The receiver  algorithms\n\
    are first, to artificially reduce the offered window when processing new\ndata\
    \  if  the  resulting  reduction  does  not  represent more than some\nfraction,\
    \ say 50 percent, of the actual space available, and second,  to\nrefrain  from\
    \  sending an acknowledgment at all if two simple conditions\nhold.\n     Either\
    \ of these algorithms will prevent the worst aspects of  Silly\nWindow  Syndrome,\
    \ and when these algorithms are used together, they will\nproduce substantial\
    \ improvement in CPU utilization, by  eliminating  the\nprocess of excess acknowledgements.\n\
    \     Preliminary  experiments  with  these  algorithms suggest that they\nwork,\
    \ and work very well.  Both the sender and receiver algorithms  have\nbeen  shown\
    \  to  eliminate  SWS,  even  when  talking  to  fairly  silly\nalgorithms at\
    \ the other end.  The Multics  mailer,  in  particular,  had\nsuffered substantial\
    \ attacks of SWS while sending large mail to a number\nof  hosts.   We believe\
    \ that implementation of the sender side algorithm\nhas  eliminated  every  known\
    \  case  of  SWS  detected  in  our  mailer.\nImplementation  of  the  receiver\
    \  side  algorithm  produced substantial\nimprovements of CPU time when Multics\
    \ was the sending system.    Multics\nTests were done sending from Multics to\
    \ a host which implemented the SWS\nsuppression  algorithm,  and  which  could\
    \  either  refrain  or not from\nsending acknowledgements on each segment.  As\
    \ predicted, suppressing the\nreturn acknowledgements did not influence the throughput\
    \ for large  data\ntransfer  at  all,  since the throttling effect was elsewhere.\
    \  However,\nthe CPU time required to process the data at the Multics end was\
    \ cut  by\na  factor  of  four  (In  this experiment, the bursts of data which\
    \ were\nbeing sent were approximately eight  segments.    Thus,  the  number \
    \ of\nacknowledgements in the two experiments differed by a factor of eight.)\n\
    \     An  important  consideration in evaluating these algorithms is that\nthey\
    \ must not cause the protocol implementations to deadlock.    All  of\nthe  recommendations\
    \  in this document have the characteristic that they\nsuggest one refrain  from\
    \  doing  something  even  though  the  protocol\nspecification  permits one to\
    \ do it.  The possibility exists that if one\nrefrains from doing something now\
    \ one may never get to do it later,  and\nboth  ends will halt, even though it\
    \ would appear superficially that the\ntransaction can continue.\n     Formally,\
    \ the idea that things continue to work is referred  to  as\n\"liveness\".   \
    \ One  of  the  defects  of ad hoc solutions to performance\nproblems is the possibility\
    \ that two different approaches will  interact\nto  prevent  liveness.   It is\
    \ believed that the algorithms described in\nthis paper are always live, and that\
    \ is one of the reasons why there  is\na strong advantage in uniform use of this\
    \ particular proposal, except in\ncases where it is explicitly demonstrated not\
    \ to work.\nFirst,  the sender algorithm can only be stopped by one thing, a refusal\n\
    of the receiver to acknowledge sent data.    As  long  as  the  receiver\ncontinues\
    \  to  acknowledge  data, the ratio of useable window to offered\nwindow will\
    \ approach one, and eventually the  sender  must  continue  to\nsend.    However,\
    \  notice  that the receiver algorithm we have advocated\ninvolves refraining\
    \ from acknowledging.  Therefore, we certainly do have\na situation where improper\
    \  operation  of  this  algorithm  can  prevent\nliveness.\n     What  we  must\
    \ show is that the receiver of the data, if it chooses\nto refrain from acknowledging,\
    \ will do so only for a short time, and not\nforever.  The design of the algorithm\
    \ described above  was  intended  to\nachieve  precisely  this  goal:  whenever\
    \ the receiver of data refrained\nfrom sending an acknowledgement it was required\
    \ to set  a  timer.    The\nonly  event  that  was  permitted to clear that timer\
    \ was the receipt of\nanother segment, which essentially reset the timer, and\
    \ started it going\nagain.  Thus, an acknowledgement will be sent as soon  as\
    \  no  data  has\nbeen received.  This has precisely the effect desired:  if the\
    \ data flow\nappears to be disrupted for any reason, the receiver responds by\
    \ sending\nan  up-to-date  acknowledgement.    In  fact,  the receiver algorithm\
    \ is\ndesigned  to  be  more  robust  than  this,  for  transmission   of   an\n\
    acknowledgment is triggered by two events, either a cessation of data or\na  reduction\
    \ in the amount of offered window to 50 percent of the actual\n              \
    \                 APPENDIX A\n     Dynamic Calculation of Acknowledgement Delay\n\
    \     The  text  suggested  that  when  setting  a  timer to postpone the\nsending\
    \  of  an  acknowledgement,  a  fixed  interval  of  200  to   300\nmilliseconds\
    \  would  work  properly  in  practice.    This  has not been\nverified over a\
    \ wide variety of network delays, and clearly if there  is\na  very  slow  net\
    \  which stretches out the intersegment arrival time, a\nfixed interval will fail.\
    \  In a sophisticated TCP, which is expected  to\nadjust   dynamically   (rather\
    \   than   manually)  to  changing  network\nconditions, it would be appropriate\
    \ to measure this interval and respond\ndynamically.  The following algorithm,\
    \ which has been  relegated  to  an\nAppendix,  because  it  has not been tested,\
    \ seems sensible.  Whenever a\nsegment arrives which does not have the push  bit\
    \  on  in  it,  start  a\ntimer,  which  runs  until  the  next  segment  arrives.\
    \   Average these\ninterarrival intervals, using an exponential  decay  smoothing\
    \  function\ntuned  to take into account perhaps the last ten or twenty segments\
    \ that\nhave come in.  Occasionally, there will be a long  interarrival  period,\n\
    even  for  a  segment  which is does not terminate a piece of data being\npushed,\
    \ perhaps because a window has gone to zero or some glitch in  the\nsender  or\
    \  the  network  has held up the data.  Therefore, examine each\ninterarrival\
    \ interval, and discard it from the smoothing algorithm if it\nexceeds the current\
    \ estimate by some amount, perhaps a ratio of  two  or\na  burst.   The number\
    \ need not be exact, since the timer which triggers\nacknowledgement can add a\
    \ fairly generous fudge factor to  this  without\ncausing  trouble  with  the\
    \  sender's  estimate  of  the  retransmission\n"
