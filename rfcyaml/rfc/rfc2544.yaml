- title: __initial_text__
  contents:
  - '       Benchmarking Methodology for Network Interconnect Devices

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (1999).  All Rights Reserved.\n"
- title: IESG Note
  contents:
  - "IESG Note\n   This document is a republication of RFC 1944 correcting the values\n\
    \   for the IP addresses which were assigned to be used as the default\n   addresses\
    \ for networking test equipment. (See section C.2.2 ).  This\n   RFC replaces\
    \ and obsoletes RFC 1944.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document discusses and defines a number of tests that may be\n\
    \   used to describe the performance characteristics of a network\n   interconnecting\
    \  device.  In addition to defining the tests this\n   document also describes\
    \ specific formats for reporting the results of\n   the tests.  Appendix A lists\
    \ the tests and conditions that we believe\n   should be included for specific\
    \ cases and gives additional\n   information about testing practices.  Appendix\
    \ B is a reference\n   listing of maximum frame rates to be used with specific\
    \ frame sizes\n   on various media and Appendix C gives some examples of frame\
    \ formats\n   to be used in testing.\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   Vendors often engage in \"specsmanship\" in an attempt to\
    \ give their\n   products a better position in the marketplace.  This often involves\n\
    \   \"smoke & mirrors\" to confuse the potential users of the products.\n   This\
    \ document defines a specific set of tests that vendors can use to\n   measure\
    \ and report the performance characteristics of network\n   devices.  The results\
    \ of these tests will provide the user comparable\n   data from different vendors\
    \ with which to evaluate these devices.\n   A previous document, \"Benchmarking\
    \ Terminology for Network\n   Interconnect Devices\" (RFC 1242), defined many\
    \ of the terms that are\n   used in this document.  The terminology document should\
    \ be consulted\n   before attempting to make use of this document.\n"
- title: 2. Real world
  contents:
  - "2. Real world\n   In producing this document the authors attempted to keep in\
    \ mind the\n   requirement that apparatus to perform the described tests must\n\
    \   actually be built.  We do not know of \"off the shelf\" equipment\n   available\
    \ to implement all of the tests but it is our opinion that\n   such equipment\
    \ can be constructed.\n"
- title: 3. Tests to be run
  contents:
  - "3. Tests to be run\n   There are a number of tests described in this document.\
    \  Not all of\n   the tests apply to all types of devices under test (DUTs). Vendors\n\
    \   should perform all of the tests that can be supported by a specific\n   type\
    \ of product.  The authors understand that it will take a\n   considerable period\
    \ of time to perform all of the recommended tests\n   nder  all of the recommended\
    \ conditions. We believe that the results\n   are worth the effort.  Appendix\
    \ A lists some of the tests and\n   conditions that we believe should be included\
    \ for specific cases.\n"
- title: 4. Evaluating the results
  contents:
  - "4. Evaluating the results\n   Performing all of the recommended tests will result\
    \ in a great deal\n   of data. Much of this data will not apply to the evaluation\
    \ of the\n   devices under each circumstance.  For example, the rate at which\
    \ a\n   router forwards IPX frames will be of little use in selecting a\n   router\
    \ for an environment that does not (and will not) support that\n   protocol. \
    \ Evaluating even that data which is relevant to a\n   particular network installation\
    \ will require experience which may not\n   be readily available. Furthermore,\
    \ selection of the tests to be run\n   and evaluation of the test data must be\
    \ done with an understanding of\n   generally accepted testing practices regarding\
    \ repeatability,\n   variance and statistical significance of small numbers of\
    \ trials.\n"
- title: 5. Requirements
  contents:
  - "5. Requirements\n   In this document, the words that are used to define the significance\n\
    \   of each particular requirement are capitalized. These words are:\n      *\
    \ \"MUST\" This word, or the words \"REQUIRED\" and \"SHALL\" mean that\n    \
    \     the item is an absolute requirement of the specification.\n      * \"SHOULD\"\
    \ This word or the adjective \"RECOMMENDED\" means that\n         there may exist\
    \ valid reasons in particular circumstances to\n         ignore this item, but\
    \ the full implications should be\n         understood and the case carefully\
    \ weighed before choosing a\n         different course.\n       * \"MAY\" This\
    \ word or the adjective \"OPTIONAL\" means that this\n         item is truly optional.\
    \  One vendor may choose to include the\n         item because a particular marketplace\
    \ requires it or because it\n         enhances the product, for example; another\
    \ vendor may omit the\n         same item.\n   An implementation is not compliant\
    \ if it fails to satisfy one or more\n   of the MUST requirements for the protocols\
    \ it implements.  An\n   implementation that satisfies all the MUST and all the\
    \ SHOULD\n   requirements for its protocols is said to be \"unconditionally\n\
    \   compliant\"; one that satisfies all the MUST requirements but not all\n  \
    \ the SHOULD requirements for its protocols is said to be\n   \"conditionally\
    \ compliant\".\n"
- title: 6. Test set up
  contents:
  - "6. Test set up\n   The ideal way to implement this series of tests is to use\
    \ a tester\n   with both transmitting and receiving ports.  Connections are made\n\
    \   from the sending ports of the tester to the receiving ports of the\n   DUT\
    \ and from the sending ports of the DUT back to the tester. (see\n   Figure 1)\
    \  Since the tester both sends the test traffic and receives\n   it back, after\
    \ the traffic has been forwarded but the DUT, the tester\n   can easily determine\
    \ if all of the transmitted packets were received\n   and verify that the correct\
    \ packets were received.  The same\n   functionality can be obtained with separate\
    \ transmitting and\n   receiving devices (see Figure 2) but unless they are remotely\n\
    \   controlled by some computer in a way that simulates the single\n   tester,\
    \ the labor required to accurately perform some of the tests\n   (particularly\
    \ the throughput test) can be prohibitive.\n                            +------------+\n\
    \                            |            |\n               +------------|  tester\
    \    |<-------------+\n               |            |            |            \
    \  |\n               |            +------------+              |\n            \
    \   |                                        |\n               |            +------------+\
    \              |\n               |            |            |              |\n\
    \               +----------->|    DUT     |--------------+\n                 \
    \           |            |\n                            +------------+\n     \
    \                         Figure 1\n         +--------+         +------------+\
    \          +----------+\n         |        |         |            |          |\
    \          |\n         | sender |-------->|    DUT     |--------->| receiver |\n\
    \         |        |         |            |          |          |\n         +--------+\
    \         +------------+          +----------+\n                             \
    \ Figure 2\n"
- title: 6.1 Test set up for multiple media types
  contents:
  - "6.1 Test set up for multiple media types\n   Two different setups could be used\
    \ to test a DUT which is used in\n   real-world networks to connect networks of\
    \ differing media type,\n   local Ethernet to a backbone FDDI ring for example.\
    \  The tester could\n   support both media types in which case the set up shown\
    \ in Figure 1\n   would be used.\n   Two identical DUTs are used in the other\
    \ test set up. (see Figure 3)\n   In many cases this set up may more accurately\
    \ simulate the real\n   world.  For example, connecting two LANs together with\
    \ a WAN link or\n   high speed backbone.  This set up would not be as good at\
    \ simulating\n   a system where clients on a Ethernet LAN were interacting with\
    \ a\n   server on an FDDI backbone.\n                               +-----------+\n\
    \                               |           |\n         +---------------------|\
    \  tester   |<---------------------+\n         |                     |       \
    \    |                      |\n         |                     +-----------+  \
    \                    |\n         |                                           \
    \             |\n         |        +----------+               +----------+   \
    \      |\n         |        |          |               |          |         |\n\
    \         +------->|  DUT 1   |-------------->|   DUT 2  |---------+\n       \
    \           |          |               |          |\n                  +----------+\
    \               +----------+\n                                  Figure 3\n"
- title: 7. DUT set up
  contents:
  - "7. DUT set up\n   Before starting to perform the tests, the DUT to be tested\
    \ MUST be\n   configured following the instructions provided to the user.\n  \
    \ Specifically, it is expected that all of the supported protocols will\n   be\
    \ configured and enabled during this set up (See Appendix A).  It is\n   expected\
    \ that all of the tests will be run without changing the\n   configuration or\
    \ setup of the DUT in any way other than that required\n   to do the specific\
    \ test.  For example, it is not acceptable to change\n   the size of frame handling\
    \ buffers between tests of frame handling\n   rates or to disable all but one\
    \ transport protocol when testing the\n   throughput of that protocol.  It is\
    \ necessary to modify the\n   configuration when starting a test to determine\
    \ the effect of filters\n   on throughput, but the only change MUST be to enable\
    \ the specific\n   filter. The DUT set up SHOULD include the normally recommended\n\
    \   routing update intervals and keep alive frequency.  The specific\n   version\
    \ of the software and the exact DUT configuration, including\n   what functions\
    \ are disabled, used during the tests MUST be included\n   as part of the report\
    \ of the results.\n"
- title: 8. Frame formats
  contents:
  - "8. Frame formats\n   The formats of the test frames to use for TCP/IP over Ethernet\
    \ are\n   shown in Appendix C: Test Frame Formats.  These exact frame formats\n\
    \   SHOULD be used in the tests described in this document for this\n   protocol/media\
    \ combination and that these frames will be used as a\n   template for testing\
    \ other protocol/media combinations.  The specific\n   formats that are used to\
    \ define the test frames for a particular test\n   series MUST be included in\
    \ the report of the results.\n"
- title: 9. Frame sizes
  contents:
  - "9. Frame sizes\n   All of the described tests SHOULD be performed at a number\
    \ of frame\n   sizes. Specifically, the sizes SHOULD include the maximum and minimum\n\
    \   legitimate sizes for the protocol under test on the media under test\n   and\
    \ enough sizes in between to be able to get a full characterization\n   of the\
    \ DUT performance.  Except where noted, at least five frame\n   sizes SHOULD be\
    \ tested for each test condition.\n   Theoretically the minimum size UDP Echo\
    \ request frame would consist\n   of an IP header (minimum length 20 octets),\
    \ a UDP header (8 octets)\n   and whatever MAC level header is required by the\
    \ media in use.  The\n   theoretical maximum frame size is determined by the size\
    \ of the\n   length field in the IP header.  In almost all cases the actual\n\
    \   maximum and minimum sizes are determined by the limitations of the\n   media.\n\
    \   In theory it would be ideal to distribute the frame sizes in a way\n   that\
    \ would evenly distribute the theoretical frame rates.  These\n   recommendations\
    \ incorporate this theory but specify frame sizes which\n   are easy to understand\
    \ and remember.  In addition, many of the same\n   frame sizes are specified on\
    \ each of the media types to allow for\n   easy performance comparisons.\n   Note:\
    \ The inclusion of an unrealistically small frame size on some of\n   the media\
    \ types (i.e. with little or no space for data) is to help\n   characterize the\
    \ per-frame processing overhead of the DUT.\n"
- title: 9.1 Frame sizes to be used on Ethernet
  contents:
  - "9.1 Frame sizes to be used on Ethernet\n       64, 128, 256, 512, 1024, 1280,\
    \ 1518\n   These sizes include the maximum and minimum frame sizes permitted by\n\
    \   the Ethernet standard and a selection of sizes between these extremes\n  \
    \ with a finer granularity for the smaller frame sizes and higher frame\n   rates.\n"
- title: 9.2 Frame sizes to be used on 4Mb and 16Mb token ring
  contents:
  - "9.2 Frame sizes to be used on 4Mb and 16Mb token ring\n       54, 64, 128, 256,\
    \ 1024, 1518, 2048, 4472\n   The frame size recommendations for token ring assume\
    \ that there is no\n   RIF field in the frames of routed protocols.  A RIF field\
    \ would be\n   present in any direct source route bridge performance test.  The\n\
    \   minimum size frame for UDP on token ring is 54 octets.  The maximum\n   size\
    \ of 4472 octets is recommended for 16Mb token ring instead of the\n   theoretical\
    \ size of 17.9Kb because of the size limitations imposed by\n   many token ring\
    \ interfaces.  The reminder of the sizes are selected\n   to permit direct comparisons\
    \ with other types of media.  An IP (i.e.\n   not UDP) frame may be used in addition\
    \ if a higher data rate is\n   desired, in which case the minimum frame size is\
    \ 46 octets.\n"
- title: 9.3 Frame sizes to be used on FDDI
  contents:
  - "9.3 Frame sizes to be used on FDDI\n       54, 64, 128, 256, 1024, 1518, 2048,\
    \ 4472\n   The minimum size frame for UDP on FDDI is 53 octets, the minimum size\n\
    \   of 54 is recommended to allow direct comparison to token ring\n   performance.\
    \  The maximum size of 4472 is recommended instead of the\n   theoretical maximum\
    \ size of 4500 octets to permit the same type of\n   comparison. An IP (i.e. not\
    \ UDP) frame may be used in addition if a\n   higher data rate is desired, in\
    \ which case the minimum frame size is\n   45 octets.\n"
- title: 9.4 Frame sizes in the presence of disparate MTUs
  contents:
  - "9.4 Frame sizes in the presence of disparate MTUs\n   When the interconnect DUT\
    \ supports connecting links with disparate\n   MTUs, the frame sizes for the link\
    \ with the *larger* MTU SHOULD be\n   used, up to the limit of the protocol being\
    \ tested. If the\n   interconnect DUT does not support the fragmenting of frames\
    \ in the\n   presence of MTU mismatch, the forwarding rate for that frame size\n\
    \   shall be reported as zero.\n   For example, the test of IP forwarding with\
    \ a bridge or router that\n   joins FDDI and Ethernet should use the frame sizes\
    \ of FDDI when going\n   from the FDDI to the Ethernet link. If the bridge does\
    \ not support IP\n   fragmentation, the forwarding rate for those frames too large\
    \ for\n   Ethernet should be reported as zero.\n"
- title: 10. Verifying received frames
  contents:
  - "10. Verifying received frames\n   The test equipment SHOULD discard any frames\
    \ received during a test\n   run that are not actual forwarded test frames.  For\
    \ example, keep-\n   alive and routing update frames SHOULD NOT be included in\
    \ the count\n   of received frames.  In any case, the test equipment SHOULD verify\n\
    \   the length of the received frames and check that they match the\n   expected\
    \ length.\n   Preferably, the test equipment SHOULD include sequence numbers in\
    \ the\n   transmitted frames and check for these numbers on the received\n   frames.\
    \  If this is done, the reported results SHOULD include in\n   addition to the\
    \ number of frames dropped, the number of frames that\n   were received out of\
    \ order, the number of duplicate frames received\n   and the number of gaps in\
    \ the received frame numbering sequence.\n   This functionality is required for\
    \ some of the described tests.\n"
- title: 11. Modifiers
  contents:
  - "11. Modifiers\n   It might be useful to know the DUT performance under a number\
    \ of\n   conditions; some of these conditions are noted below.  The reported\n\
    \   results SHOULD include as many of these conditions as the test\n   equipment\
    \ is able to generate.  The suite of tests SHOULD be first\n   run without any\
    \ modifying conditions and then repeated under each of\n   the conditions separately.\
    \  To preserve the ability to compare the\n   results of these tests any frames\
    \ that are required to generate the\n   modifying conditions (management queries\
    \ for example) will be\n   included in the same data stream as the normal test\
    \ frames in place\n   of one of the test frames and not be supplied to the DUT\
    \ on a\n   separate network port.\n"
- title: 11.1 Broadcast frames
  contents:
  - "11.1 Broadcast frames\n   In most router designs special processing is required\
    \ when frames\n   addressed to the hardware broadcast address are received.  In\
    \ bridges\n   (or in bridge mode on routers) these broadcast frames must be flooded\n\
    \   to a number of ports.  The stream of test frames SHOULD be augmented\n   with\
    \ 1% frames addressed to the hardware broadcast address.  The\n   frames sent\
    \ to the broadcast address should be of a type that the\n   router will not need\
    \ to process.  The aim of this test is to\n   determine if there is any effect\
    \ on the forwarding rate of the other\n   data in the stream.  The specific frames\
    \ that should be used are\n   included in the test frame format document. The\
    \ broadcast frames\n   SHOULD be evenly distributed throughout the data stream,\
    \ for example,\n   every 100th frame.\n   The same test SHOULD be performed on\
    \ bridge-like DUTs but in this\n   case the broadcast packets will be processed\
    \ and flooded to all\n   outputs.\n   It is understood that a level of broadcast\
    \ frames of 1% is much\n   higher than many networks experience but, as in drug\
    \ toxicity\n   evaluations, the higher level is required to be able to gage the\n\
    \   effect which would otherwise often fall within the normal variability\n  \
    \ of the system performance.  Due to design factors some test equipment\n   will\
    \ not be able to generate a level of alternate frames this low.\n   In these cases\
    \ the percentage SHOULD be as small as the equipment can\n   provide and that\
    \ the actual level be described in the report of the\n   test results.\n"
- title: 11.2 Management frames
  contents:
  - "11.2 Management frames\n   Most data networks now make use of management protocols\
    \ such as SNMP.\n   In many environments there can be a number of management stations\n\
    \   sending queries to the same DUT at the same time.\n   The stream of test frames\
    \ SHOULD be augmented with one management\n   query as the first frame sent each\
    \ second during the duration of the\n   trial.  The result of the query must fit\
    \ into one response frame. The\n   response frame SHOULD be verified by the test\
    \ equipment. One example\n   of the specific query frame that should be used is\
    \ shown in Appendix\n   C.\n"
- title: 11.3 Routing update frames
  contents:
  - "11.3 Routing update frames\n   The processing of dynamic routing protocol updates\
    \ could have a\n   significant impact on the ability of a router to forward data\
    \ frames.\n   The stream of test frames SHOULD be augmented with one routing update\n\
    \   frame transmitted as the first frame transmitted during the trial.\n   Routing\
    \ update frames SHOULD be sent at the rate specified in\n   Appendix C for the\
    \ specific routing protocol being used in the test.\n   Two routing update frames\
    \ are defined in Appendix C for the TCP/IP\n   over Ethernet example.  The routing\
    \ frames are designed to change the\n   routing to a number of networks that are\
    \ not involved in the\n   forwarding of the test data.  The first frame sets the\
    \ routing table\n   state to \"A\", the second one changes the state to \"B\"\
    .  The frames\n   MUST be alternated during the trial.\n   The test SHOULD verify\
    \ that the routing update was processed by the\n   DUT.\n"
- title: 11.4 Filters
  contents:
  - "11.4 Filters\n   Filters are added to routers and bridges to selectively inhibit\
    \ the\n   forwarding of frames that would normally be forwarded.  This is\n  \
    \ usually done to implement security controls on the data that is\n   accepted\
    \ between one area and another. Different products have\n   different capabilities\
    \ to implement filters.\n   The DUT SHOULD be first configured to add one filter\
    \ condition and\n   the tests performed.  This filter SHOULD permit the forwarding\
    \ of the\n   test data stream. In routers this filter SHOULD be of the form:\n\
    \      forward input_protocol_address to output_protocol_address\n   In bridges\
    \ the filter SHOULD be of the form:\n      forward destination_hardware_address\n\
    \   The DUT SHOULD be then reconfigured to implement a total of 25\n   filters.\
    \  The first 24 of these filters SHOULD be of the form:\n      block input_protocol_address\
    \ to output_protocol_address\n   The 24 input and output protocol addresses SHOULD\
    \ not be any that are\n   represented in the test data stream.  The last filter\
    \ SHOULD permit\n   the forwarding of the test data stream.  By \"first\" and\
    \ \"last\" we\n   mean to ensure that in the second case, 25 conditions must be\
    \ checked\n   before the data frames will match the conditions that permit the\n\
    \   forwarding of the frame. Of course, if the DUT reorders the filters\n   or\
    \ does not use a linear scan of the filter rules the effect of the\n   sequence\
    \ in which the filters are input is properly lost.\n   The exact filters configuration\
    \ command lines used SHOULD be included\n   with the report of the results.\n"
- title: 11.4.1 Filter Addresses
  contents:
  - "11.4.1 Filter Addresses\n   Two sets of filter addresses are required, one for\
    \ the single filter\n   case and one for the 25 filter case.\n   The single filter\
    \ case should permit traffic from IP address\n   198.18.1.2 to IP address 198.19.65.2\
    \ and deny all other traffic.\n   The 25 filter case should follow the following\
    \ sequence.\n         deny aa.ba.1.1 to aa.ba.100.1\n         deny aa.ba.2.2 to\
    \ aa.ba.101.2\n         deny aa.ba.3.3 to aa.ba.103.3\n           ...\n      \
    \   deny aa.ba.12.12 to aa.ba.112.12\n         allow aa.bc.1.2 to aa.bc.65.1\n\
    \         deny aa.ba.13.13 to aa.ba.113.13\n         deny aa.ba.14.14 to aa.ba.114.14\n\
    \           ...\n         deny aa.ba.24.24 to aa.ba.124.24\n         deny all\
    \ else\n   All previous filter conditions should be cleared from the router\n\
    \   before this sequence is entered.  The sequence is selected to test to\n  \
    \ see if the router sorts the filter conditions or accepts them in the\n   order\
    \ that they were entered.  Both of these procedures will result\n   in a greater\
    \ impact on performance than will some form of hash\n   coding.\n"
- title: 12. Protocol addresses
  contents:
  - "12. Protocol addresses\n   It is easier to implement these tests using a single\
    \ logical stream\n   of data, with one source protocol address and one destination\n\
    \   protocol address, and for some conditions like the filters described\n   above,\
    \ a practical requirement. Networks in the real world are not\n   limited to single\
    \ streams of data. The test suite SHOULD be first run\n   with a single protocol\
    \ (or hardware for bridge tests) source and\n   destination address pair.  The\
    \ tests SHOULD then be repeated with\n   using a random destination address. \
    \ While testing routers the\n   addresses SHOULD be random and uniformly distributed\
    \ over a range of\n   256 networks and random and uniformly distributed over the\
    \ full MAC\n   range for bridges.  The specific address ranges to use for IP are\n\
    \   shown in Appendix C.\n"
- title: 13. Route Set Up
  contents:
  - "13. Route Set Up\n   It is not reasonable that all of the routing information\
    \ necessary to\n   forward the test stream, especially in the multiple address\
    \ case,\n   will be manually set up.  At the start of each trial a routing update\n\
    \   MUST be sent to the DUT. This routing update MUST include all of the\n   network\
    \ addresses that will be required for the trial.  All of the\n   addresses SHOULD\
    \ resolve to the same \"next-hop\". Normally this will\n   be the address of the\
    \ receiving side of the test equipment. This\n   routing update will have to be\
    \ repeated at the interval required by\n   the routing protocol being used.  An\
    \ example of the format and\n   repetition interval of the update frames is given\
    \ in Appendix C.\n"
- title: 14. Bidirectional traffic
  contents:
  - "14. Bidirectional traffic\n   Normal network activity is not all in a single\
    \ direction.  To test\n   the bidirectional performance of a DUT, the test series\
    \ SHOULD be run\n   with the same data rate being offered from each direction.\
    \ The sum of\n   the data rates should not exceed the theoretical limit for the\
    \ media.\n"
- title: 15. Single stream path
  contents:
  - "15. Single stream path\n   The full suite of tests SHOULD be run along with whatever\
    \ modifier\n   conditions that are relevant using a single input and output network\n\
    \   port on the DUT. If the internal design of the DUT has multiple\n   distinct\
    \ pathways, for example, multiple interface cards each with\n   multiple network\
    \ ports, then all possible types of pathways SHOULD be\n   tested separately.\n"
- title: 16. Multi-port
  contents:
  - "16. Multi-port\n   Many current router and bridge products provide many network\
    \ ports in\n   the same module. In performing these tests first half of the ports\n\
    \   are designated as \"input ports\" and half are designated as \"output\n  \
    \ ports\".  These ports SHOULD be evenly distributed across the DUT\n   architecture.\
    \ For example if a DUT has two interface cards each of\n   which has four ports,\
    \ two ports on each interface card are designated\n   as input and two are designated\
    \ as output.  The specified tests are\n   run using the same data rate being offered\
    \ to each of the input\n   ports.  The addresses in the input data streams SHOULD\
    \ be set so that\n   a frame will be directed to each of the output ports in sequence\
    \ so\n   that all \"output\" ports will get an even distribution of packets from\n\
    \   this input.  The same configuration MAY be used to perform a\n   bidirectional\
    \ multi-stream test.  In this case all of the ports are\n   considered both input\
    \ and output ports and each data stream MUST\n   consist of frames addressed to\
    \ all of the other ports.\n   Consider the following 6 port DUT:\n           \
    \                   --------------\n                     ---------| in A  out\
    \ X|--------\n                     ---------| in B  out Y|--------\n         \
    \            ---------| in C  out Z|--------\n                              --------------\n\
    \   The addressing of the data streams for each of the inputs SHOULD be:\n   \
    \ stream sent to input A:\n      packet to out X, packet to out Y, packet to out\
    \ Z\n    stream sent to input B:\n      packet to out X, packet to out Y, packet\
    \ to out Z\n    stream sent to input C\n      packet to out X, packet to out Y,\
    \ packet to out Z\n   Note that these streams each follow the same sequence so\
    \ that 3\n   packets will arrive at output X at the same time, then 3 packets\
    \ at\n   Y, then 3 packets at Z. This procedure ensures that, as in the real\n\
    \   world, the DUT will have to deal with multiple packets addressed to\n   the\
    \ same output at the same time.\n"
- title: 17. Multiple protocols
  contents:
  - "17. Multiple protocols\n   This document does not address the issue of testing\
    \ the effects of a\n   mixed protocol environment other than to suggest that if\
    \ such tests\n   are wanted then frames SHOULD be distributed between all of the\
    \ test\n   protocols.  The distribution MAY approximate the conditions on the\n\
    \   network in which the DUT would be used.\n"
- title: 18. Multiple frame sizes
  contents:
  - "18. Multiple frame sizes\n   This document does not address the issue of testing\
    \ the effects of a\n   mixed frame size environment other than to suggest that\
    \ if such tests\n   are wanted then frames SHOULD be distributed between all of\
    \ the\n   listed sizes for the protocol under test.  The distribution MAY\n  \
    \ approximate the conditions on the network in which the DUT would be\n   used.\
    \ The authors do not have any idea how the results of such a test\n   would be\
    \ interpreted other than to directly compare multiple DUTs in\n   some very specific\
    \ simulated network.\n"
- title: 19. Testing performance beyond a single DUT.
  contents:
  - "19. Testing performance beyond a single DUT.\n   In the performance testing of\
    \ a single DUT, the paradigm can be\n   described as applying some input to a\
    \ DUT and monitoring the output.\n   The results of which can be used to form\
    \ a basis of characterization\n   of that device under those test conditions.\n\
    \   This model is useful when the test input and output are homogenous\n   (e.g.,\
    \ 64-byte IP, 802.3 frames into the DUT; 64 byte IP, 802.3\n   frames out), or\
    \ the method of test can distinguish between dissimilar\n   input/output. (E.g.,\
    \ 1518 byte IP, 802.3 frames in; 576 byte,\n   fragmented IP, X.25 frames out.)\n\
    \   By extending the single DUT test model, reasonable benchmarks\n   regarding\
    \ multiple DUTs or heterogeneous environments may be\n   collected. In this extension,\
    \ the single DUT is replaced by a system\n   of interconnected network DUTs. This\
    \ test methodology would support\n   the benchmarking of a variety of device/media/service/protocol\n\
    \   combinations. For example, a configuration for a LAN-to-WAN-to-LAN\n   test\
    \ might be:\n   (1) 802.3-> DUT 1 -> X.25 @ 64kbps -> DUT 2 -> 802.3\n   Or a\
    \ mixed LAN configuration might be:\n   (2) 802.3 -> DUT 1 -> FDDI -> DUT 2 ->\
    \ FDDI -> DUT 3 -> 802.3\n   In both examples 1 and 2, end-to-end benchmarks of\
    \ each system could\n   be empirically ascertained. Other behavior may be characterized\n\
    \   through the use of intermediate devices. In example 2, the\n   configuration\
    \ may be used to give an indication of the FDDI to FDDI\n   capability exhibited\
    \ by DUT 2.\n   Because multiple DUTs are treated as a single system, there are\n\
    \   limitations to this methodology. For instance, this methodology may\n   yield\
    \ an aggregate benchmark for a tested system. That benchmark\n   alone, however,\
    \ may not necessarily reflect asymmetries in behavior\n   between the DUTs, latencies\
    \ introduce by other apparatus (e.g.,\n   CSUs/DSUs, switches), etc.\n   Further,\
    \ care must be used when comparing benchmarks of different\n   systems by ensuring\
    \ that the DUTs' features/configuration of the\n   tested systems have the appropriate\
    \ common denominators to allow\n   comparison.\n"
- title: 20. Maximum frame rate
  contents:
  - "20. Maximum frame rate\n   The maximum frame rates that should be used when testing\
    \ LAN\n   connections SHOULD be the listed theoretical maximum rate for the\n\
    \   frame size on the media.\n   The maximum frame rate that should be used when\
    \ testing WAN\n   connections SHOULD be greater than the listed theoretical maximum\n\
    \   rate for the frame size on that speed connection.  The higher rate\n   for\
    \ WAN tests is to compensate for the fact that some vendors employ\n   various\
    \ forms of header compression.\n   A list of maximum frame rates for LAN connections\
    \ is included in\n   Appendix B.\n"
- title: 21. Bursty traffic
  contents:
  - "21. Bursty traffic\n   It is convenient to measure the DUT performance under\
    \ steady state\n   load but this is an unrealistic way to gauge the functioning\
    \ of a DUT\n   since actual network traffic normally consists of bursts of frames.\n\
    \   Some of the tests described below SHOULD be performed with both\n   steady\
    \ state traffic and with traffic consisting of repeated bursts\n   of frames.\
    \  The frames within a burst are transmitted with the\n   minimum legitimate inter-frame\
    \ gap.\n   The objective of the test is to determine the minimum interval\n  \
    \ between bursts which the DUT can process with no frame loss. During\n   each\
    \ test the number of frames in each burst is held constant and the\n   inter-burst\
    \ interval varied.  Tests SHOULD be run with burst sizes of\n   16, 64, 256 and\
    \ 1024 frames.\n"
- title: 22. Frames per token
  contents:
  - "22. Frames per token\n   Although it is possible to configure some token ring\
    \ and FDDI\n   interfaces to transmit more than one frame each time that the token\n\
    \   is received, most of the network devices currently available transmit\n  \
    \ only one frame per token.  These tests SHOULD first be performed\n   while transmitting\
    \ only one frame per token.\n   Some current high-performance workstation servers\
    \ do transmit more\n   than one frame per token on FDDI to maximize throughput.\
    \  Since this\n   may be a common feature in future workstations and servers,\n\
    \   interconnect devices with FDDI interfaces SHOULD be tested with 1, 4,\n  \
    \ 8, and 16 frames per token.  The reported frame rate SHOULD be the\n   average\
    \ rate of frame transmission over the total trial period.\n"
- title: 23. Trial description
  contents:
  - "23. Trial description\n   A particular test consists of multiple trials.  Each\
    \ trial returns\n   one piece of information, for example the loss rate at a particular\n\
    \   input frame rate.  Each trial consists of a number of phases:\n   a) If the\
    \ DUT is a router, send the routing update to the \"input\"\n   port and pause\
    \ two seconds to be sure that the routing has settled.\n   b)  Send the \"learning\
    \ frames\" to the \"output\" port and wait 2\n   seconds to be sure that the learning\
    \ has settled.  Bridge learning\n   frames are frames with source addresses that\
    \ are the same as the\n   destination addresses used by the test frames.  Learning\
    \ frames for\n   other protocols are used to prime the address resolution tables\
    \ in\n   the DUT.  The formats of the learning frame that should be used are\n\
    \   shown in the Test Frame Formats document.\n   c) Run the test trial.\n   d)\
    \ Wait for two seconds for any residual frames to be received.\n   e) Wait for\
    \ at least five seconds for the DUT to restabilize.\n"
- title: 24. Trial duration
  contents:
  - "24. Trial duration\n   The aim of these tests is to determine the rate continuously\n\
    \   supportable by the DUT.  The actual duration of the test trials must\n   be\
    \ a compromise between this aim and the duration of the benchmarking\n   test\
    \ suite.  The duration of the test portion of each trial SHOULD be\n   at least\
    \ 60 seconds.  The tests that involve some form of \"binary\n   search\", for\
    \ example the throughput test, to determine the exact\n   result MAY use a shorter\
    \ trial duration to minimize the length of the\n   search procedure, but the final\
    \ determination SHOULD be made with\n   full length trials.\n"
- title: 25. Address resolution
  contents:
  - "25. Address resolution\n   The DUT SHOULD be able to respond to address resolution\
    \ requests sent\n   by the DUT wherever the protocol requires such a process.\n"
- title: '26. Benchmarking tests:'
  contents:
  - "26. Benchmarking tests:\n   Note: The notation \"type of data stream\" refers\
    \ to the above\n   modifications to a frame stream with a constant inter-frame\
    \ gap, for\n   example, the addition of traffic filters to the configuration of\
    \ the\n   DUT.\n"
- title: 26.1 Throughput
  contents:
  - "26.1 Throughput\n   Objective:  To determine the DUT throughput as defined in\
    \ RFC 1242.\n   Procedure:  Send a specific number of frames at a specific rate\n\
    \   through the DUT and then count the frames that are transmitted by the\n  \
    \ DUT. If the count of offered frames is equal to the count of received\n   frames,\
    \ the fewer frames are received than were transmitted, the rate\n   of the offered\
    \ stream is reduced and the test is rerun.\n   The throughput is the fastest rate\
    \ at which the count of test frames\n   transmitted by the DUT is equal to the\
    \ number of test frames sent to\n   it by the test equipment.\n   Reporting format:\
    \  The results of the throughput test SHOULD be\n   reported in the form of a\
    \ graph. If it is, the x coordinate SHOULD be\n   the frame size, the y coordinate\
    \ SHOULD be the frame rate.  There\n   SHOULD be at least two lines on the graph.\
    \  There SHOULD be one line\n   showing the theoretical frame rate for the media\
    \ at the various frame\n   sizes.  The second line SHOULD be the plot of the test\
    \ results.\n   Additional lines MAY be used on the graph to report the results\
    \ for\n   each type of data stream tested.  Text accompanying the graph SHOULD\n\
    \   indicate the protocol, data stream format, and type of media used in\n   the\
    \ tests.\n   We assume that if a single value is desired for advertising purposes\n\
    \   the vendor will select the rate for the minimum frame size for the\n   media.\
    \ If this is done then the figure MUST be expressed in frames\n   per second.\
    \  The rate MAY also be expressed in bits (or bytes) per\n   second if the vendor\
    \ so desires.  The statement of performance MUST\n   include a/ the measured maximum\
    \ frame rate, b/ the size of the frame\n   used, c/ the theoretical limit of the\
    \ media for that frame size, and\n   d/ the type of protocol used in the test.\
    \  Even if a single value is\n   used as part of the advertising copy, the full\
    \ table of results\n   SHOULD be included in the product data sheet.\n"
- title: 26.2 Latency
  contents:
  - "26.2 Latency\n   Objective:  To determine the latency as defined in RFC 1242.\n\
    \   Procedure:  First determine the throughput for DUT at each of the\n   listed\
    \ frame sizes. Send a stream of frames at a particular frame\n   size through\
    \ the DUT at the determined throughput rate to a specific\n   destination.  The\
    \ stream SHOULD be at least 120 seconds in duration.\n   An identifying tag SHOULD\
    \ be included in one frame after 60 seconds\n   with the type of tag being implementation\
    \ dependent. The time at\n   which this frame is fully transmitted is recorded\
    \ (timestamp A).  The\n   receiver logic in the test equipment MUST recognize\
    \ the tag\n   information in the frame stream and record the time at which the\n\
    \   tagged frame was received (timestamp B).\n   The latency is timestamp B minus\
    \ timestamp A as per the relevant\n   definition frm RFC 1242, namely latency\
    \ as defined for store and\n   forward devices or latency as defined for bit forwarding\
    \ devices.\n   The test MUST be repeated at least 20 times with the reported value\n\
    \   being the average of the recorded values.\n   This test SHOULD be performed\
    \ with the test frame addressed to the\n   same destination as the rest of the\
    \ data stream and also with each of\n   the test frames addressed to a new destination\
    \ network.\n   Reporting format:  The report MUST state which definition of latency\n\
    \   (from RFC 1242) was used for this test.  The latency results SHOULD\n   be\
    \ reported in the format of a table with a row for each of the\n   tested frame\
    \ sizes.  There SHOULD be columns for the frame size, the\n   rate at which the\
    \ latency test was run for that frame size, for the\n   media types tested, and\
    \ for the resultant latency values for each\n   type of data stream tested.\n"
- title: 26.3 Frame loss rate
  contents:
  - "26.3 Frame loss rate\n   Objective:  To determine the frame loss rate, as defined\
    \ in RFC 1242,\n   of a DUT throughout the entire range of input data rates and\
    \ frame\n   sizes.\n   Procedure:  Send a specific number of frames at a specific\
    \ rate\n   through the DUT to be tested and count the frames that are\n   transmitted\
    \ by the DUT.  The frame loss rate at each point is\n   calculated using the following\
    \ equation:\n          ( ( input_count - output_count ) * 100 ) / input_count\n\
    \   The first trial SHOULD be run for the frame rate that corresponds to\n   100%\
    \ of the maximum rate for the frame size on the input media.\n   Repeat the procedure\
    \ for the rate that corresponds to 90% of the\n   maximum rate used and then for\
    \ 80% of this rate.  This sequence\n   SHOULD be continued (at reducing 10% intervals)\
    \ until there are two\n   successive trials in which no frames are lost. The maximum\n\
    \   granularity of the trials MUST be 10% of the maximum rate, a finer\n   granularity\
    \ is encouraged.\n   Reporting format:  The results of the frame loss rate test\
    \ SHOULD be\n   plotted as a graph.  If this is done then the X axis MUST be the\n\
    \   input frame rate as a percent of the theoretical rate for the media\n   at\
    \ the specific frame size. The Y axis MUST be the percent loss at\n   the particular\
    \ input rate.  The left end of the X axis and the bottom\n   of the Y axis MUST\
    \ be 0 percent; the right end of the X axis and the\n   top of the Y axis MUST\
    \ be 100 percent.  Multiple lines on the graph\n   MAY used to report the frame\
    \ loss rate for different frame sizes,\n   protocols, and types of data streams.\n\
    \   Note: See section 18 for the maximum frame rates that SHOULD be used.\n"
- title: 26.4 Back-to-back frames
  contents:
  - "26.4 Back-to-back frames\n   Objective:  To characterize the ability of a DUT\
    \ to process back-to-\n   back frames as defined in RFC 1242.\n   Procedure: \
    \ Send a burst of frames with minimum inter-frame gaps to\n   the DUT and count\
    \ the number of frames forwarded by the DUT.  If the\n   count of transmitted\
    \ frames is equal to the number of frames\n   forwarded the length of the burst\
    \ is increased and the test is rerun.\n   If the number of forwarded frames is\
    \ less than the number\n   transmitted, the length of the burst is reduced and\
    \ the test is\n   rerun.\n   The back-to-back value is the number of frames in\
    \ the longest burst\n   that the DUT will handle without the loss of any frames.\
    \  The trial\n   length MUST be at least 2 seconds and SHOULD be repeated at least\
    \ 50\n   times with the average of the recorded values being reported.\n   Reporting\
    \ format:  The back-to-back results SHOULD be reported in the\n   format of a\
    \ table with a row for each of the tested frame sizes.\n   There SHOULD be columns\
    \ for the frame size and for the resultant\n   average frame count for each type\
    \ of data stream tested.  The\n   standard deviation for each measurement MAY\
    \ also be reported.\n"
- title: 26.5 System recovery
  contents:
  - "26.5 System recovery\n   Objective:  To characterize the speed at which a DUT\
    \ recovers from an\n   overload condition.\n   Procedure:  First determine the\
    \ throughput for a DUT at each of the\n   listed frame sizes.\n   Send a stream\
    \ of frames at a rate 110% of the recorded throughput\n   rate or the maximum\
    \ rate for the media, whichever is lower, for at\n   least 60 seconds.  At Timestamp\
    \ A reduce the frame rate to 50% of the\n   above rate and record the time of\
    \ the last frame lost (Timestamp B).\n   The system recovery time is determined\
    \ by subtracting Timestamp B\n   from Timestamp A.  The test SHOULD be repeated\
    \ a number of times and\n   the average of the recorded values being reported.\n\
    \   Reporting format:  The system recovery results SHOULD be reported in\n   the\
    \ format of a table with a row for each of the tested frame sizes.\n   There SHOULD\
    \ be columns for the frame size, the frame rate used as\n   the throughput rate\
    \ for each type of data stream tested, and for the\n   measured recovery time\
    \ for each type of data stream tested.\n"
- title: 26.6 Reset
  contents:
  - "26.6 Reset\n   Objective:  To characterize the speed at which a DUT recovers\
    \ from a\n   device or software reset.\n   Procedure:  First determine the throughput\
    \ for the DUT for the\n   minimum frame size on the media used in the testing.\n\
    \   Send a continuous stream of frames at the determined throughput rate\n   for\
    \ the minimum sized frames. Cause a reset in the DUT.  Monitor the\n   output\
    \ until frames begin to be forwarded and record the time that\n   the last frame\
    \ (Timestamp A) of the initial stream and the first\n   frame of the new stream\
    \ (Timestamp B) are received.  A power\n   interruption reset test is performed\
    \ as above except that the power\n   to the DUT should be interrupted for 10 seconds\
    \ in place of causing a\n   reset.\n   This test SHOULD only be run using frames\
    \ addressed to networks\n   directly connected to the DUT so that there is no\
    \ requirement to\n   delay until a routing update is received.\n   The reset value\
    \ is obtained by subtracting Timestamp A from Timestamp\n   B.\n   Hardware and\
    \ software resets, as well as a power interruption SHOULD\n   be tested.\n   Reporting\
    \ format:  The reset value SHOULD be reported in a simple set\n   of statements,\
    \ one for each reset type.\n"
- title: 27. Security Considerations
  contents:
  - "27. Security Considerations\n   Security issues are not addressed in this document.\n"
- title: 28. Editors' Addresses
  contents:
  - "28. Editors' Addresses\n   Scott Bradner\n   Harvard University\n   1350 Mass.\
    \ Ave, room 813\n   Cambridge, MA 02138\n   Phone: +1 617 495-3864\n   Fax:  \
    \ +1 617 496-8500\n   EMail: sob@harvard.edu\n   Jim McQuaid\n   NetScout Systems\n\
    \   4 Westford Tech Park Drive\n   Westford, MA 01886\n   Phone: +1 978 614-4116\n\
    \   Fax:   +1 978 614-4004\n   EMail: mcquaidj@netscout.com\n"
- title: 'Appendix A: Testing Considerations'
  contents:
  - 'Appendix A: Testing Considerations

    '
- title: A.1 Scope Of This Appendix
  contents:
  - "A.1 Scope Of This Appendix\n   This appendix discusses certain issues in the\
    \ benchmarking\n   methodology where experience or judgment may play a role in\
    \ the tests\n   selected to be run or in the approach to constructing the test\
    \ with a\n   particular DUT.  As such, this appendix MUST not be read as an\n\
    \   amendment to the methodology described in the body of this document\n   but\
    \ as a guide to testing practice.\n   1. Typical testing practice has been to\
    \ enable all protocols to be\n      tested and conduct all testing with no further\
    \ configuration of\n      protocols, even though a given set of trials may exercise\
    \ only one\n      protocol at a time. This minimizes the opportunities to \"tune\"\
    \ a\n      DUT for a single protocol.\n   2. The least common denominator of the\
    \ available filter functions\n      should be used to ensure that there is a basis\
    \ for comparison\n      between vendors. Because of product differences, those\
    \ conducting\n      and evaluating tests must make a judgment about this issue.\n\
    \   3. Architectural considerations may need to be considered.  For\n      example,\
    \ first perform the tests with the stream going between\n      ports on the same\
    \ interface card and the repeat the tests with the\n      stream going into a\
    \ port on one interface card and out of a port\n      on a second interface card.\
    \ There will almost always be a best\n      case and worst case configuration\
    \ for a given DUT architecture.\n   4. Testing done using traffic streams consisting\
    \ of mixed protocols\n      has not shown much difference between testing with\
    \ individual\n      protocols.  That is, if protocol A testing and protocol B\
    \ testing\n      give two different performance results, mixed protocol testing\n\
    \      appears to give a result which is the average of the two.\n   5. Wide Area\
    \ Network (WAN) performance may be tested by setting up\n      two identical devices\
    \ connected by the appropriate short- haul\n      versions of the WAN modems.\
    \  Performance is then measured between\n      a LAN interface on one DUT to a\
    \ LAN interface on the other DUT.\n   The maximum frame rate to be used for LAN-WAN-LAN\
    \ configurations is a\n   judgment that can be based on known characteristics\
    \ of the overall\n   system including compression effects, fragmentation, and\
    \ gross link\n   speeds. Practice suggests that the rate should be at least 110%\
    \ of\n   the slowest link speed. Substantive issues of testing compression\n \
    \  itself are beyond the scope of this document.\n"
- title: 'Appendix B: Maximum frame rates reference'
  contents:
  - "Appendix B: Maximum frame rates reference\n      (Provided by Roger Beeman, Cisco\
    \ Systems)\n        Size       Ethernet    16Mb Token Ring      FDDI\n       (bytes)\
    \       (pps)           (pps)         (pps)\n       64            14880      \
    \     24691         152439\n       128            8445           13793       \
    \   85616\n       256            4528            7326          45620\n       512\
    \            2349            3780          23585\n       768            1586 \
    \           2547          15903\n       1024           1197            1921  \
    \        11996\n       1280            961            1542           9630\n  \
    \     1518            812            1302           8138\n      Ethernet size\n\
    \       Preamble 64 bits\n       Frame 8 x N bits\n       Gap  96 bits\n     \
    \ 16Mb Token Ring size\n         SD               8 bits\n         AC        \
    \       8 bits\n         FC               8 bits\n         DA              48\
    \ bits\n         SA              48 bits\n         RI              48 bits ( 06\
    \ 30 00 12 00 30 )\n         SNAP\n           DSAP           8 bits\n        \
    \   SSAP           8 bits\n           Control        8 bits\n           Vendor\
    \        24 bits\n           Type          16 bits\n         Data 8 x ( N - 18)\
    \ bits\n         FCS             32 bits\n         ED               8 bits\n \
    \        FS               8 bits\n      Tokens or idles between packets are not\
    \ included\n      FDDI size\n         Preamble        64 bits\n         SD   \
    \            8 bits\n         FC               8 bits\n         DA           \
    \   48 bits\n         SA              48 bits\n         SNAP\n           DSAP\
    \           8 bits\n           SSAP           8 bits\n           Control     \
    \   8 bits\n           Vendor        24 bits\n           Type          16 bits\n\
    \         Data 8 x ( N - 18) bits\n         FCS             32 bits\n        \
    \ ED               4 bits\n         FS              12 bits\n"
- title: 'Appendix C: Test Frame Formats'
  contents:
  - "Appendix C: Test Frame Formats\n   This appendix defines the frame formats that\
    \ may be used with these\n   tests.  It also includes protocol specific parameters\
    \ for TCP/IP over\n   Ethernet to be used with the tests as an example.\n"
- title: C.1. Introduction
  contents:
  - "C.1. Introduction\n   The general logic used in the selection of the parameters\
    \ and the\n   design of the frame formats is explained for each case within the\n\
    \   TCP/IP section.  The same logic has been used in the other sections.\n   Comments\
    \ are used in these sections only if there is a protocol\n   specific feature\
    \ to be explained.  Parameters and frame formats for\n   additional protocols\
    \ can be defined by the reader by using the same\n   logic.\n"
- title: C.2. TCP/IP Information
  contents:
  - "C.2. TCP/IP Information\n   The following section deals with the TCP/IP protocol\
    \ suite.\n"
- title: C.2.1 Frame Type.
  contents:
  - "C.2.1 Frame Type.\n   An application level datagram echo request is used for\
    \ the test data\n   frame in the protocols that support such a function.  A datagram\n\
    \   protocol is used to minimize the chance that a router might expect a\n   specific\
    \ session initialization sequence, as might be the case for a\n   reliable stream\
    \ protocol. A specific defined protocol is used because\n   some routers verify\
    \ the protocol field and refuse to forward unknown\n   protocols.\n   For TCP/IP\
    \ a UDP Echo Request is used.\n"
- title: C.2.2 Protocol Addresses
  contents:
  - "C.2.2 Protocol Addresses\n   Two sets of addresses must be defined: first the\
    \ addresses assigned\n   to the router ports, and second the address that are\
    \ to be used in\n   the frames themselves and in the routing updates.\n   The\
    \ network addresses 192.18.0.0 through 198.19.255.255 are have been\n   assigned\
    \ to the BMWG by the IANA for this purpose.  This assignment\n   was made to minimize\
    \ the chance of conflict in case a testing device\n   were to be accidentally\
    \ connected to part of the Internet.  The\n   specific use of the addresses is\
    \ detailed below.\n"
- title: C.2.2.1 Router port protocol addresses
  contents:
  - "C.2.2.1 Router port protocol addresses\n   Half of the ports on a multi-port\
    \ router are referred to as \"input\"\n   ports and the other half as \"output\"\
    \ ports even though some of the\n   tests use all ports both as input and output.\
    \  A contiguous series of\n   IP Class C network addresses from 198.18.1.0 to\
    \ 198.18.64.0 have been\n   assigned for use on the \"input\" ports.  A second\
    \ series from\n   198.19.1.0 to 198.19.64.0 have been assigned for use on the\
    \ \"output\"\n   ports. In all cases the router port is node 1 on the appropriate\n\
    \   network.  For example, a two port DUT would have an IP address of\n   198.18.1.1\
    \ on one port and 198.19.1.1 on the other port.\n   Some of the tests described\
    \ in the methodology memo make use of an\n   SNMP management connection to the\
    \ DUT.  The management access address\n   for the DUT is assumed to be the first\
    \ of the \"input\" ports\n   (198.18.1.1).\n"
- title: C.2.2.2 Frame addresses
  contents:
  - "C.2.2.2 Frame addresses\n   Some of the described tests assume adjacent network\
    \ routing (the\n   reboot time test for example).  The IP address used in the\
    \ test frame\n   is that of node 2 on the appropriate Class C network. (198.19.1.2\
    \ for\n   example)\n   If the test involves non-adjacent network routing the phantom\
    \ routers\n   are located at node 10 of each of the appropriate Class C networks.\n\
    \   A series of Class C network addresses from 198.18.65.0 to\n   198.18.254.0\
    \ has been assigned for use as the networks accessible\n   through the phantom\
    \ routers on the \"input\" side of DUT.  The series\n   of Class C networks from\
    \ 198.19.65.0 to 198.19.254.0 have been\n   assigned to be used as the networks\
    \ visible through the phantom\n   routers on the \"output\" side of the DUT.\n"
- title: C.2.3 Routing Update Frequency
  contents:
  - "C.2.3 Routing Update Frequency\n   The update interval for each routing protocol\
    \ is may have to be\n   determined by the specifications of the individual protocol.\
    \  For IP\n   RIP, Cisco IGRP and for OSPF a routing update frame or frames should\n\
    \   precede each stream of test frames by 5 seconds.  This frequency is\n   sufficient\
    \ for trial durations of up to 60 seconds.  Routing updates\n   must be mixed\
    \ with the stream of test frames if longer trial periods\n   are selected.  The\
    \ frequency of updates should be taken from the\n   following table.\n       \
    \   IP-RIP  30 sec\n          IGRP  90 sec\n          OSPF  90 sec\n"
- title: C.2.4 Frame Formats - detailed discussion
  contents:
  - 'C.2.4 Frame Formats - detailed discussion

    '
- title: C.2.4.1 Learning Frame
  contents:
  - "C.2.4.1 Learning Frame\n   In most protocols a procedure is used to determine\
    \ the mapping\n   between the protocol node address and the MAC address.  The\
    \ Address\n   Resolution Protocol (ARP) is used to perform this function in TCP/IP.\n\
    \   No such procedure is required in XNS or IPX because the MAC address\n   is\
    \ used as the protocol node address.\n   In the ideal case the tester would be\
    \ able to respond to ARP requests\n   from the DUT.  In cases where this is not\
    \ possible an ARP request\n   should be sent to the router's \"output\" port.\
    \  This request should be\n   seen as coming from the immediate destination of\
    \ the test frame\n   stream. (i.e. the phantom router (Figure 2) or the end node\
    \ if\n   adjacent network routing is being used.) It is assumed that the\n   router\
    \ will cache the MAC address of the requesting device.  The ARP\n   request should\
    \ be sent 5 seconds before the test frame stream starts\n   in each trial.  Trial\
    \ lengths of longer than 50 seconds may require\n   that the router be configured\
    \ for an extended ARP timeout.\n                      +--------+            +------------+\n\
    \                      |        |            |  phantom   |------ P LAN\n    \
    \     A\n            IN A------|   DUT  |------------|            |------ P LAN\n\
    \         B\n                      |        |   OUT A    |  router    |------\
    \ P LAN\n         C\n                      +--------+            +------------+\n\
    \                                 Figure 2\n           In the case where full\
    \ routing is being used\n"
- title: C.2.4.2 Routing Update Frame
  contents:
  - "C.2.4.2 Routing Update Frame\n   If the test does not involve adjacent net routing\
    \ the tester must\n   supply proper routing information using a routing update.\
    \  A single\n   routing update is used before each trial on each \"destination\"\
    \ port\n   (see section C.24).  This update includes the network addresses that\n\
    \   are reachable through a phantom router on the network attached to the\n  \
    \ port.  For a full mesh test, one destination network address is\n   present\
    \ in the routing update for each of the \"input\" ports.  The\n   test stream\
    \ on each \"input\" port consists of a repeating sequence of\n   frames, one to\
    \ each of the \"output\" ports.\n"
- title: C.2.4.3 Management Query Frame
  contents:
  - "C.2.4.3 Management Query Frame\n   The management overhead test uses SNMP to\
    \ query a set of variables\n   that should be present in all DUTs that support\
    \ SNMP.  The variables\n   for a single interface only are read by an NMS at the\
    \ appropriate\n   intervals.  The list of variables to retrieve follow:\n    \
    \         sysUpTime\n             ifInOctets\n             ifOutOctets\n     \
    \        ifInUcastPkts\n             ifOutUcastPkts\n"
- title: C.2.4.4 Test Frames
  contents:
  - "C.2.4.4 Test Frames\n   The test frame is an UDP Echo Request with enough data\
    \ to fill out\n   the required frame size.  The data should not be all bits off\
    \ or all\n   bits on since these patters can cause a \"bit stuffing\" process\
    \ to be\n   used to maintain clock synchronization on WAN links.  This process\n\
    \   will result in a longer frame than was intended.\n"
- title: C.2.4.5 Frame Formats - TCP/IP on Ethernet
  contents:
  - "C.2.4.5 Frame Formats - TCP/IP on Ethernet\n   Each of the frames below are described\
    \ for the 1st pair of DUT ports,\n   i.e. \"input\" port #1 and \"output\" port\
    \ #1.  Addresses must be changed\n   if the frame is to be used for other ports.\n"
- title: C.2.6.1 Learning Frame
  contents:
  - "C.2.6.1 Learning Frame\n          ARP Request on Ethernet\n          -- DATAGRAM\
    \ HEADER\n          offset data (hex)            description\n          00   \
    \  FF FF FF FF FF FF     dest MAC address send to\n         broadcast address\n\
    \          06     xx xx xx xx xx xx     set to source MAC address\n          12\
    \     08 06                 ARP type\n          14     00 01                 hardware\
    \ type Ethernet = 1\n          16     08 00                 protocol type IP =\
    \ 800\n          18     06                    hardware address length 48 bits\n\
    \         on Ethernet\n          19     04                    protocol address\
    \ length 4 octets\n         for IP\n          20     00 01                 opcode\
    \ request = 1\n          22     xx xx xx xx xx xx     source MAC address\n   \
    \       28     xx xx xx xx           source IP address\n          32     FF FF\
    \ FF FF FF FF     requesting DUT's MAC address\n          38     xx xx xx xx \
    \          DUT's IP address\n"
- title: C.2.6.2 Routing Update Frame
  contents:
  - "C.2.6.2 Routing Update Frame\n          -- DATAGRAM HEADER\n          offset\
    \ data (hex)            description\n          00     FF FF FF FF FF FF     dest\
    \ MAC address is broadcast\n          06     xx xx xx xx xx xx     source hardware\
    \ address\n          12     08 00                 type\n          -- IP HEADER\n\
    \          14     45                    IP version - 4, header length (4\n   \
    \      byte units) - 5\n          15     00                    service field\n\
    \          16     00 EE                 total length\n          18     00 00 \
    \                ID\n          20     40 00                 flags (3 bits) 4 (do\
    \ not\n         fragment),\n                                       fragment offset-0\n\
    \          22     0A                    TTL\n          23     11             \
    \       protocol - 17 (UDP)\n          24     C4 8D                 header checksum\n\
    \          26     xx xx xx xx           source IP address\n          30     xx\
    \ xx xx              destination IP address\n          33     FF             \
    \       host part = FF for broadcast\n          -- UDP HEADER\n          34  \
    \   02 08                 source port 208 = RIP\n          36     02 08      \
    \           destination port 208 = RIP\n          38     00 DA               \
    \  UDP message length\n          40     00 00                 UDP checksum\n \
    \         -- RIP packet\n          42     02                  command = response\n\
    \          43     01                  version = 1\n          44     00 00    \
    \           0\n          -- net 1\n          46     00 02               family\
    \ = IP\n          48     00 00               0\n          50     xx xx xx    \
    \        net 1 IP address\n          53     00                  net not node\n\
    \          54     00 00 00 00         0\n          58     00 00 00 00        \
    \ 0\n          62     00 00 00 07         metric 7\n          -- net 2\n     \
    \     66     00 02               family = IP\n          68     00 00         \
    \      0\n          70     xx xx xx            net 2 IP address\n          73\
    \     00                  net not node\n          74     00 00 00 00         0\n\
    \          78     00 00 00 00         0\n          82     00 00 00 07        \
    \ metric 7\n          -- net 3\n          86     00 02               family =\
    \ IP\n          88     00 00               0\n          90     xx xx xx      \
    \      net 3 IP address\n          93     00                  net not node\n \
    \         94     00 00 00 00         0\n          98     00 00 00 00         0\n\
    \          102    00 00 00 07         metric 7\n          -- net 4\n         \
    \ 106    00 02               family = IP\n          108    00 00             \
    \  0\n          110    xx xx xx            net 4 IP address\n          113   \
    \ 00                  net not node\n          114    00 00 00 00         0\n \
    \         118    00 00 00 00         0\n          122    00 00 00 07         metric\
    \ 7\n          -- net 5\n          126    00 02               family = IP\n  \
    \        128    00 00               0\n          130    00                  net\
    \ 5 IP address\n          133    00                  net not node\n          134\
    \    00 00 00 00         0\n          138    00 00 00 00         0\n         \
    \ 142    00 00 00 07         metric 7\n          -- net 6\n          146    00\
    \ 02               family = IP\n          148    00 00               0\n     \
    \     150    xx xx xx            net 6 IP address\n          153    00       \
    \           net not node\n          154    00 00 00 00         0\n          158\
    \    00 00 00 00         0\n          162    00 00 00 07         metric 7\n"
- title: C.2.4.6 Management Query Frame
  contents:
  - "C.2.4.6 Management Query Frame\n   To be defined.\n"
- title: C.2.6.4 Test Frames
  contents:
  - "C.2.6.4 Test Frames\n   UDP echo request on Ethernet\n          -- DATAGRAM HEADER\n\
    \          offset data (hex)            description\n          00     xx xx xx\
    \ xx xx xx     set to dest MAC address\n          06     xx xx xx xx xx xx   \
    \  set to source MAC address\n          12     08 00                 type\n  \
    \        -- IP HEADER\n          14     45                    IP version - 4 header\
    \ length 5 4\n         byte units\n          15     00                    TOS\n\
    \          16     00 2E                 total length*\n          18     00 00\
    \                 ID\n          20     00 00                 flags (3 bits) -\
    \ 0 fragment\n         offset-0\n          22     0A                    TTL\n\
    \          23     11                    protocol - 17 (UDP)\n          24    \
    \ C4 8D                 header checksum*\n          26     xx xx xx xx       \
    \    set to source IP address**\n          30     xx xx xx xx           set to\
    \ destination IP address**\n          -- UDP HEADER\n          34     C0 20  \
    \               source port\n          36     00 07                 destination\
    \ port 07 = Echo\n          38     00 1A                 UDP message length*\n\
    \          40     00 00                 UDP checksum\n          -- UDP DATA\n\
    \          42     00 01 02 03 04 05 06 07    some data***\n          50     08\
    \ 09 0A 0B 0C 0D 0E 0F\n         * - change for different length frames\n    \
    \     ** - change for different logical streams\n         *** - fill remainder\
    \ of frame with incrementing octets,\n         repeated if required by frame length\n\
    \   Values to be used in Total Length and UDP message length fields:\n       \
    \   frame size   total length  UDP message length\n             64           \
    \ 00 2E          00 1A\n             128           00 6E          00 5A\n    \
    \         256           00 EE          00 9A\n             512           01 EE\
    \          01 9A\n             768           02 EE          02 9A\n          \
    \   1024          03 EE          03 9A\n             1280          04 EE     \
    \     04 9A\n             1518          05 DC          05 C8\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (1999).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
