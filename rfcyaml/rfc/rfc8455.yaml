- title: __initial_text__
  contents:
  - "     Terminology for Benchmarking Software-Defined Networking (SDN)\n       \
    \                  Controller Performance\n"
- title: Abstract
  contents:
  - "Abstract\n   This document defines terminology for benchmarking a Software-Defined\n\
    \   Networking (SDN) controller's control-plane performance.  It extends\n   the\
    \ terminology already defined in RFC 7426 for the purpose of\n   benchmarking\
    \ SDN Controllers.  The terms provided in this document\n   help to benchmark\
    \ an SDN Controller's performance independently of\n   the controller's supported\
    \ protocols and/or network services.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 7841.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   https://www.rfc-editor.org/info/rfc8455.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2018 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (https://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \      1.1. Conventions Used in This Document ..........................3\n  \
    \ 2. Term Definitions ................................................4\n    \
    \  2.1. SDN Terms ..................................................4\n      \
    \     2.1.1. Flow ................................................4\n        \
    \   2.1.2. Northbound Interface ................................4\n          \
    \ 2.1.3. Southbound Interface ................................5\n           2.1.4.\
    \ Controller Forwarding Table .........................5\n           2.1.5. Proactive\
    \ Flow Provisioning Mode ....................5\n           2.1.6. Reactive Flow\
    \ Provisioning Mode .....................6\n           2.1.7. Path ................................................6\n\
    \           2.1.8. Standalone Mode .....................................6\n  \
    \         2.1.9. Cluster/Redundancy Mode .............................7\n    \
    \       2.1.10. Asynchronous Message ...............................7\n      \
    \     2.1.11. Test Traffic Generator .............................7\n        \
    \   2.1.12. Leaf-Spine Topology ................................8\n      2.2.\
    \ Test Configuration/Setup Terms .............................8\n           2.2.1.\
    \ Number of Network Devices ...........................8\n           2.2.2. Trial\
    \ Repetition ....................................8\n           2.2.3. Trial Duration\
    \ ......................................9\n           2.2.4. Number of Cluster\
    \ Nodes .............................9\n      2.3. Benchmarking Terms .........................................9\n\
    \           2.3.1. Performance .........................................9\n  \
    \                2.3.1.1. Network Topology Discovery Time ............9\n    \
    \              2.3.1.2. Asynchronous Message Processing Time ......10\n      \
    \            2.3.1.3. Asynchronous Message Processing Rate ......10\n        \
    \          2.3.1.4. Reactive Path Provisioning Time ...........11\n          \
    \        2.3.1.5. Proactive Path Provisioning Time ..........12\n            \
    \      2.3.1.6. Reactive Path Provisioning Rate ...........12\n              \
    \    2.3.1.7. Proactive Path Provisioning Rate ..........13\n                \
    \  2.3.1.8. Network Topology Change Detection Time ....13\n           2.3.2. Scalability\
    \ ........................................14\n                  2.3.2.1. Control\
    \ Sessions Capacity .................14\n                  2.3.2.2. Network Discovery\
    \ Size ....................14\n                  2.3.2.3. Forwarding Table Capacity\
    \ .................15\n           2.3.3. Security ...........................................15\n\
    \                  2.3.3.1. Exception Handling ........................15\n  \
    \                2.3.3.2. Handling Denial-of-Service Attacks ........16\n    \
    \       2.3.4. Reliability ........................................16\n      \
    \            2.3.4.1. Controller Failover Time ..................16\n        \
    \          2.3.4.2. Network Re-provisioning Time ..............17\n   3. Test\
    \ Setup .....................................................17\n      3.1. Test\
    \ Setup - Controller Operating in Standalone Mode ......18\n      3.2. Test Setup\
    \ - Controller Operating in Cluster Mode .........19\n   4. Test Coverage ..................................................20\n\
    \   5. IANA Considerations ............................................21\n  \
    \ 6. Security Considerations ........................................21\n   7.\
    \ Normative References ...........................................21\n   Acknowledgments\
    \ ...................................................22\n   Authors' Addresses\
    \ ................................................23\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Software-Defined Networking (SDN) is a networking architecture\
    \ in\n   which network control is decoupled from the underlying forwarding\n \
    \  function and is placed in a centralized location called the SDN\n   Controller.\
    \  The SDN Controller provides an abstraction of the\n   underlying network and\
    \ offers a global view of the overall network to\n   applications and business\
    \ logic.  Thus, an SDN Controller provides\n   the flexibility to program, control,\
    \ and manage network behavior\n   dynamically through northbound and southbound\
    \ interfaces.  Since the\n   network controls are logically centralized, the need\
    \ to benchmark the\n   SDN Controller's performance becomes significant.  This\
    \ document\n   defines terms to benchmark various controller designs for\n   performance,\
    \ scalability, reliability, and security, independently of\n   northbound and\
    \ southbound protocols.  A mechanism for benchmarking\n   the performance of SDN\
    \ Controllers is defined in the companion\n   methodology document [RFC8456].\
    \  These two documents provide methods\n   for measuring and evaluating the performance\
    \ of various controller\n   implementations.\n"
- title: 1.1.  Conventions Used in This Document
  contents:
  - "1.1.  Conventions Used in This Document\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"NOT RECOMMENDED\", \"MAY\", and\n   \"OPTIONAL\" in this document are to be\
    \ interpreted as described in\n   BCP 14 [RFC2119] [RFC8174] when, and only when,\
    \ they appear in all\n   capitals, as shown here.\n"
- title: 2.  Term Definitions
  contents:
  - '2.  Term Definitions

    '
- title: 2.1.  SDN Terms
  contents:
  - "2.1.  SDN Terms\n   The terms defined in this section are extensions to the terms\
    \ defined\n   in [RFC7426] (\"Software-Defined Networking (SDN): Layers and\n\
    \   Architecture Terminology\").  Readers should refer to [RFC7426] before\n \
    \  attempting to make use of this document.\n"
- title: 2.1.1.  Flow
  contents:
  - "2.1.1.  Flow\n   Definition:\n      The definition of \"flow\" is the same as\
    \ the definition of\n      \"microflows\" provided in Section 3.1.5 of [RFC4689].\n\
    \   Discussion:\n      A flow can be a set of packets having the same source address,\n\
    \      destination address, source port, and destination port, or any\n      combination\
    \ of these items.\n   Measurement Units:\n      N/A\n"
- title: 2.1.2.  Northbound Interface
  contents:
  - "2.1.2.  Northbound Interface\n   Definition:\n      The definition of \"northbound\
    \ interface\" is the same as the\n      definition of \"service interface\" provided\
    \ in [RFC7426].\n   Discussion:\n      The northbound interface allows SDN applications\
    \ and orchestration\n      systems to program and retrieve the network information\
    \ through\n      the SDN Controller.\n   Measurement Units:\n      N/A\n"
- title: 2.1.3.  Southbound Interface
  contents:
  - "2.1.3.  Southbound Interface\n   Definition:\n      The southbound interface\
    \ is the application programming interface\n      provided by the SDN Controller\
    \ to interact with the SDN nodes.\n   Discussion:\n      The southbound interface\
    \ enables the controller to interact with\n      the SDN nodes in the network\
    \ for dynamically defining the traffic\n      forwarding behavior.\n   Measurement\
    \ Units:\n      N/A\n"
- title: 2.1.4.  Controller Forwarding Table
  contents:
  - "2.1.4.  Controller Forwarding Table\n   Definition:\n      A controller Forwarding\
    \ Table contains flow entries learned in one\n      of two ways: first, entries\
    \ can be learned from traffic received\n      through the data plane, or second,\
    \ these entries can be statically\n      provisioned on the controller and distributed\
    \ to devices via the\n      southbound interface.\n   Discussion:\n      The controller\
    \ Forwarding Table has an aging mechanism that will\n      be applied only for\
    \ dynamically learned entries.\n   Measurement Units:\n      N/A\n"
- title: 2.1.5.  Proactive Flow Provisioning Mode
  contents:
  - "2.1.5.  Proactive Flow Provisioning Mode\n   Definition:\n      Controller programming\
    \ flows in Network Devices based on the flow\n      entries provisioned through\
    \ the controller's northbound interface.\n   Discussion:\n      Network orchestration\
    \ systems and SDN applications can define the\n      network forwarding behavior\
    \ by programming the controller, using\n      Proactive Flow Provisioning.  The\
    \ controller can then program the\n      Network Devices with the pre-provisioned\
    \ entries.\n   Measurement Units:\n      N/A\n"
- title: 2.1.6.  Reactive Flow Provisioning Mode
  contents:
  - "2.1.6.  Reactive Flow Provisioning Mode\n   Definition:\n      Controller programming\
    \ flows in Network Devices based on the\n      traffic received from Network Devices\
    \ through the controller's\n      southbound interface.\n   Discussion:\n    \
    \  The SDN Controller dynamically decides the forwarding behavior\n      based\
    \ on the incoming traffic from the Network Devices.  The\n      controller then\
    \ programs the Network Devices, using Reactive Flow\n      Provisioning.\n   Measurement\
    \ Units:\n      N/A\n"
- title: 2.1.7.  Path
  contents:
  - "2.1.7.  Path\n   Definition:\n      Refer to Section 5 in [RFC2330].\n   Discussion:\n\
    \      None\n   Measurement Units:\n      N/A\n"
- title: 2.1.8.  Standalone Mode
  contents:
  - "2.1.8.  Standalone Mode\n   Definition:\n      A single controller handles all\
    \ control-plane functionalities\n      without redundancy, and it is unable to\
    \ provide high availability\n      and/or automatic failover.\n   Discussion:\n\
    \      In standalone mode, one controller manages one or more network\n      domains.\n\
    \   Measurement Units:\n      N/A\n"
- title: 2.1.9.  Cluster/Redundancy Mode
  contents:
  - "2.1.9.  Cluster/Redundancy Mode\n   Definition:\n      In this mode, a group\
    \ of two or more controllers handles all\n      control-plane functionalities.\n\
    \   Discussion:\n      In cluster mode, multiple controllers are teamed together\
    \ for the\n      purpose of load sharing and/or high availability.  The controllers\n\
    \      in the group may operate in active/standby (master/slave) or\n      active/active\
    \ (equal) mode, depending on the intended purpose.\n   Measurement Units:\n  \
    \    N/A\n"
- title: 2.1.10.  Asynchronous Message
  contents:
  - "2.1.10.  Asynchronous Message\n   Definition:\n      Any message from the Network\
    \ Device that is generated for network\n      events.\n   Discussion:\n      Control\
    \ messages like flow setup request and response messages are\n      classified\
    \ as asynchronous messages.  The controller has to return\n      a response message.\
    \  Note that the Network Device will not be in\n      blocking mode and continues\
    \ to send/receive other control\n      messages.\n   Measurement Units:\n    \
    \  N/A\n"
- title: 2.1.11.  Test Traffic Generator
  contents:
  - "2.1.11.  Test Traffic Generator\n   Definition:\n      The test traffic generator\
    \ is an entity that generates/receives\n      network traffic.\n   Discussion:\n\
    \      The test traffic generator typically connects with Network Devices\n  \
    \    to send/receive real-time network traffic.\n   Measurement Units:\n     \
    \ N/A\n"
- title: 2.1.12.  Leaf-Spine Topology
  contents:
  - "2.1.12.  Leaf-Spine Topology\n   Definition:\n      \"Leaf-Spine\" is a two-layered\
    \ network topology, where a series of\n      leaf switches that form the access\
    \ layer are fully meshed to a\n      series of spine switches that form the backbone\
    \ layer.\n   Discussion:\n      In the Leaf-Spine topology, every leaf switch\
    \ is connected to each\n      of the spine switches in the topology.\n   Measurement\
    \ Units:\n      N/A\n"
- title: 2.2.  Test Configuration/Setup Terms
  contents:
  - '2.2.  Test Configuration/Setup Terms

    '
- title: 2.2.1.  Number of Network Devices
  contents:
  - "2.2.1.  Number of Network Devices\n   Definition:\n      The number of Network\
    \ Devices present in the defined test\n      topology.\n   Discussion:\n     \
    \ The Network Devices defined in the test topology can be deployed\n      using\
    \ real hardware or can be emulated in hardware platforms.\n   Measurement Units:\n\
    \      Number of Network Devices.\n"
- title: 2.2.2.  Trial Repetition
  contents:
  - "2.2.2.  Trial Repetition\n   Definition:\n      The number of times the test\
    \ needs to be repeated.\n   Discussion:\n      The test needs to be repeated for\
    \ multiple iterations to obtain a\n      reliable metric.  It is recommended that\
    \ this test SHOULD be\n      performed for at least 10 iterations to increase\
    \ confidence in the\n      measured results.\n   Measurement Units:\n      Number\
    \ of trials.\n"
- title: 2.2.3.  Trial Duration
  contents:
  - "2.2.3.  Trial Duration\n   Definition:\n      Defines the duration of test trials\
    \ for each iteration.\n   Discussion:\n      The Trial Duration forms the basis\
    \ for \"stop\" criteria for\n      benchmarking tests.  Trials not completed within\
    \ this time\n      interval are considered incomplete.\n   Measurement Units:\n\
    \      Seconds.\n"
- title: 2.2.4.  Number of Cluster Nodes
  contents:
  - "2.2.4.  Number of Cluster Nodes\n   Definition:\n      Defines the number of\
    \ controllers present in the controller\n      cluster.\n   Discussion:\n    \
    \  This parameter is relevant when testing the controller's\n      performance\
    \ in clustering/teaming mode.  The number of nodes in\n      the cluster MUST\
    \ be greater than 1.\n   Measurement Units:\n      Number of controller nodes.\n"
- title: 2.3.  Benchmarking Terms
  contents:
  - "2.3.  Benchmarking Terms\n   This section defines metrics for benchmarking the\
    \ SDN Controller.\n   The procedure for performing the defined metrics is defined\
    \ in the\n   companion methodology document [RFC8456].\n"
- title: 2.3.1.  Performance
  contents:
  - '2.3.1.  Performance

    '
- title: 2.3.1.1.  Network Topology Discovery Time
  contents:
  - "2.3.1.1.  Network Topology Discovery Time\n   Definition:\n      The time taken\
    \ by the controller(s) to determine the complete\n      network topology, defined\
    \ as the interval starting with the first\n      discovery message from the controller(s)\
    \ at its southbound\n      interface and ending with all features of the static\
    \ topology\n      determined.\n   Discussion:\n      Network topology discovery\
    \ is key for the SDN Controller to\n      provision and manage the network, so\
    \ it is important to measure\n      how quickly the controller discovers the topology\
    \ to learn the\n      current network state.  This benchmark is obtained by presenting\
    \ a\n      network topology (tree, mesh, or linear) with a specified number\n\
    \      of nodes to the controller and waiting for the discovery process\n    \
    \  to complete.  It is expected that the controller supports a\n      network\
    \ discovery mechanism and uses protocol messages for its\n      discovery process.\n\
    \   Measurement Units:\n      Milliseconds.\n"
- title: 2.3.1.2.  Asynchronous Message Processing Time
  contents:
  - "2.3.1.2.  Asynchronous Message Processing Time\n   Definition:\n      The time\
    \ taken by the controller(s) to process an asynchronous\n      message, defined\
    \ as the interval starting with an asynchronous\n      message from a Network\
    \ Device after the discovery of all the\n      devices by the controller(s) and\
    \ ending with a response message\n      from the controller(s) at its southbound\
    \ interface.\n   Discussion:\n      For SDN to support dynamic network provisioning,\
    \ it is important\n      to measure how quickly the controller responds to an\
    \ event\n      triggered from the network.  The event can be any notification\n\
    \      messages generated by a Network Device upon arrival of a new flow,\n  \
    \    link down, etc.  This benchmark is obtained by sending\n      asynchronous\
    \ messages from every connected Network Device one at a\n      time for the defined\
    \ Trial Duration.  This test assumes that the\n      controller will respond to\
    \ the received asynchronous messages.\n   Measurement Units:\n      Milliseconds.\n"
- title: 2.3.1.3.  Asynchronous Message Processing Rate
  contents:
  - "2.3.1.3.  Asynchronous Message Processing Rate\n   Definition:\n      The number\
    \ of responses to asynchronous messages per second (a new\n      flow arrival\
    \ notification message, link down, etc.) for which the\n      controller(s) performed\
    \ processing and replied with a valid and\n      productive (non-trivial) response\
    \ message.\n   Discussion:\n      As SDN assures a flexible network and agile\
    \ provisioning, it is\n      important to measure how many network events (a new\
    \ flow arrival\n      notification message, link down, etc.) the controller can\
    \ handle\n      at a time.  This benchmark is measured by sending asynchronous\n\
    \      messages from every connected Network Device at the rate that the\n   \
    \   controller processes (without dropping them).  This test assumes\n      that\
    \ the controller responds to all the received asynchronous\n      messages (the\
    \ messages can be designed to elicit individual\n      responses).\n      When\
    \ sending asynchronous messages to the controller(s) at high\n      rates, some\
    \ messages or responses may be discarded or corrupted\n      and require retransmission\
    \ to controller(s).  Therefore, a useful\n      qualification on the Asynchronous\
    \ Message Processing Rate is\n      whether the incoming message count equals\
    \ the response count in\n      each trial.  This is called the Loss-Free Asynchronous\
    \ Message\n      Processing Rate.\n      Note that several of the early controller\
    \ benchmarking tools did\n      not consider lost messages and instead report\
    \ the maximum response\n      rate.  This is called the Maximum Asynchronous Message\
    \ Processing\n      Rate.\n      To characterize both the Loss-Free Asynchronous\
    \ Message Processing\n      Rate and the Maximum Asynchronous Message Processing\
    \ Rate, a test\n      can begin the first trial by sending asynchronous messages\
    \ to the\n      controller(s) at the maximum possible rate and can then record\
    \ the\n      message reply rate and the message loss rate.  The message-sending\n\
    \      rate is then decreased by the STEP size.  The message reply rate\n    \
    \  and the message loss rate are recorded.  The test ends with a\n      trial\
    \ where the controller(s) processes all of the asynchronous\n      messages sent\
    \ without loss.  This is the Loss-Free Asynchronous\n      Message Processing\
    \ Rate.\n      The trial where the controller(s) produced the maximum response\n\
    \      rate is the Maximum Asynchronous Message Processing Rate.  Of\n      course,\
    \ the first trial can begin at a low sending rate with zero\n      lost responses\
    \ and then increase the rate until the Loss-Free\n      Asynchronous Message Processing\
    \ Rate and the Maximum Asynchronous\n      Message Processing Rate are discovered.\n\
    \   Measurement Units:\n      Messages processed per second.\n"
- title: 2.3.1.4.  Reactive Path Provisioning Time
  contents:
  - "2.3.1.4.  Reactive Path Provisioning Time\n   Definition:\n      The time taken\
    \ by the controller to set up a path reactively\n      between source and destination\
    \ nodes, defined as the interval\n      starting with the first flow provisioning\
    \ request message received\n      by the controller(s) and ending with the last\
    \ flow provisioning\n      response message sent from the controller(s) at its\
    \ southbound\n      interface.\n   Discussion:\n      As SDN supports agile provisioning,\
    \ it is important to measure how\n      fast the controller provisions an end-to-end\
    \ flow in the\n      data plane.  The benchmark is obtained by sending traffic\
    \ from a\n      source endpoint to the destination endpoint and finding the time\n\
    \      difference between the first and last flow provisioning message\n     \
    \ exchanged between the controller and the Network Devices for the\n      traffic\
    \ path.\n   Measurement Units:\n      Milliseconds.\n"
- title: 2.3.1.5.  Proactive Path Provisioning Time
  contents:
  - "2.3.1.5.  Proactive Path Provisioning Time\n   Definition:\n      The time taken\
    \ by the controller to proactively set up a path\n      between source and destination\
    \ nodes, defined as the interval\n      starting with the first proactive flow\
    \ provisioned in the\n      controller(s) at its northbound interface and ending\
    \ with the last\n      flow provisioning command message sent from the controller(s)\
    \ at\n      its southbound interface.\n   Discussion:\n      For SDN to support\
    \ pre-provisioning of the traffic path from the\n      application, it is important\
    \ to measure how fast the controller\n      provisions an end-to-end flow in the\
    \ data plane.  The benchmark is\n      obtained by provisioning a flow on the\
    \ controller's northbound\n      interface for the traffic to reach from a source\
    \ to a destination\n      endpoint and finding the time difference between the\
    \ first and\n      last flow provisioning message exchanged between the controller\n\
    \      and the Network Devices for the traffic path.\n   Measurement Units:\n\
    \      Milliseconds.\n"
- title: 2.3.1.6.  Reactive Path Provisioning Rate
  contents:
  - "2.3.1.6.  Reactive Path Provisioning Rate\n   Definition:\n      The maximum\
    \ number of independent paths a controller can\n      concurrently establish per\
    \ second between source and destination\n      nodes reactively, defined as the\
    \ number of paths provisioned per\n      second by the controller(s) at its southbound\
    \ interface for the\n      flow provisioning requests received for path provisioning\
    \ at its\n      southbound interface between the start of the trial and the expiry\n\
    \      of the given Trial Duration.\n   Discussion:\n      For SDN to support\
    \ agile traffic forwarding, it is important to\n      measure how many end-to-end\
    \ flows the controller can set up in the\n      data plane.  This benchmark is\
    \ obtained by sending each traffic\n      flow with unique source and destination\
    \ pairs from the source\n      Network Device and determining the number of frames\
    \ received at\n      the destination Network Device.\n   Measurement Units:\n\
    \      Paths provisioned per second.\n"
- title: 2.3.1.7.  Proactive Path Provisioning Rate
  contents:
  - "2.3.1.7.  Proactive Path Provisioning Rate\n   Definition:\n      The maximum\
    \ number of independent paths a controller can\n      concurrently establish per\
    \ second between source and destination\n      nodes proactively, defined as the\
    \ number of paths provisioned per\n      second by the controller(s) at its southbound\
    \ interface for the\n      paths provisioned in its northbound interface between\
    \ the start of\n      the trial and the expiry of the given Trial Duration.\n\
    \   Discussion:\n      For SDN to support pre-provisioning of the traffic path\
    \ for a\n      larger network from the application, it is important to measure\n\
    \      how many end-to-end flows the controller can set up in the\n      data\
    \ plane.  This benchmark is obtained by sending each traffic\n      flow with\
    \ unique source and destination pairs from the source\n      Network Device. \
    \ Program the flows on the controller's northbound\n      interface for traffic\
    \ to reach from each of the unique source and\n      destination pairs, and determine\
    \ the number of frames received at\n      the destination Network Device.\n  \
    \ Measurement Units:\n      Paths provisioned per second.\n"
- title: 2.3.1.8.  Network Topology Change Detection Time
  contents:
  - "2.3.1.8.  Network Topology Change Detection Time\n   Definition:\n      The amount\
    \ of time taken by the controller to detect any changes\n      in the network\
    \ topology, defined as the interval starting with the\n      notification message\
    \ received by the controller(s) at its\n      southbound interface and ending\
    \ with the first topology\n      rediscovery messages sent from the controller(s)\
    \ at its southbound\n      interface.\n   Discussion:\n      In order for the\
    \ controller to support fast network failure\n      recovery, it is critical to\
    \ measure how fast the controller is\n      able to detect any network-state change\
    \ events.  This benchmark is\n      obtained by triggering a topology change event\
    \ and measuring the\n      time the controller takes to detect and initiate a\
    \ topology\n      rediscovery process.\n   Measurement Units:\n      Milliseconds.\n"
- title: 2.3.2.  Scalability
  contents:
  - '2.3.2.  Scalability

    '
- title: 2.3.2.1.  Control Sessions Capacity
  contents:
  - "2.3.2.1.  Control Sessions Capacity\n   Definition:\n      The maximum number\
    \ of control sessions the controller can\n      maintain, defined as the number\
    \ of sessions that the controller\n      can accept from Network Devices, starting\
    \ with the first control\n      session and ending with the last control session\
    \ that the\n      controller(s) accepts at its southbound interface.\n   Discussion:\n\
    \      Measuring the controller's Control Sessions Capacity is important\n   \
    \   for determining the controller's system and bandwidth resource\n      requirements.\
    \  This benchmark is obtained by establishing a\n      control session with the\
    \ controller from each of the Network\n      Devices until the controller fails.\
    \  The number of sessions that\n      were successfully established will provide\
    \ the Control Sessions\n      Capacity.\n   Measurement Units:\n      Maximum\
    \ number of control sessions.\n"
- title: 2.3.2.2.  Network Discovery Size
  contents:
  - "2.3.2.2.  Network Discovery Size\n   Definition:\n      The network size (number\
    \ of nodes and links) that a controller can\n      discover, defined as the size\
    \ of a network that the controller(s)\n      can discover, starting with a network\
    \ topology provided by the\n      user for discovery and ending with the number\
    \ of nodes and links\n      that the controller(s) can successfully discover.\n\
    \   Discussion:\n      Measuring the maximum network size that the controller\
    \ can\n      discover is key to optimal network planning.  This benchmark is\n\
    \      obtained by presenting an initial set of Network Devices for\n      discovery\
    \ to the controller.  Based on the initial discovery, the\n      number of Network\
    \ Devices is increased or decreased to determine\n      the maximum number of\
    \ nodes and links that the controller can\n      discover.\n   Measurement Units:\n\
    \      Maximum number of network nodes and links.\n"
- title: 2.3.2.3.  Forwarding Table Capacity
  contents:
  - "2.3.2.3.  Forwarding Table Capacity\n   Definition:\n      The maximum number\
    \ of flow entries that a controller can manage in\n      its Forwarding Table.\n\
    \   Discussion:\n      It is important to measure the capacity of a controller's\n\
    \      Forwarding Table to determine the number of flows that the\n      controller\
    \ can forward without flooding or dropping any traffic.\n      This benchmark\
    \ is obtained by continuously presenting the\n      controller with new flow entries\
    \ through the Reactive Flow\n      Provisioning mode or the Proactive Flow Provisioning\
    \ mode until\n      the Forwarding Table becomes full.  The maximum number of\
    \ nodes\n      that the controller can hold in its Forwarding Table will provide\n\
    \      the Forwarding Table Capacity.\n   Measurement Units:\n      Maximum number\
    \ of flow entries managed.\n"
- title: 2.3.3.  Security
  contents:
  - '2.3.3.  Security

    '
- title: 2.3.3.1.  Exception Handling
  contents:
  - "2.3.3.1.  Exception Handling\n   Definition:\n      To determine the effect of\
    \ handling error packets and\n      notifications on performance tests.\n   Discussion:\n\
    \      This benchmark is to be performed after obtaining the baseline\n      measurement\
    \ results for the performance tests defined in\n      Section 2.3.1.  This benchmark\
    \ determines the deviation from the\n      baseline performance due to the handling\
    \ of error or failure\n      messages from the connected Network Devices.\n  \
    \ Measurement Units:\n      Deviation from baseline metrics while handling Exceptions.\n"
- title: 2.3.3.2.  Handling Denial-of-Service Attacks
  contents:
  - "2.3.3.2.  Handling Denial-of-Service Attacks\n   Definition:\n      To determine\
    \ the effect of handling denial-of-service (DoS)\n      attacks on performance\
    \ and scalability tests.\n   Discussion:\n      This benchmark is to be performed\
    \ after obtaining the baseline\n      measurement results for the performance\
    \ and scalability tests\n      defined in Sections 2.3.1 and 2.3.2.  This benchmark\
    \ determines\n      the deviation from the baseline performance due to the handling\
    \ of\n      DoS attacks on the controller.\n   Measurement Units:\n      Deviation\
    \ from baseline metrics while handling DoS attacks.\n"
- title: 2.3.4.  Reliability
  contents:
  - '2.3.4.  Reliability

    '
- title: 2.3.4.1.  Controller Failover Time
  contents:
  - "2.3.4.1.  Controller Failover Time\n   Definition:\n      The time taken to switch\
    \ from an active controller to the backup\n      controller when the controllers\
    \ operate in redundancy mode and the\n      active controller fails, defined as\
    \ the interval starting when the\n      active controller is brought down and\
    \ ending with the first\n      rediscovery message received from the new controller\
    \ at its\n      southbound interface.\n   Discussion:\n      This benchmark determines\
    \ the impact of provisioning new flows\n      when controllers are teamed together\
    \ and the active controller\n      fails.\n   Measurement Units:\n      Milliseconds.\n"
- title: 2.3.4.2.  Network Re-provisioning Time
  contents:
  - "2.3.4.2.  Network Re-provisioning Time\n   Definition:\n      The time taken\
    \ by the controller to reroute traffic when there is\n      a failure in existing\
    \ traffic paths, defined as the interval\n      starting with the first failure\
    \ notification message received by\n      the controller and ending with the last\
    \ flow re-provisioning\n      message sent by the controller at its southbound\
    \ interface.\n   Discussion:\n      This benchmark determines the controller's\
    \ re-provisioning ability\n      upon network failures and makes the following\
    \ assumptions:\n      1. The network topology supports a redundant path between\
    \ the\n         source and destination endpoints.\n      2. The controller does\
    \ not pre-provision the redundant path.\n   Measurement Units:\n      Milliseconds.\n"
- title: 3.  Test Setup
  contents:
  - "3.  Test Setup\n   This section provides common reference topologies that are\
    \ referred\n   to in individual tests defined in the companion methodology document\n\
    \   [RFC8456].\n"
- title: 3.1.  Test Setup - Controller Operating in Standalone Mode
  contents:
  - "3.1.  Test Setup - Controller Operating in Standalone Mode\n       +-----------------------------------------------------------+\n\
    \       |               Application-Plane Test Emulator             |\n      \
    \ |                                                           |\n       |    \
    \    +-----------------+      +-------------+           |\n       |        | \
    \  Application   |      |   Service   |           |\n       |        +-----------------+\
    \      +-------------+           |\n       |                                 \
    \                          |\n       +-----------------------------+(I2)-------------------------+\n\
    \                                     |\n                                    \
    \ | (Northbound Interface)\n                    +-------------------------------+\n\
    \                    |       +----------------+      |\n                    |\
    \       | SDN Controller |      |\n                    |       +----------------+\
    \      |\n                    |                               |\n            \
    \        |    Device Under Test (DUT)    |\n                    +-------------------------------+\n\
    \                                     | (Southbound Interface)\n             \
    \                        |\n       +-----------------------------+(I1)-------------------------+\n\
    \       |                                                           |\n      \
    \ |             +-----------+     +-----------+               |\n       |    \
    \         |  Network  |     |  Network  |               |\n       |          \
    \   | Device 2  |--..-| Device n-1|               |\n       |             +-----------+\
    \     +-----------+               |\n       |                     /    \\   /\
    \    \\                       |\n       |                    /      \\ /     \
    \ \\                      |\n       |                l0 /        X        \\ ln\
    \                  |\n       |                  /        / \\        \\      \
    \              |\n       |               +-----------+  +-----------+        \
    \        |\n       |               |  Network  |  |  Network  |              \
    \  |\n       |               |  Device 1 |..|  Device n |                |\n \
    \      |               +-----------+  +-----------+                |\n       |\
    \                     |              |                      |\n       |      \
    \     +---------------+  +---------------+            |\n       |           |\
    \ Test Traffic  |  | Test Traffic  |            |\n       |           |  Generator\
    \    |  |  Generator    |            |\n       |           |    (TP1)      | \
    \ |    (TP2)      |            |\n       |           +---------------+  +---------------+\
    \            |\n       |                                                     \
    \      |\n       |              Forwarding-Plane Test Emulator               |\n\
    \       +-----------------------------------------------------------+\n      \
    \                           Figure 1\n"
- title: 3.2.  Test Setup - Controller Operating in Cluster Mode
  contents:
  - "3.2.  Test Setup - Controller Operating in Cluster Mode\n       +-----------------------------------------------------------+\n\
    \       |               Application-Plane Test Emulator             |\n      \
    \ |                                                           |\n       |    \
    \    +-----------------+      +-------------+           |\n       |        | \
    \  Application   |      |   Service   |           |\n       |        +-----------------+\
    \      +-------------+           |\n       |                                 \
    \                          |\n       +-----------------------------+(I2)-------------------------+\n\
    \                                     |\n                                    \
    \ | (Northbound Interface)\n        +---------------------------------------------------------+\n\
    \        |                                                         |\n       \
    \ | +------------------+           +------------------+     |\n        | | SDN\
    \ Controller 1 | <--E/W--> | SDN Controller n |     |\n        | +------------------+\
    \           +------------------+     |\n        |                            \
    \                             |\n        |                    Device Under Test\
    \ (DUT)              |\n        +---------------------------------------------------------+\n\
    \                                     | (Southbound Interface)\n             \
    \                        |\n       +-----------------------------+(I1)-------------------------+\n\
    \       |                                                           |\n      \
    \ |             +-----------+     +-----------+               |\n       |    \
    \         |  Network  |     |  Network  |               |\n       |          \
    \   | Device 2  |--..-| Device n-1|               |\n       |             +-----------+\
    \     +-----------+               |\n       |                     /    \\   /\
    \    \\                       |\n       |                    /      \\ /     \
    \ \\                      |\n       |                l0 /        X        \\ ln\
    \                  |\n       |                  /        / \\        \\      \
    \              |\n       |               +-----------+  +-----------+        \
    \        |\n       |               |  Network  |  |  Network  |              \
    \  |\n       |               |  Device 1 |..|  Device n |                |\n \
    \      |               +-----------+  +-----------+                |\n       |\
    \                     |              |                      |\n       |      \
    \     +---------------+  +---------------+            |\n       |           |\
    \ Test Traffic  |  | Test Traffic  |            |\n       |           |  Generator\
    \    |  |  Generator    |            |\n       |           |    (TP1)      | \
    \ |    (TP2)      |            |\n       |           +---------------+  +---------------+\
    \            |\n       |                                                     \
    \      |\n       |              Forwarding-Plane Test Emulator               |\n\
    \       +-----------------------------------------------------------+\n      \
    \                           Figure 2\n"
- title: 4.  Test Coverage
  contents:
  - "4.  Test Coverage\n   +-------------------------------------------------------------------+\n\
    \   |  Lifecycle |       Speed       |  Scalability  |  Reliability     |\n  \
    \ +------------+-------------------+---------------+------------------+\n   |\
    \            | 1. Network        |1. Network     |                  |\n   |  \
    \          |    Topology       |   Discovery   |                  |\n   |    \
    \        |    Discovery      |   Size        |                  |\n   |      \
    \      |    Time           |               |                  |\n   |        \
    \    |                   |               |                  |\n   |          \
    \  | 2. Reactive Path  |               |                  |\n   |            |\
    \    Provisioning   |               |                  |\n   |            |  \
    \  Time           |               |                  |\n   |            |    \
    \               |               |                  |\n   |            | 3. Proactive\
    \ Path |               |                  |\n   |  Setup     |    Provisioning\
    \   |               |                  |\n   |            |    Time          \
    \ |               |                  |\n   |            |                   |\
    \               |                  |\n   |            | 4. Reactive Path  |  \
    \             |                  |\n   |            |    Provisioning   |    \
    \           |                  |\n   |            |    Rate           |      \
    \         |                  |\n   |            |                   |        \
    \       |                  |\n   |            | 5. Proactive Path |          \
    \     |                  |\n   |            |    Provisioning   |            \
    \   |                  |\n   |            |    Rate           |              \
    \ |                  |\n   |            |                   |               |\
    \                  |\n   +------------+-------------------+---------------+------------------+\n\
    \   |            | 1. Maximum        |1. Control     |1. Network        |\n  \
    \ |            |    Asynchronous   |   Sessions    |   Topology       |\n   |\
    \            |    Message        |   Capacity    |   Change         |\n   |  \
    \          |    Processing Rate|               |   Detection Time |\n   |    \
    \        |                   |2. Forwarding  |                  |\n   |      \
    \      | 2. Loss-Free      |   Table       |2. Exception      |\n   |        \
    \    |    Asynchronous   |   Capacity    |   Handling       |\n   |          \
    \  |    Message        |               |                  |\n   | Operational|\
    \    Processing Rate|               |3. Handling       |\n   |            |  \
    \                 |               |   Denial-of-     |\n   |            | 3. Asynchronous\
    \   |               |   Service Attacks|\n   |            |    Message       \
    \ |               |                  |\n   |            |    Processing Time|\
    \               |4. Network        |\n   |            |                   |  \
    \             |   Re-provisioning|\n   |            |                   |    \
    \           |   Time           |\n   |            |                   |      \
    \         |                  |\n   +------------+-------------------+---------------+------------------+\n\
    \   | Teardown   |                   |               |1. Controller     |\n  \
    \ |            |                   |               |   Failover Time  |\n   +------------+-------------------+---------------+------------------+\n"
- title: 5.  IANA Considerations
  contents:
  - "5.  IANA Considerations\n   This document has no IANA actions.\n"
- title: 6.  Security Considerations
  contents:
  - "6.  Security Considerations\n   The benchmarking tests described in this document\
    \ are limited to the\n   performance characterization of controllers in a lab\
    \ environment with\n   isolated networks.\n   The benchmarking network topology\
    \ will be an independent test setup\n   and MUST NOT be connected to devices that\
    \ may forward the test\n   traffic into a production network or misroute traffic\
    \ to the test\n   management network.\n   Further, benchmarking is performed on\
    \ a \"black-box\" basis, relying\n   solely on measurements observable external\
    \ to the controller.\n   Special capabilities SHOULD NOT exist in the controller\
    \ specifically\n   for benchmarking purposes.  Any implications for network security\n\
    \   arising from the controller SHOULD be identical in the lab and in\n   production\
    \ networks.\n"
- title: 7.  Normative References
  contents:
  - "7.  Normative References\n   [RFC2119]  Bradner, S., \"Key words for use in RFCs\
    \ to Indicate\n              Requirement Levels\", BCP 14, RFC 2119,\n       \
    \       DOI 10.17487/RFC2119, March 1997,\n              <https://www.rfc-editor.org/info/rfc2119>.\n\
    \   [RFC2330]  Paxson, V., Almes, G., Mahdavi, J., and M. Mathis,\n          \
    \    \"Framework for IP Performance Metrics\", RFC 2330,\n              DOI 10.17487/RFC2330,\
    \ May 1998,\n              <https://www.rfc-editor.org/info/rfc2330>.\n   [RFC4689]\
    \  Poretsky, S., Perser, J., Erramilli, S., and S. Khurana,\n              \"\
    Terminology for Benchmarking Network-layer Traffic\n              Control Mechanisms\"\
    , RFC 4689, DOI 10.17487/RFC4689,\n              October 2006, <https://www.rfc-editor.org/info/rfc4689>.\n\
    \   [RFC7426]  Haleplidis, E., Ed., Pentikousis, K., Ed., Denazis, S.,\n     \
    \         Hadi Salim, J., Meyer, D., and O. Koufopavlou, \"Software-\n       \
    \       Defined Networking (SDN): Layers and Architecture\n              Terminology\"\
    , RFC 7426, DOI 10.17487/RFC7426,\n              January 2015, <https://www.rfc-editor.org/info/rfc7426>.\n\
    \   [RFC8174]  Leiba, B., \"Ambiguity of Uppercase vs Lowercase in\n         \
    \     RFC 2119 Key Words\", BCP 14, RFC 8174,\n              DOI 10.17487/RFC8174,\
    \ May 2017,\n              <https://www.rfc-editor.org/info/rfc8174>.\n   [RFC8456]\
    \  Bhuvaneswaran, V., Basil, A., Tassinari, M., Manral, V.,\n              and\
    \ S. Banks, \"Benchmarking Methodology for Software-\n              Defined Networking\
    \ (SDN) Controller Performance\",\n              RFC 8456, DOI 10.17487/RFC8456,\
    \ October 2018,\n              <https://www.rfc-editor.org/info/rfc8456>.\n"
- title: Acknowledgments
  contents:
  - "Acknowledgments\n   The authors would like to acknowledge Al Morton (AT&T) for\
    \ his\n   significant contributions to the earlier draft versions of this\n  \
    \ document.  The authors would like to thank the following individuals\n   for\
    \ providing their valuable comments to the earlier draft versions\n   of this\
    \ document: Sandeep Gangadharan (HP), M. Georgescu (NAIST),\n   Andrew McGregor\
    \ (Google), Scott Bradner, Jay Karthik (Cisco),\n   Ramki Krishnan (VMware), and\
    \ Boris Khasanov (Huawei).\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Bhuvaneswaran Vengainathan\n   Veryx Technologies Inc.\n\
    \   1 International Plaza, Suite 550\n   Philadelphia, PA  19113\n   United States\
    \ of America\n   Email: bhuvaneswaran.vengainathan@veryxtech.com\n   Anton Basil\n\
    \   Veryx Technologies Inc.\n   1 International Plaza, Suite 550\n   Philadelphia,\
    \ PA  19113\n   United States of America\n   Email: anton.basil@veryxtech.com\n\
    \   Mark Tassinari\n   Hewlett Packard Enterprise\n   8000 Foothills Blvd.\n \
    \  Roseville, CA  95747\n   United States of America\n   Email: mark.tassinari@hpe.com\n\
    \   Vishwas Manral\n   NanoSec Co\n   3350 Thomas Rd.\n   Santa Clara, CA  95054\n\
    \   United States of America\n   Email: vishwas.manral@gmail.com\n   Sarah Banks\n\
    \   VSS Monitoring\n   930 De Guigne Drive\n   Sunnyvale, CA  94085\n   United\
    \ States of America\n   Email: sbanks@encrypted.net\n"
