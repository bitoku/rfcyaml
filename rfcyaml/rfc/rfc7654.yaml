- title: __initial_text__
  contents:
  - '    Benchmarking Methodology for In-Service Software Upgrade (ISSU)

    '
- title: Abstract
  contents:
  - "Abstract\n   Modern forwarding devices attempt to minimize any control- and data-\n\
    \   plane disruptions while performing planned software changes by\n   implementing\
    \ a technique commonly known as In-Service Software\n   Upgrade (ISSU).  This\
    \ document specifies a set of common\n   methodologies and procedures designed\
    \ to characterize the overall\n   behavior of a Device Under Test (DUT), subject\
    \ to an ISSU event.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7654.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2015 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Conventions Used in This Document ...............................4\n  \
    \ 3. Generic ISSU Process, Phased Approach ...........................4\n    \
    \  3.1. Software Download ..........................................5\n      3.2.\
    \ Software Staging ...........................................6\n      3.3. Upgrade\
    \ Run ................................................6\n      3.4. Upgrade Acceptance\
    \ .........................................7\n   4. Test Methodology ................................................7\n\
    \      4.1. Test Topology ..............................................7\n  \
    \    4.2. Load Model .................................................8\n   5.\
    \ ISSU Test Methodology ...........................................9\n      5.1.\
    \ Pre-ISSU Recommended Verifications .........................9\n      5.2. Software\
    \ Staging ...........................................9\n      5.3. Upgrade Run\
    \ ...............................................10\n      5.4. Post-ISSU Verification\
    \ ....................................11\n      5.5. ISSU under Negative Stimuli\
    \ ...............................12\n   6. ISSU Abort and Rollback ........................................12\n\
    \   7. Final Report: Data Presentation and Analysis ...................13\n  \
    \    7.1. Data Collection Considerations ............................14\n   8.\
    \ Security Considerations ........................................15\n   9. References\
    \ .....................................................15\n      9.1. Normative\
    \ References ......................................15\n      9.2. Informative\
    \ References ....................................16\n   Acknowledgments ...................................................16\n\
    \   Authors' Addresses ................................................16\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   As required by most Service Provider (SP) network operators,\
    \ ISSU\n   functionality has been implemented by modern forwarding devices to\n\
    \   upgrade or downgrade from one software version to another with a goal\n  \
    \ of eliminating the downtime of the router and/or the outage of\n   service.\
    \  However, it is noted that while most operators desire\n   complete elimination\
    \ of downtime, minimization of downtime and\n   service degradation is often the\
    \ expectation.\n   The ISSU operation may apply in terms of an atomic version\
    \ change of\n   the entire system software or it may be applied in a more modular\n\
    \   sense, such as for a patch or maintenance upgrade.  The procedure\n   described\
    \ herein may be used to verify either approach, as may be\n   supported by the\
    \ vendor hardware and software.\n   In support of this document, the desired behavior\
    \ for an ISSU\n   operation can be summarized as follows:\n   -  The software\
    \ is successfully migrated from one version to a\n      successive version or\
    \ vice versa.\n   -  There are no control-plane interruptions throughout the process.\n\
    \      That is, the upgrade/downgrade could be accomplished while the\n      device\
    \ remains \"in service\".  It is noted, however, that most\n      service providers\
    \ will still undertake such actions in a\n      maintenance window (even in redundant\
    \ environments) to minimize\n      any risk.\n   -  Interruptions to the forwarding\
    \ plane are minimal to none.\n   -  The total time to accomplish the upgrade is\
    \ minimized, again to\n      reduce potential network outage exposure (e.g., an\
    \ external\n      failure event might impact the network as it operates with reduced\n\
    \      redundancy).\n   This document provides a set of procedures to characterize\
    \ a given\n   forwarding device's ISSU behavior quantitatively, from the\n   perspective\
    \ of meeting the above expectations.\n   Different hardware configurations may\
    \ be expected to be benchmarked,\n   but a typical configuration for a forwarding\
    \ device that supports\n   ISSU consists of at least one pair of Routing Processors\
    \ (RPs) that\n   operate in a redundant fashion, and single or multiple forwarding\n\
    \   engines (line cards) that may or may not be redundant, as well as\n   fabric\
    \ cards or other components as applicable.  This does not\n   preclude the possibility\
    \ that a device in question can perform ISSU\n   functions through the operation\
    \ of independent process components,\n   which may be upgraded without impact\
    \ to the overall operation of the\n   device.  As an example, perhaps the software\
    \ module involved in SNMP\n   functions can be upgraded without impacting other\
    \ operations.\n   The concept of a multi-chassis deployment may also be characterized\n\
    \   by the current set of proposed methodologies, but the implementation-\n  \
    \ specific details (i.e., process placement and others) are beyond the\n   scope\
    \ of the current document.\n   Since most modern forwarding devices, where ISSU\
    \ would be applicable,\n   do consist of redundant RPs and hardware-separated\
    \ control-plane and\n   data-plane functionality, this document will focus on\
    \ methodologies\n   that would be directly applicable to those platforms.  It\
    \ is\n   anticipated that the concepts and approaches described herein may be\n\
    \   readily extended to accommodate other device architectures as well.\n"
- title: 2.  Conventions Used in This Document
  contents:
  - "2.  Conventions Used in This Document\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in RFC 2119 [RFC2119].\n   In this document, these words will appear with that\
    \ interpretation\n   only when in ALL CAPS.  Lowercase uses of these words are\
    \ not to be\n   interpreted as carrying the significance of RFC 2119.\n"
- title: 3.  Generic ISSU Process, Phased Approach
  contents:
  - "3.  Generic ISSU Process, Phased Approach\n   ISSU may be viewed as the behavior\
    \ of a device when exposed to a\n   planned change in its software functionality.\
    \  This may mean changes\n   to the core operating system, separate processes\
    \ or daemons, or even\n   firmware logic in programmable hardware devices (e.g.,\
    \ Complex\n   Programmable Logic Device (CPLD) or Field-Programmable Gate Array\n\
    \   (FPGA)).  The goal of an ISSU implementation is to permit such\n   actions\
    \ with minimal or no disruption to the primary operation of the\n   device in\
    \ question.\n   ISSU may be user initiated through direct interaction with the\
    \ device\n   or activated through some automated process on a management system\
    \ or\n   even on the device itself.  For the purposes of this document, we\n \
    \  will focus on the model where the ISSU action is initiated by direct\n   user\
    \ intervention.\n   The ISSU process can be viewed as a series of different phases\
    \ or\n   activities, as defined below.  For each of these phases, the test\n \
    \  operator must record the outcome as well as any relevant observations\n   (defined\
    \ further in the present document).  Note that, a given vendor\n   implementation\
    \ may or may not permit the abortion of the in-progress\n   ISSU at particular\
    \ stages.  There may also be certain restrictions as\n   to ISSU availability\
    \ given certain functional configurations (for\n   example, ISSU in the presence\
    \ of Bidirectional Failure Detection\n   (BFD) [RFC5880] may not be supported).\
    \  It is incumbent upon the test\n   operator to ensure that the DUT is appropriately\
    \ configured to\n   provide the appropriate test environment.  As with any properly\n\
    \   orchestrated test effort, the test plan document should reflect these\n  \
    \ and other relevant details and should be written with close attention\n   to\
    \ the expected production operating environment.  The combined\n   analysis of\
    \ the results of each phase will characterize the overall\n   ISSU process with\
    \ the main goal of being able to identify and\n   quantify any disruption in service\
    \ (from the data- and control-plane\n   perspective) allowing operators to plan\
    \ their maintenance activities\n   with greater precision.\n"
- title: 3.1.  Software Download
  contents:
  - "3.1.  Software Download\n   In this first phase, the requested software package\
    \ may be downloaded\n   to the router and is typically stored onto a device. \
    \ The downloading\n   of software may be performed automatically by the device\
    \ as part of\n   the upgrade process, or it may be initiated separately.  Such\n\
    \   separation allows an administrator to download the new code inside or\n  \
    \ outside of a maintenance window; it is anticipated that downloading\n   new\
    \ code and saving it to disk on the router will not impact\n   operations.  In\
    \ the case where the software can be downloaded outside\n   of the actual upgrade\
    \ process, the administrator should do so;\n   downloading software can skew timing\
    \ results based on factors that\n   are often not comparative in nature.  Internal\
    \ compatibility\n   verification may be performed by the software running on the\
    \ DUT, to\n   verify the checksum of the files downloaded as well as any other\n\
    \   pertinent checks.  Depending upon vendor implementation, these\n   mechanisms\
    \ may include 1) verifying that the downloaded module(s)\n   meet a set of identified\
    \ prerequisites such as (but not limited to)\n   hardware or firmware compatibility\
    \ or minimum software requirements\n   or even 2) ensuring that device is \"authorized\"\
    \ to run the target\n   software.\n   Where such mechanisms are made available\
    \ by the product, they should\n   be verified, by the tester, with the goal of\
    \ avoiding operational\n   issues in production.  Verification should include\
    \ both positive\n   verification (ensuring that an ISSU action should be permitted)\
    \ as\n   well as negative tests (creation of scenarios where the verification\n\
    \   mechanisms would report exceptions).\n"
- title: 3.2.  Software Staging
  contents:
  - "3.2.  Software Staging\n   In this second phase, the requested software package\
    \ is loaded in the\n   pertinent components of a given forwarding device (typically\
    \ the RP\n   in standby state).  Internal compatibility verification may be\n\
    \   performed by the software running on the DUT, as part of the upgrade\n   process\
    \ itself, to verify the checksum of the files downloaded as\n   well as any other\
    \ pertinent checks.  Depending upon vendor\n   implementation, these mechanisms\
    \ may include verification that the\n   downloaded module(s) meet a set of identified\
    \ prerequisites such as\n   hardware or firmware compatibility or minimum software\
    \ requirements.\n   Where such mechanisms are made available by the product, they\
    \ should\n   be verified, by the tester (again with the goal of avoiding\n   operational\
    \ issues in production).  In this case, the execution of\n   these checks is within\
    \ the scope of the upgrade time and should be\n   included in the testing results.\
    \  Once the new software is downloaded\n   to the pertinent components of the\
    \ DUT, the upgrade begins, and the\n   DUT begins to prepare itself for upgrade.\
    \  Depending on the vendor\n   implementation, it is expected that redundant hardware\
    \ pieces within\n   the DUT are upgraded, including the backup or secondary RP.\n"
- title: 3.3.  Upgrade Run
  contents:
  - "3.3.  Upgrade Run\n   In this phase, a switchover of RPs may take place, where\
    \ one RP is\n   now upgraded with the new version of software.  More importantly,\
    \ the\n   \"Upgrade Run\" phase is where the internal changes made to information\n\
    \   and state (stored on the router, on disk, and in memory) are either\n   migrated\
    \ to the \"new\" version of code, or transformed/rebuilt to meet\n   the standards\
    \ of the new version of code, and pushed onto the\n   appropriate pieces of hardware.\
    \  It is within this phase that any\n   outage(s) on the control or forwarding\
    \ plane may be expected to be\n   observed.  This is the critical phase of the\
    \ ISSU, where the control\n   plane should not be impacted and any interruptions\
    \ to the forwarding\n   plane should be minimal to none.\n   If any control- or\
    \ data-plane interruptions are observed within this\n   stage, they should be\
    \ recorded as part of the results document.\n   For some implementations, the\
    \ two stages, as described in Section 3.2\n   and above, may be concatenated into\
    \ one monolithic operation.  In\n   that case, the calculation of the respective\
    \ ISSU time intervals may\n   need to be adapted accordingly.\n"
- title: 3.4.  Upgrade Acceptance
  contents:
  - "3.4.  Upgrade Acceptance\n   In this phase, the new version of software must\
    \ be running in all the\n   physical nodes of the logical forwarding device (RPs\
    \ and line cards\n   as applicable).  At this point, configuration control is\
    \ returned to\n   the operator, and normal device operation, i.e., outside of\
    \ ISSU-\n   oriented operation, is resumed.\n"
- title: 4.  Test Methodology
  contents:
  - "4.  Test Methodology\n   As stated by [RFC6815], the Test Topology Setup must\
    \ be part of an\n   Isolated Test Environment (ITE).\n   The reporting of results\
    \ must take into account the repeatability\n   considerations from Section 4 of\
    \ [RFC2544].  It is RECOMMENDED to\n   perform multiple trials and report average\
    \ results.  The results are\n   reported in a simple statement including the measured\
    \ frame loss and\n   ISSU impact times.\n"
- title: 4.1.  Test Topology
  contents:
  - "4.1.  Test Topology\n   The hardware configuration of the DUT (Device Under Test)\
    \ should be\n   identical to the one expected to be or currently deployed in\n\
    \   production in order for the benchmark to have relevance.  This would\n   include\
    \ the number of RPs, hardware version, memory, and initial\n   software release,\
    \ any common chassis components, such as fabric\n   hardware in the case of a\
    \ fabric-switching platform, and the specific\n   line cards (version, memory,\
    \ interfaces type, rate, etc.).\n   For the control and data plane, differing\
    \ configuration approaches\n   may be utilized.  The recommended approach relies\
    \ on \"mimicking\" the\n   existing production data- and control-plane information,\
    \ in order to\n   emulate all the necessary Layer 1 through Layer 3 communications\
    \ and,\n   if appropriate, the upper-layer characteristics of the network, as\n\
    \   well as end-to-end traffic/communication pairs.  In other words,\n   design\
    \ a representative load model of the production environment and\n   deploy a collapsed\
    \ topology utilizing test tools and/or external\n   devices, where the DUT will\
    \ be tested.  Note that, the negative\n   impact of ISSU operations is likely\
    \ to impact scaled, dynamic\n   topologies to a greater extent than simpler, static\
    \ environments.  As\n   such, this methodology (based upon production configuration)\
    \ is\n   advised for most test scenarios.\n   The second, more simplistic approach\
    \ is to deploy an ITE in which\n   endpoints are \"directly\" connected to the\
    \ DUT.  In this manner,\n   control-plane information is kept to a minimum (only\
    \ connected\n   interfaces), and only a basic data-plane of sources and destinations\n\
    \   is applied.  If this methodology is selected, care must be taken to\n   understand\
    \ that the systemic behavior of the ITE may not be identical\n   to that experienced\
    \ by a device in a production network role.  That\n   is, control-plane validation\
    \ may be minimal to none with this\n   methodology.  Consequently, if this approach\
    \ is chosen, comparison\n   with at least one production configuration is recommended\
    \ in order to\n   understand the direct relevance and limitations of the test\
    \ exercise.\n"
- title: 4.2.  Load Model
  contents:
  - "4.2.  Load Model\n   In consideration of the defined test topology, a load model\
    \ must be\n   developed to exercise the DUT while the ISSU event is introduced.\n\
    \   This applied load should be defined in such a manner as to provide a\n   granular,\
    \ repeatable verification of the ISSU impact on transit\n   traffic.  Sufficient\
    \ traffic load (rate) should be applied to permit\n   timing extrapolations at\
    \ a minimum granularity of 100 milliseconds,\n   e.g., 100 Mbps for a 10 Gbps\
    \ interface.  The use of steady traffic\n   streams rather than bursty loads is\
    \ preferred to simplify analysis.\n   The traffic should be patterned to provide\
    \ a broad range of source\n   and destination pairs, which resolve to a variety\
    \ of FIB (Forwarding\n   Information Base) prefix lengths.  If the production\
    \ network\n   environment includes multicast traffic or VPNs (L2, L3, or IPsec),\
    \ it\n   is critical to include these in the model.\n   For mixed protocol environments\
    \ (e.g., IPv4 and IPv6), frames should\n   be distributed between the different\
    \ protocols.  The distribution\n   should approximate the network conditions of\
    \ deployment.  In all\n   cases, the details of the mixed protocol distribution\
    \ must be\n   included in the reporting.\n   The feature, protocol timing, and\
    \ other relevant configurations\n   should be matched to the expected production\
    \ environment.  Deviations\n   from the production templates may be deemed necessary\
    \ by the test\n   operator (for example, certain features may not support ISSU\
    \ or the\n   test bed may not be able to accommodate such).  However, the impact\n\
    \   of any such divergence should be clearly understood, and the\n   differences\
    \ must be recorded in the results documentation.  It is\n   recommended that a\
    \ Network Management System (NMS) be deployed,\n   preferably similar to that\
    \ utilized in production.  This will allow\n   for monitoring of the DUT while\
    \ it is being tested, both in terms of\n   supporting the impact analysis on system\
    \ resources as well as\n   detecting interference with non-transit (management)\
    \ traffic as a\n   result of the ISSU operation.  It is suggested that the actual\
    \ test\n   exercise be managed utilizing direct console access to the DUT, if\
    \ at\n   all possible, to avoid the possibility that a network interruption\n\
    \   impairs execution of the test exercise.\n   All in all, the load model should\
    \ attempt to simulate the production\n   network environment to the greatest extent\
    \ possible in order to\n   maximize the applicability of the results generated.\n"
- title: 5.  ISSU Test Methodology
  contents:
  - "5.  ISSU Test Methodology\n   As previously described, for the purposes of this\
    \ test document, the\n   ISSU process is divided into three main phases.  The\
    \ following\n   methodology assumes that a suitable test topology has been\n \
    \  constructed per Section 4.  A description of the methodology to be\n   applied\
    \ for each of the above phases follows.\n"
- title: 5.1.  Pre-ISSU Recommended Verifications
  contents:
  - "5.1.  Pre-ISSU Recommended Verifications\n   The steps of this phase are as follows.\n\
    \   1.  Verify that enough hardware and software resources are available\n   \
    \    to complete the Load operation (e.g., enough disk space).\n   2.  Verify\
    \ that the redundancy states between RPs and other nodes are\n       as expected\
    \ (e.g., redundancy on, RPs synchronized).\n   3.  Verify that the device, if\
    \ running protocols capable of NSR (Non-\n       Stop Routing), is in a \"ready\"\
    \ state; that is, that the sync\n       between RPs is complete and the system\
    \ is ready for failover, if\n       necessary.\n   4.  Gather a configuration\
    \ snapshot of the device and all of its\n       applicable components.\n   5.\
    \  Verify that the node is operating in a \"steady\" state (that is,\n       no\
    \ critical or maintenance function is being currently\n       performed).\n  \
    \ 6.  Note any other operational characteristics that the tester may\n       deem\
    \ applicable to the specific implementation deployed.\n"
- title: 5.2.  Software Staging
  contents:
  - "5.2.  Software Staging\n   The steps of this phase are as follows.\n   1.  Establish\
    \ all relevant protocol adjacencies and stabilize routing\n       within the test\
    \ topology.  In particular, ensure that the scaled\n       levels of the dynamic\
    \ protocols are dimensioned as specified by\n       the test topology plan.\n\
    \   2.  Clear, relevant logs and interface counters to simplify analysis.\n  \
    \     If possible, set logging timestamps to a highly granular mode.\n       If\
    \ the topology includes management systems, ensure that the\n       appropriate\
    \ polling levels have been applied, sessions have been\n       established, and\
    \ the responses are per expectation.\n   3.  Apply the traffic loads as specified\
    \ in the load model previously\n       developed for this exercise.\n   4.  Document\
    \ an operational baseline for the test bed with relevant\n       data supporting\
    \ the above steps (include all relevant load\n       characteristics of interest\
    \ in the topology, e.g., routing load,\n       traffic volumes, memory and CPU\
    \ utilization).\n   5.  Note the start time (T0) and begin the code change process\n\
    \       utilizing the appropriate mechanisms as expected to be used in\n     \
    \  production (e.g., active download with TFTP, FTP, SCP, etc., or\n       direct\
    \ install from local or external storage facility).  In\n       order to ensure\
    \ that ISSU process timings are not skewed by the\n       lack of a network-wide\
    \ synchronization source, the use of a\n       network NTP source is encouraged.\n\
    \   6.  Take note of any logging information and command-line interface\n    \
    \   (CLI) prompts as needed.  (This detail will be vendor specific.)\n       Respond\
    \ to any DUT prompts in a timely manner.\n   7.  Monitor the DUT for the reload\
    \ of the secondary RP to the new\n       software level.  Once the secondary has\
    \ stabilized on the new\n       code, note the completion time.  The duration\
    \ of these steps will\n       be recorded as \"T1\".\n   8.  Review system logs\
    \ for any anomalies, check that relevant dynamic\n       protocols have remained\
    \ stable, and note traffic loss if any.\n       Verify that deployed management\
    \ systems have not identified any\n       unexpected behavior.\n"
- title: 5.3.  Upgrade Run
  contents:
  - "5.3.  Upgrade Run\n   The following assumes that the software load step and upgrade\
    \ step\n   are discretely controllable.  If not, maintain the aforementioned\n\
    \   timer and monitor for completion of the ISSU as described below.\n   1.  Note\
    \ the start time and initiate the actual upgrade procedure.\n   2.  Monitor the\
    \ operation of the secondary route processor while it\n       initializes with\
    \ the new software and assumes mastership of the\n       DUT.  At this point,\
    \ pay particular attention to any indications\n       of control-plane disruption,\
    \ traffic impact, or other anomalous\n       behavior.  Once the DUT has converged\
    \ upon the new code and\n       returned to normal operation, note the completion\
    \ time and log\n       the duration of this step as \"T2\".\n   3.  Review the\
    \ syslog data in the DUT and neighboring devices for any\n       behavior that\
    \ would be disruptive in a production environment\n       (line card reloads,\
    \ control-plane flaps, etc.).  Examine the\n       traffic generators for any\
    \ indication of traffic loss over this\n       interval.  If the Test Set reported\
    \ any traffic loss, note the\n       number of frames lost as \"TPL_frames\",\
    \ where TPL stands for\n       \"Total Packet Loss\".  If the Test Set also provides\
    \ outage\n       duration, note this as \"TPL_time\".  (Alternatively, TPL_time\
    \ may\n       be calculated as (TPL / Offered Load) * 1000.  The units for\n \
    \      Offered Load are packets per second; the units for TPL_time are\n     \
    \  milliseconds.)\n   4.  Verify the DUT status observations as per any NMS managing\
    \ the\n       DUT and its neighboring devices.  Document the observed CPU and\n\
    \       memory statistics both during and after the ISSU upgrade event,\n    \
    \   and ensure that memory and CPU have returned to an expected\n       (previously\
    \ baselined) level.\n"
- title: 5.4.  Post-ISSU Verification
  contents:
  - "5.4.  Post-ISSU Verification\n   The following describes a set of post-ISSU verification\
    \ tasks that\n   are not directly part of the ISSU process, but are recommended\
    \ for\n   execution in order to validate a successful upgrade.\n   1.  Configuration\
    \ delta analysis\n       Examine the post-ISSU configurations to determine if\
    \ any changes\n       have occurred either through process error or due to differences\n\
    \       in the implementation of the upgraded code.\n   2.  Exhaustive control-plane\
    \ analysis\n       Review the details of the Routing Information Base (RIB) and\
    \ FIB\n       to assess whether any unexpected changes have been introduced in\n\
    \       the forwarding paths.\n   3.  Verify that both RPs are up and that the\
    \ redundancy mechanism for\n       the control plane is enabled and fully synchronized.\n\
    \   4.  Verify that no control-plane (protocol) events or flaps were\n       detected.\n\
    \   5.  Verify that no L1 and or L2 interface flaps were observed.\n   6.  Document\
    \ the hitless operation or presence of an outage based\n       upon the counter\
    \ values provided by the Test Set.\n"
- title: 5.5.  ISSU under Negative Stimuli
  contents:
  - "5.5.  ISSU under Negative Stimuli\n   As an OPTIONAL Test Case, the operator\
    \ may want to perform an ISSU\n   test while the DUT is under stress by introducing\
    \ route churn to any\n   or all of the involved phases of the ISSU process.\n\
    \   One approach relies on the operator to gather statistical information\n  \
    \ from the production environment and determine a specific number of\n   routes\
    \ to flap every 'fixed' or 'variable' interval.  Alternatively,\n   the operator\
    \ may wish to simply preselect a fixed number of prefixes\n   to flap.  As an\
    \ example, an operator may decide to flap 1% of all the\n   BGP routes every minute\
    \ and restore them 1 minute afterwards.  The\n   tester may wish to apply this\
    \ negative stimulus throughout the entire\n   ISSU process or, most importantly,\
    \ during the run phase.  It is\n   important to ensure that these routes, which\
    \ are introduced solely\n   for stress proposes, must not overlap the ones (per\
    \ the load model)\n   specifically leveraged to calculate the TPL_time (recorded\
    \ outage).\n   Furthermore, there should not be 'operator-induced' control-plane\n\
    \   protocol adjacency flaps for the duration of the test process as it\n   may\
    \ adversely affect the characterization of the entire test\n   exercise.  For\
    \ example, triggering IGP adjacency events may force\n   recomputation of underlying\
    \ routing tables with attendant impact to\n   the perceived ISSU timings.  While\
    \ not recommended, if such trigger\n   events are desired by the test operator,\
    \ care should be taken to\n   avoid the introduction of unexpected anomalies within\
    \ the test\n   harness.\n"
- title: 6.  ISSU Abort and Rollback
  contents:
  - "6.  ISSU Abort and Rollback\n   Where a vendor provides such support, the ISSU\
    \ process could be\n   aborted for any reason by the operator.  However, the end\
    \ results and\n   behavior may depend on the specific phase where the process\
    \ was\n   aborted.  While this is implementation dependent, as a general\n   recommendation,\
    \ if the process is aborted during the \"Software\n   Download\" or \"Software\
    \ Staging\" phases, no impact to service or\n   device functionality should be\
    \ observed.  In contrast, if the process\n   is aborted during the \"Upgrade Run\"\
    \ or \"Upgrade Accept\" phases, the\n   system may reload and revert back to the\
    \ previous software release,\n   and, as such, this operation may be service affecting.\
    \  Where vendor\n   support is available, the abort/rollback functionality should\
    \ be\n   verified, and the impact, if any, quantified generally following the\n\
    \   procedures provided above.\n"
- title: '7.  Final Report: Data Presentation and Analysis'
  contents:
  - "7.  Final Report: Data Presentation and Analysis\n   All ISSU impact results\
    \ are summarized in a simple statement\n   describing the \"ISSU Disruption Impact\"\
    \ including the measured frame\n   loss and impact time, where impact time is\
    \ defined as the time frame\n   determined per the TPL_time reported outage. \
    \ These are considered to\n   be the primary data points of interest.\n   However,\
    \ the entire ISSU operational impact should also be considered\n   in support\
    \ of planning for maintenance, and, as such, additional\n   reporting points are\
    \ included.\n      Software download / secondary update      T1\n      Upgrade/Run\
    \                               T2\n      ISSU Traffic Disruption (Frame Loss)\
    \      TPL_frames\n      ISSU Traffic Impact Time (milliseconds)   TPL_time\n\
    \      ISSU Housekeeping Interval                T3\n      (Time for both RPs\
    \ up on new code and fully synced - Redundancy\n      restored)\n      Total ISSU\
    \ Maintenance Window             T4 (sum of T1+T2+T3)\n   The results reporting\
    \ must provide the following information:\n   -  DUT hardware and software detail\n\
    \   -  Test Topology definition and diagram (especially as related to the\n  \
    \    ISSU operation)\n   -  Load Model description including protocol mixes and\
    \ any divergence\n      from the production environment\n   -  Time Results as\
    \ per above\n   -  Anomalies Observed during ISSU\n   -  Anomalies Observed in\
    \ post-ISSU analysis\n   It is RECOMMENDED that the following parameters be reported\
    \ as\n   outlined below:\n   Parameter                Units or Examples\n   ---------------------------------------------------------------\n\
    \   Traffic Load             Frames per second and bits per second\n   Disruption\
    \ (average)     Frames\n   Impact Time (average)    Milliseconds\n   Number of\
    \ trials         Integer count\n   Protocols                IPv4, IPv6, MPLS,\
    \ etc.\n   Frame Size               Octets\n   Port Media               Ethernet,\
    \ Gigabit Ethernet (GbE),\n                            Packet over SONET (POS),\
    \ etc.\n   Port Speed               10 Gbps, 1 Gbps, 100 Mbps, etc.\n   Interface\
    \ Encaps         Ethernet, Ethernet VLAN, PPP,\n                            High-Level\
    \ Data Link Control (HDLC), etc.\n   Number of Prefixes       Integer count\n\
    \   flapped (ON Interval)    (Optional)  # of prefixes / Time (min.)\n   flapped\
    \ (OFF Interval)   (Optional)  # of prefixes / Time (min.)\n   Document any configuration\
    \ deltas that are observed after the ISSU\n   upgrade has taken effect.  Note\
    \ differences that are driven by\n   changes in the patch or release level, as\
    \ well as items that are\n   aberrant changes due to software faults.  In either\
    \ of these cases,\n   any unexpected behavioral changes should be analyzed and\
    \ a\n   determination made as to the impact of the change (be it functional\n\
    \   variances or operational impacts to existing scripts or management\n   mechanisms).\n"
- title: 7.1.  Data Collection Considerations
  contents:
  - "7.1.  Data Collection Considerations\n   When a DUT is undergoing an ISSU operation,\
    \ it's worth noting that\n   the DUT's data collection and reporting of data,\
    \ such as counters,\n   interface statistics, log messages, etc., may not be accurate.\
    \  As\n   such, one should not rely on the DUT's data collection methods, but\n\
    \   rather, should use the test tools and equipment to collect data used\n   for\
    \ reporting in Section 7.  Care and consideration should be paid in\n   testing\
    \ or adding new test cases, such that the desired data can be\n   collected from\
    \ the test tools themselves, or other external\n   equipment, outside of the DUT\
    \ itself.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   All BMWG memos are limited to testing in a laboratory\
    \ Isolated Test\n   Environment (ITE), thus avoiding accidental interruption to\n\
    \   production networks due to test activities.\n   All benchmarking activities\
    \ are limited to technology\n   characterization using controlled stimuli in a\
    \ laboratory environment\n   with dedicated address space and the other constraints\
    \ [RFC2544].\n   The benchmarking network topology will be an independent test\
    \ setup\n   and MUST NOT be connected to devices that may forward the test\n \
    \  traffic into a production network or misroute traffic to the test\n   management\
    \ network.\n   Further, benchmarking is performed on a \"black-box\" basis, relying\n\
    \   solely on measurements observable external to the Device Under Test /\n  \
    \ System Under Test (DUT/SUT).\n   Special capabilities should not exist in the\
    \ DUT/SUT specifically for\n   benchmarking purposes.  Any implications for network\
    \ security arising\n   from the DUT/SUT should be identical in the lab and in\
    \ production\n   networks.\n"
- title: 9.  References
  contents:
  - '9.  References

    '
- title: 9.1.  Normative References
  contents:
  - "9.1.  Normative References\n   [RFC2119]  Bradner, S., \"Key words for use in\
    \ RFCs to Indicate\n              Requirement Levels\", BCP 14, RFC 2119,\n  \
    \            DOI 10.17487/RFC2119, March 1997,\n              <http://www.rfc-editor.org/info/rfc2119>.\n\
    \   [RFC2544]  Bradner, S. and J. McQuaid, \"Benchmarking Methodology for\n  \
    \            Network Interconnect Devices\", RFC 2544,\n              DOI 10.17487/RFC2544,\
    \ March 1999,\n              <http://www.rfc-editor.org/info/rfc2544>.\n"
- title: 9.2.  Informative References
  contents:
  - "9.2.  Informative References\n   [RFC5880]  Katz, D. and D. Ward, \"Bidirectional\
    \ Forwarding Detection\n              (BFD)\", RFC 5880, DOI 10.17487/RFC5880,\
    \ June 2010,\n              <http://www.rfc-editor.org/info/rfc5880>.\n   [RFC6815]\
    \  Bradner, S., Dubray, K., McQuaid, J., and A. Morton,\n              \"Applicability\
    \ Statement for RFC 2544: Use on Production\n              Networks Considered\
    \ Harmful\", RFC 6815,\n              DOI 10.17487/RFC6815, November 2012,\n \
    \             <http://www.rfc-editor.org/info/rfc6815>.\n"
- title: Acknowledgments
  contents:
  - "Acknowledgments\n   The authors wish to thank Vibin Thomas for his valued review\
    \ and\n   feedback.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Sarah Banks\n   VSS Monitoring\n   Email: sbanks@encrypted.net\n\
    \   Fernando Calabria\n   Cisco Systems\n   Email: fcalabri@cisco.com\n   Gery\
    \ Czirjak\n   Juniper Networks\n   Email: gczirjak@juniper.net\n   Ramdas Machat\n\
    \   Juniper Networks\n   Email: rmachat@juniper.net\n"
