- title: __initial_text__
  contents:
  - "     Benchmarking Methodology for Software-Defined Networking (SDN)\n       \
    \                  Controller Performance\n"
- title: Abstract
  contents:
  - "Abstract\n   This document defines methodologies for benchmarking the control-\n\
    \   plane performance of Software-Defined Networking (SDN) Controllers.\n   The\
    \ SDN Controller is a core component in the SDN architecture that\n   controls\
    \ the behavior of the network.  SDN Controllers have been\n   implemented with\
    \ many varying designs in order to achieve their\n   intended network functionality.\
    \  Hence, the authors of this document\n   have taken the approach of considering\
    \ an SDN Controller to be a\n   black box, defining the methodology in a manner\
    \ that is agnostic to\n   protocols and network services supported by controllers.\
    \  This\n   document provides a method for measuring the performance of all\n\
    \   controller implementations.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 7841.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   https://www.rfc-editor.org/info/rfc8456.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2018 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (https://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \      1.1. Conventions Used in This Document ..........................4\n  \
    \ 2. Scope ...........................................................4\n   3.\
    \ Test Setup ......................................................4\n      3.1.\
    \ Test Setup - Controller Operating in Standalone Mode .......5\n      3.2. Test\
    \ Setup - Controller Operating in Cluster Mode ..........6\n   4. Test Considerations\
    \ .............................................7\n      4.1. Network Topology\
    \ ...........................................7\n      4.2. Test Traffic ...............................................7\n\
    \      4.3. Test Emulator Requirements .................................7\n  \
    \    4.4. Connection Setup ...........................................8\n    \
    \  4.5. Measurement Point Specification and Recommendation .........9\n      4.6.\
    \ Connectivity Recommendation ................................9\n      4.7. Test\
    \ Repeatability .........................................9\n      4.8. Test Reporting\
    \ .............................................9\n   5. Benchmarking Tests .............................................11\n\
    \      5.1. Performance ...............................................11\n  \
    \         5.1.1. Network Topology Discovery Time ....................11\n    \
    \       5.1.2. Asynchronous Message Processing Time ...............13\n      \
    \     5.1.3. Asynchronous Message Processing Rate ...............14\n        \
    \   5.1.4. Reactive Path Provisioning Time ....................17\n          \
    \ 5.1.5. Proactive Path Provisioning Time ...................19\n           5.1.6.\
    \ Reactive Path Provisioning Rate ....................21\n           5.1.7. Proactive\
    \ Path Provisioning Rate ...................23\n           5.1.8. Network Topology\
    \ Change Detection Time .............25\n      5.2. Scalability ...............................................26\n\
    \           5.2.1. Control Sessions Capacity ..........................26\n  \
    \         5.2.2. Network Discovery Size .............................27\n    \
    \       5.2.3. Forwarding Table Capacity ..........................29\n      5.3.\
    \ Security ..................................................31\n           5.3.1.\
    \ Exception Handling .................................31\n           5.3.2. Handling\
    \ Denial-of-Service Attacks .................32\n      5.4. Reliability ...............................................34\n\
    \           5.4.1. Controller Failover Time ...........................34\n  \
    \         5.4.2. Network Re-provisioning Time .......................36\n   6.\
    \ IANA Considerations ............................................37\n   7. Security\
    \ Considerations ........................................38\n   8. References\
    \ .....................................................38\n      8.1. Normative\
    \ References ......................................38\n      8.2. Informative\
    \ References ....................................38\n   Appendix A. Benchmarking\
    \ Methodology Using OpenFlow Controllers ...39\n     A.1. Protocol Overview ..........................................39\n\
    \     A.2. Messages Overview ..........................................39\n  \
    \   A.3. Connection Overview ........................................39\n    \
    \ A.4. Performance Benchmarking Tests .............................40\n      \
    \ A.4.1. Network Topology Discovery Time ........................40\n       A.4.2.\
    \ Asynchronous Message Processing Time ...................42\n       A.4.3. Asynchronous\
    \ Message Processing Rate ...................43\n       A.4.4. Reactive Path Provisioning\
    \ Time ........................44\n       A.4.5. Proactive Path Provisioning Time\
    \ .......................46\n       A.4.6. Reactive Path Provisioning Rate ........................47\n\
    \       A.4.7. Proactive Path Provisioning Rate .......................49\n  \
    \     A.4.8. Network Topology Change Detection Time .................50\n    \
    \ A.5. Scalability ................................................51\n      \
    \ A.5.1. Control Sessions Capacity ..............................51\n       A.5.2.\
    \ Network Discovery Size .................................52\n       A.5.3. Forwarding\
    \ Table Capacity ..............................54\n     A.6. Security ...................................................55\n\
    \       A.6.1. Exception Handling .....................................55\n  \
    \     A.6.2. Handling Denial-of-Service Attacks .....................57\n    \
    \ A.7. Reliability ................................................59\n      \
    \ A.7.1. Controller Failover Time ...............................59\n       A.7.2.\
    \ Network Re-provisioning Time ...........................61\n   Acknowledgments\
    \ ...................................................63\n   Authors' Addresses\
    \ ................................................64\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document provides generic methodologies for benchmarking\n\
    \   Software-Defined Networking (SDN) Controller performance.  To achieve\n  \
    \ the desired functionality, an SDN Controller may support many\n   northbound\
    \ and southbound protocols, implement a wide range of\n   applications, and work\
    \ either alone or as part of a group.  This\n   document considers an SDN Controller\
    \ to be a black box, regardless of\n   design and implementation.  The tests defined\
    \ in this document can be\n   used to benchmark an SDN Controller for performance,\
    \ scalability,\n   reliability, and security, independently of northbound and\
    \ southbound\n   protocols.  Terminology related to benchmarking SDN Controllers\
    \ is\n   described in the companion terminology document [RFC8455].  These\n \
    \  tests can be performed on an SDN Controller running as a virtual\n   machine\
    \ (VM) instance or on a bare metal server.  This document is\n   intended for\
    \ those who want to measure an SDN Controller's\n   performance as well as compare\
    \ the performance of various SDN\n   Controllers.\n"
- title: 1.1.  Conventions Used in This Document
  contents:
  - "1.1.  Conventions Used in This Document\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"NOT RECOMMENDED\", \"MAY\", and\n   \"OPTIONAL\" in this document are to be\
    \ interpreted as described in\n   BCP 14 [RFC2119] [RFC8174] when, and only when,\
    \ they appear in all\n   capitals, as shown here.\n"
- title: 2.  Scope
  contents:
  - "2.  Scope\n   This document defines a methodology for measuring the networking\n\
    \   metrics of SDN Controllers.  For the purpose of this memo, the SDN\n   Controller\
    \ is a function that manages and controls Network Devices.\n   Any SDN Controller\
    \ without a control capability is out of scope for\n   this memo.  The tests defined\
    \ in this document enable the\n   benchmarking of SDN Controllers in two ways:\
    \ standalone mode\n   (a standalone controller) and cluster mode (a cluster of\
    \ homogeneous\n   controllers).  These tests are recommended for execution in\
    \ lab\n   environments rather than in live network deployments.  Performance\n\
    \   benchmarking of a federation of controllers (i.e., a set of SDN\n   Controllers)\
    \ managing different domains, is beyond the scope of this\n   document.\n"
- title: 3.  Test Setup
  contents:
  - "3.  Test Setup\n   As noted above, the tests defined in this document enable\
    \ the\n   measurement of an SDN Controller's performance in standalone mode and\n\
    \   cluster mode.  This section defines common reference topologies that\n   are\
    \ referred to in individual tests described later in this document.\n"
- title: 3.1.  Test Setup - Controller Operating in Standalone Mode
  contents:
  - "3.1.  Test Setup - Controller Operating in Standalone Mode\n      +-----------------------------------------------------------+\n\
    \      |               Application-Plane Test Emulator             |\n      |\
    \                                                           |\n      |       \
    \ +-----------------+      +-------------+           |\n      |        |   Application\
    \   |      |   Service   |           |\n      |        +-----------------+   \
    \   +-------------+           |\n      |                                     \
    \                      |\n      +-----------------------------+(I2)-------------------------+\n\
    \                                    |\n                                    |\
    \ (Northbound Interface)\n                   +-------------------------------+\n\
    \                   |       +----------------+      |\n                   |  \
    \     | SDN Controller |      |\n                   |       +----------------+\
    \      |\n                   |                               |\n             \
    \      |    Device Under Test (DUT)    |\n                   +-------------------------------+\n\
    \                                    | (Southbound Interface)\n              \
    \                      |\n      +-----------------------------+(I1)-------------------------+\n\
    \      |                                                           |\n      |\
    \             +-----------+     +-------------+             |\n      |       \
    \      |  Network  |     |   Network   |             |\n      |             |\
    \ Device 2  |--..-| Device n - 1|             |\n      |             +-----------+\
    \     +-------------+             |\n      |                     /    \\   / \
    \   \\                       |\n      |                    /      \\ /      \\\
    \                      |\n      |                l0 /        X        \\ ln  \
    \                |\n      |                  /        / \\        \\         \
    \           |\n      |               +-----------+  +-----------+            \
    \    |\n      |               |  Network  |  |  Network  |                |\n\
    \      |               |  Device 1 |..|  Device n |                |\n      |\
    \               +-----------+  +-----------+                |\n      |       \
    \              |              |                      |\n      |           +---------------+\
    \  +---------------+            |\n      |           | Test Traffic  |  | Test\
    \ Traffic  |            |\n      |           |  Generator    |  |  Generator \
    \   |            |\n      |           |    (TP1)      |  |    (TP2)      |   \
    \         |\n      |           +---------------+  +---------------+          \
    \  |\n      |                                                           |\n  \
    \    |              Forwarding-Plane Test Emulator               |\n      +-----------------------------------------------------------+\n\
    \                                 Figure 1\n"
- title: 3.2.  Test Setup - Controller Operating in Cluster Mode
  contents:
  - "3.2.  Test Setup - Controller Operating in Cluster Mode\n      +-----------------------------------------------------------+\n\
    \      |               Application-Plane Test Emulator             |\n      |\
    \                                                           |\n      |       \
    \ +-----------------+      +-------------+           |\n      |        |   Application\
    \   |      |   Service   |           |\n      |        +-----------------+   \
    \   +-------------+           |\n      |                                     \
    \                      |\n      +-----------------------------+(I2)-------------------------+\n\
    \                                    |\n                                    |\
    \ (Northbound Interface)\n       +---------------------------------------------------------+\n\
    \       |                                                         |\n       |\
    \ +------------------+           +------------------+     |\n       | | SDN Controller\
    \ 1 | <--E/W--> | SDN Controller n |     |\n       | +------------------+    \
    \       +------------------+     |\n       |                                 \
    \                        |\n       |                    Device Under Test (DUT)\
    \              |\n       +---------------------------------------------------------+\n\
    \                                    | (Southbound Interface)\n              \
    \                      |\n      +-----------------------------+(I1)-------------------------+\n\
    \      |                                                           |\n      |\
    \             +-----------+     +-------------+             |\n      |       \
    \      |  Network  |     |   Network   |             |\n      |             |\
    \ Device 2  |--..-| Device n - 1|             |\n      |             +-----------+\
    \     +-------------+             |\n      |                     /    \\   / \
    \   \\                       |\n      |                    /      \\ /      \\\
    \                      |\n      |                l0 /        X        \\ ln  \
    \                |\n      |                  /        / \\        \\         \
    \           |\n      |               +-----------+  +-----------+            \
    \    |\n      |               |  Network  |  |  Network  |                |\n\
    \      |               |  Device 1 |..|  Device n |                |\n      |\
    \               +-----------+  +-----------+                |\n      |       \
    \              |              |                      |\n      |           +---------------+\
    \  +---------------+            |\n      |           | Test Traffic  |  | Test\
    \ Traffic  |            |\n      |           |  Generator    |  |  Generator \
    \   |            |\n      |           |    (TP1)      |  |    (TP2)      |   \
    \         |\n      |           +---------------+  +---------------+          \
    \  |\n      |                                                           |\n  \
    \    |              Forwarding-Plane Test Emulator               |\n      +-----------------------------------------------------------+\n\
    \                                 Figure 2\n"
- title: 4.  Test Considerations
  contents:
  - '4.  Test Considerations

    '
- title: 4.1.  Network Topology
  contents:
  - "4.1.  Network Topology\n   The test cases SHOULD use Leaf-Spine topology with\
    \ at least two\n   Network Devices in the topology for benchmarking.  Test traffic\n\
    \   generators TP1 and TP2 SHOULD be connected to the leaf Network\n   Device\
    \ 1 and the leaf Network Device n.  To achieve a complete\n   performance characterization\
    \ of the SDN Controller, it is recommended\n   that the controller be benchmarked\
    \ for many network topologies and a\n   varying number of Network Devices.  Further,\
    \ care should be taken to\n   make sure that a loop-prevention mechanism is enabled\
    \ in either the\n   SDN Controller or the network when the topology contains redundant\n\
    \   network paths.\n"
- title: 4.2.  Test Traffic
  contents:
  - "4.2.  Test Traffic\n   Test traffic is used to notify the controller about the\
    \ asynchronous\n   arrival of new flows.  The test cases SHOULD use frame sizes\
    \ of 128,\n   512, and 1508 bytes for benchmarking.  Tests using jumbo frames\
    \ are\n   optional.\n"
- title: 4.3.  Test Emulator Requirements
  contents:
  - "4.3.  Test Emulator Requirements\n   The test emulator SHOULD timestamp the transmitted\
    \ and received\n   control messages to/from the controller on the established\
    \ network\n   connections.  The test cases use these values to compute the\n \
    \  controller processing time.\n"
- title: 4.4.  Connection Setup
  contents:
  - "4.4.  Connection Setup\n   There may be controller implementations that support\
    \ unencrypted and\n   encrypted network connections with Network Devices.  Further,\
    \ the\n   controller may be backward compatible with Network Devices running\n\
    \   older versions of southbound protocols.  It may be useful to measure\n   the\
    \ controller's performance with one or more applicable connection\n   setup methods\
    \ defined below.  For cases with encrypted communications\n   between the controller\
    \ and the switch, key management and key\n   exchange MUST take place before any\
    \ performance or benchmark\n   measurements.\n      1. Unencrypted connection\
    \ with Network Devices, running the same\n         protocol version.\n      2.\
    \ Unencrypted connection with Network Devices, running different\n         protocol\
    \ versions.\n         Examples:\n            a. Controller running current protocol\
    \ version and switch\n               running older protocol version.\n       \
    \     b. Controller running older protocol version and switch\n              \
    \ running current protocol version.\n      3. Encrypted connection with Network\
    \ Devices, running the same\n         protocol version.\n      4. Encrypted connection\
    \ with Network Devices, running different\n         protocol versions.\n     \
    \    Examples:\n            a. Controller running current protocol version and\
    \ switch\n               running older protocol version.\n            b. Controller\
    \ running older protocol version and switch\n               running current protocol\
    \ version.\n"
- title: 4.5.  Measurement Point Specification and Recommendation
  contents:
  - "4.5.  Measurement Point Specification and Recommendation\n   The accuracy of\
    \ the measurements depends on several factors,\n   including the point of observation\
    \ where the indications are\n   captured.  For example, the notification can be\
    \ observed at the\n   controller or test emulator.  The test operator SHOULD make\
    \ the\n   observations/measurements at the interfaces of the test emulator,\n\
    \   unless explicitly specified otherwise in the individual test.  In any\n  \
    \ case, the locations of measurement points MUST be reported.\n"
- title: 4.6.  Connectivity Recommendation
  contents:
  - "4.6.  Connectivity Recommendation\n   The SDN Controller in the test setup SHOULD\
    \ be connected directly\n   with the forwarding-plane and management-plane test\
    \ emulators to\n   avoid any delays or failure introduced by the intermediate\
    \ devices\n   during benchmarking tests.  When the controller is implemented as\
    \ a\n   virtual machine, details of the physical and logical connectivity\n  \
    \ MUST be reported.\n"
- title: 4.7.  Test Repeatability
  contents:
  - "4.7.  Test Repeatability\n   To increase confidence in the measured results,\
    \ it is recommended\n   that each test SHOULD be repeated a minimum of 10 times.\n"
- title: 4.8.  Test Reporting
  contents:
  - "4.8.  Test Reporting\n   Each test has a reporting format that contains some\
    \ global and\n   identical reporting components, and some individual components\
    \ that\n   are specific to individual tests.  The following parameters for test\n\
    \   configuration and controller settings MUST be reflected in the test\n   report.\n\
    \   Test Configuration Parameters:\n      1.  Controller name and version\n  \
    \    2.  Northbound protocols and versions\n      3.  Southbound protocols and\
    \ versions\n      4.  Controller redundancy mode (standalone or cluster mode)\n\
    \      5.  Connection setup (unencrypted or encrypted)\n      6.  Network Device\
    \ type (physical, virtual, or emulated)\n      7.  Number of nodes\n      8. \
    \ Number of links\n      9.  Data-plane test traffic type\n      10. Controller\
    \ system configuration (e.g., physical or virtual\n          machine, CPU, memory,\
    \ caches, operating system, interface\n          speed, storage)\n      11. Reference\
    \ test setup (e.g., the setup shown in Section 3.1)\n   Parameters for Controller\
    \ Settings:\n      1. Topology rediscovery timeout\n      2. Controller redundancy\
    \ mode (e.g., active-standby)\n      3. Controller state persistence enabled/disabled\n\
    \   To ensure the repeatability of the test, the following capabilities\n   of\
    \ the test emulator SHOULD be reported:\n      1. Maximum number of Network Devices\
    \ that the forwarding plane\n         emulates\n      2. Control message processing\
    \ time (e.g., topology discovery\n         messages)\n   One way to determine\
    \ the above two values is to simulate the required\n   control sessions and messages\
    \ from the control plane.\n"
- title: 5.  Benchmarking Tests
  contents:
  - '5.  Benchmarking Tests

    '
- title: 5.1.  Performance
  contents:
  - '5.1.  Performance

    '
- title: 5.1.1.  Network Topology Discovery Time
  contents:
  - "5.1.1.  Network Topology Discovery Time\n   Objective:\n      Measure the time\
    \ taken by the controller(s) to determine the\n      complete network topology,\
    \ defined as the interval starting with\n      the first discovery message from\
    \ the controller(s) at its\n      southbound interface and ending with all features\
    \ of the static\n      topology determined.\n   Reference Test Setup:\n      This\
    \ test SHOULD use one of the test setups illustrated in\n      Section 3.1 or\
    \ Section 3.2 of this document.\n   Prerequisites:\n      1. The controller MUST\
    \ support network discovery.\n      2. The tester should be able to retrieve the\
    \ discovered topology\n         information through either the controller's management\n\
    \         interface or northbound interface to determine if the discovery\n  \
    \       was successful and complete.\n      3. Ensure that the controller's topology\
    \ rediscovery timeout has\n         been set to the maximum value, to avoid initiation\
    \ of the\n         rediscovery process in the middle of the test.\n   Procedure:\n\
    \      1. Ensure that the controller is operational and that its network\n   \
    \      applications, northbound interface, and southbound interface\n        \
    \ are up and running.\n      2. Establish the network connections between the\
    \ controller and\n         the Network Devices.\n      3. Record the time for\
    \ the first discovery message (Tm1) received\n         from the controller at\
    \ the forwarding-plane test emulator\n         interface (I1).\n      4. Query\
    \ the controller every t seconds (the RECOMMENDED value for\n         t is 3)\
    \ to obtain the discovered network topology information\n         through the\
    \ northbound interface or the management interface,\n         and compare it with\
    \ the deployed network topology information.\n      5. Stop the trial when the\
    \ discovered topology information matches\n         the deployed network topology\
    \ or when the discovered topology\n         information returns the same details\
    \ for three consecutive\n         queries.\n      6. Record the time for the last\
    \ discovery message (Tmn) sent to\n         the controller from the forwarding-plane\
    \ test emulator\n         interface (I1) when the trial completes successfully\
    \ (e.g.,\n         when the topology matches).\n   Measurements:\n      Topology\
    \ Discovery Time (DT1) = Tmn - Tm1\n                                         \
    \     DT1 + DT2 + DT3 .. DTn\n      Average Topology Discovery Time (TDm) = -----------------------\n\
    \                                                   Total Trials\n           \
    \                                    SUM[SQUAREOF(DTi - TDm)]\n      Topology\
    \ Discovery Time Variance (TDv) = ------------------------\n                 \
    \                                  Total Trials - 1\n   Reporting Format:\n  \
    \    The Topology Discovery Time results MUST be reported in tabular\n      format,\
    \ with a row for each successful iteration.  The last row of\n      the table\
    \ indicates the Topology Discovery Time variance, and the\n      previous row\
    \ indicates the Average Topology Discovery Time.\n      If this test is repeated\
    \ with a varying number of nodes over the\n      same topology, the results SHOULD\
    \ be reported in the form of a\n      graph.  The X coordinate SHOULD be the number\
    \ of nodes (N), and\n      the Y coordinate SHOULD be the Average Topology Discovery\
    \ Time.\n"
- title: 5.1.2.  Asynchronous Message Processing Time
  contents:
  - "5.1.2.  Asynchronous Message Processing Time\n   Objective:\n      Measure the\
    \ time taken by the controller(s) to process an\n      asynchronous message, defined\
    \ as the interval starting with an\n      asynchronous message from a Network\
    \ Device after the discovery of\n      all the devices by the controller(s) and\
    \ ending with a response\n      message from the controller(s) at its southbound\
    \ interface.\n   Reference Test Setup:\n      This test SHOULD use one of the\
    \ test setups illustrated in\n      Section 3.1 or Section 3.2 of this document.\n\
    \   Prerequisite:\n      The controller MUST have successfully completed the network\n\
    \      topology discovery for the connected Network Devices.\n   Procedure:\n\
    \      1. Generate asynchronous messages from every connected Network\n      \
    \   Device to the SDN Controller, one at a time in series from the\n         forwarding-plane\
    \ test emulator for the Trial Duration.\n      2. Record every request transmit\
    \ time (T1) and the corresponding\n         response received time (R1) at the\
    \ forwarding-plane test\n         emulator interface (I1) for every successful\
    \ message exchange.\n   Measurements:\n     Asynchronous Message Processing Time\
    \ (APT1) =\n                                                   SUM{Ri} - SUM{Ti}\n\
    \                                                 -----------------------\n  \
    \                                                          Nrx\n        Where\
    \ Nrx is the total number of successful messages exchanged.\n     Average Asynchronous\
    \ Message Processing Time =\n                                              APT1\
    \ + APT2 + APT3 .. APTn\n                                              --------------------------\n\
    \                                                     Total Trials\n     Asynchronous\
    \ Message Processing Time Variance (TAMv) =\n                                \
    \              SUM[SQUAREOF(APTi - TAMm)]\n                                  \
    \            --------------------------\n                                    \
    \                Total Trials - 1\n        Where TAMm is the Average Asynchronous\
    \ Message Processing Time.\n   Reporting Format:\n      The Asynchronous Message\
    \ Processing Time results MUST be reported\n      in tabular format, with a row\
    \ for each iteration.  The last row of\n      the table indicates the Asynchronous\
    \ Message Processing Time\n      variance, and the previous row indicates the\
    \ Average Asynchronous\n      Message Processing Time.\n      The report SHOULD\
    \ capture the following information, in addition\n      to the configuration parameters\
    \ captured per Section 4.8:\n         -  Successful messages exchanged (Nrx)\n\
    \         -  Percentage of unsuccessful messages exchanged, computed\n       \
    \     using the formula ((1 - Nrx/Ntx) * 100), where Ntx is the\n            total\
    \ number of messages transmitted to the controller\n      If this test is repeated\
    \ with a varying number of nodes with the\n      same topology, the results SHOULD\
    \ be reported in the form of a\n      graph.  The X coordinate SHOULD be the number\
    \ of nodes (N), and\n      the Y coordinate SHOULD be the Average Asynchronous\
    \ Message\n      Processing Time.\n"
- title: 5.1.3.  Asynchronous Message Processing Rate
  contents:
  - "5.1.3.  Asynchronous Message Processing Rate\n   Objective:\n      Measure the\
    \ number of responses to asynchronous messages (a new\n      flow arrival notification\
    \ message, link down, etc.) for which the\n      controller(s) performed processing\
    \ and replied with a valid and\n      productive (non-trivial) response message.\n\
    \      Using a single procedure, this test will measure the following two\n  \
    \    benchmarks on the Asynchronous Message Processing Rate (see\n      Section\
    \ 2.3.1.3 of [RFC8455]):\n         1. Maximum Asynchronous Message Processing\
    \ Rate\n         2. Loss-Free Asynchronous Message Processing Rate\n      Here,\
    \ two benchmarks are determined through a series of trials\n      where the number\
    \ of messages sent to the controller(s) and the\n      responses received from\
    \ the controller(s) are counted over the\n      Trial Duration.  The message response\
    \ rate and the Message Loss\n      Ratio are calculated for each trial.\n   Reference\
    \ Test Setup:\n      This test SHOULD use one of the test setups illustrated in\n\
    \      Section 3.1 or Section 3.2 of this document.\n   Prerequisites:\n     \
    \ 1. The controller(s) MUST have successfully completed the network\n        \
    \ topology discovery for the connected Network Devices.\n      2. Choose and record\
    \ the Trial Duration (Td), the sending rate\n         STEP size, the tolerance\
    \ on equality for two consecutive trials\n         (P%), and the maximum possible\
    \ message-sending rate (Ntx1/Td).\n   Procedure:\n      1. Generate asynchronous\
    \ messages continuously at the maximum\n         possible rate on the established\
    \ connections from all the\n         emulated/simulated Network Devices for the\
    \ given Trial\n         Duration (Td).\n      2. Record the total number of responses\
    \ received (Nrx1) from the\n         controller as well as the number of messages\
    \ sent (Ntx1) to the\n         controller within the Trial Duration (Td).\n  \
    \    3. Calculate the Asynchronous Message Processing Rate (APR1) and\n      \
    \   the Message Loss Ratio (Lr1).  Ensure that the controller(s)\n         has\
    \ returned to normal operation.\n      4. Repeat the trial by reducing the asynchronous\
    \ message-sending\n         rate used in the last trial by the STEP size.\n  \
    \    5. Continue repeating the trials and reducing the sending rate\n        \
    \ until both the maximum value of Nrxn (number of responses\n         received\
    \ from the controller) and the Nrxn corresponding to a\n         Loss Ratio of\
    \ zero have been found.\n      6. The trials corresponding to the benchmark levels\
    \ MUST be\n         repeated using the same asynchronous message rates until the\n\
    \         responses received from the controller are equal (+/-P%) for\n     \
    \    two consecutive trials.\n      7. Record the number of responses received\
    \ (Nrxn) from the\n         controller as well as the number of messages sent\
    \ (Ntxn) to the\n         controller in the last trial.\n   Measurements:\n  \
    \                                                  Nrxn\n      Asynchronous Message\
    \ Processing Rate (APRn) = -----\n                                           \
    \          Td\n      Maximum Asynchronous Message Processing Rate = MAX(APRn)\
    \ for all n\n                                                  Nrxn\n      Asynchronous\
    \ Message Loss Ratio (Lrn) = 1 - -----\n                                     \
    \             Ntxn\n      Loss-Free Asynchronous Message Processing Rate = MAX(APRn)\n\
    \         given Lrn = 0\n   Reporting Format:\n      The Asynchronous Message\
    \ Processing Rate results MUST be reported\n      in tabular format, with a row\
    \ for each trial.\n      The table should report the following information, in\
    \ addition to\n      the configuration parameters captured per Section 4.8, with\n\
    \      columns:\n         -  Offered rate (Ntxn/Td)\n         -  Asynchronous\
    \ Message Processing Rate (APRn)\n         -  Loss Ratio (Lr)\n         -  Benchmark\
    \ at this iteration (blank for none, Maximum\n            Asynchronous Message\
    \ Processing Rate, Loss-Free Asynchronous\n            Message Processing Rate)\n\
    \      The results MAY be presented in the form of a graph.  The X axis\n    \
    \  SHOULD be the offered rate, and dual Y axes would represent the\n      Asynchronous\
    \ Message Processing Rate and the Loss Ratio,\n      respectively.\n      If this\
    \ test is repeated with a varying number of nodes over the\n      same topology,\
    \ the results SHOULD be reported in the form of a\n      graph.  The X axis SHOULD\
    \ be the number of nodes (N), and the\n      Y axis SHOULD be the Asynchronous\
    \ Message Processing Rate.  Both\n      the Maximum Asynchronous Message Processing\
    \ Rate and the Loss-Free\n      Asynchronous Message Processing Rate should be\
    \ plotted for each N.\n"
- title: 5.1.4.  Reactive Path Provisioning Time
  contents:
  - "5.1.4.  Reactive Path Provisioning Time\n   Objective:\n      Measure the time\
    \ taken by the controller to set up a path\n      reactively between source and\
    \ destination nodes, defined as the\n      interval starting with the first flow\
    \ provisioning request message\n      received by the controller(s) at its southbound\
    \ interface and\n      ending with the last flow provisioning response message\
    \ sent from\n      the controller(s) at its southbound interface.\n   Reference\
    \ Test Setup:\n      This test SHOULD use one of the test setups illustrated in\n\
    \      Section 3.1 or Section 3.2 of this document.  The number of\n      Network\
    \ Devices in the path is a parameter of the test that may be\n      varied from\
    \ two to the maximum discovery size in repetitions of\n      this test.\n   Prerequisites:\n\
    \      1. The controller MUST contain the network topology information\n     \
    \    for the deployed network topology.\n      2. The controller should know the\
    \ location of the destination\n         endpoint for which the path has to be\
    \ provisioned.  This can be\n         achieved through dynamic learning or static\
    \ provisioning.\n      3. Ensure that the default action for \"flow miss\" in\
    \ the Network\n         Device is configured to \"send to controller\".\n    \
    \  4. Ensure that each Network Device in a path requires the\n         controller\
    \ to make the forwarding decision while paving the\n         entire path.\n  \
    \ Procedure:\n      1. Send a single traffic stream from test traffic generator\
    \ TP1 to\n         test traffic generator TP2.\n      2. Record the time of the\
    \ first flow provisioning request message\n         sent to the controller (Tsf1)\
    \ from the Network Device at the\n         forwarding-plane test emulator interface\
    \ (I1).\n      3. Wait for the arrival of the first traffic frame at the endpoint\n\
    \         (i.e., test traffic generator TP2) or the expiry of the Trial\n    \
    \     Duration (Td).\n      4. Record the time of the last flow provisioning response\
    \ message\n         received from the controller (Tdf1) to the Network Device\
    \ at\n         the forwarding-plane test emulator interface (I1).\n   Measurements:\n\
    \      Reactive Path Provisioning Time (RPT1) = Tdf1 - Tsf1\n      Average Reactive\
    \ Path Provisioning Time =\n                                              RPT1\
    \ + RPT2 + RPT3 .. RPTn\n                                              --------------------------\n\
    \                                                      Total Trials\n      Reactive\
    \ Path Provisioning Time Variance (TRPv) =\n                                 \
    \             SUM[SQUAREOF(RPTi - TRPm)]\n                                   \
    \           --------------------------\n                                     \
    \                Total Trials - 1\n         Where TRPm is the Average Reactive\
    \ Path Provisioning Time.\n   Reporting Format:\n      The Reactive Path Provisioning\
    \ Time results MUST be reported in\n      tabular format, with a row for each\
    \ iteration.  The last row of\n      the table indicates the Reactive Path Provisioning\
    \ Time variance,\n      and the previous row indicates the Average Reactive Path\n\
    \      Provisioning Time.\n      The report should capture the following information,\
    \ in addition\n      to the configuration parameters captured per Section 4.8:\n\
    \         -  Number of Network Devices in the path\n"
- title: 5.1.5.  Proactive Path Provisioning Time
  contents:
  - "5.1.5.  Proactive Path Provisioning Time\n   Objective:\n      Measure the time\
    \ taken by the controller to set up a path\n      proactively between source and\
    \ destination nodes, defined as the\n      interval starting with the first proactive\
    \ flow provisioned in the\n      controller(s) at its northbound interface and\
    \ ending with the last\n      flow provisioning response message sent from the\
    \ controller(s) at\n      its southbound interface.\n   Reference Test Setup:\n\
    \      This test SHOULD use one of the test setups illustrated in\n      Section\
    \ 3.1 or Section 3.2 of this document.\n   Prerequisites:\n      1. The controller\
    \ MUST contain the network topology information\n         for the deployed network\
    \ topology.\n      2. The controller should know the location of the destination\n\
    \         endpoint for which the path has to be provisioned.  This can be\n  \
    \       achieved through dynamic learning or static provisioning.\n      3. Ensure\
    \ that the default action for \"flow miss\" in the Network\n         Device is\
    \ \"drop\".\n   Procedure:\n      1. Send a single traffic stream from test traffic\
    \ generator TP1 to\n         test traffic generator TP2.\n      2. Install the\
    \ flow entries so that the traffic travels from test\n         traffic generator\
    \ TP1 until it reaches test traffic\n         generator TP2 through the controller's\
    \ northbound interface or\n         management interface.\n      3. Wait for the\
    \ arrival of the first traffic frame at test traffic\n         generator TP2 or\
    \ the expiry of the Trial Duration (Td).\n      4. Record the time when the proactive\
    \ flow is provisioned in the\n         controller (Tsf1) at the management-plane\
    \ test emulator\n         interface (I2).\n      5. Record the time of the last\
    \ flow provisioning message received\n         from the controller (Tdf1) at the\
    \ forwarding-plane test\n         emulator interface (I1).\n   Measurements:\n\
    \      Proactive Flow Provisioning Time (PPT1) = Tdf1 - Tsf1\n      Average Proactive\
    \ Path Provisioning Time =\n                                              PPT1\
    \ + PPT2 + PPT3 .. PPTn\n                                              --------------------------\n\
    \                                                      Total Trials\n      Proactive\
    \ Path Provisioning Time Variance (TPPv) =\n                                 \
    \             SUM[SQUAREOF(PPTi - TPPm)]\n                                   \
    \           --------------------------\n                                     \
    \              Total Trials - 1\n         Where TPPm is the Average Proactive\
    \ Path Provisioning Time.\n   Reporting Format:\n      The Proactive Path Provisioning\
    \ Time results MUST be reported in\n      tabular format, with a row for each\
    \ iteration.  The last row of\n      the table indicates the Proactive Path Provisioning\
    \ Time variance,\n      and the previous row indicates the Average Proactive Path\n\
    \      Provisioning Time.\n      The report should capture the following information,\
    \ in addition\n      to the configuration parameters captured per Section 4.8:\n\
    \         -  Number of Network Devices in the path\n"
- title: 5.1.6.  Reactive Path Provisioning Rate
  contents:
  - "5.1.6.  Reactive Path Provisioning Rate\n   Objective:\n      Measure the maximum\
    \ number of independent paths a controller can\n      concurrently establish per\
    \ second between source and destination\n      nodes reactively, defined as the\
    \ number of paths provisioned per\n      second by the controller(s) at its southbound\
    \ interface for the\n      flow provisioning requests received for path provisioning\
    \ at its\n      southbound interface between the start of the test and the expiry\n\
    \      of the given Trial Duration.\n   Reference Test Setup:\n      This test\
    \ SHOULD use one of the test setups illustrated in\n      Section 3.1 or Section\
    \ 3.2 of this document.\n   Prerequisites:\n      1. The controller MUST contain\
    \ the network topology information\n         for the deployed network topology.\n\
    \      2. The controller should know the location of destination\n         addresses\
    \ for which the paths have to be provisioned.  This can\n         be achieved\
    \ through dynamic learning or static provisioning.\n      3. Ensure that the default\
    \ action for \"flow miss\" in the Network\n         Device is configured to \"\
    send to controller\".\n      4. Ensure that each Network Device in a path requires\
    \ the\n         controller to make the forwarding decision while provisioning\n\
    \         the entire path.\n   Procedure:\n      1. Send traffic with unique source\
    \ and destination addresses from\n         test traffic generator TP1.\n     \
    \ 2. Record the total number of unique traffic frames (Ndf) received\n       \
    \  at test traffic generator TP2 within the Trial Duration (Td).\n   Measurements:\n\
    \                                                Ndf\n      Reactive Path Provisioning\
    \ Rate (RPR1) = ------\n                                                Td\n \
    \     Average Reactive Path Provisioning Rate =\n                            \
    \                  RPR1 + RPR2 + RPR3 .. RPRn\n                              \
    \                --------------------------\n                                \
    \                     Total Trials\n      Reactive Path Provisioning Rate Variance\
    \ (RPPv) =\n                                              SUM[SQUAREOF(RPRi -\
    \ RPPm)]\n                                              --------------------------\n\
    \                                                    Total Trials - 1\n      \
    \   Where RPPm is the Average Reactive Path Provisioning Rate.\n   Reporting Format:\n\
    \      The Reactive Path Provisioning Rate results MUST be reported in\n     \
    \ tabular format, with a row for each iteration.  The last row of\n      the table\
    \ indicates the Reactive Path Provisioning Rate variance,\n      and the previous\
    \ row indicates the Average Reactive Path\n      Provisioning Rate.\n      The\
    \ report should capture the following information, in addition\n      to the configuration\
    \ parameters captured per Section 4.8:\n         -  Number of Network Devices\
    \ in the path\n         -  Offered rate\n"
- title: 5.1.7.  Proactive Path Provisioning Rate
  contents:
  - "5.1.7.  Proactive Path Provisioning Rate\n   Objective:\n      Measure the maximum\
    \ number of independent paths a controller can\n      concurrently establish per\
    \ second between source and destination\n      nodes proactively, defined as the\
    \ number of paths provisioned per\n      second by the controller(s) at its southbound\
    \ interface for the\n      paths requested in its northbound interface between\
    \ the start of\n      the test and the expiry of the given Trial Duration.  The\n\
    \      measurement is based on data-plane observations of successful path\n  \
    \    activation.\n   Reference Test Setup:\n      This test SHOULD use one of\
    \ the test setups illustrated in\n      Section 3.1 or Section 3.2 of this document.\n\
    \   Prerequisites:\n      1. The controller MUST contain the network topology\
    \ information\n         for the deployed network topology.\n      2. The controller\
    \ should know the location of destination\n         addresses for which the paths\
    \ have to be provisioned.  This can\n         be achieved through dynamic learning\
    \ or static provisioning.\n      3. Ensure that the default action for \"flow\
    \ miss\" in the Network\n         Device is \"drop\".\n   Procedure:\n      1.\
    \ Send traffic continuously with unique source and destination\n         addresses\
    \ from test traffic generator TP1.\n      2. Install corresponding flow entries\
    \ so that the traffic travels\n         from simulated sources at test traffic\
    \ generator TP1 until it\n         reaches the simulated destinations at test\
    \ traffic\n         generator TP2 through the controller's northbound interface\
    \ or\n         management interface.\n      3. Record the total number of unique\
    \ traffic frames (Ndf) received\n         at test traffic generator TP2 within\
    \ the Trial Duration (Td).\n   Measurements:\n                               \
    \                  Ndf\n      Proactive Path Provisioning Rate (PPR1) = ------\n\
    \                                                 Td\n      Average Proactive\
    \ Path Provisioning Rate =\n                                              PPR1\
    \ + PPR2 + PPR3 .. PPRn\n                                              --------------------------\n\
    \                                                      Total Trials\n      Proactive\
    \ Path Provisioning Rate Variance (PPPv) =\n                                 \
    \             SUM[SQUAREOF(PPRi - PPPm)]\n                                   \
    \           -------------------------\n                                      \
    \             Total Trials - 1\n         Where PPPm is the Average Proactive Path\
    \ Provisioning Rate.\n   Reporting Format:\n      The Proactive Path Provisioning\
    \ Rate results MUST be reported in\n      tabular format, with a row for each\
    \ iteration.  The last row of\n      the table indicates the Proactive Path Provisioning\
    \ Rate variance,\n      and the previous row indicates the Average Proactive Path\n\
    \      Provisioning Rate.\n      The report should capture the following information,\
    \ in addition\n      to the configuration parameters captured per Section 4.8:\n\
    \         -  Number of Network Devices in the path\n         -  Offered rate\n"
- title: 5.1.8.  Network Topology Change Detection Time
  contents:
  - "5.1.8.  Network Topology Change Detection Time\n   Objective:\n      Measure\
    \ the amount of time taken by the controller to detect any\n      changes in the\
    \ network topology, defined as the interval starting\n      with the notification\
    \ message received by the controller(s) at its\n      southbound interface and\
    \ ending with the first topology\n      rediscovery message sent from the controller(s)\
    \ at its southbound\n      interface.\n   Reference Test Setup:\n      This test\
    \ SHOULD use one of the test setups illustrated in\n      Section 3.1 or Section\
    \ 3.2 of this document.\n   Prerequisites:\n      1. The controller MUST have\
    \ successfully discovered the network\n         topology information for the deployed\
    \ network topology.\n      2. The periodic network discovery operation should\
    \ be configured\n         to twice the Trial Duration (Td) value.\n   Procedure:\n\
    \      1. Trigger a topology change event by bringing down an active\n       \
    \  Network Device in the topology.\n      2. Record the time when the first topology\
    \ change notification is\n         sent to the controller (Tcn) at the forwarding-plane\
    \ test\n         emulator interface (I1).\n      3. Stop the trial when the controller\
    \ sends the first topology\n         rediscovery message to the Network Device\
    \ or the expiry of the\n         Trial Duration (Td).\n      4. Record the time\
    \ when the first topology rediscovery message is\n         received from the controller\
    \ (Tcd) at the forwarding-plane test\n         emulator interface (I1).\n   Measurements:\n\
    \      Network Topology Change Detection Time (TDT1) = Tcd - Tcn\n      Average\
    \ Network Topology Change Detection Time =\n                                 \
    \             TDT1 + TDT2 + TDT3 .. TDTn\n                                   \
    \           --------------------------\n                                     \
    \                 Total Trials\n      Network Topology Change Detection Time Variance\
    \ (NTDv) =\n                                              SUM[SQUAREOF(TDTi -\
    \ NTDm)]\n                                              --------------------------\n\
    \                                                    Total Trials - 1\n      \
    \   Where NTDm is the Average Network Topology Change\n            Detection Time.\n\
    \   Reporting Format:\n      The Network Topology Change Detection Time results\
    \ MUST be\n      reported in tabular format, with a row for each iteration.  The\n\
    \      last row of the table indicates the Network Topology Change\n      Detection\
    \ Time variance, and the previous row indicates the\n      Average Network Topology\
    \ Change Detection Time.\n"
- title: 5.2.  Scalability
  contents:
  - '5.2.  Scalability

    '
- title: 5.2.1.  Control Sessions Capacity
  contents:
  - "5.2.1.  Control Sessions Capacity\n   Objective:\n      Measure the maximum number\
    \ of control sessions the controller can\n      maintain, defined as the number\
    \ of sessions that the controller\n      can accept from Network Devices, starting\
    \ with the first control\n      session and ending with the last control session\
    \ that the\n      controller(s) accepts at its southbound interface.\n   Reference\
    \ Test Setup:\n      This test SHOULD use one of the test setups illustrated in\n\
    \      Section 3.1 or Section 3.2 of this document.\n   Prerequisites:\n     \
    \ None\n   Procedure:\n      1. Establish control connections with the controller\
    \ from every\n         Network Device emulated in the forwarding-plane test emulator.\n\
    \      2. Stop the trial when the controller starts dropping the control\n   \
    \      connections.\n      3. Record the number of successful connections established\
    \ (CCn)\n         with the controller at the forwarding-plane test emulator.\n\
    \   Measurement:\n      Control Sessions Capacity = CCn\n   Reporting Format:\n\
    \      The Control Sessions Capacity results MUST be reported in addition\n  \
    \    to the configuration parameters captured per Section 4.8.\n"
- title: 5.2.2.  Network Discovery Size
  contents:
  - "5.2.2.  Network Discovery Size\n   Objective:\n      Measure the network size\
    \ (number of nodes, links, and hosts) that\n      a controller can discover, defined\
    \ as the size of a network that\n      the controller(s) can discover, starting\
    \ with a network topology\n      provided by the user for discovery and ending\
    \ with the number of\n      nodes, links, and hosts that the controller(s) were\
    \ able to\n      successfully discover.\n   Reference Test Setup:\n      This\
    \ test SHOULD use one of the test setups illustrated in\n      Section 3.1 or\
    \ Section 3.2 of this document.\n   Prerequisites:\n      1. The controller MUST\
    \ support automatic network discovery.\n      2. The tester should be able to\
    \ retrieve the discovered topology\n         information through either the controller's\
    \ management\n         interface or northbound interface.\n   Procedure:\n   \
    \   1. Establish the network connections between the controller and\n        \
    \ the network nodes.\n      2. Query the controller every t seconds (the RECOMMENDED\
    \ value for\n         t is 30) to obtain the discovered network topology information\n\
    \         through the northbound interface or the management interface.\n    \
    \  3. Stop the trial when the discovered network topology information\n      \
    \   remains the same as that of the last two query responses.\n      4. Compare\
    \ the obtained network topology information with the\n         deployed network\
    \ topology information.\n      5. If the comparison is successful, increase the\
    \ number of nodes\n         by 1 and repeat the trial.\n         If the comparison\
    \ is unsuccessful, decrease the number of nodes\n         by 1 and repeat the\
    \ trial.\n      6. Continue the trial until the comparison (step 5) is successful.\n\
    \      7. Record the number of nodes for the last trial run (Ns) where\n     \
    \    the topology comparison was successful.\n   Measurement:\n       Network\
    \ Discovery Size = Ns\n   Reporting Format:\n      The Network Discovery Size\
    \ results MUST be reported in addition to\n      the configuration parameters\
    \ captured per Section 4.8.\n"
- title: 5.2.3.  Forwarding Table Capacity
  contents:
  - "5.2.3.  Forwarding Table Capacity\n   Objective:\n      Measure the maximum number\
    \ of flow entries a controller can manage\n      in its Forwarding Table.\n  \
    \ Reference Test Setup:\n      This test SHOULD use one of the test setups illustrated\
    \ in\n      Section 3.1 or Section 3.2 of this document.\n   Prerequisites:\n\
    \      1. The controller's Forwarding Table should be empty.\n      2. \"Flow\
    \ idle time\" MUST be set to a higher or infinite value.\n      3. The controller\
    \ MUST have successfully completed network\n         topology discovery.\n   \
    \   4. The tester should be able to retrieve the Forwarding Table\n         information\
    \ through either the controller's management\n         interface or northbound\
    \ interface.\n   Procedures:\n      o  Reactive Flow Provisioning Mode:\n    \
    \     1. Send bidirectional traffic continuously with unique source\n        \
    \    and destination addresses from test traffic generators TP1\n            and\
    \ TP2 at the Asynchronous Message Processing Rate of the\n            controller.\n\
    \         2. Query the controller at a regular interval (e.g., every\n       \
    \     5 seconds) for the number of learned flow entries from its\n           \
    \ northbound interface.\n         3. Stop the trial when the retrieved value is\
    \ constant for\n            three consecutive iterations, and record the value\
    \ received\n            from the last query (Nrp).\n      o  Proactive Flow Provisioning\
    \ Mode:\n         1. Install unique flows continuously through the controller's\n\
    \            northbound interface or management interface until a failure\n  \
    \          response is received from the controller.\n         2. Record the total\
    \ number of successful responses (Nrp).\n         Note:\n         Some controller\
    \ designs for Proactive Flow Provisioning mode\n         may require the switch\
    \ to send flow setup requests in order to\n         generate flow setup responses.\
    \  In such cases, it is\n         recommended to generate bidirectional traffic\
    \ for the\n         provisioned flows.\n   Measurements:\n      Proactive Flow\
    \ Provisioning Mode:\n         Max Flow Entries = Total number of flows provisioned\
    \ (Nrp)\n      Reactive Flow Provisioning Mode:\n         Max Flow Entries = Total\
    \ number of learned flow entries (Nrp)\n      Forwarding Table Capacity = Max\
    \ Flow Entries\n   Reporting Format:\n      The Forwarding Table Capacity results\
    \ MUST be tabulated with the\n      following information, in addition to the\
    \ configuration parameters\n      captured per Section 4.8:\n         -  Provisioning\
    \ Type (Proactive/Reactive)\n"
- title: 5.3.  Security
  contents:
  - '5.3.  Security

    '
- title: 5.3.1.  Exception Handling
  contents:
  - "5.3.1.  Exception Handling\n   Objective:\n      Determine the effects of handling\
    \ error packets and notifications\n      on performance tests.  The impact MUST\
    \ be measured for the\n      following performance tests:\n         1. Path Provisioning\
    \ Rate\n         2. Path Provisioning Time\n         3. Network Topology Change\
    \ Detection Time\n   Reference Test Setup:\n      This test SHOULD use one of\
    \ the test setups illustrated in\n      Section 3.1 or Section 3.2 of this document.\n\
    \   Prerequisites:\n      1. This test MUST be performed after obtaining the baseline\n\
    \         measurement results for the performance tests listed above.\n      2.\
    \ Ensure that the invalid messages are not dropped by the\n         intermediate\
    \ devices connecting the controller and Network\n         Devices.\n   Procedure:\n\
    \      1. Perform the above-listed performance tests, and send 1% of the\n   \
    \      messages from the Asynchronous Message Processing Rate test\n         (Section\
    \ 5.1.3) as invalid messages from the connected Network\n         Devices emulated\
    \ at the forwarding-plane test emulator.\n      2. Perform the above-listed performance\
    \ tests, and send 2% of the\n         messages from the Asynchronous Message Processing\
    \ Rate test\n         (Section 5.1.3) as invalid messages from the connected Network\n\
    \         Devices emulated at the forwarding-plane test emulator.\n      Note:\n\
    \      Invalid messages can be frames with incorrect protocol fields or\n    \
    \  any form of failure notifications sent towards the controller.\n   Measurements:\n\
    \      Measurements MUST be done as per the equation defined in the\n      \"\
    Measurements\" section of the corresponding test listed under\n      \"Objective\"\
    .\n   Reporting Format:\n      The Exception Handling results MUST be reported\
    \ in tabular format,\n      with a column for each of the below parameters and\
    \ row for each of\n      the above-listed performance tests:\n         -  Without\
    \ Exceptions\n         -  With 1% Exceptions\n         -  With 2% Exceptions\n"
- title: 5.3.2.  Handling Denial-of-Service Attacks
  contents:
  - "5.3.2.  Handling Denial-of-Service Attacks\n   Objective:\n      Determine the\
    \ effects of handling DoS attacks on performance and\n      scalability tests.\
    \  The impact MUST be measured for the following\n      tests:\n         1. Path\
    \ Provisioning Rate\n         2. Path Provisioning Time\n         3. Network Topology\
    \ Change Detection Time\n         4. Network Discovery Size\n   Reference Test\
    \ Setup:\n      This test SHOULD use one of the test setups illustrated in\n \
    \     Section 3.1 or Section 3.2 of this document.\n   Prerequisite:\n      This\
    \ test MUST be performed after obtaining the baseline\n      measurement results\
    \ for the performance tests listed above.\n   Procedure:\n      Perform the above-listed\
    \ tests, and launch a DoS attack towards\n      the controller while the trial\
    \ is running.\n      Note: DoS attacks can be launched on one of the following\n\
    \      interfaces:\n         1. Northbound (e.g., query for flow entries continuously\
    \ on the\n            northbound interface)\n         2. Management (e.g., Ping\
    \ requests to the controller's\n            management interface)\n         3.\
    \ Southbound (e.g., TCP SYN messages on the southbound\n            interface)\n\
    \   Measurements:\n      Measurements MUST be done as per the equation defined\
    \ in the\n      \"Measurements\" section of the corresponding test listed under\n\
    \      \"Objective\".\n   Reporting Format:\n      The results regarding the handling\
    \ of DoS attacks MUST be reported\n      in tabular format, with a column for\
    \ each of the below parameters\n      and a row for each of the above-listed tests.\n\
    \         -  Without any attacks\n         -  With attacks\n      The report should\
    \ also specify the nature of the attack and the\n      interface in question.\n"
- title: 5.4.  Reliability
  contents:
  - '5.4.  Reliability

    '
- title: 5.4.1.  Controller Failover Time
  contents:
  - "5.4.1.  Controller Failover Time\n   Objective:\n      Measure the time taken\
    \ to switch from an active controller to the\n      backup controller when the\
    \ controllers work in redundancy mode and\n      the active controller fails,\
    \ defined as the interval starting when\n      the active controller is brought\
    \ down and ending with the first\n      rediscovery message received from the\
    \ new controller at its\n      southbound interface.\n   Reference Test Setup:\n\
    \      This test SHOULD use the test setup illustrated in Section 3.2 of\n   \
    \   this document.\n   Prerequisites:\n      1. Master controller election MUST\
    \ be completed.\n      2. Nodes are connected to the controller cluster per the\n\
    \         implemented redundancy mode (e.g., active-standby).\n      3. The controller\
    \ cluster should have successfully completed the\n         network topology discovery.\n\
    \      4. The Network Device MUST send all new flows to the controller\n     \
    \    when it receives them from the test traffic generator.\n      5. The controller\
    \ should have learned the location of the\n         destination (D1) at test traffic\
    \ generator TP2.\n   Procedure:\n      1. Send unidirectional traffic continuously\
    \ with incremental\n         sequence numbers and source addresses from test traffic\n\
    \         generator TP1 at the rate at which the controller can process\n    \
    \     the traffic without any drops.\n      2. Ensure that there are no packet\
    \ drops observed at test traffic\n         generator TP2.\n      3. Bring down\
    \ the active controller.\n      4. Stop the trial when the first frame after the\
    \ failover\n         operation is received on test traffic generator TP2.\n  \
    \    5. Record the time at which the last valid frame was received (T1)\n    \
    \     at test traffic generator TP2 before the sequence error and the\n      \
    \   time at which the first valid frame was received (T2) after the\n        \
    \ sequence error at test traffic generator TP2.\n   Measurements:\n      Controller\
    \ Failover Time = (T2 - T1)\n      Packet Loss = Number of missing packet sequences\n\
    \   Reporting Format:\n      The Controller Failover Time results MUST be tabulated\
    \ with the\n      following information:\n         -  Number of cluster nodes\n\
    \         -  Redundancy mode\n         -  Controller Failover Time\n         -\
    \  Packet Loss\n         -  Cluster keep-alive interval\n"
- title: 5.4.2.  Network Re-provisioning Time
  contents:
  - "5.4.2.  Network Re-provisioning Time\n   Objective:\n      Measure the time taken\
    \ by the controller to reroute traffic when\n      there is a failure in existing\
    \ traffic paths, defined as the\n      interval starting with the first failure\
    \ notification message\n      received by the controller and ending with the last\
    \ flow\n      re-provisioning message sent by the controller at its southbound\n\
    \      interface.\n   Reference Test Setup:\n      This test SHOULD use one of\
    \ the test setups illustrated in\n      Section 3.1 or Section 3.2 of this document.\n\
    \   Prerequisites:\n      1. A network with a specified number of nodes and redundant\
    \ paths\n         MUST be deployed.\n      2. The controller MUST know the location\
    \ of test traffic\n         generators TP1 and TP2.\n      3. Ensure that the\
    \ controller does not pre-provision the alternate\n         path in the emulated\
    \ Network Devices at the forwarding-plane\n         test emulator.\n   Procedure:\n\
    \      1. Send bidirectional traffic continuously with a unique sequence\n   \
    \      number from test traffic generators TP1 and TP2.\n      2. Bring down a\
    \ link or switch in the traffic path.\n      3. Stop the trial after receiving\
    \ the first frame after network\n         reconvergence.\n      4. Record the\
    \ time of the last received frame prior to the frame\n         loss at test traffic\
    \ generator TP2 (TP2-Tlfr) and the time of\n         the first frame received\
    \ after the frame loss at test traffic\n         generator TP2 (TP2-Tffr).  There\
    \ must be a gap in sequence\n         numbers of these frames.\n      5. Record\
    \ the time of the last received frame prior to the frame\n         loss at test\
    \ traffic generator TP1 (TP1-Tlfr) and the time of\n         the first frame received\
    \ after the frame loss at test traffic\n         generator TP1 (TP1-Tffr).\n \
    \  Measurements:\n      Forward Direction Path Re-provisioning Time (FDRT)\n \
    \                                                = (TP2-Tffr - TP2-Tlfr)\n   \
    \   Reverse Direction Path Re-provisioning Time (RDRT)\n                     \
    \                            = (TP1-Tffr - TP1-Tlfr)\n      Network Re-provisioning\
    \ Time = (FDRT + RDRT)/2\n      Forward Direction Packet Loss = Number of missing\
    \ sequence frames\n         at test traffic generator TP1\n      Reverse Direction\
    \ Packet Loss = Number of missing sequence frames\n         at test traffic generator\
    \ TP2\n   Reporting Format:\n      The Network Re-provisioning Time results MUST\
    \ be tabulated with\n      the following information:\n         -  Number of nodes\
    \ in the primary path\n         -  Number of nodes in the alternate path\n   \
    \      -  Network Re-provisioning Time\n         -  Forward Direction Packet Loss\n\
    \         -  Reverse Direction Packet Loss\n"
- title: 6.  IANA Considerations
  contents:
  - "6.  IANA Considerations\n   This document has no IANA actions.\n"
- title: 7.  Security Considerations
  contents:
  - "7.  Security Considerations\n   The benchmarking tests described in this document\
    \ are limited to the\n   performance characterization of controllers in a lab\
    \ environment with\n   isolated networks.\n   The benchmarking network topology\
    \ will be an independent test setup\n   and MUST NOT be connected to devices that\
    \ may forward the test\n   traffic into a production network or misroute traffic\
    \ to the test\n   management network.\n   Further, benchmarking is performed on\
    \ a \"black-box\" basis, relying\n   solely on measurements observable external\
    \ to the controller.\n   Special capabilities SHOULD NOT exist in the controller\
    \ specifically\n   for benchmarking purposes.  Any implications for network security\n\
    \   arising from the controller SHOULD be identical in the lab and in\n   production\
    \ networks.\n"
- title: 8.  References
  contents:
  - '8.  References

    '
- title: 8.1.  Normative References
  contents:
  - "8.1.  Normative References\n   [RFC2119]  Bradner, S., \"Key words for use in\
    \ RFCs to Indicate\n              Requirement Levels\", BCP 14, RFC 2119,\n  \
    \            DOI 10.17487/RFC2119, March 1997,\n              <https://www.rfc-editor.org/info/rfc2119>.\n\
    \   [RFC8174]  Leiba, B., \"Ambiguity of Uppercase vs Lowercase in\n         \
    \     RFC 2119 Key Words\", BCP 14, RFC 8174,\n              DOI 10.17487/RFC8174,\
    \ May 2017,\n              <https://www.rfc-editor.org/info/rfc8174>.\n   [RFC8455]\
    \  Bhuvaneswaran, V., Basil, A., Tassinari, M., Manral, V.,\n              and\
    \ S. Banks, \"Terminology for Benchmarking\n              Software-Defined Networking\
    \ (SDN) Controller Performance\",\n              RFC 8455, DOI 10.17487/RFC8455,\
    \ October 2018,\n              <https://www.rfc-editor.org/info/rfc8455>.\n"
- title: 8.2.  Informative References
  contents:
  - "8.2.  Informative References\n   [OpenFlow-Spec]\n              ONF, \"OpenFlow\
    \ Switch Specification\" Version 1.4.0 (Wire\n              Protocol 0x05), October\
    \ 2013,\n              <https://www.opennetworking.org/wp-content/\n         \
    \     uploads/2014/10/openflow-spec-v1.4.0.pdf>.\n"
- title: Appendix A.  Benchmarking Methodology Using OpenFlow Controllers
  contents:
  - "Appendix A.  Benchmarking Methodology Using OpenFlow Controllers\n   This section\
    \ gives an overview of the OpenFlow protocol\n   [OpenFlow-Spec] and provides\
    \ a test methodology for benchmarking SDN\n   Controllers supporting the OpenFlow\
    \ southbound protocol.  The\n   OpenFlow protocol is used as an example to illustrate\
    \ the\n   methodologies defined in this document.\n"
- title: A.1.  Protocol Overview
  contents:
  - "A.1.  Protocol Overview\n   OpenFlow [OpenFlow-Spec] is an open standard protocol\
    \ defined by the\n   Open Networking Foundation (ONF) and used for programming\
    \ the\n   forwarding plane of network switches or routers via a centralized\n\
    \   controller.\n"
- title: A.2.  Messages Overview
  contents:
  - "A.2.  Messages Overview\n   The OpenFlow protocol supports three message types\
    \ -- namely,\n   controller-to-switch, asynchronous, and symmetric.\n   Controller-to-switch\
    \ messages are initiated by the controller and\n   used to directly manage or\
    \ inspect the state of the switch.  These\n   messages allow controllers to query/configure\
    \ the switch (\"features\"\n   messages, configuration messages), collect information\
    \ from a switch\n   (Read-State messages), send packets on a specified port of\
    \ a switch\n   (OFPT_PACKET_OUT messages), and modify the switch forwarding plane\n\
    \   and state (Modify-State messages, Role-Request messages, etc.).\n   Asynchronous\
    \ messages are generated by the switch without a\n   controller soliciting them.\
    \  These messages allow switches to update\n   controllers to denote an arrival\
    \ of a new flow (OFPT_PACKET_IN\n   messages), switch state changes (\"flow-removed\"\
    \ messages, port-status\n   messages), and errors (Error messages).\n   Symmetric\
    \ messages are generated in either direction without\n   solicitation.  These\
    \ messages allow switches and controllers to set\n   up a connection (Hello messages),\
    \ verify liveness (Echo messages),\n   and offer additional functionalities (Experimenter\
    \ messages).\n"
- title: A.3.  Connection Overview
  contents:
  - "A.3.  Connection Overview\n   The OpenFlow channel is used to exchange OpenFlow\
    \ messages between an\n   OpenFlow switch and an OpenFlow controller.  The OpenFlow\
    \ channel\n   connection can be set up using plain TCP or TLS.  By default, a\n\
    \   switch establishes a single connection with the SDN Controller.  A\n   switch\
    \ may establish multiple parallel connections to a single\n   controller (auxiliary\
    \ connection) or multiple controllers to handle\n   controller failures and load\
    \ balancing.\n"
- title: A.4.  Performance Benchmarking Tests
  contents:
  - 'A.4.  Performance Benchmarking Tests

    '
- title: A.4.1.  Network Topology Discovery Time
  contents:
  - "A.4.1.  Network Topology Discovery Time\n   Procedure:\n      Network Devices\
    \               OpenFlow                    SDN\n                            \
    \       Controller               Application\n            |                  \
    \          |                           |\n            |                      \
    \      |<Initialize controller     |\n            |                          \
    \  |app., NB and SB interfaces>|\n            |                            | \
    \                          |\n            |<Deploy network with        |     \
    \                      |\n            | given no. of OF switches>  |         \
    \                  |\n            |                            |             \
    \              |\n            |    OFPT_HELLO Exchange     |                 \
    \          |\n            |<-------------------------->|                     \
    \      |\n            |                            |                         \
    \  |\n            |   OFPT_PACKET_OUT with LLDP|                           |\n\
    \            |             to all switches|                           |\n    \
    \   (Tm1)|<---------------------------|                           |\n        \
    \    |                            |                           |\n            |\
    \    OFPT_PACKET_IN with LLDP|                           |\n            |    \
    \      rcvd from Switch 1|                           |\n            |--------------------------->|\
    \                           |\n            |                            |    \
    \                       |\n            |    OFPT_PACKET_IN with LLDP|        \
    \                   |\n            |          rcvd from Switch 2|            \
    \               |\n            |--------------------------->|                \
    \           |\n            |            .               |                    \
    \       |\n            |            .               |                        \
    \   |\n            |                            |                           |\n\
    \            |    OFPT_PACKET_IN with LLDP|                           |\n    \
    \        |          rcvd from Switch n|                           |\n       (Tmn)|--------------------------->|\
    \                           |\n            |                            |    \
    \                       |\n            |                            |    <Wait\
    \ for the expiry of|\n            |                            |   the Trial Duration\
    \ (Td)>|\n            |                            |                         \
    \  |\n            |                            |   Query the controller for|\n\
    \            |                            |  discovered n/w topo. (Di)|\n    \
    \        |                            |<--------------------------|\n        \
    \    |                            |                           |\n            |\
    \                            |    <Compare the discovered|\n            |    \
    \                        |       n/w topology and the|\n            |        \
    \                    |      offered n/w topology>|\n            |            \
    \                |                           |\n   Legend:\n      NB: Northbound\n\
    \      SB: Southbound\n      OF: OpenFlow\n      OFP: OpenFlow Protocol\n    \
    \  LLDP: Link-Layer Discovery Protocol\n      Tm1: Time of reception of first\
    \ LLDP message from controller\n      Tmn: Time of last LLDP message sent to controller\n\
    \   Discussion:\n      The Network Topology Discovery Time can be obtained by\
    \ calculating\n      the time difference between the first OFPT_PACKET_OUT with\
    \ an LLDP\n      message received from the controller (Tm1) and the last\n   \
    \   OFPT_PACKET_IN with an LLDP message sent to the controller (Tmn)\n      when\
    \ the comparison is successful.\n"
- title: A.4.2.  Asynchronous Message Processing Time
  contents:
  - "A.4.2.  Asynchronous Message Processing Time\n   Procedure:\n         Network\
    \ Devices            OpenFlow                    SDN\n                       \
    \            Controller               Application\n            |             \
    \               |                           |\n            |OFPT_PACKET_IN with\
    \ single  |                           |\n            |OFP match header       \
    \     |                           |\n        (T0)|--------------------------->|\
    \                           |\n            |                            |    \
    \                       |\n            |OFPT_PACKET_OUT with single |        \
    \                   |\n            |          OFP action header |            \
    \               |\n        (R0)|<---------------------------|                \
    \           |\n            |          .                 |                    \
    \       |\n            |          .                 |                        \
    \   |\n            |          .                 |                           |\n\
    \            |                            |                           |\n    \
    \        |OFPT_PACKET_IN with single  |                           |\n        \
    \    |OFP match header            |                           |\n        (Tn)|--------------------------->|\
    \                           |\n            |                            |    \
    \                       |\n            |OFPT_PACKET_OUT with single |        \
    \                   |\n            |          OFP action header |            \
    \               |\n        (Rn)|<---------------------------|                \
    \           |\n            |                            |                    \
    \       |\n            |<Wait for the expiry of the |                        \
    \   |\n            |Trial Duration>             |                           |\n\
    \            |                            |                           |\n    \
    \        |<Record the number of       |                           |\n        \
    \    |OFPT_PACKET_INs/            |                           |\n            |OFPT_PACKET_OUTs\
    \            |                           |\n            |exchanged (Nrx)>    \
    \        |                           |\n            |                        \
    \    |                           |\n   Legend:\n      T0,T1, ..Tn: transmit timestamps\
    \ of OFPT_PACKET_IN messages\n      R0,R1, ..Rn: receive timestamps of OFPT_PACKET_OUT\
    \ messages\n      Nrx: Number of successful OFPT_PACKET_IN/OFPT_PACKET_OUT\n \
    \          message exchanges\n   Discussion:\n      The Asynchronous Message Processing\
    \ Time will be obtained by\n      calculating the sum of ((R0 - T0),(R1 - T1)..(Rn\
    \ - Tn))/Nrx.\n"
- title: A.4.3.  Asynchronous Message Processing Rate
  contents:
  - "A.4.3.  Asynchronous Message Processing Rate\n   Procedure:\n         Network\
    \ Devices           OpenFlow                    SDN\n                        \
    \          Controller               Application\n            |               \
    \             |                          |\n            |OFPT_PACKET_IN with single\
    \  |                          |\n            |OFP match header            |  \
    \                        |\n            |--------------------------->|       \
    \                   |\n            |                            |            \
    \              |\n            |OFPT_PACKET_OUT with single |                 \
    \         |\n            |          OFP action header |                      \
    \    |\n            |<---------------------------|                          |\n\
    \            |                            |                          |\n     \
    \       |            .               |                          |\n          \
    \  |            .               |                          |\n            |  \
    \          .               |                          |\n            |       \
    \                     |                          |\n            |OFPT_PACKET_IN\
    \ with single  |                          |\n            |OFP match header   \
    \         |                          |\n            |--------------------------->|\
    \                          |\n            |                            |     \
    \                     |\n            |OFPT_PACKET_OUT with single |          \
    \                |\n            |          OFP action header |               \
    \           |\n            |<---------------------------|                    \
    \      |\n            |                            |                         \
    \ |\n            |<Repeat the steps until     |                          |\n \
    \           |the expiry of the           |                          |\n      \
    \      |Trial Duration>             |                          |\n           \
    \ |                            |                          |\n            |<Record\
    \ the number of OFP   |                          |\n      (Ntx1)|match headers\
    \ sent>         |                          |\n            |                  \
    \          |                          |\n            |<Record the number of OFP\
    \   |                          |\n      (Nrx1)|action headers rcvd>        | \
    \                         |\n            |                            |      \
    \                    |\n      Note: The Ntx1 on initial trials should be greater\
    \ than Nrx1.\n      Repeat the trials until the Nrxn for two consecutive trials\
    \ equals\n      (+/-P%).\n   Discussion:\n      Using a single procedure, this\
    \ test will measure two benchmarks:\n         1. The Maximum Asynchronous Message\
    \ Processing Rate will be\n            obtained by calculating the maximum OFPT_PACKET_OUTs\
    \ (Nrxn)\n            received from the controller(s) across n trials.\n     \
    \    2. The Loss-Free Asynchronous Message Processing Rate will be\n         \
    \   obtained by calculating the maximum OFPT_PACKET_OUTs\n            received\
    \ from the controller(s) when the Loss Ratio equals\n            zero.  The Loss\
    \ Ratio is obtained by calculating\n            1 - Nrxn/Ntxn.\n"
- title: A.4.4.  Reactive Path Provisioning Time
  contents:
  - "A.4.4.  Reactive Path Provisioning Time\n   Procedure:\n       Test Traffic \
    \    Test Traffic      Network Devices      OpenFlow\n      Generator TP1    Generator\
    \ TP2                          Controller\n            |             |       \
    \               |                     |\n            |             |G-ARP (D1)\
    \            |                     |\n            |             |--------------------->|\
    \                     |\n            |             |                      |  \
    \                   |\n            |             |                      |OFPT_PACKET_IN(D1)\
    \   |\n            |             |                      |-------------------->|\n\
    \            |             |                      |                     |\n  \
    \          |Traffic (S1,D1)                     |                     |\n    \
    \  (Tsf1)|----------------------------------->|                     |\n      \
    \      |             |                      |                     |\n        \
    \    |             |                      |                     |\n          \
    \  |             |                      |                     |\n            |\
    \             |                      |OFPT_PACKET_IN(S1,D1)|\n            |  \
    \           |                      |-------------------->|\n            |    \
    \         |                      |                     |\n            |      \
    \       |                      |  FLOW_MOD(D1)       |\n            |        \
    \     |                      |<--------------------|\n            |          \
    \   |                      |                     |\n            |            \
    \ |Traffic (S1,D1)       |                     |\n            |       (Tdf1)|<---------------------|\
    \                     |\n            |             |                      |  \
    \                   |\n   Legend:\n      G-ARP: Gratuitous ARP message\n     \
    \ Tsf1: Time of first frame sent from TP1\n      Tdf1: Time of first frame received\
    \ from TP2\n   Discussion:\n      The Reactive Path Provisioning Time can be obtained\
    \ by finding the\n      time difference between the transmit and receive times\
    \ of the\n      traffic (Tsf1 - Tdf1).\n"
- title: A.4.5.  Proactive Path Provisioning Time
  contents:
  - "A.4.5.  Proactive Path Provisioning Time\n   Procedure:\n   Test Traffic  Test\
    \ Traffic    Network Devices OpenFlow       SDN\n   Generator TP1 Generator TP2\
    \                  Controller   Application\n         |            |         \
    \      |                  |             |\n         |            |           \
    \    |                  |             |\n         |            |             \
    \  |                  |<Install flow|\n         |            |               |\
    \                  |  for S1,D1> |\n         |            |G-ARP (D1)     |  \
    \                |             |\n         |            |-------------->|    \
    \              |             |\n         |            |               |      \
    \            |             |\n         |            |               |OFPT_PACKET_IN(D1)|\
    \             |\n         |            |               |----------------->|  \
    \           |\n         |            |               |                  |    \
    \         |\n         |Traffic (S1,D1)             |                  |      \
    \       |\n   (Tsf1)|--------------------------->|                  |        \
    \     |\n         |            |               |                  |          \
    \   |\n         |            |               |   FLOW_MOD(D1)   |            \
    \ |\n         |            |               |<-----------------|             |\n\
    \         |            |               |                  |             |\n  \
    \       |            |Traffic (S1,D1)|                  |             |\n    \
    \     |      (Tdf1)|<--------------|                  |             |\n      \
    \   |            |               |                  |             |\n   Legend:\n\
    \      G-ARP: Gratuitous ARP message\n      Tsf1: Time of first frame sent from\
    \ TP1\n      Tdf1: Time of first frame received from TP2\n   Discussion:\n   \
    \   The Proactive Path Provisioning Time can be obtained by finding\n      the\
    \ time difference between the transmit and receive times of the\n      traffic\
    \ (Tsf1 - Tdf1).\n"
- title: A.4.6.  Reactive Path Provisioning Rate
  contents:
  - "A.4.6.  Reactive Path Provisioning Rate\n   Procedure:\n       Test Traffic \
    \    Test Traffic   Network Devices         OpenFlow\n      Generator TP1    Generator\
    \ TP2                         Controller\n            |             |        \
    \            |                      |\n            |             |           \
    \         |                      |\n            |             |              \
    \      |                      |\n            |             |G-ARP (D1..Dn)   \
    \   |                      |\n            |             |--------------------|\
    \                      |\n            |             |                    |   \
    \                   |\n            |             |                    |OFPT_PACKET_IN(D1..Dn)|\n\
    \            |             |                    |--------------------->|\n   \
    \         |             |                    |                      |\n      \
    \      |Traffic (S1..Sn,D1..Dn)           |                      |\n         \
    \   |--------------------------------->|                      |\n            |\
    \             |                    |                      |\n            |   \
    \          |                    |OFPT_PACKET_IN(S1..Sn,|\n            |      \
    \       |                    |               D1..Dn)|\n            |         \
    \    |                    |--------------------->|\n            |            \
    \ |                    |                      |\n            |             | \
    \                   |        FLOW_MOD(S1)  |\n            |             |    \
    \                |<---------------------|\n            |             |       \
    \             |                      |\n            |             |          \
    \          |        FLOW_MOD(D1)  |\n            |             |             \
    \       |<---------------------|\n            |             |                \
    \    |                      |\n            |             |                   \
    \ |        FLOW_MOD(S2)  |\n            |             |                    |<---------------------|\n\
    \            |             |                    |                      |\n   \
    \         |             |                    |        FLOW_MOD(D2)  |\n      \
    \      |             |                    |<---------------------|\n         \
    \   |             |                    |             .        |\n            |\
    \             |                    |             .        |\n            |   \
    \          |                    |                      |\n            |      \
    \       |                    |        FLOW_MOD(Sn)  |\n            |         \
    \    |                    |<---------------------|\n            |            \
    \ |                    |                      |\n            |             | \
    \                   |        FLOW_MOD(Dn)  |\n            |             |    \
    \                |<---------------------|\n            |             |       \
    \             |                      |\n            |             | Traffic (S1..Sn,\
    \   |                      |\n            |             |             D1..Dn)|\
    \                      |\n            |             |<-------------------|   \
    \                   |\n            |             |                    |      \
    \                |\n            |             |                    |         \
    \             |\n   Legend:\n      G-ARP: Gratuitous ARP message\n      D1..Dn:\
    \ Destination Endpoint 1, Destination Endpoint 2 ...,\n              Destination\
    \ Endpoint n\n      S1..Sn: Source Endpoint 1, Source Endpoint 2 ...,\n      \
    \        Source Endpoint n\n   Discussion:\n      The Reactive Path Provisioning\
    \ Rate can be obtained by finding the\n      total number of frames received at\
    \ test traffic generator TP2\n      after the Trial Duration.\n"
- title: A.4.7.  Proactive Path Provisioning Rate
  contents:
  - "A.4.7.  Proactive Path Provisioning Rate\n   Procedure:\n   Test Traffic  Test\
    \ Traffic   Network Devices   OpenFlow        SDN\n   Generator TP1 Generator\
    \ TP2                   Controller  Application\n         |            |     \
    \           |                 |             |\n         |            |G-ARP (D1..Dn)\
    \  |                 |             |\n         |            |--------------->|\
    \                 |             |\n         |            |                |  \
    \               |             |\n         |            |                |OFPT_PACKET_IN\
    \   |             |\n         |            |                |         (D1..Dn)|\
    \             |\n         |            |                |---------------->|  \
    \           |\n         |            |                |                 |    \
    \         |\n         |Traffic (S1..Sn,D1..Dn)      |                 |      \
    \       |\n   (Tsf1)|---------------------------->|                 |        \
    \     |\n         |            |                |                 |          \
    \   |\n         |            |                |                 |<Install flow|\n\
    \         |            |                |                 |  for S1,D1> |\n  \
    \       |            |                |                 |             |\n    \
    \     |            |                |                 |       .     |\n      \
    \   |            |                |                 |<Install flow|\n        \
    \ |            |                |                 |  for Sn,Dn> |\n         |\
    \            |                |                 |             |\n         |  \
    \          |                |  FLOW_MOD(S1)   |             |\n         |    \
    \        |                |<----------------|             |\n         |      \
    \      |                |                 |             |\n         |        \
    \    |                |  FLOW_MOD(D1)   |             |\n         |          \
    \  |                |<----------------|             |\n         |            |\
    \                |                 |             |\n         |            |  \
    \              |       .         |             |\n         |            |    \
    \            |  FLOW_MOD(Sn)   |             |\n         |            |      \
    \          |<----------------|             |\n         |            |        \
    \        |                 |             |\n         |            |          \
    \      |  FLOW_MOD(Dn)   |             |\n         |            |            \
    \    |<----------------|             |\n         |            |              \
    \  |                 |             |\n         |            |Traffic (S1..Sn,|\
    \                 |             |\n         |            |         D1..Dn)|  \
    \               |             |\n         |      (Tdf1)|<---------------|    \
    \             |             |\n         |            |                |      \
    \           |             |\n   Legend:\n      G-ARP: Gratuitous ARP message\n\
    \      D1..Dn: Destination Endpoint 1, Destination Endpoint 2 ...,\n         \
    \     Destination Endpoint n\n      S1..Sn: Source Endpoint 1, Source Endpoint\
    \ 2 ...,\n              Source Endpoint n\n   Discussion:\n      The Proactive\
    \ Path Provisioning Rate can be obtained by finding\n      the total number of\
    \ frames received at test traffic generator TP2\n      after the Trial Duration.\n"
- title: A.4.8.  Network Topology Change Detection Time
  contents:
  - "A.4.8.  Network Topology Change Detection Time\n   Procedure:\n       Network\
    \ Devices              OpenFlow                    SDN\n                     \
    \              Controller               Application\n            |           \
    \                 |                           |\n            |               \
    \             |     <Bring down a link in |\n            |                   \
    \         |                 Switch S1>|\n            |                       \
    \     |                           |\n         T0 |PORT_STATUS with link down \
    \ |                           |\n            | from S1                    |  \
    \                         |\n            |--------------------------->|      \
    \                     |\n            |                            |          \
    \                 |\n            |First OFPT_PACKET_OUT with  |              \
    \             |\n            |LLDP to OF switch           |                  \
    \         |\n         T1 |<---------------------------|                      \
    \     |\n            |                            |                          \
    \ |\n            |                            |      <Record time of first|\n\
    \            |                            |       OFPT_PACKET_OUT with|\n    \
    \        |                            |                   LLDP T1>|\n        \
    \    |                            |                           |\n   Discussion:\n\
    \      The Network Topology Change Detection Time can be obtained by\n      finding\
    \ the difference between the time that OpenFlow Switch S1\n      sends the PORT_STATUS\
    \ message (T0) and the time that the OpenFlow\n      controller sends the first\
    \ topology rediscovery message (T1) to\n      OpenFlow switches.\n"
- title: A.5.  Scalability
  contents:
  - 'A.5.  Scalability

    '
- title: A.5.1.  Control Sessions Capacity
  contents:
  - "A.5.1.  Control Sessions Capacity\n   Procedure:\n         Network Devices  \
    \                      OpenFlow\n                                            \
    \   Controller\n            |                                       |\n      \
    \      |    OFPT_HELLO Exchange for Switch 1   |\n            |<------------------------------------->|\n\
    \            |                                       |\n            |    OFPT_HELLO\
    \ Exchange for Switch 2   |\n            |<------------------------------------->|\n\
    \            |                  .                    |\n            |        \
    \          .                    |\n            |                  .          \
    \          |\n            |    OFPT_HELLO Exchange for Switch n   |\n        \
    \    |X<----------------------------------->X|\n            |                \
    \                       |\n   Discussion:\n      The value of Switch (n - 1) will\
    \ provide the Control Sessions\n      Capacity.\n"
- title: A.5.2.  Network Discovery Size
  contents:
  - "A.5.2.  Network Discovery Size\n   Procedure:\n       Network Devices       \
    \       OpenFlow                    SDN\n                                   Controller\
    \               Application\n            |                            |      \
    \                     |\n            |                            |     <Deploy\
    \ network with  |\n            |                            |given no. of OF switches\
    \ N>|\n            |                            |                           |\n\
    \            |    OFPT_HELLO Exchange     |                           |\n    \
    \        |<-------------------------->|                           |\n        \
    \    |                            |                           |\n            |\
    \   OFPT_PACKET_OUT with LLDP|                           |\n            |    \
    \  to all switches       |                           |\n            |<---------------------------|\
    \                           |\n            |                            |    \
    \                       |\n            |    OFPT_PACKET_IN with LLDP|        \
    \                   |\n            |          rcvd from Switch 1|            \
    \               |\n            |--------------------------->|                \
    \           |\n            |                            |                    \
    \       |\n            |    OFPT_PACKET_IN with LLDP|                        \
    \   |\n            |          rcvd from Switch 2|                           |\n\
    \            |--------------------------->|                           |\n    \
    \        |            .               |                           |\n        \
    \    |            .               |                           |\n            |\
    \                            |                           |\n            |    OFPT_PACKET_IN\
    \ with LLDP|                           |\n            |          rcvd from Switch\
    \ n|                           |\n            |--------------------------->| \
    \                          |\n            |                            |     \
    \                      |\n            |                            |    <Wait\
    \ for the expiry of|\n            |                            |   the Trial Duration\
    \ (Td)>|\n            |                            |                         \
    \  |\n            |                            |   Query the controller for|\n\
    \            |                            |  discovered n/w topo. (N1)|\n    \
    \        |                            |<--------------------------|\n        \
    \    |                            |                           |\n            |\
    \                            |   <If N1==N, repeat Step 1|\n            |    \
    \                        |           with N + 1 nodes|\n            |        \
    \                    |               until N1<N >|\n            |            \
    \                |                           |\n            |                \
    \            |   <If N1<N, repeat Step 1 |\n            |                    \
    \        | with N=N1 nodes once and  |\n            |                        \
    \    | exit>                     |\n            |                            |\
    \                           |\n   Legend:\n      n/w topo: Network topology\n\
    \      OF: OpenFlow\n   Discussion:\n      The value of N1 provides the Network\
    \ Discovery Size value.  The\n      Trial Duration can be set to the stipulated\
    \ time within which the\n      user expects the controller to complete the discovery\
    \ process.\n"
- title: A.5.3.  Forwarding Table Capacity
  contents:
  - "A.5.3.  Forwarding Table Capacity\n   Procedure:\n   Test Traffic     Network\
    \ Devices        OpenFlow          SDN\n   Generator TP1                     \
    \      Controller     Application\n        |                 |               \
    \       |                 |\n        |                 |                     \
    \ |                 |\n        |G-ARP (H1..Hn)   |                      |    \
    \             |\n        |---------------->|                      |          \
    \       |\n        |                 |                      |                \
    \ |\n        |                 |OFPT_PACKET_IN(D1..Dn)|                 |\n  \
    \      |                 |--------------------->|                 |\n        |\
    \                 |                      |                 |\n        |      \
    \           |                      |<Wait for 5 secs>|\n        |            \
    \     |                      |                 |\n        |                 |\
    \                      |  <Query for FWD |\n        |                 |      \
    \                |          entry> |(F1)\n        |                 |        \
    \              |                 |\n        |                 |              \
    \        |<Wait for 5 secs>|\n        |                 |                    \
    \  |                 |\n        |                 |                      |  <Query\
    \ for FWD |\n        |                 |                      |          entry>\
    \ |(F2)\n        |                 |                      |                 |\n\
    \        |                 |                      |<Wait for 5 secs>|\n      \
    \  |                 |                      |                 |\n        |   \
    \              |                      |  <Query for FWD |\n        |         \
    \        |                      |          entry> |(F3)\n        |           \
    \      |                      |                 |\n        |                 |\
    \                      | <Repeat Step 2  |\n        |                 |      \
    \                |until F1==F2==F3>|\n        |                 |            \
    \          |                 |\n   Legend:\n      G-ARP: Gratuitous ARP message\n\
    \      H1..Hn: Host 1 .. Host n\n      FWD: Forwarding Table\n   Discussion:\n\
    \      Query the controller's Forwarding Table entries multiple times,\n     \
    \ until three consecutive queries return the same value.  The last\n      value\
    \ retrieved from the controller will provide the Forwarding\n      Table Capacity\
    \ value.  The query interval is user configurable.\n      The interval of 5 seconds\
    \ shown in this example is for\n      representational purposes.\n"
- title: A.6.  Security
  contents:
  - 'A.6.  Security

    '
- title: A.6.1.  Exception Handling
  contents:
  - 'A.6.1.  Exception Handling

    '
- title: 'Procedure:'
  contents:
  - 'Procedure:

    '
- title: Test Traffic  Test Traffic   Network Devices   OpenFlow          SDN
  contents:
  - 'Test Traffic  Test Traffic   Network Devices   OpenFlow          SDN

    '
- title: Generator TP1 Generator TP2                  Controller      Application
  contents:
  - "Generator TP1 Generator TP2                  Controller      Application\n  \
    \ |          |                |                      |                |\n   |\
    \          |G-ARP (D1..Dn)  |                      |                |\n   |  \
    \        |--------------->|                      |                |\n   |    \
    \      |                |                      |                |\n   |      \
    \    |                |OFPT_PACKET_IN(D1..Dn)|                |\n   |        \
    \  |                |--------------------->|                |\n   |          |\
    \                |                      |                |\n   |Traffic (S1..Sn,D1..Dn)\
    \    |                      |                |\n   |-------------------------->|\
    \                      |                |\n   |          |                |  \
    \                    |                |\n   |          |                |OFPT_PACKET_IN(S1..Sa,|\
    \                |\n   |          |                |               D1..Da)|  \
    \              |\n   |          |                |--------------------->|    \
    \            |\n   |          |                |                      |      \
    \          |\n   |          |                |OFPT_PACKET_IN        |        \
    \        |\n   |          |                |            (Sa+1..Sn,|          \
    \      |\n   |          |                |             Da+1..Dn)|            \
    \    |\n   |          |                |     (1% incorrect OFP|              \
    \  |\n   |          |                |         match header)|                |\n\
    \   |          |                |--------------------->|                |\n  \
    \ |          |                |                      |                |\n   |\
    \          |                |      FLOW_MOD(D1..Dn)|                |\n   |  \
    \        |                |<---------------------|                |\n   |    \
    \      |                |                      |                |\n   |      \
    \    |                |      FLOW_MOD(S1..Sa)|                |\n   |        \
    \  |                |           OFP headers|                |\n   |          |\
    \                |<---------------------|                |\n   |          |  \
    \              |                      |                |\n   |          |Traffic\
    \ (S1..Sa,|                      |                |\n   |          |         D1..Da)|\
    \                      |                |\n   |          |<---------------|  \
    \                    |                |\n   |          |                |    \
    \                  |                |\n   |          |                |      \
    \                |   <Wait for the|\n   |          |                |        \
    \              |   expiry of the|\n   |          |                |          \
    \            |           Trial|\n   |          |                |            \
    \          |       Duration>|\n   |          |                |              \
    \        |                |\n   |          |                |                \
    \      |      <Record Rx|\n   |          |                |                  \
    \    |       frames at|\n   |          |                |                    \
    \  |      TP2 (Rn1)>|\n   |          |                |                      |\
    \                |\n   |          |                |                      |  \
    \      <Repeat |\n   |          |                |                      |    \
    \ Step 1 with|\n   |          |                |                      |    2%\
    \ incorrect|\n   |          |                |                      |OFPT_PACKET_INs>|\n\
    \   |          |                |                      |                |\n  \
    \ |          |                |                      |      <Record Rx|\n   |\
    \          |                |                      |       frames at|\n   |  \
    \        |                |                      |      TP2 (Rn2)>|\n   Legend:\n\
    \      G-ARP: Gratuitous ARP message\n      OFPT_PACKET_IN(Sa+1..Sn,Da+1..Dn):\
    \ OFPT_PACKET_IN with\n                                         wrong version\
    \ number\n      Rn1: Total number of frames received at Test Port 2\n        \
    \   with 1% incorrect frames\n      Rn2: Total number of frames received at Test\
    \ Port 2\n           with 2% incorrect frames\n   Discussion:\n      The traffic\
    \ rate sent towards the OpenFlow switch from Test Port 1\n      should be 1% higher\
    \ than the Path Programming Rate.  Rn1 will\n      provide the Path Provisioning\
    \ Rate of the controller when 1% of\n      incorrect frames are received, and\
    \ Rn2 will provide the Path\n      Provisioning Rate of the controller when 2%\
    \ of incorrect frames\n      are received.\n      The procedure defined above\
    \ provides test steps to determine the\n      effects of handling error packets\
    \ on the Path Programming Rate.\n      The same procedure can be adapted to determine\
    \ the effects on\n      other performance tests listed in this benchmarking test.\n"
- title: A.6.2.  Handling Denial-of-Service Attacks
  contents:
  - 'A.6.2.  Handling Denial-of-Service Attacks

    '
- title: 'Procedure:'
  contents:
  - 'Procedure:

    '
- title: Test Traffic  Test Traffic   Network Device      OpenFlow         SDN
  contents:
  - 'Test Traffic  Test Traffic   Network Device      OpenFlow         SDN

    '
- title: Generator TP1 Generator TP2                     Controller  Application
  contents:
  - "Generator TP1 Generator TP2                     Controller  Application\n   \
    \ |          |                 |                      |             |\n    | \
    \         |G-ARP (D1..Dn)   |                      |             |\n    |    \
    \      |---------------->|                      |             |\n    |       \
    \   |                 |                      |             |\n    |          |\
    \                 |OFPT_PACKET_IN(D1..Dn)|             |\n    |          |   \
    \              |--------------------->|             |\n    |          |      \
    \           |                      |             |\n    |Traffic (S1..Sn,D1..Dn)\
    \     |                      |             |\n    |--------------------------->|\
    \                      |             |\n    |          |                 |   \
    \                   |             |\n    |          |                 |OFPT_PACKET_IN(S1..Sn,|\
    \             |\n    |          |                 |               D1..Dn)|   \
    \          |\n    |          |                 |--------------------->|      \
    \       |\n    |          |                 |                      |         \
    \    |\n    |          |                 |TCP SYN attack        |            \
    \ |\n    |          |                 |from a switch         |             |\n\
    \    |          |                 |--------------------->|             |\n   \
    \ |          |                 |                      |             |\n    | \
    \         |                 |FLOW_MOD(D1..Dn)      |             |\n    |    \
    \      |                 |<---------------------|             |\n    |       \
    \   |                 |                      |             |\n    |          |\
    \                 | FLOW_MOD(S1..Sn)     |             |\n    |          |   \
    \              |      OFP headers     |             |\n    |          |      \
    \           |<---------------------|             |\n    |          |         \
    \        |                      |             |\n    |          |Traffic (S1..Sn,\
    \ |                      |             |\n    |          |         D1..Dn) | \
    \                     |             |\n    |          |<----------------|    \
    \                  |             |\n    |          |                 |       \
    \               |             |\n    |          |                 |          \
    \            |<Wait for the|\n    |          |                 |             \
    \         |expiry of the|\n    |          |                 |                \
    \      |        Trial|\n    |          |                 |                   \
    \   |    Duration>|\n    |          |                 |                      |\
    \             |\n    |          |                 |                      |   <Record\
    \ Rx|\n    |          |                 |                      |    frames at|\n\
    \    |          |                 |                      |   TP2 (Rn1)>|\n   \
    \ |          |                 |                      |             |\n   Legend:\n\
    \      G-ARP: Gratuitous ARP message\n   Discussion:\n      A TCP SYN attack should\
    \ be launched from one of the\n      emulated/simulated OpenFlow switches.  Rn1\
    \ provides the Path\n      Programming Rate of the controller upon handling a\
    \ denial-of-\n      service attack.\n      The procedure defined above provides\
    \ test steps to determine the\n      effects of handling denial of service on\
    \ the Path Programming\n      Rate.  The same procedure can be adapted to determine\
    \ the effects\n      on other performance tests listed in this benchmarking test.\n"
- title: A.7.  Reliability
  contents:
  - 'A.7.  Reliability

    '
- title: A.7.1.  Controller Failover Time
  contents:
  - 'A.7.1.  Controller Failover Time

    '
- title: 'Procedure:'
  contents:
  - 'Procedure:

    '
- title: Test Traffic  Test Traffic  Network Device       OpenFlow      SDN
  contents:
  - 'Test Traffic  Test Traffic  Network Device       OpenFlow      SDN

    '
- title: Generator TP1 Generator TP2                    Controller   Application
  contents:
  - "Generator TP1 Generator TP2                    Controller   Application\n   |\
    \            |               |                       |             |\n   |   \
    \         |G-ARP (D1)     |                       |             |\n   |      \
    \      |-------------->|                       |             |\n   |         \
    \   |               |                       |             |\n   |            |\
    \               |OFPT_PACKET_IN(D1)     |             |\n   |            |   \
    \            |---------------------->|             |\n   |            |      \
    \         |                       |             |\n   |Traffic (S1..Sn,D1)   \
    \      |                       |             |\n   |--------------------------->|\
    \                       |             |\n   |            |               |   \
    \                    |             |\n   |            |               |      \
    \                 |             |\n   |            |               |OFPT_PACKET_IN(S1,D1)\
    \  |             |\n   |            |               |---------------------->|\
    \             |\n   |            |               |                       |   \
    \          |\n   |            |               |FLOW_MOD(D1)           |      \
    \       |\n   |            |               |<----------------------|         \
    \    |\n   |            |               |FLOW_MOD(S1)           |            \
    \ |\n   |            |               |<----------------------|             |\n\
    \   |            |               |                       |             |\n   |\
    \            |Traffic (S1,D1)|                       |             |\n   |   \
    \         |<--------------|                       |             |\n   |      \
    \      |               |                       |             |\n   |         \
    \   |               |OFPT_PACKET_IN(S2,D1)  |             |\n   |            |\
    \               |---------------------->|             |\n   |            |   \
    \            |                       |             |\n   |            |      \
    \         |FLOW_MOD(S2)           |             |\n   |            |         \
    \      |<----------------------|             |\n   |            |            \
    \   |                       |             |\n   |            |               |OFPT_PACKET_IN\
    \         |             |\n   |            |               |             (Sn-1,D1)\
    \ |             |\n   |            |               |---------------------->| \
    \            |\n   |            |               |                       |    \
    \         |\n   |            |               |OFPT_PACKET_IN(Sn,D1)  |       \
    \      |\n   |            |               |---------------------->|          \
    \   |\n   |            |               |          .            |             |\n\
    \   |            |               |          .            |<Bring down  |\n   |\
    \            |               |          .            | the active  |\n   |   \
    \         |               |                       | controller> |\n   |      \
    \      |               |  FLOW_MOD(Sn-1)       |             |\n   |         \
    \   |               |    X<-----------------|             |\n   |            |\
    \               |                       |             |\n   |            |   \
    \            |FLOW_MOD(Sn)           |             |\n   |            |      \
    \         |<----------------------|             |\n   |            |         \
    \      |                       |             |\n   |            |Traffic (Sn,D1)|\
    \                       |             |\n   |            |<--------------|   \
    \                    |             |\n   |            |               |      \
    \                 |             |\n   |            |               |         \
    \              |<Stop the    |\n   |            |               |            \
    \           |test after   |\n   |            |               |               \
    \        |recv. traffic|\n   |            |               |                  \
    \     |upon         |\n   |            |               |                     \
    \  |failure>     |\n   Legend:\n      G-ARP: Gratuitous ARP message\n   Discussion:\n\
    \      The time difference between the last valid frame received before\n    \
    \  the traffic loss and the first frame received after the traffic\n      loss\
    \ will provide the Controller Failover Time.\n      If there is no frame loss\
    \ during the Controller Failover Time, the\n      Controller Failover Time can\
    \ be deemed negligible.\n"
- title: A.7.2.  Network Re-provisioning Time
  contents:
  - 'A.7.2.  Network Re-provisioning Time

    '
- title: 'Procedure:'
  contents:
  - 'Procedure:

    '
- title: Test Traffic  Test Traffic   Network Devices     OpenFlow       SDN
  contents:
  - 'Test Traffic  Test Traffic   Network Devices     OpenFlow       SDN

    '
- title: Generator TP1 Generator TP2                     Controller   Application
  contents:
  - "Generator TP1 Generator TP2                     Controller   Application\n  |\
    \             |                |                      |              |\n  |  \
    \           |G-ARP (D1)      |                      |              |\n  |    \
    \         |--------------->|                      |              |\n  |      \
    \       |                |                      |              |\n  |        \
    \     |                |OFPT_PACKET_IN(D1)    |              |\n  |          \
    \   |                |--------------------->|              |\n  |            \
    \ |G-ARP (S1)      |                      |              |\n  |----------------------------->|\
    \                      |              |\n  |             |                |  \
    \                    |              |\n  |             |                |OFPT_PACKET_IN(S1)\
    \    |              |\n  |             |                |--------------------->|\
    \              |\n  |             |                |                      |  \
    \            |\n  |Traffic (S1,D1,Seq. no (1..n))|                      |    \
    \          |\n  |----------------------------->|                      |      \
    \        |\n  |             |                |                      |        \
    \      |\n  |             |                |OFPT_PACKET_IN(S1,D1) |          \
    \    |\n  |             |                |--------------------->|            \
    \  |\n  |             |                |                      |              |\n\
    \  |             | Traffic (D1,S1,|                      |              |\n  |\
    \             | Seq. no (1..n))|                      |              |\n  |  \
    \           |--------------->|                      |              |\n  |    \
    \         |                |                      |              |\n  |      \
    \       |                |OFPT_PACKET_IN(D1,S1) |              |\n  |        \
    \     |                |--------------------->|              |\n  |          \
    \   |                |                      |              |\n  |            \
    \ |                |FLOW_MOD(D1)          |              |\n  |             |\
    \                |<---------------------|              |\n  |             |  \
    \              |                      |              |\n  |             |    \
    \            |FLOW_MOD(S1)          |              |\n  |             |      \
    \          |<---------------------|              |\n  |             |        \
    \        |                      |              |\n  |             | Traffic (S1,D1,|\
    \                      |              |\n  |             |     Seq. no(1))|  \
    \                    |              |\n  |             |<---------------|    \
    \                  |              |\n  |             |                |      \
    \                |              |\n  |             | Traffic (S1,D1,|        \
    \              |              |\n  |             |     Seq. no(2))|          \
    \            |              |\n  |             |<---------------|            \
    \          |              |\n  |             |                |              \
    \        |              |\n  |             |                |                \
    \      |              |\n  |    Traffic (D1,S1,Seq. no(1))|                  \
    \    |              |\n  |<-----------------------------|                    \
    \  |              |\n  |             |                |                      |\
    \              |\n  |    Traffic (D1,S1,Seq. no(2))|                      |  \
    \            |\n  |<-----------------------------|                      |    \
    \          |\n  |             |                |                      |      \
    \        |\n  |    Traffic (D1,S1,Seq. no(x))|                      |        \
    \      |\n  |<-----------------------------|                      |          \
    \    |\n  |             |                |                      |            \
    \  |\n  |             | Traffic (S1,D1,|                      |              |\n\
    \  |             |     Seq. no(x))|                      |              |\n  |\
    \             |<---------------|                      |              |\n  |  \
    \           |                |                      |              |\n  |    \
    \         |                |                      |              |\n  |      \
    \       |                |                      |  <Bring down |\n  |        \
    \     |                |                      | the switch in|\n  |          \
    \   |                |                      |    the active|\n  |            \
    \ |                |                      | traffic path>|\n  |             |\
    \                |                      |              |\n  |             |  \
    \              |PORT_STATUS(Sa)       |              |\n  |             |    \
    \            |--------------------->|              |\n  |             |      \
    \          |                      |              |\n  |             | Traffic\
    \ (S1,D1,|                      |              |\n  |             | Seq. no(n\
    \ - 1))|                      |              |\n  |             |  X<------------|\
    \                      |              |\n  |             |                |  \
    \                    |              |\n  |Traffic (D1,S1,Seq. no(n - 1))|    \
    \                  |              |\n  |    X<------------------------|      \
    \                |              |\n  |             |                |        \
    \              |              |\n  |             |                |          \
    \            |              |\n  |             |                |FLOW_MOD(D1)\
    \          |              |\n  |             |                |<---------------------|\
    \              |\n  |             |                |                      |  \
    \            |\n  |             |                |FLOW_MOD(S1)          |    \
    \          |\n  |             |                |<---------------------|      \
    \        |\n  |             |                |                      |        \
    \      |\n  |    Traffic (D1,S1,Seq. no(n))|                      |          \
    \    |\n  |<-----------------------------|                      |            \
    \  |\n  |             |                |                      |              |\n\
    \  |             | Traffic (S1,D1,|                      |              |\n  |\
    \             |     Seq. no(n))|                      |              |\n  |  \
    \           |<---------------|                      |              |\n  |    \
    \         |                |                      |              |\n  |      \
    \       |                |                      |<Stop the test|\n  |        \
    \     |                |                      |  after recv. |\n  |          \
    \   |                |                      |  traffic upon|\n  |            \
    \ |                |                      |   failover>  |\n   Legend:\n     \
    \ G-ARP: Gratuitous ARP message\n      Seq. no: Sequence number\n      Sa: Neighbor\
    \ switch of the switch that was brought down\n   Discussion:\n      The time difference\
    \ between the last valid frame received before\n      the traffic loss (packet\
    \ with sequence number x) and the first\n      frame received after the traffic\
    \ loss (packet with sequence\n      number n) will provide the Network Re-provisioning\
    \ Time.\n      Note that the trial is valid only when the controller provisions\n\
    \      the alternate path upon network failure.\n"
- title: Acknowledgments
  contents:
  - "Acknowledgments\n   The authors would like to thank the following individuals\
    \ for\n   providing their valuable comments regarding the earlier draft\n   versions\
    \ of this document: Al Morton (AT&T), Sandeep Gangadharan\n   (HP), M. Georgescu\
    \ (NAIST), Andrew McGregor (Google), Scott Bradner,\n   Jay Karthik (Cisco), Ramki\
    \ Krishnan (VMware), Boris Khasanov\n   (Huawei), and Brian Castelli (Spirent).\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Bhuvaneswaran Vengainathan\n   Veryx Technologies Inc.\n\
    \   1 International Plaza, Suite 550\n   Philadelphia, PA  19113\n   United States\
    \ of America\n   Email: bhuvaneswaran.vengainathan@veryxtech.com\n   Anton Basil\n\
    \   Veryx Technologies Inc.\n   1 International Plaza, Suite 550\n   Philadelphia,\
    \ PA  19113\n   United States of America\n   Email: anton.basil@veryxtech.com\n\
    \   Mark Tassinari\n   Hewlett Packard Enterprise\n   8000 Foothills Blvd.\n \
    \  Roseville, CA  95747\n   United States of America\n   Email: mark.tassinari@hpe.com\n\
    \   Vishwas Manral\n   NanoSec Co\n   3350 Thomas Rd.\n   Santa Clara, CA  95054\n\
    \   United States of America\n   Email: vishwas.manral@gmail.com\n   Sarah Banks\n\
    \   VSS Monitoring\n   930 De Guigne Drive\n   Sunnyvale, CA  94085\n   United\
    \ States of America\n   Email: sbanks@encrypted.net\n"
