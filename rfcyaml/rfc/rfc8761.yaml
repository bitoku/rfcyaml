- title: __initial_text__
  contents:
  - '          Video Codec Requirements and Evaluation Methodology

    '
- title: Abstract
  contents:
  - "Abstract\n   This document provides requirements for a video codec designed mainly\n\
    \   for use over the Internet.  In addition, this document describes an\n   evaluation\
    \ methodology for measuring the compression efficiency to\n   determine whether\
    \ or not the stated requirements have been fulfilled.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are candidates for any level of Internet\n\
    \   Standard; see Section 2 of RFC 7841.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   https://www.rfc-editor.org/info/rfc8761.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2020 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (https://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction\n   2.  Terminology Used in This Document\n\
    \     2.1.  Definitions\n     2.2.  Abbreviations\n   3.  Applications\n     3.1.\
    \  Internet Video Streaming\n     3.2.  Internet Protocol Television (IPTV)\n\
    \     3.3.  Video Conferencing\n     3.4.  Video Sharing\n     3.5.  Screencasting\n\
    \     3.6.  Game Streaming\n     3.7.  Video Monitoring and Surveillance\n   4.\
    \  Requirements\n     4.1.  General Requirements\n       4.1.1.  Coding Efficiency\n\
    \       4.1.2.  Profiles and Levels\n       4.1.3.  Bitstream Syntax\n       4.1.4.\
    \  Parsing and Identification of Sample Components\n       4.1.5.  Perceptual\
    \ Quality Tools\n       4.1.6.  Buffer Model\n       4.1.7.  Integration\n   \
    \  4.2.  Basic Requirements\n       4.2.1.  Input Source Formats\n       4.2.2.\
    \  Coding Delay\n       4.2.3.  Complexity\n       4.2.4.  Scalability\n     \
    \  4.2.5.  Error Resilience\n     4.3.  Optional Requirements\n       4.3.1. \
    \ Input Source Formats\n       4.3.2.  Scalability\n       4.3.3.  Complexity\n\
    \       4.3.4.  Coding Efficiency\n   5.  Evaluation Methodology\n   6.  Security\
    \ Considerations\n   7.  IANA Considerations\n   8.  References\n     8.1.  Normative\
    \ References\n     8.2.  Informative References\n   Acknowledgments\n   Authors'\
    \ Addresses\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document presents the requirements for a video codec\
    \ designed\n   mainly for use over the Internet.  The requirements encompass a\
    \ wide\n   range of applications that use data transmission over the Internet,\n\
    \   including Internet video streaming, IPTV, peer-to-peer video\n   conferencing,\
    \ video sharing, screencasting, game streaming, and video\n   monitoring and surveillance.\
    \  For each application, typical\n   resolutions, frame rates, and picture-access\
    \ modes are presented.\n   Specific requirements related to data transmission\
    \ over packet-loss\n   networks are considered as well.  In this document, when\
    \ we discuss\n   data-protection techniques, we only refer to methods designed\
    \ and\n   implemented to protect data inside the video codec since there are\n\
    \   many existing techniques that protect generic data transmitted over\n   networks\
    \ with packet losses.  From the theoretical point of view,\n   both packet-loss\
    \ and bit-error robustness can be beneficial for video\n   codecs.  In practice,\
    \ packet losses are a more significant problem\n   than bit corruption in IP networks.\
    \  It is worth noting that there is\n   an evident interdependence between the\
    \ possible amount of delay and\n   the necessity of error-robust video streams:\n\
    \   *  If the amount of delay is not crucial for an application, then\n      reliable\
    \ transport protocols such as TCP that retransmit\n      undelivered packets can\
    \ be used to guarantee correct decoding of\n      transmitted data.\n   *  If\
    \ the amount of delay must be kept low, then either data\n      transmission should\
    \ be error free (e.g., by using managed\n      networks) or the compressed video\
    \ stream should be error\n      resilient.\n   Thus, error resilience can be useful\
    \ for delay-critical applications\n   to provide low delay in a packet-loss environment.\n"
- title: 2.  Terminology Used in This Document
  contents:
  - '2.  Terminology Used in This Document

    '
- title: 2.1.  Definitions
  contents:
  - "2.1.  Definitions\n   High dynamic range imaging\n      A set of techniques that\
    \ allows a greater dynamic range of\n      exposures or values (i.e., a wider\
    \ range of values between light\n      and dark areas) than normal digital imaging\
    \ techniques.  The\n      intention is to accurately represent the wide range\
    \ of intensity\n      levels found in examples such as exterior scenes that include\n\
    \      light-colored items struck by direct sunlight and areas of deep\n     \
    \ shadow [7].\n   Random access period\n      The period of time between the two\
    \ closest independently decodable\n      frames (pictures).\n   RD-point\n   \
    \   A point in a two-dimensional rate-distortion space where the\n      values\
    \ of bitrate and quality metric are used as x- and\n      y-coordinates, respectively.\n\
    \   Visually lossless compression\n      A form or manner of lossy compression\
    \ where the data that are lost\n      after the file is compressed and decompressed\
    \ is not detectable to\n      the eye; the compressed data appear identical to\
    \ the uncompressed\n      data [8].\n   Wide color gamut\n      A certain complete\
    \ color subset (e.g., considered in ITU-R BT.2020\n      [1]) that supports a\
    \ wider range of colors (i.e., an extended\n      range of colors that can be\
    \ generated by a specific input or\n      output device such as a video camera,\
    \ monitor, or printer and can\n      be interpreted by a color model) than conventional\
    \ color gamuts\n      (e.g., considered in ITU-R BT.601 [17] or BT.709 [20]).\n"
- title: 2.2.  Abbreviations
  contents:
  - "2.2.  Abbreviations\n   AI          All-Intra (each picture is intra-coded)\n\
    \   BD-Rate     Bjontegaard Delta Rate\n   FIZD        just the First picture\
    \ is Intra-coded, Zero structural\n               Delay\n   FPS         Frames\
    \ per Second\n   GOP         Group of Picture\n   GPU         Graphics Processing\
    \ Unit\n   HBR         High Bitrate Range\n   HDR         High Dynamic Range\n\
    \   HRD         Hypothetical Reference Decoder\n   HEVC        High Efficiency\
    \ Video Coding\n   IPTV        Internet Protocol Television\n   LBR         Low\
    \ Bitrate Range\n   MBR         Medium Bitrate Range\n   MOS         Mean Opinion\
    \ Score\n   MS-SSIM     Multi-Scale Structural Similarity quality index\n   PAM\
    \         Picture Access Mode\n   PSNR        Peak Signal-to-Noise Ratio\n   QoS\
    \         Quality of Service\n   QP          Quantization Parameter\n   RA   \
    \       Random Access\n   RAP         Random Access Period\n   RD          Rate-Distortion\n\
    \   SEI         Supplemental Enhancement Information\n   SIMD        Single Instruction,\
    \ Multiple Data\n   SNR         Signal-to-Noise Ratio\n   UGC         User-Generated\
    \ Content\n   VDI         Virtual Desktop Infrastructure\n   VUI         Video\
    \ Usability Information\n   WCG         Wide Color Gamut\n"
- title: 3.  Applications
  contents:
  - "3.  Applications\n   In this section, an overview of video codec applications\
    \ that are\n   currently available on the Internet market is presented.  It is\
    \ worth\n   noting that there are different use cases for each application that\n\
    \   define a target platform; hence, there are different types of\n   communication\
    \ channels involved (e.g., wired or wireless channels)\n   that are characterized\
    \ by different QoS as well as bandwidth; for\n   instance, wired channels are\
    \ considerably more free from error than\n   wireless channels and therefore require\
    \ different QoS approaches.\n   The target platform, the channel bandwidth, and\
    \ the channel quality\n   determine resolutions, frame rates, and either quality\
    \ or bitrates\n   for video streams to be encoded or decoded.  By default, color\
    \ format\n   YCbCr 4:2:0 is assumed for the application scenarios listed below.\n"
- title: 3.1.  Internet Video Streaming
  contents:
  - "3.1.  Internet Video Streaming\n   Typical content for this application is movies,\
    \ TV series and shows,\n   and animation.  Internet video streaming uses a variety\
    \ of client\n   devices and has to operate under changing network conditions.\
    \  For\n   this reason, an adaptive streaming model has been widely adopted.\n\
    \   Video material is encoded at different quality levels and different\n   resolutions,\
    \ which are then chosen by a client depending on its\n   capabilities and current\
    \ network bandwidth.  An example combination\n   of resolutions and bitrates is\
    \ shown in Table 1.\n   A video encoding pipeline in on-demand Internet video\
    \ streaming\n   typically operates as follows:\n   *  Video is encoded in the\
    \ cloud by software encoders.\n   *  Source video is split into chunks, each of\
    \ which is encoded\n      separately, in parallel.\n   *  Closed-GOP encoding\
    \ with intrapicture intervals of 2-5 seconds (or\n      longer) is used.\n   *\
    \  Encoding is perceptually optimized.  Perceptual quality is\n      important\
    \ and should be considered during the codec development.\n   | Resolution | PAM\
    \ |               Frame Rate, FPS **               |\n   | 4K,        | RA  |\
    \               24/1.001, 24, 25,                |\n   | 3840x2160  |     |  \
    \             30/1.001, 30, 50,                |\n   | 2K         | RA  |    \
    \             120/1.001, 120                 |\n   | (1080p),   |     |      \
    \                                          |\n   | 1920x1080  |     |        \
    \                                        |\n   | 1080i,     | RA  |          \
    \                                      |\n   | 1920x1080* |     |            \
    \                                    |\n   | 720p,      | RA  |              \
    \                                  |\n   | 1280x720   |     |                \
    \                                |\n   | 576p       | RA  |                  \
    \                              |\n   | (EDTV),    |     |                    \
    \                            |\n   | 720x576    |     |                      \
    \                          |\n   | 576i       | RA  |                        \
    \                        |\n   | (SDTV),    |     |                          \
    \                      |\n   | 720x576*   |     |                            \
    \                    |\n   | 480p       | RA  |                              \
    \                  |\n   | (EDTV),    |     |                                \
    \                |\n   | 720x480    |     |                                  \
    \              |\n   | 480i       | RA  |                                    \
    \            |\n   | (SDTV),    |     |                                      \
    \          |\n   | 720x480*   |     |                                        \
    \        |\n   | 512x384    | RA  |                                          \
    \      |\n   | QVGA,      | RA  |                                            \
    \    |\n   | 320x240    |     |                                              \
    \  |\n     Table 1: Internet Video Streaming: Typical Values of Resolutions,\n\
    \                           Frame Rates, and PAMs\n   *Note: Interlaced content\
    \ can be handled at the higher system level\n   and not necessarily by using specialized\
    \ video coding tools.  It is\n   included in this table only for the sake of completeness,\
    \ as most\n   video content today is in the progressive format.\n   **Note: The\
    \ set of frame rates presented in this table is taken from\n   Table 2 in [1].\n\
    \   The characteristics and requirements of this application scenario are\n  \
    \ as follows:\n   *  High encoder complexity (up to 10x and more) can be tolerated\n\
    \      since encoding happens once and in parallel for different\n      segments.\n\
    \   *  Decoding complexity should be kept at reasonable levels to enable\n   \
    \   efficient decoder implementation.\n   *  Support and efficient encoding of\
    \ a wide range of content types\n      and formats is required:\n      -  High\
    \ Dynamic Range (HDR), Wide Color Gamut (WCG), high-\n         resolution (currently,\
    \ up to 4K), and high-frame-rate content\n         are important use cases; the\
    \ codec should be able to encode\n         such content efficiently.\n      -\
    \  Improvement of coding efficiency at both lower and higher\n         resolutions\
    \ is important since low resolutions are used when\n         streaming in low-bandwidth\
    \ conditions.\n      -  Improvement on both \"easy\" and \"difficult\" content\
    \ in terms of\n         compression efficiency at the same quality level contributes\
    \ to\n         the overall bitrate/storage savings.\n      -  Film grain (and\
    \ sometimes other types of noise) is often\n         present in movies and similar\
    \ content; this is usually part of\n         the creative intent.\n   *  Significant\
    \ improvements in compression efficiency between\n      generations of video standards\
    \ are desirable since this scenario\n      typically assumes long-term support\
    \ of legacy video codecs.\n   *  Random access points are inserted frequently\
    \ (one per 2-5 seconds)\n      to enable switching between resolutions and fast-forward\
    \ playback.\n   *  The elementary stream should have a model that allows easy\
    \ parsing\n      and identification of the sample components.\n   *  Middle QP\
    \ values are normally used in streaming; this is also the\n      range where compression\
    \ efficiency is important for this scenario.\n   *  Scalability or other forms\
    \ of supporting multiple quality\n      representations are beneficial if they\
    \ do not incur significant\n      bitrate overhead and if mandated in the first\
    \ version.\n"
- title: 3.2.  Internet Protocol Television (IPTV)
  contents:
  - "3.2.  Internet Protocol Television (IPTV)\n   This is a service for delivering\
    \ television content over IP-based\n   networks.  IPTV may be classified into\
    \ two main groups based on the\n   type of delivery, as follows:\n   *  unicast\
    \ (e.g., for video on demand), where delay is not crucial;\n      and\n   *  multicast/broadcast\
    \ (e.g., for transmitting news) where zapping\n      (i.e., stream changing) delay\
    \ is important.\n   In the IPTV scenario, traffic is transmitted over managed\
    \ (QoS-based)\n   networks.  Typical content used in this application is news,\
    \ movies,\n   cartoons, series, TV shows, etc.  One important requirement for\
    \ both\n   groups is that random access to pictures (i.e., the random access\n\
    \   period (RAP)) should be kept small enough (approximately 1-5\n   seconds).\
    \  Optional requirements are as follows:\n   *  Temporal (frame-rate) scalability;\
    \ and\n   *  Resolution and quality (SNR) scalability.\n   For this application,\
    \ typical values of resolutions, frame rates, and\n   PAMs are presented in Table\
    \ 2.\n   | Resolution | PAM |               Frame Rate, FPS **               |\n\
    \   |   2160p    | RA  |               24/1.001, 24, 25,                |\n  \
    \ |   (4K),    |     |               30/1.001, 30, 50,                |\n   |\
    \ 3840x2160  |     |               60/1.001, 60, 100,               |\n   | 1080p,\
    \     | RA  |                                                |\n   | 1920x1080\
    \  |     |                                                |\n   | 1080i,     |\
    \ RA  |                                                |\n   | 1920x1080* |  \
    \   |                                                |\n   | 720p,      | RA \
    \ |                                                |\n   | 1280x720   |     |\
    \                                                |\n   | 576p       | RA  |  \
    \                                              |\n   | (EDTV),    |     |    \
    \                                            |\n   | 720x576    |     |      \
    \                                          |\n   | 576i       | RA  |        \
    \                                        |\n   | (SDTV),    |     |          \
    \                                      |\n   | 720x576*   |     |            \
    \                                    |\n   | 480p       | RA  |              \
    \                                  |\n   | (EDTV),    |     |                \
    \                                |\n   | 720x480    |     |                  \
    \                              |\n   | 480i       | RA  |                    \
    \                            |\n   | (SDTV),    |     |                      \
    \                          |\n   | 720x480*   |     |                        \
    \                        |\n    Table 2: IPTV: Typical Values of Resolutions,\
    \ Frame Rates, and PAMs\n   *Note: Interlaced content can be handled at the higher\
    \ system level\n   and not necessarily by using specialized video coding tools.\
    \  It is\n   included in this table only for the sake of completeness, as most\n\
    \   video content today is in a progressive format.\n   **Note: The set of frame\
    \ rates presented in this table is taken from\n   Table 2 in [1].\n"
- title: 3.3.  Video Conferencing
  contents:
  - "3.3.  Video Conferencing\n   This is a form of video connection over the Internet.\
    \  This form\n   allows users to establish connections to two or more people by\
    \ two-\n   way video and audio transmission for communication in real time.  For\n\
    \   this application, both stationary and mobile devices can be used.\n   The\
    \ main requirements are as follows:\n   *  Delay should be kept as low as possible\
    \ (the preferable and\n      maximum end-to-end delay values should be less than\
    \ 100 ms [9] and\n      320 ms [2], respectively);\n   *  Temporal (frame-rate)\
    \ scalability; and\n   *  Error robustness.\n   Support of resolution and quality\
    \ (SNR) scalability is highly\n   desirable.  For this application, typical values\
    \ of resolutions,\n   frame rates, and PAMs are presented in Table 3.\n      \
    \         | Resolution       | Frame Rate, FPS | PAM  |\n               | 1080p,\
    \ 1920x1080 | 15, 30          | FIZD |\n               | 720p, 1280x720   | 30,\
    \ 60          | FIZD |\n               | 4CIF, 704x576    | 30, 60          |\
    \ FIZD |\n               | 4SIF, 704x480    | 30, 60          | FIZD |\n     \
    \          | VGA, 640x480     | 30, 60          | FIZD |\n               | 360p,\
    \ 640x360    | 30, 60          | FIZD |\n                    Table 3: Video Conferencing:\
    \ Typical\n                  Values of Resolutions, Frame Rates, and\n"
- title: 3.4.  Video Sharing
  contents:
  - "3.4.  Video Sharing\n   This is a service that allows people to upload and share\
    \ video data\n   (using live streaming or not) and watch those videos.  It is\
    \ also\n   known as video hosting.  A typical User-Generated Content (UGC)\n \
    \  scenario for this application is to capture video using mobile\n   cameras\
    \ such as GoPros or cameras integrated into smartphones\n   (amateur video). \
    \ The main requirements are as follows:\n   *  Random access to pictures for downloaded\
    \ video data;\n   *  Temporal (frame-rate) scalability; and\n   *  Error robustness.\n\
    \   Support of resolution and quality (SNR) scalability is highly\n   desirable.\
    \  For this application, typical values of resolutions,\n   frame rates, and PAMs\
    \ are presented in Table 4.\n   Typical values of resolutions and frame rates\
    \ in Table 4 are taken\n   from [10].\n         | Resolution            | Frame\
    \ Rate, FPS        | PAM |\n         | 2160p (4K), 3840x2160 | 24, 25, 30, 48,\
    \ 50, 60 | RA  |\n         | 1440p (2K), 2560x1440 | 24, 25, 30, 48, 50, 60 |\
    \ RA  |\n         | 1080p, 1920x1080      | 24, 25, 30, 48, 50, 60 | RA  |\n \
    \        | 720p, 1280x720        | 24, 25, 30, 48, 50, 60 | RA  |\n         |\
    \ 480p, 854x480         | 24, 25, 30, 48, 50, 60 | RA  |\n         | 360p, 640x360\
    \         | 24, 25, 30, 48, 50, 60 | RA  |\n                Table 4: Video Sharing:\
    \ Typical Values of\n                    Resolutions, Frame Rates, and PAMs\n"
- title: 3.5.  Screencasting
  contents:
  - "3.5.  Screencasting\n   This is a service that allows users to record and distribute\
    \ video\n   data from a computer screen.  This service requires efficient\n  \
    \ compression of computer-generated content with high visual quality up\n   to\
    \ visually and mathematically (numerically) lossless [11].\n   Currently, this\
    \ application includes business presentations\n   (PowerPoint, Word documents,\
    \ email messages, etc.), animation\n   (cartoons), gaming content, and data visualization.\
    \  This type of\n   content is characterized by fast motion, rotation, smooth\
    \ shade, 3D\n   effect, highly saturated colors with full resolution, clear textures\n\
    \   and sharp edges with distinct colors [11], virtual desktop\n   infrastructure\
    \ (VDI), screen/desktop sharing and collaboration,\n   supervisory control and\
    \ data acquisition (SCADA) display, automotive/\n   navigation display, cloud\
    \ gaming, factory automation display,\n   wireless display, display wall, digital\
    \ operating room (DiOR), etc.\n   For this application, an important requirement\
    \ is the support of low-\n   delay configurations with zero structural delay for\
    \ a wide range of\n   video formats (e.g., RGB) in addition to YCbCr 4:2:0 and\
    \ YCbCr 4:4:4\n   [11].  For this application, typical values of resolutions,\
    \ frame\n   rates, and PAMs are presented in Table 5.\n        |       Resolution\
    \      | Frame Rate, FPS |     PAM      |\n        |             Input color format:\
    \ RGB 4:4:4              |\n        | 5k, 5120x2880         | 15, 30, 60     \
    \ | AI, RA, FIZD |\n        | 4k, 3840x2160         | 15, 30, 60      | AI, RA,\
    \ FIZD |\n        | WQXGA, 2560x1600      | 15, 30, 60      | AI, RA, FIZD |\n\
    \        | WUXGA, 1920x1200      | 15, 30, 60      | AI, RA, FIZD |\n        |\
    \ WSXGA+, 1680x1050     | 15, 30, 60      | AI, RA, FIZD |\n        | WXGA, 1280x800\
    \        | 15, 30, 60      | AI, RA, FIZD |\n        | XGA, 1024x768         |\
    \ 15, 30, 60      | AI, RA, FIZD |\n        | SVGA, 800x600         | 15, 30,\
    \ 60      | AI, RA, FIZD |\n        | VGA, 640x480          | 15, 30, 60     \
    \ | AI, RA, FIZD |\n        |            Input color format: YCbCr 4:4:4     \
    \        |\n        | 5k, 5120x2880         | 15, 30, 60      | AI, RA, FIZD |\n\
    \        | 4k, 3840x2160         | 15, 30, 60      | AI, RA, FIZD |\n        |\
    \ 1440p (2K), 2560x1440 | 15, 30, 60      | AI, RA, FIZD |\n        | 1080p, 1920x1080\
    \      | 15, 30, 60      | AI, RA, FIZD |\n        | 720p, 1280x720        | 15,\
    \ 30, 60      | AI, RA, FIZD |\n          Table 5: Screencasting for RGB and YCbCr\
    \ 4:4:4 Format:\n           Typical Values of Resolutions, Frame Rates, and PAMs\n"
- title: 3.6.  Game Streaming
  contents:
  - "3.6.  Game Streaming\n   This is a service that provides game content over the\
    \ Internet to\n   different local devices such as notebooks and gaming tablets.\
    \  In\n   this category of applications, the server renders 3D games in a cloud\n\
    \   server and streams the game to any device with a wired or wireless\n   broadband\
    \ connection [12].  There are low-latency requirements for\n   transmitting user\
    \ interactions and receiving game data with a\n   turnaround delay of less than\
    \ 100 ms.  This allows anyone to play (or\n   resume) full-featured games from\
    \ anywhere on the Internet [12].  An\n   example of this application is Nvidia\
    \ Grid [12].  Another application\n   scenario of this category is broadcast of\
    \ video games played by\n   people over the Internet in real time or for later\
    \ viewing [12].\n   There are many companies, such as Twitch and YY in China,\
    \ that enable\n   game broadcasting [12].  Games typically contain a lot of sharp\
    \ edges\n   and large motion [12].  The main requirements are as follows:\n  \
    \ *  Random access to pictures for game broadcasting;\n   *  Temporal (frame-rate)\
    \ scalability; and\n   *  Error robustness.\n   Support of resolution and quality\
    \ (SNR) scalability is highly\n   desirable.  For this application, typical values\
    \ of resolutions,\n   frame rates, and PAMs are similar to ones presented in Table\
    \ 3.\n"
- title: 3.7.  Video Monitoring and Surveillance
  contents:
  - "3.7.  Video Monitoring and Surveillance\n   This is a type of live broadcasting\
    \ over IP-based networks.  Video\n   streams are sent to many receivers at the\
    \ same time.  A new receiver\n   may connect to the stream at an arbitrary moment,\
    \ so the random\n   access period should be kept small enough (approximately,\
    \ 1-5\n   seconds).  Data are transmitted publicly in the case of video\n   monitoring\
    \ and privately in the case of video surveillance.  For IP\n   cameras that have\
    \ to capture, process, and encode video data,\n   complexity -- including computational\
    \ and hardware complexity, as\n   well as memory bandwidth -- should be kept low\
    \ to allow real-time\n   processing.  In addition, support of a high dynamic range\
    \ and a\n   monochrome mode (e.g., for infrared cameras) as well as resolution\n\
    \   and quality (SNR) scalability is an essential requirement for video\n   surveillance.\
    \  In some use cases, high video signal fidelity is\n   required even after lossy\
    \ compression.  Typical values of\n   resolutions, frame rates, and PAMs for video\
    \ monitoring and\n   surveillance applications are presented in Table 6.\n   \
    \       | Resolution            | Frame Rate, FPS | PAM      |\n          | 2160p\
    \ (4K), 3840x2160 | 12, 25, 30      | RA, FIZD |\n          | 5Mpixels, 2560x1920\
    \   | 12, 25, 30      | RA, FIZD |\n          | 1080p, 1920x1080      | 25, 30\
    \          | RA, FIZD |\n          | 1.23Mpixels, 1280x960 | 25, 30          |\
    \ RA, FIZD |\n          | 720p, 1280x720        | 25, 30          | RA, FIZD |\n\
    \          | SVGA, 800x600         | 25, 30          | RA, FIZD |\n          \
    \     Table 6: Video Monitoring and Surveillance:\n             Typical Values\
    \ of Resolutions, Frame Rates, and\n"
- title: 4.  Requirements
  contents:
  - "4.  Requirements\n   Taking the requirements discussed above for specific video\n\
    \   applications, this section proposes requirements for an Internet\n   video\
    \ codec.\n"
- title: 4.1.  General Requirements
  contents:
  - '4.1.  General Requirements

    '
- title: 4.1.1.  Coding Efficiency
  contents:
  - "4.1.1.  Coding Efficiency\n   The most fundamental requirement is coding efficiency,\
    \ i.e.,\n   compression performance on both \"easy\" and \"difficult\" content\
    \ for\n   applications and use cases in Section 3.  The codec should provide\n\
    \   higher coding efficiency over state-of-the-art video codecs such as\n   HEVC/H.265\
    \ and VP9, at least 25%, in accordance with the methodology\n   described in Section\
    \ 5 of this document.  For higher resolutions, the\n   improvements in coding\
    \ efficiency are expected to be higher than for\n   lower resolutions.\n"
- title: 4.1.2.  Profiles and Levels
  contents:
  - "4.1.2.  Profiles and Levels\n   Good-quality specification and well-defined profiles\
    \ and levels are\n   required to enable device interoperability and facilitate\
    \ decoder\n   implementations.  A profile consists of a subset of entire bitstream\n\
    \   syntax elements; consequently, it also defines the necessary tools\n   for\
    \ decoding a conforming bitstream of that profile.  A level imposes\n   a set\
    \ of numerical limits to the values of some syntax elements.  An\n   example of\
    \ codec levels to be supported is presented in Table 7.  An\n   actual level definition\
    \ should include constraints on features that\n   impact the decoder complexity.\
    \  For example, these features might be\n   as follows: maximum bitrate, line\
    \ buffer size, memory usage, etc.\n   | Level | Example picture resolution at\
    \ highest frame rate          |\n   | 1     | 128x96(12,288*)@30.0           \
    \                           |\n   |       | 176x144(25,344*)@15.0            \
    \                         |\n   | 2     | 352x288(101,376*)@30.0             \
    \                       |\n   | 3     | 352x288(101,376*)@60.0               \
    \                     |\n   |       | 640x360(230,400*)@30.0                 \
    \                   |\n   | 4     | 640x360(230,400*)@60.0                   \
    \                 |\n   |       | 960x540(518,400*)@30.0                     \
    \               |\n   | 5     | 720x576(414,720*)@75.0                       \
    \             |\n   |       | 960x540(518,400*)@60.0                         \
    \           |\n   |       | 1280x720(921,600*)@30.0                          \
    \         |\n   | 6     | 1,280x720(921,600*)@68.0                           \
    \       |\n   |       | 2,048x1,080(2,211,840*)@30.0                         \
    \     |\n   | 7     | 1,280x720(921,600*)@120.0                              \
    \   |\n   | 8     | 1,920x1,080(2,073,600*)@120.0                            \
    \ |\n   |       | 3,840x2,160(8,294,400*)@30.0                              |\n\
    \   |       | 4,096x2,160(8,847,360*)@30.0                              |\n  \
    \ | 9     | 1,920x1,080(2,073,600*)@250.0                             |\n   |\
    \       | 4,096x2,160(8,847,360*)@60.0                              |\n   | 10\
    \    | 1,920x1,080(2,073,600*)@300.0                             |\n   |     \
    \  | 4,096x2,160(8,847,360*)@120.0                             |\n   | 11    |\
    \ 3,840x2,160(8,294,400*)@120.0                             |\n   |       | 8,192x4,320(35,389,440*)@30.0\
    \                             |\n   | 12    | 3,840x2,160(8,294,400*)@250.0  \
    \                           |\n   |       | 8,192x4,320(35,389,440*)@60.0    \
    \                         |\n   | 13    | 3,840x2,160(8,294,400*)@300.0      \
    \                       |\n   |       | 8,192x4,320(35,389,440*)@120.0       \
    \                     |\n                           Table 7: Codec Levels\n  \
    \ *Note: The quantities of pixels are presented for applications in\n   which\
    \ a picture can have an arbitrary size (e.g., screencasting).\n"
- title: 4.1.3.  Bitstream Syntax
  contents:
  - "4.1.3.  Bitstream Syntax\n   Bitstream syntax should allow extensibility and\
    \ backward\n   compatibility.  New features can be supported easily by using\n\
    \   metadata (such as SEI messages, VUI, and headers) without affecting\n   the\
    \ bitstream compatibility with legacy decoders.  A newer version of\n   the decoder\
    \ shall be able to play bitstreams of an older version of\n   the same or lower\
    \ profile and level.\n"
- title: 4.1.4.  Parsing and Identification of Sample Components
  contents:
  - "4.1.4.  Parsing and Identification of Sample Components\n   A bitstream should\
    \ have a model that allows easy parsing and\n   identification of the sample components\
    \ (such as Annex B of ISO/IEC\n   14496-10 [18] or ISO/IEC 14496-15 [19]).  In\
    \ particular, information\n   needed for packet handling (e.g., frame type) should\
    \ not require\n   parsing anything below the header level.\n"
- title: 4.1.5.  Perceptual Quality Tools
  contents:
  - "4.1.5.  Perceptual Quality Tools\n   Perceptual quality tools (such as adaptive\
    \ QP and quantization\n   matrices) should be supported by the codec bitstream.\n"
- title: 4.1.6.  Buffer Model
  contents:
  - "4.1.6.  Buffer Model\n   The codec specification shall define a buffer model\
    \ such as\n   hypothetical reference decoder (HRD).\n"
- title: 4.1.7.  Integration
  contents:
  - "4.1.7.  Integration\n   Specifications providing integration with system and\
    \ delivery layers\n   should be developed.\n"
- title: 4.2.  Basic Requirements
  contents:
  - '4.2.  Basic Requirements

    '
- title: 4.2.1.  Input Source Formats
  contents:
  - "4.2.1.  Input Source Formats\n   Input pictures coded by a video codec should\
    \ have one of the\n   following formats:\n   *  Bit depth: 8 and 10 bits (up to\
    \ 12 bits for a high profile) per\n      color component.\n   *  Color sampling\
    \ formats:\n      -  YCbCr 4:2:0\n      -  YCbCr 4:4:4, YCbCr 4:2:2, and YCbCr\
    \ 4:0:0 (preferably in\n         different profile(s))\n   *  For profiles with\
    \ bit depth of 10 bits per sample or higher,\n      support of high dynamic range\
    \ and wide color gamut.\n   *  Support of arbitrary resolution according to the\
    \ level constraints\n      for applications in which a picture can have an arbitrary\
    \ size\n      (e.g., in screencasting).\n   Exemplary input source formats for\
    \ codec profiles are shown in\n   Table 8.\n   | Profile | Bit depths per color\
    \ component | Color sampling         |\n   | 1       | 8 and 10              \
    \         | 4:0:0 and 4:2:0        |\n   | 2       | 8 and 10                \
    \       | 4:0:0, 4:2:0,          |\n   | 3       | 8, 10, and 12             \
    \     | 4:0:0, 4:2:0,          |\n         Table 8: Exemplary Input Source Formats\
    \ for Codec Profiles\n"
- title: 4.2.2.  Coding Delay
  contents:
  - "4.2.2.  Coding Delay\n   In order to meet coding delay requirements, a video\
    \ codec should\n   support all of the following:\n   *  Support of configurations\
    \ with zero structural delay, also\n      referred to as \"low-delay\" configurations.\n\
    \      -  Note: End-to-end delay should be no more than 320 ms [2], but\n    \
    \     it is preferable for its value to be less than 100 ms [9].\n   *  Support\
    \ of efficient random access point encoding (such as\n      intracoding and resetting\
    \ of context variables), as well as\n      efficient switching between multiple\
    \ quality representations.\n   *  Support of configurations with nonzero structural\
    \ delay (such as\n      out-of-order or multipass encoding) for applications without\
    \ low-\n      delay requirements, if such configurations provide additional\n\
    \      compression efficiency improvements.\n"
- title: 4.2.3.  Complexity
  contents:
  - "4.2.3.  Complexity\n   Encoding and decoding complexity considerations are as\
    \ follows:\n   *  Feasible real-time implementation of both an encoder and a decoder\n\
    \      supporting a chosen subset of tools for hardware and software\n      implementation\
    \ on a wide range of state-of-the-art platforms.  The\n      subset of real-time\
    \ encoder tools should provide meaningful\n      improvement in compression efficiency\
    \ at reasonable complexity of\n      hardware and software encoder implementations\
    \ as compared to real-\n      time implementations of state-of-the-art video compression\n\
    \      technologies such as HEVC/H.265 and VP9.\n   *  High-complexity software\
    \ encoder implementations used by offline\n      encoding applications can have\
    \ a 10x or more complexity increase\n      compared to state-of-the-art video\
    \ compression technologies such\n      as HEVC/H.265 and VP9.\n"
- title: 4.2.4.  Scalability
  contents:
  - "4.2.4.  Scalability\n   The mandatory scalability requirement is as follows:\n\
    \   *  Temporal (frame-rate) scalability should be supported.\n"
- title: 4.2.5.  Error Resilience
  contents:
  - "4.2.5.  Error Resilience\n   In order to meet the error resilience requirement,\
    \ a video codec\n   should satisfy all of the following conditions:\n   *  Tools\
    \ that are complementary to the error-protection mechanisms\n      implemented\
    \ on the transport level should be supported.\n   *  The codec should support\
    \ mechanisms that facilitate packetization\n      of a bitstream for common network\
    \ protocols.\n   *  Packetization mechanisms should enable frame-level error recovery\n\
    \      by means of retransmission or error concealment.\n   *  The codec should\
    \ support effective mechanisms for allowing\n      decoding and reconstruction\
    \ of significant parts of pictures in\n      the event that parts of the picture\
    \ data are lost in transmission.\n   *  The bitstream specification shall support\
    \ independently decodable\n      subframe units similar to slices or independent\
    \ tiles.  It shall\n      be possible for the encoder to restrict the bitstream\
    \ to allow\n      parsing of the bitstream after a packet loss and to communicate\
    \ it\n      to the decoder.\n"
- title: 4.3.  Optional Requirements
  contents:
  - '4.3.  Optional Requirements

    '
- title: 4.3.1.  Input Source Formats
  contents:
  - "4.3.1.  Input Source Formats\n   It is a desired but not mandatory requirement\
    \ for a video codec to\n   support some of the following features:\n   *  Bit\
    \ depth: up to 16 bits per color component.\n   *  Color sampling formats: RGB\
    \ 4:4:4.\n   *  Auxiliary channel (e.g., alpha channel) support.\n"
- title: 4.3.2.  Scalability
  contents:
  - "4.3.2.  Scalability\n   Desirable scalability requirements are as follows:\n\
    \   *  Resolution and quality (SNR) scalability that provides a low-\n      compression\
    \ efficiency penalty (increase of up to 5% of BD-rate\n      [13] per layer with\
    \ reasonable increase of both computational and\n      hardware complexity) can\
    \ be supported in the main profile of the\n      codec being developed by the\
    \ NETVC Working Group.  Otherwise, a\n      separate profile is needed to support\
    \ these types of scalability.\n   *  Computational complexity scalability (i.e.,\
    \ computational\n      complexity is decreasing along with degrading picture quality)\
    \ is\n      desirable.\n"
- title: 4.3.3.  Complexity
  contents:
  - "4.3.3.  Complexity\n   Tools that enable parallel processing (e.g., slices, tiles,\
    \ and wave-\n   front propagation processing) at both encoder and decoder sides\
    \ are\n   highly desirable for many applications.\n   *  High-level multicore\
    \ parallelism: encoder and decoder operation,\n      especially entropy encoding\
    \ and decoding, should allow multiple\n      frames or subframe regions (e.g.,\
    \ 1D slices, 2D tiles, or\n      partitions) to be processed concurrently, either\
    \ independently or\n      with deterministic dependencies that can be efficiently\
    \ pipelined.\n   *  Low-level instruction-set parallelism: favor algorithms that\
    \ are\n      SIMD/GPU friendly over inherently serial algorithms\n"
- title: 4.3.4.  Coding Efficiency
  contents:
  - "4.3.4.  Coding Efficiency\n   Compression efficiency on noisy content, content\
    \ with film grain,\n   computer generated content, and low resolution materials\
    \ is\n   desirable.\n"
- title: 5.  Evaluation Methodology
  contents:
  - "5.  Evaluation Methodology\n   As shown in Figure 1, compression performance\
    \ testing is performed in\n   three overlapped ranges that encompass ten different\
    \ bitrate values:\n   *  Low bitrate range (LBR) is the range that contains the\
    \ four lowest\n      bitrates of the ten specified bitrates (one of the four bitrate\n\
    \      values is shared with the neighboring range).\n   *  Medium bitrate range\
    \ (MBR) is the range that contains the four\n      medium bitrates of the ten\
    \ specified bitrates (two of the four\n      bitrate values are shared with the\
    \ neighboring ranges).\n   *  High bitrate range (HBR) is the range that contains\
    \ the four\n      highest bitrates of the ten specified bitrates (one of the four\n\
    \      bitrate values is shared with the neighboring range).\n   Initially, for\
    \ the codec selected as a reference one (e.g., HEVC or\n   VP9), a set of ten\
    \ QP (quantization parameter) values should be\n   specified as in [14], and corresponding\
    \ quality values should be\n   calculated.  In Figure 1, QP and quality values\
    \ are denoted as\n   \"QP0\"-\"QP9\" and \"Q0\"-\"Q9\", respectively.  To guarantee\
    \ the overlaps\n   of quality levels between the bitrate ranges of the reference\
    \ and\n   tested codecs, a quality alignment procedure should be performed for\n\
    \   each range's outermost (left- and rightmost) quality levels Qk of the\n  \
    \ reference codec (i.e., for Q0, Q3, Q6, and Q9) and the quality levels\n   Q'k\
    \ (i.e., Q'0, Q'3, Q'6, and Q'9) of the tested codec.  Thus, these\n   quality\
    \ levels Q'k, and hence the corresponding QP value QP'k (i.e.,\n   QP'0, QP'3,\
    \ QP'6, and QP'9), of the tested codec should be selected\n   using the following\
    \ formulas:\n   Q'k =   min { abs(Q'i - Qk) },\n         i in R\n   QP'k = argmin\
    \ { abs(Q'i(QP'i) - Qk(QPk)) },\n          i in R\n   where R is the range of\
    \ the QP indexes of the tested codec, i.e., the\n   candidate Internet video codec.\
    \  The inner quality levels (i.e., Q'1,\n   Q'2, Q'4, Q'5, Q'7, and Q'8), as well\
    \ as their corresponding QP\n   values of each range (i.e., QP'1, QP'2, QP'4,\
    \ QP'5, QP'7, and QP'8),\n   should be as equidistantly spaced as possible between\
    \ the left- and\n   rightmost quality levels without explicitly mapping their\
    \ values\n   using the procedure described above.\n   QP'9 QP'8  QP'7 QP'6 QP'5\
    \ QP'4 QP'3 QP'2 QP'1 QP'0 <+-----\n   Q'0   Q'1  Q'2  Q'3  Q'4  Q'5  Q'6  Q'7\
    \  Q'8  Q'9  <+-----\n   Q0    Q1    Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  <+-----\n\
    \   QP9  QP8   QP7  QP6  QP5  QP4  QP3  QP2  QP1  QP0  <+-----\n   |-------LBR------|\
    \              |-----HBR------|\n                    |------MBR-----|\n   Figure\
    \ 1: Quality/QP Alignment for Compression Performance Evaluation\n   Since the\
    \ QP mapping results may vary for different sequences, this\n   quality alignment\
    \ procedure eventually needs to be performed\n   separately for each quality assessment\
    \ index and each sequence used\n   for codec performance evaluation to fulfill\
    \ the requirements\n   described above.\n   To assess the quality of output (decoded)\
    \ sequences, two indexes\n   (PSNR [3] and MS-SSIM [3] [15]) are separately computed.\
    \  In the case\n   of the YCbCr color format, PSNR should be calculated for each\
    \ color\n   plane, whereas MS-SSIM is calculated for the luma channel only.  In\n\
    \   the case of the RGB color format, both metrics are computed for R, G,\n  \
    \ and B channels.  Thus, for each sequence, 30 RD-points for PSNR\n   (i.e., three\
    \ RD-curves, one for each channel) and 10 RD-points for\n   MS-SSIM (i.e., one\
    \ RD-curve, for luma channel only) should be\n   calculated in the case of YCbCr.\
    \  If content is encoded as RGB, 60\n   RD-points (30 for PSNR and 30 for MS-SSIM)\
    \ should be calculated\n   (i.e., three RD-curves, one for each channel) are computed\
    \ for PSNR\n   as well as three RD-curves (one for each channel) for MS-SSIM.\n\
    \   Finally, to obtain an integral estimation, BD-rate savings [13]\n   should\
    \ be computed for each range and each quality index.  In\n   addition, average\
    \ values over all three ranges should be provided for\n   both PSNR and MS-SSIM.\
    \  A list of video sequences that should be used\n   for testing, as well as the\
    \ ten QP values for the reference codec,\n   are defined in [14].  Testing processes\
    \ should use the information on\n   the codec applications presented in this document.\
    \  As the reference\n   for evaluation, state-of-the-art video codecs such as\
    \ HEVC/H.265\n   [4][5] or VP9 must be used.  The reference source code of the\
    \ HEVC/\n   H.265 codec can be found at [6].  The HEVC/H.265 codec must be\n \
    \  configured according to [16] and Table 9.\n   | Intra-period, second | HEVC/H.265\
    \ encoding                        |\n   |                      | mode according\
    \ to [16]                     |\n   | AI                   | Intra Main or Intra\
    \                        |\n   |                      | Main10               \
    \                      |\n   | RA                   | Random access Main or  \
    \                    |\n   |                      | Random access Main10     \
    \                  |\n   | FIZD                 | Low delay Main or          \
    \                |\n   |                      | Low delay Main10             \
    \              |\n       Table 9: Intraperiods for Different HEVC/H.265 Encoding\
    \ Modes\n                             According to [16]\n   According to the coding\
    \ efficiency requirement described in\n   Section 4.1.1, BD-rate savings calculated\
    \ for each color plane and\n   averaged for all the video sequences used to test\
    \ the NETVC codec\n   should be, at least,\n   *  25% if calculated over the whole\
    \ bitrate range; and\n   *  15% if calculated for each bitrate subrange (LBR,\
    \ MBR, HBR).\n   Since values of the two objective metrics (PSNR and MS-SSIM)\
    \ are\n   available for some color planes, each value should meet these coding\n\
    \   efficiency requirements.  That is, the final BD-rate saving denoted\n   as\
    \ S is calculated for a given color plane as follows:\n   S = min { S_psnr, S_ms-ssim\
    \ }\n   where S_psnr and S_ms-ssim are BD-rate savings calculated for the\n  \
    \ given color plane using PSNR and MS-SSIM metrics, respectively.\n   In addition\
    \ to the objective quality measures defined above,\n   subjective evaluation must\
    \ also be performed for the final NETVC\n   codec adoption.  For subjective tests,\
    \ the MOS-based evaluation\n   procedure must be used as described in Section\
    \ 2.1 of [3].  For\n   perception-oriented tools that primarily impact subjective\
    \ quality,\n   additional tests may also be individually assigned even for\n \
    \  intermediate evaluation, subject to a decision of the NETVC WG.\n"
- title: 6.  Security Considerations
  contents:
  - "6.  Security Considerations\n   This document itself does not address any security\
    \ considerations.\n   However, it is worth noting that a codec implementation\
    \ (for both an\n   encoder and a decoder) should take into consideration the worst-case\n\
    \   computational complexity, memory bandwidth, and physical memory size\n   needed\
    \ to process the potentially untrusted input (e.g., the decoded\n   pictures used\
    \ as references).\n"
- title: 7.  IANA Considerations
  contents:
  - "7.  IANA Considerations\n   This document has no IANA actions.\n"
- title: 8.  References
  contents:
  - '8.  References

    '
- title: 8.1.  Normative References
  contents:
  - "8.1.  Normative References\n   [1]        ITU-R, \"Parameter values for ultra-high\
    \ definition\n              television systems for production and international\n\
    \              programme exchange\", ITU-R Recommendation BT.2020-2,\n       \
    \       October 2015,\n              <https://www.itu.int/rec/R-REC-BT.2020-2-201510-I/en>.\n\
    \   [2]        ITU-T, \"Quality of Experience requirements for\n             \
    \ telepresence services\", ITU-T Recommendation G.1091,\n              October\
    \ 2014, <https://www.itu.int/rec/T-REC-G.1091/en>.\n   [3]        ISO, \"Information\
    \ technology -- Advanced image coding and\n              evaluation -- Part 1:\
    \ Guidelines for image coding system\n              evaluation\", ISO/IEC TR 29170-1:2017,\
    \ October 2017,\n              <https://www.iso.org/standard/63637.html>.\n  \
    \ [4]        ISO, \"Information technology -- High efficiency coding and\n   \
    \           media delivery in heterogeneous environments -- Part 2:\n        \
    \      High efficiency video coding\", ISO/IEC 23008-2:2015, May\n           \
    \   2018, <https://www.iso.org/standard/67660.html>.\n   [5]        ITU-T, \"\
    High efficiency video coding\", ITU-T\n              Recommendation H.265, November\
    \ 2019,\n              <https://www.itu.int/rec/T-REC-H.265>.\n   [6]        Fraunhofer\
    \ Institute for Telecommunications, \"High\n              Efficiency Video Coding\
    \ (HEVC) reference software (HEVC\n              Test Model also known as HM)\"\
    ,\n              <https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/>.\n"
- title: 8.2.  Informative References
  contents:
  - "8.2.  Informative References\n   [7]        Federal Agencies Digital Guidelines\
    \ Initiative, \"Term:\n              High dynamic range imaging\",\n         \
    \     <http://www.digitizationguidelines.gov/\n              term.php?term=highdynamicrangeimaging>.\n\
    \   [8]        Federal Agencies Digital Guidelines Initiative, \"Term:\n     \
    \         Compression, visually lossless\",\n              <http://www.digitizationguidelines.gov/\n\
    \              term.php?term=compressionvisuallylossless>.\n   [9]        Wenger,\
    \ S., \"The case for scalability support in version 1\n              of Future\
    \ Video Coding\", SG 16 (Study Period\n              2013) Contribution 988, September\
    \ 2015,\n              <https://www.itu.int/md/T13-SG16-C-0988/en>.\n   [10] \
    \      YouTube, \"Recommended upload encoding settings\",\n              <https://support.google.com/youtube/answer/1722171?hl=en>.\n\
    \   [11]       Yu, H., Ed., McCann, K., Ed., Cohen, R., Ed., and P. Amon,\n  \
    \            Ed., \"Requirements for an extension of HEVC for coding of\n    \
    \          screen content\", ISO/IEC JTC 1/SC 29/WG 11 Moving Picture\n      \
    \        Experts Group MPEG2013/N14174, San Jose, USA, January\n             \
    \ 2014, <https://mpeg.chiariglione.org/standards/mpeg-h/\n              high-efficiency-video-coding/requirements-extension-hevc-\n\
    \              coding-screen-content>.\n   [12]       Parhy, M., \"Game streaming\
    \ requirement for Future Video\n              Coding\", ISO/IEC JTC 1/SC 29/WG\
    \ 11 Moving Picture Experts\n              Group N36771, Warsaw, Poland, June\
    \ 2015.\n   [13]       Bjontegaard, G., \"Calculation of average PSNR differences\n\
    \              between RD-curves\", SG 16 VCEG-M33, April 2001,\n            \
    \  <https://www.itu.int/wftp3/av-arch/video-site/0104_Aus/>.\n   [14]       Daede,\
    \ T., Norkin, A., and I. Brailovskiy, \"Video Codec\n              Testing and\
    \ Quality Measurement\", Work in Progress,\n              Internet-Draft, draft-ietf-netvc-testing-09,\
    \ 31 January\n              2020,\n              <https://tools.ietf.org/html/draft-ietf-netvc-testing-09>.\n\
    \   [15]       Wang, Z., Simoncelli, E.P., and A.C. Bovik, \"Multiscale\n    \
    \          structural similarity for image quality assessment\", IEEE \n     \
    \         Thirty-Seventh Asilomar Conference on Signals, Systems and\n       \
    \       Computers, DOI 10.1109/ACSSC.2003.1292216, November 2003,\n          \
    \    <https://ieeexplore.ieee.org/document/1292216>.\n   [16]       Bossen, F.,\
    \ \"Common HM test conditions and software\n              reference configurations\"\
    , Joint Collaborative Team on\n              Video Coding (JCT-VC) of the ITU-T\
    \ Video Coding Experts\n              Group (ITU-T Q.6/SG 16) and ISO/IEC Moving\
    \ Picture Experts\n              Group (ISO/IEC JTC 1/SC 29/WG 11) , Document\
    \ JCTVC-L1100,\n              April 2013, <http://phenix.it-\n              sudparis.eu/jct/doc_end_user/\n\
    \              current_document.php?id=7281>.\n   [17]       ITU-R, \"Studio encoding\
    \ parameters of digital television\n              for standard 4:3 and wide screen\
    \ 16:9 aspect ratios\",\n              ITU-R Recommendation BT.601, March 2011,\n\
    \              <https://www.itu.int/rec/R-REC-BT.601/>.\n   [18]       ISO/IEC,\
    \ \"Information technology -- Coding of audio-visual\n              objects --\
    \ Part 10: Advanced video coding\", ISO/IEC\n              DIS 14496-10, <https://www.iso.org/standard/75400.html>.\n\
    \   [19]       ISO/IEC, \"Information technology -- Coding of audio-visual\n \
    \             objects -- Part 15: Carriage of network abstraction layer\n    \
    \          (NAL) unit structured video in the ISO base media file\n          \
    \    format\", ISO/IEC 14496-15,\n              <https://www.iso.org/standard/74429.html>.\n\
    \   [20]       ITU-R, \"Parameter values for the HDTV standards for\n        \
    \      production and international programme exchange\", ITU-R\n            \
    \  Recommendation BT.709, June 2015,\n              <https://www.itu.int/rec/R-REC-BT.709>.\n"
- title: Acknowledgments
  contents:
  - "Acknowledgments\n   The authors would like to thank Mr. Paul Coverdale, Mr. Vasily\n\
    \   Rufitskiy, and Dr. Jianle Chen for many useful discussions on this\n   document\
    \ and their help while preparing it, as well as Mr. Mo Zanaty,\n   Dr. Minhua\
    \ Zhou, Dr. Ali Begen, Mr. Thomas Daede, Mr. Adam Roach,\n   Dr. Thomas Davies,\
    \ Mr. Jonathan Lennox, Dr. Timothy Terriberry,\n   Mr. Peter Thatcher, Dr. Jean-Marc\
    \ Valin, Mr. Roman Danyliw, Mr. Jack\n   Moffitt, Mr. Greg Coppa, and Mr. Andrew\
    \ Krupiczka for their valuable\n   comments on different revisions of this document.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Alexey Filippov\n   Huawei Technologies\n   Email: alexey.filippov@huawei.com\n\
    \   Andrey Norkin\n   Netflix\n   Email: anorkin@netflix.com\n   Jose Roberto\
    \ Alvarez\n"
