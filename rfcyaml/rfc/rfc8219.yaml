- title: __initial_text__
  contents:
  - '       Benchmarking Methodology for IPv6 Transition Technologies

    '
- title: Abstract
  contents:
  - "Abstract\n   Benchmarking methodologies that address the performance of network\n\
    \   interconnect devices that are IPv4- or IPv6-capable exist, but the\n   IPv6\
    \ transition technologies are outside of their scope.  This\n   document provides\
    \ complementary guidelines for evaluating the\n   performance of IPv6 transition\
    \ technologies.  More specifically, this\n   document targets IPv6 transition\
    \ technologies that employ\n   encapsulation or translation mechanisms, as dual-stack\
    \ nodes can be\n   tested using the recommendations of RFCs 2544 and 5180.  The\n\
    \   methodology also includes a metric for benchmarking load scalability.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 7841.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc8219.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2017 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \      1.1. IPv6 Transition Technologies ...............................4\n  \
    \ 2. Conventions Used in This Document ...............................6\n   3.\
    \ Terminology .....................................................7\n   4. Test\
    \ Setup ......................................................7\n      4.1. Single-Translation\
    \ Transition Technologies .................8\n      4.2. Encapsulation and Double-Translation\
    \ Transition\n           Technologies ...............................................8\n\
    \   5. Test Traffic ....................................................9\n  \
    \    5.1. Frame Formats and Sizes ....................................9\n    \
    \       5.1.1. Frame Sizes to Be Used over Ethernet ...............10\n      5.2.\
    \ Protocol Addresses ........................................10\n      5.3. Traffic\
    \ Setup .............................................10\n   6. Modifiers ......................................................11\n\
    \   7. Benchmarking Tests .............................................11\n  \
    \    7.1. Throughput ................................................11\n    \
    \  7.2. Latency ...................................................11\n      7.3.\
    \ Packet Delay Variation ....................................13\n           7.3.1.\
    \ PDV ................................................13\n           7.3.2. IPDV\
    \ ...............................................14\n      7.4. Frame Loss Rate\
    \ ...........................................15\n      7.5. Back-to-Back Frames\
    \ .......................................15\n      7.6. System Recovery ...........................................15\n\
    \      7.7. Reset .....................................................15\n  \
    \ 8. Additional Benchmarking Tests for Stateful IPv6 Transition\n      Technologies\
    \ ...................................................15\n      8.1. Concurrent\
    \ TCP Connection Capacity ........................15\n      8.2. Maximum TCP Connection\
    \ Establishment Rate .................15\n   9. DNS Resolution Performance .....................................15\n\
    \      9.1. Test and Traffic Setup ....................................16\n  \
    \    9.2. Benchmarking DNS Resolution Performance ...................17\n    \
    \       9.2.1. Requirements for the Tester ........................18\n   10.\
    \ Overload Scalability ..........................................19\n      10.1.\
    \ Test Setup ...............................................19\n           10.1.1.\
    \ Single-Translation Transition Technologies ........19\n           10.1.2. Encapsulation\
    \ and Double-Translation\n                   Transition Technologies ...........................20\n\
    \      10.2. Benchmarking Performance Degradation .....................21\n  \
    \         10.2.1. Network Performance Degradation with\n                   Simultaneous\
    \ Load .................................21\n           10.2.2. Network Performance\
    \ Degradation with\n                   Incremental Load ..................................22\n\
    \   11. NAT44 and NAT66 ...............................................22\n  \
    \ 12. Summarizing Function and Variation ............................23\n   13.\
    \ Security Considerations .......................................23\n   14. IANA\
    \ Considerations ...........................................24\n   15. References\
    \ ....................................................24\n      15.1. Normative\
    \ References .....................................24\n      15.2. Informative\
    \ References ...................................25\n   Appendix A. Theoretical\
    \ Maximum Frame Rates........................29\n   Acknowledgements...................................................30\n\
    \   Authors' Addresses ................................................30\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The methodologies described in [RFC2544] and [RFC5180] help\
    \ vendors\n   and network operators alike analyze the performance of IPv4 and\n\
    \   IPv6-capable network devices.  The methodology presented in [RFC2544]\n  \
    \ is mostly IP version independent, while [RFC5180] contains\n   complementary\
    \ recommendations that are specific to the latest IP\n   version, IPv6.  However,\
    \ [RFC5180] does not cover IPv6 transition\n   technologies.\n   IPv6 is not backwards\
    \ compatible, which means that IPv4-only nodes\n   cannot directly communicate\
    \ with IPv6-only nodes.  To solve this\n   issue, IPv6 transition technologies\
    \ have been proposed and\n   implemented.\n   This document presents benchmarking\
    \ guidelines dedicated to IPv6\n   transition technologies.  The benchmarking\
    \ tests can provide insights\n   about the performance of these technologies,\
    \ which can act as useful\n   feedback for developers and network operators going\
    \ through the IPv6\n   transition process.\n   The document also includes an approach\
    \ to quantify performance when\n   operating in overload.  Overload scalability\
    \ can be defined as a\n   system's ability to gracefully accommodate a greater\
    \ number of flows\n   than the maximum number of flows that the Device Under Test\
    \ (DUT) can\n   operate normally.  The approach taken here is to quantify the\n\
    \   overload scalability by measuring the performance created by an\n   excessive\
    \ number of network flows and comparing performance to the\n   non-overloaded\
    \ case.\n"
- title: 1.1.  IPv6 Transition Technologies
  contents:
  - "1.1.  IPv6 Transition Technologies\n   Two of the basic transition technologies,\
    \ dual IP layer (also known\n   as dual stack) and encapsulation, are presented\
    \ in [RFC4213].\n   IPv4/IPv6 translation is presented in [RFC6144].  Most of\
    \ the\n   transition technologies employ at least one variation of these\n   mechanisms.\
    \  In this context, a generic classification of the\n   transition technologies\
    \ can prove useful.\n   We can consider a production network transitioning to\
    \ IPv6 as being\n   constructed using the following IP domains:\n   o  Domain\
    \ A: IPvX-specific domain\n   o  Core domain: IPvY-specific or dual-stack (IPvX\
    \ and IPvY) domain\n   o  Domain B: IPvX-specific domain\n   Note: X,Y are part\
    \ of the set {4,6}, and X is NOT EQUAL to Y.\n   The transition technologies can\
    \ be categorized according to the\n   technology used for traversal of the core\
    \ domain:\n   1.  Dual stack: Devices in the core domain implement both IP\n \
    \      protocols.\n   2.  Single translation: In this case, the production network\
    \ is\n       assumed to have only two domains: Domain A and the core domain.\n\
    \       The core domain is assumed to be IPvY specific.  IPvX packets are\n  \
    \     translated to IPvY at the edge between Domain A and the core\n       domain.\n\
    \   3.  Double translation: The production network is assumed to have all\n  \
    \     three domains; Domains A and B are IPvX specific, while the core\n     \
    \  domain is IPvY specific.  A translation mechanism is employed for\n       the\
    \ traversal of the core network.  The IPvX packets are\n       translated to IPvY\
    \ packets at the edge between Domain A and the\n       core domain.  Subsequently,\
    \ the IPvY packets are translated back\n       to IPvX at the edge between the\
    \ core domain and Domain B.\n   4.  Encapsulation: The production network is assumed\
    \ to have all\n       three domains; Domains A and B are IPvX specific, while\
    \ the core\n       domain is IPvY specific.  An encapsulation mechanism is used\
    \ to\n       traverse the core domain.  The IPvX packets are encapsulated to\n\
    \       IPvY packets at the edge between Domain A and the core domain.\n     \
    \  Subsequently, the IPvY packets are de-encapsulated at the edge\n       between\
    \ the core domain and Domain B.\n   The performance of dual-stack transition technologies\
    \ can be fully\n   evaluated using the benchmarking methodologies presented by\
    \ [RFC2544]\n   and [RFC5180].  Consequently, this document focuses on the other\n\
    \   three categories: single-translation, double-translation, and\n   encapsulation\
    \ transition technologies.\n   Another important aspect by which IPv6 transition\
    \ technologies can be\n   categorized is their use of stateful or stateless mapping\
    \ algorithms.\n   The technologies that use stateful mapping algorithms (e.g.,\
    \ Stateful\n   NAT64 [RFC6146]) create dynamic correlations between IP addresses\
    \ or\n   {IP address, transport protocol, transport port number} tuples, which\n\
    \   are stored in a state table.  For ease of reference, IPv6 transition\n   technologies\
    \ that employ stateful mapping algorithms will be called\n   \"stateful IPv6 transition\
    \ technologies\".  The efficiency with which\n   the state table is managed can\
    \ be an important performance indicator\n   for these technologies.  Hence, additional\
    \ benchmarking tests are\n   RECOMMENDED for stateful IPv6 transition technologies.\n\
    \   Table 1 contains the generic categories and associations with some of\n  \
    \ the IPv6 transition technologies proposed in the IETF.  Please note\n   that\
    \ the list is not exhaustive.\n      +---+--------------------+------------------------------------+\n\
    \      |   | Generic category   | IPv6 Transition Technology         |\n     \
    \ +---+--------------------+------------------------------------+\n      | 1 |\
    \ Dual stack         | Dual IP Layer Operations [RFC4213] |\n      +---+--------------------+------------------------------------+\n\
    \      | 2 | Single translation | NAT64 [RFC6146], IVI [RFC6219]     |\n     \
    \ +---+--------------------+------------------------------------+\n      | 3 |\
    \ Double translation | 464XLAT [RFC6877], MAP-T [RFC7599] |\n      +---+--------------------+------------------------------------+\n\
    \      | 4 | Encapsulation      | DS-Lite [RFC6333], MAP-E [RFC7597],|\n     \
    \ |   |                    | Lightweight 4over6 [RFC7596],      |\n      |   |\
    \                    | 6rd [RFC5569], 6PE [RFC4798],      |\n      |   |     \
    \               | 6VPE [RFC4659]                     |\n      +---+--------------------+------------------------------------+\n\
    \            Table 1: IPv6 Transition Technologies Categories\n"
- title: 2.  Conventions Used in This Document
  contents:
  - "2.  Conventions Used in This Document\n   The key words \"MUST\", \"MUST NOT\"\
    , \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"NOT RECOMMENDED\", \"MAY\", and\n   \"OPTIONAL\" in this document are to be\
    \ interpreted as described in BCP\n   14 [RFC2119] [RFC8174] when, and only when,\
    \ they appear in all\n   capitals, as shown here.\n   Although these terms are\
    \ usually associated with protocol\n   requirements, in this document, the terms\
    \ are requirements for users\n   and systems that intend to implement the test\
    \ conditions and claim\n   conformance with this specification.\n"
- title: 3.  Terminology
  contents:
  - "3.  Terminology\n   A number of terms used in this memo have been defined in\
    \ other RFCs.\n   Please refer to the RFCs below for definitions, testing procedures,\n\
    \   and reporting formats.\n   o  Throughput (Benchmark) [RFC2544]\n   o  Frame\
    \ Loss Rate (Benchmark) [RFC2544]\n   o  Back-to-Back Frames (Benchmark) [RFC2544]\n\
    \   o  System Recovery (Benchmark) [RFC2544]\n   o  Reset (Benchmark) [RFC6201]\n\
    \   o  Concurrent TCP Connection Capacity (Benchmark) [RFC3511]\n   o  Maximum\
    \ TCP Connection Establishment Rate (Benchmark) [RFC3511]\n"
- title: 4.  Test Setup
  contents:
  - "4.  Test Setup\n   The test environment setup options recommended for benchmarking\
    \ IPv6\n   transition technologies are very similar to the ones presented in\n\
    \   Section 6 of [RFC2544].  In the case of the Tester setup, the options\n  \
    \ presented in [RFC2544] and [RFC5180] can be applied here as well.\n   However,\
    \ the DUT setup options should be explained in the context of\n   the targeted\
    \ categories of IPv6 transition technologies: single\n   translation, double translation,\
    \ and encapsulation.\n   Although both single Tester and sender/receiver setups\
    \ are applicable\n   to this methodology, the single Tester setup will be used\
    \ to describe\n   the DUT setup options.\n   For the test setups presented in\
    \ this memo, dynamic routing SHOULD be\n   employed.  However, the presence of\
    \ routing and management frames can\n   represent unwanted background data that\
    \ can affect the benchmarking\n   result.  To that end, the procedures defined\
    \ in Sections 11.2 and\n   11.3 of [RFC2544] related to routing and management\
    \ frames SHOULD be\n   used here.  Moreover, the \"trial description\" recommendations\n\
    \   presented in Section 23 of [RFC2544] are also valid for this memo.\n   In\
    \ terms of route setup, the recommendations of Section 13 of\n   [RFC2544] are\
    \ valid for this document, assuming that IPv6-capable\n   routing protocols are\
    \ used.\n"
- title: 4.1.  Single-Translation Transition Technologies
  contents:
  - "4.1.  Single-Translation Transition Technologies\n   For the evaluation of single-translation\
    \ transition technologies, a\n   single DUT setup (see Figure 1) SHOULD be used.\
    \  The DUT is\n   responsible for translating the IPvX packets into IPvY packets.\
    \  In\n   this context, the Tester device SHOULD be configured to support both\n\
    \   IPvX and IPvY.\n                           +--------------------+\n      \
    \                     |                    |\n              +------------|IPvX\
    \   Tester   IPvY|<-------------+\n              |            |              \
    \      |              |\n              |            +--------------------+   \
    \           |\n              |                                               \
    \ |\n              |            +--------------------+              |\n      \
    \        |            |                    |              |\n              +----------->|IPvX\
    \     DUT    IPvY|--------------+\n                           |              \
    \      |\n                           +--------------------+\n                \
    \        Figure 1: Test Setup 1 (Single DUT)\n"
- title: 4.2.  Encapsulation and Double-Translation Transition Technologies
  contents:
  - "4.2.  Encapsulation and Double-Translation Transition Technologies\n   For evaluating\
    \ the performance of encapsulation and double-\n   translation transition technologies,\
    \ a dual DUT setup (see Figure 2)\n   SHOULD be employed.  The Tester creates\
    \ a network flow of IPvX\n   packets.  The first DUT is responsible for the encapsulation\
    \ or\n   translation of IPvX packets into IPvY packets.  The IPvY packets are\n\
    \   de-encapsulated/translated back to IPvX packets by the second DUT and\n  \
    \ forwarded to the Tester.\n                           +--------------------+\n\
    \                           |                    |\n     +---------------------|IPvX\
    \   Tester   IPvX|<------------------+\n     |                     |         \
    \           |                   |\n     |                     +--------------------+\
    \                   |\n     |                                                \
    \              |\n     |      +--------------------+      +--------------------+\
    \      |\n     |      |                    |      |                    |     \
    \ |\n     +----->|IPvX    DUT 1  IPvY |----->|IPvY   DUT 2   IPvX |------+\n \
    \           |                    |      |                    |\n            +--------------------+\
    \      +--------------------+\n                         Figure 2: Test Setup 2\
    \ (Dual DUT)\n   One of the limitations of the dual DUT setup is the inability\
    \ to\n   reflect asymmetries in behavior between the DUTs.  Considering this,\n\
    \   additional performance tests SHOULD be performed using the single DUT\n  \
    \ setup.\n   Note: For encapsulation IPv6 transition technologies in the single\n\
    \   DUT setup, the Tester SHOULD be able to send IPvX packets\n   encapsulated\
    \ as IPvY in order to test the de-encapsulation\n   efficiency.\n"
- title: 5.  Test Traffic
  contents:
  - "5.  Test Traffic\n   The test traffic represents the experimental workload and\
    \ SHOULD meet\n   the requirements specified in this section.  The requirements\
    \ are\n   dedicated to unicast IP traffic.  Multicast IP traffic is outside of\n\
    \   the scope of this document.\n"
- title: 5.1.  Frame Formats and Sizes
  contents:
  - "5.1.  Frame Formats and Sizes\n   [RFC5180] describes the frame size requirements\
    \ for two commonly used\n   media types: Ethernet and SONET (Synchronous Optical\
    \ Network).\n   [RFC2544] also covers other media types, such as token ring and\
    \ Fiber\n   Distributed Data Interface (FDDI).  The recommendations of those two\n\
    \   documents can be used for the dual-stack transition technologies.\n   For\
    \ the rest of the transition technologies, the frame overhead\n   introduced by\
    \ translation or encapsulation MUST be considered.\n   The encapsulation/translation\
    \ process generates different size frames\n   on different segments of the test\
    \ setup.  For instance, the single-\n   translation transition technologies will\
    \ create different frame sizes\n   on the receiving segment of the test setup,\
    \ as IPvX packets are\n   translated to IPvY.  This is not a problem if the bandwidth\
    \ of the\n   employed media is not exceeded.  To prevent exceeding the limitations\n\
    \   imposed by the media, the frame size overhead needs to be taken into\n   account\
    \ when calculating the maximum theoretical frame rates.  The\n   calculation method\
    \ for the Ethernet, as well as a calculation\n   example, are detailed in Appendix\
    \ A.  The details of the media\n   employed for the benchmarking tests MUST be\
    \ noted in all test\n   reports.\n   In the context of frame size overhead, MTU\
    \ recommendations are needed\n   in order to avoid frame loss due to MTU mismatch\
    \ between the virtual\n   encapsulation/translation interfaces and the physical\
    \ network\n   interface controllers (NICs).  To avoid this situation, the larger\n\
    \   MTU between the physical NICs and virtual encapsulation/translation\n   interfaces\
    \ SHOULD be set for all interfaces of the DUT and Tester.\n   To be more specific,\
    \ the minimum IPv6 MTU size (1280 bytes) plus the\n   encapsulation/translation\
    \ overhead is the RECOMMENDED value for the\n   physical interfaces as well as\
    \ virtual ones.\n"
- title: 5.1.1.  Frame Sizes to Be Used over Ethernet
  contents:
  - "5.1.1.  Frame Sizes to Be Used over Ethernet\n   Based on the recommendations\
    \ of [RFC5180], the following frame sizes\n   SHOULD be used for benchmarking\
    \ IPvX/IPvY traffic on Ethernet links:\n   64, 128, 256, 512, 768, 1024, 1280,\
    \ 1518, 1522, 2048, 4096, 8192, and\n   9216.\n   For Ethernet frames exceeding\
    \ 1500 bytes in size, the [IEEE802.1AC]\n   standard can be consulted.\n   Note:\
    \ For single-translation transition technologies (e.g., NAT64) in\n   the IPv6\
    \ -> IPv4 translation direction, 64-byte frames SHOULD be\n   replaced by 84-byte\
    \ frames.  This would allow the frames to be\n   transported over media such as\
    \ the ones described by the [IEEE802.1Q]\n   standard.  Moreover, this would also\
    \ allow the implementation of a\n   frame identifier in the UDP data.\n   The\
    \ theoretical maximum frame rates considering an example of frame\n   overhead\
    \ are presented in Appendix A.\n"
- title: 5.2.  Protocol Addresses
  contents:
  - "5.2.  Protocol Addresses\n   The selected protocol addresses should follow the\
    \ recommendations of\n   Section 5 of [RFC5180] for IPv6 and Section 12 of [RFC2544]\
    \ for IPv4.\n   Note: Testing traffic with extension headers might not be possible\n\
    \   for the transition technologies that employ translation.  Proposed\n   IPvX/IPvY\
    \ translation algorithms such as IP/ICMP translation\n   [RFC7915] do not support\
    \ the use of extension headers.\n"
- title: 5.3.  Traffic Setup
  contents:
  - "5.3.  Traffic Setup\n   Following the recommendations of [RFC5180], all tests\
    \ described\n   SHOULD be performed with bidirectional traffic.  Unidirectional\n\
    \   traffic tests MAY also be performed for a fine-grained performance\n   assessment.\n\
    \   Because of the simplicity of UDP, UDP measurements offer a more\n   reliable\
    \ basis for comparison than other transport-layer protocols.\n   Consequently,\
    \ for the benchmarking tests described in Section 7 of\n   this document, UDP\
    \ traffic SHOULD be employed.\n   Considering that a transition technology could\
    \ process both native\n   IPv6 traffic and translated/encapsulated traffic, the\
    \ following\n   traffic setups are recommended:\n   i)   IPvX only traffic (where\
    \ the IPvX traffic is to be\n        translated/encapsulated by the DUT)\n   ii)\
    \  90% IPvX traffic and 10% IPvY native traffic\n   iii) 50% IPvX traffic and\
    \ 50% IPvY native traffic\n   iv)  10% IPvX traffic and 90% IPvY native traffic\n\
    \   For the benchmarks dedicated to stateful IPv6 transition\n   technologies,\
    \ included in Section 8 of this memo (Concurrent TCP\n   Connection Capacity and\
    \ Maximum TCP Connection Establishment Rate),\n   the traffic SHOULD follow the\
    \ recommendations of Sections 5.2.2.2 and\n   5.3.2.2 of [RFC3511].\n"
- title: 6. Modifiers
  contents:
  - "6. Modifiers\n   The idea of testing under different operational conditions was\
    \ first\n   introduced in Section 11 of [RFC2544] and represents an important\n\
    \   aspect of benchmarking network elements, as it emulates, to some\n   extent,\
    \ the conditions of a production environment.  Section 6 of\n   [RFC5180] describes\
    \ complementary test conditions specific to IPv6.\n   The recommendations in [RFC2544]\
    \ and [RFC5180] can also be followed\n   for testing of IPv6 transition technologies.\n"
- title: 7.  Benchmarking Tests
  contents:
  - "7.  Benchmarking Tests\n   The following sub-sections describe all recommended\
    \ benchmarking\n   tests.\n"
- title: 7.1.  Throughput
  contents:
  - "7.1.  Throughput\n   Use Section 26.1 of [RFC2544] unmodified.\n"
- title: 7.2.  Latency
  contents:
  - "7.2.  Latency\n   Objective: To determine the latency.  Typical latency is based\
    \ on the\n   definitions of latency from [RFC1242].  However, this memo provides\
    \ a\n   new measurement procedure.\n   Procedure: Similar to [RFC2544], the throughput\
    \ for DUT at each of\n   the listed frame sizes SHOULD be determined.  Send a\
    \ stream of frames\n   at a particular frame size through the DUT at the determined\n\
    \   throughput rate to a specific destination.  The stream SHOULD be at\n   least\
    \ 120 seconds in duration.\n   Identifying tags SHOULD be included in at least\
    \ 500 frames after 60\n   seconds.  For each tagged frame, the time at which the\
    \ frame was\n   fully transmitted (timestamp A) and the time at which the frame\
    \ was\n   received (timestamp B) MUST be recorded.  The latency is timestamp B\n\
    \   minus timestamp A as per the relevant definition from RFC 1242,\n   namely,\
    \ latency as defined for store and forward devices or latency\n   as defined for\
    \ bit forwarding devices.\n   We recommend encoding the identifying tag in the\
    \ payload of the\n   frame.  To be more exact, the identifier SHOULD be inserted\
    \ after the\n   UDP header.\n   From the resulted (at least 500) latencies, two\
    \ quantities SHOULD be\n   calculated.  One is the typical latency, which SHOULD\
    \ be calculated\n   with the following formula:\n   TL = Median(Li)\n   Where:\n\
    \   o  TL = the reported typical latency of the stream\n   o  Li = the latency\
    \ for tagged frame i\n   The other measure is the worst-case latency, which SHOULD\
    \ be\n   calculated with the following formula:\n   WCL = L99.9thPercentile\n\
    \   Where:\n   o  WCL = the reported worst-case latency\n   o  L99.9thPercentile\
    \ = the 99.9th percentile of the stream-measured\n      latencies\n   The test\
    \ MUST be repeated at least 20 times with the reported value\n   being the median\
    \ of the recorded values for TL and WCL.\n   Reporting Format:  The report MUST\
    \ state which definition of latency\n   (from RFC 1242) was used for this test.\
    \  The summarized latency\n   results SHOULD be reported in the format of a table\
    \ with a row for\n   each of the tested frame sizes.  There SHOULD be columns\
    \ for the\n   frame size, the rate at which the latency test was run for that\
    \ frame\n   size, the media types tested, and the resultant typical latency, and\n\
    \   the worst-case latency values for each type of data stream tested.\n   To\
    \ account for the variation, the 1st and 99th percentiles of the 20\n   iterations\
    \ MAY be reported in two separated columns.  For a fine-\n   grained analysis,\
    \ the histogram (as exemplified in Section 4.4 of\n   [RFC5481]) of one of the\
    \ iterations MAY be displayed.\n"
- title: 7.3.  Packet Delay Variation
  contents:
  - "7.3.  Packet Delay Variation\n   [RFC5481] presents two metrics: Packet Delay\
    \ Variation (PDV) and\n   Inter Packet Delay Variation (IPDV).  Measuring PDV\
    \ is RECOMMENDED;\n   for a fine-grained analysis of delay variation, IPDV measurements\
    \ MAY\n   be performed.\n"
- title: 7.3.1.  PDV
  contents:
  - "7.3.1.  PDV\n   Objective: To determine the Packet Delay Variation as defined\
    \ in\n   [RFC5481].\n   Procedure: As described by [RFC2544], first determine\
    \ the throughput\n   for the DUT at each of the listed frame sizes.  Send a stream\
    \ of\n   frames at a particular frame size through the DUT at the determined\n\
    \   throughput rate to a specific destination.  The stream SHOULD be at\n   least\
    \ 60 seconds in duration.  Measure the one-way delay as described\n   by [RFC3393]\
    \ for all frames in the stream.  Calculate the PDV of the\n   stream using the\
    \ formula:\n   PDV = D99.9thPercentile - Dmin\n   Where:\n   o  D99.9thPercentile\
    \ = the 99.9th percentile (as described in\n      [RFC5481]) of the one-way delay\
    \ for the stream\n   o  Dmin = the minimum one-way delay in the stream\n   As\
    \ recommended in [RFC2544], the test MUST be repeated at least 20\n   times with\
    \ the reported value being the median of the recorded\n   values.  Moreover, the\
    \ 1st and 99th percentiles SHOULD be calculated\n   to account for the variation\
    \ of the dataset.\n   Reporting Format: The PDV results SHOULD be reported in\
    \ a table with\n   a row for each of the tested frame sizes and columns for the\
    \ frame\n   size and the applied frame rate for the tested media types.  Two\n\
    \   columns for the 1st and 99th percentile values MAY be displayed.\n   Following\
    \ the recommendations of [RFC5481], the RECOMMENDED units of\n   measurement are\
    \ milliseconds.\n"
- title: 7.3.2.  IPDV
  contents:
  - "7.3.2.  IPDV\n   Objective: To determine the Inter Packet Delay Variation as\
    \ defined\n   in [RFC5481].\n   Procedure: As described by [RFC2544], first determine\
    \ the throughput\n   for the DUT at each of the listed frame sizes.  Send a stream\
    \ of\n   frames at a particular frame size through the DUT at the determined\n\
    \   throughput rate to a specific destination.  The stream SHOULD be at\n   least\
    \ 60 seconds in duration.  Measure the one-way delay as described\n   by [RFC3393]\
    \ for all frames in the stream.  Calculate the IPDV for\n   each of the frames\
    \ using the formula:\n   IPDV(i) = D(i) - D(i-1)\n   Where:\n   o  D(i) = the\
    \ one-way delay of the i-th frame in the stream\n   o  D(i-1) = the one-way delay\
    \ of (i-1)th frame in the stream\n   Given the nature of IPDV, reporting a single\
    \ number might lead to\n   over-summarization.  In this context, the report for\
    \ each measurement\n   SHOULD include three values: Dmin, Dmed, and Dmax.\n  \
    \ Where:\n   o  Dmin = the minimum IPDV in the stream\n   o  Dmed = the median\
    \ IPDV of the stream\n   o  Dmax = the maximum IPDV in the stream\n   The test\
    \ MUST be repeated at least 20 times.  To summarize the 20\n   repetitions, for\
    \ each of the three (Dmin, Dmed, and Dmax), the median\n   value SHOULD be reported.\n\
    \   Reporting format: The median for the three proposed values SHOULD be\n   reported.\
    \  The IPDV results SHOULD be reported in a table with a row\n   for each of the\
    \ tested frame sizes.  The columns SHOULD include the\n   frame size and associated\
    \ frame rate for the tested media types and\n   sub-columns for the three proposed\
    \ reported values.  Following the\n   recommendations of [RFC5481], the RECOMMENDED\
    \ units of measurement\n   are milliseconds.\n"
- title: 7.4.  Frame Loss Rate
  contents:
  - "7.4.  Frame Loss Rate\n   Use Section 26.3 of [RFC2544] unmodified.\n"
- title: 7.5.  Back-to-Back Frames
  contents:
  - "7.5.  Back-to-Back Frames\n   Use Section 26.4 of [RFC2544] unmodified.\n"
- title: 7.6.  System Recovery
  contents:
  - "7.6.  System Recovery\n   Use Section 26.5 of [RFC2544] unmodified.\n"
- title: 7.7.  Reset
  contents:
  - "7.7.  Reset\n   Use Section 4 of [RFC6201] unmodified.\n"
- title: 8.  Additional Benchmarking Tests for Stateful IPv6 Transition
  contents:
  - "8.  Additional Benchmarking Tests for Stateful IPv6 Transition\n    Technologies\n\
    \   This section describes additional tests dedicated to stateful IPv6\n   transition\
    \ technologies.  For the tests described in this section,\n   the DUT devices\
    \ SHOULD follow the test setup and test parameters\n   recommendations presented\
    \ in Sections 5.2 and 5.3 of [RFC3511].\n   The following additional tests SHOULD\
    \ be performed.\n"
- title: 8.1.  Concurrent TCP Connection Capacity
  contents:
  - "8.1.  Concurrent TCP Connection Capacity\n   Use Section 5.2 of [RFC3511] unmodified.\n"
- title: 8.2.  Maximum TCP Connection Establishment Rate
  contents:
  - "8.2.  Maximum TCP Connection Establishment Rate\n   Use Section 5.3 of [RFC3511]\
    \ unmodified.\n"
- title: 9.  DNS Resolution Performance
  contents:
  - "9.  DNS Resolution Performance\n   This section describes benchmarking tests\
    \ dedicated to DNS64 (see\n   [RFC6147]), used as DNS support for single-translation\
    \ technologies\n   such as NAT64.\n"
- title: 9.1.  Test and Traffic Setup
  contents:
  - "9.1.  Test and Traffic Setup\n   The test setup in Figure 3 follows the setup\
    \ proposed for single-\n   translation IPv6 transition technologies in Figure\
    \ 1.\n      1:AAAA query    +--------------------+\n         +------------|  \
    \                  |<-------------+\n         |            |IPv6   Tester   IPv4|\
    \              |\n         |  +-------->|                    |----------+   |\n\
    \         |  |         +--------------------+ 3:empty  |   |\n         |  | 6:synt'd\
    \                         AAAA,  |   |\n         |  |   AAAA  +--------------------+\
    \ 5:valid A|   |\n         |  +---------|                    |<---------+   |\n\
    \         |            |IPv6     DUT    IPv4|              |\n         +----------->|\
    \       (DNS64)      |--------------+\n                      +--------------------+\
    \ 2:AAAA query, 4:A query\n                   Figure 3: Test Setup 3 (DNS64)\n\
    \   The test traffic SHOULD be composed of the following messages.\n   1.  Query\
    \ for the AAAA record of a domain name (from client to DNS64\n       server)\n\
    \   2.  Query for the AAAA record of the same domain name (from DNS64\n      \
    \ server to authoritative DNS server)\n   3.  Empty AAAA record answer (from authoritative\
    \ DNS server to DNS64\n       server)\n   4.  Query for the A record of the same\
    \ domain name (from DNS64 server\n       to authoritative DNS server)\n   5. \
    \ Valid A record answer (from authoritative DNS server to DNS64\n       server)\n\
    \   6.  Synthesized AAAA record answer (from DNS64 server to client)\n   The Tester\
    \ plays the role of DNS client as well as authoritative DNS\n   server.  It MAY\
    \ be realized as a single physical device, or\n   alternatively, two physical\
    \ devices MAY be used.\n   Please note that:\n   o  If the DNS64 server implements\
    \ caching and there is a cache hit,\n      then step 1 is followed by step 6 (and\
    \ steps 2 through 5 are\n      omitted).\n   o  If the domain name has a AAAA\
    \ record, then it is returned in step\n      3 by the authoritative DNS server,\
    \ steps 4 and 5 are omitted, and\n      the DNS64 server does not synthesize a\
    \ AAAA record but returns the\n      received AAAA record to the client.\n   o\
    \  As for the IP version used between the Tester and the DUT, IPv6\n      MUST\
    \ be used between the client and the DNS64 server (as a DNS64\n      server provides\
    \ service for an IPv6-only client), but either IPv4\n      or IPv6 MAY be used\
    \ between the DNS64 server and the authoritative\n      DNS server.\n"
- title: 9.2.  Benchmarking DNS Resolution Performance
  contents:
  - "9.2.  Benchmarking DNS Resolution Performance\n   Objective: To determine DNS64\
    \ performance by means of the maximum\n   number of successfully processed DNS\
    \ requests per second.\n   Procedure: Send a specific number of DNS queries at\
    \ a specific rate\n   to the DUT, and then count the replies from the DUT that\
    \ are received\n   in time (within a predefined timeout period from the sending\
    \ time of\n   the corresponding query, having the default value 1 second) and\
    \ that\n   are valid (contain a AAAA record).  If the count of sent queries is\n\
    \   equal to the count of received replies, the rate of the queries is\n   raised,\
    \ and the test is rerun.  If fewer replies are received than\n   queries were\
    \ sent, the rate of the queries is reduced, and the test\n   is rerun.  The duration\
    \ of each trial SHOULD be at least 60 seconds.\n   This will reduce the potential\
    \ gain of a DNS64 server, which is able\n   to exhibit higher performance by storing\
    \ the requests and thus also\n   utilizing the timeout time for answering them.\
    \  For the same reason,\n   no higher timeout time than 1 second SHOULD be used.\
    \  For further\n   considerations, see [Lencse1].\n   The maximum number of processed\
    \ DNS queries per second is the fastest\n   rate at which the count of DNS replies\
    \ sent by the DUT is equal to\n   the number of DNS queries sent to it by the\
    \ test equipment.\n   The test SHOULD be repeated at least 20 times, and the median\
    \ and\n   1st/99th percentiles of the number of processed DNS queries per\n  \
    \ second SHOULD be calculated.\n   Details and parameters:\n   1.  Caching\n \
    \      First, all the DNS queries MUST contain different domain names\n      \
    \ (or domain names MUST NOT be repeated before the cache of the DUT\n       is\
    \ exhausted).  Then, new tests MAY be executed when domain names\n       are 20%,\
    \ 40%, 60%, 80%, and 100% cached.  Ensuring that a record\n       is cached requires\
    \ repeating a domain name both \"late enough\"\n       after the first query to\
    \ be already resolved and be present in\n       the cache and \"early enough\"\
    \ to be still present in the cache.\n   2.  Existence of a AAAA record\n     \
    \  First, all the DNS queries MUST contain domain names that do not\n       have\
    \ a AAAA record and have exactly one A record.  Then, new\n       tests MAY be\
    \ executed when 20%, 40%, 60%, 80%, and 100% of domain\n       names have a AAAA\
    \ record.\n   Please note that the two conditions above are orthogonal; thus,\
    \ all\n   their combinations are possible and MAY be tested.  The testing with\n\
    \   0% cached domain names and with 0% existing AAAA records is REQUIRED,\n  \
    \ and the other combinations are OPTIONAL.  (When all the domain names\n   are\
    \ cached, then the results do not depend on what percentage of the\n   domain\
    \ names have AAAA records; thus, these combinations are not\n   worth testing\
    \ one by one.)\n   Reporting format: The primary result of the DNS64 test is the\
    \ median\n   of the number of processed DNS queries per second measured with the\n\
    \   above mentioned \"0% + 0% combination\".  The median SHOULD be\n   complemented\
    \ with the 1st and 99th percentiles to show the stability\n   of the result. \
    \ If optional tests are done, the median and the 1st\n   and 99th percentiles\
    \ MAY be presented in a two-dimensional table\n   where the dimensions are the\
    \ proportion of the repeated domain names\n   and the proportion of the DNS names\
    \ having AAAA records.  The two\n   table headings SHOULD contain these percentage\
    \ values.\n   Alternatively, the results MAY be presented as a corresponding two-\n\
    \   dimensional graph.  In this case, the graph SHOULD show the median\n   values\
    \ with the percentiles as error bars.  From both the table and\n   the graph,\
    \ one-dimensional excerpts MAY be made at any given fixed-\n   percentage value\
    \ of the other dimension.  In this case, the fixed\n   value MUST be given together\
    \ with a one-dimensional table or graph.\n"
- title: 9.2.1.  Requirements for the Tester
  contents:
  - "9.2.1.  Requirements for the Tester\n   Before a Tester can be used for testing\
    \ a DUT at rate r queries per\n   second with t seconds timeout, it MUST perform\
    \ a self-test in order\n   to exclude the possibility that the poor performance\
    \ of the Tester\n   itself influences the results.  To perform a self-test, the\
    \ Tester is\n   looped back (leaving out DUT), and its authoritative DNS server\n\
    \   subsystem is configured to be able to answer all the AAAA record\n   queries.\
    \  To pass the self-test, the Tester SHOULD be able to answer\n   AAAA record\
    \ queries at rate of 2*(r+delta) within a 0.25*t timeout,\n   where the value\
    \ of delta is at least 0.1.\n   Explanation: When performing DNS64 testing, each\
    \ AAAA record query\n   may result in at most two queries sent by the DUT: the\
    \ first for a\n   AAAA record and the second for an A record (they are both sent\
    \ when\n   there is no cache hit and also no AAAA record exists).  The\n   parameters\
    \ above guarantee that the authoritative DNS server\n   subsystem of the DUT is\
    \ able to answer the queries at the required\n   frequency using up not more than\
    \ half of the timeout time.\n   Note: A sample open-source test program, dns64perf++,\
    \ is available\n   from [Dns64perf] and is documented in [Lencse2].  It implements\
    \ only\n   the client part of the Tester and should be used together with an\n\
    \   authoritative DNS server implementation, e.g., BIND, NSD, or YADIFA.\n   Its\
    \ experimental extension for testing caching is available from\n   [Lencse3] and\
    \ is documented in [Lencse4].\n"
- title: 10.  Overload Scalability
  contents:
  - "10.  Overload Scalability\n   Scalability has been often discussed; however,\
    \ in the context of\n   network devices, a formal definition or a measurement\
    \ method has not\n   yet been proposed.  In this context, we can define overload\n\
    \   scalability as the ability of each transition technology to\n   accommodate\
    \ network growth.  Poor scalability usually leads to poor\n   performance.  Considering\
    \ this, overload scalability can be measured\n   by quantifying the network performance\
    \ degradation associated with an\n   increased number of network flows.\n   The\
    \ following subsections describe how the test setups can be\n   modified to create\
    \ network growth and how the associated performance\n   degradation can be quantified.\n"
- title: 10.1.  Test Setup
  contents:
  - "10.1.  Test Setup\n   The test setups defined in Section 4 have to be modified\
    \ to create\n   network growth.\n"
- title: 10.1.1.  Single-Translation Transition Technologies
  contents:
  - "10.1.1.  Single-Translation Transition Technologies\n   In the case of single-translation\
    \ transition technologies, the\n   network growth can be generated by increasing\
    \ the number of network\n   flows (NFs) generated by the Tester machine (see Figure\
    \ 4).\n                        +-------------------------+\n           +------------|NF1\
    \                   NF1|<-------------+\n           |  +---------|NF2      Tester\
    \       NF2|<----------+  |\n           |  |      ...|                       \
    \  |           |  |\n           |  |   +-----|NFn                   NFn|<------+\
    \   |  |\n           |  |   |     +-------------------------+       |   |  |\n\
    \           |  |   |                                       |   |  |\n        \
    \   |  |   |     +-------------------------+       |   |  |\n           |  | \
    \  +---->|NFn                   NFn|-------+   |  |\n           |  |      ...|\
    \           DUT           |           |  |\n           |  +-------->|NF2    (translator)\
    \   NF2|-----------+  |\n           +----------->|NF1                   NF1|--------------+\n\
    \                        +-------------------------+\n                 Figure\
    \ 4: Test Setup 4 (Single DUT with Increased\n                              Network\
    \ Flows)\n"
- title: 10.1.2.  Encapsulation and Double-Translation Transition Technologies
  contents:
  - "10.1.2.  Encapsulation and Double-Translation Transition Technologies\n   Similarly,\
    \ for the encapsulation and double-translation transition\n   technologies, a\
    \ multi-flow setup is recommended.  Considering a\n   multipoint-to-point scenario,\
    \ for most transition technologies, one\n   of the edge nodes is designed to support\
    \ more than one connecting\n   device.  Hence, the recommended test setup is an\
    \ n:1 design, where n\n   is the number of client DUTs connected to the same server\
    \ DUT (see\n   Figure 5).\n                          +-------------------------+\n\
    \     +--------------------|NF1                   NF1|<--------------+\n     |\
    \  +-----------------|NF2      Tester       NF2|<-----------+  |\n     |  |  \
    \            ...|                         |            |  |\n     |  |   +-------------|NFn\
    \                   NFn|<-------+   |  |\n     |  |   |             +-------------------------+\
    \        |   |  |\n     |  |   |                                             \
    \   |   |  |\n     |  |   |    +-----------------+    +---------------+    | \
    \  |  |\n     |  |   +--->| NFn  DUT n  NFn |--->|NFn         NFn| ---+   |  |\n\
    \     |  |        +-----------------+    |               |        |  |\n     |\
    \  |     ...                       |               |        |  |\n     |  |  \
    \      +-----------------+    |     DUT n+1   |        |  |\n     |  +------->|\
    \ NF2  DUT 2  NF2 |--->|NF2         NF2|--------+  |\n     |           +-----------------+\
    \    |               |           |\n     |           +-----------------+    |\
    \               |           |\n     +---------->| NF1  DUT 1  NF1 |--->|NF1  \
    \       NF1|-----------+\n                 +-----------------+    +---------------+\n\
    \                Figure 5: Test Setup 5 (DUAL DUT with Increased\n           \
    \                  Network Flows)\n   This test setup can help to quantify the\
    \ scalability of the server\n   device.  However, for testing the overload scalability\
    \ of the client\n   DUTs, additional recommendations are needed.\n   For encapsulation\
    \ transition technologies, an m:n setup can be\n   created, where m is the number\
    \ of flows applied to the same client\n   device and n the number of client devices\
    \ connected to the same\n   server device.\n   For translation-based transition\
    \ technologies, the client devices can\n   be separately tested with n network\
    \ flows using the test setup\n   presented in Figure 4.\n"
- title: 10.2.  Benchmarking Performance Degradation
  contents:
  - '10.2.  Benchmarking Performance Degradation

    '
- title: 10.2.1.  Network Performance Degradation with Simultaneous Load
  contents:
  - "10.2.1.  Network Performance Degradation with Simultaneous Load\n   Objective:\
    \ To quantify the performance degradation introduced by n\n   parallel and simultaneous\
    \ network flows.\n   Procedure: First, the benchmarking tests presented in Section\
    \ 7 have\n   to be performed for one network flow.\n   The same tests have to\
    \ be repeated for n network flows, where the\n   network flows are started simultaneously.\
    \  The performance\n   degradation of the X benchmarking dimension SHOULD be calculated\
    \ as\n   relative performance change between the 1-flow (single flow) results\n\
    \   and the n-flow results, using the following formula:\n               Xn -\
    \ X1\n       Xpd = ----------- * 100, where: X1 = result for 1-flow\n        \
    \          X1                   Xn = result for n-flows\n   This formula SHOULD\
    \ be applied only for \"lower is better\" benchmarks\n   (e.g., latency).  For\
    \ \"higher is better\" benchmarks (e.g.,\n   throughput), the following formula\
    \ is RECOMMENDED:\n               X1 - Xn\n       Xpd = ----------- * 100, where:\
    \ X1 = result for 1-flow\n                  X1                   Xn = result for\
    \ n-flows\n   As a guideline for the maximum number of flows n, the value can\
    \ be\n   deduced by measuring the Concurrent TCP Connection Capacity as\n   described\
    \ by [RFC3511], following the test setups specified by\n   Section 4.\n   Reporting\
    \ Format: The performance degradation SHOULD be expressed as\n   a percentage.\
    \  The number of tested parallel flows n MUST be clearly\n   specified.  For each\
    \ of the performed benchmarking tests, there\n   SHOULD be a table containing\
    \ a column for each frame size.  The table\n   SHOULD also state the applied frame\
    \ rate.  In the case of benchmarks\n   for which more than one value is reported\
    \ (e.g., IPDV, discussed in\n   Section 7.3.2), a column for each of the values\
    \ SHOULD be included.\n"
- title: 10.2.2.  Network Performance Degradation with Incremental Load
  contents:
  - "10.2.2.  Network Performance Degradation with Incremental Load\n   Objective:\
    \ To quantify the performance degradation introduced by n\n   parallel and incrementally\
    \ started network flows.\n   Procedure: First, the benchmarking tests presented\
    \ in Section 7 have\n   to be performed for one network flow.\n   The same tests\
    \ have to be repeated for n network flows, where the\n   network flows are started\
    \ incrementally in succession, each after\n   time t.  In other words, if flow\
    \ i is started at time x, flow i+1\n   will be started at time x+t.  Considering\
    \ the time t, the time\n   duration of each iteration must be extended with the\
    \ time necessary\n   to start all the flows, namely, (n-1)xt.  The measurement\
    \ for the\n   first flow SHOULD be at least 60 seconds in duration.\n   The performance\
    \ degradation of the x benchmarking dimension SHOULD be\n   calculated as relative\
    \ performance change between the 1-flow results\n   and the n-flow results, using\
    \ the formula presented in\n   Section 10.2.1.  Intermediary degradation points\
    \ for 1/4*n, 1/2*n,\n   and 3/4*n MAY also be performed.\n   Reporting Format:\
    \ The performance degradation SHOULD be expressed as\n   a percentage.  The number\
    \ of tested parallel flows n MUST be clearly\n   specified.  For each of the performed\
    \ benchmarking tests, there\n   SHOULD be a table containing a column for each\
    \ frame size.  The table\n   SHOULD also state the applied frame rate and time\
    \ duration T, which\n   is used as an incremental step between the network flows.\
    \  The units\n   of measurement for T SHOULD be seconds.  A column for the\n \
    \  intermediary degradation points MAY also be displayed.  In the case\n   of\
    \ benchmarks for which more than one value is reported (e.g., IPDV,\n   discussed\
    \ in Section 7.3.2), a column for each of the values SHOULD\n   be included.\n"
- title: 11.  NAT44 and NAT66
  contents:
  - "11.  NAT44 and NAT66\n   Although these technologies are not the primary scope\
    \ of this\n   document, the benchmarking methodology associated with single-\n\
    \   translation technologies as defined in Section 4.1 can be employed to\n  \
    \ benchmark implementations that use NAT44 (as defined by [RFC2663]\n   with the\
    \ behavior described by [RFC7857]) and implementations that\n   use NAT66 (as\
    \ defined by [RFC6296]).\n"
- title: 12.  Summarizing Function and Variation
  contents:
  - "12.  Summarizing Function and Variation\n   To ensure the stability of the benchmarking\
    \ scores obtained using the\n   tests presented in Sections 7 through 9, multiple\
    \ test iterations are\n   RECOMMENDED.  Using a summarizing function (or measure\
    \ of central\n   tendency) can be a simple and effective way to compare the results\n\
    \   obtained across different iterations.  However, over-summarization is\n  \
    \ an unwanted effect of reporting a single number.\n   Measuring the variation\
    \ (dispersion index) can be used to counter the\n   over-summarization effect.\
    \  Empirical data obtained following the\n   proposed methodology can also offer\
    \ insights on which summarizing\n   function would fit better.\n   To that end,\
    \ data presented in [ietf95pres] indicate the median as a\n   suitable summarizing\
    \ function and the 1st and 99th percentiles as\n   variation measures for DNS\
    \ Resolution Performance and PDV.  The\n   median and percentile calculation functions\
    \ SHOULD follow the\n   recommendations of Section 11.3 of [RFC2330].\n   For\
    \ a fine-grained analysis of the frequency distribution of the\n   data, histograms\
    \ or cumulative distribution function plots can be\n   employed.\n"
- title: 13.  Security Considerations
  contents:
  - "13.  Security Considerations\n   Benchmarking activities as described in this\
    \ memo are limited to\n   technology characterization using controlled stimuli\
    \ in a laboratory\n   environment, with dedicated address space and the constraints\n\
    \   specified in the sections above.\n   The benchmarking network topology will\
    \ be an independent test setup\n   and MUST NOT be connected to devices that may\
    \ forward the test\n   traffic into a production network or misroute traffic to\
    \ the test\n   management network.\n   Further, benchmarking is performed on a\
    \ \"black-box\" basis, relying\n   solely on measurements observable external\
    \ to the DUT or System Under\n   Test (SUT).  Special capabilities SHOULD NOT\
    \ exist in the DUT/SUT\n   specifically for benchmarking purposes.  Any implications\
    \ for network\n   security arising from the DUT/SUT SHOULD be identical in the\
    \ lab and\n   in production networks.\n"
- title: 14.  IANA Considerations
  contents:
  - "14.  IANA Considerations\n   The IANA has allocated the prefix 2001:2::/48 [RFC5180]\
    \ for IPv6\n   benchmarking.  For IPv4 benchmarking, the 198.18.0.0/15 prefix\
    \ was\n   reserved, as described in [RFC6890].  The two ranges are sufficient\n\
    \   for benchmarking IPv6 transition technologies.  Thus, no action is\n   requested.\n"
- title: 15.  References
  contents:
  - '15.  References

    '
- title: 15.1.  Normative References
  contents:
  - "15.1.  Normative References\n   [RFC1242]  Bradner, S., \"Benchmarking Terminology\
    \ for Network\n              Interconnection Devices\", RFC 1242, DOI 10.17487/RFC1242,\n\
    \              July 1991, <http://www.rfc-editor.org/info/rfc1242>.\n   [RFC2119]\
    \  Bradner, S., \"Key words for use in RFCs to Indicate\n              Requirement\
    \ Levels\", BCP 14, RFC 2119,\n              DOI 10.17487/RFC2119, March 1997,\n\
    \              <http://www.rfc-editor.org/info/rfc2119>.\n   [RFC2330]  Paxson,\
    \ V., Almes, G., Mahdavi, J., and M. Mathis,\n              \"Framework for IP\
    \ Performance Metrics\", RFC 2330,\n              DOI 10.17487/RFC2330, May 1998,\n\
    \              <http://www.rfc-editor.org/info/rfc2330>.\n   [RFC2544]  Bradner,\
    \ S. and J. McQuaid, \"Benchmarking Methodology for\n              Network Interconnect\
    \ Devices\", RFC 2544,\n              DOI 10.17487/RFC2544, March 1999,\n    \
    \          <http://www.rfc-editor.org/info/rfc2544>.\n   [RFC3393]  Demichelis,\
    \ C. and P. Chimento, \"IP Packet Delay Variation\n              Metric for IP\
    \ Performance Metrics (IPPM)\", RFC 3393,\n              DOI 10.17487/RFC3393,\
    \ November 2002,\n              <http://www.rfc-editor.org/info/rfc3393>.\n  \
    \ [RFC3511]  Hickman, B., Newman, D., Tadjudin, S., and T. Martin,\n         \
    \     \"Benchmarking Methodology for Firewall Performance\",\n              RFC\
    \ 3511, DOI 10.17487/RFC3511, April 2003,\n              <http://www.rfc-editor.org/info/rfc3511>.\n\
    \   [RFC5180]  Popoviciu, C., Hamza, A., Van de Velde, G., and D.\n          \
    \    Dugatkin, \"IPv6 Benchmarking Methodology for Network\n              Interconnect\
    \ Devices\", RFC 5180, DOI 10.17487/RFC5180,\n              May 2008, <http://www.rfc-editor.org/info/rfc5180>.\n\
    \   [RFC5481]  Morton, A. and B. Claise, \"Packet Delay Variation\n          \
    \    Applicability Statement\", RFC 5481, DOI 10.17487/RFC5481,\n            \
    \  March 2009, <http://www.rfc-editor.org/info/rfc5481>.\n   [RFC6201]  Asati,\
    \ R., Pignataro, C., Calabria, F., and C. Olvera,\n              \"Device Reset\
    \ Characterization\", RFC 6201,\n              DOI 10.17487/RFC6201, March 2011,\n\
    \              <http://www.rfc-editor.org/info/rfc6201>.\n   [RFC8174]  Leiba,\
    \ B., \"Ambiguity of Uppercase vs Lowercase in RFC\n              2119 Key Words\"\
    , BCP 14, RFC 8174, DOI 10.17487/RFC8174,\n              May 2017, <http://www.rfc-editor.org/info/rfc8174>.\n"
- title: 15.2.  Informative References
  contents:
  - "15.2.  Informative References\n   [RFC2663]  Srisuresh, P. and M. Holdrege, \"\
    IP Network Address\n              Translator (NAT) Terminology and Considerations\"\
    ,\n              RFC 2663, DOI 10.17487/RFC2663, August 1999,\n              <http://www.rfc-editor.org/info/rfc2663>.\n\
    \   [RFC4213]  Nordmark, E. and R. Gilligan, \"Basic Transition Mechanisms\n \
    \             for IPv6 Hosts and Routers\", RFC 4213,\n              DOI 10.17487/RFC4213,\
    \ October 2005,\n              <http://www.rfc-editor.org/info/rfc4213>.\n   [RFC4659]\
    \  De Clercq, J., Ooms, D., Carugi, M., and F. Le Faucheur,\n              \"\
    BGP-MPLS IP Virtual Private Network (VPN) Extension for\n              IPv6 VPN\"\
    , RFC 4659, DOI 10.17487/RFC4659, September 2006,\n              <http://www.rfc-editor.org/info/rfc4659>.\n\
    \   [RFC4798]  De Clercq, J., Ooms, D., Prevost, S., and F. Le Faucheur,\n   \
    \           \"Connecting IPv6 Islands over IPv4 MPLS Using IPv6\n            \
    \  Provider Edge Routers (6PE)\", RFC 4798,\n              DOI 10.17487/RFC4798,\
    \ February 2007,\n              <http://www.rfc-editor.org/info/rfc4798>.\n  \
    \ [RFC5569]  Despres, R., \"IPv6 Rapid Deployment on IPv4\n              Infrastructures\
    \ (6rd)\", RFC 5569, DOI 10.17487/RFC5569,\n              January 2010, <http://www.rfc-editor.org/info/rfc5569>.\n\
    \   [RFC6144]  Baker, F., Li, X., Bao, C., and K. Yin, \"Framework for\n     \
    \         IPv4/IPv6 Translation\", RFC 6144, DOI 10.17487/RFC6144,\n         \
    \     April 2011, <http://www.rfc-editor.org/info/rfc6144>.\n   [RFC6146]  Bagnulo,\
    \ M., Matthews, P., and I. van Beijnum, \"Stateful\n              NAT64: Network\
    \ Address and Protocol Translation from IPv6\n              Clients to IPv4 Servers\"\
    , RFC 6146, DOI 10.17487/RFC6146,\n              April 2011, <http://www.rfc-editor.org/info/rfc6146>.\n\
    \   [RFC6147]  Bagnulo, M., Sullivan, A., Matthews, P., and I. van\n         \
    \     Beijnum, \"DNS64: DNS Extensions for Network Address\n              Translation\
    \ from IPv6 Clients to IPv4 Servers\", RFC 6147,\n              DOI 10.17487/RFC6147,\
    \ April 2011,\n              <http://www.rfc-editor.org/info/rfc6147>.\n   [RFC6219]\
    \  Li, X., Bao, C., Chen, M., Zhang, H., and J. Wu, \"The\n              China\
    \ Education and Research Network (CERNET) IVI\n              Translation Design\
    \ and Deployment for the IPv4/IPv6\n              Coexistence and Transition\"\
    , RFC 6219,\n              DOI 10.17487/RFC6219, May 2011,\n              <http://www.rfc-editor.org/info/rfc6219>.\n\
    \   [RFC6296]  Wasserman, M. and F. Baker, \"IPv6-to-IPv6 Network Prefix\n   \
    \           Translation\", RFC 6296, DOI 10.17487/RFC6296, June 2011,\n      \
    \        <http://www.rfc-editor.org/info/rfc6296>.\n   [RFC6333]  Durand, A.,\
    \ Droms, R., Woodyatt, J., and Y. Lee, \"Dual-\n              Stack Lite Broadband\
    \ Deployments Following IPv4\n              Exhaustion\", RFC 6333, DOI 10.17487/RFC6333,\
    \ August 2011,\n              <http://www.rfc-editor.org/info/rfc6333>.\n   [RFC6877]\
    \  Mawatari, M., Kawashima, M., and C. Byrne, \"464XLAT:\n              Combination\
    \ of Stateful and Stateless Translation\",\n              RFC 6877, DOI 10.17487/RFC6877,\
    \ April 2013,\n              <http://www.rfc-editor.org/info/rfc6877>.\n   [RFC6890]\
    \  Cotton, M., Vegoda, L., Bonica, R., Ed., and B. Haberman,\n              \"\
    Special-Purpose IP Address Registries\", BCP 153,\n              RFC 6890, DOI\
    \ 10.17487/RFC6890, April 2013,\n              <http://www.rfc-editor.org/info/rfc6890>.\n\
    \   [RFC7596]  Cui, Y., Sun, Q., Boucadair, M., Tsou, T., Lee, Y., and I.\n  \
    \            Farrer, \"Lightweight 4over6: An Extension to the Dual-\n       \
    \       Stack Lite Architecture\", RFC 7596, DOI 10.17487/RFC7596,\n         \
    \     July 2015, <http://www.rfc-editor.org/info/rfc7596>.\n   [RFC7597]  Troan,\
    \ O., Ed., Dec, W., Li, X., Bao, C., Matsushima, S.,\n              Murakami,\
    \ T., and T. Taylor, Ed., \"Mapping of Address and\n              Port with Encapsulation\
    \ (MAP-E)\", RFC 7597,\n              DOI 10.17487/RFC7597, July 2015,\n     \
    \         <http://www.rfc-editor.org/info/rfc7597>.\n   [RFC7599]  Li, X., Bao,\
    \ C., Dec, W., Ed., Troan, O., Matsushima, S.,\n              and T. Murakami,\
    \ \"Mapping of Address and Port using\n              Translation (MAP-T)\", RFC\
    \ 7599, DOI 10.17487/RFC7599, July\n              2015, <http://www.rfc-editor.org/info/rfc7599>.\n\
    \   [RFC7857]  Penno, R., Perreault, S., Boucadair, M., Ed., Sivakumar,\n    \
    \          S., and K. Naito, \"Updates to Network Address Translation\n      \
    \        (NAT) Behavioral Requirements\", BCP 127, RFC 7857,\n              DOI\
    \ 10.17487/RFC7857, April 2016,\n              <http://www.rfc-editor.org/info/rfc7857>.\n\
    \   [RFC7915]  Bao, C., Li, X., Baker, F., Anderson, T., and F. Gont,\n      \
    \        \"IP/ICMP Translation Algorithm\", RFC 7915,\n              DOI 10.17487/RFC7915,\
    \ June 2016,\n              <http://www.rfc-editor.org/info/rfc7915>.\n   [Dns64perf]\n\
    \              Bakai, D., \"A C++11 DNS64 performance tester\",\n            \
    \  <https://github.com/bakaid/dns64perfpp>.\n   [ietf95pres]\n              Georgescu,\
    \ M., \"Benchmarking Methodology for IPv6\n              Transition Technologies\"\
    , IETF 95 Proceedings, Buenos\n              Aires, Argentina, April 2016,\n \
    \             <https://www.ietf.org/proceedings/95/slides/\n              slides-95-bmwg-2.pdf>.\n\
    \   [Lencse1]  Lencse, G., Georgescu, M., and Y. Kadobayashi,\n              \"\
    Benchmarking Methodology for DNS64 Servers\", Computer\n              Communications,\
    \ vol. 109, no. 1, pp. 162-175,\n              DOI 10.1016/j.comcom.2017.06.004,\
    \ September 2017,\n              <http://www.sciencedirect.com/science/article/pii/\n\
    \              S0140366416305904?via%3Dihub>\n   [Lencse2]  Lencse, G. and D.\
    \ Bakai, \"Design and Implementation of a\n              Test Program for Benchmarking\
    \ DNS64 Servers\", IEICE\n              Transactions on Communications, Vol. E100-B,\
    \ No. 6,\n              pp. 948-954, DOI 10.1587/transcom.2016EBN0007, June 2017,\n\
    \              <https://www.jstage.jst.go.jp/article/transcom/E100.B/\n      \
    \        6/E100.B_2016EBN0007/_article>.\n   [Lencse3]  dns64perfppc,\n      \
    \        <http://www.hit.bme.hu/~lencse/dns64perfppc/>.\n   [Lencse4]  Lencse,\
    \ G., \"Enabling Dns64perf++ for Benchmarking the\n              Caching Performance\
    \ of DNS64 Servers\", unpublished, review\n              version, <http://www.hit.bme.hu/~lencse/publications/\n\
    \              IEICE-2016-dns64perfppc-for-review.pdf>.\n   [IEEE802.1AC]\n  \
    \            IEEE, \"IEEE Standard for Local and metropolitan area\n         \
    \     networks -- Media Access Control (MAC) Service\n              Definition\"\
    , IEEE 802.1AC.\n   [IEEE802.1Q]\n              IEEE, \"IEEE Standard for Local\
    \ and metropolitan area\n              networks -- Bridges and Bridged Networks\"\
    , IEEE Std\n              802.1Q.\n"
- title: Appendix A.  Theoretical Maximum Frame Rates
  contents:
  - "Appendix A.  Theoretical Maximum Frame Rates\n   This appendix describes the\
    \ recommended calculation formulas for the\n   theoretical maximum frame rates\
    \ to be employed over Ethernet as\n   example media.  The formula takes into account\
    \ the frame size\n   overhead created by the encapsulation or translation process.\
    \  For\n   example, the 6in4 encapsulation described in [RFC4213] adds 20 bytes\n\
    \   of overhead to each frame.\n   Considering X to be the frame size and O to\
    \ be the frame size\n   overhead created by the encapsulation or translation process,\
    \ the\n   maximum theoretical frame rate for Ethernet can be calculated using\n\
    \   the following formula:\n                Line Rate (bps)\n         ------------------------------------\n\
    \         (8 bits/byte) * (X+O+20) bytes/frame\n   The calculation is based on\
    \ the formula recommended by [RFC5180] in\n   Appendix A.1.  As an example, the\
    \ frame rate recommended for testing\n   a 6in4 implementation over 10 Mb/s Ethernet\
    \ with 64 bytes frames is:\n                10,000,000 (bps)\n         --------------------------------------\
    \  = 12,019 fps\n         (8 bits/byte) * (64+20+20) bytes/frame\n   The complete\
    \ list of recommended frame rates for 6in4 encapsulation\n   can be found in the\
    \ following table:\n   +------------+---------+----------+-----------+------------+\n\
    \   | Frame size | 10 Mb/s | 100 Mb/s | 1000 Mb/s | 10000 Mb/s |\n   | (bytes)\
    \    | (fps)   | (fps)    | (fps)     | (fps)      |\n   +------------+---------+----------+-----------+------------+\n\
    \   | 64         | 12,019  | 120,192  | 1,201,923 | 12,019,231 |\n   | 128   \
    \     | 7,440   | 74,405   | 744,048   | 7,440,476  |\n   | 256        | 4,223\
    \   | 42,230   | 422,297   | 4,222,973  |\n   | 512        | 2,264   | 22,645\
    \   | 226,449   | 2,264,493  |\n   | 678        | 1,740   | 17,409   | 174,094\
    \   | 1,740,947  |\n   | 1024       | 1,175   | 11,748   | 117,481   | 1,174,812\
    \  |\n   | 1280       | 947     | 9,470    | 94,697    | 946,970    |\n   | 1518\
    \       | 802     | 8,023    | 80,231    | 802,311    |\n   | 1522       | 800\
    \     | 8,003    | 80,026    | 800,256    |\n   | 2048       | 599     | 5,987\
    \    | 59,866    | 598,659    |\n   | 4096       | 302     | 3,022    | 30,222\
    \    | 302,224    |\n   | 8192       | 152     | 1,518    | 15,185    | 151,846\
    \    |\n   | 9216       | 135     | 1,350    | 13,505    | 135,048    |\n   +------------+---------+----------+-----------+------------+\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   The authors thank Youki Kadobayashi and Hiroaki Hazeyama\
    \ for their\n   constant feedback and support.  The thanks should be extended\
    \ to the\n   NECOMA project members for their continuous support.  We thank\n\
    \   Emanuel Popa, Ionut Spirlea, and the RCS&RDS IP/MPLS Backbone Team\n   for\
    \ their support and insights.  We thank Scott Bradner for the\n   useful suggestions\
    \ and note that portions of text from Scott's\n   documents were used in this\
    \ memo (e.g., the \"Latency\" section).  A\n   big thank you to Al Morton and\
    \ Fred Baker for their detailed review\n   of the document and very helpful suggestions.\
    \  Other helpful comments\n   and suggestions were offered by Bhuvaneswaran Vengainathan,\
    \ Andrew\n   McGregor, Nalini Elkins, Kaname Nishizuka, Yasuhiro Ohara, Masataka\n\
    \   Mawatari, Kostas Pentikousis, Bela Almasi, Tim Chown, Paul Emmerich,\n   and\
    \ Stenio Fernandes.  A special thank you to the RFC Editor Team for\n   their\
    \ thorough editorial review and helpful suggestions.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Marius Georgescu\n   RCS&RDS\n   Strada Dr. Nicolae D.\
    \ Staicovici 71-75\n   Bucharest 030167\n   Romania\n   Phone: +40 31 005 0979\n\
    \   Email: marius.georgescu@rcs-rds.ro\n   Liviu Pislaru\n   RCS&RDS\n   Strada\
    \ Dr. Nicolae D. Staicovici 71-75\n   Bucharest 030167\n   Romania\n   Phone:\
    \ +40 31 005 0979\n   Email: liviu.pislaru@rcs-rds.ro\n   Gabor Lencse\n   Szechenyi\
    \ Istvan University\n   Egyetem ter 1.\n   Gyor\n   Hungary\n   Phone: +36 20\
    \ 775 8267\n   Email: lencse@sze.hu\n"
