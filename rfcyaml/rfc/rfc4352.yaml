- contents:
  - "                       RTP Payload Format for the\n      Extended Adaptive Multi-Rate
    Wideband (AMR-WB+) Audio Codec\n"
  title: __initial_text__
- contents:
  - "Status of This Memo\n   This document specifies an Internet standards track protocol
    for the\n   Internet community, and requests discussion and suggestions for\n
    \  improvements.  Please refer to the current edition of the \"Internet\n   Official
    Protocol Standards\" (STD 1) for the standardization state\n   and status of this
    protocol.  Distribution of this memo is unlimited.\n"
  title: Status of This Memo
- contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2006).\n"
  title: Copyright Notice
- contents:
  - "Abstract\n   This document specifies a Real-time Transport Protocol (RTP) payload\n
    \  format for Extended Adaptive Multi-Rate Wideband (AMR-WB+) encoded\n   audio
    signals.  The AMR-WB+ codec is an audio extension of the AMR-WB\n   speech codec.
    \ It encompasses the AMR-WB frame types and a number of\n   new frame types designed
    to support high-quality music and speech.  A\n   media type registration for AMR-WB+
    is included in this\n   specification.\n"
  title: Abstract
- contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n
    \  2. Definitions .....................................................4\n      2.1.
    Glossary ...................................................4\n      2.2. Terminology
    ................................................4\n   3. Background of AMR-WB+
    and Design Principles .....................4\n      3.1. The AMR-WB+ Audio Codec
    ....................................4\n      3.2. Multi-rate Encoding and Rate
    Adaptation ....................8\n      3.3. Voice Activity Detection and Discontinuous
    Transmission ....8\n      3.4. Support for Multi-Channel Session ..........................8\n
    \     3.5. Unequal Bit-Error Detection and Protection .................9\n      3.6.
    Robustness against Packet Loss .............................9\n           3.6.1.
    Use of Forward Error Correction (FEC) ...............9\n           3.6.2. Use
    of Frame Interleaving ..........................10\n      3.7. AMR-WB+ Audio over
    IP Scenarios ...........................11\n      3.8. Out-of-Band Signaling .....................................11\n
    \  4. RTP Payload Format for AMR-WB+ .................................12\n      4.1.
    RTP Header Usage ..........................................13\n      4.2. Payload
    Structure .........................................14\n      4.3. Payload Definitions
    .......................................14\n           4.3.1. Payload Header .....................................14\n
    \          4.3.2. The Payload Table of Contents ......................15\n           4.3.3.
    Audio Data .........................................20\n           4.3.4. Methods
    for Forming the Payload ....................21\n           4.3.5. Payload Examples
    ...................................21\n      4.4. Interleaving Considerations
    ...............................24\n      4.5. Implementation Considerations .............................25\n
    \          4.5.1. ISF Recovery in Case of Packet Loss ................26\n           4.5.2.
    Decoding Validation ................................28\n   5. Congestion Control
    .............................................28\n   6. Security Considerations
    ........................................28\n      6.1. Confidentiality ...........................................29\n
    \     6.2. Authentication and Integrity ..............................29\n   7.
    Payload Format Parameters ......................................29\n      7.1.
    Media Type Registration ...................................30\n      7.2. Mapping
    Media Type Parameters into SDP ....................32\n           7.2.1. Offer-Answer
    Model Considerations ..................32\n           7.2.2. Examples ...........................................34\n
    \  8. IANA Considerations ............................................34\n   9.
    Contributors ...................................................34\n   10. Acknowledgements
    ..............................................34\n   11. References ....................................................35\n
    \     11.1. Normative References .....................................35\n      11.2.
    Informative References ...................................35\n"
  title: Table of Contents
- contents:
  - "1.  Introduction\n   This document specifies the payload format for packetization
    of\n   Extended Adaptive Multi-Rate Wideband (AMR-WB+) [1] encoded audio\n   signals
    into the Real-time Transport Protocol (RTP) [3].  The payload\n   format supports
    the transmission of mono or stereo audio, aggregating\n   multiple frames per
    payload, and mechanisms enhancing the robustness\n   of the packet stream against
    packet loss.\n   The AMR-WB+ codec is an extension of the Adaptive Multi-Rate
    Wideband\n   (AMR-WB) speech codec.  New features include extended audio bandwidth\n
    \  to enable high quality for non-speech signals (e.g., music), native\n   support
    for stereophonic audio, and the option to operate on, and\n   switch between,
    several internal sampling frequencies (ISFs).  The\n   primary usage scenario
    for AMR-WB+ is the transport over IP.\n   Therefore, interworking with other transport
    networks, as discussed\n   for AMR-WB in [7], is not a major concern and hence
    not addressed in\n   this memo.\n   The expected key application for AMR-WB+ is
    streaming.  To make the\n   packetization process on a streaming server as efficient
    as possible,\n   an octet-aligned payload format is desirable.  Therefore, a\n
    \  bandwidth-efficient mode (as defined for AMR-WB in [7]) is not\n   specified
    herein; the bandwidth savings of the bandwidth-efficient\n   mode would be very
    small anyway, since all extension frame types are\n   octet aligned.\n   The stereo
    encoding capability of AMR-WB+ renders the support for\n   multi-channel transport
    at RTP payload format level, as specified for\n   AMR-WB [7], obsolete.  Therefore,
    this feature is not included in\n   this memo.\n   This specification does not
    include a definition of a file format for\n   AMR-WB+.  Instead, it refers to
    the ISO-based 3GP file format [14],\n   which supports AMR-WB+ and provides all
    functionality required.  The\n   3GP format also supports storage of AMR, AMR-WB,
    and many other\n   multi-media formats, thereby allowing synchronized playback.\n
    \  The rest of the document is organized as follows: Background\n   information
    on the AMR-WB+ codec, and design principles, can be found\n   in Section 3.  The
    payload format itself is specified in Section 4.\n   Sections 5 and 6 discuss
    congestion control and security\n   considerations, respectively.  In Section
    7, a media type\n   registration is provided.\n"
  title: 1.  Introduction
- contents:
  - '2.  Definitions

    '
  - contents:
    - "2.1.  Glossary\n   3GPP    - Third Generation Partnership Project\n   AMR     -
      Adaptive Multi-Rate (Codec)\n   AMR-WB  - Adaptive Multi-Rate Wideband (Codec)\n
      \  AMR-WB+ - Extended Adaptive Multi-Rate Wideband (Codec)\n   CN      - Comfort
      Noise\n   DTX     - Discontinuous Transmission\n   FEC     - Forward Error Correction\n
      \  FT      - Frame Type\n   ISF     - Internal Sampling Frequency\n   SCR     -
      Source-Controlled Rate Operation\n   SID     - Silence Indicator (the frames
      containing only CN\n             parameters)\n   TFI     - Transport Frame Index\n
      \  TS      - Timestamp\n   VAD     - Voice Activity Detection\n   UED     -
      Unequal Error Detection\n   UEP     - Unequal Error Protection\n"
    title: 2.1.  Glossary
  - contents:
    - "2.2.  Terminology\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\",
      \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and
      \"OPTIONAL\" in this\n   document are to be interpreted as described in RFC
      2119 [2].\n"
    title: 2.2.  Terminology
  title: 2.  Definitions
- contents:
  - "3.  Background of AMR-WB+ and Design Principles\n   The Extended Adaptive Multi-Rate
    Wideband (AMR-WB+) [1] audio codec\n   is designed to compress speech and audio
    signals at low bit-rate and\n   good quality.  The codec is specified by the Third
    Generation\n   Partnership Project (3GPP).  The primary target applications are
    1)\n   the packet-switched streaming service (PSS) [13], 2) multimedia\n   messaging
    service (MMS) [18], and 3) multimedia broadcast and\n   multicast service (MBMS)
    [19].  However, due to its flexibility and\n   robustness, AMR-WB+ is also well
    suited for streaming services in\n   other highly varying transport environments,
    for example, the\n   Internet.\n"
  - contents:
    - "3.1.  The AMR-WB+ Audio Codec\n   3GPP originally developed the AMR-WB+ audio
      codec for streaming and\n   messaging services in Global System for Mobile communications
      (GSM)\n   and third generation (3G) cellular systems.  The codec is designed
      as\n   an audio extension of the AMR-WB speech codec.  The extension adds\n
      \  new functionality to the codec in order to provide high audio quality\n   for
      a wide range of signals including music.  Stereophonic operation\n   has also
      been added.  A new, high-efficiency hybrid stereo coding\n   algorithm enables
      stereo operation at bit-rates as low as 6.2 kbit/s.\n   The AMR-WB+ codec includes
      the nine frame types specified for AMR-WB,\n   extended by new bit-rates ranging
      from 5.2 to 48 kbit/s.  The AMR-WB\n   frame types can employ only a 16000 Hz
      sampling frequency and operate\n   only on monophonic signals.  The newly introduced
      extension frame\n   types, however, can operate at a number of internal sampling\n
      \  frequencies (ISFs), both in mono and stereo.  Please see Table 24 in\n   [1]
      for details.  The output sampling frequency of the decoder is\n   limited to
      8, 16, 24, 32, or 48 kHz.\n   An overview of the AMR-WB+ encoding operations
      is provided as\n   follows.  The encoder receives the audio sampled at, for
      example, 48\n   kHz.  The encoding process starts with pre-processing and resampling\n
      \  to the user-selected ISF.  The encoding is performed on equally sized\n   super-frames.
      \ Each super-frame corresponds to 2048 samples per\n   channel, at the ISF.
      \ The codec carries out a number of encoding\n   decisions for each super-frame,
      thereby choosing between different\n   encoding algorithms and block lengths,
      so as to achieve a fidelity-\n   optimized encoding adapted to the signal characteristics
      of the\n   source.  The stereo encoding (if used) executes separately from the\n
      \  monophonic core encoding, thus enabling the selection of different\n   combinations
      of core and stereo encoding rates.  The resulting\n   encoded audio is produced
      in four transport frames of equal length.\n   Each transport frame corresponds
      to 512 samples at the ISF and is\n   individually usable by the decoder, provided
      that its position in the\n   super-frame structure is known.\n   The codec supports
      13 different ISFs, ranging from 12.8 to 38.4 kHz,\n   as described by Table
      24 of [1].  The high number of ISFs allows a\n   trade-off between the audio
      bandwidth and the target bit-rate.  As\n   encoding is performed on 2048 samples
      at the ISF, the duration of a\n   super-frame and the effective bit-rate of
      the frame type in use\n   varies.\n   The ISF of 25600 Hz has a super-frame
      duration of 80 ms.  This is the\n   'nominal' value used to describe the encoding
      bit-rates henceforth.\n   Assuming this normalization, the ISF selection results
      in bit-rate\n   variations from 1/2 up to 3/2 of the nominal bit-rate.\n   The
      encoding for the extension modes is performed as one monophonic\n   core encoding
      and one stereo encoding.  The core encoding is executed\n   by splitting the
      monophonic signal into a lower and a higher\n   frequency band.  The lower band
      is encoded employing either algebraic\n   code excited linear prediction (ACELP)
      or transform coded excitation\n   (TCX).  This selection can be made once per
      transport frame, but must\n   obey certain limitations of legal combinations
      within the super-\n   frame.  The higher band is encoded using a low-rate parametric\n
      \  bandwidth extension approach.\n   The stereo signal is encoded employing
      a similar frequency band\n   decomposition; however, here the signal is divided
      into three bands\n   that are individually parameterized.\n   The total bit-rate
      produced by the extension is the result of the\n   combination of the encoder's
      core rate, stereo rate, and ISF.  The\n   extension supports 8 different core
      encoding rates, producing bit-\n   rates between 10.4 and 24.0 kbit/s; see Table
      22 in [1].  There are\n   16 stereo encoding rates generating bit-rates between
      2.0 and 8.0\n   kbit/s; see Table 23 in [1].  The frame type uniquely identifies
      the\n   AMR-WB modes, 4 fixed extension rates (see below), 24 combinations of\n
      \  core and stereo rates for stereo signals, and the 8 core rates for\n   mono
      signals, as listed in Table 25 in [1].  This implies that the\n   AMR-WB+ supports
      encoding rates between 10.4 and 32 kbit/s, assuming\n   an ISF of 25600 Hz.\n
      \  Different ISFs allow for additional freedom in the produced bit-rates\n   and
      audio quality.  The selection of an ISF changes the available\n   audio bandwidth
      of the reconstructed signal, and also the total bit-\n   rate.  The bit-rate
      for a given combination of frame type and ISF is\n   determined by multiplying
      the frame type's bit-rate with the used\n   ISF's bit-rate factor; see Table
      24 in [1].\n   The extension also has four frame types which have fixed ISFs.\n
      \  Please see frame types 10-13 in Table 21 in [1].  These four pre-\n   defined
      frame types have a fixed input sampling frequency at the\n   encoder, which
      can be set at either 16 or 24 kHz.  Like the AMR-WB\n   frame types, transport
      frames encoded utilizing these frame types\n   represent exactly 20 ms of the
      audio signal.  However, they are also\n   part of 80 ms super-frames.  Frame
      types 0-13 (AMR-WB and fixed\n   extension rates), as listed in Table 21 in
      [1], do not require an\n   explicit ISF indication.  The other frame types,
      14-47, require the\n   ISF employed to be indicated.\n   The 32 different frame
      types of the extension, in combination with 13\n   ISFs, allows for a great
      flexibility in bit-rate and selection of\n   desired audio quality.  A number
      of combinations exist that produce\n   the same codec bit-rate.  For example,
      a 32 kbit/s audio stream can\n   be produced by utilizing frame type 41 (i.e.,
      25.6 kbit/s) and the\n   ISF of 32kHz (5/4 * (19.2+6.4) = 32 kbit/s), or frame
      type 47 and the\n   ISF of 25.6 kHz (1 * (24 + 8) = 32 kbit/s).  Which combination
      is\n   more beneficial for the perceived audio quality depends on the\n   content.
      \ In the above example, the first case provides a higher\n   audio bandwidth,
      while the second one spends the same number of bits\n   on somewhat narrower
      audio bandwidth but provides higher fidelity.\n   Encoders are free to select
      the combination they deem most\n   beneficial.\n   Since a transport frame always
      corresponds to 512 samples at the used\n   ISF, its duration is limited to the
      range 13.33 to 40 ms; see Table\n   1.  An RTP Timestamp clock rate of 72000
      Hz, as mandated by this\n   specification, results in AMR-WB+ transport frame
      lengths of 960 to\n   2880 timestamp ticks, depending solely on the selected
      ISF.\n      Index   ISF   Duration(ms) Duration(TS Ticks @ 72 kHz)\n      ------------------------------------------------------\n
      \       0     N/A      20             1440\n        1    12800     40             2880\n
      \       2    14400     35.55          2560\n        3    16000     32             2304\n
      \       4    17067     30             2160\n        5    19200     26.67          1920\n
      \       6    21333     24             1728\n        7    24000     21.33          1536\n
      \       8    25600     20             1440\n        9    28800     17.78          1280\n
      \      10    32000     16             1152\n       11    34133     15             1080\n
      \      12    36000     14.22          1024\n       13    38400     13.33           960\n
      \     Table 1: Normative number of RTP Timestamp Ticks for each\n               Transport
      Frame depending on ISF (ISF and Duration in\n               ms are rounded)\n
      \  The encoder is free to change both the ISF and the encoding frame\n   type
      (both mono and stereo) during a session.  For the extension\n   frame types
      with index 10-13 and 16-47, the ISF and frame type\n   changes are constrained
      to occur at super-frame boundaries.  This\n   implies that, for the frame types
      mentioned, the ISF is constant\n   throughout a super-frame.  This limitation
      does not apply for frame\n   types with index 0-9, 14, and 15; i.e., the original
      AMR-WB frame\n   types.\n   A number of features of the AMR-WB+ codec require
      special\n   consideration from a transport point of view, and solutions that\n
      \  could perhaps be viewed as unorthodox.  First, there are constraints\n   on
      the RTP timestamping, due to the relationship of the frame\n   duration and
      the ISFs.  Second, each frame of encoded audio must\n   maintain information
      about its frame type, ISF, and position in the\n   super-frame.\n"
    title: 3.1.  The AMR-WB+ Audio Codec
  - contents:
    - "3.2.  Multi-rate Encoding and Rate Adaptation\n   The multi-rate encoding capability
      of AMR-WB+ is designed to preserve\n   high audio quality under a wide range
      of bandwidth requirements and\n   transmission conditions.\n   AMR-WB+ enables
      seamless switching between frame types that use the\n   same number of audio
      channels and the same ISF.  Every AMR-WB+ codec\n   implementation is required
      to support all frame types defined by the\n   codec and must be able to handle
      switching between any two frame\n   types.  Switching between frame types employing
      a different number of\n   audio channels or a different ISF must also be supported,
      but it may\n   not be completely seamless.  Therefore, it is recommended to
      perform\n   such switching infrequently and, if possible, during periods of\n
      \  silence.\n"
    title: 3.2.  Multi-rate Encoding and Rate Adaptation
  - contents:
    - "3.3.  Voice Activity Detection and Discontinuous Transmission\n   AMR-WB+ supports
      the same algorithms as AMR-WB for voice activity\n   detection (VAD) and generation
      of comfort noise (CN) parameters\n   during silence periods.  However, these
      functionalities can only be\n   used in conjunction with the AMR-WB frame types
      (FT=0-8).  This\n   option allows reducing the number of transmitted bits and
      packets\n   during silence periods to a minimum.  The operation of sending CN\n
      \  parameters at regular intervals during silence periods is usually\n   called
      discontinuous transmission (DTX) or source controlled rate\n   (SCR) operation.
      \ The AMR-WB+ frames containing CN parameters are\n   called Silence Indicator
      (SID) frames.  More details about the VAD\n   and DTX functionality are provided
      in [4] and [5].\n"
    title: 3.3.  Voice Activity Detection and Discontinuous Transmission
  - contents:
    - "3.4.  Support for Multi-Channel Session\n   Some of the AMR-WB+ frame types
      support the encoding of stereophonic\n   audio.  Because of this native support
      for a two-channel stereophonic\n   signal, it does not seem necessary to support
      multi-channel transport\n   with separate codec instances, as specified in the
      AMR-WB RTP payload\n   [7].  The codec has the capability of stereo to mono
      downmixing as\n   part of the decoding process.  Thus, a receiver that is only
      capable\n   of playout of monophonic audio must still be able to decode and
      play\n   signals originally encoded and transmitted as stereo.  However, to\n
      \  avoid spending bits on a stereo encoding that is not going to be\n   utilized,
      a mechanism is defined in this specification to signal\n   mono-only audio.\n"
    title: 3.4.  Support for Multi-Channel Session
  - contents:
    - "3.5.  Unequal Bit-Error Detection and Protection\n   The audio bits encoded
      in each AMR-WB frame are sorted according to\n   their different perceptual
      sensitivity to bit errors.  In cellular\n   systems, for example, this property
      can be exploited to achieve\n   better voice quality, by using unequal error
      protection and detection\n   (UEP and UED) mechanisms.  However, the bits of
      the extension frame\n   types of the AMR-WB+ codec do not have a consistent
      perceptual\n   significance property and are not sorted in this order.  Thus,
      UEP or\n   UED is meaningless with the extension frame types.  If there is a\n
      \  need to use UEP or UED for AMR-WB frame types, it is recommended that\n   RFC
      3267 [7] be used.\n"
    title: 3.5.  Unequal Bit-Error Detection and Protection
  - contents:
    - "3.6.  Robustness against Packet Loss\n   The payload format supports two mechanisms
      to improve robustness\n   against packet loss: simple forward error correction
      (FEC) and frame\n   interleaving.\n"
    - contents:
      - "3.6.1.  Use of Forward Error Correction (FEC)\n   Generic forward error correction
        within RTP is defined, for example,\n   in RFC 2733 [11].  Audio redundancy
        coding is defined in RFC 2198\n   [12].  Either scheme can be used to add
        redundant information to the\n   RTP packet stream and make it more resilient
        to packet losses, at the\n   expense of a higher bit rate.  Please see either
        RFC for a discussion\n   of the implications of the higher bit rate to network
        congestion.\n   In addition to these media-unaware mechanisms, this memo specifies
        an\n   AMR-WB+ specific form of audio redundancy coding, which may be\n   beneficial
        in terms of packetization overhead.\n   Conceptually, previously transmitted
        transport frames are aggregated\n   together with new ones.  A sliding window
        is used to group the frames\n   to be sent in each payload.  Figure 1 below
        shows an example.\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \    | f(n-2) | f(n-1) |  f(n)  | f(n+1) | f(n+2) | f(n+3) | f(n+4) |\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \    <---- p(n-1) ---->\n              <----- p(n) ----->\n                       <----
        p(n+1) ---->\n                                <---- p(n+2) ---->\n                                         <----
        p(n+3) ---->\n                                                  <---- p(n+4)
        ---->\n   Figure 1: An example of redundant transmission\n   Here, each frame
        is retransmitted once in the following RTP payload\n   packet.  F(n-2)...f(n+4)
        denote a sequence of audio frames, and\n   p(n-1)...p(n+4) a sequence of payload
        packets.\n   The mechanism described does not require signaling at the session\n
        \  setup.  In other words, the audio sender can choose to use this\n   scheme
        without consulting the receiver.  For a certain timestamp, the\n   receiver
        may receive multiple copies of a frame containing encoded\n   audio data or
        frames indicated as NO_DATA.  The cost of this scheme\n   is bandwidth and
        the receiver delay necessary to allow the redundant\n   copy to arrive.\n
        \  This redundancy scheme provides a functionality similar to the one\n   described
        in RFC 2198, but it works only if both original frames and\n   redundant representations
        are AMR-WB+ frames.  When the use of other\n   media coding schemes is desirable,
        one has to resort to RFC 2198.\n   The sender is responsible for selecting
        an appropriate amount of\n   redundancy based on feedback about the channel
        conditions, e.g., in\n   the RTP Control Protocol (RTCP) [3] receiver reports.
        \ The sender is\n   also responsible for avoiding congestion, which may be
        exacerbated by\n   redundancy (see Section 5 for more details).\n"
      title: 3.6.1.  Use of Forward Error Correction (FEC)
    - contents:
      - "3.6.2.  Use of Frame Interleaving\n   To decrease protocol overhead, the
        payload design allows several\n   audio transport frames to be encapsulated
        into a single RTP packet.\n   One of the drawbacks of such an approach is
        that in case of packet\n   loss several consecutive frames are lost.  Consecutive
        frame loss\n   normally renders error concealment less efficient and usually
        causes\n   clearly audible and annoying distortions in the reconstructed audio.\n
        \  Interleaving of transport frames can improve the audio quality in\n   such
        cases by distributing the consecutive losses into a number of\n   isolated
        frame losses, which are easier to conceal.  However,\n   interleaving and
        bundling several frames per payload also increases\n   end-to-end delay and
        sets higher buffering requirements.  Therefore,\n   interleaving is not appropriate
        for all use cases or devices.\n   Streaming applications should most likely
        be able to exploit\n   interleaving to improve audio quality in lossy transmission\n
        \  conditions.\n   Note that this payload design supports the use of frame
        interleaving\n   as an option.  The usage of this feature needs to be negotiated
        in\n   the session setup.\n   The interleaving supported by this format is
        rather flexible.  For\n   example, a continuous pattern can be defined, as
        depicted in Figure\n   2.\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \    | f(n-2) | f(n-1) |  f(n)  | f(n+1) | f(n+2) | f(n+3) | f(n+4) |\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \             [ P(n)   ]\n     [ P(n+1) ]                 [ P(n+1) ]\n                       [
        P(n+2) ]                 [ P(n+2) ]\n                                         [
        P(n+3) ]                 [P(\n                                                           [
        P(n+4) ]\n   Figure 2: An example of interleaving pattern that has constant
        delay\n   In Figure 2 the consecutive frames, denoted f(n-2) to f(n+4), are\n
        \  aggregated into packets P(n) to P(n+4), each packet carrying two\n   frames.
        \ This approach provides an interleaving pattern that allows\n   for constant
        delay in both the interleaving and deinterleaving\n   processes.  The deinterleaving
        buffer needs to have room for at least\n   three frames, including the one
        that is ready to be consumed.  The\n   storage space for three frames is needed,
        for example, when f(n) is\n   the next frame to be decoded: since frame f(n)
        was received in packet\n   P(n+2), which also carried frame f(n+3), both these
        frames are stored\n   in the buffer.  Furthermore, frame f(n+1) received in
        the previous\n   packet, P(n+1), is also in the deinterleaving buffer.  Note
        also that\n   in this example the buffer occupancy varies: when frame f(n+1)
        is the\n   next one to be decoded, there are only two frames, f(n+1) and f(n+3),\n
        \  in the buffer.\n"
      title: 3.6.2.  Use of Frame Interleaving
    title: 3.6.  Robustness against Packet Loss
  - contents:
    - "3.7.  AMR-WB+ Audio over IP Scenarios\n   Since the primary target application
      for the AMR-WB+ codec is\n   streaming over packet networks, the most relevant
      usage scenario for\n   this payload format is IP end-to-end between a server
      and a terminal,\n   as shown in Figure 3.\n              +----------+                          +----------+\n
      \             |          |    IP/UDP/RTP/AMR-WB+    |          |\n              |
      \ SERVER  |<------------------------>| TERMINAL |\n              |          |
      \                         |          |\n              +----------+                          +----------+\n
      \              Figure 3: Server to terminal IP scenario\n"
    title: 3.7.  AMR-WB+ Audio over IP Scenarios
  - contents:
    - "3.8.  Out-of-Band Signaling\n   Some of the options of this payload format
      remain constant throughout\n   a session.  Therefore, they can be controlled/negotiated
      at the\n   session setup.  Throughout this specification, these options and\n
      \  variables are denoted as \"parameters to be established through out-\n   of-band
      means\".  In Section 7, all the parameters are formally\n   specified in the
      form of media type registration for the AMR-WB+\n   encoding.  The method used
      to signal these parameters at session\n   setup or to arrange prior agreement
      of the participants is beyond the\n   scope of this document; however, Section
      7.2 provides a mapping of\n   the parameters into the Session Description Protocol
      (SDP) [6] for\n   those applications that use SDP.\n"
    title: 3.8.  Out-of-Band Signaling
  title: 3.  Background of AMR-WB+ and Design Principles
- contents:
  - "4.  RTP Payload Format for AMR-WB+\n   The main emphasis in the payload design
    for AMR-WB+ has been to\n   minimize the overhead in typical use cases, while
    providing full\n   flexibility with a slightly higher overhead.  In order to keep
    the\n   specification reasonably simple, we refrained from defining frame-\n   specific
    parameters for each frame type.  Instead, a few common\n   parameters were specified
    that cover all types of frames.\n   The payload format has two modes: basic mode
    and interleaved mode.\n   The main structural difference between the two modes
    is the extension\n   of the table of content entries with frame displacement fields
    when\n   operating in the interleaved mode.  The basic mode supports\n   aggregation
    of multiple consecutive frames in a payload.  The\n   interleaved mode supports
    aggregation of multiple frames that are\n   non-consecutive in time.  In both
    modes it is possible to have frames\n   encoded with different frame types in
    the same payload.  The ISF must\n   remain constant throughout the payload of
    a single packet.\n   The payload format is designed around the property of AMR-WB+
    frames\n   that the frames are consecutive in time and share the same frame\n
    \  duration (in the absence of an ISF change).  This enables the\n   receiver
    to derive the timestamp for an individual frame within a\n   payload.  In basic
    mode, the deriving process is based on the order\n   of frames.  In interleaved
    mode, it is based on the compact\n   displacement fields.  The frame timestamps
    are used to regenerate the\n   correct order of frames after reception, identify
    duplicates, and\n   detect lost frames that require concealment.\n   The interleaving
    scheme of this payload format is significantly more\n   flexible than the one
    specified in RFC 3267.  The AMR and AMR-WB\n   payload format is only capable
    of using periodic patterns with frames\n   taken from an interleaving group at
    fixed intervals.  The\n   interleaving scheme of this specification, in contrast,
    allows for\n   any interleaving pattern, as long as the distance in decoding order\n
    \  between any two adjacent frames is not more than 256 frames.  Note\n   that
    even at the highest ISF this allows an interleaving depth of up\n   to 3.41 seconds.\n
    \  To allow for error resiliency through redundant transmission, the\n   periods
    covered by multiple packets MAY overlap in time.  A receiver\n   MUST be prepared
    to receive any audio frame multiple times.  All\n   redundantly sent frames MUST
    use the same frame type and ISF, and\n   MUST have the same RTP timestamp, or
    MUST be a NO_DATA frame (FT=15).\n   The payload consists of octet-aligned elements
    (header, ToC, and\n   audio frames).  Only the audio frames for AMR-WB frame types
    (0-9)\n   require padding for octet alignment.  If additional padding is\n   desired,
    then the P bit in the RTP header MAY be set, and padding MAY\n   be appended as
    specified in [3].\n"
  - contents:
    - "4.1.  RTP Header Usage\n   The format of the RTP header is specified in [3].
      \ This payload\n   format uses the fields of the header in a manner consistent
      with that\n   specification.\n   The RTP timestamp corresponds to the sampling
      instant of the first\n   sample encoded for the first frame in the packet.  The
      timestamp\n   clock frequency SHALL be 72000 Hz.  This frequency allows the
      frame\n   duration to be integer RTP timestamp ticks for the ISFs specified
      in\n   Table 1.  It also provides reasonable conversion factors to the\n   input/output
      audio sampling frequencies supported by the codec.  See\n   Section 4.3.2.3
      for guidance on how to derive the RTP timestamp for\n   any audio frame beyond
      the first one.\n   The RTP header marker bit (M) SHALL be set to 1 whenever
      the first\n   frame carried in the packet is the first frame in a talkspurt
      (see\n   the definition of talkspurt in Section 4.1 of [9]).  For all other\n
      \  packets, the marker bit SHALL be set to zero (M=0).\n   The assignment of
      an RTP payload type for the format defined in this\n   memo is outside the scope
      of this document.  The RTP profile in use\n   either assigns a static payload
      type or mandates binding the payload\n   type dynamically.\n   The media type
      parameter \"channels\" is used to indicate the maximum\n   number of channels
      allowed for a given payload type.  A payload type\n   where channels=1 (mono)
      SHALL only carry mono content.  A payload\n   type for which channels=2 has
      been declared MAY carry both mono and\n   stereo content.  Note that this definition
      is different from the one\n   in RFC 3551 [9].  As mentioned before, the AMR-WB+
      codec handles the\n   support of stereo content and the (eventual) downmixing
      of stereo to\n   mono internally.  This makes it unnecessary to negotiate for
      the\n   number of channels for reasons other than bit-rate efficiency.\n"
    title: 4.1.  RTP Header Usage
  - contents:
    - "4.2.  Payload Structure\n   The payload consists of a payload header, a table
      of contents, and\n   the audio data representing one or more audio frames.  The
      following\n   diagram shows the general payload format layout:\n   +----------------+-------------------+----------------\n
      \  | payload header | table of contents | audio data ...\n   +----------------+-------------------+----------------\n
      \  Payloads containing more than one audio frame are called compound\n   payloads.\n
      \  The following sections describe the variations taken by the payload\n   format
      depending on the mode in use: basic mode or interleaved mode.\n"
    title: 4.2.  Payload Structure
  - contents:
    - '4.3.  Payload Definitions

      '
    - contents:
      - "4.3.1.  Payload Header\n   The payload header carries data that is common
        for all frames in the\n   payload.  The structure of the payload header is
        described below.\n    0 1 2 3 4 5 6 7\n   +-+-+-+-+-+-+-+-+\n   |   ISF   |TFI|L|\n
        \  +-+-+-+-+-+-+-+-+\n   ISF (5 bits): Indicates the Internal Sampling Frequency
        employed for\n      all frames in this payload.  The index value corresponds
        to\n      internal sampling frequency as specified in Table 24 in [1].  This\n
        \     field SHALL be set to 0 for payloads containing frames with Frame\n
        \     Type values 0-13.\n   TFI (2 bits): Transport Frame Index, from 0 (first)
        to 3 (last),\n      indicating the position of the first transport frame of
        this\n      payload in the AMR-WB+ super-frame structure.  For payloads with\n
        \     frames of only Frame Type values 0-9, this field SHALL be set to 0\n
        \     by the sender.  The TFI value for a frame of type 0-9 SHALL be\n      ignored
        by the receiver.  Note that the frame type is coded in the\n      table of
        contents (as discussed later); hence, the mentioned\n      dependencies of
        the frame type can be applied easily by\n      interpreting only values carried
        in the payload header.  It is not\n      necessary to interpret the audio
        bit stream itself.\n   L (1 bit): Long displacement field flag for payloads
        in interleaved\n      mode.  If set to 0, four-bit displacement fields are
        used to\n      indicate interleaving offset; if set to 1, displacement fields
        of\n      eight bits are used (see Section 4.3.2.2).  For payloads in the\n
        \     basic mode, this bit SHALL be set to 0 and SHALL be ignored by the\n
        \     receiver.\n   Note that frames employing different ISF values require
        encapsulation\n   in separate packets.  Thus, special considerations apply
        when\n   generating interleaved packets and an ISF change is executed.  In\n
        \  particular, frames that, according to the previously used\n   interleaving
        pattern, would be aggregated into a single packet have\n   to be separated
        into different packets, so that the aforementioned\n   condition (all frames
        in a packet share the ISF) remains true.  A\n   naive implementation that
        splits the frames with different ISF into\n   different packets can result
        in up to twice the number of RTP\n   packets, when compared to an optimal
        interleaved solution.\n   Alteration of the interleaving before and after
        the ISF change may\n   reduce the need for extra RTP packets.\n"
      title: 4.3.1.  Payload Header
    - contents:
      - "4.3.2.  The Payload Table of Contents\n   The table of contents (ToC) consists
        of a list of entries, each entry\n   corresponds to a group of audio frames
        carried in the payload, as\n   depicted below.\n   +----------------+----------------+-
        ... -+----------------+\n   |  ToC entry #1  |  ToC entry #2  |          ToC
        entry #N  |\n   +----------------+----------------+- ... -+----------------+\n
        \  When multiple groups of frames are present in a payload, the ToC\n   entries
        SHALL be placed in the packet in order of increasing RTP\n   timestamp value
        (modulo 2^32) of the first transport frame the TOC\n   entry represents.\n"
      - contents:
        - "4.3.2.1.  ToC Entry in the Basic Mode\n   A ToC entry of a payload in the
          basic mode has the following format:\n    0                   1\n    0 1
          2 3 4 5 6 7 8 9 0 1 2 3 4 5\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |F|
          Frame Type  |    #frames    |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   F
          (1 bit): If set to 1, indicates that this ToC entry is followed by\n      another
          ToC entry; if set to 0, indicates that this ToC entry is\n      the last
          one in the ToC.\n   Frame Type (FT) (7 bits): Indicates the audio codec
          frame type used\n      for the group of frames referenced by this ToC entry.
          \ FT\n      designates the combination of AMR-WB+ core and stereo rate,
          one of\n      the special AMR-WB+ frame types, the AMR-WB rate, or comfort\n
          \     noise, as specified by Table 25 in [1].\n   #frames (8 bits): Indicates
          the number of frames in the group\n      referenced by this ToC entry.  ToC
          entries with this field equal\n      to 0 (which would indicate zero frames)
          SHALL NOT be used, and\n      received packets with such a TOC entry SHALL
          be discarded.\n"
        title: 4.3.2.1.  ToC Entry in the Basic Mode
      - contents:
        - "4.3.2.2.  ToC Entry in the Interleaved Mode\n   Two different ToC entry
          formats are defined in interleaved mode.\n   They differ in the length of
          the displacement field, 4 bits or 8\n   bits.  The L-bit in the payload
          header differentiates between the two\n   modes.\n   If L=0, a ToC entry
          has the following format:\n    0                   1                   2
          \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2
          3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |F| Frame Type  |    #frames    |  DIS1 |  ...  |  DISi |  ...  |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |  ...  |  ...  |  DISn |  Padd |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  F (1 bit): See definition in 4.3.2.1.\n   Frame Type (FT) (7 bits): See
          definition in 4.3.2.1.\n   #frames (8 bits): See definition in 4.3.2.1.\n
          \  DIS1...DISn (4 bits): A list of n (n=#frames) displacement fields\n      indicating
          the displacement of the i:th (i=1..n) audio frame\n      relative to the
          preceding audio frame in the payload, in units of\n      frames.  The four-bit
          unsigned integer displacement values may be\n      between 0 and 15, indicating
          the number of audio frames in\n      decoding order between the (i-1):th
          and the i:th frame in the\n      payload.  Note that for the first ToC entry
          of the payload, the\n      value of DIS1 is meaningless.  It SHALL be set
          to zero by a sender\n      and SHALL be ignored by a receiver.  This frame's
          location in the\n      decoding order is uniquely defined by the RTP timestamp
          and TFI in\n      the payload header.  Note also that for subsequent ToC
          entries,\n      DIS1 indicates the number of frames between the last frame
          of the\n      previous group and the first frame of this group.\n   Padd
          (4 bits): To ensure octet alignment, four padding bits SHALL be\n      included
          at the end of the ToC entry in case there is odd number\n      of frames
          in the group referenced by this entry.  These bits SHALL\n      be set to
          zero and SHALL be ignored by the receiver.  If a group\n      containing
          an even number of frames is referenced by this ToC\n      entry, these padding
          bits SHALL NOT be included in the payload.\n   If L=1, a ToC entry has the
          following format:\n    0                   1                   2                   3\n
          \   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |F| Frame Type  |    #frames    |      DIS1     |      ...      |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |      ...      |     DISn      |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  F (1 bit): See definition in 4.3.2.1.\n   Frame Type (FT) (7 bits): See
          definition in 4.3.2.1.\n   #frames (8 bits): See definition in 4.3.2.1.\n
          \  DIS1...DISn (8 bits): A list of n (n=#frames) displacement fields\n      indicating
          the displacement of the i:th (i=1..n) audio frame\n      relative to the
          preceding audio frame in the payload, in units of\n      frames.  The eight-bit
          unsigned integer displacement values may be\n      between 0 and 255, indicating
          the number of audio frames in\n      decoding order between the (i-1):th
          and the i:th frame in the\n      payload.  Note that for the first ToC entry
          of the payload, the\n      value of DIS1 is meaningless.  It SHALL be set
          to zero by a sender\n      and SHALL be ignored by a receiver.  This frame's
          location in the\n      decoding order is uniquely defined by the RTP timestamp
          and TFI in\n      the payload header.  Note also that for subsequent ToC
          entries,\n      DIS1 indicates the displacement between the last frame of
          the\n      previous group and the first frame of this group.\n"
        title: 4.3.2.2.  ToC Entry in the Interleaved Mode
      - contents:
        - "4.3.2.3.  RTP Timestamp Derivation\n   The RTP Timestamp value for a frame
          SHALL be the timestamp value of\n   the first audio sample encoded in the
          frame.  The timestamp value for\n   a frame is derived differently depending
          on the payload mode, basic\n   or interleaved.  In both cases, the first
          frame in a compound packet\n   has an RTP timestamp equal to the one received
          in the RTP header.  In\n   the basic mode, the RTP time for any subsequent
          frame is derived in\n   two steps.  First, the sum of the frame durations
          (see Table 1) of\n   all the preceding frames in the payload is calculated.
          \ Then, this\n   sum is added to the RTP header timestamp value.  For example,
          let's\n   assume that the RTP Header timestamp value is 12345, the payload\n
          \  carries four frames, and the frame duration is 16 ms (ISF = 32 kHz)\n
          \  corresponding to 1152 timestamp ticks.  Then the RTP timestamp of the\n
          \  fourth frame in the payload is 12345 + 3 * 1152 = 15801.\n   In interleaved
          mode, the RTP timestamp for each frame in the payload\n   is derived from
          the RTP header timestamp and the sum of the time\n   offsets of all preceding
          frames in this payload.  The frame\n   timestamps are computed based on
          displacement fields and the frame\n   duration derived from the ISF value.
          \ Note that the displacement in\n   time between frame i-1 and frame i is
          (DISi + 1) * frame duration\n   because the duration of the (i-1):th must
          also be taken into account.\n   The timestamp of the first frame of the
          first group of frames (TS(1))\n   (i.e., the first frame of the payload)
          is the RTP header timestamp.\n   For subsequent frames in the group, the
          timestamp is computed by\n      TS(i) = TS(i-1) + (DISi + 1) * frame duration,
          \   2 < i < n\n   For subsequent groups of frames, the timestamp of the
          first frame is\n   computed by\n      TS(1) = TSprev + (DIS1 + 1) * frame
          duration,\n   where TSprev denotes the timestamp of the last frame in the
          previous\n   group.  The timestamps of the subsequent frames in the group
          are\n   computed in the same way as for the first group.\n   The following
          example derives the RTP timestamps for the frames in an\n   interleaved
          mode payload having the following header and ToC\n   information:\n   RTP
          header timestamp: 12345\n   ISF = 32 kHz\n   Frame 1 displacement field:
          DIS1 = 0\n   Frame 2 displacement field: DIS2 = 6\n   Frame 3 displacement
          field: DIS3 = 4\n   Frame 4 displacement field: DIS4 = 7\n   Assuming an
          ISF of 32 kHz, which implies a frame duration of 16 ms,\n   one frame lasts
          1152 ticks.  The timestamp of the first frame in the\n   payload is the
          RTP timestamp, i.e., TS(1) = RTP TS.  Note that the\n   displacement field
          value for this frame must be ignored.  For the\n   second frame in the payload,
          the timestamp can be calculated as TS(2)\n   = TS(1) + (DIS2 + 1) * 1152
          = 20409.  For the third frame, the\n   timestamp is TS(3) = TS(2) + (DIS3
          + 1) * 1152 = 26169.  Finally, for\n   the fourth frame of the payload,
          we have TS(4) = TS(3) + (DIS4 + 1) *\n   1152 = 35385.\n"
        title: 4.3.2.3.  RTP Timestamp Derivation
      - contents:
        - "4.3.2.4.  Frame Type Considerations\n   The value of Frame Type (FT) is
          defined in Table 25 in [1].  FT=14\n   (AUDIO_LOST) is used to denote frames
          that are lost.  A NO_DATA\n   (FT=15) frame could result from two situations:
          First, that no data\n   has been produced by the audio encoder; and second,
          that no data is\n   transmitted in the current payload.  An example for
          the latter would\n   be that the frame in question has been or will be sent
          in an earlier\n   or later packet.  The duration for these non-included
          frames is\n   dependent on the internal sampling frequency indicated by
          the ISF\n   field.\n   For frame types with index 0-13, the ISF field SHALL
          be set 0.  The\n   frame duration for these frame types is fixed to 20 ms
          in time, i.e.,\n   1440 ticks in 72 kHz.  For payloads containing only frames
          of type\n   0-9, the TFI field SHALL be set to 0 and SHALL be ignored by
          the\n   receiver.  In a payload combining frames of type 0-9 and 10-13,
          the\n   TFI values need to be set to match the transport frames of type\n
          \  10-13.  Thus, frames of type 0-9 will also have a derived TFI, which\n
          \  is ignored.\n"
        title: 4.3.2.4.  Frame Type Considerations
      - contents:
        - "4.3.2.5.  Other TOC Considerations\n   If a ToC entry with an undefined
          FT value is received, the whole\n   packet SHALL be discarded.  This is
          to avoid the loss of data\n   synchronization in the depacketization process,
          which can result in a\n   severe degradation in audio quality.\n   Packets
          containing only NO_DATA frames SHOULD NOT be transmitted.\n   Also, NO_DATA
          frames at the end of a frame sequence to be carried in\n   a payload SHOULD
          NOT be included in the transmitted packet.  The\n   AMR-WB+ SCR/DTX is identical
          with AMR-WB SCR/DTX described in [5] and\n   can only be used in combination
          with the AMR-WB frame types (0-8).\n   When multiple groups of frames are
          present, their ToC entries SHALL\n   be placed in the ToC in order of increasing
          RTP timestamp value\n   (modulo 2^32) of the first transport frame the TOC
          entry represents,\n   independent of the payload mode.  In basic mode, the
          frames SHALL be\n   consecutive in time, while in interleaved mode the frames
          MAY not\n   only be non-consecutive in time but MAY even have varying inter-frame\n
          \  distances.\n"
        title: 4.3.2.5.  Other TOC Considerations
      - contents:
        - "4.3.2.6.  ToC Examples\n   The following example illustrates a ToC for
          three audio frames in\n   basic mode.  Note that in this case all audio
          frames are encoded\n   using the same frame type, i.e., there is only one
          ToC entry.\n    0                   1\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4
          5\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   |0| Frame Type1 |  #frames =
          3  |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   The next example depicts
          a ToC of three entries in basic mode.  Note\n   that in this case the payload
          also carries three frames, but three\n   ToC entries are needed because
          the frames of the payload are encoded\n   using different frame types.\n
          \   0                   1                   2                   3\n    0
          1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |1| Frame Type1 |  #frames = 1  |1| Frame Type2 |  #frames = 1  |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |0| Frame Type3 |  #frames = 1  |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  The following example illustrates a ToC with two entries in\n   interleaved
          mode using four-bit displacement fields.  The payload\n   includes two groups
          of frames, the first one including a single\n   frame, and the other one
          consisting of two frames.\n    0                   1                   2
          \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2
          3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |1| Frame Type1 |  #frames = 1  |  DIS1 |  padd |0| Frame Type2 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |  #frames = 2  |  DIS1 |  DIS2 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n"
        title: 4.3.2.6.  ToC Examples
      title: 4.3.2.  The Payload Table of Contents
    - contents:
      - "4.3.3.  Audio Data\n   Audio data of a payload consists of zero or more audio
        frames, as\n   described in the ToC of the payload.\n   ToC entries with FT=14
        or 15 represent frame types with a length of\n   0.  Hence, no data SHALL
        be placed in the audio data section to\n   represent frames of this type.\n
        \  As already discussed, each audio frame of an extension frame type\n   represents
        an AMR-WB+ transport frame corresponding to the encoding\n   of 512 samples
        of audio, sampled with the internal sampling frequency\n   specified by the
        ISF indicator.  As an exception, frame types with\n   index 10-13 are only
        capable of using a single internal sampling\n   frequency (25600 Hz).  The
        encoding rates (combination of core bit-\n   rate and stereo bit-rate) are
        indicated in the frame type field of\n   the corresponding ToC entry.  The
        octet length of the audio frame is\n   implicitly defined by the frame type
        field and is given in Tables 21\n   and 25 of [1].  The order and numbering
        notation of the bits are as\n   specified in [1].  For the AMR-WB+ extension
        frame types and comfort\n   noise frames, the bits are in the order produced
        by the encoder.  The\n   last octet of each audio frame MUST be padded with
        zeroes at the end\n   if not all bits in the octet are used.  In other words,
        each audio\n   frame MUST be octet-aligned.\n"
      title: 4.3.3.  Audio Data
    - contents:
      - "4.3.4.  Methods for Forming the Payload\n   The payload begins with the payload
        header, followed by the table of\n   contents, which consists of a list of
        ToC entries.\n   The audio data follows the table of contents.  All the octets\n
        \  comprising an audio frame SHALL be appended to the payload as a unit.\n
        \  The audio frames are packetized in timestamp order within each group\n
        \  of frames (per ToC entry).  The groups of frames are packetized in\n   the
        same order as their corresponding ToC entries.  Note that there\n   are no
        data octets in a group having a ToC entry with FT=14 or FT=15.\n"
      title: 4.3.4.  Methods for Forming the Payload
    - contents:
      - '4.3.5.  Payload Examples

        '
      - contents:
        - "4.3.5.1.  Example 1: Basic Mode Payload Carrying Multiple Frames Encoded\n
          \         Using the Same Frame Type\n   Figure 4 depicts a payload that
          carries three AMR-WB+ frames encoded\n   using 14 kbit/s frame type (FT=26)
          with a frame length of 280 bits\n   (35 bytes).  The internal sampling frequency
          in this example is 25.6\n   kHz (ISF = 8).  The TFI for the first frame
          is 2, indicating that the\n   first transport frame in this payload is the
          third in a super-frame.\n   Since this payload is in the basic mode, the
          subsequent frames of the\n   payload are consecutive frames in decoding
          order, i.e., the fourth\n   transport frame of the current super-frame and
          the first transport\n   frame of the next super-frame.  Note that because
          the frames are all\n   encoded using the same frame type, only one ToC entry
          is required.\n    0                   1                   2                   3\n
          \   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ISF = 8 | 2 |0|0|  FT = 26    |  #frames = 3  |   f1(0...7)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...           | f1(272...279) |   f2(0...7)   |               |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | f2(272...279) |   f3(0...7)   | ...                           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                                           | f3(272...279) |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  Figure 4: An example of a basic mode payload carrying three frames\n
          \            of the same frame type\n"
        title: '4.3.5.1.  Example 1: Basic Mode Payload Carrying Multiple Frames Encoded'
      - contents:
        - "4.3.5.2.  Example 2: Basic Mode Payload Carrying Multiple Frames Encoded\n
          \         Using Different Frame Types\n   Figure 5 depicts a payload that
          carries three AMR-WB+ frames; the\n   first frame is encoded using 18.4
          kbit/s frame type (FT=33) with a\n   frame length of 368 bits (46 bytes),
          and the two subsequent frames\n   are encoded using 20 kbit/s frame type
          (FT=35) having frame length of\n   400 bits (50 bytes).  The internal sampling
          frequency in this example\n   is 32 kHz (ISF = 10), implying the overall
          bit-rates of 23 kbit/s for\n   the first frame of the payload, and 25 kbit/s
          for the subsequent\n   frames.  The TFI for the first frame is 3, indicating
          that the first\n   transport frame in this payload is the fourth in a super-frame.\n
          \  Since this is a payload in the basic mode, the subsequent frames of\n
          \  the payload are consecutive frames in decoding order, i.e., the first\n
          \  and second transport frames of the current super-frame.  Note that\n
          \  since the payload carries two different frame types, there are two\n
          \  ToC entries.\n    0                   1                   2                   3\n
          \   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |  ISF=10 | 3 |0|1|  FT = 33    |  #frames = 1  |0|  FT = 35    |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |  #frames = 2  |   f1(0...7)   | ...                           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                           | f1(360...367) |   f2(0...7)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | f2(392...399) |   f3(0...7)   | ...                           |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                           | f3(392...399) |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  Figure 5: An example of a basic mode payload carrying three frames\n
          \            employing two different frame types\n"
        title: '4.3.5.2.  Example 2: Basic Mode Payload Carrying Multiple Frames Encoded'
      - contents:
        - "4.3.5.3.  Example 3: Payload in Interleaved Mode\n   The example in Figure
          6 depicts a payload in interleaved mode,\n   carrying four frames encoded
          using 32 kbit/s frame type (FT=47) with\n   frame length of 640 bits (80
          bytes).  The internal sampling frequency\n   is 38.4 kHz (ISF = 13), implying
          a bit-rate of 48 kbit/s for all\n   frames in the payload.  The TFI for
          the first frame is 0; hence, it\n   is the first transport frame of a super-frame.
          \ The displacement\n   fields for the subsequent frames are DIS2=18, DIS3=15,
          and DIS4=10,\n   which indicates that the subsequent frames have the TFIs
          of 3, 3, and\n   2, respectively.  The long displacement field flag L in
          the payload\n   header is set to 1, which results in the use of eight bits
          for the\n   displacement fields in the ToC entry.  Note that since all frames
          of\n   this payload are encoded using the same frame type, there is need\n
          \  only for a single ToC entry.  Furthermore, the displacement field for\n
          \  the first frame (corresponding to the first ToC entry with DIS1=0)\n
          \  must be ignored, since its timestamp and TFI are defined by the RTP\n
          \  timestamp and the TFI found in the payload header.\n   The RTP timestamp
          values of the frames in this example are:\n   Frame1: TS1 = RTP Timestamp\n
          \  Frame2: TS2 = TS1 + 19 * 960\n   Frame3: TS3 = TS2 + 16 * 960\n   Frame4:
          TS4 = TS3 + 11 * 960\n    0                   1                   2                   3\n
          \   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |  ISF=13 | 0 |1|0|  FT = 47    |  #frames = 4  |   DIS1 = 0    |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  |   DIS2 = 18   |   DIS3 = 15   |   DIS4 = 10   |   f1(0...7)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                           | f1(632...639) |   f2(0...7)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                           | f2(632...639) |   f3(0...7)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                           | f3(632...639) |   f4(0...7)   |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  : ...                                                           :\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  | ...                           | f4(632...639) |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
          \  Figure 6: An example of an interleaved mode payload carrying four\n             frames
          at the same frame type\n"
        title: '4.3.5.3.  Example 3: Payload in Interleaved Mode'
      title: 4.3.5.  Payload Examples
    title: 4.3.  Payload Definitions
  - contents:
    - "4.4.  Interleaving Considerations\n   The use of interleaving requires further
      considerations.  As\n   presented in the example in Section 3.6.2, a given interleaving\n
      \  pattern requires a certain amount of the deinterleaving buffer.  This\n   buffer
      space, expressed in a number of transport frame slots, is\n   indicated by the
      \"interleaving\" media type parameter.  The number of\n   frame slots needed
      can be converted into actual memory requirements\n   by considering the 80 bytes
      per frame used by the largest combination\n   of AMR-WB+'s core and stereo rates.\n
      \  The information about the frame buffer size is not always sufficient\n   to
      determine when it is appropriate to start consuming frames from\n   the interleaving
      buffer.  There are two cases in which additional\n   information is needed:
      first, when switching of the ISF occurs, and\n   second, when the interleaving
      pattern changes.  The \"int-delay\" media\n   type parameter is defined to convey
      this information.  It allows a\n   sender to indicate the minimal media time
      that needs to be present in\n   the buffer before the decoder can start consuming
      frames from the\n   buffer.  Because the sender has full control over ISF changes
      and the\n   interleaving pattern, it can calculate this value.\n   In certain
      cases (for example, if joining a multicast session with\n   interleaving mid-session),
      a receiver may initially receive only part\n   of the packets in the interleaving
      pattern.  This initial partial\n   reception (in frame sequence order) of frames
      can yield too few\n   frames for acceptable quality from the audio decoding.
      \ This problem\n   also arises when using encryption for access control, and
      the\n   receiver does not have the previous key.\n   Although the AMR-WB+ is
      robust and thus tolerant to a high random\n   frame erasure rate, it would have
      difficulties handling consecutive\n   frame losses at startup.  Thus, some special
      implementation\n   considerations are described.  In order to handle this type
      of\n   startup efficiently, it must be noted that decoding is only possible\n
      \  to start at the beginning of a super-frame, and that holds true even\n   if
      the first transport frame is indicated as lost.  Secondly,\n   decoding is only
      RECOMMENDED to start if at least 2 transport frames\n   are available out of
      the 4 belonging to that super-frame.\n   After receiving a number of packets,
      in the worst case as many\n   packets as the interleaving pattern covers, the
      previously described\n   effects disappear and normal decoding is resumed.\n
      \  Similar issues arise when a receiver leaves a session or has lost\n   access
      to the stream.  If the receiver leaves the session, this would\n   be a minor
      issue since playout is normally stopped.  It is also a\n   minor issue for the
      case of lost access, since the AMR-WB+ error\n   concealment will fade out the
      audio if massive consecutive losses are\n   encountered.\n   The sender can
      avoid this type of problem in many sessions by\n   starting and ending interleaving
      patterns correctly when risks of\n   losses occur.  One such example is a key-change
      done for access\n   control to encrypted streams.  If only some keys are provided
      to\n   clients and there is a risk of their receiving content for which they\n
      \  do not have the key, it is recommended that interleaving patterns not\n   overlap
      key changes.\n"
    title: 4.4.  Interleaving Considerations
  - contents:
    - "4.5.  Implementation Considerations\n   An application implementing this payload
      format MUST understand all\n   the payload parameters.  Any mapping of the parameters
      to a signaling\n   protocol MUST support all parameters.  So an implementation
      of this\n   payload format in an application using SDP is required to understand\n
      \  all the payload parameters in their SDP-mapped form.  This\n   requirement
      ensures that an implementation always can decide whether\n   it is capable of
      communicating.\n   Both basic and interleaved mode SHALL be implemented.  The\n
      \  implementation burden of both is rather small, and requiring both\n   ensures
      interoperability.  As the AMR-WB+ codec contains the full\n   functionality
      of the AMR-WB codec, it is RECOMMENDED to also\n   implement the payload format
      in RFC 3267 [7] for the AMR-WB frame\n   types when implementing this specification.
      \ Doing so makes\n   interoperability with devices that only support AMR-WB
      more likely.\n   The switching of ISF, when combined with packet loss, could
      result in\n   concealment using the wrong audio frame length.  This can occur
      if\n   packet losses result in lost frames directly after the point of ISF\n
      \  change.  The packet loss would prevent the receiver from noticing the\n   changed
      ISF and thereby conceal the lost transport frame with the\n   previous ISF,
      instead of the new one.  Although always later\n   detectable, such an error
      results in frame boundary misalignment,\n   which can cause audio distortions
      and problems with synchronization,\n   as too many or too few audio samples
      were created.  This problem can\n   be mitigated in most cases by performing
      ISF recovery prior to\n   concealment as outlined in Section 4.5.1.\n"
    - contents:
      - "4.5.1.  ISF Recovery in Case of Packet Loss\n   In case of packet loss, it
        is important that the AMR-WB+ decoder\n   initiates a proper error concealment
        to replace the frames carried in\n   the lost packet.  A loss concealment
        algorithm requires a codec\n   framing that matches the timestamps of the
        correctly received frames.\n   Hence, it is necessary to recover the timestamps
        of the lost frames.\n   Doing so is non-trivial because the codec frame length
        that is\n   associated with the ISF may have changed during the frame loss.\n
        \  In the following, the recovery of the timestamp information of lost\n   frames
        is illustrated by the means of an example.  Two frames with\n   timestamps
        t0 and t1 have been received properly, the first one being\n   the last packet
        before the loss, and the latter one being the first\n   packet after the loss
        period.  The ISF values for these packets are\n   isf0 and isf1, respectively.
        \ The TFIs of these frames are tfi0 and\n   tfi1, respectively.  The associated
        frame lengths (in timestamp\n   ticks) are given as L0 and L1, respectively.
        \ In this example three\n   frames with timestamps x1 - x3 have been lost.
        \ The example further\n   assumes that ISF changes once from isf0 to isf1
        during the frame loss\n   period, as shown in the figure below.\n   Since
        not all information required for the full recovery of the\n   timestamps is
        generally known in the receiver, an algorithm is needed\n   to estimate the
        ISF associated with the lost frames.  Also, the\n   number of lost frames
        needs to be recovered.\n     |<---L0--->|<---L0--->|<-L1->|<-L1->|<-L1->|\n
        \    |   Rxd    |   lost   | lost | lost |  Rxd |\n   --+----------+----------+------+------+------+--\n
        \    t0         x1         x2     x3     t1\n   Example Algorithm:\n   Start:
        \                             # check for frame loss\n   If (t0 + L0) == t1
        Then goto End    # no frame loss\n   Step 1:                             #
        check case with no ISF change\n   If (isf0 != isf1) Then goto Step 2  # At
        least one ISF change\n   If (isFractional(t1 - t0)/L0) Then goto Step 3\n
        \                                      # More than 1 ISF change\n   Return
        recovered timestamps as\n   x(n) = t0 + n*L1 and associated ISF equal to isf0,\n
        \  for 0 < n < (t1 - t0)/L0\n   goto End\n   Step 2:\n   Loop initialization:
        n := 4 - tfi0 mod 4\n   While n <= (t1-t0)/L0\n     Evaluate m := (t1 - t0
        - n*L0)/L1\n     If (isInteger(m) AND ((tfi0+n+m) mod 4 == tfi1)) Then goto
        found;\n     n := n+4\n     endloop\n   goto step 3                         #
        More than 1 ISF change\n   found:\n   Return recovered timestamps and ISFs
        as\n   x(i) = t0 + i*L0 and associated ISF equal to isf0, for 0 < i <= n\n
        \  x(i) = t0 + n*L0 + (i-n)*L1 and associated ISF equal to isf1,\n   for n
        < i <= n+m\n   goto End\n   Step 3:\n   More than 1 ISF change has occurred.
        \ Since ISF changes can be\n   assumed to be infrequent, such a situation
        occurs only if long\n   sequences of frames are lost.  In that case it is
        probably not useful\n   to try to recover the timestamps of the lost frames.
        \ Rather, the\n   AMR-WB+ decoder should be reset, and decoding should be
        resumed\n   starting with the frame with timestamp t1.\n   End:\n   The above
        algorithm still does not solve the issue when the receiver\n   buffer depth
        is shallower than the loss burst.  In this kind of case,\n   where the concealment
        must be done without any knowledge about future\n   frames, the concealment
        may result in loss of frame boundary\n   alignment.  If that occurs, it may
        be necessary to reset and restart\n   the codec to perform resynchronization.\n"
      title: 4.5.1.  ISF Recovery in Case of Packet Loss
    - contents:
      - "4.5.2.  Decoding Validation\n   If the receiver finds a mismatch between
        the size of a received\n   payload and the size indicated by the ToC of the
        payload, the\n   receiver SHOULD discard the packet.  This is recommended
        because\n   decoding a frame parsed from a payload based on erroneous ToC
        data\n   could severely degrade the audio quality.\n"
      title: 4.5.2.  Decoding Validation
    title: 4.5.  Implementation Considerations
  title: 4.  RTP Payload Format for AMR-WB+
- contents:
  - "5.  Congestion Control\n   The general congestion control considerations for
    transporting RTP\n   data apply; see RTP [3] and any applicable RTP profile like
    AVP [9].\n   However, the multi-rate capability of AMR-WB+ audio coding provides
    a\n   mechanism that may help to control congestion, since the bandwidth\n   demand
    can be adjusted (within the limits of the codec) by selecting\n   a different
    coding frame type or lower internal sampling rate.\n   The number of frames encapsulated
    in each RTP payload highly\n   influences the overall bandwidth of the RTP stream
    due to header\n   overhead constraints.  Packetizing more frames in each RTP payload\n
    \  can reduce the number of packets sent and hence the header overhead,\n   at
    the expense of increased delay and reduced error robustness.\n   If forward error
    correction (FEC) is used, the amount of FEC-induced\n   redundancy needs to be
    regulated such that the use of FEC itself does\n   not cause a congestion problem.\n"
  title: 5.  Congestion Control
- contents:
  - "6.  Security Considerations\n   RTP packets using the payload format defined
    in this specification\n   are subject to the general security considerations discussed
    in RTP\n   [3] and any applicable profile such as AVP [9] or SAVP [10].  As this\n
    \  format transports encoded audio, the main security issues include\n   confidentiality,
    integrity protection, and data origin authentication\n   of the audio itself.
    \ The payload format itself does not have any\n   built-in security mechanisms.
    \ Any suitable external mechanisms, such\n   as SRTP [10], MAY be used.\n   This
    payload format and the AMR-WB+ decoder do not exhibit any\n   significant non-uniformity
    in the receiver-side computational\n   complexity for packet processing, and thus
    are unlikely to pose a\n   denial-of-service threat due to the receipt of pathological
    data.\n"
  - contents:
    - "6.1.  Confidentiality\n   In order to ensure confidentiality of the encoded
      audio, all audio\n   data bits MUST be encrypted.  There is less need to encrypt
      the\n   payload header or the table of contents since they only carry\n   information
      about the frame type.  This information could also be\n   useful to a third
      party, for example, for quality monitoring.\n   The use of interleaving in conjunction
      with encryption can have a\n   negative impact on confidentiality, for a short
      period of time.\n   Consider the following packets (in brackets) containing
      frame numbers\n   as indicated: {10, 14, 18}, {13, 17, 21}, {16, 20, 24} (a
      popular\n   continuous diagonal interleaving pattern).  The originator wishes
      to\n   deny some participants the ability to hear material starting at time\n
      \  16.  Simply changing the key on the packet with the timestamp at or\n   after
      16, and denying that new key to those participants, does not\n   achieve this;
      frames 17, 18, and 21 have been supplied in prior\n   packets under the prior
      key, and error concealment may make the audio\n   intelligible at least as far
      as frame 18 or 19, and possibly further.\n"
    title: 6.1.  Confidentiality
  - contents:
    - "6.2.  Authentication and Integrity\n   To authenticate the sender of the speech,
      an external mechanism MUST\n   be used.  It is RECOMMENDED that such a mechanism
      protects both the\n   complete RTP header and the payload (speech and data bits).\n
      \  Data tampering by a man-in-the-middle attacker could replace audio\n   content
      and also result in erroneous depacketization/decoding that\n   could lower the
      audio quality.\n"
    title: 6.2.  Authentication and Integrity
  title: 6.  Security Considerations
- contents:
  - "7.  Payload Format Parameters\n   This section defines the parameters that may
    be used to select\n   features of the AMR-WB+ payload format.  The parameters
    are defined\n   as part of the media type registration for the AMR-WB+ audio codec.\n
    \  A mapping of the parameters into the Session Description Protocol\n   (SDP)
    [6] is also provided for those applications that use SDP.\n   Equivalent parameters
    could be defined elsewhere for use with control\n   protocols that do not use
    MIME or SDP.\n   The data format and parameters are only specified for real-time\n
    \  transport in RTP.\n"
  - contents:
    - "7.1.  Media Type Registration\n   The media type for the Extended Adaptive
      Multi-Rate Wideband\n   (AMR-WB+) codec is allocated from the IETF tree, since
      AMR-WB+ is\n   expected to be a widely used audio codec in general streaming\n
      \  applications.\n   Note: Parameters not listed below MUST be ignored by the
      receiver.\n   Media Type name:     audio\n   Media subtype name:  AMR-WB+\n
      \  Required parameters:\n   None\n   Optional parameters:\n   channels:       The
      maximum number of audio channels used by the\n                   audio frames.
      \ Permissible values are 1 (mono) or 2\n                   (stereo).  If no
      parameter is present, the maximum\n                   number of channels is
      2 (stereo).  Note: When set to\n                   1, implicitly the stereo
      frame types cannot be used.\n   interleaving:   Indicates that interleaved mode
      SHALL\n                   be used for the payload.  The parameter specifies\n
      \                  the number of transport frame slots required in a\n                   deinterleaving
      buffer (including the frame that is\n                   ready to be consumed).
      \ Its value is equal to one\n                   plus the maximum number of frames
      that precede any\n                   frame in transmission order and follow
      the frame in\n                   RTP timestamp order.  The value MUST be greater
      than\n                   zero.  If this parameter is not present,\n                   interleaved
      mode SHALL NOT be used.\n   int-delay:      The minimal media time delay in
      RTP timestamp ticks\n                   that is needed in the deinterleaving
      buffer, i.e.,\n                   the difference in RTP timestamp ticks between
      the\n                   earliest and latest audio frame present in the\n                   deinterleaving
      buffer.\n   ptime:          See Section 6 in RFC 2327 [6].\n   maxptime:       See
      Section 8 in RFC 3267 [7].\n   Restriction on Usage:\n                This type
      is only defined for transfer via RTP (STD 64).\n   Encoding considerations:\n
      \               An RTP payload according to this format is binary data\n                and
      thus may need to be appropriately encoded in non-\n                binary environments.
      \ However, as long as used within\n                RTP, no encoding is necessary.\n
      \  Security considerations:\n                See Section 6 of RFC 4352.\n   Interoperability
      considerations:\n                To maintain interoperability with AMR-WB-capable
      end-\n                points, in cases where negotiation is possible and the\n
      \               AMR-WB+ end-point supporting this format also supports\n                RFC
      3267 for AMR-WB transport, an AMR-WB+ end-point\n                SHOULD declare
      itself also as AMR-WB capable (i.e.,\n                supporting also \"audio/AMR-WB\"
      as specified in RFC\n                3267).\n                As the AMR-WB+
      decoder is capable of performing stereo\n                to mono conversions,
      all receivers of AMR-WB+ should be\n                able to receive both stereo
      and mono, although the\n                receiver is only capable of playout
      of mono signals.\n   Public specification:\n                RFC 4352\n                3GPP
      TS 26.290, see reference [1] of RFC 4352\n   Additional information:\n                This
      MIME type is not applicable for file storage.\n                Instead, file
      storage of AMR-WB+ encoded audio is\n                specified within the 3GPP-defined
      ISO-based multimedia\n                file format defined in 3GPP TS 26.244;
      see reference\n                [14] of RFC 4352.  This file format has the MIME
      types\n                \"audio/3GPP\" or \"video/3GPP\" as defined by RFC 3839\n
      \               [15].\n   Person & email address to contact for further information:\n
      \               magnus.westerlund@ericsson.com\n                ari.lakaniemi@nokia.com\n
      \  Intended usage: COMMON.\n                It is expected that many IP-based
      streaming\n                applications will use this type.\n   Change controller:\n
      \               IETF Audio/Video Transport working group delegated from\n                the
      IESG.\n"
    title: 7.1.  Media Type Registration
  - contents:
    - "7.2.  Mapping Media Type Parameters into SDP\n   The information carried in
      the media type specification has a\n   specific mapping to fields in the Session
      Description Protocol (SDP)\n   [6], which is commonly used to describe RTP sessions.
      \ When SDP is\n   used to specify an RTP session using this RTP payload format,
      the\n   mapping is as follows:\n   -  The media type (\"audio\") is used in
      SDP \"m=\" as the media name.\n   -  The media type (payload format name) is
      used in SDP \"a=rtpmap\" as\n      the encoding name.  The RTP clock rate in
      \"a=rtpmap\" SHALL be\n      72000 for AMR-WB+, and the encoding parameter number
      of channels\n      MUST either be explicitly set to 1 or 2, or be omitted, implying\n
      \     the default value of 2.\n   -  The parameters \"ptime\" and \"maxptime\"
      are placed in the SDP\n      attributes \"a=ptime\" and \"a=maxptime\", respectively.\n
      \  -  Any remaining parameters are placed in the SDP \"a=fmtp\" attribute\n
      \     by copying them directly from the MIME media type string as a\n      semicolon-separated
      list of parameter=value pairs.\n"
    - contents:
      - "7.2.1.  Offer-Answer Model Considerations\n   To achieve good interoperability
        in an Offer-Answer [8] negotiation\n   usage, the following considerations
        should be taken into account:\n   For negotiable offer/answer usage the following
        interpretation rules\n   SHALL be applied:\n   -  The \"interleaving\" parameter
        is symmetric, thus requiring that the\n      answerer must also include it
        for the answer to an offered payload\n      type that contains the parameter.
        \ However, the buffer space value\n      is declarative in usage in unicast.
        \ For multicast usage, the same\n      value in the response is required in
        order to accept the payload\n      type.  For streams declared as sendrecv
        or recvonly: The receiver\n      will accept reception of streams using the
        interleaved mode of the\n      payload format.  The value declares the amount
        of buffer space the\n      receiver has available for the sender to utilize.
        \ For sendonly\n      streams, the parameter indicates the desired configuration
        and\n      amount of buffer space.  An answerer is RECOMMENDED to respond\n
        \     using the offered value, if capable of using it.\n   -  The \"int-delay\"
        parameter is declarative.  For streams declared as\n      sendrecv or recvonly,
        the value indicates the maximum initial\n      delay the receiver will accept
        in the deinterleaving buffer.  For\n      sendonly streams, the value is the
        amount of media time the sender\n      desires to use.  The value SHOULD be
        copied into any response.\n   -  The \"channels\" parameter is declarative.
        \ For \"sendonly\" streams,\n      it indicates the desired channel usage,
        stereo and mono, or mono\n      only.  For \"recvonly\" and \"sendrecv\" streams,
        the parameter\n      indicates what the receiver accepts to use.  As any receiver
        will\n      be capable of receiving stereo frame type and perform local mixing\n
        \     within the AMR-WB+ decoder, there is normally only one reason to\n      restrict
        to mono only: to avoid spending bit-rate on data that are\n      not utilized
        if the front-end is only capable of mono.\n   -  The \"ptime\" parameter works
        as indicated by the offer/answer model\n      [8]; \"maxptime\" SHALL be used
        in the same way.\n   -  To maintain interoperability with AMR-WB in cases
        where\n      negotiation is possible, an AMR-WB+ capable end-point that also\n
        \     implements the AMR-WB payload format [7] is RECOMMENDED to declare\n
        \     itself capable of AMR-WB as it is a subset of the AMR-WB+ codec.\n   In
        declarative usage, like SDP in RTSP [16] or SAP [17], the\n   following interpretation
        of the parameters SHALL be done:\n   -  The \"interleaving\" parameter, if
        present, configures the payload\n      format in that mode, and the value
        indicates the number of frames\n      that the deinterleaving buffer is required
        to support to be able\n      to handle this session correctly.\n   -  The
        \"int-delay\" parameter indicates the initial buffering delay\n      required
        to receive this stream correctly.\n   -  The \"channels\" parameter indicates
        if the content being\n      transmitted can contain either both stereo and
        mono rates, or only\n      mono.\n   -  All other parameters indicate values
        that are being used by the\n      sending entity.\n"
      title: 7.2.1.  Offer-Answer Model Considerations
    - contents:
      - "7.2.2.  Examples\n   One example of an SDP session description utilizing
        AMR-WB+ mono and\n   stereo encoding follows.\n    m=audio 49120 RTP/AVP 99\n
        \   a=rtpmap:99 AMR-WB+/72000/2\n    a=fmtp:99 interleaving=30; int-delay=86400\n
        \   a=maxptime:100\n   Note that the payload format (encoding) names are commonly
        shown in\n   uppercase.  Media subtypes are commonly shown in lowercase.  These\n
        \  names are case-insensitive in both places.  Similarly, parameter\n   names
        are case-insensitive both in MIME types and in the default\n   mapping to
        the SDP a=fmtp attribute.\n"
      title: 7.2.2.  Examples
    title: 7.2.  Mapping Media Type Parameters into SDP
  title: 7.  Payload Format Parameters
- contents:
  - "8.  IANA Considerations\n   The IANA has registered one new MIME subtype (audio/amr-wb+);
    see\n   Section 7.\n"
  title: 8.  IANA Considerations
- contents:
  - "9.  Contributors\n   Daniel Enstrom has contributed in writing the codec introduction\n
    \  section.  Stefan Bruhn has contributed by writing the ISF recovery\n   algorithm.\n"
  title: 9.  Contributors
- contents:
  - "10.  Acknowledgements\n   The authors would like to thank Redwan Salami and Stefan
    Bruhn for\n   their significant contributions made throughout the writing and\n
    \  reviewing of this document.  Dave Singer contributed by reviewing and\n   suggesting
    improved language.  Anisse Taleb and Ingemar Johansson\n   contributed by implementing
    the payload format and thus helped locate\n   some flaws.  We would also like
    to acknowledge Qiaobing Xie, coauthor\n   of RFC 3267, on which this document
    is based.\n"
  title: 10.  Acknowledgements
- contents:
  - '11.  References

    '
  - contents:
    - "11.1.  Normative References\n   [1]  3GPP TS 26.290 \"Audio codec processing
      functions; Extended\n        Adaptive Multi-Rate Wideband (AMR-WB+) codec; Transcoding\n
      \       functions\", version 6.3.0 (2005-06), 3rd Generation Partnership\n        Project
      (3GPP).\n   [2]  Bradner, S., \"Key words for use in RFCs to Indicate Requirement\n
      \       Levels\", BCP 14, RFC 2119, March 1997.\n   [3]  Schulzrinne, H.,  Casner,
      S., Frederick, R., and V. Jacobson,\n        \"RTP: A Transport Protocol for
      Real-Time Applications\", STD 64,\n        RFC 3550, July 2003.\n   [4]  3GPP
      TS 26.192 \"AMR Wideband speech codec; Comfort Noise\n        aspects\", version
      6.0.0 (2004-12), 3rd Generation Partnership\n        Project (3GPP).\n   [5]
      \ 3GPP TS 26.193 \"AMR Wideband speech codec; Source Controlled\n        Rate
      operation\", version 6.0.0 (2004-12), 3rd Generation\n        Partnership Project
      (3GPP).\n   [6]  Handley, M. and V. Jacobson, \"SDP: Session Description\n        Protocol\",
      RFC 2327, April 1998.\n   [7]  Sjoberg, J., Westerlund, M., Lakaniemi, A., and
      Q. Xie, \"Real-\n        Time Transport Protocol (RTP) Payload Format and File
      Storage\n        Format for the Adaptive Multi-Rate (AMR) and Adaptive Multi-Rate\n
      \       Wideband (AMR-WB) Audio Codecs\", RFC 3267, June 2002.\n   [8]  Rosenberg,
      J. and H. Schulzrinne, \"An Offer/Answer Model with\n        Session Description
      Protocol (SDP)\", RFC 3264, June 2002.\n   [9]  Schulzrinne, H. and S. Casner,
      \"RTP Profile for Audio and Video\n        Conferences with Minimal Control\",
      STD 65, RFC 3551, July 2003.\n"
    title: 11.1.  Normative References
  - contents:
    - "11.2.  Informative References\n   [10] Baugher, M., McGrew, D., Naslund, M.,
      Carrara, E., and K.\n        Norrman, \"The Secure Real-time Transport Protocol
      (SRTP)\", RFC\n        3711, March 2004.\n   [11] Rosenberg, J. and H. Schulzrinne,
      \"An RTP Payload Format for\n        Generic Forward Error Correction\", RFC
      2733, December 1999.\n   [12] Perkins, C., Kouvelas, I., Hodson, O., Hardman,
      V., Handley, M.,\n        Bolot, J., Vega-Garcia, A., and S. Fosse-Parisis,
      \"RTP Payload\n        for Redundant Audio Data\", RFC 2198, September 1997.\n
      \  [13] 3GPP TS 26.233 \"Packet Switched Streaming service\", version\n        5.7.0
      (2005-03), 3rd Generation Partnership Project (3GPP).\n   [14] 3GPP TS 26.244
      \"Transparent end-to-end packet switched streaming\n        service (PSS); 3GPP
      file format (3GP)\", version 6.4.0 (2005-09),\n        3rd Generation Partnership
      Project (3GPP).\n   [15] Castagno, R. and D. Singer, \"MIME Type Registrations
      for 3rd\n        Generation Partnership Project (3GPP) Multimedia files\", RFC\n
      \       3839, July 2004.\n   [16] Schulzrinne, H., Rao, A., and R. Lanphier,
      \"Real Time Streaming\n        Protocol (RTSP)\", RFC 2326, April 1998.\n   [17]
      Handley, M., Perkins, C., and E. Whelan, \"Session Announcement\n        Protocol\",
      RFC 2974, October 2000.\n   [18] 3GPP TS 26.140 \"Multimedia Messaging Service
      (MMS); Media\n        formats and codes\", version 6.2.0 (2005-03), 3rd Generation\n
      \       Partnership Project (3GPP).\n   [19] 3GPP TS 26.140 \"Multimedia Broadcast/Multicast
      Service (MBMS);\n        Protocols and codecs\", version 6.3.0 (2005-12), 3rd
      Generation\n        Partnership Project (3GPP).\n   Any 3GPP document can be
      downloaded from the 3GPP webserver,\n   \"http://www.3gpp.org/\", see specifications.\n"
    title: 11.2.  Informative References
  title: 11.  References
- contents:
  - "Authors' Addresses\n   Johan Sjoberg\n   Ericsson Research\n   Ericsson AB\n
    \  SE-164 80 Stockholm\n   SWEDEN\n   Phone: +46 8 7190000\n   EMail: Johan.Sjoberg@ericsson.com\n
    \  Magnus Westerlund\n   Ericsson Research\n   Ericsson AB\n   SE-164 80 Stockholm\n
    \  SWEDEN\n   Phone: +46 8 7190000\n   EMail: Magnus.Westerlund@ericsson.com\n
    \  Ari Lakaniemi\n   Nokia Research Center\n   P.O. Box 407\n   FIN-00045 Nokia
    Group\n   FINLAND\n   Phone: +358-71-8008000\n   EMail: ari.lakaniemi@nokia.com\n
    \  Stephan Wenger\n   Nokia Corporation\n   P.O. Box 100\n   FIN-33721 Tampere\n
    \  FINLAND\n   Phone: +358-50-486-0637\n   EMail: Stephan.Wenger@nokia.com\n"
  title: Authors' Addresses
- contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2006).\n   This
    document is subject to the rights, licenses and restrictions\n   contained in
    BCP 78, and except as set forth therein, the authors\n   retain all their rights.\n
    \  This document and the information contained herein are provided on an\n   \"AS
    IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n   OR IS SPONSORED
    BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET\n   ENGINEERING TASK FORCE
    DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT LIMITED TO
    ANY WARRANTY THAT THE USE OF THE\n   INFORMATION HEREIN WILL NOT INFRINGE ANY
    RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR
    PURPOSE.\n"
  title: Full Copyright Statement
- contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or
    scope of any\n   Intellectual Property Rights or other rights that might be claimed
    to\n   pertain to the implementation or use of the technology described in\n   this
    document or the extent to which any license under such rights\n   might or might
    not be available; nor does it represent that it has\n   made any independent effort
    to identify any such rights.  Information\n   on the procedures with respect to
    rights in RFC documents can be\n   found in BCP 78 and BCP 79.\n   Copies of IPR
    disclosures made to the IETF Secretariat and any\n   assurances of licenses to
    be made available, or the result of an\n   attempt made to obtain a general license
    or permission for the use of\n   such proprietary rights by implementers or users
    of this\n   specification can be obtained from the IETF on-line IPR repository
    at\n   http://www.ietf.org/ipr.\n   The IETF invites any interested party to bring
    to its attention any\n   copyrights, patents or patent applications, or other
    proprietary\n   rights that may cover technology that may be required to implement\n
    \  this standard.  Please address the information to the IETF at\n   ietf-ipr@ietf.org.\n"
  title: Intellectual Property
- contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is provided by the IETF\n
    \  Administrative Support Activity (IASA).\n"
  title: Acknowledgement
