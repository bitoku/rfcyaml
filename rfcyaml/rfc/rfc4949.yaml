- title: __initial_text__
  contents:
  - '                 Internet Security Glossary, Version 2

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The IETF Trust (2007).\n   This document is\
    \ both a major revision and a major expansion of the\n   Security Glossary in\
    \ RFC 2828. This revised Glossary is an extensive\n   reference that should help\
    \ the Internet community to improve the\n   clarity of documentation and discussion\
    \ in an important area of\n   Internet technology. However, readers should be\
    \ aware of the\n   following:\n   (1) The recommendations and some particular\
    \ interpretations in\n   definitions are those of the author, not an official\
    \ IETF position.\n   The IETF has not taken a formal position either for or against\n\
    \   recommendations made by this Glossary, and the use of RFC 2119\n   language\
    \ (e.g., SHOULD NOT) in the Glossary must be understood as\n   unofficial. In\
    \ other words, the usage rules, wording interpretations,\n   and other recommendations\
    \ that the Glossary offers are personal\n   opinions of the Glossary's author.\
    \ Readers must judge for themselves\n   whether or not to follow his recommendations,\
    \ based on their own\n   knowledge combined with the reasoning presented in the\
    \ Glossary.\n   (2) The glossary is rich in the history of early network security\n\
    \   work, but it may be somewhat incomplete in describing recent security\n  \
    \ work, which has been developing rapidly.\n"
- title: Abstract
  contents:
  - "Abstract\n   This Glossary provides definitions, abbreviations, and explanations\n\
    \   of terminology for information system security. The 334 pages of\n   entries\
    \ offer recommendations to improve the comprehensibility of\n   written material\
    \ that is generated in the Internet Standards Process\n   (RFC 2026). The recommendations\
    \ follow the principles that such\n   writing should (a) use the same term or\
    \ definition whenever the same\n   concept is mentioned; (b) use terms in their\
    \ plainest, dictionary\n   sense; (c) use terms that are already well-established\
    \ in open\n   publications; and (d) avoid terms that either favor a particular\n\
    \   vendor or favor a particular technology or mechanism over other,\n   competing\
    \ techniques that already exist or could be developed.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Format of Entries ...............................................4\n  \
    \    2.1. Order of Entries ...........................................4\n    \
    \  2.2. Capitalization and Abbreviations ...........................5\n      2.3.\
    \ Support for Automated Searching ............................5\n      2.4. Definition\
    \ Type and Context ................................5\n      2.5. Explanatory Notes\
    \ ..........................................6\n      2.6. Cross-References ...........................................6\n\
    \      2.7. Trademarks .................................................6\n  \
    \    2.8. The New Punctuation ........................................6\n   3.\
    \ Types of Entries ................................................7\n      3.1.\
    \ Type \"I\": Recommended Definitions of Internet Origin .......7\n      3.2.\
    \ Type \"N\": Recommended Definitions of Non-Internet Origin ...8\n      3.3.\
    \ Type \"O\": Other Terms and Definitions To Be Noted ..........8\n      3.4.\
    \ Type \"D\": Deprecated Terms and Definitions .................8\n      3.5.\
    \ Definition Substitutions ...................................8\n   4. Definitions\
    \ .....................................................9\n   5. Security Considerations\
    \ .......................................343\n   6. Normative Reference ...........................................343\n\
    \   7. Informative References ........................................343\n  \
    \ 8. Acknowledgments ...............................................364\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   This Glossary is *not* an Internet Standard, and its recommendations\n\
    \   represent only the opinions of its author. However, this Glossary\n   gives\
    \ reasons for its recommendations -- especially for the SHOULD\n   NOTs -- so\
    \ that readers can judge for themselves what to do.\n   This Glossary provides\
    \ an internally consistent and self-contained\n   set of terms, abbreviations,\
    \ and definitions -- supported by\n   explanations, recommendations, and references\
    \ -- for terminology that\n   concerns information system security. The intent\
    \ of this Glossary is\n   to improve the comprehensibility of written materials\
    \ that are\n   generated in the Internet Standards Process (RFC 2026) -- i.e.,\
    \ RFCs,\n   Internet-Drafts, and other items of discourse -- which are referred\n\
    \   to here as IDOCs. A few non-security, networking terms are included\n   to\
    \ make the Glossary self-contained, but more complete glossaries of\n   such terms\
    \ are available elsewhere [A1523, F1037, R1208, R1983].\n   This Glossary supports\
    \ the goals of the Internet Standards Process:\n   o  Clear, Concise, Easily Understood\
    \ Documentation\n      This Glossary seeks to improve comprehensibility of security-\n\
    \      related content of IDOCs. That requires wording to be clear and\n     \
    \ understandable, and requires the set of security-related terms and\n      definitions\
    \ to be consistent and self-supporting. Also,\n      terminology needs to be uniform\
    \ across all IDOCs; i.e., the same\n      term or definition needs to be used\
    \ whenever and wherever the same\n      concept is mentioned. Harmonization of\
    \ existing IDOCs need not be\n      done immediately, but it is desirable to correct\
    \ and standardize\n      terminology when new versions are issued in the normal\
    \ course of\n      standards development and evolution.\n   o  Technical Excellence\n\
    \      Just as Internet Standard (STD) protocols should operate\n      effectively,\
    \ IDOCs should use terminology accurately, precisely,\n      and unambiguously\
    \ to enable standards to be implemented correctly.\n   o  Prior Implementation\
    \ and Testing\n      Just as STD protocols require demonstrated experience and\n\
    \      stability before adoption, IDOCs need to use well-established\n      language;\
    \ and the robustness principle for protocols -- \"be\n      liberal in what you\
    \ accept, and conservative in what you send\" --\n      is also applicable to\
    \ the language used in IDOCs that describe\n      protocols. Using terms in their\
    \ plainest, dictionary sense (when\n      appropriate) helps to make them more\
    \ easily understood by\n      international readers. IDOCs need to avoid using\
    \ private, newly\n      invented terms in place of generally accepted terms from\
    \ open\n      publications. IDOCs need to avoid substituting new definitions\n\
    \      that conflict with established ones. IDOCs need to avoid using\n      \"\
    cute\" synonyms (e.g., \"Green Book\"), because no matter how\n      popular a\
    \ nickname may be in one community, it is likely to cause\n      confusion in\
    \ another.\n      However, although this Glossary strives for plain, internationally\n\
    \      understood English language, its terms and definitions are biased\n   \
    \   toward English as used in the United States of America (U.S.).\n      Also,\
    \ with regard to terminology used by national governments and\n      in national\
    \ defense areas, the glossary addresses only U.S. usage.\n   o  Openness, Fairness,\
    \ and Timeliness\n      IDOCs need to avoid using proprietary and trademarked\
    \ terms for\n      purposes other than referring to those particular systems.\
    \ IDOCs\n      also need to avoid terms that either favor a particular vendor\
    \ or\n      favor a particular security technology or mechanism over other,\n\
    \      competing techniques that already exist or might be developed in\n    \
    \  the future. The set of terminology used across the set of IDOCs\n      needs\
    \ to be flexible and adaptable as the state of Internet\n      security art evolves.\n\
    \   In support of those goals, this Glossary offers guidance by marking\n   terms\
    \ and definitions as being either endorsed or deprecated for use\n   in IDOCs.\
    \ The key words \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\",\n   and\
    \ \"OPTIONAL\" are intended to be interpreted the same way as in an\n   Internet\
    \ Standard (i.e., as specified in RFC 2119 [R2119]). Other\n   glossaries (e.g.,\
    \ [Raym]) list additional terms that deal with\n   Internet security but have\
    \ not been included in this Glossary because\n   they are not appropriate for\
    \ IDOCs.\n"
- title: 2. Format of Entries
  contents:
  - "2. Format of Entries\n   Section 4 presents Glossary entries in the following\
    \ manner:\n"
- title: 2.1. Order of Entries
  contents:
  - "2.1. Order of Entries\n   Entries are sorted in lexicographic order, without\
    \ regard to\n   capitalization. Numeric digits are treated as preceding alphabetic\n\
    \   characters, and special characters are treated as preceding digits.\n   Blanks\
    \ are treated as preceding non-blank characters, except that a\n   hyphen or slash\
    \ between the parts of a multiword entry (e.g.,\n   \"RED/BLACK separation\")\
    \ is treated like a blank.\n   If an entry has multiple definitions (e.g., \"\
    domain\"), they are\n   numbered beginning with \"1\", and any of those multiple\
    \ definitions\n   that are RECOMMENDED for use in IDOCs are presented before other\n\
    \   definitions for that entry. If definitions are closely related (e.g.,\n  \
    \ \"threat\"), they are denoted by adding letters to a number, such as\n   \"\
    1a\" and \"1b\".\n"
- title: 2.2. Capitalization and Abbreviations
  contents:
  - "2.2. Capitalization and Abbreviations\n   Entries that are proper nouns are capitalized\
    \ (e.g., \"Data Encryption\n   Algorithm\"), as are other words derived from proper\
    \ nouns (e.g.,\n   \"Caesar cipher\"). All other entries are not capitalized (e.g.,\n\
    \   \"certification authority\"). Each acronym or other abbreviation that\n  \
    \ appears in this Glossary, either as an entry or in a definition or\n   explanation,\
    \ is defined in this Glossary, except items of common\n   English usage, such\
    \ as \"a.k.a.\", \"e.g.\", \"etc.\", \"i.e.\", \"vol.\",\n   \"pp.\", and \"U.S.\"\
    .\n"
- title: 2.3. Support for Automated Searching
  contents:
  - "2.3. Support for Automated Searching\n   Each entry is preceded by a dollar sign\
    \ ($) and a space. This makes\n   it possible to find the defining entry for an\
    \ item \"X\" by searching\n   for the character string \"$ X\", without stopping\
    \ at other entries in\n   which \"X\" is used in explanations.\n"
- title: 2.4. Definition Type and Context
  contents:
  - "2.4. Definition Type and Context\n   Each entry is preceded by a character --\
    \ I, N, O, or D -- enclosed in\n   parentheses, to indicate the type of definition\
    \ (as is explained\n   further in Section 3):\n   -  \"I\" for a RECOMMENDED term\
    \ or definition of Internet origin.\n   -  \"N\" if RECOMMENDED but not of Internet\
    \ origin.\n   -  \"O\" for a term or definition that is NOT recommended for use\
    \ in\n      IDOCs but is something that authors of Internet documents should\n\
    \      know about.\n   -  \"D\" for a term or definition that is deprecated and\
    \ SHOULD NOT be\n      used in Internet documents.\n   If a definition is valid\
    \ only in a specific context (e.g.,\n   \"baggage\"), that context is shown immediately\
    \ following the\n   definition type and is enclosed by a pair of slash symbols\
    \ (/). If\n   the definition is valid only for specific parts of speech, that\
    \ is\n   shown in the same way (e.g., \"archive\").\n"
- title: 2.5. Explanatory Notes
  contents:
  - "2.5. Explanatory Notes\n   Some entries have explanatory text that is introduced\
    \ by one or more\n   of the following keywords:\n   -  Deprecated Abbreviation\
    \ (e.g., \"AA\")\n   -  Deprecated Definition (e.g., \"digital certification\"\
    )\n   -  Deprecated Usage (e.g., \"authenticate\")\n   -  Deprecated Term (e.g.,\
    \ \"certificate authority\")\n   -  Pronunciation (e.g., \"*-property\")\n   -\
    \  Derivation (e.g., \"discretionary access control\")\n   -  Tutorial (e.g.,\
    \ \"accreditation\")\n   -  Example (e.g., \"back door\")\n   -  Usage (e.g.,\
    \ \"access\")\n   Explanatory text in this Glossary MAY be reused in IDOCs. However,\n\
    \   this text is not intended to authoritatively supersede text of an\n   IDOC\
    \ in which the Glossary entry is already used.\n"
- title: 2.6. Cross-References
  contents:
  - "2.6. Cross-References\n   Some entries contain a parenthetical remark of the\
    \ form \"(See: X.)\",\n   where X is a list of other, related terms. Some entries\
    \ contain a\n   remark of the form \"(Compare: X)\", where X is a list of terms\
    \ that\n   either are antonyms of the entry or differ in some other manner worth\n\
    \   noting.\n"
- title: 2.7. Trademarks
  contents:
  - "2.7. Trademarks\n   All servicemarks and trademarks that appear in this Glossary\
    \ are used\n   in an editorial fashion and to the benefit of the mark owner, without\n\
    \   any intention of infringement.\n"
- title: 2.8. The New Punctuation
  contents:
  - "2.8. The New Punctuation\n   This Glossary uses the \"new\" or \"logical\" punctuation\
    \ style favored\n   by computer programmers, as described by Raymond [Raym]: Programmers\n\
    \   use pairs of quotation marks the same way they use pairs of\n   parentheses,\
    \ i.e., as balanced delimiters. For example, if \"Alice\n   sends\" is a phrase,\
    \ and so are \"Bill receives\" and \"Eve listens\",\n   then a programmer would\
    \ write the following sentence:\n      \"Alice sends\", \"Bill receives\", and\
    \ \"Eve listens\".\n   According to standard American usage, the punctuation in\
    \ that\n   sentence is incorrect; the continuation commas and the final period\n\
    \   should go inside the string quotes, like this:\n      \"Alice sends,\" \"\
    Bill receives,\" and \"Eve listens.\"\n   However, a programmer would not include\
    \ a character in a literal\n   string if the character did not belong there, because\
    \ that could\n   cause an error. For example, suppose a sentence in a draft of\
    \ a\n   tutorial on the vi editing language looked like this:\n      Then delete\
    \ one line from the file by typing \"dd\".\n   A book editor following standard\
    \ usage might change the sentence to\n   look like this:\n      Then delete one\
    \ line from the file by typing \"dd.\"\n   However, in the vi language, the dot\
    \ character repeats the last\n   command accepted. So, if a reader entered \"\
    dd.\", two lines would be\n   deleted instead of one.\n   Similarly, use of standard\
    \ American punctuation might cause\n   misunderstanding in entries in this Glossary.\
    \ Thus, the new\n   punctuation is used here, and we recommend it for IDOCs.\n"
- title: 3. Types of Entries
  contents:
  - "3. Types of Entries\n   Each entry in this Glossary is marked as type I, N, O,\
    \ or D:\n"
- title: '3.1. Type "I": Recommended Definitions of Internet Origin'
  contents:
  - "3.1. Type \"I\": Recommended Definitions of Internet Origin\n   The marking \"\
    I\" indicates two things:\n   -  Origin: \"I\" (as opposed to \"N\") means either\
    \ that the Internet\n      Standards Process or Internet community is authoritative\
    \ for the\n      definition *or* that the term is sufficiently generic that this\n\
    \      Glossary can freely state a definition without contradicting a\n      non-Internet\
    \ authority (e.g., \"attack\").\n   -  Recommendation: \"I\" (as opposed to \"\
    O\") means that the term and\n      definition are RECOMMENDED for use in IDOCs.\
    \ However, some \"I\"\n      entries may be accompanied by a \"Usage\" note that\
    \ states a\n      limitation (e.g., \"certification\"), and IDOCs SHOULD NOT use\
    \ the\n      defined term outside that limited context.\n   Many \"I\" entries\
    \ are proper nouns (e.g., \"Internet Protocol\") for\n   which the definition\
    \ is intended only to provide basic information;\n   i.e., the authoritative definition\
    \ of such terms is found elsewhere.\n   For a proper noun described as an \"Internet\
    \ protocol\", please refer\n   to the current edition of \"Internet Official Protocol\
    \ Standards\"\n   (Standard 1) for the standardization status of the protocol.\n"
- title: '3.2. Type "N": Recommended Definitions of Non-Internet Origin'
  contents:
  - "3.2. Type \"N\": Recommended Definitions of Non-Internet Origin\n   The marking\
    \ \"N\" indicates two things:\n   -  Origin: \"N\" (as opposed to \"I\") means\
    \ that the entry has a non-\n      Internet basis or origin.\n   -  Recommendation:\
    \ \"N\" (as opposed to \"O\") means that the term and\n      definition are RECOMMENDED\
    \ for use in IDOCs, if they are needed at\n      all in IDOCs. Many of these entries\
    \ are accompanied by a label\n      that states a context (e.g., \"package\")\
    \ or a note that states a\n      limitation (e.g., \"data integrity\"), and IDOCs\
    \ SHOULD NOT use the\n      defined term outside that context or limit. Some of\
    \ the contexts\n      are rarely if ever expected to occur in an IDOC (e.g., \"\
    baggage\").\n      In those cases, the listing exists to make Internet authors\
    \ aware\n      of the non-Internet usage so that they can avoid conflicts with\n\
    \      non-Internet documents.\n"
- title: '3.3. Type "O": Other Terms and Definitions To Be Noted'
  contents:
  - "3.3. Type \"O\": Other Terms and Definitions To Be Noted\n   The marking \"O\"\
    \ means that the definition is of non-Internet origin\n   and SHOULD NOT be used\
    \ in IDOCs *except* in cases where the term is\n   specifically identified as\
    \ non-Internet.\n   For example, an IDOC might mention \"BCA\" (see: brand certification\n\
    \   authority) or \"baggage\" as an example of some concept; in that case,\n \
    \  the document should specifically say \"SET(trademark) BCA\" or\n   \"SET(trademark)\
    \ baggage\" and include the definition of the term.\n"
- title: '3.4. Type "D": Deprecated Terms and Definitions'
  contents:
  - "3.4. Type \"D\": Deprecated Terms and Definitions\n   If this Glossary recommends\
    \ that a term or definition SHOULD NOT be\n   used in IDOCs, then the entry is\
    \ marked as type \"D\", and an\n   explanatory note -- \"Deprecated Term\", \"\
    Deprecated Abbreviation\",\n   \"Deprecated Definition\", or \"Deprecated Usage\"\
    \ -- is provided.\n"
- title: 3.5. Definition Substitutions
  contents:
  - "3.5. Definition Substitutions\n   Some terms have a definition published by a\
    \ non-Internet authority --\n   a government (e.g., \"object reuse\"), an industry\
    \ (e.g., \"Secure Data\n   Exchange\"), a national authority (e.g., \"Data Encryption\
    \ Standard\"),\n   or an international body (e.g., \"data confidentiality\") --\
    \ that is\n   suitable for use in IDOCs. In those cases, this Glossary marks the\n\
    \   definition \"N\", recommending its use in Internet documents.\n   Other such\
    \ terms have definitions that are inadequate or\n   inappropriate for IDOCs. For\
    \ example, a definition might be outdated\n   or too narrow, or it might need\
    \ clarification by substituting more\n   careful wording (e.g., \"authentication\
    \ exchange\") or explanations,\n   using other terms that are defined in this\
    \ Glossary. In those cases,\n   this Glossary marks the entry \"O\", and provides\
    \ an \"I\" or \"N\" entry\n   that precedes, and is intended to supersede, the\
    \ \"O\" entry.\n   In some cases where this Glossary provides a definition to\
    \ supersede\n   an \"O\" definition, the substitute is intended to subsume the\
    \ meaning\n   of the \"O\" entry and not conflict with it. For the term \"security\n\
    \   service\", for example, the \"O\" definition deals narrowly with only\n  \
    \ communication services provided by layers in the OSIRM and is\n   inadequate\
    \ for the full range of IDOC usage, while the new \"I\"\n   definition provided\
    \ by this Glossary can be used in more situations\n   and for more kinds of service.\
    \ However, the \"O\" definition is also\n   listed so that IDOC authors will be\
    \ aware of the context in which the\n   term is used more narrowly.\n   When making\
    \ substitutions, this Glossary attempts to avoid\n   contradicting any non-Internet\
    \ authority. Still, terminology differs\n   between authorities such as the American\
    \ Bar Association, OSI, SET,\n   the U.S. DoD, and other authorities; and this\
    \ Glossary probably is\n   not exactly aligned with any of them.\n"
- title: 4. Definitions
  contents:
  - "4. Definitions\n   $ *-property\n      (N) Synonym for \"confinement property\"\
    \ in the context of the Bell-\n      LaPadula model. Pronunciation: star property.\n\
    \   $ 3DES\n      (N) See: Triple Data Encryption Algorithm.\n   $ A1 computer\
    \ system\n      (O) /TCSEC/ See: Tutorial under \"Trusted Computer System\n  \
    \    Evaluation Criteria\". (Compare: beyond A1.)\n   $ AA\n      (D) See: Deprecated\
    \ Usage under \"attribute authority\".\n   $ ABA Guidelines\n      (N) \"American\
    \ Bar Association (ABA) Digital Signature Guidelines\"\n      [DSG], a framework\
    \ of legal principles for using digital\n      signatures and digital certificates\
    \ in electronic commerce.\n   $ Abstract Syntax Notation One (ASN.1)\n      (N)\
    \ A standard for describing data objects. [Larm, X680] (See:\n      CMS.)\n  \
    \    Usage: IDOCs SHOULD use the term \"ASN.1\" narrowly to describe the\n   \
    \   notation or language called \"Abstract Syntax Notation One\". IDOCs\n    \
    \  MAY use the term more broadly to encompass the notation, its\n      associated\
    \ encoding rules (see: BER), and software tools that\n      assist in its use,\
    \ when the context makes this meaning clear.\n      Tutorial: OSIRM defines computer\
    \ network functionality in layers.\n      Protocols and data objects at higher\
    \ layers are abstractly defined\n      to be implemented using protocols and data\
    \ objects from lower\n      layers. A higher layer may define transfers of abstract\
    \ objects\n      between computers, and a lower layer may define those transfers\n\
    \      concretely as strings of bits. Syntax is needed to specify data\n     \
    \ formats of abstract objects, and encoding rules are needed to\n      transform\
    \ abstract objects into bit strings at lower layers. OSI\n      standards use\
    \ ASN.1 for those specifications and use various\n      encoding rules for those\
    \ transformations. (See: BER.)\n      In ASN.1, formal names are written without\
    \ spaces, and separate\n      words in a name are indicated by capitalizing the\
    \ first letter of\n      each word except the first word. For example, the name\
    \ of a CRL is\n      \"certificateRevocationList\".\n   $ ACC\n      (I) See:\
    \ access control center.\n   $ acceptable risk\n      (I) A risk that is understood\
    \ and tolerated by a system's user,\n      operator, owner, or accreditor, usually\
    \ because the cost or\n      difficulty of implementing an effective countermeasure\
    \ for the\n      associated vulnerability exceeds the expectation of loss. (See:\n\
    \      adequate security, risk, \"second law\" under \"Courtney's laws\".)\n \
    \  $ access\n      1a. (I) The ability and means to communicate with or otherwise\n\
    \      interact with a system to use system resources either to handle\n     \
    \ information or to gain knowledge of the information the system\n      contains.\
    \ (Compare: handle.)\n      Usage: The definition is intended to include all types\
    \ of\n      communication with a system, including one-way communication in\n\
    \      either direction. In actual practice, however, passive users might\n  \
    \    be treated as not having \"access\" and, therefore, be exempt from\n    \
    \  most requirements of the system's security policy. (See: \"passive\n      user\"\
    \ under \"user\".)\n      1b. (O) \"Opportunity to make use of an information\
    \ system (IS)\n      resource.\" [C4009]\n      2. (O) /formal model/ \"A specific\
    \ type of interaction between a\n      subject and an object that results in the\
    \ flow of information from\n      one to the other.\" [NCS04]\n   $ Access Certificate\
    \ for Electronic Services (ACES)\n      (O) A PKI operated by the U.S. Government's\
    \ General Services\n      Administration in cooperation with industry partners.\
    \ (See: CAM.)\n   $ access control\n      1. (I) Protection of system resources\
    \ against unauthorized access.\n      2. (I) A process by which use of system\
    \ resources is regulated\n      according to a security policy and is permitted\
    \ only by authorized\n      entities (users, programs, processes, or other systems)\
    \ according\n      to that policy. (See: access, access control service, computer\n\
    \      security, discretionary access control, mandatory access control,\n   \
    \   role-based access control.)\n      3. (I) /formal model/ Limitations on interactions\
    \ between subjects\n      and objects in an information system.\n      4. (O)\
    \ \"The prevention of unauthorized use of a resource,\n      including the prevention\
    \ of use of a resource in an unauthorized\n      manner.\" [I7498-2]\n      5.\
    \ (O) /U.S. Government/ A system using physical, electronic, or\n      human controls\
    \ to identify or admit personnel with properly\n      authorized access to a SCIF.\n\
    \   $ access control center (ACC)\n      (I) A computer that maintains a database\
    \ (possibly in the form of\n      an access control matrix) defining the security\
    \ policy for an\n      access control service, and that acts as a server for clients\n\
    \      requesting access control decisions.\n      Tutorial: An ACC is sometimes\
    \ used in conjunction with a key\n      center to implement access control in\
    \ a key-distribution system\n      for symmetric cryptography. (See: BLACKER,\
    \ Kerberos.)\n   $ access control list (ACL)\n      (I) /information system/ A\
    \ mechanism that implements access\n      control for a system resource by enumerating\
    \ the system entities\n      that are permitted to access the resource and stating,\
    \ either\n      implicitly or explicitly, the access modes granted to each entity.\n\
    \      (Compare: access control matrix, access list, access profile,\n      capability\
    \ list.)\n   $ access control matrix\n      (I) A rectangular array of cells,\
    \ with one row per subject and one\n      column per object. The entry in a cell\
    \ -- that is, the entry for a\n      particular subject-object pair -- indicates\
    \ the access mode that\n      the subject is permitted to exercise on the object.\
    \ Each column is\n      equivalent to an \"access control list\" for the object;\
    \ and each\n      row is equivalent to an \"access profile\" for the subject.\n\
    \   $ access control service\n      (I) A security service that protects against\
    \ a system entity using\n      a system resource in a way not authorized by the\
    \ system's security\n      policy. (See: access control, discretionary access\
    \ control,\n      identity-based security policy, mandatory access control, rule-\n\
    \      based security policy.)\n      Tutorial: This service includes protecting\
    \ against use of a\n      resource in an unauthorized manner by an entity (i.e.,\
    \ a\n      principal) that is authorized to use the resource in some other\n \
    \     manner. (See: insider.) The two basic mechanisms for implementing\n    \
    \  this service are ACLs and tickets.\n   $ access level\n      1. (D) Synonym\
    \ for the hierarchical \"classification level\" in a\n      security level. [C4009]\
    \ (See: security level.)\n      2. (D) Synonym for \"clearance level\".\n    \
    \  Deprecated Definitions: IDOCs SHOULD NOT use this term with these\n      definitions\
    \ because they duplicate the meaning of more specific\n      terms. Any IDOC that\
    \ uses this term SHOULD provide a specific\n      definition for it because access\
    \ control may be based on many\n      attributes other than classification level\
    \ and clearance level.\n   $ access list\n      (I) /physical security/ Roster\
    \ of persons who are authorized to\n      enter a controlled area. (Compare: access\
    \ control list.)\n   $ access mode\n      (I) A distinct type of data processing\
    \ operation (e.g., read,\n      write, append, or execute, or a combination of\
    \ operations) that a\n      subject can potentially perform on an object in an\
    \ information\n      system. [Huff] (See: read, write.)\n   $ access policy\n\
    \      (I) A kind of \"security policy\". (See: access, access control.)\n   $\
    \ access profile\n      (O) Synonym for \"capability list\".\n      Usage: IDOCs\
    \ that use this term SHOULD state a definition for it\n      because the definition\
    \ is not widely known.\n   $ access right\n      (I) Synonym for \"authorization\"\
    ; emphasizes the possession of the\n      authorization by a system entity.\n\
    \   $ accountability\n      (I) The property of a system or system resource that\
    \ ensures that\n      the actions of a system entity may be traced uniquely to\
    \ that\n      entity, which can then be held responsible for its actions. [Huff]\n\
    \      (See: audit service.)\n      Tutorial: Accountability (a.k.a. individual\
    \ accountability)\n      typically requires a system ability to positively associate\
    \ the\n      identity of a user with the time, method, and mode of the user's\n\
    \      access to the system. This ability supports detection and\n      subsequent\
    \ investigation of security breaches. Individual persons\n      who are system\
    \ users are held accountable for their actions after\n      being notified of\
    \ the rules of behavior for using the system and\n      the penalties associated\
    \ with violating those rules.\n   $ accounting See: COMSEC accounting.\n   $ accounting\
    \ legend code (ALC)\n      (O) /U.S. Government/ Numeric system used to indicate\
    \ the minimum\n      accounting controls required for items of COMSEC material\
    \ within\n      the CMCS. [C4009] (See: COMSEC accounting.)\n   $ accreditation\n\
    \      (N) An administrative action by which a designated authority\n      declares\
    \ that an information system is approved to operate in a\n      particular security\
    \ configuration with a prescribed set of\n      safeguards. [FP102, SP37] (See:\
    \ certification.)\n      Tutorial: An accreditation is usually based on a technical\n\
    \      certification of the system's security mechanisms. To accredit a\n    \
    \  system, the approving authority must determine that any residual\n      risk\
    \ is an acceptable risk. Although the terms \"certification\" and\n      \"accreditation\"\
    \ are used more in the U.S. DoD and other U.S.\n      Government agencies than\
    \ in commercial organizations, the concepts\n      apply any place where managers\
    \ are required to deal with and\n      accept responsibility for security risks.\
    \ For example, the\n      American Bar Association is developing accreditation\
    \ criteria for\n      CAs.\n   $ accreditation boundary\n      (O) Synonym for\
    \ \"security perimeter\". [C4009]\n   $ accreditor\n      (N) A management official\
    \ who has been designated to have the\n      formal authority to \"accredit\"\
    \ an information system, i.e., to\n      authorize the operation of, and the processing\
    \ of sensitive data\n      in, the system and to accept the residual risk associated\
    \ with the\n      system. (See: accreditation, residual risk.)\n   $ ACES\n  \
    \    (O) See: Access Certificate for Electronic Services.\n   $ ACL\n      (I)\
    \ See: access control list.\n   $ acquirer\n      1. (O) /SET/ \"The financial\
    \ institution that establishes an\n      account with a merchant and processes\
    \ payment card authorizations\n      and payments.\" [SET1]\n      2. (O) /SET/\
    \ \"The institution (or its agent) that acquires from\n      the card acceptor\
    \ the financial data relating to the transaction\n      and initiates that data\
    \ into an interchange system.\" [SET2]\n   $ activation data\n      (N) Secret\
    \ data, other than keys, that is required to access a\n      cryptographic module.\
    \ (See: CIK. Compare: initialization value.)\n   $ active attack\n      (I) See:\
    \ secondary definition under \"attack\".\n   $ active content\n      1a. (I) Executable\
    \ software that is bound to a document or other\n      data file and that executes\
    \ automatically when a user accesses the\n      file, without explicit initiation\
    \ by the user. (Compare: mobile\n      code.)\n      Tutorial: Active content\
    \ can be mobile code when its associated\n      file is transferred across a network.\n\
    \      1b. (O) \"Electronic documents that can carry out or trigger\n      actions\
    \ automatically on a computer platform without the\n      intervention of a user.\
    \ [This technology enables] mobile code\n      associated with a document to execute\
    \ as the document is\n      rendered.\" [SP28]\n   $ active user\n      (I) See:\
    \ secondary definition under \"system user\".\n   $ active wiretapping\n     \
    \ (I) A wiretapping attack that attempts to alter data being\n      communicated\
    \ or otherwise affect data flow. (See: wiretapping.\n      Compare: active attack,\
    \ passive wiretapping.)\n   $ add-on security\n      (N) The retrofitting of protection\
    \ mechanisms, implemented by\n      hardware or software, in an information system\
    \ after the system\n      has become operational. [FP039] (Compare: baked-in security.)\n\
    \   $ adequate security\n      (O) /U.S. DoD/ \"Security commensurate with the\
    \ risk and magnitude\n      of harm resulting from the loss, misuse, or unauthorized\
    \ access to\n      or modification of information.\" (See: acceptable risk, residual\n\
    \      risk.)\n   $ administrative security\n      1. (I) Management procedures\
    \ and constraints to prevent\n      unauthorized access to a system. (See: \"\
    third law\" under\n      \"Courtney's laws\", manager, operational security, procedural\n\
    \      security, security architecture. Compare: technical security.)\n      Examples:\
    \ Clear delineation and separation of duties;\n      configuration control.\n\
    \      Usage: Administrative security is usually understood to consist of\n  \
    \    methods and mechanisms that are implemented and executed primarily\n    \
    \  by people, rather than by automated systems.\n      2. (O) \"The management\
    \ constraints, operational procedures,\n      accountability procedures, and supplemental\
    \ controls established\n      to provide an acceptable level of protection for\
    \ sensitive data.\"\n      [FP039]\n   $ administrator\n      1. (O) /Common Criteria/\
    \ A person that is responsible for\n      configuring, maintaining, and administering\
    \ the TOE in a correct\n      manner for maximum security. (See: administrative\
    \ security.)\n      2. (O) /ITSEC/ A person in contact with the TOE, who is\n\
    \      responsible for maintaining its operational capability.\n   $ Advanced\
    \ Encryption Standard (AES)\n      (N) A U.S. Government standard [FP197] (the\
    \ successor to DES) that\n      (a) specifies \"the AES algorithm\", which is\
    \ a symmetric block\n      cipher that is based on Rijndael and uses key sizes\
    \ of 128, 192,\n      or 256 bits to operate on a 128-bit block, and (b) states\
    \ policy\n      for using that algorithm to protect unclassified, sensitive data.\n\
    \      Tutorial: Rijndael was designed to handle additional block sizes\n    \
    \  and key lengths that were not adopted in the AES. Rijndael was\n      selected\
    \ by NIST through a public competition that was held to\n      find a successor\
    \ to the DEA; the other finalists were MARS, RC6,\n      Serpent, and Twofish.\n\
    \   $ adversary\n      1. (I) An entity that attacks a system. (Compare: cracker,\n\
    \      intruder, hacker.)\n      2. (I) An entity that is a threat to a system.\n\
    \   $ AES\n      (N) See: Advanced Encryption Standard.\n   $ Affirm\n      (O)\
    \ A formal methodology, language, and integrated set of software\n      tools\
    \ developed at the University of Southern California's\n      Information Sciences\
    \ Institute for specifying, coding, and\n      verifying software to produce correct\
    \ and reliable programs.\n      [Cheh]\n   $ aggregation\n      (I) A circumstance\
    \ in which a collection of information items is\n      required to be classified\
    \ at a higher security level than any of\n      the items is classified individually.\
    \ (See: classification.)\n   $ AH\n      (I) See: Authentication Header\n   $\
    \ air gap\n      (I) An interface between two systems at which (a) they are not\n\
    \      connected physically and (b) any logical connection is not\n      automated\
    \ (i.e., data is transferred through the interface only\n      manually, under\
    \ human control). (See: sneaker net. Compare:\n      gateway.)\n      Example:\
    \ Computer A and computer B are on opposite sides of a\n      room. To move data\
    \ from A to B, a person carries a disk across the\n      room. If A and B operate\
    \ in different security domains, then\n      moving data across the air gap may\
    \ involve an upgrade or downgrade\n      operation.\n   $ ALC\n      (O) See:\
    \ accounting legend code.\n   $ algorithm\n      (I) A finite set of step-by-step\
    \ instructions for a problem-\n      solving or computation procedure, especially\
    \ one that can be\n      implemented by a computer. (See: cryptographic algorithm.)\n\
    \   $ alias\n      (I) A name that an entity uses in place of its real name, usually\n\
    \      for the purpose of either anonymity or masquerade.\n   $ Alice and Bob\n\
    \      (I) The parties that are most often called upon to illustrate the\n   \
    \   operation of bipartite security protocols. These and other\n      dramatis\
    \ personae are listed by Schneier [Schn].\n   $ American National Standards Institute\
    \ (ANSI)\n      (N) A private, not-for-profit association that administers U.S.\n\
    \      private-sector voluntary standards.\n      Tutorial: ANSI has approximately\
    \ 1,000 member organizations,\n      including equipment users, manufacturers,\
    \ and others. These\n      include commercial firms, governmental agencies, and\
    \ other\n      institutions and international entities.\n      ANSI is the sole\
    \ U.S. representative to (a) ISO and (b) (via the\n      U.S. National Committee)\
    \ the International Electrotechnical\n      Commission (IEC), which are the two\
    \ major, non-treaty,\n      international standards organizations.\n      ANSI\
    \ provides a forum for ANSI-accredited standards development\n      groups. Among\
    \ those groups, the following are especially relevant\n      to Internet security:\n\
    \      -  International Committee for Information Technology\n         Standardization\
    \ (INCITS) (formerly X3): Primary U.S. focus of\n         standardization in information\
    \ and communications technologies,\n         encompassing storage, processing,\
    \ transfer, display,\n         management, organization, and retrieval of information.\n\
    \         Example: [A3092].\n      -  Accredited Standards Committee X9: Develops,\
    \ establishes,\n         maintains, and promotes standards for the financial services\n\
    \         industry. Example: [A9009].\n      -  Alliance for Telecommunications\
    \ Industry Solutions (ATIS):\n         Develops standards, specifications, guidelines,\
    \ requirements,\n         technical reports, industry processes, and verification\
    \ tests\n         for interoperability and reliability of telecommunications\n\
    \         networks, equipment, and software. Example: [A1523].\n   $ American\
    \ Standard Code for Information Interchange (ASCII)\n      (N) A scheme that encodes\
    \ 128 specified characters -- the numbers\n      0-9, the letters a-z and A-Z,\
    \ some basic punctuation symbols, some\n      control codes that originated with\
    \ Teletype machines, and a blank\n      space -- into the 7-bit binary integers.\
    \ Forms the basis of the\n      character set representations used in most computers\
    \ and many\n      Internet standards. [FP001] (See: code.)\n   $ Anderson report\n\
    \      (O) A 1972 study of computer security that was written by James P.\n  \
    \    Anderson for the U.S. Air Force [Ande].\n      Tutorial: Anderson collaborated\
    \ with a panel of experts to study\n      Air Force requirements for multilevel\
    \ security. The study\n      recommended research and development that was urgently\
    \ needed to\n      provide secure information processing for command and control\n\
    \      systems and support systems. The report introduced the reference\n    \
    \  monitor concept and provided development impetus for computer and\n      network\
    \ security technology. However, many of the security\n      problems that the\
    \ 1972 report called \"current\" still plague\n      information systems today.\n\
    \   $ anomaly detection\n      (I) An intrusion detection method that searches\
    \ for activity that\n      is different from the normal behavior of system entities\
    \ and\n      system resources. (See: IDS. Compare: misuse detection.)\n   $ anonymity\n\
    \      (I) The condition of an identity being unknown or concealed. (See:\n  \
    \    alias, anonymizer, anonymous credential, anonymous login,\n      identity,\
    \ onion routing, persona certificate. Compare: privacy.)\n      Tutorial: An application\
    \ may require security services that\n      maintain anonymity of users or other\
    \ system entities, perhaps to\n      preserve their privacy or hide them from\
    \ attack. To hide an\n      entity's real name, an alias may be used; for example,\
    \ a financial\n      institution may assign account numbers. Parties to transactions\n\
    \      can thus remain relatively anonymous, but can also accept the\n      transactions\
    \ as legitimate. Real names of the parties cannot be\n      easily determined\
    \ by observers of the transactions, but an\n      authorized third party may be\
    \ able to map an alias to a real name,\n      such as by presenting the institution\
    \ with a court order. In other\n      applications, anonymous entities may be\
    \ completely untraceable.\n   $ anonymizer\n      (I) An internetwork service,\
    \ usually provided via a proxy server,\n      that provides anonymity and privacy\
    \ for clients. That is, the\n      service enables a client to access servers\
    \ (a) without allowing\n      anyone to gather information about which servers\
    \ the client\n      accesses and (b) without allowing the accessed servers to\
    \ gather\n      information about the client, such as its IP address.\n   $ anonymous\
    \ credential\n      (D) /U.S. Government/ A credential that (a) can be used to\n\
    \      authenticate a person as having a specific attribute or being a\n     \
    \ member of a specific group (e.g., military veterans or U.S.\n      citizens)\
    \ but (b) does not reveal the individual identity of the\n      person that presents\
    \ the credential. [M0404] (See: anonymity.)\n      Deprecated Term: IDOCs SHOULD\
    \ NOT use this term; it mixes concepts\n      in a potentially misleading way.\
    \ For example, when the credential\n      is an X.509 certificate, the term could\
    \ be misunderstood to mean\n      that the certificate was signed by a CA that\
    \ has a persona\n      certificate. Instead, use \"attribute certificate\", \"\
    organizational\n      certificate\", or \"persona certificate\" depending on what\
    \ is meant,\n      and provide additional explanations as needed.\n   $ anonymous\
    \ login\n      (I) An access control feature (actually, an access control\n  \
    \    vulnerability) in many Internet hosts that enables users to gain\n      access\
    \ to general-purpose or public services and resources of a\n      host (such as\
    \ allowing any user to transfer data using FTP)\n      without having a pre-established,\
    \ identity-specific account (i.e.,\n      user name and password). (See: anonymity.)\n\
    \      Tutorial: This feature exposes a system to more threats than when\n   \
    \   all the users are known, pre-registered entities that are\n      individually\
    \ accountable for their actions. A user logs in using a\n      special, publicly\
    \ known user name (e.g., \"anonymous\", \"guest\", or\n      \"ftp\"). To use\
    \ the public login name, the user is not required to\n      know a secret password\
    \ and may not be required to input anything\n      at all except the name. In\
    \ other cases, to complete the normal\n      sequence of steps in a login protocol,\
    \ the system may require the\n      user to input a matching, publicly known password\
    \ (such as\n      \"anonymous\") or may ask the user for an e-mail address or\
    \ some\n      other arbitrary character string.\n   $ ANSI\n      (N) See: American\
    \ National Standards Institute.\n   $ anti-jam\n      (N) \"Measures ensuring\
    \ that transmitted information can be\n      received despite deliberate jamming\
    \ attempts.\" [C4009] (See:\n      electronic security, frequency hopping, jam,\
    \ spread spectrum.)\n   $ apex trust anchor\n      (N) The trust anchor that is\
    \ superior to all other trust anchors\n      in a particular system or context.\
    \ (See: trust anchor, top CA.)\n   $ API\n      (I) See: application programming\
    \ interface.\n   $ APOP\n      (I) See: POP3 APOP.\n   $ Application Layer\n \
    \     See: Internet Protocol Suite, OSIRM.\n   $ application program\n      (I)\
    \ A computer program that performs a specific function directly\n      for a user\
    \ (as opposed to a program that is part of a computer\n      operating system\
    \ and exists to perform functions in support of\n      application programs).\n\
    \   $ architecture\n      (I) See: security architecture, system architecture.\n\
    \   $ archive\n      1a. (I) /noun/ A collection of data that is stored for a\n\
    \      relatively long period of time for historical and other purposes,\n   \
    \   such as to support audit service, availability service, or system\n      integrity\
    \ service. (Compare: backup, repository.)\n      1b. (I) /verb/ To store data\
    \ in such a way as to create an\n      archive. (Compare: back up.)\n      Tutorial:\
    \ A digital signature may need to be verified many years\n      after the signing\
    \ occurs. The CA -- the one that issued the\n      certificate containing the\
    \ public key needed to verify that\n      signature -- may not stay in operation\
    \ that long. So every CA\n      needs to provide for long-term storage of the\
    \ information needed\n      to verify the signatures of those to whom it issues\
    \ certificates.\n   $ ARPANET\n      (I) Advanced Research Projects Agency (ARPA)\
    \ Network, a pioneer\n      packet-switched network that (a) was designed, implemented,\n\
    \      operated, and maintained by BBN from January 1969 until July 1975\n   \
    \   under contract to the U.S. Government; (b) led to the development\n      of\
    \ today's Internet; and (c) was decommissioned in June 1990.\n      [B4799, Hafn]\n\
    \   $ ASCII\n      (N) See: American Standard Code for Information Interchange.\n\
    \   $ ASN.1\n      (N) See: Abstract Syntax Notation One.\n   $ asset\n      (I)\
    \ A system resource that is (a) required to be protected by an\n      information\
    \ system's security policy, (b) intended to be protected\n      by a countermeasure,\
    \ or (c) required for a system's mission.\n   $ association\n      (I) A cooperative\
    \ relationship between system entities, usually\n      for the purpose of transferring\
    \ information between them. (See:\n      security association.)\n   $ assurance\
    \ See: security assurance.\n   $ assurance level\n      (N) A rank on a hierarchical\
    \ scale that judges the confidence\n      someone can have that a TOE adequately\
    \ fulfills stated security\n      requirements. (See: assurance, certificate policy,\
    \ EAL, TCSEC.)\n      Example: U.S. Government guidance [M0404] describes four\
    \ assurance\n      levels for identity authentication, where each level \"describes\n\
    \      the [U.S. Federal Government] agency's degree of certainty that\n     \
    \ the user has presented [a credential] that refers to [the user's]\n      identity.\"\
    \ In that guidance, assurance is defined as (a) \"the\n      degree of confidence\
    \ in the vetting process used to establish the\n      identity of the individual\
    \ to whom the credential was issued\" and\n      (b) \"the degree of confidence\
    \ that the individual who uses the\n      credential is the individual to whom\
    \ the credential was issued.\"\n      The four levels are described as follows:\n\
    \      -  Level 1: Little or no confidence in the asserted identity.\n      -\
    \  Level 2: Some confidence in the asserted identity.\n      -  Level 3: High\
    \ confidence in the asserted identity.\n      -  Level 4: Very high confidence\
    \ in the asserted identity.\n      Standards for determining these levels are\
    \ provided in a NIST\n      publication [SP12]. However, as noted there, an assurance\
    \ level is\n      \"a degree of confidence, not a true measure of how secure the\n\
    \      system actually is. This distinction is necessary because it is\n     \
    \ extremely difficult -- and in many cases, virtually impossible --\n      to\
    \ know exactly how secure a system is.\"\n   $ asymmetric cryptography\n     \
    \ (I) A modern branch of cryptography (popularly known as \"public-\n      key\
    \ cryptography\") in which the algorithms use a pair of keys (a\n      public\
    \ key and a private key) and use a different component of the\n      pair for\
    \ each of two counterpart cryptographic operations (e.g.,\n      encryption and\
    \ decryption, or signature creation and signature\n      verification). (See:\
    \ key pair, symmetric cryptography.)\n      Tutorial: Asymmetric algorithms have\
    \ key management advantages\n      over equivalently strong symmetric ones. First,\
    \ one key of the\n      pair need not be known by anyone but its owner; so it\
    \ can more\n      easily be kept secret. Second, although the other key is shared\
    \ by\n      all entities that use the algorithm, that key need not be kept\n \
    \     secret from other, non-using entities; thus, the key-distribution\n    \
    \  part of key management can be done more easily.\n      Asymmetric cryptography\
    \ can be used to create algorithms for\n      encryption, digital signature, and\
    \ key agreement:\n      -  In an asymmetric encryption algorithm (e.g., \"RSA\"\
    ), when Alice\n         wants to ensure confidentiality for data she sends to\
    \ Bob, she\n         encrypts the data with a public key provided by Bob. Only\
    \ Bob\n         has the matching private key that is needed to decrypt the\n \
    \        data. (Compare: seal.)\n      -  In an asymmetric digital signature algorithm\
    \ (e.g., \"DSA\"),\n         when Alice wants to ensure data integrity or provide\n\
    \         authentication for data she sends to Bob, she uses her private\n   \
    \      key to sign the data (i.e., create a digital signature based on\n     \
    \    the data). To verify the signature, Bob uses the matching\n         public\
    \ key that Alice has provided.\n      -  In an asymmetric key-agreement algorithm\
    \ (e.g., \"Diffie-\n         Hellman-Merkle\"), Alice and Bob each send their\
    \ own public key\n         to the other party. Then each uses their own private\
    \ key and\n         the other's public key to compute the new key value.\n   $\
    \ asymmetric key\n      (I) A cryptographic key that is used in an asymmetric\n\
    \      cryptographic algorithm. (See: asymmetric cryptography, private\n     \
    \ key, public key.)\n   $ ATIS\n      (N) See: \"Alliance for Telecommunications\
    \ Industry Solutions\"\n      under \"ANSI\".\n   $ attack\n      1. (I) An intentional\
    \ act by which an entity attempts to evade\n      security services and violate\
    \ the security policy of a system.\n      That is, an actual assault on system\
    \ security that derives from an\n      intelligent threat. (See: penetration,\
    \ violation, vulnerability.)\n      2. (I) A method or technique used in an assault\
    \ (e.g.,\n      masquerade). (See: blind attack, distributed attack.)\n      Tutorial:\
    \ Attacks can be characterized according to intent:\n      -  An \"active attack\"\
    \ attempts to alter system resources or affect\n         their operation.\n  \
    \    -  A \"passive attack\" attempts to learn or make use of information\n  \
    \       from a system but does not affect system resources of that\n         system.\
    \ (See: wiretapping.)\n      The object of a passive attack might be to obtain\
    \ data that is\n      needed for an off-line attack.\n      -  An \"off-line attack\"\
    \ is one in which the attacker obtains data\n         from the target system and\
    \ then analyzes the data on a\n         different system of the attacker's own\
    \ choosing, possibly in\n         preparation for a second stage of attack on\
    \ the target.\n      Attacks can be characterized according to point of initiation:\n\
    \      -  An \"inside attack\" is one that is initiated by an entity inside\n\
    \         the security perimeter (an \"insider\"), i.e., an entity that is\n \
    \        authorized to access system resources but uses them in a way\n      \
    \   not approved by the party that granted the authorization.\n      -  An \"\
    outside attack\" is initiated from outside the security\n         perimeter, by\
    \ an unauthorized or illegitimate user of the\n         system (an \"outsider\"\
    ). In the Internet, potential outside\n         attackers range from amateur pranksters\
    \ to organized criminals,\n         international terrorists, and hostile governments.\n\
    \      Attacks can be characterized according to method of delivery:\n      -\
    \  In a \"direct attack\", the attacker addresses attacking packets\n        \
    \ to the intended victim(s).\n      -  In an \"indirect attack\", the attacker\
    \ addresses packets to a\n         third party, and the packets either have the\
    \ address(es) of the\n         intended victim(s) as their source address(es)\
    \ or indicate the\n         intended victim(s) in some other way. The third party\
    \ responds\n         by sending one or more attacking packets to the intended\n\
    \         victims. The attacker can use third parties as attack\n         amplifiers\
    \ by providing a broadcast address as the victim\n         address (e.g., \"smurf\
    \ attack\"). (See: reflector attack.\n         Compare: reflection attack, replay\
    \ attack.)\n      The term \"attack\" relates to some other basic security terms\
    \ as\n      shown in the following diagram:\n      + - - - - - - - - - - - - +\
    \  + - - - - +  + - - - - - - - - - - -+\n      | An Attack:              |  |Counter-\
    \ |  | A System Resource:   |\n      | i.e., A Threat Action   |  | measure |\
    \  | Target of the Attack |\n      | +----------+            |  |         |  |\
    \ +-----------------+  |\n      | | Attacker |<==================||<=========\
    \                 |  |\n      | |   i.e.,  |   Passive  |  |         |  | |  Vulnerability\
    \  |  |\n      | | A Threat |<=================>||<========>                 |\
    \  |\n      | |  Agent   |  or Active |  |         |  | +-------|||-------+  |\n\
    \      | +----------+   Attack   |  |         |  |         VVV          |\n  \
    \    |                         |  |         |  | Threat Consequences  |\n    \
    \  + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+\n   $ attack\
    \ potential\n      (I) The perceived likelihood of success should an attack be\n\
    \      launched, expressed in terms of the attacker's ability (i.e.,\n      expertise\
    \ and resources) and motivation. (Compare: threat, risk.)\n   $ attack sensing,\
    \ warning, and response\n      (I) A set of security services that cooperate with\
    \ audit service\n      to detect and react to indications of threat actions, including\n\
    \      both inside and outside attacks. (See: indicator.)\n   $ attack tree\n\
    \      (I) A branching, hierarchical data structure that represents a set\n  \
    \    of potential approaches to achieving an event in which system\n      security\
    \ is penetrated or compromised in a specified way. [Moor]\n      Tutorial: Attack\
    \ trees are special cases of fault trees. The\n      security incident that is\
    \ the goal of the attack is represented as\n      the root node of the tree, and\
    \ the ways that an attacker could\n      reach that goal are iteratively and incrementally\
    \ represented as\n      branches and subnodes of the tree. Each subnode defines\
    \ a subgoal,\n      and each subgoal may have its own set of further subgoals,\
    \ etc.\n      The final nodes on the paths outward from the root, i.e., the leaf\n\
    \      nodes, represent different ways to initiate an attack. Each node\n    \
    \  other than a leaf is either an AND-node or an OR-node. To achieve\n      the\
    \ goal represented by an AND-node, the subgoals represented by\n      all of that\
    \ node's subnodes must be achieved; and for an OR-node,\n      at least one of\
    \ the subgoals must be achieved. Branches can be\n      labeled with values representing\
    \ difficulty, cost, or other attack\n      attributes, so that alternative attacks\
    \ can be compared.\n   $ attribute\n      (N) Information of a particular type\
    \ concerning an identifiable\n      system entity or object. An \"attribute type\"\
    \ is the component of\n      an attribute that indicates the class of information\
    \ given by the\n      attribute; and an \"attribute value\" is a particular instance\
    \ of\n      the class of information indicated by an attribute type. (See:\n \
    \     attribute certificate.)\n   $ attribute authority (AA)\n      1. (N) A CA\
    \ that issues attribute certificates.\n      2. (O) \"An authority [that] assigns\
    \ privileges by issuing\n      attribute certificates.\" [X509]\n      Deprecated\
    \ Usage: The abbreviation \"AA\" SHOULD NOT be used in an\n      IDOC unless it\
    \ is first defined in the IDOC.\n   $ attribute certificate\n      1. (I) A digital\
    \ certificate that binds a set of descriptive data\n      items, other than a\
    \ public key, either directly to a subject name\n      or to the identifier of\
    \ another certificate that is a public-key\n      certificate. (See: capability\
    \ token.)\n      2. (O) \"A data structure, digitally signed by an [a]ttribute\n\
    \      [a]uthority, that binds some attribute values with identification\n   \
    \   information about its holder.\" [X509]\n      Tutorial: A public-key certificate\
    \ binds a subject name to a\n      public key value, along with information needed\
    \ to perform certain\n      cryptographic functions using that key. Other attributes\
    \ of a\n      subject, such as a security clearance, may be certified in a\n \
    \     separate kind of digital certificate, called an attribute\n      certificate.\
    \ A subject may have multiple attribute certificates\n      associated with its\
    \ name or with each of its public-key\n      certificates.\n      An attribute\
    \ certificate might be issued to a subject in the\n      following situations:\n\
    \      -  Different lifetimes: When the lifetime of an attribute binding\n   \
    \      is shorter than that of the related public-key certificate, or\n      \
    \   when it is desirable not to need to revoke a subject's public\n         key\
    \ just to revoke an attribute.\n      -  Different authorities: When the authority\
    \ responsible for the\n         attributes is different than the one that issues\
    \ the public-key\n         certificate for the subject. (There is no requirement\
    \ that an\n         attribute certificate be issued by the same CA that issued\
    \ the\n         associated public-key certificate.)\n   $ audit\n      See: security\
    \ audit.\n   $ audit log\n      (I) Synonym for \"security audit trail\".\n  \
    \ $ audit service\n      (I) A security service that records information needed\
    \ to\n      establish accountability for system events and for the actions of\n\
    \      system entities that cause them. (See: security audit.)\n   $ audit trail\n\
    \      (I) See: security audit trail.\n   $ AUTH\n      (I) See: POP3 AUTH.\n\
    \   $ authenticate\n      (I) Verify (i.e., establish the truth of) an attribute\
    \ value\n      claimed by or for a system entity or system resource. (See:\n \
    \     authentication, validate vs. verify, \"relationship between data\n     \
    \ integrity service and authentication services\" under \"data\n      integrity\
    \ service\".)\n      Deprecated Usage: In general English usage, this term is\
    \ used with\n      the meaning \"to prove genuine\" (e.g., an art expert authenticates\n\
    \      a Michelangelo painting); but IDOCs should restrict usage as\n      follows:\n\
    \      -  IDOCs SHOULD NOT use this term to refer to proving or checking\n   \
    \      that data has not been changed, destroyed, or lost in an\n         unauthorized\
    \ or accidental manner. Instead, use \"verify\".\n      -  IDOCs SHOULD NOT use\
    \ this term to refer to proving the truth or\n         accuracy of a fact or value\
    \ such as a digital signature.\n         Instead, use \"verify\".\n      -  IDOCs\
    \ SHOULD NOT use this term to refer to establishing the\n         soundness or\
    \ correctness of a construct, such as a digital\n         certificate. Instead,\
    \ use \"validate\".\n   $ authentication\n      (I) The process of verifying a\
    \ claim that a system entity or\n      system resource has a certain attribute\
    \ value. (See: attribute,\n      authenticate, authentication exchange, authentication\
    \ information,\n      credential, data origin authentication, peer entity\n  \
    \    authentication, \"relationship between data integrity service and\n     \
    \ authentication services\" under \"data integrity service\", simple\n      authentication,\
    \ strong authentication, verification, X.509.)\n      Tutorial: Security services\
    \ frequently depend on authentication of\n      the identity of users, but authentication\
    \ may involve any type of\n      attribute that is recognized by a system. A claim\
    \ may be made by a\n      subject about itself (e.g., at login, a user typically\
    \ asserts its\n      identity) or a claim may be made on behalf of a subject or\
    \ object\n      by some other system entity (e.g., a user may claim that a data\n\
    \      object originates from a specific source, or that a data object is\n  \
    \    classified at a specific security level).\n      An authentication process\
    \ consists of two basic steps:\n      -  Identification step: Presenting the claimed\
    \ attribute value\n         (e.g., a user identifier) to the authentication subsystem.\n\
    \      -  Verification step: Presenting or generating authentication\n       \
    \  information (e.g., a value signed with a private key) that acts\n         as\
    \ evidence to prove the binding between the attribute and that\n         for which\
    \ it is claimed. (See: verification.)\n   $ authentication code\n      (D) Synonym\
    \ for a checksum based on cryptography. (Compare: Data\n      Authentication Code,\
    \ Message Authentication Code.)\n      Deprecated Term: IDOCs SHOULD NOT use this\
    \ uncapitalized term as a\n      synonym for any kind of checksum, regardless\
    \ of whether or not the\n      checksum is cryptographic. Instead, use \"checksum\"\
    , \"Data\n      Authentication Code\", \"error detection code\", \"hash\", \"\
    keyed\n      hash\", \"Message Authentication Code\", \"protected checksum\",\
    \ or\n      some other recommended term, depending on what is meant.\n      The\
    \ term mixes concepts in a potentially misleading way. The word\n      \"authentication\"\
    \ is misleading because the checksum may be used to\n      perform a data integrity\
    \ function rather than a data origin\n      authentication function.\n   $ authentication\
    \ exchange\n      1. (I) A mechanism to verify the identity of an entity by means\
    \ of\n      information exchange.\n      2. (O) \"A mechanism intended to ensure\
    \ the identity of an entity\n      by means of information exchange.\" [I7498-2]\n\
    \   $ Authentication Header (AH)\n      (I) An Internet protocol [R2402, R4302]\
    \ designed to provide\n      connectionless data integrity service and connectionless\
    \ data\n      origin authentication service for IP datagrams, and (optionally)\n\
    \      to provide partial sequence integrity and protection against\n      replay\
    \ attacks. (See: IPsec. Compare: ESP.)\n      Tutorial: Replay protection may\
    \ be selected by the receiver when a\n      security association is established.\
    \ AH authenticates the upper-\n      layer PDU that is carried as an IP SDU, and\
    \ also authenticates as\n      much of the IP PCI (i.e., the IP header) as possible.\
    \ However,\n      some IP header fields may change in transit, and the value of\n\
    \      these fields, when the packet arrives at the receiver, may not be\n   \
    \   predictable by the sender. Thus, the values of such fields cannot\n      be\
    \ protected end-to-end by AH; protection of the IP header by AH\n      is only\
    \ partial when such fields are present.\n      AH may be used alone, or in combination\
    \ with the ESP, or in a\n      nested fashion with tunneling. Security services\
    \ can be provided\n      between a pair of communicating hosts, between a pair\
    \ of\n      communicating security gateways, or between a host and a gateway.\n\
    \      ESP can provide nearly the same security services as AH, and ESP\n    \
    \  can also provide data confidentiality service. The main difference\n      between\
    \ authentication services provided by ESP and AH is the\n      extent of the coverage;\
    \ ESP does not protect IP header fields\n      unless they are encapsulated by\
    \ AH.\n   $ authentication information\n      (I) Information used to verify an\
    \ identity claimed by or for an\n      entity. (See: authentication, credential,\
    \ user. Compare:\n      identification information.)\n      Tutorial: Authentication\
    \ information may exist as, or be derived\n      from, one of the following: (a)\
    \ Something the entity knows (see:\n      password); (b) something the entity\
    \ possesses (see: token); (c)\n      something the entity is (see: biometric authentication).\n\
    \   $ authentication service\n      (I) A security service that verifies an identity\
    \ claimed by or for\n      an entity. (See: authentication.)\n      Tutorial:\
    \ In a network, there are two general forms of\n      authentication service:\
    \ data origin authentication service and\n      peer entity authentication service.\n\
    \   $ authenticity\n      (I) The property of being genuine and able to be verified\
    \ and be\n      trusted. (See: authenticate, authentication, validate vs. verify.)\n\
    \   $ authority\n      (D) /PKI/ \"An entity [that is] responsible for the issuance\
    \ of\n      certificates.\" [X509]\n      Deprecated Usage: IDOCs SHOULD NOT use\
    \ this term as a synonym for\n      attribute authority, certification authority,\
    \ registration\n      authority, or similar terms; the shortened form may cause\n\
    \      confusion. Instead, use the full term at the first instance of\n      usage\
    \ and then, if it is necessary to shorten text, use AA, CA,\n      RA, and other\
    \ abbreviations defined in this Glossary.\n   $ authority certificate\n      (D)\
    \ \"A certificate issued to an authority (e.g. either to a\n      certification\
    \ authority or to an attribute authority).\" [X509]\n      (See: authority.)\n\
    \      Deprecated Term: IDOCs SHOULD NOT use this term because it is\n      ambiguous.\
    \ Instead, use the full term \"certification authority\n      certificate\", \"\
    attribute authority certificate\", \"registration\n      authority certificate\"\
    , etc. at the first instance of usage and\n      then, if it is necessary to shorten\
    \ text, use AA, CA, RA, and\n      other abbreviations defined in this Glossary.\n\
    \   $ Authority Information Access extension\n      (I) The private extension\
    \ defined by PKIX for X.509 certificates\n      to indicate \"how to access CA\
    \ information and services for the\n      issuer of the certificate in which the\
    \ extension appears.\n      Information and services may include on-line validation\
    \ services\n      and CA policy data.\" [R3280] (See: private extension.)\n  \
    \ $ authorization\n      1a. (I) An approval that is granted to a system entity\
    \ to access a\n      system resource. (Compare: permission, privilege.)\n    \
    \  Usage: Some synonyms are \"permission\" and \"privilege\". Specific\n     \
    \ terms are preferred in certain contexts:\n      -  /PKI/ \"Authorization\" SHOULD\
    \ be used, to align with\n         \"certification authority\" in the standard\
    \ [X509].\n      -  /role-based access control/ \"Permission\" SHOULD be used,\
    \ to\n         align with the standard [ANSI].\n      -  /computer operating systems/\
    \ \"Privilege\" SHOULD be used, to\n         align with the literature. (See:\
    \ privileged process, privileged\n         user.)\n      Tutorial: The semantics\
    \ and granularity of authorizations depend\n      on the application and implementation\
    \ (see: \"first law\" under\n      \"Courtney's laws\"). An authorization may\
    \ specify a particular\n      access mode -- such as read, write, or execute --\
    \ for one or more\n      system resources.\n      1b. (I) A process for granting\
    \ approval to a system entity to\n      access a system resource.\n      2. (O)\
    \ /SET/ \"The process by which a properly appointed person or\n      persons grants\
    \ permission to perform some action on behalf of an\n      organization. This\
    \ process assesses transaction risk, confirms\n      that a given transaction\
    \ does not raise the account holder's debt\n      above the account's credit limit,\
    \ and reserves the specified\n      amount of credit. (When a merchant obtains\
    \ authorization, payment\n      for the authorized amount is guaranteed -- provided,\
    \ of course,\n      that the merchant followed the rules associated with the\n\
    \      authorization process.)\" [SET2]\n   $ authorization credential\n     \
    \ (I) See: /access control/ under \"credential\".\n   $ authorize\n      (I) Grant\
    \ an authorization to a system entity.\n   $ authorized user\n      (I) /access\
    \ control/ A system entity that accesses a system\n      resource for which the\
    \ entity has received an authorization.\n      (Compare: insider, outsider, unauthorized\
    \ user.)\n      Deprecated Usage: IDOCs that use this term SHOULD state a\n  \
    \    definition for it because the term is used in many ways and could\n     \
    \ easily be misunderstood.\n   $ automated information system\n      See: information\
    \ system.\n   $ availability\n      1. (I) The property of a system or a system\
    \ resource being\n      accessible, or usable or operational upon demand, by an\
    \ authorized\n      system entity, according to performance specifications for\
    \ the\n      system; i.e., a system is available if it provides services\n   \
    \   according to the system design whenever users request them. (See:\n      critical,\
    \ denial of service. Compare: precedence, reliability,\n      survivability.)\n\
    \      2. (O) \"The property of being accessible and usable upon demand by\n \
    \     an authorized entity.\" [I7498-2]\n      3. (D) \"Timely, reliable access\
    \ to data and information services\n      for authorized users.\" [C4009]\n  \
    \    Deprecated Definition: IDOCs SHOULD NOT use the term with\n      definition\
    \ 3; the definition mixes \"availability\" with\n      \"reliability\", which\
    \ is a different property. (See: reliability.)\n      Tutorial: Availability requirements\
    \ can be specified by\n      quantitative metrics, but sometimes are stated qualitatively,\
    \ such\n      as in the following:\n      -  \"Flexible tolerance for delay\"\
    \ may mean that brief system\n         outages do not endanger mission accomplishment,\
    \ but extended\n         outages may endanger the mission.\n      -  \"Minimum\
    \ tolerance for delay\" may mean that mission\n         accomplishment requires\
    \ the system to provide requested\n         services in a short time.\n   $ availability\
    \ service\n      (I) A security service that protects a system to ensure its\n\
    \      availability.\n      Tutorial: This service addresses the security concerns\
    \ raised by\n      denial-of-service attacks. It depends on proper management\
    \ and\n      control of system resources, and thus depends on access control\n\
    \      service and other security services.\n   $ avoidance\n      (I) See: secondary\
    \ definition under \"security\".\n   $ B1, B2, or B3 computer system\n      (O)\
    \ /TCSEC/ See: Tutorial under \"Trusted Computer System\n      Evaluation Criteria\"\
    .\n   $ back door\n      1. (I) /COMPUSEC/ A computer system feature -- which\
    \ may be (a) an\n      unintentional flaw, (b) a mechanism deliberately installed\
    \ by the\n      system's creator, or (c) a mechanism surreptitiously installed\
    \ by\n      an intruder -- that provides access to a system resource by other\n\
    \      than the usual procedure and usually is hidden or otherwise not\n     \
    \ well-known. (See: maintenance hook. Compare: Trojan Horse.)\n      Example:\
    \ A way to access a computer other than through a normal\n      login. Such an\
    \ access path is not necessarily designed with\n      malicious intent; operating\
    \ systems sometimes are shipped by the\n      manufacturer with hidden accounts\
    \ intended for use by field\n      service technicians or the vendor's maintenance\
    \ programmers.\n      2. (I) /cryptography/ A feature of a cryptographic system\
    \ that\n      makes it easily possible to break or circumvent the protection\n\
    \      that the system is designed to provide.\n      Example: A feature that\
    \ makes it possible to decrypt cipher text\n      much more quickly than by brute-force\
    \ cryptanalysis, without\n      having prior knowledge of the decryption key.\n\
    \   $ back up\n      (I) /verb/ Create a reserve copy of data or, more generally,\n\
    \      provide alternate means to perform system functions despite loss\n    \
    \  of system resources. (See: contingency plan. Compare: archive.)\n   $ backup\n\
    \      (I) /noun or adjective/ Refers to alternate means of performing\n     \
    \ system functions despite loss of system resources. (See:\n      contingency\
    \ plan).\n      Example: A reserve copy of data, preferably one that is stored\n\
    \      separately from the original, for use if the original becomes lost\n  \
    \    or damaged. (Compare: archive.)\n   $ bagbiter\n      (D) /slang/ \"An entity,\
    \ such as a program or a computer, that\n      fails to work or that works in\
    \ a remarkably clumsy manner. A\n      person who has caused some trouble, inadvertently\
    \ or otherwise,\n      typically by failing to program the computer properly.\"\
    \ [NCSSG]\n      (See: flaw.)\n      Deprecated Term: It is likely that other\
    \ cultures use different\n      metaphors for these concepts. Therefore, to avoid\
    \ international\n      misunderstanding, IDOCs SHOULD NOT use this term. (See:\
    \ Deprecated\n      Usage under \"Green Book\".)\n   $ baggage\n      (O) /SET/\
    \ An \"opaque encrypted tuple, which is included in a SET\n      message but appended\
    \ as external data to the PKCS encapsulated\n      data. This avoids superencryption\
    \ of the previously encrypted\n      tuple, but guarantees linkage with the PKCS\
    \ portion of the\n      message.\" [SET2]\n      Deprecated Usage: IDOCs SHOULD\
    \ NOT use this term to describe a\n      data element, except in the form \"SET(trademark)\
    \ baggage\" with the\n      meaning given above.\n   $ baked-in security\n   \
    \   (D) The inclusion of security mechanisms in an information system\n      beginning\
    \ at an early point in the system's lifecycle, i.e.,\n      during the design\
    \ phase, or at least early in the implementation\n      phase. (Compare: add-on\
    \ security.)\n      Deprecated Term: It is likely that other cultures use different\n\
    \      metaphors for this concept. Therefore, to avoid international\n      misunderstanding,\
    \ IDOCs SHOULD NOT use this term (unless they also\n      provide a definition\
    \ like this one). (See: Deprecated Usage under\n      \"Green Book\".)\n   $ bandwidth\n\
    \      (I) The total width of the frequency band that is available to or\n   \
    \   used by a communication channel; usually expressed in Hertz (Hz).\n      (RFC\
    \ 3753) (Compare: channel capacity.)\n   $ bank identification number (BIN)\n\
    \      1. (O) The digits of a credit card number that identify the\n      issuing\
    \ bank. (See: primary account number.)\n      2. (O) /SET/ The first six digits\
    \ of a primary account number.\n   $ Basic Encoding Rules (BER)\n      (I) A standard\
    \ for representing ASN.1 data types as strings of\n      octets. [X690] (See:\
    \ Distinguished Encoding Rules.)\n      Deprecated Usage: Sometimes incorrectly\
    \ treated as part of ASN.1.\n      However, ASN.1 properly refers only to a syntax\
    \ description\n      language, and not to the encoding rules for the language.\n\
    \   $ Basic Security Option\n      (I) See: secondary definition under \"IPSO\"\
    .\n   $ bastion host\n      (I) A strongly protected computer that is in a network\
    \ protected\n      by a firewall (or is part of a firewall) and is the only host\
    \ (or\n      one of only a few) in the network that can be directly accessed\n\
    \      from networks on the other side of the firewall. (See: firewall.)\n   \
    \   Tutorial: Filtering routers in a firewall typically restrict\n      traffic\
    \ from the outside network to reaching just one host, the\n      bastion host,\
    \ which usually is part of the firewall. Since only\n      this one host can be\
    \ directly attacked, only this one host needs\n      to be very strongly protected,\
    \ so security can be maintained more\n      easily and less expensively. However,\
    \ to allow legitimate internal\n      and external users to access application\
    \ resources through the\n      firewall, higher-layer protocols and services need\
    \ to be relayed\n      and forwarded by the bastion host. Some services (e.g.,\
    \ DNS and\n      SMTP) have forwarding built in; other services (e.g., TELNET\
    \ and\n      FTP) require a proxy server on the bastion host.\n   $ BBN Technologies\
    \ Corp. (BBN)\n      (O) The research-and-development company (originally called\
    \ Bolt\n      Baranek and Newman, Inc.) that built the ARPANET.\n   $ BCA\n  \
    \    (O) See: brand certification authority.\n   $ BCR\n      (O) See: BLACK/Crypto/RED.\n\
    \   $ BCI\n      (O) See: brand CRL identifier.\n   $ Bell-LaPadula model\n  \
    \    (N) A formal, mathematical, state-transition model of\n      confidentiality\
    \ policy for multilevel-secure computer systems\n      [Bell]. (Compare: Biba\
    \ model, Brewer-Nash model.)\n      Tutorial: The model, devised by David Bell\
    \ and Leonard LaPadula at\n      The MITRE Corporation in 1973, characterizes\
    \ computer system\n      elements as subjects and objects. To determine whether\
    \ or not a\n      subject is authorized for a particular access mode on an object,\n\
    \      the clearance of the subject is compared to the classification of\n   \
    \   the object. The model defines the notion of a \"secure state\", in\n     \
    \ which the only permitted access modes of subjects to objects are\n      in accordance\
    \ with a specified security policy. It is proven that\n      each state transition\
    \ preserves security by moving from secure\n      state to secure state, thereby\
    \ proving that the system is secure.\n      In this model, a multilevel-secure\
    \ system satisfies several rules,\n      including the \"confinement property\"\
    \ (a.k.a. the \"*-property\"),\n      the \"simple security property\", and the\
    \ \"tranquility property\".\n   $ benign\n      1. (N) /COMSEC/ \"Condition of\
    \ cryptographic data [such] that [the\n      data] cannot be compromised by human\
    \ access [to the data].\"\n      [C4009]\n      2. (O) /COMPUSEC/ See: secondary\
    \ definition under \"trust\".\n   $ benign fill\n      (N) Process by which keying\
    \ material is generated, distributed,\n      and placed into an ECU without exposure\
    \ to any human or other\n      system entity, except the cryptographic module\
    \ that consumes and\n      uses the material. (See: benign.)\n   $ BER\n     \
    \ (I) See: Basic Encoding Rules.\n   $ beyond A1\n      1. (O) /formal/ A level\
    \ of security assurance that is beyond the\n      highest level (level A1) of\
    \ criteria specified by the TCSEC. (See:\n      Tutorial under \"Trusted Computer\
    \ System Evaluation Criteria\".)\n      2. (O) /informal/ A level of trust so\
    \ high that it is beyond\n      state-of-the-art technology; i.e., it cannot be\
    \ provided or\n      verified by currently available assurance methods, and especially\n\
    \      not by currently available formal methods.\n   $ Biba integrity\n     \
    \ (N) Synonym for \"source integrity\".\n   $ Biba model\n      (N) A formal,\
    \ mathematical, state-transition model of integrity\n      policy for multilevel-secure\
    \ computer systems [Biba]. (See: source\n      integrity. Compare: Bell-LaPadula\
    \ model.)\n      Tutorial: This model for integrity control is analogous to the\n\
    \      Bell-LaPadula model for confidentiality control. Each subject and\n   \
    \   object is assigned an integrity level and, to determine whether or\n     \
    \ not a subject is authorized for a particular access mode on an\n      object,\
    \ the integrity level of the subject is compared to that of\n      the object.\
    \ The model prohibits the changing of information in an\n      object by a subject\
    \ with a lesser or incomparable level. The rules\n      of the Biba model are\
    \ duals of the corresponding rules in the\n      Bell-LaPadula model.\n   $ billet\n\
    \      (N) \"A personnel position or assignment that may be filled by one\n  \
    \    person.\" [JCP1] (Compare: principal, role, user.)\n      Tutorial: In an\
    \ organization, a \"billet\" is a populational\n      position, of which there\
    \ is exactly one instance; but a \"role\" is\n      functional position, of which\
    \ there can be multiple instances.\n      System entities are in one-to-one relationships\
    \ with their\n      billets, but may be in many-to-one and one-to-many relationships\n\
    \      with their roles.\n   $ BIN\n      (O) See: bank identification number.\n\
    \   $ bind\n      (I) To inseparably associate by applying some security mechanism.\n\
    \      Example: A CA creates a public-key certificate by using a digital\n   \
    \   signature to bind together (a) a subject name, (b) a public key,\n      and\
    \ usually (c) some additional data items (e.g., \"X.509 public-\n      key certificate\"\
    ).\n   $ biometric authentication\n      (I) A method of generating authentication\
    \ information for a person\n      by digitizing measurements of a physical or\
    \ behavioral\n      characteristic, such as a fingerprint, hand shape, retina\
    \ pattern,\n      voiceprint, handwriting style, or face.\n   $ birthday attack\n\
    \      (I) A class of attacks against cryptographic functions, including\n   \
    \   both encryption functions and hash functions. The attacks take\n      advantage\
    \ of a statistical property: Given a cryptographic\n      function having an N-bit\
    \ output, the probability is greater than\n      1/2 that for 2**(N/2) randomly\
    \ chosen inputs, the function will\n      produce at least two outputs that are\
    \ identical. (See: Tutorial\n      under \"hash function\".)\n      Derivation:\
    \ From the somewhat surprising fact (often called the\n      \"birthday paradox\"\
    ) that although there are 365 days in a year,\n      the probability is greater\
    \ than 1/2 that two of more people share\n      the same birthday in any randomly\
    \ chosen group of 23 people.\n      Birthday attacks enable an adversary to find\
    \ two inputs for which\n      a cryptographic function produces the same cipher\
    \ text (or find\n      two inputs for which a hash functions produces the same\
    \ hash\n      result) much faster than a brute-force attack can; and a clever\n\
    \      adversary can use such a capability to create considerable\n      mischief.\
    \ However, no birthday attack can enable an adversary to\n      decrypt a given\
    \ cipher text (or find a hash input that results in\n      a given hash result)\
    \ any faster than a brute-force attack can.\n   $ bit\n      (I) A contraction\
    \ of the term \"binary digit\"; the smallest unit of\n      information storage,\
    \ which has two possible states or values. The\n      values usually are represented\
    \ by the symbols \"0\" (zero) and \"1\"\n      (one). (See: block, byte, nibble,\
    \ word.)\n   $ bit string\n      (I) A sequence of bits, each of which is either\
    \ \"0\" or \"1\".\n   $ BLACK\n      1. (N) Designation for data that consists\
    \ only of cipher text, and\n      for information system equipment items or facilities\
    \ that handle\n      only cipher text. Example: \"BLACK key\". (See: BCR, color\
    \ change,\n      RED/BLACK separation. Compare: RED.)\n      2. (O) /U.S. Government/\
    \ \"Designation applied to information\n      systems, and to associated areas,\
    \ circuits, components, and\n      equipment, in which national security information\
    \ is encrypted or\n      is not processed.\" [C4009]\n      3. (D) Any data that\
    \ can be disclosed without harm.\n      Deprecated Definition: IDOCs SHOULD NOT\
    \ use the term with\n      definition 3 because the definition is ambiguous with\
    \ regard to\n      whether or not the data is protected.\n   $ BLACK/Crypto/RED\
    \ (BCR)\n      (N) An experimental, end-to-end, network packet encryption system\n\
    \      developed in a working prototype form by BBN and the Collins Radio\n  \
    \    division of Rockwell Corporation in the 1975-1980 time frame for\n      the\
    \ U.S. DoD. BCR was the first network security system to support\n      TCP/IP\
    \ traffic, and it incorporated the first DES chips that were\n      validated\
    \ by the U.S. National Bureau of Standards (now called\n      NIST). BCR also\
    \ was the first to use a KDC and an ACC to manage\n      connections.\n   $ BLACK\
    \ key\n      (N) A key that is protected with a key-encrypting key and that\n\
    \      must be decrypted before use. (See: BLACK. Compare: RED key.)\n   $ BLACKER\n\
    \      (O) An end-to-end encryption system for computer data networks\n      that\
    \ was developed by the U.S. DoD in the 1980s to provide host-\n      to-host data\
    \ confidentiality service for datagrams at OSIRM Layer\n      3. [Weis] (Compare:\
    \ CANEWARE, IPsec.)\n      Tutorial: Each user host connects to its own bump-in-the-wire\n\
    \      encryption device called a BLACKER Front End (BFE, TSEC/KI-111),\n    \
    \  through which the host connects to the subnetwork. The system also\n      includes\
    \ two types of centralized devices: one or more KDCs\n      connect to the subnetwork\
    \ and communicate with assigned sets of\n      BFEs, and one or more ACCs connect\
    \ to the subnetwork and\n      communicate with assigned KDCs. BLACKER uses only\
    \ symmetric\n      encryption. A KDC distributes session keys to BFE pairs as\n\
    \      authorized by an ACC. Each ACC maintains a database for a set of\n    \
    \  BFEs, and the database determines which pairs from that set (i.e.,\n      which\
    \ pairs of user hosts behind the BFEs) are authorized to\n      communicate and\
    \ at what security levels.\n      The BLACKER system is MLS in three ways: (a)\
    \ The BFEs form a\n      security perimeter around a subnetwork, separating user\
    \ hosts from\n      the subnetwork, so that the subnetwork can operate at a different\n\
    \      security level (possibly a lower, less expensive level) than the\n    \
    \  hosts. (b) The BLACKER components are trusted to separate\n      datagrams\
    \ of different security levels, so that each datagram of a\n      given security\
    \ level can be received only by a host that is\n      authorized for that security\
    \ level; and thus BLACKER can separate\n      host communities that operate at\
    \ different security levels. (c)\n      The host side of a BFE is itself MLS and\
    \ can recognize a security\n      label on each packet, so that an MLS user host\
    \ can be authorized\n      to successively transmit datagrams that are labeled\
    \ with different\n      security levels.\n   $ blind attack\n      (I) A type\
    \ of network-based attack method that does not require\n      the attacking entity\
    \ to receive data traffic from the attacked\n      entity; i.e., the attacker\
    \ does not need to \"see\" data packets\n      sent by the victim. Example: SYN\
    \ flood.\n      Tutorial: If an attack method is blind, the attacker's packets\
    \ can\n      carry (a) a false IP source address (making it difficult for the\n\
    \      victim to find the attacker) and (b) a different address on every\n   \
    \   packet (making it difficult for the victim to block the attack).\n      If\
    \ the attacker needs to receive traffic from the victim, the\n      attacker must\
    \ either (c) reveal its own IP address to the victim\n      (which enables the\
    \ victim to find the attacker or block the attack\n      by filtering) or (d)\
    \ provide a false address and also subvert\n      network routing mechanisms to\
    \ divert the returning packets to the\n      attacker (which makes the attack\
    \ more complex, more difficult, or\n      more expensive). [R3552]\n   $ block\n\
    \      (I) A bit string or bit vector of finite length. (See: bit, block\n   \
    \   cipher. Compare: byte, word.)\n      Usage: An \"N-bit block\" contains N\
    \ bits, which usually are\n      numbered from left to right as 1, 2, 3, ...,\
    \ N.\n   $ block cipher\n      (I) An encryption algorithm that breaks plain text\
    \ into fixed-size\n      segments and uses the same key to transform each plaintext\
    \ segment\n      into a fixed-size segment of cipher text. Examples: AES, Blowfish,\n\
    \      DEA, IDEA, RC2, and SKIPJACK. (See: block, mode. Compare: stream\n    \
    \  cipher.)\n      Tutorial: A block cipher can be adapted to have a different\n\
    \      external interface, such as that of a stream cipher, by using a\n     \
    \ mode of cryptographic operation to package the basic algorithm.\n      (See:\
    \ CBC, CCM, CFB, CMAC, CTR, DEA, ECB, OFB.)\n   $ Blowfish\n      (N) A symmetric\
    \ block cipher with variable-length key (32 to 448\n      bits) designed in 1993\
    \ by Bruce Schneier as an unpatented,\n      license-free, royalty-free replacement\
    \ for DES or IDEA. [Schn]\n      (See: Twofish.)\n   $ brain-damaged\n      (D)\
    \ /slang/ \"Obviously wrong: extremely poorly designed. Calling\n      something\
    \ brain-damaged is very extreme. The word implies that the\n      thing is completely\
    \ unusable, and that its failure to work is due\n      to poor design, not accident.\"\
    \ [NCSSG] (See: flaw.)\n      Deprecated Term: It is likely that other cultures\
    \ use different\n      metaphors for this concept. Therefore, to avoid international\n\
    \      misunderstanding, IDOCs SHOULD NOT use this term. (See: Deprecated\n  \
    \    Usage under \"Green Book\".)\n   $ brand\n      1. (I) A distinctive mark\
    \ or name that identifies a product or\n      business entity.\n      2. (O) /SET/\
    \ The name of a payment card. (See: BCA.)\n      Tutorial: Financial institutions\
    \ and other companies have founded\n      payment card brands, protect and advertise\
    \ the brands, establish\n      and enforce rules for use and acceptance of their\
    \ payment cards,\n      and provide networks to interconnect the financial institutions.\n\
    \      These brands combine the roles of issuer and acquirer in\n      interactions\
    \ with cardholders and merchants. [SET1]\n   $ brand certification authority (BCA)\n\
    \      (O) /SET/ A CA owned by a payment card brand, such as MasterCard,\n   \
    \   Visa, or American Express. [SET2] (See: certification hierarchy,\n      SET.)\n\
    \   $ brand CRL identifier (BCI)\n      (O) /SET/ A digitally signed list, issued\
    \ by a BCA, of the names\n      of CAs for which CRLs need to be processed when\
    \ verifying\n      signatures in SET messages. [SET2]\n   $ break\n      (I) /cryptography/\
    \ To successfully perform cryptanalysis and thus\n      succeed in decrypting\
    \ data or performing some other cryptographic\n      function, without initially\
    \ having knowledge of the key that the\n      function requires. (See: penetrate,\
    \ strength, work factor.)\n      Usage: This term applies to encrypted data or,\
    \ more generally, to\n      a cryptographic algorithm or cryptographic system.\
    \ Also, while the\n      most common use is to refer to completely breaking an\
    \ algorithm,\n      the term is also used when a method is found that substantially\n\
    \      reduces the work factor.\n   $ Brewer-Nash model\n      (N) A security\
    \ model [BN89] to enforce the Chinese wall policy.\n      (Compare: Bell-LaPadula\
    \ model, Clark-Wilson model.)\n      Tutorial: All proprietary information in\
    \ the set of commercial\n      firms F(1), F(2), ..., F(N) is categorized into\
    \ mutually exclusive\n      conflict-of-interest classes I(1), I(2), ..., I(M)\
    \ that apply\n      across all firms. Each firm belongs to exactly one class.\
    \ The\n      Brewer-Nash model has the following mandatory rules:\n      -  Brewer-Nash\
    \ Read Rule: Subject S can read information object O\n         from firm F(i)\
    \ only if either (a) O is from the same firm as\n         some object previously\
    \ read by S *or* (b) O belongs to a class\n         I(i) from which S has not\
    \ previously read any object. (See:\n         object, subject.)\n      -  Brewer-Nash\
    \ Write Rule: Subject S can write information object\n         O to firm F(i)\
    \ only if (a) S can read O by the Brewer-Nash Read\n         Rule *and* (b) no\
    \ object can be read by S from a different firm\n         F(j), no matter whether\
    \ F(j) belongs to the same class as F(i)\n         or to a different class.\n\
    \   $ bridge\n      (I) A gateway for traffic flowing at OSIRM Layer 2 between\
    \ two\n      networks (usually two LANs). (Compare: bridge CA, router.)\n   $\
    \ bridge CA\n      (I) A PKI consisting of only a CA that cross-certifies with\
    \ CAs of\n      some other PKIs. (See: cross-certification. Compare: bridge.)\n\
    \      Tutorial: A bridge CA functions as a hub that enables a\n      certificate\
    \ user in any of the PKIs that attach to the bridge, to\n      validate certificates\
    \ issued in the other attached PKIs.\n      For example, a bridge CA (BCA)   \
    \              CA1\n      could cross-certify with four                   ^\n\
    \      PKIs that have the roots CA1,                   |\n      CA2, CA3, and\
    \ CA4. The cross-                   v\n      certificates that the roots     \
    \       CA2 <-> BCA <-> CA3\n      exchange with the BCA enable an           \
    \      ^\n      end entity EE1 certified under                  |\n      under\
    \ CA1 in PK1 to construct                   v\n      a certification path needed\
    \ to                 CA4\n      validate the certificate of\n      end entity\
    \ EE2 under CA2,           CA1 -> BCA -> CA2 -> EE2\n      or vice versa.    \
    \                 CA2 -> BCA -> CA1 -> EE1\n   $ British Standard 7799\n     \
    \ (N) Part 1 of the standard is a code of practice for how to secure\n      an\
    \ information system. Part 2 specifies the management framework,\n      objectives,\
    \ and control requirements for information security\n      management systems.\
    \ [BS7799] (See: ISO 17799.)\n   $ browser\n      (I) A client computer program\
    \ that can retrieve and display\n      information from servers on the World Wide\
    \ Web. Examples: Netscape\n      Navigator and Microsoft Internet Explorer.\n\
    \   $ brute force\n      (I) A cryptanalysis technique or other kind of attack\
    \ method\n      involving an exhaustive procedure that tries a large number of\n\
    \      possible solutions to the problem. (See: impossible, strength,\n      work\
    \ factor.)\n      Tutorial: In some cases, brute force involves trying all of\
    \ the\n      possibilities. For example, for cipher text where the analyst\n \
    \     already knows the decryption algorithm, a brute-force technique\n      for\
    \ finding matching plain text is to decrypt the message with\n      every possible\
    \ key. In other cases, brute force involves trying a\n      large number of possibilities\
    \ but substantially fewer than all of\n      them. For example, given a hash function\
    \ that produces an N-bit\n      hash result, the probability is greater than 1/2\
    \ that the analyst\n      will find two inputs that have the same hash result\
    \ after trying\n      only 2**(N/2) randomly chosen inputs. (See: birthday attack.)\n\
    \   $ BS7799\n      (N) See: British Standard 7799.\n   $ buffer overflow\n  \
    \    (I) Any attack technique that exploits a vulnerability resulting\n      from\
    \ computer software or hardware that does not check for\n      exceeding the bounds\
    \ of a storage area when data is written into a\n      sequence of storage locations\
    \ beginning in that area.\n      Tutorial: By causing a normal system operation\
    \ to write data\n      beyond the bounds of a storage area, the attacker seeks\
    \ to either\n      disrupt system operation or cause the system to execute malicious\n\
    \      software inserted by the attacker.\n   $ buffer zone\n      (I) A neutral\
    \ internetwork segment used to connect other segments\n      that each operate\
    \ under a different security policy.\n      Tutorial: To connect a private network\
    \ to the Internet or some\n      other relatively public network, one could construct\
    \ a small,\n      separate, isolated LAN and connect it to both the private network\n\
    \      and the public network; one or both of the connections would\n      implement\
    \ a firewall to limit the traffic that could pass through\n      the buffer zone.\n\
    \   $ bulk encryption\n      1. (I) Encryption of multiple channels by aggregating\
    \ them into a\n      single transfer path and then encrypting that path. (See:\n\
    \      channel.)\n      2. (O) \"Simultaneous encryption of all channels of a\
    \ multichannel\n      telecommunications link.\" [C4009] (Compare: bulk keying\
    \ material.)\n      Usage: The use of \"simultaneous\" in definition 2 could be\n\
    \      interpreted to mean that multiple channels are encrypted\n      separately\
    \ but at the same time. However, the common meaning of\n      the term is that\
    \ multiple data flows are combined into a single\n      stream and then that stream\
    \ is encrypted as a whole.\n   $ bulk key\n      (D) In a few published descriptions\
    \ of hybrid encryption for SSH,\n      Windows 2000, and other applications, this\
    \ term refers to a\n      symmetric key that (a) is used to encrypt a relatively\
    \ large\n      amount of data and (b) is itself encrypted with a public key.\n\
    \      (Compare: bulk keying material, session key.)\n      Example: To send a\
    \ large file to Bob, Alice (a) generates a\n      symmetric key and uses it to\
    \ encrypt the file (i.e., encrypt the\n      bulk of the information that is to\
    \ be sent) and then (b) encrypts\n      that symmetric key (the \"bulk key\")\
    \ with Bob's public key.\n      Deprecated Term: IDOCs SHOULD NOT use this term\
    \ or definition; the\n      term is not well-established and could be confused\
    \ with the\n      established term \"bulk keying material\". Instead, use \"symmetric\n\
    \      key\" and carefully explain how the key is applied.\n   $ bulk keying material\n\
    \      (N) Refers to handling keying material in large quantities, e.g.,\n   \
    \   as a dataset that contains many items of keying material. (See:\n      type\
    \ 0. Compare: bulk key, bulk encryption.)\n   $ bump-in-the-stack\n      (I) An\
    \ implementation approach that places a network security\n      mechanism inside\
    \ the system that is to be protected. (Compare:\n      bump-in-the-wire.)\n  \
    \    Example: IPsec can be implemented inboard, in the protocol stack\n      of\
    \ an existing system or existing system design, by placing a new\n      layer\
    \ between the existing IP layer and the OSIRM Layer 3 drivers.\n      Source code\
    \ access for the existing stack is not required, but the\n      system that contains\
    \ the stack does need to be modified [R4301].\n   $ bump-in-the-wire\n      (I)\
    \ An implementation approach that places a network security\n      mechanism outside\
    \ of the system that is to be protected. (Compare:\n      bump-in-the-stack.)\n\
    \      Example: IPsec can be implemented outboard, in a physically\n      separate\
    \ device, so that the system that receives the IPsec\n      protection does not\
    \ need to be modified at all [R4301]. Military-\n      grade link encryption has\
    \ mainly been implemented as bump-in-the-\n      wire devices.\n   $ business-case\
    \ analysis\n      (N) An extended form of cost-benefit analysis that considers\n\
    \      factors beyond financial metrics, including security factors such\n   \
    \   as the requirement for security services, their technical and\n      programmatic\
    \ feasibility, their qualitative benefits, and\n      associated risks. (See:\
    \ risk analysis.)\n   $ byte\n      (I) A fundamental unit of computer storage;\
    \ the smallest\n      addressable unit in a computer's architecture. Usually holds\
    \ one\n      character of information and, today, usually means eight bits.\n\
    \      (Compare: octet.)\n      Usage: Understood to be larger than a \"bit\"\
    , but smaller than a\n      \"word\". Although \"byte\" almost always means \"\
    octet\" today, some\n      computer architectures have had bytes in other sizes\
    \ (e.g., six\n      bits, nine bits). Therefore, an STD SHOULD state the number\
    \ of\n      bits in a byte where the term is first used in the STD.\n   $ C field\n\
    \      (D) See: Compartments field.\n   $ C1 or C2 computer system\n      (O)\
    \ /TCSEC/ See: Tutorial under \"Trusted Computer System\n      Evaluation Criteria\"\
    .\n   $ CA\n      (I) See: certification authority.\n   $ CA certificate\n   \
    \   (D) \"A [digital] certificate for one CA issued by another CA.\"\n      [X509]\n\
    \      Deprecated Definition: IDOCs SHOULD NOT use the term with this\n      definition;\
    \ the definition is ambiguous with regard to how the\n      certificate is constructed\
    \ and how it is intended to be used.\n      IDOCs that use this term SHOULD provide\
    \ a technical definition for\n      it. (See: certificate profile.)\n      Tutorial:\
    \ There is no single, obvious choice for a technical\n      definition of this\
    \ term. Different PKIs can use different\n      certificate profiles, and X.509\
    \ provides several choices of how to\n      issue certificates to CAs. For example,\
    \ one possible definition is\n      the following: A v3 X.509 public-key certificate\
    \ that has a\n      \"basicConstraints\" extension containing a \"cA\" value of\
    \ \"TRUE\".\n      That would specifically indicate that \"the certified public\
    \ key\n      may be used to verify certificate signatures\", i.e., that the\n\
    \      private key may be used by a CA.\n      However, there also are other ways\
    \ to indicate such usage. The\n      certificate may have a \"key Usage\" extension\
    \ that indicates the\n      purposes for which the public key may be used, and\
    \ one of the\n      values that X.509 defines for that extension is \"keyCertSign\"\
    , to\n      indicate that the certificate may be used for verifying a CA's\n \
    \     signature on certificates. If \"keyCertSign\" is present in a\n      certificate\
    \ that also has a \"basicConstraints\" extension, then\n      \"cA\" is set to\
    \ \"TRUE\" in that extension. Alternatively, a CA could\n      be issued a certificate\
    \ in which \"keyCertSign\" is asserted without\n      \"basicConstraints\" being\
    \ present; and an entity that acts as a CA\n      could be issued a certificate\
    \ with \"keyUsage\" set to other values,\n      either with or without \"keyCertSign\"\
    .\n   $ CA domain\n      (N) /PKI/ A security policy domain that \"consists of\
    \ a CA and its\n      subjects [i.e., the entities named in the certificates issued\
    \ by\n      the CA]. Sometimes referred to as a PKI domain.\" [PAG] (See:\n  \
    \    domain.)\n   $ Caesar cipher\n      (I) A cipher that is defined for an alphabet\
    \ of N characters,\n      A(1), A(2), ..., A(N), and creates cipher text by replacing\
    \ each\n      plaintext character A(i) by A(i+K, mod N) for some 0<K<N+1. [Schn]\n\
    \      Examples: (a) During the Gallic wars, Julius Caesar used a cipher\n   \
    \   with K=3. In a Caesar cipher with K=3 for the English alphabet, A\n      is\
    \ replaced by D, B by E, C by F, ..., W by Z, X by A, Y by B, Z\n      by C. (b)\
    \ UNIX systems sometimes include \"ROT13\" software that\n      implements a Caesar\
    \ cipher with K=13 (i.e., ROTate by 13).\n   $ call back\n      (I) An authentication\
    \ technique for terminals that remotely access\n      a computer via telephone\
    \ lines; the host system disconnects the\n      caller and then reconnects on\
    \ a telephone number that was\n      previously authorized for that terminal.\n\
    \   $ CAM\n      (O) See: Certificate Arbitrator Module.\n   $ CANEWARE\n    \
    \  (O) An end-to-end encryption system for computer data networks\n      that\
    \ was developed by the U.S. DoD in the 1980s to provide host-\n      to-host data\
    \ confidentiality service for datagrams in OSIRM Layer\n      3. [Roge] (Compare:\
    \ BLACKER, IPsec.)\n      Tutorial: Each user host connects to its own bump-in-the-wire\n\
    \      encryption device called a CANEWARE Front End (CFE), through which\n  \
    \    the host connects to the subnetwork. CANEWARE uses symmetric\n      encryption\
    \ for CFE-to-CFE traffic, but also uses FIREFLY to\n      establish those session\
    \ keys. The public-key certificates issued\n      by the FIREFLY system include\
    \ credentials for mandatory access\n      control. For discretionary access control,\
    \ the system also\n      includes one or more centralized CANEWARE Control Processors\n\
    \      (CCPs) that connect to the subnetwork, maintain a database for\n      discretionary\
    \ access control authorizations, and communicate those\n      authorizations to\
    \ assigned sets of CFEs.\n      The CANEWARE system is MLS in only two of the\
    \ three ways that\n      BLACKER is MLS: (a) Like BLACKER BFEs, CFEs form a security\n\
    \      perimeter around a subnetwork, separating user hosts from the\n      subnetwork,\
    \ so that the subnetwork can operate at a different\n      security level than\
    \ the hosts. (b) Like BLACKER, the CANEWARE\n      components are trusted to separate\
    \ datagrams of different security\n      levels, so that each datagram of a given\
    \ security level can be\n      received only by a host that is authorized for\
    \ that security\n      level; and thus CANEWARE can separate host communities\
    \ that\n      operate at different security levels. (c) Unlike a BFE, the host\n\
    \      side of a CFE is not MLS, and treats all packets received from a\n    \
    \  user host as being at the same mandatory security level.\n   $ capability list\n\
    \      (I) /information system/ A mechanism that implements access\n      control\
    \ for a system entity by enumerating the system resources\n      that the entity\
    \ is permitted to access and, either implicitly or\n      explicitly, the access\
    \ modes granted for each resource. (Compare:\n      access control list, access\
    \ control matrix, access profile,\n      capability token.)\n   $ capability token\n\
    \      (I) A token (usually an unforgeable data object) that gives the\n     \
    \ bearer or holder the right to access a system resource. Possession\n      of\
    \ the token is accepted by a system as proof that the holder has\n      been authorized\
    \ to access the resource indicated by the token.\n      (See: attribute certificate,\
    \ capability list, credential, digital\n      certificate, ticket, token.)\n \
    \  $ Capability Maturity Model (CMM)\n      (N) Method for judging the maturity\
    \ of software processes in an\n      organization and for identifying crucial\
    \ practices needed to\n      increase process maturity. [Chris] (Compare: Common\
    \ Criteria.)\n      Tutorial: The CMM does not specify security evaluation criteria\n\
    \      (see: assurance level), but its use may improve security\n      assurance.\
    \ The CMM describes principles and practices that can\n      improve software\
    \ processes in terms of evolving from ad hoc\n      processes to disciplined processes.\
    \ The CMM has five levels:\n      -  Initial: Software processes are ad hoc or\
    \ chaotic, and few are\n         well-defined. Success depends on individual effort\
    \ and heroics.\n      -  Repeatable: Basic project management processes are established\n\
    \         to track cost, schedule, and functionality. Necessary process\n    \
    \     discipline is in place to repeat earlier successes on projects\n       \
    \  with similar applications.\n      -  Defined: Software process for both management\
    \ and engineering\n         activities is documented, standardized, and integrated\
    \ into a\n         standard software process for the organization. Each project\n\
    \         uses an approved, tailored version of the organization's\n         standard\
    \ process for developing and maintaining software.\n      -  Managed: Detailed\
    \ measures of software process and product\n         quality are collected. Both\
    \ software process and products are\n         quantitatively understood and controlled.\n\
    \      -  Optimizing: Continuous process improvement is enabled by\n         quantitative\
    \ feedback from the process and from piloting\n         innovative ideas and technologies.\n\
    \   $ CAPI\n      (I) See: cryptographic application programming interface.\n\
    \   $ CAPSTONE\n      (N) An integrated microcircuit (in MYK-8x series manufactured\
    \ by\n      Mykotronx, Inc.) that implements SKIPJACK, KEA, DSA, SHA, and\n  \
    \    basic mathematical functions needed to support asymmetric\n      cryptography;\
    \ has a non-deterministic random number generator; and\n      supports key escrow.\
    \ (See: FORTEZZA. Compare: CLIPPER.)\n   $ card\n      See: cryptographic card,\
    \ FORTEZZA, payment card, PC card, smart\n      card, token.\n   $ card backup\n\
    \      See: token backup.\n   $ card copy\n      See: token copy.\n   $ card restore\n\
    \      See: token restore.\n   $ cardholder\n      1. (I) An entity to whom or\
    \ to which a card has been issued.\n      Usage: Usually refers to a living human\
    \ being, but might refer (a)\n      to a position (see: billet, role) in an organization\
    \ or (b) to an\n      automated process. (Compare: user.)\n      2. (O) /SET/\
    \ \"The holder of a valid payment card account and user\n      of software supporting\
    \ electronic commerce.\" [SET2] A cardholder\n      is issued a payment card by\
    \ an issuer. SET ensures that in the\n      cardholder's interactions with merchants,\
    \ the payment card account\n      information remains confidential. [SET1]\n \
    \  $ cardholder certificate\n      (O) /SET/ A digital certificate that is issued\
    \ to a cardholder\n      upon approval of the cardholder's issuing financial institution\n\
    \      and that is transmitted to merchants with purchase requests and\n     \
    \ encrypted payment instructions, carrying assurance that the\n      account number\
    \ has been validated by the issuing financial\n      institution and cannot be\
    \ altered by a third party. [SET1]\n   $ cardholder certification authority (CCA)\n\
    \      (O) /SET/ A CA responsible for issuing digital certificates to\n      cardholders\
    \ and operated on behalf of a payment card brand, an\n      issuer, or another\
    \ party according to brand rules. A CCA maintains\n      relationships with card\
    \ issuers to allow for the verification of\n      cardholder accounts. A CCA does\
    \ not issue a CRL but does\n      distribute CRLs issued by root CAs, brand CAs,\
    \ geopolitical CAs,\n      and payment gateway CAs. [SET2]\n   $ CAST\n      (N)\
    \ A design procedure for symmetric encryption algorithms, and a\n      resulting\
    \ family of algorithms, invented by Carlisle Adams (C.A.)\n      and Stafford\
    \ Tavares (S.T.). [R2144, R2612]\n   $ category\n      (I) A grouping of sensitive\
    \ information items to which a non-\n      hierarchical restrictive security label\
    \ is applied to increase\n      protection of the data. (See: formal access approval.\
    \ Compare:\n      compartment, classification.)\n   $ CAW\n      (N) See: certification\
    \ authority workstation.\n   $ CBC\n      (N) See: cipher block chaining.\n  \
    \ $ CCA\n      (O) See: cardholder certification authority.\n   $ CCEP\n     \
    \ (O) See: Commercial COMSEC Endorsement Program.\n   $ CCI\n      (O) See: Controlled\
    \ Cryptographic Item.\n   $ CCITT\n      (N) Acronym for French translation of\
    \ International Telephone and\n      Telegraph Consultative Committee. Now renamed\
    \ ITU-T.\n   $ CCM\n      (N) See: Counter with Cipher Block Chaining-Message\
    \ Authentication\n      Code.\n   $ CERIAS\n      (O) Purdue University's Center\
    \ for Education and Research in\n      Information Assurance and Security, which\
    \ includes faculty from\n      multiple schools and departments and takes a multidisciplinary\n\
    \      approach to security problems ranging from technical to ethical,\n    \
    \  legal, educational, communicational, linguistic, and economic.\n   $ CERT\n\
    \      (I) See: computer emergency response team.\n   $ certificate\n      1.\
    \ (I) /general English/ A document that attests to the truth of\n      something\
    \ or the ownership of something.\n      2. (I) /general security/ See: capability\
    \ token, digital\n      certificate.\n      3. (I) /PKI/ See: attribute certificate,\
    \ public-key certificate.\n   $ Certificate Arbitrator Module (CAM)\n      (O)\
    \ An open-source software module that is designed to be\n      integrated with\
    \ an application for routing, replying to, and\n      otherwise managing and meditating\
    \ certificate validation requests\n      between that application and the CAs\
    \ in the ACES PKI.\n   $ certificate authority\n      (D) Synonym for \"certification\
    \ authority\".\n      Deprecated Term: IDOCs SHOULD NOT use this term; it suggests\n\
    \      careless use of the term \"certification authority\", which is\n      preferred\
    \ in PKI standards (e.g., [X509, R3280]).\n   $ certificate chain\n      (D) Synonym\
    \ for \"certification path\". (See: trust chain.)\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term; it duplicates the\n      meaning of a standardized\
    \ term. Instead, use \"certification path\".\n   $ certificate chain validation\n\
    \      (D) Synonym for \"certificate validation\" or \"path validation\".\n  \
    \    Deprecated Term: IDOCs SHOULD NOT use this term; it duplicates the\n    \
    \  meaning of standardized terms and mixes concepts in a potentially\n      misleading\
    \ way. Instead, use \"certificate validation\" or \"path\n      validation\",\
    \ depending on what is meant. (See: validate vs.\n      verify.)\n   $ certificate\
    \ creation\n      (I) The act or process by which a CA sets the values of a digital\n\
    \      certificate's data fields and signs it. (See: issue.)\n   $ certificate\
    \ expiration\n      (I) The event that occurs when a certificate ceases to be\
    \ valid\n      because its assigned lifetime has been exceeded. (See: certificate\n\
    \      revocation, expire.)\n      Tutorial: The assigned lifetime of an X.509\
    \ certificate is stated\n      in the certificate itself. (See: validity period.)\n\
    \   $ certificate extension\n      (I) See: extension.\n   $ certificate holder\n\
    \      (D) Synonym for the \"subject\" of a digital certificate. (Compare:\n \
    \     certificate owner, certificate user.)\n      Deprecated Definition: IDOCs\
    \ SHOULD NOT use this term as a synonym\n      for the subject of a digital certificate;\
    \ the term is potentially\n      ambiguous. For example, the term could be misunderstood\
    \ as\n      referring to a system entity or component, such as a repository,\n\
    \      that simply has possession of a copy of the certificate.\n   $ certificate\
    \ management\n      (I) The functions that a CA may perform during the lifecycle\
    \ of a\n      digital certificate, including the following:\n      -  Acquire\
    \ and verify data items to bind into the certificate.\n      -  Encode and sign\
    \ the certificate.\n      -  Store the certificate in a directory or repository.\n\
    \      -  Renew, rekey, and update the certificate.\n      -  Revoke the certificate\
    \ and issue a CRL.\n      (See: archive management, certificate management, key\
    \ management,\n      security architecture, token management.)\n   $ certificate\
    \ management authority (CMA)\n      (D) /U.S. DoD/ Used to mean either a CA or\
    \ an RA. [DoD7, SP32]\n      Deprecated Term: IDOCs SHOULD NOT use this term because\
    \ it is\n      potentially ambiguous, such as in a context involving ICRLs.\n\
    \      Instead, use CA, RA, or both, depending on what is meant.\n   $ certificate\
    \ owner\n      (D) Synonym for the \"subject\" of a digital certificate. (Compare:\n\
    \      certificate holder, certificate user.)\n      Deprecated Definition: IDOCs\
    \ SHOULD NOT use this term as a synonym\n      for the subject of a digital certificate;\
    \ the term is potentially\n      ambiguous. For example, the term could refer\
    \ to a system entity,\n      such as a corporation, that has purchased a certificate\
    \ to operate\n      equipment, such as a Web server.\n   $ certificate path\n\
    \      (D) Synonym for \"certification path\".\n      Deprecated Term: IDOCs SHOULD\
    \ NOT use this term; it suggests\n      careless use of \"certification path\"\
    , which is preferred in PKI\n      standards (e.g., [X509, R3280]).\n   $ certificate\
    \ policy\n      (I) \"A named set of rules that indicates the applicability of\
    \ a\n      certificate to a particular community and/or class of application\n\
    \      with common security requirements.\" [X509] (Compare: CPS, security\n \
    \     policy.)\n      Example: U.S. DoD's certificate policy [DoD7] defined four\
    \ classes\n      (i.e., assurance levels) for X.509 public-key certificates and\n\
    \      defines the applicability of those classes. (See: class 2.)\n      Tutorial:\
    \ A certificate policy can help a certificate user to\n      decide whether a\
    \ certificate should be trusted in a particular\n      application. \"For example,\
    \ a particular certificate policy might\n      indicate applicability of a type\
    \ of certificate for the\n      authentication of electronic data interchange\
    \ transactions for the\n      trading of goods within a given price range.\" [R3647]\n\
    \      A v3 X.509 public-key certificate may have a \"certificatePolicies\"\n\
    \      extension that lists certificate policies, recognized by the\n      issuing\
    \ CA, that apply to the certificate and govern its use. Each\n      policy is\
    \ denoted by an object identifier and may optionally have\n      certificate policy\
    \ qualifiers. (See: certificate profile.)\n      Each SET certificate specifies\
    \ at least one certificate policy,\n      that of the SET root CA. SET uses certificate\
    \ policy qualifiers to\n      point to the actual policy statement and to add\
    \ qualifying\n      policies to the root policy. (See: SET qualifier.)\n   $ certificate\
    \ policy qualifier\n      (I) Information that pertains to a certificate policy\
    \ and is\n      included in a \"certificatePolicies\" extension in a v3 X.509\n\
    \      public-key certificate.\n   $ certificate profile\n      (I) A specification\
    \ (e.g., [DoD7, R3280]) of the format and\n      semantics of public-key certificates\
    \ or attribute certificates,\n      constructed for use in a specific application\
    \ context by selecting\n      from among options offered by a broader standard.\
    \ (Compare:\n      protection profile.)\n   $ certificate reactivation\n     \
    \ (I) The act or process by which a digital certificate, that a CA\n      has\
    \ designated for revocation but not yet listed on a CRL, is\n      returned to\
    \ the valid state.\n   $ certificate rekey\n      1. (I) The act or process by\
    \ which an existing public-key\n      certificate has its key value changed by\
    \ issuing a new certificate\n      with a different (usually new) public key.\
    \ (See: certificate\n      renewal, certificate update, rekey.)\n      Tutorial:\
    \ For an X.509 public-key certificate, the essence of\n      rekey is that the\
    \ subject stays the same and a new public key is\n      bound to that subject.\
    \ Other changes are made, and the old\n      certificate is revoked, only as required\
    \ by the PKI and CPS in\n      support of the rekey. If changes go beyond that,\
    \ the process is a\n      \"certificate update\".\n      2. (O) /MISSI/ The act\
    \ or process by which a MISSI CA creates a\n      new X.509 public-key certificate\
    \ that is identical to the old one,\n      except the new one has (a) a new, different\
    \ KEA key or (b) a new,\n      different DSS key or (c) new, different KEA and\
    \ DSS keys. The new\n      certificate also has a different serial number and\
    \ may have a\n      different validity period. A new key creation date and maximum\
    \ key\n      lifetime period are assigned to each newly generated key. If a new\n\
    \      KEA key is generated, that key is assigned a new KMID. The old\n      certificate\
    \ remains valid until it expires, but may not be further\n      renewed, rekeyed,\
    \ or updated.\n   $ certificate renewal\n      (I) The act or process by which\
    \ the validity of the binding\n      asserted by an existing public-key certificate\
    \ is extended in time\n      by issuing a new certificate. (See: certificate rekey,\
    \ certificate\n      update.)\n      Tutorial: For an X.509 public-key certificate,\
    \ this term means\n      that the validity period is extended (and, of course,\
    \ a new serial\n      number is assigned) but the binding of the public key to\
    \ the\n      subject and to other data items stays the same. The other data\n\
    \      items are changed, and the old certificate is revoked, only as\n      required\
    \ by the PKI and CPS to support the renewal. If changes go\n      beyond that,\
    \ the process is a \"certificate rekey\" or \"certificate\n      update\".\n \
    \  $ certificate request\n      (D) Synonym for \"certification request\".\n \
    \     Deprecated Term: IDOCs SHOULD NOT use this term; it suggests\n      careless\
    \ use of the term \"certification request\", which is\n      preferred in PKI\
    \ standards (e.g., see PKCS #10).\n   $ certificate revocation\n      (I) The\
    \ event that occurs when a CA declares that a previously\n      valid digital\
    \ certificate issued by that CA has become invalid;\n      usually stated with\
    \ an effective date.\n      Tutorial: In X.509, a revocation is announced to potential\n\
    \      certificate users by issuing a CRL that mentions the certificate.\n   \
    \   Revocation and listing on a CRL is only necessary prior to the\n      certificate's\
    \ scheduled expiration.\n   $ certificate revocation list (CRL)\n      1. (I)\
    \ A data structure that enumerates digital certificates that\n      have been\
    \ invalidated by their issuer prior to when they were\n      scheduled to expire.\
    \ (See: certificate expiration, delta CRL,\n      X.509 certificate revocation\
    \ list.)\n      2. (O) \"A signed list indicating a set of certificates that are\
    \ no\n      longer considered valid by the certificate issuer. In addition to\n\
    \      the generic term CRL, some specific CRL types are defined for CRLs\n  \
    \    that cover particular scopes.\" [X509]\n   $ certificate revocation tree\n\
    \      (N) A mechanism for distributing notices of certificate\n      revocations;\
    \ uses a tree of hash results that is signed by the\n      tree's issuer. Offers\
    \ an alternative to issuing a CRL, but is not\n      supported in X.509. (See:\
    \ certificate status responder.)\n   $ certificate serial number\n      1. (I)\
    \ An integer value that (a) is associated with, and may be\n      carried in,\
    \ a digital certificate; (b) is assigned to the\n      certificate by the certificate's\
    \ issuer; and (c) is unique among\n      all the certificates produced by that\
    \ issuer.\n      2. (O) \"An integer value, unique within the issuing CA, [that]\
    \ is\n      unambiguously associated with a certificate issued by that CA.\"\n\
    \      [X509]\n   $ certificate status authority\n      (D) /U.S. DoD/ \"A trusted\
    \ entity that provides on-line\n      verification to a Relying Party of a subject\
    \ certificate's\n      trustworthiness [should instead say 'validity'], and may\
    \ also\n      provide additional attribute information for the subject\n     \
    \ certificate.\" [DoD7]\n      Deprecated Term: IDOCs SHOULD NOT use this term\
    \ because it is not\n      widely accepted; instead, use \"certificate status\
    \ responder\" or\n      \"OCSP server\", or otherwise explain what is meant.\n\
    \   $ certificate status responder\n      (N) /FPKI/ A trusted online server that\
    \ acts for a CA to provide\n      authenticated certificate status information\
    \ to certificate users\n      [FPKI]. Offers an alternative to issuing a CR. (See:\
    \ certificate\n      revocation tree, OCSP.)\n   $ certificate update\n      (I)\
    \ The act or process by which non-key data items bound in an\n      existing public-key\
    \ certificate, especially authorizations granted\n      to the subject, are changed\
    \ by issuing a new certificate. (See:\n      certificate rekey, certificate renewal.)\n\
    \      Usage: For an X.509 public-key certificate, the essence of this\n     \
    \ process is that fundamental changes are made in the data that is\n      bound\
    \ to the public key, such that it is necessary to revoke the\n      old certificate.\
    \ (Otherwise, the process is only a \"certificate\n      rekey\" or \"certificate\
    \ renewal\".)\n   $ certificate user\n      1. (I) A system entity that depends\
    \ on the validity of information\n      (such as another entity's public key value)\
    \ provided by a digital\n      certificate. (See: relying party. Compare: /digital\
    \ certificate/\n      subject.)\n      Usage: The depending entity may be a human\
    \ being or an\n      organization, or a device or process controlled by a human\
    \ or\n      organization. (See: user.)\n      2. (O) \"An entity that needs to\
    \ know, with certainty, the public\n      key of another entity.\" [X509]\n  \
    \    3. (D) Synonym for \"subject\" of a digital certificate.\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use this term with\n      definition 3; the term\
    \ could be confused with one of the other two\n      definitions given above.\n\
    \   $ certificate validation\n      1. (I) An act or process by which a certificate\
    \ user establishes\n      that the assertions made by a digital certificate can\
    \ be trusted.\n      (See: valid certificate, validate vs. verify.)\n      2.\
    \ (O) \"The process of ensuring that a certificate was valid at a\n      given\
    \ time, including possibly the construction and processing of\n      a certification\
    \ path [R4158], and ensuring that all certificates\n      in that path were valid\
    \ (i.e. were not expired or revoked) at that\n      given time.\" [X509]\n   \
    \   Tutorial: To validate a certificate, a certificate user checks\n      that\
    \ the certificate is properly formed and signed and is\n      currently in force:\n\
    \      -  Checks the syntax and semantics: Parses the certificate's\n        \
    \ syntax and interprets its semantics, applying rules specified\n         for\
    \ and by its data fields, such as for critical extensions in\n         an X.509\
    \ certificate.\n      -  Checks the signature: Uses the issuer's public key to\
    \ verify\n         the digital signature of the CA who issued the certificate\
    \ in\n         question. If the verifier obtains the issuer's public key from\n\
    \         the issuer's own public-key certificate, that certificate\n        \
    \ should be validated, too. That validation may lead to yet\n         another\
    \ certificate to be validated, and so on. Thus, in\n         general, certificate\
    \ validation involves discovering and\n         validating a certification path.\n\
    \      -  Checks currency and revocation: Verifies that the certificate\n    \
    \     is currently in force by checking that the current date and\n         time\
    \ are within the validity period (if that is specified in\n         the certificate)\
    \ and that the certificate is not listed on a\n         CRL or otherwise announced\
    \ as invalid. (The CRLs also must be\n         checked by a similar validation\
    \ process.)\n   $ certification\n      1. (I) /information system/ Comprehensive\
    \ evaluation (usually made\n      in support of an accreditation action) of an\
    \ information system's\n      technical security features and other safeguards\
    \ to establish the\n      extent to which the system's design and implementation\
    \ meet a set\n      of specified security requirements. [C4009, FP102, SP37] (See:\n\
    \      accreditation. Compare: evaluation.)\n      2. (I) /digital certificate/\
    \ The act or process of vouching for\n      the truth and accuracy of the binding\
    \ between data items in a\n      certificate. (See: certify.)\n      3. (I) /PKI/\
    \ The act or process of vouching for the ownership of a\n      public key by issuing\
    \ a public-key certificate that binds the key\n      to the name of the entity\
    \ that possesses the matching private key.\n      Besides binding a key with a\
    \ name, a public-key certificate may\n      bind those items with other restrictive\
    \ or explanatory data items.\n      (See: X.509 public-key certificate.)\n   \
    \   4. (O) /SET/ \"The process of ascertaining that a set of\n      requirements\
    \ or criteria has been fulfilled and attesting to that\n      fact to others,\
    \ usually with some written instrument. A system\n      that has been inspected\
    \ and evaluated as fully compliant with the\n      SET protocol by duly authorized\
    \ parties and process would be said\n      to have been certified compliant.\"\
    \ [SET2]\n   $ certification authority (CA)\n      1. (I) An entity that issues\
    \ digital certificates (especially\n      X.509 certificates) and vouches for\
    \ the binding between the data\n      items in a certificate.\n      2. (O) \"\
    An authority trusted by one or more users to create and\n      assign certificates.\
    \ Optionally the certification authority may\n      create the user's keys.\"\
    \ [X509]\n      Tutorial: Certificate users depend on the validity of information\n\
    \      provided by a certificate. Thus, a CA should be someone that\n      certificate\
    \ users trust and that usually holds an official\n      position created and granted\
    \ power by a government, a corporation,\n      or some other organization. A CA\
    \ is responsible for managing the\n      life cycle of certificates (see: certificate\
    \ management) and,\n      depending on the type of certificate and the CPS that\
    \ applies, may\n      be responsible for the lifecycle of key pairs associated\
    \ with the\n      certificates (see: key management).\n   $ certification authority\
    \ workstation (CAW)\n      (N) A computer system that enables a CA to issue digital\n\
    \      certificates and supports other certificate management functions\n    \
    \  as required.\n   $ certification hierarchy\n      1. (I) A tree-structured\
    \ (loop-free) topology of relationships\n      between CAs and the entities to\
    \ whom the CAs issue public-key\n      certificates. (See: hierarchical PKI, hierarchy\
    \ management.)\n      Tutorial: In this structure, one CA is the top CA, the highest\n\
    \      level of the hierarchy. (See: root, top CA.) The top CA may issue\n   \
    \   public-key certificates to one or more additional CAs that form\n      the\
    \ second-highest level. Each of these CAs may issue certificates\n      to more\
    \ CAs at the third-highest level, and so on. The CAs at the\n      second-lowest\
    \ level issue certificates only to non-CA entities\n      that form the lowest\
    \ level (see: end entity). Thus, all\n      certification paths begin at the top\
    \ CA and descend through zero\n      or more levels of other CAs. All certificate\
    \ users base path\n      validations on the top CA's public key.\n      2. (I)\
    \ /PEM/ A certification hierarchy for PEM has three levels of\n      CAs [R1422]:\n\
    \      -  The highest level is the \"Internet Policy Registration\n         Authority\"\
    .\n      -  A CA at the second-highest level is a \"policy certification\n   \
    \      authority\".\n      -  A CA at the third-highest level is a \"certification\
    \ authority\".\n      3. (O) /MISSI/ A certification hierarchy for MISSI has three\
    \ or\n      four levels of CAs:\n      -  A CA at the highest level, the top CA,\
    \ is a \"policy approving\n         authority\".\n      -  A CA at the second-highest\
    \ level is a \"policy creation\n         authority\".\n      -  A CA at the third-highest\
    \ level is a local authority called a\n         \"certification authority\".\n\
    \      -  A CA at the fourth-highest (optional) level is a \"subordinate\n   \
    \      certification authority\".\n      4. (O) /SET/ A certification hierarchy\
    \ for SET has three or four\n      levels of CAs:\n      -  The highest level\
    \ is a \"SET root CA\".\n      -  A CA at the second-highest level is a \"brand\
    \ certification\n         authority\".\n      -  A CA at the third-highest (optional)\
    \ level is a \"geopolitical\n         certification authority\".\n      -  A CA\
    \ at the fourth-highest level is a \"cardholder CA\", a\n         \"merchant CA\"\
    , or a \"payment gateway CA\".\n   $ certification path\n      1. (I) A linked\
    \ sequence of one or more public-key certificates,\n      or one or more public-key\
    \ certificates and one attribute\n      certificate, that enables a certificate\
    \ user to verify the\n      signature on the last certificate in the path, and\
    \ thus enables\n      the user to obtain (from that last certificate) a certified\
    \ public\n      key, or certified attributes, of the system entity that is the\n\
    \      subject of that last certificate. (See: trust anchor, certificate\n   \
    \   validation, valid certificate.)\n      2. (O) \"An ordered sequence of certificates\
    \ of objects in the\n      [X.500 Directory Information Tree] which, together\
    \ with the public\n      key of the initial object in the path, can be processed\
    \ to obtain\n      that of the final object in the path.\" [R3647, X509]\n   \
    \   Tutorial: The list is \"linked\" in the sense that the digital\n      signature\
    \ of each certificate (except possibly the first) is\n      verified by the public\
    \ key contained in the preceding certificate;\n      i.e., the private key used\
    \ to sign a certificate and the public\n      key contained in the preceding certificate\
    \ form a key pair that\n      has previously been bound to the authority that\
    \ signed.\n      The path is the \"list of certificates needed to [enable] a\n\
    \      particular user to obtain the public key [or attributes] of\n      another\
    \ [user].\" [X509] Here, the word \"particular\" points out\n      that a certification\
    \ path that can be validated by one certificate\n      user might not be able\
    \ to be validated by another. That is because\n      either the first certificate\
    \ needs to be a trusted certificate or\n      the signature on the first certificate\
    \ needs to be verifiable by a\n      trusted key (e.g., a root key), but such\
    \ trust is established only\n      relative to a \"particular\" (i.e., specific)\
    \ user, not absolutely\n      for all users.\n   $ certification policy\n    \
    \  (D) Synonym for either \"certificate policy\" or \"certification\n      practice\
    \ statement\".\n      Deprecated Term: IDOCs SHOULD NOT use this term as a synonym\
    \ for\n      either of those terms; that would be duplicative and would mix\n\
    \      concepts in a potentially misleading way. Instead, use either\n      \"\
    certificate policy\" or \"certification practice statement\",\n      depending\
    \ on what is meant.\n   $ certification practice statement (CPS)\n      (I) \"\
    A statement of the practices which a certification authority\n      employs in\
    \ issuing certificates.\" [DSG, R3647] (See: certificate\n      policy.)\n   \
    \   Tutorial: A CPS is a published security policy that can help a\n      certificate\
    \ user to decide whether a certificate issued by a\n      particular CA can be\
    \ trusted enough to use in a particular\n      application. A CPS may be (a) a\
    \ declaration by a CA of the details\n      of the system and practices it uses\
    \ in its certificate management\n      operations, (b) part of a contract between\
    \ the CA and an entity to\n      whom a certificate is issued, (c) a statute or\
    \ regulation\n      applicable to the CA, or (d) a combination of these types\n\
    \      involving multiple documents. [DSG]\n      A CPS is usually more detailed\
    \ and procedurally oriented than a\n      certificate policy. A CPS applies to\
    \ a particular CA or CA\n      community, while a certificate policy applies across\
    \ CAs or\n      communities. A CA with its single CPS may support multiple\n \
    \     certificate policies, which may be used for different application\n    \
    \  purposes or by different user communities. On the other hand,\n      multiple\
    \ CAs, each with a different CPS, may support the same\n      certificate policy.\
    \ [R3647]\n   $ certification request\n      (I) An algorithm-independent transaction\
    \ format (e.g., PKCS #10,\n      RFC 4211) that contains a DN, and a public key\
    \ or, optionally, a\n      set of attributes, collectively signed by the entity\
    \ requesting\n      certification, and sent to a CA, which transforms the request\
    \ to\n      an X.509 public-key certificate or another type of certificate.\n\
    \   $ certify\n      1. (I) Issue a digital certificate and thus vouch for the\
    \ truth,\n      accuracy, and binding between data items in the certificate (e.g.,\n\
    \      \"X.509 public-key certificate\"), such as the identity of the\n      certificate's\
    \ subject and the ownership of a public key. (See:\n      certification.)\n  \
    \    Usage: To \"certify a public key\" means to issue a public-key\n      certificate\
    \ that vouches for the binding between the certificate's\n      subject and the\
    \ key.\n      2. (I) The act by which a CA uses measures to verify the truth,\n\
    \      accuracy, and binding between data items in a digital certificate.\n  \
    \    Tutorial: A description of the measures used for verification\n      should\
    \ be included in the CA's CPS.\n   $ CFB\n      (N) See: cipher feedback.\n  \
    \ $ chain\n      (D) See: trust chain.\n   $ Challenge Handshake Authentication\
    \ Protocol (CHAP)\n      (I) A peer entity authentication method (employed by\
    \ PPP and other\n      protocols, e.g., RFC 3720) that uses a randomly generated\n\
    \      challenge and requires a matching response that depends on a\n      cryptographic\
    \ hash of some combination of the challenge and a\n      secret key. [R1994] (See:\
    \ challenge-response, PAP.)\n   $ challenge-response\n      (I) An authentication\
    \ process that verifies an identity by\n      requiring correct authentication\
    \ information to be provided in\n      response to a challenge. In a computer\
    \ system, the authentication\n      information is usually a value that is required\
    \ to be computed in\n      response to an unpredictable challenge value, but it\
    \ might be just\n      a password.\n   $ Challenge-Response Authentication Mechanism\
    \ (CRAM)\n      (I) /IMAP4/ A mechanism [R2195], intended for use with IMAP4\n\
    \      AUTHENTICATE, by which an IMAP4 client uses a keyed hash [R2104]\n    \
    \  to authenticate itself to an IMAP4 server. (See: POP3 APOP.)\n      Tutorial:\
    \ The server includes a unique time stamp in its ready\n      response to the\
    \ client. The client replies with the client's name\n      and the hash result\
    \ of applying MD5 to a string formed from\n      concatenating the time stamp\
    \ with a shared secret that is known\n      only to the client and the server.\n\
    \   $ channel\n      1. (I) An information transfer path within a system. (See:\
    \ covert\n      channel.)\n      2. (O) \"A subdivision of the physical medium\
    \ allowing possibly\n      shared independent uses of the medium.\" (RFC 3753)\n\
    \   $ channel capacity\n      (I) The total capacity of a link to carry information;\
    \ usually\n      expressed in bits per second. (RFC 3753) (Compare: bandwidth.)\n\
    \      Tutorial: Within a given bandwidth, the theoretical maximum\n      channel\
    \ capacity is given by Shannon's Law. The actual channel\n      capacity is determined\
    \ by the bandwidth, the coding system used,\n      and the signal-to-noise ratio.\n\
    \   $ CHAP\n      (I) See: Challenge Handshake Authentication Protocol.\n   $\
    \ checksum\n      (I) A value that (a) is computed by a function that is dependent\n\
    \      on the contents of a data object and (b) is stored or transmitted\n   \
    \   together with the object, for detecting changes in the data. (See:\n     \
    \ cyclic redundancy check, data integrity service, error detection\n      code,\
    \ hash, keyed hash, parity bit, protected checksum.)\n      Tutorial: To gain\
    \ confidence that a data object has not been\n      changed, an entity that later\
    \ uses the data can independently\n      recompute the checksum value and compare\
    \ the result with the value\n      that was stored or transmitted with the object.\n\
    \      Computer systems and networks use checksums (and other mechanisms)\n  \
    \    to detect accidental changes in data. However, active wiretapping\n     \
    \ that changes data could also change an accompanying checksum to\n      match\
    \ the changed data. Thus, some checksum functions by\n      themselves are not\
    \ good countermeasures for active attacks. To\n      protect against active attacks,\
    \ the checksum function needs to be\n      well-chosen (see: cryptographic hash),\
    \ and the checksum result\n      needs to be cryptographically protected (see:\
    \ digital signature,\n      keyed hash).\n   $ Chinese wall policy\n      (I)\
    \ A security policy to prevent conflict of interest caused by an\n      entity\
    \ (e.g., a consultant) interacting with competing firms.\n      (See: Brewer-Nash\
    \ model.)\n      Tutorial: All information is categorized into mutually exclusive\n\
    \      conflict-of-interest classes I(1), I(2), ..., I(M), and each firm\n   \
    \   F(1), F(2), ..., F(N) belongs to exactly one class. The policy\n      states\
    \ that if a consultant has access to class I(i) information\n      from a firm\
    \ in that class, then the consultant may not access\n      information from another\
    \ firm in that same class, but may access\n      information from another firm\
    \ that is in a different class. Thus,\n      the policy creates a barrier to communication\
    \ between firms that\n      are in the same conflict-of-interest class. Brewer\
    \ and Nash\n      modeled enforcement of this policy [BN89], including dealing\
    \ with\n      policy violations that could occur because two or more consultants\n\
    \      work for the same firm.\n   $ chosen-ciphertext attack\n      (I) A cryptanalysis\
    \ technique in which the analyst tries to\n      determine the key from knowledge\
    \ of plain text that corresponds to\n      cipher text selected (i.e., dictated)\
    \ by the analyst.\n   $ chosen-plaintext attack\n      (I) A cryptanalysis technique\
    \ in which the analyst tries to\n      determine the key from knowledge of cipher\
    \ text that corresponds\n      to plain text selected (i.e., dictated) by the\
    \ analyst.\n   $ CIAC\n      (O) See: Computer Incident Advisory Capability.\n\
    \   $ CIK\n      (N) See: cryptographic ignition key.\n   $ cipher\n      (I)\
    \ A cryptographic algorithm for encryption and decryption.\n   $ cipher block\
    \ chaining (CBC)\n      (N) A block cipher mode that enhances ECB mode by chaining\n\
    \      together blocks of cipher text it produces. [FP081] (See: block\n     \
    \ cipher, [R1829], [R2405], [R2451], [SP38A].)\n      Tutorial: This mode operates\
    \ by combining (exclusive OR-ing) the\n      algorithm's ciphertext output block\
    \ with the next plaintext block\n      to form the next input block for the algorithm.\n\
    \   $ cipher feedback (CFB)\n      (N) A block cipher mode that enhances ECB mode\
    \ by chaining\n      together the blocks of cipher text it produces and operating\
    \ on\n      plaintext segments of variable length less than or equal to the\n\
    \      block length. [FP081] (See: block cipher, [SP38A].)\n      Tutorial: This\
    \ mode operates by using the previously generated\n      ciphertext segment as\
    \ the algorithm's input (i.e., by \"feeding\n      back\" the cipher text) to\
    \ generate an output block, and then\n      combining (exclusive OR-ing) that\
    \ output block with the next\n      plaintext segment (block length or less) to\
    \ form the next\n      ciphertext segment.\n   $ cipher text\n      1. (I) /noun/\
    \ Data that has been transformed by encryption so that\n      its semantic information\
    \ content (i.e., its meaning) is no longer\n      intelligible or directly available.\
    \ (See: ciphertext. Compare:\n      clear text, plain text.)\n      2. (O) \"\
    Data produced through the use of encipherment. The\n      semantic content of\
    \ the resulting data is not available.\"\n      [I7498-2]\n   $ ciphertext\n \
    \     1. (O) /noun/ Synonym for \"cipher text\" [I7498-2].\n      2. (I) /adjective/\
    \ Referring to cipher text. Usage: Commonly used\n      instead of \"cipher-text\"\
    . (Compare: cleartext, plaintext.)\n   $ ciphertext auto-key (CTAK)\n      (D)\
    \ \"Cryptographic logic that uses previous cipher text to\n      generate a key\
    \ stream.\" [C4009, A1523] (See: KAK.)\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use this term; it is neither\n      well-known nor precisely defined. Instead,\
    \ use terms associated\n      with modes that are defined in standards, such as\
    \ CBC, CFB, and\n      OFB.\n   $ ciphertext-only attack\n      (I) A cryptanalysis\
    \ technique in which the analyst tries to\n      determine the key solely from\
    \ knowledge of intercepted cipher text\n      (although the analyst may also know\
    \ other clues, such as the\n      cryptographic algorithm, the language in which\
    \ the plain text was\n      written, the subject matter of the plain text, and\
    \ some probable\n      plaintext words.)\n   $ ciphony\n      (O) The process\
    \ of encrypting audio information.\n   $ CIPSO\n      (I) See: Common IP Security\
    \ Option.\n   $ CKL\n      (I) See: compromised key list.\n   $ Clark-Wilson model\n\
    \      (N) A security model [Clark] to maintain data integrity in the\n      commercial\
    \ world. (Compare: Bell-LaPadula model.)\n   $ class 2, 3, 4, 5\n      (O) /U.S.\
    \ DoD/ Assurance levels for PKIs, and for X.509 public-key\n      certificates\
    \ issued by a PKI. [DoD7] (See: \"first law\" under\n      \"Courtney's laws\"\
    .)\n      -  \"Class 2\": Intended for applications handling unclassified,\n \
    \        low-value data in minimally or moderately protected\n         environments.\n\
    \      -  \"Class 3\": Intended for applications handling unclassified,\n    \
    \     medium-value data in moderately protected environments, or\n         handling\
    \ unclassified or high-value data in highly protected\n         environments,\
    \ and for discretionary access control of\n         classified data in highly\
    \ protected environments.\n      -  \"Class 4\": Intended for applications handling\
    \ unclassified,\n         high-value data in minimally protected environments.\n\
    \      -  \"Class 5\": Intended for applications handling classified data\n  \
    \       in minimally protected environments, and for authentication of\n     \
    \    material that would affect the security of classified systems.\n      The\
    \ environments are defined as follows:\n      -  \"Highly protected environment\"\
    : Networks that are protected\n         either with encryption devices approved\
    \ by NSA for protection\n         of classified data or via physical isolation,\
    \ and that are\n         certified for processing system-high classified data,\
    \ where\n         exposure of unencrypted data is limited to U.S. citizens\n \
    \        holding appropriate security clearances.\n      -  \"Moderately protected\
    \ environment\":\n         -- Physically isolated unclassified, unencrypted networks\
    \ in\n            which access is restricted based on legitimate need.\n     \
    \    -- Networks protected by NSA-approved, type 1 encryption,\n            accessible\
    \ by U.S.-authorized foreign nationals.\n      -  \"Minimally protected environments\"\
    : Unencrypted networks\n         connected to either the Internet or NIPRNET,\
    \ either directly or\n         via a firewall.\n   $ Class A1, B3, B2, B1, C2,\
    \ or C1 computer system\n      (O) /TCSEC/ See: Tutorial under \"Trusted Computer\
    \ System\n      Evaluation Criteria\".\n   $ classification\n      1. (I) A grouping\
    \ of classified information to which a\n      hierarchical, restrictive security\
    \ label is applied to increase\n      protection of the data from unauthorized\
    \ disclosure. (See:\n      aggregation, classified, data confidentiality service.\
    \ Compare:\n      category, compartment.)\n      2. (I) An authorized process\
    \ by which information is determined to\n      be classified and assigned to a\
    \ security level. (Compare:\n      declassification.)\n      Usage: Usually understood\
    \ to involve data confidentiality, but\n      IDOCs SHOULD make this clear when\
    \ data also is sensitive in other\n      ways and SHOULD use other terms for those\
    \ other sensitivity\n      concepts. (See: sensitive information, data integrity.)\n\
    \   $ classification label\n      (I) A security label that tells the degree of\
    \ harm that will\n      result from unauthorized disclosure of the labeled data,\
    \ and may\n      also tell what countermeasures are required to be applied to\n\
    \      protect the data from unauthorized disclosure. Example: IPSO.\n      (See:\
    \ classified, data confidentiality service. Compare: integrity\n      label.)\n\
    \      Usage: Usually understood to involve data confidentiality, but\n      IDOCs\
    \ SHOULD make this clear when data also is sensitive in other\n      ways and\
    \ SHOULD use other terms for those other sensitivity\n      concepts. (See: sensitive\
    \ information, data integrity.)\n   $ classification level\n      (I) A hierarchical\
    \ level of protection (against unauthorized\n      disclosure) that is required\
    \ to be applied to certain classified\n      data. (See: classified. Compare:\
    \ security level.)\n      Usage: Usually understood to involve data confidentiality,\
    \ but\n      IDOCs SHOULD make this clear when data also is sensitive in other\n\
    \      ways and SHOULD use other terms for those other sensitivity\n      concepts.\
    \ (See: sensitive information, data integrity.)\n   $ classified\n      1. (I)\
    \ Refers to information (stored or conveyed, in any form)\n      that is formally\
    \ required by a security policy to receive data\n      confidentiality service\
    \ and to be marked with a security label\n      (which, in some cases, might be\
    \ implicit) to indicate its\n      protected status. (See: classify, collateral\
    \ information, SAP,\n      security level. Compare: unclassified.)\n      Usage:\
    \ Usually understood to involve data confidentiality, but\n      IDOCs SHOULD\
    \ make this clear when data also is sensitive in other\n      ways and SHOULD\
    \ use other terms for those other sensitivity\n      concepts. (See: sensitive\
    \ information, data integrity.)\n      Mainly used by national governments, especially\
    \ by the military,\n      but the underlying concept also applies outside of governments.\n\
    \      2. (O) /U.S. Government/ \"Information that has been determined\n     \
    \ pursuant to Executive Order 12958 or any predecessor Order, or by\n      the\
    \ Atomic Energy Act of 1954, as amended, to require protection\n      against\
    \ unauthorized disclosure and is marked to indicate its\n      classified status.\"\
    \ [C4009]\n   $ classify\n      (I) To officially designate an information item\
    \ or type of\n      information as being classified and assigned to a specific\n\
    \      security level. (See: classified, declassify, security level.)\n   $ clean\
    \ system\n      (I) A computer system in which the operating system and\n    \
    \  application system software and files have been freshly installed\n      from\
    \ trusted software distribution media. (Compare: secure state.)\n   $ clear\n\
    \      (D) /verb/ Synonym for \"erase\". [C4009]\n      Deprecated Definition:\
    \ IDOCs SHOULD NOT use the term with this\n      definition; that could be confused\
    \ with \"clear text\" in which\n      information is directly recoverable.\n \
    \  $ clear text\n      1. (I) /noun/ Data in which the semantic information content\n\
    \      (i.e., the meaning) is intelligible or is directly available,\n      i.e.,\
    \ not encrypted. (See: cleartext, in the clear. Compare:\n      cipher text, plain\
    \ text.)\n      2. (O) /noun/ \"Intelligible data, the semantic content of which\
    \ is\n      available.\" [I7498-2]\n      3. (D) /noun/ Synonym for \"plain text\"\
    .\n      Deprecated Definition: IDOCs SHOULD NOT use this term as a synonym\n\
    \      for \"plain text\", because the plain text that is input to an\n      encryption\
    \ operation may itself be cipher text that was output\n      from a previous encryption\
    \ operation. (See: superencryption.)\n   $ clearance\n      See: security clearance.\n\
    \   $ clearance level\n      (I) The security level of information to which a\
    \ security\n      clearance authorizes a person to have access.\n   $ cleartext\n\
    \      1. (O) /noun/ Synonym for \"clear text\" [I7498-2].\n      2. (I) /adjective/\
    \ Referring to clear text. Usage: Commonly used\n      instead of \"clear-text\"\
    . (Compare: ciphertext, plaintext.)\n      3. (D) /adjective/ Synonym for \"plaintext\"\
    .\n      Deprecated Definition: IDOCs SHOULD NOT use this term as a synonym\n\
    \      for \"plaintext\", because the plaintext data that is input to an\n   \
    \   encryption operation may itself be ciphertext data that was output\n     \
    \ from a previous encryption operation. (See: superencryption.)\n   $ CLEF\n \
    \     (N) See: commercially licensed evaluation facility.\n   $ client\n     \
    \ (I) A system entity that requests and uses a service provided by\n      another\
    \ system entity, called a \"server\". (See: server.)\n      Tutorial: Usually,\
    \ it is understood that the client and server are\n      automated components\
    \ of the system, and the client makes the\n      request on behalf of a human\
    \ user. In some cases, the server may\n      itself be a client of some other\
    \ server.\n   $ client-server system\n      (I) A distributed system in which\
    \ one or more entities, called\n      clients, request a specific service from\
    \ one or more other\n      entities, called servers, that provide the service\
    \ to the clients.\n      Example: The Word Wide Web, in which component servers\
    \ provide\n      information that is requested by component clients called\n \
    \     \"browsers\".\n   $ CLIPPER\n      (N) An integrated microcircuit (in MYK-7x\
    \ series manufactured by\n      Mykotronx, Inc.) that implements SKIPJACK, has\
    \ a non-deterministic\n      random number generator, and supports key escrow.\
    \ (See: Escrowed\n      Encryption Standard. Compare: CLIPPER.)\n      Tutorial:\
    \ The chip was mainly intended for protecting\n      telecommunications over the\
    \ public switched network. The key\n      escrow scheme for the chip involves\
    \ a SKIPJACK key that is common\n      to all chips and that protects the unique\
    \ serial number of the\n      chip, and a second SKIPJACK key unique to the chip\
    \ that protects\n      all data encrypted by the chip. The second key is escrowed\
    \ as\n      split key components held by NIST and the U.S. Treasury\n      Department.\n\
    \   $ closed security environment\n      (O) /U.S. DoD/ A system environment that\
    \ meets both of the\n      following conditions: (a) Application developers (including\n\
    \      maintainers) have sufficient clearances and authorizations to\n      provide\
    \ an acceptable presumption that they have not introduced\n      malicious logic.\
    \ (b) Configuration control provides sufficient\n      assurance that system applications\
    \ and the equipment they run on\n      are protected against the introduction\
    \ of malicious logic prior to\n      and during the operation of applications.\
    \ [NCS04] (See: \"first\n      law\" under \"Courtney's laws\". Compare: open\
    \ security environment.)\n   $ CMA\n      (D) See: certificate management authority.\n\
    \   $ CMAC\n      (N) A message authentication code [SP38B] that is based on a\n\
    \      symmetric block cipher. (See: block cipher.)\n      Derivation: Cipher-based\
    \ MAC. (Compare: HMAC.)\n      Tutorial: Because CMAC is based on approved, symmetric-key\
    \ block\n      ciphers, such as AES, CMAC can be considered a mode of operation\n\
    \      for those block ciphers. (See: mode of operation.)\n   $ CMCS\n      (O)\
    \ See: COMSEC Material Control System.\n   $ CMM\n      (N) See: Capability Maturity\
    \ Model.\n   $ CMS\n      (I) See: Cryptographic Message Syntax.\n   $ code\n\
    \      1. (I) A system of symbols used to represent information, which\n     \
    \ might originally have some other representation. Examples: ASCII,\n      BER,\
    \ country code, Morse code. (See: encode, object code, source\n      code.)\n\
    \      Deprecated Abbreviation: To avoid confusion with definition 1,\n      IDOCs\
    \ SHOULD NOT use \"code\" as an abbreviation of \"country code\",\n      \"cyclic\
    \ redundancy code\", \"Data Authentication Code\", \"error\n      detection code\"\
    , or \"Message Authentication Code\". To avoid\n      misunderstanding, use the\
    \ fully qualified term in these other\n      cases, at least at the point of first\
    \ usage.\n      2. (I) /cryptography/ An encryption algorithm based on\n     \
    \ substitution; i.e., a system for providing data confidentiality by\n      using\
    \ arbitrary groups (called \"code groups\") of letters, numbers,\n      or symbols\
    \ to represent units of plain text of varying length.\n      (See: codebook, cryptography.)\n\
    \      Deprecated Usage: To avoid confusion with definition 1, IDOCs\n      SHOULD\
    \ NOT use \"code\" as a synonym for any of the following terms:\n      (a) \"\
    cipher\", \"hash\", or other words that mean \"a cryptographic\n      algorithm\"\
    ; (b) \"cipher text\"; or (c) \"encrypt\", \"hash\", or other\n      words that\
    \ refer to applying a cryptographic algorithm.\n      3. (I) An algorithm based\
    \ on substitution, but used to shorten\n      messages rather than to conceal\
    \ their content.\n      4. (I) /computer programming/ To write computer software.\
    \ (See:\n      object code, source code.)\n      Deprecated Abbreviation: To avoid\
    \ confusion with definition 1,\n      IDOCs SHOULD NOT use \"code\" as an abbreviation\
    \ of \"object code\" or\n      \"source code\". To avoid misunderstanding, use\
    \ the fully qualified\n      term in these other cases, at least at the point\
    \ of first usage.\n   $ code book\n      1. (I) Document containing a systematically\
    \ arranged list of\n      plaintext units and their ciphertext equivalents. [C4009]\n\
    \      2. (I) An encryption algorithm that uses a word substitution\n      technique.\
    \ [C4009] (See: code, ECB.)\n   $ code signing\n      (I) A security mechanism\
    \ that uses a digital signature to provide\n      data integrity and data origin\
    \ authentication for software that is\n      being distributed for use. (See:\
    \ mobile code, trusted\n      distribution.)\n      Tutorial: In some cases, the\
    \ signature on a software module may\n      imply some assertion that the signer\
    \ makes about the software. For\n      example, a signature may imply that the\
    \ software has been\n      designed, developed, or tested according to some criterion.\n\
    \   $ code word\n      (O) /U.S. Government/ A single word that is used as a security\n\
    \      label (usually applied to classified information) but which itself\n  \
    \    has a classified meaning. (See: classified, /U.S. Government/\n      security\
    \ label.)\n   $ COI\n      (I) See: community of interest.\n   $ cold start\n\
    \      (N) /cryptographic module/ A procedure for initially keying\n      cryptographic\
    \ equipment. [C4009]\n   $ collateral information\n      (O) /U.S. Government/\
    \ Information that is classified but is not\n      required to be protected by\
    \ an SAP. (See: /U.S. Government/\n      classified.)\n   $ color change\n   \
    \   (I) In a system being operated in periods-processing mode, the act\n     \
    \ of purging all information from one processing period and then\n      changing\
    \ over to the next processing period. (See: BLACK, RED.)\n   $ Commercial COMSEC\
    \ Evaluation Program (CCEP)\n      (O) \"Relationship between NSA and industry\
    \ in which NSA provides\n      the COMSEC expertise (i.e., standards, algorithms,\
    \ evaluations,\n      and guidance) and industry provides design, development,\
    \ and\n      production capabilities to produce a type 1 or type 2 product.\"\n\
    \      [C4009]\n   $ commercially licensed evaluation facility (CLEF)\n      (N)\
    \ An organization that has official approval to evaluate the\n      security of\
    \ products and systems under the Common Criteria, ITSEC,\n      or some other\
    \ standard. (Compare: KLIF.)\n   $ Committee on National Security Systems (CNSS)\n\
    \      (O) /U.S. Government/ A Government, interagency, standing\n      committee\
    \ of the President's Critical Infrastructure Protection\n      Board. The CNSS\
    \ is chaired by the Secretary of Defense and\n      provides a forum for the discussion\
    \ of policy issues, sets\n      national policy, and promulgates direction, operational\n\
    \      procedures, and guidance for the security of national security\n      systems.\
    \ The Secretary of Defense and the Director of Central\n      Intelligence are\
    \ responsible for developing and overseeing the\n      implementation of Government-wide\
    \ policies, principles, standards,\n      and guidelines for the security of systems\
    \ that handle national\n      security information.\n   $ Common Criteria for\
    \ Information Technology Security\n      (N) A standard for evaluating information\
    \ technology (IT) products\n      and systems. It states requirements for security\
    \ functions and for\n      assurance measures. [CCIB] (See: CLEF, EAL, packages,\
    \ protection\n      profile, security target, TOE. Compare: CMM.)\n      Tutorial:\
    \ Canada, France, Germany, the Netherlands, the United\n      Kingdom, and the\
    \ United States (NIST and NSA) began developing\n      this standard in 1993,\
    \ based on the European ITSEC, the Canadian\n      Trusted Computer Product Evaluation\
    \ Criteria (CTCPEC), and the\n      U.S. \"Federal Criteria for Information Technology\
    \ Security\" and\n      its precursor, the TCSEC. Work was done in cooperation\
    \ with\n      ISO/IEC Joint Technical Committee 1 (Information Technology),\n\
    \      Subcommittee 27 (Security Techniques), Working Group 3 (Security\n    \
    \  Criteria). Version 2.0 of the Criteria has been issued as ISO's\n      International\
    \ Standard 15408. The U.S. Government intends this\n      standard to supersede\
    \ both the TCSEC and FIPS PUB 140. (See:\n      NIAP.)\n      The standard addresses\
    \ data confidentiality, data integrity, and\n      availability and may apply\
    \ to other aspects of security. It\n      focuses on threats to information arising\
    \ from human activities,\n      malicious or otherwise, but may apply to non-human\
    \ threats. It\n      applies to security measures implemented in hardware, firmware,\
    \ or\n      software. It does not apply to (a) administrative security not\n \
    \     related directly to technical security, (b) technical physical\n      aspects\
    \ of security such as electromagnetic emanation control, (c)\n      evaluation\
    \ methodology or administrative and legal framework under\n      which the criteria\
    \ may be applied, (d) procedures for use of\n      evaluation results, or (e)\
    \ assessment of inherent qualities of\n      cryptographic algorithms.\n     \
    \ Part 1, Introduction and General Model, defines general concepts\n      and\
    \ principles of IT security evaluation; presents a general model\n      of evaluation;\
    \ and defines constructs for expressing IT security\n      objectives, for selecting\
    \ and defining IT security requirements,\n      and for writing high-level specifications\
    \ for products and\n      systems.\n      Part 2, Security Functional Requirements,\
    \ contains a catalog of\n      well-defined and well-understood functional requirement\
    \ statements\n      that are intended to be used as a standard way of expressing\
    \ the\n      security requirements for IT products and systems.\n      Part 3,\
    \ Security Assurance Requirements, contains a catalog of\n      assurance components\
    \ for use as a standard way of expressing such\n      requirements for IT products\
    \ and systems, and defines evaluation\n      criteria for protection profiles\
    \ and security targets.\n   $ Common IP Security Option (CIPSO)\n      (I) See:\
    \ secondary definition under \"IPSO\".\n   $ common name\n      (N) A character\
    \ string that (a) may be a part of the X.500 DN of a\n      Directory object (\"\
    commonName\" attribute), (b) is a (possibly\n      ambiguous) name by which the\
    \ object is commonly known in some\n      limited scope (such as an organization),\
    \ and (c) conforms to the\n      naming conventions of the country or culture\
    \ with which it is\n      associated. [X520] (See: \"subject\" and \"issuer\"\
    \ under \"X.509\n      public-key certificate\".)\n      Examples: \"Dr. Albert\
    \ Einstein\", \"The United Nations\", and \"12-th\n      Floor Laser Printer\"\
    .\n   $ communications cover\n      (N) \"Concealing or altering of characteristic\
    \ communications\n      patterns to hide information that could be of value to\
    \ an\n      adversary.\" [C4009] (See: operations security, traffic-flow\n   \
    \   confidentiality, TRANSEC.)\n   $ communication security (COMSEC)\n      (I)\
    \ Measures that implement and assure security services in a\n      communication\
    \ system, particularly those that provide data\n      confidentiality and data\
    \ integrity and that authenticate\n      communicating entities.\n      Usage:\
    \ COMSEC is usually understood to include (a) cryptography\n      and its related\
    \ algorithms and key management methods and\n      processes, devices that implement\
    \ those algorithms and processes,\n      and the lifecycle management of the devices\
    \ and keying material.\n      Also, COMSEC is sometimes more broadly understood\
    \ as further\n      including (b) traffic-flow confidentiality, (c) TRANSEC, and\
    \ (d)\n      steganography [Kahn]. (See: cryptology, signal security.)\n   $ community\
    \ of interest (COI)\n      1. (I) A set of entities that operate under a common\
    \ security\n      policy. (Compare: domain.)\n      2. (I) A set of entities that\
    \ exchange information collaboratively\n      for some purpose.\n   $ community\
    \ risk\n      (N) Probability that a particular vulnerability will be exploited\n\
    \      within an interacting population and adversely affect some members\n  \
    \    of that population. [C4009] (See: Morris worm, risk.)\n   $ community string\n\
    \      (I) A community name in the form of an octet string that serves as\n  \
    \    a cleartext password in SNMP version 1 (RFC 1157) and version 2\n      (RFC\
    \ 1901). (See: password, Simple Network Management Protocol.)\n      Tutorial:\
    \ The SNMPv1 and SNMPv2 protocols have been declared\n      \"historic\" and have\
    \ been replaced by the more secure SNMPv3\n      standard (RFCs 3410-3418), which\
    \ does not use cleartext passwords.\n   $ compartment\n      1. (I) A grouping\
    \ of sensitive information items that require\n      special access controls beyond\
    \ those normally provided for the\n      basic classification level of the information.\
    \ (See: compartmented\n      security mode. Compare: category, classification.)\n\
    \      Usage: The term is usually understood to include the special\n      handling\
    \ procedures to be used for the information.\n      2. (I) Synonym for \"category\"\
    .\n      Deprecated Usage: This Glossary defines \"category\" with a slightly\n\
    \      narrower meaning than \"compartment\". That is, a security label is\n \
    \     assigned to a category because the data owner needs to handle the\n    \
    \  data as a compartment. However, a compartment could receive\n      special\
    \ protection in a system without being assigned a category\n      label.\n   $\
    \ compartmented security mode\n      (N) A mode of system operation wherein all\
    \ users having access to\n      the system have the necessary security clearance\
    \ for the single,\n      hierarchical classification level of all data handled\
    \ by the\n      system, but some users do not have the clearance for a non-\n\
    \      hierarchical category of some data handled by the system. (See:\n     \
    \ category, /system operation/ under \"mode\", protection level,\n      security\
    \ clearance.)\n      Usage: Usually abbreviated as \"compartmented mode\". This\
    \ term was\n      defined in U.S. Government policy on system accreditation. In\
    \ this\n      mode, a system may handle (a) a single hierarchical classification\n\
    \      level and (b) multiple non-hierarchical categories within that\n      level.\n\
    \   $ Compartments field\n      (I) A 16-bit field (the \"C field\") that specifies\
    \ compartment\n      values in the security option (option type 130) of version\
    \ 4 IP's\n      datagram header format. The valid field values are assigned by\
    \ the\n      U.S. Government, as specified in RFC 791.\n      Deprecated Abbreviation:\
    \ IDOCs SHOULD NOT use the abbreviation \"C\n      field\"; the abbreviation is\
    \ potentially ambiguous. Instead, use\n      \"Compartments field\".\n   $ component\n\
    \      See: system component.\n   $ compression\n      (I) A process that encodes\
    \ information in a way that minimizes the\n      number of resulting code symbols\
    \ and thus reduces storage space or\n      transmission time.\n      Tutorial:\
    \ A data compression algorithm may be \"lossless\", i.e.,\n      retain all information\
    \ that was encoded in the data, so that\n      decompression can recover all the\
    \ information; or an algorithm may\n      be \"lossy\". Text usually needs to\
    \ be compressed losslessly, but\n      images are often compressed with lossy\
    \ schemes.\n      Not all schemes that encode information losslessly for machine\n\
    \      processing are efficient in terms of minimizing the number of\n      output\
    \ bits. For example, ASCII encoding is lossless, but ASCII\n      data can often\
    \ be losslessly reencoded in fewer bits with other\n      schemes. These more\
    \ efficient schemes take advantage of some sort\n      of inherent imbalance,\
    \ redundancy, or repetition in the data, such\n      as by replacing a character\
    \ string in which all characters are the\n      same by a shorter string consisting\
    \ of only the single character\n      and a character count.\n      Lossless compression\
    \ schemes cannot effectively reduce the number\n      of bits in cipher text produced\
    \ by a strong encryption algorithm,\n      because the cipher text is essentially\
    \ a pseudorandom bit string\n      that does not contain patterns susceptible\
    \ to reencoding.\n      Therefore, protocols that offer both encryption and compression\n\
    \      services (e.g., SSL) need to perform the compression operation\n      before\
    \ the encryption operation.\n   $ compromise\n      See: data compromise, security\
    \ compromise.\n   $ compromise recovery\n      (I) The process of regaining a\
    \ secure state for a system after\n      detecting that the system has experienced\
    \ a security compromise.\n   $ compromised key list (CKL)\n      (N) /MISSI/ A\
    \ list that identifies keys for which unauthorized\n      disclosure or alteration\
    \ may have occurred. (See: compromise.)\n      Tutorial: A CKL is issued by a\
    \ CA, like a CRL is issued. But a CKL\n      lists only KMIDs, not subjects that\
    \ hold the keys, and not\n      certificates in which the keys are bound.\n  \
    \ $ COMPUSEC\n      (I) See: computer security.\n   $ computer emergency response\
    \ team (CERT)\n      (I) An organization that studies computer and network INFOSEC\
    \ in\n      order to provide incident response services to victims of attacks,\n\
    \      publish alerts concerning vulnerabilities and threats, and offer\n    \
    \  other information to help improve computer and network security.\n      (See:\
    \ CSIRT, security incident.)\n      Examples: CERT Coordination Center at Carnegie\
    \ Mellon University\n      (sometimes called \"the\" CERT); CIAC.\n   $ Computer\
    \ Incident Advisory Capability (CIAC)\n      (O) The centralized CSIRT of the\
    \ U.S. Department of Energy; a\n      member of FIRST.\n   $ computer network\n\
    \      (I) A collection of host computers together with the subnetwork or\n  \
    \    internetwork through which they can exchange data.\n      Usage: This definition\
    \ is intended to cover systems of all sizes\n      and types, ranging from the\
    \ complex Internet to a simple system\n      composed of a personal computer dialing\
    \ in as a remote terminal of\n      another computer.\n   $ computer platform\n\
    \      (I) A combination of computer hardware and an operating system\n      (which\
    \ may consist of software, firmware, or both) for that\n      hardware. (Compare:\
    \ computer system.)\n   $ computer security (COMPUSEC)\n      1. (I) Measures\
    \ to implement and assure security services in a\n      computer system, particularly\
    \ those that assure access control\n      service.\n      Usage: Usually refers\
    \ to internal controls (functions, features,\n      and technical characteristics)\
    \ that are implemented in software\n      (especially in operating systems); sometimes\
    \ refers to internal\n      controls implemented in hardware; rarely used to refer\
    \ to external\n      controls.\n      2. (O) \"The protection afforded to an automated\
    \ information system\n      in order to attain the applicable objectives of preserving\
    \ the\n      integrity, availability and confidentiality of information system\n\
    \      resources (includes hardware, software, firmware,\n      information/data,\
    \ and telecommunications).\" [SP12]\n   $ computer security incident response\
    \ team (CSIRT)\n      (I) An organization \"that coordinates and supports the\
    \ response to\n      security incidents that involve sites within a defined\n\
    \      constituency.\" [R2350] (See: CERT, FIRST, security incident.)\n      Tutorial:\
    \ To be considered a CSIRT, an organization must do as\n      follows: (a) Provide\
    \ a (secure) channel for receiving reports\n      about suspected security incidents.\
    \ (b) Provide assistance to\n      members of its constituency in handling the\
    \ incidents. (c)\n      Disseminate incident-related information to its constituency\
    \ and\n      other involved parties.\n   $ computer security object\n      (I)\
    \ The definition or representation of a resource, tool, or\n      mechanism used\
    \ to maintain a condition of security in computerized\n      environments. Includes\
    \ many items referred to in standards that\n      are either selected or defined\
    \ by separate user communities.\n      [CSOR] (See: object identifier, Computer\
    \ Security Objects\n      Register.)\n   $ Computer Security Objects Register\
    \ (CSOR)\n      (N) A service operated by NIST is establishing a catalog for\n\
    \      computer security objects to provide stable object definitions\n      identified\
    \ by unique names. The use of this register will enable\n      the unambiguous\
    \ specification of security parameters and\n      algorithms to be used in secure\
    \ data exchanges. (See: object\n      identifier.)\n      Tutorial: The CSOR follows\
    \ registration guidelines established by\n      the international standards community\
    \ and ANSI. Those guidelines\n      establish minimum responsibilities for registration\
    \ authorities\n      and assign the top branches of an international registration\n\
    \      hierarchy. Under that international registration hierarchy, the\n     \
    \ CSOR is responsible for the allocation of unique identifiers under\n      the\
    \ branch: {joint-iso-ccitt(2) country(16) us(840)\n      organization(1) gov(101)\
    \ csor(3)}.\n   $ computer system\n      (I) Synonym for \"information system\"\
    , or a component thereof.\n      (Compare: computer platform.)\n   $ Computers\
    \ At Risk\n      (O) The 1991 report [NRC91] of the System Security Study\n  \
    \    Committee, sponsored by the U.S. National Academy of Sciences and\n     \
    \ supported by the Defense Advanced Research Projects Agency of the\n      U.S.\
    \ DoD. It made many recommendations for industry and\n      governments to improve\
    \ computer security and trustworthiness. Some\n      of the most important recommendations\
    \ (e.g., establishing an\n      Information Security Foundation chartered by the\
    \ U.S. Government)\n      have not been implemented at all, and others (e.g.,\
    \ codifying\n      Generally Accepted System Security Principles similar to\n\
    \      accounting principles) have been implemented but not widely\n      adopted\
    \ [SP14, SP27].\n   $ COMSEC\n      (I) See: communication security.\n   $ COMSEC\
    \ account\n      (O) /U.S. Government/ \"Administrative entity, identified by\
    \ an\n      account number, used to maintain accountability, custody, and\n  \
    \    control of COMSEC material.\" [C4009] (See: COMSEC custodian.)\n   $ COMSEC\
    \ accounting\n      (O) /U.S. Government/ The process of creating, collecting,\
    \ and\n      maintaining data records that describe the status and custody of\n\
    \      designated items of COMSEC material. (See: accounting legend\n      code.)\n\
    \      Tutorial: Almost any secure information system needs to record a\n    \
    \  security audit trail, but a system that manages COMSEC material\n      needs\
    \ to record additional data about the status and custody of\n      COMSEC items.\n\
    \      -  COMSEC tracking: The process of automatically collecting,\n        \
    \ recording, and managing information that describes the status\n         of designated\
    \ items of COMSEC material at all times during each\n         product's lifecycle.\n\
    \      -  COMSEC controlling: The process of supplementing tracking data\n   \
    \      with custody data, which consists of explicit acknowledgements\n      \
    \   of system entities that they (a) have received specific COMSEC\n         items\
    \ and (b) are responsible for preventing exposure of those\n         items.\n\
    \      For example, a key management system that serves a large customer\n   \
    \   base needs to record tracking data for the same reasons that a\n      national\
    \ parcel delivery system does, i.e., to answer the question\n      \"Where is\
    \ that thing now?\". If keys are encrypted immediately upon\n      generation\
    \ and handled only in BLACK form between the point of\n      generation and the\
    \ point of use, then tracking may be all that is\n      needed. However, in cases\
    \ where keys are handled at least partly\n      in RED form and are potentially\
    \ subject to exposure, then tracking\n      needs to be supplemented by controlling.\n\
    \      Data that is used purely for tracking need be retained only\n      temporarily,\
    \ until an item's status changes. Data that is used for\n      controlling is\
    \ retained indefinitely to ensure accountability and\n      support compromise\
    \ recovery.\n   $ COMSEC boundary\n      (N) \"Definable perimeter encompassing\
    \ all hardware, firmware, and\n      software components performing critical COMSEC\
    \ functions, such as\n      key generation and key handling and storage.\" [C4009]\
    \ (Compare:\n      cryptographic boundary.)\n   $ COMSEC custodian\n      (O)\
    \ /U.S. Government/ \"Individual designated by proper authority\n      to be responsible\
    \ for the receipt, transfer, accounting,\n      safeguarding, and destruction\
    \ of COMSEC material assigned to a\n      COMSEC account.\" [C4009]\n   $ COMSEC\
    \ material\n      (N) /U.S. Government/ Items designed to secure or authenticate\n\
    \      communications or information in general; these items include (but\n  \
    \    are not limited to) keys; equipment, devices, documents, firmware,\n    \
    \  and software that embodies or describes cryptographic logic; and\n      other\
    \ items that perform COMSEC functions. [C4009] (Compare:\n      keying material.)\n\
    \   $ COMSEC Material Control System (CMCS)\n      (O) /U.S. Government/ \"Logistics\
    \ and accounting system through\n      which COMSEC material marked 'CRYPTO' is\
    \ distributed, controlled,\n      and safeguarded.\" [C4009] (See: COMSEC account,\
    \ COMSEC custodian.)\n   $ confidentiality\n      See: data confidentiality.\n\
    \   $ concealment system\n      (O) \"A method of achieving confidentiality in\
    \ which sensitive\n      information is hidden by embedding it in irrelevant data.\"\
    \ [NCS04]\n      (Compare: steganography.)\n   $ configuration control\n     \
    \ (I) The process of regulating changes to hardware, firmware,\n      software,\
    \ and documentation throughout the development and\n      operational life of\
    \ a system. (See: administrative security,\n      harden, trusted distribution.)\n\
    \      Tutorial: Configuration control helps protect against unauthorized\n  \
    \    or malicious alteration of a system and thus provides assurance of\n    \
    \  system integrity. (See: malicious logic.)\n   $ confinement property\n    \
    \  (N) /formal model/ Property of a system whereby a subject has\n      write\
    \ access to an object only if the classification of the object\n      dominates\
    \ the clearance of the subject. (See: *-property, Bell-\n      LaPadula model.)\n\
    \   $ constraint\n      (I) /access control/ A limitation on the function of an\
    \ identity,\n      role, or privilege. (See: rule-based access control.)\n   \
    \   Tutorial: In effect, a constraint is a form of security policy and\n     \
    \ may be either static or dynamic:\n      -  \"Static constraint\": A constraint\
    \ that must be satisfied at the\n         time the policy is defined, and then\
    \ continues to be satisfied\n         until the constraint is removed.\n     \
    \ -  \"Dynamic constraint\": A constraint that may be defined to apply\n     \
    \    at various times that the identity, role, or other object of\n         the\
    \ constraint is active in the system.\n   $ content filter\n      (I) /World Wide\
    \ Web/ Application software used to prevent access\n      to certain Web servers,\
    \ such as by parents who do not want their\n      children to access pornography.\
    \ (See: filter, guard.)\n      Tutorial: The filter is usually browser-based,\
    \ but could be part\n      of an intermediate cache server. The two basic content\
    \ filtering\n      techniques are (a) to block a specified list of URLs and (b)\
    \ to\n      block material that contains specified words and phrases.\n   $ contingency\
    \ plan\n      (I) A plan for emergency response, backup operations, and post-\n\
    \      disaster recovery in a system as part of a security program to\n      ensure\
    \ availability of critical system resources and facilitate\n      continuity of\
    \ operations in a crisis. [NCS04] (See: availability.)\n   $ control zone\n  \
    \    (O) \"The space, expressed in feet of radius, surrounding equipment\n   \
    \   processing sensitive information, that is under sufficient\n      physical\
    \ and technical control to preclude an unauthorized entry\n      or compromise.\"\
    \ [NCSSG] (Compare: inspectable space, TEMPEST\n      zone.)\n   $ controlled\
    \ access protection\n      (O) /TCSEC/ The level of evaluation criteria for a\
    \ C2 computer\n      system.\n      Tutorial: The major features of the C2 level\
    \ are individual\n      accountability, audit, access control, and object reuse.\n\
    \   $ controlled cryptographic item (CCI)\n      (O) /U.S. Government/ \"Secure\
    \ telecommunications or information\n      handling equipment, or associated cryptographic\
    \ component, that is\n      unclassified but governed by a special set of control\n\
    \      requirements.\" [C4009] (Compare: EUCI.)\n      Tutorial: This category\
    \ of equipment was established in 1985 to\n      promote broad use of secure equipment\
    \ for protecting both\n      classified and unclassified information in the national\
    \ interest.\n      CCI equipment uses a classified cryptographic logic, but the\n\
    \      hardware or firmware embodiment of that logic is unclassified.\n      Drawings,\
    \ software implementations, and other descriptions of that\n      logic remain\
    \ classified. [N4001]\n   $ controlled interface\n      (I) A mechanism that facilitates\
    \ the adjudication of the different\n      security policies of interconnected\
    \ systems. (See: domain, guard.)\n   $ controlled security mode\n      (D) /U.S.\
    \ DoD/ A mode of system operation wherein (a) two or more\n      security levels\
    \ of information are allowed to be handled\n      concurrently within the same\
    \ system when some users having access\n      to the system have neither a security\
    \ clearance nor need-to-know\n      for some of the data handled by the system,\
    \ but (b) separation of\n      the users and the classified material on the basis,\
    \ respectively,\n      of clearance and classification level are not dependent\
    \ only on\n      operating system control (like they are in multilevel security\n\
    \      mode). (See: /system operation/ under \"mode\", protection level.)\n  \
    \    Deprecated Term: IDOCs SHOULD NOT use this term. It was defined in\n    \
    \  a U.S. Government policy regarding system accreditation and was\n      subsumed\
    \ by \"partitioned security mode\" in a later policy. Both\n      terms were dropped\
    \ in still later policies.\n      Tutorial: Controlled mode was intended to encourage\
    \ ingenuity in\n      meeting data confidentiality requirements in ways less restrictive\n\
    \      than \"dedicated security mode\" and \"system-high security mode\",\n \
    \     but at a level of risk lower than that generally associated with\n     \
    \ true \"multilevel security mode\". This was intended to be\n      accomplished\
    \ by implementation of explicit augmenting measures to\n      reduce or remove\
    \ a substantial measure of system software\n      vulnerability together with\
    \ specific limitation of the security\n      clearance levels of users having\
    \ concurrent access to the system.\n   $ controlling authority\n      (O) /U.S.\
    \ Government/ \"Official responsible for directing the\n      operation of a cryptonet\
    \ and for managing the operational use and\n      control of keying material assigned\
    \ to the cryptonet.\" [C4009,\n      N4006]\n   $ cookie\n      1. (I) /HTTP/\
    \ Data exchanged between an HTTP server and a browser\n      (a client of the\
    \ server) to store state information on the client\n      side and retrieve it\
    \ later for server use.\n      Tutorial: An HTTP server, when sending data to\
    \ a client, may send\n      along a cookie, which the client retains after the\
    \ HTTP connection\n      closes. A server can use this mechanism to maintain persistent\n\
    \      client-side state information for HTTP-based applications,\n      retrieving\
    \ the state information in later connections. A cookie\n      may include a description\
    \ of the range of URLs for which the state\n      is valid. Future requests made\
    \ by the client in that range will\n      also send the current value of the cookie\
    \ to the server. Cookies\n      can be used to generate profiles of web usage\
    \ habits, and thus may\n      infringe on personal privacy.\n      2. (I) /IPsec/\
    \ Data objects exchanged by ISAKMP to prevent certain\n      denial-of-service\
    \ attacks during the establishment of a security\n      association.\n      3.\
    \ (D) /access control/ Synonym for \"capability token\" or\n      \"ticket\".\n\
    \      Deprecated Definition: IDOCs SHOULD NOT use this term with\n      definition\
    \ 3; that would duplicate the meaning of better-\n      established terms and\
    \ mix concepts in a potentially misleading\n      way.\n   $ Coordinated Universal\
    \ Time (UTC)\n      (N) UTC is derived from International Atomic Time (TAI) by\
    \ adding\n      a number of leap seconds. The International Bureau of Weights\
    \ and\n      Measures computes TAI once each month by averaging data from many\n\
    \      laboratories. (See: GeneralizedTime, UTCTime.)\n   $ correction\n     \
    \ (I) /security/ A system change made to eliminate or reduce the\n      risk of\
    \ reoccurrence of a security violation or threat\n      consequence. (See: secondary\
    \ definition under \"security\".)\n   $ correctness\n      (I) \"The property\
    \ of a system that is guaranteed as the result of\n      formal verification activities.\"\
    \ [Huff] (See: correctness proof,\n      verification.)\n   $ correctness integrity\n\
    \      (I) The property that the information represented by data is\n      accurate\
    \ and consistent. (Compare: data integrity, source\n      integrity.)\n      Tutorial:\
    \ IDOCs SHOULD NOT use this term without providing a\n      definition; the term\
    \ is neither well-known nor precisely defined.\n      Data integrity refers to\
    \ the constancy of data values, and source\n      integrity refers to confidence\
    \ in data values. However,\n      correctness integrity refers to confidence in\
    \ the underlying\n      information that data values represent, and this property\
    \ is\n      closely related to issues of accountability and error handling.\n\
    \   $ correctness proof\n      (I) A mathematical proof of consistency between\
    \ a specification\n      for system security and the implementation of that specification.\n\
    \      (See: correctness, formal specification.)\n   $ corruption\n      (I) A\
    \ type of threat action that undesirably alters system\n      operation by adversely\
    \ modifying system functions or data. (See:\n      disruption.)\n      Usage:\
    \ This type of threat action includes the following subtypes:\n      -  \"Tampering\"\
    : /corruption/ Deliberately altering a system's\n         logic, data, or control\
    \ information to interrupt or prevent\n         correct operation of system functions.\
    \ (See: misuse, main entry\n         for \"tampering\".)\n      -  \"Malicious\
    \ logic\": /corruption/ Any hardware, firmware, or\n         software (e.g., a\
    \ computer virus) intentionally introduced into\n         a system to modify system\
    \ functions or data. (See:\n         incapacitation, main entry for \"malicious\
    \ logic\", masquerade,\n         misuse.)\n      -  \"Human error\": /corruption/\
    \ Human action or inaction that\n         unintentionally results in the alteration\
    \ of system functions\n         or data.\n      -  \"Hardware or software error\"\
    : /corruption/ Error that results\n         in the alteration of system functions\
    \ or data.\n      -  \"Natural disaster\": /corruption/ Any \"act of God\" (e.g.,\
    \ power\n         surge caused by lightning) that alters system functions or\n\
    \         data. [FP031 Section 2]\n   $ counter\n      1. (N) /noun/ See: counter\
    \ mode.\n      2. (I) /verb/ See: countermeasure.\n   $ counter-countermeasure\n\
    \      (I) An action, device, procedure, or technique used by an attacker\n  \
    \    to offset a defensive countermeasure.\n      Tutorial: For every countermeasure\
    \ devised to protect computers\n      and networks, some cracker probably will\
    \ be able to devise a\n      counter-countermeasure. Thus, systems must use \"\
    defense in depth\".\n   $ counter mode (CTR)\n      (N) A block cipher mode that\
    \ enhances ECB mode by ensuring that\n      each encrypted block is different\
    \ from every other block encrypted\n      under the same key. [SP38A] (See: block\
    \ cipher.)\n      Tutorial: This mode operates by first encrypting a generated\n\
    \      sequence of blocks, called \"counters\", that are separate from the\n \
    \     input sequence of plaintext blocks which the mode is intended to\n     \
    \ protect. The resulting sequence of encrypted counters is\n      exclusive-ORed\
    \ with the sequence of plaintext blocks to produce\n      the final ciphertext\
    \ output blocks. The sequence of counters must\n      have the property that each\
    \ counter is different from every other\n      counter for all of the plain text\
    \ that is encrypted under the same\n      key.\n   $ Counter with Cipher Block\
    \ Chaining-Message Authentication Code\n      (CCM)\n      (N) A block cipher\
    \ mode [SP38C] that provides both data\n      confidentiality and data origin\
    \ authentication, by combining the\n      techniques of CTR and a CBC-based message\
    \ authentication code.\n      (See: block cipher.)\n   $ countermeasure\n    \
    \  (I) An action, device, procedure, or technique that meets or\n      opposes\
    \ (i.e., counters) a threat, a vulnerability, or an attack\n      by eliminating\
    \ or preventing it, by minimizing the harm it can\n      cause, or by discovering\
    \ and reporting it so that corrective\n      action can be taken.\n      Tutorial:\
    \ In an Internet protocol, a countermeasure may take the\n      form of a protocol\
    \ feature, a component function, or a usage\n      constraint.\n   $ country code\n\
    \      (I) An identifier that is defined for a nation by ISO. [I3166]\n      Tutorial:\
    \ For each nation, ISO Standard 3166 defines a unique two-\n      character alphabetic\
    \ code, a unique three-character alphabetic\n      code, and a three-digit code.\
    \ Among many uses of these codes, the\n      two-character codes are used as top-level\
    \ domain names.\n   $ Courtney's laws\n      (N) Principles for managing system\
    \ security that were stated by\n      Robert H. Courtney, Jr.\n      Tutorial:\
    \ Bill Murray codified Courtney's laws as follows: [Murr]\n      -  Courtney's\
    \ first law: You cannot say anything interesting\n         (i.e., significant)\
    \ about the security of a system except in\n         the context of a particular\
    \ application and environment.\n      -  Courtney's second law: Never spend more\
    \ money eliminating a\n         security exposure than tolerating it will cost\
    \ you. (See:\n         acceptable risk, risk analysis.)\n         -- First corollary:\
    \ Perfect security has infinite cost.\n         -- Second corollary: There is\
    \ no such thing as zero risk.\n      -  Courtney's third law: There are no technical\
    \ solutions to\n         management problems, but there are management solutions\
    \ to\n         technical problems.\n   $ covert action\n      (I) An operation\
    \ that is planned and executed in a way that\n      conceals the identity of the\
    \ operator.\n   $ covert channel\n      1. (I) An unintended or unauthorized intra-system\
    \ channel that\n      enables two cooperating entities to transfer information\
    \ in a way\n      that violates the system's security policy but does not exceed\
    \ the\n      entities' access authorizations. (See: covert storage channel,\n\
    \      covert timing channel, out-of-band, tunnel.)\n      2. (O) \"A communications\
    \ channel that allows two cooperating\n      processes to transfer information\
    \ in a manner that violates the\n      system's security policy.\" [NCS04]\n \
    \     Tutorial: The cooperating entities can be either two insiders or\n     \
    \ an insider and an outsider. Of course, an outsider has no access\n      authorization\
    \ at all. A covert channel is a system feature that\n      the system architects\
    \ neither designed nor intended for\n      information transfer.\n   $ covert\
    \ storage channel\n      (I) A system feature that enables one system entity to\
    \ signal\n      information to another entity by directly or indirectly writing\
    \ a\n      storage location that is later directly or indirectly read by the\n\
    \      second entity. (See: covert channel.)\n   $ covert timing channel\n   \
    \   (I) A system feature that enables one system entity to signal\n      information\
    \ to another by modulating its own use of a system\n      resource in such a way\
    \ as to affect system response time observed\n      by the second entity. (See:\
    \ covert channel.)\n   $ CPS\n      (I) See: certification practice statement.\n\
    \   $ cracker\n      (I) Someone who tries to break the security of, and gain\n\
    \      unauthorized access to, someone else's system, often with\n      malicious\
    \ intent. (See: adversary, intruder, packet monkey, script\n      kiddy. Compare:\
    \ hacker.)\n      Usage: Was sometimes spelled \"kracker\". [NCSSG]\n   $ CRAM\n\
    \      (I) See: Challenge-Response Authentication Mechanism.\n   $ CRC\n     \
    \ (I) See: cyclic redundancy check.\n   $ credential\n      1. (I) /authentication/\
    \ \"identifier credential\": A data object\n      that is a portable representation\
    \ of the association between an\n      identifier and a unit of authentication\
    \ information, and that can\n      be presented for use in verifying an identity\
    \ claimed by an entity\n      that attempts to access a system. Example: X.509\
    \ public-key\n      certificate. (See: anonymous credential.)\n      2. (I) /access\
    \ control/ \"authorization credential\": A data object\n      that is a portable\
    \ representation of the association between an\n      identifier and one or more\
    \ access authorizations, and that can be\n      presented for use in verifying\
    \ those authorizations for an entity\n      that attempts such access. Example:\
    \ X.509 attribute certificate.\n      (See: capability token, ticket.)\n     \
    \ 3. (D) /OSIRM/ \"Data that is transferred to establish the claimed\n      identity\
    \ of an entity.\" [I7498-2]\n      Deprecated Definition: IDOCs SHOULD NOT use\
    \ the term with\n      definition 3. As explained in the tutorial below, an\n\
    \      authentication process can involve the transfer of multiple data\n    \
    \  objects, and not all of those are credentials.\n      4. (D) /U.S. Government/\
    \ \"An object that is verified when\n      presented to the verifier in an authentication\
    \ transaction.\"\n      [M0404]\n      Deprecated Definition: IDOCs SHOULD NOT\
    \ use the term with\n      definition 4; it mixes concepts in a potentially misleading\
    \ way.\n      For example, in an authentication process, it is the identity that\n\
    \      is \"verified\", not the credential; the credential is \"validated\".\n\
    \      (See: validate vs. verify.)\n      Tutorial: In general English, \"credentials\"\
    \ are evidence or\n      testimonials that (a) support a claim of identity or\
    \ authorization\n      and (b) usually are intended to be used more than once\
    \ (i.e., a\n      credential's life is long compared to the time needed for one\n\
    \      use). Some examples are a policeman's badge, an automobile\n      driver's\
    \ license, and a national passport. An authentication or\n      access control\
    \ process that uses a badge, license, or passport is\n      outwardly simple:\
    \ the holder just shows the thing.\n      The problem with adopting this term\
    \ in Internet security is that\n      an automated process for authentication\
    \ or access control usually\n      requires multiple steps using multiple data\
    \ objects, and it might\n      not be immediately obvious which of those objects\
    \ should get the\n      name \"credential\".\n      For example, if the verification\
    \ step in a user authentication\n      process employs public-key technology,\
    \ then the process involves\n      at least three data items: (a) the user's private\
    \ key, (b) a\n      signed value -- signed with that private key and passed to\
    \ the\n      system, perhaps in response to a challenge from the system -- and\n\
    \      (c) the user's public-key certificate, which is validated by the\n    \
    \  system and provides the public key needed to verify the signature.\n      -\
    \  Private key: The private key is *not* a credential, because it\n         is\
    \ never transferred or presented. Instead, the private key is\n         \"authentication\
    \ information\", which is associated with the\n         user's identifier for\
    \ a specified period of time and can be\n         used in multiple authentications\
    \ during that time.\n      -  Signed value: The signed value is *not* a credential;\
    \ the\n         signed value is only ephemeral, not long lasting. The OSIRM\n\
    \         definition could be interpreted to call the signed value a\n       \
    \  credential, but that would conflict with general English.\n      -  Certificate:\
    \ The user's certificate *is* a credential. It can\n         be \"transferred\"\
    \ or \"presented\" to any person or process that\n         needs it at any time.\
    \ A public-key certificate may be used as\n         an \"identity credential\"\
    , and an attribute certificate may be\n         used as an \"authorization credential\"\
    .\n   $ critical\n      1. (I) /system resource/ A condition of a system resource\
    \ such\n      that denial of access to, or lack of availability of, that\n   \
    \   resource would jeopardize a system user's ability to perform a\n      primary\
    \ function or would result in other serious consequences,\n      such as human\
    \ injury or loss of life. (See: availability,\n      precedence. Compare: sensitive.)\n\
    \      2. (N) /extension/ An indication that an application is not\n      permitted\
    \ to ignore an extension. [X509]\n      Tutorial: Each extension of an X.509 certificate\
    \ or CRL is flagged\n      as either \"critical\" or \"non-critical\". In a certificate,\
    \ if a\n      computer program does not recognize an extension's type (i.e.,\n\
    \      does not implement its semantics), then if the extension is\n      critical,\
    \ the program is required to treat the certificate as\n      invalid; but if the\
    \ extension is non-critical, the program is\n      permitted to ignore the extension.\n\
    \      In a CRL, if a program does not recognize a critical extension\n      that\
    \ is associated with a specific certificate, the program is\n      required to\
    \ assume that the listed certificate has been revoked\n      and is no longer\
    \ valid, and then take whatever action is required\n      by local policy.\n \
    \     When a program does not recognize a critical extension that is\n      associated\
    \ with the CRL as a whole, the program is required to\n      assume that all listed\
    \ certificates have been revoked and are no\n      longer valid. However, since\
    \ failing to process the extension may\n      mean that the list has not been\
    \ completed, the program cannot\n      assume that other certificates are valid,\
    \ and the program needs to\n      take whatever action is therefore required by\
    \ local policy.\n   $ critical information infrastructure\n      (I) Those systems\
    \ that are so vital to a nation that their\n      incapacity or destruction would\
    \ have a debilitating effect on\n      national security, the economy, or public\
    \ health and safety.\n   $ CRL\n      (I) See: certificate revocation list.\n\
    \   $ CRL distribution point\n      (I) See: distribution point.\n   $ CRL extension\n\
    \      (I) See: extension.\n   $ cross-certificate\n      (I) A public-key certificate\
    \ issued by a CA in one PKI to a CA in\n      another PKI. (See: cross-certification.)\n\
    \   $ cross-certification\n      (I) The act or process by which a CA in one PKI\
    \ issues a public-\n      key certificate to a CA in another PKI. [X509] (See:\
    \ bridge CA.)\n      Tutorial: X.509 says that a CA (say, CA1) may issue a \"\
    cross-\n      certificate\" in which the subject is another CA (say, CA2). X.509\n\
    \      calls CA2 the \"subject CA\" and calls CA1 an \"intermediate CA\", but\n\
    \      this Glossary deprecates those terms. (See: intermediate CA,\n      subject\
    \ CA).\n      Cross-certification of CA2 by CA1 appears similar to certification\n\
    \      of a subordinate CA by a superior CA, but cross-certification\n      involves\
    \ a different concept. The \"subordinate CA\" concept applies\n      when both\
    \ CAs are in the same PKI, i.e., when either (a) CA1 and\n      CA2 are under\
    \ the same root or (b) CA1 is itself a root. The\n      \"cross-certification\"\
    \ concept applies in other cases:\n      First, cross-certification applies when\
    \ two CAs are in different\n      PKIs, i.e., when CA1 and CA2 are under different\
    \ roots, or perhaps\n      are both roots themselves. Issuing the cross-certificate\
    \ enables\n      end entities certified under CA1 in PK1 to construct the\n  \
    \    certification paths needed to validate the certificates of end\n      entities\
    \ certified under CA2 in PKI2. Sometimes, a pair of cross-\n      certificates\
    \ is issued -- by CA1 to CA2, and by CA2 to CA1 -- so\n      that an end entity\
    \ in either PKI can validate certificates issued\n      in the other PKI.\n  \
    \    Second, X.509 says that two CAs in some complex, multi-CA PKI can\n     \
    \ cross-certify one another to shorten the certification paths\n      constructed\
    \ by end entities. Whether or not a CA may perform this\n      or any other form\
    \ of cross-certification, and how such\n      certificates may be used by end\
    \ entities, should be addressed by\n      the local certificate policy and CPS.\n\
    \   $ cross-domain solution\n      1. (D) Synonym for \"guard\".\n      Deprecated\
    \ Term: IDOCs SHOULD NOT use this term as a synonym for\n      \"guard\"; this\
    \ term unnecessarily (and verbosely) duplicates the\n      meaning of the long-established\
    \ \"guard\".\n      2. (O) /U.S. Government/ A process or subsystem that provides\
    \ a\n      capability (which could be either manual or automated) to access\n\
    \      two or more differing security domains in a system, or to transfer\n  \
    \    information between such domains. (See: domain, guard.)\n   $ cryptanalysis\n\
    \      1. (I) The mathematical science that deals with analysis of a\n      cryptographic\
    \ system to gain knowledge needed to break or\n      circumvent the protection\
    \ that the system is designed to provide.\n      (See: cryptology, secondary definition\
    \ under \"intrusion\".)\n      2. (O) \"The analysis of a cryptographic system\
    \ and/or its inputs\n      and outputs to derive confidential variables and/or\
    \ sensitive data\n      including cleartext.\" [I7498-2]\n      Tutorial: Definition\
    \ 2 states the traditional goal of\n      cryptanalysis, i.e., convert cipher\
    \ text to plain text (which\n      usually is clear text) without knowing the\
    \ key; but that\n      definition applies only to encryption systems. Today, the\
    \ term is\n      used with reference to all kinds of cryptographic algorithms\
    \ and\n      key management, and definition 1 reflects that. In all cases,\n \
    \     however, a cryptanalyst tries to uncover or reproduce someone\n      else's\
    \ sensitive data, such as clear text, a key, or an algorithm.\n      The basic\
    \ cryptanalytic attacks on encryption systems are\n      ciphertext-only, known-plaintext,\
    \ chosen-plaintext, and chosen-\n      ciphertext; and these generalize to the\
    \ other kinds of\n      cryptography.\n   $ crypto, CRYPTO\n      1. (N) A prefix\
    \ (\"crypto-\") that means \"cryptographic\".\n      Usage: IDOCs MAY use this\
    \ prefix when it is part of a term listed\n      in this Glossary. Otherwise,\
    \ IDOCs SHOULD NOT use this prefix;\n      instead, use the unabbreviated adjective,\
    \ \"cryptographic\".\n      2. (D) In lower case, \"crypto\" is an abbreviation\
    \ for the\n      adjective \"cryptographic\", or for the nouns \"cryptography\"\
    \ or\n      \"cryptographic component\".\n      Deprecated Abbreviation: IDOCs\
    \ SHOULD NOT use this abbreviation\n      because it could easily be misunderstood\
    \ in some technical sense.\n      3. (O) /U.S. Government/ In upper case, \"CRYPTO\"\
    \ is a marking or\n      designator that identifies \"COMSEC keying material used\
    \ to secure\n      or authenticate telecommunications carrying classified or\n\
    \      sensitive U.S. Government or U.S. Government-derived information.\"\n \
    \     [C4009] (See: security label, security marking.)\n   $ cryptographic\n \
    \     (I) An adjective that refers to cryptography.\n   $ cryptographic algorithm\n\
    \      (I) An algorithm that uses the science of cryptography, including\n   \
    \   (a) encryption algorithms, (b) cryptographic hash algorithms, (c)\n      digital\
    \ signature algorithms, and (d) key-agreement algorithms.\n   $ cryptographic\
    \ application programming interface (CAPI)\n      (I) The source code formats\
    \ and procedures through which an\n      application program accesses cryptographic\
    \ services, which are\n      defined abstractly compared to their actual implementation.\n\
    \      Example, see: PKCS #11, [R2628].\n   $ cryptographic association\n    \
    \  (I) A security association that involves the use of cryptography\n      to\
    \ provide security services for data exchanged by the associated\n      entities.\
    \ (See: ISAKMP.)\n   $ cryptographic boundary\n      (I) See: secondary definition\
    \ under \"cryptographic module\".\n   $ cryptographic card\n      (I) A cryptographic\
    \ token in the form of a smart card or a PC\n      card.\n   $ cryptographic component\n\
    \      (I) A generic term for any system component that involves\n      cryptography.\
    \ (See: cryptographic module.)\n   $ cryptographic hash\n      (I) See: secondary\
    \ definition under \"hash function\".\n   $ cryptographic ignition key (CIK)\n\
    \      1. (N) A physical (usually electronic) token used to store,\n      transport,\
    \ and protect cryptographic keys and activation data.\n      (Compare: dongle,\
    \ fill device.)\n      Tutorial: A key-encrypting key could be divided (see: split\
    \ key)\n      between a CIK and a cryptographic module, so that it would be\n\
    \      necessary to combine the two to regenerate the key, use it to\n      decrypt\
    \ other keys and data contained in the module, and thus\n      activate the module.\n\
    \      2. (O) \"Device or electronic key used to unlock the secure mode of\n \
    \     cryptographic equipment.\" [C4009] Usage: Abbreviated as \"crypto-\n   \
    \   ignition key\".\n   $ cryptographic key\n      (I) See: key. Usage: Usually\
    \ shortened to just \"key\".\n   $ Cryptographic Message Syntax (CMS)\n      (I)\
    \ An encapsulation syntax (RFC 3852) for digital signatures,\n      hashes, and\
    \ encryption of arbitrary messages.\n      Tutorial: CMS derives from PKCS #7.\
    \ CMS values are specified with\n      ASN.1 and use BER encoding. The syntax\
    \ permits multiple\n      encapsulation with nesting, permits arbitrary attributes\
    \ to be\n      signed along with message content, and supports a variety of\n\
    \      architectures for digital certificate-based key management.\n   $ cryptographic\
    \ module\n      (I) A set of hardware, software, firmware, or some combination\n\
    \      thereof that implements cryptographic logic or processes,\n      including\
    \ cryptographic algorithms, and is contained within the\n      module's \"cryptographic\
    \ boundary\", which is an explicitly defined\n      contiguous perimeter that\
    \ establishes the physical bounds of the\n      module. [FP140]\n   $ cryptographic\
    \ system\n      1. (I) A set of cryptographic algorithms together with the key\n\
    \      management processes that support use of the algorithms in some\n     \
    \ application context.\n      Usage: IDOCs SHOULD use definition 1 because it\
    \ covers a wider\n      range of algorithms than definition 2.\n      2. (O) \"\
    A collection of transformations from plain text into\n      cipher text and vice\
    \ versa [which would exclude digital signature,\n      cryptographic hash, and\
    \ key-agreement algorithms], the particular\n      transformation(s) to be used\
    \ being selected by keys. The\n      transformations are normally defined by a\
    \ mathematical algorithm.\"\n      [X509]\n   $ cryptographic token\n      1.\
    \ (I) A portable, user-controlled, physical device (e.g., smart\n      card or\
    \ PCMCIA card) used to store cryptographic information and\n      possibly also\
    \ perform cryptographic functions. (See: cryptographic\n      card, token.)\n\
    \      Tutorial: A smart token might implement some set of cryptographic\n   \
    \   algorithms and might incorporate related key management functions,\n     \
    \ such as a random number generator. A smart cryptographic token may\n      contain\
    \ a cryptographic module or may not be explicitly designed\n      that way.\n\
    \   $ cryptography\n      1. (I) The mathematical science that deals with transforming\
    \ data\n      to render its meaning unintelligible (i.e., to hide its semantic\n\
    \      content), prevent its undetected alteration, or prevent its\n      unauthorized\
    \ use. If the transformation is reversible,\n      cryptography also deals with\
    \ restoring encrypted data to\n      intelligible form. (See: cryptology, steganography.)\n\
    \      2. (O) \"The discipline which embodies principles, means, and\n      methods\
    \ for the transformation of data in order to hide its\n      information content,\
    \ prevent its undetected modification and/or\n      prevent its unauthorized use....\
    \ Cryptography determines the\n      methods used in encipherment and decipherment.\"\
    \ [I7498-2]\n      Tutorial: Comprehensive coverage of applied cryptographic\n\
    \      protocols and algorithms is provided by Schneier [Schn].\n      Businesses\
    \ and governments use cryptography to make data\n      incomprehensible to outsiders;\
    \ to make data incomprehensible to\n      both outsiders and insiders, the data\
    \ is sent to lawyers for a\n      rewrite.\n   $ Cryptoki\n      (N) A CAPI defined\
    \ in PKCS #11. Pronunciation: \"CRYPTO-key\".\n      Derivation: Abbreviation\
    \ of \"cryptographic token interface\".\n   $ cryptology\n      (I) The science\
    \ of secret communication, which includes both\n      cryptography and cryptanalysis.\n\
    \      Tutorial: Sometimes the term is used more broadly to denote\n      activity\
    \ that includes both rendering signals secure (see: signal\n      security) and\
    \ extracting information from signals (see: signal\n      intelligence) [Kahn].\n\
    \   $ cryptonet\n      (I) A network (i.e., a communicating set) of system entities\
    \ that\n      share a secret cryptographic key for a symmetric algorithm. (See:\n\
    \      controlling authority.)\n      (O) \"Stations holding a common key.\" [C4009]\n\
    \   $ cryptoperiod\n      (I) The time span during which a particular key value\
    \ is\n      authorized to be used in a cryptographic system. (See: key\n     \
    \ management.)\n      Usage: This term is long-established in COMPUSEC usage.\
    \ In the\n      context of certificates and public keys, \"key lifetime\" and\n\
    \      \"validity period\" are often used instead.\n      Tutorial: A cryptoperiod\
    \ is usually stated in terms of calendar or\n      clock time, but sometimes is\
    \ stated in terms of the maximum amount\n      of data permitted to be processed\
    \ by a cryptographic algorithm\n      using the key. Specifying a cryptoperiod\
    \ involves a tradeoff\n      between the cost of rekeying and the risk of successful\n\
    \      cryptoanalysis.\n   $ cryptosystem\n      (I) Contraction of \"cryptographic\
    \ system\".\n   $ cryptovariable\n      (D) Synonym for \"key\".\n      Deprecated\
    \ Usage: In contemporary COMSEC usage, the term \"key\" has\n      replaced the\
    \ term \"cryptovariable\".\n   $ CSIRT\n      (I) See: computer security incident\
    \ response team.\n   $ CSOR\n      (N) See: Computer Security Objects Register.\n\
    \   $ CTAK\n      (D) See: ciphertext auto-key.\n   $ CTR\n      (N) See: counter\
    \ mode.\n   $ cut-and-paste attack\n      (I) An active attack on the data integrity\
    \ of cipher text,\n      effected by replacing sections of cipher text with other\
    \ cipher\n      text, such that the result appears to decrypt correctly but\n\
    \      actually decrypts to plain text that is forged to the satisfaction\n  \
    \    of the attacker.\n   $ cyclic redundancy check (CRC)\n      (I) A type of\
    \ checksum algorithm that is not a cryptographic hash\n      but is used to implement\
    \ data integrity service where accidental\n      changes to data are expected.\
    \ Sometimes called \"cyclic redundancy\n      code\".\n   $ DAC\n      (N) See:\
    \ Data Authentication Code, discretionary access control.\n      Deprecated Usage:\
    \ IDOCs that use this term SHOULD state a\n      definition for it because this\
    \ abbreviation is ambiguous.\n   $ daemon\n      (I) A computer program that is\
    \ not invoked explicitly but waits\n      until a specified condition occurs,\
    \ and then runs with no\n      associated user (principal), usually for an administrative\n\
    \      purpose. (See: zombie.)\n   $ dangling threat\n      (O) A threat to a\
    \ system for which there is no corresponding\n      vulnerability and, therefore,\
    \ no implied risk.\n   $ dangling vulnerability\n      (O) A vulnerability of\
    \ a system for which there is no\n      corresponding threat and, therefore, no\
    \ implied risk.\n   $ DASS\n      (I) See: Distributed Authentication Security\
    \ Service.\n   $ data\n      (I) Information in a specific representation, usually\
    \ as a\n      sequence of symbols that have meaning.\n      Usage: Refers to both\
    \ (a) representations that can be recognized,\n      processed, or produced by\
    \ a computer or other type of machine, and\n      (b) representations that can\
    \ be handled by a human.\n   $ Data Authentication Algorithm, data authentication\
    \ algorithm\n      1. (N) /capitalized/ The ANSI standard for a keyed hash function\n\
    \      that is equivalent to DES cipher block chaining with IV = 0.\n      [A9009]\n\
    \      2. (D) /not capitalized/ Synonym for some kind of \"checksum\".\n     \
    \ Deprecated Term: IDOCs SHOULD NOT use the uncapitalized form \"data\n      authentication\
    \ algorithm\" as a synonym for any kind of checksum,\n      regardless of whether\
    \ or not the checksum is based on a hash.\n      Instead, use \"checksum\", \"\
    Data Authentication Code\", \"error\n      detection code\", \"hash\", \"keyed\
    \ hash\", \"Message Authentication\n      Code\", \"protected checksum\", or some\
    \ other specific term,\n      depending on what is meant.\n      The uncapitalized\
    \ term can be confused with the Data\n      Authentication Code and also mixes\
    \ concepts in a potentially\n      misleading way. The word \"authentication\"\
    \ is misleading because\n      the checksum may be used to perform a data integrity\
    \ function\n      rather than a data origin authentication function.\n   $ Data\
    \ Authentication Code, data authentication code\n      1. (N) /capitalized/ A\
    \ specific U.S. Government standard [FP113]\n      for a checksum that is computed\
    \ by the Data Authentication\n      Algorithm. Usage: a.k.a. Message Authentication\
    \ Code [A9009].)\n      (See: DAC.)\n      2. (D) /not capitalized/ Synonym for\
    \ some kind of \"checksum\".\n      Deprecated Term: IDOCs SHOULD NOT use the\
    \ uncapitalized form \"data\n      authentication code\" as a synonym for any\
    \ kind of checksum,\n      regardless of whether or not the checksum is based\
    \ on the Data\n      Authentication Algorithm. The uncapitalized term can be confused\n\
    \      with the Data Authentication Code and also mixes concepts in a\n      potentially\
    \ misleading way (see: authentication code).\n   $ data compromise\n      1. (I)\
    \ A security incident in which information is exposed to\n      potential unauthorized\
    \ access, such that unauthorized disclosure,\n      alteration, or use of the\
    \ information might have occurred.\n      (Compare: security compromise, security\
    \ incident.)\n      2. (O) /U.S. DoD/ A \"compromise\" is a \"communication or\
    \ physical\n      transfer of information to an unauthorized recipient.\" [DoD5]\n\
    \      3. (O) /U.S. Government/ \"Type of [security] incident where\n      information\
    \ is disclosed to unauthorized individuals or a\n      violation of the security\
    \ policy of a system in which unauthorized\n      intentional or unintentional\
    \ disclosure, modification,\n      destruction, or loss of an object may have\
    \ occurred.\" [C4009]\n   $ data confidentiality\n      1. (I) The property that\
    \ data is not disclosed to system entities\n      unless they have been authorized\
    \ to know the data. (See: Bell-\n      LaPadula model, classification, data confidentiality\
    \ service,\n      secret. Compare: privacy.)\n      2. (D) \"The property that\
    \ information is not made available or\n      disclosed to unauthorized individuals,\
    \ entities, or processes\n      [i.e., to any unauthorized system entity].\" [I7498-2].\n\
    \      Deprecated Definition: The phrase \"made available\" might be\n      interpreted\
    \ to mean that the data could be altered, and that would\n      confuse this term\
    \ with the concept of \"data integrity\".\n   $ data confidentiality service\n\
    \      (I) A security service that protects data against unauthorized\n      disclosure.\
    \ (See: access control, data confidentiality, datagram\n      confidentiality\
    \ service, flow control, inference control.)\n      Deprecated Usage: IDOCs SHOULD\
    \ NOT use this term as a synonym for\n      \"privacy\", which is a different\
    \ concept.\n   $ Data Encryption Algorithm (DEA)\n      (N) A symmetric block\
    \ cipher, defined in the U.S. Government's\n      DES. DEA uses a 64-bit key,\
    \ of which 56 bits are independently\n      chosen and 8 are parity bits, and\
    \ maps a 64-bit block into another\n      64-bit block. [FP046] (See: AES, symmetric\
    \ cryptography.)\n      Usage: This algorithm is usually referred to as \"DES\"\
    . The\n      algorithm has also been adopted in standards outside the\n      Government\
    \ (e.g., [A3092]).\n   $ data encryption key (DEK)\n      (I) A cryptographic\
    \ key that is used to encipher application data.\n      (Compare: key-encrypting\
    \ key.)\n   $ Data Encryption Standard (DES)\n      (N) A U.S. Government standard\
    \ [FP046] that specifies the DEA and\n      states policy for using the algorithm\
    \ to protect unclassified,\n      sensitive data. (See: AES.)\n   $ data integrity\n\
    \      1. (I) The property that data has not been changed, destroyed, or\n   \
    \   lost in an unauthorized or accidental manner. (See: data integrity\n     \
    \ service. Compare: correctness integrity, source integrity.)\n      2. (O) \"\
    The property that information has not been modified or\n      destroyed in an\
    \ unauthorized manner.\" [I7498-2]\n      Usage: Deals with (a) constancy of and\
    \ confidence in data values,\n      and not with either (b) information that the\
    \ values represent\n      (see: correctness integrity) or (c) the trustworthiness\
    \ of the\n      source of the values (see: source integrity).\n   $ data integrity\
    \ service\n      (I) A security service that protects against unauthorized changes\n\
    \      to data, including both intentional change or destruction and\n      accidental\
    \ change or loss, by ensuring that changes to data are\n      detectable. (See:\
    \ data integrity, checksum, datagram integrity\n      service.)\n      Tutorial:\
    \ A data integrity service can only detect a change and\n      report it to an\
    \ appropriate system entity; changes cannot be\n      prevented unless the system\
    \ is perfect (error-free) and no\n      malicious user has access. However, a\
    \ system that offers data\n      integrity service might also attempt to correct\
    \ and recover from\n      changes.\n      The ability of this service to detect\
    \ changes is limited by the\n      technology of the mechanisms used to implement\
    \ the service. For\n      example, if the mechanism were a one-bit parity check\
    \ across each\n      entire SDU, then changes to an odd number of bits in an SDU\
    \ would\n      be detected, but changes to an even number of bits would not.\n\
    \      Relationship between data integrity service and authentication\n      services:\
    \ Although data integrity service is defined separately\n      from data origin\
    \ authentication service and peer entity\n      authentication service, it is\
    \ closely related to them.\n      Authentication services depend, by definition,\
    \ on companion data\n      integrity services. Data origin authentication service\
    \ provides\n      verification that the identity of the original source of a\n\
    \      received data unit is as claimed; there can be no such\n      verification\
    \ if the data unit has been altered. Peer entity\n      authentication service\
    \ provides verification that the identity of\n      a peer entity in a current\
    \ association is as claimed; there can be\n      no such verification if the claimed\
    \ identity has been altered.\n   $ data origin authentication\n      (I) \"The\
    \ corroboration that the source of data received is as\n      claimed.\" [I7498-2]\
    \ (See: authentication.)\n   $ data origin authentication service\n      (I) A\
    \ security service that verifies the identity of a system\n      entity that is\
    \ claimed to be the original source of received data.\n      (See: authentication,\
    \ authentication service.)\n      Tutorial: This service is provided to any system\
    \ entity that\n      receives or holds the data. Unlike peer entity authentication\n\
    \      service, this service is independent of any association between\n     \
    \ the originator and the recipient, and the data in question may\n      have originated\
    \ at any time in the past.\n      A digital signature mechanism can be used to\
    \ provide this service,\n      because someone who does not know the private key\
    \ cannot forge the\n      correct signature. However, by using the signer's public\
    \ key,\n      anyone can verify the origin of correctly signed data.\n      This\
    \ service is usually bundled with connectionless data integrity\n      service.\
    \ (See: \"relationship between data integrity service and\n      authentication\
    \ services\" under \"data integrity service\".\n   $ data owner\n      (N) The\
    \ organization that has the final statutory and operational\n      authority for\
    \ specified information.\n   $ data privacy\n      (D) Synonym for \"data confidentiality\"\
    .\n      Deprecated Term: IDOCs SHOULD NOT use this term; it mixes concepts\n\
    \      in a potentially misleading way. Instead, use either \"data\n      confidentiality\"\
    \ or \"privacy\" or both, depending on what is meant.\n   $ data recovery\n  \
    \    1. (I) /cryptanalysis/ A process for learning, from some cipher\n      text,\
    \ the plain text that was previously encrypted to produce the\n      cipher text.\
    \ (See: recovery.)\n      2. (I) /system integrity/ The process of restoring information\n\
    \      following damage or destruction.\n   $ data security\n      (I) The protection\
    \ of data from disclosure, alteration,\n      destruction, or loss that either\
    \ is accidental or is intentional\n      but unauthorized.\n      Tutorial: Both\
    \ data confidentiality service and data integrity\n      service are needed to\
    \ achieve data security.\n   $ datagram\n      (I) \"A self-contained, independent\
    \ entity of data [i.e., a packet]\n      carrying sufficient information to be\
    \ routed from the source\n      [computer] to the destination computer without\
    \ reliance on earlier\n      exchanges between this source and destination computer\
    \ and the\n      transporting network.\" [R1983] Example: A PDU of IP.\n   $ datagram\
    \ confidentiality service\n      (I) A data confidentiality service that preserves\
    \ the\n      confidentiality of data in a single, independent, packet; i.e.,\n\
    \      the service applies to datagrams one-at-a-time. Example: ESP.\n      (See:\
    \ data confidentiality.)\n      Usage: When a protocol is said to provide data\
    \ confidentiality\n      service, this is usually understood to mean that only\
    \ the SDU is\n      protected in each packet. IDOCs that use the term to mean\
    \ that the\n      entire PDU is protected should include a highlighted definition.\n\
    \      Tutorial: This basic form of network confidentiality service\n      suffices\
    \ for protecting the data in a stream of packets in both\n      connectionless\
    \ and connection-oriented protocols. Except perhaps\n      for traffic flow confidentiality,\
    \ nothing further is needed to\n      protect the confidentiality of data carried\
    \ by a packet stream.\n      The OSIRM distinguishes between connection confidentiality\
    \ and\n      connectionless confidentiality. The IPS need not make that\n    \
    \  distinction, because those services are just instances of the same\n      service\
    \ (i.e., datagram confidentiality) being offered in two\n      different protocol\
    \ contexts. (For data integrity service, however,\n      additional effort is\
    \ needed to protect a stream, and the IPS does\n      need to distinguish between\
    \ \"datagram integrity service\" and\n      \"stream integrity service\".)\n \
    \  $ datagram integrity service\n      (I) A data integrity service that preserves\
    \ the integrity of data\n      in a single, independent, packet; i.e., the service\
    \ applies to\n      datagrams one-at-a-time. (See: data integrity. Compare: stream\n\
    \      integrity service.)\n      Tutorial: The ability to provide appropriate\
    \ data integrity is\n      important in many Internet security situations, and\
    \ so there are\n      different kinds of data integrity services suited to different\n\
    \      applications. This service is the simplest kind; it is suitable\n     \
    \ for connectionless data transfers.\n      Datagram integrity service usually\
    \ is designed only to attempt to\n      detect changes to the SDU in each packet,\
    \ but it might also\n      attempt to detect changes to some or all of the PCI\
    \ in each packet\n      (see: selective field integrity). In contrast to this\
    \ simple,\n      one-at-a-time service, some security situations demand a more\n\
    \      complex service that also attempts to detect deleted, inserted, or\n  \
    \    reordered datagrams within a stream of datagrams (see: stream\n      integrity\
    \ service).\n   $ DEA\n      (N) See: Data Encryption Algorithm.\n   $ deception\n\
    \      (I) A circumstance or event that may result in an authorized\n      entity\
    \ receiving false data and believing it to be true. (See:\n      authentication.)\n\
    \      Tutorial: This is a type of threat consequence, and it can be\n      caused\
    \ by the following types of threat actions: masquerade,\n      falsification,\
    \ and repudiation.\n   $ decipher\n      (D) Synonym for \"decrypt\".\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use this term as a synonym\n      for \"decrypt\"\
    . However, see usage note under \"encryption\".\n   $ decipherment\n      (D)\
    \ Synonym for \"decryption\".\n      Deprecated Definition: IDOCs SHOULD NOT use\
    \ this term as a synonym\n      for \"decryption\". However, see the Usage note\
    \ under \"encryption\".\n   $ declassification\n      (I) An authorized process\
    \ by which information is declassified.\n      (Compare: classification.)\n  \
    \ $ declassify\n      (I) To officially remove the security level designation\
    \ of a\n      classified information item or information type, such that the\n\
    \      information is no longer classified (i.e., becomes unclassified).\n   \
    \   (See: classified, classify, security level. Compare: downgrade.)\n   $ decode\n\
    \      1. (I) Convert encoded data back to its original form of\n      representation.\
    \ (Compare: decrypt.)\n      2. (D) Synonym for \"decrypt\".\n      Deprecated\
    \ Definition: Encoding is not usually meant to conceal\n      meaning. Therefore,\
    \ IDOCs SHOULD NOT use this term as a synonym\n      for \"decrypt\", because\
    \ that would mix concepts in a potentially\n      misleading way.\n   $ decrypt\n\
    \      (I) Cryptographically restore cipher text to the plaintext form it\n  \
    \    had before encryption.\n   $ decryption\n      (I) See: secondary definition\
    \ under \"encryption\".\n   $ dedicated security mode\n      (I) A mode of system\
    \ operation wherein all users having access to\n      the system possess, for\
    \ all data handled by the system, both (a)\n      all necessary authorizations\
    \ (i.e., security clearance and formal\n      access approval) and (b) a need-to-know.\
    \ (See: /system operation/\n      under \"mode\", formal access approval, need\
    \ to know, protection\n      level, security clearance.)\n      Usage: Usually\
    \ abbreviated as \"dedicated mode\". This mode was\n      defined in U.S. Government\
    \ policy on system accreditation, but the\n      term is also used outside the\
    \ Government. In this mode, the system\n      may handle either (a) a single classification\
    \ level or category of\n      information or (b) a range of levels and categories.\n\
    \   $ default account\n      (I) A system login account (usually accessed with\
    \ a user\n      identifier and password) that has been predefined in a\n     \
    \ manufactured system to permit initial access when the system is\n      first\
    \ put into service. (See: harden.)\n      Tutorial: A default account becomes\
    \ a serious vulnerability if not\n      properly administered. Sometimes, the\
    \ default identifier and\n      password are well-known because they are the same\
    \ in each copy of\n      the system. In any case, when a system is put into service,\
    \ any\n      default password should immediately be changed or the default\n \
    \     account should be disabled.\n   $ defense in depth\n      (N) \"The siting\
    \ of mutually supporting defense positions designed\n      to absorb and progressively\
    \ weaken attack, prevent initial\n      observations of the whole position by\
    \ the enemy, and [enable] the\n      commander to maneuver the reserve.\" [JP1]\n\
    \      Tutorial: In information systems, defense in depth means\n      constructing\
    \ a system's security architecture with layered and\n      complementary security\
    \ mechanisms and countermeasures, so that if\n      one security mechanism is\
    \ defeated, one or more other mechanisms\n      (which are \"behind\" or \"beneath\"\
    \ the first mechanism) still\n      provide protection.\n      This architectural\
    \ concept is appealing because it aligns with\n      traditional warfare doctrine,\
    \ which applies defense in depth to\n      physical, geospatial structures; but\
    \ applying the concept to\n      logical, cyberspace structures of computer networks\
    \ is more\n      difficult. The concept assumes that networks have a spatial or\n\
    \      topological representation. It also assumes that there can be\n      implemented\
    \ -- from the \"outer perimeter\" of a network, through\n      its various \"\
    layers\" of components, to its \"center\" (i.e., to the\n      subscriber application\
    \ systems supported by the network) -- a\n      varied series of countermeasures\
    \ that together provide adequate\n      protection. However, it is more difficult\
    \ to map the topology of\n      networks and make certain that no path exists\
    \ by which an attacker\n      could bypass all defensive layers.\n   $ Defense\
    \ Information Infrastructure (DII)\n      (O) /U.S. DoD/ The U.S. DoD's shared,\
    \ interconnected system of\n      computers, communications, data, applications,\
    \ security, people,\n      training, and support structures, serving information\
    \ needs\n      worldwide. (See: DISN.) Usage: Has evolved to be called the GIG.\n\
    \      Tutorial: The DII connects mission support, command and control,\n    \
    \  and intelligence computers and users through voice, data, imagery,\n      video,\
    \ and multimedia services, and provides information\n      processing and value-added\
    \ services to subscribers over the DISN.\n      Users' own data and application\
    \ software are not considered part\n      of the DII.\n   $ Defense Information\
    \ Systems Network (DISN)\n      (O) /U.S. DoD/ The U.S. DoD's consolidated, worldwide,\
    \ enterprise\n      level telecommunications infrastructure that provides end-to-end\n\
    \      information transfer for supporting military operations; a part of\n  \
    \    the DII. (Compare: GIG.)\n   $ degauss\n      1a. (N) Apply a magnetic field\
    \ to permanently remove data from a\n      magnetic storage medium, such as a\
    \ tape or disk [NCS25]. (Compare:\n      erase, purge, sanitize.)\n      1b. (N)\
    \ Reduce magnetic flux density to zero by applying a\n      reversing magnetic\
    \ field. (See: magnetic remanence.)\n   $ degausser\n      (N) An electrical device\
    \ that can degauss magnetic storage media.\n   $ DEK\n      (I) See: data encryption\
    \ key.\n   $ delay\n      (I) /packet/ See: secondary definition under \"stream\
    \ integrity\n      service\".\n   $ deletion\n      (I) /packet/ See: secondary\
    \ definition under \"stream integrity\n      service\".\n   $ deliberate exposure\n\
    \      (I) /threat action/ See: secondary definition under \"exposure\".\n   $\
    \ delta CRL\n      (I) A partial CRL that only contains entries for certificates\
    \ that\n      have been revoked since the issuance of a prior, base CRL [X509].\n\
    \      This method can be used to partition CRLs that become too large\n     \
    \ and unwieldy. (Compare: CRL distribution point.)\n   $ demilitarized zone (DMZ)\n\
    \      (D) Synonym for \"buffer zone\".\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use this term because it mixes\n      concepts in a potentially misleading way.\
    \ (See: Deprecated Usage\n      under \"Green Book\".)\n   $ denial of service\n\
    \      (I) The prevention of authorized access to a system resource or\n     \
    \ the delaying of system operations and functions. (See:\n      availability,\
    \ critical, flooding.)\n      Tutorial: A denial-of-service attack can prevent\
    \ the normal\n      conduct of business on the Internet. There are four types\
    \ of\n      solutions to this security problem:\n      -  Awareness: Maintaining\
    \ cognizance of security threats and\n         vulnerabilities. (See: CERT.)\n\
    \      -  Detection: Finding attacks on end systems and subnetworks.\n       \
    \  (See: intrusion detection.)\n      -  Prevention: Following defensive practices\
    \ on network-connected\n         systems. (See: [R2827].)\n      -  Response:\
    \ Reacting effectively when attacks occur. (See: CSIRT,\n         contingency\
    \ plan.)\n   $ DES\n      (N) See: Data Encryption Standard.\n   $ designated\
    \ approving authority (DAA)\n      (O) /U.S. Government/ Synonym for \"accreditor\"\
    .\n   $ detection\n      (I) See: secondary definition under \"security\".\n \
    \  $ deterrence\n      (I) See: secondary definition under \"security\".\n   $\
    \ dictionary attack\n      (I) An attack that uses a brute-force technique of\
    \ successively\n      trying all the words in some large, exhaustive list.\n \
    \     Examples: Attack an authentication service by trying all possible\n    \
    \  passwords. Attack an encryption service by encrypting some known\n      plaintext\
    \ phrase with all possible keys so that the key for any\n      given encrypted\
    \ message containing that phrase may be obtained by\n      lookup.\n   $ Diffie-Hellman\n\
    \   $ Diffie-Hellman-Merkle\n      (N) A key-agreement algorithm published in\
    \ 1976 by Whitfield\n      Diffie and Martin Hellman [DH76, R2631].\n      Usage:\
    \ The algorithm is most often called \"Diffie-Hellman\".\n      However, in the\
    \ November 1978 issue of \"IEEE Communications\n      Magazine\", Hellman wrote\
    \ that the algorithm \"is a public key\n      distribution system, a concept developed\
    \ by [Ralph C.] Merkle, and\n      hence should be called 'Diffie-Hellman-Merkle'\
    \ ... to recognize\n      Merkle's equal contribution to the invention of public\
    \ key\n      cryptography.\"\n      Tutorial: Diffie-Hellman-Merkle does key establishment,\
    \ not\n      encryption. However, the key that it produces may be used for\n \
    \     encryption, for further key management operations, or for any\n      other\
    \ cryptography.\n      The algorithm is described in [R2631] and [Schn]. In brief,\
    \ Alice\n      and Bob together pick large integers that satisfy certain\n   \
    \   mathematical conditions, and then use the integers to each\n      separately\
    \ compute a public-private key pair. They send each other\n      their public\
    \ key. Each person uses their own private key and the\n      other person's public\
    \ key to compute a key, k, that, because of\n      the mathematics of the algorithm,\
    \ is the same for each of them.\n      Passive wiretapping cannot learn the shared\
    \ k, because k is not\n      transmitted, and neither are the private keys needed\
    \ to compute k.\n      The difficulty of breaking Diffie-Hellman-Merkle is considered\
    \ to\n      be equal to the difficulty of computing discrete logarithms modulo\n\
    \      a large prime. However, without additional mechanisms to\n      authenticate\
    \ each party to the other, a protocol based on the\n      algorithm may be vulnerable\
    \ to a man-in-the-middle attack.\n   $ digest\n      See: message digest.\n  \
    \ $ digital certificate\n      (I) A certificate document in the form of a digital\
    \ data object (a\n      data object used by a computer) to which is appended a\
    \ computed\n      digital signature value that depends on the data object. (See:\n\
    \      attribute certificate, public-key certificate.)\n      Deprecated Usage:\
    \ IDOCs SHOULD NOT use this term to refer to a\n      signed CRL or CKL. Although\
    \ the recommended definition can be\n      interpreted to include other signed\
    \ items, the security community\n      does not use the term with those meanings.\n\
    \   $ digital certification\n      (D) Synonym for \"certification\".\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use this definition unless\n      the context is\
    \ not sufficient to distinguish between digital\n      certification and another\
    \ kind of certification, in which case it\n      would be better to use \"public-key\
    \ certification\" or another\n      phrase that indicates what is being certified.\n\
    \   $ digital document\n      (I) An electronic data object that represents information\n\
    \      originally written in a non-electronic, non-magnetic medium\n      (usually\
    \ ink on paper) or is an analogue of a document of that\n      type.\n   $ digital\
    \ envelope\n      (I) A combination of (a) encrypted content data (of any kind)\n\
    \      intended for a recipient and (b) the content encryption key in an\n   \
    \   encrypted form that has been prepared for the use of the\n      recipient.\n\
    \      Usage: In IDOCs, the term SHOULD be defined at the point of first\n   \
    \   use because, although the term is defined in PKCS #7 and used in\n      S/MIME,\
    \ it is not widely known.\n      Tutorial: Digital enveloping is not simply a\
    \ synonym for\n      implementing data confidentiality with encryption; digital\n\
    \      enveloping is a hybrid encryption scheme to \"seal\" a message or\n   \
    \   other data, by encrypting the data and sending both it and a\n      protected\
    \ form of the key to the intended recipient, so that no\n      one other than\
    \ the intended recipient can \"open\" the message. In\n      PKCS #7, it means\
    \ first encrypting the data using a symmetric\n      encryption algorithm and\
    \ a secret key, and then encrypting the\n      secret key using an asymmetric\
    \ encryption algorithm and the public\n      key of the intended recipient. In\
    \ S/MIME, additional methods are\n      defined for encrypting the content encryption\
    \ key.\n   $ Digital ID(service mark)\n      (D) Synonym for \"digital certificate\"\
    .\n      Deprecated Term: IDOCs SHOULD NOT use this term. It is a service\n  \
    \    mark of a commercial firm, and it unnecessarily duplicates the\n      meaning\
    \ of a better-established term. (See: credential.)\n   $ digital key\n      (D)\
    \ Synonym for an input parameter of a cryptographic algorithm or\n      other\
    \ process. (See: key.)\n      Deprecated Usage: The adjective \"digital\" need\
    \ not be used with\n      \"key\" or \"cryptographic key\", unless the context\
    \ is insufficient\n      to distinguish the digital key from another kind of key,\
    \ such as a\n      metal key for a door lock.\n   $ digital notary\n      (I)\
    \ An electronic functionary analogous to a notary public.\n      Provides a trusted\
    \ timestamp for a digital document, so that\n      someone can later prove that\
    \ the document existed at that point in\n      time; verifies the signature(s)\
    \ on a signed document before\n      applying the stamp. (See: notarization.)\n\
    \   $ digital signature\n      1. (I) A value computed with a cryptographic algorithm\
    \ and\n      associated with a data object in such a way that any recipient of\n\
    \      the data can use the signature to verify the data's origin and\n      integrity.\
    \ (See: data origin authentication service, data\n      integrity service, signer.\
    \ Compare: digitized signature,\n      electronic signature.)\n      2. (O) \"\
    Data appended to, or a cryptographic transformation of, a\n      data unit that\
    \ allows a recipient of the data unit to prove the\n      source and integrity\
    \ of the data unit and protect against forgery,\n      e.g. by the recipient.\"\
    \ [I7498-2]\n      Tutorial: A digital signature should have these properties:\n\
    \      -  Be capable of being verified. (See: validate vs. verify.)\n      - \
    \ Be bound to the signed data object in such a way that if the\n         data\
    \ is changed, then when an attempt is made to verify the\n         signature,\
    \ it will be seen as not authentic. (In some schemes,\n         the signature\
    \ is appended to the signed object as stated by\n         definition 2, but in\
    \ other it, schemes is not.)\n      -  Uniquely identify a system entity as being\
    \ the signer.\n      -  Be under the signer's sole control, so that it cannot\
    \ be\n         created by any other entity.\n      To achieve these properties,\
    \ the data object is first input to a\n      hash function, and then the hash\
    \ result is cryptographically\n      transformed using a private key of the signer.\
    \ The final resulting\n      value is called the digital signature of the data\
    \ object. The\n      signature value is a protected checksum, because the properties\
    \ of\n      a cryptographic hash ensure that if the data object is changed,\n\
    \      the digital signature will no longer match it. The digital\n      signature\
    \ is unforgeable because one cannot be certain of\n      correctly creating or\
    \ changing the signature without knowing the\n      private key of the supposed\
    \ signer.\n      Some digital signature schemes use an asymmetric encryption\n\
    \      algorithm (e.g., \"RSA\") to transform the hash result. Thus, when\n  \
    \    Alice needs to sign a message to send to Bob, she can use her\n      private\
    \ key to encrypt the hash result. Bob receives both the\n      message and the\
    \ digital signature. Bob can use Alice's public key\n      to decrypt the signature,\
    \ and then compare the plaintext result to\n      the hash result that he computes\
    \ by hashing the message himself.\n      If the values are equal, Bob accepts\
    \ the message because he is\n      certain that it is from Alice and has arrived\
    \ unchanged. If the\n      values are not equal, Bob rejects the message because\
    \ either the\n      message or the signature was altered in transit.\n      Other\
    \ digital signature schemes (e.g., \"DSS\") transform the hash\n      result with\
    \ an algorithm (e.g., \"DSA\", \"El Gamal\") that cannot be\n      directly used\
    \ to encrypt data. Such a scheme creates a signature\n      value from the hash\
    \ and provides a way to verify the signature\n      value, but does not provide\
    \ a way to recover the hash result from\n      the signature value. In some countries,\
    \ such a scheme may improve\n      exportability and avoid other legal constraints\
    \ on usage. Alice\n      sends the signature value to Bob along with both the\
    \ message and\n      its hash result. The algorithm enables Bob to use Alice's\
    \ public\n      signature key and the signature value to verify the hash result\
    \ he\n      receives. Then, as before, he compares that hash result she sent\n\
    \      to the one that he computes by hashing the message himself.\n   $ Digital\
    \ Signature Algorithm (DSA)\n      (N) An asymmetric cryptographic algorithm for\
    \ a digital signature\n      in the form of a pair of large numbers. The signature\
    \ is computed\n      using rules and parameters such that the identity of the\
    \ signer\n      and the integrity of the signed data can be verified. (See: DSS.)\n\
    \   $ Digital Signature Standard (DSS)\n      (N) The U.S. Government standard\
    \ [FP186] that specifies the DSA.\n   $ digital watermarking\n      (I) Computing\
    \ techniques for inseparably embedding unobtrusive\n      marks or labels as bits\
    \ in digital data -- text, graphics, images,\n      video, or audio -- and for\
    \ detecting or extracting the marks\n      later.\n      Tutorial: A \"digital\
    \ watermark\", i.e., the set of embedded bits,\n      is sometimes hidden, usually\
    \ imperceptible, and always intended to\n      be unobtrusive. Depending on the\
    \ particular technique that is\n      used, digital watermarking can assist in\
    \ proving ownership,\n      controlling duplication, tracing distribution, ensuring\
    \ data\n      integrity, and performing other functions to protect intellectual\n\
    \      property rights. [ACM]\n   $ digitized signature\n      (D) Denotes various\
    \ forms of digitized images of handwritten\n      signatures. (Compare: digital\
    \ signature).\n      Deprecated Term: IDOCs SHOULD NOT use this term without including\n\
    \      this definition. This term suggests careless use of \"digital\n      signature\"\
    , which is the term standardized by [I7498-2]. (See:\n      electronic signature.)\n\
    \   $ DII\n      (O) See: Defense Information Infrastructure.\n   $ direct attack\n\
    \      (I) See: secondary definition under \"attack\". (Compare: indirect\n  \
    \    attack.)\n   $ directory, Directory\n      1. (I) /not capitalized/ Refers\
    \ generically to a database server\n      or other system that stores and provides\
    \ access to values of\n      descriptive or operational data items that are associated\
    \ with the\n      components of a system. (Compare: repository.)\n      2. (N)\
    \ /capitalized/ Refers specifically to the X.500 Directory.\n      (See: DN, X.500.)\n\
    \   $ Directory Access Protocol (DAP)\n      (N) An OSI protocol [X519] for communication\
    \ between a Directory\n      User Agent (a type of X.500 client) and a Directory\
    \ System Agent\n      (a type of X.500 server). (See: LDAP.)\n   $ disaster plan\n\
    \      (O) Synonym for \"contingency plan\".\n      Deprecated Term: IDOCs SHOULD\
    \ NOT use this term; instead, for\n      consistency and neutrality of language,\
    \ IDOCs SHOULD use\n      \"contingency plan\".\n   $ disclosure\n      See: unauthorized\
    \ disclosure. Compare: exposure.\n   $ discretionary access control\n      1a.\
    \ (I) An access control service that (a) enforces a security\n      policy based\
    \ on the identity of system entities and the\n      authorizations associated\
    \ with the identities and (b) incorporates\n      a concept of ownership in which\
    \ access rights for a system\n      resource may be granted and revoked by the\
    \ entity that owns the\n      resource. (See: access control list, DAC, identity-based\
    \ security\n      policy, mandatory access control.)\n      Derivation: This service\
    \ is termed \"discretionary\" because an\n      entity can be granted access rights\
    \ to a resource such that the\n      entity can by its own volition enable other\
    \ entities to access the\n      resource.\n      1b. (O) /formal model/ \"A means\
    \ of restricting access to objects\n      based on the identity of subjects and/or\
    \ groups to which they\n      belong. The controls are discretionary in the sense\
    \ that a subject\n      with a certain access permission is capable of passing\
    \ that\n      permission (perhaps indirectly) on to any other subject.\" [DoD1]\n\
    \   $ DISN\n      (O) See: Defense Information Systems Network (DISN).\n   $ disruption\n\
    \      (I) A circumstance or event that interrupts or prevents the\n      correct\
    \ operation of system services and functions. (See:\n      availability, critical,\
    \ system integrity, threat consequence.)\n      Tutorial: Disruption is a type\
    \ of threat consequence; it can be\n      caused by the following types of threat\
    \ actions: incapacitation,\n      corruption, and obstruction.\n   $ Distinguished\
    \ Encoding Rules (DER)\n      (N) A subset of the Basic Encoding Rules that always\
    \ provides only\n      one way to encode any data structure defined by ASN.1.\
    \ [X690].\n      Tutorial: For a data structure defined abstractly in ASN.1, BER\n\
    \      often provides for encoding the structure into an octet string in\n   \
    \   more than one way, so that two separate BER implementations can\n      legitimately\
    \ produce different octet strings for the same ASN.1\n      definition. However,\
    \ some applications require all encodings of a\n      structure to be the same,\
    \ so that encodings can be compared for\n      equality. Therefore, DER is used\
    \ in applications in which unique\n      encoding is needed, such as when a digital\
    \ signature is computed\n      on a structure defined by ASN.1.\n   $ distinguished\
    \ name (DN)\n      (N) An identifier that uniquely represents an object in the\
    \ X.500\n      Directory Information Tree (DIT) [X501]. (Compare: domain name,\n\
    \      identity, naming authority.)\n      Tutorial: A DN is a set of attribute\
    \ values that identify the path\n      leading from the base of the DIT to the\
    \ object that is named. An\n      X.509 public-key certificate or CRL contains\
    \ a DN that identifies\n      its issuer, and an X.509 attribute certificate contains\
    \ a DN or\n      other form of name that identifies its subject.\n   $ distributed\
    \ attack\n      1a. (I) An attack that is implemented with distributed computing.\n\
    \      (See: zombie.)\n      1b. (I) An attack that deploys multiple threat agents.\n\
    \   $ Distributed Authentication Security Service (DASS)\n      (I) An experimental\
    \ Internet protocol [R1507] that uses\n      cryptographic mechanisms to provide\
    \ strong, mutual authentication\n      services in a distributed environment.\n\
    \   $ distributed computing\n      (I) A technique that disperses a single, logically\
    \ related set of\n      tasks among a group of geographically separate yet cooperating\n\
    \      computers. (See: distributed attack.)\n   $ distribution point\n      (I)\
    \ An X.500 Directory entry or other information source that is\n      named in\
    \ a v3 X.509 public-key certificate extension as a location\n      from which\
    \ to obtain a CRL that may list the certificate.\n      Tutorial: A v3 X.509 public-key\
    \ certificate may have a\n      \"cRLDistributionPoints\" extension that names\
    \ places to get CRLs on\n      which the certificate might be listed. (See: certificate\
    \ profile.)\n      A CRL obtained from a distribution point may (a) cover either\
    \ all\n      reasons for which a certificate might be revoked or only some of\n\
    \      the reasons, (b) be issued by either the authority that signed the\n  \
    \    certificate or some other authority, and (c) contain revocation\n      entries\
    \ for only a subset of the full set of certificates issued\n      by one CA or\
    \ (d) contain revocation entries for multiple CAs.\n   $ DKIM\n      (I) See:\
    \ Domain Keys Identified Mail.\n   $ DMZ\n      (D) See: demilitarized zone.\n\
    \   $ DN\n      (N) See: distinguished name.\n   $ DNS\n      (I) See: Domain\
    \ Name System.\n   $ doctrine\n      See: security doctrine.\n   $ DoD\n     \
    \ (N) Department of Defense.\n      Usage: To avoid international misunderstanding,\
    \ IDOCs SHOULD use\n      this abbreviation only with a national qualifier (e.g.,\
    \ U.S. DoD).\n   $ DOI\n      (I) See: Domain of Interpretation.\n   $ domain\n\
    \      1a. (I) /general security/ An environment or context that (a)\n      includes\
    \ a set of system resources and a set of system entities\n      that have the\
    \ right to access the resources and (b) usually is\n      defined by a security\
    \ policy, security model, or security\n      architecture. (See: CA domain, domain\
    \ of interpretation, security\n      perimeter. Compare: COI, enclave.)\n    \
    \  Tutorial: A \"controlled interface\" or \"guard\" is required to\n      transfer\
    \ information between network domains that operate under\n      different security\
    \ policies.\n      1b. (O) /security policy/ A set of users, their information\n\
    \      objects, and a common security policy. [DoD6, SP33]\n      1c. (O) /security\
    \ policy/ A system or collection of systems that\n      (a) belongs to a community\
    \ of interest that implements a\n      consistent security policy and (b) is administered\
    \ by a single\n      authority.\n      2. (O) /COMPUSEC/ An operating state or\
    \ mode of a set of computer\n      hardware.\n      Tutorial: Most computers have\
    \ at least two hardware operating\n      modes [Gass]:\n      -  \"Privileged\"\
    \ mode: a.k.a. \"executive\", \"master\", \"system\",\n         \"kernel\", or\
    \ \"supervisor\" mode. In this mode, software can\n         execute all machine\
    \ instructions and access all storage\n         locations.\n      -  \"Unprivileged\"\
    \ mode: a.k.a. \"user\", \"application\", or \"problem\"\n         mode. In this\
    \ mode, software is restricted to a subset of the\n         instructions and a\
    \ subset of the storage locations.\n      3. (O) \"A distinct scope within which\
    \ certain common\n      characteristics are exhibited and common rules are observed.\"\
    \n      [CORBA]\n      4. (O) /MISSI/ The domain of a MISSI CA is the set of MISSI\
    \ users\n      whose certificates are signed by the CA.\n      5. (I) /Internet/\
    \ That part of the tree-structured name space of\n      the DNS that is at or\
    \ below the name that specifies the domain. A\n      domain is a subdomain of\
    \ another domain if it is contained within\n      that domain. For example, D.C.B.A\
    \ is a subdomain of C.B.A\n      6. (O) /OSI/ An administrative partition of a\
    \ complex distributed\n      OSI system.\n   $ Domain Keys Identified Mail (DKIM)\n\
    \      (I) A protocol, which is being specified by the IETF working group\n  \
    \    of the same name, to provide data integrity and domain-level (see:\n    \
    \  DNS, domain name) data origin authentication for Internet mail\n      messages.\
    \ (Compare: PEM.)\n      Tutorial: DKIM employs asymmetric cryptography to create\
    \ a digital\n      signature for an Internet email message's body and selected\n\
    \      headers (see RFC 1822), and the signature is then carried in a\n      header\
    \ of the message. A recipient of the message can verify the\n      signature and,\
    \ thereby, authenticate the identity of the\n      originating domain and the\
    \ integrity of the signed content, by\n      using a public key belonging to the\
    \ domain. The key can be\n      obtained from the DNS.\n   $ domain name\n   \
    \   (I) The style of identifier that is defined for subtrees in the\n      Internet\
    \ DNS -- i.e., a sequence of case-insensitive ASCII labels\n      separated by\
    \ dots (e.g., \"bbn.com\") -- and also is used in other\n      types of Internet\
    \ identifiers, such as host names (e.g.,\n      \"rosslyn.bbn.com\"), mailbox\
    \ names (e.g., \"rshirey@bbn.com\") and\n      URLs (e.g., \"http://www.rosslyn.bbn.com/foo\"\
    ). (See: domain.\n      Compare: DN.)\n      Tutorial: The name space of the DNS\
    \ is a tree structure in which\n      each node and leaf holds records describing\
    \ a resource. Each node\n      has a label. The domain name of a node is the list\
    \ of labels on\n      the path from the node to the root of the tree. The labels\
    \ in a\n      domain name are printed or read left to right, from the most\n \
    \     specific (lowest, farthest from the root) to the least specific\n      (highest,\
    \ closest to the root), but the root's label is the null\n      string. (See:\
    \ country code.)\n   $ Domain Name System (DNS)\n      (I) The main Internet operations\
    \ database, which is distributed\n      over a collection of servers and used\
    \ by client software for\n      purposes such as (a) translating a domain name-style\
    \ host name\n      into an IP address (e.g., \"rosslyn.bbn.com\" translates to\n\
    \      \"192.1.7.10\") and (b) locating a host that accepts mail for a\n     \
    \ given mailbox address. (RFC 1034) (See: domain name.)\n      Tutorial: The DNS\
    \ has three major components:\n      -  Domain name space and resource records:\
    \ Specifications for the\n         tree-structured domain name space, and data\
    \ associated with the\n         names.\n      -  Name servers: Programs that hold\
    \ information about a subset of\n         the tree's structure and data holdings,\
    \ and also hold pointers\n         to other name servers that can provide information\
    \ from any\n         part of the tree.\n      -  Resolvers: Programs that extract\
    \ information from name servers\n         in response to client requests; typically,\
    \ system routines\n         directly accessible to user programs.\n      Extensions\
    \ to the DNS [R4033, R4034, R4035] support (a) key\n      distribution for public\
    \ keys needed for the DNS and for other\n      protocols, (b) data origin authentication\
    \ service and data\n      integrity service for resource records, (c) data origin\n\
    \      authentication service for transactions between resolvers and\n      servers,\
    \ and (d) access control of records.\n   $ domain of interpretation (DOI)\n  \
    \    (I) /IPsec/ A DOI for ISAKMP or IKE defines payload formats,\n      exchange\
    \ types, and conventions for naming security-relevant\n      information such\
    \ as security policies or cryptographic algorithms\n      and modes. Example:\
    \ See [R2407].\n      Derivation: The DOI concept is based on work by the TSIG's\
    \ CIPSO\n      Working Group.\n   $ dominate\n      (I) Security level A is said\
    \ to \"dominate\" security level B if the\n      (hierarchical) classification\
    \ level of A is greater (higher) than\n      or equal to that of B, and A's (nonhierarchical)\
    \ categories\n      include (as a subset) all of B's categories. (See: lattice,\n\
    \      lattice model.)\n   $ dongle\n      (I) A portable, physical, usually electronic\
    \ device that is\n      required to be attached to a computer to enable a particular\n\
    \      software program to run. (See: token.)\n      Tutorial: A dongle is essentially\
    \ a physical key used for copy\n      protection of software; that is, the program\
    \ will not run unless\n      the matching dongle is attached. When the software\
    \ runs, it\n      periodically queries the dongle and quits if the dongle does\
    \ not\n      reply with the proper authentication information. Dongles were\n\
    \      originally constructed as an EPROM (erasable programmable read-\n     \
    \ only memory) to be connected to a serial input-output port of a\n      personal\
    \ computer.\n   $ downgrade\n      (I) /data security/ Reduce the security level\
    \ of data (especially\n      the classification level) without changing the information\
    \ content\n      of the data. (Compare: downgrade.)\n   $ downgrade attack\n \
    \     (I) A type of man-in-the-middle attack in which the attacker can\n     \
    \ cause two parties, at the time they negotiate a security\n      association,\
    \ to agree on a lower level of protection than the\n      highest level that could\
    \ have been supported by both of them.\n      (Compare: downgrade.)\n   $ draft\
    \ RFC\n      (D) A preliminary, temporary version of a document that is\n    \
    \  intended to become an RFC. (Compare: Internet-Draft.)\n      Deprecated Term:\
    \ IDOCs SHOULD NOT use this term. The RFC series is\n      archival in nature\
    \ and consists only of documents in permanent\n      form. A document that is\
    \ intended to become an RFC usually needs\n      to be published first as an Internet-Draft\
    \ (RFC 2026). (See:\n      \"Draft Standard\" under \"Internet Standard\".)\n\
    \   $ Draft Standard\n      (I) See: secondary definition under \"Internet Standard\"\
    .\n   $ DSA\n      (N) See: Digital Signature Algorithm.\n   $ DSS\n      (N)\
    \ See: Digital Signature Standard.\n   $ dual control\n      (I) A procedure that\
    \ uses two or more entities (usually persons)\n      operating in concert to protect\
    \ a system resource, such that no\n      single entity acting alone can access\
    \ that resource. (See: no-lone\n      zone, separation of duties, split knowledge.)\n\
    \   $ dual signature\n      (O) /SET/ A single digital signature that protects\
    \ two separate\n      messages by including the hash results for both sets in\
    \ a single\n      encrypted value. [SET2]\n      Deprecated Usage: IDOCs SHOULD\
    \ NOT use this term except when\n      qualified as \"SET(trademark) dual signature\"\
    \ with this definition.\n      Tutorial: Generated by hashing each message separately,\n\
    \      concatenating the two hash results, and then hashing that value\n     \
    \ and encrypting the result with the signer's private key. Done to\n      reduce\
    \ the number of encryption operations and to enable\n      verification of data\
    \ integrity without complete disclosure of the\n      data.\n   $ dual-use certificate\n\
    \      (O) A certificate that is intended for use with both digital\n      signature\
    \ and data encryption services. [SP32]\n      Usage: IDOCs that use this term\
    \ SHOULD state a definition for it\n      by identifying the intended uses of\
    \ the certificate, because there\n      are more than just these two uses mentioned\
    \ in the NIST\n      publication. A v3 X.509 public-key certificate may have a\
    \ \"key\n      Usage\" extension, which indicates the purposes for which the\n\
    \      public key may be used. (See: certificate profile.)\n   $ duty\n      (I)\
    \ An attribute of a role that obligates an entity playing the\n      role to perform\
    \ one or more tasks, which usually are essential for\n      the functioning of\
    \ the system. [Sand] (Compare authorization,\n      privilege. See: role, billet.)\n\
    \   $ e-cash\n      (O) Electronic cash; money that is in the form of data and\
    \ can be\n      used as a payment mechanism on the Internet. (See: IOTP.)\n  \
    \    Usage: IDOCs that use this term SHOULD state a definition for it\n      because\
    \ many different types of electronic cash have been devised\n      with a variety\
    \ of security mechanisms.\n   $ EAP\n      (I) See: Extensible Authentication\
    \ Protocol.\n   $ EAL\n      (O) See: evaluation assurance level.\n   $ Easter\
    \ egg\n      (O) \"Hidden functionality within an application program, which\n\
    \      becomes activated when an undocumented, and often convoluted, set\n   \
    \   of commands and keystrokes is entered. Easter eggs are typically\n      used\
    \ to display the credits for the development team and [are]\n      intended to\
    \ be non-threatening\" [SP28], but Easter eggs have the\n      potential to contain\
    \ malicious code.\n      Deprecated Usage: It is likely that other cultures use\
    \ different\n      metaphors for this concept. Therefore, to avoid international\n\
    \      misunderstanding, IDOCs SHOULD NOT use this term. (See: Deprecated\n  \
    \    Usage under \"Green Book\".)\n   $ eavesdropping\n      (I) Passive wiretapping\
    \ done secretly, i.e., without the knowledge\n      of the originator or the intended\
    \ recipients of the communication.\n   $ ECB\n      (N) See: electronic codebook.\n\
    \   $ ECDSA\n      (N) See: Elliptic Curve Digital Signature Algorithm.\n   $\
    \ economy of alternatives\n      (I) The principle that a security mechanism should\
    \ be designed to\n      minimize the number of alternative ways of achieving a\
    \ service.\n      (Compare: economy of mechanism.)\n   $ economy of mechanism\n\
    \      (I) The principle that a security mechanism should be designed to\n   \
    \   be as simple as possible, so that (a) the mechanism can be\n      correctly\
    \ implemented and (b) it can be verified that the\n      operation of the mechanism\
    \ enforces the system's security policy.\n      (Compare: economy of alternatives,\
    \ least privilege.)\n   $ ECU\n      (N) See: end cryptographic unit.\n   $ EDI\n\
    \      (I) See: electronic data interchange.\n   $ EDIFACT\n      (N) See: secondary\
    \ definition under \"electronic data interchange\".\n   $ EE\n      (D) Abbreviation\
    \ of \"end entity\" and other terms.\n      Deprecated Abbreviation: IDOCs SHOULD\
    \ NOT use this abbreviation;\n      there could be confusion among \"end entity\"\
    , \"end-to-end\n      encryption\", \"escrowed encryption standard\", and other\
    \ terms.\n   $ EES\n      (O) See: Escrowed Encryption Standard.\n   $ effective\
    \ key length\n      (O) \"A measure of strength of a cryptographic algorithm,\n\
    \      regardless of actual key length.\" [IATF] (See: work factor.)\n   $ effectiveness\n\
    \      (O) /ITSEC/ A property of a TOE representing how well it provides\n   \
    \   security in the context of its actual or proposed operational use.\n   $ El\
    \ Gamal algorithm\n      (N) An algorithm for asymmetric cryptography, invented\
    \ in 1985 by\n      Taher El Gamal, that is based on the difficulty of calculating\n\
    \      discrete logarithms and can be used for both encryption and\n      digital\
    \ signatures. [ElGa]\n   $ electronic codebook (ECB)\n      (N) A block cipher\
    \ mode in which a plaintext block is used\n      directly as input to the encryption\
    \ algorithm and the resultant\n      output block is used directly as cipher text\
    \ [FP081]. (See: block\n      cipher, [SP38A].)\n   $ electronic commerce\n  \
    \    1. (I) Business conducted through paperless exchanges of\n      information,\
    \ using electronic data interchange, electronic funds\n      transfer (EFT), electronic\
    \ mail, computer bulletin boards,\n      facsimile, and other paperless technologies.\n\
    \      2. (O) /SET/ \"The exchange of goods and services for payment\n      between\
    \ the cardholder and merchant when some or all of the\n      transaction is performed\
    \ via electronic communication.\" [SET2]\n   $ electronic data interchange (EDI)\n\
    \      (I) Computer-to-computer exchange, between trading partners, of\n     \
    \ business data in standardized document formats.\n      Tutorial: EDI formats\
    \ have been standardized primarily by ANSI X12\n      and by EDIFACT (EDI for\
    \ Administration, Commerce, and\n      Transportation), which is an international,\
    \ UN-sponsored standard\n      primarily used in Europe and Asia. X12 and EDIFACT\
    \ are aligning to\n      create a single, global EDI standard.\n   $ Electronic\
    \ Key Management System (EKMS)\n      (O) \"Interoperable collection of systems\
    \ developed by ... the U.S.\n      Government to automate the planning, ordering,\
    \ generating,\n      distributing, storing, filling, using, and destroying of\n\
    \      electronic keying material and the management of other types of\n     \
    \ COMSEC material.\" [C4009]\n   $ electronic signature\n      (D) Synonym for\
    \ \"digital signature\" or \"digitized signature\".\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term; there is no\n      current consensus on its definition.\
    \ Instead, use \"digital\n      signature\", if that is what was intended\n  \
    \ $ electronic wallet\n      (D) A secure container to hold, in digitized form,\
    \ some sensitive\n      data objects that belong to the owner, such as electronic\
    \ money,\n      authentication material, and various types of personal\n     \
    \ information. (See: IOTP.)\n      Deprecated Term: IDOCs SHOULD NOT use this\
    \ term. There is no\n      current consensus on its definition; and some uses\
    \ and definitions\n      may be proprietary. Meanings range from virtual wallets\n\
    \      implemented by data structures to physical wallets implemented by\n   \
    \   cryptographic tokens. (See: Deprecated Usage under \"Green Book\".)\n   $\
    \ elliptic curve cryptography (ECC)\n      (I) A type of asymmetric cryptography\
    \ based on mathematics of\n      groups that are defined by the points on a curve,\
    \ where the curve\n      is defined by a quadratic equation in a finite field.\
    \ [Schn]\n      Tutorial: ECC is based on mathematics different than that\n  \
    \    originally used to define the Diffie-Hellman-Merkle algorithm and\n     \
    \ the DSA, but ECC can be used to define an algorithm for key\n      agreement\
    \ that is an analog of Diffie-Hellman-Merkle [A9063] and\n      an algorithm for\
    \ digital signature that is an analog of DSA\n      [A9062]. The mathematical\
    \ problem upon which ECC is based is\n      believed to be more difficult than\
    \ the problem upon which Diffie-\n      Hellman-Merkle is based and, therefore,\
    \ that keys for ECC can be\n      shorter for a comparable level of security.\
    \ (See: ECDSA.)\n   $ Elliptic Curve Digital Signature Algorithm (ECDSA)\n   \
    \   (N) A standard [A9062] that is the analog, in elliptic curve\n      cryptography,\
    \ of the Digital Signature Algorithm.\n   $ emanation\n      (I) A signal (e.g.,\
    \ electromagnetic or acoustic) that is emitted\n      by a system (e.g., through\
    \ radiation or conductance) as a\n      consequence (i.e., byproduct) of the system's\
    \ operation, and that\n      may contain information. (See: emanations security.)\n\
    \   $ emanations analysis\n      (I) /threat action/ See: secondary definition\
    \ under\n      \"interception\".\n   $ emanations security (EMSEC)\n      (I)\
    \ Physical security measures to protect against data compromise\n      that could\
    \ occur because of emanations that might be received and\n      read by an unauthorized\
    \ party. (See: emanation, TEMPEST.)\n      Usage: Refers either to preventing\
    \ or limiting emanations from a\n      system and to preventing or limiting the\
    \ ability of unauthorized\n      parties to receive the emissions.\n   $ embedded\
    \ cryptography\n      (N) \"Cryptography engineered into an equipment or system\
    \ whose\n      basic function is not cryptographic.\" [C4009]\n   $ emergency\
    \ plan\n      (D) Synonym for \"contingency plan\".\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term. Instead, for\n      neutrality and consistency of\
    \ language, use \"contingency plan\".\n   $ emergency response\n      (O) An urgent\
    \ response to a fire, flood, civil commotion, natural\n      disaster, bomb threat,\
    \ or other serious situation, with the intent\n      of protecting lives, limiting\
    \ damage to property, and minimizing\n      disruption of system operations. [FP087]\
    \ (See: availability, CERT,\n      emergency plan.)\n   $ EMSEC\n      (I) See:\
    \ emanations security.\n   $ EMV\n      (N) Abbreviation of \"Europay, MasterCard,\
    \ Visa\". Refers to a\n      specification for smart cards that are used as payment\
    \ cards, and\n      for related terminals and applications. [EMV1, EMV2, EMV3]\n\
    \   $ Encapsulating Security Payload (ESP)\n      (I) An Internet protocol [R2406,\
    \ R4303] designed to provide data\n      confidentiality service and other security\
    \ services for IP\n      datagrams. (See: IPsec. Compare: AH.)\n      Tutorial:\
    \ ESP may be used alone, or in combination with AH, or in\n      a nested fashion\
    \ with tunneling. Security services can be provided\n      between a pair of communicating\
    \ hosts, between a pair of\n      communicating security gateways, or between\
    \ a host and a gateway.\n      The ESP header is encapsulated by the IP header,\
    \ and the ESP\n      header encapsulates either the upper-layer protocol header\n\
    \      (transport mode) or an IP header (tunnel mode). ESP can provide\n     \
    \ data confidentiality service, data origin authentication service,\n      connectionless\
    \ data integrity service, an anti-replay service, and\n      limited traffic-flow\
    \ confidentiality. The set of services depends\n      on the placement of the\
    \ implementation and on options selected\n      when the security association\
    \ is established.\n   $ encipher\n      (D) Synonym for \"encrypt\".\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use this term as a synonym\n      for \"encrypt\"\
    . However, see Usage note under \"encryption\".\n   $ encipherment\n      (D)\
    \ Synonym for \"encryption\".\n      Deprecated Definition: IDOCs SHOULD NOT use\
    \ this term as a synonym\n      for \"encryption\". However, see Usage note under\
    \ \"encryption\".\n   $ enclave\n      1. (I) A set of system resources that operate\
    \ in the same security\n      domain and that share the protection of a single,\
    \ common,\n      continuous security perimeter. (Compare: domain.)\n      2. (D)\
    \ /U.S. Government/ \"Collection of computing environments\n      connected by\
    \ one or more internal networks under the control of a\n      single authority\
    \ and security policy, including personnel and\n      physical security.\" [C4009]\n\
    \      Deprecated Definition: IDOCs SHOULD NOT use this term with\n      definition\
    \ 2 because the definition applies to what is usually\n      called a \"security\
    \ domain\". That is, a security domain is a set of\n      one or more security\
    \ enclaves.\n   $ encode\n      1. (I) Use a system of symbols to represent information,\
    \ which\n      might originally have some other representation. Example: Morse\n\
    \      code. (See: ASCII, BER.) (See: code, decode.)\n      2. (D) Synonym for\
    \ \"encrypt\".\n      Deprecated Definition: IDOCs SHOULD NOT use this term as\
    \ a synonym\n      for \"encrypt\"; encoding is not always meant to conceal meaning.\n\
    \   $ encrypt\n      (I) Cryptographically transform data to produce cipher text.\
    \ (See:\n      encryption. Compare: seal.)\n   $ encryption\n      1. (I) Cryptographic\
    \ transformation of data (called \"plain text\")\n      into a different form\
    \ (called \"cipher text\") that conceals the\n      data's original meaning and\
    \ prevents the original form from being\n      used. The corresponding reverse\
    \ process is \"decryption\", a\n      transformation that restores encrypted data\
    \ to its original form.\n      (See: cryptography.)\n      2. (O) \"The cryptographic\
    \ transformation of data to produce\n      ciphertext.\" [I7498-2]\n      Usage:\
    \ For this concept, IDOCs SHOULD use the verb \"to encrypt\"\n      (and related\
    \ variations: encryption, decrypt, and decryption).\n      However, because of\
    \ cultural biases involving human burial, some\n      international documents\
    \ (particularly ISO and CCITT standards)\n      avoid \"to encrypt\" and instead\
    \ use the verb \"to encipher\" (and\n      related variations: encipherment, decipher,\
    \ decipherment).\n      Tutorial: Usually, the plaintext input to an encryption\
    \ operation\n      is clear text. But in some cases, the plain text may be cipher\n\
    \      text that was output from another encryption operation. (See:\n      superencryption.)\n\
    \      Encryption and decryption involve a mathematical algorithm for\n      transforming\
    \ data. Besides the data to be transformed, the\n      algorithm has one or more\
    \ inputs that are control parameters: (a)\n      a key that varies the transformation\
    \ and, in some cases, (b) an IV\n      that establishes the starting state of\
    \ the algorithm.\n   $ encryption certificate\n      (I) A public-key certificate\
    \ that contains a public key that is\n      intended to be used for encrypting\
    \ data, rather than for verifying\n      digital signatures or performing other\
    \ cryptographic functions.\n      Tutorial: A v3 X.509 public-key certificate\
    \ may have a \"keyUsage\"\n      extension that indicates the purpose for which\
    \ the certified\n      public key is intended. (See: certificate profile.)\n \
    \  $ end cryptographic unit (ECU)\n      1. (N) Final destination device into\
    \ which a key is loaded for\n      operational use.\n      2. (N) A device that\
    \ (a) performs cryptographic functions, (b)\n      typically is part of a larger\
    \ system for which the device provides\n      security services, and (c), from\
    \ the viewpoint of a supporting\n      security infrastructure such as a key management\
    \ system, is the\n      lowest level of identifiable component with which a management\n\
    \      transaction can be conducted\n   $ end entity\n      1. (I) A system entity\
    \ that is the subject of a public-key\n      certificate and that is using, or\
    \ is permitted and able to use,\n      the matching private key only for purposes\
    \ other than signing a\n      digital certificate; i.e., an entity that is not\
    \ a CA.\n      2. (O) \"A certificate subject [that] uses its public [sic] key\
    \ for\n      purposes other than signing certificates.\" [X509]\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use definition 2, which is\n      misleading and\
    \ incomplete. First, that definition should have said\n      \"private key\" rather\
    \ than \"public key\" because certificates are\n      not usefully signed with\
    \ a public key. Second, the X.509\n      definition is ambiguous regarding whether\
    \ an end entity may or may\n      not use the private key to sign a certificate,\
    \ i.e., whether the\n      subject may be a CA. The intent of X.509's authors\
    \ was that an end\n      entity certificate is not valid for use in verifying\
    \ a signature\n      on an X.509 certificate or X.509 CRL. Thus, it would have\
    \ been\n      better for the X.509 definition to have said \"only for purposes\n\
    \      other than signing certificates\".\n      Usage: Despite the problems in\
    \ the X.509 definition, the term\n      itself is useful in describing applications\
    \ of asymmetric\n      cryptography. The way the term is used in X.509 implies\
    \ that it\n      was meant to be defined, as we have done here, relative to roles\n\
    \      that an entity (which is associated with an OSI end system) is\n      playing\
    \ or is permitted to play in applications of asymmetric\n      cryptography other\
    \ than the PKI that supports applications.\n      Tutorial: Whether a subject\
    \ can play both CA and non-CA roles,\n      with either the same or different\
    \ certificates, is a matter of\n      policy. (See: CPS.) A v3 X.509 public-key\
    \ certificate may have a\n      \"basicConstraints\" extension containing a \"\
    cA\" value that\n      specifically \"indicates whether or not the public key\
    \ may be used\n      to verify certificate signatures\". (See: certificate profile.)\n\
    \   $ end system\n      (N) /OSIRM/ A computer that implements all seven layers\
    \ of the\n      OSIRM and may attach to a subnetwork. Usage: In the IPS context,\n\
    \      an end system is called a \"host\".\n   $ end-to-end encryption\n     \
    \ (I) Continuous protection of data that flows between two points in\n      a\
    \ network, effected by encrypting data when it leaves its source,\n      keeping\
    \ it encrypted while it passes through any intermediate\n      computers (such\
    \ as routers), and decrypting it only when it\n      arrives at the intended final\
    \ destination. (See: wiretapping.\n      Compare: link encryption.)\n      Examples:\
    \ A few are BLACKER, CANEWARE, IPLI, IPsec, PLI, SDNS,\n      SILS, SSH, SSL,\
    \ TLS.\n      Tutorial: When two points are separated by multiple communication\n\
    \      links that are connected by one or more intermediate relays, end-\n   \
    \   to-end encryption enables the source and destination systems to\n      protect\
    \ their communications without depending on the intermediate\n      systems to\
    \ provide the protection.\n   $ end user\n      1. (I) /information system/ A\
    \ system entity, usually a human\n      individual, that makes use of system resources,\
    \ primarily for\n      application purposes as opposed to system management purposes.\n\
    \      2. (D) /PKI/ Synonym for \"end entity\".\n      Deprecated Definition:\
    \ IDOCs SHOULD NOT use \"end user\" as a\n      synonym for \"end entity\", because\
    \ that would mix concepts in a\n      potentially misleading way.\n   $ endorsed-for-unclassified\
    \ cryptographic item (EUCI)\n      (O) /U.S. Government/ \"Unclassified cryptographic\
    \ equipment that\n      embodies a U.S. Government classified cryptographic logic\
    \ and is\n      endorsed by NSA for the protection of national security\n    \
    \  information.\" [C4009] (Compare: CCI, type 2 product.)\n   $ entity\n     \
    \ See: system entity.\n   $ entrapment\n      (I) \"The deliberate planting of\
    \ apparent flaws in a system for the\n      purpose of detecting attempted penetrations\
    \ or confusing an\n      intruder about which flaws to exploit.\" [FP039] (See:\
    \ honey pot.)\n   $ entropy\n      1. (I) An information-theoretic measure (usually\
    \ stated as a\n      number of bits) of the amount of uncertainty that an attacker\n\
    \      faces to determine the value of a secret. [SP63] (See: strength.)\n   \
    \   Example: If a password is said to contain at least 20 bits of\n      entropy,\
    \ that means that it must be as hard to find the password\n      as to guess a\
    \ 20-bit random number.\n      2. (I) An information-theoretic measure (usually\
    \ stated as a\n      number of bits) of the amount of information in a message;\
    \ i.e.,\n      the minimum number of bits needed to encode all possible meanings\n\
    \      of that message. [Schn] (See: uncertainty.)\n   $ ephemeral\n      (I)\
    \ /adjective/ Refers to a cryptographic key or other\n      cryptographic parameter\
    \ or data object that is short-lived,\n      temporary, or used one time. (See:\
    \ session key. Compare: static.)\n   $ erase\n      1. (I) Delete stored data.\
    \ (See: sanitize, zeroize.)\n      2. (O) /U.S. Government/ Delete magnetically\
    \ stored data in such a\n      way that the data cannot be recovered by ordinary\
    \ means, but might\n      be recoverable by laboratory methods. [C4009] (Compare:\
    \ /U.S.\n      Government/ purge.)\n   $ error detection code\n      (I) A checksum\
    \ designed to detect, but not correct, accidental\n      (i.e., unintentional)\
    \ changes in data.\n   $ Escrowed Encryption Standard (EES)\n      (N) A U.S.\
    \ Government standard [FP185] that specifies how to use a\n      symmetric encryption\
    \ algorithm (SKIPJACK) and create a Law\n      Enforcement Access Field (LEAF)\
    \ for implementing part of a key\n      escrow system that enables decryption\
    \ of telecommunications when\n      interception is lawfully authorized.\n   \
    \   Tutorial: Both SKIPJACK and the LEAF are intended for use in\n      equipment\
    \ used to encrypt and decrypt sensitive, unclassified,\n      telecommunications\
    \ data.\n   $ ESP\n      (I) See: Encapsulating Security Payload.\n   $ Estelle\n\
    \      (N) A language (ISO 9074-1989) for formal specification of\n      computer\
    \ network protocols.\n   $ ETSI\n      (N) See: European Telecommunication Standards\
    \ Institute.\n   $ EUCI\n      (O) See: endorsed-for-unclassified cryptographic\
    \ item.\n   $ European Telecommunication Standards Institute (ETSI)\n      (N)\
    \ An independent, non-profit organization, based in France, that\n      is officially\
    \ recognized by the European Commission and\n      responsible for standardization\
    \ of information and communication\n      technologies within Europe.\n      Tutorial:\
    \ ETSI maintains the standards for a number of security\n      algorithms, including\
    \ encryption algorithms for mobile telephone\n      systems in Europe.\n   $ evaluated\
    \ system\n      (I) A system that has been evaluated against security criteria\n\
    \      (for example, against the TCSEC or against a profile based on the\n   \
    \   Common Criteria).\n   $ evaluation\n      (I) Assessment of an information\
    \ system against defined security\n      criteria (for example, against the TCSEC\
    \ or against a profile\n      based on the Common Criteria). (Compare: certification.)\n\
    \   $ evaluation assurance level (EAL)\n      (N) A predefined package of assurance\
    \ components that represents a\n      point on the Common Criteria's scale for\
    \ rating confidence in the\n      security of information technology products\
    \ and systems.\n      Tutorial: The Common Criteria defines a scale of seven,\n\
    \      hierarchically ordered EALs for rating a TOE. From highest to\n      lowest,\
    \ they are as follows:\n      -  EAL7. Formally verified design and tested.\n\
    \      -  EAL6. Semiformally verified design and tested.\n      -  EAL5. Semiformally\
    \ designed and tested.\n      -  EAL4. Methodically designed, tested, and reviewed.\n\
    \      -  EAL3. Methodically tested and checked.\n      -  EAL2. Structurally\
    \ tested.\n      -  EAL1. Functionally tested.\n      An EAL is a consistent,\
    \ baseline set of requirements. The increase\n      in assurance from EAL to EAL\
    \ is accomplished by substituting\n      higher assurance components (i.e., criteria\
    \ of increasing rigor,\n      scope, or depth) from seven assurance classes: (a)\
    \ configuration\n      management, (b) delivery and operation, (c) development,\
    \ (d)\n      guidance documents, (e) lifecycle support, (f) tests, and (g)\n \
    \     vulnerability assessment.\n      The EALs were developed with the goal of\
    \ preserving concepts of\n      assurance that were adopted from earlier criteria,\
    \ so that results\n      of previous evaluations would remain relevant. For example,\
    \ EALs\n      levels 2-7 are generally equivalent to the assurance portions of\n\
    \      the TCSEC C2-A1 scale. However, this equivalency should be used\n     \
    \ with caution. The levels do not derive assurance in the same\n      manner,\
    \ and exact mappings do not exist.\n   $ expire\n      (I) /credential/ Cease\
    \ to be valid (i.e., change from being valid\n      to being invalid) because\
    \ its assigned lifetime has been exceeded.\n      (See: certificate expiration.)\n\
    \   $ exposure\n      (I) A type of threat action whereby sensitive data is directly\n\
    \      released to an unauthorized entity. (See: unauthorized\n      disclosure.)\n\
    \      Usage: This type of threat action includes the following subtypes:\n  \
    \    -  \"Deliberate Exposure\": Intentional release of sensitive data to\n  \
    \       an unauthorized entity.\n      -  \"Scavenging\": Searching through data\
    \ residue in a system to\n         gain unauthorized knowledge of sensitive data.\n\
    \      -  \"Human error\": /exposure/ Human action or inaction that\n        \
    \ unintentionally results in an entity gaining unauthorized\n         knowledge\
    \ of sensitive data. (Compare: corruption,\n         incapacitation.)\n      -\
    \  \"Hardware or software error\": /exposure/ System failure that\n         unintentionally\
    \ results in an entity gaining unauthorized\n         knowledge of sensitive data.\
    \ (Compare: corruption,\n         incapacitation.)\n   $ Extended Security Option\n\
    \      (I) See: secondary definition under \"IPSO\".\n   $ Extensible Authentication\
    \ Protocol (EAP)\n      (I) An extension framework for PPP that supports multiple,\n\
    \      optional authentication mechanisms, including cleartext passwords,\n  \
    \    challenge-response, and arbitrary dialog sequences. [R3748]\n      (Compare:\
    \ GSS-API, SASL.)\n      Tutorial: EAP typically runs directly over IPS data link\
    \ protocols\n      or OSIRM Layer 2 protocols, i.e., without requiring IP.\n \
    \     Originally, EAP was developed for use in PPP, by a host or router\n    \
    \  that connects to a network server via switched circuits or dial-up\n      lines.\
    \ Today, EAP's domain of applicability includes other areas\n      of network\
    \ access control; it is used in wired and wireless LANs\n      with IEEE 802.1X,\
    \ and in IPsec with IKEv2. EAP is conceptually\n      related to other authentication\
    \ mechanism frameworks, such as SASL\n      and GSS-API.\n   $ Extensible Markup\
    \ Language (XML)\n      (N) A version of Standard Generalized Markup Language\
    \ (ISO 8879)\n      that separately represents a document's content and its structure.\n\
    \      XML was designed by W3C for use on the World Wide Web.\n   $ extension\n\
    \      (I) /protocol/ A data item or a mechanism that is defined in a\n      protocol\
    \ to extend the protocol's basic or original functionality.\n      Tutorial: Many\
    \ protocols have extension mechanisms, and the use of\n      these extension is\
    \ usually optional. IP and X.509 are two examples\n      of protocols that have\
    \ optional extensions. In IP version 4,\n      extensions are called \"options\"\
    , and some of the options have\n      security purposes (see: IPSO).\n      In\
    \ X.509, certificate and CRL formats can be extended to provide\n      methods\
    \ for associating additional attributes with subjects and\n      public keys and\
    \ for managing a certification hierarchy:\n      -  A \"certificate extension\"\
    : X.509 defines standard extensions\n         that may be included in v3 certificates\
    \ to provide additional\n         key and security policy information, subject\
    \ and issuer\n         attributes, and certification path constraints.\n     \
    \ -  A \"CRL extension\": X.509 defines extensions that may be\n         included\
    \ in v2 CRLs to provide additional issuer key and name\n         information,\
    \ revocation reasons and constraints, and\n         information about distribution\
    \ points and delta CRLs.\n      -  A \"private extension\": Additional extensions,\
    \ each named by an\n         OID, can be locally defined as needed by applications\
    \ or\n         communities. (See: Authority Information Access extension, SET\n\
    \         private extensions.)\n   $ external controls\n      (I) /COMPUSEC/ Refers\
    \ to administrative security, personnel\n      security, and physical security.\
    \ (Compare: internal controls.)\n   $ extranet\n      (I) A computer network that\
    \ an organization uses for application\n      data traffic between the organization\
    \ and its business partners.\n      (Compare: intranet.)\n      Tutorial: An extranet\
    \ can be implemented securely, either on the\n      Internet or using Internet\
    \ technology, by constructing the\n      extranet as a VPN.\n   $ extraction resistance\n\
    \      (O) Ability of cryptographic equipment to resist efforts to\n      extract\
    \ keying material directly from the equipment (as opposed to\n      gaining knowledge\
    \ of keying material by cryptanalysis). [C4009]\n   $ extrusion detection\n  \
    \    (I) Monitoring for unauthorized transfers of sensitive information\n    \
    \  and other communications that originate inside a system's security\n      perimeter\
    \ and are directed toward the outside; i.e., roughly the\n      opposite of \"\
    intrusion detection\".\n   $ fail-safe\n      1. (I) Synonym for \"fail-secure\"\
    .\n      2. (I) A mode of termination of system functions that prevents\n    \
    \  damage to specified system resources and system entities (i.e.,\n      specified\
    \ data, property, and life) when a failure occurs or is\n      detected in the\
    \ system (but the failure still might cause a\n      security compromise). (See:\
    \ failure control.)\n      Tutorial: Definitions 1 and 2 are opposing design alternatives.\n\
    \      Therefore, IDOCs SHOULD NOT use this term without providing a\n      definition\
    \ for it. If definition 1 is intended, IDOCs can avoid\n      ambiguity by using\
    \ \"fail-secure\" instead.\n   $ fail-secure\n      (I) A mode of termination\
    \ of system functions that prevents loss\n      of secure state when a failure\
    \ occurs or is detected in the system\n      (but the failure still might cause\
    \ damage to some system resource\n      or system entity). (See: failure control.\
    \ Compare: fail-safe.)\n   $ fail-soft\n      (I) Selective termination of affected,\
    \ non-essential system\n      functions when a failure occurs or is detected in\
    \ the system.\n      (See: failure control.)\n   $ failure control\n      (I)\
    \ A methodology used to provide fail-safe, fail-secure or fail-\n      soft termination\
    \ and recovery of system functions. [FP039]\n   $ fairness\n      (I) A property\
    \ of an access protocol for a system resource whereby\n      the resource is made\
    \ equitably or impartially available to all\n      eligible users. (RFC 3753)\n\
    \      Tutorial: Fairness can be used to defend against some types of\n      denial-of-service\
    \ attacks on a system connected to a network.\n      However, this technique assumes\
    \ that the system can properly\n      receive and process inputs from the network.\
    \ Therefore, the\n      technique can mitigate flooding but is ineffective against\n\
    \      jamming.\n   $ falsification\n      (I) A type of threat action whereby\
    \ false data deceives an\n      authorized entity. (See: active wiretapping, deception.)\n\
    \      Usage: This type of threat action includes the following subtypes:\n  \
    \    -  \"Substitution\": Altering or replacing valid data with false\n      \
    \   data that serves to deceive an authorized entity.\n      -  \"Insertion\"\
    : Introducing false data that serves to deceive an\n         authorized entity.\n\
    \   $ fault tree\n      (I) A branching, hierarchical data structure that is used\
    \ to\n      represent events and to determine the various combinations of\n  \
    \    component failures and human acts that could result in a specified\n    \
    \  undesirable system event. (See: attack tree, flaw hypothesis\n      methodology.)\n\
    \      Tutorial: \"Fault-tree analysis\" is a technique in which an\n      undesired\
    \ state of a system is specified and the system is studied\n      in the context\
    \ of its environment and operation to find all\n      credible ways in which the\
    \ event could occur. The specified fault\n      event is represented as the root\
    \ of the tree. The remainder of the\n      tree represents AND or OR combinations\
    \ of subevents, and\n      sequential combinations of subevents, that could cause\
    \ the root\n      event to occur. The main purpose of a fault-tree analysis is\
    \ to\n      calculate the probability of the root event, using statistics or\n\
    \      other analytical methods and incorporating actual or predicted\n      quantitative\
    \ reliability and maintainability data. When the root\n      event is a security\
    \ violation, and some of the subevents are\n      deliberate acts intended to\
    \ achieve the root event, then the fault\n      tree is an attack tree.\n   $\
    \ FEAL\n      (O) A family of symmetric block ciphers that was developed in\n\
    \      Japan; uses a 64-bit block, keys of either 64 or 128 bits, and a\n    \
    \  variable number of rounds; and has been successfully attacked by\n      cryptanalysts.\
    \ [Schn]\n   $ Federal Information Processing Standards (FIPS)\n      (N) The\
    \ Federal Information Processing Standards Publication (FIPS\n      PUB) series\
    \ issued by NIST under the provisions of Section 111(d)\n      of the Federal\
    \ Property and Administrative Services Act of 1949 as\n      amended by the Computer\
    \ Security Act of 1987 (Public Law 100-235)\n      as technical guidelines for\
    \ U.S. Government procurements of\n      information processing system equipment\
    \ and services. (See:\n      \"[FPxxx]\" items in Section 7, Informative References.)\n\
    \   $ Federal Public-key Infrastructure (FPKI)\n      (O) A PKI being planned\
    \ to establish facilities, specifications,\n      and policies needed by the U.S.\
    \ Government to use public-key\n      certificates in systems involving unclassified\
    \ but sensitive\n      applications and interactions between Federal agencies\
    \ as well as\n      with entities of state and local governments, the business\n\
    \      community, and the public. [FPKI]\n   $ Federal Standard 1027\n      (N)\
    \ An U.S. Government document defining emanation, anti-tamper,\n      security\
    \ fault analysis, and manual key management criteria for\n      DES encryption\
    \ devices, primary for OSIRM Layer 2. Was renamed\n      \"FIPS PUB 140\" when\
    \ responsibility for protecting unclassified,\n      sensitive information was\
    \ transferred from NSA to NIST, and has\n      since been superseded by newer\
    \ versions of that standard [FP140].\n   $ File Transfer Protocol (FTP)\n    \
    \  (I) A TCP-based, Application-Layer, Internet Standard protocol\n      (RFC\
    \ 959) for moving data files from one computer to another.\n   $ fill device\n\
    \      (N) /COMSEC/ A device used to transfer or store keying material in\n  \
    \    electronic form or to insert keying material into cryptographic\n      equipment.\n\
    \   $ filter\n      1. (I) /noun/ Synonym for \"guard\". (Compare: content filter,\n\
    \      filtering router.)\n      2. (I) /verb/ To process a flow of data and selectively\
    \ block\n      passage or permit passage of individual data items according to\
    \ a\n      security policy.\n   $ filtering router\n      (I) An internetwork\
    \ router that selectively prevents the passage\n      of data packets according\
    \ to a security policy. (See: guard.)\n      Tutorial: A router usually has two\
    \ or more physical connections to\n      networks or other systems; and when the\
    \ router receives a packet\n      on one of those connections, it forwards the\
    \ packet on a second\n      connection. A filtering router does the same; but\
    \ it first\n      decides, according to some security policy, whether the packet\n\
    \      should be forwarded at all. The policy is implemented by rules\n      (packet\
    \ filters) loaded into the router. The rules mostly involve\n      values of data\
    \ packet control fields (especially IP source and\n      destination addresses\
    \ and TCP port numbers) [R2179]. A filtering\n      router may be used alone as\
    \ a simple firewall or be used as a\n      component of a more complex firewall.\n\
    \   $ financial institution\n      (N) \"An establishment responsible for facilitating\
    \ customer-\n      initiated transactions or transmission of funds for the extension\n\
    \      of credit or the custody, loan, exchange, or issuance of money.\"\n   \
    \   [SET2]\n   $ fingerprint\n      1. (I) A pattern of curves formed by the ridges\
    \ on a fingertip.\n      (See: biometric authentication. Compare: thumbprint.)\n\
    \      2. (D) /PGP/ A hash result (\"key fingerprint\") used to\n      authenticate\
    \ a public key or other data. [PGP]\n      Deprecated Definition: IDOCs SHOULD\
    \ NOT use this term with\n      definition 2, and SHOULD NOT use this term as\
    \ a synonym for \"hash\n      result\" of *any* kind. Either use would mix concepts\
    \ in a\n      potentially misleading way.\n   $ FIPS\n      (N) See: Federal Information\
    \ Processing Standards.\n   $ FIPS PUB 140\n      (N) The U.S. Government standard\
    \ [FP140] for security requirements\n      to be met by a cryptographic module\
    \ when the module is used to\n      protect unclassified information in computer\
    \ and communication\n      systems. (See: Common Criteria, FIPS, Federal Standard\
    \ 1027.)\n      Tutorial: The standard specifies four increasing levels (from\n\
    \      \"Level 1\" to \"Level 4\") of requirements to cover a wide range of\n\
    \      potential applications and environments. The requirements address\n   \
    \   basic design and documentation, module interfaces, authorized\n      roles\
    \ and services, physical security, software security,\n      operating system\
    \ security, key management, cryptographic\n      algorithms, electromagnetic interference\
    \ and electromagnetic\n      compatibility (EMI/EMC), and self-testing. NIST and\
    \ the Canadian\n      Communication Security Establishment jointly certify modules.\n\
    \   $ FIREFLY\n      (O) /U.S. Government/ \"Key management protocol based on\
    \ public-key\n      cryptography.\" [C4009]\n   $ firewall\n      1. (I) An internetwork\
    \ gateway that restricts data communication\n      traffic to and from one of\
    \ the connected networks (the one said to\n      be \"inside\" the firewall) and\
    \ thus protects that network's system\n      resources against threats from the\
    \ other network (the one that is\n      said to be \"outside\" the firewall).\
    \ (See: guard, security\n      gateway.)\n      2. (O) A device or system that\
    \ controls the flow of traffic\n      between networks using differing security\
    \ postures. [SP41]\n      Tutorial: A firewall typically protects a smaller, secure\
    \ network\n      (such as a corporate LAN, or even just one host) from a larger\n\
    \      network (such as the Internet). The firewall is installed at the\n    \
    \  point where the networks connect, and the firewall applies policy\n      rules\
    \ to control traffic that flows in and out of the protected\n      network.\n\
    \      A firewall is not always a single computer. For example, a\n      firewall\
    \ may consist of a pair of filtering routers and one or\n      more proxy servers\
    \ running on one or more bastion hosts, all\n      connected to a small, dedicated\
    \ LAN (see: buffer zone) between the\n      two routers. The external router blocks\
    \ attacks that use IP to\n      break security (IP address spoofing, source routing,\
    \ packet\n      fragments), while proxy servers block attacks that would exploit\
    \ a\n      vulnerability in a higher-layer protocol or service. The internal\n\
    \      router blocks traffic from leaving the protected network except\n     \
    \ through the proxy servers. The difficult part is defining criteria\n      by\
    \ which packets are denied passage through the firewall, because\n      a firewall\
    \ not only needs to keep unauthorized traffic (i.e.,\n      intruders) out, but\
    \ usually also needs to let authorized traffic\n      pass both in and out.\n\
    \   $ firmware\n      (I) Computer programs and data stored in hardware -- typically\
    \ in\n      read-only memory (ROM) or programmable read-only memory (PROM) --\n\
    \      such that the programs and data cannot be dynamically written or\n    \
    \  modified during execution of the programs. (See: hardware,\n      software.)\n\
    \   $ FIRST\n      (N) See: Forum of Incident Response and Security Teams.\n \
    \  $ flaw\n      1. (I) An error in the design, implementation, or operation of\
    \ an\n      information system. A flaw may result in a vulnerability.\n      (Compare:\
    \ vulnerability.)\n      2. (D) \"An error of commission, omission, or oversight\
    \ in a system\n      that allows protection mechanisms to be bypassed.\" [NCSSG]\n\
    \      (Compare: vulnerability. See: brain-damaged.)\n      Deprecated Definition:\
    \ IDOCs SHOULD NOT use this term with\n      definition 2; not every flaw is a\
    \ vulnerability.\n   $ flaw hypothesis methodology\n      (I) An evaluation or\
    \ attack technique in which specifications and\n      documentation for a system\
    \ are analyzed to hypothesize flaws in\n      the system. The list of hypothetical\
    \ flaws is prioritized on the\n      basis of the estimated probability that a\
    \ flaw exists and,\n      assuming it does, on the ease of exploiting it and the\
    \ extent of\n      control or compromise it would provide. The prioritized list\
    \ is\n      used to direct a penetration test or attack against the system.\n\
    \      [NCS04] (See: fault tree, flaw.)\n   $ flooding\n      1. (I) An attack\
    \ that attempts to cause a failure in a system by\n      providing more input\
    \ than the system can process properly. (See:\n      denial of service, fairness.\
    \ Compare: jamming.)\n      Tutorial: Flooding uses \"overload\" as a type of\
    \ \"obstruction\"\n      intended to cause \"disruption\".\n      2. (I) The process\
    \ of delivering data or control messages to every\n      node of a network. (RFC\
    \ 3753)\n   $ flow analysis\n      (I) An analysis performed on a nonprocedural,\
    \ formal, system\n      specification that locates potential flows of information\
    \ between\n      system variables. By assigning security levels to the variables,\n\
    \      the analysis can find some types of covert channels. [Huff]\n   $ flow\
    \ control\n      1. (I) /data security/ A procedure or technique to ensure that\n\
    \      information transfers within a system are not made from one\n      security\
    \ level to another security level, and especially not from\n      a higher level\
    \ to a lower level. [Denns] (See: covert channel,\n      confinement property,\
    \ information flow policy, simple security\n      property.)\n      2. (O) /data\
    \ security/ \"A concept requiring that information\n      transfers within a system\
    \ be controlled so that information in\n      certain types of objects cannot,\
    \ via any channel within the\n      system, flow to certain other types of objects.\"\
    \ [NCSSG]\n   $ For Official Use Only (FOUO)\n      (O) /U.S. DoD/ A U.S. Government\
    \ designation for information that\n      has not been given a security classification\
    \ pursuant to the\n      criteria of an Executive Order dealing with national\
    \ security, but\n      which may be withheld from the public because disclosure\
    \ would\n      cause a foreseeable harm to an interest protected by one of the\n\
    \      exemptions stated in the Freedom of Information Act (Section 552\n    \
    \  of title 5, United States Code). (See: security label, security\n      marking.\
    \ Compare: classified.)\n   $ formal\n      (I) Expressed in a restricted syntax\
    \ language with defined\n      semantics based on well-established mathematical\
    \ concepts. [CCIB]\n      (Compare: informal, semiformal.)\n   $ formal access\
    \ approval\n      (O) /U.S. Government/ Documented approval by a data owner to\
    \ allow\n      access to a particular category of information in a system. (See:\n\
    \      category.)\n   $ Formal Development Methodology\n      (O) See: Ina Jo.\n\
    \   $ formal model\n      (I) A security model that is formal. Example: Bell-LaPadula\
    \ model.\n      [Land] (See: formal, security model.)\n   $ formal proof\n   \
    \   (I) \"A complete and convincing mathematical argument, presenting\n      the\
    \ full logical justification for each step in the proof, for the\n      truth\
    \ of a theorem or set of theorems.\" [NCSSG]\n   $ formal specification\n    \
    \  (I) A precise description of the (intended) behavior of a system,\n      usually\
    \ written in a mathematical language, sometimes for the\n      purpose of supporting\
    \ formal verification through a correctness\n      proof. [Huff] (See: Affirm,\
    \ Gypsy, HDM, Ina Jo.) (See: formal.)\n      Tutorial: A formal specification\
    \ can be written at any level of\n      detail but is usually a top-level specification.\n\
    \   $ formal top-level specification\n      (I) \"A top-level specification that\
    \ is written in a formal\n      mathematical language to allow theorems showing\
    \ the correspondence\n      of the system specification to its formal requirements\
    \ to be\n      hypothesized and formally proven.\" [NCS04] (See: formal\n    \
    \  specification.)\n   $ formulary\n      (I) A technique for enabling a decision\
    \ to grant or deny access to\n      be made dynamically at the time the access\
    \ is attempted, rather\n      than earlier when an access control list or ticket\
    \ is created.\n   $ FORTEZZA(trademark)\n      (O) A registered trademark of NSA,\
    \ used for a family of\n      interoperable security products that implement a\
    \ NIST/NSA-approved\n      suite of cryptographic algorithms for digital signature,\
    \ hash,\n      encryption, and key exchange. The products include a PC card\n\
    \      (which contains a CAPSTONE chip), and compatible serial port\n      modems,\
    \ server boards, and software implementations.\n   $ Forum of Incident Response\
    \ and Security Teams (FIRST)\n      (N) An international consortium of CSIRTs\
    \ (e.g., CIAC) that work\n      together to handle computer security incidents\
    \ and promote\n      preventive activities. (See: CSIRT, security incident.)\n\
    \      Tutorial: FIRST was founded in 1990 and, as of July 2004, had more\n  \
    \    than 100 members spanning the globe. Its mission includes:\n      -  Provide\
    \ members with technical information, tools, methods,\n         assistance, and\
    \ guidance.\n      -  Coordinate proactive liaison activities and analytical support.\n\
    \      -  Encourage development of quality products and services.\n      -  Improve\
    \ national and international information security for\n         governments, private\
    \ industry, academia, and the individual.\n      -  Enhance the image and status\
    \ of the CSIRT community.\n   $ forward secrecy\n      (I) See: perfect forward\
    \ secrecy.\n   $ FOUO\n      (O) See: For Official Use Only.\n   $ FPKI\n    \
    \  (O) See: Federal Public-Key Infrastructure.\n   $ fraggle attack\n      (D)\
    \ /slang/ A synonym for \"smurf attack\".\n      Deprecated Term: It is likely\
    \ that other cultures use different\n      metaphors for this concept. Therefore,\
    \ to avoid international\n      misunderstanding, IDOCs SHOULD NOT use this term.\n\
    \      Derivation: The Fraggles are a fictional race of small humanoids\n    \
    \  (represented as hand puppets in a children's television series,\n      \"Fraggle\
    \ Rock\") that live underground.\n   $ frequency hopping\n      (N) Repeated switching\
    \ of frequencies during radio transmission\n      according to a specified algorithm.\
    \ [C4009] (See: spread\n      spectrum.)\n      Tutorial: Frequency hopping is\
    \ a TRANSEC technique to minimize the\n      potential for unauthorized interception\
    \ or jamming.\n   $ fresh\n      (I) Recently generated; not replayed from some\
    \ earlier interaction\n      of the protocol.\n      Usage: Describes data contained\
    \ in a PDU that is received and\n      processed for the first time. (See: liveness,\
    \ nonce, replay\n      attack.)\n   $ FTP\n      (I) See: File Transfer Protocol.\n\
    \   $ gateway\n      (I) An intermediate system (interface, relay) that attaches\
    \ to two\n      (or more) computer networks that have similar functions but\n\
    \      dissimilar implementations and that enables either one-way or two-\n  \
    \    way communication between the networks. (See: bridge, firewall,\n      guard,\
    \ internetwork, proxy server, router, and subnetwork.)\n      Tutorial: The networks\
    \ may differ in any of several aspects,\n      including protocols and security\
    \ mechanisms. When two computer\n      networks differ in the protocol by which\
    \ they offer service to\n      hosts, a gateway may translate one protocol into\
    \ the other or\n      otherwise facilitate interoperation of hosts (see: Internet\n\
    \      Protocol). In theory, gateways between computer networks are\n      conceivable\
    \ at any OSIRM layer. In practice, they usually operate\n      at OSIRM Layer\
    \ 2 (see: bridge), 3 (see: router), or 7 (see: proxy\n      server).\n   $ GCA\n\
    \      (O) See: geopolitical certificate authority.\n   $ GDOI\n      (O) See:\
    \ Group Domain of Interpretation.\n   $ GeldKarte\n      (O) A smartcard-based,\
    \ electronic money system that is maintained\n      by the German banking industry,\
    \ incorporates cryptography, and can\n      be used to make payments via the Internet.\
    \ (See: IOTP.)\n   $ GeneralizedTime\n      (N) The ASN.1 data type \"GeneralizedTime\"\
    \ (ISO 8601) contains a\n      calendar date (YYYYMMDD) and a time of day, which\
    \ is either (a)\n      the local time, (b) the Coordinated Universal Time, or\
    \ (c) both\n      the local time and an offset that enables Coordinated Universal\n\
    \      Time to be calculated. (See: Coordinated Universal Time. Compare:\n   \
    \   UTCTime.)\n   $ Generic Security Service Application Program Interface (GSS-API)\n\
    \      (I) An Internet Standard protocol [R2743] that specifies calling\n    \
    \  conventions by which an application (typically another\n      communication\
    \ protocol) can obtain authentication, integrity, and\n      confidentiality security\
    \ services independently of the underlying\n      security mechanisms and technologies,\
    \ thus enabling the\n      application source code to be ported to different environments.\n\
    \      (Compare: EAP, SASL.)\n      Tutorial: \"A GSS-API caller accepts tokens\
    \ provided to it by its\n      local GSS-API implementation and transfers the\
    \ tokens to a peer on\n      a remote system; that peer passes the received tokens\
    \ to its local\n      GSS-API implementation for processing. The security services\n\
    \      available through GSS-API in this fashion are implementable (and\n    \
    \  have been implemented) over a range of underlying mechanisms based\n      on\
    \ [symmetric] and [asymmetric cryptography].\" [R2743]\n   $ geopolitical certificate\
    \ authority (GCA)\n      (O) /SET/ In a SET certification hierarchy, an optional\
    \ level that\n      is certified by a BCA and that may certify cardholder CAs,\n\
    \      merchant CAs, and payment gateway CAs. Using GCAs enables a brand\n   \
    \   to distribute responsibility for managing certificates to\n      geographic\
    \ or political regions, so that brand policies can vary\n      between regions\
    \ as needed.\n   $ GIG\n      (O) See: Global Information Grid.\n   $ Global Information\
    \ Grid (GIG)\n      (O) /U.S. DoD/ The GIG is \"a globally interconnected, end-to-end\n\
    \      set of information capabilities, associated processes and\n      personnel\
    \ for collecting, processing, storing, disseminating, and\n      managing information\
    \ on demand to war fighters, policy makers, and\n      support personnel.\" [IATF]\
    \ Usage: Formerly referred to as the DII.\n   $ good engineering practice(s)\n\
    \      (N) A term used to specify or characterize design, implementation,\n  \
    \    installation, or operating practices for an information system,\n      when\
    \ a more explicit specification is not possible. Generally\n      understood to\
    \ refer to the state of the engineering art for\n      commercial systems that\
    \ have problems and solutions equivalent to\n      the system in question.\n \
    \  $ granularity\n      1. (N) /access control/ Relative fineness to which an\
    \ access\n      control mechanism can be adjusted.\n      2. (N) /data security/\
    \ \"The size of the smallest protectable unit\n      of information\" in a trusted\
    \ system. [Huff]\n   $ Green Book\n      (D) /slang/ Synonym for \"Defense Password\
    \ Management Guideline\"\n      [CSC2].\n      Deprecated Term: Except as an explanatory\
    \ appositive, IDOCs SHOULD\n      NOT use this term, regardless of the associated\
    \ definition.\n      Instead, use the full proper name of the document or, in\n\
    \      subsequent references, a conventional abbreviation. (See: Rainbow\n   \
    \   Series.)\n      Deprecated Usage: To improve international comprehensibility\
    \ of\n      Internet Standards and the Internet Standards Process, IDOCs\n   \
    \   SHOULD NOT use \"cute\" synonyms. No matter how clearly understood\n     \
    \ or popular a nickname may be in one community, it is likely to\n      cause\
    \ confusion or offense in others. For example, several other\n      information\
    \ system standards also are called \"the Green Book\"; the\n      following are\
    \ some examples:\n      -  Each volume of 1992 ITU-T (known at that time as CCITT)\n\
    \         standards.\n      -  \"PostScript Language Program Design\", Adobe Systems,\
    \ Addison-\n         Wesley, 1988.\n      -  IEEE 1003.1 POSIX Operating Systems\
    \ Interface.\n      -  \"Smalltalk-80: Bits of History, Words of Advice\", Glenn\n\
    \         Krasner, Addison-Wesley, 1983.\n      -  \"X/Open Compatibility Guide\"\
    .\n      -  A particular CD-ROM format developed by Phillips.\n   $ Group Domain\
    \ of Interpretation (GDOI)\n      (I) An ISAKMP/IKE domain of interpretation for\
    \ group key\n      management; i.e., a phase 2 protocol in ISAKMP. [R3547] (See:\n\
    \      secure multicast.)\n      Tutorial: In this group key management model\
    \ that extends the\n      ISAKMP standard, the protocol is run between a group\
    \ member and a\n      \"group controller/key server\", which establishes security\n\
    \      associations [R4301] among authorized group members. The GDOI\n      protocol\
    \ is itself protected by an ISAKMP phase 1 association.\n      For example, multicast\
    \ applications may use ESP to protect their\n      data traffic. GDOI carries\
    \ the needed security association\n      parameters for ESP. In this way, GDOI\
    \ supports multicast ESP with\n      group authentication of ESP packets using\
    \ a shared, group key.\n   $ group identity\n      (I) See: secondary definition\
    \ under \"identity\".\n   $ group security association\n      (I) \"A bundling\
    \ of [security associations] (SAs) that together\n      define how a group communicates\
    \ securely. The [group SA] may\n      include a registration protocol SA, a rekey\
    \ protocol SA, and one\n      or more data security protocol SAs.\" [R3740]\n\
    \   $ GSS-API\n      (I) See: Generic Security Service Application Program Interface.\n\
    \   $ guard\n      (I) A computer system that (a) acts as gateway between two\n\
    \      information systems operating under different security policies\n     \
    \ and (b) is trusted to mediate information data transfers between\n      the\
    \ two. (See: controlled interface, cross-domain solution,\n      domain, filter.\
    \ Compare: firewall.)\n      Usage: Frequently understood to mean that one system\
    \ is operating\n      at a higher security level than the other, and that the\
    \ gateway's\n      purpose is to prevent unauthorized disclosure of data from\
    \ the\n      higher system to the lower. However, the purpose might also be to\n\
    \      protect the data integrity, availability, or general system\n      integrity\
    \ of one system from threats posed by connecting to the\n      other system. The\
    \ mediation may be entirely automated or may\n      involve \"reliable human review\"\
    .\n   $ guest login\n      (I) See: anonymous login.\n   $ GULS\n      (I) Generic\
    \ Upper Layer Security service element (ISO 11586), a\n      five-part standard\
    \ for the exchange of security information and\n      security-transformation\
    \ functions that protect confidentiality and\n      integrity of application data.\n\
    \   $ Gypsy verification environment\n      (O) A methodology, language, and integrated\
    \ set of software tools\n      developed at the University of Texas for specifying,\
    \ coding, and\n      verifying software to produce correct and reliable programs.\n\
    \      [Cheh]\n   $ H field\n      (D) See: Deprecated Usage under \"Handling\
    \ Restrictions field\".\n   $ hack\n      1a. (I) /verb/ To work on something,\
    \ especially to program a\n      computer. (See: hacker.)\n      1b. (I) /verb/\
    \ To do some kind of mischief, especially to play a\n      prank on, or penetrate,\
    \ a system. (See: hacker, cracker.)\n      2. (I) /noun/ An item of completed\
    \ work, or a solution for a\n      problem, that is non-generalizable, i.e., is\
    \ very specific to the\n      application area or problem being solved.\n    \
    \  Tutorial: Often, the application area or problem involves computer\n      programming\
    \ or other use of a computer. Characterizing something\n      as a hack can be\
    \ a compliment, such as when the solution is\n      minimal and elegant; or it\
    \ can be derogatory, such as when the\n      solution fixes the problem but leaves\
    \ the system in an\n      unmaintainable state.\n      See [Raym] for several\
    \ other meanings of this term and also\n      definitions of several derivative\
    \ terms.\n   $ hacker\n      1. (I) Someone with a strong interest in computers,\
    \ who enjoys\n      learning about them, programming them, and experimenting and\n\
    \      otherwise working with them. (See: hack. Compare: adversary,\n      cracker,\
    \ intruder.)\n      Usage: This first definition is the original meaning of the\
    \ term\n      (circa 1960); it then had a neutral or positive connotation of\n\
    \      \"someone who figures things out and makes something cool happen\".\n \
    \     2. (O) \"An individual who spends an inordinate amount of time\n      working\
    \ on computer systems for other than professional purposes.\"\n      [NCSSG]\n\
    \      3. (D) Synonym for \"cracker\".\n      Deprecated Usage: Today, the term\
    \ is frequently (mis)used\n      (especially by journalists) with definition 3.\n\
    \   $ handle\n      1. (I) /verb/ Perform processing operations on data, such\
    \ as\n      receive and transmit, collect and disseminate, create and delete,\n\
    \      store and retrieve, read and write, and compare. (See: access.)\n     \
    \ 2. (I) /noun/ An online pseudonym, particularly one used by a\n      cracker;\
    \ derived from citizens' band radio culture.\n   $ handling restriction\n    \
    \  (I) A type of access control other than (a) the rule-based\n      protections\
    \ of mandatory access control and (b) the identity-based\n      protections of\
    \ discretionary access control; usually involves\n      administrative security.\n\
    \   $ Handling Restrictions field\n      (I) A 16-bit field that specifies a control\
    \ and release marking in\n      the security option (option type 130) of IP's\
    \ datagram header\n      format. The valid field values are alphanumeric digraphs\
    \ assigned\n      by the U.S. Government, as specified in RFC 791.\n      Deprecated\
    \ Abbreviation: IDOCs SHOULD NOT use the abbreviation \"H\n      field\" because\
    \ it is potentially ambiguous. Instead, use \"Handling\n      Restrictions field\"\
    .\n   $ handshake\n      (I) Protocol dialogue between two systems for identifying\
    \ and\n      authenticating themselves to each other, or for synchronizing\n \
    \     their operations with each other.\n   $ Handshake Protocol\n      (I) /TLS/\
    \ The TLS Handshake Protocol consists of three parts\n      (i.e., subprotocols)\
    \ that enable peer entities to agree upon\n      security parameters for the record\
    \ layer, authenticate themselves\n      to each other, instantiate negotiated\
    \ security parameters, and\n      report error conditions to each other. [R4346]\n\
    \   $ harden\n      (I) To protect a system by configuring it to operate in a\
    \ way that\n      eliminates or mitigates known vulnerabilities. Example: [RSCG].\n\
    \      (See: default account.)\n   $ hardware\n      (I) The material physical\
    \ components of an information system.\n      (See: firmware, software.)\n   $\
    \ hardware error\n      (I) /threat action/ See: secondary definitions under \"\
    corruption\",\n      \"exposure\", and \"incapacitation\".\n   $ hardware token\n\
    \      See: token.\n   $ hash code\n      (D) Synonym for \"hash result\" or \"\
    hash function\".\n      Deprecated Term: IDOCs SHOULD NOT use this term; it mixes\
    \ concepts\n      in a potentially misleading way. A hash result is not a \"code\"\
    ,\n      and a hash function does not \"encode\" in any sense defined by this\n\
    \      glossary. (See: hash value, message digest.)\n   $ hash function\n    \
    \  1. (I) A function H that maps an arbitrary, variable-length bit\n      string,\
    \ s, into a fixed-length string, h = H(s) (called the \"hash\n      result\").\
    \ For most computing applications, it is desirable that\n      given a string\
    \ s with H(s) = h, any change to s that creates a\n      different string s' will\
    \ result in an unpredictable hash result\n      H(s') that is, with high probability,\
    \ not equal to H(s).\n      2. (O) \"A (mathematical) function which maps values\
    \ from a large\n      (possibly very large) domain into a smaller range. A 'good'\
    \ hash\n      function is such that the results of applying the function to a\n\
    \      (large) set of values in the domain will be evenly distributed\n      (and\
    \ apparently at random) over the range.\" [X509]\n      Tutorial: A hash function\
    \ operates on variable-length input (e.g.,\n      a message or a file) and outputs\
    \ a fixed-length output, which\n      typically is much shorter than most input\
    \ values. If the algorithm\n      is \"good\" as described in the \"O\" definition,\
    \ then the hash\n      function may be a candidate for use in a security mechanism\
    \ to\n      detect accidental changes in data, but not necessarily for a\n   \
    \   mechanism to detect changes made by active wiretapping. (See:\n      Tutorial\
    \ under \"checksum\".)\n      Security mechanisms require a \"cryptographic hash\
    \ function\" (e.g.,\n      MD2, MD4, MD5, SHA-1, Snefru), i.e., a good hash function\
    \ that\n      also has the one-way property and one of the two collision-free\n\
    \      properties:\n      -  \"One-way property\": Given H and a hash result h\
    \ = H(s), it is\n         hard (i.e., computationally infeasible, \"impossible\"\
    ) to find\n         s. (Of course, given H and an input s, it must be relatively\n\
    \         easy to compute the hash result H(s).)\n      -  \"Weakly collision-free\
    \ property\": Given H and an input s, it is\n         hard (i.e., computationally\
    \ infeasible, \"impossible\") to find a\n         different input, s', such that\
    \ H(s) = H(s').\n      -  \"Strongly collision-free property\": Given H, it is\
    \ hard to find\n         any pair of inputs s and s' such that H(s) = H(s').\n\
    \      If H produces a hash result N bits long, then to find an s' where\n   \
    \   H(s') = H(s) for a specific given s, the amount of computation\n      required\
    \ is O(2**n); i.e., it is necessary to try on the order of\n      2 to the power\
    \ n values of s' before finding a collision. However,\n      to simply find any\
    \ pair of values s and s' that collide, the\n      amount of computation required\
    \ is only O(2**(n/2)); i.e., after\n      computing H(s) for 2 to the power n/2\
    \ randomly chosen values of s,\n      the probability is greater than 1/2 that\
    \ two of those values have\n      the same hash result. (See: birthday attack.)\n\
    \   $ hash result\n      1. (I) The output of a hash function. (See: hash code,\
    \ hash value.\n      Compare: hash value.)\n      2. (O) \"The output produced\
    \ by a hash function upon processing a\n      message\" (where \"message\" is\
    \ broadly defined as \"a digital\n      representation of data\"). [DSG]\n   \
    \   Usage: IDOCs SHOULD avoid the unusual usage of \"message\" that is\n     \
    \ seen in the \"O\" definition.\n   $ hash value\n      (D) Synonym for \"hash\
    \ result\".\n      Deprecated Term: IDOCs SHOULD NOT use this term for the output\
    \ of\n      a hash function; the term could easily be confused with \"hashed\n\
    \      value\", which means the input to a hash function. (See: hash code,\n \
    \     hash result, message digest.)\n   $ HDM\n      (O) See: Hierarchical Development\
    \ Methodology.\n   $ Hierarchical Development Methodology (HDM)\n      (O) A methodology,\
    \ language, and integrated set of software tools\n      developed at SRI International\
    \ for specifying, coding, and\n      verifying software to produce correct and\
    \ reliable programs.\n      [Cheh]\n   $ hierarchical PKI\n      (I) A PKI architecture\
    \ based on a certification hierarchy.\n      (Compare: mesh PKI, trust-file PKI.)\n\
    \   $ hierarchy management\n      (I) The process of generating configuration\
    \ data and issuing\n      public-key certificates to build and operate a certification\n\
    \      hierarchy. (See: certificate management.)\n   $ hierarchy of trust\n  \
    \    (D) Synonym for \"certification hierarchy\".\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term; it mixes concepts\n      in a potentially misleading\
    \ way. (See: certification hierarchy,\n      trust, web of trust.)\n   $ high-assurance\
    \ guard\n      (O) \"An oxymoron,\" said Lt. Gen. William H. Campbell, former\
    \ U.S.\n      Army chief information officer, speaking at an Armed Forces\n  \
    \    Communications and Electronics Association conference.\n      Usage: IDOCs\
    \ that use this term SHOULD state a definition for it\n      because the term\
    \ mixes concepts and could easily be misunderstood.\n   $ hijack attack\n    \
    \  (I) A form of active wiretapping in which the attacker seizes\n      control\
    \ of a previously established communication association.\n      (See: man-in-the-middle\
    \ attack, pagejacking, piggyback attack.)\n   $ HIPAA\n      (N) Health Information\
    \ Portability and Accountability Act of 1996,\n      a U.S. law (Public Law 104-191)\
    \ that is intended to protect the\n      privacy of patients' medical records\
    \ and other health information\n      in all forms, and mandates security for\
    \ that information,\n      including for its electronic storage and transmission.\n\
    \   $ HMAC\n      (I) A keyed hash [R2104] that can be based on any iterated\n\
    \      cryptographic hash (e.g., MD5 or SHA-1), so that the cryptographic\n  \
    \    strength of HMAC depends on the properties of the selected\n      cryptographic\
    \ hash. (See: [R2202, R2403, R2404].)\n      Derivation: Hash-based MAC. (Compare:\
    \ CMAC.)\n      Tutorial: Assume that H is a generic cryptographic hash in which\
    \ a\n      function is iterated on data blocks of length B bytes. L is the\n \
    \     length of the of hash result of H. K is a secret key of length L\n     \
    \ <= K <= B. The values IPAD and OPAD are fixed strings used as\n      inner and\
    \ outer padding and defined as follows: IPAD = the byte\n      0x36 repeated B\
    \ times, and OPAD = the byte 0x5C repeated B times.\n      HMAC is computed by\
    \ H(K XOR OPAD, H(K XOR IPAD, inputdata)).\n      HMAC has the following goals:\n\
    \      -  To use available cryptographic hash functions without\n         modification,\
    \ particularly functions that perform well in\n         software and for which\
    \ software is freely and widely available.\n      -  To preserve the original\
    \ performance of the selected hash\n         without significant degradation.\n\
    \      -  To use and handle keys in a simple way.\n      -  To have a well-understood\
    \ cryptographic analysis of the\n         strength of the mechanism based on reasonable\
    \ assumptions about\n         the underlying hash function.\n      -  To enable\
    \ easy replacement of the hash function in case a\n         faster or stronger\
    \ hash is found or required.\n   $ honey pot\n      (N) A system (e.g., a web\
    \ server) or system resource (e.g., a file\n      on a server) that is designed\
    \ to be attractive to potential\n      crackers and intruders, like honey is attractive\
    \ to bears. (See:\n      entrapment.)\n      Usage: It is likely that other cultures\
    \ use different metaphors\n      for this concept. Therefore, to avoid international\n\
    \      misunderstanding, an IDOC SHOULD NOT use this term without\n      providing\
    \ a definition for it. (See: Deprecated Usage under \"Green\n      Book\".)\n\
    \   $ host\n      1. (I) /general/ A computer that is attached to a communication\n\
    \      subnetwork or internetwork and can use services provided by the\n     \
    \ network to exchange data with other attached systems. (See: end\n      system.\
    \ Compare: server.)\n      2. (I) /IPS/ A networked computer that does not forward\
    \ IP packets\n      that are not addressed to the computer itself. (Compare: router.)\n\
    \      Derivation: As viewed by its users, a host \"entertains\" them,\n     \
    \ providing Application-Layer services or access to other computers\n      attached\
    \ to the network. However, even though some traditional\n      peripheral service\
    \ devices, such as printers, can now be\n      independently connected to networks,\
    \ they are not usually called\n      hosts.\n   $ HTML\n      (I) See: Hypertext\
    \ Markup Language.\n   $ HTTP\n      (I) See: Hypertext Transfer Protocol.\n \
    \  $ https\n      (I) When used in the first part of a URL (the part that precedes\n\
    \      the colon and specifies an access scheme or protocol), this term\n    \
    \  specifies the use of HTTP enhanced by a security mechanism, which\n      is\
    \ usually SSL. (Compare: S-HTTP.)\n   $ human error\n      (I) /threat action/\
    \ See: secondary definitions under \"corruption\",\n      \"exposure\", and \"\
    incapacitation\".\n   $ hybrid encryption\n      (I) An application of cryptography\
    \ that combines two or more\n      encryption algorithms, particularly a combination\
    \ of symmetric and\n      asymmetric encryption. Examples: digital envelope, MSP,\
    \ PEM, PGP.\n      (Compare: superencryption.)\n      Tutorial: Asymmetric algorithms\
    \ require more computation than\n      equivalently strong symmetric ones. Thus,\
    \ asymmetric encryption is\n      not normally used for data confidentiality except\
    \ to distribute a\n      symmetric key in a hybrid encryption scheme, where the\
    \ symmetric\n      key is usually very short (in terms of bits) compared to the\
    \ data\n      file it protects. (See: bulk key.)\n   $ hyperlink\n      (I) In\
    \ hypertext or hypermedia, an information object (such as a\n      word, a phrase,\
    \ or an image, which usually is highlighted by color\n      or underscoring) that\
    \ points (i.e., indicates how to connect) to\n      related information that is\
    \ located elsewhere and can be retrieved\n      by activating the link (e.g.,\
    \ by selecting the object with a mouse\n      pointer and then clicking).\n  \
    \ $ hypermedia\n      (I) A generalization of hypertext; any media that contain\n\
    \      hyperlinks that point to material in the same or another data\n      object.\n\
    \   $ hypertext\n      (I) A computer document, or part of a document, that contains\n\
    \      hyperlinks to other documents; i.e., text that contains active\n      pointers\
    \ to other text. Usually written in HTML and accessed using\n      a web browser.\
    \ (See: hypermedia.)\n   $ Hypertext Markup Language (HTML)\n      (I) A platform-independent\
    \ system of syntax and semantics (RFC\n      1866) for adding characters to data\
    \ files (particularly text\n      files) to represent the data's structure and\
    \ to point to related\n      data, thus creating hypertext for use in the World\
    \ Wide Web and\n      other applications. (Compare: XML.)\n   $ Hypertext Transfer\
    \ Protocol (HTTP)\n      (I) A TCP-based, Application-Layer, client-server, Internet\n\
    \      protocol (RFC 2616) that is used to carry data requests and\n      responses\
    \ in the World Wide Web. (See: hypertext.)\n   $ IAB\n      (I) See: Internet\
    \ Architecture Board.\n   $ IANA\n      (I) See: Internet Assigned Numbers Authority.\n\
    \   $ IATF\n      (O) See: Information Assurance Technical Framework.\n   $ ICANN\n\
    \      (I) See: Internet Corporation for Assigned Names and Numbers.\n   $ ICMP\n\
    \      (I) See: Internet Control Message Protocol.\n   $ ICMP flood\n      (I)\
    \ A denial-of-service attack that sends a host more ICMP echo\n      request (\"\
    ping\") packets than the protocol implementation can\n      handle. (See: flooding,\
    \ smurf.)\n   $ ICRL\n      (N) See: indirect certificate revocation list.\n \
    \  $ IDEA\n      (N) See: International Data Encryption Algorithm.\n   $ identification\n\
    \      (I) An act or process that presents an identifier to a system so\n    \
    \  that the system can recognize a system entity and distinguish it\n      from\
    \ other entities. (See: authentication.)\n   $ identification information\n  \
    \    (D) Synonym for \"identifier\"; synonym for \"authentication\n      information\"\
    . (See: authentication, identifying information.)\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term as a synonym for\n      either of those terms; this\
    \ term (a) is not as precise as they are\n      and (b) mixes concepts in a potentially\
    \ misleading way. Instead,\n      use \"identifier\" or \"authentication information\"\
    , depending on\n      what is meant.\n   $ Identification Protocol\n      (I)\
    \ A client-server Internet protocol [R1413] for learning the\n      identity of\
    \ a user of a particular TCP connection.\n      Tutorial: Given a TCP port number\
    \ pair, the server returns a\n      character string that identifies the owner\
    \ of that connection on\n      the server's system. The protocol does not provide\
    \ an\n      authentication service and is not intended for authorization or\n\
    \      access control. At best, it provides additional auditing\n      information\
    \ with respect to TCP.\n   $ identifier\n      (I) A data object -- often, a printable,\
    \ non-blank character\n      string -- that definitively represents a specific\
    \ identity of a\n      system entity, distinguishing that identity from all others.\n\
    \      (Compare: identity.)\n      Tutorial: Identifiers for system entities must\
    \ be assigned very\n      carefully, because authenticated identities are the\
    \ basis for\n      other security services, such as access control service.\n\
    \   $ identifier credential\n      1. (I) See: /authentication/ under \"credential\"\
    .\n      2. (D) Synonym for \"signature certificate\".\n      Usage: IDOCs that\
    \ use this term SHOULD state a definition for it\n      because the term is used\
    \ in many ways and could easily be\n      misunderstood.\n   $ identifying information\n\
    \      (D) Synonym for \"identifier\"; synonym for \"authentication\n      information\"\
    . (See: authentication, identification information.)\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term as a synonym for\n      either of those terms; this\
    \ term (a) is not as precise as they are\n      and (b) mixes concepts in a potentially\
    \ misleading way. Instead,\n      use \"identifier\" or \"authentication information\"\
    , depending on\n      what is meant.\n   $ identity\n      (I) The collective\
    \ aspect of a set of attribute values (i.e., a\n      set of characteristics)\
    \ by which a system user or other system\n      entity is recognizable or known.\
    \ (See: authenticate, registration.\n      Compare: identifier.)\n      Usage:\
    \ An IDOC MAY apply this term to either a single entity or a\n      set of entities.\
    \ If an IDOC involves both meanings, the IDOC\n      SHOULD use the following\
    \ terms and definitions to avoid ambiguity:\n      -  \"Singular identity\": An\
    \ identity that is registered for an\n         entity that is one person or one\
    \ process.\n      -  \"Shared identity\": An identity that is registered for an\
    \ entity\n         that is a set of singular entities (1) in which each member\
    \ is\n         authorized to assume the identity individually and (2) for\n  \
    \       which the registering system maintains a record of the singular\n    \
    \     entities that comprise the set. In this case, we would expect\n        \
    \ each member entity to be registered with a singular identity\n         before\
    \ becoming associated with the shared identity.\n      -  \"Group identity\":\
    \ An identity that is registered for an entity\n         (1) that is a set of\
    \ entities (2) for which the registering\n         system does not maintain a\
    \ record of singular entities that\n         comprise the set.\n      Tutorial:\
    \ When security services are based on identities, two\n      properties are desirable\
    \ for the set of attributes used to define\n      identities:\n      -  The set\
    \ should be sufficient to distinguish each entity from\n         all other entities,\
    \ i.e., to represent each entity uniquely.\n      -  The set should be sufficient\
    \ to distinguish each identity from\n         any other identities of the same\
    \ entity.\n      The second property is needed if a system permits an entity to\n\
    \      register two or more concurrent identities. Having two or more\n      identities\
    \ for the same entity implies that the entity has two\n      separate justifications\
    \ for registration. In that case, the set of\n      attributes used for identities\
    \ must be sufficient to represent\n      multiple identities for a single entity.\n\
    \      Having two or more identities registered for the same entity is\n     \
    \ different from concurrently associating two different identifiers\n      with\
    \ the same identity, and also is different from a single\n      identity concurrently\
    \ accessing the system in two different roles.\n      (See: principal, role-based\
    \ access control.)\n      When an identity of a user is being registered in a\
    \ system, the\n      system may require presentation of evidence that proves the\n\
    \      identity's authenticity (i.e., that the user has the right to\n      claim\
    \ or use the identity) and its eligibility (i.e., that the\n      identity is\
    \ qualified to be registered and needs to be\n      registered).\n      The following\
    \ diagram illustrates how this term relates to some\n      other terms in a PKI\
    \ system: authentication information,\n      identifier, identifier credential,\
    \ registration, registered user,\n      subscriber, and user.\n      Relationships:\
    \  === one-to-one, ==> one-to-many, <=> many-to-many.\n                  +- -\
    \ - - - - - - - - - - - - - - - - - - - - - - - - +\n                  |     \
    \                 PKI System                    |\n      + - - - - + | +------------------+\
    \   +-------------------------+ |\n      |  User,  | | |Subscriber, i.e., |  \
    \ | Identity of Subscriber  | |\n      |i.e., one| | | Registered User, |   |\
    \    is system-unique     | |\n      | of the  | | | is system-unique |   | +---------------------+\
    \ | |\n      |following| | | +--------------+ |   | |     Subscriber      | |\
    \ |\n      |         | | | | User's core  | |   | |     Identity's      | | |\n\
    \      | +-----+ |===| | Registration | |==>| |  Registration data  | | |\n  \
    \    | |human| | | | | data, i.e.,  | |   | |+-------------------+| | |\n    \
    \  | |being| | | | | an entity's  | |   | ||  same core data   || | |\n      |\
    \ +-----+ | | | |distinguishing|========|for all Identities || | |\n      |  \
    \ or    | | | |  attribute   | |   | || of the same User  || | |\n      | +-----+\
    \ | | | |   values     | | +===|+-------------------+| | |\n      | |auto-| |\
    \ | | +--------------+ | | | +---------------------+ | |\n      | |mated| | |\
    \ +------------------+ | +------------|------------+ |\n      | |pro- | | |  \
    \       |    +=======+              |              |\n      | |cess | | | +-------v----|----------------------|------------+\
    \ |\n      | +-----+ | | | +----------v---+     +------------v----------+ | |\n\
    \      |   or    | | | |Authentication|<===>|Identifier of Identity | | |\n  \
    \    |+-------+| | | | Information  |     |    is system-unique   | | |\n    \
    \  || a set || | | +--------------+     +-----------------------+ | |\n      ||\
    \  of   || | | Identifier Credential that associates unit of  | |\n      || either||\
    \ | | Authentication Information with the Identifier | |\n      |+-------+| |\
    \ +------------------------------------------------+ |\n      + - - - - + + -\
    \ - - - - - - - - - - - - - - - - - - - - - - - - -+\n   $ identity-based security\
    \ policy\n      (I) \"A security policy based on the identities and/or attributes\n\
    \      of users, a group of users, or entities acting on behalf of the\n     \
    \ users and the resources/objects being accessed.\" [I7498-2] (See:\n      rule-based\
    \ security policy.)\n   $ identity proofing\n      (I) A process that vets and\
    \ verifies the information that is used\n      to establish the identity of a\
    \ system entity. (See: registration.)\n   $ IDOC\n      (I) An abbreviation used\
    \ in this Glossary to refer to a document\n      or other item of written material\
    \ that is generated in the\n      Internet Standards Process (RFC 2026), i.e.,\
    \ an RFC, an Internet-\n      Draft, or some other item of discourse.\n      Deprecated\
    \ Usage: This abbreviation SHOULD NOT be used in an IDOC\n      unless it is first\
    \ defined in the IDOC because the abbreviation\n      was invented for this Glossary\
    \ and is not widely known.\n   $ IDS\n      (I) See: intrusion detection system.\n\
    \   $ IEEE\n      (N) See: Institute of Electrical and Electronics Engineers,\
    \ Inc.\n   $ IEEE 802.10\n      (N) An IEEE committee developing security standards\
    \ for LANs.\n      (See: SILS.)\n   $ IEEE P1363\n      (N) An IEEE working group,\
    \ Standard for Public-Key Cryptography,\n      engaged in developing a comprehensive\
    \ reference standard for\n      asymmetric cryptography. Covers discrete logarithm\
    \ (e.g., DSA),\n      elliptic curve, and integer factorization (e.g., RSA); and\
    \ covers\n      key agreement, digital signature, and encryption.\n   $ IESG\n\
    \      (I) See: Internet Engineering Steering Group.\n   $ IETF\n      (I) See:\
    \ Internet Engineering Task Force.\n   $ IKE\n      (I) See: IPsec Key Exchange.\n\
    \   $ IMAP4\n      (I) See: Internet Message Access Protocol, version 4.\n   $\
    \ IMAP4 AUTHENTICATE\n      (I) An IMAP4 command (better described as a transaction\
    \ type, or\n      subprotocol) by which an IMAP4 client optionally proposes a\n\
    \      mechanism to an IMAP4 server to authenticate the client to the\n      server\
    \ and provide other security services. (See: POP3.)\n      Tutorial: If the server\
    \ accepts the proposal, the command is\n      followed by performing a challenge-response\
    \ authentication\n      protocol and, optionally, negotiating a protection mechanism\
    \ for\n      subsequent POP3 interactions. The security mechanisms that are\n\
    \      used by IMAP4 AUTHENTICATE -- including Kerberos, GSS-API, and\n      S/Key\
    \ -- are described in [R1731].\n   $ impossible\n      (O) Cannot be done in any\
    \ reasonable amount of time. (See: break,\n      brute force, strength, work factor.)\n\
    \   $ in the clear\n      (I) Not encrypted. (See: clear text.)\n   $ Ina Jo\n\
    \      (O) A methodology, language, and integrated set of software tools\n   \
    \   developed at the System Development Corporation for specifying,\n      coding,\
    \ and verifying software to produce correct and reliable\n      programs. Usage:\
    \ a.k.a. the Formal Development Methodology. [Cheh]\n   $ incapacitation\n   \
    \   (I) A type of threat action that prevents or interrupts system\n      operation\
    \ by disabling a system component. (See: disruption.)\n      Usage: This type\
    \ of threat action includes the following subtypes:\n      -  \"Malicious logic\"\
    : In context of incapacitation, any hardware,\n         firmware, or software\
    \ (e.g., logic bomb) intentionally\n         introduced into a system to destroy\
    \ system functions or\n         resources. (See: corruption, main entry for \"\
    malicious logic\",\n         masquerade, misuse.)\n      -  \"Physical destruction\"\
    : Deliberate destruction of a system\n         component to interrupt or prevent\
    \ system operation.\n      -  \"Human error\": /incapacitation/ Action or inaction\
    \ that\n         unintentionally disables a system component. (See: corruption,\n\
    \         exposure.)\n      -  \"Hardware or software error\": /incapacitation/\
    \ Error that\n         unintentionally causes failure of a system component and\
    \ leads\n         to disruption of system operation. (See: corruption, exposure.)\n\
    \      -  \"Natural disaster\": /incapacitation/ Any \"act of God\" (e.g.,\n \
    \        fire, flood, earthquake, lightning, or wind) that disables a\n      \
    \   system component. [FP031 Section 2]\n   $ incident\n      See: security incident.\n\
    \   $ INCITS\n      (N) See: \"International Committee for Information Technology\n\
    \      Standardization\" under \"ANSI\".\n   $ indicator\n      (N) An action\
    \ -- either specific, generalized, or theoretical --\n      that an adversary\
    \ might be expected to take in preparation for an\n      attack. [C4009] (See:\
    \ \"attack sensing, warning, and response\".\n      Compare: message indicator.)\n\
    \   $ indirect attack\n      (I) See: secondary definition under \"attack\". Compare:\
    \ direct\n      attack.\n   $ indirect certificate revocation list (ICRL)\n  \
    \    (N) In X.509, a CRL that may contain certificate revocation\n      notifications\
    \ for certificates issued by CAs other than the issuer\n      (i.e., signer) of\
    \ the ICRL.\n   $ indistinguishability\n      (I) An attribute of an encryption\
    \ algorithm that is a\n      formalization of the notion that the encryption of\
    \ some string is\n      indistinguishable from the encryption of an equal-length\
    \ string of\n      nonsense. (Compare: semantic security.)\n   $ inference\n \
    \     1. (I) A type of threat action that reasons from characteristics\n     \
    \ or byproducts of communication and thereby indirectly accesses\n      sensitive\
    \ data, but not necessarily the data contained in the\n      communication. (See:\
    \ traffic analysis, signal analysis.)\n      2. (I) A type of threat action that\
    \ indirectly gains unauthorized\n      access to sensitive information in a database\
    \ management system by\n      correlating query responses with information that\
    \ is already\n      known.\n   $ inference control\n      (I) Protection of data\
    \ confidentiality against inference attack.\n      (See: traffic-flow confidentiality.)\n\
    \      Tutorial: A database management system containing N records about\n   \
    \   individuals may be required to provide statistical summaries about\n     \
    \ subsets of the population, while not revealing sensitive\n      information\
    \ about a single individual. An attacker may try to\n      obtain sensitive information\
    \ about an individual by isolating a\n      desired record at the intersection\
    \ of a set of overlapping\n      queries. A system can attempt to prevent this\
    \ by restricting the\n      size and overlap of query sets, distorting responses\
    \ by rounding\n      or otherwise perturbing database values, and limiting queries\
    \ to\n      random samples. However, these techniques may be impractical to\n\
    \      implement or use, and no technique is totally effective. For\n      example,\
    \ restricting the minimum size of a query set -- that is,\n      not responding\
    \ to queries for which there are fewer than K or more\n      than N-K records\
    \ that satisfy the query -- usually cannot prevent\n      unauthorized disclosure.\
    \ An attacker can pad small query sets with\n      extra records, and then remove\
    \ the effect of the extra records.\n      The formula for identifying the extra\
    \ records is called the\n      \"tracker\". [Denns]\n   $ INFOCON\n      (O) See:\
    \ information operations condition\n   $ informal\n      (N) Expressed in natural\
    \ language. [CCIB] (Compare: formal,\n      semiformal.)\n   $ information\n \
    \     1. (I) Facts and ideas, which can be represented (encoded) as\n      various\
    \ forms of data.\n      2. (I) Knowledge -- e.g., data, instructions -- in any\
    \ medium or\n      form that can be communicated between system entities.\n  \
    \    Tutorial: Internet security could be defined simply as protecting\n     \
    \ information in the Internet. However, the perceived need to use\n      different\
    \ protective measures for different types of information\n      (e.g., authentication\
    \ information, classified information,\n      collateral information, national\
    \ security information, personal\n      information, protocol control information,\
    \ sensitive compartmented\n      information, sensitive information) has led to\
    \ the diversity of\n      terminology listed in this Glossary.\n   $ information\
    \ assurance\n      (N) /U.S. Government/ \"Measures that protect and defend\n\
    \      information and information systems by ensuring their availability\n  \
    \    integrity, authentication, confidentiality, and non-repudiation.\n      These\
    \ measures include providing for restoration of information\n      systems by\
    \ incorporating protection, detection, and reaction\n      capabilities.\" [C4009]\n\
    \   $ Information Assurance Technical Framework (IATF)\n      (O) A publicly available\
    \ document [IATF], developed through a\n      collaborative effort by organizations\
    \ in the U.S. Government and\n      industry, and issued by NSA. Intended for\
    \ security managers and\n      system security engineers as a tutorial and reference\
    \ document\n      about security problems in information systems and networks,\
    \ to\n      improve awareness of tradeoffs among available technology\n      solutions\
    \ and of desired characteristics of security approaches\n      for particular\
    \ problems. (See: ISO 17799, [SP14].)\n   $ information domain\n      (O) See:\
    \ secondary definition under \"domain\".\n   $ information domain security policy\n\
    \      (O) See: secondary definition under \"domain\".\n   $ information flow\
    \ policy\n      (N) /formal model/ A triple consisting of a set of security levels\n\
    \      (or their equivalent security labels), a binary operator that maps\n  \
    \    each pair of security levels into a security level, and a binary\n      relation\
    \ on the set that selects a set of pairs of levels such\n      that information\
    \ is permitted to flow from an object of the first\n      level to an object of\
    \ the second level. (See: flow control,\n      lattice model.)\n   $ information\
    \ operations condition (INFOCON)\n      (O) /U.S. DoD/ A comprehensive defense\
    \ posture and response based\n      on the status of information systems, military\
    \ operations, and\n      intelligence assessments of adversary capabilities and\
    \ intent.\n      (See: threat)\n      Derivation: From DEFCON, i.e., defense condition.\n\
    \      Tutorial: The U.S. DoD defines five INFOCON levels: NORMAL (normal\n  \
    \    activity), ALPHA (increased risk of attack), BRAVO (specific risk\n     \
    \ of attack), CHARLIE (limited attack), and DELTA (general attack).\n   $ information\
    \ security (INFOSEC)\n      (N) Measures that implement and assure security services\
    \ in\n      information systems, including in computer systems (see: COMPUSEC)\n\
    \      and in communication systems (see: COMSEC).\n   $ information system\n\
    \      (I) An organized assembly of computing and communication resources\n  \
    \    and procedures -- i.e., equipment and services, together with\n      their\
    \ supporting infrastructure, facilities, and personnel -- that\n      create,\
    \ collect, record, process, store, transport, retrieve,\n      display, disseminate,\
    \ control, or dispose of information to\n      accomplish a specified set of functions.\
    \ (See: system entity,\n      system resource. Compare: computer platform.)\n\
    \   $ Information Technology Security Evaluation Criteria (ITSEC)\n      (N) A\
    \ Standard [ITSEC] jointly developed by France, Germany, the\n      Netherlands,\
    \ and the United Kingdom for use in the European Union;\n      accommodates a\
    \ wider range of security assurance and functionality\n      combinations than\
    \ the TCSEC. Superseded by the Common Criteria.\n   $ INFOSEC\n      (I) See:\
    \ information security.\n   $ ingress filtering\n      (I) A method [R2827] for\
    \ countering attacks that use packets with\n      false IP source addresses, by\
    \ blocking such packets at the\n      boundary between connected networks.\n \
    \     Tutorial: Suppose network A of an internet service provider (ISP)\n    \
    \  includes a filtering router that is connected to customer network\n      B,\
    \ and an attacker in B at IP source address \"foo\" attempts to\n      send packets\
    \ with false source address \"bar\" into A. The false\n      address may be either\
    \ fixed or randomly changing, and it may\n      either be unreachable or be a\
    \ forged address that legitimately\n      exists within either B or some other\
    \ network C. In ingress\n      filtering, the ISP's router blocks all inbound\
    \ packet that arrive\n      from B with a source address that is not within the\
    \ range of\n      legitimately advertised addresses for B. This method does not\n\
    \      prevent all attacks that can originate from B, but the actual\n      source\
    \ of such attacks can be more easily traced because the\n      originating network\
    \ is known.\n   $ initialization value (IV)\n      (I) /cryptography/ An input\
    \ parameter that sets the starting state\n      of a cryptographic algorithm or\
    \ mode. (Compare: activation data.)\n      Tutorial: An IV can be used to synchronize\
    \ one cryptographic\n      process with another; e.g., CBC, CFB, and OFB use IVs.\
    \ An IV also\n      can be used to introduce cryptographic variance (see: salt)\n\
    \      besides that provided by a key.\n   $ initialization vector\n      (D)\
    \ /cryptography/ Synonym for \"initialization value\".\n      Deprecated Term:\
    \ To avoid international misunderstanding, IDOCs\n      SHOULD NOT use this term\
    \ in the context of cryptography because\n      most dictionary definitions of\
    \ \"vector\" includes a concept of\n      direction or magnitude, which are irrelevant\
    \ to cryptographic use.\n   $ insertion\n      1. (I) /packet/ See: secondary\
    \ definition under \"stream integrity\n      service\".\n      2. (I) /threat\
    \ action/ See: secondary definition under\n      \"falsification\".\n   $ inside\
    \ attack\n      (I) See: secondary definition under \"attack\". Compare: insider.\n\
    \   $ insider\n      1. (I) A user (usually a person) that accesses a system from\
    \ a\n      position that is inside the system's security perimeter. (Compare:\n\
    \      authorized user, outsider, unauthorized user.)\n      Tutorial: An insider\
    \ has been assigned a role that has more\n      privileges to access system resources\
    \ than do some other types of\n      users, or can access those resources without\
    \ being constrained by\n      some access controls that are applied to outside\
    \ users. For\n      example, a salesclerk is an insider who has access to the\
    \ cash\n      register, but a store customer is an outsider.\n      The actions\
    \ performed by an insider in accessing the system may be\n      either authorized\
    \ or unauthorized; i.e., an insider may act either\n      as an authorized user\
    \ or as an unauthorized user.\n      2. (O) A person with authorized physical\
    \ access to the system.\n      Example: In this sense, an office janitor is an\
    \ insider, but a\n      burglar or casual visitor is not. [NRC98]\n      3. (O)\
    \ A person with an organizational status that causes the\n      system or members\
    \ of the organization to view access requests as\n      being authorized. Example:\
    \ In this sense, a purchasing agent is an\n      insider but a vendor is not.\
    \ [NRC98]\n   $ inspectable space\n      (O) /EMSEC/ \"Three-dimensional space\
    \ surrounding equipment that\n      process classified and/or sensitive information\
    \ within which\n      TEMPEST exploitation is not considered practical or where\
    \ legal\n      authority to identify and/or remove a potential TEMPEST\n     \
    \ exploitation exists.\" [C4009] (Compare: control zone, TEMPEST\n      zone.)\n\
    \   $ Institute of Electrical and Electronics Engineers, Inc. (IEEE)\n      (N)\
    \ The IEEE is a not-for-profit association of approximately\n      300,000 individual\
    \ members in 150 countries. The IEEE produces\n      nearly one third of the world's\
    \ published literature in electrical\n      engineering, computers, and control\
    \ technology; holds hundreds of\n      major, annual conferences; and maintains\
    \ more than 800 active\n      standards, with many more under development. (See:\
    \ SILS.)\n   $ integrity\n      See: data integrity, datagram integrity service,\
    \ correctness\n      integrity, source integrity, stream integrity service, system\n\
    \      integrity.\n   $ integrity check\n      (D) A computation that is part\
    \ of a mechanism to provide data\n      integrity service or data origin authentication\
    \ service. (Compare:\n      checksum.)\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use this term as a synonym for\n      \"cryptographic hash\" or \"protected\
    \ checksum\". This term\n      unnecessarily duplicates the meaning of other,\
    \ well-established\n      terms; this term only mentions integrity, even though\
    \ the intended\n      service may be data origin authentication; and not every\
    \ checksum\n      is cryptographically protected.\n   $ integrity label\n    \
    \  (I) A security label that tells the degree of confidence that may\n      be\
    \ placed in the data, and may also tell what countermeasures are\n      required\
    \ to be applied to protect the data from alteration and\n      destruction. (See:\
    \ integrity. Compare: classification label.)\n   $ intelligent threat\n      (I)\
    \ A circumstance in which an adversary has the technical and\n      operational\
    \ ability to detect and exploit a vulnerability and also\n      has the demonstrated,\
    \ presumed, or inferred intent to do so. (See:\n      threat.)\n   $ interception\n\
    \      (I) A type of threat action whereby an unauthorized entity\n      directly\
    \ accesses sensitive data while the data is traveling\n      between authorized\
    \ sources and destinations. (See: unauthorized\n      disclosure.)\n      Usage:\
    \ This type of threat action includes the following subtypes:\n      -  \"Theft\"\
    : Gaining access to sensitive data by stealing a\n         shipment of a physical\
    \ medium, such as a magnetic tape or disk,\n         that holds the data.\n  \
    \    -  \"Wiretapping (passive)\": Monitoring and recording data that is\n   \
    \      flowing between two points in a communication system. (See:\n         wiretapping.)\n\
    \      -  \"Emanations analysis\": Gaining direct knowledge of communicated\n\
    \         data by monitoring and resolving a signal that is emitted by a\n   \
    \      system and that contains the data but was not intended to\n         communicate\
    \ the data. (See: emanation.)\n   $ interference\n      (I) /threat action/ See:\
    \ secondary definition under \"obstruction\".\n   $ intermediate CA\n      (D)\
    \ The CA that issues a cross-certificate to another CA. [X509]\n      (See: cross-certification.)\n\
    \      Deprecated Term: IDOCs SHOULD NOT use this term because it is not\n   \
    \   widely known and mixes concepts in a potentially misleading way.\n      For\
    \ example, suppose that end entity 1 (\"EE1) is in one PKI\n      (\"PKI1\"),\
    \ end entity 2 (\"EE2) is in another PKI (\"PKI2\"), and the\n      root in PKI1\
    \ (\"CA1\") cross-certifies the root CA in PKI2 (\"CA2\").\n      Then, if EE1\
    \ constructs the certification path CA1-to-CA2-to-EE2\n      to validate a certificate\
    \ of EE2, conventional English usage would\n      describe CA2 as being in the\
    \ \"intermediate\" position in that path,\n      not CA1.\n   $ internal controls\n\
    \      (I) /COMPUSEC/ Functions, features, and technical characteristics\n   \
    \   of computer hardware and software, especially of operating\n      systems.\
    \ Includes mechanisms to regulate the operation of a\n      computer system with\
    \ regard to access control, flow control, and\n      inference control. (Compare:\
    \ external controls.)\n   $ International Data Encryption Algorithm (IDEA)\n \
    \     (N) A patented, symmetric block cipher that uses a 128-bit key and\n   \
    \   operates on 64-bit blocks. [Schn] (See: symmetric cryptography.)\n   $ International\
    \ Standard\n      (N) See: secondary definition under \"ISO\".\n   $ International\
    \ Traffic in Arms Regulations (ITAR)\n      (O) Rules issued by the U.S. State\
    \ Department, by authority of the\n      Arms Export Control Act (22 U.S.C. 2778),\
    \ to control export and\n      import of defense articles and defense services,\
    \ including\n      information security systems, such as cryptographic systems,\
    \ and\n      TEMPEST suppression technology. (See: type 1 product, Wassenaar\n\
    \      Arrangement.)\n   $ internet, Internet\n      1. (I) /not capitalized/\
    \ Abbreviation of \"internetwork\".\n      2. (I) /capitalized/ The Internet is\
    \ the single, interconnected,\n      worldwide system of commercial, governmental,\
    \ educational, and\n      other computer networks that share (a) the protocol\
    \ suite\n      specified by the IAB (RFC 2026) and (b) the name and address\n\
    \      spaces managed by the ICANN. (See: Internet Layer, Internet\n      Protocol\
    \ Suite.)\n      Usage: Use with definite article (\"the\") when using as a noun.\
    \ For\n      example, say \"My LAN is small, but the Internet is large.\" Don't\n\
    \      say \"My LAN is small, but Internet is large.\"\n   $ Internet Architecture\
    \ Board (IAB)\n      (I) A technical advisory group of the ISOC, chartered by\
    \ the ISOC\n      Trustees to provide oversight of Internet architecture and\n\
    \      protocols and, in the context of Internet Standards, a body to\n      which\
    \ decisions of the IESG may be appealed. Responsible for\n      approving appointments\
    \ to the IESG from among nominees submitted\n      by the IETF nominating committee.\
    \ (RFC 2026)\n   $ Internet Assigned Numbers Authority (IANA)\n      (I) From\
    \ the early days of the Internet, the IANA was chartered by\n      the ISOC and\
    \ the U.S. Government's Federal Network Council to be\n      the central coordination,\
    \ allocation, and registration body for\n      parameters for Internet protocols.\
    \ Superseded by ICANN.\n   $ Internet Control Message Protocol (ICMP)\n      (I)\
    \ An Internet Standard protocol (RFC 792) that is used to report\n      error\
    \ conditions during IP datagram processing and to exchange\n      other information\
    \ concerning the state of the IP network.\n   $ Internet Corporation for Assigned\
    \ Names and Numbers (ICANN)\n      (I) The non-profit, private corporation that\
    \ has assumed\n      responsibility for the IP address space allocation, protocol\n\
    \      parameter assignment, DNS management, and root server system\n      management\
    \ functions formerly performed under U.S. Government\n      contract by IANA and\
    \ other entities.\n      Tutorial: The IPS, as defined by the IETF and the IESG,\
    \ contains\n      numerous parameters, such as Internet addresses, domain names,\n\
    \      autonomous system numbers, protocol numbers, port numbers,\n      management\
    \ information base OIDs, including private enterprise\n      numbers, and many\
    \ others. The Internet community requires that the\n      values used in these\
    \ parameter fields be assigned uniquely. ICANN\n      makes those assignments\
    \ as requested and maintains a registry of\n      the current values.\n      ICANN\
    \ was formed in October 1998, by a coalition of the Internet's\n      business,\
    \ technical, and academic communities. The U.S. Government\n      designated ICANN\
    \ to serve as the global consensus entity with\n      responsibility for coordinating\
    \ four key functions for the\n      Internet: allocation of IP address space,\
    \ assignment of protocol\n      parameters, management of the DNS, and management\
    \ of the DNS root\n      server system.\n   $ Internet-Draft\n      (I) A working\
    \ document of the IETF, its areas, and its working\n      groups. (RFC 2026) (Compare:\
    \ RFC.)\n      Usage: The term is customarily hyphenated when used either as a\n\
    \      adjective or a noun, even though the latter is not standard\n      English\
    \ punctuation.\n      Tutorial: An Internet-Draft is not an archival document\
    \ like an\n      RFC is. Instead, an Internet-Draft is a preliminary or working\n\
    \      document that is valid for a maximum of six months and may be\n      updated,\
    \ replaced, or made obsolete by other documents at any\n      time. It is inappropriate\
    \ to use an Internet-Draft as reference\n      material or to cite it other than\
    \ as a \"work in progress\".\n      Although most of the Internet-Drafts are produced\
    \ by the IETF, any\n      interested organization may request to have its working\
    \ documents\n      published as Internet-Drafts.\n   $ Internet Engineering Steering\
    \ Group (IESG)\n      (I) The part of the ISOC responsible for technical management\
    \ of\n      IETF activities and administration of the Internet Standards\n   \
    \   Process according to procedures approved by the ISOC Trustees.\n      Directly\
    \ responsible for actions along the \"standards track\",\n      including final\
    \ approval of specifications as Internet Standards.\n      Composed of IETF Area\
    \ Directors and the IETF chairperson, who also\n      chairs the IESG. (RFC 2026)\n\
    \   $ Internet Engineering Task Force (IETF)\n      (I) A self-organized group\
    \ of people who make contributions to the\n      development of Internet technology.\
    \ The principal body engaged in\n      developing Internet Standards, although\
    \ not itself a part of the\n      ISOC. Composed of Working Groups, which are\
    \ arranged into Areas\n      (such as the Security Area), each coordinated by\
    \ one or more Area\n      Directors. Nominations to the IAB and the IESG are made\
    \ by a\n      committee selected at random from regular IETF meeting attendees\n\
    \      who have volunteered. (RFCs 2026, 3935) [R2323]\n   $ Internet Key Exchange\
    \ (IKE)\n      (I) An Internet, IPsec, key-establishment protocol [R4306] for\n\
    \      putting in place authenticated keying material (a) for use with\n     \
    \ ISAKMP and (b) for other security associations, such as in AH and\n      ESP.\n\
    \      Tutorial: IKE is based on three earlier protocol designs: ISAKMP,\n   \
    \   OAKLEY, and SKEME.\n   $ Internet Layer\n      (I) See: Internet Protocol\
    \ Suite.\n   $ Internet Message Access Protocol, version 4 (IMAP4)\n      (I)\
    \ An Internet protocol (RFC 2060) by which a client workstation\n      can dynamically\
    \ access a mailbox on a server host to manipulate\n      and retrieve mail messages\
    \ that the server has received and is\n      holding for the client. (See: POP3.)\n\
    \      Tutorial: IMAP4 has mechanisms for optionally authenticating a\n      client\
    \ to a server and providing other security services. (See:\n      IMAP4 AUTHENTICATE.)\n\
    \   $ Internet Open Trading Protocol (IOTP)\n      (I) An Internet protocol [R2801]\
    \ proposed as a general framework\n      for Internet commerce, able to encapsulate\
    \ transactions of various\n      proprietary payment systems (e.g., GeldKarte,\
    \ Mondex, SET, Visa\n      Cash). Provides optional security services by incorporating\n\
    \      various Internet security mechanisms (e.g., MD5) and protocols\n      (e.g.,\
    \ TLS).\n   $ Internet Policy Registration Authority (IPRA)\n      (I) An X.509-compliant\
    \ CA that is the top CA of the Internet\n      certification hierarchy operated\
    \ under the auspices of the ISOC\n      [R1422]. (See: /PEM/ under \"certification\
    \ hierarchy\".)\n   $ Internet Private Line Interface (IPLI)\n      (O) A successor\
    \ to the PLI, updated to use TCP/IP and newer\n      military-grade COMSEC equipment\
    \ (TSEC/KG-84). The IPLI was a\n      portable, modular system that was developed\
    \ for use in tactical,\n      packet-radio networks. (See: end-to-end encryption.)\n\
    \   $ Internet Protocol (IP)\n      (I) An Internet Standard, Internet-Layer protocol\
    \ that moves\n      datagrams (discrete sets of bits) from one computer to another\n\
    \      across an internetwork but does not provide reliable delivery,\n      flow\
    \ control, sequencing, or other end-to-end services that TCP\n      provides.\
    \ IP version 4 (IPv4) is specified in RFC 791, and IP\n      version 6 (IPv6)\
    \ is specified in RFC 2460. (See: IP address,\n      TCP/IP.)\n      Tutorial:\
    \ If IP were used in an OSIRM stack, IP would be placed at\n      the top of Layer\
    \ 3, above other Layer 3 protocols in the stack.\n      In any IPS stack, IP is\
    \ always present in the Internet Layer and\n      is always placed at the top\
    \ of that layer, on top of any other\n      protocols that are used in that layer.\
    \ In some sense, IP is the\n      only protocol specified for the IPS Internet\
    \ Layer; other\n      protocols used there, such as AH and ESP, are just IP variations.\n\
    \   $ Internet Protocol security\n      See: IP Security Protocol.\n   $ Internet\
    \ Protocol Security Option (IPSO)\n      (I) Refers to one of three types of IP\
    \ security options, which are\n      fields that may be added to an IP datagram\
    \ for carrying security\n      information about the datagram. (Compare: IPsec.)\n\
    \      Deprecated Usage: IDOCs SHOULD NOT use this term without a\n      modifier\
    \ to indicate which of the following three types is meant:\n      -  \"DoD Basic\
    \ Security Option\" (IP option type 130): Defined for\n         use on U.S. DoD\
    \ common-use data networks. Identifies the DoD\n         classification level\
    \ at which the datagram is to be protected\n         and the protection authorities\
    \ whose rules apply to the\n         datagram. (A \"protection authority\" is\
    \ a National Access\n         Program (e.g., GENSER, SIOP-ESI, SCI, NSA, Department\
    \ of\n         Energy) or Special Access Program that specifies protection\n \
    \        rules for transmission and processing of the information\n         contained\
    \ in the datagram.) [R1108]\n      -  \"DoD Extended Security Option\" (IP option\
    \ type 133): Permits\n         additional security labeling information, beyond\
    \ that present\n         in the Basic Security Option, to be supplied in the datagram\
    \ to\n         meet the needs of registered authorities. [R1108]\n      -  \"\
    Common IP Security Option\" (CIPSO) (IP option type 134):\n         Designed by\
    \ TSIG to carry hierarchic and non-hierarchic\n         security labels. (Formerly\
    \ called \"Commercial IP Security\n         Option\"; a version 2.3 draft was\
    \ published 9 March 1993 as an\n         Internet-Draft but did not advance to\
    \ RFC form.) [CIPSO]\n   $ Internet Protocol Suite (IPS)\n      (I) The set of\
    \ network communication protocols that are specified\n      by the IETF, and approved\
    \ as Internet Standards by the IESG,\n      within the oversight of the IAB. (See:\
    \ OSIRM Security\n      Architecture. Compare: OSIRM.)\n      Usage: This set\
    \ of protocols is popularly known as \"TCP/IP\"\n      because TCP and IP are\
    \ its most basic and important components.\n      For clarity, this Glossary refers\
    \ to IPS protocol layers by name\n      and capitalizes those names, and refers\
    \ to OSIRM protocol layers\n      by number.\n      Tutorial: The IPS does have\
    \ architectural principles [R1958], but\n      there is no Internet Standard that\
    \ defines a layered IPS reference\n      model like the OSIRM. Still, Internet\
    \ community literature has\n      referred (inconsistently) to IPS layers since\
    \ early in the\n      Internet's development [Padl].\n      This Glossary treats\
    \ the IPS as having five protocol layers --\n      Application, Transport, Internet,\
    \ Network Interface, and Network\n      Hardware (or Network Substrate) -- which\
    \ are illustrated in the\n      following diagram:\n      OSIRM Layers       Examples\
    \          IPS Layers     Examples\n      ------------------ --------------- \
    \ --------------- --------------\n      Message Format:    P2   [X420]      Message\
    \ Format: ARPA (RFC 822)\n      +----------------+                  +-------------+\n\
    \      |7.Application   | P1   [X419]      | Application | SMTP (RFC 821)\n  \
    \    +----------------+ -  -  -  -  -  - |             |\n      |6.Presentation\
    \  |      [I8823]     |             |\n      +----------------+ -  -  -  -  -\
    \  - |             |\n      |5.Session       |      [I8327]     +-------------+\n\
    \      +----------------+ -  -  -  -  -  - |  Transport  | TCP  (RFC 793)\n  \
    \    |4.Transport     | TP4  [I8073]     |             |\n      +----------------+\
    \ -  -  -  -  -  - +-------------+\n      |3.Network       | CLNP [I8473]    \
    \ |  Internet   | IP   (RFC 791)\n      |                |                  +-------------+\n\
    \      |                |                  |   Network   | IP over IEEE\n    \
    \  +----------------+ -  -  -  -  -  - |  Interface  | 802 (RFC 1042)\n      |2.Data\
    \ Link     |                  +-------------+\n      |                | LLC  [I8802-2]\
    \   -   Network   - The IPS does\n      |                | MAC  [I8802-3]   -\
    \  Hardware   - not include\n      +----------------+                  - (or Network\
    \ - standards for\n      |1.Physical      | Baseband         -  Substrate) - this\
    \ layer.\n      +----------------+ Signaling [Stal] + - - - - - - +\n      The\
    \ diagram approximates how the five IPS layers align with the\n      seven OSIRM\
    \ layers, and it offers examples of protocol stacks that\n      provide roughly\
    \ equivalent electronic mail service over a private\n      LAN that uses baseband\
    \ signaling.\n      -  IPS Application Layer: The user runs an application program.\n\
    \         The program selects the data transport service it needs --\n       \
    \  either a sequence of data messages or a continuous stream of\n         data\
    \ -- and hands application data to the Transport Layer for\n         delivery.\n\
    \      -  IPS Transport Layer: This layer divides application data into\n    \
    \     packets, adds a destination address to each, and communicates\n        \
    \ them end-to-end -- from one application program to another --\n         optionally\
    \ regulating the flow and ensuring reliable (error-\n         free and sequenced)\
    \ delivery.\n      -  IPS Internet Layer: This layer carries transport packets\
    \ in IP\n         datagrams. It moves each datagram independently, from its\n\
    \         source computer to its addressed destination computer, routing\n   \
    \      the datagram through a sequence of networks and relays and\n         selecting\
    \ appropriate network interfaces en route.\n      -  IPS Network Interface Layer:\
    \ This layer accepts datagrams for\n         transmission over a specific network.\
    \ This layer specifies\n         interface conventions for carrying IP over OSIRM\
    \ Layer 3\n         protocols and over Media Access Control sublayer protocols\
    \ of\n         OSIRM Layer 2. An example is IP over IEEE 802 (RFD 1042).\n   \
    \   -  IPS Network Hardware Layer: This layer consists of specific,\n        \
    \ physical communication media. However, the IPS does not specify\n         its\
    \ own peer-to-peer protocols in this layer. Instead, the\n         layering conventions\
    \ specified by the Network Interface Layer\n         use Layer 2 and Layer 3 protocols\
    \ that are specified by bodies\n         other than the IETF. That is, the IPS\
    \ addresses *inter*-network\n         functions and does not address *intra*-network\
    \ functions.\n      The two models are most dissimilar in the upper layers, where\
    \ the\n      IPS model does not include Session and Presentation layers.\n   \
    \   However, this omission causes fewer functional differences between\n     \
    \ the models than might be imagined, and the differences have\n      relatively\
    \ few security implications:\n      -  Formal separation of OSIRM Layers 5, 6,\
    \ and 7 is not needed in\n         implementations; the functions of these layers\
    \ sometimes are\n         mixed in a single software unit, even in protocols in\
    \ the OSI\n         suite.\n      -  Some OSIRM Layer 5 services -- for example,\
    \ connection\n         termination -- are built into TCP, and the remaining Layer\
    \ 5\n         and 6 functions are built into IPS Application-Layer protocols\n\
    \         where needed.\n      -  The OSIRM does not place any security services\
    \ in Layer 5 (see:\n         OSIRM Security Architecture).\n      -  The lack\
    \ of an explicit Presentation Layer in the IPS sometimes\n         makes it simpler\
    \ to implement security in IPS applications. For\n         example, a primary\
    \ function of Layer 6 is to convert data\n         between internal and external\
    \ forms, using a transfer syntax to\n         unambiguously encode data for transmission.\
    \ If an OSIRM\n         application encrypts data to protect against disclosure\
    \ during\n         transmission, the transfer encoding must be done before the\n\
    \         encryption. If an application does encryption, as is done in\n     \
    \    OSI message handling and directory service protocols, then\n         Layer\
    \ 6 functions must be replicated in Layer 7. [X400, X500].\n      The two models\
    \ are most alike at the top of OSIRM Layer 3, where\n      the OSI Connectionless\
    \ Network Layer Protocol (CLNP) and the IPS\n      IP are quite similar. Connection-oriented\
    \ security services\n      offered in OSIRM Layer 3 are inapplicable in the IPS,\
    \ because the\n      IPS Internet Layer lacks the explicit, connection-oriented\
    \ service\n      offered in the OSIRM.\n   $ Internet Security Association and\
    \ Key Management Protocol (ISAKMP)\n      (I) An Internet IPsec protocol [R2408]\
    \ to negotiate, establish,\n      modify, and delete security associations, and\
    \ to exchange key\n      generation and authentication data, independent of the\
    \ details of\n      any specific key generation technique, key establishment protocol,\n\
    \      encryption algorithm, or authentication mechanism.\n      Tutorial: ISAKMP\
    \ supports negotiation of security associations for\n      protocols at all IPS\
    \ layers. By centralizing management of\n      security associations, ISAKMP reduces\
    \ duplicated functionality\n      within each protocol. ISAKMP can also reduce\
    \ connection setup\n      time, by negotiating a whole stack of services at once.\
    \ Strong\n      authentication is required on ISAKMP exchanges, and a digital\n\
    \      signature algorithm based on asymmetric cryptography is used\n      within\
    \ ISAKMP's authentication component.\n      ISAKMP negotiations are conducted\
    \ in two \"phases\":\n      -  \"Phase 1 negotiation\". A phase 1 negotiation\
    \ establishes a\n         security association to be used by ISAKMP to protect\
    \ its own\n         protocol operations.\n      -  \"Phase 2 negotiation\". A\
    \ phase 2 negotiation (which is\n         protected by a security association\
    \ that was established by a\n         phase 1 negotiation) establishes a security\
    \ association to be\n         used to protect the operations of a protocol other\
    \ than ISAKMP,\n         such as ESP.\n   $ Internet Society (ISOC)\n      (I)\
    \ A professional society concerned with Internet development\n      (including\
    \ technical Internet Standards); with how the Internet is\n      and can be used;\
    \ and with social, political, and technical issues\n      that result. The ISOC\
    \ Board of Trustees approves appointments to\n      the IAB from among nominees\
    \ submitted by the IETF nominating\n      committee. (RFC 2026)\n   $ Internet\
    \ Standard\n      (I) A specification, approved by the IESG and published as an\
    \ RFC,\n      that is stable and well-understood, is technically competent, has\n\
    \      multiple, independent, and interoperable implementations with\n      substantial\
    \ operational experience, enjoys significant public\n      support, and is recognizably\
    \ useful in some or all parts of the\n      Internet. (RFC 2026) (Compare: RFC.)\n\
    \      Tutorial: The \"Internet Standards Process\" is an activity of the\n  \
    \    ISOC and is organized and managed by the IAB and the IESG. The\n      process\
    \ is concerned with all protocols, procedures, and\n      conventions used in\
    \ or by the Internet, whether or not they are\n      part of the IPS. The \"Internet\
    \ Standards Track\" has three levels\n      of increasing maturity: Proposed Standard,\
    \ Draft Standard, and\n      Standard. (Compare: ISO, W3C.)\n   $ internetwork\n\
    \      (I) A system of interconnected networks; a network of networks.\n     \
    \ Usually shortened to \"internet\". (See: internet, Internet.)\n      Tutorial:\
    \ An internet can be built using OSIRM Layer 3 gateways to\n      implement connections\
    \ between a set of similar subnetworks. With\n      dissimilar subnetworks, i.e.,\
    \ subnetworks that differ in the Layer\n      3 protocol service they offer, an\
    \ internet can be built by\n      implementing a uniform internetwork protocol\
    \ (e.g., IP) that\n      operates at the top of Layer 3 and hides the underlying\n\
    \      subnetworks' heterogeneity from hosts that use communication\n      services\
    \ provided by the internet. (See: router.)\n   $ intranet\n      (I) A computer\
    \ network, especially one based on Internet\n      technology, that an organization\
    \ uses for its own internal (and\n      usually private) purposes and that is\
    \ closed to outsiders. (See:\n      extranet, VPN.)\n   $ intruder\n      (I)\
    \ An entity that gains or attempts to gain access to a system or\n      system\
    \ resource without having authorization to do so. (See:\n      intrusion. Compare:\
    \ adversary, cracker, hacker.)\n   $ intrusion\n      1. (I) A security event,\
    \ or a combination of multiple security\n      events, that constitutes a security\
    \ incident in which an intruder\n      gains, or attempts to gain, access to a\
    \ system or system resource\n      without having authorization to do so. (See:\
    \ IDS.)\n      2. (I) A type of threat action whereby an unauthorized entity\n\
    \      gains access to sensitive data by circumventing a system's\n      security\
    \ protections. (See: unauthorized disclosure.)\n      Usage: This type of threat\
    \ action includes the following subtypes:\n      -  \"Trespass\": Gaining physical\
    \ access to sensitive data by\n         circumventing a system's protections.\n\
    \      -  \"Penetration\": Gaining logical access to sensitive data by\n     \
    \    circumventing a system's protections.\n      -  \"Reverse engineering\":\
    \ Acquiring sensitive data by\n         disassembling and analyzing the design\
    \ of a system component.\n      -  \"Cryptanalysis\": Transforming encrypted data\
    \ into plain text\n         without having prior knowledge of encryption parameters\
    \ or\n         processes. (See: main entry for \"cryptanalysis\".)\n   $ intrusion\
    \ detection\n      (I) Sensing and analyzing system events for the purpose of\n\
    \      noticing (i.e., becoming aware of) attempts to access system\n      resources\
    \ in an unauthorized manner. (See: anomaly detection, IDS,\n      misuse detection.\
    \ Compare: extrusion detection.) [IDSAN, IDSSC,\n      IDSSE, IDSSY]\n      Usage:\
    \ This includes the following subtypes:\n      -  \"Active detection\": Real-time\
    \ or near-real-time analysis of\n         system event data to detect current\
    \ intrusions, which result in\n         an immediate protective response.\n  \
    \    -  \"Passive detection\": Off-line analysis of audit data to detect\n   \
    \      past intrusions, which are reported to the system security\n         officer\
    \ for corrective action. (Compare: security audit.)\n   $ intrusion detection\
    \ system (IDS)\n      1. (N) A process or subsystem, implemented in software or\n\
    \      hardware, that automates the tasks of (a) monitoring events that\n    \
    \  occur in a computer network and (b) analyzing them for signs of\n      security\
    \ problems. [SP31] (See: intrusion detection.)\n      2. (N) A security alarm\
    \ system to detect unauthorized entry.\n      [DC6/9].\n      Tutorial: Active\
    \ intrusion detection processes can be either host-\n      based or network-based:\n\
    \      -  \"Host-based\": Intrusion detection components -- traffic sensors\n\
    \         and analyzers -- run directly on the hosts that they are\n         intended\
    \ to protect.\n      -  \"Network-based\": Sensors are placed on subnetwork components,\n\
    \         and analysis components run either on subnetwork components or\n   \
    \      hosts.\n   $ invalidity date\n      (N) An X.509 CRL entry extension that\
    \ \"indicates the date at which\n      it is known or suspected that the [revoked\
    \ certificate's private\n      key] was compromised or that the certificate should\
    \ otherwise be\n      considered invalid.\" [X509].\n      Tutorial: This date\
    \ may be earlier than the revocation date in the\n      CRL entry, and may even\
    \ be earlier than the date of issue of\n      earlier CRLs. However, the invalidity\
    \ date is not, by itself,\n      sufficient for purposes of non-repudiation service.\
    \ For example,\n      to fraudulently repudiate a validly generated signature,\
    \ a private\n      key holder may falsely claim that the key was compromised at\
    \ some\n      time in the past.\n   $ IOTP\n      (I) See: Internet Open Trading\
    \ Protocol.\n   $ IP\n      (I) See: Internet Protocol.\n   $ IP address\n   \
    \   (I) A computer's internetwork address that is assigned for use by\n      IP\
    \ and other protocols.\n      Tutorial: An IP version 4 address (RFC 791) has\
    \ four 8-bit parts\n      and is written as a series of four decimal numbers separated\
    \ by\n      periods. Example: The address of the host named \"rosslyn.bbn.com\"\
    \n      is 192.1.7.10.\n      An IP version 6 address (RFC 2373) has eight 16-bit\
    \ parts and is\n      written as eight hexadecimal numbers separated by colons.\n\
    \      Examples: 1080:0:0:0:8:800:200C:417A and\n      FEDC:BA98:7654:3210:FEDC:BA98:7654:3210.\n\
    \   $ IP Security Option\n      (I) See: Internet Protocol Security Option.\n\
    \   $ IP Security Protocol (IPsec)\n      1a. (I) The name of the IETF working\
    \ group that is specifying an\n      architecture [R2401, R4301] and set of protocols\
    \ to provide\n      security services for IP traffic. (See: AH, ESP, IKE, SAD,\
    \ SPD.\n      Compare: IPSO.)\n      1b. (I) A collective name for the IP security\
    \ architecture [R4301]\n      and associated set of protocols (primarily AH, ESP,\
    \ and IKE).\n      Usage: In IDOCs that use the abbreviation \"IPsec\", the letters\n\
    \      \"IP\" SHOULD be in uppercase, and the letters \"sec\" SHOULD NOT.\n  \
    \    Tutorial: The security services provided by IPsec include access\n      control\
    \ service, connectionless data integrity service, data\n      origin authentication\
    \ service, protection against replays\n      (detection of the arrival of duplicate\
    \ datagrams, within a\n      constrained window), data confidentiality service,\
    \ and limited\n      traffic-flow confidentiality. IPsec specifies (a) security\n\
    \      protocols (AH and ESP), (b) security associations (what they are,\n   \
    \   how they work, how they are managed, and associated processing),\n      (c)\
    \ key management (IKE), and (d) algorithms for authentication\n      and encryption.\
    \ Implementation of IPsec is optional for IP version\n      4, but mandatory for\
    \ IP version 6. (See: transport mode, tunnel\n      mode.)\n   $ IPLI\n      (I)\
    \ See: Internet Private Line Interface.\n   $ IPRA\n      (I) See: Internet Policy\
    \ Registration Authority.\n   $ IPS\n      (I) See: Internet Protocol Suite.\n\
    \   $ IPsec\n      (I) See: IP Security Protocol.\n   $ IPSO\n      (I) See: Internet\
    \ Protocol Security Option.\n   $ ISAKMP\n      (I) See: Internet Security Association\
    \ and Key Management\n      Protocol.\n   $ ISO\n      (I) International Organization\
    \ for Standardization, a voluntary,\n      non-treaty, non-governmental organization,\
    \ established in 1947,\n      with voting members that are designated standards\
    \ bodies of\n      participating nations and non-voting observer organizations.\n\
    \      (Compare: ANSI, IETF, ITU-T, W3C.)\n      Tutorial: Legally, ISO is a Swiss,\
    \ non-profit, private\n      organization. ISO and the IEC (the International\
    \ Electrotechnical\n      Commission) form the specialized system for worldwide\n\
    \      standardization. National bodies that are members of ISO or IEC\n     \
    \ participate in developing international standards through ISO and\n      IEC\
    \ technical committees that deal with particular fields of\n      activity. Other\
    \ international governmental and non-governmental\n      organizations, in liaison\
    \ with ISO and IEC, also take part. (ANSI\n      is the U.S. voting member of\
    \ ISO. ISO is a class D member of ITU-\n      T.)\n      The ISO standards development\
    \ process has four levels of\n      increasing maturity: Working Draft (WD), Committee\
    \ Draft (CD),\n      Draft International Standard (DIS), and International Standard\n\
    \      (IS). (Compare: \"Internet Standards Track\" under \"Internet\n      Standard\"\
    .) In information technology, ISO and IEC have a joint\n      technical committee,\
    \ ISO/IEC JTC 1. DISs adopted by JTC 1 are\n      circulated to national bodies\
    \ for voting, and publication as an IS\n      requires approval by at least 75%\
    \ of the national bodies casting a\n      vote.\n   $ ISO 17799\n      (N) An\
    \ International Standard that is a code of practice, derived\n      from Part\
    \ 1 of British Standard 7799, for managing the security of\n      information\
    \ systems in an organization. This standard does not\n      provide definitive\
    \ or specific material on any security topic. It\n      provides general guidance\
    \ on a wide variety of topics, but\n      typically does not go into depth. (See:\
    \ IATF, [SP14].)\n   $ ISOC\n      (I) See: Internet Society.\n   $ issue\n  \
    \    (I) /PKI/ Generate and sign a digital certificate (or a CRL) and,\n     \
    \ usually, distribute it and make it available to potential\n      certificate\
    \ users (or CRL users). (See: certificate creation.)\n      Usage: The term \"\
    issuing\" is usually understood to refer not only\n      to creating a digital\
    \ certificate (or a CRL) but also to making it\n      available to potential users,\
    \ such as by storing it in a\n      repository or other directory or otherwise\
    \ publishing it. However,\n      the ABA [DSG] explicitly limits this term to\
    \ the creation process\n      and excludes any related publishing or distribution\
    \ process.\n   $ issuer\n      1. (I) /certificate, CRL/ The CA that signs a digital\
    \ certificate\n      or CRL.\n      Tutorial: An X.509 certificate always includes\
    \ the issuer's name.\n      The name may include a common name value.\n      2.\
    \ (O) /payment card, SET/ \"The financial institution or its agent\n      that\
    \ issues the unique primary account number to the cardholder\n      for the payment\
    \ card brand.\" [SET2]\n      Tutorial: The institution that establishes the account\
    \ for a\n      cardholder and issues the payment card also guarantees payment\
    \ for\n      authorized transactions that use the card in accordance with card\n\
    \      brand regulations and local legislation. [SET1]\n   $ ITAR\n      (O) See:\
    \ International Traffic in Arms Regulations.\n   $ ITSEC\n      (N) See: Information\
    \ Technology System Evaluation Criteria.\n   $ ITU-T\n      (N) International\
    \ Telecommunications Union, Telecommunication\n      Standardization Sector (formerly\
    \ \"CCITT\"), a United Nations treaty\n      organization that is composed mainly\
    \ of postal, telephone, and\n      telegraph authorities of the member countries\
    \ and that publishes\n      standards called \"Recommendations\". (See: X.400,\
    \ X.500.)\n      Tutorial: The Department of State represents the United States.\n\
    \      ITU-T works on many kinds of communication systems. ITU-T\n      cooperates\
    \ with ISO on communication protocol standards, and many\n      Recommendations\
    \ in that area are also published as an ISO standard\n      with an ISO name and\
    \ number.\n   $ IV\n      (I) See: initialization value.\n   $ jamming\n     \
    \ (N) An attack that attempts to interfere with the reception of\n      broadcast\
    \ communications. (See: anti-jam, denial of service.\n      Compare: flooding.)\n\
    \      Tutorial: Jamming uses \"interference\" as a type of \"obstruction\"\n\
    \      intended to cause \"disruption\". Jamming a broadcast signal is\n     \
    \ typically done by broadcasting a second signal that receivers\n      cannot\
    \ separate from the first one. Jamming is mainly thought of\n      in the context\
    \ of wireless communication, but also can be done in\n      some wired technologies,\
    \ such as LANs that use contention\n      techniques to share a broadcast medium.\n\
    \   $ KAK\n      (D) See: key-auto-key. (Compare: KEK.)\n   $ KDC\n      (I) See:\
    \ Key Distribution Center.\n   $ KEA\n      (N) See: Key Exchange Algorithm.\n\
    \   $ KEK\n      (I) See: key-encrypting key. (Compare: KAK.)\n   $ Kerberos\n\
    \      (I) A system developed at the Massachusetts Institute of\n      Technology\
    \ that depends on passwords and symmetric cryptography\n      (DES) to implement\
    \ ticket-based, peer entity authentication\n      service and access control service\
    \ distributed in a client-server\n      network environment. [R4120, Stei] (See:\
    \ realm.)\n      Tutorial: Kerberos was originally developed by Project Athena\
    \ and\n      is named for the mythical three-headed dog that guards Hades. The\n\
    \      system architecture includes authentication servers and ticket-\n     \
    \ granting servers that function as an ACC and a KDC.\n      RFC 4556 describes\
    \ extensions to the Kerberos specification that\n      modify the initial authentication\
    \ exchange between a client and\n      the KDC. The extensions employ public-key\
    \ cryptography to enable\n      the client and KDC to mutually authenticate and\
    \ establish shared,\n      symmetric keys that are used to complete the exchange.\
    \ (See:\n      PKINIT.)\n   $ kernel\n      (I) A small, trusted part of a system\
    \ that provides services on\n      which the other parts of the system depend.\
    \ (See: security\n      kernel.)\n   $ Kernelized Secure Operating System (KSOS)\n\
    \      (O) An MLS computer operating system, designed to be a provably\n     \
    \ secure replacement for UNIX Version 6, and consisting of a\n      security kernel,\
    \ non-kernel security-related utility programs, and\n      optional UNIX application\
    \ development and support environments.\n      [Perr]\n      Tutorial: KSOS-6\
    \ was the implementation on a SCOMP. KSOS-11 was\n      the implementation by\
    \ Ford Aerospace and Communications\n      Corporation on the DEC PDP-11/45 and\
    \ PDP-11/70 computers.\n   $ key\n      1a. (I) /cryptography/ An input parameter\
    \ used to vary a\n      transformation function performed by a cryptographic algorithm.\n\
    \      (See: private key, public key, storage key, symmetric key, traffic\n  \
    \    key. Compare: initialization value.)\n      1b. (O) /cryptography/ Used in\
    \ singular form as a collective noun\n      referring to keys or keying material.\
    \ Example: A fill device can\n      be used transfer key between two cryptographic\
    \ devices.\n      2. (I) /anti-jam/ An input parameter used to vary a process\
    \ that\n      determines patterns for an anti-jam measure. (See: frequency\n \
    \     hopping, spread spectrum.)\n      Tutorial: A key is usually specified as\
    \ a sequence of bits or\n      other symbols. If a key value needs to be kept\
    \ secret, the\n      sequence of symbols that comprise it should be random, or\
    \ at least\n      pseudorandom, because that makes the key harder for an adversary\n\
    \      to guess. (See: brute-force attack, cryptanalysis, strength.)\n   $ key\
    \ agreement (algorithm or protocol)\n      1. (I) A key establishment method (especially\
    \ one involving\n      asymmetric cryptography) by which two or more entities,\
    \ without\n      prior arrangement except a public exchange of data (such as public\n\
    \      keys), each can generate the same key value. That is, the method\n    \
    \  does not send a secret from one entity to the other; instead, both\n      entities,\
    \ without prior arrangement except a public exchange of\n      data, can compute\
    \ the same secret value, but that value cannot be\n      computed by other, unauthorized\
    \ entities. (See: Diffie-Hellman-\n      Merkle, key establishment, KEA, MQV.\
    \ Compare: key transport.)\n      2. (O) \"A method for negotiating a key value\
    \ on line without\n      transferring the key, even in an encrypted form, e.g.,\
    \ the Diffie-\n      Hellman technique.\" [X509] (See: Diffie-Hellman-Merkle.)\n\
    \      3. (O) \"The procedure whereby two different parties generate\n      shared\
    \ symmetric keys such that any of the shared symmetric keys\n      is a function\
    \ of the information contributed by all legitimate\n      participants, so that\
    \ no party [alone] can predetermine the value\n      of the key.\" [A9042]\n \
    \     Example: A message originator and the intended recipient can each\n    \
    \  use their own private key and the other's public key with the\n      Diffie-Hellman-Merkle\
    \ algorithm to first compute a shared secret\n      value and, from that value,\
    \ derive a session key to encrypt the\n      message.\n   $ key authentication\n\
    \      (N) \"The assurance of the legitimate participants in a key\n      agreement\
    \ [i.e., in a key-agreement protocol] that no non-\n      legitimate party possesses\
    \ the shared symmetric key.\" [A9042]\n   $ key-auto-key (KAK)\n      (D) \"Cryptographic\
    \ logic [i.e., a mode of operation] using\n      previous key to produce key.\"\
    \ [C4009, A1523] (See: CTAK,\n      /cryptographic operation/ under \"mode\".)\n\
    \      Deprecated Term: IDOCs SHOULD NOT use this term; it is neither\n      well-known\
    \ nor precisely defined. Instead, use terms associated\n      with modes that\
    \ are defined in standards, such as CBC, CFB, and\n      OFB.\n   $ key center\n\
    \      (I) A centralized, key-distribution process (used in symmetric\n      cryptography),\
    \ usually a separate computer system, that uses\n      master keys (i.e., KEKs)\
    \ to encrypt and distribute session keys\n      needed by a community of users.\n\
    \      Tutorial: An ANSI standard [A9017] defines two types of key\n      center:\
    \ \"key distribution center\" and \"key translation center\".\n   $ key confirmation\n\
    \      (N) \"The assurance [provided to] the legitimate participants in a\n  \
    \    key establishment protocol that the [parties that are intended to\n     \
    \ share] the symmetric key actually possess the shared symmetric\n      key.\"\
    \ [A9042]\n   $ key distribution\n      (I) A process that delivers a cryptographic\
    \ key from the location\n      where it is generated to the locations where it\
    \ is used in a\n      cryptographic algorithm. (See: key establishment, key management.)\n\
    \   $ key distribution center (KDC)\n      1. (I) A type of key center (used in\
    \ symmetric cryptography) that\n      implements a key-distribution protocol to\
    \ provide keys (usually,\n      session keys) to two (or more) entities that wish\
    \ to communicate\n      securely. (Compare: key translation center.)\n      2.\
    \ (N) \"COMSEC facility generating and distributing key in\n      electrical form.\"\
    \ [C4009]\n      Tutorial: A KDC distributes keys to Alice and Bob, who (a) wish\
    \ to\n      communicate with each other but do not currently share keys, (b)\n\
    \      each share a KEK with the KDC, and (c) may not be able to generate\n  \
    \    or acquire keys by themselves. Alice requests the keys from the\n      KDC.\
    \ The KDC generates or acquires the keys and makes two\n      identical sets.\
    \ The KDC encrypts one set in the KEK it shares with\n      Alice, and sends that\
    \ encrypted set to Alice. The KDC encrypts the\n      second set in the KEK it\
    \ shares with Bob, and either (a) sends\n      that encrypted set to Alice for\
    \ her to forward to Bob or (b) sends\n      it directly to Bob (although the latter\
    \ option is not supported in\n      the ANSI standard [A9017]).\n   $ key encapsulation\n\
    \      (N) A key recovery technique for storing knowledge of a\n      cryptographic\
    \ key by encrypting it with another key and ensuring\n      that only certain\
    \ third parties called \"recovery agents\" can\n      perform the decryption operation\
    \ to retrieve the stored key. Key\n      encapsulation typically permits direct\
    \ retrieval of a secret key\n      used to provide data confidentiality. (Compare:\
    \ key escrow.)\n   $ key-encrypting key (KEK)\n      (I) A cryptographic key that\
    \ (a) is used to encrypt other keys\n      (either DEKs or other TEKs) for transmission\
    \ or storage but (b)\n      (usually) is not used to encrypt application data.\
    \ Usage:\n      Sometimes called \"key-encryption key\".\n   $ key escrow\n  \
    \    (N) A key recovery technique for storing knowledge of a\n      cryptographic\
    \ key or parts thereof in the custody of one or more\n      third parties called\
    \ \"escrow agents\", so that the key can be\n      recovered and used in specified\
    \ circumstances. (Compare: key\n      encapsulation.)\n      Tutorial: Key escrow\
    \ is typically implemented with split knowledge\n      techniques. For example,\
    \ the Escrowed Encryption Standard [FP185]\n      entrusts two components of a\
    \ device-unique split key to separate\n      escrow agents. The agents provide\
    \ the components only to someone\n      legally authorized to conduct electronic\
    \ surveillance of\n      telecommunications encrypted by that specific device.\
    \ The\n      components are used to reconstruct the device-unique key, and it\n\
    \      is used to obtain the session key needed to decrypt\n      communications.\n\
    \   $ key establishment (algorithm or protocol)\n      1. (I) A procedure that\
    \ combines the key-generation and key-\n      distribution steps needed to set\
    \ up or install a secure\n      communication association.\n      2. (I) A procedure\
    \ that results in keying material being shared\n      among two or more system\
    \ entities. [A9042, SP56]\n      Tutorial: The two basic techniques for key establishment\
    \ are \"key\n      agreement\" and \"key transport\".\n   $ Key Exchange Algorithm\
    \ (KEA)\n      (N) A key-agreement method [SKIP, R2773] that is based on the\n\
    \      Diffie-Hellman-Merkle algorithm and uses 1024-bit asymmetric keys.\n  \
    \    (See: CAPSTONE, CLIPPER, FORTEZZA, SKIPJACK.)\n      Tutorial: KEA was developed\
    \ by NSA and formerly classified at the\n      U.S. DoD \"Secret\" level. On 23\
    \ June 1998, the NSA announced that\n      KEA had been declassified.\n   $ key\
    \ generation\n      (I) A process that creates the sequence of symbols that comprise\
    \ a\n      cryptographic key. (See: key management.)\n   $ key generator\n   \
    \   1. (I) An algorithm that uses mathematical rules to\n      deterministically\
    \ produce a pseudorandom sequence of cryptographic\n      key values.\n      2.\
    \ (I) An encryption device that incorporates a key-generation\n      mechanism\
    \ and applies the key to plain text to produce cipher text\n      (e.g., by exclusive\
    \ OR-ing (a) a bit-string representation of the\n      key with (b) a bit-string\
    \ representation of the plaintext).\n   $ key length\n      (I) The number of\
    \ symbols (usually stated as a number of bits)\n      needed to be able to represent\
    \ any of the possible values of a\n      cryptographic key. (See: key space.)\n\
    \   $ key lifetime\n      1. (D) Synonym for \"cryptoperiod\".\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use this term with\n      definition 1 because\
    \ a key's cryptoperiod may be only a part of\n      the key's lifetime. A key\
    \ could be generated at some time prior to\n      when its cryptoperiod begins\
    \ and might not be destroyed (i.e.,\n      zeroized) until some time after its\
    \ cryptoperiod ends.\n      2. (O) /MISSI/ An attribute of a MISSI key pair that\
    \ specifies a\n      time span that bounds the validity period of any MISSI X.509\n\
    \      public-key certificate that contains the public component of the\n    \
    \  pair. (See: cryptoperiod.)\n   $ key loader\n      (N) Synonym for \"fill device\"\
    .\n   $ key loading and initialization facility (KLIF)\n      (N) A place where\
    \ ECU hardware is activated after being\n      fabricated. (Compare: CLEF.)\n\
    \      Tutorial: Before going to its KLIF, an ECU is not ready to be\n      fielded,\
    \ usually because it is not yet able to receive DEKs. The\n      KLIF employs\
    \ trusted processes to complete the ECU by installing\n      needed data such\
    \ as KEKs, seed values, and, in some cases,\n      cryptographic software. After\
    \ KLIF processing, the ECU is ready\n      for deployment.\n   $ key management\n\
    \      1a. (I) The process of handling keying material during its life\n     \
    \ cycle in a cryptographic system; and the supervision and control\n      of that\
    \ process. (See: key distribution, key escrow, keying\n      material, public-key\
    \ infrastructure.)\n      Usage: Usually understood to include ordering, generating,\n\
    \      storing, archiving, escrowing, distributing, loading, destroying,\n   \
    \   auditing, and accounting for the material.\n      1b. (O) /NIST/ \"The activities\
    \ involving the handling of\n      cryptographic keys and other related security\
    \ parameters (e.g.,\n      IVs, counters) during the entire life cycle of the\
    \ keys, including\n      their generation, storage, distribution, entry and use,\
    \ deletion\n      or destruction, and archiving.\" [FP140, SP57]\n      2. (O)\
    \ /OSIRM/ \"The generation, storage, distribution, deletion,\n      archiving\
    \ and application of keys in accordance with a security\n      policy.\" [I7498-2]\n\
    \   $ Key Management Protocol (KMP)\n      (N) A protocol to establish a shared\
    \ symmetric key between a pair\n      (or a group) of users. (One version of KMP\
    \ was developed by SDNS,\n      and another by SILS.) Superseded by ISAKMP and\
    \ IKE.\n   $ key material\n      (D) Synonym for \"keying material\".\n      Deprecated\
    \ Usage: IDOCs SHOULD NOT use this term as a synonym for\n      \"keying material\"\
    .\n   $ key pair\n      (I) A set of mathematically related keys -- a public key\
    \ and a\n      private key -- that are used for asymmetric cryptography and are\n\
    \      generated in a way that makes it computationally infeasible to\n      derive\
    \ the private key from knowledge of the public key. (See:\n      Diffie-Hellman-Merkle,\
    \ RSA.)\n      Tutorial: A key pair's owner discloses the public key to other\n\
    \      system entities so they can use the key to (a) encrypt data, (b)\n    \
    \  verify a digital signature, or (c) generate a key with a key-\n      agreement\
    \ algorithm. The matching private key is kept secret by\n      the owner, who\
    \ uses it to (a') decrypt data, (b') generate a\n      digital signature, or (c')\
    \ generate a key with a key-agreement\n      algorithm.\n   $ key recovery\n \
    \     1. (I) /cryptanalysis/ A process for learning the value of a\n      cryptographic\
    \ key that was previously used to perform some\n      cryptographic operation.\
    \ (See: cryptanalysis, recovery.)\n      2. (I) /backup/ Techniques that provide\
    \ an intentional, alternate\n      means to access the key used for data confidentiality\
    \ service in\n      an encrypted association. [DoD4] (Compare: recovery.)\n  \
    \    Tutorial: It is assumed that the cryptographic system includes a\n      primary\
    \ means of obtaining the key through a key-establishment\n      algorithm or protocol.\
    \ For the secondary means, there are two\n      classes of key recovery techniques:\
    \ key encapsulation and key\n      escrow.\n   $ key space\n      (I) The range\
    \ of possible values of a cryptographic key; or the\n      number of distinct\
    \ transformations supported by a particular\n      cryptographic algorithm. (See:\
    \ key length.)\n   $ key translation center\n      (I) A type of key center that\
    \ implements a key-distribution\n      protocol (based on symmetric cryptography)\
    \ to convey keys between\n      two (or more) parties who wish to communicate\
    \ securely. (Compare:\n      key distribution center.)\n      Tutorial: A key\
    \ translation center transfers keys for future\n      communication between Bob\
    \ and Alice, who (a) wish to communicate\n      with each other but do not currently\
    \ share keys, (b) each share a\n      KEK with the center, and (c) have the ability\
    \ to generate or\n      acquire keys by themselves. Alice generates or acquires\
    \ a set of\n      keys for communication with Bob. Alice encrypts the set in the\
    \ KEK\n      she shares with the center and sends the encrypted set to the\n \
    \     center. The center decrypts the set, reencrypts the set in the KEK\n   \
    \   it shares with Bob, and either (a) sends that reencrypted set to\n      Alice\
    \ for her to forward to Bob or (b) sends it directly to Bob\n      (although direct\
    \ distribution is not supported in the ANSI\n      standard [A9017]).\n   $ key\
    \ transport (algorithm or protocol)\n      1. (I) A key establishment method by\
    \ which a secret key is\n      generated by a system entity in a communication\
    \ association and\n      securely sent to another entity in the association. (Compare:\
    \ key\n      agreement.)\n      Tutorial: Either (a) one entity generates a secret\
    \ key and\n      securely sends it to the other entity, or (b) each entity\n \
    \     generates a secret value and securely sends it to the other\n      entity,\
    \ where the two values are combined to form a secret key.\n      For example,\
    \ a message originator can generate a random session\n      key and then use the\
    \ RSA algorithm to encrypt that key with the\n      public key of the intended\
    \ recipient.\n      2. (O) \"The procedure to send a symmetric key from one party\
    \ to\n      other parties. As a result, all legitimate participants share a\n\
    \      common symmetric key in such a way that the symmetric key is\n      determined\
    \ entirely by one party.\" [A9042]\n   $ key update\n      1. (I) Derive a new\
    \ key from an existing key. (Compare: rekey.)\n      2. (O) Irreversible cryptographic\
    \ process that modifies a key to\n      produce a new key. [C4009]\n   $ key validation\n\
    \      1. (I) \"The procedure for the receiver of a public key to check\n    \
    \  that the key conforms to the arithmetic requirements for such a\n      key\
    \ in order to thwart certain types of attacks.\" [A9042] (See:\n      weak key)\n\
    \      2. (D) Synonym for \"certificate validation\".\n      Deprecated Usage:\
    \ IDOCs SHOULD NOT use the term as a synonym for\n      \"certificate validation\"\
    ; that would unnecessarily duplicate the\n      meaning of the latter term and\
    \ mix concepts in a potentially\n      misleading way. In validating an X.509\
    \ public-key certificate, the\n      public key contained in the certificate is\
    \ normally treated as an\n      opaque data object.\n   $ keyed hash\n      (I)\
    \ A cryptographic hash (e.g., [R1828]) in which the mapping to a\n      hash result\
    \ is varied by a second input parameter that is a\n      cryptographic key. (See:\
    \ checksum.)\n      Tutorial: If the input data object is changed, a new,\n  \
    \    corresponding hash result cannot be correctly computed without\n      knowledge\
    \ of the secret key. Thus, the secret key protects the\n      hash result so it\
    \ can be used as a checksum even when there is a\n      threat of an active attack\
    \ on the data. There are two basic types\n      of keyed hash:\n      -  A function\
    \ based on a keyed encryption algorithm. Example: Data\n         Authentication\
    \ Code.\n      -  A function based on a keyless hash that is enhanced by\n   \
    \      combining (e.g., by concatenating) the input data object\n         parameter\
    \ with a key parameter before mapping to the hash\n         result. Example: HMAC.\n\
    \   $ keying material\n      1. (I) Data that is needed to establish and maintain\
    \ a\n      cryptographic security association, such as keys, key pairs, and\n\
    \      IVs.\n      2. (O) \"Key, code, or authentication information in physical\
    \ or\n      magnetic form.\" [C4009] (Compare: COMSEC material.)\n   $ keying\
    \ material identifier (KMID)\n      1. (I) An identifier assigned to an item of\
    \ keying material.\n      2. (O) /MISSI/ A 64-bit identifier that is assigned\
    \ to a key pair\n      when the public key is bound in a MISSI X.509 public-key\n\
    \      certificate.\n   $ Khafre\n      (N) A patented, symmetric block cipher\
    \ designed by Ralph C. Merkle\n      as a plug-in replacement for DES. [Schn]\n\
    \      Tutorial: Khafre was designed for efficient encryption of small\n     \
    \ amounts of data. However, because Khafre does not precompute\n      tables used\
    \ for encryption, it is slower than Khufu for large\n      amounts of data.\n\
    \   $ Khufu\n      (N) A patented, symmetric block cipher designed by Ralph C.\
    \ Merkle\n      as a plug-in replacement for DES. [Schn]\n      Tutorial: Khufu\
    \ was designed for fast encryption of large amounts\n      of data. However, because\
    \ Khufu precomputes tables used in\n      encryption, it is less efficient than\
    \ Khafre for small amounts of\n      data.\n   $ KLIF\n      (N) See: key loading\
    \ and initialization facility.\n   $ KMID\n      (I) See: keying material identifier.\n\
    \   $ known-plaintext attack\n      (I) A cryptanalysis technique in which the\
    \ analyst tries to\n      determine the key from knowledge of some plaintext-ciphertext\n\
    \      pairs (although the analyst may also have other clues, such as\n      knowing\
    \ the cryptographic algorithm).\n   $ kracker\n      (O) Old spelling for \"cracker\"\
    .\n   $ KSOS, KSOS-6, KSOS-11\n      (O) See: Kernelized Secure Operating System.\n\
    \   $ L2F\n      (N) See: Layer 2 Forwarding Protocol.\n   $ L2TP\n      (N) See:\
    \ Layer 2 Tunneling Protocol.\n   $ label\n      See: time stamp, security label.\n\
    \   $ laboratory attack\n      (O) \"Use of sophisticated signal recovery equipment\
    \ in a\n      laboratory environment to recover information from data storage\n\
    \      media.\" [C4009]\n   $ LAN\n      (I) Abbreviation for \"local area network\"\
    \ [R1983]. (See: [FP191].)\n   $ land attack\n      (I) A denial-of-service attack\
    \ that sends an IP packet that (a)\n      has the same address in both the Source\
    \ Address and Destination\n      Address fields and (b) contains a TCP SYN packet\
    \ that has the same\n      port number in both the Source Port and Destination\
    \ Port fields.\n      Derivation: This single-packet attack was named for \"land\"\
    , the\n      program originally published by the cracker who invented this\n \
    \     exploit. Perhaps that name was chosen because the inventor thought\n   \
    \   of multi-packet (i.e., flooding) attacks as arriving by sea.\n   $ Language\
    \ of Temporal Ordering Specification (LOTOS)\n      (N) A language (ISO 8807-1990)\
    \ for formal specification of\n      computer network protocols; describes the\
    \ order in which events\n      occur.\n   $ lattice\n      (I) A finite set together\
    \ with a partial ordering on its elements\n      such that for every pair of elements\
    \ there is a least upper bound\n      and a greatest lower bound.\n      Example:\
    \ A lattice is formed by a finite set S of security levels\n      -- i.e., a set\
    \ S of all ordered pairs (x,c), where x is one of a\n      finite set X of hierarchically\
    \ ordered classification levels X(1),\n      non-hierarchical categories C(1),\
    \ ..., C(M) -- together with the\n      \"dominate\" relation. Security level\
    \ (x,c) is said to \"dominate\"\n      (x',c') if and only if (a) x is greater\
    \ (higher) than or equal to\n      x' and (b) c includes at least all of the elements\
    \ of c'. (See:\n      dominate, lattice model.)\n      Tutorial: Lattices are\
    \ used in some branches of cryptography, both\n      as a basis for hard computational\
    \ problems upon which\n      cryptographic algorithms can be defined, and also\
    \ as a basis for\n      attacks on cryptographic algorithms.\n   $ lattice model\n\
    \      1. (I) A description of the semantic structure formed by a finite\n   \
    \   set of security levels, such as those used in military\n      organizations.\
    \ (See: dominate, lattice, security model.)\n      2. (I) /formal model/ A model\
    \ for flow control in a system, based\n      on the lattice that is formed by\
    \ the finite security levels in a\n      system and their partial ordering. [Denn]\n\
    \   $ Law Enforcement Access Field (LEAF)\n      (N) A data item that is automatically\
    \ embedded in data encrypted\n      by devices (e.g., CLIPPER chip) that implement\
    \ the Escrowed\n      Encryption Standard.\n   $ Layer 1, 2, 3, 4, 5, 6, 7\n \
    \     (N) See: OSIRM.\n   $ Layer 2 Forwarding Protocol (L2F)\n      (N) An Internet\
    \ protocol (originally developed by Cisco\n      Corporation) that uses tunneling\
    \ of PPP over IP to create a\n      virtual extension of a dial-up link across\
    \ a network, initiated by\n      the dial-up server and transparent to the dial-up\
    \ user. (See:\n      L2TP.)\n   $ Layer 2 Tunneling Protocol (L2TP)\n      (N)\
    \ An Internet client-server protocol that combines aspects of\n      PPTP and\
    \ L2F and supports tunneling of PPP over an IP network or\n      over frame relay\
    \ or other switched network. (See: VPN.)\n      Tutorial: PPP can in turn encapsulate\
    \ any OSIRM Layer 3 protocol.\n      Thus, L2TP does not specify security services;\
    \ it depends on\n      protocols layered above and below it to provide any needed\n\
    \      security.\n   $ LDAP\n      (I) See: Lightweight Directory Access Protocol.\n\
    \   $ least common mechanism\n      (I) The principle that a security architecture\
    \ should minimize\n      reliance on mechanisms that are shared by many users.\n\
    \      Tutorial: Shared mechanisms may include cross-talk paths that\n      permit\
    \ a breach of data security, and it is difficult to make a\n      single mechanism\
    \ operate in a correct and trusted manner to the\n      satisfaction of a wide\
    \ range of users.\n   $ least privilege\n      (I) The principle that a security\
    \ architecture should be designed\n      so that each system entity is granted\
    \ the minimum system resources\n      and authorizations that the entity needs\
    \ to do its work. (Compare:\n      economy of mechanism, least trust.)\n     \
    \ Tutorial: This principle tends to limit damage that can be caused\n      by\
    \ an accident, error, or unauthorized act. This principle also\n      tends to\
    \ reduce complexity and promote modularity, which can make\n      certification\
    \ easier and more effective. This principle is similar\n      to the principle\
    \ of protocol layering, wherein each layer provides\n      specific, limited communication\
    \ services, and the functions in one\n      layer are independent of those in\
    \ other layers.\n   $ least trust\n      (I) The principle that a security architecture\
    \ should be designed\n      in a way that minimizes (a) the number of components\
    \ that require\n      trust and (b) the extent to which each component is trusted.\n\
    \      (Compare: least privilege, trust level.)\n   $ legacy system\n      (I)\
    \ A system that is in operation but will not be improved or\n      expanded while\
    \ a new system is being developed to supersede it.\n   $ legal non-repudiation\n\
    \      (I) See: secondary definition under \"non-repudiation\".\n   $ leap of\
    \ faith\n      1. (I) /general security/ Operating a system as though it began\n\
    \      operation in a secure state, even though it cannot be proven that\n   \
    \   such a state was established (i.e., even though a security\n      compromise\
    \ might have occurred at or before the time when\n      operation began).\n  \
    \    2. (I) /COMSEC/ The initial part, i.e., the first communication\n      step,\
    \ or steps, of a protocol that is vulnerable to attack\n      (especially a man-in-the-middle\
    \ attack) during that part but, if\n      that part is completed without being\
    \ attacked, is subsequently not\n      vulnerable in later steps (i.e., results\
    \ in a secure communication\n      association for which no man-in-the-middle\
    \ attack is possible).\n      Usage: This term is listed in English dictionaries,\
    \ but their\n      definitions are broad and can be interpreted in many ways in\n\
    \      Internet contexts. Similarly, the definition stated here can be\n     \
    \ interpreted in several ways. Therefore, IDOCs that use this term\n      (especially\
    \ IDOCs that are protocol specifications) SHOULD state a\n      more specific\
    \ definition for it.\n      Tutorial: In a protocol, a leap of faith typically\
    \ consists of\n      accepting a claim of peer identity, data origin, or data\
    \ integrity\n      without authenticating that claim. When a protocol includes\
    \ such a\n      step, the protocol might also be designed so that if a man-in-\n\
    \      the-middle attack succeeds during the vulnerable first part, then\n   \
    \   the attacker must remain in the middle for all subsequent\n      exchanges\
    \ or else one of the legitimate parties will be able to\n      detect the attack.\n\
    \   $ level of concern\n      (N) /U.S. DoD/ A rating assigned to an information\
    \ system that\n      indicates the extent to which protective measures, techniques,\
    \ and\n      procedures must be applied. (See: critical, sensitive, level of\n\
    \      robustness.)\n   $ level of robustness\n      (N) /U.S. DoD/ A characterization\
    \ of (a) the strength of a\n      security function, mechanism, service, or solution\
    \ and (b) the\n      assurance (or confidence) that it is implemented and functioning.\n\
    \      [Cons, IATF] (See: level of concern.)\n   $ Liberty Alliance\n      (O)\
    \ An international consortium of more than 150 commercial,\n      nonprofit, and\
    \ governmental organizations that was created in 2001\n      to address technical,\
    \ business, and policy problems of identity\n      and identity-based Web services\
    \ and develop a standard for\n      federated network identity that supports current\
    \ and emerging\n      network devices.\n   $ Lightweight Directory Access Protocol\
    \ (LDAP)\n      (I) An Internet client-server protocol (RFC 3377) that supports\n\
    \      basic use of the X.500 Directory (or other directory servers)\n      without\
    \ incurring the resource requirements of the full Directory\n      Access Protocol\
    \ (DAP).\n      Tutorial: Designed for simple management and browser applications\n\
    \      that provide simple read/write interactive directory service.\n      Supports\
    \ both simple authentication and strong authentication of\n      the client to\
    \ the directory server.\n   $ link\n      1a. (I) A communication facility or\
    \ physical medium that can\n      sustain data communications between multiple\
    \ network nodes, in the\n      protocol layer immediately below IP. (RFC 3753)\n\
    \      1b. (I) /subnetwork/ A communication channel connecting subnetwork\n  \
    \    relays (especially one between two packet switches) that is\n      implemented\
    \ at OSIRM Layer 2. (See: link encryption.)\n      Tutorial: The relay computers\
    \ assume that links are logically\n      passive. If a computer at one end of\
    \ a link sends a sequence of\n      bits, the sequence simply arrives at the other\
    \ end after a finite\n      time, although some bits may have been changed either\
    \ accidentally\n      (errors) or by active wiretapping.\n      2. (I) /World\
    \ Wide Web/ See: hyperlink.\n   $ link encryption\n      (I) Stepwise (link-by-link)\
    \ protection of data that flows between\n      two points in a network, provided\
    \ by encrypting data separately on\n      each network link, i.e., by encrypting\
    \ data when it leaves a host\n      or subnetwork relay and decrypting when it\
    \ arrives at the next\n      host or relay. Each link may use a different key\
    \ or even a\n      different algorithm. [R1455] (Compare: end-to-end encryption.)\n\
    \   $ liveness\n      (I) A property of a communication association or a feature\
    \ of a\n      communication protocol that provides assurance to the recipient\
    \ of\n      data that the data is being freshly transmitted by its originator,\n\
    \      i.e., that the data is not being replayed, by either the\n      originator\
    \ or a third party, from a previous transmission. (See:\n      fresh, nonce, replay\
    \ attack.)\n   $ logic bomb\n      (I) Malicious logic that activates when specified\
    \ conditions are\n      met. Usually intended to cause denial of service or otherwise\n\
    \      damage system resources. (See: Trojan horse, virus, worm.)\n   $ login\n\
    \      1a. (I) An act by which a system entity establishes a session in\n    \
    \  which the entity can use system resources. (See: principal,\n      session.)\n\
    \      1b. (I) An act by which a system user has its identity\n      authenticated\
    \ by the system. (See: principal, session.)\n      Usage: Usually understood to\
    \ be accomplished by providing an\n      identifier and matching authentication\
    \ information (e.g., a\n      password) to a security mechanism that authenticates\
    \ the user's\n      identity; but sometimes refers to establishing a connection\
    \ with a\n      server when no authentication or specific authorization is\n \
    \     involved.\n      Derivation: Refers to \"log\" file, a security audit trail\
    \ that\n      records (a) security events, such as the beginning of a session,\n\
    \      and (b) the names of the system entities that initiate events.\n   $ long\
    \ title\n      (O) /U.S. Government/ \"Descriptive title of [an item of COMSEC\n\
    \      material].\" [C4009] (Compare: short title.)\n   $ low probability of detection\n\
    \      (I) Result of TRANSEC measures used to hide or disguise a\n      communication.\n\
    \   $ low probability of intercept\n      (I) Result of TRANSEC measures used\
    \ to prevent interception of a\n      communication.\n   $ LOTOS\n      (N) See:\
    \ Language of Temporal Ordering Specification.\n   $ MAC\n      (N) See: mandatory\
    \ access control, Message Authentication Code.\n      Deprecated Usage: IDOCs\
    \ that use this term SHOULD state a\n      definition for it because this abbreviation\
    \ is ambiguous.\n   $ magnetic remanence\n      (N) Magnetic representation of\
    \ residual information remaining on a\n      magnetic medium after the medium\
    \ has been cleared. [NCS25] (See:\n      clear, degauss, purge.)\n   $ main mode\n\
    \      (I) See: /IKE/ under \"mode\".\n   $ maintenance hook\n      (N) \"Special\
    \ instructions (trapdoors) in software allowing easy\n      maintenance and additional\
    \ feature development. Since maintenance\n      hooks frequently allow entry into\
    \ the code without the usual\n      checks, they are a serious security risk if\
    \ they are not removed\n      prior to live implementation.\" [C4009] (See: back\
    \ door.)\n   $ malicious logic\n      (I) Hardware, firmware, or software that\
    \ is intentionally included\n      or inserted in a system for a harmful purpose.\
    \ (See: logic bomb,\n      Trojan horse, spyware, virus, worm. Compare: secondary\
    \ definitions\n      under \"corruption\", \"incapacitation\", \"masquerade\"\
    , and \"misuse\".)\n   $ malware\n      (D) A contraction of \"malicious software\"\
    . (See: malicious logic.)\n      Deprecated Term: IDOCs SHOULD NOT use this term;\
    \ it is not listed\n      in most dictionaries and could confuse international\
    \ readers.\n   $ MAN\n      (I) metropolitan area network.\n   $ man-in-the-middle\
    \ attack\n      (I) A form of active wiretapping attack in which the attacker\n\
    \      intercepts and selectively modifies communicated data to\n      masquerade\
    \ as one or more of the entities involved in a\n      communication association.\
    \ (See: hijack attack, piggyback attack.)\n      Tutorial: For example, suppose\
    \ Alice and Bob try to establish a\n      session key by using the Diffie-Hellman-Merkle\
    \ algorithm without\n      data origin authentication service. A \"man in the\
    \ middle\" could\n      (a) block direct communication between Alice and Bob and\
    \ then (b)\n      masquerade as Alice sending data to Bob, (c) masquerade as Bob\n\
    \      sending data to Alice, (d) establish separate session keys with\n     \
    \ each of them, and (e) function as a clandestine proxy server\n      between\
    \ them to capture or modify sensitive information that Alice\n      and Bob think\
    \ they are sending only to each other.\n   $ manager\n      (I) A person who controls\
    \ the service configuration of a system or\n      the functional privileges of\
    \ operators and other users. (See:\n      administrative security. Compare: operator,\
    \ SSO, user.)\n   $ mandatory access control\n      1. (I) An access control service\
    \ that enforces a security policy\n      based on comparing (a) security labels,\
    \ which indicate how\n      sensitive or critical system resources are, with (b)\
    \ security\n      clearances, which indicate that system entities are eligible\
    \ to\n      access certain resources. (See: discretionary access control, MAC,\n\
    \      rule-based security policy.)\n      Derivation: This kind of access control\
    \ is called \"mandatory\"\n      because an entity that has clearance to access\
    \ a resource is not\n      permitted, just by its own volition, to enable another\
    \ entity to\n      access that resource.\n      2. (O) \"A means of restricting\
    \ access to objects based on the\n      sensitivity (as represented by a label)\
    \ of the information\n      contained in the objects and the formal authorization\
    \ (i.e.,\n      clearance) of subjects to access information of such sensitivity.\"\
    \n      [DoD1]\n   $ manipulation detection code\n      (D) Synonym for \"checksum\"\
    .\n      Deprecated Term: IDOCs SHOULD NOT use this term as a synonym for\n  \
    \    \"checksum\"; the word \"manipulation\" implies protection against\n    \
    \  active attacks, which an ordinary checksum might not provide.\n      Instead,\
    \ if such protection is intended, use \"protected checksum\"\n      or some particular\
    \ type thereof, depending on which is meant. If\n      such protection is not\
    \ intended, use \"error detection code\" or\n      some specific type of checksum\
    \ that is not protected.\n   $ marking\n      See: time stamp, security marking.\n\
    \   $ MARS\n      (O) A symmetric, 128-bit block cipher with variable key length\n\
    \      (128 to 448 bits), developed by IBM as a candidate for the AES.\n   $ Martian\n\
    \      (D) /slang/ A packet that arrives unexpectedly at the wrong\n      address\
    \ or on the wrong network because of incorrect routing or\n      because it has\
    \ a non-registered or ill-formed IP address. [R1208]\n      Deprecated Term: It\
    \ is likely that other cultures use different\n      metaphors for this concept.\
    \ Therefore, to avoid international\n      misunderstanding, IDOCs SHOULD NOT\
    \ use this term. (See: Deprecated\n      Usage under \"Green Book\".)\n   $ masquerade\n\
    \      (I) A type of threat action whereby an unauthorized entity gains\n    \
    \  access to a system or performs a malicious act by illegitimately\n      posing\
    \ as an authorized entity. (See: deception.)\n      Usage: This type of threat\
    \ action includes the following subtypes:\n      -  \"Spoof\": Attempt by an unauthorized\
    \ entity to gain access to a\n         system by posing as an authorized user.\n\
    \      -  \"Malicious logic\": In context of masquerade, any hardware,\n     \
    \    firmware, or software (e.g., Trojan horse) that appears to\n         perform\
    \ a useful or desirable function, but actually gains\n         unauthorized access\
    \ to system resources or tricks a user into\n         executing other malicious\
    \ logic. (See: corruption,\n         incapacitation, main entry for \"malicious\
    \ logic\", misuse.)\n   $ MCA\n      (O) See: merchant certification authority.\n\
    \   $ MD2\n      (N) A cryptographic hash [R1319] that produces a 128-bit hash\n\
    \      result, was designed by Ron Rivest, and is similar to MD4 and MD5\n   \
    \   but slower.\n      Derivation: Apparently, an abbreviation of \"message digest\"\
    , but\n      that term is deprecated by this Glossary.\n   $ MD4\n      (N) A\
    \ cryptographic hash [R1320] that produces a 128-bit hash\n      result and was\
    \ designed by Ron Rivest. (See: Derivation under\n      \"MD2\", SHA-1.)\n   $\
    \ MD5\n      (N) A cryptographic hash [R1321] that produces a 128-bit hash\n \
    \     result and was designed by Ron Rivest to be an improved version of\n   \
    \   MD4. (See: Derivation under \"MD2\".)\n   $ merchant\n      (O) /SET/ \"A\
    \ seller of goods, services, and/or other information\n      who accepts payment\
    \ for these items electronically.\" [SET2] A\n      merchant may also provide\
    \ electronic selling services and/or\n      electronic delivery of items for sale.\
    \ With SET, the merchant can\n      offer its cardholders secure electronic interactions,\
    \ but a\n      merchant that accepts payment cards is required to have a\n   \
    \   relationship with an acquirer. [SET1, SET2]\n   $ merchant certificate\n \
    \     (O) /SET/ A public-key certificate issued to a merchant. Sometimes\n   \
    \   used to refer to a pair of such certificates where one is for\n      digital\
    \ signature use and the other is for encryption.\n   $ merchant certification\
    \ authority (MCA)\n      (O) /SET/ A CA that issues digital certificates to merchants\
    \ and\n      is operated on behalf of a payment card brand, an acquirer, or\n\
    \      another party according to brand rules. Acquirers verify and\n      approve\
    \ requests for merchant certificates prior to issuance by\n      the MCA. An MCA\
    \ does not issue a CRL, but does distribute CRLs\n      issued by root CAs, brand\
    \ CAs, geopolitical CAs, and payment\n      gateway CAs. [SET2]\n   $ mesh PKI\n\
    \      (I) A non-hierarchical PKI architecture in which there are several\n  \
    \    trusted CAs rather than a single root. Each certificate user bases\n    \
    \  path validations on the public key of one of the trusted CAs,\n      usually\
    \ the one that issued that user's own public-key\n      certificate. Rather than\
    \ having superior-to-subordinate\n      relationships between CAs, the relationships\
    \ are peer-to-peer, and\n      CAs issue cross-certificates to each other. (Compare:\
    \ hierarchical\n      PKI, trust-file PKI.)\n   $ Message Authentication Code\
    \ (MAC), message authentication code\n      1. (N) /capitalized/ A specific ANSI\
    \ standard for a checksum that\n      is computed with a keyed hash that is based\
    \ on DES. [A9009] Usage:\n      a.k.a. Data Authentication Code, which is a U.S.\
    \ Government\n      standard. [FP113] (See: MAC.)\n      2. (D) /not capitalized/\
    \ Synonym for \"error detection code\".\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use the uncapitalized form\n      \"message authentication code\". Instead,\
    \ use \"checksum\", \"error\n      detection code\", \"hash\", \"keyed hash\"\
    , \"Message Authentication\n      Code\", or \"protected checksum\", depending\
    \ on what is meant. (See:\n      authentication code.)\n      The uncapitalized\
    \ form mixes concepts in a potentially misleading\n      way. The word \"message\"\
    \ is misleading because it implies that the\n      mechanism is particularly suitable\
    \ for or limited to electronic\n      mail (see: Message Handling Systems). The\
    \ word \"authentication\" is\n      misleading because the mechanism primarily\
    \ serves a data integrity\n      function rather than an authentication function.\
    \ The word \"code\"\n      is misleading because it implies that either encoding\
    \ or\n      encryption is involved or that the term refers to computer\n     \
    \ software.\n   $ message digest\n      (D) Synonym for \"hash result\". (See:\
    \ cryptographic hash.)\n      Deprecated Term: IDOCs SHOULD NOT use this term\
    \ as a synonym for\n      \"hash result\"; this term unnecessarily duplicates\
    \ the meaning of\n      the other, more general term and mixes concepts in a potentially\n\
    \      misleading way. The word \"message\" is misleading because it\n      implies\
    \ that the mechanism is particularly suitable for or limited\n      to electronic\
    \ mail (see: Message Handling Systems).\n   $ message handling system\n      (D)\
    \ Synonym for the Internet electronic mail system.\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term, because it could\n      be confused with Message Handling\
    \ System. Instead, use \"Internet\n      electronic mail\" or some other, more\
    \ specific term.\n   $ Message Handling System\n      (O) An ITU-T system concept\
    \ that encompasses the notion of\n      electronic mail but defines more comprehensive\
    \ OSI systems and\n      services that enable users to exchange messages on a\
    \ store-and-\n      forward basis. (The ISO equivalent is \"Message Oriented Text\n\
    \      Interchange System\".) (See: X.400.)\n   $ message indicator\n      1.\
    \ (D) /cryptographic function/ Synonym for \"initialization\n      value\". (Compare:\
    \ indicator.)\n      2. (D) \"Sequence of bits transmitted over a communications\
    \ system\n      for synchronizing cryptographic equipment.\" [C4009]\n      Deprecated\
    \ Term: IDOCs SHOULD NOT use this term as a synonym for\n      \"initialization\
    \ value\"; the term mixes concepts in a potentially\n      misleading way. The\
    \ word \"message\" is misleading because it\n      suggests that the mechanism\
    \ is specific to electronic mail. (See:\n      Message Handling System.)\n   $\
    \ message integrity check\n   $ message integrity code (MIC)\n      (D) Synonyms\
    \ for some form of \"checksum\".\n      Deprecated Term: IDOCs SHOULD NOT use\
    \ these terms for any form of\n      checksum. Instead, use \"checksum\", \"error\
    \ detection code\", \"hash\",\n      \"keyed hash\", \"Message Authentication\
    \ Code\", or \"protected\n      checksum\", depending on what is meant.\n    \
    \  These two terms mix concepts in potentially misleading ways. The\n      word\
    \ \"message\" is misleading because it suggests that the\n      mechanism is particularly\
    \ suitable for or limited to electronic\n      mail. The word \"integrity\" is\
    \ misleading because the checksum may\n      be used to perform a data origin\
    \ authentication function rather\n      than an integrity function. The word \"\
    code\" is misleading because\n      it suggests either that encoding or encryption\
    \ is involved or that\n      the term refers to computer software.\n   $ Message\
    \ Security Protocol (MSP)\n      (N) A secure message handling protocol [SDNS7]\
    \ for use with X.400\n      and Internet mail protocols. Developed by NSA's SDNS\
    \ program and\n      used in the U.S. DoD's Defense Message System.\n   $ meta-data\n\
    \      (I) Descriptive information about a data object; i.e., data about\n   \
    \   data, or data labels that describe other data. (See: security\n      label.\
    \ Compare: metadata)\n      Tutorial: Meta-data can serve various management purposes:\n\
    \      -  System management: File name, type, size, creation date.\n      -  Application\
    \ management: Document title, version, author.\n      -  Usage management: Data\
    \ categories, keywords, classifications.\n      Meta-data can be associated with\
    \ a data object in two basic ways:\n      -  Explicitly: Be part of the data object\
    \ (e.g., a header field of\n         a data file or packet) or be linked to the\
    \ object.\n      -  Implicitly: Be associated with the data object because of\
    \ some\n         other, explicit attribute of the object.\n   $ metadata, Metadata(trademark),\
    \ METADATA(trademark)\n      (D) Proprietary variants of \"meta-data\". (See:\
    \ SPAM(trademark).)\n      Deprecated Usage: IDOCs SHOULD NOT use these unhypenated\
    \ forms;\n      IDOCs SHOULD use only the uncapitalized, hyphenated \"meta-data\"\
    .\n      The terms \"Metadata\" and \"METADATA\" are claimed as registered\n \
    \     trademarks (numbers 1,409,260 and 2,185,504) owned by The Metadata\n   \
    \   Company, originally known as Metadata Information Partners, a\n      company\
    \ founded by Jack Myers. The status of \"metadata\" is\n      unclear.\n   $ MHS\n\
    \      (N) See: message handling system.\n   $ MIC\n      (D) See: message integrity\
    \ code.\n   $ MIME\n      (I) See: Multipurpose Internet Mail Extensions.\n  \
    \ $ MIME Object Security Services (MOSS)\n      (I) An Internet protocol [R1848]\
    \ that applies end-to-end\n      encryption and digital signature to MIME message\
    \ content, using\n      symmetric cryptography for encryption and asymmetric cryptography\n\
    \      for key distribution and signature. MOSS is based on features and\n   \
    \   specifications of PEM. (See: S/MIME.)\n   $ Minimum Interoperability Specification\
    \ for PKI Components (MISPC)\n      (N) A technical description to provide a basis\
    \ for interoperation\n      between PKI components from different vendors; consists\
    \ primarily\n      of a profile of certificate and CRL extensions and a set of\n\
    \      transactions for PKI operation. [SP15]\n   $ misappropriation\n      (I)\
    \ A type of threat action whereby an entity assumes unauthorized\n      logical\
    \ or physical control of a system resource. (See:\n      usurpation.)\n      Usage:\
    \ This type of threat action includes the following subtypes:\n      -  Theft\
    \ of data: Unauthorized acquisition and use of data\n         contained in a system.\n\
    \      -  Theft of service: Unauthorized use of a system service.\n      -  Theft\
    \ of functionality: Unauthorized acquisition of actual\n         hardware, firmware,\
    \ or software of a system component.\n   $ MISPC\n      (N) See: Minimum Interoperability\
    \ Specification for PKI\n      Components.\n   $ MISSI\n      (O) Multilevel Information\
    \ System Security Initiative, an NSA\n      program to encourage development of\
    \ interoperable, modular\n      products for constructing secure network information\
    \ systems in\n      support of a wide variety of U.S. Government missions. (See:\
    \ MSP,\n      SP3, SP4.)\n   $ MISSI user\n      (O) /MISSI/ A system entity that\
    \ is the subject of one or more\n      MISSI X.509 public-key certificates issued\
    \ under a MISSI\n      certification hierarchy. (See: personality.)\n      Tutorial:\
    \ MISSI users include both end users and the authorities\n      that issue certificates.\
    \ A MISSI user is usually a person but may\n      be a machine or other automated\
    \ process. Machines that are\n      required to operate nonstop may be issued\
    \ their own certificates\n      to avoid downtime needed to exchange the FORTEZZA\
    \ cards of machine\n      operators at shift changes.\n   $ mission\n      (I)\
    \ A statement of a (relatively long-term) duty or (relatively\n      short-term)\
    \ task that is assigned to an organization or system,\n      indicates the purpose\
    \ and objectives of the duty or task, and may\n      indicate the actions to be\
    \ taken to achieve it.\n   $ mission critical\n      (I) A condition of a system\
    \ service or other system resource such\n      that denial of access to, or lack\
    \ of availability of, the resource\n      would jeopardize a system user's ability\
    \ to perform a primary\n      mission function or would result in other serious\
    \ consequences.\n      (See: Critical. Compare: mission essential.)\n   $ mission\
    \ essential\n      (O) /U.S. DoD/ Refers to materiel that is authorized and available\n\
    \      to combat, combat support, combat service support, and combat\n      readiness\
    \ training forces to accomplish their assigned missions.\n      [JP1] (Compare:\
    \ mission critical.)\n   $ misuse\n      1. (I) The intentional use (by authorized\
    \ users) of system\n      resources for other than authorized purposes. Example:\
    \ An\n      authorized system administrator creates an unauthorized account\n\
    \      for a friend. (See: misuse detection.)\n      2. (I) A type of threat action\
    \ that causes a system component to\n      perform a function or service that\
    \ is detrimental to system\n      security. (See: usurpation.)\n      Usage: This\
    \ type of threat action includes the following subtypes:\n      -  \"Tampering\"\
    : /misuse/ Deliberately altering a system's logic,\n         data, or control\
    \ information to cause the system to perform\n         unauthorized functions\
    \ or services. (See: corruption, main\n         entry for \"tampering\".)\n  \
    \    -  \"Malicious logic\": /misuse/ Any hardware, firmware, or software\n  \
    \       intentionally introduced into a system to perform or control\n       \
    \  execution of an unauthorized function or service. (See:\n         corruption,\
    \ incapacitation, main entry for \"malicious logic\",\n         masquerade.)\n\
    \      -  \"Violation of authorizations\": Action by an entity that exceeds\n\
    \         the entity's system privileges by executing an unauthorized\n      \
    \   function. (See: authorization.)\n   $ misuse detection\n      (I) An intrusion\
    \ detection method that is based on rules that\n      specify system events, sequences\
    \ of events, or observable\n      properties of a system that are believed to\
    \ be symptomatic of\n      security incidents. (See: IDS, misuse. Compare: anomaly\n\
    \      detection.)\n   $ MLS\n      (I) See: multilevel secure\n   $ mobile code\n\
    \      1a. (I) Software that originates from a remote server, is\n      transmitted\
    \ across a network, and is loaded onto and executed on a\n      local client system\
    \ without explicit initiation by the client's\n      user and, in some cases,\
    \ without that user's knowledge. (Compare:\n      active content.)\n      Tutorial:\
    \ One form of mobile code is active content in a file that\n      is transferred\
    \ across a network.\n      1b. (O) /U.S. DoD/ \"Software modules obtained from\
    \ remote systems,\n      transferred across a network, and then downloaded and\
    \ executed on\n      local systems without explicit installation or execution\
    \ by the\n      recipient.\" [JP1]\n      2a. (O) /U.S. DoD/ Technology that enables\
    \ the creation of\n      executable information that can be delivered to an information\n\
    \      system and directly executed on any hardware/software architecture\n  \
    \    that has an appropriate host execution environment.\n      2b. (O) \"Programs\
    \ (e.g., script, macro, or other portable\n      instruction) that can be shipped\
    \ unchanged to a heterogeneous\n      collection of platforms and executed with\
    \ identical semantics\"\n      [SP28]. (See: active content.)\n      Tutorial:\
    \ Mobile code might be malicious. Using techniques such as\n      \"code signing\"\
    \ and a \"sandbox\" can reduce the risks of receiving\n      and executing mobile\
    \ code.\n   $ mode\n   $ mode of operation\n      1. (I) /cryptographic operation/\
    \ A technique for enhancing the\n      effect of a cryptographic algorithm or\
    \ adapting the algorithm for\n      an application, such as applying a block cipher\
    \ to a sequence of\n      data blocks or a data stream. (See: CBC, CCM, CMAC,\
    \ CFB, CTR, ECB,\n      OFB.)\n      2. (I) /system operation/ A type of security\
    \ policy that states\n      the range of classification levels of information\
    \ that a system is\n      permitted to handle and the range of clearances and\
    \ authorizations\n      of users who are permitted to access the system. (See:\n\
    \      compartmented security mode, controlled security mode, dedicated\n    \
    \  security mode, multilevel security mode, partitioned security\n      mode,\
    \ system-high security mode. Compare: protection level.)\n      3. (I) /IKE/ IKE\
    \ refers to its various types of ISAKMP-scripted\n      exchanges of messages\
    \ as \"modes\". Among these are the following:\n      -  \"Main mode\": One of\
    \ IKE's two phase 1 modes. (See: ISAKMP.)\n      -  \"Quick mode\": IKE's only\
    \ phase 2 mode. (See: ISAKMP.)\n   $ model\n      See: formal model, security\
    \ model.\n   $ modulus\n      (I) The defining constant in modular arithmetic,\
    \ and usually a\n      part of the public key in asymmetric cryptography that\
    \ is based on\n      modular arithmetic. (See: Diffie-Hellman-Merkle, RSA.)\n\
    \   $ Mondex\n      (O) A smartcard-based electronic money system that incorporates\n\
    \      cryptography and can be used to make payments via the Internet.\n     \
    \ (See: IOTP.)\n   $ Morris Worm\n      (I) A worm program that flooded the ARPANET\
    \ in November 1988,\n      causing problems for thousands of hosts. [R1135] (See:\
    \ community\n      risk, worm)\n   $ MOSS\n      (I) See: MIME Object Security\
    \ Services.\n   $ MQV\n      (N) A key-agreement protocol [Mene] that was proposed\
    \ by A.J.\n      Menezes, M. Qu, and S.A. Vanstone in 1995 and is based on the\n\
    \      Diffie-Hellman-Merkle algorithm.\n   $ MSP\n      (N) See: Message Security\
    \ Protocol.\n   $ multicast security\n      See: secure multicast\n   $ Multics\n\
    \      (N) MULTiplexed Information and Computing Service, an MLS computer\n  \
    \    timesharing system designed and implemented during 1965-69 by a\n      consortium\
    \ including Massachusetts Institute of Technology,\n      General Electric, and\
    \ Bell Laboratories, and later offered\n      commercially by Honeywell.\n   \
    \   Tutorial: Multics was one of the first large, general-purpose,\n      operating\
    \ systems to include security as a primary goal from the\n      inception of the\
    \ design and development and was rated in TCSEC\n      Class B2. Its many innovative\
    \ hardware and software security\n      mechanisms (e.g., protection ring) were\
    \ adopted by later systems.\n   $ multilevel secure (MLS)\n      (I) Describes\
    \ an information system that is trusted to contain,\n      and maintain separation\
    \ between, resources (particularly stored\n      data) of different security levels.\
    \ (Examples: BLACKER, CANEWARE,\n      KSOS, Multics, SCOMP.)\n      Usage: Usually\
    \ understood to mean that the system permits\n      concurrent access by users\
    \ who differ in their access\n      authorizations, while denying users access\
    \ to resources for which\n      they lack authorization.\n   $ multilevel security\
    \ mode\n      1. (N) A mode of system operation wherein (a) two or more security\n\
    \      levels of information are allowed to be to be handled concurrently\n  \
    \    within the same system when some users having access to the system\n    \
    \  have neither a security clearance nor need-to-know for some of the\n      data\
    \ handled by the system and (b) separation of the users and the\n      classified\
    \ material on the basis, respectively, of clearance and\n      classification\
    \ level are dependent on operating system control.\n      (See: /system operation/\
    \ under \"mode\", need to know, protection\n      level, security clearance. Compare:\
    \ controlled mode.)\n      Usage: Usually abbreviated as \"multilevel mode\".\
    \ This term was\n      defined in U.S. Government policy regarding system accreditation,\n\
    \      but the term is also used outside the Government.\n      2. (O) A mode\
    \ of system operation in which all three of the\n      following statements are\
    \ true: (a) Some authorized users do not\n      have a security clearance for\
    \ all the information handled in the\n      system. (b) All authorized users have\
    \ the proper security\n      clearance and appropriate specific access approval\
    \ for the\n      information to which they have access. (c) All authorized users\n\
    \      have a need-to-know only for information to which they have\n      access.\
    \ [C4009] (See: formal access approval, protection level.)\n   $ Multipurpose\
    \ Internet Mail Extensions (MIME)\n      (I) An Internet protocol (RFC 2045) that\
    \ enhances the basic format\n      of Internet electronic mail messages (RFC 822)\
    \ (a) to enable\n      character sets other than U.S. ASCII to be used for textual\n\
    \      headers and content and (b) to carry non-textual and multi-part\n     \
    \ content. (See: S/MIME.)\n   $ mutual suspicion\n      (I) The state that exists\
    \ between two interacting system entities\n      in which neither entity can trust\
    \ the other to function correctly\n      with regard to some security requirement.\n\
    \   $ name\n      (I) Synonym for \"identifier\".\n   $ naming authority\n   \
    \   (O) /U.S. DoD/ An organizational entity responsible for assigning\n      DNs\
    \ and for assuring that each DN is meaningful and unique within\n      its domain.\
    \ [DoD9]\n   $ National Computer Security Center (NCSC)\n      (O) A U.S. DoD\
    \ organization, housed in NSA, that has\n      responsibility for encouraging\
    \ widespread availability of trusted\n      systems throughout the U.S. Federal\
    \ Government. It has established\n      criteria for, and performed evaluations\
    \ of, computer and network\n      systems that have a TCB. (See: Rainbow Series,\
    \ TCSEC.)\n   $ National Information Assurance Partnership (NIAP)\n      (N) A\
    \ joint initiative of NIST and NSA to enhance the quality of\n      commercial\
    \ products for information security and increase consumer\n      confidence in\
    \ those products through objective evaluation and\n      testing methods.\n  \
    \    Tutorial: NIAP is registered, through the U.S. DoD, as a National\n     \
    \ Performance Review Reinvention Laboratory. NIAP functions include\n      the\
    \ following:\n      -  Developing tests, test methods, and other tools that developers\n\
    \         and testing laboratories may use to improve and evaluate\n         security\
    \ products.\n      -  Collaborating with industry and others on research and testing\n\
    \         programs.\n      -  Using the Common Criteria to develop protection\
    \ profiles and\n         associated test sets for security products and systems.\n\
    \      -  Cooperating with the NIST National Voluntary Laboratory\n         Accreditation\
    \ Program to develop a program to accredit private-\n         sector laboratories\
    \ for the testing of information security\n         products using the Common\
    \ Criteria.\n      -  Working to establish a formal, international mutual recognition\n\
    \         scheme for a Common Criteria-based evaluation.\n   $ National Institute\
    \ of Standards and Technology (NIST)\n      (N) A U.S. Department of Commerce\
    \ organization that promotes U.S.\n      economic growth by working with industry\
    \ to develop and apply\n      technology, measurements, and standards. Has primary\
    \ U.S.\n      Government responsibility for INFOSEC standards for sensitive\n\
    \      unclassified information. (See: ANSI, DES, DSA, DSS, FIPS, NIAP,\n    \
    \  NSA.)\n   $ National Reliability and Interoperability Council (NRIC)\n    \
    \  (N) An advisory committee chartered by the U.S. Federal\n      Communications\
    \ Commission (FCC), with participation by network\n      service providers and\
    \ vendors, to provide recommendations to the\n      FCC for assuring reliability,\
    \ interoperability, robustness, and\n      security of wireless, wireline, satellite,\
    \ cable, and public data\n      communication networks.\n   $ national security\n\
    \      (O) /U.S. Government/ The national defense or foreign relations of\n  \
    \    the United States of America.\n   $ National Security Agency (NSA)\n    \
    \  (N) A U.S. DoD organization that has primary U.S. Government\n      responsibility\
    \ for INFOSEC standards for classified information\n      and for sensitive unclassified\
    \ information handled by national\n      security systems. (See: FORTEZZA, KEA,\
    \ MISSI, national security\n      system, NIAP, NIST, SKIPJACK.)\n   $ national\
    \ security information\n      (O) /U.S. Government/ Information that has been\
    \ determined,\n      pursuant to Executive Order 12958 or any predecessor order,\
    \ to\n      require protection against unauthorized disclosure. [C4009]\n   $\
    \ national security system\n      (O) /U.S. Government/ Any Government-operated\
    \ information system\n      for which the function, operation, or use (a) involves\n\
    \      intelligence activities; (b) involves cryptologic activities\n      related\
    \ to national security; (c) involves command and control of\n      military forces;\
    \ (d) involves equipment that is an integral part\n      of a weapon or weapon\
    \ system; or (e) is critical to the direct\n      fulfillment of military or intelligence\
    \ missions and does not\n      include a system that is to be used for routine\
    \ administrative and\n      business applications (including payroll, finance,\
    \ logistics, and\n      personnel management applications). [Title 40 U.S.C. Section\
    \ 1552,\n      Information Technology Management Reform Act of 1996.] (See: type\n\
    \      2 product.)\n   $ natural disaster\n      (I) /threat action/ See: secondary\
    \ definitions under \"corruption\"\n      and \"incapacitation\".\n   $ NCSC\n\
    \      (O) See: National Computer Security Center.\n   $ need to know, need-to-know\n\
    \      (I) The necessity for access to, knowledge of, or possession of\n     \
    \ specific information required to carry out official duties.\n      Usage: The\
    \ compound \"need-to-know\" is commonly used as either an\n      adjective or\
    \ a noun.\n      Tutorial: The need-to-know criterion is used in security\n  \
    \    procedures that require a custodian of sensitive information,\n      prior\
    \ to disclosing the information to someone else, to establish\n      that the\
    \ intended recipient has proper authorization to access the\n      information.\n\
    \   $ network\n      (I) An information system comprised of a collection of\n\
    \      interconnected nodes. (See: computer network.)\n   $ Network Hardware Layer\n\
    \      (I) See: Internet Protocol Suite.\n   $ Network Interface Layer\n     \
    \ (I) See: Internet Protocol Suite.\n   $ Network Layer Security Protocol (NLSP).\n\
    \      (N) An OSI protocol (IS0 11577) for end-to-end encryption services\n  \
    \    at the top of OSIRM Layer 3. NLSP is derived from SP3 but is more\n     \
    \ complex. (Compare: IPsec.)\n   $ Network Substrate Layer\n      (I) Synonym\
    \ for \"Network Hardware Layer\".\n   $ network weaving\n      (I) A penetration\
    \ technique in which an intruder avoids detection\n      and traceback by using\
    \ multiple, linked, communication networks to\n      access and attack a system.\
    \ [C4009]\n   $ NIAP\n      (N) See: National Information Assurance Partnership.\n\
    \   $ nibble\n      (D) Half of a byte (i.e., usually, 4 bits).\n      Deprecated\
    \ Term: To avoid international misunderstanding, IDOCs\n      SHOULD NOT use this\
    \ term; instead, state the size of the block\n      explicitly (e.g., \"4-bit\
    \ block\"). (See: Deprecated Usage under\n      \"Green Book\".)\n   $ NIPRNET\n\
    \      (O) The U.S. DoD's common-use Non-Classified Internet Protocol\n      Router\
    \ Network; the part of the Internet that is wholly controlled\n      by the U.S.\
    \ DoD and is used for official DoD business.\n   $ NIST\n      (N) See: National\
    \ Institute of Standards and Technology.\n   $ NLSP\n      (N) See: Network Layer\
    \ Security Protocol\n   $ no-lone zone\n      (I) A room or other space or area\
    \ to which no person may have\n      unaccompanied access and that, when occupied,\
    \ is required to be\n      occupied by two or more appropriately authorized persons.\
    \ [C4009]\n      (See: dual control.)\n   $ no-PIN ORA (NORA)\n      (O) /MISSI/\
    \ An organizational RA that operates in a mode in which\n      the ORA performs\
    \ no card management functions and, therefore, does\n      not require knowledge\
    \ of either the SSO PIN or user PIN for an end\n      user's FORTEZZA PC card.\n\
    \   $ node\n      (I) A collection of related subsystems located on one or more\n\
    \      computer platforms at a single site. (See: site.)\n   $ nonce\n      (I)\
    \ A random or non-repeating value that is included in data\n      exchanged by\
    \ a protocol, usually for the purpose of guaranteeing\n      liveness and thus\
    \ detecting and protecting against replay attacks.\n      (See: fresh.)\n   $\
    \ non-critical\n      See: critical.\n   $ non-repudiation service\n      1. (I)\
    \ A security service that provide protection against false\n      denial of involvement\
    \ in an association (especially a\n      communication association that transfers\
    \ data). (See: repudiation,\n      time stamp.)\n      Tutorial: Two separate\
    \ types of denial are possible -- an entity\n      can deny that it sent a data\
    \ object, or it can deny that it\n      received a data object -- and, therefore,\
    \ two separate types of\n      non-repudiation service are possible. (See: non-repudiation\
    \ with\n      proof of origin, non-repudiation with proof of receipt.)\n     \
    \ 2. (D) \"Assurance [that] the sender of data is provided with proof\n      of\
    \ delivery and the recipient is provided with proof of the\n      sender's identity,\
    \ so neither can later deny having processed the\n      data.\" [C4009]\n    \
    \  Deprecated Definition: IDOCs SHOULD NOT use definition 2 because\n      it\
    \ bundles two security services -- non-repudiation with proof of\n      origin,\
    \ and non-repudiation with proof of receipt -- that can be\n      provided independently\
    \ of each other.\n      Usage: IDOCs SHOULD distinguish between the technical\
    \ aspects and\n      the legal aspects of a non-repudiation service:\n      -\
    \  \"Technical non-repudiation\": Refers to the assurance a relying\n        \
    \ party has that if a public key is used to validate a digital\n         signature,\
    \ then that signature had to have been made by the\n         corresponding private\
    \ signature key. [SP32]\n      -  \"Legal non-repudiation\": Refers to how well\
    \ possession or\n         control of the private signature key can be established.\
    \ [SP32]\n      Tutorial: Non-repudiation service does not prevent an entity from\n\
    \      repudiating a communication. Instead, the service provides\n      evidence\
    \ that can be stored and later presented to a third party\n      to resolve disputes\
    \ that arise if and when a communication is\n      repudiated by one of the entities\
    \ involved.\n      Ford describes the six phases of a complete non-repudiation\n\
    \      service and uses \"critical action\" to refer to the act of\n      communication\
    \ that is the subject of the service [For94, For97]:\n      --------   --------\
    \   --------   --------   --------   . --------\n      Phase 1:   Phase 2:   Phase\
    \ 3:   Phase 4:   Phase 5:   . Phase 6:\n      Request    Generate   Transfer\
    \   Verify     Retain     . Resolve\n      Service    Evidence   Evidence   Evidence\
    \   Evidence   . Dispute\n      --------   --------   --------   --------   --------\
    \   . --------\n      Service    Critical   Evidence   Evidence   Archive    .\
    \ Evidence\n      Request => Action  => Stored  => Is      => Evidence   . Is\n\
    \      Is Made    Occurs     For Later  Tested     In Case    . Verified\n   \
    \              and        Use |          ^      Critical   .    ^\n          \
    \       Evidence       v          |      Action Is  .    |\n                 Is\
    \         +-------------------+ Repudiated .    |\n                 Generated\
    \  |Verifiable Evidence|------> ... . ----+\n                            +-------------------+\n\
    \      Phase / Explanation\n      -------------------\n      1. Request service:\
    \ Before the critical action, the service\n         requester asks, either implicitly\
    \ or explicitly, to have\n         evidence of the action be generated.\n    \
    \  2. Generate evidence: When the critical action occurs, evidence is\n      \
    \   generated by a process involving the potential repudiator and\n         possibly\
    \ also a trusted third party.\n      3. Transfer evidence: The evidence is transferred\
    \ to the requester\n         or stored by a third party, for later use (if needed).\n\
    \      4. Verify evidence: The entity that holds the evidence tests it to\n  \
    \       be sure that it will suffice if a dispute arises.\n      5. Retain evidence:\
    \ The evidence is retained for possible future\n         retrieval and use.\n\
    \      6. Resolve dispute: In this phase, which occurs only if the\n         critical\
    \ action is repudiated, the evidence is retrieved from\n         storage, presented,\
    \ and verified to resolve the dispute.\n   $ non-repudiation with proof of origin\n\
    \      (I) A security service that provides the recipient of data with\n     \
    \ evidence that proves the origin of the data, and thus protects the\n      recipient\
    \ against an attempt by the originator to falsely deny\n      sending the data.\
    \ (See: non-repudiation service.)\n      Tutorial: This service is a strong version\
    \ of data origin\n      authentication service. This service can not only verify\
    \ the\n      identity of a system entity that is the original source of\n    \
    \  received data; it can also provide proof of that identity to a\n      third\
    \ party.\n   $ non-repudiation with proof of receipt\n      (I) A security service\
    \ that provides the originator of data with\n      evidence that proves the data\
    \ was received as addressed, and thus\n      protects the originator against an\
    \ attempt by the recipient to\n      falsely deny receiving the data. (See: non-repudiation\
    \ service.)\n   $ non-volatile media\n      (I) Storage media that, once written\
    \ into, provide stable storage\n      of information without an external power\
    \ supply. (Compare:\n      permanent storage, volatile media.)\n   $ NORA\n  \
    \    (O) See: no-PIN ORA.\n   $ notarization\n      (I) Registration of data under\
    \ the authority or in the care of a\n      trusted third party, thus making it\
    \ possible to provide subsequent\n      assurance of the accuracy of characteristics\
    \ claimed for the data,\n      such as content, origin, time of existence, and\
    \ delivery.\n      [I7498-2] (See: digital notary.)\n   $ NRIC\n      (N) See:\
    \ Network Reliability and Interoperability Council.\n   $ NSA\n      (N) See:\
    \ National Security Agency\n   $ null\n      (N) /encryption/ \"Dummy letter,\
    \ letter symbol, or code group\n      inserted into an encrypted message to delay\
    \ or prevent its\n      decryption or to complete encrypted groups for transmission\
    \ or\n      transmission security purposes.\" [C4009]\n   $ NULL encryption algorithm\n\
    \      (I) An algorithm [R2410] that is specified as doing nothing to\n      transform\
    \ plaintext data; i.e., a no-op. It originated because ESP\n      always specifies\
    \ the use of an encryption algorithm for\n      confidentiality. The NULL encryption\
    \ algorithm is a convenient way\n      to represent the option of not applying\
    \ encryption in ESP (or in\n      any other context where a no-op is needed).\
    \ (Compare: null.)\n   $ OAKLEY\n      (I) A key establishment protocol (proposed\
    \ for IPsec but\n      superseded by IKE) based on the Diffie-Hellman-Merkle algorithm\n\
    \      and designed to be a compatible component of ISAKMP. [R2412]\n      Tutorial:\
    \ OAKLEY establishes a shared key with an assigned\n      identifier and associated\
    \ authenticated identities for parties;\n      i.e., OAKLEY provides authentication\
    \ service to ensure the\n      entities of each other's identity, even if the\
    \ Diffie-Hellman-\n      Merkle exchange is threatened by active wiretapping.\
    \ Also, it\n      provides public-key forward secrecy for the shared key and\n\
    \      supports key updates, incorporation of keys distributed by out-of-\n  \
    \    band mechanisms, and user-defined abstract group structures for\n      use\
    \ with Diffie-Hellman-Merkle.\n   $ object\n      (I) /formal model/ Trusted-system\
    \ modeling usage: A system\n      component that contains or receives information.\
    \ (See: Bell-\n      LaPadula model, object reuse, trusted system.)\n   $ object\
    \ identifier (OID)\n      1. (N) An official, globally unique name for a thing,\
    \ written as a\n      sequence of integers (which are formed and assigned as defined\
    \ in\n      the ASN.1 standard) and used to reference the thing in abstract\n\
    \      specifications and during negotiation of security services in a\n     \
    \ protocol.\n      2. (O) \"A value (distinguishable from all other such values)\n\
    \      [that] is associated with an object.\" [X680]\n      Tutorial: Objects\
    \ named by OIDs are leaves of the object\n      identifier tree (which is similar\
    \ to but different from the X.500\n      Directory Information Tree). Each arc\
    \ (i.e., each branch of the\n      tree) is labeled with a non-negative integer.\
    \ An OID is the\n      sequence of integers on the path leading from the root\
    \ of the tree\n      to a named object.\n      The OID tree has three arcs immediately\
    \ below the root: {0} for\n      use by ITU-T, {1} for use by ISO, and {2} for\
    \ use by both jointly.\n      Below ITU-T are four arcs, where {0 0} is for ITU-T\n\
    \      recommendations. Below {0 0} are 26 arcs, one for each series of\n    \
    \  recommendations starting with the letters A to Z, and below these\n      are\
    \ arcs for each recommendation. Thus, the OID for ITU-T\n      Recommendation\
    \ X.509 is {0 0 24 509}. Below ISO are four arcs,\n      where {1 0 }is for ISO\
    \ standards, and below these are arcs for\n      each ISO standard. Thus, the\
    \ OID for ISO/IEC 9594-8 (the ISO\n      number for X.509) is {1 0 9594 8}.\n\
    \      ANSI registers organization names below the branch {joint-iso-\n      ccitt(2)\
    \ country(16) US(840) organization(1) gov(101) csor(3)}.\n      The NIST CSOR\
    \ records PKI objects below the branch {joint-iso-itu-\n      t(2) country(16)\
    \ us(840) organization (1) gov(101) csor(3)}. The\n      U.S. DoD registers INFOSEC\
    \ objects below the branch {joint-iso-\n      itu-t(2) country(16) us(840) organization(1)\
    \ gov(101) dod(2)\n      infosec(1)}.\n      The IETF's Public-Key Infrastructure\
    \ (pkix) Working Group\n      registers PKI objects below the branch {iso(1) identified-\n\
    \      organization(3) dod(6) internet(1) security(5) mechanisms(5)\n      pkix(7)}.\
    \ [R3280]\n   $ object reuse\n      (N) /COMPUSEC/ Reassignment and reuse of an\
    \ area of a storage\n      medium (e.g., random-access memory, floppy disk, magnetic\
    \ tape)\n      that once contained sensitive data objects. Before being\n    \
    \  reassigned for use by a new subject, the area needs to be erased\n      or,\
    \ in some cases, purged. [NCS04] (See: object.)\n   $ obstruction\n      (I) A\
    \ type of threat action that interrupts delivery of system\n      services by\
    \ hindering system operations. (See: disruption.)\n      Tutorial: This type of\
    \ threat action includes the following\n      subtypes:\n      -  \"Interference\"\
    : Disruption of system operations by blocking\n         communication of user\
    \ data or control information. (See:\n         jamming.)\n      -  \"Overload\"\
    : Hindrance of system operation by placing excess\n         burden on the performance\
    \ capabilities of a system component.\n         (See: flooding.)\n   $ OCSP\n\
    \      (I) See: Online Certificate Status Protocol.\n   $ octet\n      (I) A data\
    \ unit of eight bits. (Compare: byte.)\n      Usage: This term is used in networking\
    \ (especially in OSI\n      standards) in preference to \"byte\", because some\
    \ systems use\n      \"byte\" for data storage units of a size other than eight\
    \ bits.\n   $ OFB\n      (N) See: output feedback.\n   $ off-line attack\n   \
    \   (I) See: secondary definition under \"attack\".\n   $ ohnosecond\n      (D)\
    \ That minuscule fraction of time in which you realize that your\n      private\
    \ key has been compromised.\n      Deprecated Usage: IDOCs SHOULD NOT use this\
    \ term; it is a joke for\n      English speakers. (See: Deprecated Usage under\
    \ \"Green Book\".)\n   $ OID\n      (N) See: object identifier.\n   $ Online Certificate\
    \ Status Protocol (OCSP)\n      (I) An Internet protocol [R2560] used by a client\
    \ to obtain from a\n      server the validity status and other information about\
    \ a digital\n      certificate. (Mentioned in [X509] but not specified there.)\n\
    \      Tutorial: In some applications, such as those involving high-value\n  \
    \    commercial transactions, it may be necessary either (a) to obtain\n     \
    \ certificate revocation status that is timelier than is possible\n      with\
    \ CRLs or (b) to obtain other kinds of status information. OCSP\n      may be\
    \ used to determine the current revocation status of a\n      digital certificate,\
    \ in lieu of or as a supplement to checking\n      against a periodic CRL. An\
    \ OCSP client issues a status request to\n      an OCSP server and suspends acceptance\
    \ of the certificate in\n      question until the server provides a response.\n\
    \   $ one-time pad\n      1. (N) A manual encryption system in the form of a paper\
    \ pad for\n      one-time use.\n      2. (I) An encryption algorithm in which\
    \ the key is a random\n      sequence of symbols and each symbol is used for encryption\
    \ only\n      one time -- i.e., used to encrypt only one plaintext symbol and\n\
    \      thus produce only one ciphertext symbol -- and a copy of the key\n    \
    \  is used similarly for decryption.\n      Tutorial: To ensure one-time use,\
    \ the copy of the key used for\n      encryption is destroyed after use, as is\
    \ the copy used for\n      decryption. This is the only encryption algorithm that\
    \ is truly\n      unbreakable, even given unlimited resources for cryptanalysis\n\
    \      [Schn], but key management costs and synchronization problems make\n  \
    \    it impractical except in special situations.\n   $ one-time password, One-Time\
    \ Password (OTP)\n      1. (I) /not capitalized/ A \"one-time password\" is a\
    \ simple\n      authentication technique in which each password is used only once\n\
    \      as authentication information that verifies an identity. This\n      technique\
    \ counters the threat of a replay attack that uses\n      passwords captured by\
    \ wiretapping.\n      2. (I) /capitalized/ \"One-Time Password\" is an Internet\
    \ protocol\n      [R2289] that is based on S/KEY and uses a cryptographic hash\n\
    \      function to generate one-time passwords for use as authentication\n   \
    \   information in system login and in other processes that need\n      protection\
    \ against replay attacks.\n   $ one-way encryption\n      (I) Irreversible transformation\
    \ of plain text to cipher text, such\n      that the plain text cannot be recovered\
    \ from the cipher text by\n      other than exhaustive procedures even if the\
    \ cryptographic key is\n      known. (See: brute force, encryption.)\n   $ one-way\
    \ function\n      (I) \"A (mathematical) function, f, [that] is easy to compute,\
    \ but\n      which for a general value y in the range, it is computationally\n\
    \      difficult to find a value x in the domain such that f(x) = y.\n      There\
    \ may be a few values of y for which finding x is not\n      computationally difficult.\"\
    \ [X509]\n      Deprecated Usage: IDOCs SHOULD NOT use this term as a synonym\
    \ for\n      \"cryptographic hash\".\n   $ onion routing\n      (I) A system that\
    \ can be used to provide both (a) data\n      confidentiality and (b) traffic-flow\
    \ confidentiality for network\n      packets, and also provide (c) anonymity for\
    \ the source of the\n      packets.\n      Tutorial: The source, instead of sending\
    \ a packet directly to the\n      intended destination, sends it to an \"onion\
    \ routing proxy\" that\n      builds an anonymous connection through several other\
    \ \"onion\n      routers\" to the destination. The proxy defines a route through\
    \ the\n      \"onion routing network\" by encapsulating the original payload in\
    \ a\n      layered data packet called an \"onion\", in which each layer defines\n\
    \      the next hop in the route and each layer is also encrypted. Along\n   \
    \   the route, each onion router that receives the onion peels off one\n     \
    \ layer; decrypts that layer and reads from it the address of the\n      next\
    \ onion router on the route; pads the remaining onion to some\n      constant\
    \ size; and sends the padded onion to that next router.\n   $ open security environment\n\
    \      (O) /U.S. DoD/ A system environment that meets at least one of the\n  \
    \    following two conditions: (a) Application developers (including\n      maintainers)\
    \ do not have sufficient clearance or authorization to\n      provide an acceptable\
    \ presumption that they have not introduced\n      malicious logic. (b) Configuration\
    \ control does not provide\n      sufficient assurance that applications and the\
    \ equipment are\n      protected against the introduction of malicious logic prior\
    \ to and\n      during the operation of system applications. [NCS04] (See: \"\
    first\n      law\" under \"Courtney's laws\". Compare: closed security\n     \
    \ environment.)\n   $ open storage\n      (N) /U.S. Government/ \"Storage of classified\
    \ information within an\n      accredited facility, but not in General Services\
    \ Administration\n      approved secure containers, while the facility is unoccupied\
    \ by\n      authorized personnel.\" [C4009]\n   $ Open Systems Interconnection\
    \ (OSI) Reference Model (OSIRM)\n      (N) A joint ISO/ITU-T standard [I7498-1]\
    \ for a seven-layer,\n      architectural communication framework for interconnection\
    \ of\n      computers in networks. (See: OSIRM Security Architecture. Compare:\n\
    \      Internet Protocol Suite.)\n      Tutorial: OSIRM-based standards include\
    \ communication protocols\n      that are mostly incompatible with the IPS, but\
    \ also include\n      security models, such as X.509, that are used in the Internet.\n\
    \      The OSIRM layers, from highest to lowest, are (7) Application, (6)\n  \
    \    Presentation, (5) Session, (4) Transport, (3) Network, (2) Data\n      Link,\
    \ and (1) Physical.\n      Usage: This Glossary refers to OSIRM layers by number\
    \ to avoid\n      confusing them with IPS layers, which are referred to by name.\n\
    \      Some unknown person described how the OSIRM layers correspond to\n    \
    \  the seven deadly sins:\n      7. Wrath: Application is always angry with the\
    \ mess it sees below\n         itself. (Hey! Who is it to be pointing fingers?)\n\
    \      6. Sloth: Presentation is too lazy to do anything productive by\n     \
    \    itself.\n      5. Lust: Session is always craving and demanding what truly\n\
    \         belongs to Application's functionality.\n      4. Avarice: Transport\
    \ wants all of the end-to-end functionality.\n         (Of course, it deserves\
    \ it, but life isn't fair.)\n      3. Gluttony: (Connection-Oriented) Network\
    \ is overweight and\n         overbearing after trying too often to eat Transport's\
    \ lunch.\n      2. Envy: Poor Data Link is always starved for attention. (With\n\
    \         Asynchronous Transfer Mode, maybe now it is feeling less\n         neglected.)\n\
    \      1. Pride: Physical has managed to avoid much of the controversy,\n    \
    \     and nearly all of the embarrassment, suffered by the others.\n      John\
    \ G. Fletcher described how the OSIRM layers correspond to Snow\n      White's\
    \ dwarf friends:\n      7. Doc: Application acts as if it is in charge, but sometimes\n\
    \         muddles its syntax.\n      6. Sleepy: Presentation is indolent, being\
    \ guilty of the sin of\n         Sloth.\n      5. Dopey: Session is confused because\
    \ its charter is not very\n         clear.\n      4. Grumpy: Transport is irritated\
    \ because Network has encroached\n         on Transport's turf.\n      3. Happy:\
    \ Network smiles for the same reason that Transport is\n         irritated.\n\
    \      2. Sneezy: Data Link makes loud noises in the hope of attracting\n    \
    \     attention.\n      1. Bashful: Physical quietly does its work, unnoticed\
    \ by the\n         others.\n   $ operational integrity\n      (I) Synonym for\
    \ \"system integrity\"; this synonym emphasizes the\n      actual performance\
    \ of system functions rather than just the\n      ability to perform them.\n \
    \  $ operational security\n      1. (I) System capabilities, or performance of\
    \ system functions,\n      that are needed either (a) to securely manage a system\
    \ or (b) to\n      manage security features of a system. (Compare: operations\n\
    \      security (OPSEC).)\n      Usage: IDOCs that use this term SHOULD state\
    \ a definition because\n      (a) the definition provided here is general and\
    \ vague and (b) the\n      term could easily be confused with \"operations security\"\
    , which is\n      a different concept.\n      Tutorial: For example, in the context\
    \ of an Internet service\n      provider, the term could refer to capabilities\
    \ to manage network\n      devices in the event of attacks, simplify troubleshooting,\
    \ keep\n      track of events that affect system integrity, help analyze sources\n\
    \      of attacks, and provide administrators with control over network\n    \
    \  addresses and protocols to help mitigate the most common attacks\n      and\
    \ exploits. [R3871]\n      2. (D) Synonym for \"administrative security\".\n \
    \     Deprecated Definition: IDOCs SHOULD NOT use this term as a synonym\n   \
    \   for \"administrative security\". Any type of security may affect\n      system\
    \ operations; therefore, the term may be misleading. Instead,\n      use \"administrative\
    \ security\", \"communication security\", \"computer\n      security\", \"emanations\
    \ security\", \"personnel security\", \"physical\n      security\", or whatever\
    \ specific type is meant. (See: security\n      architecture. Compare: operational\
    \ integrity, OPSEC.)\n   $ operations security (OPSEC)\n      (I) A process to\
    \ identify, control, and protect evidence of the\n      planning and execution\
    \ of sensitive activities and operations, and\n      thereby prevent potential\
    \ adversaries from gaining knowledge of\n      capabilities and intentions. (See:\
    \ communications cover. Compare:\n      operational security.)\n   $ operator\n\
    \      (I) A person who has been authorized to direct selected functions\n   \
    \   of a system. (Compare: manager, user.)\n      Usage: IDOCs that use this term\
    \ SHOULD state a definition for it\n      because a system operator may or may\
    \ not be treated as a \"user\".\n   $ OPSEC\n      1. (I) Abbreviation for \"\
    operations security\".\n      2. (D) Abbreviation for \"operational security\"\
    .\n      Deprecated Usage: IDOCs SHOULD NOT use this abbreviation for\n      \"\
    operational security\" (as defined in this Glossary), because its\n      use for\
    \ \"operations security\" has been well established for many\n      years, particular\
    \ in the military community.\n   $ ORA\n      See: organizational registration\
    \ authority.\n   $ Orange Book\n      (D) /slang/ Synonym for \"Trusted Computer\
    \ System Evaluation\n      Criteria\" [CSC1, DoD1].\n      Deprecated Usage: IDOCs\
    \ SHOULD NOT use this term as a synonym for\n      \"Trusted Computer System Evaluation\
    \ Criteria\" [CSC1, DoD1].\n      Instead, use the full, proper name of the document\
    \ or, in\n      subsequent references, the abbreviation \"TCSEC\". (See: Deprecated\n\
    \      Usage under \"Green Book\".)\n   $ organizational certificate\n      1.\
    \ (I) An X.509 public-key certificate in which the \"subject\"\n      field contains\
    \ the name of an institution or set (e.g., a\n      business, government, school,\
    \ labor union, club, ethnic group,\n      nationality, system, or group of individuals\
    \ playing the same\n      role), rather than the name of an individual person\
    \ or device.\n      (Compare: persona certificate, role certificate.)\n      Tutorial:\
    \ Such a certificate might be issued for one of the\n      following purposes:\n\
    \      -  To enable an individual to prove membership in the\n         organization.\n\
    \      -  To enable an individual to represent the organization, i.e., to\n  \
    \       act in its name and with its powers or permissions.\n      2. (O) /MISSI/\
    \ A type of MISSI X.509 public-key certificate that\n      is issued to support\
    \ organizational message handling for the U.S.\n      DoD's Defense Message System.\n\
    \   $ organizational registration authority (ORA)\n      1. (I) /PKI/ An RA for\
    \ an organization.\n      2. (O) /MISSI/ An end entity that (a) assists a PCA,\
    \ CA, or SCA to\n      register other end entities, by gathering, verifying, and\
    \ entering\n      data and forwarding it to the signing authority and (b) may\
    \ also\n      assist with card management functions. An ORA is a local\n     \
    \ administrative authority, and the term refers both to the role and\n      to\
    \ the person who plays that role. An ORA does not sign\n      certificates, CRLs,\
    \ or CKLs. (See: no-PIN ORA, SSO-PIN ORA, user-\n      PIN ORA.)\n   $ origin\
    \ authentication\n      (D) Synonym for \"data origin authentication\". (See:\n\
    \      authentication, data origin authentication.)\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term; it suggests\n      careless use of the internationally\
    \ standardized term \"data origin\n      authentication\" and also could be confused\
    \ with \"peer entity\n      authentication.\"\n   $ origin authenticity\n    \
    \  (D) Synonym for \"data origin authentication\". (See: authenticity,\n     \
    \ data origin authentication.)\n      Deprecated Term: IDOCs SHOULD NOT use this\
    \ term; it suggests\n      careless use of the internationally standardized term\
    \ \"data origin\n      authentication\" and mixes concepts in a potentially misleading\n\
    \      way.\n   $ OSI, OSIRM\n      (N) See: Open Systems Interconnection Reference\
    \ Model.\n   $ OSIRM Security Architecture\n      (N) The part of the OSIRM [I7498-2]\
    \ that specifies the security\n      services and security mechanisms that can\
    \ be applied to protect\n      communications between two systems. (See: security\
    \ architecture.)\n      Tutorial: This part of the OSIRM includes an allocation\
    \ of\n      security services to protocol layers. The following table shows\n\
    \      which security services (see definitions in this Glossary) are\n      permitted\
    \ by the OSIRM in each of its layers. (Also, an\n      application process that\
    \ operates above the Application Layer may\n      itself provide security services.)\
    \ Similarly, the table suggests\n      which services are suitable for each IPS\
    \ layer. However,\n      explaining and justifying these allocations is beyond\
    \ the scope of\n      this Glossary.\n      Legend for Table Entries:\n      \
    \   O = Yes, [I7498-2] permits the service in this OSIRM layer.\n         I =\
    \ Yes, the service can be incorporated in this IPS layer.\n         * = This layer\
    \ subsumed by Application Layer in IPS.\n      IPS Protocol Layers    +-----------------------------------------+\n\
    \                             |Network| Net |In-| Trans |  Application  |\n  \
    \                           |  H/W  |Inter|ter| -port |               |\n    \
    \                         |       |-face|net|       |               |\n      OSIRM\
    \ Protocol Layers  +-----------------------------------------+\n             \
    \                |  1  |  2  |  3  |  4  |  5  |  6  |  7  |\n      Confidentiality\
    \        +-----------------------------------------+\n      -  Datagram      \
    \      | O I | O I | O I | O I |     | O * | O I |\n      -  Selective Field \
    \    |     |     |   I |     |     | O * | O I |\n      -  Traffic Flow      \
    \  | O   |     | O   |     |     |     | O   |\n         -- Full             |\
    \   I |     |     |     |     |     |     |\n         -- Partial          |  \
    \   |   I |   I |     |     |     |   I |\n      Integrity              +-----------------------------------------+\n\
    \      -  Datagram            |   I |   I | O I | O I |     |     | O I |\n  \
    \    -  Selective Field     |     |     |   I |     |     |     | O I |\n    \
    \  -  Stream              |     |     | O I | O I |     |     | O I |\n      Authentication\
    \         +-----------------------------------------+\n      -  Peer Entity  \
    \       |     |   I | O I | O I |     |     | O I |\n      -  Data Origin    \
    \     |     |   I | O I | O I |     |     | O I |\n      Access Control      \
    \   +-----------------------------------------+\n      -  type as appropriate\
    \ |     |   I | O I | O I |     |     | O I |\n      Non-Repudiation        +-----------------------------------------+\n\
    \      -  of Origin           |     |     |     |     |     |     | O I |\n  \
    \    -  of Receipt          |     |     |     |     |     |     | O I |\n    \
    \                         +-----------------------------------------+\n   $ OTAR\n\
    \      (N) See: over-the-air rekeying.\n   $ OTP\n      (I) See: One-Time Password.\n\
    \   $ out-of-band\n      (I) /adjective, adverb/ Information transfer using a\
    \ channel or\n      method that is outside (i.e., separate from or different from)\
    \ the\n      main channel or normal method.\n      Tutorial: Out-of-band mechanisms\
    \ are often used to distribute\n      shared secrets (e.g., a symmetric key) or\
    \ other sensitive\n      information items (e.g., a root key) that are needed\
    \ to initialize\n      or otherwise enable the operation of cryptography or other\n\
    \      security mechanisms. Example: Using postal mail to distribute\n      printed\
    \ or magnetic media containing symmetric cryptographic keys\n      for use in\
    \ Internet encryption devices. (See: key distribution.)\n   $ output feedback\
    \ (OFB)\n      (N) A block cipher mode that modifies ECB mode to operate on\n\
    \      plaintext segments of variable length less than or equal to the\n     \
    \ block length. [FP081] (See: block cipher, [SP38A].)\n      Tutorial: This mode\
    \ operates by directly using the algorithm's\n      previously generated output\
    \ block as the algorithm's next input\n      block (i.e., by \"feeding back\"\
    \ the output block) and combining\n      (exclusive OR-ing) the output block with\
    \ the next plaintext\n      segment (of block length or less) to form the next\
    \ ciphertext\n      segment.\n   $ outside attack\n      (I) See: secondary definition\
    \ under \"attack\". Compare: outsider.)\n   $ outsider\n      (I) A user (usually\
    \ a person) that accesses a system from a\n      position that is outside the\
    \ system's security perimeter.\n      (Compare: authorized user, insider, unauthorized\
    \ user.)\n      Tutorial: The actions performed by an outsider in accessing the\n\
    \      system may be either authorized or unauthorized; i.e., an outsider\n  \
    \    may act either as an authorized user or as an unauthorized user.\n   $ over-the-air\
    \ rekeying (OTAR)\n      (N) Changing a key in a remote cryptographic device by\
    \ sending a\n      new key directly to the device via a channel that the device\
    \ is\n      protecting. [C4009]\n   $ overload\n      (I) /threat action/ See:\
    \ secondary definition under \"obstruction\".\n   $ P1363\n      (N) See: IEEE\
    \ P1363.\n   $ PAA\n      (O) See: policy approving authority.\n   $ package\n\
    \      (N) /Common Criteria/ A reusable set of either functional or\n      assurance\
    \ components, combined in a single unit to satisfy a set\n      of identified\
    \ security objectives. (Compare: protection profile.)\n      Example: The seven\
    \ EALs defined in Part 3 of the Common Criteria\n      are predefined assurance\
    \ packages.\n      Tutorial: A package is a combination of security requirement\n\
    \      components and is intended to be reusable in the construction of\n    \
    \  either more complex packages or protection profiles and security\n      targets.\
    \ A package expresses a set of either functional or\n      assurance requirements\
    \ that meet some particular need, expressed\n      as a set of security objectives.\n\
    \   $ packet\n      (I) A block of data that is carried from a source to a destination\n\
    \      through a communication channel or, more generally, across a\n      network.\
    \ (Compare: datagram, PDU.)\n   $ packet filter\n      (I) See: secondary definition\
    \ under \"filtering router\".\n   $ packet monkey\n      (D) /slang/ Someone who\
    \ floods a system with packets, creating a\n      denial-of-service condition\
    \ for the system's users. (See:\n      cracker.)\n      Deprecated Term: It is\
    \ likely that other cultures use different\n      metaphors for this concept.\
    \ Therefore, to avoid international\n      misunderstanding, IDOCs SHOULD NOT\
    \ use this term. (See: Deprecated\n      Usage under \"Green Book\".)\n   $ pagejacking\n\
    \      (D) /slang/ A contraction of \"Web page hijacking\". A masquerade\n   \
    \   attack in which the attacker copies (steals) a home page or other\n      material\
    \ from the target server, rehosts the page on a server the\n      attacker controls,\
    \ and causes the rehosted page to be indexed by\n      the major Web search services,\
    \ thereby diverting browsers from the\n      target server to the attacker's server.\n\
    \      Deprecated Term: IDOCs SHOULD NOT use this contraction. The term\n    \
    \  is not listed in most dictionaries and could confuse international\n      readers.\
    \ (See: Deprecated Usage under \"Green Book\".)\n   $ PAN\n      (O) See: primary\
    \ account number.\n   $ PAP\n      (I) See: Password Authentication Protocol.\n\
    \   $ parity bit\n      (I) A checksum that is computed on a block of bits by\
    \ computing\n      the binary sum of the individual bits in the block and then\n\
    \      discarding all but the low-order bit of the sum. (See: checksum.)\n   $\
    \ partitioned security mode\n      (N) A mode of system operation wherein all\
    \ users having access to\n      the system have the necessary security clearances\
    \ for all data\n      handled by the system, but some users might not have either\
    \ formal\n      access approval or need-to-know for all the data. (See: /system\n\
    \      operation/ under \"mode\", formal access approval, need to know,\n    \
    \  protection level, security clearance.)\n      Usage: Usually abbreviated as\
    \ \"partitioned mode\". This term was\n      defined in U.S. Government policy\
    \ on system accreditation.\n   $ PASS\n      (N) See: personnel authentication\
    \ system string.\n   $ passive attack\n      (I) See: secondary definition under\
    \ \"attack\".\n   $ passive user\n      (I) See: secondary definition under \"\
    system user\".\n   $ passive wiretapping\n      (I) A wiretapping attack that\
    \ attempts only to observe a\n      communication flow and gain knowledge of the\
    \ data it contains, but\n      does not alter or otherwise affect that flow. (See:\
    \ wiretapping.\n      Compare: passive attack, active wiretapping.)\n   $ password\n\
    \      1a. (I) A secret data value, usually a character string, that is\n    \
    \  presented to a system by a user to authenticate the user's\n      identity.\
    \ (See: authentication information, challenge-response,\n      PIN, simple authentication.)\n\
    \      1b. (O) \"A character string used to authenticate an identity.\"\n    \
    \  [CSC2]\n      1c. (O) \"A string of characters (letters, numbers, and other\n\
    \      symbols) used to authenticate an identity or to verify access\n      authorization.\"\
    \ [FP140]\n      1d. (O) \"A secret that a claimant memorizes and uses to\n  \
    \    authenticate his or her identity. Passwords are typically\n      character\
    \ strings.\" [SP63]\n      Tutorial: A password is usually paired with a user\
    \ identifier that\n      is explicit in the authentication process, although in\
    \ some cases\n      the identifier may be implicit. A password is usually verified\
    \ by\n      matching it to a stored value held by the access control system\n\
    \      for that identifier.\n      Using a password as authentication information\
    \ is based on\n      assuming that the password is known only by the system entity\
    \ for\n      which the identity is being authenticated. Therefore, in a network\n\
    \      environment where wiretapping is possible, simple authentication\n    \
    \  that relies on transmission of static (i.e., repetitively used)\n      passwords\
    \ in cleartext form is inadequate. (See: one-time\n      password, strong authentication.)\n\
    \   $ Password Authentication Protocol (PAP)\n      (I) A simple authentication\
    \ mechanism in PPP. In PAP, a user\n      identifier and password are transmitted\
    \ in cleartext form. [R1334]\n      (See: CHAP.)\n   $ password sniffing\n   \
    \   (D) /slang/ Passive wiretapping to gain knowledge of passwords.\n      (See:\
    \ Deprecated Usage under \"sniffing\".)\n   $ path discovery\n      (I) For a\
    \ digital certificate, the process of finding a set of\n      public-key certificates\
    \ that comprise a certification path from a\n      trusted key to that specific\
    \ certificate.\n   $ path validation\n      (I) The process of validating (a)\
    \ all of the digital certificates\n      in a certification path and (b) the required\
    \ relationships between\n      those certificates, thus validating the contents\
    \ of the last\n      certificate on the path. (See: certificate validation.)\n\
    \      Tutorial: To promote interoperable PKI applications in the\n      Internet,\
    \ RFC 3280 specifies a detailed algorithm for validation\n      of a certification\
    \ path.\n   $ payment card\n      (N) /SET/ Collectively refers \"to credit cards,\
    \ debit cards,\n      charge cards, and bank cards issued by a financial institution\
    \ and\n      which reflects a relationship between the cardholder and the\n  \
    \    financial institution.\" [SET2]\n   $ payment gateway\n      (O) /SET/ A\
    \ system operated by an acquirer, or a third party\n      designated by an acquirer,\
    \ to provide electronic commerce services\n      to the merchants in support of\
    \ the acquirer, and which interfaces\n      to the acquirer to support the authorization,\
    \ capture, and\n      processing of merchant payment messages, including payment\n\
    \      instructions from cardholders. [SET1, SET2]\n   $ payment gateway certification\
    \ authority (SET PCA)\n      (O) /SET/ A CA that issues digital certificates to\
    \ payment\n      gateways and is operated on behalf of a payment card brand, an\n\
    \      acquirer, or another party according to brand rules. A SET PCA\n      issues\
    \ a CRL for compromised payment gateway certificates. [SET2]\n      (See: PCA.)\n\
    \   $ PC card\n      (N) A type of credit card-sized, plug-in peripheral device\
    \ that\n      was originally developed to provide memory expansion for portable\n\
    \      computers, but is also used for other kinds of functional\n      expansion.\
    \ (See: FORTEZZA, PCMCIA.)\n      Tutorial: The international PC Card Standard\
    \ defines a non-\n      proprietary form factor in three sizes -- Types I, II,\
    \ and III --\n      each of which have a 68-pin interface between the card and\
    \ the\n      socket into which it plugs. All three types have the same length\n\
    \      and width, roughly the size of a credit card, but differ in their\n   \
    \   thickness from 3.3 to 10.5 mm. Examples include storage modules,\n      modems,\
    \ device interface adapters, and cryptographic modules.\n   $ PCA\n      (D) Abbreviation\
    \ of various kinds of \"certification authority\".\n      (See: Internet policy\
    \ certification authority, (MISSI) policy\n      creation authority, (SET) payment\
    \ gateway certification\n      authority.)\n      Deprecated Usage: An IDOC that\
    \ uses this abbreviation SHOULD\n      define it at the point of first use.\n\
    \   $ PCI\n      (N) See: \"protocol control information\" under \"protocol data\n\
    \      unit\".\n   $ PCMCIA\n      (N) Personal Computer Memory Card International\
    \ Association, a\n      group of manufacturers, developers, and vendors, founded\
    \ in 1989\n      to standardize plug-in peripheral memory cards for personal\n\
    \      computers and now extended to deal with any technology that works\n   \
    \   in the PC Card form factor. (See: PC card.)\n   $ PDS\n      (N) See: protective\
    \ distribution system.\n   $ PDU\n      (N) See: protocol data unit.\n   $ peer\
    \ entity authentication\n      (I) \"The corroboration that a peer entity in an\
    \ association is the\n      one claimed.\" [I7498-2] (See: authentication.)\n\
    \   $ peer entity authentication service\n      (I) A security service that verifies\
    \ an identity claimed by or for\n      a system entity in an association. (See:\
    \ authentication,\n      authentication service.)\n      Tutorial: This service\
    \ is used at the establishment of, or at\n      times during, an association to\
    \ confirm the identity of one entity\n      to another, thus protecting against\
    \ a masquerade by the first\n      entity. However, unlike data origin authentication\
    \ service, this\n      service requires an association to exist between the two\
    \ entities,\n      and the corroboration provided by the service is valid only\
    \ at the\n      current time that the service is provided. (See: \"relationship\n\
    \      between data integrity service and authentication services\" under\n  \
    \    \"data integrity service\").\n   $ PEM\n      (I) See: Privacy Enhanced Mail.\n\
    \   $ penetrate\n      1a. (I) Circumvent a system's security protections. (See:\
    \ attack,\n      break, violation.)\n      1b. (I) Successfully and repeatedly\
    \ gain unauthorized access to a\n      protected system resource. [Huff]\n   $\
    \ penetration\n      (I) /threat action/ See: secondary definition under \"intrusion\"\
    .\n   $ penetration test\n      (I) A system test, often part of system certification,\
    \ in which\n      evaluators attempt to circumvent the security features of a\n\
    \      system. [NCS04, SP42] (See: tiger team.)\n      Tutorial: Penetration testing\
    \ evaluates the relative vulnerability\n      of a system to attacks and identifies\
    \ methods of gaining access to\n      a system by using tools and techniques that\
    \ are available to\n      adversaries. Testing may be performed under various\
    \ constraints\n      and conditions, including a specified level of knowledge\
    \ of the\n      system design and implementation. For a TCSEC evaluation, testers\n\
    \      are assumed to have all system design and implementation\n      documentation,\
    \ including source code, manuals, and circuit\n      diagrams, and to work under\
    \ no greater constraints than those\n      applied to ordinary users.\n   $ perfect\
    \ forward secrecy\n      (I) For a key agreement protocol, the property that compromises\n\
    \      long-term keying material does not compromise session keys that\n     \
    \ were previously derived from the long-term material. (Compare:\n      public-key\
    \ forward secrecy.)\n      Usage: Some existing RFCs use this term but either\
    \ do not define\n      it or do not define it precisely. While preparing this\
    \ Glossary,\n      we found this to be a muddled area. Experts did not agree.\
    \ For all\n      practical purposes, the literature defines \"perfect forward\n\
    \      secrecy\" by stating the Diffie-Hellman-Merkle algorithm. The term\n  \
    \    \"public-key forward secrecy\" (suggested by Hilarie Orman) and the\n   \
    \   definition stated for it in this Glossary were crafted to be\n      compatible\
    \ with current Internet documents, yet be narrow and\n      leave room for improved\
    \ terminology.\n      Challenge to the Internet security community: We need a\
    \ taxonomy\n      of terms and definitions to cover the basic properties discussed\n\
    \      here for the full range of cryptographic algorithms and protocols\n   \
    \   used in Internet Standards:\n      Involvement of session keys vs. long-term\
    \ keys: Experts disagree\n      about the basic ideas involved:\n      -  One\
    \ concept of \"forward secrecy\" is that, given observations of\n         the\
    \ operation of a key establishment protocol up to time t, and\n         given\
    \ some of the session keys derived from those protocol\n         runs, you cannot\
    \ derive unknown past session keys or future\n         session keys.\n      -\
    \  A related property is that, given observations of the protocol\n         and\
    \ knowledge of the derived session keys, you cannot derive\n         one or more\
    \ of the long-term private keys.\n      -  The \"I\" definition presented above\
    \ involves a third concept of\n         \"forward secrecy\" that refers to the\
    \ effect of the compromise\n         of long-term keys.\n      -  All three concepts\
    \ involve the idea that a compromise of \"this\"\n         encryption key is not\
    \ supposed to compromise the \"next\" one.\n         There also is the idea that\
    \ compromise of a single key will\n         compromise only the data protected\
    \ by the single key. In\n         Internet literature, the focus has been on protection\
    \ against\n         decryption of back traffic in the event of a compromise of\n\
    \         secret key material held by one or both parties to a\n         communication.\n\
    \      Forward vs. backward: Experts are unhappy with the word \"forward\",\n\
    \      because compromise of \"this\" encryption key also is not supposed\n  \
    \    to compromise the \"previous\" one, which is \"backward\" rather than\n \
    \     forward. In S/KEY, if the key used at time t is compromised, then\n    \
    \  all keys used prior to that are compromised. If the \"long-term\"\n      key\
    \ (i.e., the base of the hashing scheme) is compromised, then\n      all keys\
    \ past and future are compromised; thus, you could say that\n      S/KEY has neither\
    \ forward nor backward secrecy.\n      Asymmetric cryptography vs. symmetric:\
    \ Experts disagree about\n      forward secrecy in the context of symmetric cryptographic\
    \ systems.\n      In the absence of asymmetric cryptography, compromise of any\
    \ long-\n      term key seems to compromise any session key derived from the\n\
    \      long-term key. For example, Kerberos isn't forward secret, because\n  \
    \    compromising a client's password (thus compromising the key shared\n    \
    \  by the client and the authentication server) compromises future\n      session\
    \ keys shared by the client and the ticket-granting server.\n      Ordinary forward\
    \ secrecy vs. \"perfect\" forward secret: Experts\n      disagree about the difference\
    \ between these two. Some say there is\n      no difference, and some say that\
    \ the initial naming was\n      unfortunate and suggest dropping the word \"perfect\"\
    . Some suggest\n      using \"forward secrecy\" for the case where one long-term\
    \ private\n      key is compromised, and adding \"perfect\" for when both private\n\
    \      keys (or, when the protocol is multi-party, all private keys) are\n   \
    \   compromised.\n      Acknowledgements: Bill Burr, Burt Kaliski, Steve Kent,\
    \ Paul Van\n      Oorschot, Jonathan Trostle, Michael Wiener, and, especially,\n\
    \      Hilarie Orman contributed ideas to this discussion.\n   $ perimeter\n \
    \     See: security perimeter.\n   $ periods processing\n      (I) A mode of system\
    \ operation in which information of different\n      sensitivities is processed\
    \ at distinctly different times by the\n      same system, with the system being\
    \ properly purged or sanitized\n      between periods. (See: color change.)\n\
    \      Tutorial: The security mode of operation and maximum\n      classification\
    \ of data handled by the system is established for an\n      interval of time\
    \ and then is changed for the following interval of\n      time. A period extends\
    \ from the secure initialization of the\n      system to the completion of any\
    \ purging of sensitive data handled\n      by the system during the period.\n\
    \   $ permanent storage\n      (I) Non-volatile media that, once written into,\
    \ can never be\n      completely erased.\n   $ permission\n      1a. (I) Synonym\
    \ for \"authorization\". (Compare: privilege.)\n      1b. (N) An authorization\
    \ or set of authorizations to perform\n      security-relevant functions in the\
    \ context of role-based access\n      control. [ANSI]\n      Tutorial: A permission\
    \ is a positively stated authorization for\n      access that (a) can be associated\
    \ with one or more roles and (b)\n      enables a user in a role to access a specified\
    \ set of system\n      resources by causing a specific set of system actions to\
    \ be\n      performed on the resources.\n   $ persona certificate\n      (I) An\
    \ X.509 certificate issued to a system entity that wishes to\n      use a persona\
    \ to conceal its true identity when using PEM or other\n      Internet services\
    \ that depend on PKI support. (See: anonymity.)\n      [R1422]\n      Tutorial:\
    \ PEM designers intended that (a) a CA issuing persona\n      certificates would\
    \ explicitly not be vouching for the identity of\n      the system entity to whom\
    \ the certificate is issued, (b) such\n      certificates would be issued only\
    \ by CAs subordinate to a policy\n      CA having a policy stating that purpose\
    \ (i.e., that would warn\n      relying parties that the \"subject\" field DN\
    \ represented only a\n      persona and not a true, vetted user identity), and\
    \ (c) the CA\n      would not need to maintain records binding the true identity\
    \ of\n      the subject to the certificate.\n      However, the PEM designers\
    \ also intended that a CA issuing persona\n      certificates would establish\
    \ procedures (d) to enable \"the holder\n      of a PERSONA certificate to request\
    \ that his certificate be\n      revoked\" and (e) to ensure that it did not issue\
    \ the same subject\n      DN to multiple users. The latter condition implies that\
    \ a persona\n      certificate is not an organizational certificate unless the\n\
    \      organization has just one member or representative.\n   $ personal identification\
    \ number (PIN)\n      1a. (I) A character string used as a password to gain access\
    \ to a\n      system resource. (See: authentication information.)\n      Example:\
    \ A cryptographic token typically requires its user to\n      enter a PIN in order\
    \ to access information stored in the token and\n      invoke the token's cryptographic\
    \ functions.\n      1b. (O) An alphanumeric code or password used to authenticate\
    \ an\n      identity.\n      Tutorial: Despite the words \"identification\" and\
    \ \"number\", a PIN\n      seldom serves as a user identifier, and a PIN's characters\
    \ are not\n      necessarily all numeric. Retail banking applications use 4-digit\n\
    \      numeric user PINs, but the FORTEZZA PC card uses 12-character\n      alphanumeric\
    \ SSO PINs. (See: SSO PIN, user PIN.)\n      A better name for this concept would\
    \ have been \"personnel\n      authentication system string\" (PASS), in which\
    \ case, an\n      alphanumeric character string for this purpose would have been\n\
    \      called, obviously, a \"PASSword\".\n   $ personal information\n      (I)\
    \ Information about a particular person, especially information\n      of an intimate\
    \ or critical nature, that could cause harm or pain\n      to that person if disclosed\
    \ to unauthorized parties. Examples:\n      medical record, arrest record, credit\
    \ report, academic transcript,\n      training report, job application, credit\
    \ card number, Social\n      Security number. (See: privacy.)\n   $ personality\n\
    \      1. (I) Synonym for \"principal\".\n      2. (O) /MISSI/ A set of MISSI\
    \ X.509 public-key certificates that\n      have the same subject DN, together\
    \ with their associated private\n      keys and usage specifications, that is\
    \ stored on a FORTEZZA PC\n      card to support a role played by the card's user.\n\
    \      Tutorial: When a card's user selects a personality to use in a\n      FORTEZZA-aware\
    \ application, the data determines behavior traits\n      (the personality) of\
    \ the application. A card's user may have\n      multiple personalities on the\
    \ card. Each has a \"personality\n      label\", a user-friendly character string\
    \ that applications can\n      display to the user for selecting or changing the\
    \ personality to\n      be used. For example, a military user's card might contain\
    \ three\n      personalities: GENERAL HALFTRACK, COMMANDER FORT SWAMPY, and NEW\n\
    \      YEAR'S EVE PARTY CHAIRMAN. Each personality includes one or more\n    \
    \  certificates of different types (such as DSA versus RSA), for\n      different\
    \ purposes (such as digital signature versus encryption),\n      or with different\
    \ authorizations.\n   $ personnel authentication system string (PASS)\n      (N)\
    \ See: Tutorial under \"personal identification number\".\n   $ personnel security\n\
    \      (I) Procedures to ensure that persons who access a system have\n      proper\
    \ clearance, authorization, and need-to-know as required by\n      the system's\
    \ security policy. (See: security architecture.)\n   $ PGP(trademark)\n      (O)\
    \ See: Pretty Good Privacy(trademark).\n   $ phase 1 negotiation\n   $ phase 2\
    \ negotiation\n      (I) /ISAKMP/ See: secondary definition under \"Internet Security\n\
    \      Association and Key Management Protocol\".\n   $ phishing\n      (D) /slang/\
    \ A technique for attempting to acquire sensitive data,\n      such as bank account\
    \ numbers, through a fraudulent solicitation in\n      email or on a Web site,\
    \ in which the perpetrator masquerades as a\n      legitimate business or reputable\
    \ person. (See: social\n      engineering.)\n      Derivation: Possibly from \"\
    phony fishing\"; the solicitation\n      usually involves some kind of lure or\
    \ bait to hook unwary\n      recipients. (Compare: phreaking.)\n      Deprecated\
    \ Term: IDOCs SHOULD NOT use this term; it is not listed\n      in most dictionaries\
    \ and could confuse international readers.\n      (See: Deprecated Usage under\
    \ \"Green Book\".)\n   $ Photuris\n      (I) A UDP-based, key establishment protocol\
    \ for session keys,\n      designed for use with the IPsec protocols AH and ESP.\
    \ Superseded\n      by IKE.\n   $ phreaking\n      (D) A contraction of \"telephone\
    \ breaking\". An attack on or\n      penetration of a telephone system or, by\
    \ extension, any other\n      communication or information system. [Raym]\n  \
    \    Deprecated Term: IDOCs SHOULD NOT use this contraction; it is not\n     \
    \ listed in most dictionaries and could confuse international\n      readers.\
    \ (See: Deprecated Usage under \"Green Book\".)\n   $ physical destruction\n \
    \     (I) /threat action/ See: secondary definition under\n      \"incapacitation\"\
    .\n   $ physical security\n      (I) Tangible means of preventing unauthorized\
    \ physical access to a\n      system. Examples: Fences, walls, and other barriers;\
    \ locks, safes,\n      and vaults; dogs and armed guards; sensors and alarm bells.\n\
    \      [FP031, R1455] (See: security architecture.)\n   $ piggyback attack\n \
    \     (I) A form of active wiretapping in which the attacker gains\n      access\
    \ to a system via intervals of inactivity in another user's\n      legitimate\
    \ communication connection. Sometimes called a \"between-\n      the-lines\" attack.\
    \ (See: hijack attack, man-in-the-middle attack.)\n      Deprecated Usage: IDOCs\
    \ that use this term SHOULD state a\n      definition for it because the term\
    \ could confuse international\n      readers.\n   $ PIN\n      (I) See: personal\
    \ identification number.\n   $ ping of death\n      (D) A denial-of-service attack\
    \ that sends an improperly large ICMP\n      echo request packet (a \"ping\")\
    \ with the intent of causing the\n      destination system to fail. (See: ping\
    \ sweep, teardrop.)\n      Deprecated Term: IDOCs SHOULD NOT use this term; instead,\
    \ use\n      \"ping packet overflow attack\" or some other term that is specific\n\
    \      with regard to the attack mechanism.\n      Tutorial: This attack seeks\
    \ to exploit an implementation\n      vulnerability. The IP specification requires\
    \ hosts to be prepared\n      to accept datagrams of up to 576 octets, but also\
    \ permits IP\n      datagrams to be up to 65,535 octets long. If an IP implementation\n\
    \      does not properly handle very long IP packets, the ping packet may\n  \
    \    overflow the input buffer and cause a fatal system error.\n   $ ping sweep\n\
    \      (I) An attack that sends ICMP echo requests (\"pings\") to a range\n  \
    \    of IP addresses, with the goal of finding hosts that can be probed\n    \
    \  for vulnerabilities. (See: ping of death. Compare: port scan.)\n   $ PKCS\n\
    \      (N) See: Public-Key Cryptography Standards.\n   $ PKCS #5\n      (N) A\
    \ standard [PKC05] (see: RFC 2898) from the PKCS series;\n      defines a method\
    \ for encrypting an octet string with a secret key\n      derived from a password.\n\
    \      Tutorial: Although the method can be used for arbitrary octet\n      strings,\
    \ its intended primary application in public-key\n      cryptography is for encrypting\
    \ private keys when transferring them\n      from one computer system to another,\
    \ as described in PKCS #8.\n   $ PKCS #7\n      (N) A standard [PKC07] (see: RFC\
    \ 2315) from the PKCS series;\n      defines a syntax for data that may have cryptography\
    \ applied to\n      it, such as for digital signatures and digital envelopes.\
    \ (See:\n      CMS.)\n   $ PKCS #10\n      (N) A standard [PKC10] (see: RFC 2986)\
    \ from the PKCS series;\n      defines a syntax for certification requests. (See:\
    \ certification\n      request.)\n      Tutorial: A PKCS #10 request contains\
    \ a DN and a public key, and\n      may contain other attributes, and is signed\
    \ by the entity making\n      the request. The request is sent to a CA, who converts\
    \ it to an\n      X.509 public-key certificate (or some other form), and returns\
    \ it,\n      possibly in PKCS #7 format.\n   $ PKCS #11\n      (N) A standard\
    \ [PKC11] from the PKCS series; defines CAPI called\n      \"Cryptoki\" for devices\
    \ that hold cryptographic information and\n      perform cryptographic functions.\n\
    \   $ PKI\n      (I) See: public-key infrastructure.\n   $ PKINIT\n      (I) Abbreviation\
    \ for \"Public Key Cryptography for Initial\n      Authentication in Kerberos\"\
    \ (RFC 4556). (See: Tutorial under\n      \"Kerberos\".)\n   $ PKIX\n      1a.\
    \ (I) A contraction of \"Public-Key Infrastructure (X.509)\", the\n      name\
    \ of the IETF working group that is specifying an architecture\n      [R3280]\
    \ and set of protocols [R4210] to provide X.509-based PKI\n      services for\
    \ the Internet.\n      1b. (I) A collective name for that Internet PKI architecture\
    \ and\n      associated set of protocols.\n      Tutorial: The goal of PKIX is\
    \ to facilitate the use of X.509\n      public-key certificates in multiple Internet\
    \ applications and to\n      promote interoperability between different implementations\
    \ that\n      use those certificates. The resulting PKI is intended to provide\
    \ a\n      framework that supports a range of trust and hierarchy\n      environments\
    \ and a range of usage environments. PKIX specifies (a)\n      profiles of the\
    \ v3 X.509 public-key certificate standards and the\n      v2 X.509 CRL standards\
    \ for the Internet, (b) operational protocols\n      used by relying parties to\
    \ obtain information such as certificates\n      or certificate status, (c) management\
    \ protocols used by system\n      entities to exchange information needed for\
    \ proper management of\n      the PKI, and (d) information about certificate policies\
    \ and CPSs,\n      covering the areas of PKI security not directly addressed in\
    \ the\n      rest of PKIX.\n   $ plain text\n      1. (I) /noun/ Data that is\
    \ input to an encryption process. (See:\n      plaintext. Compare: cipher text,\
    \ clear text.)\n      2. (D) /noun/ Synonym for \"clear text\".\n      Deprecated\
    \ Definition: IDOCs SHOULD NOT use this term as a synonym\n      for \"clear text\"\
    . Sometimes plain text that is input to an\n      encryption operation is clear\
    \ text, but other times plain text is\n      cipher text that was output from\
    \ a previous encryption operation.\n      (See: superencryption.)\n   $ plaintext\n\
    \      1. (O) /noun/ Synonym for \"plain text\".\n      2. (I) /adjective/ Referring\
    \ to plain text. Usage: Commonly used\n      instead of \"plain-text\". (Compare:\
    \ ciphertext, cleartext.)\n      3. (D) /noun/ Synonym for \"cleartext\".\n  \
    \    Deprecated Definition: IDOCs SHOULD NOT use this term as a synonym\n    \
    \  for \"cleartext\". Cleartext data is, by definition, not encrypted;\n     \
    \ but plaintext data that is input to an encryption operation may be\n      cleartext\
    \ data or may be ciphertext data that was output from a\n      previous encryption\
    \ operation. (See: superencryption.)\n   $ PLI\n      (I) See: Private Line Interface.\n\
    \   $ PMA\n      (N) See: policy management authority.\n   $ Point-to-Point Protocol\
    \ (PPP)\n      (I) An Internet Standard protocol (RFC 1661) for encapsulation\
    \ and\n      full-duplex transportation of protocol data packets in OSIRM Layer\n\
    \      3 over an OSIRM Layer 2 link between two peers, and for\n      multiplexing\
    \ different Layer 3 protocols over the same link.\n      Includes optional negotiation\
    \ to select and use a peer entity\n      authentication protocol to authenticate\
    \ the peers to each other\n      before they exchange Layer 3 data. (See: CHAP,\
    \ EAP, PAP.)\n   $ Point-to-Point Tunneling Protocol (PPTP)\n      (I) An Internet\
    \ client-server protocol (RFC 2637) (originally\n      developed by Ascend and\
    \ Microsoft) that enables a dial-up user to\n      create a virtual extension\
    \ of the dial-up link across a network by\n      tunneling PPP over IP. (See:\
    \ L2TP.)\n      Tutorial: PPP can encapsulate any IPS Network Interface Layer\n\
    \      protocol or OSIRM Layer 3 protocol. Therefore, PPTP does not\n      specify\
    \ security services; it depends on protocols above and below\n      it to provide\
    \ any needed security. PPTP makes it possible to\n      divorce the location of\
    \ the initial dial-up server (i.e., the PPTP\n      Access Concentrator, the client,\
    \ which runs on a special-purpose\n      host) from the location at which the\
    \ dial-up protocol (PPP)\n      connection is terminated and access to the network\
    \ is provided\n      (i.e., at the PPTP Network Server, which runs on a general-purpose\n\
    \      host).\n   $ policy\n      1a. (I) A plan or course of action that is stated\
    \ for a system or\n      organization and is intended to affect and direct the\
    \ decisions\n      and deeds of that entity's components or members. (See: security\n\
    \      policy.)\n      1b. (O) A definite goal, course, or method of action to\
    \ guide and\n      determine present and future decisions, that is implemented\
    \ or\n      executed within a particular context, such as within a business\n\
    \      unit. [R3198]\n      Deprecated Abbreviation: IDOCs SHOULD NOT use \"policy\"\
    \ as an\n      abbreviation of either \"security policy\" or \"certificate policy\"\
    .\n      Instead, to avoid misunderstanding, use a fully qualified term, at\n\
    \      least at the point of first usage.\n      Tutorial: The introduction of\
    \ new technology to replace\n      traditional systems can result in new systems\
    \ being deployed\n      without adequate policy definition and before the implications\
    \ of\n      the new technology are fully understand. In some cases, it can be\n\
    \      difficult to establish policies for new technology before the\n      technology\
    \ has been operationally tested and evaluated. Thus,\n      policy changes tend\
    \ to lag behind technological changes, such that\n      either old policies impede\
    \ the technical innovation, or the new\n      technology is deployed without adequate\
    \ policies to govern its\n      use.\n      When new technology changes the ways\
    \ that things are done, new\n      \"procedures\" must be defined to establish\
    \ operational guidelines\n      for using the technology and achieving satisfactory\
    \ results, and\n      new \"practices\" must be established for managing new systems\
    \ and\n      monitoring results. Practices and procedures are more directly\n\
    \      coupled to actual systems and business operations than are\n      polices,\
    \ which tend to be more abstract.\n      -  \"Practices\" define how a system\
    \ is to be managed and what\n         controls are in place to monitor the system\
    \ and detect abnormal\n         behavior or quality problems. Practices are established\
    \ to\n         ensure that a system is managed in compliance with stated\n   \
    \      policies. System audits are primarily concerned with whether or\n     \
    \    not practices are being followed. Auditors evaluate the\n         controls\
    \ to make sure they conform to accepted industry\n         standards, and then\
    \ confirm that controls are in place and that\n         control measurements are\
    \ being gathered. Audit trails are\n         examples of control measurements\
    \ that are recorded as part of\n         system operations.\n      -  \"Procedures\"\
    \ define how a system is operated, and relate\n         closely to issues of what\
    \ technology is used, who the operators\n         are, and how the system is deployed\
    \ physically. Procedures\n         define both normal and abnormal operating circumstances.\n\
    \      -  For every control defined by a practice statement, there should\n  \
    \       be corresponding procedures to implement the control and\n         provide\
    \ ongoing measurement of the control parameters.\n         Conversely, procedures\
    \ require management practices to insure\n         consistent and correct operational\
    \ behavior.\n   $ policy approval authority\n      (D) /PKI/ Synonym for \"policy\
    \ management authority\". [PAG]\n      Deprecated Term: IDOCs SHOULD NOT use this\
    \ term as synonym for\n      \"policy management authority\". The term suggests\
    \ a limited,\n      passive role that is not typical of PMAs.\n   $ policy approving\
    \ authority (PAA)\n      (O) /MISSI/ The top-level signing authority of a MISSI\n\
    \      certification hierarchy. The term refers both to that\n      authoritative\
    \ office or role and to the person who plays that\n      role. (See: policy management\
    \ authority, root registry.)\n      Tutorial: A MISSI PAA (a) registers MISSI\
    \ PCAs and signs their\n      X.509 public-key certificates, (b) issues CRLs but\
    \ does not issue\n      a CKL, and (c) may issue cross-certificates to other PAAs.\n\
    \   $ policy authority\n      (D) /PKI/ Synonym for \"policy management authority\"\
    . [PAG]\n      Deprecated Term: IDOCs SHOULD NOT use this term as synonym for\n\
    \      \"policy management authority\". The term is unnecessarily vague and\n\
    \      thus may be confused with other PKI entities, such as CAs and RAs,\n  \
    \    that enforce of apply various aspects of PKI policy.\n   $ policy certification\
    \ authority (Internet PCA)\n      (I) An X.509-compliant CA at the second level\
    \ of the Internet\n      certification hierarchy, under the IPRA. Each PCA operates\
    \ under\n      its published security policy (see: certificate policy, CPS) and\n\
    \      within constraints established by the IPRA for all PCAs. [R1422].\n   \
    \   (See: policy creation authority.)\n   $ policy creation authority (MISSI PCA)\n\
    \      (O) /MISSI/ The second level of a MISSI certification hierarchy;\n    \
    \  the administrative root of a security policy domain of MISSI users\n      and\
    \ other, subsidiary authorities. The term refers both to that\n      authoritative\
    \ office or role and to the person who fills that\n      office. (See: policy\
    \ certification authority.)\n      Tutorial: A MISSI PCA's certificate is issued\
    \ by a PAA. The PCA\n      registers the CAs in its domain, defines their configurations,\
    \ and\n      issues their X.509 public-key certificates. (The PCA may also\n \
    \     issue certificates for SCAs, ORAs, and other end entities, but a\n     \
    \ PCA does not usually do this.) The PCA periodically issues CRLs\n      and CKLs\
    \ for its domain.\n   $ policy management authority (PMA)\n      (I) /PKI/ A person,\
    \ role, or organization within a PKI that is\n      responsible for (a) creating\
    \ or approving the content of the\n      certificate policies and CPSs that are\
    \ used in the PKI; (b)\n      ensuring the administration of those policies; and\
    \ (c) approving\n      any cross-certification or interoperability agreements\
    \ with CAs\n      external to the PKI and any related policy mappings. The PMA\
    \ may\n      also be the accreditor for the PKI as a whole or for some of its\n\
    \      components or applications. [DoD9, PAG] (See: policy approving\n      authority.)\n\
    \      Example: In the U.S. Department of Defense, an organization called\n  \
    \    the Policy Management Authority is responsible for DoD PKI [DoD9].\n   $\
    \ policy mapping\n      (I) \"Recognizing that, when a CA in one domain certifies\
    \ a CA in\n      another domain, a particular certificate policy in the second\n\
    \      domain may be considered by the authority of the first domain to\n    \
    \  be equivalent (but not necessarily identical in all respects) to a\n      particular\
    \ certificate policy in the first domain.\" [X509]\n   $ policy rule\n      (I)\
    \ A building block of a security policy; it (a) defines a set of\n      system\
    \ conditions and (b) specifies a set of system actions that\n      are to be performed\
    \ if those conditions occur. [R3198]\n   $ POP3\n      (I) See: Post Office Protocol,\
    \ version 3.\n   $ POP3 APOP\n      (I) A POP3 command (better described as a\
    \ transaction type, or\n      subprotocol) by which a POP3 client optionally uses\
    \ a keyed hash\n      (based on MD5) to authenticate itself to a POP3 server and,\n\
    \      depending on the server implementation, to protect against replay\n   \
    \   attacks. (See: CRAM, POP3 AUTH, IMAP4 AUTHENTICATE.)\n      Tutorial: The\
    \ server includes a unique time stamp in its greeting\n      to the client. The\
    \ subsequent APOP command sent by the client to\n      the server contains the\
    \ client's name and the hash result of\n      applying MD5 to a string formed\
    \ from both the time stamp and a\n      shared secret value that is known only\
    \ to the client and the\n      server. APOP was designed to provide an alternative\
    \ to using\n      POP3's USER and PASS (i.e., password) command pair, in which\
    \ the\n      client sends a cleartext password to the server.\n   $ POP3 AUTH\n\
    \      (I) A POP3 command [R1734] (better described as a transaction\n      type,\
    \ or subprotocol) by which a POP3 client optionally proposes a\n      mechanism\
    \ to a POP3 server to authenticate the client to the\n      server and provide\
    \ other security services. (See: POP3 APOP, IMAP4\n      AUTHENTICATE.)\n    \
    \  Tutorial: If the server accepts the proposal, the command is\n      followed\
    \ by performing a challenge-response authentication\n      protocol and, optionally,\
    \ negotiating a protection mechanism for\n      subsequent POP3 interactions.\
    \ The security mechanisms used by POP3\n      AUTH are those used by IMAP4.\n\
    \   $ port scan\n      (I) A technique that sends client requests to a range of\
    \ service\n      port addresses on a host. (See: probe. Compare: ping sweep.)\n\
    \      Tutorial: A port scan can be used for pre-attack surveillance,\n      with\
    \ the goal of finding an active port and subsequently\n      exploiting a known\
    \ vulnerability of that port's service. A port\n      scan can also be used as\
    \ a flooding attack.\n   $ positive authorization\n      (I) The principle that\
    \ a security architecture should be designed\n      so that access to system resources\
    \ is permitted only when\n      explicitly granted; i.e., in the absence of an\
    \ explicit\n      authorization that grants access, the default action shall be\
    \ to\n      refuse access. (See: authorization, access.)\n   $ POSIX\n      (N)\
    \ Portable Operating System Interface for Computer Environments,\n      a standard\
    \ [FP151, I9945] (originally IEEE Standard P1003.1) that\n      defines an operating\
    \ system interface and environment to support\n      application portability at\
    \ the source code level. It is intended\n      to be used by both application\
    \ developers and system implementers.\n      Tutorial: P1003.1 supports security\
    \ functionality like that on\n      most UNIX systems, including discretionary\
    \ access control and\n      privileges. IEEE Draft Standard P1003.6 specifies\
    \ additional\n      functionality not provided in the base standard, including\
    \ (a)\n      discretionary access control, (b) audit trail mechanisms, (c)\n \
    \     privilege mechanisms, (d) mandatory access control, and (e)\n      information\
    \ label mechanisms.\n   $ Post Office Protocol, version 3 (POP3)\n      (I) An\
    \ Internet Standard protocol (RFC 1939) by which a client\n      workstation can\
    \ dynamically access a mailbox on a server host to\n      retrieve mail messages\
    \ that the server has received and is holding\n      for the client. (See: IMAP4.)\n\
    \      Tutorial: POP3 has mechanisms for optionally authenticating a\n      client\
    \ to a server and providing other security services. (See:\n      POP3 APOP, POP3\
    \ AUTH.)\n   $ PPP\n      (I) See: Point-to-Point Protocol.\n   $ PPTP\n     \
    \ (I) See: Point-to-Point Tunneling Protocol.\n   $ preauthorization\n      (N)\
    \ /PKI/ A CAW feature that enables certification requests to be\n      automatically\
    \ validated against data provided in advance to the CA\n      by an authorizing\
    \ entity.\n   $ precedence\n      1. (I) /information system/ A ranking assigned\
    \ to events or data\n      objects that determines the relative order in which\
    \ they are\n      processed.\n      2. (N) /communication system/ A designation\
    \ assigned to a\n      communication (i.e., packet, message, data stream, connection,\n\
    \      etc.) by the originator to state the importance or urgency of that\n  \
    \    communication versus other communications, and thus indicate to\n      the\
    \ transmission system the relative order of handling, and\n      indicate to the\
    \ receiver the order in which the communication is\n      to be noted. [F1037]\
    \ (See: availability, critical, preemption.)\n      Example: The \"Precedence\"\
    \ subfield of the \"Type of Service\" field\n      of the IPv4 header supports\
    \ the following designations (in\n      descending order of importance): 111 Network\
    \ Control, 110\n      Internetwork Control, 101 CRITIC/ECP (Critical Intelligence\n\
    \      Communication/Emergency Command Precedence), 100 Flash Override,\n    \
    \  011 Flash, 010 Immediate, 001 Priority, and 000 Routine. These\n      designations\
    \ were adopted from U.S. DoD systems that existed\n      before ARPANET.\n   $\
    \ preemption\n      (N) The seizure, usually automatic, of system resources that\
    \ are\n      being used to serve a lower-precedence communication, in order to\n\
    \      serve immediately a higher-precedence communication. [F1037]\n   $ Pretty\
    \ Good Privacy(trademark) (PGP(trademark))\n      (O) Trademarks of Network Associates,\
    \ Inc., referring to a\n      computer program (and related protocols) that uses\
    \ cryptography to\n      provide data security for electronic mail and other applications\n\
    \      on the Internet. (Compare: DKIM, MOSS, MSP, PEM, S/MIME.)\n      Tutorial:\
    \ PGP encrypts messages with a symmetric algorithm\n      (originally, IDEA in\
    \ CFB mode), distributes the symmetric keys by\n      encrypting them with an\
    \ asymmetric algorithm (originally, RSA),\n      and creates digital signatures\
    \ on messages with a cryptographic\n      hash and an asymmetric encryption algorithm\
    \ (originally, MD5 and\n      RSA). To establish ownership of public keys, PGP\
    \ depends on the\n      \"web of trust\".\n   $ prevention\n      (I) See: secondary\
    \ definition under \"security\".\n   $ primary account number (PAN)\n      (O)\
    \ /SET/ \"The assigned number that identifies the card issuer and\n      cardholder.\
    \ This account number is composed of an issuer\n      identification number, an\
    \ individual account number\n      identification, and an accompanying check digit\
    \ as defined by ISO\n      7812-1985.\" [SET2, I7812] (See: bank identification\
    \ number.)\n      Tutorial: The PAN is embossed, encoded, or both on a magnetic-\n\
    \      strip-based credit card. The PAN identifies the issuer to which a\n   \
    \   transaction is to be routed and the account to which it is to be\n      applied\
    \ unless specific instructions indicate otherwise. The\n      authority that assigns\
    \ the BIN part of the PAN is the American\n      Bankers Association.\n   $ principal\n\
    \      (I) A specific identity claimed by a user when accessing a system.\n  \
    \    Usage: Usually understood to be an identity that is registered in\n     \
    \ and authenticated by the system; equivalent to the notion of login\n      account\
    \ identifier. Each principal is normally assigned to a\n      single user, but\
    \ a single user may be assigned (or attempt to use)\n      more than one principal.\
    \ Each principal can spawn one or more\n      subjects, but each subject is associated\
    \ with only one principal.\n      (Compare: role, subject, user.)\n      (I) /Kerberos/\
    \ A uniquely identified (i.e., uniquely named) client\n      or server instance\
    \ that participates in a network communication.\n   $ priority\n      (I) /information\
    \ system/ Precedence for processing an event or\n      data object, determined\
    \ by security importance or other factors.\n      (See: precedence.)\n   $ privacy\n\
    \      1. (I) The right of an entity (normally a person), acting in its\n    \
    \  own behalf, to determine the degree to which it will interact with\n      its\
    \ environment, including the degree to which the entity is\n      willing to share\
    \ its personal information with others. (See:\n      HIPAA, personal information,\
    \ Privacy Act of 1974. Compare:\n      anonymity, data confidentiality.) [FP041]\n\
    \      2. (O) \"The right of individuals to control or influence what\n      information\
    \ related to them may be collected and stored and by\n      whom and to whom that\
    \ information may be disclosed.\" [I7498-2]\n      3. (D) Synonym for \"data confidentiality\"\
    .\n      Deprecated Definition: IDOCs SHOULD NOT use this term as a synonym\n\
    \      for \"data confidentiality\" or \"data confidentiality service\",\n   \
    \   which are different concepts. Privacy is a reason for security\n      rather\
    \ than a kind of security. For example, a system that stores\n      personal data\
    \ needs to protect the data to prevent harm,\n      embarrassment, inconvenience,\
    \ or unfairness to any person about\n      whom data is maintained, and to protect\
    \ the person's privacy. For\n      that reason, the system may need to provide\
    \ data confidentiality\n      service.\n      Tutorial: The term \"privacy\" is\
    \ used for various separate but\n      related concepts, including bodily privacy,\
    \ territorial privacy,\n      personal information privacy, and communication\
    \ privacy. IDOCs are\n      expected to address only communication privacy, which\
    \ in this\n      Glossary is defined primarily by \"data confidentiality\" and\n\
    \      secondarily by \"data integrity\".\n      IDOCs are not expected to address\
    \ information privacy, but this\n      Glossary provides definition 1 for that\
    \ concept because personal\n      information privacy is often confused with communication\
    \ privacy.\n      IDOCs are not expected to address bodily privacy or territorial\n\
    \      privacy, and this Glossary does not define those concepts because\n   \
    \   they are not easily confused with communication privacy.\n   $ Privacy Act\
    \ of 1974\n      (O) A U.S. Federal law (Section 552a of Title 5, United States\n\
    \      Code) that seeks to balance the U.S. Government's need to maintain\n  \
    \    data about individuals with the rights of individuals to be\n      protected\
    \ against unwarranted invasions of their privacy stemming\n      from federal\
    \ agencies' collection, maintenance, use, and\n      disclosure of personal data.\
    \ (See: privacy.)\n      Tutorial: In 1974, the U.S. Congress was concerned with\
    \ the\n      potential for abuses that could arise from the Government's\n   \
    \   increasing use of computers to store and retrieve personal data.\n      Therefore,\
    \ the Act has four basic policy objectives:\n      -  To restrict disclosure of\
    \ personally identifiable records\n         maintained by Federal agencies.\n\
    \      -  To grant individuals increased rights of access to Federal\n       \
    \  agency records maintained on themselves.\n      -  To grant individuals the\
    \ right to seek amendment of agency\n         records maintained on themselves\
    \ upon a showing that the\n         records are not accurate, relevant, timely,\
    \ or complete.\n      -  To establish a code of \"fair information practices\"\
    \ that\n         requires agencies to comply with statutory norms for\n      \
    \   collection, maintenance, and dissemination of records.\n   $ Privacy Enhanced\
    \ Mail (PEM)\n      (I) An Internet protocol to provide data confidentiality,\
    \ data\n      integrity, and data origin authentication for electronic mail.\n\
    \      [R1421, R1422]. (Compare: DKIM, MOSS, MSP, PGP, S/MIME.)\n      Tutorial:\
    \ PEM encrypts messages with a symmetric algorithm\n      (originally, DES in\
    \ CBC mode), provides distribution for the\n      symmetric keys by encrypting\
    \ them with an asymmetric algorithm\n      (originally, RSA), and signs messages\
    \ with an asymmetric\n      encryption algorithm over a cryptographic hash (originally,\
    \ RSA\n      over either MD2 or MD5). To establish ownership of public keys,\n\
    \      PEM uses a certification hierarchy, with X.509 public-key\n      certificates\
    \ and X.509 CRLs that are signed with an asymmetric\n      encryption algorithm\
    \ over a cryptographic hash (originally, RSA\n      over MD2).\n      PEM is designed\
    \ to be compatible with a wide range of key\n      management methods, but is\
    \ limited to specifying security services\n      only for text messages and, like\
    \ MOSS, has not been widely\n      implemented in the Internet.\n   $ private\
    \ component\n      (I) Synonym for \"private key\".\n      Deprecated Usage: In\
    \ most cases, IDOCs SHOULD NOT use this term;\n      instead, to avoid confusing\
    \ readers, use \"private key\". However,\n      the term MAY be used when discussing\
    \ a key pair; e.g., \"A key pair\n      has a public component and a private component.\"\
    \n   $ private extension\n      (I) See: secondary definition under \"extension\"\
    .\n   $ private key\n      1. (I) The secret component of a pair of cryptographic\
    \ keys used\n      for asymmetric cryptography. (See: key pair, public key, secret\n\
    \      key.)\n      2. (O) In a public key cryptosystem, \"that key of a user's\
    \ key\n      pair which is known only by that user.\" [X509]\n   $ Private Line\
    \ Interface (PLI)\n      (I) The first end-to-end packet encryption system for\
    \ a computer\n      network, developed by BBN starting in 1975 for the U.S. DoD,\n\
    \      incorporating U.S. Government-furnished, military-grade COMSEC\n      equipment\
    \ (TSEC/KG-34). [B1822] (Compare: IPLI.)\n   $ privilege\n      1a. (I) /access\
    \ control/ A synonym for \"authorization\". (See\n      authorization. Compare:\
    \ permission.)\n      1b. (I) /computer platform/ An authorization to perform\
    \ a\n      security-relevant function in the context of a computer's\n      operating\
    \ system.\n   $ privilege management infrastructure\n      (O) \"The infrastructure\
    \ able to support the management of\n      privileges in support of a comprehensive\
    \ authorization service and\n      in relationship with a\" PKI; i.e., processes\
    \ concerned with\n      attribute certificates. [X509]\n      Deprecated Usage:\
    \ IDOCs SHOULD NOT use this term with this\n      definition. This definition\
    \ is vague, and there is no consensus on\n      a more specific one.\n   $ privileged\
    \ process\n      (I) A computer process that is authorized (and, therefore,\n\
    \      trusted) to perform some security-relevant functions that ordinary\n  \
    \    processes are not. (See: privilege, trusted process.)\n   $ privileged user\n\
    \      (I) An user that has access to system control, monitoring, or\n      administration\
    \ functions. (See: privilege, /UNIX/ under \"root\",\n      superuser, user.)\n\
    \      Tutorial: Privileged users include the following types:\n      -  Users\
    \ with near or complete control of a system, who are\n         authorized to set\
    \ up and administer user accounts, identifiers,\n         and authentication information,\
    \ or are authorized to assign or\n         change other users' access to system\
    \ resources.\n      -  Users that are authorized to change control parameters\
    \ (e.g.,\n         network addresses, routing tables, processing priorities) on\n\
    \         routers, multiplexers, and other important equipment.\n      -  Users\
    \ that are authorized to monitor or perform troubleshooting\n         for a system's\
    \ security functions, typically using special\n         tools and features that\
    \ are not available to ordinary users.\n   $ probe\n      (I) /verb/ A technique\
    \ that attempts to access a system to learn\n      something about the system.\
    \ (See: port scan.)\n      Tutorial: The purpose of a probe may be offensive,\
    \ e.g., an\n      attempt to gather information for circumventing the system's\n\
    \      protections; or the purpose may be defensive, e.g., to verify that\n  \
    \    the system is working properly.\n   $ procedural security\n      (D) Synonym\
    \ for \"administrative security\".\n      Deprecated Term: IDOCs SHOULD NOT use\
    \ this term as a synonym for\n      \"administrative security\". The term may\
    \ be misleading because any\n      type of security may involve procedures, and\
    \ procedures may be\n      either external to the system or internal. Instead,\
    \ use\n      \"administrative security\", \"communication security\", \"computer\n\
    \      security\", \"emanations security\", \"personnel security\", \"physical\n\
    \      security\", or whatever specific type is meant. (See: security\n      architecture.)\n\
    \   $ profile\n      See: certificate profile, protection profile.\n   $ proof-of-possession\
    \ protocol\n      (I) A protocol whereby a system entity proves to another that\
    \ it\n      possesses and controls a cryptographic key or other secret\n     \
    \ information. (See: zero-knowledge proof.)\n   $ proprietary\n      (I) Refers\
    \ to information (or other property) that is owned by an\n      individual or\
    \ organization and for which the use is restricted by\n      that entity.\n  \
    \ $ protected checksum\n      (I) A checksum that is computed for a data object\
    \ by means that\n      protect against active attacks that would attempt to change\
    \ the\n      checksum to make it match changes made to the data object. (See:\n\
    \      digital signature, keyed hash, Tutorial under \"checksum\".)\n   $ protective\
    \ packaging\n      (N) \"Packaging techniques for COMSEC material that discourage\n\
    \      penetration, reveal a penetration has occurred or was attempted,\n    \
    \  or inhibit viewing or copying of keying material prior to the time\n      it\
    \ is exposed for use.\" [C4009] (See: tamper-evident, tamper-\n      resistant.\
    \ Compare: QUADRANT.)\n   $ protection authority\n      (I) See: secondary definition\
    \ under \"Internet Protocol Security\n      Option\".\n   $ protection level\n\
    \      (N) /U.S. Government/ An indication of the trust that is needed in\n  \
    \    a system's technical ability to enforce security policy for\n      confidentiality.\
    \ (Compare: /system operation/ under \"mode of\n      operation\".)\n      Tutorial:\
    \ An organization's security policy could define\n      protection levels that\
    \ are based on comparing (a) the sensitivity\n      of information handled by\
    \ a system to (b) the authorizations of\n      users that receive information\
    \ from the system without manual\n      intervention and reliable human review.\
    \ For each level, the policy\n      could specify security features and assurances\
    \ that must be\n      included in any system that was intended to operate at that\
    \ level.\n      Example: Given some set of data objects that are classified at\
    \ one\n      or more hierarchical levels and in one or more non-hierarchical\n\
    \      categories, the following table defines five protection levels for\n  \
    \    systems that would handle that data. Beginning with PL1 and\n      evolving\
    \ to PL5, each successive level would require stronger\n      features and assurances\
    \ to handle the dataset. (See: clearance,\n      formal access approval, and need-to-know.)\n\
    \             Lowest Clearance      Formal Access       Need-To-Know\n       \
    \       Among All Users    Approval of Users      of Users\n           +-------------------+-------------------+-------------------+\n\
    \      PL5  | Some user has no  | [Does not matter.]| [Does not matter.]|\n  \
    \    High | clearance at all. |                   |                   |\n    \
    \       +-------------------+-------------------+-------------------+\n      PL4\
    \  | All are cleared   | [Does not matter.]| [Does not matter.]|\n           |\
    \ for some data.    |                   |                   |\n           +-------------------+-------------------+-------------------+\n\
    \      PL3  | All are cleared   | Some not approved | [Does not matter.]|\n  \
    \         | for all data.     | for all data.     |                   |\n    \
    \       +-------------------+-------------------+-------------------+\n      PL2\
    \  | All are cleared   | All are approved  | Some don't need to|\n           |\
    \ for all data.     | for all data.     | to know all data. |\n           +-------------------+-------------------+-------------------+\n\
    \      PL1  | All are cleared   | All are approved  | All have a need   |\n  \
    \    Low  | for all data.     | for all data.     | to know all data. |\n    \
    \       +-------------------+-------------------+-------------------+\n   Each\
    \ of these protection levels can be viewed as being equivalent to\n   one or more\
    \ modes of system operation defined in this Glossary:\n   -  PL5 is equivalent\
    \ to multilevel security mode.\n   -  PL4 is equivalent to either multilevel or\
    \ compartmented\n      security mode, depending on the details of users' clearances.\n\
    \   -  PL3 is equivalent to partitioned security mode.\n   -  PL2 is equivalent\
    \ to system-high security mode.\n   -  PL1 is equivalent to dedicated security\
    \ mode.\n   $ protection profile\n      (N) /Common Criteria/ An implementation-independent\
    \ set of\n      security requirements for a category of targets of evaluation\
    \ that\n      meet specific consumer needs. [CCIB] Example: [IDSAN]. (See:\n \
    \     target of evaluation. Compare: certificate profile, package.)\n      Tutorial:\
    \ A protection profile (PP) is the kind of document used\n      by consumers to\
    \ specify functional requirements they want in a\n      product, and a security\
    \ target (ST) is the kind of document used\n      by vendors to make functional\
    \ claims about a product.\n      A PP is intended to be a reusable statement of\
    \ product security\n      needs, which are known to be useful and effective, for\
    \ a set of\n      information technology security products that could be built.\
    \ A PP\n      contains a set of security requirements, preferably taken from the\n\
    \      catalogs in Parts 2 and 3 of the Common Criteria, and should\n      include\
    \ an EAL. A PP could be developed by user communities,\n      product developers,\
    \ or any other parties interested in defining a\n      common set of requirements.\n\
    \   $ protection ring\n      (I) One of a hierarchy of privileged operation modes\
    \ of a system\n      that gives certain access rights to processes authorized\
    \ to\n      operate in that mode. (See: Multics.)\n   $ protective distribution\
    \ system (PDS)\n      (N) A wireline or fiber-optic communication system used\
    \ to\n      transmit cleartext classified information through an area of\n   \
    \   lesser classification or control. [N7003]\n   $ protocol\n      1a. (I) A\
    \ set of rules (i.e., formats and procedures) to implement\n      and control\
    \ some type of association (e.g., communication) between\n      systems. Example:\
    \ Internet Protocol.\n      1b. (I) A series of ordered computing and communication\
    \ steps that\n      are performed by two or more system entities to achieve a\
    \ joint\n      objective. [A9042]\n   $ protocol control information (PCI)\n \
    \     (N) See: secondary definition under \"protocol data unit\".\n   $ protocol\
    \ data unit (PDU)\n      (N) A data packet that is defined for peer-to-peer transfers\
    \ in a\n      protocol layer.\n      Tutorial: A PDU consists of two disjoint\
    \ subsets of data: the SDU\n      and the PCI. (Although these terms -- PDU, SDU,\
    \ and PCI --\n      originated in the OSIRM, they are also useful and permissible\
    \ in\n      an IPS context.)\n      -  The \"service data unit\" (SDU) in a packet\
    \ is data that the\n         protocol transfers between peer protocol entities\
    \ on behalf of\n         the users of that layer's services. For Layers 1 through\
    \ 6, the\n         layer's users are peer protocol entities at a higher layer;\
    \ for\n         Layer 7, the users are application entities outside the scope\n\
    \         of the OSIRM.\n      -  The \"protocol control information\" (PCI) in\
    \ a packet is data\n         that peer protocol entities exchange between themselves\
    \ to\n         control their joint operation of the layer.\n   $ protocol suite\n\
    \      (I) A complementary collection of communication protocols used in\n   \
    \   a computer network. (See: IPS, OSI.)\n   $ proxy\n      1. (I) A computer\
    \ process that acts on behalf of a user or client.\n      2. (I) A computer process\
    \ -- often used as, or as part of, a\n      firewall -- that relays application\
    \ transactions or a protocol\n      between client and server computer systems,\
    \ by appearing to the\n      client to be the server and appearing to the server\
    \ to be the\n      client. (See: SOCKS.)\n      Tutorial: In a firewall, a proxy\
    \ server usually runs on a bastion\n      host, which may support proxies for\
    \ several applications and\n      protocols (e.g., FTP, HTTP, and TELNET). Instead\
    \ of a client in\n      the protected enclave connecting directly to an external\
    \ server,\n      the internal client connects to the proxy server, which in turn\n\
    \      connects to the external server. The proxy server waits for a\n      request\
    \ from inside the firewall, forwards the request to the\n      server outside\
    \ the firewall, gets the response, then sends the\n      response back to the\
    \ client. The proxy may be transparent to the\n      clients, or they may need\
    \ to connect first to the proxy server,\n      and then use that association to\
    \ also initiate a connection to the\n      real server.\n      Proxies are generally\
    \ preferred over SOCKS for their ability to\n      perform caching, high-level\
    \ logging, and access control. A proxy\n      can provide security service beyond\
    \ that which is normally part of\n      the relayed protocol, such as access control\
    \ based on peer entity\n      authentication of clients, or peer entity authentication\
    \ of\n      servers when clients do not have that ability. A proxy at OSIRM\n\
    \      Layer 7 can also provide finer-grained security service than can a\n  \
    \    filtering router at Layer 3. For example, an FTP proxy could\n      permit\
    \ transfers out of, but not into, a protected network.\n   $ proxy certificate\n\
    \      (I) An X.509 public-key certificate derived from an end-entity\n      certificate,\
    \ or from another proxy certificate, for the purpose of\n      establishing proxies\
    \ and delegating authorizations in the context\n      of a PKI-based authentication\
    \ system. [R3820]\n      Tutorial: A proxy certificate has the following properties:\n\
    \      -  It contains a critical extension that (a) identifies it as a\n     \
    \    proxy certificate and (b) may contain a certification path\n         length\
    \ constraint and policy constraints.\n      -  It contains the public component\
    \ of a key pair that is distinct\n         from that associated with any other\
    \ certificate.\n      -  It is signed by the private component of a key pair that\
    \ is\n         associated with an end-entity certificate or another proxy\n  \
    \       certificate.\n      -  Its associated private key can be used to sign\
    \ only other proxy\n         certificates (not end-entity certificates).\n   \
    \   -  Its \"subject\" DN is derived from its \"issuer\" DN and is unique.\n \
    \     -  Its \"issuer\" DN is the \"subject\" DN of an end-entity\n         certificate\
    \ or another proxy certificate.\n   $ pseudorandom\n      (I) A sequence of values\
    \ that appears to be random (i.e.,\n      unpredictable) but is actually generated\
    \ by a deterministic\n      algorithm. (See: compression, random, random number\
    \ generator.)\n   $ pseudorandom number generator\n      (I) See: secondary definition\
    \ under \"random number generator\".\n   $ public component\n      (I) Synonym\
    \ for \"public key\".\n      Deprecated Usage: In most cases, IDOCs SHOULD NOT\
    \ use this term;\n      to avoid confusing readers, use \"private key\" instead.\
    \ However,\n      the term MAY be used when discussing a key pair; e.g., \"A key\
    \ pair\n      has a public component and a private component.\"\n   $ public key\n\
    \      1. (I) The publicly disclosable component of a pair of\n      cryptographic\
    \ keys used for asymmetric cryptography. (See: key\n      pair. Compare: private\
    \ key.)\n      2. (O) In a public key cryptosystem, \"that key of a user's key\n\
    \      pair which is publicly known.\" [X509]\n   $ public-key certificate\n \
    \     1. (I) A digital certificate that binds a system entity's\n      identifier\
    \ to a public key value, and possibly to additional,\n      secondary data items;\
    \ i.e., a digitally signed data structure that\n      attests to the ownership\
    \ of a public key. (See: X.509 public-key\n      certificate.)\n      2. (O) \"\
    The public key of a user, together with some other\n      information, rendered\
    \ unforgeable by encipherment with the private\n      key of the certification\
    \ authority which issued it.\" [X509]\n      Tutorial: The digital signature on\
    \ a public-key certificate is\n      unforgeable. Thus, the certificate can be\
    \ published, such as by\n      posting it in a directory, without the directory\
    \ having to protect\n      the certificate's data integrity.\n   $ public-key\
    \ cryptography\n      (I) Synonym for \"asymmetric cryptography\".\n   $ Public-Key\
    \ Cryptography Standards (PKCS)\n      (N) A series of specifications published\
    \ by RSA Laboratories for\n      data structures and algorithms used in basic\
    \ applications of\n      asymmetric cryptography. [PKCS] (See: PKCS #5 through\
    \ PKCS #11.)\n      Tutorial: The PKCS were begun in 1991 in cooperation with\
    \ industry\n      and academia, originally including Apple, Digital, Lotus,\n\
    \      Microsoft, Northern Telecom, Sun, and MIT. Today, the\n      specifications\
    \ are widely used, but they are not sanctioned by an\n      official standards\
    \ organization, such as ANSI, ITU-T, or IETF. RSA\n      Laboratories retains\
    \ sole decision-making authority over the PKCS.\n   $ public-key forward secrecy\
    \ (PFS)\n      (I) For a key-agreement protocol based on asymmetric cryptography,\n\
    \      the property that ensures that a session key derived from a set of\n  \
    \    long-term public and private keys will not be compromised if one\n      of\
    \ the private keys is compromised in the future. (See: Usage note\n      and other\
    \ discussion under \"perfect forward secrecy\".)\n   $ public-key Kerberos\n \
    \     (I) See: Tutorial under \"Kerberos\", PKINIT.\n   $ public-key infrastructure\
    \ (PKI)\n      1. (I) A system of CAs (and, optionally, RAs and other supporting\n\
    \      servers and agents) that perform some set of certificate\n      management,\
    \ archive management, key management, and token\n      management functions for\
    \ a community of users in an application of\n      asymmetric cryptography. (See:\
    \ hierarchical PKI, mesh PKI,\n      security management infrastructure, trust-file\
    \ PKI.)\n      2. (I) /PKIX/ The set of hardware, software, people, policies,\
    \ and\n      procedures needed to create, manage, store, distribute, and revoke\n\
    \      digital certificates based on asymmetric cryptography.\n      Tutorial:\
    \ The core PKI functions are (a) to register users and\n      issue their public-key\
    \ certificates, (b) to revoke certificates\n      when required, and (c) to archive\
    \ data needed to validate\n      certificates at a much later time. Key pairs\
    \ for data\n      confidentiality may be generated (and perhaps escrowed) by CAs\
    \ or\n      RAs, but requiring a PKI client to generate its own digital\n    \
    \  signature key pair helps maintain system integrity of the\n      cryptographic\
    \ system, because then only the client ever possesses\n      the private key it\
    \ uses. Also, an authority may be established to\n      approve or coordinate\
    \ CPSs, which are security policies under\n      which components of a PKI operate.\n\
    \      A number of other servers and agents may support the core PKI, and\n  \
    \    PKI clients may obtain services from them, such as certificate\n      validation\
    \ services. The full range of such services is not yet\n      fully understood\
    \ and is evolving, but supporting roles may include\n      archive agent, certified\
    \ delivery agent, confirmation agent,\n      digital notary, directory, key escrow\
    \ agent, key generation agent,\n      naming agent who ensures that issuers and\
    \ subjects have unique\n      identifiers within the PKI, repository, ticket-granting\
    \ agent,\n      time-stamp agent, and validation agent.\n   $ purge\n      1.\
    \ (I) Synonym for \"erase\".\n      2. (O) /U.S. Government/ Use degaussing or\
    \ other methods to render\n      magnetically stored data unusable and irrecoverable\
    \ by any means,\n      including laboratory methods. [C4009] (Compare: /U.S. Government/\n\
    \      erase.)\n   $ QUADRANT\n      (O) /U.S. Government/ Short name for technology\
    \ and methods that\n      protect cryptographic equipment by making the equipment\
    \ tamper-\n      resistant. [C4009] (Compare: protective packaging, TEMPEST.)\n\
    \      Tutorial: Equipment cannot be made completely tamper-proof, but it\n  \
    \    can be made tamper-resistant or tamper-evident.\n   $ qualified certificate\n\
    \      (I) A public-key certificate that has the primary purpose of\n      identifying\
    \ a person with a high level of assurance, where the\n      certificate meets\
    \ some qualification requirements defined by an\n      applicable legal framework,\
    \ such as the European Directive on\n      Electronic Signature. [R3739]\n   $\
    \ quick mode\n      (I) See: /IKE/ under \"mode\".\n   $ RA\n      (I) See: registration\
    \ authority.\n   $ RA domains\n      (I) A feature of a CAW that allows a CA to\
    \ divide the\n      responsibility for certificate requests among multiple RAs.\n\
    \      Tutorial: This ability might be used to restrict access to private\n  \
    \    authorization data that is provided with a certificate request,\n      and\
    \ to distribute the responsibility to review and approve\n      certificate requests\
    \ in high-volume environments. RA domains might\n      segregate certificate requests\
    \ according to an attribute of the\n      certificate's subject, such as an organizational\
    \ unit.\n   $ RADIUS\n      (I) See: Remote Authentication Dial-In User Service.\n\
    \   $ Rainbow Series\n      (O) /COMPUSEC/ A set of more than 30 technical and\
    \ policy\n      documents with colored covers, issued by the NCSC, that discuss\
    \ in\n      detail the TCSEC and provide guidance for meeting and applying the\n\
    \      criteria. (See: Green Book, Orange Book, Red Book, Yellow Book.)\n   $\
    \ random\n      (I) In essence, \"random\" means \"unpredictable\". [SP22, Knut,\n\
    \      R4086] (See: cryptographic key, pseudorandom.)\n      -  \"Random sequence\"\
    : A sequence in which each successive value is\n         obtained merely by chance\
    \ and does not depend on the preceding\n         values of the sequence. In a\
    \ random sequence of bits, each bit\n         is unpredictable; i.e., (a) the\
    \ probability of each bit being a\n         \"0\" or \"1\" is 1/2, and (b) the\
    \ value of each bit is independent\n         of any other bit in the sequence.\n\
    \      -  \"Random value\": An individual value that is unpredictable;\n     \
    \    i.e., each value in the total population of possibilities has\n         equal\
    \ probability of being selected.\n   $ random number generator\n      (I) A process\
    \ that is invoked to generate a random sequence of\n      values (usually a sequence\
    \ of bits) or an individual random value.\n      Tutorial: There are two basic\
    \ types of generators. [SP22]\n      -  \"(True) random number generator\": It\
    \ uses one or more non-\n         deterministic bit sources (e.g., electrical\
    \ circuit noise,\n         timing of human processes such as key strokes or mouse\n\
    \         movements, semiconductor quantum effects, and other physical\n     \
    \    phenomena) and a processing function that formats the bits, and\n       \
    \  it outputs a sequence of values that is unpredictable and\n         uniformly\
    \ distributed.\n      -  \"Pseudorandom number generator\": It uses a deterministic\n\
    \         computational process (usually implemented by software) that\n     \
    \    has one or more inputs called \"seeds\", and it outputs a\n         sequence\
    \ of values that appears to be random according to\n         specified statistical\
    \ tests.\n   $ RBAC\n      (N) See: role-based access control, rule-based access\
    \ control.\n      Deprecated Usage: IDOCs that use this term SHOULD state a\n\
    \      definition for it because the abbreviation is ambiguous.\n   $ RC2, RC4,\
    \ RC6\n      (N) See: Rivest Cipher #2, #4, #6.\n   $ read\n      (I) /security\
    \ model/ A system operation that causes a flow of\n      information from an object\
    \ to a subject. (See: access mode.\n      Compare: write.)\n   $ realm\n     \
    \ (I) /Kerberos/ A domain consisting of a set of Kerberized clients,\n      Kerberized\
    \ application servers, and one or more Kerberos\n      authentication servers\
    \ and ticket-granting servers that support\n      the clients and applications,\
    \ all operating under the same\n      security policy. (See: domain.)\n   $ recovery\n\
    \      1. (I) /cryptography/ The process of learning or obtaining\n      cryptographic\
    \ data or plain text through cryptanalysis. (See: key\n      recovery, data recovery.)\n\
    \      2a. (I) /system integrity/ The process of restoring a secure state\n  \
    \    in a system after there has been an accidental failure or a\n      successful\
    \ attack. (See: secondary definition under \"security\",\n      system integrity.)\n\
    \      2b. (I) /system integrity/ The process of restoring an information\n  \
    \    system's assets and operation following damage or destruction.\n      (See:\
    \ contingency plan.)\n   $ RED\n      1. (N) Designation for data that consists\
    \ only of clear text, and\n      for information system equipment items and facilities\
    \ that handle\n      clear text. Example: \"RED key\". (See: BCR, color change,\
    \ RED/BLACK\n      separation. Compare: BLACK.)\n      Derivation: From the practice\
    \ of marking equipment with colors to\n      prevent operational errors.\n   \
    \   2. (O) /U.S. Government/ Designation applied to information\n      systems,\
    \ and to associated areas, circuits, components, and\n      equipment, \"in which\
    \ unencrypted national security information is\n      being processed.\" [C4009]\n\
    \   $ RED/BLACK separation\n      (N) An architectural concept for cryptographic\
    \ systems that\n      strictly separates the parts of a system that handle plain\
    \ text\n      (i.e., RED information) from the parts that handle cipher text\n\
    \      (i.e., BLACK information). (See: BLACK, RED.)\n   $ Red Book\n      (D)\
    \ /slang/ Synonym for \"Trusted Network Interpretation of the\n      Trusted Computer\
    \ System Evaluation Criteria\" [NCS05].\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use this term. Instead, use the\n      full proper name of the document or,\
    \ in subsequent references, a\n      more conventional abbreviation, e.g., TNI-TCSEC.\
    \ (See: TCSEC,\n      Rainbow Series, Deprecated Usage under \"Green Book\".)\n\
    \   $ RED key\n      (N) A cleartext key, which is usable in its present form\
    \ (i.e., it\n      does not need to be decrypted before being used). (See: RED.\n\
    \      Compare: BLACK key.)\n   $ reference monitor\n      (I) \"An access control\
    \ concept that refers to an abstract machine\n      that mediates all accesses\
    \ to objects by subjects.\" [NCS04] (See:\n      security kernel.)\n      Tutorial:\
    \ This concept was described in the Anderson report. A\n      reference monitor\
    \ should be (a) complete (i.e., it mediates every\n      access), (b) isolated\
    \ (i.e., it cannot be modified by other system\n      entities), and (c) verifiable\
    \ (i.e., small enough to be subjected\n      to analysis and tests to ensure that\
    \ it is correct).\n   $ reflection attack\n      (I) An attack in which a valid\
    \ data transmission is replayed to\n      the originator by an attacker who intercepts\
    \ the original\n      transmission. (Compare: indirect attack, replay attack.)\n\
    \   $ reflector attack\n      (D) Synonym for \"indirect attack\".\n      Deprecated\
    \ Term: IDOCs SHOULD NOT use this term; it could be\n      confused with \"reflection\
    \ attack\", which is a different concept.\n   $ registered user\n      (I) A system\
    \ entity that is authorized to receive a system's\n      products and services\
    \ or otherwise access system resources. (See:\n      registration, user.)\n  \
    \ $ registration\n      1. (I) /information system/ A system process that (a)\
    \ initializes\n      an identity (of a system entity) in the system, (b) establishes\
    \ an\n      identifier for that identity, (c) may associate authentication\n \
    \     information with that identifier, and (d) may issue an identifier\n    \
    \  credential (depending on the type of authentication mechanism\n      being\
    \ used). (See: authentication information, credential,\n      identifier, identity,\
    \ identity proofing.)\n      2. (I) /PKI/ An administrative act or process whereby\
    \ an entity's\n      name and other attributes are established for the first time\
    \ at a\n      CA, prior to the CA issuing a digital certificate that has the\n\
    \      entity's name as the subject. (See: registration authority.)\n      Tutorial:\
    \ Registration may be accomplished either directly, by the\n      CA, or indirectly,\
    \ by a separate RA. An entity is presented to the\n      CA or RA, and the authority\
    \ either records the name(s) claimed for\n      the entity or assigns the entity's\
    \ name(s). The authority also\n      determines and records other attributes of\
    \ the entity that are to\n      be bound in a certificate (such as a public key\
    \ or authorizations)\n      or maintained in the authority's database (such as\
    \ street address\n      and telephone number). The authority is responsible, possibly\n\
    \      assisted by an RA, for verifying the entity's identity and vetting\n  \
    \    the other attributes, in accordance with the CA's CPS.\n      Among the registration\
    \ issues that a CPS may address are the\n      following [R3647]:\n      -  How\
    \ a claimed identity and other attributes are verified.\n      -  How organization\
    \ affiliation or representation is verified.\n      -  What forms of names are\
    \ permitted, such as X.500 DN, domain\n         name, or IP address.\n      -\
    \  Whether names are required to be meaningful or unique, and\n         within\
    \ what domain.\n      -  How naming disputes are resolved, including the role\
    \ of\n         trademarks.\n      -  Whether certificates are issued to entities\
    \ that are not\n         persons.\n      -  Whether a person is required to appear\
    \ before the CA or RA, or\n         can instead be represented by an agent.\n\
    \      -  Whether and how an entity proves possession of the private key\n   \
    \      matching a public key.\n   $ registration authority (RA)\n      1. (I)\
    \ An optional PKI entity (separate from the CAs) that does\n      not sign either\
    \ digital certificates or CRLs but has\n      responsibility for recording or\
    \ verifying some or all of the\n      information (particularly the identities\
    \ of subjects) needed by a\n      CA to issue certificates and CRLs and to perform\
    \ other certificate\n      management functions. (See: ORA, registration.)\n \
    \     2. (I) /PKIX/ An optional PKI component, separate from the CA(s).\n    \
    \  The functions that the RA performs will vary from case to case but\n      may\
    \ include identity authentication and name assignment, key\n      generation and\
    \ archiving of key pairs, token distribution, and\n      revocation reporting.\
    \ [R4210]\n      Tutorial: Sometimes, a CA may perform all certificate management\n\
    \      functions for all end users for which the CA signs certificates.\n    \
    \  Other times, such as in a large or geographically dispersed\n      community,\
    \ it may be necessary or desirable to offload secondary\n      CA functions and\
    \ delegate them to an assistant, while the CA\n      retains the primary functions\
    \ (signing certificates and CRLs). The\n      tasks that are delegated to an RA\
    \ by a CA may include personal\n      authentication, name assignment, token distribution,\
    \ revocation\n      reporting, key generation, and archiving.\n      An RA is\
    \ an optional PKI entity, separate from the CA, that is\n      assigned secondary\
    \ functions. The duties assigned to RAs vary from\n      case to case but may\
    \ include the following:\n      -  Verifying a subject's identity, i.e., performing\
    \ personal\n         authentication functions.\n      -  Assigning a name to a\
    \ subject. (See: distinguished name.)\n      -  Verifying that a subject is entitled\
    \ to have the attributes\n         requested for a certificate.\n      -  Verifying\
    \ that a subject possesses the private key that matches\n         the public key\
    \ requested for a certificate.\n      -  Performing functions beyond mere registration,\
    \ such as\n         generating key pairs, distributing tokens, handling revocation\n\
    \         reports, and archiving data. (Such functions may be assigned to\n  \
    \       a PKI component that is separate from both the CA and the RA.)\n     \
    \ 3. (O) /SET/ \"An independent third-party organization that\n      processes\
    \ payment card applications for multiple payment card\n      brands and forwards\
    \ applications to the appropriate financial\n      institutions.\" [SET2]\n  \
    \ $ regrade\n      (I) Deliberately change the security level (especially the\n\
    \      hierarchical classification level) of information in an authorized\n  \
    \    manner. (See: downgrade, upgrade.)\n   $ rekey\n      (I) Change the value\
    \ of a cryptographic key that is being used in\n      an application of a cryptographic\
    \ system. (See: certificate\n      rekey.)\n      Tutorial: Rekey is required\
    \ at the end of a cryptoperiod or key\n      lifetime.\n   $ reliability\n   \
    \   (I) The ability of a system to perform a required function under\n      stated\
    \ conditions for a specified period of time. (Compare:\n      availability, survivability.)\n\
    \   $ reliable human review\n      (I) Any manual, automated, or hybrid process\
    \ or procedure that\n      ensures that a human examines a digital object, such\
    \ as text or an\n      image, to determine whether the object may be permitted,\
    \ according\n      to some security policy, to be transferred across a controlled\n\
    \      interface. (See: guard.)\n   $ relying party\n      (I) Synonym for \"\
    certificate user\".\n      Usage: Used in a legal context to mean a recipient\
    \ of a\n      certificate who acts in reliance on that certificate. (See: ABA\n\
    \      Guidelines.)\n   $ remanence\n      (I) Residual information that can be\
    \ recovered from a storage\n      medium after clearing. (See: clear, magnetic\
    \ remanence, purge.)\n   $ Remote Authentication Dial-In User Service (RADIUS)\n\
    \      (I) An Internet protocol [R2865] for carrying dial-in users'\n      authentication\
    \ information and configuration information between a\n      shared, centralized\
    \ authentication server (the RADIUS server) and\n      a network access server\
    \ (the RADIUS client) that needs to\n      authenticate the users of its network\
    \ access ports. (See: TACACS.)\n      User presents authentication and possibly\
    \ other information to the\n      RADIUS client (e.g., health information regarding\
    \ the user\n      device).\n      Tutorial: A user presents authentication information\
    \ and possibly\n      other information to the RADIUS client, and the client passes\
    \ that\n      information to the RADIUS server. The server authenticates the\n\
    \      client using a shared secret value and checks the presented\n      information,\
    \ and then returns to the client all authorization and\n      configuration information\
    \ needed by the client to serve the user.\n   $ renew\n      See: certificate\
    \ renewal.\n   $ reordering\n      (I) /packet/ See: secondary definition under\
    \ \"stream integrity\n      service\".\n   $ replay attack\n      (I) An attack\
    \ in which a valid data transmission is maliciously or\n      fraudulently repeated,\
    \ either by the originator or by a third\n      party who intercepts the data\
    \ and retransmits it, possibly as part\n      of a masquerade attack. (See: active\
    \ wiretapping, fresh, liveness,\n      nonce. Compare: indirect attack, reflection\
    \ attack.)\n   $ repository\n      1. (I) A system for storing and distributing\
    \ digital certificates\n      and related information (including CRLs, CPSs, and\
    \ certificate\n      policies) to certificate users. (Compare: archive, directory.)\n\
    \      2. (O) \"A trustworthy system for storing and retrieving\n      certificates\
    \ or other information relevant to certificates.\" [DSG]\n      Tutorial: A certificate\
    \ is published to those who might need it by\n      putting it in a repository.\
    \ The repository usually is a publicly\n      accessible, on-line server. In the\
    \ FPKI, for example, the expected\n      repository is a directory that uses LDAP,\
    \ but also may be an X.500\n      Directory that uses DAP, or an HTTP server,\
    \ or an FTP server that\n      permits anonymous login.\n   $ repudiation\n  \
    \    1. (I) Denial by a system entity that was involved in an\n      association\
    \ (especially a communication association that transfers\n      data) of having\
    \ participated in the relationship. (See:\n      accountability, non-repudiation\
    \ service.)\n      2. (I) A type of threat action whereby an entity deceives another\n\
    \      by falsely denying responsibility for an act. (See: deception.)\n     \
    \ Usage: This type of threat action includes the following subtypes:\n      -\
    \  False denial of origin: Action whereby an originator denies\n         responsibility\
    \ for sending data.\n      -  False denial of receipt: Action whereby a recipient\
    \ denies\n         receiving and possessing data.\n      3. (O) /OSIRM/ \"Denial\
    \ by one of the entities involved in a\n      communication of having participated\
    \ in all or part of the\n      communication.\" [I7498-2]\n   $ Request for Comment\
    \ (RFC)\n      1. (I) One of the documents in the archival series that is the\n\
    \      official channel for IDOCs and other publications of the Internet\n   \
    \   Engineering Steering Group, the Internet Architecture Board, and\n      the\
    \ Internet community in general. (RFC 2026, 2223) (See: Internet\n      Standard.)\n\
    \      2. (D) A popularly misused synonym for a document on the Internet\n   \
    \   Standards Track, i.e., an Internet Standard, Draft Standard, or\n      Proposed\
    \ Standard. (See: Internet Standard.)\n      Deprecated Definition: IDOCs SHOULD\
    \ NOT use this term with\n      definition 2 because many other types of documents\
    \ also are\n      published as RFCs.\n   $ residual risk\n      (I) The portion\
    \ of an original risk or set of risks that remains\n      after countermeasures\
    \ have been applied. (Compare: acceptable\n      risk, risk analysis.)\n   $ restore\n\
    \      See: card restore.\n   $ reverse engineering\n      (I) /threat action/\
    \ See: secondary definition under \"intrusion\".\n   $ revocation\n      See:\
    \ certificate revocation.\n   $ revocation date\n      (N) /X.509/ In a CRL entry,\
    \ a date-time field that states when the\n      certificate revocation occurred,\
    \ i.e., when the CA declared the\n      digital certificate to be invalid. (See:\
    \ invalidity date.)\n      Tutorial: The revocation date may not resolve some\
    \ disputes\n      because, in the worst case, all signatures made during the\n\
    \      validity period of the certificate may have to be considered\n      invalid.\
    \ However, it may be desirable to treat a digital signature\n      as valid even\
    \ though the private key used to sign was compromised\n      after the signing.\
    \ If more is known about when the compromise\n      actually occurred, a second\
    \ date-time, an \"invalidity date\", can\n      be included in an extension of\
    \ the CRL entry.\n   $ revocation list\n      See: certificate revocation list.\n\
    \   $ revoke\n      (I) See: certificate revocation.\n   $ RFC\n      (I) See:\
    \ Request for Comment.\n   $ Rijndael\n      (N) A symmetric, block cipher that\
    \ was designed by Joan Daemen and\n      Vincent Rijmen as a candidate for the\
    \ AES, and that won that\n      competition. [Daem] (See: Advanced Encryption\
    \ Standard.)\n   $ risk\n      1. (I) An expectation of loss expressed as the\
    \ probability that a\n      particular threat will exploit a particular vulnerability\
    \ with a\n      particular harmful result. (See: residual risk.)\n      2. (O)\
    \ /SET/ \"The possibility of loss because of one or more\n      threats to information\
    \ (not to be confused with financial or\n      business risk).\" [SET2]\n    \
    \  Tutorial: There are four basic ways to deal with a risk [SP30]:\n      -  \"\
    Risk avoidance\": Eliminate the risk by either countering the\n         threat\
    \ or removing the vulnerability. (Compare: \"avoidance\"\n         under \"security\"\
    .)\n      -  \"Risk transference\": Shift the risk to another system or\n    \
    \     entity; e.g., buy insurance to compensate for potential loss.\n      - \
    \ \"Risk limitation\": Limit the risk by implementing controls that\n        \
    \ minimize resulting loss.\n      -  \"Risk assumption\": Accept the potential\
    \ for loss and continue\n         operating the system.\n   $ risk analysis\n\
    \      (I) An assessment process that systematically (a) identifies\n      valuable\
    \ system resources and threats to those resources, (b)\n      quantifies loss\
    \ exposures (i.e., loss potential) based on\n      estimated frequencies and costs\
    \ of occurrence, and (c)\n      (optionally) recommends how to allocate available\
    \ resources to\n      countermeasures so as to minimize total exposure. (See:\
    \ risk\n      management, business-case analysis. Compare: threat analysis.)\n\
    \      Tutorial: Usually, it is financially and technically infeasible to\n  \
    \    avoid or transfer all risks (see: \"first corollary\" of \"second\n     \
    \ law\" under \"Courtney's laws\"), and some residual risks will\n      remain,\
    \ even after all available countermeasures have been\n      deployed (see: \"\
    second corollary\" of \"second law\" under\n      \"Courtney's laws\"). Thus,\
    \ a risk analysis typically lists risks in\n      order of cost and criticality,\
    \ thereby determining where\n      countermeasures should be applied first. [FP031,\
    \ R2196]\n      In some contexts, it is infeasible or inadvisable to attempt a\n\
    \      complete or quantitative risk analysis because needed data, time,\n   \
    \   and expertise are not available. Instead, basic answers to\n      questions\
    \ about threats and risks may be already built into\n      institutional security\
    \ policies. For example, U.S. DoD policies\n      for data confidentiality \"\
    do not explicitly itemize the range of\n      expected threats\" but instead \"\
    reflect an operational approach ...\n      by stating the particular management\
    \ controls that must be used to\n      achieve [confidentiality] ... Thus, they\
    \ avoid listing threats,\n      which would represent a severe risk in itself,\
    \ and avoid the risk\n      of poor security design implicit in taking a fresh\
    \ approach to\n      each new problem\". [NRC91]\n   $ risk assumption\n     \
    \ (I) See: secondary definition under \"risk\".\n   $ risk avoidance\n      (I)\
    \ See: secondary definition under \"risk\".\n   $ risk limitation\n      (I) See:\
    \ secondary definition under \"risk\".\n   $ risk management\n      1. (I) The\
    \ process of identifying, measuring, and controlling\n      (i.e., mitigating)\
    \ risks in information systems so as to reduce\n      the risks to a level commensurate\
    \ with the value of the assets\n      protected. (See: risk analysis.)\n     \
    \ 2. (I) The process of controlling uncertain events that may affect\n      information\
    \ system resources.\n      3. (O) \"The total process of identifying, controlling,\
    \ and\n      mitigating information system-related risks. It includes risk\n \
    \     assessment; cost-benefit analysis; and the selection,\n      implementation,\
    \ test, and security evaluation of safeguards. This\n      overall system security\
    \ review considers both effectiveness and\n      efficiency, including impact\
    \ on the mission and constraints due to\n      policy, regulations, and laws.\"\
    \ [SP30]\n   $ risk transference\n      (I) See: secondary definition under \"\
    risk\".\n   $ Rivest Cipher #2 (RC2)\n      (N) A proprietary, variable-key-length\
    \ block cipher invented by\n      Ron Rivest for RSA Data Security, Inc.\n   $\
    \ Rivest Cipher #4 (RC4)\n      (N) A proprietary, variable-key-length stream\
    \ cipher invented by\n      Ron Rivest for RSA Data Security, Inc.\n   $ Rivest\
    \ Cipher #6 (RC6)\n      (N) A symmetric, block cipher with 128-bit or longer\
    \ key length,\n      developed by Ron Rivest for RSA Data Security, Inc. as a\
    \ candidate\n      for the AES.\n   $ Rivest-Shamir-Adleman (RSA)\n      (N) An\
    \ algorithm for asymmetric cryptography, invented in 1977 by\n      Ron Rivest,\
    \ Adi Shamir, and Leonard Adleman [RSA78].\n      Tutorial: RSA uses exponentiation\
    \ modulo the product of two large\n      prime numbers. The difficulty of breaking\
    \ RSA is believed to be\n      equivalent to the difficulty of factoring integers\
    \ that are the\n      product of two large prime numbers of approximately equal\
    \ size.\n      To create an RSA key pair, randomly choose two large prime\n  \
    \    numbers, p and q, and compute the modulus, n = pq. Randomly choose\n    \
    \  a number e, the public exponent, that is less than n and\n      relatively\
    \ prime to (p-1)(q-1). Choose another number d, the\n      private exponent, such\
    \ that ed-1 evenly divides (p-1)(q-1). The\n      public key is the set of numbers\
    \ (n,e), and the private key is the\n      set (n,d).\n      It is assumed to\
    \ be difficult to compute the private key (n,d)\n      from the public key (n,e).\
    \ However, if n can be factored into p\n      and q, then the private key d can\
    \ be computed easily. Thus, RSA\n      security depends on the assumption that\
    \ it is computationally\n      difficult to factor a number that is the product\
    \ of two large\n      prime numbers. (Of course, p and q are treated as part of\
    \ the\n      private key, or else are destroyed after computing n.)\n      For\
    \ encryption of a message, m, to be sent to Bob, Alice uses\n      Bob's public\
    \ key (n,e) to compute m**e (mod n) = c. She sends c to\n      Bob. Bob computes\
    \ c**d (mod n) = m. Only Bob knows d, so only Bob\n      can compute c**d (mod\
    \ n) to recover m.\n      To provide data origin authentication of a message,\
    \ m, to be sent\n      to Bob, Alice computes m**d (mod n) = s, where (d,n) is\
    \ Alice's\n      private key. She sends m and s to Bob. To recover the message\
    \ that\n      only Alice could have sent, Bob computes s**e (mod n) = m, where\n\
    \      (e,n) is Alice's public key.\n      To ensure data integrity in addition\
    \ to data origin authentication\n      requires extra computation steps in which\
    \ Alice and Bob use a\n      cryptographic hash function h (see: digital signature).\
    \ Alice\n      computes the hash value h(m) = v, and then encrypts v with her\n\
    \      private key to get s. She sends m and s. Bob receives m' and s',\n    \
    \  either of which might have been changed from the m and s that\n      Alice\
    \ sent. To test this, he decrypts s' with Alice's public key\n      to get v'.\
    \ He then computes h(m') = v\". If v' equals v\", Bob is\n      assured that m'\
    \ is the same m that Alice sent.\n   $ robustness\n      (N) See: level of robustness.\n\
    \   $ role\n      1. (I) A job function or employment position to which people\
    \ or\n      other system entities may be assigned in a system. (See: role-\n \
    \     based access control. Compare: duty, billet, principal, user.)\n      2.\
    \ (O) /Common Criteria/ A pre-defined set of rules establishing\n      the allowed\
    \ interactions between a user and the TOE.\n   $ role-based access control\n \
    \     (I) A form of identity-based access control wherein the system\n      entities\
    \ that are identified and controlled are functional\n      positions in an organization\
    \ or process. [Sand] (See:\n      authorization, constraint, identity, principal,\
    \ role.)\n      Tutorial: Administrators assign permissions to roles as needed\
    \ to\n      perform functions in the system. Administrators separately assign\n\
    \      user identities to roles. When a user accesses the system in an\n     \
    \ identity (for which the user has been registered) and initiates a\n      session\
    \ using a role (to which the user has been assigned), then\n      the permissions\
    \ that have been assigned to the role are available\n      to be exercised by\
    \ the user.\n      The following diagram shows that role-based access control\n\
    \      involves five different relationships: (a) administrators assign\n    \
    \  identities to roles, (b) administrators assign permissions to\n      roles,\
    \ (c) administrators assign roles to roles, (d) users select\n      identities\
    \ in sessions, and (e) users select roles in sessions.\n      Security policies\
    \ may define constraints on these assignments and\n      selections.\n       \
    \  (c) Permission Inheritance Assignments (i.e., Role Hierarchy)\n           \
    \                    [Constraints]\n                                  +=====+\n\
    \                                  |     |\n                   (a) Identity  \
    \ v     v  (b) Permission\n      +----------+  Assignments  +-------+  Assignments\
    \  +----------+\n      |Identities|<=============>| Roles |<=============>|Permissions|\n\
    \      +----------+ [Constraints] +-------+ [Constraints] +----------+\n     \
    \      |   |                   ^   ^\n           |   |   +-----------+   |   |\
    \       +---------------------+\n           |   |   | +-------+ |   |   |    \
    \   |       Legend        |\n           |   +====>|Session|=====+   |       |\
    \                     |\n           |       | +-------+ |       |       |    \
    \ One-to-One      |\n           |       |    ...   |       |       | ===================\
    \ |\n           |       | +-------+ |       |       |                     |\n\
    \           +========>|Session|=========+       |     One-to-Many     |\n    \
    \  (d) Identity | +-------+ |  (e) Role     | ==================> |\n       Selections\
    \  |           | Selections    |                     |\n      [Constraints]| \
    \ Access   |[Constraints]  |    Many-to-Many     |\n                   | Sessions\
    \  |               | <=================> |\n                   +-----------+ \
    \              +---------------------+\n   $ role certificate\n      (I) An organizational\
    \ certificate that is issued to a system\n      entity that is a member of the\
    \ set of users that have identities\n      that are assigned to the same role.\
    \ (See: role-based access\n      control.)\n   $ root, root CA\n      1. (I) /PKI/\
    \ A CA that is directly trusted by an end entity. (See:\n      trust anchor, trusted\
    \ CA.)\n      2. (I) /hierarchical PKI/ The CA that is the highest level (most\n\
    \      trusted) CA in a certification hierarchy; i.e., the authority upon\n  \
    \    whose public key all certificate users base their validation of\n      certificates,\
    \ CRLs, certification paths, and other constructs.\n      (See: top CA.)\n   \
    \   Tutorial: The root CA in a certification hierarchy issues public-\n      key\
    \ certificates to one or more additional CAs that form the\n      second-highest\
    \ level. Each of these CAs may issue certificates to\n      more CAs at the third-highest\
    \ level, and so on. To initialize\n      operation of a hierarchical PKI, the\
    \ root's initial public key is\n      securely distributed to all certificate\
    \ users in a way that does\n      not depend on the PKI's certification relationships,\
    \ i.e., by an\n      out-of-band procedure. The root's public key may be distributed\n\
    \      simply as a numerical value, but typically is distributed in a\n      self-signed\
    \ certificate in which the root is the subject. The\n      root's certificate\
    \ is signed by the root itself because there is\n      no higher authority in\
    \ a certification hierarchy. The root's\n      certificate is then the first certificate\
    \ in every certification\n      path.\n      3. (I) /DNS/ The base of the tree\
    \ structure that defines the name\n      space for the Internet DNS. (See: domain\
    \ name.)\n      4. (O) /MISSI/ A name previously used for a MISSI policy creation\n\
    \      authority, which is not a root as defined above for general usage,\n  \
    \    but is a CA at the second level of the MISSI hierarchy,\n      immediately\
    \ subordinate to a MISSI policy approving authority.\n      5. (O) /UNIX/ A user\
    \ account (a.k.a. \"superuser\") that has all\n      privileges (including all\
    \ security-related privileges) and thus\n      can manage the system and its other\
    \ user accounts.\n   $ root certificate\n      1. (I) /PKI/ A certificate for\
    \ which the subject is a root. (See:\n      trust anchor certificate, trusted\
    \ certificate.)\n      2. (I) /hierarchical PKI/ The self-signed public-key certificate\n\
    \      at the top of a certification hierarchy.\n   $ root key\n      (I) /PKI/\
    \ A public key for which the matching private key is held\n      by a root. (See:\
    \ trust anchor key, trusted key.)\n   $ root registry\n      (O) /MISSI/ A name\
    \ previously used for a MISSI PAA.\n   $ ROT13\n      (I) See: secondary definition\
    \ under \"Caesar cipher\".\n   $ router\n      1a. (I) /IP/ A networked computer\
    \ that forwards IP packets that\n      are not addressed to the computer itself.\
    \ (Compare: host.)\n      1b. (I) /IPS/ A gateway that operates in the IPS Internet\
    \ Layer to\n      connect two or more subnetworks.\n      1c. (N) /OSIRM/ A computer\
    \ that is a gateway between two networks\n      at OSIRM Layer 3 and that relays\
    \ and directs data packets through\n      that internetwork. (Compare: bridge,\
    \ proxy.)\n   $ RSA\n      (N) See: Rivest-Shamir-Adleman.\n   $ rule\n      See:\
    \ policy rule.\n   $ rule-based security policy\n      (I) \"A security policy\
    \ based on global rules [i.e., policy rules]\n      imposed for all users. These\
    \ rules usually rely on comparison of\n      the sensitivity of the resource being\
    \ accessed and the possession\n      of corresponding attributes of users, a group\
    \ of users, or\n      entities acting on behalf of users.\" [I7498-2] (Compare:\
    \ identity-\n      based security policy, policy rule, RBAC.)\n   $ rules of behavior\n\
    \      (I) A body of security policy that has been established and\n      implemented\
    \ concerning the responsibilities and expected behavior\n      of entities that\
    \ have access to a system. (Compare: [R1281].)\n      Tutorial: For persons employed\
    \ by a corporation or government, the\n      rules might cover such matters as\
    \ working at home, remote access,\n      use of the Internet, use of copyrighted\
    \ works, use of system\n      resources for unofficial purpose, assignment and\
    \ limitation of\n      system privileges, and individual accountability.\n   $\
    \ S field\n      (D) See: Security Level field.\n   $ S-BGP\n      (I) See: Secure\
    \ BGP.\n   $ S-HTTP\n      (I) See: Secure Hypertext Transfer Protocol.\n   $\
    \ S/Key\n      (I) A security mechanism that uses a cryptographic hash function\n\
    \      to generate a sequence of 64-bit, one-time passwords for remote\n     \
    \ user login. [R1760]\n      Tutorial: The client generates a one-time password\
    \ by applying the\n      MD4 cryptographic hash function multiple times to the\
    \ user's\n      secret key. For each successive authentication of the user, the\n\
    \      number of hash applications is reduced by one. (Thus, an intruder\n   \
    \   using wiretapping cannot compute a valid password from knowledge\n      of\
    \ one previously used.) The server verifies a password by hashing\n      the currently\
    \ presented password (or initialization value) one\n      time and comparing the\
    \ hash result with the previously presented\n      password.\n   $ S/MIME\n  \
    \    (I) See: Secure/MIME.\n   $ SAD\n      (I) See: Security Association Database.\n\
    \   $ safety\n      (I) The property of a system being free from risk of causing\
    \ harm\n      (especially physical harm) to its system entities. (Compare:\n \
    \     security.)\n   $ SAID\n      (I) See: security association identifier.\n\
    \   $ salami swindle\n      (D) /slang/ \"Slicing off a small amount from each\
    \ transaction.\n      This kind of theft was made worthwhile by automation. Given\
    \ a high\n      transaction flow, even rounding down to the nearest cent and\n\
    \      putting the 'extra' in a bogus account can be very profitable.\"\n    \
    \  [NCSSG]\n      Deprecated Term: It is likely that other cultures use different\n\
    \      metaphors for this concept. Therefore, to avoid international\n      misunderstanding,\
    \ IDOCs SHOULD NOT use this term. (See: Deprecated\n      Usage under \"Green\
    \ Book\".)\n   $ salt\n      (I) A data value used to vary the results of a computation\
    \ in a\n      security mechanism, so that an exposed computational result from\n\
    \      one instance of applying the mechanism cannot be reused by an\n      attacker\
    \ in another instance. (Compare: initialization value.)\n      Example: A password-based\
    \ access control mechanism might protect\n      against capture or accidental\
    \ disclosure of its password file by\n      applying a one-way encryption algorithm\
    \ to passwords before\n      storing them in the file. To increase the difficulty\
    \ of off-line,\n      dictionary attacks that match encrypted values of potential\n\
    \      passwords against a copy of the password file, the mechanism can\n    \
    \  concatenate each password with its own random salt value before\n      applying\
    \ the one-way function.\n   $ SAML\n      (N) See: Security Assertion Markup Language\
    \ (SAML).\n   $ sandbox\n      (I) A restricted, controlled execution environment\
    \ that prevents\n      potentially malicious software, such as mobile code, from\n\
    \      accessing any system resources except those for which the software\n  \
    \    is authorized.\n   $ sanitize\n      1. (I) Delete sensitive data from a\
    \ file, device, or system. (See:\n      erase, zeroize.)\n      2. (I) Modify\
    \ data so as to be able either (a) to completely\n      declassify it or (b) to\
    \ downgrade it to a lower security level.\n   $ SAP\n      (O) See: special access\
    \ program.\n   $ SASL\n      (I) See: Simple Authentication and Security Layer.\n\
    \   $ SCA\n      (I) See: subordinate certification authority.\n   $ scavenging\n\
    \      (I) /threat action/ See: secondary definition under \"exposure\".\n   $\
    \ SCI\n      (O) See: sensitive compartmented information.\n   $ SCIF\n      (O)\
    \ See: sensitive compartmented information facility.\n   $ SCOMP\n      (N) Secure\
    \ COMmunications Processor; an enhanced, MLS version of\n      the Honeywell Level\
    \ 6 minicomputer. It was the first system to be\n      rated in TCSEC Class A1.\
    \ (See: KSOS.)\n   $ screen room\n      (D) /slang/ Synonym for \"shielded enclosure\"\
    \ in the context of\n      electromagnetic emanations. (See: EMSEC, TEMPEST.)\n\
    \      Deprecated Term: To avoid international misunderstanding, IDOCs\n     \
    \ SHOULD NOT use this term.\n   $ screening router\n      (I) Synonym for \"filtering\
    \ router\".\n   $ script kiddy\n      (D) /slang/ A cracker who is able to use\
    \ existing attack\n      techniques (i.e., to read scripts) and execute existing\
    \ attack\n      software, but is unable to invent new exploits or manufacture\
    \ the\n      tools to perform them; pejoratively, an immature or novice\n    \
    \  cracker.\n      Deprecated Term: It is likely that other cultures use different\n\
    \      metaphors for this concept. Therefore, to avoid international\n      misunderstanding,\
    \ IDOCs SHOULD NOT use this term. (See: Deprecated\n      Usage under \"Green\
    \ Book\".)\n   $ SDE\n      (N) See: Secure Data Exchange.\n   $ SDNS\n      (O)\
    \ See: Secure Data Network System.\n   $ SDU\n      (N) See: \"service data unit\"\
    \ under \"protocol data unit\".\n   $ seal\n      1. (I) To use asymmetric cryptography\
    \ to encrypt plain text with a\n      public key in such a way that only the holder\
    \ of the matching\n      private key can learn what was the plain text. [Chau]\
    \ (Compare:\n      shroud, wrap.)\n      Deprecated Usage: An IDOC SHOULD NOT\
    \ use this term with definition\n      1 unless the IDOC includes the definition,\
    \ because the definition\n      is not widely known and the concept can be expressed\
    \ by using\n      other, standard terms. Instead, use \"salt and encrypt\" or\
    \ other\n      terminology that is specific with regard to the mechanism being\n\
    \      used.\n      Tutorial: The definition does *not* say \"only the holder\
    \ of the\n      matching private key can decrypt the ciphertext to learn what\
    \ was\n      the plaintext\"; sealing is stronger than that. If Alice simply\n\
    \      encrypts a plaintext P with a public key K to produce ciphertext C\n  \
    \    = K(P), then if Bob guesses that P = X, Bob could verify the guess\n    \
    \  by checking whether K(P) = K(X). To \"seal\" P and block Bob's\n      guessing\
    \ attack, Alice could attach a long string R of random bits\n      to P before\
    \ encrypting to produce C = K(P,R); if Bob guesses that\n      P = X, Bob can\
    \ only test the guess by also guessing R. (See:\n      salt.)\n      2. (D) To\
    \ use cryptography to provide data integrity service for a\n      data object.\
    \ (See: sign.)\n      Deprecated Definition: IDOCs SHOULD NOT use this term with\n\
    \      definition 2. Instead, use a term that is more specific with\n      regard\
    \ to the mechanism used to provide the data integrity\n      service; e.g., use\
    \ \"sign\" when the mechanism is digital signature.\n   $ secret\n      1a. (I)\
    \ /adjective/ The condition of information being protected\n      from being known\
    \ by any system entities except those that are\n      intended to know it. (See:\
    \ data confidentiality.)\n      1b. (I) /noun/ An item of information that is\
    \ protected thusly.\n      Usage: This term applies to symmetric keys, private\
    \ keys, and\n      passwords.\n   $ secret key\n      (D) A key that is kept secret\
    \ or needs to be kept secret.\n      Deprecated Term: IDOCs SHOULD NOT use this\
    \ term; it mixes concepts\n      in a potentially misleading way. In the context\
    \ of asymmetric\n      cryptography, IDOCs SHOULD use \"private key\". In the\
    \ context of\n      symmetric cryptography, the adjective \"secret\" is unnecessary\n\
    \      because all keys must be kept secret.\n   $ secret-key cryptography\n \
    \     (D) Synonym for \"symmetric cryptography\".\n      Deprecated Term: IDOCs\
    \ SHOULD NOT use this term; it could be\n      confused with \"asymmetric cryptography\"\
    , in which the private key\n      is kept secret.\n      Derivation: Symmetric\
    \ cryptography is sometimes called \"secret-key\n      cryptography\" because\
    \ entities that share the key, such as the\n      originator and the recipient\
    \ of a message, need to keep the key\n      secret from other entities.\n   $\
    \ Secure BGP (S-BGP)\n      (I) A project of BBN Technologies, sponsored by the\
    \ U.S. DoD's\n      Defense Advanced Research Projects Agency, to design and\n\
    \      demonstrate an architecture to secure the Border Gateway Protocol\n   \
    \   (RFC 1771) and to promote deployment of that architecture in the\n      Internet.\n\
    \      Tutorial: S-BGP incorporates three security mechanisms:\n      -  A PKI\
    \ supports authentication of ownership of IP address\n         blocks, autonomous\
    \ system (AS) numbers, an AS's identity, and a\n         BGP router's identity\
    \ and its authorization to represent an AS.\n         This PKI parallels and takes\
    \ advantage of the Internet's\n         existing IP address and AS number assignment\
    \ system.\n      -  A new, optional, BGP transitive path attribute carries digital\n\
    \         signatures (in \"attestations\") covering the routing information\n\
    \         in a BGP UPDATE. These signatures along with certificates from\n   \
    \      the S-BGP PKI enable the receiver of a BGP routing UPDATE to\n        \
    \ validate the attribute and gain trust in the address prefixes\n         and\
    \ path information that it contains.\n      -  IPsec provides data and partial\
    \ sequence integrity, and enables\n         BGP routers to authenticate each other\
    \ for exchanges of BGP\n         control traffic.\n   $ Secure Data Exchange (SDE)\n\
    \      (N) A LAN security protocol defined by the IEEE 802.10 standard.\n   $\
    \ Secure Data Network System (SDNS)\n      (O) An NSA program that developed security\
    \ protocols for\n      electronic mail (see: MSP), OSIRM Layer 3 (see: SP3), OSIRM\
    \ Layer\n      4 (see: SP4), and key establishment (see: KMP).\n   $ secure distribution\n\
    \      (I) See: trusted distribution.\n   $ Secure Hash Algorithm (SHA)\n    \
    \  (N) A cryptographic hash function (specified in SHS) that produces\n      an\
    \ output (see: \"hash result\") -- of selectable length of either\n      160,\
    \ 224, 256, 384, or 512 bits -- for input data of any length <\n      2**64 bits.\n\
    \   $ Secure Hash Standard (SHS)\n      (N) The U.S. Government standard [FP180]\
    \ that specifies SHA.\n   $ Secure Hypertext Transfer Protocol (S-HTTP)\n    \
    \  (I) An Internet protocol [R2660] for providing client-server\n      security\
    \ services for HTTP communications. (Compare: https.)\n      Tutorial: S-HTTP\
    \ was originally specified by CommerceNet, a\n      coalition of businesses interested\
    \ in developing the Internet for\n      commercial uses. Several message formats\
    \ may be incorporated into\n      S-HTTP clients and servers, particularly CMS\
    \ and MOSS. S-HTTP\n      supports choice of security policies, key management\
    \ mechanisms,\n      and cryptographic algorithms through option negotiation between\n\
    \      parties for each transaction. S-HTTP supports modes of operation\n    \
    \  for both asymmetric and symmetric cryptography. S-HTTP attempts to\n      avoid\
    \ presuming a particular trust model, but it attempts to\n      facilitate multiply\
    \ rooted, hierarchical trust and anticipates\n      that principals may have many\
    \ public-key certificates.\n   $ Secure/MIME (S/MIME)\n      (I) Secure/Multipurpose\
    \ Internet Mail Extensions, an Internet\n      protocol [R3851] to provide encryption\
    \ and digital signatures for\n      Internet mail messages.\n   $ secure multicast\n\
    \      (I) Refers generally to providing security services for multicast\n   \
    \   groups of various types (e.g., 1-to-N and M-to-N) and to classes\n      of\
    \ protocols used to protect multicast packets.\n      Tutorial: Multicast applications\
    \ include video broadcast and\n      multicast file transfer, and many of these\
    \ applications require\n      network security services. The Multicast Security\
    \ Reference\n      Framework [R3740] covers three functional areas:\n      - \
    \ Multicast data handling: Security-related treatment of\n         multicast data\
    \ by the sender and the receiver.\n      -  Group key management: Secure distribution\
    \ and refreshment of\n         keying material. (See: Group Domain of Interpretation.)\n\
    \      -  Multicast security policy: Policy translation and\n         interpretation\
    \ across the multiple administrative domains that\n         typically are spanned\
    \ by a multicast application.\n   $ Secure Shell(trademark) (SSH(trademark))\n\
    \      (N) Refers to a protocol for secure remote login and other secure\n   \
    \   network services.\n      Usage: On the Web site of SSH Communication Security\
    \ Corporation,\n      at http://www.ssh.com/legal_notice.html, it says, \"SSH\
    \ [and] the\n      SSH logo ... are either trademarks or registered trademarks\
    \ of\n      SSH.\" This Glossary seeks to make readers aware of this trademark\n\
    \      claim but takes no position on its validity.\n      Tutorial: SSH has three\
    \ main parts:\n      -  Transport layer protocol: Provides server authentication,\n\
    \         confidentiality, and integrity; and can optionally provide\n       \
    \  compression. This layer typically runs over a TCP connection,\n         but\
    \ might also run on top of any other reliable data stream.\n      -  User authentication\
    \ protocol: Authenticates the client-side\n         user to the server. It runs\
    \ over the transport layer protocol.\n      -  Connection protocol: Multiplexes\
    \ the encrypted tunnel into\n         several logical channels. It runs over the\
    \ user authentication\n         protocol.\n   $ Secure Sockets Layer (SSL)\n \
    \     (N) An Internet protocol (originally developed by Netscape\n      Communications,\
    \ Inc.) that uses connection-oriented end-to-end\n      encryption to provide\
    \ data confidentiality service and data\n      integrity service for traffic between\
    \ a client (often a web\n      browser) and a server, and that can optionally\
    \ provide peer entity\n      authentication between the client and the server.\
    \ (See: Transport\n      Layer Security.)\n      Tutorial: SSL has two layers;\
    \ SSL's lower layer, the SSL Record\n      Protocol, is layered on top of an IPS\
    \ Transport-Layer protocol and\n      encapsulates protocols that run in the upper\
    \ layer. The upper-\n      layer protocols are the three SSL management protocols\
    \ -- SSL\n      Handshake Protocol, SSL Change Cipher Spec Protocol, or SSL Alert\n\
    \      Protocol -- and some Application-Layer protocol (e.g., HTTP).\n      The\
    \ SSL management protocols provide asymmetric cryptography for\n      server authentication\
    \ (verifying the server's identity to the\n      client) and optional client authentication\
    \ (verifying the client's\n      identity to the server), and also enable them,\
    \ before the\n      application protocol transmits or receives data, to negotiate\
    \ a\n      symmetric encryption algorithm and secret session key (to use for\n\
    \      data confidentiality service) and a keyed hash (to use for data\n     \
    \ integrity service).\n      SSL is independent of the application it encapsulates,\
    \ and any\n      application can layer on top of SSL transparently. However, many\n\
    \      Internet applications might be better served by IPsec.\n   $ secure state\n\
    \      1a. (I) A system condition in which the system is in conformance\n    \
    \  with the applicable security policy. (Compare: clean system,\n      transaction.)\n\
    \      1b. (I) /formal model/ A system condition in which no subject can\n   \
    \   access any object in an unauthorized manner. (See: secondary\n      definition\
    \ under \"Bell-LaPadula model\".)\n   $ security\n      1a. (I) A system condition\
    \ that results from the establishment and\n      maintenance of measures to protect\
    \ the system.\n      1b. (I) A system condition in which system resources are\
    \ free from\n      unauthorized access and from unauthorized or accidental change,\n\
    \      destruction, or loss. (Compare: safety.)\n      2. (I) Measures taken to\
    \ protect a system.\n      Tutorial: Parker [Park] suggests that providing a condition\
    \ of\n      system security may involve the following six basic functions,\n \
    \     which overlap to some extent:\n      -  \"Deterrence\": Reducing an intelligent\
    \ threat by discouraging\n         action, such as by fear or doubt. (See: attack,\
    \ threat action.)\n      -  \"Avoidance\": Reducing a risk by either reducing\
    \ the value of\n         the potential loss or reducing the probability that the\
    \ loss\n         will occur. (See: risk analysis. Compare: \"risk avoidance\"\n\
    \         under \"risk\".)\n      -  \"Prevention\": Impeding or thwarting a potential\
    \ security\n         violation by deploying a countermeasure.\n      -  \"Detection\"\
    : Determining that a security violation is\n         impending, is in progress,\
    \ or has recently occurred, and thus\n         make it possible to reduce the\
    \ potential loss. (See: intrusion\n         detection.)\n      -  \"Recovery\"\
    : Restoring a normal state of system operation by\n         compensating for a\
    \ security violation, possibly by eliminating\n         or repairing its effects.\
    \ (See: contingency plan, main entry\n         for \"recovery\".)\n      -  \"\
    Correction\": Changing a security architecture to eliminate or\n         reduce\
    \ the risk of reoccurrence of a security violation or\n         threat consequence,\
    \ such as by eliminating a vulnerability.\n   $ security architecture\n      (I)\
    \ A plan and set of principles that describe (a) the security\n      services\
    \ that a system is required to provide to meet the needs of\n      its users,\
    \ (b) the system components required to implement the\n      services, and (c)\
    \ the performance levels required in the\n      components to deal with the threat\
    \ environment (e.g., [R2179]).\n      (See: defense in depth, IATF, OSIRM Security\
    \ Architecture,\n      security controls, Tutorial under \"security policy\".)\n\
    \      Tutorial: A security architecture is the result of applying the\n     \
    \ system engineering process. A complete system security\n      architecture includes\
    \ administrative security, communication\n      security, computer security, emanations\
    \ security, personnel\n      security, and physical security. A complete security\
    \ architecture\n      needs to deal with both intentional, intelligent threats\
    \ and\n      accidental threats.\n   $ Security Assertion Markup Language (SAML)\n\
    \      (N) A protocol consisting of XML-based request and response\n      message\
    \ formats for exchanging security information, expressed in\n      the form of\
    \ assertions about subjects, between on-line business\n      partners. [SAML]\n\
    \   $ security association\n      1. (I) A relationship established between two\
    \ or more entities to\n      enable them to protect data they exchange. (See:\
    \ association,\n      ISAKMP, SAD. Compare: session.)\n      Tutorial: The relationship\
    \ is represented by a set of data that is\n      shared between the entities and\
    \ is agreed upon and considered a\n      contract between them. The data describes\
    \ how the associated\n      entities jointly use security services. The relationship\
    \ is used\n      to negotiate characteristics of security mechanisms, but the\n\
    \      relationship is usually understood to exclude the mechanisms\n      themselves.\n\
    \      2. (I) /IPsec/ A simplex (uni-directional) logical connection\n      created\
    \ for security purposes and implemented with either AH or\n      ESP (but not\
    \ both). The security services offered by a security\n      association depend\
    \ on the protocol (AH or ESP), the IPsec mode\n      (transport or tunnel), the\
    \ endpoints, and the election of optional\n      services within the protocol.\
    \ A security association is identified\n      by a triple consisting of (a) a\
    \ destination IP address, (b) a\n      protocol (AH or ESP) identifier, and (c)\
    \ a Security Parameter\n      Index.\n      3. (O) \"A set of policy and cryptographic\
    \ keys that provide\n      security services to network traffic that matches that\
    \ policy\".\n      [R3740] (See: cryptographic association, group security\n \
    \     association.)\n      4. (O) \"The totality of communications and security\
    \ mechanisms and\n      functions (e.g., communications protocols, security protocols,\n\
    \      security mechanisms and functions) that securely binds together\n     \
    \ two security contexts in different end systems or relay systems\n      supporting\
    \ the same information domain.\" [DoD6]\n   $ Security Association Database (SAD)\n\
    \      (I) /IPsec/ In an IPsec implementation that operates in a network\n   \
    \   node, a database that contains parameters to describe the status\n      and\
    \ operation of each of the active security associations that the\n      node has\
    \ established with other nodes. Separate inbound and\n      outbound SADs are\
    \ needed because of the directionality of IPsec\n      security associations.\
    \ [R4301] (Compare: SPD.)\n   $ security association identifier (SAID)\n     \
    \ (I) A data field in a security protocol (such as NLSP or SDE),\n      used to\
    \ identify the security association to which a PDU is bound.\n      The SAID value\
    \ is usually used to select a key for decryption or\n      authentication at the\
    \ destination. (See: Security Parameter\n      Index.)\n   $ security assurance\n\
    \      1. (I) An attribute of an information system that provides grounds\n  \
    \    for having confidence that the system operates such that the\n      system's\
    \ security policy is enforced. (Compare: trust.)\n      2. (I) A procedure that\
    \ ensures a system is developed and operated\n      as intended by the system's\
    \ security policy.\n      3. (D) \"The degree of confidence one has that the security\n\
    \      controls operate correctly and protect the system as intended.\"\n    \
    \  [SP12]\n      Deprecated Definition: IDOCs SHOULD NOT use definition 3; it\
    \ is a\n      definition for \"assurance level\" rather than for \"assurance\"\
    .\n      4. (D) /U.S. Government, identity authentication/ The (a) \"degree\n\
    \      of confidence in the vetting process used to establish the\n      identity\
    \ of the individual to whom the [identity] credential was\n      issued\" and\
    \ the (b) \"degree of confidence that the individual who\n      uses the credential\
    \ is the individual to whom the credential was\n      issued\". [M0404]\n    \
    \  Deprecated Definition: IDOCs SHOULD NOT use definition 4; it mixes\n      concepts\
    \ in a potentially misleading way. Part \"a\" is a definition\n      for \"assurance\
    \ level\" (rather than \"security assurance\") of an\n      identity registration\
    \ process; and part \"b\" is a definition for\n      \"assurance level\" (rather\
    \ than \"security assurance\") of an\n      identity authentication process. Also,\
    \ the processes of\n      registration and authentication should be defined and\
    \ designed\n      separately to ensure clarity in certification.\n   $ security\
    \ audit\n      (I) An independent review and examination of a system's records\n\
    \      and activities to determine the adequacy of system controls,\n      ensure\
    \ compliance with established security policy and procedures,\n      detect breaches\
    \ in security services, and recommend any changes\n      that are indicated for\
    \ countermeasures. [I7498-2, NCS01] (Compare:\n      accounting, intrusion detection.)\n\
    \      Tutorial: The basic audit objective is to establish accountability\n  \
    \    for system entities that initiate or participate in security-\n      relevant\
    \ events and actions. Thus, means are needed to generate\n      and record a security\
    \ audit trail and to review and analyze the\n      audit trail to discover and\
    \ investigate security violations.\n   $ security audit trail\n      (I) A chronological\
    \ record of system activities that is sufficient\n      to enable the reconstruction\
    \ and examination of the sequence of\n      environments and activities surrounding\
    \ or leading to an\n      operation, procedure, or event in a security-relevant\
    \ transaction\n      from inception to final results. [NCS04] (See: security audit.)\n\
    \   $ security by obscurity\n      (O) Attempting to maintain or increase security\
    \ of a system by\n      keeping secret the design or construction of a security\
    \ mechanism.\n      Tutorial: This approach has long been discredited in cryptography,\n\
    \      where the phrase refers to trying to keep an algorithm secret,\n      rather\
    \ than just concealing the keys [Schn]. One must assume that\n      mass-produced\
    \ or widely fielded cryptographic devices eventually\n      will be lost or stolen\
    \ and, therefore, that the algorithms will be\n      reverse engineered and become\
    \ known to the adversary. Thus, one\n      should rely on only those algorithms\
    \ and protocols that are strong\n      enough to have been published widely, and\
    \ have been peer reviewed\n      for long enough that their flaws have been found\
    \ and removed. For\n      example, NIST used a long, public process to select\
    \ AES to replace\n      DES.\n      In computer and network security, the principle\
    \ of \"no security by\n      obscurity\" also applies to security mechanisms other\
    \ than\n      cryptography. For example, if the design and implementation of a\n\
    \      protocol for access control are strong, then reading the\n      protocol's\
    \ source code should not enable you to find a way to\n      evade the protection\
    \ and penetrate the system.\n   $ security class\n      (D) Synonym for \"security\
    \ level\".\n      Deprecated Term: IDOCs SHOULD NOT use this term. Instead, use\n\
    \      \"security level\", which is more widely established and understood.\n\
    \   $ security clearance\n      (I) A determination that a person is eligible,\
    \ under the standards\n      of a specific security policy, for authorization\
    \ to access\n      sensitive information or other system resources. (See: clearance\n\
    \      level.)\n   $ security compromise\n      (I) A security violation in which\
    \ a system resource is exposed, or\n      is potentially exposed, to unauthorized\
    \ access. (Compare: data\n      compromise, exposure, violation.)\n   $ security\
    \ controls\n      (N) The management, operational, and technical controls\n  \
    \    (safeguards or countermeasures) prescribed for an information\n      system\
    \ which, taken together, satisfy the specified security\n      requirements and\
    \ adequately protect the confidentiality,\n      integrity, and availability of\
    \ the system and its information.\n      [FP199] (See: security architecture.)\n\
    \   $ security doctrine\n      (I) A specified set of procedures or practices\
    \ that direct or\n      provide guidance for how to comply with security policy.\
    \ (Compare:\n      security mechanism, security policy.)\n      Tutorial: Security\
    \ policy and security doctrine are closely\n      related. However, policy deals\
    \ mainly with strategy, and doctrine\n      deals with tactics.\n      Security\
    \ doctrine is often understood to refer mainly to\n      administrative security,\
    \ personnel security, and physical\n      security. For example, security mechanisms\
    \ and devices that\n      implement them are normally designed to operate in a\
    \ limited range\n      of environmental and administrative conditions, and these\n\
    \      conditions must be met to complement and ensure the technical\n      protection\
    \ afforded by the hardware, firmware, and software in the\n      devices. Security\
    \ doctrine specifies how to achieve those\n      conditions. (See: \"first law\"\
    \ under \"Courtney's laws\".)\n   $ security domain\n      (I) See: domain.\n\
    \   $ security environment\n      (I) The set of external entities, procedures,\
    \ and conditions that\n      affect secure development, operation, and maintenance\
    \ of a system.\n      (See: \"first law\" under \"Courtney's laws\".)\n   $ security\
    \ event\n      (I) An occurrence in a system that is relevant to the security\
    \ of\n      the system. (See: security incident.)\n      Tutorial: The term covers\
    \ both events that are security incidents\n      and those that are not. In a\
    \ CA workstation, for example, a list\n      of security events might include\
    \ the following:\n      -  Logging an operator into or out of the system.\n  \
    \    -  Performing a cryptographic operation, e.g., signing a digital\n      \
    \   certificate or CRL.\n      -  Performing a cryptographic card operation: creation,\
    \ insertion,\n         removal, or backup.\n      -  Performing a digital certificate\
    \ lifecycle operation: rekey,\n         renewal, revocation, or update.\n    \
    \  -  Posting a digital certificate to an X.500 Directory.\n      -  Receiving\
    \ a key compromise notification.\n      -  Receiving an improper certification\
    \ request.\n      -  Detecting an alarm condition reported by a cryptographic\n\
    \         module.\n      -  Failing a built-in hardware self-test or a software\
    \ system\n         integrity check.\n   $ security fault analysis\n      (I) A\
    \ security analysis, usually performed on hardware at the\n      level of gate\
    \ logic, gate-by-gate, to determine the security\n      properties of a device\
    \ when a hardware fault is encountered.\n   $ security function\n      (I) A function\
    \ in a system that is relevant to the security of the\n      system; i.e., a system\
    \ function that must operate correctly to\n      ensure adherence to the system's\
    \ security policy.\n   $ security gateway\n      1. (I) An internetwork gateway\
    \ that separates trusted (or\n      relatively more trusted) hosts on one side\
    \ from untrusted (or less\n      trusted) hosts on the other side. (See: firewall\
    \ and guard.)\n      2. (O) /IPsec/ \"An intermediate system that implements IPsec\n\
    \      protocols.\" [R4301]\n      Tutorial: IPsec's AH or ESP can be implemented\
    \ on a gateway\n      between a protected network and an unprotected network,\
    \ to provide\n      security services to the protected network's hosts when they\n\
    \      communicate across the unprotected network to other hosts and\n      gateways.\n\
    \   $ security incident\n      1. (I) A security event that involves a security\
    \ violation. (See:\n      CERT, security event, security intrusion, security violation.)\n\
    \      Tutorial: In other words, a security event in which the system's\n    \
    \  security policy is disobeyed or otherwise breached.\n      2. (D) \"Any adverse\
    \ event [that] compromises some aspect of\n      computer or network security.\"\
    \ [R2350]\n      Deprecated Definition: IDOCs SHOULD NOT use definition 2 because\n\
    \      (a) a security incident may occur without actually being harmful\n    \
    \  (i.e., adverse) and because (b) this Glossary defines \"compromise\"\n    \
    \  more narrowly in relation to unauthorized access.\n      3. (D) \"A violation\
    \ or imminent threat of violation of computer\n      security policies, acceptable\
    \ use policies, or standard computer\n      security practices.\" [SP61]\n   \
    \   Deprecated Definition: IDOCs SHOULD NOT use definition 3 because\n      it\
    \ mixes concepts in way that does not agree with common usage; a\n      security\
    \ incident is commonly thought of as involving a\n      realization of a threat\
    \ (see: threat action), not just a threat.\n   $ security intrusion\n      (I)\
    \ A security event, or a combination of multiple security\n      events, that\
    \ constitutes a security incident in which an intruder\n      gains, or attempts\
    \ to gain, access to a system or system resource\n      without having authorization\
    \ to do so.\n   $ security kernel\n      (I) \"The hardware, firmware, and software\
    \ elements of a trusted\n      computing base that implement the reference monitor\
    \ concept. It\n      must mediate all accesses, be protected from modification,\
    \ and be\n      verifiable as correct.\" [NCS04] (See: kernel, TCB.)\n      Tutorial:\
    \ A security kernel is an implementation of a reference\n      monitor for a given\
    \ hardware base. [Huff]\n   $ security label\n      (I) An item of meta-data that\
    \ designates the value of one or more\n      security-relevant attributes (e.g.,\
    \ security level) of a system\n      resource. (See: [R1457]. Compare: security\
    \ marking.)\n      Deprecated usage: To avoid confusion, IDOCs SHOULD NOT use\n\
    \      \"security label\" for \"security marking\", or vice versa, even\n    \
    \  though that is commonly done (including in some national and\n      international\
    \ standards that should know better).\n      Tutorial: Humans and automated security\
    \ mechanisms use a security\n      label of a system resource to determine, according\
    \ to applicable\n      security policy, how to control access to the resource\
    \ (and they\n      affix appropriate, matching security markings to physical\n\
    \      instances of the resource). Security labels are most often used to\n  \
    \    support data confidentiality policy, and sometimes used to support\n    \
    \  data integrity policy.\n      As explained in [R1457], the form that is taken\
    \ by security labels\n      of a protocol's packets varies depending on the OSIRM\
    \ layer in\n      which the protocol operates. Like meta-data generally, a security\n\
    \      label of a data packet may be either explicit (e.g., IPSO) or\n      implicit\
    \ (e.g., Alice treats all messages received from Bob as\n      being labeled \"\
    Not For Public Release\"). In a connectionless\n      protocol, every packet might\
    \ have an explicit label; but in a\n      connection-oriented protocol, all packets\
    \ might have the same\n      implicit label that is determined at the time the\
    \ connection is\n      established.\n      Both classified and unclassified system\
    \ resources may require a\n      security label. (See: FOUO.)\n   $ security level\n\
    \      (I) The combination of a hierarchical classification level and a\n    \
    \  set of non-hierarchical category designations that represents how\n      sensitive\
    \ a specified type or item of information is. (See:\n      dominate, lattice model.\
    \ Compare: classification level.)\n      Usage: IDOCs that use this term SHOULD\
    \ state a definition for it.\n      The term is usually understood to involve\
    \ sensitivity to\n      disclosure, but it also is used in many other ways and\
    \ could\n      easily be misunderstood.\n   $ Security Level field\n      (I)\
    \ A 16-bit field that specifies a security level value in the\n      security\
    \ option (option type 130) of version 4 IP's datagram\n      header format.\n\
    \      Deprecated Abbreviation: IDOCs SHOULD NOT use the abbreviation \"S\n  \
    \    field\", which is potentially ambiguous.\n   $ security management infrastructure\
    \ (SMI)\n      (I) System components and activities that support security policy\n\
    \      by monitoring and controlling security services and mechanisms,\n     \
    \ distributing security information, and reporting security events.\n      Tutorial:\
    \ The associated functions are as follows [I7498-4]:\n      -  Controlling (granting\
    \ or restricting) access to system\n         resources: This includes verifying\
    \ authorizations and\n         identities, controlling access to sensitive security\
    \ data, and\n         modifying access priorities and procedures in the event\
    \ of\n         attacks.\n      -  Retrieving (gathering) and archiving (storing)\
    \ security\n         information: This includes logging security events and\n\
    \         analyzing the log, monitoring and profiling usage, and\n         reporting\
    \ security violations.\n      -  Managing and controlling the encryption process:\
    \ This includes\n         performing the functions of key management and reporting\
    \ on key\n         management problems. (See: PKI.)\n   $ security marking\n \
    \     (I) A physical marking that is bound to an instance of a system\n      resource\
    \ and that represents a security label of the resource,\n      i.e., that names\
    \ or designates the value of one or more security-\n      relevant attributes\
    \ of the resource. (Compare: security label.)\n      Tutorial: A security label\
    \ may be represented by various\n      equivalent markings depending on the physical\
    \ form taken by the\n      labeled resource. For example, a document could have\
    \ a marking\n      composed of a bit pattern [FP188] when the document is stored\n\
    \      electronically as a file in a computer, and also a marking of\n      printed\
    \ alphabetic characters when the document is in paper form.\n   $ security mechanism\n\
    \      (I) A method or process (or a device incorporating it) that can be\n  \
    \    used in a system to implement a security service that is provided\n     \
    \ by or within the system. (See: Tutorial under \"security policy\".\n      Compare:\
    \ security doctrine.)\n      Usage: Usually understood to refer primarily to components\
    \ of\n      communication security, computer security, and emanation security.\n\
    \      Examples: Authentication exchange, checksum, digital signature,\n     \
    \ encryption, and traffic padding.\n   $ security model\n      (I) A schematic\
    \ description of a set of entities and relationships\n      by which a specified\
    \ set of security services are provided by or\n      within a system. Example:\
    \ Bell-LaPadula model, OSIRM. (See:\n      Tutorial under \"security policy\"\
    .)\n   $ security parameters index (SPI)\n      1. (I) /IPsec/ A 32-bit identifier\
    \ used to distinguish among\n      security associations that terminate at the\
    \ same destination (IP\n      address) and use the same security protocol (AH\
    \ or ESP). Carried\n      in AH and ESP to enable the receiving system to determine\
    \ under\n      which security association to process a received packet.\n    \
    \  2. (I) /mobile IP/ A 32-bit index identifying a security\n      association\
    \ from among the collection of associations that are\n      available between\
    \ a pair of nodes, for application to mobile IP\n      protocol messages that\
    \ the nodes exchange.\n   $ security perimeter\n      (I) A physical or logical\
    \ boundary that is defined for a domain or\n      enclave and within which a particular\
    \ security policy or security\n      architecture applies. (See: insider, outsider.)\n\
    \   $ security policy\n      1. (I) A definite goal, course, or method of action\
    \ to guide and\n      determine present and future decisions concerning security\
    \ in a\n      system. [NCS03, R3198] (Compare: certificate policy.)\n      2a.\
    \ (I) A set of policy rules (or principles) that direct how a\n      system (or\
    \ an organization) provides security services to protect\n      sensitive and\
    \ critical system resources. (See: identity-based\n      security policy, policy\
    \ rule, rule-based security policy, rules of\n      behavior. Compare: security\
    \ architecture, security doctrine,\n      security mechanism, security model,\
    \ [R1281].)\n      2b. (O) A set of rules to administer, manage, and control access\n\
    \      to network resources. [R3060, R3198]\n      2c. (O) /X.509/ A set of rules\
    \ laid down by an authority to govern\n      the use and provision of security\
    \ services and facilities.\n      2d. (O) /Common Criteria/ A set of rules that\
    \ regulate how assets\n      are managed, protected, and distributed within a\
    \ TOE.\n      Tutorial: Ravi Sandhu suggests that security policy is one of four\n\
    \      layers of the security engineering process (as shown in the\n      following\
    \ diagram). Each layer provides a different view of\n      security, ranging from\
    \ what services are needed to how services\n      are implemented.\n         What\
    \ Security Services\n         Should Be Provided?        +- - - - - - - - - -\
    \ - - -+\n         ^  +- - - - - - - - - - - -| Mission Functions View  |\n  \
    \       |  | Security Policy       |- - - - - - - - - - - - -+\n         |  +-\
    \ - - - - - - - - - - -| Domain Practices View   |\n         |  | Security Model\
    \        |- - - - - - - - - - - - -+\n         |  +- - - - - - - - - - - -| Enclave\
    \ Services View   |\n         |  | Security Architecture |- - - - - - - - - -\
    \ - - -+\n         |  +- - - - - - - - - - - -| Agent Mechanisms View   |\n  \
    \       |  | Security Mechanism    |- - - - - - - - - - - - -+\n         v  +-\
    \ - - - - - - - - - - -| Platform Devices View   |\n         How Are Security\
    \           +- - - - - - - - - - - - -+\n         Services Implemented?\n    \
    \  We suggest that each of Sandhu's four layers is a mapping between\n      two\
    \ points of view that differ in their degree of abstraction,\n      according\
    \ to the perspectives of various participants in system\n      design, development,\
    \ and operation activities, as follows:.\n      -  Mission functions view: The\
    \ perspective of a user of system\n         resources. States time-phased protection\
    \ needs for resources\n         and identifies sensitive and critical resources\
    \ -- networks,\n         hosts, applications, and databases. Independent of rules\
    \ and\n         practices used to achieve protection.\n      -  Domain practices\
    \ view: The perspective of an enterprise manager\n         who sets protection\
    \ standards for resources. States rules and\n         practices for protection.\
    \ Identifies domain members; i.e.,\n         entities (users/providers) and resources\
    \ (including data\n         objects). Independent of system topology. Not required\
    \ to be\n         hierarchical.\n      -  Enclave services view: The perspective\
    \ of a system designer who\n         allocates security functions to major components.\
    \ Assigns\n         security services to system topology structures and their\n\
    \         contents. Independent of security mechanisms. Hierarchical\n       \
    \  across all domains.\n      -  Agent mechanisms view: The perspective of a system\
    \ engineer who\n         specifies security mechanisms to implement security services.\n\
    \         Specifies mechanisms to be used by protocol, database, and\n       \
    \  application engines. Independent of type and manufacture of\n         platforms\
    \ and other physical devices.\n      -  Platform devices view: The perspective\
    \ of an as-built\n         description of the system in operation. Specifies exactly\
    \ how\n         to build or assemble the system, and also specifies procedures\n\
    \         for operating the system.\n   $ Security Policy Database (SPD)\n   \
    \   (I) /IPsec/ In an IPsec implementation operating in a network\n      node,\
    \ a database that contains parameters that specify policies\n      set by a user\
    \ or administrator to determine what IPsec services,\n      if any, are to be\
    \ provided to IP datagrams sent or received by the\n      node, and in what fashion\
    \ they are provided. For each datagram,\n      the SPD specifies one of three\
    \ choices: discard the datagram,\n      apply IPsec services (e.g., AH or ESP),\
    \ or bypass IPsec. Separate\n      inbound and outbound SPDs are needed because\
    \ of the directionality\n      of IPsec security associations. [R4301] (Compare:\
    \ SAD.)\n   $ Security Protocol 3 (SP3)\n      (O) A protocol [SDNS3] developed\
    \ by SDNS to provide connectionless\n      data security at the top of OSIRM Layer\
    \ 3. (Compare: IPsec, NLSP.)\n   $ Security Protocol 4 (SP4)\n      (O) A protocol\
    \ [SDNS4] developed by SDNS to provide either\n      connectionless or end-to-end\
    \ connection-oriented data security at\n      the bottom of OSIRM Layer 4. (See:\
    \ TLSP.)\n   $ security-relevant event\n      (D) Synonym for \"security event\"\
    .\n      Deprecated Term: IDOCs SHOULD NOT use this term; it is wordy.\n   $ security-sensitive\
    \ function\n      (D) Synonym for \"security function\".\n      Deprecated Term:\
    \ IDOCs SHOULD NOT use this term; it is wordy.\n   $ security service\n      1.\
    \ (I) A processing or communication service that is provided by a\n      system\
    \ to give a specific kind of protection to system resources.\n      (See: access\
    \ control service, audit service, availability service,\n      data confidentiality\
    \ service, data integrity service, data origin\n      authentication service,\
    \ non-repudiation service, peer entity\n      authentication service, system integrity\
    \ service.)\n      Tutorial: Security services implement security policies, and\
    \ are\n      implemented by security mechanisms.\n      2. (O) \"A service, provided\
    \ by a layer of communicating open\n      systems, [that] ensures adequate security\
    \ of the systems or the\n      data transfers.\" [I7498-2]\n   $ security situation\n\
    \      (I) /ISAKMP/ The set of all security-relevant information (e.g.,\n    \
    \  network addresses, security classifications, manner of operation\n      such\
    \ as normal or emergency) that is needed to decide the security\n      services\
    \ that are required to protect the association that is\n      being negotiated.\n\
    \   $ security target\n      (N) /Common Criteria/ A set of security requirements\
    \ and\n      specifications to be used as the basis for evaluation of an\n   \
    \   identified TOE.\n      Tutorial: A security target (ST) is a statement of\
    \ security claims\n      for a particular information technology security product\
    \ or\n      system, and is the basis for agreement among all parties as to\n \
    \     what security the product or system offers. An ST parallels the\n      structure\
    \ of a protection profile, but has additional elements\n      that include product-specific\
    \ detailed information. An ST contains\n      a summary specification, which defines\
    \ the specific measures taken\n      in the product or system to meet the security\
    \ requirements.\n   $ security token\n      (I) See: token.\n   $ security violation\n\
    \      (I) An act or event that disobeys or otherwise breaches security\n    \
    \  policy. (See: compromise, penetration, security incident.)\n   $ seed\n   \
    \   (I) A value that is an input to a pseudorandom number generator.\n   $ selective-field\
    \ confidentiality\n      (I) A data confidentiality service that preserves confidentiality\n\
    \      for one or more parts (i.e., fields) of each packet. (See:\n      selective-field\
    \ integrity.)\n      Tutorial: Data confidentiality service usually is applied\
    \ to\n      entire SDUs, but some situations might require protection of only\n\
    \      part of each packet. For example, when Alice uses a debit card at\n   \
    \   an automated teller machine (ATM), perhaps only her PIN is\n      enciphered\
    \ for confidentiality when her transaction request is\n      transmitted from\
    \ the ATM to her bank's computer.\n      In any given operational situation, there\
    \ could be many different\n      reasons for using selective field confidentiality.\
    \ In the ATM\n      example, there are at least four possibilities: The service\
    \ may\n      provide a fail-safe mode of operation, ensuring that the bank can\n\
    \      still process transactions (although with some risk) even when the\n  \
    \    encryption system fails. It may make messages easier to work with\n     \
    \ when doing system fault isolation. It may avoid problems with laws\n      that\
    \ prevent shipping enciphered data across international\n      borders. It may\
    \ improve efficiency by reducing processing load at\n      a central computer\
    \ site.\n   $ selective-field integrity\n      (I) A data integrity service that\
    \ preserves integrity for one or\n      more parts (i.e., fields) of each packet.\
    \ (See: selective-field\n      confidentiality.)\n      Tutorial: Data integrity\
    \ service may be implemented in a protocol\n      to protect the SDU part of packets,\
    \ the PCI part, or both.\n      -  SDU protection: When service is provided for\
    \ SDUs, it usually\n         is applied to entire SDUs, but it might be applied\
    \ only to\n         parts of SDUs in some situations. For example, an IPS\n  \
    \       Application-Layer protocol might need protection of only part\n      \
    \   of each packet, and this might enable faster processing.\n      -  PCI protection:\
    \ To prevent active wiretapping, it might be\n         desirable to apply data\
    \ integrity service to the entire PCI,\n         but some PCI fields in some protocols\
    \ need to be mutable in\n         transit. For example, the \"Time to Live\" field\
    \ in IPv4 is\n         changed each time a packet passes through a router in the\n\
    \         Internet Layer. Thus, the value that the field will have when\n    \
    \     the packet arrives at its destination is not predictable by the\n      \
    \   sender and cannot be included in a checksum computed by the\n         sender.\
    \ (See: Authentication Header.)\n   $ self-signed certificate\n      (I) A public-key\
    \ certificate for which the public key bound by the\n      certificate and the\
    \ private key used to sign the certificate are\n      components of the same key\
    \ pair, which belongs to the signer.\n      (Compare: root certificate.)\n   \
    \   Tutorial: In a self-signed X.509 public-key certificate, the\n      issuer's\
    \ DN is the same as the subject's DN.\n   $ semantic security\n      (I) An attribute\
    \ of an encryption algorithm that is a\n      formalization of the notion that\
    \ the algorithm not only hides the\n      plain text but also reveals no partial\
    \ information about the plain\n      text; i.e., whatever is computable about\
    \ the plain text when given\n      the cipher text, is also computable without\
    \ the cipher text.\n      (Compare: indistinguishability.)\n   $ semiformal\n\
    \      (I) Expressed in a restricted syntax language with defined\n      semantics.\
    \ [CCIB] (Compare: formal, informal.)\n   $ sensitive\n      (I) A condition of\
    \ a system resource such that the loss of some\n      specified property of that\
    \ resource, such as confidentiality or\n      integrity, would adversely affect\
    \ the interests or business of its\n      owner or user. (See: sensitive information.\
    \ Compare: critical.)\n   $ sensitive compartmented information (SCI)\n      (O)\
    \ /U.S. Government/ Classified information concerning or derived\n      from intelligence\
    \ sources, methods, or analytical processes, which\n      is required to be handled\
    \ within formal control systems\n      established by the Director of Central\
    \ Intelligence. [C4009] (See:\n      compartment, SAP, SCIF. Compare: collateral\
    \ information.)\n   $ sensitive compartmented information facility (SCIF)\n  \
    \    (O) /U.S. Government/ \"An accredited area, room, group of rooms,\n     \
    \ building, or installation where SCI may be stored, used,\n      discussed, and/or\
    \ processed.\" [C4009] (See: SCI. Compare: shielded\n      enclosure.)\n   $ sensitive\
    \ information\n      1. (I) Information for which (a) disclosure, (b) alteration,\
    \ or\n      (c) destruction or loss could adversely affect the interests or\n\
    \      business of its owner or user. (See: data confidentiality, data\n     \
    \ integrity, sensitive. Compare: classified, critical.)\n      2. (O) /U.S. Government/\
    \ Information for which (a) loss, (b)\n      misuse, (c) unauthorized access,\
    \ or (d) unauthorized modification\n      could adversely affect the national\
    \ interest or the conduct of\n      federal programs, or the privacy to which\
    \ individuals are entitled\n      under the Privacy Act of 1974, but that has\
    \ not been specifically\n      authorized under criteria established by an Executive\
    \ Order or an\n      Act of Congress to be kept classified in the interest of\
    \ national\n      defense or foreign policy.\n      Tutorial: Systems that are\
    \ not U.S. national security systems, but\n      contain sensitive U.S. Federal\
    \ Government information, must be\n      protected according to the Computer Security\
    \ Act of 1987 (Public\n      Law 100-235). (See: national security.)\n   $ sensitivity\
    \ label\n      (D) Synonym for \"classification label\".\n      Deprecated term:\
    \ IDOCs SHOULD NOT use this term because the\n      definition of \"sensitive\"\
    \ involves not only data confidentiality,\n      but also data integrity.\n  \
    \ $ sensitivity level\n      (D) Synonym for \"classification level\".\n     \
    \ Deprecated term: IDOCs SHOULD NOT use this term because the\n      definition\
    \ of \"sensitive\" involves not only data confidentiality,\n      but also data\
    \ integrity.\n   $ separation of duties\n      (I) The practice of dividing the\
    \ steps in a system process among\n      different individual entities (i.e.,\
    \ different users or different\n      roles) so as to prevent a single entity\
    \ acting alone from being\n      able to subvert the process. Usage: a.k.a. \"\
    separation of\n      privilege\". (See: administrative security, dual control.)\n\
    \   $ serial number\n      See: certificate serial number.\n   $ Serpent\n   \
    \   (O) A symmetric, 128-bit block cipher designed by Ross Anderson,\n      Eli\
    \ Biham, and Lars Knudsen as a candidate for the AES.\n   $ server\n      (I)\
    \ A system entity that provides a service in response to\n      requests from\
    \ other system entities called clients.\n   $ service data unit (SDU)\n      (N)\
    \ See: secondary definition under \"protocol data unit\".\n   $ session\n    \
    \  1a. (I) /computer usage/ A continuous period of time, usually\n      initiated\
    \ by a login, during which a user accesses a computer\n      system.\n      1b.\
    \ (I) /computer activity/ The set of transactions or other\n      computer activities\
    \ that are performed by or for a user during a\n      period of computer usage.\n\
    \      2. (I) /access control/ A temporary mapping of a principal to one\n   \
    \   or more roles. (See: role-based access control.)\n      Tutorial: A user establishes\
    \ a session as a principal and\n      activates some subset of roles to which\
    \ the principal has been\n      assigned. The authorizations available to the\
    \ principal in the\n      session are the union of the permissions of all the\
    \ roles\n      activated in the session. Each session is associated with a single\n\
    \      principal and, therefore, with a single user. A principal may have\n  \
    \    multiple, concurrent sessions and may activate a different set of\n     \
    \ roles in each session.\n      3. (I) /computer network/ A persistent but (normally)\
    \ temporary\n      association between a user agent (typically a client) and a\
    \ second\n      process (typically a server). The association may persist across\n\
    \      multiple exchanges of data, including multiple connections.\n      (Compare:\
    \ security association.)\n   $ session key\n      (I) In the context of symmetric\
    \ encryption, a key that is\n      temporary or is used for a relatively short\
    \ period of time. (See:\n      ephemeral, KDC, session. Compare: master key.)\n\
    \      Tutorial: A session key is used for a defined period of\n      communication\
    \ between two system entities or components, such as\n      for the duration of\
    \ a single connection or transaction set; or the\n      key is used in an application\
    \ that protects relatively large\n      amounts of data and, therefore, needs\
    \ to be rekeyed frequently.\n   $ SET(trademark)\n      (O) See: SET Secure Electronic\
    \ Transaction(trademark).\n   $ SET private extension\n      (O) One of the private\
    \ extensions defined by SET for X.509\n      certificates. Carries information\
    \ about hashed root key,\n      certificate type, merchant data, cardholder certificate\n\
    \      requirements, encryption support for tunneling, or message support\n  \
    \    for payment instructions.\n   $ SET qualifier\n      (O) A certificate policy\
    \ qualifier that provides information about\n      the location and content of\
    \ a SET certificate policy.\n      Tutorial: Besides the policies and qualifiers\
    \ inherited from its\n      own certificate, each CA in the SET certification\
    \ hierarchy may\n      add one qualifying statement to the root policy when the\
    \ CA issues\n      a certificate. The additional qualifier is a certificate policy\n\
    \      for that CA. Each policy in a SET certificate may have these\n      qualifiers:\
    \ (a) a URL where a copy of the policy statement may be\n      found; (b) an electronic\
    \ mail address where a copy of the policy\n      statement may be found; (c) a\
    \ hash result of the policy statement,\n      computed using the indicated algorithm;\
    \ and (d) a statement\n      declaring any disclaimers associated with the issuing\
    \ of the\n      certificate.\n   $ SET Secure Electronic Transaction(trademark)\
    \ or SET(trademark)\n      (N) A protocol developed jointly by MasterCard International\
    \ and\n      Visa International and published as an open standard to provide\n\
    \      confidentiality of transaction information, payment integrity, and\n  \
    \    authentication of transaction participants for payment card\n      transactions\
    \ over unsecured networks, such as the Internet. [SET1]\n      (See: acquirer,\
    \ brand, cardholder, dual signature, electronic\n      commerce, IOTP, issuer,\
    \ merchant, payment gateway, third party.)\n      Tutorial: This term and acronym\
    \ are trademarks of SETCo.\n      MasterCard and Visa announced the SET standard\
    \ on 1 February 1996.\n   $ SETCo\n      (O) Abbreviation of \"SET Secure Electronic\
    \ Transaction LLC\",\n      formed on 19 December 1997 by MasterCard and Visa\
    \ for implementing\n      the SET Secure Electronic Transaction(trademark) standard.\
    \ A later\n      memorandum of understanding added American Express and JCB Credit\n\
    \      Card Company as co-owners of SETCo.\n   $ SHA, SHA-1, SHA-2\n      (N)\
    \ See: Secure Hash Algorithm.\n   $ shared identity\n      (I) See: secondary\
    \ definition under \"identity\".\n   $ shared secret\n      (D) Synonym for \"\
    cryptographic key\" or \"password\".\n      Deprecated Usage: IDOCs that use this\
    \ term SHOULD state a\n      definition for it because the term is used in many\
    \ ways and could\n      easily be misunderstood.\n   $ shielded enclosure\n  \
    \    (O) \"Room or container designed to attenuate electromagnetic\n      radiation,\
    \ acoustic signals, or emanations.\" [C4009] (See:\n      emanation. Compare:\
    \ SCIF.)\n   $ short title\n      (O) \"Identifying combination of letters and\
    \ numbers assigned to\n      certain items of COMSEC material to facilitate handling,\n\
    \      accounting, and controlling.\" [C4009] (Compare: KMID, long title.)\n \
    \  $ shroud\n      (D) /verb/ To encrypt a private key, possibly in concert with\
    \ a\n      policy that prevents the key from ever being available in\n      cleartext\
    \ form beyond a certain, well-defined security perimeter.\n      [PKC12] (See:\
    \ encrypt. Compare: seal, wrap.)\n      Deprecated Term: IDOCs SHOULD NOT use\
    \ this term as defined here;\n      the definition duplicates the meaning of other,\
    \ standard terms.\n      Instead, use \"encrypt\" or other terminology that is\
    \ specific with\n      regard to the mechanism being used.\n   $ SHS\n      (N)\
    \ See: Secure Hash Standard.\n   $ sign\n      (I) Create a digital signature\
    \ for a data object. (See: signer.)\n   $ signal analysis\n      (I) Gaining indirect\
    \ knowledge (inference) of communicated data by\n      monitoring and analyzing\
    \ a signal that is emitted by a system and\n      that contains the data but is\
    \ not intended to communicate the\n      data. (See: emanation. Compare: traffic\
    \ analysis.)\n   $ signal intelligence\n      (I) The science and practice of\
    \ extracting information from\n      signals. (See: signal security.)\n   $ signal\
    \ security\n      (N) (I) The science and practice of protecting signals. (See:\n\
    \      cryptology, security.)\n      Tutorial: The term \"signal\" denotes (a)\
    \ communication in almost\n      any form and also (b) emanations for other purposes,\
    \ such as\n      radar. Signal security is opposed by signal intelligence, and\
    \ each\n      discipline includes opposed sub-disciplines as follows [Kahn]:\n\
    \      Signal Security                 Signal Intelligence\n      ------------------------------\
    \  ---------------------------------\n      1. Communication Security       1.\
    \ Communication Intelligence\n         1a. Cryptography                1a. Cryptanalysis\n\
    \         1b. Traffic Security            1b. Traffic Analysis\n         1c. Steganography\
    \               1c. Detection and Interception\n      2. Electronic Security \
    \         2. Electronic Intelligence\n         2a. Emission Security         \
    \  2a. Electronic Reconnaissance\n         2b. Counter-Countermeasures     2b.\
    \ Countermeasures\n      ------------------------------  ---------------------------------\n\
    \   $ signature\n      (O) A symbol or process adopted or executed by a system\
    \ entity\n      with present intention to declare that a data object is genuine.\n\
    \      (See: digital signature, electronic signature.)\n   $ signature certificate\n\
    \      (I) A public-key certificate that contains a public key that is\n     \
    \ intended to be used for verifying digital signatures, rather than\n      for\
    \ encrypting data or performing other cryptographic functions.\n      Tutorial:\
    \ A v3 X.509 public-key certificate may have a \"keyUsage\"\n      extension that\
    \ indicates the purpose for which the certified\n      public key is intended.\
    \ (See: certificate profile.)\n   $ signed receipt\n      (I) An S/MIME service\
    \ [R2634] that (a) provides, to the originator\n      of a message, proof of delivery\
    \ of the message and (b) enables the\n      originator to demonstrate to a third\
    \ party that the recipient was\n      able to verify the signature of the original\
    \ message.\n      Tutorial: The receipt is bound to the original message by a\n\
    \      signature; consequently, the service may be requested only for a\n    \
    \  message that is signed. The receipt sender may optionally also\n      encrypt\
    \ the receipt to provide confidentiality between the receipt\n      sender and\
    \ the receipt recipient.\n   $ signer\n      (N) A human being or organization\
    \ entity that uses a private key\n      to sign (i.e., create a digital signature\
    \ on) a data object. [DSG]\n   $ SILS\n      (N) See: Standards for Interoperable\
    \ LAN/MAN Security.\n   $ simple authentication\n      1. (I) An authentication\
    \ process that uses a password as the\n      information needed to verify an identity\
    \ claimed for an entity.\n      (Compare: strong authentication.)\n      2. (O)\
    \ \"Authentication by means of simple password arrangements.\"\n      [X509]\n\
    \   $ Simple Authentication and Security Layer (SASL)\n      (I) An Internet specification\
    \ [R2222, R4422] for adding\n      authentication service to connection-based\
    \ protocols. (Compare:\n      EAP, GSS-API.)\n      Tutorial: To use SASL, a protocol\
    \ includes a command for\n      authenticating a user to a server and for optionally\
    \ negotiating\n      protection of subsequent protocol interactions. The command\
    \ names\n      a registered security mechanism. SASL mechanisms include Kerberos,\n\
    \      GSS-API, S/KEY, and others. Some protocols that use SASL are IMAP4\n  \
    \    and POP3.\n   $ Simple Key Management for Internet Protocols (SKIP)\n   \
    \   (I) A key-distribution protocol that uses hybrid encryption to\n      convey\
    \ session keys that are used to encrypt data in IP packets.\n      (See:  SKIP\
    \ reference in [R2356].)\n      Tutorial: SKIP was designed by Ashar Aziz and\
    \ Whitfield Diffie at\n      Sun Microsystems and proposed as the standard key\
    \ management\n      protocol for IPsec, but IKE was chosen instead. Although IKE\
    \ is\n      mandatory for an IPsec implementation, the use of SKIP is not\n  \
    \    excluded.\n      SKIP uses the Diffie-Hellman-Merkle algorithm (or could\
    \ use\n      another key-agreement algorithm) to generate a key-encrypting key\n\
    \      for use between two entities. A session key is used with a\n      symmetric\
    \ algorithm to encrypt data in one or more IP packets that\n      are to be sent\
    \ from one entity to the other. A symmetric KEK is\n      established and used\
    \ to encrypt the session key, and the encrypted\n      session key is placed in\
    \ a SKIP header that is added to each IP\n      packet that is encrypted with\
    \ that session key.\n   $ Simple Mail Transfer Protocol (SMTP)\n      (I) A TCP-based,\
    \ Application-Layer, Internet Standard protocol\n      (RFC 821) for moving electronic\
    \ mail messages from one computer to\n      another.\n   $ Simple Network Management\
    \ Protocol (SNMP)\n      (I) A (usually) UDP-based, Application-Layer, Internet\
    \ Standard\n      protocol (RFCs 3410-3418) for conveying management information\n\
    \      between system components that act as managers and agents.\n   $ Simple\
    \ Public Key Infrastructure (SPKI)\n      (I) A set of experimental concepts (RFCs\
    \ 2692, 2693) that were\n      proposed as alternatives to the concepts standardized\
    \ in PKIX.\n   $ simple security property\n      (N) /formal model/ Property of\
    \ a system whereby a subject has read\n      access to an object only if the clearance\
    \ of the subject dominates\n      the classification of the object. See: Bell-LaPadula\
    \ model.\n   $ single sign-on\n      1. (I) An authentication subsystem that enables\
    \ a user to access\n      multiple, connected system components (such as separate\
    \ hosts on a\n      network) after a single login at only one of the components.\
    \ (See:\n      Kerberos.)\n      2. (O) /Liberty Alliance/ A security subsystem\
    \ that enables a user\n      identity to be authenticated at an identity provider\
    \ -- i.e., at a\n      service that authenticates and asserts the user's identity\
    \ -- and\n      then have that authentication be honored by other service\n  \
    \    providers.\n      Tutorial: A single sign-on subsystem typically requires\
    \ a user to\n      log in once at the beginning of a session, and then during\
    \ the\n      session transparently grants access by the user to multiple,\n  \
    \    separately protected hosts, applications, or other system\n      resources,\
    \ without further login action by the user (unless, of\n      course, the user\
    \ logs out). Such a subsystem has the advantages of\n      being user friendly\
    \ and enabling authentication to be managed\n      consistently across an entire\
    \ enterprise. Such a subsystem also\n      has the disadvantage of requiring all\
    \ the accessed components to\n      depend on the security of the same authentication\
    \ information.\n   $ singular identity\n      (I) See: secondary definition under\
    \ \"identity\".\n   $ site\n      (I) A facility -- i.e., a physical space, room,\
    \ or building\n      together with its physical, personnel, administrative, and\
    \ other\n      safeguards -- in which system functions are performed. (See:\n\
    \      node.)\n   $ situation\n      (I) See: security situation.\n   $ SKEME\n\
    \      (I) A key-distribution protocol from which features were adapted\n    \
    \  for IKE. [SKEME]\n   $ SKIP\n      (I) See: Simple Key Management for Internet\
    \ Protocols.\n   $ SKIPJACK\n      (N) A type 2, 64-bit block cipher [SKIP, R2773]\
    \ with a key size of\n      80 bits. (See: CAPSTONE, CLIPPER, FORTEZZA, Key Exchange\n\
    \      Algorithm.)\n      Tutorial: SKIPJACK was developed by NSA and formerly\
    \ classified at\n      the U.S. DoD \"Secret\" level. On 23 June 1998, NSA announced\
    \ that\n      SKIPJACK had been declassified.\n   $ slot\n      (O) /MISSI/ One\
    \ of the FORTEZZA PC card storage areas that are\n      each able to hold an X.509\
    \ certificate plus other data, including\n      the private key that is associated\
    \ with a public-key certificate.\n   $ smart card\n      (I) A credit-card sized\
    \ device containing one or more integrated\n      circuit chips that perform the\
    \ functions of a computer's central\n      processor, memory, and input/output\
    \ interface. (See: PC card,\n      smart token.)\n      Usage: Sometimes this\
    \ term is used rather strictly to mean a card\n      that closely conforms to\
    \ the dimensions and appearance of the kind\n      of plastic credit card issued\
    \ by banks and merchants. At other\n      times, the term is used loosely to include\
    \ cards that are larger\n      than credit cards, especially cards that are thicker,\
    \ such as PC\n      cards.\n   $ smart token\n      (I) A device that conforms\
    \ to the definition of \"smart card\"\n      except that rather than having the\
    \ standard dimensions of a credit\n      card, the token is packaged in some other\
    \ form, such as a military\n      dog tag or a door key. (See: smart card, cryptographic\
    \ token.)\n   $ SMI\n      (I) See: security management infrastructure.\n   $\
    \ SMTP\n      (I) See: Simple Mail Transfer Protocol.\n   $ smurf attack\n   \
    \   (D) /slang/ A denial-of-service attack that uses IP broadcast\n      addressing\
    \ to send ICMP ping packets with the intent of flooding a\n      system. (See:\
    \ fraggle attack, ICMP flood.)\n      Deprecated Term: It is likely that other\
    \ cultures use different\n      metaphors for this concept. Therefore, to avoid\
    \ international\n      misunderstanding, IDOCs SHOULD NOT use this term.\n   \
    \   Derivation: The Smurfs are a fictional race of small, blue\n      creatures\
    \ that were created by a cartoonist. Perhaps the inventor\n      of this attack\
    \ thought that a swarm of ping packets resembled a\n      gang of smurfs. (See:\
    \ Deprecated Usage under \"Green Book\".)\n      Tutorial: The attacker sends\
    \ ICMP echo request (\"ping\") packets\n      that appear to originate not from\
    \ the attacker's own IP address,\n      but from the address of the host or router\
    \ that is the target of\n      the attack. Each packet is addressed to an IP broadcast\
    \ address,\n      e.g., to all IP addresses in a given network. Thus, each echo\n\
    \      request that is sent by the attacker results in many echo\n      responses\
    \ being sent to the target address. This attack can\n      disrupt service at\
    \ a particular host, at the hosts that depend on\n      a particular router, or\
    \ in an entire network.\n   $ sneaker net\n      (D) /slang/ A process that transfers\
    \ data between systems only\n      manually, under human control; i.e., a data\
    \ transfer process that\n      involves an air gap.\n      Deprecated Term: It\
    \ is likely that other cultures use different\n      metaphors for this concept.\
    \ Therefore, to avoid international\n      misunderstanding, IDOCs SHOULD NOT\
    \ use this term.\n   $ Snefru\n      (N) A public-domain, cryptographic hash function\
    \ (a.k.a. \"The\n      Xerox Secure Hash Function\") designed by Ralph C. Merkle\
    \ at Xerox\n      Corporation. Snefru can produce either a 128-bit or 256-bit\
    \ output\n      (i.e., hash result). [Schn] (See: Khafre, Khufu.)\n   $ sniffing\n\
    \      (D) /slang/ Synonym for \"passive wiretapping\"; most often refers\n  \
    \    to capturing and examining the data packets carried on a LAN.\n      (See:\
    \ password sniffing.)\n      Deprecated Term: IDOCs SHOULD NOT use this term;\
    \ it unnecessarily\n      duplicates the meaning of a term that is better established.\
    \ (See:\n      Deprecated Usage under \"Green Book\".\n   $ SNMP\n      (I) See:\
    \ Simple Network Management Protocol.\n   $ social engineering\n      (D) Euphemism\
    \ for non-technical or low-technology methods, often\n      involving trickery\
    \ or fraud, that are used to attack information\n      systems. Example: phishing.\n\
    \      Deprecated Term: IDOCs SHOULD NOT use this term; it is too vague.\n   \
    \   Instead, use a term that is specific with regard to the means of\n      attack,\
    \ e.g., blackmail, bribery, coercion, impersonation,\n      intimidation, lying,\
    \ or theft.\n   $ SOCKS\n      (I) An Internet protocol [R1928] that provides\
    \ a generalized proxy\n      server that enables client-server applications (e.g.,\
    \ TELNET, FTP,\n      or HTTP; running over either TCP or UDP) to use the services\
    \ of a\n      firewall.\n      Tutorial: SOCKS is layered under the IPS Application\
    \ Layer and\n      above the Transport Layer. When a client inside a firewall\
    \ wishes\n      to establish a connection to an object that is reachable only\n\
    \      through the firewall, it uses TCP to connect to the SOCKS server,\n   \
    \   negotiates with the server for the authentication method to be\n      used,\
    \ authenticates with the chosen method, and then sends a relay\n      request.\
    \ The SOCKS server evaluates the request, typically based\n      on source and\
    \ destination addresses, and either establishes the\n      appropriate connection\
    \ or denies it.\n   $ soft TEMPEST\n      (O) The use of software techniques to\
    \ reduce the radio frequency\n      information leakage from computer displays\
    \ and keyboards. [Kuhn]\n      (See: TEMPEST.)\n   $ soft token\n      (D) A data\
    \ object that is used to control access or authenticate\n      authorization.\
    \ (See: token.)\n      Deprecated Term: IDOCs SHOULD NOT use this term as defined\
    \ here;\n      the definition duplicates the meaning of other, standard terms.\n\
    \      Instead, use \"attribute certificate\" or another term that is\n      specific\
    \ with regard to the mechanism being used.\n   $ software\n      (I) Computer\
    \ programs (which are stored in and executed by\n      computer hardware) and\
    \ associated data (which also is stored in\n      the hardware) that may be dynamically\
    \ written or modified during\n      execution. (Compare: firmware.)\n   $ software\
    \ error\n      (I) /threat action/ See: secondary definitions under \"corruption\"\
    ,\n      \"exposure\", and \"incapacitation\".\n   $ SORA\n      (O) See: SSO-PIN\
    \ ORA.\n   $ source authentication\n      (D) Synonym for \"data origin authentication\"\
    \ or \"peer entity\n      authentication\". (See: data origin authentication,\
    \ peer entity\n      authentication).\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use this term because it is\n      ambiguous and, in either meaning, duplicates\
    \ the meaning of\n      internationally standardized terms. If the intent is to\n\
    \      authenticate the original creator or packager of data received,\n     \
    \ then use \"data origin authentication\". If the intent is to\n      authenticate\
    \ the identity of the sender of data in the current\n      instance, then use\
    \ \"peer entity authentication\".\n   $ source integrity\n      (I) The property\
    \ that data is trustworthy (i.e., worthy of\n      reliance or trust), based on\
    \ the trustworthiness of its sources\n      and the trustworthiness of any procedures\
    \ used for handling data\n      in the system. Usage: a.k.a. Biba integrity. (See:\
    \ integrity.\n      Compare: correctness integrity, data integrity.)\n      Tutorial:\
    \ For this kind of integrity, there are formal models of\n      unauthorized modification\
    \ (see: Biba model) that logically\n      complement the more familiar models\
    \ of unauthorized disclosure\n      (see: Bell-LaPadula model). In these models,\
    \ objects are labeled\n      to indicate the credibility of the data they contain,\
    \ and there\n      are rules for access control that depend on the labels.\n \
    \  $ SP3\n      (O) See: Security Protocol 3.\n   $ SP4\n      (O) See: Security\
    \ Protocol 4.\n   $ spam\n      1a. (I) /slang verb/ To indiscriminately send\
    \ unsolicited,\n      unwanted, irrelevant, or inappropriate messages, especially\n\
    \      commercial advertising in mass quantities.\n      1b. (I) /slang noun/\
    \ Electronic \"junk mail\". [R2635]\n      Deprecated Usage: IDOCs SHOULD NOT\
    \ use this term in uppercase\n      letters, because SPAM(trademark) is a trademark\
    \ of Hormel Foods\n      Corporation. Hormel says, \"We do not object to use of\
    \ this slang\n      term [spam] to describe [unsolicited advertising email], although\n\
    \      we do object to the use of our product image in association with\n    \
    \  that term. Also, if the term is to be used, it SHOULD be used in\n      all\
    \ lower-case letters to distinguish it from our trademark SPAM,\n      which SHOULD\
    \ be used with all uppercase letters.\" (See: metadata.)\n      Tutorial: In sufficient\
    \ volume, spam can cause denial of service.\n      (See: flooding.) According\
    \ to Hormel, the term was adopted as a\n      result of a Monty Python skit in\
    \ which a group of Vikings sang a\n      chorus of 'SPAM, SPAM, SPAM ...' in an\
    \ increasing crescendo,\n      drowning out other conversation. This lyric became\
    \ a metaphor for\n      the unsolicited advertising messages that threaten to\
    \ overwhelm\n      other discourse on the Internet.\n   $ SPD\n      (I) See:\
    \ Security Policy Database.\n   $ special access program (SAP)\n      (O) /U.S.\
    \ Government/ \"Sensitive program, [that is] approved in\n      writing by a head\
    \ of agency with [i.e., who has] original top\n      secret classification authority,\
    \ [and] that imposes need-to-know\n      and access controls beyond those normally\
    \ provided for access to\n      Confidential, Secret, or Top Secret information.\
    \ The level of\n      controls is based on the criticality of the program and\
    \ the\n      assessed hostile intelligence threat. The program may be an\n   \
    \   acquisition program, an intelligence program, or an operations and\n     \
    \ support program.\" [C4009] (See: formal access approval, SCI.\n      Compare:\
    \ collateral information.)\n   $ SPI\n      (I) See: Security Parameters Index.\n\
    \   $ SPKI\n      (I) See: Simple Public Key Infrastructure.\n   $ split key\n\
    \      (I) A cryptographic key that is generated and distributed as two\n    \
    \  or more separate data items that individually convey no knowledge\n      of\
    \ the whole key that results from combining the items. (See: dual\n      control,\
    \ split knowledge.)\n   $ split knowledge\n      1. (I) A security technique in\
    \ which two or more entities\n      separately hold data items that individually\
    \ do not convey\n      knowledge of the information that results from combining\
    \ the\n      items. (See: dual control, split key.)\n      2. (O) \"A condition\
    \ under which two or more entities separately\n      have key components [that]\
    \ individually convey no knowledge of the\n      plaintext key [that] will be\
    \ produced when the key components are\n      combined in the cryptographic module.\"\
    \ [FP140]\n   $ spoof\n      (I) /threat action/ See: secondary definition under\
    \ \"masquerade\".\n   $ spoofing attack\n      (I) Synonym for \"masquerade attack\"\
    .\n   $ spread spectrum\n      (N) A TRANSEC technique that transmits a signal\
    \ in a bandwidth\n      much greater than the transmitted information needs. [F1037]\n\
    \      Example: frequency hopping.\n      Tutorial: Usually uses a sequential,\
    \ noise-like signal structure\n      to spread the normally narrowband information\
    \ signal over a\n      relatively wide band of frequencies. The receiver correlates\
    \ the\n      signals to retrieve the original information signal. This\n     \
    \ technique decreases potential interference to other receivers,\n      while\
    \ achieving data confidentiality and increasing immunity of\n      spread spectrum\
    \ receivers to noise and interference.\n   $ spyware\n      (D) /slang/ Software\
    \ that an intruder has installed\n      surreptitiously on a networked computer\
    \ to gather data from that\n      computer and send it through the network to\
    \ the intruder or some\n      other interested party. (See: malicious logic, Trojan\
    \ horse.)\n      Deprecated Usage: IDOCs that use this term SHOULD state a\n \
    \     definition for it because the term is used in many ways and could\n    \
    \  easily be misunderstood.\n      Tutorial: Some examples of the types of data\
    \ that might be\n      gathered by spyware are application files, passwords, email\n\
    \      addresses, usage histories, and keystrokes. Some examples of\n      motivations\
    \ for gathering the data are blackmail, financial fraud,\n      identity theft,\
    \ industrial espionage, market research, and\n      voyeurism.\n   $ SSH(trademark)\n\
    \      (N) See: Secure Shell(trademark).\n   $ SSL\n      (I) See: Secure Sockets\
    \ Layer.\n   $ SSO\n      (I) See: system security officer.\n   $ SSO PIN\n  \
    \    (O) /MISSI/ One of two PINs that control access to the functions\n      and\
    \ stored data of a FORTEZZA PC card. Knowledge of the SSO PIN\n      enables a\
    \ card user to perform the FORTEZZA functions intended for\n      use by an end\
    \ user and also the functions intended for use by a\n      MISSI CA. (See: user\
    \ PIN.)\n   $ SSO-PIN ORA (SORA)\n      (O) /MISSI/ A MISSI organizational RA\
    \ that operates in a mode in\n      which the ORA performs all card management\
    \ functions and,\n      therefore, requires knowledge of the SSO PIN for FORTEZZA\
    \ PC cards\n      issued to end users.\n   $ Standards for Interoperable LAN/MAN\
    \ Security (SILS)\n      1. (N) The IEEE 802.10 standards committee. (See: [FP191].)\n\
    \      2. (N) A set of IEEE standards, which has eight parts: (a) Model,\n   \
    \   including security management, (b) Secure Data Exchange protocol,\n      (c)\
    \ Key Management, (d) [has been incorporated in (a)], (e) SDE\n      Over Ethernet\
    \ 2.0, (f) SDE Sublayer Management, (g) SDE Security\n      Labels, and (h) SDE\
    \ PICS Conformance. Parts b, e, f, g, and h are\n      incorporated in IEEE Standard\
    \ 802.10-1998.\n   $ star property\n      (N) See: *-property.\n   $ Star Trek\
    \ attack\n      (D) /slang/ An attack that penetrates your system where no attack\n\
    \      has ever gone before.\n      Deprecated Usage: IDOCs SHOULD NOT use this\
    \ term; it is a joke for\n      Trekkies. (See: Deprecated Usage under \"Green\
    \ Book\".)\n   $ static\n      (I) /adjective/ Refers to a cryptographic key or\
    \ other parameter\n      that is relatively long-lived. (Compare: ephemeral.)\n\
    \   $ steganography\n      (I) Methods of hiding the existence of a message or\
    \ other data.\n      This is different than cryptography, which hides the meaning\
    \ of a\n      message but does not hide the message itself. Examples: For\n  \
    \    classic, physical methods, see [Kahn]; for modern, digital\n      methods,\
    \ see [John]. (See: cryptology. Compare: concealment\n      system, digital watermarking.)\n\
    \   $ storage channel\n      (I) See: covert storage channel.\n   $ storage key\n\
    \      (I) A cryptographic key used by a device for protecting\n      information\
    \ that is being maintained in the device, as opposed to\n      protecting information\
    \ that is being transmitted between devices.\n      (See: cryptographic token,\
    \ token copy. Compare: traffic key.)\n   $ stream cipher\n      (I) An encryption\
    \ algorithm that breaks plain text into a stream\n      of successive elements\
    \ (usually, bits) and encrypts the n-th\n      plaintext element with the n-th\
    \ element of a parallel key stream,\n      thus converting the plaintext stream\
    \ into a ciphertext stream.\n      [Schn] (See: block cipher.)\n   $ stream integrity\
    \ service\n      (I) A data integrity service that preserves integrity for a\n\
    \      sequence of data packets, including both (a) bit-by-bit datagram\n    \
    \  integrity of each individual packet in the set and (b) packet-by-\n      packet\
    \ sequential integrity of the set as a whole. (See: data\n      integrity. Compare:\
    \ datagram integrity service.)\n      Tutorial: Some internetwork applications\
    \ need only datagram\n      integrity, but others require that an entire stream\
    \ of packets be\n      protected against insertion, reordering, deletion, and\
    \ delay:\n      -  \"Insertion\": The destination receives an additional packet\
    \ that\n         was not sent by the source.\n      -  \"Reordering\": The destination\
    \ receives packets in a different\n         order than that in which they were\
    \ sent by the source.\n      -  \"Deletion\": A packet sent by the source is not\
    \ ever delivered\n         to the intended destination.\n      -  \"Delay\": A\
    \ packet is detained for some period of time at a\n         relay, thus hampering\
    \ and postponing the packet's normal timely\n         delivery from source to\
    \ destination.\n   $ strength\n      1. (I) /cryptography/ A cryptographic mechanism's\
    \ level of\n      resistance to attacks [R3766]. (See: entropy, strong, work\n\
    \      factor.)\n      2. (N) /Common Criteria/ \"Strength of function\" is a\n\
    \      \"qualification of a TOE security function expressing the minimum\n   \
    \   efforts assumed necessary to defeat its expected security behavior\n     \
    \ by directly attacking its underlying security mechanisms\": (See:\n      strong.)\n\
    \      -  Basic: \"A level of the TOE strength of function where analysis\n  \
    \       shows that the function provides adequate protection against\n       \
    \  casual breach of TOE security by attackers possessing a low\n         attack\
    \ potential.\"\n      -  Medium: \"... against straightforward or intentional\
    \ breach ...\n         by attackers possessing a moderate attack potential.\"\n\
    \      -  High: \"... against deliberately planned or organized breach ...\n \
    \        by attackers possessing a high attack potential.\"\n   $ strong\n   \
    \   1. (I) /cryptography/ Used to describe a cryptographic algorithm\n      that\
    \ would require a large amount of computational power to defeat\n      it. (See:\
    \ strength, work factor, weak key.)\n      2. (I) /COMPUSEC/ Used to describe\
    \ a security mechanism that would\n      be difficult to defeat. (See: strength,\
    \ work factor.)\n   $ strong authentication\n      1. (I) An authentication process\
    \ that uses a cryptographic\n      security mechanism -- particularly public-key\
    \ certificates -- to\n      verify the identity claimed for an entity. (Compare:\
    \ simple\n      authentication.)\n      2. (O) \"Authentication by means of cryptographically\
    \ derived\n      credentials.\" [X509]\n   $ subject\n      1a. (I) A process\
    \ in a computer system that represents a principal\n      and that executes with\
    \ the privileges that have been granted to\n      that principal. (Compare: principal,\
    \ user.)\n      1b. (I) /formal model/ A system entity that causes information\
    \ to\n      flow among objects or changes the system state; technically, a\n \
    \     process-domain pair. A subject may itself be an object relative to\n   \
    \   some other subject; thus, the set of subjects in a system is a\n      subset\
    \ of the set of objects. (See: Bell-LaPadula model, object.)\n      2. (I) /digital\
    \ certificate/ The name (of a system entity) that is\n      bound to the data\
    \ items in a digital certificate; e.g., a DN that\n      is bound to a key in\
    \ a public-key certificate. (See: X.509.)\n   $ subject CA\n      (D) The CA that\
    \ is the subject of a cross-certificate issued by\n      another CA. [X509] (See:\
    \ cross-certification.)\n      Deprecated Term: IDOCs SHOULD NOT use this term\
    \ because it is not\n      widely known and could be misunderstood. Instead, say\
    \ \"the CA that\n      is the subject of the cross-certificate\".\n   $ subnetwork\n\
    \      (N) An OSI term for a system of packet relays and connecting links\n  \
    \    that implement OSIRM layer 2 or 3 to provide a communication\n      service\
    \ that interconnects attached end systems. Usually, the\n      relays are all\
    \ of the same type (e.g., X.25 packet switches, or\n      interface units in an\
    \ IEEE 802.3 LAN). (See: gateway, internet,\n      router.)\n   $ subordinate\
    \ CA (SCA)\n      1. (I) A CA whose public-key certificate is issued by another\n\
    \      (superior) CA. (See: certification hierarchy. Compare: cross-\n      certification.)\n\
    \      2. (O) /MISSI/ The fourth-highest (i.e., bottom) level of a MISSI\n   \
    \   certification hierarchy; a MISSI CA whose public-key certificate\n      is\
    \ signed by a MISSI CA rather than by a MISSI PCA. A MISSI SCA is\n      the administrative\
    \ authority for a subunit of an organization,\n      established when it is desirable\
    \ to organizationally distribute or\n      decentralize the CA service. The term\
    \ refers both to that\n      authoritative office or role, and to the person who\
    \ fills that\n      office. A MISSI SCA registers end users and issues their\n\
    \      certificates and may also register ORAs, but may not register\n      other\
    \ CAs. An SCA periodically issues a CRL.\n   $ subordinate DN\n      (I) An X.500\
    \ DN is subordinate to another X.500 DN if it begins\n      with a set of attributes\
    \ that is the same as the entire second DN\n      except for the terminal attribute\
    \ of the second DN (which is\n      usually the name of a CA). For example, the\
    \ DN <C=FooLand, O=Gov,\n      OU=Treasurer, CN=DukePinchpenny> is subordinate\
    \ to the DN\n      <C=FooLand, O=Gov, CN=KingFooCA>.\n   $ subscriber\n      (I)\
    \ /PKI/ A user that is registered in a PKI and, therefore, can\n      be named\
    \ in the \"subject\" field of a certificate issued by a CA in\n      that PKI.\
    \ (See: registration, user.)\n      Usage: This term is needed to distinguish\
    \ registered users from\n      two other kinds of PKI users:\n      -  Users that\
    \ access the PKI but are not identified to it: For\n         example, a relying\
    \ party may access a PKI repository to obtain\n         the certificate of some\
    \ other party. (See: access.)\n      -  Users that do not access the PKI: For\
    \ example, a relying party\n         (see: certificate user) may use a digital\
    \ certificate that was\n         obtained from a database that is not part of\
    \ the PKI that\n         issued the certificate.\n   $ substitution\n      1.\
    \ (I) /cryptography/ A method of encryption in which elements of\n      the plain\
    \ text retain their sequential position but are replaced\n      by elements of\
    \ cipher text. (Compare: transposition.)\n      2. (I) /threat action/ See: secondary\
    \ definition under\n      \"falsification\".\n   $ subsystem\n      (I) A collection\
    \ of related system components that together\n      perform a system function\
    \ or deliver a system service.\n   $ superencryption\n      (I) An encryption\
    \ operation for which the plaintext input to be\n      transformed is the ciphertext\
    \ output of a previous encryption\n      operation. (Compare: hybrid encryption.)\n\
    \   $ superuser\n      (I) /UNIX/ Synonym for \"root\".\n   $ survivability\n\
    \      (I) The ability of a system to remain in operation or existence\n     \
    \ despite adverse conditions, including natural occurrences,\n      accidental\
    \ actions, and attacks. (Compare: availability,\n      reliability.)\n   $ swIPe\n\
    \      (I) An encryption protocol for IP that provides confidentiality,\n    \
    \  integrity, and authentication and can be used for both end-to-end\n      and\
    \ intermediate-hop security. [Ioan] (Compare: IPsec.)\n      Tutorial: The swIPe\
    \ protocol is an IP predecessor that is\n      concerned only with encryption\
    \ mechanisms; policy and key\n      management are handled outside the protocol.\n\
    \   $ syllabary\n      (N) /encryption/ A list of individual letters, combinations\
    \ of\n      letters, or syllables, with their equivalent code groups, used for\n\
    \      spelling out proper names or other unusual words that are not\n      present\
    \ in the basic vocabulary (i.e., are not in the codebook) of\n      a code used\
    \ for encryption.\n   $ symmetric cryptography\n      (I) A branch of cryptography\
    \ in which the algorithms use the same\n      key for both of two counterpart\
    \ cryptographic operations (e.g.,\n      encryption and decryption). (See: asymmetric\
    \ cryptography.\n      Compare: secret-key cryptography.)\n      Tutorial: Symmetric\
    \ cryptography has been used for thousands of\n      years [Kahn]. A modern example\
    \ is AES.\n      Symmetric cryptography has a disadvantage compared to asymmetric\n\
    \      cryptography with regard to key distribution. For example, when\n     \
    \ Alice wants to ensure confidentiality for data she sends to Bob,\n      she\
    \ encrypts the data with a key, and Bob uses the same key to\n      decrypt. However,\
    \ keeping the shared key secret entails both cost\n      and risk when the key\
    \ is distributed to both Alice and Bob. (See:\n      key distribution, key management.)\n\
    \   $ symmetric key\n      (I) A cryptographic key that is used in a symmetric\
    \ cryptographic\n      algorithm. (See: symmetric cryptography.)\n   $ SYN flood\n\
    \      (I) A denial-of-service attack that sends a large number of TCP\n     \
    \ SYN (synchronize) packets to a host with the intent of disrupting\n      the\
    \ operation of that host. (See: blind attack, flooding.)\n      Tutorial: This\
    \ attack seeks to exploit a vulnerability in the TCP\n      specification or in\
    \ a TCP implementation. Normally, two hosts use\n      a three-way exchange of\
    \ packets to establish a TCP connection: (a)\n      host 1 requests a connection\
    \ by sending a SYN packet to host 2;\n      (b) host 2 replies by sending a SYN-ACK\
    \ (acknowledgement) packet\n      to host 1; and (c) host 1 completes the connection\
    \ by sending an\n      ACK packet to host 2. To attack host 2, host 1 can send\
    \ a series\n      of TCP SYNs, each with a different phony source address. ([R2827]\n\
    \      discusses how to use packet filtering to prevent such attacks from\n  \
    \    being launched from behind an Internet service provider's\n      aggregation\
    \ point.) Host 2 treats each SYN as a request from a\n      separate host, replies\
    \ to each with a SYN-ACK, and waits to\n      receive the matching ACKs. (The\
    \ attacker can use random or\n      unreachable sources addresses in the SYN packets,\
    \ or can use\n      source addresses that belong to third parties, that then become\n\
    \      secondary victims.)\n      For each SYN-ACK that is sent, the TCP process\
    \ in host 2 needs\n      some memory space to store state information while waiting\
    \ for the\n      matching ACK to be returned. If the matching ACK never arrives\
    \ at\n      host 2, a timer associated with the pending SYN-ACK will\n      eventually\
    \ expire and release the space. But if host 1 (or a\n      cooperating group of\
    \ hosts) can rapidly send many SYNs to host 2,\n      host 2 will need to store\
    \ state information for many pending SYN-\n      ACKs and may run out of space.\
    \ This can prevent host 2 from\n      responding to legitimate connection requests\
    \ from other hosts or\n      even, if there are flaws in host 2's TCP implementation,\
    \ crash\n      when the available space is exhausted.\n   $ synchronization\n\
    \      (I) Any technique by which a receiving (decrypting) cryptographic\n   \
    \   process attains an internal state that matches the transmitting\n      (encrypting)\
    \ process, i.e., has the appropriate keying material to\n      process the cipher\
    \ text and is correctly initialized to do so.\n   $ system\n      (I) Synonym\
    \ for \"information system\".\n      Usage: This is a generic definition, and\
    \ is the one with which the\n      term is used in this Glossary. However, IDOCs\
    \ that use the term,\n      especially IDOCs that are protocol specifications,\
    \ SHOULD state a\n      more specific definition. Also, IDOCs that specify security\n\
    \      features, services, and assurances need to define which system\n      components\
    \ and system resources are inside the applicable security\n      perimeter and\
    \ which are outside. (See: security architecture.)\n   $ system architecture\n\
    \      (N) The structure of system components, their relationships, and\n    \
    \  the principles and guidelines governing their design and evolution\n      over\
    \ time. [DoD10] (Compare: security architecture.)\n   $ system component\n   \
    \   1. (I) A collection of system resources that (a) forms a physical\n      or\
    \ logical part of the system, (b) has specified functions and\n      interfaces,\
    \ and (c) is treated (e.g., by policies or\n      specifications) as existing\
    \ independently of other parts of the\n      system. (See: subsystem.)\n     \
    \ 2. (O) /ITSEC/ An identifiable and self-contained part of a TOE.\n      Usage:\
    \ Component is a relative term because components may be\n      nested; i.e.,\
    \ one component of a system may be a part of another\n      component of that\
    \ system.\n      Tutorial: Components can be characterized as follows:\n     \
    \ -  A \"physical component\" has mass and takes up space.\n      -  A \"logical\
    \ component\" is an abstraction used to manage and\n         coordinate aspects\
    \ of the physical environment, and typically\n         represents a set of states\
    \ or capabilities of the system.\n   $ system entity\n      (I) An active part\
    \ of a system -- a person, a set of persons\n      (e.g., some kind of organization),\
    \ an automated process, or a set\n      of processes (see: subsystem) -- that\
    \ has a specific set of\n      capabilities. (Compare: subject, user.)\n   $ system\
    \ high\n      (I) The highest security level at which a system operates, or is\n\
    \      capable of operating, at a particular time or in a particular\n      environment.\
    \ (See: system-high security mode.)\n   $ system-high security mode\n      (I)\
    \ A mode of system operation wherein all users having access to\n      the system\
    \ possess all necessary authorizations (both security\n      clearance and formal\
    \ access approval) for all data handled by the\n      system, but some users might\
    \ not have need-to-know for all the\n      data. (See: /system operation/ under\
    \ \"mode\", formal access\n      approval, protection level, security clearance.)\n\
    \      Usage: Usually abbreviated as \"system-high mode\". This mode was\n   \
    \   defined in U.S. DoD policy that applied to system accreditation,\n      but\
    \ the term is widely used outside the Government.\n   $ system integrity\n   \
    \   1. (I) An attribute or quality \"that a system has when it can\n      perform\
    \ its intended function in a unimpaired manner, free from\n      deliberate or\
    \ inadvertent unauthorized manipulation.\" [C4009,\n      NCS04] (See: recovery,\
    \ system integrity service.)\n      2. (D) \"Quality of an [information system]\
    \ reflecting the logical\n      correctness and reliability of the operating system;\
    \ the logical\n      completeness of the hardware and software implementing the\n\
    \      protection mechanisms; and the consistency of the data structures\n   \
    \   and occurrence of the stored data.\" [from an earlier version of\n      C4009]\n\
    \      Deprecated Definition: IDOCs SHOULD NOT use definition 2 because\n    \
    \  it mixes several concepts in a potentially misleading way.\n      Instead,\
    \ IDOCs should use the term with definition 1 and,\n      depending on what is\
    \ meant, couple the term with additional, more\n      specifically descriptive\
    \ and informative terms, such as\n      \"correctness\", \"reliability\", and\
    \ \"data integrity\".\n   $ system integrity service\n      (I) A security service\
    \ that protects system resources in a\n      verifiable manner against unauthorized\
    \ or accidental change, loss,\n      or destruction. (See: system integrity.)\n\
    \   $ system low\n      (I) The lowest security level supported by a system at\
    \ a\n      particular time or in a particular environment. (Compare: system\n\
    \      high.)\n   $ system resource\n      (I) Data contained in an information\
    \ system; or a service provided\n      by a system; or a system capacity, such\
    \ as processing power or\n      communication bandwidth; or an item of system\
    \ equipment (i.e.,\n      hardware, firmware, software, or documentation); or\
    \ a facility\n      that houses system operations and equipment. (See: system\n\
    \      component.)\n   $ system security officer (SSO)\n      (I) A person responsible\
    \ for enforcement or administration of the\n      security policy that applies\
    \ to a system. (Compare: manager,\n      operator.)\n   $ system user\n      (I)\
    \ A system entity that consumes a product or service provided by\n      the system,\
    \ or that accesses and employs system resources to\n      produce a product or\
    \ service of the system. (See: access, [R2504].\n      Compare: authorized user,\
    \ manager, operator, principal, privileged\n      user, subject, subscriber, system\
    \ entity, unauthorized user.)\n      Usage: IDOCs that use this term SHOULD state\
    \ a definition for it\n      because the term is used in many ways and could easily\
    \ be\n      misunderstood:\n      -  This term usually refers to an entity that\
    \ has been authorized\n         to access the system, but the term sometimes is\
    \ used without\n         regard for whether access is authorized.\n      -  This\
    \ term usually refers to a living human being acting either\n         personally\
    \ or in an organizational role. However, the term also\n         may refer to\
    \ an automated process in the form of hardware,\n         software, or firmware;\
    \ to a set of persons; or to a set of\n         processes.\n      -  IDOCs SHOULD\
    \ NOT use the term to refer to a mixed set\n         containing both persons and\
    \ processes. This exclusion is\n         intended to prevent situations that might\
    \ cause a security\n         policy to be interpreted in two different and conflicting\
    \ ways.\n      A system user can be characterized as direct or indirect:\n   \
    \   -  \"Passive user\": A system entity that is (a) outside the\n         system's\
    \ security perimeter *and* (b) can receive output from\n         the system but\
    \ cannot provide input or otherwise interact with\n         the system.\n    \
    \  -  \"Active user\": A system entity that is (a) inside the system's\n     \
    \    security perimeter *or* (b) can provide input or otherwise\n         interact\
    \ with the system.\n   $ TACACS\n      (I) See: Terminal Access Controller (TAC)\
    \ Access Control System.\n   $ TACACS+\n      (I) A TCP-based protocol that improves\
    \ on TACACS by separating the\n      functions of authentication, authorization,\
    \ and accounting and by\n      encrypting all traffic between the network access\
    \ server and\n      authentication server. TACACS+ is extensible to allow any\n\
    \      authentication mechanism to be used with TACACS+ clients.\n   $ tamper\n\
    \      (I) Make an unauthorized modification in a system that alters the\n   \
    \   system's functioning in a way that degrades the security services\n      that\
    \ the system was intended to provide. (See: QUADRANT. Compare:\n      secondary\
    \ definitions under \"corruption\" and \"misuse\".)\n   $ tamper-evident\n   \
    \   (I) A characteristic of a system component that provides evidence\n      that\
    \ an attack has been attempted on that component or system.\n      Usage: Usually\
    \ involves physical evidence. (See: tamper.)\n   $ tamper-resistant\n      (I)\
    \ A characteristic of a system component that provides passive\n      protection\
    \ against an attack. (See: tamper.)\n      Usage: Usually involves physical means\
    \ of protection.\n   $ tampering\n      (I) /threat action/ See: secondary definitions\
    \ under \"corruption\"\n      and \"misuse\".\n   $ target of evaluation (TOE)\n\
    \      (N) /Common Criteria/ An information technology product or system\n   \
    \   that is the subject of a security evaluation, together with the\n      product's\
    \ associated administrator and user documentation.\n      (Compare: protection\
    \ profile.)\n      Tutorial: The security characteristics of the target of evaluation\n\
    \      (TOE) are described in specific terms by a corresponding security\n   \
    \   target, or in more general terms by a protection profile. In\n      Common\
    \ Criteria philosophy, it is important that a TOE be\n      evaluated against\
    \ the specific set of criteria expressed in the\n      target. This evaluation\
    \ consists of rigorous analysis and testing\n      performed by an accredited,\
    \ independent laboratory. The scope of a\n      TOE evaluation is set by the EAL\
    \ and other requirements specified\n      in the target. Part of this process\
    \ is an evaluation of the target\n      itself, to ensure that it is correct,\
    \ complete, and internally\n      consistent and can be used as the baseline for\
    \ the TOE evaluation.\n   $ TCB\n      (N) See: trusted computing base.\n   $\
    \ TCC field\n      (I) See: Transmission Control Code field.\n   $ TCG\n     \
    \ (N) See: Trusted Computing Group.\n   $ TCP\n      (I) See: Transmission Control\
    \ Protocol.\n   $ TCP/IP\n      (I) Synonym for \"Internet Protocol Suite\".\n\
    \   $ TCSEC\n      (N) See: Trusted Computer System Evaluation Criteria. (Compare:\n\
    \      TSEC.)\n   $ TDEA\n      (I) See: Triple Data Encryption Algorithm.\n \
    \  $ teardrop attack\n      (D) /slang/ A denial-of-service attack that sends\
    \ improperly\n      formed IP packet fragments with the intent of causing the\n\
    \      destination system to fail.\n      Deprecated Term: IDOCs that use this\
    \ term SHOULD state a\n      definition for it because the term is often used\
    \ imprecisely and\n      could easily be misunderstood. (See: Deprecated Usage\
    \ under \"Green\n      Book\".)\n   $ technical non-repudiation\n      (I) See:\
    \ (secondary definition under) non-repudiation.\n   $ technical security\n   \
    \   (I) Security mechanisms and procedures that are implemented in and\n     \
    \ executed by computer hardware, firmware, or software to provide\n      automated\
    \ protection for a system. (See: security architecture.\n      Compare: administrative\
    \ security.)\n   $ Telecommunications Security Word System (TSEC)\n      (O) /U.S.\
    \ Government/ A terminology for designating\n      telecommunication security\
    \ equipment. (Compare: TCSEC.)\n      Tutorial: A TSEC designator has the following\
    \ parts:\n      -  Prefix \"TSEC/\" for items and systems, or suffix \"/TSEC\"\
    \ for\n         assemblies. (Often omitted when the context is clear.)\n     \
    \ -  First letter, for function: \"C\" COMSEC equipment system, \"G\"\n      \
    \   general purpose, \"K\" cryptographic, \"H\" crypto-ancillary, \"M\"\n    \
    \     manufacturing, \"N\" noncryptographic, \"S\" special purpose.\n      - \
    \ Second letter, for type or purpose: \"G\" key generation, \"I\"\n         data\
    \ transmission, \"L\" literal conversion, \"N\" signal\n         conversion, \"\
    O\" multipurpose, \"P\" materials production, \"S\"\n         special purpose,\
    \ \"T\" testing or checking, \"U\" television, \"W\"\n         teletypewriter,\
    \ \"X\" facsimile, \"Y\" speech.\n      -  Optional third letter, used only in\
    \ designations of assemblies,\n         for type or purpose: \"A\" advancing,\
    \ \"B\" base or cabinet, \"C\"\n         combining, \"D\" drawer or panel, \"\
    E\" strip or chassis, \"F\" frame\n         or rack, \"G\" key generator, \"H\"\
    \ keyboard, \"I\" translator or\n         reader, \"J\" speech processing, \"\
    K\" keying or permuting, \"L\"\n         repeater, \"M\" memory or storage, \"\
    O\" observation, \"P\" power\n         supply or converter, \"R\" receiver, \"\
    S\" synchronizing, \"T\"\n         transmitter, \"U\" printer, \"V\" removable\
    \ COMSEC component, \"W\"\n         logic programmer/programming, \"X\" special\
    \ purpose.\n      -  Model number, usually two or three digits, assigned\n   \
    \      sequentially within each letter combination (e.g., KG-34, KG-\n       \
    \  84).\n      -  Optional suffix letter, used to designate a version. First\n\
    \         version has no letter, next version has \"A\" (e.g., KG-84, KG-\n  \
    \       84A), etc.\n   $ TELNET\n      (I) A TCP-based, Application-Layer, Internet\
    \ Standard protocol\n      (RFC 854) for remote login from one host to another.\n\
    \   $ TEMPEST\n      1. (N) Short name for technology and methods for protecting\n\
    \      against data compromise due to electromagnetic emanations from\n      electrical\
    \ and electronic equipment. [Army, Russ] (See:\n      inspectable space, soft\
    \ TEMPEST, TEMPEST zone. Compare: QUADRANT)\n      2. (O) /U.S. Government/ \"\
    Short name referring to investigation,\n      study, and control of compromising\
    \ emanations from IS equipment.\"\n      [C4009]\n      Deprecated Usage: IDOCs\
    \ SHOULD NOT use this term as a synonym for\n      \"electromagnetic emanations\
    \ security\"; instead, use EMSEC. Also,\n      the term is NOT an acronym for\
    \ Transient Electromagnetic Pulse\n      Surveillance Technology.\n      Tutorial:\
    \ The U.S. Federal Government issues security policies\n      that (a) state specifications\
    \ and standards for techniques to\n      reduce the strength of emanations from\
    \ systems and reduce the\n      ability of unauthorized parties to receive and\
    \ make use of\n      emanations and (b) state rules for applying those techniques.\n\
    \      Other nations presumably do the same.\n   $ TEMPEST zone\n      (O) \"\
    Designated area [i.e., a physical volume] within a facility\n      where equipment\
    \ with appropriate TEMPEST characteristics ... may\n      be operated.\" [C4009]\
    \ (See: emanation security, TEMPEST. Compare:\n      control zone, inspectable\
    \ space.)\n      Tutorial: The strength of an electromagnetic signal decreases\
    \ in\n      proportion to the square of the distance between the source and\n\
    \      the receiver. Therefore, EMSEC for electromagnetic signals can be\n   \
    \   achieved by a combination of (a) reducing the strength of\n      emanations\
    \ to a defined level and (b) establishing around that\n      equipment an appropriately\
    \ sized physical buffer zone from which\n      unauthorized entities are excluded.\
    \ By making the zone large\n      enough, it is possible to limit the signal strength\
    \ available to\n      entities outside the zone to a level lower than can be received\n\
    \      and read with known, state-of-the-art methods. Typically, the need\n  \
    \    for and size of a TEMPEST zone established by a security policy\n      depends\
    \ not only on the measured level of signal emitted by\n      equipment, but also\
    \ on the perceived threat level in the\n      equipment's environment.\n   $ Terminal\
    \ Access Controller (TAC) Access Control System (TACACS)\n      (I) A UDP-based\
    \ authentication and access control protocol [R1492]\n      in which a network\
    \ access server receives an identifier and\n      password from a remote terminal\
    \ and passes them to a separate\n      authentication server for verification.\
    \ (See: TACACS+.)\n      Tutorial: TACACS can provide service not only for network\
    \ access\n      servers but also routers and other networked computing devices\
    \ via\n      one or more centralized authentication servers. TACACS was\n    \
    \  originally developed for ARPANET and has evolved for use in\n      commercial\
    \ equipment.\n   $ TESS\n      (I) See: The Exponential Encryption System.\n \
    \  $ The Exponential Encryption System (TESS)\n      (I) A system of separate\
    \ but cooperating cryptographic mechanisms\n      and functions for the secure\
    \ authenticated exchange of\n      cryptographic keys, the generation of digital\
    \ signatures, and the\n      distribution of public keys. TESS uses asymmetric\
    \ cryptography,\n      based on discrete exponentiation, and a structure of self-\n\
    \      certified public keys. [R1824]\n   $ theft\n      (I) /threat action/ See:\
    \ secondary definitions under\n      \"interception\" and \"misappropriation\"\
    .\n   $ threat\n      1a. (I) A potential for violation of security, which exists\
    \ when\n      there is an entity, circumstance, capability, action, or event\n\
    \      that could cause harm. (See: dangling threat, INFOCON level,\n      threat\
    \ action, threat agent, threat consequence. Compare: attack,\n      vulnerability.)\n\
    \      1b. (N) Any circumstance or event with the potential to adversely\n   \
    \   affect a system through unauthorized access, destruction,\n      disclosure,\
    \ or modification of data, or denial of service. [C4009]\n      (See: sensitive\
    \ information.)\n      Usage: (a) Frequently misused with the meaning of either\
    \ \"threat\n      action\" or \"vulnerability\". (b) In some contexts, \"threat\"\
    \ is used\n      more narrowly to refer only to intelligent threats; for example,\n\
    \      see definition 2 below. (c) In some contexts, \"threat\" is used\n    \
    \  more broadly to cover both definition 1 and other concepts, such\n      as\
    \ in definition 3 below.\n      Tutorial: A threat is a possible danger that might\
    \ exploit a\n      vulnerability. Thus, a threat may be intentional or not:\n\
    \      -  \"Intentional threat\": A possibility of an attack by an\n         intelligent\
    \ entity (e.g., an individual cracker or a criminal\n         organization).\n\
    \      -  \"Accidental threat\": A possibility of human error or omission,\n \
    \        unintended equipment malfunction, or natural disaster (e.g.,\n      \
    \   fire, flood, earthquake, windstorm, and other causes listed in\n         [FP031]).\n\
    \      The Common Criteria characterizes a threat in terms of (a) a\n      threat\
    \ agent, (b) a presumed method of attack, (c) any\n      vulnerabilities that\
    \ are the foundation for the attack, and (d)\n      the system resource that is\
    \ attacked. That characterization agrees\n      with the definitions in this Glossary\
    \ (see: diagram under\n      \"attack\").\n      2. (O) The technical and operational\
    \ ability of a hostile entity\n      to detect, exploit, or subvert a friendly\
    \ system and the\n      demonstrated, presumed, or inferred intent of that entity\
    \ to\n      conduct such activity.\n      Tutorial: To be likely to launch an\
    \ attack, an adversary must have\n      (a) a motive to attack, (b) a method or\
    \ technical ability to make\n      the attack, and (c) an opportunity to appropriately\
    \ access the\n      targeted system.\n      3. (D) \"An indication of an impending\
    \ undesirable event.\" [Park]\n      Deprecated Definition: IDOCs SHOULD NOT use\
    \ this term with\n      definition 3 because the definition is ambiguous; the\
    \ definition\n      was intended to include the following three meanings:\n  \
    \    -  \"Potential threat\": A possible security violation; i.e., the\n     \
    \    same as definition 1.\n      -  \"Active threat\": An expression of intent\
    \ to violate security.\n         (Context usually distinguishes this meaning from\
    \ the previous\n         one.)\n      -  \"Accomplished threat\" or \"actualized\
    \ threat\": That is, a threat\n         action. Deprecated Usage: IDOCs SHOULD\
    \ NOT use the term\n         \"threat\" with this meaning; instead, use \"threat\
    \ action\".\n   $ threat action\n      (I) A realization of a threat, i.e., an\
    \ occurrence in which system\n      security is assaulted as the result of either\
    \ an accidental event\n      or an intentional act. (See: attack, threat, threat\
    \ consequence.)\n      Tutorial: A complete security architecture deals with both\n\
    \      intentional acts (i.e., attacks) and accidental events [FP031].\n     \
    \ (See: various kinds of threat actions defined under the four kinds\n      of\
    \ \"threat consequence\".)\n   $ threat agent\n      (I) A system entity that\
    \ performs a threat action, or an event\n      that results in a threat action.\n\
    \   $ threat analysis\n      (I) An analysis of the threat actions that might\
    \ affect a system,\n      primarily emphasizing their probability of occurrence\
    \ but also\n      considering their resulting threat consequences. Example: RFC\n\
    \      3833. (Compare: risk analysis.)\n   $ threat consequence\n      (I) A security\
    \ violation that results from a threat action.\n      Tutorial: The four basic\
    \ types of threat consequence are\n      \"unauthorized disclosure\", \"deception\"\
    , \"disruption\", and\n      \"usurpation\". (See main Glossary entries of each\
    \ of these four\n      terms for lists of the types of threat actions that can\
    \ result in\n      these consequences.)\n   $ thumbprint\n      1. (I) A pattern\
    \ of curves formed by the ridges on the tip of a\n      thumb. (See: biometric\
    \ authentication, fingerprint.)\n      2. (D) Synonym for some type of \"hash\
    \ result\". (See: biometric\n      authentication. Compare: fingerprint.)\n  \
    \    Deprecated Usage: IDOCs SHOULD NOT use this term with definition 2\n    \
    \  because that meaning mixes concepts in a potentially misleading\n      way.\n\
    \   $ ticket\n      (I) Synonym for \"capability token\".\n      Tutorial: A ticket\
    \ is usually granted by a centralized access\n      control server (ticket-granting\
    \ agent) to authorize access to a\n      system resource for a limited time. Tickets\
    \ can be implemented\n      with either symmetric cryptography (see: Kerberos)\
    \ or asymmetric\n      cryptography (see: attribute certificate).\n   $ tiger\
    \ team\n      (O) A group of evaluators employed by a system's managers to\n \
    \     perform penetration tests on the system.\n      Deprecated Usage: It is\
    \ likely that other cultures use different\n      metaphors for this concept.\
    \ Therefore, to avoid international\n      misunderstanding, IDOCs SHOULD NOT\
    \ use this term. (See: Deprecated\n      Usage under \"Green Book\".)\n   $ time\
    \ stamp\n      1. (I) /noun/ With respect to a data object, a label or marking\
    \ in\n      which is recorded the time (time of day or other instant of\n    \
    \  elapsed time) at which the label or marking was affixed to the\n      data\
    \ object. (See: Time-Stamp Protocol.)\n      2. (O) /noun/ \"With respect to a\
    \ recorded network event, a data\n      field in which is recorded the time (time\
    \ of day or other instant\n      of elapsed time) at which the event took place.\"\
    \ [A1523]\n      Tutorial: A time stamp can be used as evidence to prove that\
    \ a\n      data object existed (or that an event occurred) at or before a\n  \
    \    particular time. For example, a time stamp might be used to prove\n     \
    \ that a digital signature based on a private key was created while\n      the\
    \ corresponding public-key certificate was valid, i.e., before\n      the certificate\
    \ either expired or was revoked. Establishing this\n      proof would enable the\
    \ certificate to be used after its expiration\n      or revocation, to verify\
    \ a signature that was created earlier.\n      This kind of proof is required\
    \ as part of implementing PKI\n      services, such as non-repudiation service,\
    \ and long-term security\n      services, such as audit.\n   $ Time-Stamp Protocol\n\
    \      (I) An Internet protocol (RFC 3161) that specifies how a client\n     \
    \ requests and receives a time stamp from a server for a data object\n      held\
    \ by the client.\n      Tutorial: The protocol describes the format of (a) a request\
    \ sent\n      to a time-stamp authority and (b) the response that is returned\n\
    \      containing a time stamp. The authority creates the stamp by\n      concatenating\
    \ (a) a hash value of the input data object with (b) a\n      UTC time value and\
    \ other parameters (policy OID, serial number,\n      indication of time accuracy,\
    \ nonce, DN of the authority, and\n      various extensions), and then signing\
    \ that dataset with the\n      authority's private key as specified in CMS. Such\
    \ an authority\n      typically would operate as a trusted third-party service,\
    \ but\n      other operational models might be used.\n   $ timing channel\n  \
    \    (I) See: covert timing channel.\n   $ TKEY\n      (I) A mnemonic referring\
    \ to an Internet protocol (RFC 2930) for\n      establishing a shared secret key\
    \ between a DNS resolver and a DNS\n      name server. (See: TSIG.)\n   $ TLS\n\
    \      (I) See: Transport Layer Security.\n   $ TLSP\n      (N) See: Transport\
    \ Layer Security Protocol.\n   $ TOE\n      (N) See: target of evaluation.\n \
    \  $ token\n      1. (I) /cryptography/ See: cryptographic token. (Compare: dongle.)\n\
    \      2. (I) /access control/ An object that is used to control access\n    \
    \  and is passed between cooperating entities in a protocol that\n      synchronizes\
    \ use of a shared resource. Usually, the entity that\n      currently holds the\
    \ token has exclusive access to the resource.\n      (See: capability token.)\n\
    \      Usage: This term is heavily overloaded in the computing\n      literature;\
    \ therefore, IDOCs SHOULD NOT use this term with any\n      definition other than\
    \ 1 or 2.\n      3a. (D) /authentication/ A data object or a physical device used\n\
    \      to verify an identity in an authentication process.\n      3b. (D) /U.S.\
    \ Government/ Something that the claimant in an\n      authentication process\
    \ (i.e., the entity that claims an identity)\n      possesses and controls, and\
    \ uses to prove the claim during the\n      verification step of the process.\
    \ [SP63]\n      Deprecated usage: IDOCs SHOULD NOT use this term with definitions\n\
    \      3a and 3b; instead, use more specifically descriptive and\n      informative\
    \ terms such as \"authentication information\" or\n      \"cryptographic token\"\
    , depending on what is meant.\n      NIST defines four types of claimant tokens\
    \ for electronic\n      authentication in an information system [SP63]. IDOCs\
    \ SHOULD NOT\n      use these four NIST terms; they mix concepts in potentially\n\
    \      confusing ways and duplicate the meaning of better-established\n      terms.\
    \ These four terms can be avoided by using more specifically\n      descriptive\
    \ terms as follows:\n      -  NIST \"hard token\": A hardware device that contains\
    \ a protected\n         cryptographic key. (This is a type of \"cryptographic\
    \ token\",\n         and the key is a type of \"authentication information\".)\n\
    \      -  NIST \"one-time password device token\": A personal hardware\n     \
    \    device that generates one-time passwords. (One-time passwords\n         are\
    \ typically generated cryptographically. Therefore, this is a\n         type of\
    \ \"cryptographic token\", and the key is a type of\n         \"authentication\
    \ information\".)\n      -  NIST \"soft token\": A cryptographic key that typically\
    \ is stored\n         on disk or some other magnetic media. (The key is a type\
    \ of\n         \"authentication information\"; \"authentication key\" would be\
    \ a\n         better description.)\n      -  NIST \"password token\": A secret\
    \ data value that the claimant\n         memorizes. (This is a \"password\" that\
    \ is being used as\n         \"authentication information\".)\n   $ token backup\n\
    \      (I) A token management operation that stores sufficient\n      information\
    \ in a database (e.g., in a CAW) to recreate or restore\n      a security token\
    \ (e.g., a smart card) if it is lost or damaged.\n   $ token copy\n      (I) A\
    \ token management operation that copies all the personality\n      information\
    \ from one security token to another. However, unlike in\n      a token restore\
    \ operation, the second token is initialized with\n      its own, different local\
    \ security values such as PINs and storage\n      keys.\n   $ token management\n\
    \      (I) The process that includes initializing security tokens (e.g.,\n   \
    \   \"smart card\"), loading data into the tokens, and controlling the\n     \
    \ tokens during their lifecycle. May include performing key\n      management\
    \ and certificate management functions; generating and\n      installing PINs;\
    \ loading user personality data; performing card\n      backup, card copy, and\
    \ card restore operations; and updating\n      firmware.\n   $ token restore\n\
    \      (I) A token management operation that loads a security token with\n   \
    \   data for the purpose of recreating (duplicating) the contents\n      previously\
    \ held by that or another token. (See: recovery.)\n   $ token storage key\n  \
    \    (I) A cryptographic key used to protect data that is stored on a\n      security\
    \ token.\n   $ top CA\n      (I) Synonym for \"root\" in a certification hierarchy.\
    \ (See: apex\n      trust anchor.)\n   $ top-level specification\n      (I) \"\
    A non-procedural description of system behavior at the most\n      abstract level;\
    \ typically a functional specification that omits\n      all implementation details.\"\
    \ [NCS04] (See: formal top-level\n      specification, Tutorial under \"security\
    \ policy\".)\n      Tutorial: A top-level specification is at a level of abstraction\n\
    \      below \"security model\" and above \"security architecture\" (see:\n  \
    \    Tutorial under \"security policy\").\n      A top-level specification may\
    \ be descriptive or formal:\n      -  \"Descriptive top-level specification\"\
    : One that is written in a\n         natural language like English or an informal\
    \ design notation.\n      -  \"Formal top-level specification\": One that is written\
    \ in a\n         formal mathematical language to enable theorems to be proven\n\
    \         that show that the specification correctly implements a set of\n   \
    \      formal requirements or a formal security model. (See:\n         correctness\
    \ proof.)\n   $ TPM\n      (N) See: Trusted Platform Module.\n   $ traceback\n\
    \      (I) Identification of the source of a data packet. (See:\n      masquerade,\
    \ network weaving.)\n   $ tracker\n      (N) An attack technique for achieving\
    \ unauthorized disclosure from\n      a statistical database. [Denns] (See: Tutorial\
    \ under \"inference\n      control\".)\n   $ traffic analysis\n      1. (I) Gaining\
    \ knowledge of information by inference from\n      observable characteristics\
    \ of a data flow, even if the information\n      is not directly available (e.g.,\
    \ when the data is encrypted).\n      These characteristics include the identities\
    \ and locations of the\n      source(s) and destination(s) of the flow, and the\
    \ flow's presence,\n      amount, frequency, and duration of occurrence. The object\
    \ of the\n      analysis might be information in SDUs, information in the PCI,\
    \ or\n      both. (See: inference, traffic-flow confidentiality, wiretapping.\n\
    \      Compare: signal analysis.)\n      2. (O) \"The inference of information\
    \ from observation of traffic\n      flows (presence, absence, amount, direction,\
    \ and frequency).\"\n      [I7498-2]\n   $ traffic-flow analysis\n      (I) Synonym\
    \ for \"traffic analysis\".\n   $ traffic-flow confidentiality (TFC)\n      1.\
    \ (I) A data confidentiality service to protect against traffic\n      analysis.\
    \ (See: communications cover.)\n      2. (O) \"A confidentiality service to protect\
    \ against traffic\n      analysis.\" [I7498-2]\n      Tutorial: Confidentiality\
    \ concerns involve both direct and\n      indirect disclosure of data, and the\
    \ latter includes traffic\n      analysis. However, operational considerations\
    \ can make TFC\n      difficult to achieve. For example, if Alice sends a product\
    \ idea\n      to Bob in an email message, she wants data confidentiality for the\n\
    \      message's content, and she might also want to conceal the\n      destination\
    \ of the message to hide Bob's identity from her\n      competitors. However,\
    \ the identity of the intended recipient, or\n      at least a network address\
    \ for that recipient, needs to be made\n      available to the mail system. Thus,\
    \ complex forwarding schemes may\n      be needed to conceal the ultimate destination\
    \ as the message\n      travels through the open Internet (see: onion routing).\n\
    \      Later, if Alice uses an ATM during a clandestine visit to\n      negotiate\
    \ with Bob, she might prefer that her bank conceal the\n      origin of her transaction,\
    \ because knowledge of the ATM's location\n      might allow a competitor to infer\
    \ Bob's identity. The bank, on the\n      other hand, might prefer to protect\
    \ only Alice's PIN (see:\n      selective-field confidentiality).\n      A TFC\
    \ service can be either full or partial:\n      -  \"Full TFC\": This type of\
    \ service conceals all traffic\n         characteristics.\n      -  \"Partial\
    \ TFC\": This type of service either (a) conceals some\n         but not all of\
    \ the characteristics or (b) does not completely\n         conceal some characteristic.\n\
    \      On point-to-point data links, full TFC can be provided by\n      enciphering\
    \ all PDUs and also generating a continuous, random data\n      stream to seamlessly\
    \ fill all gaps between PDUs. To a wiretapper,\n      the link then appears to\
    \ be carrying an unbroken stream of\n      enciphered data. In other cases --\
    \ including on a shared or\n      broadcast medium, or end-to-end in a network\
    \ -- only partial TFC\n      is possible, and that may require a combination of\
    \ techniques. For\n      example, a LAN that uses \"carrier sense multiple access\
    \ with\n      collision detection\" (CSMA/CD; a.k.a. \"listen while talk\") to\n\
    \      control access to the medium, relies on detecting intervals of\n      silence,\
    \ which prevents using full TFC. Partial TFC can be\n      provided on that LAN\
    \ by measures such as adding spurious PDUs,\n      padding PDUs to a constant\
    \ size, or enciphering addresses just\n      above the Physical Layer; but these\
    \ measures reduce the efficiency\n      with which the LAN can carry traffic.\
    \ At higher protocol layers,\n      SDUs can be protected, but addresses and other\
    \ items of PCI must\n      be visible at the layers below.\n   $ traffic key\n\
    \      (I) A cryptographic key used by a device for protecting\n      information\
    \ that is being transmitted between devices, as opposed\n      to protecting information\
    \ that being is maintained in the device.\n      (Compare: storage key.)\n   $\
    \ traffic padding\n      (I) \"The generation of spurious instances of communication,\n\
    \      spurious data units, and/or spurious data within data units.\"\n      [I7498-2]\n\
    \   $ tranquility property\n      (N) /formal model/ Property of a system whereby\
    \ the security level\n      of an object cannot change while the object is being\
    \ processed by\n      the system. (See: Bell-LaPadula model.)\n   $ transaction\n\
    \      1. (I) A unit of interaction between an external entity and a\n      system,\
    \ or between components within a system, that involves a\n      series of system\
    \ actions or events.\n      2. (O) \"A discrete event between user and systems\
    \ that supports a\n      business or programmatic purpose.\" [M0404]\n      Tutorial:\
    \ To maintain secure state, transactions need to be\n      processed coherently\
    \ and reliably. Usually, they need to be\n      designed to be atomic, consistent,\
    \ isolated, and durable [Gray]:\n      -  \"Atomic\": All actions and events that\
    \ comprise the transaction\n         are guaranteed to be completed successfully,\
    \ or else the result\n         is as if none at all were executed.\n      -  \"\
    Consistent\": The transaction satisfies correctness constraints\n         defined\
    \ for the data that is being processed.\n      -  \"Isolated\": If two transactions\
    \ are performed concurrently,\n         they do not interfere with each other,\
    \ and it appears as though\n         the system performs one at a time.\n    \
    \  -  \"Durable\": System state and transaction semantics survive\n         system\
    \ failures.\n   $ TRANSEC\n      (I) See: transmission security.\n   $ Transmission\
    \ Control Code field (TCC field)\n      (I) A data field that provides a means\
    \ to segregate traffic and\n      define controlled communities of interest in\
    \ the security option\n      (option type = 130) of IPv4's datagram header format.\
    \ The TCC\n      values are alphanumeric trigraphs assigned by the U.S. Government\n\
    \      as specified in RFC 791.\n   $ Transmission Control Protocol (TCP)\n  \
    \    (I) An Internet Standard, Transport-Layer protocol (RFC 793) that\n     \
    \ reliably delivers a sequence of datagrams from one computer to\n      another\
    \ in a computer network. (See: TCP/IP.)\n      Tutorial: TCP is designed to fit\
    \ into a layered suite of protocols\n      that support internetwork applications.\
    \ TCP assumes it can obtain\n      a simple but potentially unreliable end-to-end\
    \ datagram service\n      (such as IP) from the lower-layer protocols.\n   $ transmission\
    \ security (TRANSEC)\n      (I) COMSEC measures that protect communications from\
    \ interception\n      and exploitation by means other than cryptanalysis. Example:\n\
    \      frequency hopping. (Compare: anti-jam, traffic flow\n      confidentiality.)\n\
    \   $ Transport Layer\n      See: Internet Protocol Suite, OSIRM.\n   $ Transport\
    \ Layer Security (TLS)\n      (I) TLS is an Internet protocol [R4346] that is\
    \ based on, and very\n      similar to, SSL Version 3.0. (Compare: TLSP.)\n  \
    \    Tutorial: The TLS protocol is misnamed. The name misleadingly\n      suggests\
    \ that TLS is situated in the IPS Transport Layer, but TLS\n      is always layered\
    \ above a reliable Transport-Layer protocol\n      (usually TCP) and either layered\
    \ immediately below or integrated\n      with an Application-Layer protocol (often\
    \ HTTP).\n   $ Transport Layer Security Protocol (TLSP)\n      (N) An end-to-end\
    \ encryption protocol (ISO 10736) that provides\n      security services at the\
    \ bottom of OSIRM Layer 4, i.e., directly\n      above Layer 3. (Compare: TLS.)\n\
    \      Tutorial: TLSP evolved directly from SP4.\n   $ transport mode\n      (I)\
    \ One of two ways to apply AH or ESP to protect data packets; in\n      this mode,\
    \ the IPsec protocol encapsulates (i.e., the protection\n      applies to) the\
    \ packets of an IPS Transport-Layer protocol (e.g.,\n      TCP, UDP), which normally\
    \ is carried directly above IP in an IPS\n      protocol stack. (Compare: tunnel\
    \ mode.)\n      Tutorial: An IPsec transport-mode security association is always\n\
    \      between two hosts; neither end has the role of a security gateway.\n  \
    \    Whenever either end of an IPsec security association is a security\n    \
    \  gateway, the association is required to be in tunnel mode.\n   $ transposition\n\
    \      (I) /cryptography/ A method of encryption in which elements of the\n  \
    \    plain text retain their original form but undergo some change in\n      their\
    \ sequential position. (Compare: substitution.)\n   $ trap door\n      (I) Synonym\
    \ for \"back door\".\n   $ trespass\n      (I) /threat action/ See: secondary\
    \ definition under \"intrusion\".\n   $ Triple Data Encryption Algorithm\n   \
    \   (I) A block cipher that transforms each 64-bit plaintext block by\n      applying\
    \ the DEA three successive times, using either two or three\n      different keys\
    \ for an effective key length of 112 or 168 bits.\n      [A9052, SP67]\n     \
    \ Example: A variation proposed for IPsec's ESP uses a 168-bit key,\n      consisting\
    \ of three independent 56-bit values used by the DEA, and\n      a 64-bit initialization\
    \ vector. Each datagram contains an IV to\n      ensure that each received datagram\
    \ can be decrypted even when\n      other datagrams are dropped or a sequence\
    \ of datagrams is\n      reordered in transit. [R1851]\n   $ triple-wrapped\n\
    \      (I) /S-MIME/ Data that has been signed with a digital signature,\n    \
    \  then encrypted, and then signed again. [R2634]\n   $ Trojan horse\n      (I)\
    \ A computer program that appears to have a useful function, but\n      also has\
    \ a hidden and potentially malicious function that evades\n      security mechanisms,\
    \ sometimes by exploiting legitimate\n      authorizations of a system entity\
    \ that invokes the program. (See:\n      malware, spyware. Compare: logic bomb,\
    \ virus, worm.)\n   $ trust\n      1. (I) /information system/ A feeling of certainty\
    \ (sometimes\n      based on inconclusive evidence) either (a) that the system\
    \ will\n      not fail or (b) that the system meets its specifications (i.e.,\n\
    \      the system does what it claims to do and does not perform unwanted\n  \
    \    functions). (See: trust level, trusted system, trustworthy system.\n    \
    \  Compare: assurance.)\n      Tutorial: Components of a system can be grouped\
    \ into three classes\n      of trust [Gass]:\n      -  \"Trusted\": The component\
    \ is responsible for enforcing security\n         policy on other components;\
    \ the system's security depends on\n         flawless operation of the component.\
    \ (See: trusted process.)\n      -  \"Benign\": The component is not responsible\
    \ for enforcing\n         security policy, but it has sensitive authorizations.\
    \ It must\n         be trusted not to intentionally violate security policy, but\n\
    \         security violations are assumed to be accidental and not likely\n  \
    \       to affect overall system security.\n      -  \"Untrusted\": The component\
    \ is of unknown or suspicious\n         provenance and must be treated as deliberately\
    \ malicious. (See:\n         malicious logic.)\n      2. (I) /PKI/ A relationship\
    \ between a certificate user and a CA in\n      which the user acts according\
    \ to the assumption that the CA\n      creates only valid digital certificates.\n\
    \      Tutorial: \"Generally, an entity is said to 'trust' a second entity\n \
    \     when the first entity makes the assumption that the second entity\n    \
    \  will behave exactly as the first entity expects. This trust may\n      apply\
    \ only for some specific function. The key role of trust in\n      [X.509] is\
    \ to describe the relationship between an entity [i.e., a\n      certificate user]\
    \ and a [CA]; an entity shall be certain that it\n      can trust the CA to create\
    \ only valid and reliable certificates.\"\n      [X509]\n   $ trust anchor\n \
    \     (I) /PKI/ An established point of trust (usually based on the\n      authority\
    \ of some person, office, or organization) from which a\n      certificate user\
    \ begins the validation of a certification path.\n      (See: apex trust anchor,\
    \ path validation, trust anchor CA, trust\n      anchor certificate, trust anchor\
    \ key.)\n      Usage: IDOCs that use this term SHOULD state a definition for it\n\
    \      because it is used in various ways in existing IDOCs and other PKI\n  \
    \    literature. The literature almost always uses this term in a sense\n    \
    \  that is equivalent to this definition, but usage often differs\n      with\
    \ regard to what constitutes the point of trust.\n      Tutorial: A trust anchor\
    \ may be defined as being based on a public\n      key, a CA, a public-key certificate,\
    \ or some combination or\n      variation of those:\n      -  1. A public key\
    \ as a point of trust: Although a certification\n         path is defined as beginning\
    \ with a \"sequence of public-key\n         certificates\", an implementation\
    \ of a path validation process\n         might not explicitly handle a root certificate\
    \ as part of the\n         path, but instead begin the process by using a trusted\
    \ root key\n         to verify the signature on a certificate that was issued\
    \ by the\n         root.\n         Therefore, \"trust anchor\" is sometimes defined\
    \ as just a public\n         key. (See: root key, trust anchor key, trusted key.)\n\
    \      -  2. A CA as a point of trust: A trusted public key is just one\n    \
    \     of the data elements needed for path validation; the IPS path\n        \
    \ validation algorithm [R3280] also needs the name of the CA to\n         which\
    \ that key belongs, i.e., the DN of the issuer of the first\n         X.509 certificate\
    \ to be validated on the path. (See: issue.)\n         Therefore, \"trust anchor\"\
    \ is sometimes defined as either just a\n         CA (where some public key is\
    \ implied) or as a CA together with\n         a specified public key belonging\
    \ to that CA. (See: root, trust\n         anchor CA, trusted CA.)\n         Example:\
    \ \"A public key and the name of a [CA] that is used to\n         validate the\
    \ first certificate in a sequence of certificates.\n         The trust anchor\
    \ public key is used to verify the signature on\n         a certificate issued\
    \ by a trust anchor [CA].\" [SP57]\n      -  3. A public-key certificate as a\
    \ point of trust: Besides the\n         trusted CA's public key and name, the\
    \ path validation algorithm\n         needs to know the digital signature algorithm\
    \ and any\n         associated parameters with which the public key is used, and\n\
    \         also any constraints that have been placed on the set of paths\n   \
    \      that may be validated using the key. All of this information is\n     \
    \    available from a CA's public-key certificate.\n         Therefore, \"trust\
    \ anchor\" is sometimes defined as a public-key\n         certificate of a CA.\
    \ (See: root certificate, trust anchor\n         certificate, trusted certificate.)\n\
    \      -  4. Combinations: Combinations and variations of the first three\n  \
    \       definitions are also used in the PKI literature.\n         Example: \"\
    trust anchor information\". The IPS standard for path\n         validation [R3280]\
    \ specifies the information that describes \"a\n         CA that serves as a trust\
    \ anchor for the certification path.\n         The trust anchor information includes:\
    \ (a) the trusted issuer\n         name, (b) the trusted public key algorithm,\
    \ (c) the trusted\n         public key, and (d) optionally, the trusted public\
    \ key\n         parameters associated with the public key. The trust anchor\n\
    \         information may be provided to the path processing procedure in\n  \
    \       the form of a self-signed certificate. The trusted anchor\n         information\
    \ is trusted because it was delivered to the path\n         processing procedure\
    \ by some trustworthy out-of-band procedure.\n         If the trusted public key\
    \ algorithm requires parameters, then\n         the parameters are provided along\
    \ with the trusted public key.\"\n   $ trust anchor CA\n      (I) A CA that is\
    \ the subject of a trust anchor certificate or\n      otherwise establishes a\
    \ trust anchor key. (See: root, trusted CA.)\n      Tutorial: The selection of\
    \ a CA to be a trust anchor is a matter\n      of policy. Some of the possible\
    \ choices include (a) the top CA in\n      a hierarchical PKI, (b) the CA that\
    \ issued the verifier's own\n      certificate, or (c) any other CA in a network\
    \ PKI. Different\n      applications may rely on different trust anchors, or may\
    \ accept\n      paths that begin with any of a set of trust anchors. The IPS path\n\
    \      validation algorithm is the same, regardless of the choice.\n   $ trust\
    \ anchor certificate\n      (I) A public-key certificate that is used to provide\
    \ the first\n      public key in a certification path. (See: root certificate,\
    \ trust\n      anchor, trusted certificate.)\n   $ trust anchor key\n      (I)\
    \ A public key that is used as the first public key in a\n      certification\
    \ path. (See: root key, trust anchor, trusted public\n      key.)\n   $ trust\
    \ anchor information\n      (I) See: secondary definition under \"trust anchor\"\
    .\n   $ trust chain\n      (D) Synonym for \"certification path\". (See: trust\
    \ anchor, trusted\n      certificate.)\n      Deprecated Term: IDOCs SHOULD NOT\
    \ use this term, because it\n      unnecessarily duplicates the meaning of the\
    \ internationally\n      standardized term.\n      Also, the term mixes concepts\
    \ in a potentially misleading way.\n      Having \"trust\" involves factors unrelated\
    \ to simply verifying\n      signatures and performing other tests as specified\
    \ by a standard\n      algorithm for path validation (e.g., RFC 3280). Thus, even\
    \ if a\n      user is able to validate a certification path algorithmically, the\n\
    \      user still might distrust one of the CAs that issued certificates\n   \
    \   in that path or distrust some other aspects of the PKI.\n   $ trust-file PKI\n\
    \      (I) A non-hierarchical PKI in which each certificate user has its\n   \
    \   own local file (which is used by application software) of trust\n      anchors,\
    \ i.e., either public keys or public-key certificates that\n      the user trusts\
    \ as starting points for certification paths. (See:\n      trust anchor, web of\
    \ trust. Compare: hierarchical PKI, mesh PKI.)\n      Example: Popular browsers\
    \ are distributed with an initial file of\n      trust anchor certificates, which\
    \ often are self-signed\n      certificates. Users can add certificates to the\
    \ file or delete\n      from it. The file may be directly managed by the user,\
    \ or the\n      user's organization may manage it from a centralized server.\n\
    \   $ trust hierarchy\n      (D) Synonym for \"certification hierarchy\".\n  \
    \    Deprecated Usage: IDOCs SHOULD NOT use this term because it mixes\n     \
    \ concepts in a potentially misleading way, and because a trust\n      hierarchy\
    \ could be implemented in other ways. (See: trust, trust\n      chain, web of\
    \ trust.)\n   $ trust level\n      (N) A characterization of a standard of security\
    \ protection to be\n      met by an information system. (See: Common Criteria,\
    \ TCSEC.)\n      Tutorial: A trust level is based not only on (a) the presence\
    \ of\n      security mechanisms, but also on the use of (b) systems\n      engineering\
    \ discipline to properly structure the system and (c)\n      implementation analysis\
    \ to ensure that the system provides an\n      appropriate degree of trust.\n\
    \   $ trusted\n      (I) See: secondary definition under \"trust\".\n   $ trusted\
    \ CA\n      (I) A CA upon which a certificate user relies as issuing valid\n \
    \     certificates; especially a CA that is used as a trust anchor CA.\n     \
    \ (See: certification path, root, trust anchor CA, validation.)\n      Tutorial.\
    \ This trust is transitive to the extent that the X.509\n      certificate extensions\
    \ permit; that is, if a trusted CA issues a\n      certificate to another CA,\
    \ a user that trusts the first CA also\n      trusts the second CA if the user\
    \ succeeds in validating the\n      certificate path (see: path validation).\n\
    \   $ trusted certificate\n      (I) A digital certificate that a certificate\
    \ user accepts as being\n      valid \"a priori\", i.e., without testing the certificate\
    \ to\n      validate it as the final certificate on a certification path;\n  \
    \    especially a certificate that is used as a trust anchor\n      certificate.\
    \ (See: certification path, root certificate, trust\n      anchor certificate,\
    \ trust-file PKI, validation.)\n      Tutorial: The acceptance of a certificate\
    \ as trusted is a matter\n      of policy and choice. Usually, a certificate is\
    \ accepted as\n      trusted because the user obtained it by reliable, out-of-band\n\
    \      means that cause the user to believe the certificate accurately\n     \
    \ binds its subject's name to the subject's public key or other\n      attribute\
    \ values. Many choices are possible; e.g., a trusted\n      public-key certificate\
    \ might be (a) the root certificate in a\n      hierarchical PKI, (b) the certificate\
    \ of the CA that issued the\n      user's own certificate in a mesh PKI, or (c)\
    \ a certificate\n      provided with an application that uses a trust-file PKI.\n\
    \   $ Trusted Computer System Evaluation Criteria (TCSEC)\n      (N) A standard\
    \ for evaluating the security provided by operating\n      systems [CSC1, DoD1].\
    \ Known as the \"Orange Book\" because of the\n      color of its cover; first\
    \ document in the Rainbow Series. (See:\n      Common Criteria, Deprecated Usage\
    \ under \"Green Book\", Orange Book,\n      trust level, trusted system. Compare:\
    \ TSEC.)\n      Tutorial: The TCSEC defines classes of hierarchically ordered\n\
    \      assurance levels for rating computer systems. From highest to\n      lowest,\
    \ the classes are as follows:\n      -  Division A:  Verified protection.\n  \
    \         Beyond A1    Beyond current technology. (See: beyond A1.)\n        \
    \   Class  A1    Verified design. (See: SCOMP.)\n      -  Division B:  Mandatory\
    \ protection.\n           Class  B3    Security domains.\n           Class  B2\
    \    Structured protection. (See: Multics.)\n           Class  B1    Labeled security\
    \ protection.\n      -  Division C:  Discretionary protection.\n           Class\
    \  C2    Controlled access protection.\n           Class  C1    Discretionary\
    \ security protection.\n      -  Division D:  Minimal protection, i.e., has been\
    \ evaluated but\n         does not meet the requirements for a higher evaluation\
    \ class.\n   $ trusted computing base (TCB)\n      (N) \"The totality of protection\
    \ mechanisms within a computer\n      system, including hardware, firmware, and\
    \ software, the\n      combination of which is responsible for enforcing a security\n\
    \      policy.\" [NCS04] (See: \"trusted\" under \"trust\". Compare: TPM.)\n \
    \  $ Trusted Computing Group (TCG)\n      (N) A not-for-profit, industry standards\
    \ organization formed to\n      develop, define, and promote open standards for\
    \ hardware-enabled\n      trusted computing and security technologies, including\
    \ hardware\n      building blocks and software interfaces, across multiple\n \
    \     platforms, peripherals, and devices. (See: TPM, trusted system.\n      Compare:\
    \ TSIG.)\n   $ trusted distribution\n      (I) /COMPUSEC/ \"A trusted method for\
    \ distributing the TCB\n      hardware, software, and firmware components, both\
    \ originals and\n      updates, that provides methods for protecting the TCB from\n\
    \      modification during distribution and for detection of any changes\n   \
    \   to the TCB that may occur.\" [NCS04] (See: code signing,\n      configuration\
    \ control.)\n   $ trusted key\n      (D) Abbreviation for \"trusted public key\"\
    \ and also for other types\n      of keys. (See: root key, trust anchor key.)\n\
    \      Deprecated Usage: IDOCs SHOULD either (a) state a definition for\n    \
    \  this term or (b) use a different, less ambiguous term. This term\n      is\
    \ ambiguous when it stands alone; e.g., it could refer to a\n      trusted public\
    \ key or to a private key or symmetric key that is\n      believed to be secure\
    \ (i.e., not compromised).\n   $ trusted path\n      1a. (I) /COMPUSEC/ A mechanism\
    \ by which a computer system user can\n      communicate directly and reliably\
    \ with the TCB and that can only\n      be activated by the user or the TCB and\
    \ cannot be imitated by\n      untrusted software within the computer. [NCS04]\n\
    \      1b. (I) /COMSEC/ A mechanism by which a person or process can\n      communicate\
    \ directly with a cryptographic module and that can only\n      be activated by\
    \ the person, process, or module, and cannot be\n      imitated by untrusted software\
    \ within the module. [FP140]\n   $ Trusted Platform Module (TPM)\n      (N) The\
    \ name of a specification, published by the TCG, for a\n      microcontroller\
    \ that can store secured information; and also the\n      general name of implementations\
    \ of that specification. (Compare:\n      TCB.)\n   $ trusted process\n      (I)\
    \ A system component that has privileges that enable it to\n      affect the state\
    \ of system security and that can, therefore,\n      through incorrect or malicious\
    \ execution, violate the system's\n      security policy. (See: privileged process,\
    \ trusted system.)\n   $ trusted public key\n      (I) A public key upon which\
    \ a user relies; especially a public key\n      that is used as a trust anchor\
    \ key. (See: certification path, root\n      key, trust anchor key, validation.)\n\
    \      Tutorial: A trusted public key could be (a) the root key in a\n      hierarchical\
    \ PKI, (b) the key of the CA that issued the user's own\n      certificate in\
    \ a mesh PKI, or (c) any key accepted by the user in\n      a trust-file PKI.\n\
    \   $ trusted recovery\n      (I) A process that, after a system has experienced\
    \ a failure or an\n      attack, restores the system to normal operation (or to\
    \ a secure\n      state) without causing a security compromise. (See: recovery.)\n\
    \   $ trusted subnetwork\n      (I) A subnetwork containing hosts and routers\
    \ that trust each\n      other not to engage in active or passive attacks. (There\
    \ also is\n      an assumption that the underlying communication channels, such\
    \ as\n      telephone lines or a LAN, are protected from attack.)\n   $ trusted\
    \ system\n      1. (I) /information system/ A system that operates as expected,\n\
    \      according to design and policy, doing what is required -- despite\n   \
    \   environmental disruption, human user and operator errors, and\n      attacks\
    \ by hostile parties -- and not doing other things [NRC98].\n      (See: trust\
    \ level, trusted process. Compare: trustworthy.)\n      2. (N) /multilevel secure/\
    \ \"A [trusted system is a] system that\n      employs sufficient hardware and\
    \ software assurance measures to\n      allow its use for simultaneous processing\
    \ of a range of sensitive\n      or classified information.\" [NCS04] (See: multilevel\
    \ security\n      mode.)\n   $ Trusted Systems Interoperability Group (TSIG)\n\
    \      (N) A forum of computer vendors, system integrators, and users\n      devoted\
    \ to promoting interoperability of trusted computer systems.\n      (See: trusted\
    \ system. Compare: TCG.)\n   $ trustworthy system\n      1. (I) A system that\
    \ not only is trusted, but also warrants that\n      trust because the system's\
    \ behavior can be validated in some\n      convincing way, such as through formal\
    \ analysis or code review.\n      (See: trust. Compare: trusted.)\n      2. (O)\
    \ /Digital Signature Guidelines/ \"Computer hardware,\n      software, and procedures\
    \ that: (a) are reasonably secure from\n      intrusion and misuse; (b) provide\
    \ a reasonably reliable level of\n      availability, reliability, and correct\
    \ operation; (c) are\n      reasonably suited to performing their intended functions;\
    \ and (d)\n      adhere to generally accepted security principles.\" [DSG]\n \
    \  $ TSEC\n      (O) See: Telecommunications Security Nomenclature System.\n \
    \     (Compare: TCSEC.)\n   $ TSIG\n      1. (N) See: Trusted System Interoperability\
    \ Group.\n      2. (I) A mnemonic (presumed to be derived from \"Transaction\n\
    \      SIGnature\") referring to an Internet protocol (RFC 2845) for data\n  \
    \    origin authentication and data integrity for certain DNS\n      operations.\
    \ (See: TKEY.)\n   $ tunnel\n      1. (I) A communication channel created in a\
    \ computer network by\n      encapsulating (i.e., layering) a communication protocol's\
    \ data\n      packets in (i.e., above) a second protocol that normally would be\n\
    \      carried above, or at the same layer as, the first one. (See: L2TP,\n  \
    \    tunnel mode, VPN. Compare: covert channel.)\n      Tutorial: Tunneling can\
    \ involve almost any two IPS protocol\n      layers. For example, a TCP connection\
    \ between two hosts could\n      conceivably be carried above SMTP (i.e., in SMTP\
    \ messages) as a\n      covert channel to evade access controls that a security\
    \ gateway\n      applies to the normal TCP layer that is below SMTP.\n      Usually,\
    \ however, a tunnel is a logical point-to-point link --\n      i.e., an OSIRM\
    \ Layer 2 connection -- created by encapsulating the\n      Layer 2 protocol in\
    \ one of the following three types of IPS\n      protocols: (a) an IPS Transport-Layer\
    \ protocol (such as TCP), (b)\n      an IPS Network-Layer or Internet-Layer protocol\
    \ (such as IP), or\n      (c) another Layer 2 protocol. In many cases, the encapsulation\
    \ is\n      accomplished with an extra, intermediate protocol (i.e., a\n     \
    \ \"tunneling protocol\"; e.g., L2TP) that is layered below the\n      tunneled\
    \ Layer 2 protocol and above the encapsulating protocol.\n      Tunneling can\
    \ be used to move data between computers that use a\n      protocol not supported\
    \ by the network connecting them. Tunneling\n      also can enable a computer\
    \ network to use the services of a second\n      network as though the second\
    \ network were a set of point-to-point\n      links between the first network's\
    \ nodes. (See: VPN.)\n      2. (O) /SET/ The name of a SET private extension that\
    \ indicates\n      whether the CA or the payment gateway supports passing encrypted\n\
    \      messages to the cardholder through the merchant. If so, the\n      extension\
    \ lists OIDs of symmetric encryption algorithms that are\n      supported.\n \
    \  $ tunnel mode\n      (I) One of two ways to apply the IPsec protocols (AH and\
    \ ESP) to\n      protect data packets; in this mode, the IPsec protocol\n    \
    \  encapsulates (i.e., the protection applies to) IP packets, rather\n      than\
    \ the packets of higher-layer protocols. (See: tunnel. Compare:\n      transport\
    \ mode.)\n      Tutorial: Each end of a tunnel-mode security association may be\n\
    \      either a host or a security gateway. Whenever either end of an\n      IPsec\
    \ security association is a security gateway, the association\n      is required\
    \ to be in tunnel mode.\n   $ two-person control\n      (I) The close surveillance\
    \ and control of a system, a process, or\n      materials (especially with regard\
    \ to cryptography) at all times by\n      a minimum of two appropriately authorized\
    \ persons, each capable of\n      detecting incorrect and unauthorized procedures\
    \ with respect to\n      the tasks to be performed and each familiar with established\n\
    \      security requirements. (See: dual control, no-lone zone.)\n   $ Twofish\n\
    \      (O) A symmetric, 128-bit block cipher with variable key length\n      (128,\
    \ 192, or 256 bits), developed by Counterpane Labs as a\n      candidate for the\
    \ AES. (See: Blowfish.)\n   $ type 0 product\n      (O) /cryptography, U.S. Government/\
    \ Classified cryptographic\n      equipment endorsed by NSA for use (when appropriately\
    \ keyed) in\n      electronically distributing bulk keying material.\n   $ type\
    \ 1 key\n      (O) /cryptography, U.S. Government/ \"Generated and distributed\n\
    \      under the auspices of NSA for use in a cryptographic device for\n     \
    \ the protection of classified and sensitive national security\n      information.\"\
    \ [C4009]\n   $ type 1 product\n      (O) /cryptography, U.S. Government/ \"Cryptographic\
    \ equipment,\n      assembly or component classified or certified by NSA for\n\
    \      encrypting and decrypting classified and sensitive national\n      security\
    \ information when appropriately keyed. Developed using\n      established NSA\
    \ business processes and containing NSA approved\n      algorithms. Used to protect\
    \ systems requiring the most stringent\n      protection mechanisms.\" [C4009]\n\
    \      Tutorial: The current definition of this term is less specific\n      than\
    \ an earlier version: \"Classified or controlled cryptographic\n      item endorsed\
    \ by the NSA for securing classified and sensitive\n      U.S. Government information,\
    \ when appropriately keyed. The term\n      refers only to products, and not to\
    \ information, key, services, or\n      controls. Type 1 products contain classified\
    \ NSA algorithms. They\n      are available to U.S. Government users, their contractors,\
    \ and\n      federally sponsored non-U.S. Government activities subject to\n \
    \     export restrictions in accordance with International Traffic in\n      Arms\
    \ Regulation.\" [from an earlier version of C4009] (See: ITAR.)\n   $ type 2 key\n\
    \      (O) /cryptography, U.S. Government/ \"Generated and distributed\n     \
    \ under the auspices of NSA for use in a cryptographic device for\n      the protection\
    \ of unclassified national security information.\"\n      [C4009]\n   $ type 2\
    \ product\n      (O) /cryptography, U.S. Government/ \"Cryptographic equipment,\n\
    \      assembly, or component certified by NSA for encrypting or\n      decrypting\
    \ sensitive national security information when\n      appropriately keyed. Developed\
    \ using established NSA business\n      processes and containing NSA approved\
    \ algorithms. Used to protect\n      systems requiring protection mechanisms exceeding\
    \ best commercial\n      practices including systems used for the protection of\n\
    \      unclassified national security information.\" [C4009]\n      Tutorial:\
    \ The current definition of this term is less specific\n      than an earlier\
    \ version: \"Unclassified cryptographic equipment,\n      assembly, or component,\
    \ endorsed by the NSA, for use in national\n      security systems as defined\
    \ in Title 40 U.S.C. Section 1452.\"\n      [from an earlier version of C4009]\
    \ (See: national security system.\n      Compare: EUCI.)\n   $ type 3 key\n  \
    \    (O) /cryptography, U.S. Government/ \"Used in a cryptographic\n      device\
    \ for the protection of unclassified sensitive information,\n      even if used\
    \ in a Type 1 or Type 2 product.\" [C4009]\n   $ type 3 product\n      (O) /cryptography,\
    \ U.S. Government/ \"Unclassified cryptographic\n      equipment, assembly, or\
    \ component used, when appropriately keyed,\n      for encrypting or decrypting\
    \ unclassified sensitive U.S.\n      Government or commercial information, and\
    \ to protect systems\n      requiring protection mechanisms consistent with standard\n\
    \      commercial practices. Developed using established commercial\n      standards\
    \ and containing NIST approved cryptographic\n      algorithms/modules or successfully\
    \ evaluated by the National\n      Information Assurance Partnership (NIAP).\"\
    \ [C4009]\n   $ type 4 key\n      (O) /cryptography, U.S. Government/ \"Used by\
    \ a cryptographic\n      device in support of its Type 4 functionality; i.e.,\
    \ any provision\n      of key that lacks U.S. Government endorsement or oversight.\"\
    \n      [C4009]\n   $ type 4 product\n      (O) /cryptography, U.S. Government/\
    \ \"Unevaluated commercial\n      cryptographic equipment, assemblies, or components\
    \ that neither\n      NSA nor NIST certify for any Government usage. These products\
    \ are\n      typically delivered as part of commercial offerings and are\n   \
    \   commensurate with the vendor's commercial practices. These\n      products\
    \ may contain either vendor proprietary algorithms,\n      algorithms registered\
    \ by NIST, or algorithms registered by NIST\n      and published in a FIPS.\"\
    \ [C4009]\n   $ UDP\n      (I) See: User Datagram Protocol.\n   $ UDP flood\n\
    \      (I) A denial-of-service attack that takes advantage of (a) one\n      system's\
    \ UDP test function that generates a series of characters\n      for each packet\
    \ it receives and (b) another system's UPD test\n      function that echoes any\
    \ character it receives; the attack\n      connects (a) to (b) to cause a nonstop\
    \ flow of data between the\n      two systems. (See: flooding.)\n   $ unauthorized\
    \ disclosure\n      (I) A circumstance or event whereby an entity gains access\
    \ to\n      information for which the entity is not authorized.\n      Tutorial:\
    \ This type of threat consequence can be caused by the\n      following types\
    \ of threat actions: exposure, interception,\n      inference, and intrusion.\
    \ Some methods of protecting against this\n      consequence include access control,\
    \ flow control, and inference\n      control. (See: data confidentiality.)\n \
    \  $ unauthorized user\n      (I) /access control/ A system entity that accesses\
    \ a system\n      resource for which the entity has not received an authorization.\n\
    \      (See: user. Compare: authorized user, insider, outsider.)\n      Usage:\
    \ IDOCs that use this term SHOULD state a definition for it\n      because the\
    \ term is used in many ways and could easily be\n      misunderstood.\n   $ uncertainty\n\
    \      (N) An information-theoretic measure (usually stated as a number\n    \
    \  of bits) of the minimum amount of plaintext information that needs\n      to\
    \ be recovered from cipher text to learn the entire plain text\n      that was\
    \ encrypted. [SP63] (See: entropy.)\n   $ unclassified\n      (I) Not classified.\
    \ (Compare: FOUO.)\n   $ unencrypted\n      (I) Not encrypted.\n   $ unforgeable\n\
    \      (I) /cryptography/ The property of a cryptographic data structure\n   \
    \   (i.e., a data structure that is defined using one or more\n      cryptographic\
    \ functions, e.g., \"digital certificate\") that makes\n      it computationally\
    \ infeasible to construct (i.e., compute) an\n      unauthorized but correct value\
    \ of the structure without having\n      knowledge of one of more keys.\n    \
    \  Tutorial: This definition is narrower than general English usage,\n      where\
    \ \"unforgeable\" means unable to be fraudulently created or\n      duplicated.\
    \ In that broader sense, anyone can forge a digital\n      certificate containing\
    \ any set of data items whatsoever by\n      generating the to-be-signed certificate\
    \ and signing it with any\n      private key whatsoever. But for PKI purposes,\
    \ the forged data\n      structure is invalid if it is not signed with the true\
    \ private key\n      of the claimed issuer; thus, the forgery will be detected\
    \ when a\n      certificate user uses the true public key of the claimed issuer\
    \ to\n      verify the signature.\n   $ uniform resource identifier (URI)\n  \
    \    (I) A type of formatted identifier (RFC 3986) that encapsulates\n      the\
    \ name of an Internet object, and labels it with an\n      identification of the\
    \ name space, thus producing a member of the\n      universal set of names in\
    \ registered name spaces and of addresses\n      referring to registered protocols\
    \ or name spaces.\n      Example: HTML uses URIs to identify the target of hyperlinks.\n\
    \      Usage: \"A URI can be classified as a locator (see: URL), a name\n    \
    \  (see: URN), or both. ... Instances of URIs from any given scheme\n      may\
    \ have the characteristics of names or locators or both, often\n      depending\
    \ on the persistence and care in the assignment of\n      identifiers by the naming\
    \ authority, rather than on any quality of\n      the scheme.\" IDOCs SHOULD \"\
    use the general term 'URI' rather than\n      the more restrictive terms 'URL'\
    \ and 'URN'.\" (RFC 3986)\n   $ uniform resource locator (URL)\n      (I) A URI\
    \ that describes the access method and location of an\n      information resource\
    \ object on the Internet. (See: Usage under\n      \"URI\". Compare: URN.)\n \
    \     Tutorial: The term URL \"refers to the subset of URIs that, besides\n  \
    \    identifying a resource, provide a means of locating the resource\n      by\
    \ describing its primary access mechanism (e.g., its network\n      'location').\"\
    \ (RFC 3986)\n      A URL provides explicit instructions on how to access the\
    \ named\n      object. For example,\n      \"ftp://bbnarchive.bbn.com/foo/bar/picture/cambridge.zip\"\
    \ is a URL.\n      The part before the colon specifies the access scheme or protocol,\n\
    \      and the part after the colon is interpreted according to that\n      access\
    \ method. Usually, two slashes after the colon indicate the\n      host name of\
    \ a server (written as a domain name). In an FTP or\n      HTTP URL, the host\
    \ name is followed by the path name of a file on\n      the server. The last (optional)\
    \ part of a URL may be either a\n      fragment identifier that indicates a position\
    \ in the file, or a\n      query string.\n   $ uniform resource name (URN)\n \
    \     (I) A URI with the properties of a name. (See: Usage under \"URI\".\n  \
    \    Compare: URL.)\n      Tutorial: The term URN \"has been used historically\
    \ to refer to\n      both URIs under the \"urn\" scheme (RFC 2141), which are\
    \ required to\n      remain globally unique and persistent even when the resource\n\
    \      ceases to exist or becomes unavailable, and to any other URI with\n   \
    \   the properties of a name.\" (RFC 3986)\n   $ untrusted\n      (I) See: secondary\
    \ definition under \"trust\".\n   $ untrusted process\n      1. (I) A system component\
    \ that is not able to affect the state of\n      system security through incorrect\
    \ or malicious operation. Example:\n      A component that has its operations\
    \ confined by a security kernel.\n      (See: trusted process.)\n      2. (I)\
    \ A system component that (a) has not been evaluated or\n      examined for adherence\
    \ to a specified security policy and,\n      therefore, (b) must be assumed to\
    \ contain logic that might attempt\n      to circumvent system security.\n   $\
    \ UORA\n      (O) See: user-PIN ORA.\n   $ update\n      See: \"certificate update\"\
    \ and \"key update\".\n   $ upgrade\n      (I) /data security/ Increase the classification\
    \ level of data\n      without changing the information content of the data. (See:\n\
    \      classify, downgrade, regrade.)\n   $ URI\n      (I) See: uniform resource\
    \ identifier.\n   $ URL\n      (I) See: uniform resource locator.\n   $ URN\n\
    \      (I) See: uniform resource name.\n   $ user\n      See: system user.\n \
    \     Usage: IDOCs that use this term SHOULD state a definition for it\n     \
    \ because the term is used in many ways and could easily be\n      misunderstood.\n\
    \   $ user authentication service\n      (I) A security service that verifies\
    \ the identity claimed by an\n      entity that attempts to access the system.\
    \ (See: authentication,\n      user.)\n   $ User Datagram Protocol (UDP)\n   \
    \   (I) An Internet Standard, Transport-Layer protocol (RFC 768) that\n      delivers\
    \ a sequence of datagrams from one computer to another in a\n      computer network.\
    \ (See: UPD flood.)\n      Tutorial: UDP assumes that IP is the underlying protocol.\
    \ UDP\n      enables application programs to send transaction-oriented data to\n\
    \      other programs with minimal protocol mechanism. UDP does not\n      provide\
    \ reliable delivery, flow control, sequencing, or other end-\n      to-end service\
    \ guarantees that TCP does.\n   $ user identifier\n      (I) See: identifier.\n\
    \   $ user identity\n      (I) See: identity.\n   $ user PIN\n      (O) /MISSI/\
    \ One of two PINs that control access to the functions\n      and stored data\
    \ of a FORTEZZA PC card. Knowledge of the user PIN\n      enables a card user\
    \ to perform the FORTEZZA functions that are\n      intended for use by an end\
    \ user. (See: PIN. Compare: SSO PIN.)\n   $ user-PIN ORA (UORA)\n      (O) /MISSI/\
    \ A MISSI organizational RA that operates in a mode in\n      which the ORA performs\
    \ only the subset of card management\n      functions that are possible with knowledge\
    \ of the user PIN for a\n      FORTEZZA PC card. (See: no-PIN ORA, SSO-PIN ORA.)\n\
    \   $ usurpation\n      (I) A circumstance or event that results in control of\
    \ system\n      services or functions by an unauthorized entity. This type of\n\
    \      threat consequence can be caused by the following types of threat\n   \
    \   actions: misappropriation, misuse. (See: access control.)\n   $ UTCTime\n\
    \      (N) The ASN.1 data type \"UTCTime\" contains a calendar date\n      (YYMMDD)\
    \ and a time to a precision of either one minute (HHMM) or\n      one second (HHMMSS),\
    \ where the time is either (a) Coordinated\n      Universal Time or (b) the local\
    \ time followed by an offset that\n      enables Coordinated Universal Time to\
    \ be calculated. (See:\n      Coordinated Universal Time. Compare: GeneralizedTime.)\n\
    \      Usage: If you care about centuries or millennia, you probably need\n  \
    \    to use the GeneralizedTime data type instead of UTCTime.\n   $ v1 certificate\n\
    \      (N) An abbreviation that ambiguously refers to either an \"X.509\n    \
    \  public-key certificate in version 1 format\" or an \"X.509 attribute\n    \
    \  certificate in version 1 format\".\n      Deprecated Usage: IDOCs MAY use this\
    \ term as an abbreviation of\n      \"version 1 X.509 public-key certificate\"\
    , but only after using the\n      full term at the first instance. Otherwise,\
    \ the term is ambiguous,\n      because X.509 specifies both v1 public-key certificates\
    \ and v1\n      attribute certificates. (See: X.509 attribute certificate, X.509\n\
    \      public-key certificate.)\n   $ v1 CRL\n      (N) Abbreviation of \"X.509\
    \ CRL in version 1 format\".\n      Usage: IDOCs MAY use this abbreviation, but\
    \ SHOULD use the full\n      term at its first occurrence and define the abbreviation\
    \ there.\n   $ v2 certificate\n      (N) Abbreviation of \"X.509 public-key certificate\
    \ in version 2\n      format\".\n      Usage: IDOCs MAY use this abbreviation,\
    \ but SHOULD use the full\n      term at its first occurrence and define the abbreviation\
    \ there.\n   $ v2 CRL\n      (N) Abbreviation of \"X.509 CRL in version 2 format\"\
    .\n      Usage: IDOCs MAY use this abbreviation, but SHOULD use the full\n   \
    \   term at its first occurrence and define the abbreviation there.\n   $ v3 certificate\n\
    \      (N) Abbreviation of \"X.509 public-key certificate in version 3\n     \
    \ format\".\n      Usage: IDOCs MAY use this abbreviation, but SHOULD use the\
    \ full\n      term at its first occurrence and define the abbreviation there.\n\
    \   $ valid certificate\n      1. (I) A digital certificate that can be validated\
    \ successfully.\n      (See: validate, verify.)\n      2. (I) A digital certificate\
    \ for which the binding of the data\n      items can be trusted.\n   $ valid signature\n\
    \      (D) Synonym for \"verified signature\".\n      Deprecated Term: IDOCs SHOULD\
    \ NOT use this synonym. This Glossary\n      recommends saying \"validate the\
    \ certificate\" and \"verify the\n      signature\"; therefore, it would be inconsistent\
    \ to say that a\n      signature is \"valid\". (See: validate, verify.)\n   $\
    \ validate\n      1. (I) Establish the soundness or correctness of a construct.\n\
    \      Example: certificate validation. (See: validate vs. verify.)\n      2.\
    \ (I) To officially approve something, sometimes in relation to a\n      standard.\
    \ Example: NIST validates cryptographic modules for\n      conformance with [FP140].\n\
    \   $ validate vs. verify\n      Usage: To ensure consistency and align with ordinary\
    \ English\n      usage, IDOCs SHOULD comply with the following two rules:\n  \
    \    -  Rule 1: Use \"validate\" when referring to a process intended to\n   \
    \      establish the soundness or correctness of a construct (e.g.,\n        \
    \ \"certificate validation\"). (See: validate.)\n      -  Rule 2: Use \"verify\"\
    \ when referring to a process intended to\n         test or prove the truth or\
    \ accuracy of a fact or value (e.g.,\n         \"authenticate\"). (See: verify.)\n\
    \      Tutorial: The Internet security community sometimes uses these two\n  \
    \    terms inconsistently, especially in a PKI context. Most often,\n      however,\
    \ we say \"verify the signature\" but say \"validate the\n      certificate\"\
    . That is, we \"verify\" atomic truths but \"validate\"\n      data structures,\
    \ relationships, and systems that are composed of\n      or depend on verified\
    \ items. This usage has a basis in Latin:\n      The word \"valid\" derives from\
    \ a Latin word that means \"strong\".\n      Thus, to validate means to check\
    \ that a construct is sound. For\n      example, a certificate user validates\
    \ a public-key certificate to\n      establish trust in the binding that the certificate\
    \ asserts\n      between an identity and a key. This can include checking various\n\
    \      aspects of the certificate's construction, such as verifying the\n    \
    \  digital signature on the certificate by performing calculations,\n      verifying\
    \ that the current time is within the certificate's\n      validity period, and\
    \ validating a certification path involving\n      additional certificates.\n\
    \      The word \"verify\" derives from a Latin word that means \"true\".\n  \
    \    Thus, to verify means to check the truth of an assertion by\n      examining\
    \ evidence or performing tests. For example, to verify an\n      identity, an\
    \ authentication process examines identification\n      information that is presented\
    \ or generated. To validate a\n      certificate, a certificate user verifies\
    \ the digital signature on\n      the certificate by performing calculations,\
    \ verifies that the\n      current time is within the certificate's validity period,\
    \ and may\n      need to validate a certification path involving additional\n\
    \      certificates.\n   $ validation\n      (I) See: validate vs. verify.\n \
    \  $ validity period\n      (I) /PKI/ A data item in a digital certificate that\
    \ specifies the\n      time period for which the binding between data items (especially\n\
    \      between the subject name and the public key value in a public-key\n   \
    \   certificate) is valid, except if the certificate appears on a CRL\n      or\
    \ the key appears on a CKL. (See: cryptoperiod, key lifetime.)\n   $ value-added\
    \ network (VAN)\n      (I) A computer network or subnetwork (usually a commercial\n\
    \      enterprise) that transmits, receives, and stores EDI transactions\n   \
    \   on behalf of its users.\n      Tutorial: A VAN may also provide additional\
    \ services, ranging from\n      EDI format translation, to EDI-to-FAX conversion,\
    \ to integrated\n      business systems.\n   $ VAN\n      (I) See: value-added\
    \ network.\n   $ verification\n      1. (I) /authentication/ The process of examining\
    \ information to\n      establish the truth of a claimed fact or value. (See:\
    \ validate vs.\n      verify, verify. Compare: authentication.)\n      2. (N)\
    \ /COMPUSEC/ The process of comparing two levels of system\n      specification\
    \ for proper correspondence, such as comparing a\n      security model with a\
    \ top-level specification, a top-level\n      specification with source code,\
    \ or source code with object code.\n      [NCS04]\n   $ verified design\n    \
    \  (O) See: TCSEC Class A1.\n   $ verify\n      (I) To test or prove the truth\
    \ or accuracy of a fact or value.\n      (See: validate vs. verify, verification.\
    \ Compare: authenticate.)\n   $ vet\n      (I) /verb/ To examine or evaluate thoroughly.\
    \ (Compare:\n      authenticate, identity proofing, validate, verify.)\n   $ violation\n\
    \      See: security violation.\n   $ virtual private network (VPN)\n      (I)\
    \ A restricted-use, logical (i.e., artificial or simulated)\n      computer network\
    \ that is constructed from the system resources of\n      a relatively public,\
    \ physical (i.e., real) network (e.g., the\n      Internet), often by using encryption\
    \ (located at hosts or\n      gateways), and often by tunneling links of the virtual\
    \ network\n      across the real network. (See: tunnel.)\n      Tutorial: A VPN\
    \ is generally less expensive to build and operate\n      than a dedicated real\
    \ network, because the virtual network shares\n      the cost of system resources\
    \ with other users of the underlying\n      real network. For example, if a corporation\
    \ has LANs at several\n      different sites, each connected to the Internet by\
    \ a firewall, the\n      corporation could create a VPN by using encrypted tunnels\
    \ to\n      connect from firewall to firewall across the Internet.\n   $ virus\n\
    \      (I) A self-replicating (and usually hidden) section of computer\n     \
    \ software (usually malicious logic) that propagates by infecting --\n      i.e.,\
    \ inserting a copy of itself into and becoming part of --\n      another program.\
    \ A virus cannot run by itself; it requires that\n      its host program be run\
    \ to make the virus active.\n   $ Visa Cash\n      (O) A smartcard-based electronic\
    \ money system that incorporates\n      cryptography and can be used to make payments\
    \ via the Internet.\n      (See: IOTP.)\n   $ volatile media\n      (I) Storage\
    \ media that require an external power supply to\n      maintain stored information.\
    \ (Compare: non-volatile media,\n      permanent storage.)\n   $ VPN\n      (I)\
    \ See: virtual private network.\n   $ vulnerability\n      (I) A flaw or weakness\
    \ in a system's design, implementation, or\n      operation and management that\
    \ could be exploited to violate the\n      system's security policy. (See: harden.)\n\
    \      Tutorial: A system can have three types of vulnerabilities: (a)\n     \
    \ vulnerabilities in design or specification; (b) vulnerabilities in\n      implementation;\
    \ and (c) vulnerabilities in operation and\n      management. Most systems have\
    \ one or more vulnerabilities, but\n      this does not mean that the systems\
    \ are too flawed to use. Not\n      every threat results in an attack, and not\
    \ every attack succeeds.\n      Success depends on the degree of vulnerability,\
    \ the strength of\n      attacks, and the effectiveness of any countermeasures\
    \ in use. If\n      the attacks needed to exploit a vulnerability are very difficult\n\
    \      to carry out, then the vulnerability may be tolerable. If the\n      perceived\
    \ benefit to an attacker is small, then even an easily\n      exploited vulnerability\
    \ may be tolerable. However, if the attacks\n      are well understood and easily\
    \ made, and if the vulnerable system\n      is employed by a wide range of users,\
    \ then it is likely that there\n      will be enough motivation for someone to\
    \ launch an attack.\n   $ W3\n      (D) Synonym for WWW.\n      Deprecated Abbreviation:\
    \ This abbreviation could be confused with\n      W3C; use \"WWW\" instead.\n\
    \   $ W3C\n      (N) See: World Wide Web Consortium.\n   $ war dialer\n      (I)\
    \ /slang/ A computer program that automatically dials a series\n      of telephone\
    \ numbers to find lines connected to computer systems,\n      and catalogs those\
    \ numbers so that a cracker can try to break the\n      systems.\n      Deprecated\
    \ Usage: IDOCs that use this term SHOULD state a\n      definition for it because\
    \ the term could confuse international\n      readers.\n   $ Wassenaar Arrangement\n\
    \      (N) The Wassenaar Arrangement on Export Controls for Conventional\n   \
    \   Arms and Dual-Use Goods and Technologies is a global, multilateral\n     \
    \ agreement approved by 33 countries in July 1996 to contribute to\n      regional\
    \ and international security and stability, by promoting\n      information exchange\
    \ concerning, and greater responsibility in,\n      transfers of arms and dual-use\
    \ items, thus preventing\n      destabilizing accumulations. (See: International\
    \ Traffic in Arms\n      Regulations.)\n      Tutorial: The Arrangement began\
    \ operations in September 1996 with\n      headquarters in Vienna. The participating\
    \ countries were\n      Argentina, Australia, Austria, Belgium, Bulgaria, Canada,\
    \ Czech\n      Republic, Denmark, Finland, France, Germany, Greece, Hungary,\n\
    \      Ireland, Italy, Japan, Luxembourg, Netherlands, New Zealand,\n      Norway,\
    \ Poland, Portugal, Republic of Korea, Romania, Russian\n      Federation, Slovak\
    \ Republic, Spain, Sweden, Switzerland, Turkey,\n      Ukraine, United Kingdom,\
    \ and United States.\n      Participating countries seek through their national\
    \ policies to\n      ensure that transfers do not contribute to the development\
    \ or\n      enhancement of military capabilities that undermine the goals of\n\
    \      the arrangement, and are not diverted to support such\n      capabilities.\
    \ The countries maintain effective export controls for\n      items on the agreed\
    \ lists, which are reviewed periodically to\n      account for technological developments\
    \ and experience gained.\n      Through transparency and exchange of views and\
    \ information,\n      suppliers of arms and dual-use items can develop common\n\
    \      understandings of the risks associated with their transfer and\n      assess\
    \ the scope for coordinating national control policies to\n      combat these\
    \ risks. Members provide semi-annual notification of\n      arms transfers, covering\
    \ seven categories derived from the UN\n      Register of Conventional Arms. Members\
    \ also report transfers or\n      denials of transfers of certain controlled dual-use\
    \ items.\n      However, the decision to transfer or deny transfer of any item\
    \ is\n      the sole responsibility of each participating country. All\n     \
    \ measures undertaken with respect to the arrangement are in\n      accordance\
    \ with national legislation and policies and are\n      implemented on the basis\
    \ of national discretion.\n   $ watermarking\n      See: digital watermarking.\n\
    \   $ weak key\n      (I) In the context of a particular cryptographic algorithm,\
    \ a key\n      value that provides poor security. (See: strong.)\n      Example:\
    \ The DEA has four \"weak keys\" [Schn] for which encryption\n      produces the\
    \ same result as decryption. It also has ten pairs of\n      \"semi-weak keys\"\
    \ [Schn] (a.k.a. \"dual keys\" [FP074]) for which\n      encryption with one key\
    \ in the pair produces the same result as\n      decryption with the other key.\n\
    \   $ web, Web\n      1. (I) /not capitalized/ IDOCs SHOULD NOT capitalize \"\
    web\" when\n      using the term (usually as an adjective) to refer generically\
    \ to\n      technology -- such as web browsers, web servers, HTTP, and HTML --\n\
    \      that is used in the Web or similar networks.\n      2. (I) /capitalized/\
    \ IDOCs SHOULD capitalize \"Web\" when using the\n      term (as either a noun\
    \ or an adjective) to refer specifically to\n      the World Wide Web. (Similarly,\
    \ see: internet.)\n      Usage: IDOCs SHOULD NOT use \"web\" or \"Web\" in a way\
    \ that might\n      confuse these definitions with the PGP \"web of trust\". When\
    \ using\n      Web as an abbreviation for \"World Wide Web\", IDOCs SHOULD fully\n\
    \      spell out the term at the first instance of usage.\n   $ web of trust\n\
    \      (D) /PGP/ A PKI architecture in which each certificate user\n      defines\
    \ their own trust anchor(s) by depending on personal\n      relationships. (See:\
    \ trust anchor. Compare: hierarchical PKI, mesh\n      PKI.)\n      Deprecated\
    \ Usage: IDOCs SHOULD NOT use this term except with\n      reference to PGP. This\
    \ term mixes concepts in potentially\n      misleading ways; e.g., this architecture\
    \ does not depend on World\n      Wide Web technology. Instead of this term, IDOCs\
    \ MAY use \"trust-\n      file PKI\". (See: web, Web).\n      Tutorial: This type\
    \ of architecture does not usually include\n      public repositories of certificates.\
    \ Instead, each certificate\n      user builds their own, private repository of\
    \ trusted public keys\n      by making personal judgments about being able to\
    \ trust certain\n      people to be holding properly certified keys of other people.\
    \ It\n      is this set of person-to-person relationships from which the\n   \
    \   architecture gets its name.\n   $ web server\n      (I) A software process\
    \ that runs on a host computer connected to a\n      network and responds to HTTP\
    \ requests made by client web browsers.\n   $ WEP\n      (N) See: Wired Equivalency\
    \ Protocol.\n   $ Wired Equivalent Privacy (WEP)\n      (N) A cryptographic protocol\
    \ that is defined in the IEEE 802.11\n      standard and encapsulates the packets\
    \ on wireless LANs. Usage:\n      a.k.a. \"Wired Equivalency Protocol\".\n   \
    \   Tutorial: The WEP design, which uses RC4 to encrypt both the plain\n     \
    \ text and a CRC, has been shown to be flawed in multiple ways; and\n      it\
    \ also has often suffered from flawed implementation and\n      management.\n\
    \   $ wiretapping\n      (I) An attack that intercepts and accesses information\
    \ contained\n      in a data flow in a communication system. (See: active\n  \
    \    wiretapping, end-to-end encryption, passive wiretapping, secondary\n    \
    \  definition under \"interception\".)\n      Usage: Although the term originally\
    \ referred to making a\n      mechanical connection to an electrical conductor\
    \ that links two\n      nodes, it is now used to refer to accessing information\
    \ from any\n      sort of medium used for a link or even from a node, such as\
    \ a\n      gateway or subnetwork switch.\n      Tutorial: Wiretapping can be characterized\
    \ according to intent:\n      -  \"Active wiretapping\" attempts to alter the\
    \ data or otherwise\n         affect the flow.\n      -  \"Passive wiretapping\"\
    \ only attempts to observe the data flow\n         and gain knowledge of information\
    \ contained in it.\n   $ work factor\n      1a. (I) /COMPUSEC/ The estimated amount\
    \ of effort or time that can\n      be expected to be expended by a potential\
    \ intruder to penetrate a\n      system, or defeat a particular countermeasure,\
    \ when using\n      specified amounts of expertise and resources. (See: brute\
    \ force,\n      impossible, strength.)\n      1b. (I) /cryptography/ The estimated\
    \ amount of computing power and\n      time needed to break a cryptographic system.\
    \ (See: brute force,\n      impossible, strength.)\n   $ World Wide Web (\"the\
    \ Web\", WWW)\n      (N) The global, hypermedia-based collection of information\
    \ and\n      services that is available on Internet servers and is accessed by\n\
    \      browsers using Hypertext Transfer Protocol and other information\n    \
    \  retrieval mechanisms. (See: web vs. Web, [R2084].)\n   $ World Wide Web Consortium\
    \ (W3C)\n      (N) Created in October 1994 to develop and standardize protocols\n\
    \      to promote the evolution and interoperability of the Web, and now\n   \
    \   consisting of hundreds of member organizations (commercial firms,\n      governmental\
    \ agencies, schools, and others).\n      Tutorial: W3C Recommendations are developed\
    \ through a process\n      similar to that of the standards published by other\
    \ organizations,\n      such as the IETF. The W3 Recommendation Track (i.e., standards\n\
    \      track) has four levels of increasing maturity: Working, Candidate\n   \
    \   Recommendation, Proposed Recommendation, and W3C Recommendation.\n      W3C\
    \ Recommendations are similar to the standards published by\n      other organizations.\
    \ (Compare: Internet Standard, ISO.)\n   $ worm\n      (I) A computer program\
    \ that can run independently, can propagate a\n      complete working version\
    \ of itself onto other hosts on a network,\n      and may consume system resources\
    \ destructively. (See: mobile code,\n      Morris Worm, virus.)\n   $ wrap\n \
    \     1. (N) To use cryptography to provide data confidentiality service\n   \
    \   for keying material. (See: encrypt, wrapping algorithm, wrapping\n      key.\
    \ Compare: seal, shroud.)\n      2. (D) To use cryptography to provide data confidentiality\
    \ service\n      for data in general.\n      Deprecated Usage: IDOCs SHOULD NOT\
    \ use this term with definition 2\n      because that duplicates the meaning of\
    \ the more widely understood\n      \"encrypt\".\n   $ wrapping algorithm\n  \
    \    (N) An encryption algorithm that is specifically intended for use\n     \
    \ in encrypting keys. (See: KEK, wrap.)\n   $ wrapping key\n      (N) Synonym\
    \ for \"KEK\". (See: encrypt. Compare: seal, shroud.)\n   $ write\n      (I) /security\
    \ model/ A system operation that causes a flow of\n      information from a subject\
    \ to an object. (See: access mode.\n      Compare: read.)\n   $ WWW\n      (I)\
    \ See: World Wide Web.\n   $ X.400\n      (N) An ITU-T Recommendation [X400] that\
    \ is one part of a joint\n      ITU-T/ISO multi-part standard (X.400-X.421) that\
    \ defines the\n      Message Handling Systems. (The ISO equivalent is IS 10021,\
    \ parts\n      1-7.) (See: Message Handling Systems.)\n   $ X.500\n      (N) An\
    \ ITU-T Recommendation [X500] that is one part of a joint\n      ITU-T/ISO multi-part\
    \ standard (X.500-X.525) that defines the X.500\n      Directory, a conceptual\
    \ collection of systems that provide\n      distributed directory capabilities\
    \ for OSI entities, processes,\n      applications, and services. (The ISO equivalent\
    \ is IS 9594-1 and\n      related standards, IS 9594-x.) (See: directory vs. Directory,\n\
    \      X.509.)\n      Tutorial: The X.500 Directory is structured as a tree (the\n\
    \      Directory Information Tree), and information is stored in\n      directory\
    \ entries. Each entry is a collection of information about\n      one object,\
    \ and each object has a DN. A directory entry is\n      composed of attributes,\
    \ each with a type and one or more values.\n      For example, if a PKI uses the\
    \ Directory to distribute\n      certificates, then the X.509 public-key certificate\
    \ of an end user\n      is normally stored as a value of an attribute of type\n\
    \      \"userCertificate\" in the Directory entry that has the DN that is\n  \
    \    the subject of the certificate.\n   $ X.509\n      (N) An ITU-T Recommendation\
    \ [X509] that defines a framework to\n      provide and support data origin authentication\
    \ and peer entity\n      authentication, including formats for X.509 public-key\n\
    \      certificates, X.509 attribute certificates, and X.509 CRLs. (The\n    \
    \  ISO equivalent is IS 9498-4.) (See: X.500.)\n      Tutorial: X.509 describes\
    \ two \"levels\" of authentication: \"simple\n      authentication\" and \"strong\
    \ authentication\". It recommends, \"While\n      simple authentication offers\
    \ some limited protection against\n      unauthorized access, only strong authentication\
    \ should be used as\n      the basis for providing secure services.\"\n   $ X.509\
    \ attribute certificate\n      (N) An attribute certificate in the version 1 (v1)\
    \ format defined\n      by X.509. (The v1 designation for an X.509 attribute certificate\n\
    \      is disjoint from the v1 designation for an X.509 public-key\n      certificate,\
    \ and from the v1 designation for an X.509 CRL.)\n      Tutorial: An X.509 attribute\
    \ certificate has a \"subject\" field,\n      but the attribute certificate is\
    \ a separate data structure from\n      that subject's public-key certificate.\
    \ A subject may have multiple\n      attribute certificates associated with each\
    \ of its public-key\n      certificates, and an attribute certificate may be issued\
    \ by a\n      different CA than the one that issued the associated public-key\n\
    \      certificate.\n      An X.509 attribute certificate contains a sequence\
    \ of data items\n      and has a digital signature that is computed from that\
    \ sequence.\n      Besides the signature, an attribute certificate contains items\
    \ 1\n      through 9 listed below:\n      1. version                 Identifies\
    \ v1.\n      2. subject                 Is one of the following:\n         2a.\
    \ baseCertificateID   Issuer and serial number of an\n                       \
    \          X.509 public-key certificate.\n         2b. subjectName         DN\
    \ of the subject.\n      3. issuer                  DN of the issuer (the CA who\
    \ signed).\n      4. signature               OID of algorithm that signed the\
    \ cert.\n      5. serialNumber            Certificate serial number;\n       \
    \                          an integer assigned by the issuer.\n      6. attCertValidityPeriod\
    \   Validity period; a pair of UTCTime\n                                 values:\
    \ \"not before\" and \"not after\".\n      7. attributes              Sequence\
    \ of attributes describing the\n                                 subject.\n  \
    \    8. issuerUniqueId          Optional, when a DN is not sufficient.\n     \
    \ 9. extensions              Optional.\n   $ X.509 certificate\n      (N) Synonym\
    \ for \"X.509 public-key certificate\".\n      Usage: IDOCs MAY use this term\
    \ as an abbreviation of \"X.509\n      public-key certificate\", but only after\
    \ using the full term at the\n      first instance. Otherwise, the term is ambiguous,\
    \ because X.509\n      specifies both public-key certificates and attribute certificates.\n\
    \      (See: X.509 attribute certificate, X.509 public-key certificate.)\n   \
    \   Deprecated Usage: IDOCs SHOULD NOT use this term as an\n      abbreviation\
    \ of \"X.509 attribute certificate\", because the term is\n      much more commonly\
    \ used to mean \"X.509 public-key certificate\"\n      and, therefore, is likely\
    \ to be misunderstood.\n   $ X.509 certificate revocation list (CRL)\n      (N)\
    \ A CRL in one of the formats defined by X.509 -- version 1 (v1)\n      or version\
    \ 2 (v2). (The v1 and v2 designations for an X.509 CRL\n      are disjoint from\
    \ the v1 and v2 designations for an X.509 public-\n      key certificate, and\
    \ from the v1 designation for an X.509\n      attribute certificate.) (See: certificate\
    \ revocation.)\n      Usage: IDOCs SHOULD NOT refer to an X.509 CRL as a digital\n\
    \      certificate; however, note that an X.509 CRL does meet this\n      Glossary's\
    \ definition of \"digital certificate\". That is, like a\n      digital certificate,\
    \ an X.509 CRL makes an assertion and is signed\n      by a CA. But instead of\
    \ binding a key or other attributes to a\n      subject, an X.509 CRL asserts\
    \ that certain previously issued,\n      X.509 certificates have been revoked.\n\
    \      Tutorial: An X.509 CRL contains a sequence of data items and has a\n  \
    \    digital signature computed on that sequence. Besides the\n      signature,\
    \ both v1 and v2 contain items 2 through 6b listed below.\n      Version 2 contains\
    \ item 1 and may optionally contain 6c and 7.\n      1. version              \
    \   Optional. If present, identifies v2.\n      2. signature               OID\
    \ of the algorithm that signed CRL.\n      3. issuer                  DN of the\
    \ issuer (the CA who signed).\n      4. thisUpdate              A UTCTime value.\n\
    \      5. nextUpdate              A UTCTime value.\n      6. revokedCertificates\
    \     3-tuples of 6a, 6b, and (optional) 6c:\n         6a. userCertificate   \
    \  A certificate's serial number.\n         6b. revocationDate      UTCTime value\
    \ for the revocation date.\n         6c. crlEntryExtensions  Optional.\n     \
    \ 7. crlExtensions           Optional.\n   $ X.509 public-key certificate\n  \
    \    (N) A public-key certificate in one of the formats defined by\n      X.509\
    \ -- version 1 (v1), version 2 (v2), or version 3 (v3). (The\n      v1 and v2\
    \ designations for an X.509 public-key certificate are\n      disjoint from the\
    \ v1 and v2 designations for an X.509 CRL, and\n      from the v1 designation\
    \ for an X.509 attribute certificate.)\n      Tutorial: An X.509 public-key certificate\
    \ contains a sequence of\n      data items and has a digital signature computed\
    \ on that sequence.\n      Besides the signature, all three versions contain items\
    \ 1 through\n      7 listed below. Only v2 and v3 certificates may also contain\
    \ items\n      8 and 9, and only v3 may contain item 10.\n      1. version   \
    \              Identifies v1, v2, or v3.\n      2. serialNumber            Certificate\
    \ serial number;\n                                 an integer assigned by the\
    \ issuer.\n      3. signature               OID of algorithm that was used to\n\
    \                                 sign the certificate.\n      4. issuer     \
    \             DN of the issuer (the CA who signed).\n      5. validity       \
    \         Validity period; a pair of UTCTime\n                               \
    \  values: \"not before\" and \"not after\".\n      6. subject               \
    \  DN of entity who owns the public key.\n      7. subjectPublicKeyInfo    Public\
    \ key value and algorithm OID.\n      8. issuerUniqueIdentifier  Defined for v2,\
    \ v3; optional.\n      9. subjectUniqueIdentifier Defined for v2, v2; optional.\n\
    \      10. extensions             Defined only for v3; optional.\n   $ X9\n  \
    \    (N) See: \"Accredited Standards Committee X9\" under \"ANSI\".\n   $ XML\n\
    \      (N) See: Extensible Markup Language.\n   $ XML-Signature.\n      (N) A\
    \ W3C Recommendation (i.e., approved standard) that specifies\n      XML syntax\
    \ and processing rules for creating and representing\n      digital signatures\
    \ (based on asymmetric cryptography) that can be\n      applied to any digital\
    \ content (i.e., any data object) including\n      other XML material.\n   $ Yellow\
    \ Book\n      (D) /slang/ Synonym for \"Computer Security Requirements: Guidance\n\
    \      for Applying the [U.S.] Department of Defense Trusted Computer\n      System\
    \ Evaluation Criteria in Specific Environments\" [CSC3] (See:\n      \"first law\"\
    \ under \"Courtney's laws\".)\n      Deprecated Term: IDOCs SHOULD NOT use this\
    \ term as a synonym for\n      that or any other document. Instead, use the full\
    \ proper name of\n      the document or, in subsequent references, a conventional\n\
    \      abbreviation. (See: Deprecated Usage under \"Green Book\", Rainbow\n  \
    \    Series.)\n   $ zero-knowledge proof\n      (I) /cryptography/ A proof-of-possession\
    \ protocol whereby a system\n      entity can prove possession of some information\
    \ to another entity,\n      without revealing any of that information. (See: proof-of-\n\
    \      possession protocol.)\n   $ zeroize\n      1. (I) Synonym for \"erase\"\
    . (See: sanitize.) Usage: Particularly\n      with regard to erasing keys that\
    \ are stored in a cryptographic\n      module.\n      2. (O) Erase electronically\
    \ stored data by altering the contents\n      of the data storage so as to prevent\
    \ the recovery of the data.\n      [FP140]\n      3. (O) \"To remove or eliminate\
    \ the key from a cryptoequipment or\n      fill device.\" [C4009]\n      Usage:\
    \ The phrase \"zeroize the device\" normally is used to mean\n      erasing all\
    \ keys stored in the device, but sometimes means erasing\n      all keying material\
    \ in the device, or all cryptographic\n      information in the device, or even\
    \ all sensitive information in\n      the device.\n   $ zombie\n      (I) /slang/\
    \ An Internet host computer that has been\n      surreptitiously penetrated by\
    \ an intruder that installed malicious\n      daemon software to cause the host\
    \ to operate as an accomplice in\n      attacking other hosts, particularly in\
    \ distributed attacks that\n      attempt denial of service through flooding.\n\
    \      Deprecated Usage: Other cultures likely use different metaphorical\n  \
    \    terms (such as \"robot\") for this concept, and some use this term\n    \
    \  for different concepts. Therefore, to avoid international\n      misunderstanding,\
    \ IDOCs SHOULD NOT use this term. Instead, use\n      \"compromised, coopted computer\"\
    \ or other explicitly descriptive\n      terminology. (See: Deprecated Usage under\
    \ \"Green Book\".)\n   $ zone of control\n      (O) /EMSEC/ Synonym for \"inspectable\
    \ space\". [C4009] (See:\n      TEMPEST.)\n"
- title: 5. Security Considerations
  contents:
  - "5. Security Considerations\n   This document mainly defines security terms and\
    \ recommends how to use\n   them. It also provides limited tutorial information\
    \ about security\n   aspects of Internet protocols, but it does not describe in\
    \ detail the\n   vulnerabilities of, or threats to, specific protocols and does\
    \ not\n   definitively describe mechanisms that protect specific protocols.\n"
- title: 6. Normative Reference
  contents:
  - "6. Normative Reference\n   [R2119]  Bradner, S., \"Key words for use in RFCs\
    \ to Indicate\n            Requirement Levels\", BCP 14, RFC 2119, March 1997.\n"
- title: 7. Informative References
  contents:
  - "7. Informative References\n   This Glossary focuses on the Internet Standards\
    \ Process. Therefore,\n   this set of informative references emphasizes international,\n\
    \   governmental, and industrial standards documents. Some RFCs that are\n   especially\
    \ relevant to Internet security are mentioned in Glossary\n   entries in square\
    \ brackets (e.g., \"[R1457]\" in the entry for\n   \"security label\") and are\
    \ listed here; some other RFCs are mentioned\n   in parentheses (e.g., \"(RFC\
    \ 959)\" in the entry for \"File Transport\n   Protocol\") but are not listed\
    \ here.\n   [A1523]  American National Standards Institute, \"American National\n\
    \            Standard Telecom Glossary\", ANSI T1.523-2001.\n   [A3092]  ---,\
    \ \"American National Standard Data Encryption Algorithm\",\n            ANSI\
    \ X3.92-1981, 30 December 1980.\n   [A9009]  ---, \"Financial Institution Message\
    \ Authentication\n            (Wholesale)\", ANSI X9.9-1986, 15 August 1986.\n\
    \   [A9017]  ---, \"Financial Institution Key Management (Wholesale)\",\n    \
    \        X9.17, 4 April 1985. (Defines procedures for manual and\n           \
    \ automated management of keying material and uses DES to\n            provide\
    \ key management for a variety of operational\n            environments.)\n  \
    \ [A9042]  ---, \"Public key Cryptography for the Financial Service\n        \
    \    Industry: Agreement of Symmetric Keys Using Diffie-Hellman\n            and\
    \ MQV Algorithms\", X9.42, 29 January 1999. (See: Diffie-\n            Hellman-Merkle.)\n\
    \   [A9052]  ---, \"Triple Data Encryption Algorithm Modes of Operation\",\n \
    \           X9.52-1998, ANSI approval 9 November 1998.\n   [A9062]  ---, \"Public\
    \ Key Cryptography for the Financial Services\n            Industry: The Elliptic\
    \ Curve Digital Signature Algorithm\n            (ECDSA)\", X9.62-1998, ANSI approval\
    \ 7 January 1999.\n   [A9063]  ---, \"Public Key Cryptography for the Financial\
    \ Services\n            Industry: Key Agreement and Key Transport Using Elliptic\n\
    \            Curve Cryptography\", X9.63-2001.\n   [ACM]    Association for Computing\
    \ Machinery, \"Communications of the\n            ACM\", July 1998 issue with:\
    \ M. Yeung, \"Digital\n            Watermarking\"; N. Memom and P. Wong, \"Protecting\
    \ Digital\n            Media Content\"; and S. Craver, B.-L. Yeo, and M. Yeung,\n\
    \            \"Technical Trials and Legal Tribulations\".\n   [Ande]   Anderson,\
    \ J., \"Computer Security Technology Planning Study\",\n            ESD-TR-73-51,\
    \ Vols. I and II, USAF Electronics Systems Div.,\n            Bedford, MA, October\
    \ 1972. (Available as AD-758206/772806,\n            National Technical Information\
    \ Service, Springfield, VA.)\n   [ANSI]   American National Standards Institute,\
    \ \"Role Based Access\n            Control\", Secretariat, Information Technology\
    \ Industry\n            Council, BSR INCITS 359, DRAFT, 10 November 2003.\n  \
    \ [Army]   U.S. Army Corps of Engineers, \"Electromagnetic Pulse (EMP)\n     \
    \       and Tempest Protection for Facilities\", EP 1110-3-2, 31\n           \
    \ December 1990.\n   [B1822]  Bolt Baranek and Newman Inc., \"Appendix H: Interfacing\
    \ a\n            Host to a Private Line Interface\", in \"Specifications for\n\
    \            the Interconnection of a Host and an IMP\", BBN Report No.\n    \
    \        1822, revised, December 1983.\n   [B4799]  ---, \"A History of the Arpanet:\
    \ The First Decade\", BBN\n            Report No. 4799, April 1981.\n   [Bell]\
    \   Bell, D. and L. LaPadula, \"Secure Computer Systems:\n            Mathematical\
    \ Foundations and Model\", M74-244, The MITRE\n            Corporation, Bedford,\
    \ MA, May 1973. (Available as AD-771543,\n            National Technical Information\
    \ Service, Springfield, VA.)\n   [Biba]   K. Biba, \"Integrity Considerations\
    \ for Secure Computer\n            Systems\", ESD-TR-76-372, USAF Electronic Systems\
    \ Division,\n            Bedford, MA, April 1977.\n   [BN89]   Brewer, D. and\
    \ M. Nash, \"The Chinese wall security policy\",\n            in \"Proceedings\
    \ of IEEE Symposium on Security and Privacy\",\n            May 1989, pp. 205-214.\n\
    \   [BS7799] British Standards Institution, \"Information Security\n         \
    \   Management, Part 1: Code of Practice for Information\n            Security\
    \ Management\", BS 7799-1:1999, 15 May 1999.\n            ---, \"Information Security\
    \ Management, Part 2: Specification\n            for Information Security Management\
    \ Systems\", BS 7799-\n            2:1999, 15 May 1999.\n   [C4009]  Committee\
    \ on National Security Systems (U.S. Government),\n            \"National Information\
    \ Assurance (IA) Glossary\", CNSS\n            Instruction No. 4009, revised June\
    \ 2006.\n   [CCIB]   Common Criteria Implementation Board, \"Common Criteria for\n\
    \            Information Technology Security Evaluation, Part 1:\n           \
    \ Introduction and General Model\", version 2.0, CCIB-98-026,\n            May\
    \ 1998.\n   [Chau]   D. Chaum, \"Untraceable Electronic Mail, Return Addresses,\n\
    \            and Digital Pseudonyms\", in \"Communications of the ACM\",\n   \
    \         vol. 24, no. 2, February 1981, pp. 84-88.\n   [Cheh]   Cheheyl, M.,\
    \ Gasser, M., Huff, G., and J. Millen, \"Verifying\n            Security\", in\
    \ \"ACM Computing Surveys\", vol. 13, no. 3,\n            September 1981, pp.\
    \ 279-339.\n   [Chris]  Chrissis, M. et al, 1993. \"SW-CMM [Capability Maturity\
    \ Model\n            for Software Version\", Release 3.0, Software Engineering\n\
    \            Institute, Carnegie Mellon University, August 1996.\n   [CIPSO] \
    \ Trusted Systems Interoperability Working Group, \"Common IP\n            Security\
    \ Option\", version 2.3, 9 March 1993.\n   [Clark]  Clark, D. and D. Wilson, \"\
    A Comparison of Commercial and\n            Military computer Security Policies\"\
    , in \"Proceedings of the\n            IEEE Symposium on Security and Privacy\"\
    , April 1987, pp.\n            184-194.\n   [Cons]   NSA, \"Consistency Instruction\
    \ Manual for Development of U.S.\n            Government Protection Profiles for\
    \ Use in Basic Robustness\n            Environments\", Release 2.0, 1 March 2004\n\
    \   [CORBA]  Object Management Group, Inc., \"CORBAservices: Common Object\n \
    \           Service Specification\", December 1998.\n   [CSC1]   U.S. DoD Computer\
    \ Security Center, \"Department of Defense\n            Trusted Computer System\
    \ Evaluation Criteria\", CSC-STD-001-\n            83, 15 August 1983. (Superseded\
    \ by [DoD1].)\n   [CSC2]   ---, \"Department of Defense Password Management Guideline\"\
    ,\n            CSC-STD-002-85, 12 April 1985.\n   [CSC3]   ---, \"Computer Security\
    \ Requirements: Guidance for Applying\n            the Department of Defense Trusted\
    \ Computer System Evaluation\n            Criteria in Specific Environments\"\
    , CSC-STD-003-85, 25 June\n            1985.\n   [CSOR]   U.S. Department of Commerce,\
    \ \"General Procedures for\n            Registering Computer Security Objects\"\
    , National Institute\n            of Standards Interagency Report 5308, December\
    \ 1993.\n   [Daem]   Daemen, J. and V. Rijmen, \"Rijndael, the advanced encryption\n\
    \            standard\", in \"Dr. Dobb's Journal\", vol. 26, no. 3, March\n  \
    \          2001, pp. 137-139.\n   [DC6/9]  Director of Central Intelligence, \"\
    Physical Security\n            Standards for Sensitive Compartmented Information\n\
    \            Facilities\", DCI Directive 6/9, 18 November 2002.\n   [Denn]   Denning,\
    \ D., \"A Lattice Model of Secure Information Flow\",\n            in \"Communications\
    \ of the ACM\", vol. 19, no. 5, May 1976,\n            pp. 236-243.\n   [Denns]\
    \  Denning, D. and P. Denning, \"Data Security\", in \"ACM\n            Computing\
    \ Surveys\", vol. 11, no. 3, September 1979, pp. 227-\n            249.\n   [DH76]\
    \   Diffie, W. and M. Hellman, \"New Directions in Cryptography\",\n         \
    \   in \"IEEE Transactions on Information Theory\", vol. IT-22,\n            no.\
    \ 6, November 1976, pp. 644-654. (See: Diffie-Hellman-\n            Merkle.)\n\
    \   [DoD1]   U.S. DoD, \"Department of Defense Trusted Computer System\n     \
    \       Evaluation Criteria\", DoD 5200.28-STD, 26 December 1985.\n          \
    \  (Supersedes [CSC1].) (Superseded by DoD Directive 8500.1.)\n   [DoD4]   ---,\
    \ \"NSA Key Recovery Assessment Criteria\", 8 June 1998.\n   [DoD5]   ---, Directive\
    \ 5200.1, \"DoD Information Security Program\",\n            13 December 1996.\n\
    \   [DoD6]   ---, \"Department of Defense Technical Architecture Framework\n \
    \           for Information Management, Volume 6: Department of Defense\n    \
    \        (DoD) Goal Security Architecture\", Defense Information\n           \
    \ Systems Agency, Center for Standards, version 3.0, 15 April\n            1996.\n\
    \   [DoD7]   ---, \"X.509 Certificate Policy for the United States\n         \
    \   Department of Defense\", version 7, 18 December 2002.\n            (Superseded\
    \ by [DoD9].)\n   [DoD9]   ---, \"X.509 Certificate Policy for the United States\n\
    \            Department of Defense\", version 9, 9 February 2005.\n   [DoD10]\
    \  ---, \"DoD Architecture Framework, Version 1: Deskbook\", 9\n            February\
    \ 2004.\n   [DSG]    American Bar Association, \"Digital Signature Guidelines:\n\
    \            Legal Infrastructure for Certification Authorities and\n        \
    \    Secure Electronic Commerce\", Chicago, IL, 1 August 1996.\n            (See:\
    \ [PAG].)\n   [ElGa]   El Gamal, T., \"A Public-Key Cryptosystem and a Signature\n\
    \            Scheme Based on Discrete Logarithms\", in \"IEEE Transactions\n \
    \           on Information Theory\", vol. IT-31, no. 4, 1985, pp. 469-\n     \
    \       472.\n   [EMV1]   Europay International S.A., MasterCard International\n\
    \            Incorporated, and Visa International Service Association,\n     \
    \       \"EMV '96 Integrated Circuit Card Specification for Payment\n        \
    \    Systems\", version 3.1.1, 31 May 1998.\n   [EMV2]   ---, \"EMV '96 Integrated\
    \ Circuit Card Terminal Specification\n            for Payment Systems\", version\
    \ 3.1.1, 31 May 1998.\n   [EMV3]   ---, \"EMV '96 Integrated Circuit Card Application\n\
    \            Specification for Payment Systems\", version 3.1.1, 31 May\n    \
    \        1998.\n   [F1037]  U.S. General Services Administration, \"Glossary of\n\
    \            Telecommunications Terms\", FED STD 1037C, 7 August 1996.\n   [For94]\
    \  Ford, W., \"Computer Communications Security: Principles,\n            Standard\
    \ Protocols and Techniques\", ISBN 0-13-799453-2,\n            1994.\n   [For97]\
    \  --- and M. Baum, \"Secure Electronic Commerce: Building the\n            Infrastructure\
    \ for Digital Signatures and Encryption\", ISBN\n            0-13-476342-4, 1994.\n\
    \   [FP001]  U.S. Department of Commerce, \"Code for Information\n           \
    \ Interchange\", Federal Information Processing Standards\n            Publication\
    \ (FIPS PUB) 1, 1 November 1968.\n   [FP031]  ---, \"Guidelines for Automatic\
    \ Data Processing Physical\n            Security and Risk Management\", FIPS PUB\
    \ 31, June 1974.\n   [FP039]  ---, \"Glossary for Computer Systems Security\"\
    , FIPS PUB 39,\n            15 February 1976.\n   [FP041]  ---, \"Computer Security\
    \ Guidelines for Implementing the\n            Privacy Act of 1974\", FIPS PUB\
    \ 41, 30 May 1975.\n   [FP046]  ---, \"Data Encryption Standard (DES)\", FIPS\
    \ PUB 46-3, 25\n            October 1999.\n   [FP074]  ---, \"Data Encryption\
    \ Standard (DES)\", FIPS PUB 46-3, 25\n            October 1999.\n   [FP081] \
    \ ---, \"DES Modes of Operation\", FIPS PUB 81, 2 December 1980.\n   [FP087] \
    \ ---, \"Guidelines for ADP Contingency Planning\", FIPS PUB 87,\n           \
    \ 27 March 1981.\n   [FP102]  ---, \"Guideline for Computer Security Certification\
    \ and\n            Accreditation\", FIPS PUB 102, 27 September 1983.\n   [FP113]\
    \  ---, \"Computer Data Authentication\", FIPS PUB 113, 30 May\n            1985.\n\
    \   [FP140]  ---, \"Security Requirements for Cryptographic Modules\", FIPS\n\
    \            PUB 140-2, 25 May 2001; with change notice 4, 3 December\n      \
    \      2002.\n   [FP151]  ---, \"Portable Operating System Interface (POSIX) --\
    \ System\n            Application Program Interface [C Language]\", FIPS PUB 151-2,\n\
    \            12 May 1993\n   [FP180]  ---, \"Secure Hash Standard\", FIPS PUB\
    \ 180-2, August 2000;\n            with change notice 1, 25 February 2004.\n \
    \  [FP185]  ---, \"Escrowed Encryption Standard\", FIPS PUB 185, 9\n         \
    \   February 1994.\n   [FP186]  ---, \"Digital Signature Standard (DSS)\", FIPS\
    \ PUB 186-2, 27\n            June 2000; with change notice 1, 5 October 2001.\n\
    \   [FP188]  ---, \"Standard Security Label for Information Transfer\",\n    \
    \        FIPS PUB 188, 6 September 1994.\n   [FP191]  ---, \"Guideline for the\
    \ Analysis of Local Area Network\n            Security\", FIPS PUB 191, 9 November\
    \ 1994.\n   [FP197]  ---, \"Advanced Encryption Standard\", FIPS PUB 197, 26\n\
    \            November 2001.\n   [FP199]  ---, \"Standards for Security Categorization\
    \ of Federal\n            Information and Information Systems \", FIPS PUB 199,\n\
    \            December 2003.\n   [FPKI]   ---, \"Public Key Infrastructure (PKI)\
    \ Technical\n            Specifications: Part A -- Technical Concept of Operations\"\
    ,\n            NIST, 4 September 1998.\n   [Gass]   Gasser, M., \"Building a Secure\
    \ Computer System\", Van\n            Nostrand Reinhold Company, New York, 1988,\
    \ ISBN 0-442-\n            23022-2.\n   [Gray]   Gray, J. and A. Reuter, \"Transaction\
    \ Processing: Concepts\n            and Techniques\", Morgan Kaufmann Publishers,\
    \ Inc., 1993.\n   [Hafn]   Hafner, K. and M. Lyon, \"Where Wizards Stay Up Late:\
    \ The\n            Origins of the Internet\", Simon & Schuster, New York, 1996.\n\
    \   [Huff]   Huff, G., \"Trusted Computer Systems -- Glossary\", MTR 8201,\n \
    \           The MITRE Corporation, March 1981.\n   [I3166]  International Standards\
    \ Organization, \"Codes for the\n            Representation of Names of Countries\
    \ and Their Subdivisions,\n            Part 1: Country Codes\", ISO 3166-1:1997.\n\
    \            ---, \"Codes for the Representation of Names of Countries and\n \
    \           Their Subdivisions, Part 2: Country Subdivision Codes\",\n       \
    \     ISO/DIS 3166-2.\n            ---, \"Codes for the Representation of Names\
    \ of Countries and\n            Their Subdivisions, Part 3: Codes for Formerly\
    \ Used Names of\n            Countries\", ISO/DIS 3166-3.\n   [I7498-1] ---, \"\
    Information Processing Systems -- Open Systems\n            Interconnection Reference\
    \ Model, [Part 1:] Basic Reference\n            Model\", ISO/IEC 7498-1. (Equivalent\
    \ to ITU-T Recommendation\n            X.200.)\n   [I7498-2] ---, \"Information\
    \ Processing Systems -- Open Systems\n            Interconnection Reference Model,\
    \ Part 2: Security\n            Architecture\", ISO/IEC 7499-2.\n   [I7498-4]\
    \ ---, \"Information Processing Systems -- Open Systems\n            Interconnection\
    \ Reference Model, Part 4: Management\n            Framework\", ISO/IEC 7498-4.\n\
    \   [I7812]  ---, \"Identification cards -- Identification of Issuers,\n     \
    \       Part 1: Numbering System\", ISO/IEC 7812-1:1993\n            ---, \"Identification\
    \ cards -- Identification of Issuers,\n            Part 2: Application and Registration\
    \ Procedures\", ISO/IEC\n            7812-2:1993.\n   [I8073]  ---, \"Information\
    \ Processing Systems -- Open Systems\n            Interconnection, Transport Protocol\
    \ Specification\", ISO IS\n            8073.\n   [I8327]  ---, \"Information Processing\
    \ Systems -- Open Systems\n            Interconnection, Session Protocol Specification\"\
    , ISO IS\n            8327.\n   [I8473]  ---, \"Information Processing Systems\
    \ -- Open Systems\n            Interconnection, Protocol for Providing the Connectionless\n\
    \            Network Service\", ISO IS 8473.\n   [I8802-2] ---, \"Information\
    \ Processing Systems -- Local Area\n            Networks, Part 2: Logical Link\
    \ Control\", ISO IS 8802-2.\n            (Equivalent to IEEE 802.2.)\n   [I8802-3]\
    \ ---, \"Information Processing Systems -- Local Area\n            Networks, Part\
    \ 3: Carrier Sense Multiple Access with\n            Collision Detection (CSMA/CD)\
    \ Access Method and Physical\n            Layer Specifications\", ISO IS 8802-3.\
    \ (Equivalent to IEEE\n            802.3.)\n   [I8823]  ---, \"Information Processing\
    \ Systems -- Open Systems\n            Interconnection -- Connection-Oriented\
    \ Presentation Protocol\n            Specification\", ISO IS 8823.\n   [I9945]\
    \  \"Portable Operating System Interface for Computer\n            Environments\"\
    , ISO/IEC 9945-1: 1990.\n   [IATF]   NSA, \"Information Assurance Technical Framework\"\
    , Release 3,\n            NSA, September 2000. (See: IATF.)\n   [IDSAN]  ---,\
    \ \"Intrusion Detection System Analyzer Protection\n            Profile\", version\
    \ 1.1, NSA, 10 December 2001.\n   [IDSSC]  ---, \"Intrusion Detection System Scanner\
    \ Protection\n            Profile\", version 1.1, NSA, 10 December 2001.\n   [IDSSE]\
    \  ---, \"Intrusion Detection System Sensor Protection Profile\",\n          \
    \  version 1.1, NSA, 10 December 2001.\n   [IDSSY]  ---, \"Intrusion Detection\
    \ System\", version 1.4, NSA, 4\n            February 2002.\n   [Ioan]   Ioannidis,\
    \ J. and M. Blaze, \"The Architecture and\n            Implementation of Network\
    \ Layer Security in UNIX\", in \"UNIX\n            Security IV Symposium\", October\
    \ 1993, pp. 29-39.\n   [ITSEC]  \"Information Technology Security Evaluation Criteria\n\
    \            (ITSEC): Harmonised Criteria of France, Germany, the\n          \
    \  Netherlands, and the United Kingdom\", version 1.2, U.K.\n            Department\
    \ of Trade and Industry, June 1991.\n   [JP1]    U.S. DoD, \"Department of Defense\
    \ Dictionary of Military and\n            Associated Terms\", Joint Publication\
    \ 1-02, as amended\n            through 13 June 2007.\n   [John]   Johnson, N.\
    \ and S. Jajodia, \"Exploring Steganography; Seeing\n            the Unseen\"\
    , in \"IEEE Computer\", February 1998, pp. 26-34.\n   [Kahn]   Kahn, D., \"The\
    \ Codebreakers: The Story of Secret Writing\",\n            The Macmillan Company,\
    \ New York, 1967.\n   [Knut]   Knuth, D., Chapter 3 (\"Random Numbers\") of Volume\
    \ 2\n            (\"Seminumerical Algorithms\") of \"The Art of Computer\n   \
    \         Programming\", Addison-Wesley, Reading, MA, 1969.\n   [Kuhn]   Kuhn,\
    \ M. and R. Anderson, \"Soft Tempest: Hidden Data\n            Transmission Using\
    \ Electromagnetic Emanations\", in David\n            Aucsmith, ed., \"Information\
    \ Hiding, Second International\n            Workshop, IH'98\", Portland, Oregon,\
    \ USA, 15-17 April 1998,\n            LNCS 1525, Springer-Verlag, ISBN 3-540-65386-4,\
    \ pp. 124-142.\n   [Land]   Landwehr, C., \"Formal Models for Computer Security\"\
    , in \"ACM\n            Computing Surveys\", vol. 13, no. 3, September 1981, pp.\
    \ 247-\n            278.\n   [Larm]   Larmouth, J., \"ASN.1 Complete\", Open System\
    \ Solutions, 1999\n            (a freeware book).\n   [M0404]  U.S. Office of\
    \ Management and Budget, \"E-Authentication\n            Guidance for Federal\
    \ Agencies\", Memorandum M-04-04, 16\n            December 2003.\n   [Mene]  \
    \ Menezes, A. et al, \"Some Key Agreement Protocols Providing\n            Implicit\
    \ Authentication\", in \"The 2nd Workshop on Selected\n            Areas in Cryptography\"\
    , 1995.\n   [Moor]   Moore, A. et al, \"Attack Modeling for Information Security\n\
    \            and Survivability\", Carnegie Mellon University / Software\n    \
    \        Engineering Institute, CMU/SEI-2001-TN-001, March 2001.\n   [Murr]  \
    \ Murray, W., \"Courtney's Laws of Security\", in \"Infosecurity\n           \
    \ News\", March/April 1993, p. 65.\n   [N4001]  National Security Telecommunications\
    \ and Information System\n            Security Committee, \"Controlled Cryptographic\
    \ Items\",\n            NSTISSI No. 4001, 25 March 1985.\n   [N4006]  ---, \"\
    Controlled Cryptographic Items\", NSTISSI No. 4006, 2\n            December 1991.\n\
    \   [N7003]  ---, \"Protective Distribution Systems\", NSTISSI No. 7003, 13\n\
    \            December 1996.\n   [NCS01]  National Computer Security Center, \"\
    A Guide to Understanding\n            Audit in Trusted Systems\", NCSC-TG-001,\
    \ 1 June 1988. (See:\n            Rainbow Series.)\n   [NCS03]  ---, \"Information\
    \ System Security Policy Guideline\", I942-\n            TR-003, version 1, July\
    \ 1994. (See: Rainbow Series.)\n   [NCS04]  ---, \"Glossary of Computer Security\
    \ Terms\", NCSC-TG-004,\n            version 1, 21 October 1988. (See: Rainbow\
    \ Series.)\n   [NCS05]  ---, \"Trusted Network Interpretation of the Trusted Computer\n\
    \            System Evaluation Criteria\", NCSC-TG-005, version 1, 31 July\n \
    \           1987. (See: Rainbow Series.)\n   [NCS25]  ---, \"A Guide to Understanding\
    \ Data Remanence in Automated\n            Information Systems\", NCSC-TG-025,\
    \ version 2, September\n            1991. (See: Rainbow Series.)\n   [NCSSG] \
    \ National Computer Security Center, \"COMPUSECese: Computer\n            Security\
    \ Glossary\", NCSC-WA-001-85, Edition 1, 1 October\n            1985. (See: Rainbow\
    \ Series.)\n   [NRC91]  National Research Council, \"Computers At Risk: Safe\n\
    \            Computing in the Information Age\", National Academy Press,\n   \
    \         1991.\n   [NRC98]  Schneider, F., ed., \"Trust in Cyberspace\", National\
    \ Research\n            Council, National Academy of Sciences, 1998.\n   [Padl]\
    \   Padlipsky, M., \"The Elements of Networking Style\", 1985,\n            ISBN\
    \ 0-13-268111-0.\n   [PAG]    American Bar Association, \"PKI Assessment Guidelines\"\
    ,\n            version 1.0, 10 May 2002. (See: [DSG].)\n   [Park]   Parker, D.,\
    \ \"Computer Security Management\", ISBN 0-8359-\n            0905-0, 1981\n \
    \  [Perr]   Perrine, T. et al, \"An Overview of the Kernelized Secure\n      \
    \      Operating System (KSOS)\", in \"Proceedings of the 7th DoD/NBS\n      \
    \      Computer Security Conference\", 24-26 September 1984.\n   [PGP]    Garfinkel,\
    \ S.. \"PGP: Pretty Good Privacy\", O'Reilly &\n            Associates, Inc.,\
    \ Sebastopol, CA, 1995.\n   [PKCS]   Kaliski Jr., B., \"An Overview of the PKCS\
    \ Standards\", RSA\n            Data Security, Inc., 3 June 1991.\n   [PKC05]\
    \  RSA Laboratories, \"PKCS #5: Password-Based Encryption\n            Standard\
    \ \", version 1.5, 1 November 1993. (See: RFC 2898.)\n   [PKC07]  ---, \"PKCS\
    \ #7: Cryptographic Message Syntax Standard\",\n            version 1.5, 1 November\
    \ 1993. (See: RFC 2315.)\n   [PKC10]  ---, \"PKCS #10: Certification Request Syntax\
    \ Standard\",\n            version 1.0, 1 November 1993.\n   [PKC11]  ---, \"\
    PKCS #11: Cryptographic Token Interface Standard\",\n            version 1.0,\
    \ 28 April 1995.\n   [PKC12]  ---, \"PKCS #12: Personal Information Exchange Syntax\"\
    ,\n            version 1.0, 24 June 1995.\n   [R1108]  Kent, S., \"U.S. Department\
    \ of Defense Security Options for\n            the Internet Protocol\", RFC 1108,\
    \ November 1991.\n   [R1135]  Reynolds, J., \"The Helminthiasis of the Internet\"\
    , RFC 1135,\n            December 1989\n   [R1208]  Jacobsen, O. and D. Lynch,\
    \ \"A Glossary of Networking Terms\",\n            RFC 1208, March 1991.\n   [R1281]\
    \  Pethia, R., Crocker, S., and B. Fraser, \"Guidelines for\n            Secure\
    \ Operation of the Internet\", RFC 1281, November 1991.\n   [R1319]  Kaliski,\
    \ B., \"The MD2 Message-Digest Algorithm\", RFC 1319,\n            April 1992.\n\
    \   [R1320]  Rivest, R., \"The MD4 Message-Digest Algorithm\", RFC 1320,\n   \
    \         April 1992.\n   [R1321]  ---, \"The MD5 Message-Digest Algorithm\",\
    \ RFC 1321, April\n            1992.\n   [R1334]  Lloyd, B. and W. Simpson, \"\
    PPP Authentication Protocols\",\n            RFC 1334, October 1992.\n   [R1413]\
    \  St. Johns, M., \"Identification Protocol\", RFC 1413, February\n          \
    \  1993.\n   [R1421]  Linn, J., \"Privacy Enhancement for Internet Electronic\
    \ Mail,\n            Part I: Message Encryption and Authentication Procedures\"\
    ,\n            RFC 1421, February 1993.\n   [R1422]  Kent, S., \"Privacy Enhancement\
    \ for Internet Electronic Mail,\n            Part II: Certificate-Based Key Management\"\
    , RFC 1422,\n            February 1993.\n   [R1455]  Eastlake 3rd, D., \"Physical\
    \ Link Security Type of Service\",\n            RFC 1455, May 1993.\n   [R1457]\
    \  Housley, R., \"Security Label Framework for the Internet\",\n            RFC\
    \ 1457, May 1993.\n   [R1492]  Finseth, C., \"An Access Control Protocol, Sometimes\
    \ Called\n            TACACS\", RFC 1492, July 1993.\n   [R1507]  Kaufman, C.,\
    \ \"DASS: Distributed Authentication Security\n            Service\", RFC 1507,\
    \ September 1993.\n   [R1731]  Myers, J., \"IMAP4 Authentication Mechanisms\"\
    , RFC 1731,\n            December 1994.\n   [R1734]  ---, \"POP3 AUTHentication\
    \ Command\", RFC 1734, Dec, 1994.\n   [R1760]  Haller, N., \"The S/KEY One-Time\
    \ Password System\", RFC 1760,\n            February 1995.\n   [R1824]  Danisch,\
    \ H., \"The Exponential Security System TESS: An\n            Identity-Based Cryptographic\
    \ Protocol for Authenticated Key-\n            Exchange (E.I.S.S.-Report 1995/4)\"\
    , RFC 1824, August 1995.\n   [R1828]  Metzger, P. and W. Simpson, \"IP Authentication\
    \ using Keyed\n            MD5\", RFC 1828, August 1995.\n   [R1829]  Karn, P.,\
    \ Metzger, P., and W. Simpson, \"The ESP DES-CBC\n            Transform\", RFC\
    \ 1829, August 1995.\n   [R1848]  Crocker, S., Freed, N., Galvin, J., and S. Murphy,\
    \ \"MIME\n            Object Security Services\", RFC 1848, October 1995.\n  \
    \ [R1851]  Karn, P., Metzger, P., and W. Simpson, \"The ESP Triple DES\n     \
    \       Transform\", RFC 1851, September 1995.\n   [R1928]  Leech, M., Ganis,\
    \ M., Lee, Y., Kuris, R., Koblas, D., and L.\n            Jones, \"SOCKS Protocol\
    \ Version 5\", RFC 1928, March 1996.\n   [R1958]  Carpenter, B., \"Architectural\
    \ Principles of the Internet\",\n            RFC 1958, June 1996.\n   [R1983]\
    \  Malkin, G., \"Internet Users' Glossary\", FYI 18, RFC 1983,\n            August\
    \ 1996.\n   [R1994]  Simpson, W., \"PPP Challenge Handshake Authentication\n \
    \           Protocol (CHAP)\", RFC 1994, August 1996.\n   [R2078]  Linn, J., \"\
    Generic Security Service Application Program\n            Interface, Version 2\"\
    , RFC 2078, January 1997. (Superseded\n            by RFC 2743.)\n   [R2084] \
    \ Bossert, G., Cooper, S., and W. Drummond, \"Considerations\n            for\
    \ Web Transaction Security\", RFC 2084, January 1997.\n   [R2104]  Krawczyk, H.,\
    \ Bellare, M., and R. Canetti, \"HMAC: Keyed-\n            Hashing for Message\
    \ Authentication\", RFC 2104, February\n            1997.\n   [R2144]  Adams,\
    \ C., \"The CAST-128 Encryption Algorithm\", RFC 2144,\n            May 1997.\n\
    \   [R2179]  Gwinn, A., \"Network Security For Trade Shows\", RFC 2179,\n    \
    \        July 1997.\n   [R2195]  Klensin, J., Catoe, R., and P. Krumviede, \"\
    IMAP/POP\n            AUTHorize Extension for Simple Challenge/Response\", RFC\n\
    \            2195, September 1997.\n   [R2196]  Fraser, B., \"Site Security Handbook\"\
    , FYI 8, RFC 2196,\n            September 1997.\n   [R2202]  Cheng, P. and R.\
    \ Glenn, \"Test Cases for HMAC-MD5 and HMAC-\n            SHA-1\", RFC 2202, Sep.\
    \ 1997.\n   [R2222]  Myers, J., \"Simple Authentication and Security Layer\n \
    \           (SASL)\", RFC 2222, October 1997.\n   [R2289]  Haller, N., Metz, C.,\
    \ Nesser, P., and M. Straw, \"A One-Time\n            Password System\", STD 61,\
    \ RFC 2289, February 1998.\n   [R2323]  Ramos, A., \"IETF Identification and Security\
    \ Guidelines\",\n            RFC 2323, 1 April 1998. (Intended for humorous entertainment\n\
    \            -- \"please laugh loud and hard\" -- and does not contain\n     \
    \       serious security information.)\n   [R2350]  Brownlee, N. and E. Guttman,\
    \ \"Expectations for Computer\n            Security Incident Response\", BCP 21,\
    \ RFC 2350, June 1998.\n   [R2356]  Montenegro, G. and V. Gupta, \"Sun's SKIP\
    \ Firewall Traversal\n            for Mobile IP\", RFC 2356, June 1998.\n   [R2401]\
    \  Kent, S. and R. Atkinson, \"Security Architecture for the\n            Internet\
    \ Protocol\", RFC 2401, November 1998.\n   [R2402]  ---, \"IP Authentication Header\"\
    , RFC 2402, November 1998.\n   [R2403]  Madson, C. and R. Glenn, \"The Use of\
    \ HMAC-MD5-96 within ESP\n            and AH\", RFC 2403, November 1998.\n   [R2404]\
    \  ---, \"The Use of HMAC-SHA-1-96 within ESP and AH\", RFC 2404,\n          \
    \  November 1998.\n   [R2405]  Madson, C. and N. Doraswamy, \"The ESP DES-CBC\
    \ Cipher\n            Algorithm With Explicit IV\", RFC 2405, November 1998.\n\
    \   [R2406]  Kent, S. and R. Atkinson, \"IP Encapsulating Security Payload\n \
    \           (ESP)\", RFC 2406, November 1998.\n   [R2407]  Piper, D. \"The Internet\
    \ IP Security Domain of Interpretation\n            for ISAKMP\", RFC 2407, November\
    \ 1998.\n   [R2408]  Maughan, D., Schertler, M., Schneider, M., and J. Turner,\n\
    \            \"Internet Security Association and Key Management Protocol\n   \
    \         (ISAKMP)\", RFC 2408, November 1998.\n   [R2410]  Glenn, R. and S. Kent,\
    \ \"The NULL Encryption Algorithm and\n            Its Use With IPsec\", RFC 2410,\
    \ November 1998.\n   [R2412]  Orman, H., \"The OAKLEY Key Determination Protocol\"\
    , RFC\n            2412, November 1998.\n   [R2451]  Pereira, R. and R. Adams,\
    \ \"The ESP CBC-Mode Cipher\n            Algorithms\", RFC 2451, November 1998.\n\
    \   [R2504]  Guttman, E., Leong, L., and G. Malkin, \"Users' Security\n      \
    \      Handbook\", RFC 2504, February 1999.\n   [R2560]  Myers, M., Ankney, R.,\
    \ Malpani, A., Galperin, S., and C.\n            Adams, \"X.509 Internet Public\
    \ Key Infrastructure Online\n            Certificate Status Protocol - OCSP\"\
    , RFC 2560, June 1999.\n   [R2612]  Adams, C. and J. Gilchrist, \"The CAST-256\
    \ Encryption\n            Algorithm\", RFC 2612, June 1999.\n   [R2628]  Smyslov,\
    \ V., \"Simple Cryptographic Program Interface (Crypto\n            API)\", RFC\
    \ 2628, June 1999.\n   [R2631]  Rescorla, E., \"Diffie-Hellman Key Agreement Method\"\
    , RFC\n            2631, June 1999. (See: Diffie-Hellman-Merkle.)\n   [R2634]\
    \  Hoffman, P., \"Enhanced Security Services for S/MIME\", RFC\n            2634,\
    \ June 1999.\n   [R2635]  Hambridge, S. and A. Lunde, \"DON'T SPEW: A Set of Guidelines\n\
    \            for Mass Unsolicited Mailings and Postings\", RFC 2635, June\n  \
    \          1999.\n   [R2660]  Rescorla, E. and A. Schiffman, \"The Secure HyperText\n\
    \            Transfer Protocol\", RFC 2660, August 1999.\n   [R2743]  Linn, J.,\
    \ \"Generic Security Service Application Program\n            Interface Version\
    \ 2, Update 1\", RFC 2743, January 2000.\n   [R2773]  Housley, R., Yee, P., and\
    \ W. Nace, \"Encryption using KEA and\n            SKIPJACK\", RFC 2773, February\
    \ 2000.\n   [R2801]  Burdett, D., \"Internet Open Trading Protocol - IOTP, Version\n\
    \            1.0\", RFC 2801, April 2000.\n   [R2827]  Ferguson, P. and D. Senie,\
    \ \"Network Ingress Filtering:\n            Defeating Denial of Service Attacks\
    \ which employ IP Source\n            Address Spoofing\", BCP 38, RFC 2827, May\
    \ 2000.\n   [R2865]  Rigney, C., Willens, S., Rubens, A., and W. Simpson, \"Remote\n\
    \            Authentication Dial In User Service (RADIUS)\", RFC 2865,\n     \
    \       June 2000.\n   [R3060]  Moore, B., Ellesson, E., Strassner, J., and A.\
    \ Westerinen,\n            \"Policy Core Information Model -- Version 1 Specification\"\
    ,\n            RFC 3060, February 2001.\n   [R3198]  Westerinen, A., Schnizlein,\
    \ J., Strassner, J., Scherling,\n            M., Quinn, B., Herzog, S., Huynh,\
    \ A., Carlson, M., Perry,\n            J., and S. Waldbusser, \"Terminology for\
    \ Policy-Based\n            Management\", RFC 3198, November 2001.\n   [R3280]\
    \  Housley, R., Polk, W., Ford, W., and D. Solo, \"Internet\n            X.509\
    \ Public Key Infrastructure Certificate and Certificate\n            Revocation\
    \ List (CRL) Profile\", RFC 3280, April 2002.\n   [R3547]  Baugher, M., Weis,\
    \ B., Hardjono, T., and H. Harney, \"Group\n            Domain of Interpretation\"\
    , RFC 3547, July 2003.\n   [R3552]  Rescorla, E. and B. Korver, \"Guidelines for\
    \ Writing RFC Text\n            on Security Considerations\", RFC 3552, July 2003.\n\
    \   [R3647]  Chokhani, S., Ford, W., Sabett, R., Merrill, C., and S. Wu,\n   \
    \         \"Internet X.509 Public Key Infrastructure Certificate Policy\n    \
    \        and Certification Practices Framework\", RFC 3647, November\n       \
    \     2003.\n   [R3739]  Santesson, S., Nystrom, M., and T. Polk, \"Internet X.509\n\
    \            Public Key Infrastructure: Qualified Certificates Profile\",\n  \
    \          RFC 3739, March 2004.\n   [R3740]  Hardjono, T. and B. Weis, \"The\
    \ Multicast Group Security\n            Architecture\", RFC 3740, March 2004.\n\
    \   [R3748]  Aboba, B., Blunk, L., Vollbrecht, J., Carlson, J., and H.\n     \
    \       Levkowetz, \"Extensible Authentication Protocol (EAP)\", RFC\n       \
    \     3748, June 2004.\n   [R3766]  Orman, H. and P. Hoffman, \"Determining Strengths\
    \ For Public\n            Keys Used For Exchanging Symmetric Keys\", BCP 86, RFC\
    \ 3766,\n            April 2004.\n   [R3820]  Tuecke, S., Welch, V., Engert, D.,\
    \ Pearlman, L., and M.\n            Thompson, \"Internet X.509 Public Key Infrastructure\
    \ (PKI)\n            Proxy Certificate Profile\", RFC 3820, June 2004.\n   [R3851]\
    \  Ramsdell, B., \"Secure/Multipurpose Internet Mail Extensions\n            (S/MIME)\
    \ Version 3.1 Message Specification\", RFC 3851, July\n            2004.\n   [R3871]\
    \  Jones, G., \"Operational Security Requirements for Large\n            Internet\
    \ Service Provider (ISP) IP Network Infrastructure\",\n            RFC 3871, September\
    \ 2004.\n   [R4033]  Arends, R., Austein, R., Larson, M., Massey, D., and S.\n\
    \            Rose, \"DNS Security Introduction and Requirements\", RFC\n     \
    \       4033, March 2005.\n   [R4034]  Arends, R., Austein, R., Larson, M., Massey,\
    \ D., and S.\n            Rose, \"Resource Records for the DNS Security Extensions\"\
    ,\n            RFC 4034,  March 2005.\n   [R4035]  Arends, R., Austein, R., Larson,\
    \ M., Massey, D., and S.\n            Rose, \"Protocol Modifications for the DNS\
    \ Security\n            Extensions\", RFC 4035, March 2005.\n   [R4086]  Eastlake,\
    \ D., 3rd, Schiller, J., and S. Crocker, \"Randomness\n            Requirements\
    \ for Security\", BCP 106, RFC 4086, June 2005.\n   [R4120]  Neuman, C., Yu, T.,\
    \ Hartman, S., and K. Raeburn, \"The\n            Kerberos Network Authentication\
    \ Service (V5)\", RFC 4120,\n            July 2005.\n   [R4158]  Cooper, M., Dzambasow,\
    \ Y., Hesse, P., Joseph, S., and R.\n            Nicholas, \"Internet X.509 Public\
    \ Key Infrastructure:\n            Certification Path Building\", RFC 4158, September\
    \ 2005.\n   [R4210]  Adams, C., Farrell, S., Kause, T., and T. Mononen, \"Internet\n\
    \            X.509 Public Key Infrastructure Certificate Management\n        \
    \    Protocol (CMP)\", RFC 4210, September 2005.\n   [R4301]  Kent, S. and K.\
    \ Seo, \"Security Architecture for the Internet\n            Protocol\", RFC 4301,\
    \ December 2005.\n   [R4302]  Kent, S., \"IP Authentication Header\", RFC 4302,\
    \ December\n            2005.\n   [R4303]  Kent, S., \"IP Encapsulating Security\
    \ Payload (ESP)\", RFC\n            4303, December 2005.\n   [R4306]  Kaufman,\
    \ C., \"Internet Key Exchange (IKEv2) Protocol\", RFC\n            4306, December\
    \ 2005.\n   [R4346]  Dierks, T. and E. Rescorla, \"The Transport Layer Security\n\
    \            (TLS) Protocol Version 1.1\", RFC 4346, April 2006.\n   [R4422] \
    \ Melnikov, A. and K. Zeilenga, \"Simple Authentication and\n            Security\
    \ Layer (SASL)\", RFC 4422, June 2006.\n   [Raym]   Raymond, E., ed., \"The On-Line\
    \ Hacker Jargon File\", version\n            4.0.0, 24 July 1996. (See: http://www.catb.org/~esr/jargon\n\
    \            for the latest version. Also, \"The New Hacker's Dictionary\",\n\
    \            3rd edition, MIT Press, September 1996, ISBN 0-262-68092-0.)\n  \
    \ [Roge]   Rogers, H., \"An Overview of the CANEWARE Program\", in\n         \
    \   \"Proceedings of the 10th National Computer Security\n            Conference\"\
    , NIST and NCSC, September 1987.\n   [RSA78]  Rivest, R., A. Shamir, and L. Adleman,\
    \ \"A Method for\n            Obtaining Digital Signatures and Public-Key Cryptosystems\"\
    ,\n            in \"Communications of the ACM\", vol. 21, no. 2, February\n  \
    \          1978, pp. 120-126.\n   [RSCG]   NSA, \"Router Security Configuration\
    \ Guide: Principles and\n            Guidance for Secure Configuration of IP Routers,\
    \ with\n            Detailed Instructions for Cisco Systems Routers\", version\n\
    \            1.1c, C4-040R-02, 15 December 2005, available at\n            http://www.nsa.gov/snac/routers/C4-040R-02.pdf.\n\
    \   [Russ]   Russell, D. et al, Chapter 10 (\"TEMPEST\") of \"Computer\n     \
    \       Security Basics\", ISBN 0-937175-71-4, 1991.\n   [SAML]   Organization\
    \ for the Advancement of Structured Information\n            Standards (OASIS),\
    \ \"Assertions and Protocol for the OASIS\n            Security Assertion Markup\
    \ Language (SAML)\", version 1.1, 2\n            September 2003.\n   [Sand]  \
    \ Sandhu, R. et al, \"Role-Based Access Control Models\", in\n            \"IEEE\
    \ Computer\", vol. 29, no. 2, February 1996, pp. 38-47.\n   [Schn]   Schneier,\
    \ B., \"Applied Cryptography Second Edition\", John\n            Wiley & Sons,\
    \ Inc., New York, 1996.\n   [SDNS3]  U.S. DoD, NSA, \"Secure Data Network Systems,\
    \ Security\n            Protocol 3 (SP3)\", document SDN.301, Revision 1.5, 15\
    \ May\n            1989.\n   [SDNS4]  ---, \"Secure Data Network Systems, Security\
    \ Protocol 4\n            (SP4)\", document SDN.401, Revision 1.2, 12 July 1988.\n\
    \   [SDNS7]  ---, \"Secure Data Network Systems, Message Security Protocol\n \
    \           (MSP)\", SDN.701, Revision 4.0, 7 June 1996, with\n            \"\
    Corrections to Message Security Protocol, SDN.701, Rev 4.0,\n            96-06-07\"\
    , 30 Aug, 1996.\n   [SET1]   MasterCard and Visa, \"SET Secure Electronic Transaction\n\
    \            Specification, Book 1: Business Description\", version 1.0,\n   \
    \         31 May 1997.\n   [SET2]   ---, \"SET Secure Electronic Transaction Specification,\
    \ Book\n            2: Programmer's Guide\", version 1.0, 31 May 1997.\n   [SKEME]\
    \  Krawczyk, H., \"SKEME: A Versatile Secure Key Exchange\n            Mechanism\
    \ for Internet\", in \"Proceedings of the 1996\n            Symposium on Network\
    \ and Distributed Systems Security\".\n   [SKIP]   \"SKIPJACK and KEA Algorithm\
    \ Specifications\", version 2.0, 22\n            May 1998, and \"Clarification\
    \ to the SKIPJACK Algorithm\n            Specification\", 9 May 2002 (available\
    \ from NIST Computer\n            Security Resource Center).\n   [SP12]   NIST,\
    \ \"An Introduction to Computer Security: The NIST\n            Handbook\", Special\
    \ Publication 800-12.\n   [SP14]   Swanson, M. et al (NIST), \"Generally Accepted\
    \ Principles and\n            Practices for Security Information Technology Systems\"\
    ,\n            Special Publication 800-14, September 1996.\n   [SP15]   Burr,\
    \ W. et al (NIST), \"Minimum Interoperability\n            Specification for PKI\
    \ Components (MISPC), Version 1\",\n            Special Publication 800-15, September\
    \ 1997.\n   [SP22]   Rukhin, A. et al (NIST), \"A Statistical Test Suite for\n\
    \            Random and Pseudorandom Number Generators for Cryptographic\n   \
    \         Applications\", Special Publication 800-15, 15 May 2001.\n   [SP27]\
    \   Stoneburner, G. et al (NIST), \"Engineering Principles for\n            Information\
    \ Technology Security (A Baseline for Achieving\n            Security)\", Special\
    \ Publication 800-27 Rev A, June 2004.\n   [SP28]   Jansen, W. (NIST), \"Guidelines\
    \ on Active Content and Mobile\n            Code\", Special Publication 800-28,\
    \ October 2001.\n   [SP30]   Stoneburner, G. et al (NIST), \"Risk Management Guide\
    \ for\n            Information Technology Systems\", Special Publication 800-30,\n\
    \            October 2001.\n   [SP31]   Bace, R. et al (NIST), \"Intrusion Detection\
    \ Systems\",\n            Special Publication 800-31.\n   [SP32]   Kuhn, D. (NIST),\
    \ \"Introduction to Public Key Technology and\n            the Federal PKI Infrastructure\
    \ \", Special Publication\n            800-32, 26 February 2001.\n   [SP33]  \
    \ Stoneburner, G. (NIST), \"Underlying Technical Models for\n            Information\
    \ Technology Security\", Special Publication\n            800-33, December 2001.\n\
    \   [SP37]   Ross, R. et al (NIST), \"Guide for the Security Certification\n \
    \           and Accreditation of Federal Information Systems\", Special\n    \
    \        Publication 800-37, May 2004.\n   [SP38A]  Dworkin, M. (NIST), \"Recommendation\
    \ for Block Cipher Modes\n            of Operation: Methods and Techniques\",\
    \ Special Publication\n            800-38A, 2001 Edition, December 2001.\n   [SP38B]\
    \  ---, \"Recommendation for Block Cipher Modes of Operation:\n            The\
    \ CMAC Mode for Authentication\", Special Publication\n            800-38B, May\
    \ 2005.\n   [SP38C]  ---, \"Recommendation for Block Cipher Modes of Operation:\n\
    \            The CCM Mode for Authentication and Confidentiality\",\n        \
    \    Special Publication 800-38C, May 2004.\n   [SP41]   Wack, J. et al (NIST),\
    \ \"Guidelines on Firewalls and Firewall\n            Policy\", Special Publication\
    \ 800-41, January 2002.\n   [SP42]   ---, \"Guideline on Network Security Testing\"\
    , Special\n            Publication 800-42, October 2003.\n   [SP56]   NIST, \"\
    Recommendations on Key Establishment Schemes\", Draft\n            2.0, Special\
    \ Publication 800-63, January 2003.\n   [SP57]   ---, \"Recommendation for Key\
    \ Management\", Part 1 \"General\n            Guideline\" and Part 2 \"Best Practices\
    \ for Key Management\n            Organization\", Special Publication 800-57,\
    \ DRAFT, January\n            2003.\n   [SP61]   Grance, T. et al (NIST), \"Computer\
    \ Security Incident\n            Handling Guide\", Special Publication 800-57,\
    \ January 2003.\n   [SP63]   Burr, W. et al (NIST), \"Electronic Authentication\n\
    \            Guideline\", Special Publication 800-63, June 2004\n   [SP67]   Barker,\
    \ W. (NIST), \"Recommendation for the Triple Data\n            Encryption Algorithm\
    \ (TDEA) Block Cipher\", Special\n            Publication 800-67, May 2004\n \
    \  [Stal]   Stallings, W., \"Local Networks\", 1987, ISBN 0-02-415520-9.\n   [Stei]\
    \   Steiner, J. et al, \"Kerberos: An Authentication Service for\n           \
    \ Open Network Systems\", in \"Usenix Conference Proceedings\",\n            February\
    \ 1988.\n   [Weis]   Weissman, C., \"Blacker: Security for the DDN: Examples of\
    \ A1\n            Security Engineering Trades\", in \"Symposium on Security and\n\
    \            Privacy\", IEEE Computer Society Press, May 1992, pp. 286-\n    \
    \        292.\n   [X400]   International Telecommunications Union -- Telecommunication\n\
    \            Standardization Sector (formerly \"CCITT\"), Recommendation\n   \
    \         X.400, \"Message Handling Services: Message Handling System\n      \
    \      and Service Overview\".\n   [X419]   ---, \"Message Handling Systems: Protocol\
    \ Specifications\",\n            ITU-T Recommendation X.419. (Equivalent to ISO\
    \ 10021-6).\n   [X420]   ---, \"Message Handling Systems: Interpersonal Messaging\n\
    \            System\", ITU-T Recommendation X.420. (Equivalent to ISO\n      \
    \      10021-7.).\n   [X500]   ---, Recommendation X.500, \"Information Technology\
    \ -- Open\n            Systems Interconnection -- The Directory: Overview of\n\
    \            Concepts, Models, and Services\". (Equivalent to ISO 9594-1.)\n \
    \  [X501]   ---, Recommendation X.501, \"Information Technology -- Open\n    \
    \        Systems Interconnection -- The Directory: Models\".\n   [X509]   ---,\
    \ Recommendation X.509, \"Information Technology -- Open\n            Systems\
    \ Interconnection -- The Directory: Authentication\n            Framework\", COM\
    \ 7-250-E Revision 1, 23 February 2001.\n            (Equivalent to ISO 9594-8.)\n\
    \   [X519]   ---, Recommendation X.519, \"Information Technology -- Open\n   \
    \         Systems Interconnection -- The Directory: Protocol\n            Specifications\"\
    .\n   [X520]   ---, Recommendation X.520, \"Information Technology -- Open\n \
    \           Systems Interconnection -- The Directory: Selected Attribute\n   \
    \         Types\".\n   [X680]   ---, Recommendation X.680, \"Information Technology\
    \ --\n            Abstract Syntax Notation One (ASN.1) -- Specification of\n \
    \           Basic Notation\", 15 November 1994. (Equivalent to ISO/IEC\n     \
    \       8824-1.)\n   [X690]   ---, Recommendation X.690, \"Information Technology\
    \ -- ASN.1\n            Encoding Rules -- Specification of Basic Encoding Rules\n\
    \            (BER), Canonical Encoding Rules (CER) and Distinguished\n       \
    \     Encoding Rules (DER)\", 15 November 1994. (Equivalent to\n            ISO/IEC\
    \ 8825-1.)\n"
- title: 7. Acknowledgments
  contents:
  - "7. Acknowledgments\n   George Huff had a good idea! [Huff]\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Dr. Robert W. Shirey\n   3516 N. Kensington St.\n   Arlington,\
    \ Virginia  22207-1328\n   USA\n   EMail: rwshirey4949@verizon.net\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The IETF Trust (2007).\n   This document\
    \ is subject to the rights, licenses and restrictions\n   contained in BCP 78\
    \ and at www.rfc-editor.org/copyright.html, and\n   except as set forth therein,\
    \ the authors retain all their rights.\n   This document and the information contained\
    \ herein are provided on an\n   \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION\
    \ HE/SHE REPRESENTS\n   OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY, THE\
    \ IETF TRUST AND\n   THE INTERNET ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES,\
    \ EXPRESS\n   OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE\
    \ OF\n   THE INFORMATION HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED\n\
    \   WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at\n   ietf-ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
