- title: __initial_text__
  contents:
  - ''
- title: Independent Submission                                  J. Tripathi, Ed.
  contents:
  - "Independent Submission                                  J. Tripathi, Ed.\n  \
    \                       Performance Evaluation\n     of the Routing Protocol for\
    \ Low-Power and Lossy Networks (RPL)\n"
- title: Abstract
  contents:
  - "Abstract\n   This document presents a performance evaluation of the Routing\n\
    \   Protocol for Low-Power and Lossy Networks (RPL) for a small outdoor\n   deployment\
    \ of sensor nodes and for a large-scale smart meter network.\n   Detailed simulations\
    \ are carried out to produce several routing\n   performance metrics using these\
    \ real-life deployment scenarios.\n   Please refer to the PDF version of this\
    \ document, which includes\n   several plots for the performance metrics not shown\
    \ in the plain-text\n   version.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This is a contribution to\
    \ the RFC Series, independently of any other\n   RFC stream.  The RFC Editor has\
    \ chosen to publish this document at\n   its discretion and makes no statement\
    \ about its value for\n   implementation or deployment.  Documents approved for\
    \ publication by\n   the RFC Editor are not a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6687.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2012 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................2\n\
    \   2. Terminology .....................................................3\n  \
    \ 3. Methodology and Simulation Setup ................................4\n   4.\
    \ Performance Metrics .............................................7\n      4.1.\
    \ Common Assumptions .........................................7\n      4.2. Path\
    \ Quality ...............................................7\n      4.3. Routing\
    \ Table Size ........................................10\n      4.4. Delay Bound\
    \ for P2P Routing ...............................10\n      4.5. Control Packet\
    \ Overhead ...................................11\n      4.6. Loss of Connectivity\
    \ ......................................13\n   5. RPL in a Building Automation\
    \ Routing Scenario ..................18\n      5.1. Path Quality ..............................................18\n\
    \      5.2. Delay .....................................................19\n  \
    \ 6. RPL in a Large-Scale Network ...................................19\n    \
    \  6.1. Path Quality ..............................................19\n      6.2.\
    \ Delay .....................................................21\n      6.3. Control\
    \ Packet Overhead ...................................21\n   7. Scaling Property\
    \ and Routing Stability .........................22\n   8. Comments .......................................................24\n\
    \   9. Security Considerations ........................................25\n  \
    \ 10. Acknowledgements ..............................................25\n   11.\
    \ Informative References ........................................25\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Designing a routing protocol for Low-Power and Lossy Networks\
    \ (LLNs)\n   imposes great challenges, mainly due to low data rates, high\n  \
    \ probability of packet delivery failure, and strict energy constraints\n   in\
    \ the nodes.  The IETF ROLL Working Group took on this task and\n   specified\
    \ the Routing Protocol for Low-Power and Lossy Networks (RPL)\n   in [RFC6550].\n\
    \   RPL is designed to meet the core requirements specified in [RFC5826],\n  \
    \ [RFC5867], [RFC5673], and [RFC5548].\n   This document's contribution is to\
    \ provide a performance evaluation\n   of RPL with respect to several metrics\
    \ of interest.  This is\n   accomplished using real data and topologies in a discrete\
    \ event\n   simulator developed to reproduce the protocol behavior.\n   The following\
    \ metrics are evaluated:\n   o  Path quality metrics, such as ETX path cost, ETX\
    \ path stretch, ETX\n      fractional stretch, and hop distance stretch, as defined\
    \ in\n      Section 2 (\"Terminology\");\n   o  Control plane overhead;\n   o\
    \  End-to-end delay between nodes;\n   o  Ability to cope with unstable situations\
    \ (link churns, node\n      dying);\n   o  Required resource constraints on nodes\
    \ (routing table size).\n   Some of these metrics are mentioned in the aforementioned\
    \ RFCs,\n   whereas others have been introduced to consider the challenges and\n\
    \   unique requirements of LLNs as discussed in [RFC6550].  For example,\n   routing\
    \ in a home automation deployment has strict time bounds on\n   protocol convergence\
    \ after any change in topology, as mentioned in\n   Section 3.4 of [RFC5826].\
    \  [RFC5673] requires bounded and guaranteed\n   end-to-end delay for routing\
    \ in an industrial deployment, and\n   [RFC5548] requires comparatively loose\
    \ bounds on latency for end-to-\n   end communication.  [RFC5548] mandates scalability\
    \ in terms of\n   protocol performance for a network of size ranging from 10^2\
    \ to 10^4\n   nodes.\n   Although simulation cannot prove formally that a protocol\
    \ operates\n   properly in all situations, it can give a good level of confidence\
    \ in\n   protocol behavior in highly stressful conditions, if and only if\n  \
    \ real-life data are used.  Simulation is particularly useful when\n   theoretical\
    \ model assumptions may not be applicable to such networks\n   and scenarios.\
    \  In this document, real deployed network data traces\n   have been used to model\
    \ link behaviors and network topologies.\n"
- title: 2.  Terminology
  contents:
  - "2.  Terminology\n   Please refer to [ROLL-TERMS] and [RFC6550] for terminology.\
    \  In\n   addition, the following terms are specified:\n   PDR:  Packet Delivery\
    \ Ratio.\n   CDF:  Cumulative Distribution Function.\n   Expected Transmission\
    \ Count (ETX Metric):  The expected number of\n      transmissions to reach the\
    \ next hop is determined as the inverse\n      of the link PDR.  Consequently,\
    \ in every hop, if the link quality\n      (PDR) is high, the expected number\
    \ of transmissions to reach the\n      next hop may be as low as 1.  However,\
    \ if the PDR for the\n      particular link is low, multiple transmissions may\
    \ be needed.\n   ETX Path Cost:  The ETX path cost metric is determined as the\n\
    \      summation of the ETX value for each link on the route a packet\n      takes\
    \ towards the destination.\n   ETX Path Cost Stretch:  The ETX path cost stretch\
    \ is defined as the\n      difference between the number of expected transmissions\
    \ (ETX\n      Metric) taken by a packet traveling from source to destination,\n\
    \      following a route determined by RPL and a route determined by a\n     \
    \ hypothetical ideal shortest path routing protocol (using link ETX\n      as\
    \ the metric).\n   ETX Fractional Stretch (fractional stretch factor of link ETX\
    \ metric\n      against ideal shortest path):  The fractional path stretch is\
    \ the\n      ratio of ETX path stretch to ETX path cost for the shortest path\n\
    \      route for the source-destination pair.\n   Hop Distance Stretch (stretch\
    \ factor for node hop distance against\n      ideal shortest path):  The hop distance\
    \ stretch is defined as the\n      difference between the number of hops taken\
    \ by a packet traveling\n      from source to destination, following a route determined\
    \ by RPL\n      and by a hypothetical ideal shortest path algorithm, both using\n\
    \      ETX as the link cost.  The fractional hop distance stretch is\n      computed\
    \ as the ratio of path stretch to count value between a\n      source-destination\
    \ pair for the hypothetical shortest path route\n      optimizing ETX path cost.\n"
- title: 3.  Methodology and Simulation Setup
  contents:
  - "3.  Methodology and Simulation Setup\n   In the context of this document, RPL\
    \ has been simulated using OMNeT++\n   [OMNeTpp], a well-known discrete event-based\
    \ simulator written in C++\n   and NEtwork Description (NED).  Castalia-2.2 [Castalia-2.2]\
    \ has been\n   used as a Wireless Sensor Network Simulator framework within OMNeT++.\n\
    \   The output and events in the simulation are visualized with the help\n   of\
    \ the Network AniMator, or NAM, which is distributed with the NS\n   (Network\
    \ Simulator) [NS-2].\n   Note that no versions of the NS itself are used in this\
    \ simulation\n   study.  Only the visualization tool was borrowed for verification\n\
    \   purposes.\n   In contrast with theoretical models, which may have assumptions\
    \ not\n   applicable to lossy links, real-life data was used for two aspects of\n\
    \   the simulations:\n   *  Link Failure Model: Derived from time-varying real\
    \ network traces\n      containing packet delivery probability for each link,\
    \ over all\n      channels, for both indoor network deployment and outdoor network\n\
    \      deployment.\n   *  Topology: Gathered from real-life deployment (traces\
    \ mentioned\n      above) as opposed to random topology simulations.\n   A 45-node\
    \ topology, deployed as an outdoor network and shown in\n   Figure 1, and a 2442-node\
    \ topology, gathered from a smart meter\n   network deployment, were used in the\
    \ simulations.  In Figure 1, links\n   between a most preferred parent node and\
    \ child nodes are shown in\n   red.  Links that are shown in black are also part\
    \ of the topology but\n   are not between a preferred parent and child node.\n\
    \   Figure 1 [See the PDF.]\n             Figure 1: Outdoor Network Topology with\
    \ 45 Nodes.\n   Note that this is just a start to validate the simulation before\n\
    \   using large-scale networks.\n   A set of time-varying link quality data was\
    \ gathered from a real\n   network deployment to form a database used for the\
    \ simulations.  Each\n   link in the topology randomly 'picks up' a link model\
    \ (trace) from\n   the database.  Each link has a Packet Delivery Ratio (PDR)\
    \ that\n   varies with time (in the simulation, a new PDR is read from the\n \
    \  database every 10 minutes) according to the gathered data.  Packets\n   are\
    \ dropped randomly from that link with probability (1 - PDR).  Each\n   time a\
    \ packet is about to be sent, the module generates a random\n   number using the\
    \ Mersenne Twister random number generation method.\n   The random number is compared\
    \ to the PDR to determine whether the\n   packet should be dropped.  Note that\
    \ each link uses a different\n   random number generator to maintain true randomness\
    \ in the simulator\n   and to avoid correlation between links.  Also, the packet\
    \ drop\n   applies to all kinds of data and control packets (RPL), such as the\n\
    \   DIO, DAO, and DIS packets defined in [RFC6550].  Figure 2 shows a\n   typical\
    \ temporal characteristic of links from the indoor network\n   traces used in\
    \ the simulations.  The figure shows several links with\n   perfect connectivity,\
    \ some links with a PDR as low as 10%, and\n   several for which the PDR may vary\
    \ from 30% to 80%, sharply changing\n   back and forth between a high value (strong\
    \ connectivity) and a low\n   value (weak connectivity).\n   Figure 2 [See the\
    \ PDF.]\n                Figure 2: Example of Link Characteristics.\n   In the\
    \ RPL simulator, the LBR (LLN Border Router) or the Directed\n   Acyclic Graph\
    \ (DAG) root first initiates sending out DIO messages,\n   and the DAG is gradually\
    \ constructed.  RPL makes use of trickle\n   timers: the protocol sets a minimum\
    \ time period with which the nodes\n   start re-issuing DAOs, and this minimum\
    \ period is denoted by the\n   trickle parameter Imin.  RPL also sets an upper\
    \ limit on how many\n   times this time period can be doubled; this is denoted\
    \ by the\n   parameter DIOIntervalDoublings, as defined in [RFC6550].  For the\n\
    \   simulation, Imin is initially set to 1 second and\n   DIOIntervalDoublings\
    \ is equal to 16, and therefore the maximum time\n   between two consecutive DIO\
    \ emissions by a node (under a steady\n   network condition) is 18.2 hours.  The\
    \ trickle time interval for\n   emitting DIO messages assumes the initial value\
    \ of 1 second and then\n   changes over simulation time, as mentioned in [RFC6206].\n\
    \   Another objective of this study is to give insight to the network\n   administrator\
    \ on how to tweak the trickle values.  These\n   recommendations could then be\
    \ used in applicability statement\n   documents.\n   Each node in the network,\
    \ other than the LBR or DAG root, also emits\n   DAO messages as specified in\
    \ [RFC6550], to initially populate the\n   routing tables with the prefixes received\
    \ from children via the DAO\n   messages to support Point-to-Point (P2P) and Point-to-Multipoint\n\
    \   (P2MP) traffic in the \"down\" direction.  During these simulations, it\n\
    \   is assumed that each node is capable of storing route information for\n  \
    \ other nodes in the network (storing mode of RPL).\n   For nodes implementing\
    \ RPL, as expected, the routing table memory\n   requirement varies according\
    \ to the position in the DODAG\n   (Destination-Oriented DAG).  The (worst-case)\
    \ assumption is made that\n   there is no route summarization (aggregation) in\
    \ the network.  Thus,\n   a node closer to the DAG will have to store more entries\
    \ in its\n   routing table.  It is also assumed that all nodes have equal memory\n\
    \   capacity to store the routing states.\n   For simulations of the indoor network,\
    \ each node sends traffic\n   according to a Constant Bit Rate (CBR) to all other\
    \ nodes in the\n   network, over the simulation period.  Each node generates a\
    \ new data\n   packet every 10 seconds.  Each data packet has a size of 127 bytes\n\
    \   including 802.15.4 PHY/MAC headers and RPL packet headers.  All\n   control\
    \ packets are also encapsulated with 802.15.4 PHY/MAC headers.\n   To simulate\
    \ a more realistic scenario, 80% of the packets generated\n   by each node are\
    \ destined to the root, and the remaining 20% of the\n   packets are uniformly\
    \ assigned as destined to nodes other than the\n   root.  Therefore, the root\
    \ receives a considerably larger amount of\n   data than other nodes.  These values\
    \ may be revised when studying P2P\n   traffic so as to have a majority of traffic\
    \ going to all nodes as\n   opposed to the root.  In the later part of the simulation,\
    \ a typical\n   home/building routing scenario is also simulated, and different\
    \ path\n   quality metrics are computed for that traffic pattern.\n   The packets\
    \ are routed through the DODAG built by RPL according to\n   the mechanisms specified\
    \ in [RFC6550].\n   A number of RPL parameters are varied (such as the packet\
    \ rate from\n   each source and the time period for emitting a new DAG sequence\n\
    \   number) to observe their effect on the performance metric of\n   interest.\n"
- title: 4.  Performance Metrics
  contents:
  - '4.  Performance Metrics

    '
- title: 4.1.  Common Assumptions
  contents:
  - "4.1.  Common Assumptions\n   As the DAO messages are used to feed the routing\
    \ tables in the\n   network, they grow with time and size of the network.  Nevertheless,\n\
    \   no constraint was imposed on the size of the routing table nor on how\n  \
    \ much information the node can store.  The routing table size is not\n   expressed\
    \ in terms of Kbytes of memory usage but measured in terms of\n   the number of\
    \ entries for each node.  Each entry has the next-hop\n   node and path cost associated\
    \ with the destination node.\n   The link ETX (Expected Transmission Count) metric\
    \ is used to build\n   the DODAG and is specified in [RFC6551].\n"
- title: 4.2.  Path Quality
  contents:
  - "4.2.  Path Quality\n   Hop Count:  For each source-destination pair, the number\
    \ of hops for\n      both RPL and shortest path routing is computed.  Shortest\
    \ path\n      routing refers to a hypothetical ideal routing protocol that would\n\
    \      always provide the shortest path in terms of ETX path cost (or\n      whichever\
    \ metric is used) in the network.\n   The Cumulative Distribution Function (CDF)\
    \ of the hop count for all\n   paths (n * (n - 1) in an n-node network) in the\
    \ network with respect\n   to the hop count is plotted in Figure 3 for both RPL\
    \ and shortest\n   path routing.  One can observe that the CDF corresponding to\
    \ 4 hops\n   is around 80% for RPL and 90% for shortest path routing.  In other\n\
    \   words, for the given topology, 90% of the paths have a path length of\n  \
    \ 4 hops or less with an ideal shortest path routing methodology,\n   whereas\
    \ in RPL P2P routing, 90% of the paths will have a length of no\n   more than\
    \ 5 hops.  This result indicates that despite having a\n   non-optimized P2P routing\
    \ scheme, the path quality of RPL is close to\n   an optimized P2P routing mechanism\
    \ for the topology under\n   consideration.  Another reason for this may relate\
    \ to the fact that\n   the DAG root is at the center of the network; thus, routing\
    \ through\n   the DAG root is often close to an optimal (shortest path) routing.\n\
    \   This result may be different in a topology where the DAG root is\n   located\
    \ at one end of the network.\n   Figure 3 [See the PDF.]\n               Figure\
    \ 3: CDF of Hop Count versus Hop Count.\n   ETX Path Cost:  In the simulation,\
    \ the total ETX path cost (defined\n      in the Terminology section) from source\
    \ to destination for each\n      packet is computed.\n   Figure 4 shows the CDF\
    \ of the total ETX path cost, both with RPL and\n   shortest path routing.  Here\
    \ also one can observe that the ETX path\n   cost from all sources to all destinations\
    \ is close to that of\n   shortest path routing for the network.\n   Figure 4\
    \ [See the PDF.]\n   Figure 4: CDF of Total ETX Path Cost along Path versus ETX\
    \ Path Cost.\n   Path Stretch:  The path stretch metric encompasses the stretch\
    \ factor\n      for both hop distance and ETX path cost (as defined in the\n \
    \     Terminology section).  The hop distance stretch, which is\n      determined\
    \ as the difference between the number of hops taken by a\n      packet while\
    \ following a route built via RPL and the number of\n      hops taken by shortest\
    \ path routing (using link ETX as the\n      metric), is computed.  The ETX path\
    \ cost stretch is also provided.\n   The CDF of both path stretch metrics is plotted\
    \ against the value of\n   the corresponding path stretch over all packets in\
    \ Figures 5 and 6,\n   for hop distance stretch and ETX path stretch, respectively.\
    \  It can\n   be observed that, for a few packets, the path built via RPL has\
    \ fewer\n   hops than the ideal shortest path where path ETX is minimized along\n\
    \   the DAG.  This is because there are a few source-destination pairs\n   where\
    \ the total ETX path cost is equal to or less than that of the\n   ideal shortest\
    \ path when the packet takes a longer hop count.  As the\n   RPL implementation\
    \ ignores a 20% change in total ETX path cost before\n   switching to a new parent\
    \ or emitting a new DIO, it does not\n   necessarily provide the shortest path\
    \ in terms of total ETX path\n   cost.  Thus, this implementation yields a few\
    \ paths with smaller hop\n   counts but larger (or equal) total ETX path cost.\n\
    \   Figure 5 [See the PDF.]\n               Figure 5: CDF of Hop Distance Stretch\
    \ versus\n                        Hop Distance Stretch Value.\n   Figure 6 [See\
    \ the PDF.]\n     Figure 6: CDF of ETX Path Stretch versus ETX Path Stretch Value.\n\
    \   The data for the CDF of the hop count and ETX path cost for the ideal\n  \
    \ shortest path (SP) and a path built via RPL, along with the CDF of\n   the routing\
    \ table size, is given below in Table 1.  Figures 3 to 7\n   relate to the data\
    \ in this table.\n   +---------+--------+---------+-----------+------------+-------------+\n\
    \   |   CDF   |   Hop  |   Hop   |  ETX Cost |  ETX Cost  |   Routing   |\n  \
    \ |  (%age) |  (SP)  |  (RPL)  |    (SP)   |    (RPL)   |  Table Size |\n   +---------+--------+---------+-----------+------------+-------------+\n\
    \   |     0   |   1.0  |   1.0   |     1     |    1.0     |      0      |\n  \
    \ |     5   |   1.0  |   1.03  |     1     |    1.242   |      1      |\n   |\
    \    10   |   2.0  |   2.0   |     2     |    2.048   |      2      |\n   |  \
    \  15   |   2.0  |   2.01  |     2     |    2.171   |      2      |\n   |    20\
    \   |   2.0  |   2.06  |     2     |    2.400   |      2      |\n   |    25  \
    \ |   2.0  |   2.11  |     2     |    2.662   |      3      |\n   |    30   |\
    \   2.0  |   2.42  |     2     |    2.925   |      3      |\n   |    35   |  \
    \ 2.0  |   2.90  |     3     |    3.082   |      3      |\n   |    40   |   3.0\
    \  |   3.06  |     3     |    3.194   |      4      |\n   |    45   |   3.0  |\
    \   3.1   |     3     |    3.41    |      4      |\n   |    50   |   3.0  |  \
    \ 3.15  |     3     |    3.626   |      4      |\n   |    55   |   3.0  |   3.31\
    \  |     3     |    3.823   |      5      |\n   |    60   |   3.0  |   3.50  |\
    \     3     |    4.032   |      6      |\n   |    65   |   3.0  |   3.66  |  \
    \   3     |    4.208   |      7      |\n   |    70   |   3.0  |   3.92  |    \
    \ 4     |    4.474   |      7      |\n   |    75   |   4.0  |   4.16  |     4\
    \     |    4.694   |      7      |\n   |    80   |   4.0  |   4.55  |     4  \
    \   |    4.868   |      8      |\n   |    85   |   4.0  |   4.70  |     4    \
    \ |    5.091   |      9      |\n   |    90   |   4.0  |   4.89  |     4     |\
    \    5.488   |     10      |\n   |    95   |   4.0  |   5.65  |     5     |  \
    \  5.923   |     12      |\n   |   100   |   5.0  |   7.19  |     9     |   10.125\
    \   |     44      |\n   +---------+--------+---------+-----------+------------+-------------+\n\
    \                        Table 1: Path Quality CDFs.\n   Overall, the path quality\
    \ metrics give us important information about\n   the protocol's performance when\
    \ minimizing the ETX path cost is the\n   objective to form the DAG.  The protocol,\
    \ as explained, does not\n   always provide an optimum path, especially for peer-to-peer\n\
    \   communication.  However, it does end up reducing the control overhead\n  \
    \ cost, thereby reducing unnecessary parent selection and DIO message\n   forwarding\
    \ events, by choosing a non-optimized path.  Despite this\n   specific implementation\
    \ technique, around 30% of the packets travel\n   the same number of hops as an\
    \ ideal shortest path routing mechanism,\n   and 20% of the packets experience\
    \ the same number of attempted\n   transmissions to reach the destination.  On\
    \ average, this\n   implementation costs only a few extra transmission attempts\
    \ and saves\n   a large number of control packet transmissions.\n"
- title: 4.3.  Routing Table Size
  contents:
  - "4.3.  Routing Table Size\n   The objective of this metric is to observe the distribution\
    \ of the\n   number of entries per node.  Figure 7 shows the CDF of the number\
    \ of\n   routing table entries for all nodes.  Note that 90% of the nodes need\n\
    \   to store less than 10 entries in their routing table for the topology\n  \
    \ under study.  The LBR does not have the same power or memory\n   constraints\
    \ as regular nodes do, and hence it can accommodate entries\n   for all the nodes\
    \ in the network.  The requirement to accommodate\n   devices with low storage\
    \ capacity has been mandated in [RFC5673],\n   [RFC5826], and [RFC5867].  However,\
    \ when RPL is implemented in\n   storing mode, some nodes closer to the LBR or\
    \ DAG root will require\n   more memory to store larger routing tables.\n   Figure\
    \ 7 [See the PDF.]\n   Figure 7: CDF of Routing Table Size with Respect to Number\
    \ of Nodes.\n"
- title: 4.4.  Delay Bound for P2P Routing
  contents:
  - "4.4.  Delay Bound for P2P Routing\n   For delay-sensitive applications, such\
    \ as home and building\n   automation, it is critical to optimize the end-to-end\
    \ delay.\n   Figure 8 shows the upper bound and distributions of delay for paths\n\
    \   between any two given nodes for different hop counts between the\n   source\
    \ and destination.  Here, the hop count refers to the number of\n   hops a packet\
    \ travels to reach the destination when using RPL paths.\n   This hop distance\
    \ does not correspond to the shortest path distance\n   between two nodes.  Note\
    \ that each packet has a length of 127 bytes,\n   with a 240-kbps radio, which\
    \ makes the transmission delay\n   approximately 4 milliseconds (ms).\n   Figure\
    \ 8 [See the PDF.]\n    Figure 8: Comparison of Packet Latency, for Different\
    \ Path Lengths,\n                          Expressed in Hop Count.\n   RFCs 5673\
    \ [RFC5673] and 5548 [RFC5548] mention a requirement for the\n   end-to-end delivery\
    \ delay to remain within a bounded latency.  For\n   instance, according to the\
    \ industrial routing requirement,\n   non-critical closed-loop applications may\
    \ have a latency requirement\n   that can be as low as 100 ms, whereas monitoring\
    \ services may\n   tolerate a delay in the order of seconds.  The results show\
    \ that\n   about 99% of the end-to-end communication (where the maximum hop\n\
    \   count is 7 hops) is bounded within the 100-ms requirement, for the\n   topology\
    \ under study.  It should be noted that due to poor link\n   condition, there\
    \ may be packet drops triggering retransmission, which\n   may cause larger end-to-end\
    \ delivery delays.  Nodes in the proximity\n   of the LBR may become congested\
    \ at high traffic loads, which can also\n   lead to higher end-to-end delay.\n"
- title: 4.5.  Control Packet Overhead
  contents:
  - "4.5.  Control Packet Overhead\n   The control plane overhead is an important\
    \ routing characteristic in\n   LLNs.  It is imperative to bound the control plane\
    \ overhead.  One of\n   the distinctive characteristics of RPL is that it makes\
    \ use of\n   trickle timers so as to reduce the number of control plane packets\
    \ by\n   eliminating redundant messages.  The aim of this performance metric\n\
    \   is thus to analyze the control plane overhead both in stable\n   conditions\
    \ (no network element failure overhead) and in the presence\n   of failures.\n\
    \   Data and control plane traffic comparison for each node:  Figure 9\n     \
    \ shows the comparison between the amount of data packets\n      transmitted (including\
    \ forwarded packets) and control packets (DIO\n      and DAO messages) transmitted\
    \ for all individual nodes when link\n      ETX is used to optimize the DAG. \
    \ As mentioned earlier, each node\n      generates a new data packet every 10\
    \ seconds.  Here one can\n      observe that a considerable amount of traffic\
    \ is routed through\n      the DAG root itself.  The x axis indicates the node\
    \ ID in the\n      network.  Also, as expected, the nodes that are closer to the\
    \ DAG\n      root and that act as routers (as opposed to leaves) handle much\n\
    \      more data traffic than other nodes.  Nodes 12, 36, and 38 are\n      examples\
    \ of nodes next to the DAG root, taking part in routing\n      most of the data\
    \ packets and hence having many more data packet\n      transmissions than other\
    \ nodes, as observed in Figure 9.  We can\n      also observe that the proportion\
    \ of control traffic is negligible\n      for those nodes.  This result also reinforces\
    \ the fact that the\n      amount of control plane traffic generated by RPL is\
    \ negligible on\n      these topologies.  Leaf nodes have comparable amounts of\
    \ data and\n      control packet transmissions (they do not take part in routing\
    \ the\n      data).\n   Figure 9 [See the PDF.]\n     Figure 9: Amount of Data\
    \ and Control Packets Transmitted against\n                 Node Id Using Link\
    \ ETX as Routing Metric.\n   Data and control packet transmission with respect\
    \ to time:  In\n      Figures 10, 11, and 12, the amount of data and control packets\n\
    \      transmitted for node 12 (low rank in DAG, closer to the root),\n      node\
    \ 43 (in the middle), and node 31 (leaf node) are shown,\n      respectively.\
    \  These values stand for the number of data and\n      control packets transmitted\
    \ for each 10-minute interval for the\n      particular node, to help understand\
    \ what the ratio is between data\n      and control packets exchanged in the network.\
    \  One can observe\n      that nodes closer to the DAG root have a higher proportion\
    \ of data\n      packets (as expected), and the proportion of control traffic\
    \ is\n      negligible in comparison with the data traffic.  Also, the amount\n\
    \      of data traffic handled by a node within a given interval varies\n    \
    \  largely over time for a node closer to the DAG root, because in\n      each\
    \ interval the destination of the packets from the same source\n      changes,\
    \ while 20% of the packets are destined to the DAG root.\n      As a result, the\
    \ pattern of the traffic that is handled changes\n      widely in each interval\
    \ for the nodes closer to the DAG root.  For\n      the nodes that are farther\
    \ away from the DAG root, the ratio of\n      data traffic to control traffic\
    \ is smaller, since the amount of\n      data traffic is greatly reduced.\n  \
    \ The control traffic load exhibits a wave-like pattern.  The amount of\n   control\
    \ packets for each node drops quickly as the DODAG stabilizes,\n   due to the\
    \ effect of trickle timers.  However, when a new DODAG\n   sequence is advertised\
    \ (global repair of the DODAG), the trickle\n   timers are reset and the nodes\
    \ start emitting DIOs frequently again\n   to rebuild the DODAG.  For a node closer\
    \ to the DAG root, the amount\n   of data packets is much larger than that of\
    \ control packets and\n   somewhat oscillatory around a mean value.  The amount\
    \ of control\n   packets exhibits a 'saw-tooth' behavior.  In the case where the\
    \ ETX\n   link metric is used, when the PDR changes, the ETX link metric for a\n\
    \   node to its child changes, which may lead to choosing a new parent\n   and\
    \ changing the DAG rank of the child.  This event resets the\n   trickle timer\
    \ and triggers the emission of a new DIO.  Also, the\n   issue of a new DODAG\
    \ sequence number triggers DODAG re-computation\n   and resets the trickle timers.\
    \  Therefore, one can observe that the\n   number of control packets attains a\
    \ high value for one interval and\n   comes down to lower values for subsequent\
    \ intervals.  The interval\n   with a high number of control packets denotes the\
    \ interval where the\n   timers to emit a new DIO are reset more frequently. \
    \ As the network\n   stabilizes, the control packets are less dense in volume.\
    \  For leaf\n   nodes, the amount of control packets is comparable to that of\
    \ data\n   packets, as leaf nodes are more prone to face changes in their DODAG\n\
    \   rank as opposed to nodes closer to the DAG root when the link ETX\n   value\
    \ in the topology changes dynamically.\n   Figure 10 [See the PDF.]\n        \
    \ Figure 10: Amount of Data and Control Packets Transmitted\n                \
    \               for Node 12.\n   Figure 11 [See the PDF.]\n         Figure 11:\
    \ Amount of Data and Control Packets Transmitted\n                           \
    \    for Node 43.\n   Figure 12 [See the PDF.]\n         Figure 12: Amount of\
    \ Data and Control Packets Transmitted\n                               for Node\
    \ 31.\n"
- title: 4.6.  Loss of Connectivity
  contents:
  - "4.6.  Loss of Connectivity\n   Upon link failures, a node may lose its parents\
    \ -- preferred and\n   backup (if any) -- thus leading to a loss of connectivity\
    \ (no path to\n   the DAG root).  RPL specifies two mechanisms for DODAG repairs,\n\
    \   referred to as global repair and local repair.  In this document,\n   simulation\
    \ results are presented to evaluate the amount of time data\n   packets are dropped\
    \ due to a loss of connectivity for the following\n   two cases: a) when only\
    \ using global repair (i.e., the DODAG is\n   rebuilt thanks to the emission of\
    \ new DODAG sequence numbers by the\n   DAG root), and b) when using local repair\
    \ (poisoning the sub-DAG in\n   case of loss of connectivity) in addition to global\
    \ repair.  The idea\n   is to tune the frequency at which new DODAG sequence numbers\
    \ are\n   generated by the DAG root, and also to observe the effect of varying\n\
    \   the frequency for global repair and the concurrent use of global and\n   local\
    \ repair.  It is expected that more frequent increments of DODAG\n   sequence\
    \ numbers will lead to a shorter duration of connectivity loss\n   at a price\
    \ of a higher rate of control packets in the network.  For\n   the use of both\
    \ global and local repair, the simulation results show\n   the trade-off in amount\
    \ of time that a node may remain without\n   service and total number of control\
    \ packets.\n   Figure 13 shows the CDF of time spent by any node without service,\n\
    \   when the data packet rate is one packet every 10 seconds and a new\n   DODAG\
    \ sequence number is generated every 10 minutes.  This plot\n   reflects the property\
    \ of global repair without any local repair\n   scheme.  When all the parents\
    \ are temporarily unreachable from a\n   node, the time before it hears a DIO\
    \ from another node is recorded,\n   which gives the time without service.  We\
    \ define the DAG repair timer\n   as the interval at which the LBR increments\
    \ the DAG sequence number,\n   thus triggering a global re-optimization.  In some\
    \ cases, this value\n   might go up to the DAG repair timer value, because until\
    \ a DIO is\n   heard, the node does not have a parent and hence no route to the\
    \ LBR\n   or other nodes not in its own sub-DAG.  Clearly, this situation\n  \
    \ indicates a lack of connectivity and loss of service for the node.\n   Figure\
    \ 13 [See the PDF.]\n         Figure 13: CDF: Loss of Connectivity with Global\
    \ Repair.\n   The effect of the DAG repair timer on time without service is plotted\n\
    \   in Figure 14, where the source rate is 20 seconds/packet and in\n   Figure\
    \ 15, where the source sends a packet every 10 seconds.\n   Figure 14 [See the\
    \ PDF.]\n            Figure 14: CDF: Loss of Connectivity for Different\n    \
    \       Global Repair Period, Source Rate 20 Seconds/Packet.\n   Figure 15 [See\
    \ the PDF.]\n            Figure 15: CDF: Loss of Connectivity for Different\n\
    \           Global Repair Period, Source Rate 10 Seconds/Packet.\n   The data\
    \ for Figures 13 and 15 can be found in Table 2.  The table\n   shows how the\
    \ CDF of time without connectivity to the LBR increases\n   while we increase\
    \ the time period to emit new DAG sequence numbers,\n   when the nodes generate\
    \ a packet every 10 seconds.\n   +---------+------------------+------------------+-------------------+\n\
    \   |   CDF   |  Repair Period   |  Repair Period   |   Repair Period   |\n  \
    \ |  (%age) |   10 Minutes     |   30 Minutes     |    60 Minutes     |\n   +---------+------------------+------------------+-------------------+\n\
    \   |     0   |       0.464      |       0.045      |       0.027       |\n  \
    \ |     5   |       0.609      |       0.424      |       0.396       |\n   |\
    \    10   |       1.040      |       1.451      |       0.396       |\n   |  \
    \  15   |       1.406      |       3.035      |       0.714       |\n   |    20\
    \   |       1.934      |       3.521      |       0.714       |\n   |    25  \
    \ |       2.113      |       5.461      |       1.856       |\n   |    30   |\
    \       3.152      |       5.555      |       1.856       |\n   |    35   |  \
    \     3.363      |       7.756      |       6.173       |\n   |    40   |    \
    \   4.9078     |       8.604      |       6.173       |\n   |    45   |      \
    \ 8.575      |       9.181      |      14.751       |\n   |    50   |       9.788\
    \      |      21.974      |      14.751       |\n   |    55   |      13.230  \
    \    |      30.017      |      14.751       |\n   |    60   |      17.681    \
    \  |      31.749      |      16.166       |\n   |    65   |      29.356      |\
    \      68.709      |      16.166       |\n   |    70   |      34.019      |  \
    \    92.974      |     302.459       |\n   |    75   |      49.444      |    \
    \ 117.869      |     302.459       |\n   |    80   |      75.737      |     133.653\
    \      |     488.602       |\n   |    85   |     150.089      |     167.828  \
    \    |     488.602       |\n   |    90   |     180.505      |     271.884    \
    \  |     488.602       |\n   |    95   |     242.247      |     464.047      |\
    \     488.602       |\n   |   100   |     273.808      |     464.047      |  \
    \   488.602       |\n   +---------+------------------+------------------+-------------------+\n\
    \   Table 2: Loss of Connectivity Time, Data Rate - 10 Seconds / Packet.\n   The\
    \ data for Figure 14 can be found in Table 3.  The table shows how\n   the CDF\
    \ of time without connectivity to the LBR increases while we\n   increase the\
    \ time period to emit new DAG sequence numbers, when the\n   nodes generate a\
    \ packet every 20 seconds.\n   +---------+------------------+------------------+-------------------+\n\
    \   |   CDF   |   Repair Period  |   Repair Period  |   Repair Period   |\n  \
    \ |  (%age) |    10 Minutes    |    30 Minutes    |    60 Minutes     |\n   +---------+------------------+------------------+-------------------+\n\
    \   |     0   |       0.071      |       0.955      |       0.167       |\n  \
    \ |     5   |       0.126      |       2.280      |       1.377       |\n   |\
    \    10   |       0.403      |       2.926      |       1.409       |\n   |  \
    \  15   |       0.902      |       3.269      |       1.409       |\n   |    20\
    \   |       1.281      |      16.623      |       3.054       |\n   |    25  \
    \ |       2.322      |      21.438      |       5.175       |\n   |    30   |\
    \       2.860      |      48.479      |       5.175       |\n   |    35   |  \
    \     3.316      |      49.495      |      10.30        |\n   |    40   |    \
    \   3.420      |      93.700      |      25.406       |\n   |    45   |      \
    \ 6.363      |     117.594      |      25.406       |\n   |    50   |      11.500\
    \      |     243.429      |      34.379       |\n   |    55   |      19.703  \
    \    |     277.039      |     102.141       |\n   |    60   |      22.216    \
    \  |     284.660      |     102.141       |\n   |    65   |      39.211      |\
    \     285.101      |     328.293       |\n   |    70   |      63.197      |  \
    \   376.549      |     556.296       |\n   |    75   |      88.986      |    \
    \ 443.450      |     556.296       |\n   |    80   |     147.509      |     452.883\
    \      |    1701.52        |\n   |    85   |     154.26       |     653.420  \
    \    |    2076.41        |\n   |    90   |     244.241      |     720.032    \
    \  |    2076.41        |\n   |    95   |     518.835      |    1760.47       |\
    \    2076.41        |\n   |   100   |     555.57       |    1760.47       |  \
    \  2076.41        |\n   +---------+------------------+------------------+-------------------+\n\
    \   Table 3: Loss of Connectivity Time, Data Rate - 20 Seconds / Packet.\n   Figure\
    \ 16 shows the effect of the DAG global repair timer period on\n   control traffic.\
    \  As expected, as the frequency at which new DAG\n   sequence numbers are generated\
    \ increases, the amount of control\n   traffic decreases because DIO messages\
    \ are sent less frequently to\n   rebuild the DODAG.  However, reducing the control\
    \ traffic comes at a\n   price of increased loss of connectivity when only global\
    \ repair is\n   used.\n   Figure 16 [See the PDF.]\n            Figure 16: Amount\
    \ of Control Traffic for Different\n                          Global Repair Periods.\n\
    \   From the above results, it is clear that the time the protocol takes\n   to\
    \ re-establish routes and to converge, after an unexpected link or\n   device\
    \ failure happens, is fairly long.  [RFC5826] mandates that \"the\n   routing\
    \ protocol MUST converge within 0.5 seconds if no nodes have\n   moved\".  Clearly,\
    \ implementation of a repair mechanism based on new\n   DAG sequence numbers alone\
    \ would not meet the requirements.  Hence, a\n   local repair mechanism, in the\
    \ form of poisoning the sub-DAG and\n   issuing a DIS, has been adopted.\n   The\
    \ effect of the DAG repair timer on time without service when local\n   repair\
    \ is activated is now observed and plotted in Figure 17, where\n   the source\
    \ rate is 20 seconds/packet.  A comparison of the CDF of\n   loss of connectivity\
    \ for the global repair mechanism and the global +\n   local repair mechanism\
    \ is shown in Figures 18 and 19 (semi-log plots,\n   x axis in logarithmic scale\
    \ and y axis in linear scale), where the\n   source generates a packet every 10\
    \ seconds and 20 seconds,\n   respectively.  For these plots, the x axis shows\
    \ time in log scale,\n   and the y axis denotes the corresponding CDF in linear\
    \ scale.  One\n   can observe that using local repair (with poisoning of the sub-DAG)\n\
    \   greatly reduces loss of connectivity.\n   Figure 17 [See the PDF.]\n    Figure\
    \ 17: CDF: Loss of Connectivity for Different DAG Repair Timer\n      Values for\
    \ Global+Local Repair, Source Rate 20 Seconds/Packet.\n   Figure 18 [See the PDF.]\n\
    \        Figure 18: CDF: Loss of Connectivity for Global Repair and\n        \
    \    Global+Local Repair, Source Rate 10 Seconds/Packet.\n   Figure 19 [See the\
    \ PDF.]\n        Figure 19: CDF: Loss of Connectivity for Global Repair and\n\
    \            Global+Local Repair, Source Rate 20 Seconds/Packet.\n   A comparison\
    \ between the amount of control plane overhead used for\n   global repair only\
    \ and for the global plus local repair mechanism is\n   shown in Figure 20, which\
    \ highlights the improved performance of RPL\n   in terms of convergence time\
    \ at very little extra overhead.  From\n   Figure 19, in 85% of the cases the\
    \ protocol finds connectivity to the\n   LBR for the concerned nodes within a\
    \ fraction of seconds when local\n   repair is employed.  Using only global repair\
    \ leads to repair periods\n   of 150-154 seconds, as observed in Figures 13 and\
    \ 14.\n   Figure 20 [See the PDF.]\n            Figure 20: Number of Control Packets\
    \ for Different\n            DAG Sequence Number Period, for Both Global Repair\n\
    \                         and Global+Local Repair.\n"
- title: 5.  RPL in a Building Automation Routing Scenario
  contents:
  - "5.  RPL in a Building Automation Routing Scenario\n   Unlike the previous traffic\
    \ pattern, where a majority of the total\n   traffic generated by any node is\
    \ destined to the root, this section\n   considers a different traffic pattern,\
    \ which is more prominent in a\n   home or building routing scenario.  In the\
    \ simulations shown below,\n   the nodes send 60% of their total generated traffic\
    \ to the physically\n   1-hop distant node and 20% of traffic to a 2-hop distant\
    \ node; the\n   other 20% of traffic is distributed among other nodes in the network.\n\
    \   The CDF of path quality metrics such as hop count, ETX path cost,\n   average\
    \ hop distance stretch, ETX path stretch, and delay for P2P\n   routing for all\
    \ pairs of nodes is calculated.  Maintaining a low\n   delay bound for P2P traffic\
    \ is of high importance, as applications in\n   home and building routing typically\
    \ have low delay tolerance.\n"
- title: 5.1.  Path Quality
  contents:
  - "5.1.  Path Quality\n   Figure 21 shows the CDF of the hop count for both RPL\
    \ and ideal\n   shortest path routing for the traffic pattern described above.\n\
    \   Figure 22 shows the CDF of the expected number of transmissions (ETX)\n  \
    \ for each packet to reach its destination.  Figures 23 and 24 show the\n   CDF\
    \ of the stretch factor for these two metrics.  To illustrate the\n   stretch\
    \ factor, an example from Figure 24 will be given next.  For\n   all paths built\
    \ by RPL, 85% of the time, the path cost is less than\n   the path cost for the\
    \ ideal shortest path plus one.\n   Figure 21 [See the PDF.]\n            Figure\
    \ 21: CDF of End-to-End Hop Count for RPL and\n                   Ideal Shortest\
    \ Path in Home Routing.\n   Figure 22 [See the PDF.]\n            Figure 22: CDF\
    \ of ETX Path Cost Metric for RPL and\n                   Ideal Shortest Path\
    \ in Home Routing.\n   Figure 23 [See the PDF.]\n     Figure 23: CDF of Hop Distance\
    \ Stretch from Ideal Shortest Path.\n   Figure 24 [See the PDF.]\n      Figure\
    \ 24: CDF of ETX Metric Stretch from Ideal Shortest Path.\n"
- title: 5.2.  Delay
  contents:
  - "5.2.  Delay\n   To get an idea of maximum observable delay in the above-mentioned\n\
    \   traffic pattern, the delay for different numbers of hops to the\n   destination\
    \ for RPL is considered.  Figure 25 shows how the end-to-\n   end packet latency\
    \ is distributed for different packets with\n   different hop counts in the network.\n\
    \   Figure 25 [See the PDF.]\n        Figure 25: Packet Latency for Different\
    \ Hop Counts in RPL.\n   For this deployment scenario, 60% of the traffic has\
    \ been restricted\n   to a 1-hop neighborhood.  Hence, intuitively, the protocol\
    \ is\n   expected to yield path qualities that are close to those of ideal\n \
    \  shortest path routing for most of the paths.  From the CDF of the hop\n   count\
    \ and ETX path cost, it is clear that peer-to-peer paths are more\n   often closer\
    \ to an ideal shortest path.  The end-to-end delay for\n   distances within 2\
    \ hops is less than 60 ms for 99% of the delivered\n   packets, while packets\
    \ traversing 5 hops or more are delivered within\n   100 ms 99% of the time. \
    \ These results demonstrate that for a normal\n   routing scenario of an LLN deployment\
    \ in a building, RPL performs\n   fairly well without incurring much control plane\
    \ overhead, and it can\n   be applied for delay-critical applications as well.\n"
- title: 6.  RPL in a Large-Scale Network
  contents:
  - "6.  RPL in a Large-Scale Network\n   In this section, we focus on simulating\
    \ RPL in a large network and\n   study its scalability by focusing on a few performance\
    \ metrics: the\n   latency and path cost stretch, and the amount of control packets.\n\
    \   The 2442-node smart meter network with its corresponding link traces\n   was\
    \ used in this scalability study.  To simulate a more realistic\n   scenario for\
    \ a smart meter network, 100% of the packets generated by\n   each node are destined\
    \ to the root.  Therefore, no traffic is\n   destined to nodes other than the\
    \ root.\n"
- title: 6.1.  Path Quality
  contents:
  - "6.1.  Path Quality\n   To investigate RPL's scalability, the CDF of the ETX path\
    \ cost in the\n   large-scale smart meter network is compared to a hypothetical\
    \ ideal\n   shortest path routing protocol that minimizes the total ETX path cost\n\
    \   (Figure 26).  In this simulation, the path stretch is also calculated\n  \
    \ for each packet that traverses the network.  The path stretch is\n   determined\
    \ as the difference between the path cost taken by a packet\n   while following\
    \ a route built via RPL and a path computed using an\n   ideal shortest path routing\
    \ protocol.  The CDF of the ETX fractional\n   stretch, which is determined as\
    \ the ETX metric stretch value over the\n   ETX path cost of an ideal shortest\
    \ path, is plotted in Figure 27.\n   The fractional hop distance stretch value,\
    \ as defined in the\n   Terminology section, is shown in Figure 28.\n   Looking\
    \ at the path quality plots, it is obvious that RPL works in a\n   non-optimal\
    \ fashion in this deployment scenario as well.  However, on\n   average, for each\
    \ source-destination pair, the ETX fractional stretch\n   is limited to 30% of\
    \ the ideal shortest path cost.  This fraction is\n   higher for paths with shorter\
    \ distances and lower for paths where the\n   source and destination are far apart.\
    \  The negative stretch factor\n   for the hop count is an interesting feature\
    \ of this deployment and is\n   due to RPL's decision to not switch to another\
    \ parent where the\n   improvement in path quality is not significant.  As mentioned\n\
    \   previously, in this implementation, a node will only switch to a new\n   parent\
    \ if the advertised ETX path cost to the LBR through the new\n   candidate parent\
    \ is 20% better than the old one.  The nodes tend to\n   hear DIOs from a smaller\
    \ hop count first, and later do not always\n   shift to a larger hop count and\
    \ smaller ETX path cost.  As the\n   traffic is mostly to the DAG root, some P2P\
    \ paths built via RPL do\n   yield a smaller hop count from source to destination,\
    \ albeit at a\n   larger ETX path cost.\n   As observed in Figure 26, 90% of the\
    \ packets transmitted during the\n   simulation have a (shortest) ETX path cost\
    \ to destination less than\n   or equal to 12.  However, via RPL, 90% of the packets\
    \ will follow\n   paths that have a total ETX path cost of up to 14.  Though all\n\
    \   packets are destined to the LBR, it is to be noted that this\n   implementation\
    \ ignores a change of up to 20% in total ETX path cost.\n   Figures 27 and 28\
    \ indicate that all paths have a very low ETX\n   fractional stretch factor as\
    \ far as the total ETX path cost is\n   concerned, and some of the paths have\
    \ lower hop counts to the LBR or\n   DAG root as well when compared to the hop\
    \ count of the ideal shortest\n   path.\n   Figure 26 [See the PDF.]\n       \
    \ Figure 26: CDF of Total ETX Path Cost versus ETX Path Cost.\n   Figure 27 [See\
    \ the PDF.]\n              Figure 27: CDF of ETX Fractional Stretch versus\n \
    \                      ETX Fractional Stretch Value.\n   Figure 28 [See the PDF.]\n\
    \              Figure 28: CDF of Fractional Hop Count Stretch.\n"
- title: 6.2.  Delay
  contents:
  - "6.2.  Delay\n   Figure 29 shows how end-to-end packet latency is distributed\
    \ for\n   different hop counts in the network.  According to [RFC5548], Urban\n\
    \   LLNs (U-LLNs) are delay tolerant, and the information, except for\n   critical\
    \ alarms, should arrive within a fraction of the reporting\n   interval (within\
    \ a few seconds).  The packet generation for this\n   deployment has been set\
    \ higher than usual to incur high traffic\n   volume, and nodes generate data\
    \ once every 30 seconds.  However, the\n   end-to-end latency for most of the\
    \ packets is condensed between\n   500 ms and 1 s, where the upper limit corresponds\
    \ to packets\n   traversing longer (greater than or equal to 6 hops) paths.\n\
    \   Figure 29 [See the PDF.]\n               Figure 29: End-to-End Packet Delivery\
    \ Latency\n                         for Different Hop Counts.\n"
- title: 6.3.  Control Packet Overhead
  contents:
  - "6.3.  Control Packet Overhead\n   Figure 30 shows the comparison between data\
    \ packets (originated and\n   forwarded) and control packets (DIO and DAO messages)\
    \ transmitted by\n   each node (link ETX is used as the routing metric).  Here\
    \ one can\n   observe that in spite of the large scale of the network, the amount\n\
    \   of control traffic in the protocol is negligible in comparison to\n   data\
    \ packet transmission.  The smaller node ID for this network\n   actually indicates\
    \ closer proximity to the DAG root, and nodes with\n   high ID numbers are actually\
    \ farther away from the DAG root.  Also,\n   as expected, we can observe in Figures\
    \ 31, 32, and 33 that the\n   (non-leaf) nodes closer to the DAG root have many\
    \ more data packet\n   transmissions than other nodes.  The leaf nodes have comparable\n\
    \   amounts of data and control packet transmissions, as they do not take\n  \
    \ part in routing the data.  As seen before, the data traffic for a\n   child\
    \ node has much less variation than the nodes that are closer to\n   the DAG root.\
    \  This variation decreases with increase in DAG depth.\n   In this topology,\
    \ Nodes 1, 2, and 3, etc., are direct children of\n   the LBR.\n   Figure 30 [See\
    \ the PDF.]\n              Figure 30: Data and Control Packet Comparison.\n  \
    \ Figure 31 [See the PDF.]\n         Figure 31: Data and Control Packets over\
    \ Time for Node 1.\n   Figure 32 [See the PDF.]\n        Figure 32: Data and Control\
    \ Packets over Time for Node 78.\n   Figure 33 [See the PDF.]\n        Figure\
    \ 33: Data and Control Packets over Time for Node 300.\n   In Figure 34, the effect\
    \ of the global repair period timer on control\n   packet overhead is shown.\n\
    \   Figure 34 [See the PDF.]\n            Figure 34: Numbers of Control Packets\
    \ for Different\n                       Global Repair Timer Periods.\n"
- title: 7.  Scaling Property and Routing Stability
  contents:
  - "7.  Scaling Property and Routing Stability\n   An important metric of interest\
    \ is the maximum load experienced by\n   any node (CPU usage) in terms of the\
    \ number of control packets\n   transmitted by the node.  Also, to get an idea\
    \ of scaling properties\n   of RPL in large-scale networks, it is also key to\
    \ analyze the number\n   of packets handled by the RPL nodes for networks of different\
    \ sizes.\n   In these simulations, at any given interval, the node with maximum\n\
    \   control overhead load is identified.  The amount of maximum control\n   overhead\
    \ processed by that node is plotted against time for three\n   different networks\
    \ under study.  The first one is Network 'A', which\n   has 45 nodes and is shown\
    \ in Figure 1 (Section 3); the second is\n   Network 'B', which is another deployed\
    \ outdoor network with 86 nodes;\n   and the third is Network 'C', which is the\
    \ large deployed smart meter\n   network with 2442 nodes as noted previously in\
    \ this document.\n   In Figure 35, the comparison of maximum control loads is\
    \ shown for\n   different network sizes.  For the network with 45 nodes, the maximum\n\
    \   number of control packets in the network stays within a limit of\n   50 packets\
    \ (per 1-minute interval), where for the networks with 86\n   and 2442 nodes,\
    \ this limit stretches to 100 and 2 * 10^3 packets per\n   1-minute interval,\
    \ respectively.\n   Figure 35 [See the PDF.]\n          Figure 35: Scaling Property\
    \ of Maximum Control Packets\n                     Processed by Any Node over\
    \ Time.\n   For a network built with low-power devices interconnected by lossy\n\
    \   links, it is of the utmost importance to ensure that routing packets\n   are\
    \ not flooded in the entire network and that the routing topology\n   stays as\
    \ stable as possible.  Any change in routing information,\n   especially parent-child\
    \ relationships, would reset the timer, leading\n   to emitting new DIOs, and\
    \ would hence change the node's path metric\n   to reach the root.  This change\
    \ will trigger a series of control\n   plane messages (RPL packets) in the DODAG.\
    \  Therefore, it is\n   important to carefully control the triggering of DIO control\
    \ packets\n   via the use of thresholds.\n   In this study, the effect of the\
    \ tolerance value that is considered\n   before emitting a DIO reflecting a new\
    \ path cost is analyzed.  Four\n   cases are considered:\n   o  No change in DAG\
    \ depth of a node is ignored;\n   o  The implementation ignores a 10% change in\
    \ the ETX path cost to\n      the DAG root.  That is, if the change in total path\
    \ cost to the\n      root/LBR -- due to DIO reception from the most preferred\
    \ parent or\n      due to shifting to another parent -- is less than 10%, the\
    \ node\n      will not advertise the new metric to the root;\n   o  The implementation\
    \ ignores a 20% change in ETX path cost to the\n      DAG root for any node before\
    \ deciding to advertise a new depth;\n   o  The implementation ignores a 30% change\
    \ in the total ETX path cost\n      to the DAG root of a node before deciding\
    \ to advertise a new\n      depth.\n   This decision does affect the optimum path\
    \ quality to the DAG root.\n   As observed in Figure 36, for 0% tolerance, 95%\
    \ of paths used have an\n   ETX fractional stretch factor of less than 10%.  Similarly,\
    \ for 10%\n   and 20% tolerance levels, 95% of paths will have a 15% and 20% ETX\n\
    \   fractional path stretch.  However, the increased routing stability\n   and\
    \ decreased control overhead are the profit gained from the 10%\n   extra increase\
    \ in path length or ETX path cost, whichever is used as\n   the metric to optimize\
    \ the DAG.\n   Figure 36 [See the PDF.]\n                 Figure 36: ETX Fractional\
    \ Stretch Factor\n                      for Different Tolerance Levels.\n   As\
    \ the above-mentioned threshold also affects the path taken by a\n   packet, this\
    \ study also demonstrates the effect of the threshold on\n   routing stability\
    \ (number of times P2P paths change between a source\n   and a destination). \
    \ For Network 'A' (shown in Figure 1) and the\n   large smart meter network 'C',\
    \ the CDF of path change is plotted in\n   Figures 37 and 38, respectively, against\
    \ the fraction of path change\n   for different thresholds (triggering the emission\
    \ of a new DIO upon\n   path cost change).\n   If X packets are transferred from\
    \ source A to destination B, and out\n   of X times, Y times the path between\
    \ this source-destination pair is\n   changed, then we compute the fraction of\
    \ path change as Y/X * 100%.\n   This metric is computed over all source-destination\
    \ pairs, and the\n   CDF is plotted in the y axis.\n   Figure 37 [See the PDF.]\n\
    \     Figure 37: Distribution of Fraction of Path Change for Network A.\n   Figure\
    \ 38 [See the PDF.]\n            Figure 38: Distribution of Fraction of Path Change\n\
    \                           for Large Network C.\n   This document also compares\
    \ the CDF of the fraction of path change\n   for three different networks -- A,\
    \ B, and C.  Figure 39 shows how the\n   three networks exhibit a change of P2P\
    \ path when a 30% change in\n   metric cost to the root is ignored before shifting\
    \ to a new parent.\n   Figure 39 [See the PDF.]\n     Figure 39: Comparison of\
    \ Distribution of Fraction of Path Change.\n"
- title: 8.  Comments
  contents:
  - "8.  Comments\n   All the simulation results presented in this document corroborate\
    \ the\n   expected protocol behavior for the topologies and traffic model used\n\
    \   in the study.  For the particular discussed scenarios, the protocol\n   is\
    \ shown to meet the desired delay and convergency requirements and\n   to exhibit\
    \ self-healing properties without external intervention,\n   incurring negligible\
    \ control overhead (only a small fraction of data\n   traffic).  RPL provided\
    \ near-optimum path quality for most of the\n   packets in the scenarios considered\
    \ here and is able to trade off\n   control overhead for path quality via configurable\
    \ parameters (such\n   as decisions on when to switch to a new parent), as per\
    \ the\n   application and device requirements; thus, RPL can trade off routing\n\
    \   stability for control overhead as well.  Finally, as per the\n   requirement\
    \ of urban LLN deployments, the protocol is shown to scale\n   to larger topologies\
    \ (several thousand nodes), for the topologies\n   considered in this implementation.\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   This document describes investigations performed\
    \ in the Castalia\n   wireless sensor network simulator; it does not consider\
    \ packets on\n   the Internet.  [RFC6550] describes security considerations for\
    \ RPL\n   networks.\n"
- title: 10.  Acknowledgements
  contents:
  - "10.  Acknowledgements\n   The authors would like to acknowledge Jerald P. Martocci,\
    \ Mukul\n   Goyal, Emmanuel Monnerie, Philip Levis, Omprakash Gnawali, and Craig\n\
    \   Partridge for their valuable and helpful suggestions over metrics to\n   include\
    \ and overall feedback.\n"
- title: 11.  Informative References
  contents:
  - "11.  Informative References\n   [Castalia-2.2]\n              Boulis, A., \"\
    Castalia: Revealing pitfalls in designing\n              distributed algorithms\
    \ in WSN\", Proceedings of the 5th\n              international conference on\
    \ Embedded networked sensor\n              systems (SenSys'07), pp. 407-408, 2007.\n\
    \   [NS-2]     \"The Network Simulator version 2 (ns-2)\",\n              <http://www.isi.edu/nsnam/ns/>.\n\
    \   [OMNeTpp]  Varga, A., \"The OMNeT++ Discrete Event Simulation System\",\n\
    \              Proceedings of the European Simulation\n              Multiconference\
    \ (ESM'2001), June 2001.\n   [RFC5548]  Dohler, M., Ed., Watteyne, T., Ed., Winter,\
    \ T., Ed., and\n              D. Barthel, Ed., \"Routing Requirements for Urban\
    \ Low-Power\n              and Lossy Networks\", RFC 5548, May 2009.\n   [RFC5673]\
    \  Pister, K., Ed., Thubert, P., Ed., Dwars, S., and T.\n              Phinney,\
    \ \"Industrial Routing Requirements in Low-Power and\n              Lossy Networks\"\
    , RFC 5673, October 2009.\n   [RFC5826]  Brandt, A., Buron, J., and G. Porcu,\
    \ \"Home Automation\n              Routing Requirements in Low-Power and Lossy\
    \ Networks\",\n              RFC 5826, April 2010.\n   [RFC5867]  Martocci, J.,\
    \ Ed., De Mil, P., Riou, N., and W. Vermeylen,\n              \"Building Automation\
    \ Routing Requirements in Low-Power and\n              Lossy Networks\", RFC 5867,\
    \ June 2010.\n   [RFC6206]  Levis, P., Clausen, T., Hui, J., Gnawali, O., and\
    \ J. Ko,\n              \"The Trickle Algorithm\", RFC 6206, March 2011.\n   [RFC6550]\
    \  Winter, T., Ed., Thubert, P., Ed., Brandt, A., Hui, J.,\n              Kelsey,\
    \ R., Levis, P., Pister, K., Struik, R., Vasseur,\n              JP., and R. Alexander,\
    \ \"RPL: IPv6 Routing Protocol for\n              Low-Power and Lossy Networks\"\
    , RFC 6550, March 2012.\n   [RFC6551]  Vasseur, JP., Ed., Kim, M., Ed., Pister,\
    \ K., Dejean, N.,\n              and D. Barthel, \"Routing Metrics Used for Path\
    \ Calculation\n              in Low-Power and Lossy Networks\", RFC 6551, March\
    \ 2012.\n   [ROLL-TERMS]\n              Vasseur, JP., \"Terminology in Low power\
    \ And Lossy\n              Networks\", Work in Progress, September 2011.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Joydeep Tripathi (editor)\n   Drexel University\n   3141\
    \ Chestnut Street 7-313\n   Philadelphia, PA  19104\n   USA\n   EMail: jt369@drexel.edu\n\
    \   Jaudelice C. de Oliveira (editor)\n   Drexel University\n   3141 Chestnut\
    \ Street 7-313\n   Philadelphia, PA  19104\n   USA\n   EMail: jau@coe.drexel.edu\n\
    \   JP. Vasseur (editor)\n   Cisco Systems, Inc.\n   11, Rue Camille Desmoulins\n\
    \   Issy Les Moulineaux  92782\n   France\n   EMail: jpv@cisco.com\n"
