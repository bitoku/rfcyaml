- title: __initial_text__
  contents:
  - '                Randomness Recommendations for Security

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  This memo\n   does not specify an Internet standard of any kind.  Distribution\
    \ of\n   this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   Security systems today are built on increasingly strong cryptographic\n\
    \   algorithms that foil pattern analysis attempts. However, the security\n  \
    \ of these systems is dependent on generating secret quantities for\n   passwords,\
    \ cryptographic keys, and similar quantities.  The use of\n   pseudo-random processes\
    \ to generate secret quantities can result in\n   pseudo-security.  The sophisticated\
    \ attacker of these security\n   systems may find it easier to reproduce the environment\
    \ that produced\n   the secret quantities, searching the resulting small set of\n\
    \   possibilities, than to locate the quantities in the whole of the\n   number\
    \ space.\n   Choosing random quantities to foil a resourceful and motivated\n\
    \   adversary is surprisingly difficult.  This paper points out many\n   pitfalls\
    \ in using traditional pseudo-random number generation\n   techniques for choosing\
    \ such quantities.  It recommends the use of\n   truly random hardware techniques\
    \ and shows that the existing hardware\n   on many systems can be used for this\
    \ purpose.  It provides\n   suggestions to ameliorate the problem when a hardware\
    \ solution is not\n   available.  And it gives examples of how large such quantities\
    \ need\n   to be for some particular applications.\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   Comments on this document that have been incorporated were\
    \ received\n   from (in alphabetic order) the following:\n        David M. Balenson\
    \ (TIS)\n        Don Coppersmith (IBM)\n        Don T. Davis (consultant)\n  \
    \      Carl Ellison (Stratus)\n        Marc Horowitz (MIT)\n        Christian\
    \ Huitema (INRIA)\n        Charlie Kaufman (IRIS)\n        Steve Kent (BBN)\n\
    \        Hal Murray (DEC)\n        Neil Haller (Bellcore)\n        Richard Pitkin\
    \ (DEC)\n        Tim Redmond (TIS)\n        Doug Tygar (CMU)\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction...........................................\
    \ 3\n   2. Requirements........................................... 4\n   3. Traditional\
    \ Pseudo-Random Sequences.................... 5\n   4. Unpredictability.......................................\
    \ 7\n   4.1 Problems with Clocks and Serial Numbers............... 7\n   4.2 Timing\
    \ and Content of External Events................  8\n   4.3 The Fallacy of Complex\
    \ Manipulation..................  8\n   4.4 The Fallacy of Selection from a Large\
    \ Database.......  9\n   5. Hardware for Randomness...............................\
    \ 10\n   5.1 Volume Required...................................... 10\n   5.2\
    \ Sensitivity to Skew.................................. 10\n   5.2.1 Using Stream\
    \ Parity to De-Skew..................... 11\n   5.2.2 Using Transition Mappings\
    \ to De-Skew............... 12\n   5.2.3 Using FFT to De-Skew...............................\
    \ 13\n   5.2.4 Using Compression to De-Skew....................... 13\n   5.3\
    \ Existing Hardware Can Be Used For Randomness......... 14\n   5.3.1 Using Existing\
    \ Sound/Video Input................... 14\n   5.3.2 Using Existing Disk Drives.........................\
    \ 14\n   6. Recommended Non-Hardware Strategy..................... 14\n   6.1\
    \ Mixing Functions..................................... 15\n   6.1.1 A Trivial\
    \ Mixing Function.......................... 15\n   6.1.2 Stronger Mixing Functions..........................\
    \ 16\n   6.1.3 Diff-Hellman as a Mixing Function.................. 17\n   6.1.4\
    \ Using a Mixing Function to Stretch Random Bits..... 17\n   6.1.5 Other Factors\
    \ in Choosing a Mixing Function........ 18\n   6.2 Non-Hardware Sources of Randomness...................\
    \ 19\n   6.3 Cryptographically Strong Sequences................... 19\n   6.3.1\
    \ Traditional Strong Sequences....................... 20\n   6.3.2 The Blum Blum\
    \ Shub Sequence Generator.............. 21\n   7. Key Generation Standards..............................\
    \ 22\n   7.1 US DoD Recommendations for Password Generation....... 23\n   7.2\
    \ X9.17 Key Generation................................. 23\n   8. Examples of\
    \ Randomness Required....................... 24\n   8.1  Password Generation.................................\
    \ 24\n   8.2 A Very High Security Cryptographic Key............... 25\n   8.2.1\
    \ Effort per Key Trial............................... 25\n   8.2.2 Meet in the\
    \ Middle Attacks......................... 26\n   8.2.3 Other Considerations...............................\
    \ 26\n   9. Conclusion............................................ 27\n   10.\
    \ Security Considerations.............................. 27\n   References...............................................\
    \ 28\n   Authors' Addresses....................................... 30\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   Software cryptography is coming into wider use.  Systems\
    \ like\n   Kerberos, PEM, PGP, etc. are maturing and becoming a part of the\n\
    \   network landscape [PEM].  These systems provide substantial\n   protection\
    \ against snooping and spoofing.  However, there is a\n   potential flaw.  At\
    \ the heart of all cryptographic systems is the\n   generation of secret, unguessable\
    \ (i.e., random) numbers.\n   For the present, the lack of generally available\
    \ facilities for\n   generating such unpredictable numbers is an open wound in\
    \ the design\n   of cryptographic software.  For the software developer who wants\
    \ to\n   build a key or password generation procedure that runs on a wide\n  \
    \ range of hardware, the only safe strategy so far has been to force\n   the local\
    \ installation to supply a suitable routine to generate\n   random numbers.  To\
    \ say the least, this is an awkward, error-prone\n   and unpalatable solution.\n\
    \   It is important to keep in mind that the requirement is for data that\n  \
    \ an adversary has a very low probability of guessing or determining.\n   This\
    \ will fail if pseudo-random data is used which only meets\n   traditional statistical\
    \ tests for randomness or which is based on\n   limited range sources, such as\
    \ clocks.  Frequently such random\n   quantities are determinable by an adversary\
    \ searching through an\n   embarrassingly small space of possibilities.\n   This\
    \ informational document suggests techniques for producing random\n   quantities\
    \ that will be resistant to such attack.  It recommends that\n   future systems\
    \ include hardware random number generation or provide\n   access to existing\
    \ hardware that can be used for this purpose.  It\n   suggests methods for use\
    \ if such hardware is not available.  And it\n   gives some estimates of the number\
    \ of random bits required for sample\n   applications.\n"
- title: 2. Requirements
  contents:
  - "2. Requirements\n   Probably the most commonly encountered randomness requirement\
    \ today\n   is the user password. This is usually a simple character string.\n\
    \   Obviously, if a password can be guessed, it does not provide\n   security.\
    \  (For re-usable passwords, it is desirable that users be\n   able to remember\
    \ the password.  This may make it advisable to use\n   pronounceable character\
    \ strings or phrases composed on ordinary\n   words.  But this only affects the\
    \ format of the password information,\n   not the requirement that the password\
    \ be very hard to guess.)\n   Many other requirements come from the cryptographic\
    \ arena.\n   Cryptographic techniques can be used to provide a variety of services\n\
    \   including confidentiality and authentication.  Such services are\n   based\
    \ on quantities, traditionally called \"keys\", that are unknown to\n   and unguessable\
    \ by an adversary.\n   In some cases, such as the use of symmetric encryption\
    \ with the one\n   time pads [CRYPTO*] or the US Data Encryption Standard [DES],\
    \ the\n   parties who wish to communicate confidentially and/or with\n   authentication\
    \ must all know the same secret key.  In other cases,\n   using what are called\
    \ asymmetric or \"public key\" cryptographic\n   techniques, keys come in pairs.\
    \  One key of the pair is private and\n   must be kept secret by one party, the\
    \ other is public and can be\n   published to the world.  It is computationally\
    \ infeasible to\n   determine the private key from the public key [ASYMMETRIC,\
    \ CRYPTO*].\n   The frequency and volume of the requirement for random quantities\n\
    \   differs greatly for different cryptographic systems.  Using pure RSA\n   [CRYPTO*],\
    \ random quantities are required when the key pair is\n   generated, but thereafter\
    \ any number of messages can be signed\n   without any further need for randomness.\
    \  The public key Digital\n   Signature Algorithm that has been proposed by the\
    \ US National\n   Institute of Standards and Technology (NIST) requires good random\n\
    \   numbers for each signature.  And encrypting with a one time pad, in\n   principle\
    \ the strongest possible encryption technique, requires a\n   volume of randomness\
    \ equal to all the messages to be processed.\n   In most of these cases, an adversary\
    \ can try to determine the\n   \"secret\" key by trial and error.  (This is possible\
    \ as long as the\n   key is enough smaller than the message that the correct key\
    \ can be\n   uniquely identified.)  The probability of an adversary succeeding\
    \ at\n   this must be made acceptably low, depending on the particular\n   application.\
    \  The size of the space the adversary must search is\n   related to the amount\
    \ of key \"information\" present in the information\n   theoretic sense [SHANNON].\
    \  This depends on the number of different\n   secret values possible and the\
    \ probability of each value as follows:\n                      -----\n       \
    \                \\\n        Bits-of-info =  \\  - p   * log  ( p  )\n       \
    \                 /     i       2    i\n                       /\n           \
    \           -----\n   where i varies from 1 to the number of possible secret values\
    \ and p\n   sub i is the probability of the value numbered i.  (Since p sub i\
    \ is\n   less than one, the log will be negative so each term in the sum will\n\
    \   be non-negative.)\n   If there are 2^n different values of equal probability,\
    \ then n bits\n   of information are present and an adversary would, on the average,\n\
    \   have to try half of the values, or 2^(n-1) , before guessing the\n   secret\
    \ quantity.  If the probability of different values is unequal,\n   then there\
    \ is less information present and fewer guesses will, on\n   average, be required\
    \ by an adversary.  In particular, any values that\n   the adversary can know\
    \ are impossible, or are of low probability, can\n   be initially ignored by an\
    \ adversary, who will search through the\n   more probable values first.\n   For\
    \ example, consider a cryptographic system that uses 56 bit keys.\n   If these\
    \ 56 bit keys are derived by using a fixed pseudo-random\n   number generator\
    \ that is seeded with an 8 bit seed, then an adversary\n   needs to search through\
    \ only 256 keys (by running the pseudo-random\n   number generator with every\
    \ possible seed), not the 2^56 keys that\n   may at first appear to be the case.\
    \ Only 8 bits of \"information\" are\n   in these 56 bit keys.\n"
- title: 3. Traditional Pseudo-Random Sequences
  contents:
  - "3. Traditional Pseudo-Random Sequences\n   Most traditional sources of random\
    \ numbers use deterministic sources\n   of \"pseudo-random\" numbers.  These typically\
    \ start with a \"seed\"\n   quantity and use numeric or logical operations to\
    \ produce a sequence\n   of values.\n   [KNUTH] has a classic exposition on pseudo-random\
    \ numbers.\n   Applications he mentions are simulation of natural phenomena,\n\
    \   sampling, numerical analysis, testing computer programs, decision\n   making,\
    \ and games.  None of these have the same characteristics as\n   the sort of security\
    \ uses we are talking about.  Only in the last two\n   could there be an adversary\
    \ trying to find the random quantity.\n   However, in these cases, the adversary\
    \ normally has only a single\n   chance to use a guessed value.  In guessing passwords\
    \ or attempting\n   to break an encryption scheme, the adversary normally has\
    \ many,\n   perhaps unlimited, chances at guessing the correct value and should\n\
    \   be assumed to be aided by a computer.\n   For testing the \"randomness\" of\
    \ numbers, Knuth suggests a variety of\n   measures including statistical and\
    \ spectral.  These tests check\n   things like autocorrelation between different\
    \ parts of a \"random\"\n   sequence or distribution of its values.  They could\
    \ be met by a\n   constant stored random sequence, such as the \"random\" sequence\n\
    \   printed in the CRC Standard Mathematical Tables [CRC].\n   A typical pseudo-random\
    \ number generation technique, known as a\n   linear congruence pseudo-random\
    \ number generator, is modular\n   arithmetic where the N+1th value is calculated\
    \ from the Nth value by\n        V    = ( V  * a + b )(Mod c)\n         N+1  \
    \    N\n   The above technique has a strong relationship to linear shift\n   register\
    \ pseudo-random number generators, which are well understood\n   cryptographically\
    \ [SHIFT*].  In such generators bits are introduced\n   at one end of a shift\
    \ register as the Exclusive Or (binary sum\n   without carry) of bits from selected\
    \ fixed taps into the register.\n   For example:\n      +----+     +----+    \
    \ +----+                      +----+\n      | B  | <-- | B  | <-- | B  | <-- \
    \ . . . . . . <-- | B  | <-+\n      |  0 |     |  1 |     |  2 |             \
    \         |  n |   |\n      +----+     +----+     +----+                     \
    \ +----+   |\n        |                     |            |                   \
    \  |\n        |                     |            V                  +-----+\n\
    \        |                     V            +----------------> |     |\n     \
    \   V                     +-----------------------------> | XOR |\n        +--------------------------------------------------->\
    \ |     |\n                                                              +-----+\n\
    \       V    = ( ( V  * 2 ) + B .xor. B ... )(Mod 2^n)\n        N+1         N\
    \         0       2\n   The goodness of traditional pseudo-random number generator\
    \ algorithms\n   is measured by statistical tests on such sequences.  Carefully\
    \ chosen\n   values of the initial V and a, b, and c or the placement of shift\n\
    \   register tap in the above simple processes can produce excellent\n   statistics.\n\
    \   These sequences may be adequate in simulations (Monte Carlo\n   experiments)\
    \ as long as the sequence is orthogonal to the structure\n   of the space being\
    \ explored.  Even there, subtle patterns may cause\n   problems.  However, such\
    \ sequences are clearly bad for use in\n   security applications.  They are fully\
    \ predictable if the initial\n   state is known.  Depending on the form of the\
    \ pseudo-random number\n   generator, the sequence may be determinable from observation\
    \ of a\n   short portion of the sequence [CRYPTO*, STERN].  For example, with\n\
    \   the generators above, one can determine V(n+1) given knowledge of\n   V(n).\
    \  In fact, it has been shown that with these techniques, even if\n   only one\
    \ bit of the pseudo-random values is released, the seed can be\n   determined\
    \ from short sequences.\n   Not only have linear congruent generators been broken,\
    \ but techniques\n   are now known for breaking all polynomial congruent generators\n\
    \   [KRAWCZYK].\n"
- title: 4. Unpredictability
  contents:
  - "4. Unpredictability\n   Randomness in the traditional sense described in section\
    \ 3 is NOT the\n   same as the unpredictability required for security use.\n \
    \  For example, use of a widely available constant sequence, such as\n   that\
    \ from the CRC tables, is very weak against an adversary. Once\n   they learn\
    \ of or guess it, they can easily break all security, future\n   and past, based\
    \ on the sequence [CRC].  Yet the statistical\n   properties of these tables are\
    \ good.\n   The following sections describe the limitations of some randomness\n\
    \   generation techniques and sources.\n"
- title: 4.1 Problems with Clocks and Serial Numbers
  contents:
  - "4.1 Problems with Clocks and Serial Numbers\n   Computer clocks, or similar operating\
    \ system or hardware values,\n   provide significantly fewer real bits of unpredictability\
    \ than might\n   appear from their specifications.\n   Tests have been done on\
    \ clocks on numerous systems and it was found\n   that their behavior can vary\
    \ widely and in unexpected ways.  One\n   version of an operating system running\
    \ on one set of hardware may\n   actually provide, say, microsecond resolution\
    \ in a clock while a\n   different configuration of the \"same\" system may always\
    \ provide the\n   same lower bits and only count in the upper bits at much lower\n\
    \   resolution.  This means that successive reads on the clock may\n   produce\
    \ identical values even if enough time has passed that the\n   value \"should\"\
    \ change based on the nominal clock resolution. There\n   are also cases where\
    \ frequently reading a clock can produce\n   artificial sequential values because\
    \ of extra code that checks for\n   the clock being unchanged between two reads\
    \ and increases it by one!\n   Designing portable application code to generate\
    \ unpredictable numbers\n   based on such system clocks is particularly challenging\
    \ because the\n   system designer does not always know the properties of the system\n\
    \   clocks that the code will execute on.\n   Use of a hardware serial number\
    \ such as an Ethernet address may also\n   provide fewer bits of uniqueness than\
    \ one would guess.  Such\n   quantities are usually heavily structured and subfields\
    \ may have only\n   a limited range of possible values or values easily guessable\
    \ based\n   on approximate date of manufacture or other data.  For example, it\
    \ is\n   likely that most of the Ethernet cards installed on Digital Equipment\n\
    \   Corporation (DEC) hardware within DEC were manufactured by DEC\n   itself,\
    \ which significantly limits the range of built in addresses.\n   Problems such\
    \ as those described above related to clocks and serial\n   numbers make code\
    \ to produce unpredictable quantities difficult if\n   the code is to be ported\
    \ across a variety of computer platforms and\n   systems.\n"
- title: 4.2 Timing and Content of External Events
  contents:
  - "4.2 Timing and Content of External Events\n   It is possible to measure the timing\
    \ and content of mouse movement,\n   key strokes, and similar user events.  This\
    \ is a reasonable source of\n   unguessable data with some qualifications.  On\
    \ some machines, inputs\n   such as key strokes are buffered.  Even though the\
    \ user's inter-\n   keystroke timing may have sufficient variation and unpredictability,\n\
    \   there might not be an easy way to access that variation.  Another\n   problem\
    \ is that no standard method exists to sample timing details.\n   This makes it\
    \ hard to build standard software intended for\n   distribution to a large range\
    \ of machines based on this technique.\n   The amount of mouse movement or the\
    \ keys actually hit are usually\n   easier to access than timings but may yield\
    \ less unpredictability as\n   the user may provide highly repetitive input.\n\
    \   Other external events, such as network packet arrival times, can also\n  \
    \ be used with care.  In particular, the possibility of manipulation of\n   such\
    \ times by an adversary must be considered.\n"
- title: 4.3 The Fallacy of Complex Manipulation
  contents:
  - "4.3 The Fallacy of Complex Manipulation\n   One strategy which may give a misleading\
    \ appearance of\n   unpredictability is to take a very complex algorithm (or an\
    \ excellent\n   traditional pseudo-random number generator with good statistical\n\
    \   properties) and calculate a cryptographic key by starting with the\n   current\
    \ value of a computer system clock as the seed.  An adversary\n   who knew roughly\
    \ when the generator was started would have a\n   relatively small number of seed\
    \ values to test as they would know\n   likely values of the system clock.  Large\
    \ numbers of pseudo-random\n   bits could be generated but the search space an\
    \ adversary would need\n   to check could be quite small.\n   Thus very strong\
    \ and/or complex manipulation of data will not help if\n   the adversary can learn\
    \ what the manipulation is and there is not\n   enough unpredictability in the\
    \ starting seed value.  Even if they can\n   not learn what the manipulation is,\
    \ they may be able to use the\n   limited number of results stemming from a limited\
    \ number of seed\n   values to defeat security.\n   Another serious strategy error\
    \ is to assume that a very complex\n   pseudo-random number generation algorithm\
    \ will produce strong random\n   numbers when there has been no theory behind\
    \ or analysis of the\n   algorithm.  There is a excellent example of this fallacy\
    \ right near\n   the beginning of chapter 3 in [KNUTH] where the author describes\
    \ a\n   complex algorithm.  It was intended that the machine language program\n\
    \   corresponding to the algorithm would be so complicated that a person\n   trying\
    \ to read the code without comments wouldn't know what the\n   program was doing.\
    \  Unfortunately, actual use of this algorithm\n   showed that it almost immediately\
    \ converged to a single repeated\n   value in one case and a small cycle of values\
    \ in another case.\n   Not only does complex manipulation not help you if you\
    \ have a limited\n   range of seeds but blindly chosen complex manipulation can\
    \ destroy\n   the randomness in a good seed!\n"
- title: 4.4 The Fallacy of Selection from a Large Database
  contents:
  - "4.4 The Fallacy of Selection from a Large Database\n   Another strategy that\
    \ can give a misleading appearance of\n   unpredictability is selection of a quantity\
    \ randomly from a database\n   and assume that its strength is related to the\
    \ total number of bits\n   in the database.  For example, typical USENET servers\
    \ as of this date\n   process over 35 megabytes of information per day.  Assume\
    \ a random\n   quantity was selected by fetching 32 bytes of data from a random\n\
    \   starting point in this data.  This does not yield 32*8 = 256 bits\n   worth\
    \ of unguessability.  Even after allowing that much of the data\n   is human language\
    \ and probably has more like 2 or 3 bits of\n   information per byte, it doesn't\
    \ yield 32*2.5 = 80 bits of\n   unguessability.  For an adversary with access\
    \ to the same 35\n   megabytes the unguessability rests only on the starting point\
    \ of the\n   selection.  That is, at best, about 25 bits of unguessability in\
    \ this\n   case.\n   The same argument applies to selecting sequences from the\
    \ data on a\n   CD ROM or Audio CD recording or any other large public database.\
    \  If\n   the adversary has access to the same database, this \"selection from\
    \ a\n   large volume of data\" step buys very little.  However, if a selection\n\
    \   can be made from data to which the adversary has no access, such as\n   system\
    \ buffers on an active multi-user system, it may be of some\n   help.\n"
- title: 5. Hardware for Randomness
  contents:
  - "5. Hardware for Randomness\n   Is there any hope for strong portable randomness\
    \ in the future?\n   There might be.  All that's needed is a physical source of\n\
    \   unpredictable numbers.\n   A thermal noise or radioactive decay source and\
    \ a fast, free-running\n   oscillator would do the trick directly [GIFFORD]. \
    \ This is a trivial\n   amount of hardware, and could easily be included as a\
    \ standard part\n   of a computer system's architecture.  Furthermore, any system\
    \ with a\n   spinning disk or the like has an adequate source of randomness\n\
    \   [DAVIS].  All that's needed is the common perception among computer\n   vendors\
    \ that this small additional hardware and the software to\n   access it is necessary\
    \ and useful.\n"
- title: 5.1 Volume Required
  contents:
  - "5.1 Volume Required\n   How much unpredictability is needed?  Is it possible\
    \ to quantify the\n   requirement in, say, number of random bits per second?\n\
    \   The answer is not very much is needed.  For DES, the key is 56 bits\n   and,\
    \ as we show in an example in Section 8, even the highest security\n   system\
    \ is unlikely to require a keying material of over 200 bits.  If\n   a series\
    \ of keys are needed, it can be generated from a strong random\n   seed using\
    \ a cryptographically strong sequence as explained in\n   Section 6.3.  A few\
    \ hundred random bits generated once a day would be\n   enough using such techniques.\
    \  Even if the random bits are generated\n   as slowly as one per second and it\
    \ is not possible to overlap the\n   generation process, it should be tolerable\
    \ in high security\n   applications to wait 200 seconds occasionally.\n   These\
    \ numbers are trivial to achieve.  It could be done by a person\n   repeatedly\
    \ tossing a coin.  Almost any hardware process is likely to\n   be much faster.\n"
- title: 5.2 Sensitivity to Skew
  contents:
  - "5.2 Sensitivity to Skew\n   Is there any specific requirement on the shape of\
    \ the distribution of\n   the random numbers?  The good news is the distribution\
    \ need not be\n   uniform.  All that is needed is a conservative estimate of how\
    \ non-\n   uniform it is to bound performance.  Two simple techniques to de-skew\n\
    \   the bit stream are given below and stronger techniques are mentioned\n   in\
    \ Section 6.1.2 below.\n"
- title: 5.2.1 Using Stream Parity to De-Skew
  contents:
  - "5.2.1 Using Stream Parity to De-Skew\n   Consider taking a sufficiently long\
    \ string of bits and map the string\n   to \"zero\" or \"one\".  The mapping will\
    \ not yield a perfectly uniform\n   distribution, but it can be as close as desired.\
    \  One mapping that\n   serves the purpose is to take the parity of the string.\
    \  This has the\n   advantages that it is robust across all degrees of skew up\
    \ to the\n   estimated maximum skew and is absolutely trivial to implement in\n\
    \   hardware.\n   The following analysis gives the number of bits that must be\
    \ sampled:\n   Suppose the ratio of ones to zeros is 0.5 + e : 0.5 - e, where\
    \ e is\n   between 0 and 0.5 and is a measure of the \"eccentricity\" of the\n\
    \   distribution.  Consider the distribution of the parity function of N\n   bit\
    \ samples.  The probabilities that the parity will be one or zero\n   will be\
    \ the sum of the odd or even terms in the binomial expansion of\n   (p + q)^N,\
    \ where p = 0.5 + e, the probability of a one, and q = 0.5 -\n   e, the probability\
    \ of a zero.\n   These sums can be computed easily as\n                      \
    \   N            N\n        1/2 * ( ( p + q )  + ( p - q )  )\n   and\n      \
    \                   N            N\n        1/2 * ( ( p + q )  - ( p - q )  ).\n\
    \   (Which one corresponds to the probability the parity will be 1\n   depends\
    \ on whether N is odd or even.)\n   Since p + q = 1 and p - q = 2e, these expressions\
    \ reduce to\n                       N\n        1/2 * [1 + (2e) ]\n   and\n   \
    \                    N\n        1/2 * [1 - (2e) ].\n   Neither of these will ever\
    \ be exactly 0.5 unless e is zero, but we\n   can bring them arbitrarily close\
    \ to 0.5.  If we want the\n   probabilities to be within some delta d of 0.5,\
    \ i.e. then\n                            N\n        ( 0.5 + ( 0.5 * (2e)  ) )\
    \  <  0.5 + d.\n   Solving for N yields N > log(2d)/log(2e).  (Note that 2e is\
    \ less than\n   1, so its log is negative.  Division by a negative number reverses\n\
    \   the sense of an inequality.)\n   The following table gives the length of the\
    \ string which must be\n   sampled for various degrees of skew in order to come\
    \ within 0.001 of\n   a 50/50 distribution.\n                       +---------+--------+-------+\n\
    \                       | Prob(1) |    e   |    N  |\n                       +---------+--------+-------+\n\
    \                       |   0.5   |  0.00  |    1  |\n                       |\
    \   0.6   |  0.10  |    4  |\n                       |   0.7   |  0.20  |    7\
    \  |\n                       |   0.8   |  0.30  |   13  |\n                  \
    \     |   0.9   |  0.40  |   28  |\n                       |   0.95  |  0.45 \
    \ |   59  |\n                       |   0.99  |  0.49  |  308  |\n           \
    \            +---------+--------+-------+\n   The last entry shows that even if\
    \ the distribution is skewed 99% in\n   favor of ones, the parity of a string\
    \ of 308 samples will be within\n   0.001 of a 50/50 distribution.\n"
- title: 5.2.2 Using Transition Mappings to De-Skew
  contents:
  - "5.2.2 Using Transition Mappings to De-Skew\n   Another technique, originally\
    \ due to von Neumann [VON NEUMANN], is to\n   examine a bit stream as a sequence\
    \ of non-overlapping pairs. You\n   could then discard any 00 or 11 pairs found,\
    \ interpret 01 as a 0 and\n   10 as a 1.  Assume the probability of a 1 is 0.5+e\
    \ and the\n   probability of a 0 is 0.5-e where e is the eccentricity of the source\n\
    \   and described in the previous section.  Then the probability of each\n   pair\
    \ is as follows:\n            +------+-----------------------------------------+\n\
    \            | pair |            probability                  |\n            +------+-----------------------------------------+\n\
    \            |  00  | (0.5 - e)^2          =  0.25 - e + e^2  |\n            |\
    \  01  | (0.5 - e)*(0.5 + e)  =  0.25     - e^2  |\n            |  10  | (0.5\
    \ + e)*(0.5 - e)  =  0.25     - e^2  |\n            |  11  | (0.5 + e)^2     \
    \     =  0.25 + e + e^2  |\n            +------+-----------------------------------------+\n\
    \   This technique will completely eliminate any bias but at the expense\n   of\
    \ taking an indeterminate number of input bits for any particular\n   desired\
    \ number of output bits.  The probability of any particular\n   pair being discarded\
    \ is 0.5 + 2e^2 so the expected number of input\n   bits to produce X output bits\
    \ is X/(0.25 - e^2).\n   This technique assumes that the bits are from a stream\
    \ where each bit\n   has the same probability of being a 0 or 1 as any other bit\
    \ in the\n   stream and that bits are not correlated, i.e., that the bits are\n\
    \   identical independent distributions.  If alternate bits were from two\n  \
    \ correlated sources, for example, the above analysis breaks down.\n   The above\
    \ technique also provides another illustration of how a\n   simple statistical\
    \ analysis can mislead if one is not always on the\n   lookout for patterns that\
    \ could be exploited by an adversary.  If the\n   algorithm were mis-read slightly\
    \ so that overlapping successive bits\n   pairs were used instead of non-overlapping\
    \ pairs, the statistical\n   analysis given is the same; however, instead of provided\
    \ an unbiased\n   uncorrelated series of random 1's and 0's, it instead produces\
    \ a\n   totally predictable sequence of exactly alternating 1's and 0's.\n"
- title: 5.2.3 Using FFT to De-Skew
  contents:
  - "5.2.3 Using FFT to De-Skew\n   When real world data consists of strongly biased\
    \ or correlated bits,\n   it may still contain useful amounts of randomness. \
    \ This randomness\n   can be extracted through use of the discrete Fourier transform\
    \ or its\n   optimized variant, the FFT.\n   Using the Fourier transform of the\
    \ data, strong correlations can be\n   discarded.  If adequate data is processed\
    \ and remaining correlations\n   decay, spectral lines approaching statistical\
    \ independence and\n   normally distributed randomness can be produced [BRILLINGER].\n"
- title: 5.2.4 Using Compression to De-Skew
  contents:
  - "5.2.4 Using Compression to De-Skew\n   Reversible compression techniques also\
    \ provide a crude method of de-\n   skewing a skewed bit stream.  This follows\
    \ directly from the\n   definition of reversible compression and the formula in\
    \ Section 2\n   above for the amount of information in a sequence.  Since the\n\
    \   compression is reversible, the same amount of information must be\n   present\
    \ in the shorter output than was present in the longer input.\n   By the Shannon\
    \ information equation, this is only possible if, on\n   average, the probabilities\
    \ of the different shorter sequences are\n   more uniformly distributed than were\
    \ the probabilities of the longer\n   sequences.  Thus the shorter sequences are\
    \ de-skewed relative to the\n   input.\n   However, many compression techniques\
    \ add a somewhat predicatable\n   preface to their output stream and may insert\
    \ such a sequence again\n   periodically in their output or otherwise introduce\
    \ subtle patterns\n   of their own.  They should be considered only a rough technique\n\
    \   compared with those described above or in Section 6.1.2.  At a\n   minimum,\
    \ the beginning of the compressed sequence should be skipped\n   and only later\
    \ bits used for applications requiring random bits.\n"
- title: 5.3 Existing Hardware Can Be Used For Randomness
  contents:
  - "5.3 Existing Hardware Can Be Used For Randomness\n   As described below, many\
    \ computers come with hardware that can, with\n   care, be used to generate truly\
    \ random quantities.\n"
- title: 5.3.1 Using Existing Sound/Video Input
  contents:
  - "5.3.1 Using Existing Sound/Video Input\n   Increasingly computers are being built\
    \ with inputs that digitize some\n   real world analog source, such as sound from\
    \ a microphone or video\n   input from a camera.  Under appropriate circumstances,\
    \ such input can\n   provide reasonably high quality random bits.  The \"input\"\
    \ from a\n   sound digitizer with no source plugged in or a camera with the lens\n\
    \   cap on, if the system has enough gain to detect anything, is\n   essentially\
    \ thermal noise.\n   For example, on a SPARCstation, one can read from the /dev/audio\n\
    \   device with nothing plugged into the microphone jack.  Such data is\n   essentially\
    \ random noise although it should not be trusted without\n   some checking in\
    \ case of hardware failure.  It will, in any case,\n   need to be de-skewed as\
    \ described elsewhere.\n   Combining this with compression to de-skew one can,\
    \ in UNIXese,\n   generate a huge amount of medium quality random data by doing\n\
    \        cat /dev/audio | compress - >random-bits-file\n"
- title: 5.3.2 Using Existing Disk Drives
  contents:
  - "5.3.2 Using Existing Disk Drives\n   Disk drives have small random fluctuations\
    \ in their rotational speed\n   due to chaotic air turbulence [DAVIS].  By adding\
    \ low level disk seek\n   time instrumentation to a system, a series of measurements\
    \ can be\n   obtained that include this randomness. Such data is usually highly\n\
    \   correlated so that significant processing is needed, including FFT\n   (see\
    \ section 5.2.3).  Nevertheless experimentation has shown that,\n   with such\
    \ processing, disk drives easily produce 100 bits a minute or\n   more of excellent\
    \ random data.\n   Partly offsetting this need for processing is the fact that\
    \ disk\n   drive failure will normally be rapidly noticed.  Thus, problems with\n\
    \   this method of random number generation due to hardware failure are\n   very\
    \ unlikely.\n"
- title: 6. Recommended Non-Hardware Strategy
  contents:
  - "6. Recommended Non-Hardware Strategy\n   What is the best overall strategy for\
    \ meeting the requirement for\n   unguessable random numbers in the absence of\
    \ a reliable hardware\n   source?  It is to obtain random input from a large number\
    \ of\n   uncorrelated sources and to mix them with a strong mixing function.\n\
    \   Such a function will preserve the randomness present in any of the\n   sources\
    \ even if other quantities being combined are fixed or easily\n   guessable. \
    \ This may be advisable even with a good hardware source as\n   hardware can also\
    \ fail, though this should be weighed against any\n   increase in the chance of\
    \ overall failure due to added software\n   complexity.\n"
- title: 6.1 Mixing Functions
  contents:
  - "6.1 Mixing Functions\n   A strong mixing function is one which combines two or\
    \ more inputs and\n   produces an output where each output bit is a different\
    \ complex non-\n   linear function of all the input bits.  On average, changing\
    \ any\n   input bit will change about half the output bits.  But because the\n\
    \   relationship is complex and non-linear, no particular output bit is\n   guaranteed\
    \ to change when any particular input bit is changed.\n   Consider the problem\
    \ of converting a stream of bits that is skewed\n   towards 0 or 1 to a shorter\
    \ stream which is more random, as discussed\n   in Section 5.2 above.  This is\
    \ simply another case where a strong\n   mixing function is desired, mixing the\
    \ input bits to produce a\n   smaller number of output bits.  The technique given\
    \ in Section 5.2.1\n   of using the parity of a number of bits is simply the result\
    \ of\n   successively Exclusive Or'ing them which is examined as a trivial\n \
    \  mixing function immediately below.  Use of stronger mixing functions\n   to\
    \ extract more of the randomness in a stream of skewed bits is\n   examined in\
    \ Section 6.1.2.\n"
- title: 6.1.1 A Trivial Mixing Function
  contents:
  - "6.1.1 A Trivial Mixing Function\n   A trivial example for single bit inputs is\
    \ the Exclusive Or function,\n   which is equivalent to addition without carry,\
    \ as show in the table\n   below.  This is a degenerate case in which the one\
    \ output bit always\n   changes for a change in either input bit.  But, despite\
    \ its\n   simplicity, it will still provide a useful illustration.\n         \
    \          +-----------+-----------+----------+\n                   |  input 1\
    \  |  input 2  |  output  |\n                   +-----------+-----------+----------+\n\
    \                   |     0     |     0     |     0    |\n                   |\
    \     0     |     1     |     1    |\n                   |     1     |     0 \
    \    |     1    |\n                   |     1     |     1     |     0    |\n \
    \                  +-----------+-----------+----------+\n   If inputs 1 and 2\
    \ are uncorrelated and combined in this fashion then\n   the output will be an\
    \ even better (less skewed) random bit than the\n   inputs.  If we assume an \"\
    eccentricity\" e as defined in Section 5.2\n   above, then the output eccentricity\
    \ relates to the input eccentricity\n   as follows:\n        e       = 2 * e \
    \       * e\n         output        input 1    input 2\n   Since e is never greater\
    \ than 1/2, the eccentricity is always\n   improved except in the case where at\
    \ least one input is a totally\n   skewed constant.  This is illustrated in the\
    \ following table where\n   the top and left side values are the two input eccentricities\
    \ and the\n   entries are the output eccentricity:\n     +--------+--------+--------+--------+--------+--------+--------+\n\
    \     |    e   |  0.00  |  0.10  |  0.20  |  0.30  |  0.40  |  0.50  |\n     +--------+--------+--------+--------+--------+--------+--------+\n\
    \     |  0.00  |  0.00  |  0.00  |  0.00  |  0.00  |  0.00  |  0.00  |\n     |\
    \  0.10  |  0.00  |  0.02  |  0.04  |  0.06  |  0.08  |  0.10  |\n     |  0.20\
    \  |  0.00  |  0.04  |  0.08  |  0.12  |  0.16  |  0.20  |\n     |  0.30  |  0.00\
    \  |  0.06  |  0.12  |  0.18  |  0.24  |  0.30  |\n     |  0.40  |  0.00  |  0.08\
    \  |  0.16  |  0.24  |  0.32  |  0.40  |\n     |  0.50  |  0.00  |  0.10  |  0.20\
    \  |  0.30  |  0.40  |  0.50  |\n     +--------+--------+--------+--------+--------+--------+--------+\n\
    \   However, keep in mind that the above calculations assume that the\n   inputs\
    \ are not correlated.  If the inputs were, say, the parity of\n   the number of\
    \ minutes from midnight on two clocks accurate to a few\n   seconds, then each\
    \ might appear random if sampled at random intervals\n   much longer than a minute.\
    \  Yet if they were both sampled and\n   combined with xor, the result would be\
    \ zero most of the time.\n"
- title: 6.1.2 Stronger Mixing Functions
  contents:
  - "6.1.2 Stronger Mixing Functions\n   The US Government Data Encryption Standard\
    \ [DES] is an example of a\n   strong mixing function for multiple bit quantities.\
    \  It takes up to\n   120 bits of input (64 bits of \"data\" and 56 bits of \"\
    key\") and\n   produces 64 bits of output each of which is dependent on a complex\n\
    \   non-linear function of all input bits.  Other strong encryption\n   functions\
    \ with this characteristic can also be used by considering\n   them to mix all\
    \ of their key and data input bits.\n   Another good family of mixing functions\
    \ are the \"message digest\" or\n   hashing functions such as The US Government\
    \ Secure Hash Standard\n   [SHS] and the MD2, MD4, MD5 [MD2, MD4, MD5] series.\
    \  These functions\n   all take an arbitrary amount of input and produce an output\
    \ mixing\n   all the input bits. The MD* series produce 128 bits of output and\
    \ SHS\n   produces 160 bits.\n   Although the message digest functions are designed\
    \ for variable\n   amounts of input, DES and other encryption functions can also\
    \ be used\n   to combine any number of inputs.  If 64 bits of output is adequate,\n\
    \   the inputs can be packed into a 64 bit data quantity and successive\n   56\
    \ bit keys, padding with zeros if needed, which are then used to\n   successively\
    \ encrypt using DES in Electronic Codebook Mode [DES\n   MODES].  If more than\
    \ 64 bits of output are needed, use more complex\n   mixing.  For example, if\
    \ inputs are packed into three quantities, A,\n   B, and C, use DES to encrypt\
    \ A with B as a key and then with C as a\n   key to produce the 1st part of the\
    \ output, then encrypt B with C and\n   then A for more output and, if necessary,\
    \ encrypt C with A and then B\n   for yet more output.  Still more output can\
    \ be produced by reversing\n   the order of the keys given above to stretch things.\
    \ The same can be\n   done with the hash functions by hashing various subsets\
    \ of the input\n   data to produce multiple outputs.  But keep in mind that it\
    \ is\n   impossible to get more bits of \"randomness\" out than are put in.\n\
    \   An example of using a strong mixing function would be to reconsider\n   the\
    \ case of a string of 308 bits each of which is biased 99% towards\n   zero. \
    \ The parity technique given in Section 5.2.1 above reduced this\n   to one bit\
    \ with only a 1/1000 deviance from being equally likely a\n   zero or one.  But,\
    \ applying the equation for information given in\n   Section 2, this 308 bit sequence\
    \ has 5 bits of information in it.\n   Thus hashing it with SHS or MD5 and taking\
    \ the bottom 5 bits of the\n   result would yield 5 unbiased random bits as opposed\
    \ to the single\n   bit given by calculating the parity of the string.\n"
- title: 6.1.3 Diffie-Hellman as a Mixing Function
  contents:
  - "6.1.3 Diffie-Hellman as a Mixing Function\n   Diffie-Hellman exponential key\
    \ exchange is a technique that yields a\n   shared secret between two parties\
    \ that can be made computationally\n   infeasible for a third party to determine\
    \ even if they can observe\n   all the messages between the two communicating\
    \ parties.  This shared\n   secret is a mixture of initial quantities generated\
    \ by each of them\n   [D-H].  If these initial quantities are random, then the\
    \ shared\n   secret contains the combined randomness of them both, assuming they\n\
    \   are uncorrelated.\n"
- title: 6.1.4 Using a Mixing Function to Stretch Random Bits
  contents:
  - "6.1.4 Using a Mixing Function to Stretch Random Bits\n   While it is not necessary\
    \ for a mixing function to produce the same\n   or fewer bits than its inputs,\
    \ mixing bits cannot \"stretch\" the\n   amount of random unpredictability present\
    \ in the inputs.  Thus four\n   inputs of 32 bits each where there is 12 bits\
    \ worth of\n   unpredicatability (such as 4,096 equally probable values) in each\n\
    \   input cannot produce more than 48 bits worth of unpredictable output.\n  \
    \ The output can be expanded to hundreds or thousands of bits by, for\n   example,\
    \ mixing with successive integers, but the clever adversary's\n   search space\
    \ is still 2^48 possibilities.  Furthermore, mixing to\n   fewer bits than are\
    \ input will tend to strengthen the randomness of\n   the output the way using\
    \ Exclusive Or to produce one bit from two did\n   above.\n   The last table in\
    \ Section 6.1.1 shows that mixing a random bit with a\n   constant bit with Exclusive\
    \ Or will produce a random bit.  While this\n   is true, it does not provide a\
    \ way to \"stretch\" one random bit into\n   more than one.  If, for example,\
    \ a random bit is mixed with a 0 and\n   then with a 1, this produces a two bit\
    \ sequence but it will always be\n   either 01 or 10.  Since there are only two\
    \ possible values, there is\n   still only the one bit of original randomness.\n"
- title: 6.1.5 Other Factors in Choosing a Mixing Function
  contents:
  - "6.1.5 Other Factors in Choosing a Mixing Function\n   For local use, DES has\
    \ the advantages that it has been widely tested\n   for flaws, is widely documented,\
    \ and is widely implemented with\n   hardware and software implementations available\
    \ all over the world\n   including source code available by anonymous FTP.  The\
    \ SHS and MD*\n   family are younger algorithms which have been less tested but\
    \ there\n   is no particular reason to believe they are flawed.  Both MD5 and\
    \ SHS\n   were derived from the earlier MD4 algorithm.  They all have source\n\
    \   code available by anonymous FTP [SHS, MD2, MD4, MD5].\n   DES and SHS have\
    \ been vouched for the the US National Security Agency\n   (NSA) on the basis\
    \ of criteria that primarily remain secret.  While\n   this is the cause of much\
    \ speculation and doubt, investigation of DES\n   over the years has indicated\
    \ that NSA involvement in modifications to\n   its design, which originated with\
    \ IBM, was primarily to strengthen\n   it.  No concealed or special weakness has\
    \ been found in DES.  It is\n   almost certain that the NSA modification to MD4\
    \ to produce the SHS\n   similarly strengthened the algorithm, possibly against\
    \ threats not\n   yet known in the public cryptographic community.\n   DES, SHS,\
    \ MD4, and MD5 are royalty free for all purposes.  MD2 has\n   been freely licensed\
    \ only for non-profit use in connection with\n   Privacy Enhanced Mail [PEM].\
    \  Between the MD* algorithms, some people\n   believe that, as with \"Goldilocks\
    \ and the Three Bears\", MD2 is strong\n   but too slow, MD4 is fast but too weak,\
    \ and MD5 is just right.\n   Another advantage of the MD* or similar hashing algorithms\
    \ over\n   encryption algorithms is that they are not subject to the same\n  \
    \ regulations imposed by the US Government prohibiting the unlicensed\n   export\
    \ or import of encryption/decryption software and hardware.  The\n   same should\
    \ be true of DES rigged to produce an irreversible hash\n   code but most DES\
    \ packages are oriented to reversible encryption.\n"
- title: 6.2 Non-Hardware Sources of Randomness
  contents:
  - "6.2 Non-Hardware Sources of Randomness\n   The best source of input for mixing\
    \ would be a hardware randomness\n   such as disk drive timing affected by air\
    \ turbulence, audio input\n   with thermal noise, or radioactive decay.  However,\
    \ if that is not\n   available there are other possibilities.  These include system\n\
    \   clocks, system or input/output buffers, user/system/hardware/network\n   serial\
    \ numbers and/or addresses and timing, and user input.\n   Unfortunately, any\
    \ of these sources can produce limited or\n   predicatable values under some circumstances.\n\
    \   Some of the sources listed above would be quite strong on multi-user\n   systems\
    \ where, in essence, each user of the system is a source of\n   randomness.  However,\
    \ on a small single user system, such as a\n   typical IBM PC or Apple Macintosh,\
    \ it might be possible for an\n   adversary to assemble a similar configuration.\
    \  This could give the\n   adversary inputs to the mixing process that were sufficiently\n\
    \   correlated to those used originally as to make exhaustive search\n   practical.\n\
    \   The use of multiple random inputs with a strong mixing function is\n   recommended\
    \ and can overcome weakness in any particular input.  For\n   example, the timing\
    \ and content of requested \"random\" user keystrokes\n   can yield hundreds of\
    \ random bits but conservative assumptions need\n   to be made.  For example,\
    \ assuming a few bits of randomness if the\n   inter-keystroke interval is unique\
    \ in the sequence up to that point\n   and a similar assumption if the key hit\
    \ is unique but assuming that\n   no bits of randomness are present in the initial\
    \ key value or if the\n   timing or key value duplicate previous values.  The\
    \ results of mixing\n   these timings and characters typed could be further combined\
    \ with\n   clock values and other inputs.\n   This strategy may make practical\
    \ portable code to produce good random\n   numbers for security even if some of\
    \ the inputs are very weak on some\n   of the target systems.  However, it may\
    \ still fail against a high\n   grade attack on small single user systems, especially\
    \ if the\n   adversary has ever been able to observe the generation process in\
    \ the\n   past.  A hardware based random source is still preferable.\n"
- title: 6.3 Cryptographically Strong Sequences
  contents:
  - "6.3 Cryptographically Strong Sequences\n   In cases where a series of random\
    \ quantities must be generated, an\n   adversary may learn some values in the\
    \ sequence.  In general, they\n   should not be able to predict other values from\
    \ the ones that they\n   know.\n   The correct technique is to start with a strong\
    \ random seed, take\n   cryptographically strong steps from that seed [CRYPTO2,\
    \ CRYPTO3], and\n   do not reveal the complete state of the generator in the sequence\n\
    \   elements.  If each value in the sequence can be calculated in a fixed\n  \
    \ way from the previous value, then when any value is compromised, all\n   future\
    \ values can be determined.  This would be the case, for\n   example, if each\
    \ value were a constant function of the previously\n   used values, even if the\
    \ function were a very strong, non-invertible\n   message digest function.\n \
    \  It should be noted that if your technique for generating a sequence\n   of\
    \ key values is fast enough, it can trivially be used as the basis\n   for a confidentiality\
    \ system.  If two parties use the same sequence\n   generating technique and start\
    \ with the same seed material, they will\n   generate identical sequences.  These\
    \ could, for example, be xor'ed at\n   one end with data being send, encrypting\
    \ it, and xor'ed with this\n   data as received, decrypting it due to the reversible\
    \ properties of\n   the xor operation.\n"
- title: 6.3.1 Traditional Strong Sequences
  contents:
  - "6.3.1 Traditional Strong Sequences\n   A traditional way to achieve a strong\
    \ sequence has been to have the\n   values be produced by hashing the quantities\
    \ produced by\n   concatenating the seed with successive integers or the like\
    \ and then\n   mask the values obtained so as to limit the amount of generator\
    \ state\n   available to the adversary.\n   It may also be possible to use an\
    \ \"encryption\" algorithm with a\n   random key and seed value to encrypt and\
    \ feedback some or all of the\n   output encrypted value into the value to be\
    \ encrypted for the next\n   iteration.  Appropriate feedback techniques will\
    \ usually be\n   recommended with the encryption algorithm.  An example is shown\
    \ below\n   where shifting and masking are used to combine the cypher output\n\
    \   feedback.  This type of feedback is recommended by the US Government\n   in\
    \ connection with DES [DES MODES].\n      +---------------+\n      |       V \
    \      |\n      |  |     n      |\n      +--+------------+\n            |    \
    \  |           +---------+\n            |      +---------> |         |      +-----+\n\
    \         +--+                  | Encrypt | <--- | Key |\n         |         \
    \  +-------- |         |      +-----+\n         |           |         +---------+\n\
    \         V           V\n      +------------+--+\n      |      V     |  |\n  \
    \    |       n+1     |\n      +---------------+\n   Note that if a shift of one\
    \ is used, this is the same as the shift\n   register technique described in Section\
    \ 3 above but with the all\n   important difference that the feedback is determined\
    \ by a complex\n   non-linear function of all bits rather than a simple linear\
    \ or\n   polynomial combination of output from a few bit position taps.\n   It\
    \ has been shown by Donald W. Davies that this sort of shifted\n   partial output\
    \ feedback significantly weakens an algorithm compared\n   will feeding all of\
    \ the output bits back as input.  In particular,\n   for DES, repeated encrypting\
    \ a full 64 bit quantity will give an\n   expected repeat in about 2^63 iterations.\
    \  Feeding back anything less\n   than 64 (and more than 0) bits will give an\
    \ expected repeat in\n   between 2**31 and 2**32 iterations!\n   To predict values\
    \ of a sequence from others when the sequence was\n   generated by these techniques\
    \ is equivalent to breaking the\n   cryptosystem or inverting the \"non-invertible\"\
    \ hashing involved with\n   only partial information available.  The less information\
    \ revealed\n   each iteration, the harder it will be for an adversary to predict\
    \ the\n   sequence.  Thus it is best to use only one bit from each value.  It\n\
    \   has been shown that in some cases this makes it impossible to break a\n  \
    \ system even when the cryptographic system is invertible and can be\n   broken\
    \ if all of each generated value was revealed.\n"
- title: 6.3.2 The Blum Blum Shub Sequence Generator
  contents:
  - "6.3.2 The Blum Blum Shub Sequence Generator\n   Currently the generator which\
    \ has the strongest public proof of\n   strength is called the Blum Blum Shub\
    \ generator after its inventors\n   [BBS].  It is also very simple and is based\
    \ on quadratic residues.\n   It's only disadvantage is that is is computationally\
    \ intensive\n   compared with the traditional techniques give in 6.3.1 above.\
    \  This\n   is not a serious draw back if it is used for moderately infrequent\n\
    \   purposes, such as generating session keys.\n   Simply choose two large prime\
    \ numbers, say p and q, which both have\n   the property that you get a remainder\
    \ of 3 if you divide them by 4.\n   Let n = p * q.  Then you choose a random number\
    \ x relatively prime to\n   n.  The initial seed for the generator and the method\
    \ for calculating\n   subsequent values are then\n                   2\n     \
    \   s    =  ( x  )(Mod n)\n         0\n                   2\n        s    = (\
    \ s   )(Mod n)\n         i+1      i\n   You must be careful to use only a few\
    \ bits from the bottom of each s.\n   It is always safe to use only the lowest\
    \ order bit.  If you use no\n   more than the\n                  log  ( log  (\
    \ s  ) )\n                     2      2    i\n   low order bits, then predicting\
    \ any additional bits from a sequence\n   generated in this manner is provable\
    \ as hard as factoring n.  As long\n   as the initial x is secret, you can even\
    \ make n public if you want.\n   An intersting characteristic of this generator\
    \ is that you can\n   directly calculate any of the s values.  In particular\n\
    \                     i\n               ( ( 2  )(Mod (( p - 1 ) * ( q - 1 )) )\
    \ )\n      s  = ( s                                          )(Mod n)\n      \
    \ i      0\n   This means that in applications where many keys are generated in\
    \ this\n   fashion, it is not necessary to save them all.  Each key can be\n \
    \  effectively indexed and recovered from that small index and the\n   initial\
    \ s and n.\n"
- title: 7. Key Generation Standards
  contents:
  - "7. Key Generation Standards\n   Several public standards are now in place for\
    \ the generation of keys.\n   Two of these are described below.  Both use DES\
    \ but any equally\n   strong or stronger mixing function could be substituted.\n"
- title: 7.1 US DoD Recommendations for Password Generation
  contents:
  - "7.1 US DoD Recommendations for Password Generation\n   The United States Department\
    \ of Defense has specific recommendations\n   for password generation [DoD]. \
    \ They suggest using the US Data\n   Encryption Standard [DES] in Output Feedback\
    \ Mode [DES MODES] as\n   follows:\n        use an initialization vector determined\
    \ from\n             the system clock,\n             system ID,\n            \
    \ user ID, and\n             date and time;\n        use a key determined from\n\
    \             system interrupt registers,\n             system status registers,\
    \ and\n             system counters; and,\n        as plain text, use an external\
    \ randomly generated 64 bit\n        quantity such as 8 characters typed in by\
    \ a system\n        administrator.\n   The password can then be calculated from\
    \ the 64 bit \"cipher text\"\n   generated in 64-bit Output Feedback Mode.  As\
    \ many bits as are needed\n   can be taken from these 64 bits and expanded into\
    \ a pronounceable\n   word, phrase, or other format if a human being needs to\
    \ remember the\n   password.\n"
- title: 7.2 X9.17 Key Generation
  contents:
  - "7.2 X9.17 Key Generation\n   The American National Standards Institute has specified\
    \ a method for\n   generating a sequence of keys as follows:\n        s  is the\
    \ initial 64 bit seed\n         0\n        g  is the sequence of generated 64\
    \ bit key quantities\n         n\n        k is a random key reserved for generating\
    \ this key sequence\n        t is the time at which a key is generated to as fine\
    \ a resolution\n            as is available (up to 64 bits).\n        DES ( K,\
    \ Q ) is the DES encryption of quantity Q with key K\n        g    = DES ( k,\
    \ DES ( k, t ) .xor. s  )\n         n                                  n\n   \
    \     s    = DES ( k, DES ( k, t ) .xor. g  )\n         n+1                  \
    \              n\n   If g sub n is to be used as a DES key, then every eighth\
    \ bit should\n   be adjusted for parity for that use but the entire 64 bit unmodified\n\
    \   g should be used in calculating the next s.\n"
- title: 8. Examples of Randomness Required
  contents:
  - "8. Examples of Randomness Required\n   Below are two examples showing rough calculations\
    \ of needed\n   randomness for security.  The first is for moderate security\n\
    \   passwords while the second assumes a need for a very high security\n   cryptographic\
    \ key.\n"
- title: 8.1  Password Generation
  contents:
  - "8.1  Password Generation\n   Assume that user passwords change once a year and\
    \ it is desired that\n   the probability that an adversary could guess the password\
    \ for a\n   particular account be less than one in a thousand.  Further assume\n\
    \   that sending a password to the system is the only way to try a\n   password.\
    \  Then the crucial question is how often an adversary can\n   try possibilities.\
    \  Assume that delays have been introduced into a\n   system so that, at most,\
    \ an adversary can make one password try every\n   six seconds.  That's 600 per\
    \ hour or about 15,000 per day or about\n   5,000,000 tries in a year.  Assuming\
    \ any sort of monitoring, it is\n   unlikely someone could actually try continuously\
    \ for a year.  In\n   fact, even if log files are only checked monthly, 500,000\
    \ tries is\n   more plausible before the attack is noticed and steps taken to\
    \ change\n   passwords and make it harder to try more passwords.\n   To have a\
    \ one in a thousand chance of guessing the password in\n   500,000 tries implies\
    \ a universe of at least 500,000,000 passwords or\n   about 2^29.  Thus 29 bits\
    \ of randomness are needed. This can probably\n   be achieved using the US DoD\
    \ recommended inputs for password\n   generation as it has 8 inputs which probably\
    \ average over 5 bits of\n   randomness each (see section 7.1).  Using a list\
    \ of 1000 words, the\n   password could be expressed as a three word phrase (1,000,000,000\n\
    \   possibilities) or, using case insensitive letters and digits, six\n   would\
    \ suffice ((26+10)^6 = 2,176,782,336 possibilities).\n   For a higher security\
    \ password, the number of bits required goes up.\n   To decrease the probability\
    \ by 1,000 requires increasing the universe\n   of passwords by the same factor\
    \ which adds about 10 bits.  Thus to\n   have only a one in a million chance of\
    \ a password being guessed under\n   the above scenario would require 39 bits\
    \ of randomness and a password\n   that was a four word phrase from a 1000 word\
    \ list or eight\n   letters/digits.  To go to a one in 10^9 chance, 49 bits of\
    \ randomness\n   are needed implying a five word phrase or ten letter/digit password.\n\
    \   In a real system, of course, there are also other factors.  For\n   example,\
    \ the larger and harder to remember passwords are, the more\n   likely users are\
    \ to write them down resulting in an additional risk\n   of compromise.\n"
- title: 8.2 A Very High Security Cryptographic Key
  contents:
  - "8.2 A Very High Security Cryptographic Key\n   Assume that a very high security\
    \ key is needed for symmetric\n   encryption / decryption between two parties.\
    \  Assume an adversary can\n   observe communications and knows the algorithm\
    \ being used.  Within\n   the field of random possibilities, the adversary can\
    \ try key values\n   in hopes of finding the one in use.  Assume further that\
    \ brute force\n   trial of keys is the best the adversary can do.\n"
- title: 8.2.1 Effort per Key Trial
  contents:
  - "8.2.1 Effort per Key Trial\n   How much effort will it take to try each key?\
    \  For very high security\n   applications it is best to assume a low value of\
    \ effort.  Even if it\n   would clearly take tens of thousands of computer cycles\
    \ or more to\n   try a single key, there may be some pattern that enables huge\
    \ blocks\n   of key values to be tested with much less effort per key.  Thus it\
    \ is\n   probably best to assume no more than a couple hundred cycles per key.\n\
    \   (There is no clear lower bound on this as computers operate in\n   parallel\
    \ on a number of bits and a poor encryption algorithm could\n   allow many keys\
    \ or even groups of keys to be tested in parallel.\n   However, we need to assume\
    \ some value and can hope that a reasonably\n   strong algorithm has been chosen\
    \ for our hypothetical high security\n   task.)\n   If the adversary can command\
    \ a highly parallel processor or a large\n   network of work stations, 2*10^10\
    \ cycles per second is probably a\n   minimum assumption for availability today.\
    \  Looking forward just a\n   couple years, there should be at least an order\
    \ of magnitude\n   improvement.  Thus assuming 10^9 keys could be checked per\
    \ second or\n   3.6*10^11 per hour or 6*10^13 per week or 2.4*10^14 per month\
    \ is\n   reasonable.  This implies a need for a minimum of 51 bits of\n   randomness\
    \ in keys to be sure they cannot be found in a month.  Even\n   then it is possible\
    \ that, a few years from now, a highly determined\n   and resourceful adversary\
    \ could break the key in 2 weeks (on average\n   they need try only half the keys).\n"
- title: 8.2.2 Meet in the Middle Attacks
  contents:
  - "8.2.2 Meet in the Middle Attacks\n   If chosen or known plain text and the resulting\
    \ encrypted text are\n   available, a \"meet in the middle\" attack is possible\
    \ if the structure\n   of the encryption algorithm allows it.  (In a known plain\
    \ text\n   attack, the adversary knows all or part of the messages being\n   encrypted,\
    \ possibly some standard header or trailer fields.  In a\n   chosen plain text\
    \ attack, the adversary can force some chosen plain\n   text to be encrypted,\
    \ possibly by \"leaking\" an exciting text that\n   would then be sent by the\
    \ adversary over an encrypted channel.)\n   An oversimplified explanation of the\
    \ meet in the middle attack is as\n   follows: the adversary can half-encrypt\
    \ the known or chosen plain\n   text with all possible first half-keys, sort the\
    \ output, then half-\n   decrypt the encoded text with all the second half-keys.\
    \  If a match\n   is found, the full key can be assembled from the halves and\
    \ used to\n   decrypt other parts of the message or other messages.  At its best,\n\
    \   this type of attack can halve the exponent of the work required by\n   the\
    \ adversary while adding a large but roughly constant factor of\n   effort.  To\
    \ be assured of safety against this, a doubling of the\n   amount of randomness\
    \ in the key to a minimum of 102 bits is required.\n   The meet in the middle\
    \ attack assumes that the cryptographic\n   algorithm can be decomposed in this\
    \ way but we can not rule that out\n   without a deep knowledge of the algorithm.\
    \  Even if a basic algorithm\n   is not subject to a meet in the middle attack,\
    \ an attempt to produce\n   a stronger algorithm by applying the basic algorithm\
    \ twice (or two\n   different algorithms sequentially) with different keys may\
    \ gain less\n   added security than would be expected.  Such a composite algorithm\n\
    \   would be subject to a meet in the middle attack.\n   Enormous resources may\
    \ be required to mount a meet in the middle\n   attack but they are probably within\
    \ the range of the national\n   security services of a major nation.  Essentially\
    \ all nations spy on\n   other nations government traffic and several nations\
    \ are believed to\n   spy on commercial traffic for economic advantage.\n"
- title: 8.2.3 Other Considerations
  contents:
  - "8.2.3 Other Considerations\n   Since we have not even considered the possibilities\
    \ of special\n   purpose code breaking hardware or just how much of a safety margin\
    \ we\n   want beyond our assumptions above, probably a good minimum for a very\n\
    \   high security cryptographic key is 128 bits of randomness which\n   implies\
    \ a minimum key length of 128 bits.  If the two parties agree\n   on a key by\
    \ Diffie-Hellman exchange [D-H], then in principle only\n   half of this randomness\
    \ would have to be supplied by each party.\n   However, there is probably some\
    \ correlation between their random\n   inputs so it is probably best to assume\
    \ that each party needs to\n   provide at least 96 bits worth of randomness for\
    \ very high security\n   if Diffie-Hellman is used.\n   This amount of randomness\
    \ is beyond the limit of that in the inputs\n   recommended by the US DoD for\
    \ password generation and could require\n   user typing timing, hardware random\
    \ number generation, or other\n   sources.\n   It should be noted that key length\
    \ calculations such at those above\n   are controversial and depend on various\
    \ assumptions about the\n   cryptographic algorithms in use.  In some cases, a\
    \ professional with\n   a deep knowledge of code breaking techniques and of the\
    \ strength of\n   the algorithm in use could be satisfied with less than half\
    \ of the\n   key size derived above.\n"
- title: 9. Conclusion
  contents:
  - "9. Conclusion\n   Generation of unguessable \"random\" secret quantities for\
    \ security use\n   is an essential but difficult task.\n   We have shown that\
    \ hardware techniques to produce such randomness\n   would be relatively simple.\
    \  In particular, the volume and quality\n   would not need to be high and existing\
    \ computer hardware, such as\n   disk drives, can be used.  Computational techniques\
    \ are available to\n   process low quality random quantities from multiple sources\
    \ or a\n   larger quantity of such low quality input from one source and produce\n\
    \   a smaller quantity of higher quality, less predictable key material.\n   In\
    \ the absence of hardware sources of randomness, a variety of user\n   and software\
    \ sources can frequently be used instead with care;\n   however, most modern systems\
    \ already have hardware, such as disk\n   drives or audio input, that could be\
    \ used to produce high quality\n   randomness.\n   Once a sufficient quantity\
    \ of high quality seed key material (a few\n   hundred bits) is available, strong\
    \ computational techniques are\n   available to produce cryptographically strong\
    \ sequences of\n   unpredicatable quantities from this seed material.\n"
- title: 10. Security Considerations
  contents:
  - "10. Security Considerations\n   The entirety of this document concerns techniques\
    \ and recommendations\n   for generating unguessable \"random\" quantities for\
    \ use as passwords,\n   cryptographic keys, and similar security uses.\n"
- title: References
  contents:
  - "References\n   [ASYMMETRIC] - Secure Communications and Asymmetric Cryptosystems,\n\
    \   edited by Gustavus J. Simmons, AAAS Selected Symposium 69, Westview\n   Press,\
    \ Inc.\n   [BBS] - A Simple Unpredictable Pseudo-Random Number Generator, SIAM\n\
    \   Journal on Computing, v. 15, n. 2, 1986, L. Blum, M. Blum, & M. Shub.\n  \
    \ [BRILLINGER] - Time Series: Data Analysis and Theory, Holden-Day,\n   1981,\
    \ David Brillinger.\n   [CRC] - C.R.C. Standard Mathematical Tables, Chemical\
    \ Rubber\n   Publishing Company.\n   [CRYPTO1] - Cryptography: A Primer, A Wiley-Interscience\
    \ Publication,\n   John Wiley & Sons, 1981, Alan G. Konheim.\n   [CRYPTO2] - Cryptography:\
    \  A New Dimension in Computer Data Security,\n   A Wiley-Interscience Publication,\
    \ John Wiley & Sons, 1982, Carl H.\n   Meyer & Stephen M. Matyas.\n   [CRYPTO3]\
    \ - Applied Cryptography: Protocols, Algorithms, and Source\n   Code in C, John\
    \ Wiley & Sons, 1994, Bruce Schneier.\n   [DAVIS] - Cryptographic Randomness from\
    \ Air Turbulence in Disk\n   Drives, Advances in Cryptology - Crypto '94, Springer-Verlag\
    \ Lecture\n   Notes in Computer Science #839, 1984, Don Davis, Ross Ihaka, and\n\
    \   Philip Fenstermacher.\n   [DES] -  Data Encryption Standard, United States\
    \ of America,\n   Department of Commerce, National Institute of Standards and\n\
    \   Technology, Federal Information Processing Standard (FIPS) 46-1.\n   - Data\
    \ Encryption Algorithm, American National Standards Institute,\n   ANSI X3.92-1981.\n\
    \   (See also FIPS 112, Password Usage, which includes FORTRAN code for\n   performing\
    \ DES.)\n   [DES MODES] - DES Modes of Operation, United States of America,\n\
    \   Department of Commerce, National Institute of Standards and\n   Technology,\
    \ Federal Information Processing Standard (FIPS) 81.\n   - Data Encryption Algorithm\
    \ - Modes of Operation, American National\n   Standards Institute, ANSI X3.106-1983.\n\
    \   [D-H] - New Directions in Cryptography, IEEE Transactions on\n   Information\
    \ Technology, November, 1976, Whitfield Diffie and Martin\n   E. Hellman.\n  \
    \ [DoD] - Password Management Guideline, United States of America,\n   Department\
    \ of Defense, Computer Security Center, CSC-STD-002-85.\n   (See also FIPS 112,\
    \ Password Usage, which incorporates CSC-STD-002-85\n   as one of its appendices.)\n\
    \   [GIFFORD] - Natural Random Number, MIT/LCS/TM-371, September 1988,\n   David\
    \ K. Gifford\n   [KNUTH] - The Art of Computer Programming, Volume 2: Seminumerical\n\
    \   Algorithms, Chapter 3: Random Numbers. Addison Wesley Publishing\n   Company,\
    \ Second Edition 1982, Donald E. Knuth.\n   [KRAWCZYK] - How to Predict Congruential\
    \ Generators, Journal of\n   Algorithms, V. 13, N. 4, December 1992, H. Krawczyk\n\
    \   [MD2] - The MD2 Message-Digest Algorithm, RFC1319, April 1992, B.\n   Kaliski\n\
    \   [MD4] - The MD4 Message-Digest Algorithm, RFC1320, April 1992, R.\n   Rivest\n\
    \   [MD5] - The MD5 Message-Digest Algorithm, RFC1321, April 1992, R.\n   Rivest\n\
    \   [PEM] - RFCs 1421 through 1424:\n   - RFC 1424, Privacy Enhancement for Internet\
    \ Electronic Mail: Part\n   IV: Key Certification and Related Services, 02/10/1993,\
    \ B. Kaliski\n   - RFC 1423, Privacy Enhancement for Internet Electronic Mail:\
    \ Part\n   III: Algorithms, Modes, and Identifiers, 02/10/1993, D. Balenson\n\
    \   - RFC 1422, Privacy Enhancement for Internet Electronic Mail: Part\n   II:\
    \ Certificate-Based Key Management, 02/10/1993, S. Kent\n   - RFC 1421, Privacy\
    \ Enhancement for Internet Electronic Mail: Part I:\n   Message Encryption and\
    \ Authentication Procedures, 02/10/1993, J. Linn\n   [SHANNON] - The Mathematical\
    \ Theory of Communication, University of\n   Illinois Press, 1963, Claude E. Shannon.\
    \  (originally from:  Bell\n   System Technical Journal, July and October 1948)\n\
    \   [SHIFT1] - Shift Register Sequences, Aegean Park Press, Revised\n   Edition\
    \ 1982, Solomon W. Golomb.\n   [SHIFT2] - Cryptanalysis of Shift-Register Generated\
    \ Stream Cypher\n   Systems, Aegean Park Press, 1984, Wayne G. Barker.\n   [SHS]\
    \ - Secure Hash Standard, United States of American, National\n   Institute of\
    \ Science and Technology, Federal Information Processing\n   Standard (FIPS) 180,\
    \ April 1993.\n   [STERN] - Secret Linear Congruential Generators are not\n  \
    \ Cryptograhically Secure, Proceedings of IEEE STOC, 1987, J. Stern.\n   [VON\
    \ NEUMANN] - Various techniques used in connection with random\n   digits, von\
    \ Neumann's Collected Works, Vol. 5, Pergamon Press, 1963,\n   J. von Neumann.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Donald E. Eastlake 3rd\n   Digital Equipment Corporation\n\
    \   550 King Street, LKG2-1/BB3\n   Littleton, MA 01460\n   Phone:   +1 508 486\
    \ 6577(w)  +1 508 287 4877(h)\n   EMail:   dee@lkg.dec.com\n   Stephen D. Crocker\n\
    \   CyberCash Inc.\n   2086 Hunters Crest Way\n   Vienna, VA 22181\n   Phone:\
    \   +1 703-620-1222(w)  +1 703-391-2651 (fax)\n   EMail:   crocker@cybercash.com\n\
    \   Jeffrey I. Schiller\n   Massachusetts Institute of Technology\n   77 Massachusetts\
    \ Avenue\n   Cambridge, MA 02139\n   Phone:   +1 617 253 0161(w)\n   EMail:  \
    \ jis@mit.edu\n"
