- title: __initial_text__
  contents:
  - '     Guidelines for Considering New Performance Metric Development

    '
- title: Abstract
  contents:
  - "Abstract\n   This document describes a framework and a process for developing\n\
    \   Performance Metrics of protocols and applications transported over\n   IETF-specified\
    \ protocols.  These metrics can be used to characterize\n   traffic on live networks\
    \ and services.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This memo documents an Internet Best Current Practice.\n\
    \   This document is a product of the Internet Engineering Task Force\n   (IETF).\
    \  It represents the consensus of the IETF community.  It has\n   received public\
    \ review and has been approved for publication by the\n   Internet Engineering\
    \ Steering Group (IESG).  Further information on\n   BCPs is available in Section\
    \ 2 of RFC 5741.\n   Information about the current status of this document, any\
    \ errata,\n   and how to provide feedback on it may be obtained at\n   http://www.rfc-editor.org/info/rfc6390.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n   This document\
    \ may contain material from IETF Documents or IETF\n   Contributions published\
    \ or made publicly available before November\n   10, 2008.  The person(s) controlling\
    \ the copyright in some of this\n   material may not have granted the IETF Trust\
    \ the right to allow\n   modifications of such material outside the IETF Standards\
    \ Process.\n   Without obtaining an adequate license from the person(s) controlling\n\
    \   the copyright in such materials, this document may not be modified\n   outside\
    \ the IETF Standards Process, and derivative works of it may\n   not be created\
    \ outside the IETF Standards Process, except to format\n   it for publication\
    \ as an RFC or to translate it into languages other\n   than English.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \      1.1. Background and Motivation ..................................4\n  \
    \    1.2. Organization of This Document ..............................5\n   2.\
    \ Terminology .....................................................5\n      2.1.\
    \ Requirements Language ......................................5\n      2.2. Performance\
    \ Metrics Directorate ............................5\n      2.3. Quality of Service\
    \ .........................................5\n      2.4. Quality of Experience\
    \ ......................................6\n      2.5. Performance Metric .........................................6\n\
    \   3. Purpose and Scope ...............................................6\n  \
    \ 4. Relationship between QoS, QoE, and Application-Specific\n      Performance\
    \ Metrics .............................................7\n   5. Performance Metrics\
    \ Development .................................7\n      5.1. Identifying and Categorizing\
    \ the Audience ..................7\n      5.2. Definitions of a Performance Metric\
    \ ........................8\n      5.3. Computed Performance Metrics ...............................9\n\
    \           5.3.1. Composed Performance Metrics ........................9\n  \
    \         5.3.2. Index ..............................................10\n    \
    \  5.4. Performance Metric Specification ..........................10\n      \
    \     5.4.1. Outline ............................................10\n        \
    \   5.4.2. Normative Parts of Performance Metric Definition ...11\n          \
    \ 5.4.3. Informative Parts of Performance Metric\n                  Definition\
    \ .........................................13\n           5.4.4. Performance Metric\
    \ Definition Template .............14\n           5.4.5. Example: Loss Rate .................................15\n\
    \      5.5. Dependencies ..............................................16\n  \
    \         5.5.1. Timing Accuracy ....................................16\n    \
    \       5.5.2. Dependencies of Performance Metric Definitions on\n           \
    \       Related Events or Metrics ..........................16\n           5.5.3.\
    \ Relationship between Performance Metric and\n                  Lower-Layer Performance\
    \ Metrics ....................17\n           5.5.4. Middlebox Presence .................................17\n\
    \      5.6. Organization of Results ...................................17\n  \
    \    5.7. Parameters: The Variables of a Performance Metric .........18\n   6.\
    \ Performance Metric Development Process .........................18\n      6.1.\
    \ New Proposals for Performance Metrics .....................18\n      6.2. Reviewing\
    \ Metrics .........................................19\n      6.3. Performance\
    \ Metrics Directorate Interaction with\n           Other WGs .................................................19\n\
    \      6.4. Standards Track Performance Metrics .......................20\n  \
    \ 7. Security Considerations ........................................20\n   8.\
    \ Acknowledgements ...............................................20\n   9. References\
    \ .....................................................21\n      9.1. Normative\
    \ References ......................................21\n      9.2. Informative\
    \ References ....................................21\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Many networking technologies, applications, or services\
    \ are\n   distributed in nature, and their performance may be impacted by IP\n\
    \   impairments, server capacity, congestion, and other factors.  It is\n   important\
    \ to measure the performance of applications and services to\n   ensure that quality\
    \ objectives are being met and to support problem\n   diagnosis.  Standardized\
    \ metrics help ensure that performance\n   measurement is implemented consistently,\
    \ and they facilitate\n   interpretation and comparison.\n   There are at least\
    \ three phases in the development of performance\n   standards.  They are as follows:\n\
    \   1.  Definition of a Performance Metric and its units of measure\n   2.  Specification\
    \ of a method of measurement\n   3.  Specification of the reporting format\n \
    \  During the development of metrics, it is often useful to define\n   performance\
    \ objectives and expected value ranges.  This additional\n   information is typically\
    \ not part of the formal specification of the\n   metric but does provide useful\
    \ background for implementers and users\n   of the metric.\n   The intended audience\
    \ for this document includes, but is not limited\n   to, IETF participants who\
    \ write Performance Metrics documents in the\n   IETF, reviewers of such documents,\
    \ and members of the Performance\n   Metrics Directorate.\n"
- title: 1.1.  Background and Motivation
  contents:
  - "1.1.  Background and Motivation\n   Previous IETF work related to the reporting\
    \ of application\n   Performance Metrics includes \"Real-time Application Quality-of-\n\
    \   Service Monitoring (RAQMON) Framework\" [RFC4710].  This framework\n   extends\
    \ the remote network monitoring (RMON) family of specifications\n   to allow real-time\
    \ quality-of-service (QoS) monitoring of various\n   applications that run on\
    \ devices such as IP phones, pagers, Instant\n   Messaging clients, mobile phones,\
    \ and various other handheld\n   computing devices.  Furthermore, \"RTP Control\
    \ Protocol Extended\n   Reports (RTCP XR)\" [RFC3611] and \"Session Initiation\
    \ Protocol Event\n   Package for Voice Quality Reporting\" [RFC6035] define protocols\
    \ that\n   support real-time Quality of Experience (QoE) reporting for Voice\n\
    \   over IP (VoIP) and other applications running on devices such as IP\n   phones\
    \ and mobile handsets.\n   The IETF is also actively involved in the development\
    \ of reliable\n   transport protocols, such as TCP [RFC0793] or the Stream Control\n\
    \   Transmission Protocol (SCTP) [RFC4960], which would affect the\n   relationship\
    \ between IP performance and application performance.\n   Thus, there is a gap\
    \ in the currently chartered coverage of IETF\n   Working Groups (WGs): development\
    \ of Performance Metrics for\n   protocols above and below the IP layer that can\
    \ be used to\n   characterize performance on live networks.\n   Similar to \"\
    Guidelines for Considering Operations and Management of\n   New Protocols and\
    \ Protocol Extensions\" [RFC5706], which is the\n   reference document for the\
    \ IETF Operations Directorate, this document\n   should be consulted as part of\
    \ the new Performance Metric review by\n   the members of the Performance Metrics\
    \ Directorate.\n"
- title: 1.2.  Organization of This Document
  contents:
  - "1.2.  Organization of This Document\n   This document is divided into two major\
    \ sections beyond the \"Purpose\n   and Scope\" section.  The first is a definition\
    \ and description of a\n   Performance Metric and its key aspects.  The second\
    \ defines a process\n   to develop these metrics that is applicable to the IETF\
    \ environment.\n"
- title: 2.  Terminology
  contents:
  - '2.  Terminology

    '
- title: 2.1.  Requirements Language
  contents:
  - "2.1.  Requirements Language\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\"\
    , \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"\
    MAY\", and \"OPTIONAL\" in this\n   document are to be interpreted as described\
    \ in RFC 2119 [RFC2119].\n"
- title: 2.2.  Performance Metrics Directorate
  contents:
  - "2.2.  Performance Metrics Directorate\n   The Performance Metrics Directorate\
    \ is a directorate that provides\n   guidance for Performance Metrics development\
    \ in the IETF.\n   The Performance Metrics Directorate should be composed of experts\
    \ in\n   the performance community, potentially selected from the IP\n   Performance\
    \ Metrics (IPPM), Benchmarking Methodology (BMWG), and\n   Performance Metrics\
    \ for Other Layers (PMOL) WGs.\n"
- title: 2.3.  Quality of Service
  contents:
  - "2.3.  Quality of Service\n   Quality of Service (QoS) is defined in a way similar\
    \ to the ITU\n   \"Quality of Service (QoS)\" section of [E.800], i.e., \"Totality\
    \ of\n   characteristics of a telecommunications service that bear on its\n  \
    \ ability to satisfy stated and implied needs of the user of the\n   service\"\
    .\n"
- title: 2.4.  Quality of Experience
  contents:
  - "2.4.  Quality of Experience\n   Quality of Experience (QoE) is defined in a way\
    \ similar to the ITU\n   \"QoS experienced/perceived by customer/user (QoSE)\"\
    \ section of\n   [E.800], i.e., \"a statement expressing the level of quality\
    \ that\n   customers/users believe they have experienced\".\n      NOTE 1 - The\
    \ level of QoS experienced and/or perceived by the\n      customer/user may be\
    \ expressed by an opinion rating.\n      NOTE 2 - QoE has two main components:\
    \ quantitative and\n      qualitative.  The quantitative component can be influenced\
    \ by the\n      complete end-to-end system effects (including user devices and\n\
    \      network infrastructure).\n      NOTE 3 - The qualitative component can\
    \ be influenced by user\n      expectations, ambient conditions, psychological\
    \ factors,\n      application context, etc.\n      NOTE 4 - QoE may also be considered\
    \ as QoS delivered, received,\n      and interpreted by a user with the pertinent\
    \ qualitative factors\n      influencing his/her perception of the service.\n"
- title: 2.5.  Performance Metric
  contents:
  - "2.5.  Performance Metric\n   A Performance Metric is a quantitative measure of\
    \ performance,\n   specific to an IETF-specified protocol or specific to an application\n\
    \   transported over an IETF-specified protocol.  Examples of Performance\n  \
    \ Metrics are the FTP response time for a complete file download, the\n   DNS\
    \ response time to resolve the IP address, a database logging time,\n   etc.\n"
- title: 3.  Purpose and Scope
  contents:
  - "3.  Purpose and Scope\n   The purpose of this document is to define a framework\
    \ and a process\n   for developing Performance Metrics for protocols above and\
    \ below the\n   IP layer (such as IP-based applications that operate over reliable\
    \ or\n   datagram transport protocols).  These metrics can be used to\n   characterize\
    \ traffic on live networks and services.  As such, this\n   document does not\
    \ define any Performance Metrics.\n   The scope of this document covers guidelines\
    \ for the Performance\n   Metrics Directorate members for considering new Performance\
    \ Metrics\n   and suggests how the Performance Metrics Directorate will interact\n\
    \   with the rest of the IETF.  However, this document is not intended to\n  \
    \ supersede existing working methods within WGs that have existing\n   chartered\
    \ work in this area.\n   This process is not intended to govern Performance Metric\
    \ development\n   in existing IETF WGs that are focused on metrics development,\
    \ such as\n   the IPPM and BMWG WGs.  However, this guidelines document may be\n\
    \   useful in these activities and MAY be applied where appropriate.  A\n   typical\
    \ example is the development of Performance Metrics to be\n   exported with the\
    \ IP Flow Information eXport (IPFIX) protocol\n   [RFC5101], with specific IPFIX\
    \ information elements [RFC5102], which\n   would benefit from the framework in\
    \ this document.\n   The framework in this document applies to Performance Metrics\
    \ derived\n   from both active and passive measurements.\n"
- title: 4.  Relationship between QoS, QoE, and Application-Specific Performance
  contents:
  - "4.  Relationship between QoS, QoE, and Application-Specific Performance\n   \
    \ Metrics\n   Network QoS deals with network and network protocol performance,\n\
    \   while QoE deals with the assessment of a user's experience in the\n   context\
    \ of a task or a service.  The topic of application-specific\n   Performance Metrics\
    \ includes the measurement of performance at layers\n   between IP and the user.\
    \  For example, network QoS metrics (packet\n   loss, delay, and delay variation\
    \ [RFC5481]) can be used to estimate\n   application-specific Performance Metrics\
    \ (de-jitter buffer size and\n   RTP-layer packet loss), and then combined with\
    \ other known aspects of\n   a VoIP application (such as codec type) using an\
    \ algorithm compliant\n   with ITU-T P.564 [P.564] to estimate a Mean Opinion\
    \ Score (MOS)\n   [P.800].  However, the QoE for a particular VoIP user depends\
    \ on the\n   specific context, such as a casual conversation, a business\n   conference\
    \ call, or an emergency call.  Finally, QoS and application-\n   specific Performance\
    \ Metrics are quantitative, while QoE is\n   qualitative.  Also, network QoS and\
    \ application-specific Performance\n   Metrics can be directly or indirectly evident\
    \ to the user, while the\n   QoE is directly evident.\n"
- title: 5.  Performance Metrics Development
  contents:
  - "5.  Performance Metrics Development\n   This section provides key definitions\
    \ and qualifications of\n   Performance Metrics.\n"
- title: 5.1.  Identifying and Categorizing the Audience
  contents:
  - "5.1.  Identifying and Categorizing the Audience\n   Many of the aspects of metric\
    \ definition and reporting, even the\n   selection or determination of the essential\
    \ metrics, depend on who\n   will use the results, and for what purpose.  For\
    \ example, the metric\n   description SHOULD include use cases and example reports\
    \ that\n   illustrate service quality monitoring and maintenance or\n   identification\
    \ and quantification of problems.\n   All documents defining Performance Metrics\
    \ SHOULD identify the\n   primary audience and its associated requirements.  The\
    \ audience can\n   influence both the definition of metrics and the methods of\n\
    \   measurement.\n   The key areas of variation between different metric users\
    \ include:\n   o  Suitability of passive measurements of live traffic or active\n\
    \      measurements using dedicated traffic\n   o  Measurement in laboratory environment\
    \ or on a network of deployed\n      devices\n   o  Accuracy of the results\n\
    \   o  Access to measurement points and configuration information\n   o  Measurement\
    \ topology (point-to-point, point-to-multipoint)\n   o  Scale of the measurement\
    \ system\n   o  Measurements conducted on-demand or continuously\n   o  Required\
    \ reporting formats and periods\n   o  Sampling criteria [RFC5474], such as systematic\
    \ or probabilistic\n   o  Period (and duration) of measurement, as the live traffic\
    \ can have\n      patterns\n"
- title: 5.2.  Definitions of a Performance Metric
  contents:
  - "5.2.  Definitions of a Performance Metric\n   A Performance Metric is a measure\
    \ of an observable behavior of a\n   networking technology, an application, or\
    \ a service.  Most of the\n   time, the Performance Metric can be directly measured;\
    \ however,\n   sometimes, the Performance Metric value is computed.  The process\
    \ for\n   determining the value of a metric may assume an implicit or explicit\n\
    \   underlying statistical process; in this case, the Performance Metric\n   is\
    \ an estimate of a parameter of this process, assuming that the\n   statistical\
    \ process closely models the behavior of the system.\n   A Performance Metric\
    \ should serve some defined purposes.  This may\n   include the measurement of\
    \ capacity, quantifying how bad some\n   problems are, measurement of service\
    \ level, problem diagnosis or\n   location, and other such uses.  A Performance\
    \ Metric may also be an\n   input to some other processes, for example, the computation\
    \ of a\n   composite Performance Metric or a model or simulation of a system.\n\
    \   Tests of the \"usefulness\" of a Performance Metric include:\n      (i) the\
    \ degree to which its absence would cause significant loss\n      of information\
    \ on the behavior or performance of the application\n      or system being measured\n\
    \      (ii) the correlation between the Performance Metric, the QoS, and\n   \
    \   the QoE delivered to the user (person or other application)\n      (iii) the\
    \ degree to which the Performance Metric is able to\n      support the identification\
    \ and location of problems affecting\n      service quality\n      (iv) the requirement\
    \ to develop policies (Service Level Agreement,\n      and potentially Service\
    \ Level Contract) based on the Performance\n      Metric\n   For example, consider\
    \ a distributed application operating over a\n   network connection that is subject\
    \ to packet loss.  A Packet Loss\n   Rate (PLR) Performance Metric is defined\
    \ as the mean packet loss\n   ratio over some time period.  If the application\
    \ performs poorly over\n   network connections with a high packet loss ratio and\
    \ always performs\n   well when the packet loss ratio is zero, then the PLR Performance\n\
    \   Metric is useful to some degree.  Some applications are sensitive to\n   short\
    \ periods of high loss (bursty loss) and are relatively\n   insensitive to isolated\
    \ packet loss events; for this type of\n   application, there would be very weak\
    \ correlation between PLR and\n   application performance.  A \"better\" Performance\
    \ Metric would\n   consider both the packet loss ratio and the distribution of\
    \ loss\n   events.  If application performance is degraded when the PLR exceeds\n\
    \   some rate, then a useful Performance Metric may be a measure of the\n   duration\
    \ and frequency of periods during which the PLR exceeds that\n   rate (as, for\
    \ example, in RFC 3611).\n"
- title: 5.3.  Computed Performance Metrics
  contents:
  - '5.3.  Computed Performance Metrics

    '
- title: 5.3.1.  Composed Performance Metrics
  contents:
  - "5.3.1.  Composed Performance Metrics\n   Some Performance Metrics may not be\
    \ measured directly, but can be\n   composed from base metrics that have been\
    \ measured.  A composed\n   Performance Metric is derived from other metrics by\
    \ applying a\n   deterministic process or function (e.g., a composition function).\n\
    \   The process may use metrics that are identical to the metric being\n   composed,\
    \ or metrics that are dissimilar, or some combination of both\n   types.  Usually,\
    \ the base metrics have a limited scope in time or\n   space, and they can be\
    \ combined to estimate the performance of some\n   larger entities.\n   Some examples\
    \ of composed Performance Metrics and composed\n   Performance Metric definitions\
    \ are as follows:\n      Spatial composition is defined as the composition of\
    \ metrics of\n      the same type with differing spatial domains [RFC5835] [RFC6049].\n\
    \      Ideally, for spatially composed metrics to be meaningful, the\n      spatial\
    \ domains should be non-overlapping and contiguous, and the\n      composition\
    \ operation should be mathematically appropriate for the\n      type of metric.\n\
    \      Temporal composition is defined as the composition of sets of\n      metrics\
    \ of the same type with differing time spans [RFC5835].  For\n      temporally\
    \ composed metrics to be meaningful, the time spans\n      should be non-overlapping\
    \ and contiguous, and the composition\n      operation should be mathematically\
    \ appropriate for the type of\n      metric.\n      Temporal aggregation is a\
    \ summarization of metrics into a smaller\n      number of metrics that relate\
    \ to the total time span covered by\n      the original metrics.  An example would\
    \ be to compute the minimum,\n      maximum, and average values of a series of\
    \ time-sampled values of\n      a metric.\n   In the context of flow records in\
    \ IP Flow Information eXport (IPFIX),\n   the IPFIX Mediation Framework [RFC6183],\
    \ based on \"IP Flow\n   Information Export (IPFIX) Mediation: Problem Statement\"\
    \ [RFC5982],\n   also discusses some aspects of the temporal and spatial composition.\n"
- title: 5.3.2.  Index
  contents:
  - "5.3.2.  Index\n   An index is a metric for which the output value range has been\n\
    \   selected for convenience or clarity, and the behavior of which is\n   selected\
    \ to support ease of understanding, for example, the R Factor\n   [G.107].  The\
    \ deterministic function for an index is often developed\n   after the index range\
    \ and behavior have been determined.\n"
- title: 5.4.  Performance Metric Specification
  contents:
  - '5.4.  Performance Metric Specification

    '
- title: 5.4.1.  Outline
  contents:
  - "5.4.1.  Outline\n   A Performance Metric definition MUST have a normative part\
    \ that\n   defines what the metric is and how it is measured or computed, and\
    \ it\n   SHOULD have an informative part that describes the Performance Metric\n\
    \   and its application.\n"
- title: 5.4.2.  Normative Parts of Performance Metric Definition
  contents:
  - "5.4.2.  Normative Parts of Performance Metric Definition\n   The normative part\
    \ of a Performance Metric definition MUST define at\n   least the following:\n\
    \   (i) Metric Name\n      Performance Metric names are RECOMMENDED to be unique\
    \ within the\n      set of metrics being defined for the protocol layer and context.\n\
    \      While strict uniqueness may not be attainable (see the IPPM\n      registry\
    \ [RFC6248] for an example of an IANA metric registry\n      failing to provide\
    \ sufficient specificity), broad review must be\n      sought to avoid naming\
    \ overlap.  Note that the Performance Metrics\n      Directorate can help with\
    \ suggestions for IANA metric registration\n      for unique naming.  The Performance\
    \ Metric name MAY be\n      descriptive.\n   (ii) Metric Description\n      The\
    \ Performance Metric description MUST explain what the metric\n      is, what\
    \ is being measured, and how this relates to the\n      performance of the system\
    \ being measured.\n   (iii) Method of Measurement or Calculation\n      The method\
    \ of measurement or calculation MUST define what is being\n      measured or computed\
    \ and the specific algorithm to be used.  Does\n      the measurement involve\
    \ active or only passive measurements?\n      Terms such as \"average\" should\
    \ be qualified (e.g., running average\n      or average over some interval). \
    \ Exception cases SHOULD also be\n      defined with the appropriate handling\
    \ method.  For example, there\n      are a number of commonly used metrics related\
    \ to packet loss;\n      these often don't define the criteria by which a packet\
    \ is\n      determined to be lost (versus very delayed) or how duplicate\n   \
    \   packets are handled.  For example, if the average PLR during a\n      time\
    \ interval is reported, and a packet's arrival is delayed from\n      one interval\
    \ to the next, then was it \"lost\" during the interval\n      during which it\
    \ should have arrived or should it be counted as\n      received?\n      Some\
    \ methods of calculation might require discarding some data\n      collected (due\
    \ to outliers) so as to make the measurement\n      parameters meaningful.  One\
    \ example is burstable billing that\n      sorts the 5-min samples and discards\
    \ the top 5 percentile.\n      Some parameters linked to the method MAY also be\
    \ reported, in\n      order to fully interpret the Performance Metric, for example,\
    \ the\n      time interval, the load, the minimum packet loss, the potential\n\
    \      measurement errors and their sources, the attainable accuracy of\n    \
    \  the metric (e.g., +/- 0.1), the method of calculation, etc.\n   (iv) Units\
    \ of Measurement\n      The units of measurement MUST be clearly stated.\n   (v)\
    \ Measurement Point(s) with Potential Measurement Domain\n      If the measurement\
    \ is specific to a measurement point, this SHOULD\n      be defined.  The measurement\
    \ domain MAY also be defined.\n      Specifically, if measurement points are spread\
    \ across domains, the\n      measurement domain (intra-, inter-) is another factor\
    \ to consider.\n      The Performance Metric definition should discuss how the\n\
    \      Performance Metric value might vary, depending on which\n      measurement\
    \ point is chosen.  For example, the time between a SIP\n      request [RFC3261]\
    \ and the final response can be significantly\n      different at the User Agent\
    \ Client (UAC) or User Agent Server\n      (UAS).\n      In some cases, the measurement\
    \ requires multiple measurement\n      points: all measurement points SHOULD be\
    \ defined, including the\n      measurement domain(s).\n   (vi) Measurement Timing\n\
    \      The acceptable range of timing intervals or sampling intervals for\n  \
    \    a measurement, and the timing accuracy required for such\n      intervals,\
    \ MUST be specified.  Short sampling intervals or\n      frequent samples provide\
    \ a rich source of information that can\n      help assess application performance\
    \ but may lead to excessive\n      measurement data.  Long measurement or sampling\
    \ intervals reduce\n      the amount of reported and collected data such that\
    \ it may be\n      insufficient to understand application performance or service\n\
    \      quality, insofar as the measured quantity may vary significantly\n    \
    \  with time.\n      In the case of multiple measurement points, the potential\n\
    \      requirement for synchronized clocks must be clearly specified.  In\n  \
    \    the specific example of the IP delay variation application metric,\n    \
    \  the different aspects of synchronized clocks are discussed in\n      [RFC5481].\n"
- title: 5.4.3.  Informative Parts of Performance Metric Definition
  contents:
  - "5.4.3.  Informative Parts of Performance Metric Definition\n   The informative\
    \ part of a Performance Metric specification is\n   intended to support the implementation\
    \ and use of the metric.  This\n   part SHOULD provide the following data:\n \
    \  (i) Implementation\n      The implementation description MAY be in the form\
    \ of text, an\n      algorithm, or example software.  The objective of this part\
    \ of the\n      metric definition is to help implementers achieve consistent\n\
    \      results.\n   (ii) Verification\n      The Performance Metric definition\
    \ SHOULD provide guidance on\n      verification testing.  This may be in the\
    \ form of test vectors, a\n      formal verification test method, or informal\
    \ advice.\n   (iii) Use and Applications\n      The use and applications description\
    \ is intended to help the\n      \"user\" understand how, when, and where the\
    \ metric can be applied,\n      and what significance the value range for the\
    \ metric may have.\n      This MAY include a definition of the \"typical\" and\
    \ \"abnormal\"\n      range of the Performance Metric, if this was not apparent\
    \ from the\n      nature of the metric.  The description MAY include information\n\
    \      about the influence of extreme measurement values, i.e., if the\n     \
    \ Performance Metric is sensitive to outliers.  The Use and\n      Application\
    \ section SHOULD also include the security implications\n      in the description.\n\
    \      For example:\n      (a)  it is fairly intuitive that a lower packet loss\
    \ ratio would\n           equate to better performance.  However, the user may\
    \ not know\n           the significance of some given packet loss ratio.\n   \
    \   (b)  the speech level of a telephone signal is commonly expressed\n      \
    \     in dBm0.  If the user is presented with:\n           Speech level = -7 dBm0\n\
    \           this is not intuitively understandable, unless the user\n        \
    \   is a telephony expert.  If the metric definition explains\n           that\
    \ the typical range is -18 to -28 dBm0, a value higher\n           than -18 means\
    \ the signal may be too high (loud), and\n           less than -28 means that\
    \ the signal may be too low\n           (quiet), it is much easier to interpret\
    \ the metric.\n   (iv) Reporting Model\n      The reporting model definition is\
    \ intended to make any\n      relationship between the metric and the reporting\
    \ model clear.\n      There are often implied relationships between the method\
    \ of\n      reporting metrics and the metric itself; however, these are often\n\
    \      not made apparent to the implementor.  For example, if the metric\n   \
    \   is a short-term running average packet delay variation (e.g., the\n      inter-arrival\
    \ jitter in [RFC3550]) and this value is reported at\n      intervals of 6-10\
    \ seconds, the resulting measurement may have\n      limited accuracy when packet\
    \ delay variation is non-stationary.\n"
- title: 5.4.4.  Performance Metric Definition Template
  contents:
  - "5.4.4.  Performance Metric Definition Template\n   Normative\n      o  Metric\
    \ Name\n      o  Metric Description\n      o  Method of Measurement or Calculation\n\
    \      o  Units of Measurement\n      o  Measurement Point(s) with Potential Measurement\
    \ Domain\n      o  Measurement Timing\n   Informative\n      o  Implementation\n\
    \      o  Verification\n      o  Use and Applications\n      o  Reporting Model\n"
- title: '5.4.5.  Example: Loss Rate'
  contents:
  - "5.4.5.  Example: Loss Rate\n   The example used is the loss rate metric as specified\
    \ in RFC 3611\n   [RFC3611].\n   Metric Name:  LossRate\n   Metric Description:\
    \  The fraction of RTP data packets from the source\n      lost since the beginning\
    \ of reception.\n   Method of Measurement or Calculation:  This value is calculated\
    \ by\n      dividing the total number of packets lost (after the effects of\n\
    \      applying any error protection, such as Forward Error Correction\n     \
    \ (FEC)) by the total number of packets expected, multiplying the\n      result\
    \ of the division by 256, limiting the maximum value to 255\n      (to avoid overflow),\
    \ and taking the integer part.\n   Units of Measurement:  This metric is expressed\
    \ as a fixed-point\n      number with the binary point at the left edge of the\
    \ field.  For\n      example, a metric value of 12 means a loss rate of\n    \
    \  approximately 5%.\n   Measurement Point(s) with Potential Measurement Domain:\
    \  This metric\n      is made at the receiving end of the RTP stream sent during\
    \ a Voice\n      over IP call.\n   Measurement Timing:  This metric can be used\
    \ over a wide range of\n      time intervals.  Using time intervals of longer\
    \ than one hour may\n      prevent the detection of variations in the value of\
    \ this metric\n      due to time-of-day changes in network load.  Timing intervals\n\
    \      should not vary in duration by more than +/- 2%.\n   Implementation:  The\
    \ numbers of duplicated packets and discarded\n      packets do not enter into\
    \ this calculation.  Since receivers\n      cannot be required to maintain unlimited\
    \ buffers, a receiver MAY\n      categorize late-arriving packets as lost.  The\
    \ degree of lateness\n      that triggers a loss SHOULD be significantly greater\
    \ than that\n      which triggers a discard.\n   Verification:  The metric value\
    \ ranges between 0 and 255.\n   Use and Applications:  This metric is useful for\
    \ monitoring VoIP\n      calls, more precisely, to detect the VoIP loss rate in\
    \ the\n      network.  This loss rate, along with the rate of packets discarded\n\
    \      due to jitter, has some effect on the quality of the voice stream.\n  \
    \ Reporting Model:  This metric needs to be associated with a defined\n      time\
    \ interval, which could be defined by fixed intervals or by a\n      sliding window.\
    \  In the context of RFC 3611, the metric is\n      measured continuously from\
    \ the start of the RTP stream, and the\n      value of the metric is sampled and\
    \ reported in RTCP XR VoIP\n      Metrics reports.\n"
- title: 5.5.  Dependencies
  contents:
  - "5.5.  Dependencies\n   This section introduces several Performance Metrics dependencies,\n\
    \   which the Performance Metric designer should keep in mind during\n   Performance\
    \ Metric development.  These dependencies, and any others\n   not listed here,\
    \ SHOULD be documented in the Performance Metric\n   specifications.\n"
- title: 5.5.1.  Timing Accuracy
  contents:
  - "5.5.1.  Timing Accuracy\n   The accuracy of the timing of a measurement may affect\
    \ the accuracy\n   of the Performance Metric.  This may not materially affect\
    \ a sampled-\n   value metric; however, it would affect an interval-based metric.\n\
    \   Some metrics -- for example, the number of events per time interval\n   --\
    \ would be directly affected; for example, a 10% variation in time\n   interval\
    \ would lead directly to a 10% variation in the measured\n   value.  Other metrics,\
    \ such as the average packet loss ratio during\n   some time interval, would be\
    \ affected to a lesser extent.\n   If it is necessary to correlate sampled values\
    \ or intervals, then it\n   is essential that the accuracy of sampling time and\
    \ interval start/\n   stop times is sufficient for the application (for example,\
    \ +/- 2%).\n"
- title: 5.5.2.  Dependencies of Performance Metric Definitions on Related Events
  contents:
  - "5.5.2.  Dependencies of Performance Metric Definitions on Related Events\n  \
    \      or Metrics\n   Performance Metric definitions may explicitly or implicitly\
    \ rely on\n   factors that may not be obvious.  For example, the recognition of\
    \ a\n   packet as being \"lost\" relies on having some method of knowing the\n\
    \   packet was actually lost (e.g., RTP sequence number), and some time\n   threshold\
    \ after which a non-received packet is declared lost.  It is\n   important that\
    \ any such dependencies are recognized and incorporated\n   into the metric definition.\n"
- title: 5.5.3.  Relationship between Performance Metric and Lower-Layer
  contents:
  - "5.5.3.  Relationship between Performance Metric and Lower-Layer\n        Performance\
    \ Metrics\n   Lower-layer Performance Metrics may be used to compute or infer\
    \ the\n   performance of higher-layer applications, potentially using an\n   application\
    \ performance model.  The accuracy of this will depend on\n   many factors, including:\n\
    \      (i) The completeness of the set of metrics (i.e., are there\n      metrics\
    \ for all the input values to the application performance\n      model?)\n   \
    \   (ii) Correlation between input variables (being measured) and\n      application\
    \ performance\n      (iii) Variability in the measured metrics and how this variability\n\
    \      affects application performance\n"
- title: 5.5.4.  Middlebox Presence
  contents:
  - "5.5.4.  Middlebox Presence\n   Presence of a middlebox [RFC3303], e.g., proxy,\
    \ network address\n   translation (NAT), redirect server, session border controller\
    \ (SBC)\n   [RFC5853], and application layer gateway (ALG), may add variability\n\
    \   to or restrict the scope of measurements of a metric.  For example,\n   an\
    \ SBC that does not process RTP loopback packets may block or\n   locally terminate\
    \ this traffic rather than pass it through to its\n   target.\n"
- title: 5.6.  Organization of Results
  contents:
  - "5.6.  Organization of Results\n   The IPPM Framework [RFC2330] organizes the\
    \ results of metrics into\n   three related notions:\n   o  singleton: an elementary\
    \ instance, or \"atomic\" value.\n   o  sample: a set of singletons with some\
    \ common properties and some\n      varying properties.\n   o  statistic: a value\
    \ derived from a sample through deterministic\n      calculation, such as the\
    \ mean.\n   Performance Metrics MAY use this organization for the results, with\n\
    \   or without the term names used by the IPPM WG.  Section 11 of\n   RFC 2330\
    \ [RFC2330] should be consulted for further details.\n"
- title: '5.7.  Parameters: the Variables of a Performance Metric'
  contents:
  - "5.7.  Parameters: the Variables of a Performance Metric\n   Metrics are completely\
    \ defined when all options and input variables\n   have been identified and considered.\
    \  These variables are sometimes\n   left unspecified in a metric definition,\
    \ and their general name\n   indicates that the user must set and report them\
    \ with the results.\n   Such variables are called \"parameters\" in the IPPM metric\
    \ template.\n   The scope of the metric, the time at which it was conducted, the\n\
    \   length interval of the sliding-window measurement, the settings for\n   timers,\
    \ and the thresholds for counters are all examples of\n   parameters.\n   All\
    \ documents defining Performance Metrics SHOULD identify all key\n   parameters\
    \ for each Performance Metric.\n"
- title: 6.  Performance Metric Development Process
  contents:
  - '6.  Performance Metric Development Process

    '
- title: 6.1.  New Proposals for Performance Metrics
  contents:
  - "6.1.  New Proposals for Performance Metrics\n   This process is intended to add\
    \ more considerations to the processes\n   for adopting new work as described\
    \ in RFC 2026 [RFC2026] and RFC 2418\n   [RFC2418].  Note that new Performance\
    \ Metrics work item proposals\n   SHALL be approved using the existing IETF process.\
    \  The following\n   entry criteria will be considered for each proposal.\n  \
    \ Proposals SHOULD be prepared as Internet-Drafts, describing the\n   Performance\
    \ Metric and conforming to the qualifications above as much\n   as possible. \
    \ Proposals SHOULD be deliverables of the corresponding\n   protocol development\
    \ WG charters.  As such, the proposals SHOULD be\n   vetted by that WG prior to\
    \ discussion by the Performance Metrics\n   Directorate.  This aspect of the process\
    \ includes an assessment of\n   the need for the Performance Metric proposed and\
    \ assessment of the\n   support for its development in the IETF.\n   Proposals\
    \ SHOULD include an assessment of interaction and/or overlap\n   with work in\
    \ other Standards Development Organizations (SDOs).\n   Proposals SHOULD identify\
    \ additional expertise that might be\n   consulted.\n   Proposals SHOULD specify\
    \ the intended audience and users of the\n   Performance Metrics.  The development\
    \ process encourages\n   participation by members of the intended audience.\n\
    \   Proposals SHOULD identify any security and IANA requirements.\n   Security\
    \ issues could potentially involve revealing data identifying\n   a user, or the\
    \ potential misuse of active test tools.  IANA\n   considerations may involve\
    \ the need for a Performance Metrics\n   registry.\n"
- title: 6.2.  Reviewing Metrics
  contents:
  - "6.2.  Reviewing Metrics\n   Each Performance Metric SHOULD be assessed according\
    \ to the following\n   list of qualifications:\n   o  Are the performance metrics\
    \ unambiguously defined?\n   o  Are the units of measure specified?\n   o  Does\
    \ the metric clearly define the measurement interval where\n      applicable?\n\
    \   o  Are significant sources of measurement errors identified and\n      discussed?\n\
    \   o  Does the method of measurement ensure that results are repeatable?\n  \
    \ o  Does the metric or method of measurement appear to be\n      implementable\
    \ (or offer evidence of a working implementation)?\n   o  Are there any undocumented\
    \ assumptions concerning the underlying\n      process that would affect an implementation\
    \ or interpretation of\n      the metric?\n   o  Can the metric results be related\
    \ to application performance or\n      user experience, when such a relationship\
    \ is of value?\n   o  Is there an existing relationship to metrics defined elsewhere\n\
    \      within the IETF or within other SDOs?\n   o  Do the security considerations\
    \ adequately address denial-of-\n      service attacks, unwanted interference\
    \ with the metric/\n      measurement, and user data confidentiality (when measuring\
    \ live\n      traffic)?\n"
- title: 6.3.  Performance Metrics Directorate Interaction with Other WGs
  contents:
  - "6.3.  Performance Metrics Directorate Interaction with Other WGs\n   The Performance\
    \ Metrics Directorate SHALL provide guidance to the\n   related protocol development\
    \ WG when considering an Internet-Draft\n   that specifies Performance Metrics\
    \ for a protocol.  A sufficient\n   number of individuals with expertise must\
    \ be willing to consult on\n   the draft.  If the related WG has concluded, comments\
    \ on the proposal\n   should still be sought from key RFC authors and former chairs.\n\
    \   As with expert reviews performed by other directorates, a formal\n   review\
    \ is recommended by the time the document is reviewed by the\n   Area Directors\
    \ or an IETF Last Call is being conducted.\n   Existing mailing lists SHOULD be\
    \ used; however, a dedicated mailing\n   list MAY be initiated if necessary to\
    \ facilitate work on a draft.\n   In some cases, it will be appropriate to have\
    \ the IETF session\n   discussion during the related protocol WG session, to maximize\n\
    \   visibility of the effort to that WG and expand the review.\n"
- title: 6.4.  Standards Track Performance Metrics
  contents:
  - "6.4.  Standards Track Performance Metrics\n   The Performance Metrics Directorate\
    \ will assist with the progression\n   of RFCs along the Standards Track.  See\
    \ [IPPM-STANDARD-ADV-TESTING].\n   This may include the preparation of test plans\
    \ to examine different\n   implementations of the metrics to ensure that the metric\
    \ definitions\n   are clear and unambiguous (depending on the final form of the\
    \ draft\n   mentioned above).\n"
- title: 7.  Security Considerations
  contents:
  - "7.  Security Considerations\n   In general, the existence of a framework for\
    \ Performance Metric\n   development does not constitute a security issue for\
    \ the Internet.\n   Performance Metric definitions, however, may introduce security\n\
    \   issues, and this framework recommends that persons defining\n   Performance\
    \ Metrics should identify any such risk factors.\n   The security considerations\
    \ that apply to any active measurement of\n   live networks are relevant here.\
    \  See [RFC4656].\n   The security considerations that apply to any passive measurement\
    \ of\n   specific packets in live networks are relevant here as well.  See the\n\
    \   security considerations in [RFC5475].\n"
- title: 8.  Acknowledgements
  contents:
  - "8.  Acknowledgements\n   The authors would like to thank Al Morton, Dan Romascanu,\
    \ Daryl\n   Malas, and Loki Jorgenson for their comments and contributions, and\n\
    \   Aamer Akhter, Yaakov Stein, Carsten Schmoll, and Jan Novak for their\n   reviews.\n"
- title: 9.  References
  contents:
  - '9.  References

    '
- title: 9.1.  Normative References
  contents:
  - "9.1.  Normative References\n   [RFC2026]  Bradner, S., \"The Internet Standards\
    \ Process --\n              Revision 3\", BCP 9, RFC 2026, October 1996.\n   [RFC2119]\
    \  Bradner, S., \"Key words for use in RFCs to Indicate\n              Requirement\
    \ Levels\", BCP 14, RFC 2119, March 1997.\n   [RFC2418]  Bradner, S., \"IETF Working\
    \ Group Guidelines and\n              Procedures\", BCP 25, RFC 2418, September\
    \ 1998.\n   [RFC4656]  Shalunov, S., Teitelbaum, B., Karp, A., Boote, J., and\
    \ M.\n              Zekauskas, \"A One-way Active Measurement Protocol\n     \
    \         (OWAMP)\", RFC 4656, September 2006.\n"
- title: 9.2.  Informative References
  contents:
  - "9.2.  Informative References\n   [E.800]    \"ITU-T Recommendation E.800.  E\
    \ SERIES: OVERALL NETWORK\n              OPERATION, TELEPHONE SERVICE, SERVICE\
    \ OPERATION AND HUMAN\n              FACTORS\", September 2008.\n   [G.107]  \
    \  \"ITU-T Recommendation G.107.  The E-model: a computational\n             \
    \ model for use in transmission planning\", April 2009.\n   [IPPM-STANDARD-ADV-TESTING]\n\
    \              Geib, R., Ed., Morton, A., Fardid, R., and A. Steinmitz,\n    \
    \          \"IPPM standard advancement testing\", Work in Progress,\n        \
    \      June 2011.\n   [P.564]    \"ITU-T Recommendation P.564.  Conformance Testing\
    \ for\n              Voice over IP Transmission Quality Assessment Models\",\n\
    \              November 2007.\n   [P.800]    \"ITU-T Recommendation P.800.  Methods\
    \ for subjective\n              determination of transmission quality\", August\
    \ 1996.\n   [RFC0793]  Postel, J., \"Transmission Control Protocol\", STD 7,\n\
    \              RFC 793, September 1981.\n   [RFC2330]  Paxson, V., Almes, G.,\
    \ Mahdavi, J., and M. Mathis,\n              \"Framework for IP Performance Metrics\"\
    , RFC 2330,\n              May 1998.\n   [RFC3261]  Rosenberg, J., Schulzrinne,\
    \ H., Camarillo, G., Johnston,\n              A., Peterson, J., Sparks, R., Handley,\
    \ M., and E.\n              Schooler, \"SIP: Session Initiation Protocol\", RFC\
    \ 3261,\n              June 2002.\n   [RFC3303]  Srisuresh, P., Kuthan, J., Rosenberg,\
    \ J., Molitor, A., and\n              A. Rayhan, \"Middlebox communication architecture\
    \ and\n              framework\", RFC 3303, August 2002.\n   [RFC3550]  Schulzrinne,\
    \ H., Casner, S., Frederick, R., and V.\n              Jacobson, \"RTP: A Transport\
    \ Protocol for Real-Time\n              Applications\", STD 64, RFC 3550, July\
    \ 2003.\n   [RFC3611]  Friedman, T., Ed., Caceres, R., Ed., and A. Clark, Ed.,\n\
    \              \"RTP Control Protocol Extended Reports (RTCP XR)\",\n        \
    \      RFC 3611, November 2003.\n   [RFC4710]  Siddiqui, A., Romascanu, D., and\
    \ E. Golovinsky, \"Real-time\n              Application Quality-of-Service Monitoring\
    \ (RAQMON)\n              Framework\", RFC 4710, October 2006.\n   [RFC4960] \
    \ Stewart, R., Ed., \"Stream Control Transmission Protocol\",\n              RFC\
    \ 4960, September 2007.\n   [RFC5101]  Claise, B., Ed., \"Specification of the\
    \ IP Flow Information\n              Export (IPFIX) Protocol for the Exchange\
    \ of IP Traffic\n              Flow Information\", RFC 5101, January 2008.\n \
    \  [RFC5102]  Quittek, J., Bryant, S., Claise, B., Aitken, P., and J.\n      \
    \        Meyer, \"Information Model for IP Flow Information Export\",\n      \
    \        RFC 5102, January 2008.\n   [RFC5474]  Duffield, N., Ed., Chiou, D.,\
    \ Claise, B., Greenberg, A.,\n              Grossglauser, M., and J. Rexford,\
    \ \"A Framework for Packet\n              Selection and Reporting\", RFC 5474,\
    \ March 2009.\n   [RFC5475]  Zseby, T., Molina, M., Duffield, N., Niccolini, S.,\
    \ and F.\n              Raspall, \"Sampling and Filtering Techniques for IP Packet\n\
    \              Selection\", RFC 5475, March 2009.\n   [RFC5481]  Morton, A. and\
    \ B. Claise, \"Packet Delay Variation\n              Applicability Statement\"\
    , RFC 5481, March 2009.\n   [RFC5706]  Harrington, D., \"Guidelines for Considering\
    \ Operations and\n              Management of New Protocols and Protocol Extensions\"\
    ,\n              RFC 5706, November 2009.\n   [RFC5835]  Morton, A., Ed., and\
    \ S. Van den Berghe, Ed., \"Framework\n              for Metric Composition\"\
    , RFC 5835, April 2010.\n   [RFC5853]  Hautakorpi, J., Ed., Camarillo, G., Penfield,\
    \ R.,\n              Hawrylyshen, A., and M. Bhatia, \"Requirements from Session\n\
    \              Initiation Protocol (SIP) Session Border Control (SBC)\n      \
    \        Deployments\", RFC 5853, April 2010.\n   [RFC5982]  Kobayashi, A., Ed.,\
    \ and B. Claise, Ed., \"IP Flow\n              Information Export (IPFIX) Mediation:\
    \ Problem Statement\",\n              RFC 5982, August 2010.\n   [RFC6035]  Pendleton,\
    \ A., Clark, A., Johnston, A., and H. Sinnreich,\n              \"Session Initiation\
    \ Protocol Event Package for Voice\n              Quality Reporting\", RFC 6035,\
    \ November 2010.\n   [RFC6049]  Morton, A. and E. Stephan, \"Spatial Composition\
    \ of\n              Metrics\", RFC 6049, January 2011.\n   [RFC6183]  Kobayashi,\
    \ A., Claise, B., Muenz, G., and K. Ishibashi,\n              \"IP Flow Information\
    \ Export (IPFIX) Mediation: Framework\",\n              RFC 6183, April 2011.\n\
    \   [RFC6248]  Morton, A., \"RFC 4148 and the IP Performance Metrics\n       \
    \       (IPPM) Registry of Metrics Are Obsolete\", RFC 6248,\n              April\
    \ 2011.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Alan Clark\n   Telchemy Incorporated\n   2905 Premiere\
    \ Parkway, Suite 280\n   Duluth, Georgia  30097\n   USA\n   EMail: alan.d.clark@telchemy.com\n\
    \   Benoit Claise\n   Cisco Systems, Inc.\n   De Kleetlaan 6a b1\n   Diegem  1831\n\
    \   Belgium\n   Phone: +32 2 704 5622\n   EMail: bclaise@cisco.com\n"
