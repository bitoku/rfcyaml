- title: __initial_text__
  contents:
  - '                   Known HTTP Proxy/Caching Problems

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2001).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document catalogs a number of known problems with World Wide\
    \ Web\n   (WWW) (caching) proxies and cache servers.  The goal of the document\n\
    \   is to provide a discussion of the problems and proposed workarounds,\n   and\
    \ ultimately to improve conditions by illustrating problems.  The\n   construction\
    \ of this document is a joint effort of the Web caching\n   community.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.    Introduction . . . . . . . . . . . . . . . . . .\
    \ . . . . . .  2\n   1.1   Problem Template . . . . . . . . . . . . . . . . .\
    \ . . . . .  2\n   2.    Known Problems . . . . . . . . . . . . . . . . . . .\
    \ . . . .  4\n   2.1   Known Specification Problems . . . . . . . . . . . . .\
    \ . . .  5\n   2.1.1 Vary header is underspecified and/or misleading  . . . .\
    \ . .  5\n   2.1.2 Client Chaining Loses Valuable Length Meta-Data  . . . . .\
    \ .  9\n   2.2   Known Architectural Problems . . . . . . . . . . . . . . . .\
    \ 10\n   2.2.1 Interception proxies break client cache directives . . . . . 10\n\
    \   2.2.2 Interception proxies prevent introduction of new HTTP\n            methods\
    \  . . . . . . . . . . . . . . . . . . . . . . . .  11\n   2.2.3 Interception\
    \ proxies break IP address-based authentication . 12\n   2.2.4 Caching proxy peer\
    \ selection in heterogeneous networks . . . 13\n   2.2.5 ICP Performance  . .\
    \ . . . . . . . . . . . . . . . . . . . . 15\n   2.2.6 Caching proxy meshes can\
    \ break HTTP serialization of content 16\n   2.3   Known Implementation Problems\
    \  . . . . . . . . . . . . . . . 17\n   2.3.1 User agent/proxy failover  . . .\
    \ . . . . . . . . . . . . . . 17\n   2.3.2 Some servers send bad Content-Length\
    \ headers for files that\n            contain CR . . . . . . . . . . . . . . .\
    \ . . . . . . . .  18\n   3.    Security Considerations  . . . . . . . . . . .\
    \ . . . . . . . 18\n         References . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . 19\n         Authors' Addresses . . . . . . . . . . . . . . . .\
    \ . . . . . 20\n   A.    Archived Known Problems  . . . . . . . . . . . . . .\
    \ . . . . 21\n   A.1   Architectural  . . . . . . . . . . . . . . . . . . . .\
    \ . . . 21\n   A.1.1 Cannot specify multiple URIs for replicated resources  .\
    \ . . 21\n   A.1.2 Replica distance is unknown  . . . . . . . . . . . . . . .\
    \ . 22\n   A.1.3 Proxy resource location  . . . . . . . . . . . . . . . . . .\
    \ 23\n   A.2   Implementation . . . . . . . . . . . . . . . . . . . . . . . 23\n\
    \   A.2.1 Use of Cache-Control headers . . . . . . . . . . . . . . . . 23\n  \
    \ A.2.2 Lack of HTTP/1.1 compliance for caching proxies  . . . . . . 24\n   A.2.3\
    \ ETag support . . . . . . . . . . . . . . . . . . . . . . . . 25\n   A.2.4 Servers\
    \ and content should be optimized for caching  . . . . 26\n   A.3   Administration\
    \ . . . . . . . . . . . . . . . . . . . . . . . 27\n   A.3.1 Lack of fine-grained,\
    \ standardized hierarchy controls  . . . 27\n   A.3.2 Proxy/Server exhaustive\
    \ log format standard for analysis . . 27\n   A.3.3 Trace log timestamps . . .\
    \ . . . . . . . . . . . . . . . . . 28\n   A.3.4 Exchange format for log summaries\
    \  . . . . . . . . . . . . . 29\n         Full Copyright Statement . . . . . .\
    \ . . . . . . . . . . . . 32\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   This memo discusses problems with proxies - which act as\n\
    \   application-level intermediaries for Web requests - and more\n   specifically\
    \ with caching proxies, which retain copies of previously\n   requested resources\
    \ in the hope of improving overall quality of\n   service by serving the content\
    \ locally.  Commonly used terminology in\n   this memo can be found in the \"\
    Internet Web Replication and Caching\n   Taxonomy\"[2].\n   No individual or organization\
    \ has complete knowledge of the known\n   problems in Web caching, and the editors\
    \ are grateful to the\n   contributors to this document.\n"
- title: 1.1 Problem Template
  contents:
  - "1.1 Problem Template\n   A common problem template is used within the following\
    \ sections.  We\n   gratefully acknowledge RFC2525 [1] which helped define an\
    \ initial\n   format for this known problems list.  The template format is\n \
    \  summarized in the following table and described in more detail below.\n   \
    \   Name:           short, descriptive name of the problem (3-5 words)\n     \
    \ Classification: classifies the problem: performance, security, etc\n      Description:\
    \    describes the problem succinctly\n      Significance:   magnitude of problem,\
    \ environments where it exists\n      Implications:   the impact of the problem\
    \ on systems and networks\n      See Also:       a reference to a related known\
    \ problem\n      Indications:    states how to detect the presence of this problem\n\
    \      Solution(s):    describe the solution(s) to this problem, if any\n    \
    \  Workaround:     practical workaround for the problem\n      References:   \
    \  information about the problem or solution\n      Contact:        contact name\
    \ and email address for this section\n   Name\n      A short, descriptive, name\
    \ (3-5 words) name associated with the\n      problem.\n   Classification\n  \
    \    Problems are grouped into categories of similar problems for ease\n     \
    \ of reading of this memo.  Choose the category that best describes\n      the\
    \ problem.  The suggested categories include three general\n      categories and\
    \ several more specific categories.\n      *  Architecture: the fundamental design\
    \ is incomplete, or\n         incorrect\n      *  Specification: the spec is ambiguous,\
    \ incomplete, or incorrect.\n      *  Implementation: the implementation of the\
    \ spec is incorrect.\n      *  Performance: perceived page response at the client\
    \ is\n         excessive; network bandwidth consumption is excessive; demand\n\
    \         on origin or proxy servers exceed reasonable bounds.\n      *  Administration:\
    \ care and feeding of caches is, or causes, a\n         problem.\n      *  Security:\
    \ privacy, integrity, or authentication concerns.\n   Description\n      A definition\
    \ of the problem, succinct but including necessary\n      background information.\n\
    \   Significance (High, Medium, Low)\n      May include a brief summary of the\
    \ environments for which the\n      problem is significant.\n   Implications\n\
    \      Why the problem is viewed as a problem.  What inappropriate\n      behavior\
    \ results from it? This section should substantiate the\n      magnitude of any\
    \ problem indicated with High significance.\n   See Also\n      Optional.  List\
    \ of other known problems that are related to this\n      one.\n   Indications\n\
    \      How to detect the presence of the problem.  This may include\n      references\
    \ to one or more substantiating documents that\n      demonstrate the problem.\
    \  This should include the network\n      configuration that led to the problem\
    \ such that it can be\n      reproduced.  Problems that are not reproducible will\
    \ not appear in\n      this memo.\n   Solution(s)\n      Solutions that permanently\
    \ fix the problem, if such are known. For\n      example, what version of the\
    \ software does not exhibit the\n      problem?  Indicate if the solution is accepted\
    \ by the community,\n      one of several solutions pending agreement, or open\
    \ possibly with\n      experimental solutions.\n   Workaround\n      Practical\
    \ workaround if no solution is available or usable.  The\n      workaround should\
    \ have sufficient detail for someone experiencing\n      the problem to get around\
    \ it.\n   References\n      References to related information in technical publications\
    \ or on\n      the web.  Where can someone interested in learning more go to find\n\
    \      out more about this problem, its solution, or workarounds?\n   Contact\n\
    \      Contact name and email address of the person who supplied the\n      information\
    \ for this section.  The editors are listed as contacts\n      for anonymous submissions.\n"
- title: 2. Known Problems
  contents:
  - "2. Known Problems\n   The remaining sections of this document present the currently\n\
    \   documented known problems.  The problems are ordered by\n   classification\
    \ and significance.  Issues with protocol specification\n   or architecture are\
    \ first, followed by implementation issues.  Issues\n   of high significance are\
    \ first, followed by lower significance.\n   Some of the problems initially identified\
    \ in the previous versions of\n   this document have been moved to Appendix A\
    \ since they discuss issues\n   where resolution primarily involves education\
    \ rather than protocol\n   work.\n   A full list of the problems is available\
    \ in the table of contents.\n"
- title: 2.1 Known Specification Problems
  contents:
  - '2.1 Known Specification Problems

    '
- title: 2.1.1 Vary header is underspecified and/or misleading
  contents:
  - "2.1.1 Vary header is underspecified and/or misleading\n   Name\n      The \"\
    Vary\" header is underspecified and/or misleading\n   Classification\n      Specification\n\
    \   Description\n      The Vary header in HTTP/1.1 was designed to allow a caching\
    \ proxy\n      to safely cache responses even if the server's choice of variants\n\
    \      is not entirely understood.  As RFC 2616 says:\n         The Vary header\
    \ field can be used to express the parameters the\n         server uses to select\
    \ a representation that is subject to\n         server-driven negotiation.\n \
    \     One might expect that this mechanism is useful in general for\n      extensions\
    \ that change the response message based on some aspects\n      of the request.\
    \  However, that is not true.\n      During the design of the HTTP delta encoding\
    \ specification[9] it\n      was realized that an HTTP/1.1 proxy that does not\
    \ understand delta\n      encoding might cache a delta-encoded response and then\
    \ later\n      deliver it to a non-delta-capable client, unless the extension\n\
    \      included some mechanism to prevent this.  Initially, it was\n      thought\
    \ that Vary would suffice, but the following scenario proves\n      this wrong.\n\
    \      NOTE: It is likely that other scenarios exhibiting the same basic\n   \
    \   problem with \"Vary\" could be devised, without reference to delta\n     \
    \ encoding.  This is simply a concrete scenario used to explain the\n      problem.\n\
    \      A complete description of the IM and A-IM headers may be found in\n   \
    \   the \"Delta encoding in HTTP\" specification.  For the purpose of\n      this\
    \ problem description, the relevant details are:\n      1. The concept of an \"\
    instance manipulation\" is introduced.  In\n         some ways, this is similar\
    \ to a content-coding, but there are\n         differences.  One example of an\
    \ instance manipulation name is\n         \"vcdiff\".\n      2. A client signals\
    \ its willingness to accept one or more\n         instance-manipulations using\
    \ the A-IM header.\n      3. A server indicates which instance-manipulations are\
    \ used to\n         encode the body of a response using the IM header.\n     \
    \ 4. Existing implementations will ignore the A-IM and IM headers,\n         following\
    \ the usual HTTP rules for handling unknown headers.\n      5. Responses encoded\
    \ with an instance-manipulation are sent using\n         the (proposed) 226 status\
    \ code, \"IM Used\".\n      6. In response to a conditional request that carries\
    \ an IM header,\n         if the request-URI has been modified then a server may\
    \ transmit\n         a compact encoding of the modifications using a delta-encoding\n\
    \         instead of a status-200 response.  The encoded response cannot\n   \
    \      be understood by an implementation that does not support delta\n      \
    \   encodings.\n      This summary omits many details.\n      Suppose client A\
    \ sends this request via proxy P:\n         GET http://example.com/foo.html HTTP/1.1\n\
    \         Host: example.com\n         If-None-Match: \"abc\"\n         A-IM: vcdiff\n\
    \      and the origin server returns, via P, this response:\n         HTTP/1.1\
    \ 226 IM Used\n         Etag: \"def\"\n         Date: Wed, 19 Apr 2000 18:46:13\
    \ GMT\n         IM: vcdiff\n         Cache-Control: max-age-60\n         Vary:\
    \ A-IM, If-None-Match\n      the body of which is a delta-encoded response (it\
    \ encodes the\n      difference between the Etag \"abc\" instance of foo.html,\
    \ and the\n      \"def\" instance).  Assume that P stores this response in its\
    \ cache,\n      and that P does not understand the vcdiff encoding.\n      Later,\
    \ client B, also ignorant of delta-encoding, sends this\n      request via P:\n\
    \         GET http://example.com/foo.html HTTP/1.1\n         Host: example.com\n\
    \      What can P do now?  According to the specification for the Vary\n     \
    \ header in RFC2616,\n         The Vary field value indicates the set of request-header\
    \ fields\n         that fully determines, while the response is fresh, whether\
    \ a\n         cache is permitted to use the response to reply to a subsequent\n\
    \         request without revalidation.\n      Implicitly, however, the cache\
    \ would be allowed to use the stored\n      response in response to client B WITH\
    \ \"revalidation\".  This is the\n      potential bug.\n      An obvious implementation\
    \ of the proxy would send this request to\n      test whether its cache entry\
    \ is fresh (i.e., to revalidate the\n      entry):\n         GET /foo.html HTTP/1.1\n\
    \         Host: example.com\n         If-None-Match: \"def\"\n      That is, the\
    \ proxy simply forwards the new request, after doing\n      the usual transformation\
    \ on the URL and tacking on the \"obvious\"\n      If-None-Match header.\n   \
    \   If the origin server's Etag for the current instance is still\n      \"def\"\
    , it would naturally respond:\n         HTTP/1.1 304 Not Modified\n         Etag:\
    \ \"def\"\n         Date: Wed, 19 Apr 2000 18:46:14 GMT\n      thus telling the\
    \ proxy P that it can use its stored response.  But\n      this cache response\
    \ actually involves a delta-encoding that would\n      not be sensible to client\
    \ B, signaled by a header field that would\n      be ignored by B, and so the\
    \ client displays garbage.\n      The problem here is that the original request\
    \ (from client A)\n      generated a response that is not sensible to client B,\
    \ not merely\n      one that is not \"the appropriate representation\" (as the\
    \ result of\n      server-driven negotiation).\n      One might argue that the\
    \ proxy P shouldn't be storing status-226\n      responses in the first place.\
    \  True in theory, perhaps, but\n      unfortunately RFC2616, section 13.4, says:\n\
    \         A response received with any [status code other than 200, 203,\n   \
    \      206, 300, 301 or 410] MUST NOT be returned in a reply to a\n         subsequent\
    \ request unless there are cache-control directives or\n         another header(s)\
    \ that explicitly allow it.  For example, these\n         include the following:\
    \ an Expires header (section 14.21); a\n         \"max-age\", \"s-maxage\", \"\
    must-revalidate\", \"proxy-revalidate\",\n         \"public\" or \"private\" cache-control\
    \ directive (section 14.9).\n      In other words, the specification allows caching\
    \ of responses with\n      yet-to-be-defined status codes if the response carries\
    \ a plausible\n      Cache-Control directive.  So unless we ban servers implementing\n\
    \      this kind of extension from using these Cache-Control directives\n    \
    \  at all, the Vary header just won't work.\n   Significance\n      Medium\n \
    \  Implications\n      Certain plausible extensions to the HTTP/1.1 protocol might\
    \ not\n      interoperate correctly with older HTTP/1.1 caches, if the\n     \
    \ extensions depend on an interpretation of Vary that is not the\n      same as\
    \ is used by the cache implementer.\n      This would have the effect either of\
    \ causing hard-to-debug cache\n      transparency failures, or of discouraging\
    \ the deployment of such\n      extensions, or of encouraging the implementers\
    \ of such extensions\n      to disable caching entirely.\n   Indications\n   \
    \   The problem is visible when hand-simulating plausible message\n      exchanges,\
    \ especially when using the proposed delta encoding\n      extension.  It probably\
    \ has not been visible in practice yet.\n   Solution(s)\n      1. Section 13.4\
    \ of the HTTP/1.1 specification should probably be\n         changed to prohibit\
    \ caching of responses with status codes that\n         the cache doesn't understand,\
    \ whether or not they include\n         Expires headers and the like.  (It might\
    \ require some care to\n         define what \"understands\" means, leaving room\
    \ for future\n         extensions with new status codes.)  The behavior in this\
    \ case\n         needs to be defined as equivalent to \"Cache-Control:  no-store\"\
    \n         rather than \"no-cache\", since the latter allows revalidation.\n \
    \        Possibly the specification of Vary should require that it be\n      \
    \   treated as \"Cache-Control:  no-store\" whenever the status code\n       \
    \  is unknown - that should solve the problem in the scenario\n         given\
    \ here.\n      2. Designers of HTTP/1.1 extensions should consider using\n   \
    \      mechanisms other than Vary to prevent false caching.\n         It is not\
    \ clear whether the Vary mechanism is widely\n         implemented in caches;\
    \ if not, this favors solution #1.\n   Workaround\n      A cache could treat the\
    \ presence of a Vary header in a response as\n      an implicit \"Cache-control:\
    \ no-store\", except for \"known\" status\n      codes, even though this is not\
    \ required by RFC 2616.  This would\n      avoid any transparency failures.  \"\
    Known status codes\" for basic\n      HTTP/1.1 caches probably include: 200, 203,\
    \ 206, 300, 301, 410\n      (although this list should be re-evaluated in light\
    \ of the problem\n      discussed here).\n   References\n      See [9] for the\
    \ specification of the delta encoding extension, as\n      well as for an example\
    \ of the use of a Cache-Control extension\n      instead of \"Vary.\"\n   Contact\n\
    \      Jeff Mogul <mogul@pa.dec.com>\n"
- title: 2.1.2 Client Chaining Loses Valuable Length Meta-Data
  contents:
  - "2.1.2 Client Chaining Loses Valuable Length Meta-Data\n   Name\n      Client\
    \ Chaining Loses Valuable Length Meta-Data\n   Classification\n      Performance\n\
    \   Description\n      HTTP/1.1[3] implementations are prohibited from sending\
    \ Content-\n      Length headers with any message whose body has been Transfer-\n\
    \      Encoded.  Because 1.0 clients cannot accept chunked Transfer-\n      Encodings,\
    \ receiving 1.1 implementations must forward the body to\n      1.0 clients must\
    \ do so without the benefit of information that was\n      discarded earlier in\
    \ the chain.\n   Significance\n      Low\n   Implications\n      Lacking either\
    \ a chunked transfer encoding or Content-Length\n      indication creates negative\
    \ performance implications for how the\n      proxy must forward the message body.\n\
    \      In the case of response bodies, the server may either forward the\n   \
    \   response while closing the connection to indicate the end of the\n      response\
    \ or must utilize store and forward semantics to buffer the\n      entire response\
    \ in order to calculate a Content-Length.  The\n      former option defeats the\
    \ performance benefits of persistent\n      connections in HTTP/1.1 (and their\
    \ Keep-Alive cousin in HTTP/1.0)\n      as well as creating some ambiguously lengthed\
    \ responses.  The\n      latter store and forward option may not even be feasible\
    \ given the\n      size of the resource and it will always introduce increased\n\
    \      latency.\n      Request bodies must undertake the store and forward process\
    \ as 1.0\n      request bodies must be delimited by Content-Length headers.  As\n\
    \      with response bodies this may place unacceptable resource\n      constraints\
    \ on the proxy and the request may not be able to be\n      satisfied.\n   Indications\n\
    \      The lack of HTTP/1.0 style persistent connections between 1.0\n      clients\
    \ and 1.1 proxies, only when accessing 1.1 servers, is a\n      strong indication\
    \ of this problem.\n   Solution(s)\n      An HTTP specification clarification\
    \ that would allow origin known\n      identity document Content-Lengths to be\
    \ carried end to end would\n      alleviate this issue.\n   Workaround\n     \
    \ None.\n   Contact\n      Patrick McManus <mcmanus@AppliedTheory.com>\n"
- title: 2.2 Known Architectural Problems
  contents:
  - '2.2 Known Architectural Problems

    '
- title: 2.2.1 Interception proxies break client cache directives
  contents:
  - "2.2.1 Interception proxies break client cache directives\n   Name\n      Interception\
    \ proxies break client cache directives\n   Classification\n      Architecture\n\
    \   Description\n      HTTP[3] is designed for the user agent to be aware if it\
    \ is\n      connected to an origin server or to a proxy.  User agents\n      believing\
    \ they are transacting with an origin server but which are\n      really in a\
    \ connection with an interception proxy may fail to send\n      critical cache-control\
    \ information they would have otherwise\n      included in their request.\n  \
    \ Significance\n      High\n   Implications\n      Clients may receive data that\
    \ is not synchronized with the origin\n      even when they request an end to\
    \ end refresh, because of the lack\n      of inclusion of either a \"Cache-control:\
    \ no-cache\" or \"must-\n      revalidate\" header.  These headers have no impact\
    \ on origin server\n      behavior so may not be included by the browser if it\
    \ believes it\n      is connected to that resource.  Other related data implications\n\
    \      are possible as well.  For instance, data security may be\n      compromised\
    \ by the lack of inclusion of \"private\" or \"no-store\"\n      clauses of the\
    \ Cache-control header under similar conditions.\n   Indications\n      Easily\
    \ detected by placing fresh (un-expired) content on a caching\n      proxy while\
    \ changing the authoritative copy, then requesting an\n      end-to-end reload\
    \ of the data through a proxy in both interception\n      and explicit modes.\n\
    \   Solution(s)\n      Eliminate the need for interception proxies and IP spoofing,\
    \ which\n      will return correct context awareness to the client.\n   Workaround\n\
    \      Include relevant Cache-Control directives in every request at the\n   \
    \   cost of increased bandwidth and CPU requirements.\n   Contact\n      Patrick\
    \ McManus <mcmanus@AppliedTheory.com>\n"
- title: 2.2.2 Interception proxies prevent introduction of new HTTP methods
  contents:
  - "2.2.2 Interception proxies prevent introduction of new HTTP methods\n   Name\n\
    \      Interception proxies prevent introduction of new HTTP methods\n   Classification\n\
    \      Architecture\n   Description\n      A proxy that receives a request with\
    \ a method unknown to it is\n      required to generate an HTTP 501 Error as a\
    \ response.  HTTP\n      methods are designed to be extensible so there may be\
    \ applications\n      deployed with initial support just for the user agent and\
    \ origin\n      server.  An interception proxy that hijacks requests which include\n\
    \      new methods destined for servers that have implemented those\n      methods\
    \ creates a de-facto firewall where none may be intended.\n   Significance\n \
    \     Medium within interception proxy environments.\n   Implications\n      Renders\
    \ new compliant applications useless unless modifications\n      are made to proxy\
    \ software.  Because new methods are not required\n      to be globally standardized\
    \ it is impossible to keep up to date in\n      the general case.\n   Solution(s)\n\
    \      Eliminate the need for interception proxies.  A client receiving a\n  \
    \    501 in a traditional HTTP environment may either choose to repeat\n     \
    \ the request to the origin server directly, or perhaps be\n      configured to\
    \ use a different proxy.\n   Workaround\n      Level 5 switches (sometimes called\
    \ Level 7 or application layer\n      switches) can be used to keep HTTP traffic\
    \ with unknown methods\n      out of the proxy.  However, these devices have heavy\
    \ buffering\n      responsibilities, still require TCP sequence number spoofing,\
    \ and\n      do not interact well with persistent connections.\n      The HTTP/1.1\
    \ specification allows a proxy to switch over to tunnel\n      mode when it receives\
    \ a request with a method or HTTP version it\n      does not understand how to\
    \ handle.\n   Contact\n      Patrick McManus <mcmanus@AppliedTheory.com>\n   \
    \   Henrik Nordstrom <hno@hem.passagen.se> (HTTP/1.1 clarification)\n"
- title: 2.2.3 Interception proxies break IP address-based authentication
  contents:
  - "2.2.3 Interception proxies break IP address-based authentication\n   Name\n \
    \     Interception proxies break IP address-based authentication\n   Classification\n\
    \      Architecture\n   Description\n      Some web servers are not open for public\
    \ access, but restrict\n      themselves to accept only requests from certain\
    \ IP address ranges\n      for security reasons.  Interception proxies alter the\
    \ source\n      (client) IP addresses to that of the proxy itself, without the\n\
    \      knowledge of the client/user.  This breaks such authentication\n      mechanisms\
    \ and prohibits otherwise allowed clients access to the\n      servers.\n   Significance\n\
    \      Medium\n   Implications\n      Creates end user confusion and frustration.\n\
    \   Indications\n      Users  may start to see refused connections to servers\
    \ after\n      interception proxies are deployed.\n   Solution(s)\n      Use user-based\
    \ authentication instead of (IP) address-based\n      authentication.\n   Workaround\n\
    \      Using IP filters at the intercepting device (L4 switch) and bypass\n  \
    \    all requests to such servers concerned.\n   Contact\n      Keith K. Chau\
    \ <keithc@unitechnetworks.com>\n"
- title: 2.2.4 Caching proxy peer selection in heterogeneous networks
  contents:
  - "2.2.4 Caching proxy peer selection in heterogeneous networks\n   Name\n     \
    \ Caching proxy peer selection in heterogeneous networks\n   Classification\n\
    \      Architecture\n   Description\n      ICP[4] based caching proxy peer selection\
    \ in networks with large\n      variance in latency and bandwidth between peers\
    \ can lead to non-\n      optimal peer selection.  For example take Proxy C with\
    \ two\n      siblings, Sib1 and Sib2, and the following network topology\n   \
    \   (summarized).\n      *  Cache C's link to Sib1, 2 Mbit/sec with 300 msec latency\n\
    \      *  Cache C's link to Sib2, 64 Kbit/sec with 10 msec latency.\n      ICP[4]\
    \ does not work well in this context.  If a user submits a\n      request to Proxy\
    \ C for page P that results in a miss, C will send\n      an ICP request to Sib1\
    \ and Sib2.  Assume both siblings have the\n      requested object P.  The ICP_HIT\
    \ reply will always come from Sib2\n      before Sib1.  However, it is clear that\
    \ the retrieval of large\n      objects will be faster from Sib1, rather than\
    \ Sib2.\n      The problem is more complex because Sib1 and Sib2 can't have a\n\
    \      100% hit ratio.  With a hit rate of 10%, it is more efficient to\n    \
    \  use Sib1 with resources larger than 48K.  The best choice depends\n      on\
    \ at least the hit rate and link characteristics; maybe other\n      parameters\
    \ as well.\n   Significance\n      Medium\n   Implications\n      By using the\
    \ first peer to respond, peer selection algorithms are\n      not optimizing retrieval\
    \ latency to end users.  Furthermore they\n      are causing more work for the\
    \ high-latency peer since it must\n      respond to such requests but will never\
    \ be chosen to serve content\n      if the lower latency peer has a copy.\n  \
    \ Indications\n      Inherent in design of ICP v1, ICP v2, and any cache mesh\
    \ protocol\n      that selects peers based upon first response.\n      This problem\
    \ is not exhibited by cache digest or other protocols\n      which (attempt to)\
    \ maintain knowledge of peer contents and only\n      hit peers that are believed\
    \ to have a copy of the requested page.\n   Solution(s)\n      This problem is\
    \ architectural with the peer selection protocols.\n   Workaround\n      Cache\
    \ mesh design when using such a protocol should be done in\n      such a way that\
    \ there is not a high latency variance among peers.\n      In the example presented\
    \ in the above description the high latency\n      high bandwidth peer could be\
    \ used as a parent, but should not be\n      used as a sibling.\n   Contact\n\
    \      Ivan Lovric <ivan.lovric@cnet.francetelecom.fr>\n      John Dilley <jad@akamai.com>\n"
- title: 2.2.5 ICP Performance
  contents:
  - "2.2.5 ICP Performance\n   Name\n      ICP performance\n   Classification\n  \
    \    Architecture(ICP), Performance\n   Description\n      ICP[4] exhibits O(n^2)\
    \ scaling properties, where n is the number\n      of participating peer proxies.\
    \  This can lead ICP traffic to\n      dominate HTTP traffic within a network.\n\
    \   Significance\n      Medium\n   Implications\n      If a proxy has many ICP\
    \ peers the bandwidth demand of ICP can be\n      excessive.  System managers\
    \ must carefully regulate ICP peering.\n      ICP also leads proxies to become\
    \ homogeneous in what they serve;\n      if your proxy does not have a document\
    \ it is unlikely your peers\n      will have it either.  Therefore, ICP traffic\
    \ requests are largely\n      unable to locate a local copy of an object (see\
    \ [6]).\n   Indications\n      Inherent in design of ICP v1, ICP v2.\n   Solution(s)\n\
    \      This problem is architectural - protocol redesign or replacement\n    \
    \  is required to solve it if ICP is to continue to be used.\n   Workaround\n\
    \      Implementation workarounds exist, for example to turn off use of\n    \
    \  ICP, to carefully regulate peering, or to use another mechanism if\n      available,\
    \ such as cache digests.  A cache digest protocol shares\n      a summary of cache\
    \ contents using a Bloom Filter technique.  This\n      allows a cache to estimate\
    \ whether a peer has a document.  Filters\n      are updated regularly but are\
    \ not always up-to-date so cannot help\n      when a spike in popularity occurs.\
    \  They also increase traffic but\n      not as much as ICP.\n      Proxy clustering\
    \ protocols organize proxies into a mesh provide\n      another alternative solution.\
    \  There is ongoing research on this\n      topic.\n   Contact\n      John Dilley\
    \ <jad@akamai.com>\n"
- title: 2.2.6 Caching proxy meshes can break HTTP serialization of content
  contents:
  - "2.2.6 Caching proxy meshes can break HTTP serialization of content\n   Name\n\
    \      Caching proxy meshes can break HTTP serialization of content\n   Classification\n\
    \      Architecture (HTTP protocol)\n   Description\n      A caching proxy mesh\
    \ where a request may travel different paths,\n      depending on the state of\
    \ the mesh and associated caches, can\n      break HTTP content serialization,\
    \ possibly causing the end user to\n      receive older content than seen on an\
    \ earlier request, where the\n      request traversed another path in the mesh.\n\
    \   Significance\n      Medium\n   Implications\n      Can cause end user confusion.\
    \  May in some situations (sibling\n      cache hit, object has changed state\
    \ from cacheable to uncacheable)\n      be close to impossible to get the caches\
    \ properly updated with the\n      new content.\n   Indications\n      Older content\
    \ is unexpectedly returned from a caching proxy mesh\n      after some time.\n\
    \   Solutions(s)\n      Work with caching proxy vendors and researchers to find\
    \ a suitable\n      protocol for maintaining proxy relations and object state\
    \ in a\n      mesh.\n   Workaround\n      When designing a hierarchy/mesh, make\
    \ sure that for each end-\n      user/URL combination there is only one single\
    \ path in the mesh\n      during normal operation.\n   Contact\n      Henrik Nordstrom\
    \ <hno@hem.passagen.se>\n"
- title: 2.3 Known Implementation Problems
  contents:
  - '2.3 Known Implementation Problems

    '
- title: 2.3.1 User agent/proxy failover
  contents:
  - "2.3.1 User agent/proxy failover\n   Name\n      User agent/proxy failover\n \
    \  Classification\n      Implementation\n   Description\n      Failover between\
    \ proxies at the user agent (using a proxy.pac[8]\n      file) is erratic and\
    \ no standard behavior is defined.\n      Additionally, behavior is hard-coded\
    \ into the browser, so that\n      proxy administrators cannot use failover at\
    \ the user agent\n      effectively.\n   Significance\n      Medium\n   Implications\n\
    \      Architects are forced to implement failover at the proxy itself,\n    \
    \  when it may be more appropriate and economical to do it within the\n      user\
    \ agent.\n   Indications\n      If a browser detects that its primary proxy is\
    \ down, it will wait\n      n minutes before trying the next one it is configured\
    \ to use.  It\n      will then wait y minutes before asking the user if they'd\
    \ like to\n      try the original proxy again.  This is very confusing for end\n\
    \      users.\n   Solution(s)\n      Work with browser vendors to establish standard\
    \ extensions to\n      JavaScript proxy.pac libraries that will allow configuration\
    \ of\n      these timeouts.\n   Workaround\n      User education; redundancy at\
    \ the proxy level.\n   Contact\n      Mark Nottingham <mnot@mnot.net>\n"
- title: 2.3.2 Some servers send bad Content-Length headers for files that
  contents:
  - "2.3.2 Some servers send bad Content-Length headers for files that\n      contain\
    \ CR\n   Name\n      Some servers send bad Content-Length headers for files that\n\
    \      contain CR\n   Classification\n      Implementation\n   Description\n \
    \     Certain web servers send a Content-length value that is larger\n      than\
    \ number of bytes in the HTTP message body.  This happens when\n      the server\
    \ strips off CR characters from text files with lines\n      terminated with CRLF\
    \ as the file is written to the client.  The\n      server probably uses the stat()\
    \ system call to get the file size\n      for the Content-Length header.  Servers\
    \ that exhibit this behavior\n      include the GN Web server (version 2.14 at\
    \ least).\n   Significance\n      Low.  Surveys indicate only a small number of\
    \ sites run faulty\n      servers.\n   Implications\n      In this case, an HTTP\
    \ client (e.g., user agent or proxy) may\n      believe it received a partial\
    \ response.  HTTP/1.1 [3] advises that\n      caches MAY store partial responses.\n\
    \   Indications\n      Count the number of bytes in the message body and compare\
    \ to the\n      Content-length value.  If they differ the server exhibits this\n\
    \      problem.\n   Solutions\n      Upgrade or replace the buggy server.\n  \
    \ Workaround\n      Some browsers and proxies use one TCP connection per object\
    \ and\n      ignore the Content-Length.  The document end of file is identified\n\
    \      by the close of the TCP socket.\n   Contact\n      Duane Wessels <wessels@measurement-factory.com>\n"
- title: 3. Security Considerations
  contents:
  - "3. Security Considerations\n   This memo does not raise security considerations\
    \ in itself.  See the\n   individual submissions for details of security concerns\
    \ and issues.\n"
- title: References
  contents:
  - "References\n   [1]  Paxson, V., Allman, M., Dawson, S., Fenner, W., Griner, J.,\n\
    \        Heavens, I., Lahey, K., Semke, J. and B. Volz, \"Known TCP\n        Implementation\
    \ Problems\", RFC 2525, March 1999.\n   [2]  Cooper, I., Melve, I. and G. Tomlinson,\
    \ \"Internet Web\n        Replication and Caching Taxonomy\", RFC 3040, January\
    \ 2001.\n   [3]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L.,\n\
    \        Leach, P. and T. Berners-Lee, \"Hypertext Transfer Protocol --\n    \
    \    HTTP/1.1\", RFC 2616, June 1999.\n   [4]  Wessels, D. and K. Claffy, \"Internet\
    \ Cache Protocol (ICP),\n        Version 2\", RFC 2186, September 1997.\n   [5]\
    \  Davison, B., \"Web Traffic Logs: An Imperfect Resource for\n        Evaluation\"\
    , in Proceedings of the Ninth Annual Conference of\n        the Internet Society\
    \ (INET'99), July 1999.\n   [6]  Melve, I., \"Relation Analysis, Cache Meshes\"\
    , in Proceedings of\n        the 3rd International WWW Caching Workshop, June\
    \ 1998,\n        <http://wwwcache.ja.net/events/workshop/29/magicnumber.html>.\n\
    \   [7]  Krishnamurthy, B. and M. Arlett, \"PRO-COW: Protocol Compliance\n   \
    \     on the Web\", AT&T Labs Technical Report #990803-05-TM, August\n       \
    \ 1999, <http://www.research.att.com/~bala/papers/procow-1.ps.gz>.\n   [8]  Netscape,\
    \ Inc., \"Navigator Proxy Auto-Config File Format\", March\n        1996,\n  \
    \      http://home.netscape.com/eng/mozilla/2.0/relnotes/demo/proxy-\n       \
    \ live.html\n   [9]  Mogul, J., Krishnamurthy, B., Douglis, F., Feldmann, A.,\
    \ Goland,\n        Y., van Hoff, A. and D. Hellerstein, \"HTTP Delta in HTTP\"\
    , Work\n        in Progress.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Ian Cooper\n   Equinix, Inc.\n   2450 Bayshore Parkway\n\
    \   Mountain View, CA  94043\n   USA\n   Phone: +1 650 316 6065\n   EMail: icooper@equinix.com\n\
    \   John Dilley\n   Akamai Technologies, Inc.\n   1400 Fashion Island Blvd\n \
    \  Suite 703\n   San Mateo, CA  94404\n   USA\n   Phone: +1 650 627 5244\n   EMail:\
    \ jad@akamai.com\n"
- title: Appendix A.  Archived Known Problems
  contents:
  - "Appendix A.  Archived Known Problems\n   The following sub-sections are an archive\
    \ of problems identified in\n   the initial production of this memo.  These are\
    \ typically problems\n   requiring further work/research, or user education. \
    \ They are\n   included here for reference purposes only.\n"
- title: A.1 Architectural
  contents:
  - 'A.1 Architectural

    '
- title: A.1.1 Cannot specify multiple URIs for replicated resources
  contents:
  - "A.1.1 Cannot specify multiple URIs for replicated resources\n   Name\n      Cannot\
    \ specify multiple URIs for replicated resources\n   Classification\n      Architecture\n\
    \   Description\n      There is no way to specify that multiple URIs may be used\
    \ for a\n      single resource, one for each replica of the resource.  Similarly,\n\
    \      there is no way to say that some set of proxies (each identified\n    \
    \  by a URI) may be used to resolve a URI.\n   Significance\n      Medium\n  \
    \ Implications\n      Forces users to understand the replication model and mechanism.\n\
    \      Makes it difficult to create a replication framework without\n      protocol\
    \ support for replication and naming.\n   Indications\n      Inherent in HTTP/1.0,\
    \ HTTP/1.1.\n   Solution(s)\n      Architectural - protocol design is necessary.\n\
    \   Workaround\n      Replication mechanisms force users to locate a replica or\
    \ mirror\n      site for replicated content.\n   Contact\n      Daniel LaLiberte\
    \ <liberte@w3.org>\n"
- title: A.1.2 Replica distance is unknown
  contents:
  - "A.1.2 Replica distance is unknown\n   Name\n      Replica distance is unknown\n\
    \   Classification\n      Architecture\n   Description\n      There is no recommended\
    \ way to find out which of several servers\n      or proxies is closer either\
    \ to the requesting client or to another\n      machine, either geographically\
    \ or in the network topology.\n   Significance\n      Medium\n   Implications\n\
    \      Clients must guess which replica is closer to them when requesting\n  \
    \    a copy of a document that may be served from multiple locations.\n      Users\
    \ must know the set of servers that can serve a particular\n      object.  This\
    \ in general is hard to determine and maintain.  Users\n      must understand\
    \ network topology in order to choose the closest\n      copy.  Note that the\
    \ closest copy is not always the one that will\n      result in quickest service.\
    \  A nearby but heavily loaded server\n      may be slower than a more distant\
    \ but lightly loaded server.\n   Indications\n      Inherent in HTTP/1.0, HTTP/1.1.\n\
    \   Solution(s)\n      Architectural - protocol work is necessary.  This is a\
    \ specific\n      instance of a general problem in widely distributed systems.\
    \  A\n      general solution is unlikely, however a specific solution in the\n\
    \      web context is possible.\n   Workaround\n      Servers can (many do) provide\
    \ location hints in a replica\n      selection web page.  Users choose one based\
    \ upon their location.\n      Users can learn which replica server gives them\
    \ best performance.\n      Note that the closest replica geographically is not\
    \ necessarily\n      the closest in terms of network topology.  Expecting users\
    \ to\n      understand network topology is unreasonable.\n   Contact\n      Daniel\
    \ LaLiberte <liberte@w3.org>\n"
- title: A.1.3 Proxy resource location
  contents:
  - "A.1.3 Proxy resource location\n   Name\n      Proxy resource location\n   Classification\n\
    \      Architecture\n   Description\n      There is no way for a client or server\
    \ (including another proxy)\n      to inform a proxy of an alternate address (perhaps\
    \ including the\n      proxy to use to reach that address) to use to fetch a resource.\n\
    \      If the client does not trust where the redirected resource came\n     \
    \ from, it may need to validate it or validate where it came from.\n   Significance\n\
    \      Medium\n   Implications\n      Proxies have no systematic way to locate\
    \ resources within other\n      proxies or origin servers.  This makes it more\
    \ difficult to share\n      information among proxies.  Information sharing would\
    \ improve\n      global efficiency.\n   Indications\n      Inherent in HTTP/1.0,\
    \ HTTP/1.1.\n   Solution(s)\n      Architectural - protocol design is necessary.\n\
    \   Workaround\n      Certain proxies share location hints in the form of summary\n\
    \      digests of their contents (e.g., Squid).  Certain proxy protocols\n   \
    \   enable a proxy query another for its contents (e.g., ICP).  (See\n      however\
    \ \"ICP  Performance\" issue (Section 2.2.5).)\n   Contact\n      Daniel LaLiberte\
    \ <liberte@w3.org>\n"
- title: A.2 Implementation
  contents:
  - 'A.2 Implementation

    '
- title: A.2.1 Use of Cache-Control headers
  contents:
  - "A.2.1 Use of Cache-Control headers\n   Name\n      Use of Cache-Control headers\n\
    \   Classification\n      Implementation\n   Description\n      Many (if not most)\
    \ implementations incorrectly interpret Cache-\n      Control response headers.\n\
    \   Significance\n      High\n   Implications\n      Cache-Control headers will\
    \ be spurned by end users if there are\n      conflicting or non-standard implementations.\n\
    \   Indications\n      -\n   Solution(s)\n      Work with vendors and others to\
    \ assure proper application\n   Workaround\n      None.\n   Contact\n      Mark\
    \ Nottingham <mnot@mnot.net>\n"
- title: A.2.2 Lack of HTTP/1.1 compliance for caching proxies
  contents:
  - "A.2.2 Lack of HTTP/1.1 compliance for caching proxies\n   Name\n      Lack of\
    \ HTTP/1.1 compliance for caching proxies\n   Classification\n      Implementation\n\
    \   Description\n      Although performance benchmarking of caches is starting\
    \ to be\n      explored, protocol compliance is just as important.\n   Significance\n\
    \      High\n   Implications\n      Caching proxy vendors implement their interpretation\
    \ of the\n      specification; because the specification is very large, sometimes\n\
    \      vague and ambiguous, this can lead to inconsistent behavior\n      between\
    \ caching proxies.\n      Caching proxies need to comply to the specification\
    \ (or the\n      specification needs to change).\n   Indications\n      There\
    \ is no currently known compliance test being used.\n      There is work underway\
    \ to quantify how closely servers comply with\n      the current specification.\
    \  A joint technical report between AT&T\n      and HP Labs [7] describes the\
    \ compliance testing.  This report\n      examines how well each of a set of top\
    \ traffic-producing sites\n      support certain HTTP/1.1 features.\n      The\
    \ Measurement Factory (formerly IRCache) is working to develop\n      protocol\
    \ compliance testing software.  Running such a conformance\n      test suite against\
    \ caching proxy products would measure compliance\n      and ultimately would\
    \ help assure they comply to the specification.\n   Solution(s)\n      Testing\
    \ should commence and be reported in an open industry forum.\n      Proxy implementations\
    \ should conform to the specification.\n   Workaround\n      There is no workaround\
    \ for non-compliance.\n   Contact\n      Mark Nottingham <mnot@mnot.net>\n   \
    \   Duane Wessels <wessels@measurement-factory.com>\n"
- title: A.2.3 ETag support
  contents:
  - "A.2.3 ETag support\n   Name\n      ETag support\n   Classification\n      Implementation\n\
    \   Description\n      Available caching proxies appear not to support ETag (strong)\n\
    \      validation.\n   Significance\n      Medium\n   Implications\n      Last-Modified/If-Modified-Since\
    \ validation is inappropriate for\n      many requirements, both because of its\
    \ weakness and its use of\n      dates.  Lack of a usable, strong coherency protocol\
    \ leads\n      developers and end users not to trust caches.\n   Indications\n\
    \      -\n   Solution(s)\n      Work with vendors to implement ETags; work for\
    \ better validation\n      protocols.\n   Workaround\n      Use Last-Modified/If-Modified-Since\
    \ validation.\n   Contact\n      Mark Nottingham <mnot@mnot.net>\n"
- title: A.2.4 Servers and content should be optimized for caching
  contents:
  - "A.2.4 Servers and content should be optimized for caching\n   Name\n      Servers\
    \ and content should be optimized for caching\n   Classification\n      Implementation\
    \ (Performance)\n   Description\n      Many web servers and much web content could\
    \ be implemented to be\n      more conducive to caching, reducing bandwidth demand\
    \ and page load\n      delay.\n   Significance\n      Medium\n   Implications\n\
    \      By making poor use of caches, origin servers encourage longer load\n  \
    \    times, greater load on caching proxies, and increased network\n      demand.\n\
    \   Indications\n      The problem is most apparent for pages that have low or\
    \ zero\n      expires time, yet do not change.\n   Solution(s)\n      -\n   Workaround\n\
    \      Servers could start using unique object identifiers for write-only\n  \
    \    content: if an object changes it gets a new name, otherwise it is\n     \
    \ considered to be immutable and therefore have an infinite expire\n      age.\
    \  Certain hosting providers do this already.\n   Contact\n      Peter Danzig\n"
- title: A.3 Administration
  contents:
  - 'A.3 Administration

    '
- title: A.3.1 Lack of fine-grained, standardized hierarchy controls
  contents:
  - "A.3.1 Lack of fine-grained, standardized hierarchy controls\n   Name\n      Lack\
    \ of fine-grained, standardized hierarchy controls\n   Classification\n      Administration\n\
    \   Description\n      There is no standard for instructing a proxy as to how\
    \ it should\n      resolve the parent to fetch a given object from.  Implementations\n\
    \      therefore vary greatly, and it can be difficult to make them\n      interoperate\
    \ correctly in a complex environment.\n   Significance\n      Medium\n   Implications\n\
    \      Complications in deployment of caches in a complex network\n      (especially\
    \ corporate networks)\n   Indications\n      Inability of some proxies to be configured\
    \ to direct traffic based\n      on domain name, reverse lookup IP address, raw\
    \ IP address, in\n      normal operation and in failover mode.  Inability in some\
    \ proxies\n      to set a preferred parent / backup parent configuration.\n  \
    \ Solution(s)\n      -\n   Workaround\n      Work with vendors to establish an\
    \ acceptable configuration within\n      the limits of their product; standardize\
    \ on one product.\n   Contact\n      Mark Nottingham <mnot@mnot.net>\n"
- title: A.3.2 Proxy/Server exhaustive log format standard for analysis
  contents:
  - "A.3.2 Proxy/Server exhaustive log format standard for analysis\n   Name\n   \
    \   Proxy/Server exhaustive log format standard for analysis\n   Classification\n\
    \      Administration\n   Description\n      Most proxy or origin server logs\
    \ used for characterization or\n      evaluation do not provide sufficient detail\
    \ to determine\n      cacheability of responses.\n   Significance\n      Low (for\
    \ operationality; high significance for research efforts)\n   Implications\n \
    \     Characterizations and simulations are based on non-representative\n    \
    \  workloads.\n   See Also\n      W3C Web Characterization Activity, since they\
    \ are also concerned\n      with collecting high quality logs and building characterizations\n\
    \      from them.\n   Indications\n      -\n   Solution(s)\n      To properly\
    \ clean and to accurately determine cacheability of\n      responses, a complete\
    \ log is required (including all request\n      headers as well as all response\
    \ headers such as \"User-agent\" [for\n      removal of spiders] and \"Expires\"\
    , \"max-age\", \"Set-cookie\", \"no-\n      cache\", etc.)\n   Workaround\n  \
    \    -\n   References\n      See \"Web Traffic Logs: An Imperfect Resource for\
    \ Evaluation\"[5]\n      for some discussion of this.\n   Contact\n      Brian\
    \ D. Davison <davison@acm.org>\n      Terence Kelly <tpkelly@eecs.umich.edu>\n"
- title: A.3.3 Trace log timestamps
  contents:
  - "A.3.3 Trace log timestamps\n   Name\n      Trace log timestamps\n   Classification\n\
    \      Administration\n   Description\n      Some proxies/servers log requests\
    \ without sufficient timing\n      detail.  Millisecond resolution is often too\
    \ small to preserve\n      request ordering and either the servers should record\
    \ request\n      reception time in addition to completion time, or elapsed time\n\
    \      plus either one.\n   Significance\n      Low (for operationality; medium\
    \ significance for research efforts)\n   Implications\n      Characterization\
    \ and simulation fidelity is improved with accurate\n      timing and ordering\
    \ information.  Since logs are generally written\n      in order of request completion,\
    \ these logs cannot be re-played\n      without knowing request generation times\
    \ and reordering\n      accordingly.\n   See Also\n      -\n   Indications\n \
    \     Timestamps can be identical for multiple entries (when only\n      millisecond\
    \ resolution is used).  Request orderings can be jumbled\n      when clients open\
    \ additional connections for embedded objects\n      while still receiving the\
    \ container object.\n   Solution(s)\n      Since request completion time is common\
    \ (e.g., Squid), recommend\n      continuing to use it (with microsecond resolution\
    \ if possible)\n      plus recording elapsed time since request reception.\n \
    \  Workaround\n      -\n   References\n      See \"Web Traffic Logs: An Imperfect\
    \ Resource for Evaluation\"[5]\n      for some discussion of this.\n   Contact\n\
    \      Brian D. Davison <davison@acm.org>\n"
- title: A.3.4 Exchange format for log summaries
  contents:
  - "A.3.4 Exchange format for log summaries\n   Name\n      Exchange format for log\
    \ summaries\n   Classification\n      Administration/Analysis?\n   Description\n\
    \      Although we have (more or less) a standard log file format for\n      proxies\
    \ (plain vanilla Common Logfile and Squid), there isn't a\n      commonly accepted\
    \ format for summaries of those log files.\n      Summaries could be generated\
    \ by the cache itself, or by post-\n      processing existing log file formats\
    \ such as Squid's.\n   Significance\n      High, since it means that each log\
    \ file summarizing/analysis tool\n      is essentially reinventing the wheel (un-necessary\
    \ repetition of\n      code), and the cost of processing a large number of large\
    \ log\n      files through a variety of analysis tools is (again for no good\n\
    \      reason) excessive.\n   Implications\n      In order to perform a meaningful\
    \ analysis (e.g., to measure\n      performance in relation to loading/configuration\
    \ over time) the\n      access logs from multiple busy caches, it's often necessary\
    \ to run\n      first one tool then another, each against the entire log file\
    \ (or\n      a significantly large subset of the log).  With log files running\n\
    \      into hundreds of MB even after compression (for a cache dealing\n     \
    \ with millions of transactions per day) this is a non-trivial task.\n   See Also\n\
    \      IP packet/header sniffing - it may be that individual transactions\n  \
    \    are at a level of granularity which simply isn't sensible to be\n      attempting\
    \ on extremely busy caches.  There may also be legal\n      implications in some\
    \ countries, e.g., if this analysis identifies\n      individuals.\n   Indications\n\
    \      Disks/memory full(!) Stats (using multiple programs) take too long\n  \
    \    to run.  Stats crunching must be distributed out to multiple\n      machines\
    \ because of its high computational cost.\n   Solution(s)\n      Have the proxy\
    \ produce a standardized summary of its activity\n      either automatically or\
    \ via an external (e.g., third party) tool,\n      in a commonly agreed format.\
    \  The format could be something like\n      XML or the Extended Common Logfile,\
    \ but the format and contents\n      are subjects for discussion.  Ideally this\
    \ approach would permit\n      individual cache server products to supply subsets\
    \ of the possible\n      summary info, since it may not be feasible for all servers\
    \ to\n      provide all of the information which people would like to see.\n \
    \  Workaround\n      Devise a private summary format for your own personal use\
    \ - but\n      this complicates or even precludes the exchange of summary info\n\
    \      with other interested parties.\n   References\n      See the web pages\
    \ for the commonly used cache stats analysis\n      programs, e.g., Calamaris,\
    \ squidtimes, squidclients, etc.\n   Contact\n      Martin Hamilton <martin@wwwcache.ja.net>\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2001).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
