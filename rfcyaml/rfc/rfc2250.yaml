- contents:
  - '                RTP Payload Format for MPEG1/MPEG2 Video

    '
  title: __initial_text__
- contents:
  - "Status of this Memo\n   This document specifies an Internet standards track protocol
    for the\n   Internet community, and requests discussion and suggestions for\n
    \  improvements.  Please refer to the current edition of the \"Internet\n   Official
    Protocol Standards\" (STD 1) for the standardization state\n   and status of this
    protocol.  Distribution of this memo is unlimited.\n"
  title: Status of this Memo
- contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (1998).  All Rights Reserved.\n"
  title: Copyright Notice
- contents:
  - "Abstract\n   This memo describes a packetization scheme for MPEG video and audio\n
    \  streams.  The scheme proposed can be used to transport such a video\n   or
    audio flow over the transport protocols supported by RTP.  Two\n   approaches
    are described. The first is designed to support maximum\n   interoperability with
    MPEG System environments.  The second is\n   designed to provide maximum compatibility
    with other RTP-encapsulated\n   media streams and future conference control work
    of the IETF.\n   This memo is a revision of RFC 2038, an Internet standards track\n
    \  protocol.  In this revision, the packet loss resilience mechanisms in\n   Section
    3.4 were extended to include additional picture header\n   information required
    for MPEG2.  A new section on security\n   considerations for this payload type
    is added.\n"
  title: Abstract
- contents:
  - "1. Introduction\n   ISO/IEC JTC1/SC29 WG11 (also referred to as the MPEG committee)
    has\n   defined the MPEG1 standard (ISO/IEC 11172)[1] and the MPEG2 standard\n
    \  (ISO/IEC 13818)[2].  This memo describes a packetization scheme to\n   transport
    MPEG video and audio streams using the Real-time Transport\n   Protocol (RTP),
    version 2 [3, 4].\n   The MPEG1 specification is defined in three parts: System,
    Video and\n   Audio.  It is designed primarily for CD-ROM-based applications,
    and\n   is optimized for approximately 1.5 Mbits/sec combined data rates. The\n
    \  video and audio portions of the specification describe the basic\n   format
    of the video or audio stream.  These formats define the\n   Elementary Streams
    (ES).  The MPEG1 System specification defines an\n   encapsulation of the ES that
    contains Presentation Time Stamps (PTS),\n   Decoding Time Stamps and System Clock
    references, and performs\n   multiplexing of MPEG1 compressed video and audio
    ES's with user data.\n   The MPEG2 specification is structured in a similar way.
    However, it\n   hasn't been restricted only to CD-ROM applications. The MPEG2
    System\n   specification defines two system stream formats:  the MPEG2 Transport\n
    \  Stream (MTS) and the MPEG2 Program Stream (MPS).  The MTS is tailored\n   for
    communicating or storing one or more programs of MPEG2 compressed\n   data and
    also other data in relatively error-prone environments. The\n   MPS is tailored
    for relatively error-free environments.\n   We seek to achieve interoperability
    among 4 types of end-systems in\n   the following specification. The 4 types are:\n
    \       1. Transmitting Interworking Unit (TIU)\n           Receives MPEG information
    from a native MTS system for\n           distribution over packet networks using
    a native RTP-based\n           system layer (such as an IP-based internetwork).
    Examples:\n           real-time encoder, MTS satellite link to Internet, video\n
    \          server with MTS-encoded source material.\n        2. Receiving Interworking
    Unit (RIU)\n           Receives MPEG information in real time from an RTP-based\n
    \          network for forwarding to a native MTS environment.\n           Examples:
    Internet-based video server to MTS-based cable\n           distribution plant.\n
    \       3. Transmitting Internet End-System (TAES)\n           Transmits MPEG
    information generated or stored within the\n           internet end-system itself,
    or received from internet-based\n           computer networks.  Example: video
    server.\n        4. Receiving Internet End-System (RAES)\n           Receives
    MPEG information over an RTP-based internet for\n           consumption at the
    internet end-system or forwarding to\n           traditional computer network.
    \ Example: desktop PC or\n           workstation viewing training video.\n   Each
    of the 2 types of transmitters must work with each of the 2\n   types of receivers.
    \ Because it is probable that the TAES, and\n   certain that the RAES, will be
    based on existing and planned\n   internet-connected computers, it is highly desirable
    for the\n   interoperable protocol to be based on RTP.\n   Because of the range
    of applications that might employ MPEG streams,\n   we propose to define two payload
    formats.\n   Much interest in the MPEG community is in the use of one of the MPEG\n
    \  System encodings, and hence, in Section 2 we propose encapsulations\n   of
    MPEG1 System streams and MPEG2 Transport and Program Streams with\n   RTP.  This
    profile supports the full semantics of MPEG System and\n   offers basic interoperability
    among all four end-system types.\n   When operating only among internet-based
    end-systems (i.e., TAES and\n   RAES) a payload format that provides greater compatibility
    with the\n   Internet architecture is desired, deferring some of the system issues\n
    \  to other protocols being defined in the Internet community (such as\n   the
    MMUSIC WG).  In Section 3 we propose an encapsulation of\n   compressed video
    and audio data (referred to in MPEG documentation as\n   \"Elementary Streams\"
    (ES)) complying with either MPEG1 or MPEG2.\n   Here, neither of the System standards
    of MPEG1 or MPEG2 are utilized.\n   The ES's are directly encapsulated with RTP.\n
    \  Throughout this specification, we make extensive use of MPEG\n   terminology.
    \ The reader should consult the primary MPEG references\n   for definitive descriptions
    of this terminology.\n"
  title: 1. Introduction
- contents:
  - "2. Encapsulation of MPEG System and Transport Streams\n   Each RTP packet will
    contain a timestamp derived from the sender's\n   90KHz clock reference.  This
    clock is synchronized to the system\n   stream Program Clock Reference (PCR) or
    System Clock Reference (SCR)\n   and represents the target transmission time of
    the first byte of the\n   packet payload.  The RTP timestamp will not be passed
    to the MPEG\n   decoder.  This use of the timestamp is somewhat different than\n
    \  normally is the case in RTP, in that it is not considered to be the\n   media
    display or presentation timestamp. The primary purposes of the\n   RTP timestamp
    will be to estimate and reduce any network-induced\n   jitter and to synchronize
    relative time drift between the transmitter\n   and receiver.\n   For MPEG2 Transport
    Streams the RTP payload will contain an integral\n   number of MPEG transport
    packets.  To avoid end system\n   inefficiencies, data from multiple small MTS
    packets (normally fixed\n   in size at 188 bytes) are aggregated into a single
    RTP packet.  The\n   number of transport packets contained is computed by dividing
    RTP\n   payload length by the length of an MTS packet (188).\n   For MPEG2 Program
    streams and MPEG1 system streams there are no\n   packetization restrictions;
    these streams are treated as a packetized\n   stream of bytes.\n"
  - contents:
    - "2.1 RTP header usage\n   The RTP header fields are used as follows:\n        Payload
      Type: Distinct payload types should be assigned for\n          MPEG1 System
      Streams, MPEG2 Program Streams and MPEG2\n          Transport Streams.  See
      [4] for payload type assignments.\n        M bit:  Set to 1 whenever the timestamp
      is discontinuous\n          (such as might happen when a sender switches from
      one data\n          source to another). This allows the receiver and any\n          intervening
      RTP mixers or translators that are synchronizing\n          to the flow to ignore
      the difference between this timestamp\n          and any previous timestamp
      in their clock phase detectors.\n        timestamp: 32 bit 90K Hz timestamp
      representing the target\n          transmission time for the first byte of the
      packet.\n"
    title: 2.1 RTP header usage
  title: 2. Encapsulation of MPEG System and Transport Streams
- contents:
  - "3. Encapsulation of MPEG Elementary Streams\n   The following ES types may be
    encapsulated directly in RTP:\n        (a) MPEG1 Video (ISO/IEC 11172-2) (b) MPEG2
    Video (ISO/IEC\n        13818-2) (c) MPEG1 Audio (ISO/IEC 11172-3) (d) MPEG2 Audio\n
    \       (ISO/IEC 13818-3)\n   A distinct RTP payload type is assigned to MPEG1/MPEG2
    Video and\n   MPEG1/MPEG2 Audio, respectively. Further indication as to whether
    the\n   data is MPEG1 or MPEG2 need not be provided in the RTP or MPEG-\n   specific
    headers of this encapsulation, as this information is\n   available in the ES
    headers.\n   Presentation Time Stamps (PTS) of 32 bits with an accuracy of 90
    kHz\n   shall be carried in the fixed RTP header. All packets that make up a\n
    \  audio or video frame shall have the same time stamp.\n"
  - contents:
    - "3.1 MPEG Video elementary streams\n   MPEG1 Video can be distinguished from
      MPEG2 Video at the video\n   sequence header, i.e. for MPEG2 Video a sequence_header()
      is followed\n   by sequence_extension().  The particular profile and level of
      MPEG2\n   Video (MAIN_Profile@MAIN_Level, HIGH_Profile@HIGH_Level, etc) are\n
      \  determined by the profile_and_level_indicator field of the\n   sequence_extension
      header of MPEG2 Video.\n   The MPEG bit-stream semantics were designed for relatively
      error-free\n   environments, and there is significant amount of dependency (both\n
      \  temporal and spatial) within the stream such that loss of some data\n   make
      other uncorrupted data useless.  The format as defined in this\n   encapsulation
      uses application layer framing information plus\n   additional information in
      the RTP stream-specific header to allow for\n   certain recovery mechanisms.
      \ Appendix 1 suggests several recovery\n   strategies based on the properties
      of this encapsulation.\n   Since MPEG pictures can be large, they will normally
      be fragmented\n   into packets of size less than a typical LAN/WAN MTU.  The
      following\n   fragmentation rules apply:\n        1. The MPEG Video_Sequence_Header,
      when present, will always\n           be at the beginning of an RTP payload.\n
      \       2. An MPEG GOP_header, when present, will always be at the\n           beginning
      of the RTP payload, or will follow a\n           Video_Sequence_Header.\n        3.
      An MPEG Picture_Header, when present, will always be at the\n           beginning
      of a RTP payload, or will follow a GOP_header.\n   Each ES header must be completely
      contained within the packet.\n   Consequently, a minimum RTP payload size of
      261 bytes must be\n   supported to contain the largest single header defined
      in the ES\n   (that is, the extension_data() header containing the\n   quant_matrix_extension()).
      \ Otherwise, there are no restrictions on\n   where headers may appear within
      packet payloads.\n   In MPEG, each picture is made up of one or more \"slices,\"
      and a slice\n   is intended to be the unit of recovery from data loss or corruption.\n
      \  An MPEG-compliant decoder will normally advance to the beginning of\n   next
      slice whenever an error is encountered in the stream.  MPEG\n   slice begin
      and end bits are provided in the encapsulation header to\n   facilitate this.\n
      \  The beginning of a slice must either be the first data in a packet\n   (after
      any MPEG ES headers) or must follow after some integral number\n   of slices
      in a packet.  This requirement insures that the beginning\n   of the next slice
      after one with a missing packet can be found\n   without requiring that the
      receiver scan the packet contents.  Slices\n   may be fragmented across packets
      as long as all the above rules are\n   met.\n   An implementation based on this
      encapsulation assumes that the\n   Video_Sequence_Header is repeated periodically
      in the MPEG bit-\n   stream.  In practice (though not required by MPEG standard)
      this is\n   used to allow channel switching and to receive and start decoding
      a\n   continuously relayed MPEG bit-stream at arbitrary points in the media\n
      \  stream.  It is suggested that when playing back from an MPEG stream\n   from
      a file format (where the Video_Sequence_Header may only be\n   represented at
      the beginning of the stream) that the first\n   Video_Sequence_Header (preceded
      by an end-of-stream indicator) be\n   saved by the packetizer for periodic injection
      in to the network\n   stream.\n"
    title: 3.1 MPEG Video elementary streams
  - contents:
    - "3.2 MPEG Audio elementary streams\n   MPEG1 Audio can be distinguished from
      MPEG2 Audio from the MPEG\n   ancillary_data() header.  For either MPEG1 or
      MPEG2 Audio, distinct\n   Presentation Time Stamps may be present for frames
      which correspond\n   to either 384 samples for Layer-I, or 1152 samples for
      Layer-II or\n   Layer-III.  The actual number of bytes required to represent
      this\n   number of samples will vary depending on the encoder parameters.\n
      \  Multiple audio frames may be encapsulated within one RTP packet.  In\n   this
      case, an integral number of audio frames must be contained\n   within the packet
      and the fragmentation header defined in Section 3.5\n   shall be set to 0.\n
      \  Also, if relatively short packets are to be used, one frame may be so\n   large
      that it may straddle multiple RTP packets.  For example, for\n   Layer-II MPEG
      audio sampled at a rate of 44.1 KHz each frame would\n   represent a time slot
      of 26.1 msec. At this sampling rate if the\n   compressed bit-rate is 384 kbits/sec
      (i.e.  48 kBytes/sec) then the\n   average audio frame size would be 1.25 KBytes.
      \ If packets were to be\n   500 Bytes long, then each audio frame would straddle
      3 RTP packets.\n   The audio fragmentation indicator header (See Section 3.5)
      shall be\n   present for an MPEG1/2 Audio payload type to provide for this\n
      \  fragmentation.\n"
    title: 3.2 MPEG Audio elementary streams
  - contents:
    - "3.3 RTP Fixed Header for MPEG ES encapsulation\n   The RTP header fields are
      used as follows:\n        Payload Type: Distinct payload types should be assigned\n
      \         for video elementary streams and audio elementary streams.\n          See
      [4] for payload type assignments.\n        M bit:  For video, set to 1 on packet
      containing MPEG frame\n          end code, 0 otherwise.  For audio, set to 1
      on first packet of\n          a \"talk-spurt,\" 0 otherwise.\n        PT:  MPEG
      video or audio stream ID.\n        timestamp: 32-bit 90K Hz timestamp representing
      presentation\n          time of MPEG picture or audio frame.  Same for all packets\n
      \         that make up a picture or audio frame.  May not be\n          monotonically
      increasing in video stream if B pictures present\n          in stream.  For
      packets that contain only a video sequence\n          and/or GOP header, the
      timestamp is that of the subsequent\n          picture.\n"
    title: 3.3 RTP Fixed Header for MPEG ES encapsulation
  - contents:
    - "3.4 MPEG Video-specific header\n   This header shall be attached to each RTP
      packet after the RTP fixed\n   header.\n    0                   1                   2
      \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4
      5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |    MBZ  |T|         TR        | |N|S|B|E|  P  | | BFC | | FFC |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \                                  AN              FBV     FFV\n        MBZ:
      Unused. Must be set to zero in current\n           specification. This space
      is reserved for future use.\n        T: MPEG-2 (Two) specific header extension
      present (1 bit).\n           Set to 1 when the MPEG-2 video-specific header
      extension (see\n           Section 3.4.1) follows this header. This extension
      may be\n           needed for improved error resilience; however, its inclusion\n
      \          in an RTP packet is optional. (See Appendix 1.)\n        TR: Temporal-Reference
      (10 bits). The temporal reference of\n           the current picture within
      the current GOP. This value ranges\n           from 0-1023 and is constant for
      all RTP packets of a given\n           picture.\n        AN: Active N bit for
      error resilience (1 bit). Set to 1 when\n           the following bit (N) is
      used to signal changes in the\n           picture header information for MPEG-2
      payloads. It must be\n           set to 0 for MPEG-1 payloads or when N bit
      is not used.\n        N: New picture header (1 bit). Used for MPEG-2 payloads
      when\n           the previous bit (AN) is set to 1. Otherwise, it must be set\n
      \          to zero. Set to 1 when the information contained in the\n           previously
      transmitted Picture Headers can't be used to\n           reconstruct a header
      for the current picture. This happens\n           when the current picture is
      encoded using a different set of\n           parameters than the previous pictures
      of the same type. The N\n           bit must be constant for all RTP packets
      that belong to the\n           same picture so that receipt of any packet from
      a picture\n           allows detecting whether information necessary for\n           reconstruction
      was contained in that picture (N = 1) or a\n           previous one (N = 0).\n
      \       S: Sequence-header-present (1 bit). Normally 0 and set to 1 at\n           the
      occurrence of each MPEG sequence header.  Used to detect\n           presence
      of sequence header in RTP packet.\n        B: Beginning-of-slice (BS) (1 bit).
      Set when the start of the\n           packet payload is a slice start code,
      or when a slice start\n           code is preceded only by one or more of a\n
      \          Video_Sequence_Header, GOP_header and/or Picture_Header.\n        E:
      End-of-slice (ES) (1 bit). Set when the last byte of the\n           payload
      is the end of an MPEG slice.\n        P: Picture-Type (3 bits). I (1), P (2),
      B (3) or D (4). This\n           value is constant for each RTP packet of a
      given picture.\n           Value 000B is forbidden and 101B - 111B are reserved
      to\n           support future extensions to the MPEG ES specification.\n        FBV:
      full_pel_backward_vector\n        BFC: backward_f_code\n        FFV: full_pel_forward_vector\n
      \       FFC: forward_f_code\n           Obtained from the most recent picture
      header, and are\n           constant for each RTP packet of a given picture.
      For I frames\n           none of these values are present in the picture header
      and\n           they must be set to zero in the RTP header.  For P frames\n
      \          only the last two values are present and FBV and BFC must be\n           set
      to zero in the RTP header. For B frames all the four\n           values are
      present.\n"
    - contents:
      - "3.4.1 MPEG-2 Video-specific header extension\n    0                   1                   2
        \                  3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3
        4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \  |X|E|f_[0,0]|f_[0,1]|f_[1,0]|f_[1,1]| DC| PS|T|P|C|Q|V|A|R|H|G|D|\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
        \       X: Unused (1 bit). Must be set to zero in current\n           specification.
        This space is reserved for future use.\n        E: Extensions present (1 bit).
        If set to 1, this header\n           extension, including the composite display
        extension when D =\n           1, will be followed by one or more of the following\n
        \          extensions: quant matrix extension, picture display\n           extension,
        picture temporal scalable extension, picture\n           spatial scalable
        extension and copyright extension.\n           The first byte of these extensions
        data gives the length of\n           the extensions in 32 bit words including
        the length field\n           itself. Zero padding bytes are used at the end
        if required to\n           align the extensions to 32 bit boundary.\n           Since
        they may not be vital in decoding of a picture, the\n           inclusion
        of any one of these extensions in an RTP packet is\n           optional even
        when the MPEG-2 video-specific header extension\n           is included in
        the packet (T = 1). (See Appendix 1.) If\n           present, they should
        be copied from the corresponding\n           extensions following the most
        recent MPEG-2 picture coding\n           extension and they remain constant
        for each RTP packet of a\n           given picture.\n           The extension
        start code (32 bits) and the extension start\n           code ID (4 bits)
        are included. Therefore the extensions are\n           self identifying.\n
        \       f_[0,0]: forward horizontal f_code (4 bits)\n        f_[0,1]: forward
        vertical f_code (4 bits)\n        f_[1,0]: backward horizontal f_code (4 bits)\n
        \       f_[1,1]: backward vertical f_code (4 bits)\n        DC: intra_DC_precision
        (2 bits)\n        PS: picture_structure (2 bits)\n        T: top_field_first
        (1 bit)\n        P: frame_predicted_frame_dct (1 bit)\n        C: concealment_motion_vectors
        (1 bit)\n        Q: q_scale type (1 bit)\n        V: intra_vlc_format (1 bit)\n
        \       A: alternate scan (1 bit)\n        R: repeat_first_field (1 bit)\n
        \       H: chroma_420_type (1 bit)\n        G: progressive frame (1 bit)\n
        \       D: composite_display_flag (1 bit). If set to 1, next 32 bits\n           following
        this one contains 12 zeros followed by 20 bits\n           of composite display
        information.\n        These values are copied from the most recent picture
        coding\n        extension and are constant for each RTP packet of a given\n
        \       picture. Their meanings are as explained in the MPEG-2 standard.\n"
      title: 3.4.1 MPEG-2 Video-specific header extension
    title: 3.4 MPEG Video-specific header
  - contents:
    - "3.5 MPEG Audio-specific header\n   This header shall be attached to each RTP
      packet at the start of the\n   payload and after any RTP headers for an MPEG1/2
      Audio payload type.\n    0                   1                   2                   3\n
      \   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |             MBZ               |          Frag_offset          |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \          Frag_offset: Byte offset into the audio frame for the data\n                        in
      this packet.\n"
    title: 3.5 MPEG Audio-specific header
  title: 3. Encapsulation of MPEG Elementary Streams
- contents:
  - "4. Security Considerations\n   RTP packets using the payload format defined in
    this specification\n   are subject to the security considerations discussed in
    the RTP\n   specification [3], and any appropriate RTP profile (for example [4]).\n
    \  This implies that confidentiality of the media streams is achieved by\n   encryption.
    Because the data compression used with this payload\n   format is applied end-to-end,
    encryption may be performed after\n   compression so there is no conflict between
    the two operations.\n   A potential denial-of-service threat exists for data encodings
    using\n   compression techniques that have non-uniform receiver-end\n   computational
    load. The attacker can inject pathological datagrams\n   into the stream which
    are complex to decode and cause the receiver to\n   be overloaded. However, this
    encoding does not exhibit any\n   significant non-uniformity.\n   As with any
    IP-based protocol, in some circumstances a receiver may\n   be overloaded simply
    by the receipt of too many packets, either\n   desired or undesired. Network-layer
    authentication may be used to\n   discard packets from undesired sources, but
    the processing cost of\n   the authentication itself may be too high. In a multicast\n
    \  environment, pruning of specific sources may be implemented in future\n   versions
    of IGMP [5] and in multicast routing protocols to allow a\n   receiver to select
    which sources are allowed to reach it.\n   A security review of this payload format
    found no additional\n   considerations beyond those in the RTP specification.\n"
  title: 4. Security Considerations
- contents:
  - "Appendix 1. Error Recovery and Resynchronization Strategies.\n   The following
    error recovery and resynchronization strategies are\n   intended to be guidelines
    only.  A compliant receiver is free to\n   employ alternative (or no) strategies.\n
    \  When initially decoding an RTP-encapsulated MPEG Elementary Stream,\n   the
    receiver may discard all packets until the Sequence-header-\n   present bit is
    set to 1.  At this point, sufficient state information\n   is contained in the
    stream to allow processing by an MPEG decoder.\n   Loss of packets containing
    the GOP_header and/or Picture_Header are\n   detected by an unexpected change
    in the Temporal-Reference and\n   Picture-Type values.  Consider the following
    example GOP sequence:\n        In display order: 0B 1B 2I 3B 4B 5P 6B 7B 8P GOP_HDR
    0B ...\n        In stream order:  2I 0B 1B 5P 3B 4B 8P 6B 7B GOP_HDR 2I ...\n
    \  Consider also two counters:\n        ref_pic_temp (Reference Picture (I,P)
    Temporal Reference)\n        dep_pic_temp (Dependent Picture (B) Temporal Reference)\n
    \  At each GOP beginning, set these counters to the temporal reference\n   value
    of the corresponding picture type. For our example GOP\n   sequence, ref_pic_temp
    = 2 and dep_pic_temp = 0. Keep incrementing\n   BOTH counters by unity with each
    following picture. Ref_pic_temp\n   should match the temporal references of the
    I and P frames, and\n   dep_pic_temp should match the temporal references of the
    B frames.\n       dep_pic_temp: -  0  1  2  3  4  5  6  7        8  9\n   In stream
    order:  2I 0B 1B 5P 3B 4B 8P 6B 7B GOP_H 2I 0B 1B ...\n       ref_pic_temp: 2
    \ 3  4  5  6  7  8  9  10  ^    11\n                     --------------------------
    \ |    ^\n                                Match            Drop |\n                                                      Mismatch\n
    \                                                      in ref_pic_temp\n   The
    loss of a GOP header can be detected by matching the appropriate\n   counter (based
    on picture type) to the temporal reference value. A\n   mismatch indicates a lost
    GOP header. If desired, a GOP header can be\n   re-constructed using a \"null\"
    time_code, repeating the closed_gop\n   flag from previous GOP headers, and setting
    the broken_link flag to\n   1.\n   The loss of a Picture_Header can also be detected
    by a mismatch in\n   the Temporal Reference contained in the RTP packet from the\n
    \  appropriate dep_pic_temp or ref_pic_temp counters at the receiver.\n   For
    MPEG-1 payloads, after scanning to the next Beginning-of-slice\n   the Picture_Header
    is reconstructed from the P, TR, FBV, BFC, FFV and\n   FFC contained in that packet,
    and from stream-dependent default\n   values.\n   For MPEG-2, additional information
    is needed for the reconstruction.\n   This information is provided by the MPEG-2
    video specific header\n   extension contained in that packet if the T bit is set
    to 1, or the\n   Picture Header for the current picture may be available from
    previous\n   packets belonging to the same picture. The transmitter's strategy
    for\n   inclusion of the MPEG-2 video specific header extension may depend\n   upon
    a number of factors. This header may not be needed when:\n      1. the information
    has been transmitted a sufficient number of\n      times in previous packets to
    assure reception with the desired\n      probability, or\n      2. the information
    is transmitted over a separate reliable\n      channel, or\n      3. expected
    loss rates are low enough that missed frames are not a\n      concern, or\n      4.
    conserving bandwidth is more important than error resilience,\n      etc.\n   If
    T=1 and E=0, there may be extensions present in the original video\n   bitstream
    that are not included in the current packet. The\n   transmitter may choose not
    to include extensions in a packet when\n   they are not necessary for decoding
    or if one of the cases listed\n   above for not including the MPEG-2 video specific
    header extension in\n   a packet applies only to the extension data.\n   If N=0,
    then the Picture Header from a previous picture of the same\n   type (I,P or B)
    may be used so long as at least one packet has been\n   received for every intervening
    picture of the same type and that the\n   N bit was 0 for each of those pictures.
    This may involve:\n      1. Saving the relevant picture header information that
    can be\n      obtained from the MPEG-2 video specific header extension or\n      directly
    from the video bitstream for each picture type,\n      2. Keeping validity indicators
    for this saved information based on\n      the received N bits and lost packets,
    and,\n      3. Updating the data whenever a packet with N=1 is received.\n   If
    the necessary information is not available from any of these\n   sources, data
    deletion until a new picture start code is advised.\n   Any time an RTP packet
    is lost (as indicated by a gap in the RTP\n   sequence number), the receiver may
    discard all packets until the\n   Beginning-of-slice bit is set.  At this point,
    sufficient state\n   information is contained in the stream to allow processing
    by an MPEG\n   decoder starting at the next slice boundary (possibly after\n   reconstruction
    of the GOP_header and/or Picture_Header as described\n   above).\n"
  title: Appendix 1. Error Recovery and Resynchronization Strategies.
- contents:
  - "References\n   [1] ISO/IEC International Standard 11172; \"Coding of moving pictures\n
    \      and associated audio for digital storage media up to about 1,5\n       Mbits/s\",
    November 1993.\n   [2] ISO/IEC International Standard 13818; \"Generic coding
    of moving\n       pictures and associated audio information\", November 1994.\n
    \  [3] Schulzrinne, H., Casner, S., Frederick, R., and V. Jacobson,\n       \"RTP:
    A Transport Protocol for Real-Time Applications\", RFC 1889,\n       January 1996.\n
    \  [4] Schulzrinne, H., \"RTP Profile for Audio and Video Conferences\n       with
    Minimal Control\", RFC 1890, January 1996.\n   [5] Deering, S., \"Host Extensions
    for IP Multicasting\", STD 5,\n       RFC 1112, August 1989.\n"
  title: References
- contents:
  - "Authors' Addresses\n   Gerard Fernando\n   Sun Microsystems, Inc.\n   Mail-stop
    UMPK14-305\n   2550 Garcia Avenue\n   Mountain View, California 94043-1100\n   USA\n
    \  Phone: +1 415-786-6373\n   EMail: gerard.fernando@eng.sun.com\n   Vivek Goyal\n
    \  Precept Software, Inc.\n   1072 Arastradero Rd,\n   Palo Alto, CA 94304\n   USA\n
    \  Phone: +1 415-845-5200\n   EMail: goyal@precept.com\n   Don Hoffman\n   Sun
    Microsystems, Inc.\n   Mail-stop UMPK14-305\n   2550 Garcia Avenue\n   Mountain
    View, California 94043-1100\n   USA\n   Phone: +1 503-297-1580\n   EMail: don.hoffman@eng.sun.com\n
    \  M. Reha Civanlar\n   AT&T Labs - Research\n   100 Schutlz Drive, 3-213\n   Red
    Bank, NJ 07701-7033\n   USA\n   Phone: +1 732-345-3305\n   EMail: civanlar@research.att.com\n"
  title: Authors' Addresses
- contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (1998).  All
    Rights Reserved.\n   This document and translations of it may be copied and furnished
    to\n   others, and derivative works that comment on or otherwise explain it\n
    \  or assist in its implementation may be prepared, copied, published\n   and
    distributed, in whole or in part, without restriction of any\n   kind, provided
    that the above copyright notice and this paragraph are\n   included on all such
    copies and derivative works.  However, this\n   document itself may not be modified
    in any way, such as by removing\n   the copyright notice or references to the
    Internet Society or other\n   Internet organizations, except as needed for the
    purpose of\n   developing Internet standards in which case the procedures for\n
    \  copyrights defined in the Internet Standards process must be\n   followed,
    or as required to translate it into languages other than\n   English.\n   The
    limited permissions granted above are perpetual and will not be\n   revoked by
    the Internet Society or its successors or assigns.\n   This document and the information
    contained herein is provided on an\n   \"AS IS\" basis and THE INTERNET SOCIETY
    AND THE INTERNET ENGINEERING\n   TASK FORCE DISCLAIMS ALL WARRANTIES, EXPRESS
    OR IMPLIED, INCLUDING\n   BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF THE
    INFORMATION\n   HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED WARRANTIES
    OF\n   MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.\n"
  title: Full Copyright Statement
