- title: __initial_text__
  contents:
  - "                       Design Considerations for\n           Session Initiation\
    \ Protocol (SIP) Overload Control\n"
- title: Abstract
  contents:
  - "Abstract\n   Overload occurs in Session Initiation Protocol (SIP) networks when\n\
    \   SIP servers have insufficient resources to handle all SIP messages\n   they\
    \ receive.  Even though the SIP protocol provides a limited\n   overload control\
    \ mechanism through its 503 (Service Unavailable)\n   response code, SIP servers\
    \ are still vulnerable to overload.  This\n   document discusses models and design\
    \ considerations for a SIP\n   overload control mechanism.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6357.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction . . . . . . . . . . . . . . . . . . .\
    \ . . . . . .  3\n   2.  SIP Overload Problem . . . . . . . . . . . . . . . .\
    \ . . . . .  4\n   3.  Explicit vs. Implicit Overload Control . . . . . . . .\
    \ . . . .  5\n   4.  System Model . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .  6\n   5.  Degree of Cooperation  . . . . . . . . . . . . . . . . . .\
    \ . .  8\n     5.1.  Hop-by-Hop . . . . . . . . . . . . . . . . . . . . . . .\
    \ .  9\n     5.2.  End-to-End . . . . . . . . . . . . . . . . . . . . . . . .\
    \ 10\n     5.3.  Local Overload Control . . . . . . . . . . . . . . . . . . 11\n\
    \   6.  Topologies . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n  \
    \ 7.  Fairness . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n   8.\
    \  Performance Metrics  . . . . . . . . . . . . . . . . . . . . . 14\n   9.  Explicit\
    \ Overload Control Feedback . . . . . . . . . . . . . . 15\n     9.1.  Rate-Based\
    \ Overload Control  . . . . . . . . . . . . . . . 15\n     9.2.  Loss-Based Overload\
    \ Control  . . . . . . . . . . . . . . . 17\n     9.3.  Window-Based Overload\
    \ Control  . . . . . . . . . . . . . . 18\n     9.4.  Overload Signal-Based Overload\
    \ Control . . . . . . . . . . 19\n     9.5.  On-/Off Overload Control . . . .\
    \ . . . . . . . . . . . . . 19\n   10. Implicit Overload Control  . . . . . .\
    \ . . . . . . . . . . . . 20\n   11. Overload Control Algorithms  . . . . . .\
    \ . . . . . . . . . . . 20\n   12. Message Prioritization . . . . . . . . . .\
    \ . . . . . . . . . . 21\n   13. Operational Considerations . . . . . . . . .\
    \ . . . . . . . . . 21\n   14. Security Considerations  . . . . . . . . . . .\
    \ . . . . . . . . 22\n   15. Informative References . . . . . . . . . . . . .\
    \ . . . . . . . 23\n   Appendix A.  Contributors  . . . . . . . . . . . . . .\
    \ . . . . . . 25\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   As with any network element, a Session Initiation Protocol\
    \ (SIP)\n   [RFC3261] server can suffer from overload when the number of SIP\n\
    \   messages it receives exceeds the number of messages it can process.\n   Overload\
    \ occurs if a SIP server does not have sufficient resources to\n   process all\
    \ incoming SIP messages.  These resources may include CPU,\n   memory, input/output,\
    \ or disk resources.\n   Overload can pose a serious problem for a network of\
    \ SIP servers.\n   During periods of overload, the throughput of SIP messages\
    \ in a\n   network of SIP servers can be significantly degraded.  In fact,\n \
    \  overload in a SIP server may lead to a situation in which the\n   overload\
    \ is amplified by retransmissions of SIP messages causing the\n   throughput to\
    \ drop down to a very small fraction of the original\n   processing capacity.\
    \  This is often called congestion collapse.\n   An overload control mechanism\
    \ enables a SIP server to process SIP\n   messages close to its capacity limit\
    \ during times of overload.\n   Overload control is used by a SIP server if it\
    \ is unable to process\n   all SIP requests due to resource constraints.  There\
    \ are other\n   failure cases in which a SIP server can successfully process incoming\n\
    \   requests but has to reject them for other reasons.  For example, a\n   Public\
    \ Switched Telephone Network (PSTN) gateway that runs out of\n   trunk lines but\
    \ still has plenty of capacity to process SIP messages\n   should reject incoming\
    \ INVITEs using a response such as 488 (Not\n   Acceptable Here), as described\
    \ in [RFC4412].  Similarly, a SIP\n   registrar that has lost connectivity to\
    \ its registration database but\n   is still capable of processing SIP messages\
    \ should reject REGISTER\n   requests with a 500 (Server Error) response [RFC3261].\
    \  Overload\n   control mechanisms do not apply in these cases and SIP provides\n\
    \   appropriate response codes for them.\n   There are cases in which a SIP server\
    \ runs other services that do not\n   involve the processing of SIP messages (e.g.,\
    \ processing of RTP\n   packets, database queries, software updates, and event\
    \ handling).\n   These services may, or may not, be correlated with the SIP message\n\
    \   volume.  These services can use up a substantial share of resources\n   available\
    \ on the server (e.g., CPU cycles) and leave the server in a\n   condition where\
    \ it is unable to process all incoming SIP requests.\n   In these cases, the SIP\
    \ server applies SIP overload control\n   mechanisms to avoid congestion collapse\
    \ on the SIP signaling plane.\n   However, controlling the number of SIP requests\
    \ may not significantly\n   reduce the load on the server if the resource shortage\
    \ was created by\n   another service.  In these cases, it is to be expected that\
    \ the\n   server uses appropriate methods of controlling the resource usage of\n\
    \   other services.  The specifics of controlling the resource usage of\n   other\
    \ services and their coordination is out of scope for this\n   document.\n   The\
    \ SIP protocol provides a limited mechanism for overload control\n   through its\
    \ 503 (Service Unavailable) response code and the\n   Retry-After header.  However,\
    \ this mechanism cannot prevent overload\n   of a SIP server and it cannot prevent\
    \ congestion collapse.  In fact,\n   it may cause traffic to oscillate and to\
    \ shift between SIP servers\n   and thereby worsen an overload condition.  A detailed\
    \ discussion of\n   the SIP overload problem, the problems with the 503 (Service\n\
    \   Unavailable) response code and the Retry-After header, and the\n   requirements\
    \ for a SIP overload control mechanism can be found in\n   [RFC5390].  In addition,\
    \ 503 is used for other situations, not just\n   SIP server overload.  A SIP overload\
    \ control process based on 503\n   would have to specify exactly which cause values\
    \ trigger the overload\n   control.\n   This document discusses the models, assumptions,\
    \ and design\n   considerations for a SIP overload control mechanism.  The document\n\
    \   originated in the SIP overload control design team and has been\n   further\
    \ developed by the SIP Overload Control (SOC) working group.\n"
- title: 2.  SIP Overload Problem
  contents:
  - "2.  SIP Overload Problem\n   A key contributor to SIP congestion collapse [RFC5390]\
    \ is the\n   regenerative behavior of overload in the SIP protocol.  When SIP\
    \ is\n   running over the UDP protocol, it will retransmit messages that were\n\
    \   dropped or excessively delayed by a SIP server due to overload and\n   thereby\
    \ increase the offered load for the already overloaded server.\n   This increase\
    \ in load worsens the severity of the overload condition\n   and, in turn, causes\
    \ more messages to be dropped.  A congestion\n   collapse can occur [Hilt] [Noel]\
    \ [Shen] [Abdelal].\n   Regenerative behavior under overload should ideally be\
    \ avoided by any\n   protocol as this would lead to unstable operation under overload.\n\
    \   However, this is often difficult to achieve in practice.  For\n   example,\
    \ changing the SIP retransmission timer mechanisms can reduce\n   the degree of\
    \ regeneration during overload but will impact the\n   ability of SIP to recover\
    \ from message losses.  Without any\n   retransmission, each message that is dropped\
    \ due to SIP server\n   overload will eventually lead to a failed transaction.\n\
    \   For a SIP INVITE transaction to be successful, a minimum of three\n   messages\
    \ need to be forwarded by a SIP server.  Often an INVITE\n   transaction consists\
    \ of five or more SIP messages.  If a SIP server\n   under overload randomly discards\
    \ messages without evaluating them,\n   the chances that all messages belonging\
    \ to a transaction are\n   successfully forwarded will decrease as the load increases.\
    \  Thus,\n   the number of transactions that complete successfully will decrease\n\
    \   even if the message throughput of a server remains up and assuming\n   the\
    \ overload behavior is fully non-regenerative.  A SIP server might\n   (partially)\
    \ parse incoming messages to determine if it is a new\n   request or a message\
    \ belonging to an existing transaction.\n   Discarding a SIP message after spending\
    \ the resources to parse it is\n   expensive.  The number of successful transactions\
    \ will therefore\n   decline with an increase in load as fewer resources can be\
    \ spent on\n   forwarding messages and more resources are consumed by inspecting\n\
    \   messages that will eventually be dropped.  The rate of the decline\n   depends\
    \ on the amount of resources spent to inspect each message.\n   Another challenge\
    \ for SIP overload control is controlling the rate of\n   the true traffic source.\
    \  Overload is often caused by a large number\n   of user agents (UAs), each of\
    \ which creates only a single message.\n   However, the sum of their traffic can\
    \ overload a SIP server.  The\n   overload mechanisms suitable for controlling\
    \ a SIP server (e.g., rate\n   control) may not be effective for individual UAs.\
    \  In some cases,\n   there are other non-SIP mechanisms for limiting the load\
    \ from the\n   UAs.  These may operate independently from, or in conjunction with,\n\
    \   the SIP overload mechanisms described here.  In either case, they are\n  \
    \ out of scope for this document.\n"
- title: 3.  Explicit vs. Implicit Overload Control
  contents:
  - "3.  Explicit vs. Implicit Overload Control\n   The main difference between explicit\
    \ and implicit overload control is\n   the way overload is signaled from a SIP\
    \ server that is reaching\n   overload condition to its upstream neighbors.\n\
    \   In an explicit overload control mechanism, a SIP server uses an\n   explicit\
    \ overload signal to indicate that it is reaching its capacity\n   limit.  Upstream\
    \ neighbors receiving this signal can adjust their\n   transmission rate according\
    \ to the overload signal to a level that is\n   acceptable to the downstream server.\
    \  The overload signal enables a\n   SIP server to steer the load it is receiving\
    \ to a rate at which it\n   can perform at maximum capacity.\n   Implicit overload\
    \ control uses the absence of responses and packet\n   loss as an indication of\
    \ overload.  A SIP server that is sensing such\n   a condition reduces the load\
    \ it is forwarding to a downstream\n   neighbor.  Since there is no explicit overload\
    \ signal, this mechanism\n   is robust, as it does not depend on actions taken\
    \ by the SIP server\n   running into overload.\n   The ideas of explicit and implicit\
    \ overload control are in fact\n   complementary.  By considering implicit overload\
    \ indications, a\n   server can avoid overloading an unresponsive downstream neighbor.\
    \  An\n   explicit overload signal enables a SIP server to actively steer the\n\
    \   incoming load to a desired level.\n"
- title: 4.  System Model
  contents:
  - "4.  System Model\n   The model shown in Figure 1 identifies fundamental components\
    \ of an\n   explicit SIP overload control mechanism:\n   SIP Processor:  The SIP\
    \ Processor processes SIP messages and is the\n      component that is protected\
    \ by overload control.\n   Monitor:  The Monitor measures the current load of\
    \ the SIP Processor\n      on the receiving entity.  It implements the mechanisms\
    \ needed to\n      determine the current usage of resources relevant for the SIP\n\
    \      Processor and reports load samples (S) to the Control Function.\n   Control\
    \ Function:  The Control Function implements the overload\n      control algorithm.\
    \  The Control Function uses the load samples (S)\n      and determines if overload\
    \ has occurred and a throttle (T) needs\n      to be set to adjust the load sent\
    \ to the SIP Processor on the\n      receiving entity.  The Control Function on\
    \ the receiving entity\n      sends load feedback (F) to the sending entity.\n\
    \   Actuator:  The Actuator implements the algorithms needed to act on\n     \
    \ the throttles (T) and ensures that the amount of traffic forwarded\n      to\
    \ the receiving entity meets the criteria of the throttle.  For\n      example,\
    \ a throttle may instruct the Actuator to not forward more\n      than 100 INVITE\
    \ messages per second.  The Actuator implements the\n      algorithms to achieve\
    \ this objective, e.g., using message gapping.\n      It also implements algorithms\
    \ to select the messages that will be\n      affected and determine whether they\
    \ are rejected or redirected.\n   The type of feedback (F) conveyed from the receiving\
    \ to the sending\n   entity depends on the overload control method used (i.e.,\
    \ loss-based,\n   rate-based, window-based, or signal-based overload control;\
    \ see\n   Section 9), the overload control algorithm (see Section 11), as well\n\
    \   as other design parameters.  The feedback (F) enables the sending\n   entity\
    \ to adjust the amount of traffic forwarded to the receiving\n   entity to a level\
    \ that is acceptable to the receiving entity without\n   causing overload.\n \
    \  Figure 1 depicts a general system model for overload control.  In\n   this\
    \ diagram, one instance of the control function is on the sending\n   entity (i.e.,\
    \ associated with the actuator) and one is on the\n   receiving entity (i.e.,\
    \ associated with the Monitor).  However, a\n   specific mechanism may not require\
    \ both elements.  In this case, one\n   of two control function elements can be\
    \ empty and simply passes along\n   feedback.  For example, if (F) is defined\
    \ as a loss-rate (e.g.,\n   reduce traffic by 10%), there is no need for a control\
    \ function on\n   the sending entity as the content of (F) can be copied directly\
    \ into\n   (T).\n   The model in Figure 1 shows a scenario with one sending and\
    \ one\n   receiving entity.  In a more realistic scenario, a receiving entity\n\
    \   will receive traffic from multiple sending entities and vice versa\n   (see\
    \ Section 6).  The feedback generated by a Monitor will therefore\n   often be\
    \ distributed across multiple Actuators.  A Monitor needs to\n   be able to split\
    \ the load it can process across multiple sending\n   entities and generate feedback\
    \ that correctly adjusts the load each\n   sending entity is allowed to send.\
    \  Similarly, an Actuator needs to\n   be prepared to receive different levels\
    \ of feedback from different\n   receiving entities and throttle traffic to these\
    \ entities\n   accordingly.\n   In a realistic deployment, SIP messages will flow\
    \ in both directions,\n   from server B to server A as well as server A to server\
    \ B.  The\n   overload control mechanisms in each direction can be considered\n\
    \   independently.  For messages flowing from server A to server B, the\n   sending\
    \ entity is server A and the receiving entity is server B, and\n   vice versa.\
    \  The control loops in both directions operate\n   independently.\n         \
    \    Sending                Receiving\n              Entity                  Entity\n\
    \        +----------------+      +----------------+\n        |    Server A   \
    \ |      |    Server B    |\n        |  +----------+  |      |  +----------+ \
    \ |    -+\n        |  | Control  |  |  F   |  | Control  |  |     |\n        |\
    \  | Function |<-+------+--| Function |  |     |\n        |  +----------+  | \
    \     |  +----------+  |     |\n        |     T |        |      |       ^    \
    \    |     | Overload\n        |       v        |      |       | S      |    \
    \ | Control\n        |  +----------+  |      |  +----------+  |     |\n      \
    \  |  | Actuator |  |      |  | Monitor  |  |     |\n        |  +----------+ \
    \ |      |  +----------+  |     |\n        |       |        |      |       ^ \
    \       |    -+\n        |       v        |      |       |        |    -+\n  \
    \      |  +----------+  |      |  +----------+  |     |\n      <-+--|   SIP  \
    \  |  |      |  |   SIP    |  |     |  SIP\n      --+->|Processor |--+------+->|Processor\
    \ |--+->   | System\n        |  +----------+  |      |  +----------+  |     |\n\
    \        +----------------+      +----------------+    -+\n           Figure 1:\
    \ System Model for Explicit Overload Control\n"
- title: 5.  Degree of Cooperation
  contents:
  - "5.  Degree of Cooperation\n   A SIP request is usually processed by more than\
    \ one SIP server on its\n   path to the destination.  Thus, a design choice for\
    \ an explicit\n   overload control mechanism is where to place the components\
    \ of\n   overload control along the path of a request and, in particular,\n  \
    \ where to place the Monitor and Actuator.  This design choice\n   determines\
    \ the degree of cooperation between the SIP servers on the\n   path.  Overload\
    \ control can be implemented hop-by-hop with the\n   Monitor on one server and\
    \ the Actuator on its direct upstream\n   neighbor.  Overload control can be implemented\
    \ end-to-end with\n   Monitors on all SIP servers along the path of a request\
    \ and an\n   Actuator on the sender.  In this case, the Control Functions\n  \
    \ associated with each Monitor have to cooperate to jointly determine\n   the\
    \ overall feedback for this path.  Finally, overload control can be\n   implemented\
    \ locally on a SIP server if the Monitor and Actuator\n   reside on the same server.\
    \  In this case, the sending entity and\n   receiving entity are the same SIP\
    \ server, and the Actuator and\n   Monitor operate on the same SIP Processor (although,\
    \ the Actuator\n   typically operates on a pre-processing stage in local overload\n\
    \   control).  Local overload control is an internal overload control\n   mechanism,\
    \ as the control loop is implemented internally on one\n   server.  Hop-by-hop\
    \ and end-to-end are external overload control\n   mechanisms.  All three configurations\
    \ are shown in Figure 2.\n                  +---------+             +------(+)---------+\n\
    \         +------+ |         |             |       ^          |\n         |  \
    \    | |        +---+          |       |         +---+\n         v      | v  \
    \  //=>| C |          v       |     //=>| C |\n      +---+    +---+ //    +---+\
    \       +---+    +---+ //    +---+\n      | A |===>| B |                   | A\
    \ |===>| B |\n      +---+    +---+ \\\\    +---+       +---+    +---+ \\\\   \
    \ +---+\n                  ^    \\\\=>| D |          ^       |     \\\\=>| D |\n\
    \                  |        +---+          |       |         +---+\n         \
    \         |         |             |       v          |\n                  +---------+\
    \             +------(+)---------+\n            (a) hop-by-hop               \
    \    (b) end-to-end\n                            +-+\n                       \
    \     v |\n       +-+      +-+        +---+\n       v |      v |    //=>| C |\n\
    \      +---+    +---+ //    +---+\n      | A |===>| B |\n      +---+    +---+\
    \ \\\\    +---+\n                       \\\\=>| D |\n                        \
    \   +---+\n                            ^ |\n                            +-+\n\
    \              (c) local\n       ==> SIP request flow\n       <-- Overload feedback\
    \ loop\n              Figure 2: Degree of Cooperation between Servers\n"
- title: 5.1.  Hop-by-Hop
  contents:
  - "5.1.  Hop-by-Hop\n   The idea of hop-by-hop overload control is to instantiate\
    \ a separate\n   control loop between all neighboring SIP servers that directly\n\
    \   exchange traffic.  That is, the Actuator is located on the SIP server\n  \
    \ that is the direct upstream neighbor of the SIP server that has the\n   corresponding\
    \ Monitor.  Each control loop between two servers is\n   completely independent\
    \ of the control loop between other servers\n   further up- or downstream.  In\
    \ the example in Figure 2(a), three\n   independent overload control loops are\
    \ instantiated: A - B, B - C,\n   and B - D.  Each loop only controls a single\
    \ hop.  Overload feedback\n   received from a downstream neighbor is not forwarded\
    \ further\n   upstream.  Instead, a SIP server acts on this feedback, for example,\n\
    \   by rejecting SIP messages if needed.  If the upstream neighbor of a\n   server\
    \ also becomes overloaded, it will report this problem to its\n   upstream neighbors,\
    \ which again take action based on the reported\n   feedback.  Thus, in hop-by-hop\
    \ overload control, overload is always\n   resolved by the direct upstream neighbors\
    \ of the overloaded server\n   without the need to involve entities that are located\
    \ multiple SIP\n   hops away.\n   Hop-by-hop overload control reduces the impact\
    \ of overload on a SIP\n   network and can avoid congestion collapse.  It is simple\
    \ and scales\n   well to networks with many SIP entities.  An advantage is that\
    \ it\n   does not require feedback to be transmitted across multiple-hops,\n \
    \  possibly crossing multiple trust domains.  Feedback is sent to the\n   next\
    \ hop only.  Furthermore, it does not require a SIP entity to\n   aggregate a\
    \ large number of overload status values or keep track of\n   the overload status\
    \ of SIP servers it is not communicating with.\n"
- title: 5.2.  End-to-End
  contents:
  - "5.2.  End-to-End\n   End-to-end overload control implements an overload control\
    \ loop along\n   the entire path of a SIP request, from user agent client (UAC)\
    \ to\n   user agent server (UAS).  An end-to-end overload control mechanism\n\
    \   consolidates overload information from all SIP servers on the way\n   (including\
    \ all proxies and the UAS) and uses this information to\n   throttle traffic as\
    \ far upstream as possible.  An end-to-end overload\n   control mechanism has\
    \ to be able to frequently collect the overload\n   status of all servers on the\
    \ potential path(s) to a destination and\n   combine this data into meaningful\
    \ overload feedback.\n   A UA or SIP server only throttles requests if it knows\
    \ that these\n   requests will eventually be forwarded to an overloaded server.\
    \  For\n   example, if D is overloaded in Figure 2(b), A should only throttle\n\
    \   requests it forwards to B when it knows that they will be forwarded\n   to\
    \ D. It should not throttle requests that will eventually be\n   forwarded to\
    \ C, since server C is not overloaded.  In many cases, it\n   is difficult for\
    \ A to determine which requests will be routed to C\n   and D, since this depends\
    \ on the local routing decision made by B.\n   These routing decisions can be\
    \ highly variable and, for example,\n   depend on call-routing policies configured\
    \ by the user, services\n   invoked on a call, load-balancing policies, etc. \
    \ A previous message\n   to a target that has been routed through an overloaded\
    \ server does\n   not necessarily mean that the next message to this target will\
    \ also\n   be routed through the same server.\n   The main problem of end-to-end\
    \ overload control is its inherent\n   complexity, since UAC or SIP servers need\
    \ to monitor all potential\n   paths to a destination in order to determine which\
    \ requests should be\n   throttled and which requests may be sent.  Even if this\
    \ information\n   is available, it is not clear which path a specific request\
    \ will\n   take.\n   A variant of end-to-end overload control is to implement\
    \ a control\n   loop between a set of well-known SIP servers along the path of\
    \ a SIP\n   request.  For example, an overload control loop can be instantiated\n\
    \   between a server that only has one downstream neighbor or a set of\n   closely\
    \ coupled SIP servers.  A control loop spanning multiple hops\n   can be used\
    \ if the sending entity has full knowledge about the SIP\n   servers on the path\
    \ of a SIP message.\n   Overload control for SIP servers is different from end-to-end\n\
    \   congestion control used by transport protocols such as TCP.  The\n   traffic\
    \ exchanged between SIP servers consists of many individual SIP\n   messages.\
    \  Each SIP message is created by a SIP UA to achieve a\n   specific goal (e.g.,\
    \ to start setting up a call).  All messages have\n   their own source and destination\
    \ addresses.  Even SIP messages\n   containing identical SIP URIs (e.g., a SUBSCRIBE\
    \ and an INVITE\n   message to the same SIP URI) can be routed to different destinations.\n\
    \   This is different from TCP, where the traffic exchanged between\n   routers\
    \ consists of packets belonging to a usually longer flow of\n   messages exchanged\
    \ between a source and a destination (e.g., to\n   transmit a file).  If congestion\
    \ occurs, the sources can detect this\n   condition and adjust the rate at which\
    \ the next packets are\n   transmitted.\n"
- title: 5.3.  Local Overload Control
  contents:
  - "5.3.  Local Overload Control\n   The idea of local overload control (see Figure\
    \ 2(c)) is to run the\n   Monitor and Actuator on the same server.  This enables\
    \ the server to\n   monitor the current resource usage and to reject messages\
    \ that can't\n   be processed without overusing local resources.  The fundamental\n\
    \   assumption behind local overload control is that it is less resource\n   consuming\
    \ for a server to reject messages than to process them.  A\n   server can therefore\
    \ reject the excess messages it cannot process to\n   stop all retransmissions\
    \ of these messages.  Since rejecting messages\n   does consume resources on a\
    \ SIP server, local overload control alone\n   cannot prevent a congestion collapse.\n\
    \   Local overload control can be used in conjunction with other overload\n  \
    \ control mechanisms and provides an additional layer of protection\n   against\
    \ overload.  It is fully implemented within a SIP server and\n   does not require\
    \ cooperation between servers.  In general, SIP\n   servers should apply other\
    \ overload control techniques to control\n   load before a local overload control\
    \ mechanism is activated as a\n   mechanism of last resort.\n"
- title: 6.  Topologies
  contents:
  - "6.  Topologies\n   The following topologies describe four generic SIP server\n\
    \   configurations.  These topologies illustrate specific challenges for\n   an\
    \ overload control mechanism.  An actual SIP server topology is\n   likely to\
    \ consist of combinations of these generic scenarios.\n   In the \"load balancer\"\
    \ configuration shown in Figure 3(a), a set of\n   SIP servers (D, E, and F) receives\
    \ traffic from a single source A.  A\n   load balancer is a typical example for\
    \ such a configuration.  In this\n   configuration, overload control needs to\
    \ prevent server A (i.e., the\n   load balancer) from sending too much traffic\
    \ to any of its downstream\n   neighbors D, E, and F.  If one of the downstream\
    \ neighbors becomes\n   overloaded, A can direct traffic to the servers that still\
    \ have\n   capacity.  If one of the servers acts as a backup, it can be\n   activated\
    \ once one of the primary servers reaches overload.\n   If A can reliably determine\
    \ that D, E, and F are its only downstream\n   neighbors and all of them are in\
    \ overload, it may choose to report\n   overload upstream on behalf of D, E, and\
    \ F.  However, if the set of\n   downstream neighbors is not fixed or only some\
    \ of them are in\n   overload, then A should not activate an overload control\
    \ since A can\n   still forward the requests destined to non-overloaded downstream\n\
    \   neighbors.  These requests would be throttled as well if A would use\n   overload\
    \ control towards its upstream neighbors.\n   In some cases, the servers D, E,\
    \ and F are in a server farm and are\n   configured to appear as a single server\
    \ to their upstream neighbors.\n   In this case, server A can report overload\
    \ on behalf of the server\n   farm.  If the load balancer is not a SIP entity,\
    \ servers D, E, and F\n   can report the overall load of the server farm (i.e.,\
    \ the load of the\n   virtual server) in their messages.  As an alternative, one\
    \ of the\n   servers (e.g., server E) can report overload on behalf of the server\n\
    \   farm.  In this case, not all messages contain overload control\n   information,\
    \ and all upstream neighbors need to be served by server E\n   periodically to\
    \ ensure that updated information is received.\n   In the \"multiple sources\"\
    \ configuration shown in Figure 3(b), a SIP\n   server D receives traffic from\
    \ multiple upstream sources A, B, and C.\n   Each of these sources can contribute\
    \ a different amount of traffic,\n   which can vary over time.  The set of active\
    \ upstream neighbors of D\n   can change as servers may become inactive, and previously\
    \ inactive\n   servers may start contributing traffic to D.\n   If D becomes overloaded,\
    \ it needs to generate feedback to reduce the\n   amount of traffic it receives\
    \ from its upstream neighbors.  D needs\n   to decide by how much each upstream\
    \ neighbor should reduce traffic.\n   This decision can require the consideration\
    \ of the amount of traffic\n   sent by each upstream neighbor and it may need\
    \ to be re-adjusted as\n   the traffic contributed by each upstream neighbor varies\
    \ over time.\n   Server D can use a local fairness policy to determine how much\n\
    \   traffic it accepts from each upstream neighbor.\n   In many configurations,\
    \ SIP servers form a \"mesh\" as shown in Figure\n   3(c).  Here, multiple upstream\
    \ servers A, B, and C forward traffic to\n   multiple alternative servers D and\
    \ E.  This configuration is a\n   combination of the \"load balancer\" and \"\
    multiple sources\" scenario.\n                      +---+              +---+\n\
    \                   /->| D |              | A |-\\\n                  /   +---+\
    \              +---+  \\\n                 /                               \\\
    \   +---+\n          +---+-/     +---+              +---+    \\->|   |\n     \
    \     | A |------>| E |              | B |------>| D |\n          +---+-\\   \
    \  +---+              +---+    /->|   |\n                 \\                 \
    \              /   +---+\n                  \\   +---+              +---+  /\n\
    \                   \\->| F |              | C |-/\n                      +---+\
    \              +---+\n          (a) load balancer             (b) multiple sources\n\
    \          +---+\n          | A |---\\                        a--\\\n        \
    \  +---+-\\  \\---->+---+                 \\\n                 \\/----->| D |\
    \             b--\\ \\--->+---+\n          +---+--/\\  /-->+---+             \
    \    \\---->|   |\n          | B |    \\/                      c-------->| D |\n\
    \          +---+---\\/\\--->+---+                       |   |\n              \
    \    /\\---->| E |            ...   /--->+---+\n          +---+--/   /-->+---+\
    \                 /\n          | C |-----/                      z--/\n       \
    \   +---+\n                (c) mesh                   (d) edge proxy\n       \
    \                    Figure 3: Topologies\n   Overload control that is based on\
    \ reducing the number of messages a\n   sender is allowed to send is not suited\
    \ for servers that receive\n   requests from a very large population of senders,\
    \ each of which only\n   sends a very small number of requests.  This scenario\
    \ is shown in\n   Figure 3(d).  An edge proxy that is connected to many UAs is\
    \ a\n   typical example for such a configuration.  Since each UA typically\n \
    \  infrequently sends requests, which are often related to the same\n   session,\
    \ it can't decrease its message rate to resolve the overload.\n   A SIP server\
    \ that receives traffic from many sources, which each\n   contribute only a small\
    \ number of requests, can resort to local\n   overload control by rejecting a\
    \ percentage of the requests it\n   receives with 503 (Service Unavailable) responses.\
    \  Since it has many\n   upstream neighbors, it can send 503 (Service Unavailable)\
    \ to a\n   fraction of them to gradually reduce load without entirely stopping\n\
    \   all incoming traffic.  The Retry-After header can be used in 503\n   (Service\
    \ Unavailable) responses to ask upstream neighbors to wait a\n   given number\
    \ of seconds before trying the request again.  Using 503\n   (Service Unavailable)\
    \ can, however, not prevent overload if a large\n   number of sources create requests\
    \ (e.g., to place calls) at the same\n   time.\n   Note: The requirements of the\
    \ \"edge proxy\" topology are different\n   from the ones of the other topologies,\
    \ which may require a different\n   method for overload control.\n"
- title: 7.  Fairness
  contents:
  - "7.  Fairness\n   There are many different ways to define fairness between multiple\n\
    \   upstream neighbors of a SIP server.  In the context of SIP server\n   overload,\
    \ it is helpful to describe two categories of fairness: basic\n   fairness and\
    \ customized fairness.  With basic fairness, a SIP server\n   treats all requests\
    \ equally and ensures that each request has the\n   same chance of succeeding.\
    \  With customized fairness, the server\n   allocates resources according to different\
    \ priorities.  An example\n   application of the basic fairness criteria is the\
    \ \"Third caller\n   receives free tickets\" scenario, where each call attempt\
    \ should have\n   an equal success probability in connecting through an overloaded\
    \ SIP\n   server, irrespective of the service provider in which the call was\n\
    \   initiated.  An example of customized fairness would be a server that\n   assigns\
    \ different resource allocations to its upstream neighbors\n   (e.g., service\
    \ providers) as defined in a service level agreement\n   (SLA).\n"
- title: 8.  Performance Metrics
  contents:
  - "8.  Performance Metrics\n   The performance of an overload control mechanism\
    \ can be measured\n   using different metrics.\n   A key performance indicator\
    \ is the goodput of a SIP server under\n   overload.  Ideally, a SIP server will\
    \ be enabled to perform at its\n   maximum capacity during periods of overload.\
    \  For example, if a SIP\n   server has a processing capacity of 140 INVITE transactions\
    \ per\n   second, then an overload control mechanism should enable it to\n   process\
    \ 140 INVITEs per second even if the offered load is much\n   higher.  The delay\
    \ introduced by a SIP server is another important\n   indicator.  An overload\
    \ control mechanism should ensure that the\n   delay encountered by a SIP message\
    \ is not increased significantly\n   during periods of overload.  Significantly\
    \ increased delay can lead\n   to time-outs and retransmission of SIP messages,\
    \ making the overload\n   worse.\n   Responsiveness and stability are other important\
    \ performance\n   indicators.  An overload control mechanism should quickly react\
    \ to an\n   overload occurrence and ensure that a SIP server does not become\n\
    \   overloaded, even during sudden peaks of load.  Similarly, an overload\n  \
    \ control mechanism should quickly stop rejecting requests if the\n   overload\
    \ disappears.  Stability is another important criteria.  An\n   overload control\
    \ mechanism should not cause significant oscillations\n   of load on a SIP server.\
    \  The performance of SIP overload control\n   mechanisms is discussed in [Noel],\
    \ [Shen], [Hilt], and [Abdelal].\n   In addition to the above metrics, there are\
    \ other indicators that are\n   relevant for the evaluation of an overload control\
    \ mechanism:\n   Fairness:  Which type of fairness does the overload control mechanism\n\
    \      implement?\n   Self-limiting:  Is the overload control self-limiting if\
    \ a SIP server\n      becomes unresponsive?\n   Changes in neighbor set:  How\
    \ does the mechanism adapt to a changing\n      set of sending entities?\n   Data\
    \ points to monitor:  Which and how many data points does an\n      overload control\
    \ mechanism need to monitor?\n   Computational load:  What is the (CPU) load created\
    \ by the overload\n      \"Monitor\" and \"Actuator\"?\n"
- title: 9.  Explicit Overload Control Feedback
  contents:
  - "9.  Explicit Overload Control Feedback\n   Explicit overload control feedback\
    \ enables a receiver to indicate how\n   much traffic it wants to receive.  Explicit\
    \ overload control\n   mechanisms can be differentiated based on the type of information\n\
    \   conveyed in the overload control feedback and whether the control\n   function\
    \ is in the receiving or sending entity (receiver- vs. sender-\n   based overload\
    \ control), or both.\n"
- title: 9.1.  Rate-Based Overload Control
  contents:
  - "9.1.  Rate-Based Overload Control\n   The key idea of rate-based overload control\
    \ is to limit the request\n   rate at which an upstream element is allowed to\
    \ forward traffic to\n   the downstream neighbor.  If overload occurs, a SIP server\
    \ instructs\n   each upstream neighbor to send, at most, X requests per second.\
    \  Each\n   upstream neighbor can be assigned a different rate cap.\n   An example\
    \ algorithm for an Actuator in the sending entity is request\n   gapping.  After\
    \ transmitting a request to a downstream neighbor, a\n   server waits for 1/X\
    \ seconds before it transmits the next request to\n   the same neighbor.  Requests\
    \ that arrive during the waiting period\n   are not forwarded and are either redirected,\
    \ rejected, or buffered.\n   Request gapping only affects requests that are targeted\
    \ by overload\n   control (e.g., requests that initiate a transaction and not\n\
    \   retransmissions in an ongoing transaction).\n   The rate cap ensures that\
    \ the number of requests received by a SIP\n   server never increases beyond the\
    \ sum of all rate caps granted to\n   upstream neighbors.  Rate-based overload\
    \ control protects a SIP\n   server against overload, even during load spikes\
    \ assuming there are\n   no new upstream neighbors that start sending traffic.\
    \  New upstream\n   neighbors need to be considered in the rate caps assigned\
    \ to all\n   upstream neighbors.  The rate assigned to upstream neighbors needs\
    \ to\n   be adjusted when new neighbors join.  During periods when new\n   neighbors\
    \ are joining, overload can occur in extreme cases until the\n   rate caps of\
    \ all servers are adjusted to again match the overall rate\n   cap of the server.\
    \  The overall rate cap of a SIP server is\n   determined by an overload control\
    \ algorithm, e.g., based on system\n   load.\n   Rate-based overload control requires\
    \ a SIP server to assign a rate\n   cap to each of its upstream neighbors while\
    \ it is activated.\n   Effectively, a server needs to assign a share of its overall\
    \ capacity\n   to each upstream neighbor.  A server needs to ensure that the sum\
    \ of\n   all rate caps assigned to upstream neighbors does not substantially\n\
    \   oversubscribe its actual processing capacity.  This requires a SIP\n   server\
    \ to keep track of the set of upstream neighbors and to adjust\n   the rate cap\
    \ if a new upstream neighbor appears or an existing\n   neighbor stops transmitting.\
    \  For example, if the capacity of the\n   server is X and this server is receiving\
    \ traffic from two upstream\n   neighbors, it can assign a rate of X/2 to each\
    \ of them.  If a third\n   sender appears, the rate for each sender is lowered\
    \ to X/3.  If the\n   overall rate cap is too high, a server may experience overload.\
    \  If\n   the cap is too low, the upstream neighbors will reject requests even\n\
    \   though they could be processed by the server.\n   An approach for estimating\
    \ a rate cap for each upstream neighbor is\n   using a fixed proportion of a control\
    \ variable, X, where X is\n   initially equal to the capacity of the SIP server.\
    \  The server then\n   increases or decreases X until the workload arrival rate\
    \ matches the\n   actual server capacity.  Usually, this will mean that the sum\
    \ of the\n   rate caps sent out by the server (=X) exceeds its actual capacity,\n\
    \   but enables upstream neighbors who are not generating more than their\n  \
    \ fair share of the work to be effectively unrestricted.  In this\n   approach,\
    \ the server only has to measure the aggregate arrival rate.\n   However, since\
    \ the overall rate cap is usually higher than the actual\n   capacity, brief periods\
    \ of overload may occur.\n"
- title: 9.2.  Loss-Based Overload Control
  contents:
  - "9.2.  Loss-Based Overload Control\n   A loss percentage enables a SIP server\
    \ to ask an upstream neighbor to\n   reduce the number of requests it would normally\
    \ forward to this\n   server by X%.  For example, a SIP server can ask an upstream\
    \ neighbor\n   to reduce the number of requests this neighbor would normally send\
    \ by\n   10%.  The upstream neighbor then redirects or rejects 10% of the\n  \
    \ traffic that is destined for this server.\n   To implement a loss percentage,\
    \ the sending entity may employ an\n   algorithm to draw a random number between\
    \ 1 and 100 for each request\n   to be forwarded.  The request is not forwarded\
    \ to the server if the\n   random number is less than or equal to X.\n   An advantage\
    \ of loss-based overload control is that the receiving\n   entity does not need\
    \ to track the set of upstream neighbors or the\n   request rate it receives from\
    \ each upstream neighbor.  It is\n   sufficient to monitor the overall system\
    \ utilization.  To reduce\n   load, a server can ask its upstream neighbors to\
    \ lower the traffic\n   forwarded by a certain percentage.  The server calculates\
    \ this\n   percentage by combining the loss percentage that is currently in use\n\
    \   (i.e., the loss percentage the upstream neighbors are currently using\n  \
    \ when forwarding traffic), the current system utilization, and the\n   desired\
    \ system utilization.  For example, if the server load\n   approaches 90% and\
    \ the current loss percentage is set to a 50%\n   traffic reduction, then the\
    \ server can decide to increase the loss\n   percentage to 55% in order to get\
    \ to a system utilization of 80%.\n   Similarly, the server can lower the loss\
    \ percentage if permitted by\n   the system utilization.\n   Loss-based overload\
    \ control requires that the throttle percentage be\n   adjusted to the current\
    \ overall number of requests received by the\n   server.  This is particularly\
    \ important if the number of requests\n   received fluctuates quickly.  For example,\
    \ if a SIP server sets a\n   throttle value of 10% at time t1 and the number of\
    \ requests increases\n   by 20% between time t1 and t2 (t1<t2), then the server\
    \ will see an\n   increase in traffic by 10% between time t1 and t2.  This is\
    \ even\n   though all upstream neighbors have reduced traffic by 10%.  Thus,\n\
    \   percentage throttling requires an adjustment of the throttling\n   percentage\
    \ in response to the traffic received and may not always be\n   able to prevent\
    \ a server from encountering brief periods of overload\n   in extreme cases.\n"
- title: 9.3.  Window-Based Overload Control
  contents:
  - "9.3.  Window-Based Overload Control\n   The key idea of window-based overload\
    \ control is to allow an entity\n   to transmit a certain number of messages before\
    \ it needs to receive a\n   confirmation for the messages in transit.  Each sender\
    \ maintains an\n   overload window that limits the number of messages that can\
    \ be in\n   transit without being confirmed.  Window-based overload control is\n\
    \   inspired by TCP [RFC0793].\n   Each sender maintains an unconfirmed message\
    \ counter for each\n   downstream neighbor it is communicating with.  For each\
    \ message sent\n   to the downstream neighbor, the counter is increased.  For\
    \ each\n   confirmation received, the counter is decreased.  The sender stops\n\
    \   transmitting messages to the downstream neighbor when the unconfirmed\n  \
    \ message counter has reached the current window size.\n   A crucial parameter\
    \ for the performance of window-based overload\n   control is the window size.\
    \  Each sender has an initial window size\n   it uses when first sending a request.\
    \  This window size can be\n   changed based on the feedback it receives from\
    \ the receiver.\n   The sender adjusts its window size as soon as it receives\
    \ the\n   corresponding feedback from the receiver.  If the new window size is\n\
    \   smaller than the current unconfirmed message counter, the sender\n   stops\
    \ transmitting messages until more messages are confirmed and the\n   current\
    \ unconfirmed message counter is less than the window size.\n   Note that the\
    \ reception of a 100 (Trying) response does not provide a\n   confirmation for\
    \ the successful processing of a message.  100\n   (Trying) responses are often\
    \ created by a SIP server very early in\n   processing and do not indicate that\
    \ a message has been successfully\n   processed and cleared from the input buffer.\
    \  If the downstream\n   neighbor is a stateless proxy, it will not create 100\
    \ (Trying)\n   responses at all and will instead pass through 100 (Trying) responses\n\
    \   created by the next stateful server.  Also, 100 (Trying) responses\n   are\
    \ typically only created for INVITE requests.  Explicit message\n   confirmations\
    \ do not have these problems.\n   Window-based overload control is similar to\
    \ rate-based overload\n   control in that the total available receiver buffer\
    \ space needs to be\n   divided among all upstream neighbors.  However, unlike\
    \ rate-based\n   overload control, window-based overload control is self-limiting\
    \ and\n   can ensure that the receiver buffer does not overflow under normal\n\
    \   conditions.  The transmission of messages by senders is clocked by\n   message\
    \ confirmations received from the receiver.  A buffer overflow\n   can occur in\
    \ extreme cases when a large number of new upstream\n   neighbors arrives at the\
    \ same time.  However, senders will eventually\n   stop transmitting new requests\
    \ once their initial sending window is\n   closed.\n   In window-based overload\
    \ control, the number of messages a sender is\n   allowed to send can frequently\
    \ be set to zero.  In this state, the\n   sender needs to be informed when it\
    \ is allowed to send again and when\n   the receiver window has opened up.  However,\
    \ since the sender is not\n   allowed to transmit messages, the receiver cannot\
    \ convey the new\n   window size by piggybacking it in a response to another message.\n\
    \   Instead, it needs to inform the sender through another mechanism,\n   e.g.,\
    \ by sending a message that contains the new window size.\n"
- title: 9.4.  Overload Signal-Based Overload Control
  contents:
  - "9.4.  Overload Signal-Based Overload Control\n   The key idea of overload signal-based\
    \ overload control is to use the\n   transmission of a 503 (Service Unavailable)\
    \ response as a signal for\n   overload in the downstream neighbor.  After receiving\
    \ a 503 (Service\n   Unavailable) response, the sender reduces the load forwarded\
    \ to the\n   downstream neighbor to avoid triggering more 503 (Service\n   Unavailable)\
    \ responses.  The sender keeps reducing the load if more\n   503 (Service Unavailable)\
    \ responses are received.  Note that this\n   scheme is based on the use of 503\
    \ (Service Unavailable) responses\n   without the Retry-After header, as the Retry-After\
    \ header would\n   require a sender to entirely stop forwarding requests.  It\
    \ should\n   also be noted that 503 responses can be generated for reasons other\n\
    \   than overload (e.g., server maintenance).\n   A sender that has not received\
    \ 503 (Service Unavailable) responses\n   for a while but is still throttling\
    \ traffic can start to increase the\n   offered load.  By slowly increasing the\
    \ traffic forwarded, a sender\n   can detect that overload in the downstream neighbor\
    \ has been resolved\n   and more load can be forwarded.  The load is increased\
    \ until the\n   sender receives another 503 (Service Unavailable) response or\
    \ is\n   forwarding all requests it has.  A possible algorithm for adjusting\n\
    \   traffic is additive increase/multiplicative decrease (AIMD).\n   Overload\
    \ signal-based overload control is a sender-based overload\n   control mechanism.\n"
- title: 9.5.  On-/Off Overload Control
  contents:
  - "9.5.  On-/Off Overload Control\n   On-/off overload control feedback enables\
    \ a SIP server to turn the\n   traffic it is receiving either on or off.  The\
    \ 503 (Service\n   Unavailable) response with a Retry-After header implements\
    \ on-/off\n   overload control.  On-/off overload control is less effective in\n\
    \   controlling load than the fine grained control methods above.  All of\n  \
    \ the above methods can realize on-/off overload control, e.g., by\n   setting\
    \ the allowed rate to either zero or unlimited.\n"
- title: 10.  Implicit Overload Control
  contents:
  - "10.  Implicit Overload Control\n   Implicit overload control ensures that the\
    \ transmission of a SIP\n   server is self-limiting.  It slows down the transmission\
    \ rate of a\n   sender when there is an indication that the receiving entity is\n\
    \   experiencing overload.  Such an indication can be that the receiving\n   entity\
    \ is not responding within the expected timeframe or is not\n   responding at\
    \ all.  The idea of implicit overload control is that\n   senders should try to\
    \ sense overload of a downstream neighbor even if\n   there is no explicit overload\
    \ control feedback.  It avoids an\n   overloaded server, which has become unable\
    \ to generate overload\n   control feedback, from being overwhelmed with requests.\n\
    \   Window-based overload control is inherently self-limiting since a\n   sender\
    \ cannot continue to pass messages without receiving\n   confirmations.  All other\
    \ explicit overload control schemes described\n   above do not have this property\
    \ and require additional implicit\n   controls to limit transmissions in case\
    \ an overloaded downstream\n   neighbor does not generate explicit feedback.\n"
- title: 11.  Overload Control Algorithms
  contents:
  - "11.  Overload Control Algorithms\n   An important aspect of the design of an\
    \ overload control mechanism is\n   the overload control algorithm.  The control\
    \ algorithm determines\n   when the amount of traffic to a SIP server needs to\
    \ be decreased and\n   when it can be increased.  In terms of the model described\
    \ in Section\n   4, the control algorithm takes (S) as an input value and generates\n\
    \   (T) as a result.\n   Overload control algorithms have been studied to a large\
    \ extent and\n   many different overload control algorithms exist.  With many\n\
    \   different overload control algorithms available, it seems reasonable\n   to\
    \ suggest a baseline algorithm in a specification for a SIP overload\n   control\
    \ mechanism and allow the use of other algorithms if they\n   provide the same\
    \ protocol semantics.  This will also allow the\n   development of future algorithms,\
    \ which may lead to better\n   performance.  Conversely, the overload control\
    \ mechanism should allow\n   the use of different algorithms if they adhere to\
    \ the defined\n   protocol semantics.\n"
- title: 12.  Message Prioritization
  contents:
  - "12.  Message Prioritization\n   Overload control can require a SIP server to\
    \ prioritize requests and\n   select requests to be rejected or redirected.  The\
    \ selection is\n   largely a matter of local policy of the SIP server, the overall\n\
    \   network, and the services the SIP server provides.\n   While there are many\
    \ factors that can affect the prioritization of\n   SIP requests, the Resource-Priority\
    \ Header (RPH) field [RFC4412] is a\n   prime candidate for marking the prioritization\
    \ of SIP requests.\n   Depending on the particular network and the services it\
    \ offers, a\n   particular namespace and priority value in the RPH could indicate\
    \ i)\n   a high priority request, which should be preserved if possible during\n\
    \   overload, ii) a low priority request, which should be dropped during\n   overload,\
    \ or iii) a label, which has no impact on message\n   prioritization in this network.\n\
    \   For a number of reasons, responses should not be targeted in order to\n  \
    \ reduce SIP server load.  Responses cannot be rejected and would have\n   to\
    \ be dropped.  This triggers the retransmission of the request plus\n   the response,\
    \ leading to even more load.  In addition, the request\n   associated with a response\
    \ has already been processed and dropping\n   the response will waste the efforts\
    \ that have been spent on the\n   request.  Most importantly, rejecting a request\
    \ effectively also\n   removes the request and the response.  If no requests are\
    \ passed\n   along, there will be no responses coming back in return.\n   Overload\
    \ control does not change the retransmission behavior of SIP.\n   Retransmissions\
    \ are triggered using procedures defined in RFC 3261\n   [RFC3261] and are not\
    \ subject to throttling.\n"
- title: 13.  Operational Considerations
  contents:
  - "13.  Operational Considerations\n   In addition to the design considerations\
    \ discussed above,\n   implementations of a SIP overload control mechanism need\
    \ to take the\n   following operational aspects into consideration.  These aspects,\n\
    \   while important, are out of scope for this document and are left for\n   further\
    \ discussion in other documents.\n    Selection of feedback type:  A SIP overload\
    \ control mechanism can\n      support one or multiple types of explicit overload\
    \ control\n      feedback.  Using a single type of feedback (e.g., loss-based\n\
    \      feedback) has the advantage of simplifying the protocol and\n      implementations.\
    \  Supporting multiple types of feedback (e.g.,\n      loss- and rate-based feedback)\
    \ provides more flexibility; however,\n      it requires a way to select the feedback\
    \ type used between two\n      servers.\n   Event reporting:  Overload is a serious\
    \ condition for any network of\n      SIP servers, even if it is handled properly\
    \ by an overload control\n      mechanism.  Overload events should therefore be\
    \ reported by a SIP\n      server, e.g., through a logging or management interface.\n"
- title: 14.  Security Considerations
  contents:
  - "14.  Security Considerations\n   This document presents an overview of several\
    \ overload control\n   feedback mechanisms.  These mechanisms and design consideration\
    \ are\n   presented as input to other documents that will specify a particular\n\
    \   feedback mechanism.  Specific security measures pertinent to a\n   particular\
    \ overload feedback mechanism will be discussed in the\n   context of a document\
    \ specifying that security mechanism.  However,\n   there are common security\
    \ considerations that must be taken into\n   account regardless of the choice\
    \ of a final mechanism.\n   First, the rate-based mechanism surveyed in Section\
    \ 9.1 allocates a\n   fixed portion of the total inbound traffic of a server to\
    \ each of its\n   upstream neighbors.  Consequently, an attacker can introduce\
    \ a new\n   upstream server for a short duration, causing the overloaded server\n\
    \   to lower the proportional traffic rate to all other existing servers.\n  \
    \ Introducing many such short-lived servers will cause the aggregate\n   rate\
    \ arriving at the overloaded server to decrease substantially,\n   thereby affecting\
    \ a reduction in the service offered by the server\n   under attack and leading\
    \ to a denial-of-service attack [RFC4732].\n   The same problem exists in the\
    \ windows-based mechanism discussed in\n   Section 9.3; however, because of the\
    \ window acknowledgments sent by\n   the overloaded server, the effect is not\
    \ as drastic (an attacker will\n   have to expend resources by constantly sending\
    \ traffic to keep the\n   receiver window full).\n   All mechanisms assume that\
    \ the upstream neighbors of an overloaded\n   server follow the feedback received.\
    \  In the rate- and window-based\n   mechanisms, a server can directly verify\
    \ if upstream neighbors follow\n   the requested policies.  As the loss-based\
    \ mechanism described in\n   Section 9.2 requires upstream neighbors to reduce\
    \ traffic by a\n   fraction and the current offered load in the upstream neighbor\
    \ is\n   unknown, a server cannot directly verify the compliance of upstream\n\
    \   neighbors, except when traffic reduction is set to 100%.  In this\n   case,\
    \ a server has to rely on heuristics to identify upstream\n   neighbors that try\
    \ to gain an advantage by not reducing load or not\n   reducing it at the requested\
    \ loss-rate.  A policing mechanism can be\n   used to throttle or block traffic\
    \ from unfair or malicious upstream\n   neighbors.  Barring such a widespread\
    \ policing mechanism, the\n   communication link between the upstream neighbors\
    \ and the overloaded\n   server should be such that the identity of both the servers\
    \ at the\n   end of each link can be established and logged.  The use of Transport\n\
    \   Layer Security (TLS) and mutual authentication of upstream neighbors\n   [RFC3261]\
    \ [RFC5922] can be used for this purpose.\n   If an attacker controls a server,\
    \ he or she may maliciously advertise\n   overload feedback to all of the neighbors\
    \ of the server, even if the\n   server is not experiencing overload.  This will\
    \ have the effect of\n   forcing all of the upstream neighbors to reject or queue\
    \ messages\n   arriving to them and destined for the apparently overloaded server\n\
    \   (this, in essence, is diminishing the serving capacity of the\n   upstream\
    \ neighbors since they now have to deal with their normal\n   traffic in addition\
    \ to rejecting or quarantining the traffic destined\n   to the overloaded server).\
    \  All mechanisms allow the attacker to\n   advertise a capacity of 0, effectively\
    \ disabling all traffic destined\n   to the server pretending to be in overload\
    \ and forcing all the\n   upstream neighbors to expend resources dealing with\
    \ this condition.\n   As before, a remedy for this is to use a communication link\
    \ such that\n   the identity of the servers at both ends of the link is established\n\
    \   and logged.  The use of TLS and mutual authentication of neighbors\n   [RFC3261]\
    \ [RFC5922] can be used for this purpose.\n   If an attacker controls several\
    \ servers of a load-balanced cluster,\n   he or she may maliciously advertise\
    \ overload feedback from these\n   servers to all senders.  Senders with the policy\
    \ to redirect traffic\n   that cannot be processed by an overloaded server will\
    \ start to\n   redirect this traffic to the servers that have not reported overload.\n\
    \   This attack can be used to create a denial-of-service attack on these\n  \
    \ servers.  If these servers are compromised, the attack can be used to\n   increase\
    \ the amount of traffic that is passed through the compromised\n   servers.  This\
    \ attack is ineffective if servers reject traffic based\n   on overload feedback\
    \ instead of redirecting it.\n"
- title: 15.  Informative References
  contents:
  - "15.  Informative References\n   [Abdelal]   Abdelal, A. and W. Matragi, \"Signal-Based\
    \ Overload\n               Control for SIP Servers\", 7th Annual IEEE Consumer\n\
    \               Communications and Networking Conference (CCNC-10), Las\n    \
    \           Vegas, Nevada, USA, January 2010.\n   [Hilt]      Hilt, V. and I.\
    \ Widjaja, \"Controlling overload in\n               networks of SIP servers\"\
    , IEEE International Conference\n               on Network Protocols (ICNP'08),\
    \ Orlando, Florida, October\n               2008.\n   [Noel]      Noel, E. and\
    \ C. Johnson, \"Novel Overload Controls for SIP\n               Networks\", International\
    \ Teletraffic Congress (ITC 21),\n               Paris, France, September 2009.\n\
    \   [RFC0793]   Postel, J., \"Transmission Control Protocol\", STD 7, RFC\n  \
    \             793, September 1981.\n   [RFC3261]   Rosenberg, J., Schulzrinne,\
    \ H., Camarillo, G., Johnston,\n               A., Peterson, J., Sparks, R., Handley,\
    \ M., and E.\n               Schooler, \"SIP: Session Initiation Protocol\", RFC\
    \ 3261,\n               June 2002.\n   [RFC4412]   Schulzrinne, H. and J. Polk,\
    \ \"Communications Resource\n               Priority for the Session Initiation\
    \ Protocol (SIP)\", RFC\n               4412, February 2006.\n   [RFC4732]   Handley,\
    \ M., Rescorla, E., and IAB, \"Internet Denial-of-\n               Service Considerations\"\
    , RFC 4732, December 2006.\n   [RFC5390]   Rosenberg, J., \"Requirements for Management\
    \ of Overload\n               in the Session Initiation Protocol\", RFC 5390,\
    \ December\n               2008.\n   [RFC5922]   Gurbani, V., Lawrence, S., and\
    \ A. Jeffrey, \"Domain\n               Certificates in the Session Initiation\
    \ Protocol (SIP)\",\n               RFC 5922, June 2010.\n   [Shen]      Shen,\
    \ C., Schulzrinne, H., and E. Nahum, \"Session\n               Initiation Protocol\
    \ (SIP) Server Overload Control: Design\n               and Evaluation, Principles\"\
    , Systems and Applications of\n               IP Telecommunications (IPTComm'08),\
    \ Heidelberg, Germany,\n               July 2008.\n"
- title: Appendix A.  Contributors
  contents:
  - "Appendix A.  Contributors\n   Many thanks for the contributions, comments, and\
    \ feedback on this\n   document to: Mary Barnes (Nortel), Janet Gunn (CSC), Carolyn\
    \ Johnson\n   (AT&T Labs), Paul Kyzivat (Cisco), Daryl Malas (CableLabs), Tom\n\
    \   Phelan (Sonus Networks), Jonathan Rosenberg (Cisco), Henning\n   Schulzrinne\
    \ (Columbia University), Robert Sparks (Tekelec), Nick\n   Stewart (British Telecommunications\
    \ plc), Rich Terpstra (Level 3),\n   Fangzhe Chang (Bell Labs/Alcatel-Lucent).\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Volker Hilt\n   Bell Labs/Alcatel-Lucent\n   791 Holmdel-Keyport\
    \ Rd\n   Holmdel, NJ  07733\n   USA\n   EMail: volker.hilt@alcatel-lucent.com\n\
    \   Eric Noel\n   AT&T Labs\n   EMail: eric.noel@att.com\n   Charles Shen\n  \
    \ Columbia University\n   EMail: charles@cs.columbia.edu\n   Ahmed Abdelal\n \
    \  Sonus Networks\n   EMail: aabdelal@sonusnet.com\n"
