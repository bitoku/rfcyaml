- title: __initial_text__
  contents:
  - '                     A Proposed Flow Specification

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard.  Distribution of this memo is\n\
    \   unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   A flow specification (or \"flow spec\") is a data structure used\
    \ by\n   internetwork hosts to request special services of the internetwork,\n\
    \   often guarantees about how the internetwork will handle some of the\n   hosts'\
    \ traffic.  In the future, hosts are expected to have to request\n   such services\
    \ on behalf of distributed applications such as\n   multimedia conferencing.\n\
    \   The flow specification defined in this memo is intended for\n   information\
    \ and possible experimentation (i.e., experimental use by\n   consenting routers\
    \ and applications only).  This RFC is a product of\n   the Internet Research\
    \ Task Force (IRTF).\n"
- title: Introduction
  contents:
  - "Introduction\n   The Internet research community is currently studying the problems\
    \ of\n   supporting a new suite of distributed applications over\n   internetworks.\
    \  These applications, which include multimedia\n   conferencing, data fusion,\
    \ visualization, and virtual reality, have\n   the property that they require\
    \ the distributed system (the collection\n   of hosts that support the applications\
    \ along with the internetwork to\n   which they are attached) be able to provide\
    \ guarantees about the\n   quality of communication between applications.  For\
    \ example, a video\n   conference may require a certain minimum bandwidth to be\
    \ sure that\n   the video images are delivered in a timely way to all recipients.\n\
    \   One way for the distributed system to provide guarantees is for hosts\n  \
    \ to negotiate with the internetwork for rights to use a certain part\n   of the\
    \ internetwork's resources.  (An alternative is to have the\n   internetwork infer\
    \ the hosts' needs from information embedded in the\n   data traffic each host\
    \ injects into the network.  Currently, it is\n   not clear how to make this scheme\
    \ work except for a rather limited\n   set of traffic classes.)\n   There are\
    \ a number of ways to effect a negotiation.  For example a\n   negotiation can\
    \ be done in-band or out-of-band.  It can also be done\n   in advance of sending\
    \ data (possibly days in advance), as the first\n   part of a connection setup,\
    \ or concurrently with sending (i.e., a\n   host starts sending data and starts\
    \ a negotiation to try to ensure\n   that it will allowed to continue sending).\
    \  Insofar as is possible,\n   this memo is agnostic with regard to the variety\
    \ of negotiation that\n   is to be done.\n   The purpose of this memo is to define\
    \ a data structure, called a flow\n   specification or flow spec, that can be\
    \ used as part of the\n   negotiation to describe the type of service that the\
    \ hosts need from\n   the internetwork.  This memo defines the format of the fields\
    \ of the\n   data structure and their interpretation.  It also briefly describes\n\
    \   what purpose the different fields fill, and discusses why this set of\n  \
    \ fields is thought to be both necessary and sufficient.\n   It is important to\
    \ note that the goal of this flow spec is to able to\n   describe *any* flow requirement,\
    \ both for guaranteed flows and for\n   applications that simply want to give\
    \ hints to the internetwork about\n   their requirements.\n"
- title: Format of the Flow Spec
  contents:
  - "Format of the Flow Spec\n       0                   1                   2   \
    \                3\n       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\
    \ 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      |              Version          |    Maximum Transmission Unit  |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |\
    \      Token Bucket Rate        |        Token Bucket Size      |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      |  Maximum Transmission Rate    |     Minimum Delay Noticed     |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |\
    \     Maximum Delay Variation   |        Loss Sensitivity       |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \      |     Burst Loss Sensitivity    |          Loss Interval        |\n   \
    \   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |\
    \    Quality of Guarantee       |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n"
- title: Discussion of the Flow Spec
  contents:
  - "Discussion of the Flow Spec\n   The flow spec indicates service requirements\
    \ for a single direction.\n   Multidirectional flows will need to request services\
    \ in both\n   directions (using two flow specs).\n   To characterize a unidirectional\
    \ flow, the flow spec needs to do four\n   things.\n   First, it needs to characterize\
    \ how the flow's traffic will be\n   injected into the internetwork.  If the internetwork\
    \ doesn't know\n   what to expect (is it a gigabit-per-second flow or a three\
    \ kilobit-\n   per-second flow?) then it is difficult for the internetwork to\
    \ make\n   guarantees.  (Note the word \"difficult\" rather than \"impossible.\"\
    \  It\n   may be possible to statistically manage traffic or over-engineer the\n\
    \   network so well that the network can accept almost all flows, without\n  \
    \ setup.  But this problem looks far harder than asking the sender to\n   approximate\
    \ its behavior so the network can plan.)  In this flow\n   spec, injected traffic\
    \ is characterized as having a sustainable rate\n   (the token bucket rate) a\
    \ peak rate (the maximum transmission rate),\n   and an approximate burst size\
    \ (the token bucket size).  A more\n   precise definition of each of these fields\
    \ is given below.  The\n   characterization is based, in part, on the work done\
    \ in [1].\n   Second, the flow spec needs to characterize sensitivity to delay.\n\
    \   Some applications are more sensitive than others.  At the same time,\n   the\
    \ internetwork will likely have a choice of routes with various\n   delays available\
    \ from the source to destination.  For example, both\n   routes using satellites\
    \ (which have very long delays) and routes\n   using terrestrial lines (which\
    \ will have shorter delays) may be\n   available.  So the sending host needs to\
    \ indicate the flow's\n   sensitivity to delay.  However, this field is only advisory.\
    \  It only\n   tells the network when to stop trying to reduce the delay - it\
    \ does\n   not specify a maximum acceptable delay.\n   There are two problems\
    \ with allowing applications to specify the\n   maximum acceptable delay.\n  \
    \ First, observe that an application would probably be happy with a\n   maximum\
    \ delay of 100 ms between the US and Japan but very unhappy\n   with a delay of\
    \ 100 ms within the same city.  This observation\n   suggests that the maximum\
    \ delay is actually variable, and is a\n   function of the delay that is considered\
    \ achievable.  But the\n   achievable delay is largely determined by the geographic\
    \ distance\n   between the two peers, and this sort of geographical information\
    \ is\n   usually not available from a network.  Worse yet, the advent of\n   mobile\
    \ hosts makes such information increasingly hard to provide.  So\n   there is\
    \ reason to believe that applications may have difficulty\n   choosing a rational\
    \ maximum delay.\n   The second problem with maximum delays is that they are an\
    \ attempt to\n   quantify what performance is acceptable to users, and an application\n\
    \   usually does not know what performance will be acceptable its user.\n   For\
    \ example, a common justification for specifying a maximum\n   acceptable delay\
    \ is that human users find it difficult to talk to\n   each other over a link\
    \ with more than about 100 ms of delay.\n   Certainly such delays can make the\
    \ conversation less pleasant, but it\n   is still possible to converse when delays\
    \ are several seconds long,\n   and given a choice between no connection and a\
    \ long delay, many users\n   will pick the delay.  (The phone call may involve\
    \ an important matter\n   that must be resolved.)\n   As part of specifying a\
    \ flow's delay sensitivity, the flow spec must\n   also characterize how sensitive\
    \ the flow is to the distortion of its\n   data stream.\n   Packets injected into\
    \ a network according to some pattern will not\n   normally come out of the network\
    \ still conforming to the pattern.\n   Instead, the pattern will have been distorted\
    \ by queueing effects in\n   the network.  Since there is reason to believe that\
    \ it may make\n   network design easier to continue to allow the networks slightly\n\
    \   distort traffic patterns, it is expected that those applications\n   which\
    \ are sensitive to distortion will require their hosts to use\n   some amount\
    \ of buffering to reshape the flow back into its original\n   form.  It seems\
    \ reasonable to assume that buffer space is not\n   infinite and that a receiving\
    \ system will wish to limit the amount of\n   buffering that a single flow can\
    \ use.\n   The amount of buffer space required for removing distortion at the\n\
    \   receiving system is determined by the variation in end-to-end\n   transmission\
    \ delays for data sent over the flow.  If the transmission\n   delay is a mean\
    \ delay, D, plus or minus a variance, V, the receiving\n   system needs buffer\
    \ space equivalent to 2 * V * the transmission\n   rate.  To see why this is so,\
    \ consider two packets, A and B, sent T\n   time units apart which must be delivered\
    \ to the receiving application\n   T time units apart.  In the worst case, A arrives\
    \ after a delay of\n   D-V time units (the minimum delay) and B arrives after\
    \ a delay of D+V\n   time units (the maximum delay).  The receiver cannot deliver\
    \ B until\n   it arrives, which is T + 2 * V time units after A.  To ensure that\
    \ A\n   is delivered T time units before B, A must be buffered for 2 * V time\n\
    \   units.  The delay variance field is the value of 2 * V, and allows\n   the\
    \ receiver to indicate how much buffering it is willing to provide.\n   A third\
    \ function of the flow spec is to signal sensitivity to loss of\n   data.  Some\
    \ applications are more sensitive to the loss of their data\n   than other applications.\
    \  Some real-time applications are both\n   sensitive to loss and unable to wait\
    \ for retransmissions of data.\n   For these particularly sensitive applications,\
    \ hosts may implement\n   forward error correction on a flow to try to absolutely\
    \ minimize\n   loss.  The loss fields allow hosts to request loss properties\n\
    \   appropriate for the application's requirements.\n   Finally, it is expected\
    \ that the internetwork may be able to provide\n   a range of service guarantees.\
    \  At the best, the internetwork may be\n   asked to guarantee (with tight probability\
    \ bounds) the quality of\n   service it will provide.  Or the internetwork may\
    \ simply be asked to\n   ensure that packets sent over the flow take a terrestrial\
    \ path.  The\n   quality of guarantee field indicates what type of service guarantee\n\
    \   the application desires.\n"
- title: Definition of Individual Fields
  contents:
  - 'Definition of Individual Fields

    '
- title: General Format of Fields
  contents:
  - "General Format of Fields\n   With a few exceptions, fields of the flow spec are\
    \ expressed using a\n   common 16-bit format.  This format has two forms.  The\
    \ first form is\n   shown below.\n               0 1 2 3 4 5 6 7 8 9 0 1 2 3 4\
    \ 5\n              +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n              |0|  Exponent\
    \   |     Value     |\n              +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   In\
    \ this format, the first bit is 0, followed by 7 bits of an exponent\n   (E),\
    \ and an 8-bit value (V).  This format encodes a number, of the\n   form V * (2**E).\
    \  This representation was chosen to allow easy\n   representation of a wide range\
    \ of values, while avoiding over-precise\n   representations.\n   In some case,\
    \ systems will not wish to request a precise value but\n   rather simply indicate\
    \ some sensitivity.  For example, a virtual\n   terminal application like Telnet\
    \ will likely want to indicate that it\n   is sensitive to delay, but it may not\
    \ be worth expressing particular\n   delay values for the network to try to achieve.\
    \  For these cases,\n   instead of a number, the field in the flow spec will take\
    \ the\n   following form:\n               0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n  \
    \            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n              |1|   Well-defined\
    \ Constant     |\n              +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n   The first\
    \ bit of the field is one, and is followed by a 15-bit\n   constant.  The values\
    \ of the constants for given fields are defined\n   below.  Any additional values\
    \ can be requested from the Internet\n   Assigned Numbers Authority (IANA).\n\
    \   Version Field\n      This field is a 16-bit integer in Internet byte order.\
    \  It is the\n      version number of the flow specification.  The version number\
    \ of\n      the flow specification defined in this document is 1.  The IANA is\n\
    \      responsible for assigning future version numbers for any proposed\n   \
    \   revisions of this flow specification.\n      This field does not use the general\
    \ field format.\n   Maximum Transmission Unit (MTU)\n      A 16-bit integer in\
    \ Internet byte order which is the maximum\n      number of bytes in the largest\
    \ possible packet to be transmitted\n      over this flow.\n      This field does\
    \ not use the general field format.\n      The field serves two purposes.\n  \
    \    It is a convenient unit for expressing loss properties.  Using the\n    \
    \  default MTU of the internetwork is inappropriate since the\n      internetwork\
    \ have very large MTU, such the 64Kbytes of IP, but\n      applications and hosts\
    \ may be sensitive to losses of far less than\n      an MTU's amount of data --\
    \ for example, a voice application would\n      be sensitive to a loss of several\
    \ consecutive small packets.\n      The MTU also bounds the amount of time that\
    \ a flow can transmit,\n      uninterrupted, on a shared media.\n      Similarly,\
    \ the loss rates of links that suffer bit errors will\n      vary dramatically\
    \ based on the MTU size.\n   Token Bucket Rate\n      The token bucket rate is\
    \ one of three fields used to define how\n      traffic will be injected into\
    \ the internetwork by the sending\n      application.  (The other two fields are\
    \ the token bucket size and\n      the maximum transmission rate.)\n      The\
    \ token rate is the rate at which tokens (credits) are placed\n      into an imaginary\
    \ token bucket.  For each flow, a separate bucket\n      is maintained.  To send\
    \ a packet over the flow, a host must remove\n      a number of credits equal\
    \ to the size of the packet from the token\n      bucket.  If there are not enough\
    \ credits, the host must wait until\n      enough credits accumulate in the bucket.\n\
    \      Note that the fact that the rate is expressed in terms of a token\n   \
    \   bucket rate does not mean that hosts must implement token buckets.\n     \
    \ Any traffic management scheme that yields equivalent behavior is\n      permitted.\n\
    \      The field is in the general field format and counts the number of\n   \
    \   byte credits (i.e., right to send a byte) per second which are\n      deposited\
    \ into the token bucket.  The value must be a number (not\n      a well-known\
    \ constant).\n      The value zero is slightly special.  It is used to indicate\
    \ that\n      the application is not making a request for bandwidth guarantees.\n\
    \      If this field is zero, then the Token Bucket Size must also be\n      zero,\
    \ and the type of guarantee requested may be no higher than\n      predicted service.\n\
    \   Token Bucket Size\n      The token bucket size controls the maximum amount\
    \ of data that the\n      flow can send at the peak rate.  More formally, if the\
    \ token\n      bucket size is B, and the token bucket rate is R, over any\n  \
    \    arbitrarily chosen interval T in the life of the flow, the amount\n     \
    \ of data that the flow sends cannot have exceeded B + (R * T)\n      bytes.\n\
    \      The token bucket is filled at the token bucket rate.  The bucket\n    \
    \  size limits how many credits the flow may store.  When the bucket\n      is\
    \ full, new credits are discarded.\n      The field is in the general field format\
    \ and indicates the size of\n      the bucket in bytes.  The value must be a number.\n\
    \      Note that the bucket size must be greater than or equal to the MTU\n  \
    \    size.\n      Zero is a legal value for the field and indicates that no credits\n\
    \      are saved.\n   Maximum Transmission Rate\n      The maximum transmission\
    \ rate limits how fast packets may be sent\n      back to back from the host.\
    \  Consider that if the token bucket is\n      full, it is possible for the flow\
    \ to send a series of back-to-back\n      packets equal to the size of the token\
    \ bucket.  If the token\n      bucket size is large, this back-to-back run may\
    \ be long enough to\n      significantly inhibit multiplexing.\n      To limit\
    \ this effect, the maximum transmission rate bounds how\n      fast successive\
    \ packets may be placed on the network.\n      One can think of the maximum transmission\
    \ rate control as being a\n      form of a leaky bucket.  When a packet is sent,\
    \ a number of\n      credits equal to the size of the packet is placed into an\
    \ empty\n      bucket, which drains credits at the maximum transmission rate.\
    \  No\n      more packets may be sent until the bucket has emptied again.\n  \
    \    The maximum transmission rate is the rate at which the bucket is\n      emptied.\
    \  The field is in the general field format and indicates\n      the size of the\
    \ bucket in bytes.  The value must be a number and\n      must be greater than\
    \ or equal to the token bucket rate.\n      Note that the MTU size can be used\
    \ in conjunction with the maximum\n      transmission rate to bound how long an\
    \ individual packet blocks\n      other transmissions.  The MTU specifies the\
    \ maximum time an\n      individual packet may take.  The Maximum Transmission\
    \ Rate, limits\n      the frequency with which packets may be placed on the network.\n\
    \   Minimum Delay Noticed\n      The minimum delay noticed field tells the internetwork\
    \ that the\n      host and application are effectively insensitive to improvements\n\
    \      in end-to-end delay below this value.  The network is encouraged\n    \
    \  to drive the delay down to this value but need not try to improve\n      the\
    \ delay further.\n      The field is in the general field format.\n      If expressed\
    \ as a number it is the number of microseconds of delay\n      below which the\
    \ host and application do not care about\n      improvements.  Human users only\
    \ care about delays in the\n      millisecond range but some applications will\
    \ be computer to\n      computer and computers now have clock times measured in\
    \ a handful\n      of nanoseconds.  For such computers, microseconds are an\n\
    \      appreciable time.  For this reason, this field measures in\n      microseconds,\
    \ even though that may seem small.\n      If expressed as a well-known constant\
    \ (first bit set), two field\n      values are accepted:\n         0 - the application\
    \ is not sensitive to delay\n         1 - the application is moderately delay\
    \ sensitive\n             e.g., avoid satellite links where possible).\n   Maximum\
    \ Delay Variation\n      If a receiving application requires data to be delivered\
    \ in the\n      same pattern that the data was transmitted, it may be necessary\n\
    \      for the receiving host to briefly buffer data as it is received so\n  \
    \    that the receiver can restore the old transmission pattern.  (An\n      easy\
    \ example of this is a case where an application wishes to send\n      and transmit\
    \ data such as voice samples, which are generated and\n      played at regular\
    \ intervals.  The regular intervals may be\n      distorted by queueing effects\
    \ in the network and the receiver may\n      have to restore the regular spacing.)\n\
    \      The amount of buffer space that the receiving host is willing to\n    \
    \  provide determines the amount of variation in delay permitted for\n      individual\
    \ packets within a given flow.  The maximum delay\n      variation field makes\
    \ it possible to tell the network how much\n      variation is permitted.  (Implementors\
    \ should note that the\n      restrictions on the maximum transmission rate may\
    \ cause data\n      traffic patterns to be distorted before they are placed on\
    \ the\n      network, and that this distortion must be accounted for in\n    \
    \  determining the receiver buffer size.)\n      The field is in the general field\
    \ format and must be a number.  It\n      is the difference, in microseconds,\
    \ between the maximum and\n      minimum possible delay that a packet will experience.\
    \  (There is\n      some question about whether microsecond units are too large.\
    \  At a\n      terabit per second, one microsecond is a megabit.  Presumably if\
    \ a\n      host is willing to receive data at terabit speeds it is willing to\n\
    \      provide megabits of buffer space.)\n      The value of 0, meaning the receiving\
    \ host will not buffer out\n      delays, is acceptable but the receiving host\
    \ must still have\n      enough buffer space to receive a maximum transmission\
    \ unit sized\n      packet from the sending host.  Note that it is expected that\
    \ a\n      value of 0 will make it unlikely that a flow can be established.\n\
    \   Loss Sensitivity\n      This field indicates how sensitive the flow's traffic\
    \ is to\n      losses.  Loss sensitivity can be expressed in one of two ways:\n\
    \      either as a number of losses of MTU-sized packets in an interval,\n   \
    \   or simply as a value indicating a level of sensitivity.\n      The field is\
    \ in the general field format.\n      If the value is a number, then the value\
    \ is the number of MTU-\n      sized packets that may be lost out of the number\
    \ of MTU-sized\n      packets listed in the Loss Interval field.\n      If the\
    \ value is a well-known constant, then one of two values is\n      permitted:\n\
    \         0 - the flow is insensitive to loss\n         1 - the flow is sensitive\
    \ to loss (where possible\n             choose the path with the lowest loss rate).\n\
    \   Burst Loss Sensitivity\n      This field states how sensitive the flow is\
    \ to losses of\n      consecutive packets.  The field enumerates the maximum number\
    \ of\n      consecutive MTU-sized packets that may be lost.\n      The field is\
    \ in the general field format.\n      If the value is a number, then the value\
    \ is the number of\n      consecutive MTU-sized packets that may be lost.\n  \
    \    If the value is a well-known constant, then the value 0 indicates\n     \
    \ that the flow is insensitive to burst loss.\n      Note that it is permissible\
    \ to set the loss sensitivity field to\n      simply indicate sensitivity to loss,\
    \ and set a numerical limit on\n      the number of consecutive packets that can\
    \ be lost.\n   Loss Interval\n      This field determines the period over which\
    \ the maximum number of\n      losses per interval are measured.  In other words,\
    \ given any\n      arbitrarily chosen interval of this length, the number of losses\n\
    \      may not exceed the number in the Loss Sensitivity field.\n      The field\
    \ is in the general field format.\n      If the Loss Sensitivity field is a number,\
    \ then this field must\n      also be a number and must indicate the number of\
    \ MTU-sized packets\n      which constitutes a loss interval.\n      If the Loss\
    \ Sensitivity field is not a number (i.e., is a well-\n      known constant) then\
    \ this field must use the well-known constant\n      of 0 (i.e., first bit set,\
    \ all other bits 0) indicating that no\n      loss interval is defined.\n   Quality\
    \ of Guarantee\n      It is expected that the internetwork will likely have to\
    \ offer\n      more than one type of guarantee.\n      There are two unrelated\
    \ issues related to guarantees.\n      First, it may not be possible for the internetwork\
    \ to make a firm\n      guarantee.  Consider a path through an internetwork in\
    \ which the\n      last hop is an Ethernet.  Experience has shown (e.g., some\
    \ of the\n      IETF conferencing experiments) that an Ethernet can often give\n\
    \      acceptable performance, but clearly the internetwork cannot\n      guarantee\
    \ that the Ethernet will not saturate at some time during\n      a flow's lifetime.\
    \  Thus it must be possible to distinguish\n      between flows which cannot tolerate\
    \ the small possibility of a\n      failure (and thus must guaranteed at every\
    \ hop in the path) and\n      those that can tolerate islands of uncertainty.\n\
    \      Second, there is some preliminary work (see [2]) that suggests\n      that\
    \ some applications will be able to adapt to modest variations\n      in internetwork\
    \ performance and that network designers can exploit\n      this flexibility to\
    \ allow better network utilization.  In this\n      model, the internetwork would\
    \ be allowed to deviate slightly from\n      the promised flow parameters during\
    \ periods of load.  This class\n      of service is called predicted service (to\
    \ distinguish it from\n      guaranteed service).\n      The difference between\
    \ predicted service and service which cannot\n      be perfectly guaranteed (e.g.,\
    \ the Ethernet example mentioned\n      above) is that the imperfect guarantee\
    \ makes no statistical\n      promises about how it might mis-behave.  In the\
    \ worst case, the\n      imperfect guarantee will not work at all, whereas predicted\n\
    \      service will give slightly degraded service.  Note too that\n      predicted\
    \ service assumes that the routers and links in a path all\n      cooperate (to\
    \ some degree) whereas an imperfect guarantee states\n      that some routers\
    \ or links will not cooperate.\n      The field is a 16-bit field in Internet\
    \ byte order.  There are six\n      legal values:\n         0 - no guarantee is\
    \ required (the host is simply expressing\n             desired performance for\
    \ the flow)\n         100 (hex) - an imperfect guarantee is requested.\n     \
    \    200 (hex) - predicted service is requested and if unavailable,\n        \
    \             then no flow should be established.\n         201 (hex) - predicted\
    \ service is requested but an imperfect\n                     guarantee is acceptable.\n\
    \         300 (hex) - guaranteed service is requested and if a firm\n        \
    \             guarantee cannot be given, then no flow should be\n            \
    \         established.\n         301 (hex) - guaranteed service is request and\
    \ but an imperfect\n                     guarantee is acceptable.\n      It is\
    \ expected that asking for predicted service or permitting an\n      imperfect\
    \ guarantee will substantially increase the chance that a\n      flow request\
    \ will be accepted.\n"
- title: Possible Limitations in the Proposed Flow Spec
  contents:
  - "Possible Limitations in the Proposed Flow Spec\n   There are at least three places\
    \ where the flow spec is arguably\n   imperfect, based on what we currently know\
    \ about flow reservation.\n   In addition, since this is a first attempt at a\
    \ flow spec, readers\n   should expect modifications as we learn more.\n   First,\
    \ the loss model is not perfect.  Simply stating that an\n   application is sensitive\
    \ to loss and to burst loss is a rather crude\n   indication of sensitivity. \
    \ However, explicitly enumerating loss\n   requirements within a cycle is also\
    \ an imperfect mechanism.  The key\n   problem with the explicit values is that\
    \ not all packets sent over a\n   flow will be a full MTU in size.  Expressed\
    \ another way, the current\n   flow spec expects that an MTU-sized packet will\
    \ be the unit of error\n   recovery.  If flows send packets in a range of sizes,\
    \ then the loss\n   bounds may not be very useful.  However, the thought of allowing\
    \ a\n   flow to request a set of loss models (one per packet size) is\n   sufficiently\
    \ painful that I've limited the flow to one loss profile.\n   Further study of\
    \ loss models is clearly needed.\n   Second, the minimum delay sensitivity field\
    \ limits a flow to stating\n   that there is one point on a performance sensitivity\
    \ curve below\n   which the flow is no longer interested in improved performance.\
    \  It\n   may be that a single point is insufficient to fully express a flow's\n\
    \   sensitivity.  For example, consider a flow for supporting part of a\n   two-way\
    \ voice conversation.  Human users will notice improvements in\n   delay down\
    \ to a few 10s of milliseconds.  However, the key point of\n   sensitivity is\
    \ the delay at which normal conversation begins to\n   become awkward (about 100\
    \ milliseconds).  By allowing only one\n   sensitivity point, the flow spec forces\
    \ the flow designer to either\n   ask for the best possible delay (e.g, a few\
    \ 10's of ms) to try to get\n   maximum performance from the network, or state\
    \ a sensitivity of about\n   95 ms, and accept the possibility that the internetwork\
    \ will not try\n   to improve delay below that value, even if it could (and even\
    \ though\n   the user would notice the improvement).  My expectation is that a\n\
    \   simple point is likely to be easier to deal with than attempting to\n   enumerate\
    \ two (or three or four) points in the sensitivity curve.\n   Third, the models\
    \ for service guarantees is still evolving and it is\n   by no means clear that\
    \ the service choices provided are the correct\n   set.\n"
- title: How an Internetwork is Expected to Handle a Flow Spec
  contents:
  - "How an Internetwork is Expected to Handle a Flow Spec\n   There are at least\
    \ two parts to the issue of how an internetwork is\n   expected to handle a flow\
    \ spec.  The first part deals with how the\n   flow spec is interpreted so that\
    \ the internetwork can find a route\n   which will allow the internetwork to match\
    \ the flow's requirements.\n   The second part deals with how the network replies\
    \ to the host's\n   request.\n   The precise mechanism for setting up a flow,\
    \ given a flow spec, is a\n   large topic and beyond the scope of this memo. \
    \ The purpose of the\n   next few paragraphs is simply to sketch an argument that\
    \ this flow\n   spec is sufficient to the requirements of the setup mechanisms\
    \ known\n   to the author.\n   The key problem in setting up a flow is determining\
    \ if there exist\n   one or more routes from the source to the destination(s)\
    \ which might\n   be able to support the quality of service requested.  Once one\
    \ has a\n   route (or set of candidate routes) one can take whatever actions may\n\
    \   be appropriate to confirm that the route is actually viable and to\n   cause\
    \ the flow's data to follow that route.\n   There are a number of ways to find\
    \ a route.  One might try to build a\n   route on the fly by establishing the\
    \ flow hop-by-hop (as ST-II does)\n   or one might consult a route server which\
    \ provides a set of candidate\n   source routes derived from a routing database.\
    \  However, whatever\n   system is used, some basic information about the flow\
    \ needs to be\n   provided to the routing system.  This information is:\n    \
    \  * How much bandwidth the flow may require.  There's no point\n        in routing\
    \ a flow that expects to send at over 10 megabits per\n        second via a T1\
    \ (1.5 megabit per second) link.\n      * How delay sensitive the application\
    \ is.  One does not wish\n        to route a delay-sensitive application over\
    \ a satellite link,\n        unless the satellite link is the only possible route\
    \ from here\n        to there.\n      * How much error can be tolerated.  Can\
    \ we send this flow over\n        our microwave channel on a rainy day or is a\
    \ more reliable link\n        required?\n      * How firm the guarantees need\
    \ to be.  Can we put an Ethernet\n        in as one of the hops?\n      * How\
    \ much delay variation is tolerated.  Again, can an Ethernet\n        be included\
    \ in the path?  Does the routing system need to worry\n        if the addition\
    \ of this flow will cause a few routers to run\n        at close to capacity?\
    \  (A side note: we assume that the routers\n        are running with priority\
    \ queueing systems, so running the router\n        close to capacity doesn't mean\
    \ that all flows get long and\n        variable delays.  Rather, running close\
    \ to capacity means that\n        high priority flows will be unaffected, and\
    \ low priority flows\n        will get hit with a lot of delay and variation.)\n\
    \   The flow spec provides all of this information.  So it seems\n   plausible\
    \ to assume it provides enough information to make routing\n   decisions at setup\
    \ time.\n   The flow spec was designed with the expectation that the network\n\
    \   would give a yes or no reply to a request for a guaranteed flow.\n   Some\
    \ researchers have suggested that the negotiation to set up a flow\n   might be\
    \ an extended negotiation, in which the requesting host\n   initially requests\
    \ the best possible flow it could desire and then\n   haggles with the network\
    \ until they agree on a flow with properties\n   that the network can actually\
    \ provide and the application still finds\n   useful.  This notion bothers me\
    \ for at least two reasons.  First, it\n   means setting up a flow is a potentially\
    \ long process.  Second, the\n   general problem of finding all possible routes\
    \ with a given set of\n   properties is a version of the traveling salesman problem,\
    \ and I\n   don't want to embed traveling salesman algorithms into a network's\n\
    \   routing system.\n   The model used in designing this flow spec was that a\
    \ system would\n   ask for the minimum level of service that was deemed acceptable\
    \ and\n   the network would try to find a route that met that level of service.\n\
    \   If the network is unable to achieve the desired level of service, it\n   refuses\
    \ the flow, otherwise it accepts the flow.\n"
- title: The Flow Spec as a Return Value
  contents:
  - "The Flow Spec as a Return Value\n   This memo does not specify the data structures\
    \ that the network uses\n   to accept or reject a flow.  However, the flow spec\
    \ has been designed\n   so that it can be used to return the type of service being\n\
    \   guaranteed.\n   If the request is being accepted, the minimum delay field\
    \ could be\n   set to the guaranteed or predicted delay, and the quality of\n\
    \   guarantee field could be set to no guarantee (0), imperfect guarantee\n  \
    \ (100 hex), predicted service (200 hex), or guaranteed service (300\n   hex).\n\
    \   If the request is being rejected, the flow spec could be modified to\n   indicate\
    \ what type of flow the network believes it could accept e.g.,\n   the traffic\
    \ shape or delay characteristics could be adjusted or the\n   type of guarantee\
    \ lowered).  Note that this returned flow spec would\n   likely be a hint, not\
    \ a promised offer of service.\n"
- title: Why Type of Service is not Good Enough
  contents:
  - "Why Type of Service is not Good Enough\n   The flow spec proposed in this memo\
    \ takes the form of a set of\n   parameters describing the properties and requirements\
    \ of the flow.\n   An alternative approach which is sometimes mentioned (and which\
    \ is\n   currently incorporated into IP) is to use a Type of Service (TOS)\n \
    \  value.\n   The TOS value is an integer (or bit pattern) whose values have been\n\
    \   predefined to represent requested quality of services.  Thus, a TOS\n   of\
    \ 47 might request service for a flow using up to 1 gigabit per\n   second of\
    \ bandwidth with a minimum delay sensitivity of 100\n   milliseconds.\n   TOS\
    \ schemes work well if the different quality of services that may\n   be requested\
    \ are both enumerable and reasonably small.\n   Unfortunately, these conditions\
    \ do not appear to apply to future\n   internetworks.  The range of possible bandwidth\
    \ requests alone is\n   huge.  Combine this range with several gradations of delay\n\
    \   requirements, and widely different sensitivities to errors and the\n   set\
    \ of TOS values required becomes extremely large.  (At least one\n   person has\
    \ suggested to the author that perhaps a TOS field combined\n   with a bandwidth\
    \ parameter might be appropriate.  In other words, a\n   two parameter model.\
    \  That's a tempting idea but my gut feeling is\n   that it is not quite sufficient\
    \ so I'm proposing a more complete\n   parametric model.)\n   Another reason to\
    \ prefer parametric service is optimization issues.\n   A key issue in flow setup\
    \ is trying to design the the routing system\n   to optimize its management of\
    \ flows.  One can optimize on a number of\n   criteria.  A good example of an\
    \ optimization problem is the following\n   question (expressed by Isidro Castineyra\
    \ of BBN):\n     \"Given a request to establish a flow, how can the internetwork\n\
    \     accept that request in such a way as to maximize the chance that\n     the\
    \ internetwork will also be able to accept the next flow\n     request?\"\n  \
    \ The optimization goal here is call-completion - maximizing the chance\n   that\
    \ requests to establish flows will succeed.  One might\n   alternatively try to\
    \ maximize revenue (if one is charging for flows).\n   The internetwork is presumably\
    \ in a better position to do\n   optimizations if it has more information about\
    \ the flow's expected\n   behavior.  For example, if a TOS system says only that\
    \ a flow is\n   delay sensitive, the routing system must seek out the most direct\n\
    \   route for the flow.  But if the routing system is told that the flow\n   is\
    \ sensitive only to delays over 100 milliseconds, there may be a\n   number of\
    \ routes other than the most direct route which can satisfy\n   this delay, thus\
    \ leaving the most direct route available for a later\n   flow which needs a far\
    \ lower delay.\n   In fairness, it should be noted that a danger of a parametric\
    \ model\n   is that it is very easy to have too many parameters.  The yearn to\n\
    \   optimize can be overdone.  The goal of this flow spec is to enumerate\n  \
    \ just enough parameters that it appears that essential needs can be\n   expressed,\
    \ and the internetwork has some information it can use to\n   try to manage the\
    \ flows.  Features that would simply be nice or\n   useful to have (but not essential)\
    \ are left out to keep the parameter\n   space small.\n"
- title: An Implication of the Flow Spec
  contents:
  - "An Implication of the Flow Spec\n   It is important to observe that the there\
    \ are fields in the flow spec\n   that are based on information from the sender\
    \ (such as rate\n   information) and fields in the flow spec that are based on\n\
    \   information from the receiver (such as delay variation).  There are\n   also\
    \ fields that may sender and receiver to negotiate in advance.\n   For example,\
    \ the acceptable loss rate may depend on whether the\n   sender and receiver both\
    \ support the same type of forward error\n   correction.  The delay sensitivity\
    \ for a voice connection may depend,\n   in part, on whether both sender and receiver\
    \ support echo cancelling.\n   The implication is that the internetwork must permit\
    \ the sender and\n   receiver to communicate in advance of setting up a flow,\
    \ because a\n   flow spec can only be defined once both sender and receiver have\
    \ had\n   their say.  In other words, a reserved flow should not be the only\n\
    \   form of communication.   There must be some mechanism to perform a\n   short\
    \ exchange of messages in preparation for setting up a flow.\n   (Another aside:\
    \ it has been suggested that perhaps the solution to\n   this problem is to have\
    \ the sender establish a flow with an\n   incomplete flow spec, and when the receiver\
    \ gets the flow spec, have\n   the receiver send the completed flow spec back\
    \ along the flow, so the\n   internetwork can \"revise\" the flow spec according\
    \ to the receiver's\n   desires.  I have two problems with this approach.  First,\
    \ it is\n   entirely possible that the receiver's information may lead the\n \
    \  internetwork to conclude that the flow established by the sender is\n   no\
    \ good.  For example, the receiver may indicate it has a smaller\n   tolerance\
    \ for delay variation than expected and force the flow to be\n   rerouted over\
    \ a completely different path.  Second, if we try to\n   avoid having the receiver's\
    \ information cause the flow to fail, then\n   we have to over-allocate the flow's\
    \ during the preliminary setup.\n   But over allocating the resources requested\
    \ may lead us to choose\n   better quality paths than we need for this flow. \
    \ In other words, our\n   attempts to optimize use of the network will fail.)\n"
- title: Advance Reservations and Flow Duration
  contents:
  - "Advance Reservations and Flow Duration\n   The primary purpose of a flow specification\
    \ is to provide information\n   to the internetwork so the internetwork can properly\
    \ manage the\n   proposed flow's traffic in the context of other traffic in the\n\
    \   internetwork.  One question is whether the flow should give the\n   network\
    \ information about when the flow is expected to start and how\n   long the flow\
    \ is expected to last.\n   Announcing when a flow will start is generally of interest\
    \ for\n   advance reservations.  (If the flow is not be reserved substantially\n\
    \   in advance, the presentation of the flow spec to the internetwork can\n  \
    \ be taken as an implicit request for a flow, now.)  It is my view that\n   advance\
    \ reservation is a distinct problem from the describing the\n   properties of\
    \ a flow.  Advanced reservations will require some\n   mechanism to maintain information\
    \ in the network about flows which\n   are not currently active but are expected\
    \ to be activated at some\n   time in the future.  I anticipate this will require\
    \ some sort of\n   distributed database to ensure that information about advanced\n\
    \   reservations is not accidentally lost if parts of the internetwork\n   crash.\
    \  In other words, advance reservations will require\n   considerable additional\
    \ supporting baggage that it would probably be\n   better to keep out of the average\
    \ flow spec.\n   Deciding whether a flow spec should contain information about\
    \ how\n   long the flow is expected to run is a harder decision to make.\n   Clearly\
    \ if we anticipate that the internetwork will support advance\n   reservations,\
    \ it will be necessary for elements of the internetwork\n   to predict their traffic\
    \ load, so they can ensure that advance\n   reservations are not compromised by\
    \ new flow requests.  However,\n   there is a school of thought that believes\
    \ that estimating future\n   load from current behavior of existing flows is more\
    \ accurate than\n   anything the flows may have declared in their flow specs.\
    \  For this\n   reason, I've left a duration field out of the flow spec.\n"
- title: Examples
  contents:
  - "Examples\n   To illustrate how the flow spec values might be used, this section\n\
    \   presents three example flow specs.\n   Telnet\n      For the first example,\
    \ consider using the flow spec to request\n      service for an existing application:\
    \ Telnet.  Telnet is a virtual\n      terminal protocol, and one can think of\
    \ it as stringing a virtual\n      wire across the network between the user's\
    \ terminal and a remote\n      host.\n      Telnet has proved a very successful\
    \ application without a need to\n      reserve bandwidth: the amount of data sent\
    \ over any Telnet\n      connection tends to be quite small.  However, Telnet\
    \ users are\n      often quite sensitive to delay, because delay can affect the\
    \ time\n      it takes to echo characters.  This suggests that a Telnet\n    \
    \  connection might benefit from asking the internetwork to avoid\n      long\
    \ delay paths.  It could so so using the following flow spec\n      (for both\
    \ directions):\n      Version=1\n      MTU=80 [40 bytes of overhead + 40 bytes\
    \ user data]\n      Token Bucket Rate=0/0/0 [don't want a guarantee]\n      Token\
    \ Bucket Size=0/0/0\n      Maximum Transmission Rate=0/0/0\n      Maximum Delay\
    \ Noticed=1/1 [constant = delay sensitive]\n      Maximum Delay Variation=0/0/0\
    \ [not a concern]\n      Loss Sensitivity=1/0 [don't worry about loss]\n     \
    \ Burst Loss Sensitivity=1/0\n      Loss Interval=1/0\n      Quality of Guarantee=1/0\
    \ [just asking]\n      It is worth noting that Telnet's flow spec is likely to\
    \ be the\n      same for all instantiations of a Telnet connection.  As a result,\n\
    \      there may be some optimizations possible (such as just tagging\n      Telnet\
    \ packets as being subject to the well-known Telnet flow\n      spec).\n   A Voice\
    \ Flow\n      Now consider transmitting voice over the Internet.  Currently,\n\
    \      good quality voice can be delivered at rates of 32Kbit/s or\n      16Kbit/s.\
    \  Assuming the rate is 32Kbit/s and voice samples are 16\n      bit samples packaged\
    \ into UDP datagrams (for a data rate of about\n      60 Kbyte/s), a flow spec\
    \ might be:\n      Version=1\n      MTU=30 [2 byte sample in UDP datagram]\n \
    \     Token Bucket Rate=0/10/59 [60.4 Kbytes/s]\n      Token Bucket Size=0/0/30\
    \ [save enough to send immediately\n                                after pauses]\n\
    \      Maximum Transmission Rate=0/10/59 [peak same as mean]\n      Maximum Delay\
    \ Noticed=0/10/100 [100 ms]\n      Maximum Delay Variation=0/10/10 [keep variation\
    \ low]\n      Loss Sensitivity=1/1 [loss sensitive]\n      Burst Loss Sensitivity=0/0/5\
    \ [keep bursts small]\n      Loss Interval=1/0\n      Quality of Guarantee=1/201\
    \ [predicted service and I'll accept\n                                  worse]\n\
    \   A Variable Bit-Rate Video Flow\n      Variable bit-rate video transmissions\
    \ vary the rate at which they\n      send data according to the amount of the\
    \ video image that has\n      changed between frames.  In this example, we consider\
    \ a one-way\n      broadcast of a picture.  If we assume 30 frames a second and\
    \ that\n      a full frame is about 1 megabit of data, and that on average about\n\
    \      10% of the frame changes, but in the worst case the entire frame\n    \
    \  changes, the flow spec might be:\n      Version=1\n      MTU=4096 [big so we\
    \ can put lots of bits in each packet]\n      Token Bucket Rate=0/20/1 [8 Mbits/s]\n\
    \      Token Bucket Size=0/17/2 [2 Mbits/s]\n      Maximum Transmission Rate=0/20/30\
    \ [30 Mbits/s]\n      Maximum Delay Noticed=1/1 [somewhat delay sensitive]\n \
    \     Maximum Delay Variation=0/10/1 [no more than one second of\n           \
    \                           buffering]\n      Loss Sensitivity=0/0/1 [worst case,\
    \ one loss per frame]\n      Burst Loss Sensitivity=0/0/1 [no burst errors please]\n\
    \      Loss Interval=0/0/33 [one frame in MTU sized packets]\n      Quality of\
    \ Guarantee=1/300 [guaranteed service only]\n      The token bucket is sized to\
    \ be two frames of data, and the bucket\n      rate will fill the bucket every\
    \ 250 ms.  The expectation is that\n      full scene changes will be rare and\
    \ that a fast rate with a large\n      bucket size should accommodate even a series\
    \ of scene changes.\n   Disclaimer\n      In all cases, these examples are simply\
    \ to sketch the use of the\n      flow spec.  The author makes no claims that\
    \ the actual values used\n      are the correct ones for a particular application.\n"
- title: Security Considerations
  contents:
  - "Security Considerations\n   Security considerations definitely exist.  For example,\
    \ one might\n   assume that users are charged for guaranteed flows.  In that case,\n\
    \   some mechanism must exist to ensure that a flow request (including\n   flow\
    \ spec) is authenticated.  However I believe that such issues have\n   to be dealt\
    \ with as part of designing a negotiation protocol, and are\n   not part of designing\
    \ the flow spec data structure.\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   I'd like to acknowledge the tremendous assistance of Steve\
    \ Deering,\n   Scott Shenker and Lixia Zhang of XEROX PARC in writing this RFC.\n\
    \   Much of this flow spec was sketched out in two long meetings with\n   them\
    \ at PARC.  Others who have offered notable advice and comments\n   include Isidro\
    \ Castineyra, Deborah Estrin, and members of the End-\n   to-End Research Group\
    \ chaired by Bob Braden.  All ideas that prove\n   misbegotten are the sole responsibility\
    \ of the author.  This work was\n   funded under DARPA Contract No. MDA903-91-D-0019.\
    \  The views\n   expressed in this document are not necessarily those of the Defense\n\
    \   Advanced Research Projects Agency.\n"
- title: References
  contents:
  - "References\n   1. Parekh, A., \"A Generalized Processor Sharing Approach\n  \
    \    to Flow Control in Integrated Services Networks\",\n      MIT Laboratory\
    \ for Information and Decision Systems,\n      Report No. LIDS-TH-2089.\n   2.\
    \ Clark, D., Shenker, S., and L. Zhang, \"Supporting Real-Time\n      Applications\
    \ in an Integrated Services Packet Network:\n      Architecture and Mechanism\"\
    , Proceedings of ACM SIGCOMM '92,\n      August 1992.\n"
- title: Author's Address
  contents:
  - "Author's Address\n   Craig Partridge\n   BBN\n   824 Kipling St\n   Palo Alto,\
    \ CA  94301\n   Phone: 415-325-4541\n   EMail: craig@aland.bbn.com\n"
