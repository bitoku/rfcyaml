- title: __initial_text__
  contents:
  - '                       Internet Security Glossary

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2000).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This Glossary (191 pages of definitions and 13 pages of references)\n\
    \   provides abbreviations, explanations, and recommendations for use of\n   information\
    \ system security terminology. The intent is to improve the\n   comprehensibility\
    \ of writing that deals with Internet security,\n   particularly Internet Standards\
    \ documents (ISDs). To avoid confusion,\n   ISDs should use the same term or definition\
    \ whenever the same concept\n   is mentioned. To improve international understanding,\
    \ ISDs should use\n   terms in their plainest, dictionary sense. ISDs should use\
    \ terms\n   established in standards documents and other well-founded\n   publications\
    \ and should avoid substituting private or newly made-up\n   terms. ISDs should\
    \ avoid terms that are proprietary or otherwise\n   favor a particular vendor,\
    \ or that create a bias toward a particular\n   security technology or mechanism\
    \ versus other, competing techniques\n   that already exist or might be developed\
    \ in the future.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   2\n   2. Explanation of Paragraph Markings  . . . . . . . . . .\
    \ . . . .   4\n      2.1 Recommended Terms with an Internet Basis (\"I\") . .\
    \ . . . .   4\n      2.2 Recommended Terms with a Non-Internet Basis (\"N\") \
    \ . . . .   5\n      2.3 Other Definitions (\"O\")  . . . . . . . . . . . . .\
    \ . . . .   5\n      2.4 Deprecated Terms, Definitions, and Uses (\"D\")  . .\
    \ . . . .   6\n      2.5 Commentary and Additional Guidance (\"C\") . . . . .\
    \ . . . .   6\n   3. Definitions  . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .   6\n   4. References . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . 197\n   5. Security Considerations  . . . . . . . . . . . . . . . . . .\
    \ . 211\n   6. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . .\
    \ 211\n   7. Author's Address . . . . . . . . . . . . . . . . . . . . . . . 211\n\
    \   8. Full Copyright Statement . . . . . . . . . . . . . . . . . . . 212\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   This Glossary provides an internally consistent, complementary\
    \ set of\n   abbreviations, definitions, explanations, and recommendations for\
    \ use\n   of terminology related to information system security. The intent of\n\
    \   this Glossary is to improve the comprehensibility of Internet\n   Standards\
    \ documents (ISDs)--i.e., RFCs, Internet-Drafts, and other\n   material produced\
    \ as part of the Internet Standards Process [R2026]--\n   and of all other Internet\
    \ material, too. Some non-security terms are\n   included to make the Glossary\
    \ self-contained, but more complete lists\n   of networking terms are available\
    \ elsewhere [R1208, R1983].\n   Some glossaries (e.g., [Raym]) list terms that\
    \ are not listed here\n   but could be applied to Internet security. However,\
    \ those terms have\n   not been included in this Glossary because they are not\
    \ appropriate\n   for ISDs.\n   This Glossary marks terms and definitions as being\
    \ either endorsed or\n   deprecated for use in ISDs, but this Glossary is not\
    \ an Internet\n   standard. The key words \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\"\
    , \"MAY\",\n   and \"OPTIONAL\" are intended to be interpreted the same way as\
    \ in an\n   Internet Standard [R2119], but this guidance represents only the\n\
    \   recommendations of this author. However, this Glossary includes\n   reasons\
    \ for the recommendations--particularly for the SHOULD NOTs--so\n   that readers\
    \ can judge for themselves whether to follow the\n   recommendations.\n   This\
    \ Glossary supports the goals of the Internet Standards Process:\n   o Clear,\
    \ Concise, and Easily Understood Documentation\n      This Glossary seeks to improve\
    \ comprehensibility of security-\n      related content of ISDs. That requires\
    \ wording to be clear and\n      understandable, and requires the set of security-related\
    \ terms and\n      definitions to be consistent and self-supporting. Also, the\n\
    \      terminology needs to be uniform across all ISDs; i.e., the same\n     \
    \ term or definition needs to be used whenever and wherever the same\n      concept\
    \ is mentioned. Harmonization of existing ISDs need not be\n      done immediately,\
    \ but it is desirable to correct and standardize\n      the terminology when new\
    \ versions are issued in the normal course\n      of standards development and\
    \ evolution.\n   o Technical Excellence\n      Just as Internet Standard (STD)\
    \ protocols should operate\n      effectively, ISDs should use terminology accurately,\
    \ precisely,\n      and unambiguously to enable Internet Standards to be implemented\n\
    \      correctly.\n   o Prior Implementation and Testing\n      Just as STD protocols\
    \ require demonstrated experience and\n      stability before adoption, ISDs need\
    \ to use well-established\n      language. Using terms in their plainest, dictionary\
    \ sense (when\n      appropriate) helps to ensure international understanding.\
    \ ISDs\n      need to avoid using private, made-up terms in place of generally-\n\
    \      accepted terms from standards and other publications. ISDs need to\n  \
    \    avoid substituting new definitions that conflict with established\n     \
    \ ones. ISDs need to avoid using \"cute\" synonyms (e.g., see: Green\n      Book);\
    \ no matter how popular a nickname may be in one community,\n      it is likely\
    \ to cause confusion in another.\n   o Openness, Fairness, and Timeliness\n  \
    \    ISDs need to avoid terms that are proprietary or otherwise favor a\n    \
    \  particular vendor, or that create a bias toward a particular\n      security\
    \ technology or mechanism over other, competing techniques\n      that already\
    \ exist or might be developed in the future. The set of\n      terminology used\
    \ across the set of ISDs needs to be flexible and\n      adaptable as the state\
    \ of Internet security art evolves.\n"
- title: 2. Explanation of Paragraph Markings
  contents:
  - "2. Explanation of Paragraph Markings\n   Section 3 marks terms and definitions\
    \ as follows:\n   o Capitalization: Only terms that are proper nouns are capitalized.\n\
    \   o Paragraph Marking: Definitions and explanations are stated in\n      paragraphs\
    \ that are marked as follows:\n      - \"I\" identifies a RECOMMENDED Internet\
    \ definition.\n      - \"N\" identifies a RECOMMENDED non-Internet definition.\n\
    \      - \"O\" identifies a definition that is not recommended as the first\n\
    \        choice for Internet documents but is something that authors of\n    \
    \    Internet documents need to know.\n      - \"D\" identifies a term or definition\
    \ that SHOULD NOT be used in\n        Internet documents.\n      - \"C\" identifies\
    \ commentary or additional usage guidance.\n   The rest of Section 2 further explains\
    \ these five markings.\n"
- title: 2.1 Recommended Terms with an Internet Basis ("I")
  contents:
  - "2.1 Recommended Terms with an Internet Basis (\"I\")\n   The paragraph marking\
    \ \"I\" (as opposed to \"O\") indicates a definition\n   that SHOULD be the first\
    \ choice for use in ISDs. Most terms and\n   definitions of this type MAY be used\
    \ in ISDs; however, some \"I\"\n   definitions are accompanied by a \"D\" paragraph\
    \ that recommends\n   against using the term. Also, some \"I\" definitions are\
    \ preceded by an\n   indication of a contextual usage limitation (e.g., see:\n\
    \   certification), and ISDs should not the term and definition outside\n   that\
    \ context\n   An \"I\" (as opposed to an \"N\") also indicates that the definition\
    \ has\n   an Internet basis. That is, either the Internet Standards Process is\n\
    \   authoritative for the term, or the term is sufficiently generic that\n   this\
    \ Glossary can freely state a definition without contradicting a\n   non-Internet\
    \ authority (e.g., see: attack).\n   Many terms with \"I\" definitions are proper\
    \ nouns (e.g., see:\n   Internet Protocol). For such terms, the \"I\" definition\
    \ is intended\n   only to provide basic information; the authoritative definition\
    \ is\n   found elsewhere.\n   For a proper noun identified as an \"Internet protocol\"\
    , please refer\n   to the current edition of \"Internet Official Protocol Standards\"\
    \ (STD\n   1) for the standardization state and status of the protocol.\n"
- title: 2.2 Recommended Terms with a Non-Internet Basis ("N")
  contents:
  - "2.2 Recommended Terms with a Non-Internet Basis (\"N\")\n   The paragraph marking\
    \ \"N\" (as opposed to \"O\") indicates a definition\n   that SHOULD be the first\
    \ choice for the term, if the term is used at\n   all in Internet documents. Terms\
    \ and definitions of this type MAY be\n   used in Internet documents (e.g., see:\
    \ X.509 public-key certificate).\n   However, an \"N\" (as opposed to an \"I\"\
    ) also indicates a definition\n   that has a non-Internet basis or origin. Many\
    \ such definitions are\n   preceded by an indication of a contextual usage limitation,\
    \ and this\n   Glossary's endorsement does not apply outside that context.  Also,\n\
    \   some contexts are rarely if ever expected to occur in a Internet\n   document\
    \ (e.g., see: baggage). In those cases, the listing exists to\n   make Internet\
    \ authors aware of the non-Internet usage so that they\n   can avoid conflicts\
    \ with non-Internet documents.\n   Many terms with \"N\" definitions are proper\
    \ nouns (e.g., see:\n   Computer Security Objects Register). For such terms, the\
    \ \"N\"\n   definition is intended only to provide basic information; the\n  \
    \ authoritative definition is found elsewhere.\n"
- title: 2.3 Other Definitions ("O")
  contents:
  - "2.3 Other Definitions (\"O\")\n   The paragraph marking \"O\" indicates a definition\
    \ that has a non-\n   Internet basis, but indicates that the definition SHOULD\
    \ NOT be used\n   in ISDs *except* in cases where the term is specifically identified\n\
    \   as non-Internet.\n   For example, an ISD might mention \"BCA\" (see: brand\
    \ certification\n   authority) or \"baggage\" as an example to illustrate some\
    \ concept; in\n   that case, the document should specifically say \"SET(trademark)\
    \ BCA\"\n   or \"SET(trademark) baggage\" and include the definition of the term.\n\
    \   For some terms that have a definition published by a non-Internet\n   authority--government\
    \ (see: object reuse), industry (see: Secure Data\n   Exchange), national (see:\
    \ Data Encryption Standard), or international\n   (see: data confidentiality)--this\
    \ Glossary marks the definition \"N\",\n   recommending its use in Internet documents.\
    \ In other cases, the non-\n   Internet definition of a term is inadequate or\
    \ inappropriate for\n   ISDs. For example, it may be narrow or outdated, or it\
    \ may need\n   clarification by substituting more careful or more explanatory\n\
    \   wording using other terms that are defined in this Glossary. In those\n  \
    \ cases, this Glossary marks the tern \"O\" and provides an \"I\"\n   definition\
    \ (or sometimes a different \"N\" definition), which precedes\n   and supersedes\
    \ the definition marked \"O\".\n   In most of the cases where this Glossary provides\
    \ a definition to\n   supersede one from a non-Internet standard, the substitute\
    \ is\n   intended to subsume the meaning of the superseded \"O\" definition and\n\
    \   not conflict with it. For the term \"security service\", for example,\n  \
    \ the \"O\" definition deals narrowly with only communication services\n   provided\
    \ by layers in the OSI model and is inadequate for the full\n   range of ISD usage;\
    \ the \"I\" definition can be used in more situations\n   and for more kinds of\
    \ service. However, the \"O\" definition is also\n   provided here so that ISD\
    \ authors will be aware of the context in\n   which the term is used more narrowly.\n\
    \   When making substitutions, this Glossary attempts to use\n   understandable\
    \ English that does not contradict any non-Internet\n   authority. Still, terminology\
    \ differs between the standards of the\n   American Bar Association, OSI, SET,\
    \ the U.S. Department of Defense,\n   and other authorities, and this Glossary\
    \ probably is not exactly\n   aligned with all of them.\n"
- title: 2.4 Deprecated Terms, Definitions, and Uses ("D")
  contents:
  - "2.4 Deprecated Terms, Definitions, and Uses (\"D\")\n   If this Glossary recommends\
    \ that a term or definition SHOULD NOT be\n   used in ISDs, then either the definition\
    \ has the paragraph marking\n   \"D\", or the restriction is stated in a \"D\"\
    \ paragraph that immediately\n   follows the term or definition.\n"
- title: 2.5 Commentary and Additional Guidance ("C")
  contents:
  - "2.5 Commentary and Additional Guidance (\"C\")\n   The paragraph marking \"C\"\
    \ identifies text that is advisory or\n   tutorial. This text MAY be reused in\
    \ other Internet documents.  This\n   text is not intended to be authoritative,\
    \ but is provided to clarify\n   the definitions and to enhance this Glossary\
    \ so that Internet\n   security novices can use it as a tutorial.\n"
- title: 3. Definitions
  contents:
  - "3. Definitions\n   Note: Each acronym or other abbreviation (except items of\
    \ common\n   English usage, such as \"e.g.\", \"etc.\", \"i.e.\", \"vol.\", \"\
    pp.\", \"U.S.\")\n   that is used in this Glossary, either in a definition or\
    \ as a subpart\n   of a defined term, is also defined in this Glossary.\n   $\
    \ 3DES\n      See: triple DES.\n   $ *-property\n      (N) (Pronounced \"star\
    \ property\".) See: \"confinement property\"\n      under Bell-LaPadula Model.\n\
    \   $ ABA Guidelines\n      (N) \"American Bar Association (ABA) Digital Signature\
    \ Guidelines\"\n      [ABA], a framework of legal principles for using digital\n\
    \      signatures and digital certificates in electronic commerce.\n   $ Abstract\
    \ Syntax Notation One (ASN.1)\n      (N) A standard for describing data objects.\
    \ [X680]\n      (C) OSI standards use ASN.1 to specify data formats for protocols.\n\
    \      OSI defines functionality in layers. Information objects at higher\n  \
    \    layers are abstractly defined to be implemented with objects at\n      lower\
    \ layers. A higher layer may define transfers of abstract\n      objects between\
    \ computers, and a lower layer may define transfers\n      concretely as strings\
    \ of bits. Syntax is needed to define abstract\n      objects, and encoding rules\
    \ are needed to transform between\n      abstract objects and bit strings. (See:\
    \ Basic Encoding Rules.)\n      (C) In ASN.1, formal names are written without\
    \ spaces, and\n      separate words in a name are indicated by capitalizing the\
    \ first\n      letter of each word except the first word. For example, the name\n\
    \      of a CRL is \"certificateRevocationList\".\n   $ ACC\n      See: access\
    \ control center.\n   $ access\n      (I) The ability and means to communicate\
    \ with or otherwise\n      interact with a system in order to use system resources\
    \ to either\n      handle information or gain knowledge of the information the\
    \ system\n      contains.\n      (O) \"A specific type of interaction between\
    \ a subject and an\n      object that results in the flow of information from\
    \ one to the\n      other.\" [NCS04]\n      (C) In this Glossary, \"access\" is\
    \ intended to cover any ability to\n      communicate with a system, including\
    \ one-way communication in\n      either direction. In actual practice, however,\
    \ entities outside a\n      security perimeter that can receive output from the\
    \ system but\n      cannot provide input or otherwise directly interact with the\n\
    \      system, might be treated as not having \"access\" and, therefore, be\n\
    \      exempt from security policy requirements, such as the need for a\n    \
    \  security clearance.\n   $ access control\n      (I) Protection of system resources\
    \ against unauthorized access; a\n      process by which use of system resources\
    \ is regulated according to\n      a security policy and is permitted by only\
    \ authorized entities\n      (users, programs, processes, or other systems) according\
    \ to that\n      policy. (See: access, access control service.)\n      (O) \"\
    The prevention of unauthorized use of a resource, including\n      the prevention\
    \ of use of a resource in an unauthorized manner.\"\n      [I7498 Part 2]\n  \
    \ $ access control center (ACC)\n      (I) A computer containing a database with\
    \ entries that define a\n      security policy for an access control service.\n\
    \      (C) An ACC is sometimes used in conjunction with a key center to\n    \
    \  implement access control in a key distribution system for\n      symmetric\
    \ cryptography.\n   $ access control list (ACL)\n      (I) A mechanism that implements\
    \ access control for a system\n      resource by enumerating the identities of\
    \ the system entities that\n      are permitted to access the resource. (See:\
    \ capability.)\n   $ access control service\n      (I) A security service that\
    \ protects against a system entity using\n      a system resource in a way not\
    \ authorized by the system's security\n      policy; in short, protection of system\
    \ resources against\n      unauthorized access. (See: access control, discretionary\
    \ access\n      control, identity-based security policy, mandatory access control,\n\
    \      rule-based security policy.)\n      (C) This service includes protecting\
    \ against use of a resource in\n      an unauthorized manner by an entity that\
    \ is authorized to use the\n      resource in some other manner. The two basic\
    \ mechanisms for\n      implementing this service are ACLs and tickets.\n   $\
    \ access mode\n      (I) A distinct type of data processing operation--e.g., read,\n\
    \      write, append, or execute--that a subject can potentially perform\n   \
    \   on an object in a computer system.\n   $ accountability\n      (I) The property\
    \ of a system (including all of its system\n      resources) that ensures that\
    \ the actions of a system entity may be\n      traced uniquely to that entity,\
    \ which can be held responsible for\n      its actions. (See: audit service.)\n\
    \      (C) Accountability permits detection and subsequent investigation\n   \
    \   of security breaches.\n   $ accredit\n   $ accreditation\n      (I) An administrative\
    \ declaration by a designated authority that\n      an information system is approved\
    \ to operate in a particular\n      security configuration with a prescribed set\
    \ of safeguards.\n      [FP102] (See: certification.)\n      (C) An accreditation\
    \ is usually based on a technical certification\n      of the system's security\
    \ mechanisms. The terms \"certification\" and\n      \"accreditation\" are used\
    \ more in the U.S. Department of Defense\n      and other government agencies\
    \ than in commercial organizations.\n      However, the concepts apply any place\
    \ where managers are required\n      to deal with and accept responsibility for\
    \ security risks. The\n      American Bar Association is developing accreditation\
    \ criteria for\n      CAs.\n   $ ACL\n      See: access control list.\n   $ acquirer\n\
    \      (N) SET usage: \"The financial institution that establishes an\n      account\
    \ with a merchant and processes payment card authorizations\n      and payments.\"\
    \ [SET1]\n      (O) \"The institution (or its agent) that acquires from the card\n\
    \      acceptor the financial data relating to the transaction and\n      initiates\
    \ that data into an interchange system.\" [SET2]\n   $ active attack\n      See:\
    \ (secondary definition under) attack.\n   $ active wiretapping\n      See: (secondary\
    \ definition under) wiretapping.\n   $ add-on security\n      (I) \"The retrofitting\
    \ of protection mechanisms, implemented by\n      hardware or software, after\
    \ the [automatic data processing] system\n      has become operational.\" [FP039]\n\
    \   $ administrative security\n      (I) Management procedures and constraints\
    \ to prevent unauthorized\n      access to a system. (See: security architecture.)\n\
    \      (O) \"The management constraints, operational procedures,\n      accountability\
    \ procedures, and supplemental controls established\n      to provide an acceptable\
    \ level of protection for sensitive data.\"\n      [FP039]\n      (C) Examples\
    \ include clear delineation and separation of duties,\n      and configuration\
    \ control.\n   $ Advanced Encryption Standard (AES)\n      (N) A future FIPS publication\
    \ being developed by NIST to succeed\n      DES. Intended to specify an unclassified,\
    \ publicly-disclosed,\n      symmetric encryption algorithm, available royalty-free\
    \ worldwide.\n   $ adversary\n      (I) An entity that attacks, or is a threat\
    \ to, a system.\n   $ aggregation\n      (I) A circumstance in which a collection\
    \ of information items is\n      required to be classified at a higher security\
    \ level than any of\n      the individual items that comprise it.\n   $ AH\n \
    \     See: Authentication Header\n   $ algorithm\n      (I) A finite set of step-by-step\
    \ instructions for a problem-\n      solving or computation procedure, especially\
    \ one that can be\n      implemented by a computer. (See: cryptographic algorithm.)\n\
    \   $ alias\n      (I) A name that an entity uses in place of its real name, usually\n\
    \      for the purpose of either anonymity or deception.\n   $ American National\
    \ Standards Institute (ANSI)\n      (N) A private, not-for-profit association\
    \ of users, manufacturers,\n      and other organizations, that administers U.S.\
    \ private sector\n      voluntary standards.\n      (C) ANSI is the sole U.S.\
    \ representative to the two major non-\n      treaty international standards organizations,\
    \ ISO and, via the\n      U.S. National Committee (USNC), the International Electrotechnical\n\
    \      Commission (IEC).\n   $ anonymous\n      (I) The condition of having a\
    \ name that is unknown or concealed.\n      (See: anonymous login.)\n      (C)\
    \ An application may require security services that maintain\n      anonymity\
    \ of users or other system entities, perhaps to preserve\n      their privacy\
    \ or hide them from attack. To hide an entity's real\n      name, an alias may\
    \ be used. For example, a financial institution\n      may assign an account number.\
    \ Parties to a transaction can thus\n      remain relatively anonymous, but can\
    \ also accept the transaction\n      as legitimate. Real names of the parties\
    \ cannot be easily\n      determined by observers of the transaction, but an authorized\n\
    \      third party may be able to map an alias to a real name, such as by\n  \
    \    presenting the institution with a court order. In other\n      applications,\
    \ anonymous entities may be completely untraceable.\n   $ anonymous login\n  \
    \    (I) An access control feature (or, rather, an access control\n      weakness)\
    \ in many Internet hosts that enables users to gain access\n      to general-purpose\
    \ or public services and resources on a host\n      (such as allowing any user\
    \ to transfer data using File Transfer\n      Protocol) without having a pre-established,\
    \ user-specific account\n      (i.e., user name and secret password).\n      (C)\
    \ This feature exposes a system to more threats than when all\n      the users\
    \ are known, pre-registered entities that are individually\n      accountable\
    \ for their actions. A user logs in using a special,\n      publicly known user\
    \ name (e.g., \"anonymous\", \"guest\", or \"ftp\").\n      To use the public\
    \ login name, the user is not required to know a\n      secret password and may\
    \ not be required to input anything at all\n      except the name. In other cases,\
    \ to complete the normal sequence\n      of steps in a login protocol, the system\
    \ may require the user to\n      input a matching, publicly known password (such\
    \ as \"anonymous\") or\n      may ask the user for an e-mail address or some other\
    \ arbitrary\n      character string.\n   $ APOP\n      See: POP3 APOP.\n   $ archive\n\
    \       (I) (1.) Noun: A collection of data that is stored for a\n      relatively\
    \ long period of time for historical and other purposes,\n      such as to support\
    \ audit service, availability service, or system\n      integrity service. (See:\
    \ backup.) (2.) Verb: To store data in such\n      a way. (See: back up.)\n  \
    \    (C) A digital signature may need to be verified many years after\n      the\
    \ signing occurs. The CA--the one that issued the certificate\n      containing\
    \ the public key needed to verify that signature--may not\n      stay in operation\
    \ that long. So every CA needs to provide for\n      long-term storage of the\
    \ information needed to verify the\n      signatures of those to whom it issues\
    \ certificates.\n   $ ARPANET\n      (N) Advanced Research Projects Agency Network,\
    \ a pioneer packet-\n      switched network that was built in the early 1970s\
    \ under contract\n      to the U.S. Government, led to the development of today's\n\
    \      Internet, and was decommissioned in June 1990.\n   $ ASN.1\n      See:\
    \ Abstract Syntax Notation One.\n   $ association\n      (I) A cooperative relationship\
    \ between system entities, usually\n      for the purpose of transferring information\
    \ between them. (See:\n      security association.)\n   $ assurance\n      (I)\
    \ (1.) An attribute of an information system that provides\n      grounds for\
    \ having confidence that the system operates such that\n      the system security\
    \ policy is enforced. (2.) A procedure that\n      ensures a system is developed\
    \ and operated as intended by the\n      system's security policy.\n   $ assurance\
    \ level\n      (I) Evaluation usage: A specific level on a hierarchical scale\n\
    \      representing successively increased confidence that a target of\n     \
    \ evaluation adequately fulfills the requirements. (E.g., see:\n      TCSEC.)\n\
    \   $ asymmetric cryptography\n      (I) A modern branch of cryptography (popularly\
    \ known as \"public-\n      key cryptography\") in which the algorithms employ\
    \ a pair of keys\n      (a public key and a private key) and use a different component\
    \ of\n      the pair for different steps of the algorithm. (See: key pair.)\n\
    \      (C) Asymmetric algorithms have key management advantages over\n      equivalently\
    \ strong symmetric ones. First, one key of the pair\n      does not need to be\
    \ known by anyone but its owner; so it can more\n      easily be kept secret.\
    \ Second, although the other key of the pair\n      is shared by all entities\
    \ that use the algorithm, that key does\n      not need to be kept secret from\
    \ other, non-using entities; so the\n      key distribution part of key management\
    \ can be done more easily.\n      (C) For encryption: In an asymmetric encryption\
    \ algorithm (e.g.,\n      see: RSA), when Alice wants to ensure confidentiality\
    \ for data she\n      sends to Bob, she encrypts the data with a public key provided\
    \ by\n      Bob. Only Bob has the matching private key that is needed to\n   \
    \   decrypt the data.\n      (C) For signature: In an asymmetric digital signature\
    \ algorithm\n      (e.g., see: DSA), when Alice wants to ensure data integrity\
    \ or\n      provide authentication for data she sends to Bob, she uses her\n \
    \     private key to sign the data (i.e., create a digital signature\n      based\
    \ on the data). To verify the signature, Bob uses the matching\n      public key\
    \ that Alice has provided.\n      (C) For key agreement: In an asymmetric key\
    \ agreement algorithm\n      (e.g., see: Diffie-Hellman), Alice and Bob each send\
    \ their own\n      public key to the other person. Then each uses their own private\n\
    \      key and the other's public key to compute the new key value.\n   $ attack\n\
    \      (I) An assault on system security that derives from an intelligent\n  \
    \    threat, i.e., an intelligent act that is a deliberate attempt\n      (especially\
    \ in the sense of a method or technique) to evade\n      security services and\
    \ violate the security policy of a system.\n      (See: penetration, violation,\
    \ vulnerability.)\n       - Active vs. passive: An \"active attack\" attempts\
    \ to alter system\n         resources or affect their operation. A \"passive attack\"\
    \n         attempts to learn or make use of information from the system\n    \
    \     but does not affect system resources. (E.g., see: wiretapping.)\n      \
    \ - Insider vs. outsider: An \"inside attack\" is an attack initiated\n      \
    \   by an entity inside the security perimeter (an \"insider\"),\n         i.e.,\
    \ an entity that is authorized to access system resources\n         but uses them\
    \ in a way not approved by those who granted the\n         authorization. An \"\
    outside attack\" is initiated from outside\n         the perimeter, by an unauthorized\
    \ or illegitimate user of the\n         system (an \"outsider\"). In the Internet,\
    \ potential outside\n         attackers range from amateur pranksters to organized\
    \ criminals,\n         international terrorists, and hostile governments.\n  \
    \    (C) The term \"attack\" relates to some other basic security terms\n    \
    \  as shown in the following diagram:\n      + - - - - - - - - - - - - +  + -\
    \ - - - +  + - - - - - - - - - - -+\n      | An Attack:              |  |Counter-\
    \ |  | A System Resource:   |\n      | i.e., A Threat Action   |  | measure |\
    \  | Target of the Attack |\n      | +----------+            |  |         |  |\
    \ +-----------------+  |\n      | | Attacker |<==================||<=========\
    \                 |  |\n      | |   i.e.,  |   Passive  |  |         |  | |  Vulnerability\
    \  |  |\n      | | A Threat |<=================>||<========>                 |\
    \  |\n      | |  Agent   |  or Active |  |         |  | +-------|||-------+  |\n\
    \      | +----------+   Attack   |  |         |  |         VVV          |\n  \
    \    |                         |  |         |  | Threat Consequences  |\n    \
    \  + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+\n   $ attribute\
    \ authority\n      (I) A CA that issues attribute certificates.\n      (O) \"\
    An authority, trusted by the verifier to delegate privilege,\n      which issues\
    \ attribute certificates.\" [FPDAM]\n   $ attribute certificate\n      (I) A digital\
    \ certificate that binds a set of descriptive data\n      items, other than a\
    \ public key, either directly to a subject name\n      or to the identifier of\
    \ another certificate that is a public-key\n      certificate. [X509]\n      (O)\
    \ \"A set of attributes of a user together with some other\n      information,\
    \ rendered unforgeable by the digital signature created\n      using the private\
    \ key of the CA which issued it.\" [X509]\n      (O) \"A data structure that includes\
    \ some attribute values and\n      identification information about the owner\
    \ of the attribute\n      certificate, all digitally signed by an Attribute Authority.\
    \ This\n      authority's signature serves as the guarantee of the binding\n \
    \     between the attributes and their owner.\" [FPDAM]\n      (C) A public-key\
    \ certificate binds a subject name to a public key\n      value, along with information\
    \ needed to perform certain\n      cryptographic functions. Other attributes of\
    \ a subject, such as a\n      security clearance, may be certified in a separate\
    \ kind of digital\n      certificate, called an attribute certificate. A subject\
    \ may have\n      multiple attribute certificates associated with its name or\
    \ with\n      each of its public-key certificates.\n      (C) An attribute certificate\
    \ might be issued to a subject in the\n      following situations:\n       - Different\
    \ lifetimes: When the lifetime of an attribute binding\n         is shorter than\
    \ that of the related public-key certificate, or\n         when it is desirable\
    \ not to need to revoke a subject's public\n         key just to revoke an attribute.\n\
    \       - Different authorities: When the authority responsible for the\n    \
    \     attributes is different than the one that issues the public-key\n      \
    \   certificate for the subject. (There is no requirement that an\n         attribute\
    \ certificate be issued by the same CA that issued the\n         associated public-key\
    \ certificate.)\n   $ audit service\n      (I) A security service that records\
    \ information needed to\n      establish accountability for system events and\
    \ for the actions of\n      system entities that cause them. (See: security audit.)\n\
    \   $ audit trail\n      See: security audit trail.\n   $ AUTH\n      See: POP3\
    \ AUTH.\n   $ authentic signature\n      (I) A signature (particularly a digital\
    \ signature) that can be\n      trusted because it can be verified. (See: validate\
    \ vs. verify.)\n   $ authenticate\n      (I) Verify (i.e., establish the truth\
    \ of) an identity claimed by\n      or for a system entity. (See: authentication.)\n\
    \      (D) In general English usage, this term usually means \"to prove\n    \
    \  genuine\" (e.g., an art expert authenticates a Michelangelo\n      painting).\
    \ But the recommended definition carries a much narrower\n      meaning. For example,\
    \ to be precise, an ISD SHOULD NOT say \"the\n      host authenticates each received\
    \ datagram\". Instead, the ISD\n      SHOULD say \"the host authenticates the\
    \ origin of each received\n      datagram\". In most cases, we also can say \"\
    and verifies the\n      datagram's integrity\", because that is usually implied.\
    \ (See:\n      (\"relationship between data integrity service and authentication\n\
    \      services\" under) data integrity service.)\n      (D) ISDs SHOULD NOT talk\
    \ about authenticating a digital signature\n      or digital certificate. Instead,\
    \ we \"sign\" and then \"verify\"\n      digital signatures, and we \"issue\"\
    \ and then \"validate\" digital\n      certificates. (See: validate vs. verify.)\n\
    \   $ authentication\n      (I) The process of verifying an identity claimed by\
    \ or for a\n      system entity. (See: authenticate, authentication exchange,\n\
    \      authentication information, credential, data origin\n      authentication,\
    \ peer entity authentication.)\n      (C) An authentication process consists of\
    \ two steps:\n      1. Identification step: Presenting an identifier to the security\n\
    \         system. (Identifiers should be assigned carefully, because\n       \
    \  authenticated identities are the basis for other security\n         services,\
    \ such as access control service.)\n      2. Verification step: Presenting or\
    \ generating authentication\n         information that corroborates the binding\
    \ between the entity\n         and the identifier. (See: verification.)\n    \
    \  (C) See: (\"relationship between data integrity service and\n      authentication\
    \ services\" under) data integrity service.\n   $ authentication code\n      (D)\
    \ ISDs SHOULD NOT use this term as a synonym for any form of\n      checksum,\
    \ whether cryptographic or not. The word \"authentication\"\n      is misleading\
    \ because the mechanism involved usually serves a data\n      integrity function\
    \ rather than an authentication function, and the\n      word \"code\" is misleading\
    \ because it implies that either encoding\n      or encryption is involved or\
    \ that the term refers to computer\n      software. (See: message authentication\
    \ code.)\n   $ authentication exchange\n      (I) A mechanism to verify the identity\
    \ of an entity by means of\n      information exchange.\n      (O) \"A mechanism\
    \ intended to ensure the identity of an entity by\n      means of information\
    \ exchange.\" [I7498 Part 2]\n   $ Authentication Header (AH)\n      (I) An Internet\
    \ IPsec protocol [R2402] designed to provide\n      connectionless data integrity\
    \ service and data origin\n      authentication service for IP datagrams, and\
    \ (optionally) to\n      provide protection against replay attacks.\n      (C)\
    \ Replay protection may be selected by the receiver when a\n      security association\
    \ is established. AH authenticates upper-layer\n      protocol data units and\
    \ as much of the IP header as possible.\n      However, some IP header fields\
    \ may change in transit, and the\n      value of these fields, when the packet\
    \ arrives at the receiver,\n      may not be predictable by the sender. Thus,\
    \ the values of such\n      fields cannot be protected end-to-end by AH; protection\
    \ of the IP\n      header by AH is only partial when such fields are present.\n\
    \      (C) AH may be used alone, or in combination with the IPsec ESP\n      protocol,\
    \ or in a nested fashion with tunneling. Security services\n      can be provided\
    \ between a pair of communicating hosts, between a\n      pair of communicating\
    \ security gateways, or between a host and a\n      gateway. ESP can provide the\
    \ same security services as AH, and ESP\n      can also provide data confidentiality\
    \ service. The main difference\n      between authentication services provided\
    \ by ESP and AH is the\n      extent of the coverage; ESP does not protect IP\
    \ header fields\n      unless they are encapsulated by AH.\n   $ authentication\
    \ information\n      (I) Information used to verify an identity claimed by or\
    \ for an\n      entity. (See: authentication, credential.)\n      (C) Authentication\
    \ information may exist as, or be derived from,\n      one of the following:\n\
    \       - Something the entity knows. (See: password).\n       - Something the\
    \ entity possesses. (See: token.)\n       - Something the entity is. (See: biometric\
    \ authentication.)\n   $ authentication service\n      (I) A security service\
    \ that verifies an identity claimed by or for\n      an entity. (See: authentication.)\n\
    \      (C) In a network, there are two general forms of authentication\n     \
    \ service: data origin authentication service and peer entity\n      authentication\
    \ service.\n   $ authenticity\n      (I) The property of being genuine and able\
    \ to be verified and be\n      trusted. (See: authenticate, authentication, validate\
    \ vs. verify)\n   $ authority\n      (D) \"An entity, responsible for the issuance\
    \ of certificates.\"\n      [FPDAM]\n      (C) ISDs SHOULD NOT use this term as\
    \ a synonym for AA, CA, RA,\n      ORA, or similar terms, because it may cause\
    \ confusion. Instead,\n      use the full term at the first instance of usage\
    \ and then, if it\n      is necessary to shorten text, use the style of abbreviation\n\
    \      defined in this Glossary.\n      (C) ISDs SHOULD NOT use this definition\
    \ for any PKI entity,\n      because the definition is ambiguous with regard to\
    \ whether the\n      entity actually issues certificates (e.g., attribute authority\
    \ or\n      certification authority) or just has accountability for processes\n\
    \      that precede or follow signing (e.g., registration authority).\n      (See:\
    \ issue.)\n   $ authority certificate\n      (D) \"A certificate issued to an\
    \ authority (e.g. either to a\n      certification authority or to an attribute\
    \ authority).\" [FPDAM]\n      (See: authority.)\n      (C) ISDs SHOULD NOT use\
    \ this term or definition because they are\n      ambiguous with regard to which\
    \ specific types of PKI entities they\n      address.\n   $ authority revocation\
    \ list (ARL)\n      (I) A data structure that enumerates digital certificates\
    \ that\n      were issued to CAs but have been invalidated by their issuer prior\n\
    \      to when they were scheduled to expire. (See: certificate\n      expiration,\
    \ X.509 authority revocation list.)\n      (O) \"A revocation list containing\
    \ a list of public-key\n      certificates issued to authorities, which are no\
    \ longer considered\n      valid by the certificate issuer.\" [FPDAM]\n   $ authorization\n\
    \   $ authorize\n      (I) (1.) An \"authorization\" is a right or a permission\
    \ that is\n      granted to a system entity to access a system resource. (2.)\
    \ An\n      \"authorization process\" is a procedure for granting such rights.\n\
    \      (3.) To \"authorize\" means to grant such a right or permission.\n    \
    \  (See: privilege.)\n      (O) SET usage: \"The process by which a properly appointed\
    \ person\n      or persons grants permission to perform some action on behalf\
    \ of\n      an organization. This process assesses transaction risk, confirms\n\
    \      that a given transaction does not raise the account holder's debt\n   \
    \   above the account's credit limit, and reserves the specified\n      amount\
    \ of credit. (When a merchant obtains authorization, payment\n      for the authorized\
    \ amount is guaranteed--provided, of course, that\n      the merchant followed\
    \ the rules associated with the authorization\n      process.)\" [SET2]\n   $\
    \ automated information system\n      (I) An organized assembly of resources and\
    \ procedures--i.e.,\n      computing and communications equipment and services,\
    \ with their\n      supporting facilities and personnel--that collect, record,\n\
    \      process, store, transport, retrieve, or display information to\n      accomplish\
    \ a specified set of functions.\n   $ availability\n      (I) The property of\
    \ a system or a system resource being accessible\n      and usable upon demand\
    \ by an authorized system entity, according\n      to performance specifications\
    \ for the system; i.e., a system is\n      available if it provides services according\
    \ to the system design\n      whenever users request them. (See: critical, denial\
    \ of service,\n      reliability, survivability.)\n      (O) \"The property of\
    \ being accessible and usable upon demand by an\n      authorized entity.\" [I7498\
    \ Part 2]\n   $ availability service\n      (I) A security service that protects\
    \ a system to ensure its\n      availability.\n      (C) This service addresses\
    \ the security concerns raised by denial-\n      of-service attacks. It depends\
    \ on proper management and control of\n      system resources, and thus depends\
    \ on access control service and\n      other security services.\n   $ back door\n\
    \      (I) A hardware or software mechanism that (a) provides access to a\n  \
    \    system and its resources by other than the usual procedure, (b)\n      was\
    \ deliberately left in place by the system's designers or\n      maintainers,\
    \ and (c) usually is not publicly known. (See: trap\n      door.)\n      (C) For\
    \ example, a way to access a computer other than through a\n      normal login.\
    \ Such access paths do not necessarily have malicious\n      intent; e.g., operating\
    \ systems sometimes are shipped by the\n      manufacturer with privileged accounts\
    \ intended for use by field\n      service technicians or the vendor's maintenance\
    \ programmers. (See:\n      trap door.)\n   $ back up vs. backup\n      (I) Verb\
    \ \"back up\": To store data for the purpose of creating a\n      backup copy.\
    \ (See: archive.)\n      (I) Noun/adjective \"backup\": (1.) A reserve copy of\
    \ data that is\n      stored separately from the original, for use if the original\n\
    \      becomes lost or damaged. (See: archive.) (2.) Alternate means to\n    \
    \  permit performance of system functions despite a disaster to\n      system\
    \ resources. (See: contingency plan.)\n   $ baggage\n      (D) ISDs SHOULD NOT\
    \ use this term to describe a data element\n      except when stated as \"SET(trademark)\
    \ baggage\" with the following\n      meaning:\n      (O) SET usage: An \"opaque\
    \ encrypted tuple, which is included in a\n      SET message but appended as external\
    \ data to the PKCS encapsulated\n      data. This avoids superencryption of the\
    \ previously encrypted\n      tuple, but guarantees linkage with the PKCS portion\
    \ of the\n      message.\" [SET2]\n   $ bandwidth\n      (I) Commonly used to\
    \ mean the capacity of a communication channel\n      to pass data through the\
    \ channel in a given amount of time.\n      Usually expressed in bits per second.\n\
    \   $ bank identification number (BIN)\n      (N) The digits of a credit card\
    \ number that identify the issuing\n      bank. (See: primary account number.)\n\
    \      (O) SET usage: The first six digits of a primary account number.\n   $\
    \ Basic Encoding Rules (BER)\n      (I) A standard for representing ASN.1 data\
    \ types as strings of\n      octets. [X690] (See: Distinguished Encoding Rules.)\n\
    \   $ bastion host\n      (I) A strongly protected computer that is in a network\
    \ protected\n      by a firewall (or is part of a firewall) and is the only host\
    \ (or\n      one of only a few hosts) in the network that can be directly\n  \
    \    accessed from networks on the other side of the firewall.\n      (C) Filtering\
    \ routers in a firewall typically restrict traffic\n      from the outside network\
    \ to reaching just one host, the bastion\n      host, which usually is part of\
    \ the firewall. Since only this one\n      host can be directly attacked, only\
    \ this one host needs to be very\n      strongly protected, so security can be\
    \ maintained more easily and\n      less expensively. However, to allow legitimate\
    \ internal and\n      external users to access application resources through the\n\
    \      firewall, higher layer protocols and services need to be relayed\n    \
    \  and forwarded by the bastion host. Some services (e.g., DNS and\n      SMTP)\
    \ have forwarding built in; other services (e.g., TELNET and\n      FTP) require\
    \ a proxy server on the bastion host.\n   $ BCA\n      See: brand certification\
    \ authority.\n   $ BCI\n      See: brand CRL identifier.\n   $ Bell-LaPadula Model\n\
    \      (N) A formal, mathematical, state-transition model of security\n      policy\
    \ for multilevel-secure computer systems. [Bell]\n      (C) The model separates\
    \ computer system elements into a set of\n      subjects and a set of objects.\
    \ To determine whether or not a\n      subject is authorized for a particular\
    \ access mode on an object,\n      the clearance of the subject is compared to\
    \ the classification of\n      the object. The model defines the notion of a \"\
    secure state\", in\n      which the only permitted access modes of subjects to\
    \ objects are\n      in accordance with a specified security policy. It is proven\
    \ that\n      each state transition preserves security by moving from secure\n\
    \      state to secure state, thereby proving that the system is secure.\n   \
    \   (C) In this model, a multilevel-secure system satisfies several\n      rules,\
    \ including the following:\n       - \"Confinement property\" (also called \"\
    *-property\", pronounced\n         \"star property\"): A subject has write access\
    \ to an object only\n         if classification of the object dominates the clearance\
    \ of the\n         subject.\n       - \"Simple security property\": A subject\
    \ has read access to an\n         object only if the clearance of the subject\
    \ dominates the\n         classification of the object.\n       - \"Tranquillity\
    \ property\": The classification of an object does\n         not change while\
    \ the object is being processed by the system.\n   $ BER\n      See: Basic Encoding\
    \ Rules.\n   $ beyond A1\n      (O) (1.) Formally, a level of security assurance\
    \ that is beyond\n      the highest level of criteria specified by the TCSEC.\
    \ (2.)\n      Informally, a level of trust so high that it cannot be provided\
    \ or\n      verified by currently available assurance methods, and\n      particularly\
    \ not by currently available formal methods.\n   $ BIN\n      See: bank identification\
    \ number.\n   $ bind\n      (I) To inseparably associate by applying some mechanism,\
    \ such as\n      when a CA uses a digital signature to bind together a subject\
    \ and\n      a public key in a public-key certificate.\n   $ biometric authentication\n\
    \      (I) A method of generating authentication information for a person\n  \
    \    by digitizing measurements of a physical characteristic, such as a\n    \
    \  fingerprint, a hand shape, a retina pattern, a speech pattern\n      (voiceprint),\
    \ or handwriting.\n   $ bit\n      (I) The smallest unit of information storage;\
    \ a contraction of the\n      term \"binary digit\"; one of two symbols--\"0\"\
    \ (zero) and \"1\" (one)\n      --that are used to represent binary numbers.\n\
    \   $ BLACK\n      (I) Designation for information system equipment or facilities\n\
    \      that handle (and for data that contains) only ciphertext (or,\n      depending\
    \ on the context, only unclassified information), and for\n      such data itself.\
    \ This term derives from U.S. Government COMSEC\n      terminology. (See: RED,\
    \ RED/BLACK separation.)\n   $ block cipher\n      (I) An encryption algorithm\
    \ that breaks plaintext into fixed-size\n      segments and uses the same key\
    \ to transform each plaintext segment\n      into a fixed-size segment of ciphertext.\
    \ (See: mode, stream\n      cipher.)\n      (C) For example, Blowfish, DEA, IDEA,\
    \ RC2, and SKIPJACK. However,\n      a block cipher can be adapted to have a different\
    \ external\n      interface, such as that of a stream cipher, by using a mode\
    \ of\n      operation to \"package\" the basic algorithm.\n   $ Blowfish\n   \
    \   (N) A symmetric block cipher with variable-length key (32 to 448\n      bits)\
    \ designed in 1993 by Bruce Schneier as an unpatented,\n      license-free, royalty-free\
    \ replacement for DES or IDEA. [Schn]\n   $ brand\n      (I) A distinctive mark\
    \ or name that identifies a product or\n      business entity.\n      (O) SET\
    \ usage: The name of a payment card. Financial institutions\n      and other companies\
    \ have founded payment card brands, protect and\n      advertise the brands, establish\
    \ and enforce rules for use and\n      acceptance of their payment cards, and\
    \ provide networks to\n      interconnect the financial institutions. These brands\
    \ combine the\n      roles of issuer and acquirer in interactions with cardholders\
    \ and\n      merchants. [SET1]\n   $ brand certification authority (BCA)\n   \
    \   (O) SET usage: A CA owned by a payment card brand, such as\n      MasterCard,\
    \ Visa, or American Express. [SET2] (See: certification\n      hierarchy, SET.)\n\
    \   $ brand CRL identifier (BCI)\n      (O) SET usage: A digitally signed list,\
    \ issued by a BCA, of the\n      names of CAs for which CRLs need to be processed\
    \ when verifying\n      signatures in SET messages. [SET2]\n   $ break\n     \
    \ (I) Cryptographic usage: To successfully perform cryptanalysis and\n      thus\
    \ succeed in decrypting data or performing some other\n      cryptographic function,\
    \ without initially having knowledge of the\n      key that the function requires.\
    \ (This term applies to encrypted\n      data or, more generally, to a cryptographic\
    \ algorithm or\n      cryptographic system.)\n   $ bridge\n      (I) A computer\
    \ that is a gateway between two networks (usually two\n      LANs) at OSI layer\
    \ 2. (See: router.)\n   $ British Standard 7799\n      (N) Part 1 is a standard\
    \ code of practice and provides guidance on\n      how to secure an information\
    \ system. Part 2 specifies the\n      management framework, objectives, and control\
    \ requirements for\n      information security management systems [B7799]. The\
    \ certification\n      scheme works like ISO 9000. It is in use in the UK, the\n\
    \      Netherlands, Australia, and New Zealand and might be proposed as\n    \
    \  an ISO standard or adapted to be part of the Common Criteria.\n   $ browser\n\
    \      (I) An client computer program that can retrieve and display\n      information\
    \ from servers on the World Wide Web.\n      (C) For example, Netscape's Navigator\
    \ and Communicator, and\n      Microsoft's Explorer.\n   $ brute force\n     \
    \ (I) A cryptanalysis technique or other kind of attack method\n      involving\
    \ an exhaustive procedure that tries all possibilities,\n      one-by-one.\n \
    \     (C) For example, for ciphertext where the analyst already knows\n      the\
    \ decryption algorithm, a brute force technique to finding the\n      original\
    \ plaintext is to decrypt the message with every possible\n      key.\n   $ BS7799\n\
    \      See: British Standard 7799.\n   $ byte\n      (I) A fundamental unit of\
    \ computer storage; the smallest\n      addressable unit in a computer's architecture.\
    \ Usually holds one\n      character of information and, today, usually means\
    \ eight bits.\n      (See: octet.)\n      (C) Larger than a \"bit\", but smaller\
    \ than a \"word\". Although\n      \"byte\" almost always means \"octet\" today,\
    \ bytes had other sizes\n      (e.g., six bits, nine bits) in earlier computer\
    \ architectures.\n   $ CA\n      See: certification authority.\n   $ CA certificate\n\
    \      (I) \"A [digital] certificate for one CA issued by another CA.\"\n    \
    \  [X509]\n      (C) That is, a digital certificate whose holder is able to issue\n\
    \      digital certificates. A v3 X.509 public-key certificate may have a\n  \
    \    \"basicConstraints\" extension containing a \"cA\" value that\n      specifically\
    \ \"indicates whether or not the public key may be used\n      to verify certificate\
    \ signatures.\"\n   $ call back\n      (I) An authentication technique for terminals\
    \ that remotely access\n      a computer via telephone lines. The host system\
    \ disconnects the\n      caller and then calls back on a telephone number that\
    \ was\n      previously authorized for that terminal.\n   $ capability\n     \
    \ (I) A token, usually an unforgeable data value (sometimes called a\n      \"\
    ticket\") that gives the bearer or holder the right to access a\n      system\
    \ resource. Possession of the token is accepted by a system\n      as proof that\
    \ the holder has been authorized to access the\n      resource named or indicated\
    \ by the token. (See: access control\n      list, credential, digital certificate.)\n\
    \      (C) This concept can be implemented as a digital certificate.\n      (See:\
    \ attribute certificate.)\n   $ CAPI\n      See: cryptographic application programming\
    \ interface.\n   $ CAPSTONE chip\n      (N) An integrated circuit (the Mykotronx,\
    \ Inc. MYK-82) with a Type\n      II cryptographic processor that implements SKIPJACK,\
    \ KEA, DSA,\n      SHA, and basic mathematical functions to support asymmetric\n\
    \      cryptography, and includes the key escrow feature of the CLIPPER\n    \
    \  chip. (See: FORTEZZA card.)\n   $ card\n      See: cryptographic card, FORTEZZA\
    \ card, payment card, PC card,\n      smart card, token.\n   $ card backup\n \
    \     See: token backup.\n   $ card copy\n      See: token copy.\n   $ card restore\n\
    \      See: token restore.\n   $ cardholder\n      (I) An entity that has been\
    \ issued a card.\n      (O) SET usage: \"The holder of a valid payment card account\
    \ and\n      user of software supporting electronic commerce.\" [SET2] A\n   \
    \   cardholder is issued a payment card by an issuer. SET ensures that\n     \
    \ in the cardholder's interactions with merchants, the payment card\n      account\
    \ information remains confidential. [SET1]\n   $ cardholder certificate\n    \
    \  (O) SET usage: A digital certificate that is issued to a\n      cardholder\
    \ upon approval of the cardholder's issuing financial\n      institution and that\
    \ is transmitted to merchants with purchase\n      requests and encrypted payment\
    \ instructions, carrying assurance\n      that the account number has been validated\
    \ by the issuing\n      financial institution and cannot be altered by a third\
    \ party.\n      [SET1]\n   $ cardholder certification authority (CCA)\n      (O)\
    \ SET usage: A CA responsible for issuing digital certificates\n      to cardholders\
    \ and operated on behalf of a payment card brand, an\n      issuer, or another\
    \ party according to brand rules. A CCA maintains\n      relationships with card\
    \ issuers to allow for the verification of\n      cardholder accounts. A CCA does\
    \ not issue a CRL but does\n      distribute CRLs issued by root CAs, brand CAs,\
    \ geopolitical CAs,\n      and payment gateway CAs. [SET2]\n   $ CAST\n      (N)\
    \ A design procedure for symmetric encryption algorithms, and a\n      resulting\
    \ family of algorithms, invented by C.A. (Carlisle Adams)\n      and S.T. (Stafford\
    \ Tavares). [R2144, R2612]\n   $ category\n      (I) A grouping of sensitive information\
    \ items to which a non-\n      hierarchical restrictive security label is applied\
    \ to increase\n      protection of the data. (See: compartment.)\n   $ CAW\n \
    \     See: certification authority workstation.\n   $ CBC\n      See: cipher block\
    \ chaining.\n   $ CCA\n      See: cardholder certification authority.\n   $ CCITT\n\
    \      (N) Acronym for French translation of International Telephone and\n   \
    \   Telegraph Consultative Committee. Now renamed ITU-T.\n   $ CERT\n      See:\
    \ computer emergency response team.\n   $ certificate\n      (I) General English\
    \ usage: A document that attests to the truth of\n      something or the ownership\
    \ of something.\n      (C) Security usage: See: capability, digital certificate.\n\
    \      (C) PKI usage: See: attribute certificate, public-key certificate.\n  \
    \ $ certificate authority\n      (D) ISDs SHOULD NOT use this term because it\
    \ looks like sloppy use\n      of \"certification authority\", which is the term\
    \ standardized by\n      X.509.\n   $ certificate chain\n      (D) ISDs SHOULD\
    \ NOT use this term because it duplicates the\n      meaning of a standardized\
    \ term. Instead, use \"certification path\".\n   $ certificate chain validation\n\
    \      (D) ISDs SHOULD NOT use this term because it duplicates the\n      meaning\
    \ of standardized terms and mixes concepts in a potentially\n      misleading\
    \ way. Instead, use \"certificate validation\" or \"path\n      validation\",\
    \ depending on what is meant. (See: validate vs.\n      verify.)\n   $ certificate\
    \ creation\n      (I) The act or process by which a CA sets the values of a digital\n\
    \      certificate's data fields and signs it. (See: issue.)\n   $ certificate\
    \ expiration\n      (I) The event that occurs when a certificate ceases to be\
    \ valid\n      because its assigned lifetime has been exceeded. (See: certificate\n\
    \      revocation, validity period.)\n   $ certificate extension\n      See: extension.\n\
    \   $ certificate holder\n      (D) ISDs SHOULD NOT use this term as a synonym\
    \ for the subject of\n      a digital certificate because the term is potentially\
    \ ambiguous.\n      For example, the term could also refer to a system entity,\
    \ such as\n      a repository, that simply has possession of a copy of the\n \
    \     certificate. (See: certificate owner.)\n   $ certificate management\n  \
    \    (I) The functions that a CA may perform during the life cycle of a\n    \
    \  digital certificate, including the following:\n       - Acquire and verify\
    \ data items to bind into the certificate.\n       - Encode and sign the certificate.\n\
    \       - Store the certificate in a directory or repository.\n       - Renew,\
    \ rekey, and update the certificate.\n       - Revoke the certificate and issue\
    \ a CRL.\n      (See: archive management, certificate management, key management,\n\
    \      security architecture, token management.)\n   $ certificate owner\n   \
    \   (D) ISDs SHOULD NOT use this term as a synonym for the subject of\n      a\
    \ digital certificate because the term is potentially ambiguous.\n      For example,\
    \ the term could also refer to a system entity, such as\n      a corporation,\
    \ that has acquired a certificate to operate some\n      other entity, such as\
    \ a Web server. (See: certificate holder.)\n   $ certificate policy\n      (I)\
    \ \"A named set of rules that indicates the applicability of a\n      certificate\
    \ to a particular community and/or class of application\n      with common security\
    \ requirements.\" [X509] (See: certification\n      practice statement.)\n   \
    \   (C) A certificate policy can help a certificate user decide\n      whether\
    \ a certificate should be trusted in a particular\n      application. \"For example,\
    \ a particular certificate policy might\n      indicate applicability of a type\
    \ of certificate for the\n      authentication of electronic data interchange\
    \ transactions for the\n      trading goods within a given price range.\" [R2527]\n\
    \      (C) A v3 X.509 public-key certificate may have a\n      \"certificatePolicies\"\
    \ extension that lists certificate policies,\n      recognized by the issuing\
    \ CA, that apply to the certificate and\n      govern its use. Each policy is\
    \ denoted by an object identifier and\n      may optionally have certificate policy\
    \ qualifiers.\n      (C) SET usage: Every SET certificate specifies at least one\n\
    \      certificate policy, that of the SET root CA. SET uses certificate\n   \
    \   policy qualifiers to point to the actual policy statement and to\n      add\
    \ qualifying policies to the root policy. (See: SET qualifier.)\n   $ certificate\
    \ policy qualifier\n      (I) Information that pertains to a certificate policy\
    \ and is\n      included in a \"certificatePolicies\" extension in a v3 X.509\n\
    \      public-key certificate.\n   $ certificate reactivation\n      (I) The act\
    \ or process by which a digital certificate, which a CA\n      has designated\
    \ for revocation but not yet listed on a CRL, is\n      returned to the valid\
    \ state.\n   $ certificate rekey\n      (I) The act or process by which an existing\
    \ public-key certificate\n      has its public key value changed by issuing a\
    \ new certificate with\n      a different (usually new) public key. (See: certificate\
    \ renewal,\n      certificate update, rekey.)\n      (C) For an X.509 public-key\
    \ certificate, the essence of rekey is\n      that the subject stays the same\
    \ and a new public key is bound to\n      that subject. Other changes are made,\
    \ and the old certificate is\n      revoked, only as required by the PKI and CPS\
    \ in support of the\n      rekey. If changes go beyond that, the process is a\
    \ \"certificate\n      update\".\n      (O) MISSI usage: To rekey a MISSI X.509\
    \ public-key certificate\n      means that the issuing authority creates a new\
    \ certificate that is\n      identical to the old one, except the new one has\
    \ a new, different\n      KEA key; or a new, different DSS key; or new, different\
    \ KEA and\n      DSS keys. The new certificate also has a different serial number\n\
    \      and may have a different validity period. A new key creation date\n   \
    \   and maximum key lifetime period are assigned to each newly\n      generated\
    \ key. If a new KEA key is generated, that key is assigned\n      a new KMID.\
    \ The old certificate remains valid until it expires,\n      but may not be further\
    \ renewed, rekeyed, or updated.\n   $ certificate renewal\n      (I) The act or\
    \ process by which the validity of the data binding\n      asserted by an existing\
    \ public-key certificate is extended in time\n      by issuing a new certificate.\
    \ (See: certificate rekey, certificate\n      update.)\n      (C) For an X.509\
    \ public-key certificate, this term means that the\n      validity period is extended\
    \ (and, of course, a new serial number\n      is assigned) but the binding of\
    \ the public key to the subject and\n      to other data items stays the same.\
    \ The other data items are\n      changed, and the old certificate is revoked,\
    \ only as required by\n      the PKI and CPS to support the renewal. If changes\
    \ go beyond that,\n      the process is a \"certificate rekey\" or \"certificate\
    \ update\".\n   $ certificate request\n      (D) ISDs SHOULD NOT use this term\
    \ because it looks like imprecise\n      use of a term standardized by PKCS #10\
    \ and used in PKIX. Instead,\n      use the standard term, \"certification request\"\
    .\n   $ certificate revocation\n      (I) The event that occurs when a CA declares\
    \ that a previously\n      valid digital certificate issued by that CA has become\
    \ invalid;\n      usually stated with a revocation date.\n      (C) In X.509,\
    \ a revocation is announced to potential certificate\n      users by issuing a\
    \ CRL that mentions the certificate. Revocation\n      and listing on a CRL is\
    \ only necessary before certificate\n      expiration.\n   $ certificate revocation\
    \ list (CRL)\n      (I) A data structure that enumerates digital certificates\
    \ that\n      have been invalidated by their issuer prior to when they were\n\
    \      scheduled to expire. (See: certificate expiration, X.509\n      certificate\
    \ revocation list.)\n      (O) \"A signed list indicating a set of certificates\
    \ that are no\n      longer considered valid by the certificate issuer. After\
    \ a\n      certificate appears on a CRL, it is deleted from a subsequent CRL\n\
    \      after the certificate's expiry. CRLs may be used to identify\n      revoked\
    \ public-key certificates or attribute certificates and may\n      represent revocation\
    \ of certificates issued to authorities or to\n      users. The term CRL is also\
    \ commonly used as a generic term\n      applying to all the different types of\
    \ revocation lists, including\n      CRLs, ARLs, ACRLs, etc.\" [FPDAM]\n   $ certificate\
    \ revocation tree\n      (I) A mechanism for distributing notice of certificate\n\
    \      revocations; uses a tree of hash results that is signed by the\n      tree's\
    \ issuer. Offers an alternative to issuing a CRL, but is not\n      supported\
    \ in X.509. (See: certificate status responder.)\n   $ certificate serial number\n\
    \      (I) An integer value that (a) is associated with, and may be\n      carried\
    \ in, a digital certificate; (b) is assigned to the\n      certificate by the\
    \ certificate's issuer; and (c) is unique among\n      all the certificates produced\
    \ by that issuer.\n      (O) \"An integer value, unique within the issuing CA,\
    \ which is\n      unambiguously associated with a certificate issued by that CA.\"\
    \n      [X509]\n   $ certificate status responder\n      (N) FPKI usage: A trusted\
    \ on-line server that acts for a CA to\n      provide authenticated certificate\
    \ status information to\n      certificate users. [FPKI] Offers an alternative\
    \ to issuing a CRL,\n      but is not supported in X.509. (See: certificate revocation\
    \ tree.)\n   $ certificate update\n      (I) The act or process by which non-key\
    \ data items bound in an\n      existing public-key certificate, especially authorizations\
    \ granted\n      to the subject, are changed by issuing a new certificate. (See:\n\
    \      certificate rekey, certificate renewal.)\n      (C) For an X.509 public-key\
    \ certificate, the essence of this\n      process is that fundamental changes\
    \ are made in the data that is\n      bound to the public key, such that it is\
    \ necessary to revoke the\n      old certificate. (Otherwise, the process is only\
    \ a \"certificate\n      rekey\" or \"certificate renewal\".)\n   $ certificate\
    \ user\n      (I) A system entity that depends on the validity of information\n\
    \      (such as another entity's public key value) provided by a digital\n   \
    \   certificate. (See: relying party.)\n      (O) \"An entity that needs to know,\
    \ with certainty, the public key\n      of another entity.\" [X509]\n      (C)\
    \ The system entity may be a human being or an organization, or\n      a device\
    \ or process under the control of a human or an\n      organization.\n      (D)\
    \ ISDs SHOULD NOT use this term as a synonym for the \"subject\"\n      of a certificate.\n\
    \   $ certificate validation\n      (I) An act or process by which a certificate\
    \ user establishes that\n      the assertions made by a digital certificate can\
    \ be trusted. (See:\n      valid certificate, validate vs. verify.)\n      (O)\
    \ \"The process of ensuring that a certificate is valid including\n      possibly\
    \ the construction and processing of a certification path,\n      and ensuring\
    \ that all certificates in that path have not expired\n      or been revoked.\"\
    \ [FPDAM]\n      (C) To validate a certificate, a certificate user checks that\
    \ the\n      certificate is properly formed and signed and currently in force:\n\
    \       - Checks the signature: Employs the issuer's public key to verify\n  \
    \       the digital signature of the CA who issued the certificate in\n      \
    \   question. If the verifier obtains the issuer's public key from\n         the\
    \ issuer's own public-key certificate, that certificate\n         should be validated,\
    \ too. That validation may lead to yet\n         another certificate to be validated,\
    \ and so on. Thus, in\n         general, certificate validation involves discovering\
    \ and\n         validating a certification path.\n       - Checks the syntax and\
    \ semantics: Parses the certificate's\n         syntax and interprets its semantics,\
    \ applying rules specified\n         for and by its data fields, such as for critical\
    \ extensions in\n         an X.509 certificate.\n       - Checks currency and\
    \ revocation: Verifies that the certificate\n         is currently in force by\
    \ checking that the current date and\n         time are within the validity period\
    \ (if that is specified in\n         the certificate) and that the certificate\
    \ is not listed on a\n         CRL or otherwise announced as invalid. (CRLs themselves\
    \ require\n         a similar validation process.)\n   $ certification\n     \
    \ (I) Information system usage: Technical evaluation (usually made\n      in support\
    \ of an accreditation action) of an information system's\n      security features\
    \ and other safeguards to establish the extent to\n      which the system's design\
    \ and implementation meet specified\n      security requirements. [FP102] (See:\
    \ accreditation.)\n      (I) Digital certificate usage: The act or process of\
    \ vouching for\n      the truth and accuracy of the binding between data items\
    \ in a\n      certificate. (See: certify.)\n      (I) Public key usage: The act\
    \ or process of vouching for the\n      ownership of a public key by issuing a\
    \ public-key certificate that\n      binds the key to the name of the entity that\
    \ possesses the\n      matching private key. In addition to binding a key to a\
    \ name, a\n      public-key certificate may bind those items to other restrictive\n\
    \      or explanatory data items. (See: X.509 public-key certificate.)\n     \
    \ (O) SET usage: \"The process of ascertaining that a set of\n      requirements\
    \ or criteria has been fulfilled and attesting to that\n      fact to others,\
    \ usually with some written instrument. A system\n      that has been inspected\
    \ and evaluated as fully compliant with the\n      SET protocol by duly authorized\
    \ parties and process would be said\n      to have been certified compliant.\"\
    \ [SET2]\n   $ certification authority (CA)\n      (I) An entity that issues digital\
    \ certificates (especially X.509\n      certificates) and vouches for the binding\
    \ between the data items\n      in a certificate.\n      (O) \"An authority trusted\
    \ by one or more users to create and\n      assign certificates. Optionally, the\
    \ certification authority may\n      create the user's keys.\" [X509]\n      (C)\
    \ Certificate users depend on the validity of information\n      provided by a\
    \ certificate. Thus, a CA should be someone that\n      certificate users trust,\
    \ and usually holds an official position\n      created and granted power by a\
    \ government, a corporation, or some\n      other organization. A CA is responsible\
    \ for managing the life\n      cycle of certificates (see: certificate management)\
    \ and, depending\n      on the type of certificate and the CPS that applies, may\
    \ be\n      responsible for the life cycle of key pairs associated with the\n\
    \      certificates (see: key management).\n   $ certification authority workstation\
    \ (CAW)\n      (I) A computer system that enables a CA to issue digital\n    \
    \  certificates and supports other certificate management functions\n      as\
    \ required.\n   $ certification hierarchy\n      (I) A tree-structured (loop-free)\
    \ topology of relationships among\n      CAs and the entities to whom the CAs\
    \ issue public-key\n      certificates. (See: hierarchical PKI.)\n      (C) In\
    \ this structure, one CA is the top CA, the highest level of\n      the hierarchy.\
    \ (See: root, top CA.) The top CA may issue public-\n      key certificates to\
    \ one or more additional CAs that form the\n      second highest level. Each of\
    \ these CAs may issue certificates to\n      more CAs at the third highest level,\
    \ and so on. The CAs at the\n      second-lowest of the hierarchy issue certificates\
    \ only to non-CA\n      entities, called \"end entities\" that form the lowest\
    \ level. (See:\n      end entity.) Thus, all certification paths begin at the\
    \ top CA and\n      descend through zero or more levels of other CAs. All certificate\n\
    \      users base path validations on the top CA's public key.\n      (O) MISSI\
    \ usage: A MISSI certification hierarchy has three or four\n      levels of CAs:\n\
    \       - A CA at the highest level, the top CA, is a \"policy approving\n   \
    \      authority\".\n       - A CA at the second-highest level is a \"policy creation\n\
    \         authority\".\n       - A CA at the third-highest level is a local authority\
    \ called a\n         \"certification authority\".\n       - A CA at the fourth-highest\
    \ (optional) level is a \"subordinate\n         certification authority\".\n \
    \     (O) PEM usage: A PEM certification hierarchy has three levels of\n     \
    \ CAs [R1422]:\n       - The highest level is the \"Internet Policy Registration\n\
    \         Authority\".\n       - A CA at the second-highest level is a \"policy\
    \ certification\n         authority\".\n       - A CA at the third-highest level\
    \ is a \"certification authority\".\n      (O) SET usage: A SET certification\
    \ hierarchy has three or four\n      levels of CAs:\n       - The highest level\
    \ is a \"SET root CA\".\n       - A CA at the second-highest level is a \"brand\
    \ certification\n         authority\".\n       - A CA at the third-highest (optional)\
    \ level is a \"geopolitical\n         certification authority\".\n       - A CA\
    \ at the fourth-highest level is a \"cardholder CA\", a\n         \"merchant CA\"\
    , or a \"payment gateway CA\".\n   $ certification path\n      (I) An ordered\
    \ sequence of public-key certificates (or a sequence\n      of public-key certificates\
    \ followed by one attribute certificate)\n      that enables a certificate user\
    \ to verify the signature on the\n      last certificate in the path, and thus\
    \ enables the user to obtain\n      a certified public key (or certified attributes)\
    \ of the entity\n      that is the subject of that last certificate. (See: certificate\n\
    \      validation, valid certificate.)\n      (O) \"An ordered sequence of certificates\
    \ of objects in the [X.500\n      Directory Information Tree] which, together\
    \ with the public key of\n      the initial object in the path, can be processed\
    \ to obtain that of\n      the final object in the path.\" [X509, R2527]\n   \
    \   (C) The path is the \"list of certificates needed to allow a\n      particular\
    \ user to obtain the public key of another.\" [X509] The\n      list is \"linked\"\
    \ in the sense that the digital signature of each\n      certificate (except the\
    \ first) is verified by the public key\n      contained in the preceding certificate;\
    \ i.e., the private key used\n      to sign a certificate and the public key contained\
    \ in the\n      preceding certificate form a key pair owned by the entity that\n\
    \      signed.\n      (C) In the X.509 quotation in the previous \"C\" paragraph,\
    \ the word\n      \"particular\" points out that a certification path that can\
    \ be\n      validated by one certificate user might not be able to be\n      validated\
    \ by another. That is because either the first certificate\n      should be a\
    \ trusted certificate (it might be a root certificate)\n      or the signature\
    \ on the first certificate should be verified by a\n      trusted key (it might\
    \ be a root key), but such trust is defined\n      relative to each user, not\
    \ absolutely for all users.\n   $ certification policy\n      (D) ISDs SHOULD\
    \ NOT use this term. Instead, use either\n      \"certificate policy\" or \"certification\
    \ practice statement\",\n      depending on what is meant.\n   $ certification\
    \ practice statement (CPS)\n      (I) \"A statement of the practices which a certification\
    \ authority\n      employs in issuing certificates.\" [ABA96, R2527] (See: certificate\n\
    \      policy.)\n      (C) A CPS is a published security policy that can help\
    \ a\n      certificate user to decide whether a certificate issued by a\n    \
    \  particular CA can be trusted enough to use in a particular\n      application.\
    \ A CPS may be (a) a declaration by a CA of the details\n      of the system and\
    \ practices it employs in its certificate\n      management operations, (b) part\
    \ of a contract between the CA and\n      an entity to whom a certificate is issued,\
    \ (c) a statute or\n      regulation applicable to the CA, or (d) a combination\
    \ of these\n      types involving multiple documents. [ABA]\n      (C) A CPS is\
    \ usually more detailed and procedurally oriented than\n      a certificate policy.\
    \ A CPS applies to a particular CA or CA\n      community, while a certificate\
    \ policy applies across CAs or\n      communities. A CA with a single CPS may\
    \ support multiple\n      certificate policies, which may be used for different\
    \ application\n      purposes or by different user communities. Multiple CAs,\
    \ each with\n      a different CPS, may support the same certificate policy. [R2527]\n\
    \   $ certification request\n      (I) A algorithm-independent transaction format,\
    \ defined by PCKS\n      #10 and used in PKIX, that contains a DN, a public key,\
    \ and\n      optionally a set of attributes, collectively signed by the entity\n\
    \      requesting certification, and sent to a CA, which transforms the\n    \
    \  request to an X.509 public-key certificate or another type of\n      certificate.\n\
    \   $ certify\n      1. (I) Issue a digital certificate and thus vouch for the\
    \ truth,\n      accuracy, and binding between data items in the certificate (e.g.,\n\
    \      see: X.509 public key certificate), such as the identity of the\n     \
    \ certificate's subject and the ownership of a public key. (See:\n      certification.)\n\
    \      (C) To \"certify a public key\" means to issue a public-key\n      certificate\
    \ that vouches for the binding between the certificate's\n      subject and the\
    \ key.\n      2. (I) The act by which a CA employs measures to verify the truth,\n\
    \      accuracy, and binding between data items in a digital certificate.\n  \
    \    (C) A description of the measures used for verification should be\n     \
    \ included in the CA's CPS.\n   $ CFB\n      See: cipher feedback.\n   $ Challenge\
    \ Handshake Authentication Protocol (CHAP)\n      (I) A peer entity authentication\
    \ method for PPP, using a randomly-\n      generated challenge and requiring a\
    \ matching response that depends\n      on a cryptographic hash of the challenge\
    \ and a secret key. [R1994]\n      (See: challenge-response, PAP.)\n   $ challenge-response\n\
    \      (I) An authentication process that verifies an identity by\n      requiring\
    \ correct authentication information to be provided in\n      response to a challenge.\
    \ In a computer system, the authentication\n      information is usually a value\
    \ that is required to be computed in\n      response to an unpredictable challenge\
    \ value.\n   $ Challenge-Response Authentication Mechanism (CRAM)\n      (I) IMAP4\
    \ usage: A mechanism [R2195], intended for use with IMAP4\n      AUTHENTICATE,\
    \ by which an IMAP4 client uses a keyed hash [R2104]\n      to authenticate itself\
    \ to an IMAP4 server. (See: POP3 APOP.)\n      (C) The server includes a unique\
    \ timestamp in its ready response\n      to the client. The client replies with\
    \ the client's name and the\n      hash result of applying MD5 to a string formed\
    \ from concatenating\n      the timestamp with a shared secret that is known only\
    \ to the\n      client and the server.\n   $ channel\n      (I) An information\
    \ transfer path within a system. (See: covert\n      channel.)\n   $ CHAP\n  \
    \    See: Challenge Handshake Authentication Protocol.\n   $ checksum\n      (I)\
    \ A value that (a) is computed by a function that is dependent\n      on the contents\
    \ of a data object and (b) is stored or transmitted\n      together with the object,\
    \ for the purpose of detecting changes in\n      the data. (See: cyclic redundancy\
    \ check, data integrity service,\n      error detection code, hash, keyed hash,\
    \ protected checksum.)\n      (C) To gain confidence that a data object has not\
    \ been changed, an\n      entity that later uses the data can compute a checksum\
    \ and compare\n      it with the checksum that was stored or transmitted with\
    \ the\n      object.\n      (C) Computer systems and networks employ checksums\
    \ (and other\n      mechanisms) to detect accidental changes in data. However,\
    \ active\n      wiretapping that changes data could also change an accompanying\n\
    \      checksum to match the changed data. Thus, some checksum functions\n   \
    \   by themselves are not good countermeasures for active attacks. To\n      protect\
    \ against active attacks, the checksum function needs to be\n      well-chosen\
    \ (see: cryptographic hash), and the checksum result\n      needs to be cryptographically\
    \ protected (see: digital signature,\n      keyed hash).\n   $ chosen-ciphertext\
    \ attack\n      (I) A cryptanalysis technique in which the analyst tries to\n\
    \      determine the key from knowledge of plaintext that corresponds to\n   \
    \   ciphertext selected (i.e., dictated) by the analyst.\n   $ chosen-plaintext\
    \ attack\n      (I) A cryptanalysis technique in which the analyst tries to\n\
    \      determine the key from knowledge of ciphertext that corresponds to\n  \
    \    plaintext selected (i.e., dictated) by the analyst.\n   $ CIAC\n      See:\
    \ Computer Incident Advisory Capability.\n   $ CIK\n      See: cryptographic ignition\
    \ key.\n   $ cipher\n      (I) A cryptographic algorithm for encryption and decryption.\n\
    \   $ cipher block chaining (CBC)\n      (I) An block cipher mode that enhances\
    \ electronic codebook mode by\n      chaining together blocks of ciphertext it\
    \ produces. [FP081] (See:\n      [R1829], [R2451].)\n      (C) This mode operates\
    \ by combining (exclusive OR-ing) the\n      algorithm's ciphertext output block\
    \ with the next plaintext block\n      to form the next input block for the algorithm.\n\
    \   $ cipher feedback (CFB)\n      (I) An block cipher mode that enhances electronic\
    \ code book mode\n      by chaining together the blocks of ciphertext it produces\
    \ and\n      operating on plaintext segments of variable length less than or\n\
    \      equal to the block length. [FP081]\n      (C) This mode operates by using\
    \ the previously generated\n      ciphertext segment as the algorithm's input\
    \ (i.e., by \"feeding\n      back\" the ciphertext) to generate an output block,\
    \ and then\n      combining (exclusive OR-ing) that output block with the next\n\
    \      plaintext segment (block length or less) to form the next\n      ciphertext\
    \ segment.\n   $ ciphertext\n      (I) Data that has been transformed by encryption\
    \ so that its\n      semantic information content (i.e., its meaning) is no longer\n\
    \      intelligible or directly available. (See: cleartext, plaintext.)\n    \
    \  (O) \"Data produced through the use of encipherment. The semantic\n      content\
    \ of the resulting data is not available.\" [I7498 Part 2]\n   $ ciphertext-only\
    \ attack\n      (I) A cryptanalysis technique in which the analyst tries to\n\
    \      determine the key solely from knowledge of intercepted ciphertext\n   \
    \   (although the analyst may also know other clues, such as the\n      cryptographic\
    \ algorithm, the language in which the plaintext was\n      written, the subject\
    \ matter of the plaintext, and some probable\n      plaintext words.)\n   $ CIPSO\n\
    \      See: Common IP Security Option.\n   $ CKL\n      See: compromised key list.\n\
    \   $ class 2, 3, 4, or 5\n      (O) U.S. Department of Defense usage: Levels\
    \ of PKI assurance\n      based on risk and value of information to be protected\
    \ [DOD3]:\n       - Class 2: For handling low-value information (unclassified,\
    \ not\n         mission-critical, or low monetary value) or protection of\n  \
    \       system-high information in low- to medium-risk environment.\n       -\
    \ Class 3: For handling medium-value information in low- to\n         medium-risk\
    \ environment. Typically requires identification of a\n         system entity\
    \ as a legal person, rather than merely a member of\n         an organization.\n\
    \       - Class 4: For handling medium- to high-value information in any\n   \
    \      environment. Typically requires identification of an entity as\n      \
    \   a legal person, rather than merely a member of an organization,\n        \
    \ and a cryptographic hardware token for protection of keying\n         material.\n\
    \       - Class 5: For handling high-value information in a high-risk\n      \
    \   environment.\n   $ classification\n   $ classification level\n      (I) (1.)\
    \ A grouping of classified information to which a\n      hierarchical, restrictive\
    \ security label is applied to increase\n      protection of the data. (2.) The\
    \ level of protection that is\n      required to be applied to that information.\
    \ (See: security level.)\n   $ classified\n      (I) Refers to information (stored\
    \ or conveyed, in any form) that\n      is formally required by a security policy\
    \ to be given data\n      confidentiality service and to be marked with a security\
    \ label\n      (which in some cases might be implicit) to indicate its protected\n\
    \      status. (See: unclassified.)\n      (C) The term is mainly used in government,\
    \ especially in the\n      military, although the concept underlying the term\
    \ also applies\n      outside government. In the U.S. Department of Defense, for\n\
    \      example, it means information that has been determined pursuant to\n  \
    \    Executive Order 12958 (\"Classified National Security Information\",\n  \
    \    20 April 1995) or any predecessor order to require protection\n      against\
    \ unauthorized disclosure and is marked to indicate its\n      classified status\
    \ when in documentary form.\n   $ clean system\n      (I) A computer system in\
    \ which the operating system and\n      application system software and files\
    \ have just been freshly\n      installed from trusted software distribution media.\n\
    \      (C) A clean system is not necessarily in a secure state.\n   $ clearance\n\
    \      See: security clearance.\n   $ clearance level\n      (I) The security\
    \ level of information to which a security\n      clearance authorizes a person\
    \ to have access.\n   $ cleartext\n      (I) Data in which the semantic information\
    \ content (i.e., the\n      meaning) is intelligible or is directly available.\
    \ (See:\n      plaintext.)\n      (O) \"Intelligible data, the semantic content\
    \ of which is\n      available.\" [I7498 Part 2]\n      (D) ISDs SHOULD NOT use\
    \ this term as a synonym for \"plaintext\",\n      the input to an encryption\
    \ operation, because the plaintext input\n      to encryption may itself be ciphertext\
    \ that was output from\n      another operation. (See: superencryption.)\n   $\
    \ client\n      (I) A system entity that requests and uses a service provided\
    \ by\n      another system entity, called a \"server\". (See: server.)\n     \
    \ (C) Usually, the requesting entity is a computer process, and it\n      makes\
    \ the request on behalf of a human user. In some cases, the\n      server may\
    \ itself be a client of some other server.\n   $ CLIPPER chip\n      (N) The Mykotronx,\
    \ Inc. MYK-82, an integrated microcircuit with a\n      cryptographic processor\
    \ that implements the SKIPJACK encryption\n      algorithm and supports key escrow.\
    \ (See: CAPSTONE, Escrowed\n      Encryption Standard.)\n      (C) The key escrow\
    \ scheme for a chip involves a SKIPJACK key\n      common to all chips that protects\
    \ the unique serial number of the\n      chip, and a second SKIPJACK key unique\
    \ to the chip that protects\n      all data encrypted by the chip. The second\
    \ key is escrowed as\n      split key components held by NIST and the U.S. Treasury\n\
    \      Department.\n   $ closed security environment\n      (O) U.S. Department\
    \ of Defense usage: A system environment that\n      meets both of the following\
    \ conditions: (a) Application developers\n      (including maintainers) have sufficient\
    \ clearances and\n      authorizations to provide an acceptable presumption that\
    \ they have\n      not introduced malicious logic. (b) Configuration control provides\n\
    \      sufficient assurance that system applications and the equipment\n     \
    \ they run on are protected against the introduction of malicious\n      logic\
    \ prior to and during the operation of applications. [NCS04]\n      (See: open\
    \ security environment.)\n   $ code\n      (I) noun: A system of symbols used\
    \ to represent information, which\n      might originally have some other representation.\
    \ (See: encode.)\n      (D) ISDs SHOULD NOT use this term as synonym for the following:\n\
    \      (a) \"cipher\", \"hash\", or other words that mean \"a cryptographic\n\
    \      algorithm\"; (b) \"ciphertext\"; or (c) \"encrypt\", \"hash\", or other\n\
    \      words that refer to applying a cryptographic algorithm.\n      (D) ISDs\
    \ SHOULD NOT this word as an abbreviation for the following\n      terms: country\
    \ code, cyclic redundancy code, Data Authentication\n      Code, error detection\
    \ code, Message Authentication Code, object\n      code, or source code. To avoid\
    \ misunderstanding, use the fully\n      qualified term, at least at the point\
    \ of first usage.\n   $ color change\n      (I) In a system that is being operated\
    \ in periods processing mode,\n      the act of purging all information from one\
    \ processing period and\n      then changing over to the next processing period.\n\
    \   $ Common Criteria\n   $ Common Criteria for Information Technology Security\n\
    \      (N) \"The Common Criteria\" is a standard for evaluating information\n\
    \      technology products and systems, such as operating systems,\n      computer\
    \ networks, distributed systems, and applications. It\n      states requirements\
    \ for security functions and for assurance\n      measures. [CCIB]\n      (C)\
    \ Canada, France, Germany, the Netherlands, the United Kingdom,\n      and the\
    \ United States (NIST and NSA) began developing this\n      standard in 1993,\
    \ based on the European ITSEC, the Canadian\n      Trusted Computer Product Evaluation\
    \ Criteria (CTCPEC), and the\n      U.S. \"Federal Criteria for Information Technology\
    \ Security\" (FC)\n      and its precursor, the TCSEC. Work was done in cooperation\
    \ with\n      ISO/IEC Joint Technical Committee 1 (Information Technology),\n\
    \      Subcommittee 27 (Security Techniques), Working Group 3 (Security\n    \
    \  Criteria). Version 2.1 of the Criteria is equivalent to ISO's\n      International\
    \ Standard 15408 [I15408]. The U.S. Government intends\n      that this standard\
    \ eventually will supersede both the TCSEC and\n      FIPS PUB 140-1. (See: NIAP.)\n\
    \      (C) The standard addresses data confidentiality, data integrity,\n    \
    \  and availability and may apply to other aspects of security. It\n      focuses\
    \ on threats to information arising from human activities,\n      malicious or\
    \ otherwise, but may apply to non-human threats. It\n      applies to security\
    \ measures implemented in hardware, firmware, or\n      software. It does not\
    \ apply to (a) administrative security not\n      related directly to technical\
    \ security, (b) technical physical\n      aspects of security such as electromagnetic\
    \ emanation control, (c)\n      evaluation methodology or administrative and legal\
    \ framework under\n      which the criteria may be applied, (d) procedures for\
    \ use of\n      evaluation results, or (e) assessment of inherent qualities of\n\
    \      cryptographic algorithms.\n   $ Common IP Security Option (CIPSO)\n   \
    \   See: (secondary definition under) Internet Protocol Security\n      Option.\n\
    \   $ common name\n      (I) A character string that (a) may be a part of the\
    \ X.500 DN of a\n      Directory object (\"commonName\" attribute), (b) is a (possibly\n\
    \      ambiguous) name by which the object is commonly known in some\n      limited\
    \ scope (such as an organization), and (c) conforms to the\n      naming conventions\
    \ of the country or culture with which it is\n      associated. [X520] (See: (\"\
    subject\" and \"issuer\" under) X.509\n      public-key certificate.)\n      (C)\
    \ For example, \"Dr. E. F. Moore\", \"The United Nations\", or\n      \"12-th\
    \ Floor Laser Printer\".\n   $ communication security (COMSEC)\n      (I) Measures\
    \ that implement and assure security services in a\n      communication system,\
    \ particularly those that provide data\n      confidentiality and data integrity\
    \ and that authenticate\n      communicating entities.\n      (C) Usually understood\
    \ to include cryptographic algorithms and key\n      management methods and processes,\
    \ devices that implement them, and\n      the life cycle management of keying\
    \ material and devices.\n   $ community string\n      (I) A community name in\
    \ the form of an octet string that serves as\n      a cleartext password in SNMP\
    \ version 1. [R1157]\n   $ compartment\n      (I) A grouping of sensitive information\
    \ items that require special\n      access controls beyond those normally provided\
    \ for the basic\n      classification level of the information. (See: category.)\n\
    \      (C) The term is usually understood to include the special handling\n  \
    \    procedures to be used for the information.\n   $ compromise\n      See: data\
    \ compromise, security compromise.\n   $ compromised key list (CKL)\n      (O)\
    \ MISSI usage: A list that identifies keys for which\n      unauthorized disclosure\
    \ or alteration may have occurred. (See:\n      compromise.)\n      (C) A CKL\
    \ is issued by an CA, like a CRL is issued. But a CKL\n      lists only KMIDs,\
    \ not subjects that hold the keys, and not\n      certificates in which the keys\
    \ are bound.\n   $ COMPUSEC\n      See: computer security.\n   $ computer emergency\
    \ response team (CERT)\n      (I) An organization that studies computer and network\
    \ INFOSEC in\n      order to provide incident response services to victims of\
    \ attacks,\n      publish alerts concerning vulnerabilities and threats, and offer\n\
    \      other information to help improve computer and network security.\n    \
    \  (See: CSIRT, security incident.)\n      (C) For example, the CERT Coordination\
    \ Center at Carnegie-Mellon\n      University (sometimes called \"the\" CERT)\
    \ and the Computer Incident\n      Advisory Capability.\n   $ Computer Incident\
    \ Advisory Capability (CIAC)\n      (N) A computer emergency response team in\
    \ the U.S. Department of\n      Energy.\n   $ computer network\n      (I) A collection\
    \ of host computers together with the subnetwork or\n      internetwork through\
    \ which they can exchange data.\n      (C) This definition is intended to cover\
    \ systems of all sizes and\n      types, ranging from the complex Internet to\
    \ a simple system\n      composed of a personal computer dialing in as a remote\
    \ terminal of\n      another computer.\n   $ computer security (COMPUSEC)\n  \
    \    (I) Measures that implement and assure security services in a\n      computer\
    \ system, particularly those that assure access control\n      service.\n    \
    \  (C) Usually understood to include functions, features, and\n      technical\
    \ characteristics of computer hardware and software,\n      especially operating\
    \ systems.\n   $ computer security incident response team (CSIRT)\n      (I) An\
    \ organization \"that coordinates and supports the response to\n      security\
    \ incidents that involve sites within a defined\n      constituency.\" [R2350]\
    \ (See: CERT, FIRST, security incident.)\n      (C) To be considered a CSIRT,\
    \ an organization must do as follows:\n       - Provide a (secure) channel for\
    \ receiving reports about\n         suspected security incidents.\n       - Provide\
    \ assistance to members of its constituency in handling\n         the incidents.\n\
    \       - Disseminate incident-related information to its constituency\n     \
    \    and other involved parties.\n   $ computer security object\n      (I) The\
    \ definition or representation of a resource, tool, or\n      mechanism used to\
    \ maintain a condition of security in computerized\n      environments. Includes\
    \ many elements referred to in standards that\n      are either selected or defined\
    \ by separate user communities.\n      [CSOR] (See: object identifier, Computer\
    \ Security Objects\n      Register.)\n   $ Computer Security Objects Register\
    \ (CSOR)\n      (N) A service operated by NIST is establishing a catalog for\n\
    \      computer security objects to provide stable object definitions\n      identified\
    \ by unique names. The use of this register will enable\n      the unambiguous\
    \ specification of security parameters and\n      algorithms to be used in secure\
    \ data exchanges.\n      (C) The CSOR follows registration guidelines established\
    \ by the\n      international standards community and ANSI. Those guidelines\n\
    \      establish minimum responsibilities for registration authorities\n     \
    \ and assign the top branches of an international registration\n      hierarchy.\
    \ Under that international registration hierarchy the\n      CSOR is responsible\
    \ for the allocation of unique identifiers under\n      the branch {joint-iso-ccitt(2)\
    \ country(16) us(840) gov(101)\n      csor(3)}.\n   $ COMSEC\n      See: communication\
    \ security.\n   $ confidentiality\n      See: data confidentiality.\n   $ configuration\
    \ control\n      (I) The process of regulating changes to hardware, firmware,\n\
    \      software, and documentation throughout the development and\n      operational\
    \ life of a system. (See: administrative security.)\n      (C) Configuration control\
    \ helps protect against unauthorized or\n      malicious alteration of a system\
    \ and thus provides assurance of\n      system integrity. (See: malicious logic.)\n\
    \   $ confinement property\n      See: (secondary definition under) Bell-LaPadula\
    \ Model.\n   $ connectionless data integrity service\n      (I) A security service\
    \ that provides data integrity service for an\n      individual IP datagram, by\
    \ detecting modification of the datagram,\n      without regard to the ordering\
    \ of the datagram in a stream of\n      datagrams.\n      (C) A connection-oriented\
    \ data integrity service would be able to\n      detect lost or reordered datagrams\
    \ within a stream of datagrams.\n   $ contingency plan\n      (I) A plan for emergency\
    \ response, backup operations, and post-\n      disaster recovery in a system\
    \ as part of a security program to\n      ensure availability of critical system\
    \ resources and facilitate\n      continuity of operations in a crisis. [NCS04]\
    \ (See: availability.)\n   $ controlled security mode\n      (D) ISDs SHOULD NOT\
    \ use this term. It was defined in an earlier\n      version of the U.S. Department\
    \ of Defense policy that regulates\n      system accreditation, but was subsumed\
    \ by \"partitioned security\n      mode\" in the current version. [DOD2]\n   \
    \   (C) The term refers to a mode of operation of an information\n      system,\
    \ wherein at least some users with access to the system have\n      neither a\
    \ security clearance nor a need-to-know for all classified\n      material contained\
    \ in the system. However, separation and control\n      of users and classified\
    \ material on the basis, respectively, of\n      clearance and classification\
    \ level are not essentially under\n      operating system control like they are\
    \ in \"multilevel security\n      mode\".\n      (C) Controlled mode was intended\
    \ to encourage ingenuity in meeting\n      the security requirements of Defense\
    \ policy in ways less\n      restrictive than \"dedicated security mode\" and\
    \ \"system high\n      security mode\", but at a level of risk lower than that\
    \ generally\n      associated with the true \"multilevel security mode\". This\
    \ was to\n      be accomplished by implementation of explicit augmenting measures\n\
    \      to reduce or remove a substantial measure of system software\n      vulnerability\
    \ together with specific limitation of the security\n      clearance levels of\
    \ users permitted concurrent access to the\n      system.\n   $ cookie\n     \
    \ (I) access control usage: A synonym for \"capability\" or \"ticket\"\n     \
    \ in an access control system.\n      (I) IPsec usage: Data exchanged by ISAKMP\
    \ to prevent certain\n      denial-of-service attacks during the establishment\
    \ of a security\n      association.\n      (I) HTTP usage: Data exchanged between\
    \ an HTTP server and a\n      browser (a client of the server) to store state\
    \ information on the\n      client side and retrieve it later for server use.\n\
    \      (C) An HTTP server, when sending data to a client, may send along\n   \
    \   a cookie, which the client retains after the HTTP connection\n      closes.\
    \ A server can use this mechanism to maintain persistent\n      client-side state\
    \ information for HTTP-based applications,\n      retrieving the state information\
    \ in later connections. A cookie\n      may include a description of the range\
    \ of URLs for which the state\n      is valid. Future requests made by the client\
    \ in that range will\n      also send the current value of the cookie to the server.\
    \ Cookies\n      can be used to generate profiles of web usage habits, and thus\
    \ may\n      infringe on personal privacy.\n   $ Coordinated Universal Time (UTC)\n\
    \      (N) UTC is derived from International Atomic Time (TAI) by adding\n   \
    \   a number of leap seconds. The International Bureau of Weights and\n      Measures\
    \ computes TAI once each month by averaging data from many\n      laboratories.\
    \ (See: GeneralizedTime, UTCTime.)\n   $ copy\n      See: card copy.\n   $ correctness\
    \ integrity\n      (I) Accuracy and consistency of the information that data values\n\
    \      represent, rather than of the data itself. Closely related to\n      issues\
    \ of accountability and error handling. (See: data integrity,\n      source integrity.)\n\
    \   $ correctness proof\n      (I) A mathematical proof of consistency between\
    \ a specification\n      for system security and the implementation of that specification.\n\
    \      (See: formal specification.)\n   $ countermeasure\n      (I) An action,\
    \ device, procedure, or technique that reduces a\n      threat, a vulnerability,\
    \ or an attack by eliminating or preventing\n      it, by minimizing the harm\
    \ it can cause, or by discovering and\n      reporting it so that corrective action\
    \ can be taken.\n      (C) In an Internet protocol, a countermeasure may take\
    \ the form of\n      a protocol feature, an element function, or a usage constraint.\n\
    \   $ country code\n      (I) An identifier that is defined for a nation by ISO.\
    \ [I3166]\n      (C) For each nation, ISO Standard 3166 defines a unique two-\n\
    \      character alphabetic code, a unique three-character alphabetic\n      code,\
    \ and a three-digit code. Among many uses of these codes, the\n      two-character\
    \ codes are used as top-level domain names.\n   $ covert channel\n      (I) A\
    \ intra-system channel that permits two cooperating entities,\n      without exceeding\
    \ their access authorizations, to transfer\n      information in a way that violates\
    \ the system's security policy.\n      (See: channel, out of band.)\n      (O)\
    \ \"A communications channel that allows two cooperating\n      processes to transfer\
    \ information in a manner that violates the\n      system's security policy.\"\
    \ [NCS04]\n      (C) The cooperating entities can be either two insiders or an\n\
    \      insider and an outsider. Of course, an outsider has no access\n      authorization\
    \ at all. A covert channel is a system feature that\n      the system architects\
    \ neither designed nor intended for\n      information transfer:\n       - \"\
    Timing channel\": A system feature that enable one system\n         entity to\
    \ signal information to another by modulating its own\n         use of a system\
    \ resource in such a way as to affect system\n         response time observed\
    \ by the second entity.\n       - \"Storage channel\": A system feature that enables\
    \ one system\n         entity to signal information to another entity by directly\
    \ or\n         indirectly writing a storage location that is later directly or\n\
    \         indirectly read by the second entity.\n   $ CPS\n      See: certification\
    \ practice statement.\n   $ cracker\n      (I) Someone who tries to break the\
    \ security of, and gain access\n      to, someone else's system without being\
    \ invited to do so. (See:\n      hacker and intruder.)\n   $ CRAM\n      See:\
    \ Challenge-Response Authentication Mechanism.\n   $ CRC\n      See: cyclic redundancy\
    \ check.\n   $ credential(s)\n      (I) Data that is transferred or presented\
    \ to establish either a\n      claimed identity or the authorizations of a system\
    \ entity. (See:\n      authentication information, capability, ticket.)\n    \
    \  (O) \"Data that is transferred to establish the claimed identity of\n     \
    \ an entity.\" [I7498 Part 2]\n   $ critical\n      1. (I) \"Critical\" system\
    \ resource: A condition of a service or\n      other system resource such that\
    \ denial of access to (i.e., lack of\n      availability of) that resource would\
    \ jeopardize a system user's\n      ability to perform a primary function or would\
    \ result in other\n      serious consequences. (See: availability, sensitive.)\n\
    \      2. (N) \"Critical\" extension: Each extension of an X.509\n      certificate\
    \ (or CRL) is marked as being either critical or non-\n      critical. If an extension\
    \ is critical and a certificate user (or\n      CRL user) does not recognize the\
    \ extension type or does not\n      implement its semantics, then the user is\
    \ required to treat the\n      certificate (or CRL) as invalid. If an extension\
    \ is non-critical,\n      a user that does not recognize or implement that extension\
    \ type is\n      permitted to ignore the extension and process the rest of the\n\
    \      certificate (or CRL).\n   $ CRL\n      See: certificate revocation list.\n\
    \   $ CRL distribution point\n      See: distribution point.\n   $ CRL extension\n\
    \      See: extension.\n   $ cross-certificate\n      See: cross-certification.\n\
    \   $ cross-certification\n      (I) The act or process by which two CAs each\
    \ certify a public key\n      of the other, issuing a public-key certificate to\
    \ that other CA.\n      (C) Cross-certification enables users to validate each\
    \ other's\n      certificate when the users are certified under different\n  \
    \    certification hierarchies.\n   $ cryptanalysis\n      (I) The mathematical\
    \ science that deals with analysis of a\n      cryptographic system in order to\
    \ gain knowledge needed to break or\n      circumvent the protection that the\
    \ system is designed to provide.\n      (See: cryptology.)\n      (O) \"The analysis\
    \ of a cryptographic system and/or its inputs and\n      outputs to derive confidential\
    \ variables and/or sensitive data\n      including cleartext.\" [I7498 Part 2]\n\
    \      (C) The \"O\" definition states the traditional goal of\n      cryptanalysis--convert\
    \ the ciphertext to plaintext (which usually\n      is cleartext) without knowing\
    \ the key--but that definition applies\n      only to encryption systems. Today,\
    \ the term is used with reference\n      to all kinds of cryptographic algorithms\
    \ and key management, and\n      the \"I\" definition reflects that. In all cases,\
    \ however, a\n      cryptanalyst tries to uncover or reproduce someone else's\n\
    \      sensitive data, such as cleartext, a key, or an algorithm. The\n      basic\
    \ cryptanalytic attacks on encryption systems are ciphertext-\n      only, known-plaintext,\
    \ chosen-plaintext, and chosen-ciphertext;\n      and these generalize to the\
    \ other kinds of cryptography.\n   $ crypto\n      (D) Except as part of certain\
    \ long-established terms listed in\n      this Glossary, ISDs SHOULD NOT use this\
    \ abbreviated term because\n      it may be misunderstood. Instead, use \"cryptography\"\
    \ or\n      \"cryptographic\".\n   $ cryptographic algorithm\n      (I) An algorithm\
    \ that employs the science of cryptography,\n      including encryption algorithms,\
    \ cryptographic hash algorithms,\n      digital signature algorithms, and key\
    \ agreement algorithms.\n   $ cryptographic application programming interface\
    \ (CAPI)\n      (I) The source code formats and procedures through which an\n\
    \      application program accesses cryptographic services, which are\n      defined\
    \ abstractly compared to their actual implementation. For\n      example, see:\
    \ PKCS #11, [R2628].\n   $ cryptographic card\n      (I) A cryptographic token\
    \ in the form of a smart card or a PC\n      card.\n   $ cryptographic component\n\
    \      (I) A generic term for any system component that involves\n      cryptography.\
    \ (See: cryptographic module.)\n   $ cryptographic hash\n      See: (secondary\
    \ definition under) hash function.\n   $ cryptographic ignition key (CIK)\n  \
    \    (I) A physical (usually electronic) token used to store,\n      transport,\
    \ and protect cryptographic keys. (Sometimes abbreviated\n      as \"crypto ignition\
    \ key\".)\n      (C) A typical use is to divide a split key between a CIK and\
    \ a\n      cryptographic module, so that it is necessary to combine the two\n\
    \      to regenerate a key-encrypting key and thus activate the module\n     \
    \ and other keys it contains.\n   $ cryptographic key\n      (I) Usually shortened\
    \ to just \"key\". An input parameter that\n      varies the transformation performed\
    \ by a cryptographic algorithm.\n      (O) \"A sequence of symbols that controls\
    \ the operations of\n      encipherment and decipherment.\" [I7498 Part 2]\n \
    \     (C) If a key value needs to be kept secret, the sequence of\n      symbols\
    \ (usually bits) that comprise it should be random, or at\n      least pseudo-random,\
    \ because that makes the key hard for an\n      adversary to guess. (See: cryptanalysis,\
    \ brute force attack.)\n   $ Cryptographic Message Syntax (CMS)\n      (I) A encapsulation\
    \ syntax for digital signatures, hashes, and\n      encryption of arbitrary messages.\
    \ [R2630]\n      (C) CMS was derived from PKCS #7. CMS values are specified with\n\
    \      ASN.1 and use BER encoding. The syntax permits multiple\n      encapsulation\
    \ with nesting, permits arbitrary attributes to be\n      signed along with message\
    \ content, and supports a variety of\n      architectures for digital certificate-based\
    \ key management.\n   $ cryptographic module\n      (I) A set of hardware, software,\
    \ firmware, or some combination\n      thereof that implements cryptographic logic\
    \ or processes,\n      including cryptographic algorithms, and is contained within\
    \ the\n      module's cryptographic boundary, which is an explicitly defined\n\
    \      contiguous perimeter that establishes the physical bounds of the\n    \
    \  module. [FP140]\n   $ cryptographic system\n      (I) A set of cryptographic\
    \ algorithms together with the key\n      management processes that support use\
    \ of the algorithms in some\n      application context.\n      (C) This \"I\"\
    \ definition covers a wider range of algorithms than\n      the following \"O\"\
    \ definition:\n      (O) \"A collection of transformations from plaintext into\n\
    \      ciphertext and vice versa [which would exclude digital signature,\n   \
    \   cryptographic hash, and key agreement algorithms], the particular\n      transformation(s)\
    \ to be used being selected by keys. The\n      transformations are normally defined\
    \ by a mathematical algorithm.\"\n      [X509]\n   $ cryptographic token\n   \
    \   (I) A portable, user-controlled, physical device used to store\n      cryptographic\
    \ information and possibly perform cryptographic\n      functions. (See: cryptographic\
    \ card, token.)\n      (C) A smart token may implement some set of cryptographic\n\
    \      algorithms and may implement related algorithms and key management\n  \
    \    functions, such as a random number generator. A smart\n      cryptographic\
    \ token may contain a cryptographic module or may not\n      be explicitly designed\
    \ that way.\n   $ cryptography\n      (I) The mathematical science that deals\
    \ with transforming data to\n      render its meaning unintelligible (i.e., to\
    \ hide its semantic\n      content), prevent its undetected alteration, or prevent\
    \ its\n      unauthorized use. If the transformation is reversible,\n      cryptography\
    \ also deals with restoring encrypted data to\n      intelligible form. (See:\
    \ cryptology, steganography.)\n      (O) \"The discipline which embodies principles,\
    \ means, and methods\n      for the transformation of data in order to hide its\
    \ information\n      content, prevent its undetected modification and/or prevent\
    \ its\n      unauthorized use. . . . Cryptography determines the methods used\n\
    \      in encipherment and decipherment.\" [I7498 Part 2]\n   $ Cryptoki\n   \
    \   See: (secondary definition under) PKCS #11.\n   $ cryptology\n      (I) The\
    \ science that includes both cryptography and cryptanalysis,\n      and sometimes\
    \ is said to include steganography.\n   $ cryptonet\n      (I) A group of system\
    \ entities that share a secret cryptographic\n      key for a symmetric algorithm.\n\
    \   $ cryptoperiod\n      (I) The time span during which a particular key is authorized\
    \ to\n      be used in a cryptographic system. (See: key management.)\n      (C)\
    \ A cryptoperiod is usually stated in terms of calendar or clock\n      time,\
    \ but sometimes is stated in terms of the maximum amount of\n      data permitted\
    \ to be processed by a cryptographic algorithm using\n      the key. Specifying\
    \ a cryptoperiod involves a tradeoff between the\n      cost of rekeying and the\
    \ risk of successful cryptanalysis.\n      (C) Although we deprecate its prefix,\
    \ this term is long-\n      established in COMPUSEC usage. (See: crypto) In the\
    \ context of\n      certificates and public keys, \"key lifetime\" and \"validity\
    \ period\"\n      are often used instead.\n   $ cryptosystem\n      (D) ISDs SHOULD\
    \ NOT use this term as an abbreviation for\n      cryptographic system. (For rationale,\
    \ see: crypto.)\n   $ CSIRT\n      See: computer security incident response team.\n\
    \   $ CSOR\n      See: Computer Security Objects Register.\n   $ cut-and-paste\
    \ attack\n      (I) An active attack on the data integrity of ciphertext, effected\n\
    \      by replacing sections of ciphertext with other ciphertext, such\n     \
    \ that the result appears to decrypt correctly but actually decrypts\n      to\
    \ plaintext that is forged to the satisfaction of the attacker.\n   $ cyclic redundancy\
    \ check (CRC)\n      (I) Sometimes called \"cyclic redundancy code\". A type of\
    \ checksum\n      algorithm that is not a cryptographic hash but is used to\n\
    \      implement data integrity service where accidental changes to data\n   \
    \   are expected.\n   $ DAC\n      See: Data Authentication Code, discretionary\
    \ access control.\n   $ DASS\n      See: Distributed Authentication Security Service.\n\
    \   $ data\n      (I) Information in a specific physical representation, usually\
    \ a\n      sequence of symbols that have meaning; especially a representation\n\
    \      of information that can be processed or produced by a computer.\n   $ Data\
    \ Authentication Algorithm\n      (N) A keyed hash function equivalent to DES\
    \ cipher block chaining\n      with IV = 0. [A9009]\n      (D) ISDs SHOULD NOT\
    \ use the uncapitalized form of this term as a\n      synonym for other kinds\
    \ of checksums.\n   $ data authentication code vs. Data Authentication Code (DAC)\n\
    \      1. (N) Capitalized: \"The Data Authentication Code\" refers to a\n    \
    \  U.S. Government standard [FP113] for a checksum that is computed\n      by\
    \ the Data Authentication Algorithm. (Also known as the ANSI\n      standard Message\
    \ Authentication Code [A9009].)\n      2. (D) Not capitalized: ISDs SHOULD NOT\
    \ use \"data authentication\n      code\" as a synonym for another kind of checksum,\
    \ because this term\n      mixes concepts in a potentially misleading way. (See:\n\
    \      authentication code.) Instead, use \"checksum\", \"error detection\n  \
    \    code\", \"hash\", \"keyed hash\", \"Message Authentication Code\", or\n \
    \     \"protected checksum\", depending on what is meant.\n   $ data compromise\n\
    \      (I) A security incident in which information is exposed to\n      potential\
    \ unauthorized access, such that unauthorized disclosure,\n      alteration, or\
    \ use of the information may have occurred. (See:\n      compromise.)\n   $ data\
    \ confidentiality\n      (I) \"The property that information is not made available\
    \ or\n      disclosed to unauthorized individuals, entities, or processes\n  \
    \    [i.e., to any unauthorized system entity].\" [I7498 Part 2]. (See:\n    \
    \  data confidentiality service.)\n      (D) ISDs SHOULD NOT use this term as\
    \ a synonym for \"privacy\",\n      which is a different concept.\n   $ data confidentiality\
    \ service\n      (I) A security service that protects data against unauthorized\n\
    \      disclosure. (See: data confidentiality.)\n      (D) ISDs SHOULD NOT use\
    \ this term as a synonym for \"privacy\",\n      which is a different concept.\n\
    \   $ Data Encryption Algorithm (DEA)\n      (N) A symmetric block cipher, defined\
    \ as part of the U.S.\n      Government's Data Encryption Standard. DEA uses a\
    \ 64-bit key, of\n      which 56 bits are independently chosen and 8 are parity\
    \ bits, and\n      maps a 64-bit block into another 64-bit block. [FP046] (See:\
    \ DES,\n      symmetric cryptography.)\n      (C) This algorithm is usually referred\
    \ to as \"DES\". The algorithm\n      has also been adopted in standards outside\
    \ the Government (e.g.,\n      [A3092]).\n   $ data encryption key (DEK)\n   \
    \   (I) A cryptographic key that is used to encipher application data.\n     \
    \ (See: key-encrypting key.)\n   $ Data Encryption Standard (DES)\n      (N) A\
    \ U.S. Government standard [FP046] that specifies the Data\n      Encryption Algorithm\
    \ and states policy for using the algorithm to\n      protect unclassified, sensitive\
    \ data. (See: AES, DEA.)\n   $ data integrity\n      (I) The property that data\
    \ has not been changed, destroyed, or\n      lost in an unauthorized or accidental\
    \ manner. (See: data integrity\n      service.)\n      (O) \"The property that\
    \ information has not been modified or\n      destroyed in an unauthorized manner.\"\
    \ [I7498 Part 2]\n      (C) Deals with constancy of and confidence in data values,\
    \ not\n      with the information that the values represent (see: correctness\n\
    \      integrity) or the trustworthiness of the source of the values\n      (see:\
    \ source integrity).\n   $ data integrity service\n      (I) A security service\
    \ that protects against unauthorized changes\n      to data, including both intentional\
    \ change or destruction and\n      accidental change or loss, by ensuring that\
    \ changes to data are\n      detectable. (See: data integrity.)\n      (C) A data\
    \ integrity service can only detect a change and report\n      it to an appropriate\
    \ system entity; changes cannot be prevented\n      unless the system is perfect\
    \ (error-free) and no malicious user\n      has access. However, a system that\
    \ offers data integrity service\n      might also attempt to correct and recover\
    \ from changes.\n      (C) Relationship between data integrity service and authentication\n\
    \      services: Although data integrity service is defined separately\n     \
    \ from data origin authentication service and peer entity\n      authentication\
    \ service, it is closely related to them.\n      Authentication services depend,\
    \ by definition, on companion data\n      integrity services. Data origin authentication\
    \ service provides\n      verification that the identity of the original source\
    \ of a\n      received data unit is as claimed; there can be no such\n      verification\
    \ if the data unit has been altered. Peer entity\n      authentication service\
    \ provides verification that the identity of\n      a peer entity in a current\
    \ association is as claimed; there can be\n      no such verification if the claimed\
    \ identity has been altered.\n   $ data origin authentication\n      (I) \"The\
    \ corroboration that the source of data received is as\n      claimed.\" [I7498\
    \ Part 2] (See: authentication.)\n   $ data origin authentication service\n  \
    \    (I) A security service that verifies the identity of a system\n      entity\
    \ that is claimed to be the original source of received data.\n      (See: authentication,\
    \ authentication service.)\n      (C) This service is provided to any system entity\
    \ that receives or\n      holds the data. Unlike peer entity authentication service,\
    \ this\n      service is independent of any association between the originator\n\
    \      and the recipient, and the data in question may have originated at\n  \
    \    any time in the past.\n      (C) A digital signature mechanism can be used\
    \ to provide this\n      service, because someone who does not know the private\
    \ key cannot\n      forge the correct signature. However, by using the signer's\
    \ public\n      key, anyone can verify the origin of correctly signed data.\n\
    \      (C) This service is usually bundled with connectionless data\n      integrity\
    \ service. (See: (relationship between data integrity\n      service and authentication\
    \ services under) data integrity service.\n   $ data privacy\n      (D) ISDs SHOULD\
    \ NOT use this term because it mix concepts in a\n      potentially misleading\
    \ way. Instead, use either \"data\n      confidentiality\" or \"privacy\", depending\
    \ on what is meant.\n   $ data security\n      (I) The protection of data from\
    \ disclosure, alteration,\n      destruction, or loss that either is accidental\
    \ or is intentional\n      but unauthorized.\n      (C) Both data confidentiality\
    \ service and data integrity service\n      are needed to achieve data security.\n\
    \   $ datagram\n      (I) \"A self-contained, independent entity of data carrying\n\
    \      sufficient information to be routed from the source to the\n      destination.\"\
    \ [R1983]\n   $ DEA\n      See: Data Encryption Algorithm.\n   $ deception\n \
    \     See: (secondary definition under) threat consequence.\n   $ decipher\n \
    \     (D) ISDs SHOULD NOT use this term as a synonym for \"decrypt\",\n      except\
    \ in special circumstances. (See: (usage discussion under)\n      encryption.)\n\
    \   $ decipherment\n      (D) ISDs SHOULD NOT use this term as a synonym for \"\
    decryption\",\n      except in special circumstances. (See: (usage discussion\
    \ under)\n      encryption.)\n   $ decode\n      (I) Convert encoded data back\
    \ to its original form of\n      representation. (See: decrypt.)\n      (D) ISDs\
    \ SHOULD NOT use this term as a synonym for \"decrypt\",\n      because that would\
    \ mix concepts in a potentially misleading way.\n   $ decrypt\n      (I) Cryptographically\
    \ restore ciphertext to the plaintext form it\n      had before encryption.\n\
    \   $ decryption\n      See: (secondary definition under) encryption.\n   $ dedicated\
    \ security mode\n      (I) A mode of operation of an information system, wherein\
    \ all\n      users have the clearance or authorization, and the need-to-know,\n\
    \      for all data handled by the system. In this mode, the system may\n    \
    \  handle either a single classification level or category of\n      information\
    \ or a range of levels and categories. [DOD2]\n      (C) This mode is defined\
    \ formally in U.S. Department of Defense\n      policy regarding system accreditation,\
    \ but the term is also used\n      outside the Defense Department and outside\
    \ the Government.\n   $ default account\n      (I) A system login account (usually\
    \ accessed with a user name and\n      password) that has been predefined in a\
    \ manufactured system to\n      permit initial access when the system is first\
    \ put into service.\n      (C) Sometimes, the default user name and password are\
    \ the same in\n      each copy of the system. In any case, when the system is\
    \ put into\n      service, the default password should immediately be changed\
    \ or the\n      default account should be disabled.\n   $ degauss\n      (N) Apply\
    \ a magnetic field to permanently remove, erase, or clear\n      data from a magnetic\
    \ storage medium, such as a tape or disk\n      [NCS25]. Reduce magnetic flux\
    \ density to zero by applying a\n      reversing magnetic field.\n   $ degausser\n\
    \      (N) An electrical device that can degauss magnetic storage media.\n   $\
    \ DEK\n      See: data encryption key.\n   $ delta CRL\n      (I) A partial CRL\
    \ that only contains entries for X.509\n      certificates that have been revoked\
    \ since the issuance of a prior,\n      base CRL. This method can be used to partition\
    \ CRLs that become\n      too large and unwieldy.\n   $ denial of service\n  \
    \    (I) The prevention of authorized access to a system resource or\n      the\
    \ delaying of system operations and functions. (See:\n      availability, critical\
    \ (resource of a system), flooding.)\n   $ DES\n      See: Data Encryption Standard.\n\
    \   $ dictionary attack\n      (I) An attack that uses a brute-force technique\
    \ of successively\n      trying all the words in some large, exhaustive list.\n\
    \      (C) For example, an attack on an authentication service by trying\n   \
    \   all possible passwords; or an attack on encryption by encrypting\n      some\
    \ known plaintext phrase with all possible keys so that the key\n      for any\
    \ given encrypted message containing that phrase may be\n      obtained by lookup.\n\
    \   $ Diffie-Hellman\n      (N) A key agreement algorithm published in 1976 by\
    \ Whitfield\n      Diffie and Martin Hellman [DH76, R2631].\n      (C) Diffie-Hellman\
    \ does key establishment, not encryption.\n      However, the key that it produces\
    \ may be used for encryption, for\n      further key management operations, or\
    \ for any other cryptography.\n      (C) The difficulty of breaking Diffie-Hellman\
    \ is considered to be\n      equal to the difficulty of computing discrete logarithms\
    \ modulo a\n      large prime. The algorithm is described in [R2631] and [Schn].\
    \ In\n      brief, Alice and Bob together pick large integers that satisfy\n \
    \     certain mathematical conditions, and then use the integers to each\n   \
    \   separately compute a public-private key pair. They send each other\n     \
    \ their public key. Each person uses their own private key and the\n      other\
    \ person's public key to compute a key, k, that, because of\n      the mathematics\
    \ of the algorithm, is the same for each of them.\n      Passive wiretapping cannot\
    \ learn the shared k, because k is not\n      transmitted, and neither are the\
    \ private keys needed to compute k.\n      However, without additional mechanisms\
    \ to authenticate each party\n      to the other, a protocol based on the algorithm\
    \ may be vulnerable\n      to a man-in-the-middle attack.\n   $ digest\n     \
    \ See: message digest.\n   $ digital certificate\n      (I) A certificate document\
    \ in the form of a digital data object (a\n      data object used by a computer)\
    \ to which is appended a computed\n      digital signature value that depends\
    \ on the data object. (See:\n      attribute certificate, capability, public-key\
    \ certificate.)\n      (D) ISDs SHOULD NOT use this term to refer to a signed\
    \ CRL or CKL.\n      Although the recommended definition can be interpreted to\
    \ include\n      those items, the security community does not use the term with\n\
    \      those meanings.\n   $ digital certification\n      (D) ISDs SHOULD NOT\
    \ use this term as a synonym for\n      \"certification\", unless the context\
    \ is not sufficient to\n      distinguish between digital certification and another\
    \ kind of\n      certification, in which case it would be better to use \"public-key\n\
    \      certification\" or another phrase that indicates what is being\n      certified.\n\
    \   $ digital document\n      (I) An electronic data object that represents information\n\
    \      originally written in a non-electronic, non-magnetic  medium\n      (usually\
    \ ink on paper) or is an analogue of a document of that\n      type.\n   $ digital\
    \ envelope\n      (I) A digital envelope for a recipient is a combination of (a)\n\
    \      encrypted content data (of any kind) and (b) the content\n      encryption\
    \ key in an encrypted form that has been prepared for the\n      use of the recipient.\n\
    \      (C) In ISDs, this term should be defined at the point of first use\n  \
    \    because, although the term is defined in PKCS #7 and used in\n      S/MIME,\
    \ it is not yet widely established.\n      (C) Digital enveloping is not simply\
    \ a synonym for implementing\n      data confidentiality with encryption; digital\
    \ enveloping is a\n      hybrid encryption scheme to \"seal\" a message or other\
    \ data, by\n      encrypting the data and sending both it and a protected form\
    \ of\n      the key to the intended recipient, so that no one other than the\n\
    \      intended recipient can \"open\" the message. In PCKS #7, it means\n   \
    \   first encrypting the data using a symmetric encryption algorithm\n      and\
    \ a secret key, and then encrypting the secret key using an\n      asymmetric\
    \ encryption algorithm and the public key of the intended\n      recipient. In\
    \ S/MIME, additional methods are defined for\n      conveying the content encryption\
    \ key.\n   $ Digital ID(service mark)\n      (D) ISDs SHOULD NOT use this term\
    \ as a synonym for \"digital\n      certificate\" because (a) it is the service\
    \ mark of a commercial\n      firm, (b) it unnecessarily duplicates the meaning\
    \ of other, well-\n      established terms, and (c) a certificate is not always\
    \ used as\n      authentication information. In some contexts, however, it may\
    \ be\n      useful to explain that the key conveyed in a public-key\n      certificate\
    \ can be used to verify an identity and, therefore, that\n      the certificate\
    \ can be thought of as digital identification\n      information. (See: identification\
    \ information.)\n   $ digital key\n      (C) The adjective \"digital\" need not\
    \ be used with \"key\" or\n      \"cryptographic key\", unless the context is\
    \ insufficient to\n      distinguish the digital key from another kind of key,\
    \ such as a\n      metal key for a door lock.\n   $ digital notary\n      (I)\
    \ Analogous to a notary public. Provides a trusted date-and-time\n      stamp\
    \ for a document, so that someone can later prove that the\n      document existed\
    \ at a point in time. May also verify the\n      signature(s) on a signed document\
    \ before applying the stamp. (See:\n      notarization.)\n   $ digital signature\n\
    \      (I) A value computed with a cryptographic algorithm and appended\n    \
    \  to a data object in such a way that any recipient of the data can\n      use\
    \ the signature to verify the data's origin and integrity. (See:\n      data origin\
    \ authentication service, data integrity service,\n      digitized signature,\
    \ electronic signature, signer.)\n      (I) \"Data appended to, or a cryptographic\
    \ transformation of, a\n      data unit that allows a recipient of the data unit\
    \ to prove the\n      source and integrity of the data unit and protect against\
    \ forgery,\n      e.g. by the recipient.\" [I7498 Part 2]\n      (C) Typically,\
    \ the data object is first input to a hash function,\n      and then the hash\
    \ result is cryptographically transformed using a\n      private key of the signer.\
    \ The final resulting value is called the\n      digital signature of the data\
    \ object. The signature value is a\n      protected checksum, because the properties\
    \ of a cryptographic hash\n      ensure that if the data object is changed, the\
    \ digital signature\n      will no longer match it. The digital signature is unforgeable\n\
    \      because one cannot be certain of correctly creating or changing\n     \
    \ the signature without knowing the private key of the supposed\n      signer.\n\
    \      (C) Some digital signature schemes use a asymmetric encryption\n      algorithm\
    \ (e.g., see: RSA) to transform the hash result. Thus,\n      when Alice needs\
    \ to sign a message to send to Bob, she can use her\n      private key to encrypt\
    \ the hash result. Bob receives both the\n      message and the digital signature.\
    \ Bob can use Alice's public key\n      to decrypt the signature, and then compare\
    \ the plaintext result to\n      the hash result that he computes by hashing the\
    \ message himself.\n      If the values are equal, Bob accepts the message because\
    \ he is\n      certain that it is from Alice and has arrived unchanged. If the\n\
    \      values are not equal, Bob rejects the message because either the\n    \
    \  message or the signature was altered in transit.\n      (C) Other digital signature\
    \ schemes (e.g., see: DSS) transform the\n      hash result with an algorithm\
    \ (e.g., see: DSA, El Gamal) that\n      cannot be directly used to encrypt data.\
    \ Such a scheme creates a\n      signature value from the hash and provides a\
    \ way to verify the\n      signature value, but does not provide a way to recover\
    \ the hash\n      result from the signature value. In some countries, such a scheme\n\
    \      may improve exportability and avoid other legal constraints on\n      usage.\n\
    \   $ Digital Signature Algorithm (DSA)\n      (N) An asymmetric cryptographic\
    \ algorithm that produces a digital\n      signature in the form of a pair of\
    \ large numbers. The signature is\n      computed using rules and parameters such\
    \ that the identity of the\n      signer and the integrity of the signed data\
    \ can be verified. (See:\n      Digital Signature Standard.)\n   $ Digital Signature\
    \ Standard (DSS)\n      (N) The U.S. Government standard [FP186] that specifies\
    \ the\n      Digital Signature Algorithm (DSA), which involves asymmetric\n  \
    \    cryptography.\n   $ digital watermarking\n      (I) Computing techniques\
    \ for inseparably embedding unobtrusive\n      marks or labels as bits in digital\
    \ data--text, graphics, images,\n      video, or audio--and for detecting or extracting\
    \ the marks later.\n      (C) The set of embedded bits (the digital watermark)\
    \ is sometimes\n      hidden, usually imperceptible, and always intended to be\n\
    \      unobtrusive. Depending on the particular technique that is used,\n    \
    \  digital watermarking can assist in proving ownership, controlling\n      duplication,\
    \ tracing distribution, ensuring data integrity, and\n      performing other functions\
    \ to protect intellectual property\n      rights. [ACM]\n   $ digitized signature\n\
    \      (D) ISDs SHOULD NOT use this term because there is no current\n      consensus\
    \ on its definition. Although it appears to be used mainly\n      to refer to\
    \ various forms of digitized images of handwritten\n      signatures, the term\
    \ should be avoided because it might be\n      confused with \"digital signature\"\
    .\n   $ directory\n   $ Directory\n      See: directory vs. Directory.\n   $ Directory\
    \ Access Protocol (DAP)\n      (N) An OSI protocol [X519] for communication between\
    \ a Directory\n      User Agent (a client) and a Directory System Agent (a server).\n\
    \      (See: Lightweight Directory Access Protocol.)\n   $ directory vs. Directory\n\
    \      1. (I) Not capitalized: The term \"directory\" refers generically to\n\
    \      a database server or other system that provides information--such\n   \
    \   as a digital certificate or CRL--about an entity whose name is\n      known.\n\
    \      2. (I) Capitalized: \"Directory\" refers specifically to the X.500\n  \
    \    Directory. (See: repository.)\n   $ disaster plan\n      (D) A synonym for\
    \ \"contingency plan\". In the interest of\n      consistency, ISDs SHOULD use\
    \ \"contingency plan\" instead of\n      \"disaster plan\".\n   $ disclosure (i.e.,\
    \ unauthorized disclosure)\n      See: (secondary definition under) threat consequence.\n\
    \   $ discretionary access control (DAC)\n      (I) An access control service\
    \ that enforces a security policy\n      based on the identity of system entities\
    \ and their authorizations\n      to access system resources. (See: access control\
    \ list, identity-\n      based security policy, mandatory access control.)\n \
    \     (C) This service is termed \"discretionary\" because an entity might\n \
    \     have access rights that permit the entity, by its own volition, to\n   \
    \   enable another entity to access some resource.\n      (O) \"A means of restricting\
    \ access to objects based on the\n      identity of subjects and/or groups to\
    \ which they belong. The\n      controls are discretionary in the sense that a\
    \ subject with a\n      certain access permission is capable of passing that permission\n\
    \      (perhaps indirectly) on to any other subject.\" [DOD1]\n   $ disruption\n\
    \      See: (secondary definition under) threat consequence.\n   $ Distinguished\
    \ Encoding Rules (DER)\n      (N) A subset of the Basic Encoding Rules, which\
    \ gives exactly one\n      way to represent any ASN.1 value as an octet string\
    \ [X690].\n      (C) Since there is more than one way to encode ASN.1 in BER,\
    \ DER\n      is used in applications in which a unique encoding is needed, such\n\
    \      as when a digital signature is computed on an ASN.1 value.\n   $ distinguished\
    \ name (DN)\n      (I) An identifier that uniquely represents an object in the\
    \ X.500\n      Directory Information Tree (DIT) [X501]. (See: domain name.)\n\
    \      (C) A DN is a set of attribute values that identify the path\n      leading\
    \ from the base of the DIT to the object that is named. An\n      X.509 public-key\
    \ certificate or CRL contains a DN that identifies\n      its issuer, and an X.509\
    \ attribute certificate contains a DN or\n      other form of name that identifies\
    \ its subject.\n   $ Distributed Authentication Security Service (DASS)\n    \
    \  (I) An experimental Internet protocol [R1507] that uses\n      cryptographic\
    \ mechanisms to provide strong, mutual authentication\n      services in a distributed\
    \ environment.\n   $ distribution point\n      (I) An X.500 Directory entry or\
    \ other information source that is\n      named in a v3 X.509 public-key certificate\
    \ extension as a location\n      from which to obtain a CRL that might list the\
    \ certificate.\n      (C) A v3 X.509 public-key certificate may have a\n     \
    \ \"cRLDistributionPoints\" extension that names places to get CRLs on\n     \
    \ which the certificate might be listed. A CRL obtained from a\n      distribution\
    \ point may (a) cover either all reasons for which a\n      certificate might\
    \ be revoked or only some of the reasons, (b) be\n      issued by either the authority\
    \ that signed the certificate or some\n      other authority, and (c) contain\
    \ revocation entries for only a\n      subset of the full set of certificates\
    \ issued by one CA or (c')\n      contain revocation entries for multiple CAs.\n\
    \   $ DN\n      See: distinguished name.\n   $ DNS\n      See: Domain Name System.\n\
    \   $ DOI\n      See: Domain of Interpretation.\n   $ domain\n      (I) Security\
    \ usage: An environment or context that is defined by a\n      security policy,\
    \ security model, or security architecture to\n      include a set of system resources\
    \ and the set of system entities\n      that have the right to access the resources.\
    \ (See: domain of\n      interpretation, security perimeter.)\n      (I) Internet\
    \ usage: That part of the Internet domain name space\n      tree [R1034] that\
    \ is at or below the name the specifies the\n      domain. A domain is a subdomain\
    \ of another domain if it is\n      contained within that domain. For example,\
    \ D.C.B.A is a subdomain\n      of C.B.A. (See: Domain Name System.)\n      (O)\
    \ MISSI usage: The domain of a MISSI CA is the set of MISSI\n      users whose\
    \ certificates are signed by the CA.\n      (O) OSI usage: An administrative partition\
    \ of a complex\n      distributed OSI system.\n   $ domain name\n      (I) The\
    \ style of identifier--a sequence of case-insensitive ASCII\n      labels separated\
    \ by dots (\"bbn.com.\")--defined for subtrees in the\n      Internet Domain Name\
    \ System [R1034] and used in other Internet\n      identifiers, such as host names\
    \ (e.g., \"rosslyn.bbn.com.\"),\n      mailbox names (e.g., \"rshirey@bbn.com.\"\
    ), and URLs (e.g.,\n      \"http://www.rosslyn.bbn.com/foo\"). (See: distinguished\
    \ name,\n      domain.)\n      (C) The domain name space of the DNS is a tree\
    \ structure in which\n      each node and leaf holds records describing a resource.\
    \ Each node\n      has a label. The domain name of a node is the list of labels\
    \ on\n      the path from the node to the root of the tree. The labels in a\n\
    \      domain name are printed or read left to right, from the most\n      specific\
    \ (lowest, farthest from the root) to the least specific\n      (highest, closest\
    \ to the root). The root's label is the null\n      string, so a complete domain\
    \ name properly ends in a dot. The top-\n      level domains, those immediately\
    \ below the root, include COM, EDU,\n      GOV, INT, MIL, NET, ORG, and two-letter\
    \ country codes (such as US)\n      from ISO-3166. [R1591] (See: country code.)\n\
    \   $ Domain Name System (DNS)\n      (I) The main Internet operations database,\
    \ which is distributed\n      over a collection of servers and used by client\
    \ software for\n      purposes such as translating a domain name-style host name\
    \ into an\n      IP address (e.g., \"rosslyn.bbn.com\" is \"192.1.7.10\") and\
    \ locating\n      a host that accepts mail for some mailbox address. [R1034]\n\
    \      (C) The DNS has three major components:\n       - Domain name space and\
    \ resource records: Specifications for the\n         tree-structured domain name\
    \ space, and data associated with the\n         names.\n       - Name servers:\
    \ Programs that hold information about a subset of\n         the tree's structure\
    \ and data holdings, and also hold pointers\n         to other name servers that\
    \ can provide information from any\n         part of the tree.\n       - Resolvers:\
    \ Programs that extract information from name servers\n         in response to\
    \ client requests; typically, system routines\n         directly accessible to\
    \ user programs.\n      (C) Extensions to the DNS [R2065, R2137, R2536] support\
    \ (a) key\n      distribution for public keys needed for the DNS and for other\n\
    \      protocols, (b) data origin authentication service and data\n      integrity\
    \ service for resource records, (c) data origin\n      authentication service\
    \ for transactions between resolvers and\n      servers, and (d) access control\
    \ of records.\n   $ domain of interpretation (DOI)\n      (I) IPsec usage: An\
    \ ISAKMP/IKE DOI defines payload formats,\n      exchange types, and conventions\
    \ for naming security-relevant\n      information such as security policies or\
    \ cryptographic algorithms\n      and modes.\n      (C) For example, see [R2407].\
    \ The DOI concept is based on work by\n      the TSIG's CIPSO Working Group.\n\
    \   $ dominate\n      (I) Security level A is said to \"dominate\" security level\
    \ B if the\n      hierarchical classification level of A is greater (higher) than\
    \ or\n      equal to that of B and the nonhierarchical categories of A include\n\
    \      all of those of B.\n   $ dongle\n      (I) A portable, physical, electronic\
    \ device that is required to be\n      attached to a computer to enable a particular\
    \ software program to\n      run. (See: token.)\n      (C) A dongle is essentially\
    \ a physical key used for copy\n      protection of software, because the program\
    \ will not run unless\n      the matching dongle is attached. When the software\
    \ runs, it\n      periodically queries the dongle and quits if the dongle does\
    \ not\n      reply with the proper authentication information. Dongles were\n\
    \      originally constructed as an EPROM (erasable programmable read-\n     \
    \ only memory) to be connected to a serial input-output port of a\n      personal\
    \ computer.\n   $ downgrade\n      (I) Reduce the classification level of information\
    \ in an\n      authorized manner.\n   $ draft RFC\n      (D) ISDs SHOULD NOT use\
    \ this term, because the Request for Comment\n      series is archival in nature\
    \ and does not have a \"draft\" category.\n      (Instead, see: Internet Draft,\
    \ Draft Standard (in Internet\n      Standard).)\n   $ DSA\n      See: Digital\
    \ Signature Algorithm.\n   $ DSS\n      See: Digital Signature Standard.\n   $\
    \ dual control\n      (I) A procedure that uses two or more entities (usually\
    \ persons)\n      operating in concert to protect a system resource, such that\
    \ no\n      single entity acting alone can access that resource. (See: no-lone\n\
    \      zone, separation of duties, split knowledge.)\n   $ dual signature\n  \
    \    (D) ISDs SHOULD NOT use this term except when stated as\n      \"SET(trademark)\
    \ dual signature\" with the following meaning:\n      (O) SET usage: A single\
    \ digital signature that protects two\n      separate messages by including the\
    \ hash results for both sets in a\n      single encrypted value. [SET2]\n    \
    \  (C) Generated by hashing each message separately, concatenating\n      the\
    \ two hash results, and then hashing that value and encrypting\n      the result\
    \ with the signer's private key. Done to reduce the\n      number of encryption\
    \ operations and to enable verification of data\n      integrity without complete\
    \ disclosure of the data.\n   $ EAP\n      See: Extensible Authentication Protocol\n\
    \   $ eavesdropping\n      (I) Passive wiretapping done secretly, i.e., without\
    \ the knowledge\n      of the originator or the intended recipients of the communication.\n\
    \   $ ECB\n      See: electronic codebook.\n   $ ECDSA\n      See: Elliptic Curve\
    \ Digital Signature Algorithm.\n   $ economy of mechanism\n      (I) The principle\
    \ that each security mechanism should be designed\n      to be as simple as possible,\
    \ so that the mechanism can be\n      correctly implemented and so that it can\
    \ be verified that the\n      operation of the mechanism enforces the containing\
    \ system's\n      security policy. (See: least privilege.)\n   $ EDI\n      See:\
    \ electronic data interchange.\n   $ EDIFACT\n      See: (secondary definition\
    \ under) electronic data interchange.\n   $ EE\n      (D) ISDs SHOULD NOT use\
    \ this abbreviation because of possible\n      confusion among \"end entity\"\
    , \"end-to-end encryption\", \"escrowed\n      encryption standard\", and other\
    \ terms.\n   $ EES\n      See: Escrowed Encryption Standard.\n   $ El Gamal algorithm\n\
    \      (N) An algorithm for asymmetric cryptography, invented in 1985 by\n   \
    \   Taher El Gamal, that is based on the difficulty of calculating\n      discrete\
    \ logarithms and can be used for both encryption and\n      digital signatures.\
    \ [ElGa, Schn]\n   $ electronic codebook (ECB)\n      (I) An block cipher mode\
    \ in which a plaintext block is used\n      directly as input to the encryption\
    \ algorithm and the resultant\n      output block is used directly as ciphertext\
    \ [FP081].\n   $ electronic commerce\n      (I) General usage: Business conducted\
    \ through paperless exchanges\n      of information, using electronic data interchange,\
    \ electronic\n      funds transfer (EFT), electronic mail, computer bulletin boards,\n\
    \      facsimile, and other paperless technologies.\n      (O) SET usage: \"The\
    \ exchange of goods and services for payment\n      between the cardholder and\
    \ merchant when some or all of the\n      transaction is performed via electronic\
    \ communication.\" [SET2]\n   $ electronic data interchange (EDI)\n      (I) Computer-to-computer\
    \ exchange, between trading partners, of\n      business data in standardized\
    \ document formats.\n      (C) EDI formats have been standardized primarily by\
    \ ANSI X12 and\n      by EDIFACT (EDI for Administration, Commerce, and Transportation),\n\
    \      which is an international, UN-sponsored standard primarily used in\n  \
    \    Europe and Asia. X12 and EDIFACT are aligning to create a single,\n     \
    \ global EDI standard.\n   $ electronic signature\n      (D) ISDs SHOULD NOT use\
    \ this term because there is no current\n      consensus on its definition. (Instead,\
    \ see: digital signature.)\n   $ elliptic curve cryptography (ECC)\n      (I)\
    \ A type of asymmetric cryptography based on mathematics of\n      groups that\
    \ are defined by the points on a curve.\n      (C) The most efficient implementation\
    \ of ECC is claimed to be\n      stronger per bit of key (against cryptanalysis\
    \ that uses a brute\n      force attack) than any other known form of asymmetric\n\
    \      cryptography. ECC is based on mathematics different than the kinds\n  \
    \    originally used to define the Diffie-Hellman algorithm and the\n      Digital\
    \ Signature Algorithm. ECC is based on the mathematics of\n      groups defined\
    \ by the points on a curve, where the curve is\n      defined by a quadratic equation\
    \ in a finite field. ECC can be used\n      to define both an algorithm for key\
    \ agreement that is an analog of\n      Diffie-Hellman and an algorithm for digital\
    \ signature that is an\n      analog of DSA. (See: ECDSA.)\n   $ Elliptic Curve\
    \ Digital Signature Algorithm (ECDSA)\n      (N) A standard [A9062] that is the\
    \ elliptic curve cryptography\n      analog of the Digital Signature Algorithm.\n\
    \   $ emanation\n      (I) An signal (electromagnetic, acoustic, or other medium)\
    \ that is\n      emitted by a system (through radiation or conductance) as a\n\
    \      consequence (i.e., byproduct) of its operation, and that may\n      contain\
    \ information. (See: TEMPEST.)\n   $ emanations security (EMSEC)\n      (I) Physical\
    \ constraints to prevent information compromise through\n      signals emanated\
    \ by a system, particular the application of\n      TEMPEST technology to block\
    \ electromagnetic radiation.\n   $ emergency plan\n      (D) A synonym for \"\
    contingency plan\". In the interest of\n      consistency, ISDs SHOULD use \"\
    contingency plan\" instead of\n      \"emergency plan\".\n   $ EMSEC\n      See:\
    \ emanations security.\n   $ EMV\n      (I) An abbreviation of \"Europay, MasterCard,\
    \ Visa\". Refers to a\n      specification for smart cards that are used as payment\
    \ cards, and\n      for related terminals and applications. [EMV1, EMV2, EMV3]\n\
    \   $ Encapsulating Security Payload (ESP)\n      (I) An Internet IPsec protocol\
    \ [R2406] designed to provide a mix\n      of security services--especially data\
    \ confidentiality service--in\n      the Internet Protocol. (See: Authentication\
    \ Header.)\n      (C) ESP may be used alone, or in combination with the IPsec\
    \ AH\n      protocol, or in a nested fashion with tunneling. Security services\n\
    \      can be provided between a pair of communicating hosts, between a\n    \
    \  pair of communicating security gateways, or between a host and a\n      gateway.\
    \ The ESP header is encapsulated by the IP header, and the\n      ESP header encapsulates\
    \ either the upper layer protocol header\n      (transport mode) or an IP header\
    \ (tunnel mode). ESP can provide\n      data confidentiality service, data origin\
    \ authentication service,\n      connectionless data integrity service, an anti-replay\
    \ service, and\n      limited traffic flow confidentiality. The set of services\
    \ depends\n      on the placement of the implementation and on options selected\n\
    \      when the security association is established.\n   $ encipher\n      (D)\
    \ ISDs SHOULD NOT use this term as a synonym for \"encrypt\".\n      However,\
    \ see the usage note under \"encryption\".\n   $ encipherment\n      (D) ISDs\
    \ SHOULD NOT use this term as a synonym for \"encryption\",\n      except in special\
    \ circumstances that are explained in the usage\n      discussion under \"encryption\"\
    .\n   $ encode\n      (I) Use a system of symbols to represent information, which\
    \ might\n      originally have some other representation. (See: decode.)\n   \
    \   (C) Examples include Morse code, ASCII, and BER.\n      (D) ISDs SHOULD NOT\
    \ use this term as a synonym for \"encrypt\",\n      because encoding is not usually\
    \ intended to conceal meaning.\n   $ encrypt\n      (I) Cryptographically transform\
    \ data to produce ciphertext. (See:\n      encryption.)\n   $ encryption\n   \
    \   (I) Cryptographic transformation of data (called \"plaintext\") into\n   \
    \   a form (called \"ciphertext\") that conceals the data's original\n      meaning\
    \ to prevent it from being known or used. If the\n      transformation is reversible,\
    \ the corresponding reversal process\n      is called \"decryption\", which is\
    \ a transformation that restores\n      encrypted data to its original state.\
    \ (See: cryptography.)\n      (C) Usage note: For this concept, ISDs should use\
    \ the verb \"to\n      encrypt\" (and related variations: encryption, decrypt,\
    \ and\n      decryption). However, because of cultural biases, some\n      international\
    \ usage, particularly ISO and CCITT standards, avoids\n      \"to encrypt\" and\
    \ instead uses the verb \"to encipher\" (and related\n      variations: encipherment,\
    \ decipher, decipherment).\n      (O) \"The cryptographic transformation of data\
    \ (see: cryptography)\n      to produce ciphertext.\" [I7498 Part 2]\n      (C)\
    \ Usually, the plaintext input to an encryption operation is\n      cleartext.\
    \ But in some cases, the plaintext may be ciphertext that\n      was output from\
    \ another encryption operation. (See:\n      superencryption.)\n      (C) Encryption\
    \ and decryption involve a mathematical algorithm for\n      transforming data.\
    \ In addition to the data to be transformed, the\n      algorithm has one or more\
    \ inputs that are control parameters: (a)\n      a key value that varies the transformation\
    \ and, in some cases, (b)\n      an initialization value that establishes the\
    \ starting state of the\n      algorithm.\n   $ encryption certificate\n     \
    \ (I) A public-key certificate that contains a public key that is\n      intended\
    \ to be used for encrypting data, rather than for verifying\n      digital signatures\
    \ or performing other cryptographic functions.\n      C) A v3 X.509 public-key\
    \ certificate may have a \"keyUsage\"\n      extension that indicates the purpose\
    \ for which the certified\n      public key is intended.\n   $ end entity\n  \
    \    (I) A system entity that is the subject of a public-key\n      certificate\
    \ and that is using, or is permitted and able to use,\n      the matching private\
    \ key only for a purpose or purposes other than\n      signing a digital certificate;\
    \ i.e., an entity that is not a CA.\n      (D) \"A certificate subject which uses\
    \ its public [sic] key for\n      purposes other than signing certificates.\"\
    \ [X509]\n      (C) ISDs SHOULD NOT use the X.509 definition, because it is\n\
    \      misleading and incomplete. First, the X.509 definition should say\n   \
    \   \"private key\" rather than \"public key\" because certificates are\n    \
    \  not usefully signed with a public key. Second, the X.509\n      definition\
    \ is weak regarding whether an end entity may or may not\n      use the private\
    \ key to sign a certificate, i.e., whether the\n      subject may be a CA. The\
    \ intent of X.509's authors was that an end\n      entity certificate is not valid\
    \ for use in verifying a signature\n      on an X.509 certificate or X.509 CRL.\
    \ Thus, it would have been\n      better for the X.509 definition to have said\
    \ \"only for purposes\n      other than signing certificates\".\n      (C) Despite\
    \ the problems in the X.509 definition, the term itself\n      is useful in describing\
    \ applications of asymmetric cryptography.\n      The way the term is used in\
    \ X.509 implies that it was meant to be\n      defined, as we have done here,\
    \ relative to roles that an entity\n      (which is associated with an OSI end\
    \ system) is playing or is\n      permitted to play in applications of asymmetric\
    \ cryptography other\n      than the PKI that supports applications.\n      (C)\
    \ Whether a subject can play both CA and non-CA roles, with\n      either the\
    \ same or different certificates, is a matter of policy.\n      (See: certification\
    \ practice statement.) A v3 X.509 public-key\n      certificate may have a \"\
    basicConstraints\" extension containing a\n      \"cA\" value that specifically\
    \ \"indicates whether or not the public\n      key may be used to verify certificate\
    \ signatures\".\n   $ end system\n      (I) An OSI term for a computer that implements\
    \ all seven layers of\n      the OSIRM and may attach to a subnetwork. (In the\
    \ context of the\n      Internet Protocol Suite, usually called a \"host\".)\n\
    \   $ end-to-end encryption\n      (I) Continuous protection of data that flows\
    \ between two points in\n      a network, provided by encrypting data when it\
    \ leaves its source,\n      leaving it encrypted while it passes through any intermediate\n\
    \      computers (such as routers), and decrypting only when the data\n      arrives\
    \ at the intended destination. (See: link encryption,\n      wiretapping.)\n \
    \     (C) When two points are separated by multiple communication links\n    \
    \  that are connected by one or more intermediate relays, end-to-end\n      encryption\
    \ enables the source and destination systems to protect\n      their communications\
    \ without depending on the intermediate systems\n      to provide the protection.\n\
    \   $ end user\n      (I) General usage: A system entity, usually a human individual,\n\
    \      that makes use of system resources, primarily for application\n      purposes\
    \ as opposed to system management purposes.\n      (I) PKI usage: A synonym for\
    \ \"end entity\"; but the term \"end\n      entity\" is preferred.\n   $ entity\n\
    \      See: system entity.\n   $ entrapment\n      (I) \"The deliberate planting\
    \ of apparent flaws in a system for the\n      purpose of detecting attempted\
    \ penetrations or confusing an\n      intruder about which flaws to exploit.\"\
    \ [FP039] (See: honey pot.)\n   $ ephemeral key\n      (I) A public key or a private\
    \ key that is relatively short-lived.\n      (See: session key.)\n   $ error detection\
    \ code\n      (I) A checksum designed to detect, but not correct, accidental\n\
    \      (i.e., unintentional) changes in data.\n   $ Escrowed Encryption Standard\
    \ (EES)\n      (N) A U.S. Government standard [FP185] that specifies use of a\n\
    \      symmetric encryption algorithm (SKIPJACK) and a Law Enforcement\n     \
    \ Access Field (LEAF) creation method to implement part of a key\n      escrow\
    \ system that provides for decryption of encrypted\n      telecommunications when\
    \ interception is lawfully authorized.\n      (C) Both SKIPJACK and the LEAF are\
    \ to be implemented in equipment\n      used to encrypt and decrypt unclassified,\
    \ sensitive\n      telecommunications data.\n   $ ESP\n      See: Encapsulating\
    \ Security Payload.\n   $ Estelle\n      (N) A language (ISO 9074-1989) for formal\
    \ specification of\n      computer network protocols.\n   $ evaluated products\
    \ list\n      (O) General usage: A list of information system equipment items\n\
    \      that have been evaluated against, and found to be compliant with,\n   \
    \   a particular set of criteria.\n      (O) U.S. Department of Defense usage:\
    \ The Evaluated Products List\n      (http://www.radium.ncsc.mil/tpep/epl/) contains\
    \ items that have\n      been evaluated against the TCSEC by the NCSC, or against\
    \ the\n      Common Criteria by the NCSC or one of its partner agencies in\n \
    \     another county. The List forms Chapter 4 of NSA's \"Information\n      Systems\
    \ Security Products and Services Catalogue\".\n   $ evaluated system\n      (I)\
    \ Refers to a system that has been evaluated against security\n      criteria\
    \ such as the TCSEC or the Common Criteria.\n   $ expire\n      See: certificate\
    \ expiration.\n   $ exposure\n      See: (secondary definition under) threat consequence.\n\
    \   $ Extensible Authentication Protocol\n      (I) A framework that supports\
    \ multiple, optional authentication\n      mechanisms for PPP, including cleartext\
    \ passwords, challenge-\n      response, and arbitrary dialog sequences. [R2284]\n\
    \      (C) This protocol is intended for use primarily by a host or\n      router\
    \ that connects to a PPP network server via switched circuits\n      or dial-up\
    \ lines.\n   $ extension\n      (I) A data item defined for optional inclusion\
    \ in a v3 X.509\n      public-key certificate or a v2 X.509 CRL.\n      (C) The\
    \ formats defined in X.509 can be extended to provide\n      methods for associating\
    \ additional attributes with subjects and\n      public keys and for managing\
    \ a certification hierarchy:\n       - \"Certificate extension\": X.509 defines\
    \ standard extensions that\n         may be included in v3 certificates to provide\
    \ additional key\n         and security policy information, subject and issuer\
    \ attributes,\n         and certification path constraints.\n       - \"CRL extension\"\
    : X.509 defines extensions that may be included\n         in v2 CRLs to provide\
    \ additional issuer key and name\n         information, revocation reasons and\
    \ constraints, and\n         information about distribution points and delta CRLs.\n\
    \       - \"Private extension\": Additional extensions, each named by an\n   \
    \      OID, can be locally defined as needed by applications or\n         communities.\
    \ (See: PKIX private extension, SET private\n         extensions.)\n   $ extranet\n\
    \      (I) A computer network that an organization uses to carry\n      application\
    \ data traffic between the organization and its business\n      partners. (See:\
    \ intranet.)\n      (C) An extranet can be implemented securely, either on the\n\
    \      Internet or using Internet technology, by constructing the\n      extranet\
    \ as a VPN.\n   $ fail safe\n      (I) A mode of system termination that automatically\
    \ leaves system\n      processes and components in a secure state when a failure\
    \ occurs\n      or is detected in the system.\n   $ fail soft\n      (I) Selective\
    \ termination of affected non-essential system\n      functions and processes\
    \ when a failure occurs or is detected in\n      the system.\n   $ failure control\n\
    \      (I) A methodology used to provide fail-safe or fail-soft\n      termination\
    \ and recovery of functions and processes when failures\n      are detected or\
    \ occur in a system. [FP039]\n   $ Federal Information Processing Standards (FIPS)\n\
    \      (N) The Federal Information Processing Standards Publication (FIPS\n  \
    \    PUB) series issued by the U.S. National Institute of Standards and\n    \
    \  Technology as technical guidelines for U.S. Government\n      procurements\
    \ of information processing system equipment and\n      services. [FP031, FP039,\
    \ FP046, FP081, FP102, FP113, FP140, FP151,\n      FP180, FP185, FP186, FP188]\n\
    \      (C) Issued under the provisions of section 111(d) of the Federal\n    \
    \  Property and Administrative Services Act of 1949 as amended by the\n      Computer\
    \ Security Act of 1987, Public Law 100-235.\n   $ Federal Public-key Infrastructure\
    \ (FPKI)\n      (N) A PKI being planned to establish facilities, specifications,\n\
    \      and policies needed by the U.S. Federal Government to use public-\n   \
    \   key certificates for INFOSEC, COMSEC, and electronic commerce\n      involving\
    \ unclassified but sensitive applications and interactions\n      between Federal\
    \ agencies as well as with entities of other\n      branches of the Federal Government,\
    \ state, and local governments,\n      business, and the public. [FPKI]\n   $\
    \ Federal Standard 1027\n      (N) An U.S. Government document defining emanation,\
    \ anti-tamper,\n      security fault analysis, and manual key management criteria\
    \ for\n      DES encryption devices, primary for OSI layer 2. Was renamed \"FIPS\n\
    \      PUB 140\" when responsibility for protecting unclassified,\n      sensitive\
    \ information was transferred from NSA to NIST, and then\n      was superseded\
    \ by FIPS PUB 140-1.\n   $ File Transfer Protocol (FTP)\n      (I) A TCP-based,\
    \ application-layer, Internet Standard protocol\n      [R0959] for moving data\
    \ files from one computer to another.\n   $ filtering router\n      (I) An internetwork\
    \ router that selectively prevents the passage\n      of data packets according\
    \ to a security policy.\n      (C) A filtering router may be used as a firewall\
    \ or part of a\n      firewall. A router usually receives a packet from a network\
    \ and\n      decides where to forward it on a second network. A filtering\n  \
    \    router does the same, but first decides whether the packet should\n     \
    \ be forwarded at all, according to some security policy. The policy\n      is\
    \ implemented by rules (packet filters) loaded into the router.\n      The rules\
    \ mostly involve values of data packet control fields\n      (especially IP source\
    \ and destination addresses and TCP port\n      numbers). [R2179]\n   $ financial\
    \ institution\n      (N) \"An establishment responsible for facilitating customer-\n\
    \      initiated transactions or transmission of funds for the extension\n   \
    \   of credit or the custody, loan, exchange, or issuance of money.\"\n      [SET2]\n\
    \   $ fingerprint\n      (I) A pattern of curves formed by the ridges on a fingertip.\
    \ (See:\n      biometric authentication, thumbprint.)\n      (D) ISDs SHOULD NOT\
    \ use this term as a synonym for \"hash result\"\n      because it mixes concepts\
    \ in a potentially misleading way.\n      (D) ISDs SHOULD NOT use this term with\
    \ the following PGP\n      definition, because the term and definition mix concepts\
    \ in a\n      potentially misleading way and duplicate the meaning of \"hash\n\
    \      result\":\n      (O) PGP usage: A hash result used to authenticate a public\
    \ key\n      (key fingerprint) or other data. [PGP]\n   $ FIPS\n      See: Federal\
    \ Information Processing Standards.\n   $ FIPS PUB 140-1\n      (N) The U.S. Government\
    \ standard [FP140] for security requirements\n      to be met by a cryptographic\
    \ module used to protect unclassified\n      information in computer and communication\
    \ systems. (See: Common\n      Criteria, FIPS, Federal Standard 1027.)\n     \
    \ (C) The standard specifies four increasing levels (from \"Level 1\"\n      to\
    \ \"Level 4\") of requirements to cover a wide range of potential\n      applications\
    \ and environments. The requirements address basic\n      design and documentation,\
    \ module interfaces, authorized roles and\n      services, physical security,\
    \ software security, operating system\n      security, key management, cryptographic\
    \ algorithms,\n      electromagnetic interference and electromagnetic compatibility\n\
    \      (EMI/EMC), and self-testing. NIST and the Canadian Communication\n    \
    \  Security Establishment jointly certify modules.\n   $ firewall\n      (I) An\
    \ internetwork gateway that restricts data communication\n      traffic to and\
    \ from one of the connected networks (the one said to\n      be \"inside\" the\
    \ firewall) and thus protects that network's system\n      resources against threats\
    \ from the other network (the one that is\n      said to be \"outside\" the firewall).\
    \ (See: guard, security\n      gateway.)\n      (C) A firewall typically protects\
    \ a smaller, secure network (such\n      as a corporate LAN, or even just one\
    \ host) from a larger network\n      (such as the Internet). The firewall is installed\
    \ at the point\n      where the networks connect, and the firewall applies security\n\
    \      policy rules to control traffic that flows in and out of the\n      protected\
    \ network.\n      (C) A firewall is not always a single computer. For example,\
    \ a\n      firewall may consist of a pair of filtering routers and one or\n  \
    \    more proxy servers running on one or more bastion hosts, all\n      connected\
    \ to a small, dedicated LAN between the two routers. The\n      external router\
    \ blocks attacks that use IP to break security (IP\n      address spoofing, source\
    \ routing, packet fragments), while proxy\n      servers block attacks that would\
    \ exploit a vulnerability in a\n      higher layer protocol or service. The internal\
    \ router blocks\n      traffic from leaving the protected network except through\
    \ the\n      proxy servers. The difficult part is defining criteria by which\n\
    \      packets are denied passage through the firewall, because a\n      firewall\
    \ not only needs to keep intruders out, but usually also\n      needs to let authorized\
    \ users in and out.\n   $ firmware\n      (I) Computer programs and data stored\
    \ in hardware--typically in\n      read-only memory (ROM) or programmable read-only\
    \ memory (PROM)--\n      such that the programs and data cannot be dynamically\
    \ written or\n      modified during execution of the programs. (See: hardware,\n\
    \      software.)\n   $ FIRST\n      See: Forum of Incident Response and Security\
    \ Teams.\n   $ flaw hypothesis methodology\n      (I) An evaluation or attack\
    \ technique in which specifications and\n      documentation for a system are\
    \ analyzed to hypothesize flaws in\n      the system. The list of hypothetical\
    \ flaws is prioritized on the\n      basis of the estimated probability that a\
    \ flaw exists and,\n      assuming it does, on the ease of exploiting it and the\
    \ extent of\n      control or compromise it would provide. The prioritized list\
    \ is\n      used to direct a penetration test or attack against the system.\n\
    \      [NCS04]\n   $ flooding\n      (I) An attack that attempts to cause a failure\
    \ in (especially, in\n      the security of) a computer system or other data processing\
    \ entity\n      by providing more input than the entity can process properly.\n\
    \      (See: denial of service.)\n   $ flow analysis\n      (I) An analysis performed\
    \ on a nonprocedural formal system\n      specification that locates potential\
    \ flows of information between\n      system variables. By assigning security\
    \ levels to the variables,\n      the analysis can find some types of covert channels.\n\
    \   $ flow control\n      (I) A procedure or technique to ensure that information\
    \ transfers\n      within a system are not made from one security level to another\n\
    \      security level, and especially not from a higher level to a lower\n   \
    \   level. (See: covert channel, simple security property, confinement\n     \
    \ property.)\n   $ formal specification\n      (I) A specification of hardware\
    \ or software functionality in a\n      computer-readable language; usually a\
    \ precise mathematical\n      description of the behavior of the system with the\
    \ aim of\n      providing a correctness proof.\n   $ formulary\n      (I) A technique\
    \ for enabling a decision to grant or deny access to\n      be made dynamically\
    \ at the time the access is attempted, rather\n      than earlier when an access\
    \ control list or ticket is created.\n   $ FORTEZZA(trademark)\n      (N) A registered\
    \ trademark of NSA, used for a family of\n      interoperable security products\
    \ that implement a NIST/NSA-approved\n      suite of cryptographic algorithms\
    \ for digital signature, hash,\n      encryption, and key exchange. The products\
    \ include a PC card that\n      contains a CAPSTONE chip, serial port modems,\
    \ server boards, smart\n      cards, and software implementations.\n   $ Forum\
    \ of Incident Response and Security Teams (FIRST)\n      (N) An international\
    \ consortium of CSIRTs that work together to\n      handle computer security incidents\
    \ and promote preventive\n      activities. (See: CSIRT, security incident.)\n\
    \      (C) FIRST was founded in 1990 and, as of September 1999, had\n      nearly\
    \ 70 members spanning the globe. Its mission includes:\n       - Provide members\
    \ with technical information, tools, methods,\n         assistance, and guidance.\n\
    \       - Coordinate proactive liaison activities and analytical support.\n  \
    \     - Encourage development of quality products and services.\n       - Improve\
    \ national and international information security for\n         government, private\
    \ industry, academia, and the individual.\n       - Enhance the image and status\
    \ of the CSIRT community.\n   $ forward secrecy\n      See: public-key forward\
    \ secrecy.\n   $ FPKI\n      See: Federal Public-Key Infrastructure.\n   $ FTP\n\
    \      See: File Transfer Protocol.\n   $ gateway\n      (I) A relay mechanism\
    \ that attaches to two (or more) computer\n      networks that have similar functions\
    \ but dissimilar\n      implementations and that enables host computers on one\
    \ network to\n      communicate with hosts on the other; an intermediate system\
    \ that\n      is the interface between two computer networks. (See: bridge,\n\
    \      firewall, guard, internetwork, proxy server, router, and\n      subnetwork.)\n\
    \      (C) In theory, gateways are conceivable at any OSI layer. In\n      practice,\
    \ they operate at OSI layer 3 (see: bridge, router) or\n      layer 7 (see: proxy\
    \ server). When the two networks differ in the\n      protocol by which they offer\
    \ service to hosts, the gateway may\n      translate one protocol into another\
    \ or otherwise facilitate\n      interoperation of hosts (see: Internet Protocol).\n\
    \   $ GCA\n      See: geopolitical certificate authority.\n   $ GeneralizedTime\n\
    \      (N) The ASN.1 data type \"GeneralizedTime\" (specified in ISO 8601)\n \
    \     contains a calendar date (YYYYMMDD) and a time of day, which is\n      either\
    \ (a) the local time, (b) the Coordinated Universal Time, or\n      (c) both the\
    \ local time and an offset allowing Coordinated\n      Universal Time to be calculated.\
    \ (See: Coordinated Universal Time,\n      UTCTime.)\n   $ Generic Security Service\
    \ Application Program Interface (GSS-API)\n      (I) An Internet Standard protocol\
    \ [R2078] that specifies calling\n      conventions by which an application (typically\
    \ another\n      communication protocol) can obtain authentication, integrity,\
    \ and\n      confidentiality security services independently of the underlying\n\
    \      security mechanisms and technologies, thus allowing the\n      application\
    \ source code to be ported to different environments.\n      (C) \"A GSS-API caller\
    \ accepts tokens provided to it by its local\n      GSS-API implementation and\
    \ transfers the tokens to a peer on a\n      remote system; that peer passes the\
    \ received tokens to its local\n      GSS-API implementation for processing. The\
    \ security services\n      available through GSS-API in this fashion are implementable\
    \ (and\n      have been implemented) over a range of underlying mechanisms based\n\
    \      on [symmetric] and [asymmetric cryptography].\" [R2078]\n   $ geopolitical\
    \ certificate authority (GCA)\n      (O) SET usage: In a SET certification hierarchy,\
    \ an optional level\n      that is certified by a BCA and that may certify cardholder\
    \ CAs,\n      merchant CAs, and payment gateway CAs. Using GCAs enables a brand\n\
    \      to distribute responsibility for managing certificates to\n      geographic\
    \ or political regions, so that brand policies can vary\n      between regions\
    \ as needed.\n   $ Green Book\n      (D) Except as an explanatory appositive,\
    \ ISDs SHOULD NOT use this\n      term as a synonym for \"Defense Password Management\
    \ Guideline\"\n      [CSC2]. Instead, use the full proper name of the document\
    \ or, in\n      subsequent references, a conventional abbreviation. (See: Rainbow\n\
    \      Series.)\n      (D) Usage note: To improve international comprehensibility\
    \ of\n      Internet Standards and the Internet Standards Process, ISDs SHOULD\n\
    \      NOT use \"cute\" synonyms for document titles. No matter how popular\n\
    \      and clearly understood a nickname may be in one community, it is\n    \
    \  likely to cause confusion in others. For example, several other\n      information\
    \ system standards also are called \"the Green Book\". The\n      following are\
    \ some examples:\n       - Each volume of 1992 ITU-T (at that time, CCITT) standards.\n\
    \       - \"PostScript Language Program Design\", Adobe Systems, Addison-\n  \
    \       Wesley, 1988.\n       - IEEE 1003.1 POSIX Operating Systems Interface.\n\
    \       - \"Smalltalk-80: Bits of History, Words of Advice\", Glenn\n        \
    \ Krasner, Addison-Wesley, 1983.\n       - \"X/Open Compatibility Guide\".\n \
    \      - A particular CD-ROM format developed by Phillips.\n   $ GRIP\n      (I)\
    \ A contraction of \"Guidelines and Recommendations for Security\n      Incident\
    \ Processing\", the name of the IETF working group that\n      seeks to facilitate\
    \ consistent handling of security incidents in\n      the Internet community.\
    \ (See: security incident.)\n      (C) Guidelines to be produced by the WG will\
    \ address technology\n      vendors, network service providers, and response teams\
    \ in their\n      roles assisting organizations in resolving security incidents.\n\
    \      These relationships are functional and can exist within and across\n  \
    \    organizational boundaries.\n   $ GSS-API\n      See: Generic Security Service\
    \ Application Program Interface.\n   $ guard\n      (I) A gateway that is interposed\
    \ between two networks (or\n      computers, or other information systems) operating\
    \ at different\n      security levels (one level is usually higher than the other)\
    \ and\n      is trusted to mediate all information transfers between the two\n\
    \      levels, either to ensure that no sensitive information from the\n     \
    \ first (higher) level is disclosed to the second (lower) level, or\n      to\
    \ protect the integrity of data on the first (higher) level.\n      (See: firewall.)\n\
    \   $ guest login\n      See: anonymous login.\n   $ GULS\n      (I) Generic Upper\
    \ Layer Security service element (ISO 11586), a\n      five-part standard for\
    \ the exchange of security information and\n      security-transformation functions\
    \ that protect confidentiality and\n      integrity of application data.\n   $\
    \ hacker\n      (I) Someone with a strong interest in computers, who enjoys\n\
    \      learning about them and experimenting with them. (See: cracker.)\n    \
    \  (C) The recommended definition is the original meaning of the term\n      (circa\
    \ 1960), which then had a neutral or positive connotation of\n      \"someone\
    \ who figures things out and makes something cool\n      happen\". Today, the\
    \ term is frequently misused, especially by\n      journalists, to have the pejorative\
    \ meaning of cracker.\n   $ handle\n      (I) (1.) Verb: Perform processing operations\
    \ on data, such as\n      receive and transmit, collect and disseminate, create\
    \ and delete,\n      store and retrieve, read and write, and compare. (2.) Noun:\
    \ An on-\n      line pseudonym, particularly one used by a cracker; derived from\n\
    \      citizens band radio culture.\n   $ hardware\n      (I) The material physical\
    \ components of a computer system. (See:\n      firmware, software.)\n   $ hardware\
    \ token\n      See: token.\n   $ hash code\n      (D) ISDs SHOULD NOT use this\
    \ term (especially not as a synonym for\n      \"hash result\") because it mixes\
    \ concepts in a potentially\n      misleading way. A hash result is not a \"code\"\
    \ in any sense defined\n      by this glossary. (See: code, hash result, hash\
    \ value, message\n      digest.)\n   $ hash function\n      (I) An algorithm that\
    \ computes a value based on a data object\n      (such as a message or file; usually\
    \ variable-length; possibly very\n      large), thereby mapping the data object\
    \ to a smaller data object\n      (the \"hash result\") which is usually a fixed-size\
    \ value. (See:\n      checksum, keyed hash.)\n      (O) \"A (mathematical) function\
    \ which maps values from a large\n      (possibly very large) domain into a smaller\
    \ range. A 'good' hash\n      function is such that the results of applying the\
    \ function to a\n      (large) set of values in the domain will be evenly distributed\n\
    \      (and apparently at random) over the range.\" [X509]\n      (C) The kind\
    \ of hash function needed for security applications is\n      called a \"cryptographic\
    \ hash function\", an algorithm for which it\n      is computationally infeasible\
    \ (because no attack is significantly\n      more efficient than brute force)\
    \ to find either (a) a data object\n      that maps to a pre-specified hash result\
    \ (the \"one-way\" property)\n      or (b) two data objects that map to the same\
    \ hash result (the\n      \"collision-free\" property). (See: MD2, MD4, MD5, SHA-1.)\n\
    \      (C) A cryptographic hash is \"good\" in the sense stated in the \"O\"\n\
    \      definition for hash function. Any change to an input data object\n    \
    \  will, with high probability, result in a different hash result, so\n      that\
    \ the result of a cryptographic hash makes a good checksum for\n      a data object.\n\
    \   $ hash result\n      (I) The output of a hash function. (See: hash code, hash\
    \ value.)\n      (O) \"The output produced by a hash function upon processing\
    \ a\n      message\" (where \"message\" is broadly defined as \"a digital\n  \
    \    representation of data\"). [ABA] (The recommended definition is\n      compatible\
    \ with this ABA definition, but we avoid the unusual\n      definition of \"message\"\
    .)\n   $ hash value\n      (D) ISDs SHOULD NOT use this term (especially not as\
    \ a synonym for\n      \"hash result\", the output of a hash function) because\
    \ it might be\n      confused with \"hashed value\" (the input to a hash function).\
    \ (See:\n      hash code, hash result, message digest.)\n   $ hierarchical PKI\n\
    \      (I) A PKI architecture based on a certification hierarchy. (See:\n    \
    \  mesh PKI, trust-file PKI.)\n   $ hierarchy management\n      (I) The process\
    \ of generating configuration data and issuing\n      public-key certificates\
    \ to build and operate a certification\n      hierarchy.\n   $ hierarchy of trust\n\
    \      (D) ISDs SHOULD NOT use this term with regard to PKI, especially\n    \
    \  not as a synonym for \"certification hierarchy\", because this term\n     \
    \ mixes concepts in a potentially misleading way. (See:\n      certification hierarchy,\
    \ trust, web of trust.)\n   $ hijack attack\n      (I) A form of active wiretapping\
    \ in which the attacker seizes\n      control of a previously established communication\
    \ association.\n      (See: man-in-the-middle attack, pagejacking, piggyback attack.)\n\
    \   $ HMAC\n      (I) A keyed hash [R2104] that can be based on any iterated\n\
    \      cryptographic hash (e.g., MD5 or SHA-1), so that the cryptographic\n  \
    \    strength of HMAC depends on the properties of the selected\n      cryptographic\
    \ hash. (See: [R2202, R2403, R2404].)\n      (C) Assume that H is a generic cryptographic\
    \ hash in which a\n      function is iterated on data blocks of length B bytes.\
    \ L is the\n      length of the of hash result of H. K is a secret key of length\
    \ L\n      <= K <= B. The values IPAD and OPAD are fixed strings used as\n   \
    \   inner and outer padding and defined as follows: IPAD = the byte\n      0x36\
    \ repeated B times, OPAD = the byte 0x5C repeated B times. HMAC\n      is computed\
    \ by H(K XOR OPAD, H(K XOR IPAD, inputdata)).\n      (C) The goals of HMAC are\
    \ as follows:\n       - To use available cryptographic hash functions without\n\
    \         modification, particularly functions that perform well in\n        \
    \ software and for which software is freely and widely available.\n       - To\
    \ preserve the original performance of the selected hash\n         without significant\
    \ degradation.\n       - To use and handle keys in a simple way.\n       - To\
    \ have a well-understood cryptographic analysis of the\n         strength of the\
    \ mechanism based on reasonable assumptions about\n         the underlying hash\
    \ function.\n       - To enable easy replacement of the hash function in case\
    \ a\n         faster or stronger hash is found or required.\n   $ honey pot\n\
    \      (I) A system (e.g., a web server) or a system resource (e.g., a\n     \
    \ file on a server), that is designed to be attractive to potential\n      crackers\
    \ and intruders, like honey is attractive to bears. (See:\n      entrapment.)\n\
    \      (D) It is likely that other cultures have different metaphors for\n   \
    \   this concept. To ensure international understanding, ISDs should\n      not\
    \ use this term unless they also provide an explanation like\n      this one.\
    \ (See: (usage note under) Green Book.)\n   $ host\n      (I) General computer\
    \ network usage: A computer that is attached to\n      a communication subnetwork\
    \ or internetwork and can use services\n      provided by the network to exchange\
    \ data with other attached\n      systems. (See: end system.)\n      (I) Specific\
    \ Internet Protocol Suite usage: A networked computer\n      that does not forward\
    \ Internet Protocol packets that are not\n      addressed to the computer itself.\
    \ (See: router.)\n      (C) Derivation: As viewed by its users, a host \"entertains\"\
    \n      guests, providing application layer services or access to other\n    \
    \  computers attached to the network. However, even though some\n      traditional\
    \ peripheral service devices, such as printers, can now\n      be independently\
    \ connected to networks, they are not usually\n      called hosts.\n   $ HTML\n\
    \      See: Hypertext Markup Language.\n   $ HTTP\n      See: Hypertext Transfer\
    \ Protocol.\n   $ https\n      (I) When used in the first part of a URL (the part\
    \ that precedes\n      the colon and specifies an access scheme or protocol),\
    \ this term\n      specifies the use of HTTP enhanced by a security mechanism,\
    \ which\n      is usually SSL. (See: S-HTTP.)\n   $ hybrid encryption\n      (I)\
    \ An application of cryptography that combines two or more\n      encryption algorithms,\
    \ particularly a combination of symmetric and\n      asymmetric encryption. (E.g.,\
    \ see: digital envelope.)\n      (C) Asymmetric algorithms require more computation\
    \ than\n      equivalently strong symmetric ones. Thus, asymmetric encryption\
    \ is\n      not normally used for data confidentiality except in distributing\n\
    \      symmetric keys in applications where the key data is usually short\n  \
    \    (in terms of bits) compared to the data it protects. (E.g., see:\n      MSP,\
    \ PEM, PGP.)\n   $ hyperlink\n      (I) In hypertext or hypermedia, an information\
    \ object (such as a\n      word, a phrase, or an image; usually highlighted by\
    \ color or\n      underscoring) that points (indicates how to connect) to related\n\
    \      information that is located elsewhere and can be retrieved by\n      activating\
    \ the link (e.g., by selecting the object with a mouse\n      pointer and then\
    \ clicking).\n   $ hypermedia\n      (I) A generalization of hypertext; any media\
    \ that contain\n      hyperlinks that point to material in the same or another\
    \ data\n      object.\n   $ hypertext\n      (I) A computer document, or part\
    \ of a document, that contains\n      hyperlinks to other documents; i.e., text\
    \ that contains active\n      pointers to other text. Usually written in Hypertext\
    \ Markup\n      Language and accessed using a web browser. (See: hypermedia.)\n\
    \   $ Hypertext Markup Language (HTML)\n      (I) A platform-independent system\
    \ of syntax and semantics for\n      adding characters to data files (particularly\
    \ text files) to\n      represent the data's structure and to point to related\
    \ data, thus\n      creating hypertext for use in the World Wide Web and other\n\
    \      applications. [R1866]\n   $ Hypertext Transfer Protocol (HTTP)\n      (I)\
    \ A TCP-based, application-layer, client-server, Internet\n      protocol [R2616]\
    \ used to carry data requests and responses in the\n      World Wide Web. (See:\
    \ hypertext.)\n   $ IAB\n      See: Internet Architecture Board.\n   $ IANA\n\
    \      See: Internet Assigned Numbers Authority.\n   $ ICANN\n      See: Internet\
    \ Corporation for Assigned Names and Numbers.\n   $ ICMP\n      See: Internet\
    \ Control Message Protocol.\n   $ ICMP flood\n      (I) A denial of service attack\
    \ that sends a host more ICMP echo\n      request (\"ping\") packets than the\
    \ protocol implementation can\n      handle. (See: flooding, smurf.)\n   $ ICRL\n\
    \      See: indirect certificate revocation list.\n   $ IDEA\n      See: International\
    \ Data Encryption Algorithm.\n   $ identification\n      (I) An act or process\
    \ that presents an identifier to a system so\n      that the system can recognize\
    \ a system entity and distinguish it\n      from other entities. (See: authentication.)\n\
    \   $ Identification Protocol\n      (I) An client-server Internet protocol [R1413]\
    \ for learning the\n      identity of a user of a particular TCP connection.\n\
    \      (C) Given a TCP port number pair, the server returns a character\n    \
    \  string that identifies the owner of that connection on the\n      server's\
    \ system. The protocol is not intended for authorization or\n      access control.\
    \ At best, it provides additional auditing\n      information with respect to\
    \ TCP.\n   $ identity-based security policy\n      (I) \"A security policy based\
    \ on the identities and/or attributes\n      of users, a group of users, or entities\
    \ acting on behalf of the\n      users and the resources/objects being accessed.\"\
    \ [I7498 Part 2]\n      (See: rule-based security policy.)\n   $ IEEE\n      See:\
    \ Institute of Electrical and Electronics Engineers, Inc.\n   $ IEEE 802.10\n\
    \      (N) An IEEE committee developing security standards for local area\n  \
    \    networks. (See: SILS.)\n   $ IEEE P1363\n      (N) An IEEE working group,\
    \ Standard for Public-Key Cryptography,\n      developing a comprehensive reference\
    \ standard for asymmetric\n      cryptography. Covers discrete logarithm (e.g.,\
    \ DSA), elliptic\n      curve, and integer factorization (e.g., RSA); and covers\
    \ key\n      agreement, digital signature, and encryption.\n   $ IESG\n      See:\
    \ Internet Engineering Steering Group.\n   $ IETF\n      See: Internet Engineering\
    \ Task Force.\n   $ IKE\n      See: IPsec Key Exchange.\n   $ IMAP4\n      See:\
    \ Internet Message Access Protocol, version 4.\n   $ IMAP4 AUTHENTICATE\n    \
    \  (I) A IMAP4 \"command\" (better described as a transaction type, or\n     \
    \ a protocol-within-a-protocol) by which an IMAP4 client optionally\n      proposes\
    \ a mechanism to an IMAP4 server to authenticate the client\n      to the server\
    \ and provide other security services. (See: POP3.)\n      (C) If the server accepts\
    \ the proposal, the command is followed by\n      performing a challenge-response\
    \ authentication protocol and,\n      optionally, negotiating a protection mechanism\
    \ for subsequent POP3\n      interactions. The security mechanisms that are used\
    \ by IMAP4\n      AUTHENTICATE--including Kerberos, GSSAPI, and S/Key--are described\n\
    \      in [R1731].\n   $ in the clear\n      (I) Not encrypted. (See: cleartext.)\n\
    \   $ indirect certificate revocation list (ICRL)\n      (I) In X.509, a CRL that\
    \ may contain certificate revocation\n      notifications for certificates issued\
    \ by CAs other than the issuer\n      of the ICRL.\n   $ indistinguishability\n\
    \      (I) An attribute of an encryption algorithm that is a\n      formalization\
    \ of the notion that the encryption of some string is\n      indistinguishable\
    \ from the encryption of an equal-length string of\n      nonsense.\n      (C)\
    \ Under certain conditions, this notion is equivalent to\n      \"semantic security\"\
    .\n   $ information\n      (I) Facts and ideas, which can be represented (encoded)\
    \ as various\n      forms of data.\n   $ Information Technology Security Evaluation\
    \ Criteria (ITSEC)\n      (N) Standard developed for use in the European Union;\
    \ accommodates\n      a wider range of security assurance and functionality combinations\n\
    \      than the TCSEC. Superseded by the Common Criteria. [ITSEC]\n   $ INFOSEC\n\
    \      (I) Abbreviation for \"information security\", referring to security\n\
    \      measures that implement and assure security services in computer\n    \
    \  systems (i.e., COMPUSEC) and communication systems (i.e., COMSEC).\n   $ initialization\
    \ value (IV)\n      (I) An input parameter that sets the starting state of a\n\
    \      cryptographic algorithm or mode. (Sometimes called \"initialization\n \
    \     vector\" or \"message indicator\".)\n      (C) An IV can be used to introduce\
    \ cryptographic variance in\n      addition to that provided by a key (see: salt),\
    \ and to synchronize\n      one cryptographic process with another. For an example\
    \ of the\n      latter, cipher block chaining mode requires an IV. [R2405]\n \
    \  $ initialization vector\n      (D) For consistency, ISDs SHOULD NOT use this\
    \ term as a synonym\n      for \"initialization value\".\n   $ insider attack\n\
    \      See: (secondary definition under) attack.\n   $ Institute of Electrical\
    \ and Electronics Engineers, Inc. (IEEE)\n      (N) The IEEE is a not-for-profit\
    \ association of more than 330,000\n      individual members in 150 countries.\
    \ The IEEE produces 30 percent\n      of the world's published literature in electrical\
    \ engineering,\n      computers, and control technology; holds annually more than\
    \ 300\n      major conferences; and has more than 800 active standards with 700\n\
    \      under development. (See: Standards for Interoperable LAN/MAN\n      Security.)\n\
    \   $ integrity\n      See: data integrity, correctness integrity, source integrity,\n\
    \      system integrity.\n   $ integrity check\n      (D) ISDs SHOULD NOT use\
    \ this term as a synonym for \"cryptographic\n      hash\" or \"protected checksum\"\
    , because this term unnecessarily\n      duplicates the meaning of other, well-established\
    \ terms.\n   $ intelligent threat\n      (I) A circumstance in which an adversary\
    \ has the technical and\n      operational capability to detect and exploit a\
    \ vulnerability and\n      also has the demonstrated, presumed, or inferred intent\
    \ to do so.\n      (See: threat.)\n   $ International Data Encryption Algorithm\
    \ (IDEA)\n      (N) A patented, symmetric block cipher that uses a 128-bit key\
    \ and\n      operates on 64-bit blocks. [Schn] (See: symmetric cryptography.)\n\
    \   $ International Standard\n      See: (secondary definition under) ISO.\n \
    \  $ International Traffic in Arms Regulations (ITAR)\n      (N) Rules issued\
    \ by the U.S. State Department, by authority of the\n      Arms Export Control\
    \ Act (22 U.S.C. 2778), to control export and\n      import of defense articles\
    \ and defense services, including\n      information security systems, such as\
    \ cryptographic systems, and\n      TEMPEST suppression technology. (See: Wassenaar\
    \ Arrangement.)\n   $ internet\n   $ Internet\n      See: internet vs. Internet.\n\
    \   $ Internet Architecture Board (IAB)\n      (I) A technical advisory group\
    \ of the ISOC, chartered by the ISOC\n      Trustees to provide oversight of Internet\
    \ architecture and\n      protocols and, in the context of Internet Standards,\
    \ a body to\n      which decisions of the IESG may be appealed. Responsible for\n\
    \      approving appointments to the IESG from among nominees submitted\n    \
    \  by the IETF nominating committee. [R2026]\n   $ Internet Assigned Numbers Authority\
    \ (IANA)\n      (I) From the early days of the Internet, the IANA was chartered\
    \ by\n      the ISOC and the U.S. Government's Federal Network Council to be\n\
    \      the central coordination, allocation, and registration body for\n     \
    \ parameters for Internet protocols. Superseded by ICANN.\n   $ Internet Control\
    \ Message Protocol (ICMP)\n      (I) An Internet Standard protocol [R0792] that\
    \ is used to report\n      error conditions during IP datagram processing and\
    \ to exchange\n      other information concerning the state of the IP network.\n\
    \   $ Internet Corporation for Assigned Names and Numbers (ICANN)\n      (I) The\
    \ non-profit, private corporation that has assumed\n      responsibility for the\
    \ IP address space allocation, protocol\n      parameter assignment, domain name\
    \ system management, and root\n      server system management functions formerly\
    \ performed under U.S.\n      Government contract by IANA and other entities.\n\
    \      (C) The Internet Protocol Suite, as defined by the IETF and the\n     \
    \ IESG, contains numerous parameters, such as internet addresses,\n      domain\
    \ names, autonomous system numbers, protocol numbers, port\n      numbers, management\
    \ information base object identifiers, including\n      private enterprise numbers,\
    \ and many others. The Internet\n      community requires that the values used\
    \ in these parameter fields\n      be assigned uniquely. ICANN makes those assignments\
    \ as requested\n      and maintains a registry of the current values.\n      (C)\
    \ ICANN was formed in October 1998, by a coalition of the\n      Internet's business,\
    \ technical, and academic communities. The U.S.\n      Government designated ICANN\
    \ to serve as the global consensus\n      entity with responsibility for coordinating\
    \ four key functions for\n      the Internet: the allocation of IP address space,\
    \ the assignment\n      of protocol parameters, the management of the DNS, and\
    \ the\n      management of the DNS root server system.\n   $ Internet Draft\n\
    \      (I) A working document of the IETF, its areas, and its working\n      groups.\
    \ (Other groups may also distribute working documents as\n      Internet Drafts.)\
    \ An Internet Draft is not an archival document\n      like an RFC is. Instead,\
    \ an Internet Draft is a preliminary or\n      working document that is valid\
    \ for a maximum of six months and may\n      be updated, replaced, or made obsolete\
    \ by other documents at any\n      time. It is inappropriate to use an Internet\
    \ Draft as reference\n      material or to cite it other than as \"work in progress.\"\
    \n   $ Internet Engineering Steering Group (IESG)\n      (I) The part of the ISOC\
    \ responsible for technical management of\n      IETF activities and administration\
    \ of the Internet Standards\n      Process according to procedures approved by\
    \ the ISOC Trustees.\n      Directly responsible for actions along the \"standards\
    \ track\",\n      including final approval of specifications as Internet Standards.\n\
    \      Composed of IETF Area Directors and the IETF chairperson, who also\n  \
    \    chairs the IESG. [R2026]\n   $ Internet Engineering Task Force (IETF)\n \
    \     (I) A self-organized group of people who make contributions to the\n   \
    \   development of Internet technology. The principal body engaged in\n      developing\
    \ Internet Standards, although not itself a part of the\n      ISOC. Composed\
    \ of Working Groups, which are arranged into Areas\n      (such as the Security\
    \ Area), each coordinated by one or more Area\n      Directors. Nominations to\
    \ the IAB and the IESG are made by a\n      committee selected at random from\
    \ regular IETF meeting attendees\n      who have volunteered. [R2026, R2323]\n\
    \   $ Internet Message Access Protocol, version 4 (IMAP4)\n      (I) An Internet\
    \ protocol [R2060] by which a client workstation can\n      dynamically access\
    \ a mailbox on a server host to manipulate and\n      retrieve mail messages that\
    \ the server has received and is holding\n      for the client. (See: POP3.)\n\
    \      (C) IMAP4 has mechanisms for optionally authenticating a client to\n  \
    \    a server and providing other security services. (See: IMAP4\n      AUTHENTICATE.)\n\
    \   $ Internet Policy Registration Authority (IPRA)\n      (I) An X.509-compliant\
    \ CA that is the top CA of the Internet\n      certification hierarchy operated\
    \ under the auspices of the ISOC\n      [R1422]. (See: (PEM usage under) certification\
    \ hierarchy.)\n   $ Internet Protocol (IP)\n      (I) A Internet Standard protocol\
    \ (version 4 [R0791] and version 6\n      [R2460]) that moves datagrams (discrete\
    \ sets of bits) from one\n      computer to another across an internetwork but\
    \ does not provide\n      reliable delivery, flow control, sequencing, or other\
    \ end-to-end\n      services that TCP provides. (See: IP address, TCP/IP.)\n \
    \     (C) In the OSIRM, IP would be located at the top of layer 3.\n   $ Internet\
    \ Protocol security (IPsec)\n      (I) (1.) The name of the IETF working group\
    \ that is specifying a\n      security architecture [R2401] and protocols to provide\
    \ security\n      services for Internet Protocol traffic. (2.) A collective name\
    \ for\n      that architecture and set of protocols. (Implementation of IPsec\n\
    \      protocols is optional for IP version 4, but mandatory for IP\n      version\
    \ 6.) (See: Internet Protocol Security Option.)\n      (C) Note that the letters\
    \ \"sec\" are lower-case.\n      (C) The IPsec architecture specifies (a) security\
    \ protocols (AH\n      and ESP), (b) security associations (what they are, how\
    \ they work,\n      how they are managed, and associated processing), (c) key\n\
    \      management (IKE), and (d) algorithms for authentication and\n      encryption.\
    \ The set of security services include access control\n      service, connectionless\
    \ data integrity service, data origin\n      authentication service, protection\
    \ against replays (detection of\n      the arrival of duplicate datagrams, within\
    \ a constrained window),\n      data confidentiality service, and limited traffic\
    \ flow\n      confidentiality.\n   $ Internet Protocol Security Option (IPSO)\n\
    \      (I) Refers to one of three types of IP security options, which are\n  \
    \    fields that may be added to an IP datagram for the purpose of\n      carrying\
    \ security information about the datagram. (See: IPsec.)\n      (D) ISDs SHOULD\
    \ NOT use this term without a modifier to indicate\n      which of the three types\
    \ is meant.\n      1. \"DoD Basic Security Option\" (IP option type 130): Defined\
    \ for\n      use on U.S. Department of Defense common user data networks.\n  \
    \    Identifies the Defense classification level at which the\n      datagram\
    \ is to be protected and the protection authorities\n      whose rules apply to\
    \ the datagram. [R1108]\n      A \"protection authority\" is a National Access\
    \ Program (e.g.,\n      GENSER, SIOP-ESI, SCI, NSA, Department of Energy) or Special\n\
    \      Access Program that specifies protection rules for transmission\n     \
    \ and processing of the information contained in the datagram.\n      [R1108]\n\
    \      2. \"DoD Extended Security Option\" (IP option type 133): Permits\n   \
    \   additional security labeling information, beyond that present\n      in the\
    \ Basic Security Option, to be supplied in the datagram to\n      meet the needs\
    \ of registered authorities. [R1108]\n      3. \"Common IP Security Option\" (CIPSO)\
    \ (IP option type 134):\n      Designed by TSIG to carry hierarchic and non-hierarchic\n\
    \      security labels. (Formerly called \"Commercial IP Security\n      Option\"\
    .) Was published as Internet-Draft [CIPSO]; not advanced\n      to RFC.\n   $\
    \ Internet Protocol Suite\n      See: (secondary definition under) Internet.\n\
    \   $ Internet Security Association and Key Management Protocol (ISAKMP)\n   \
    \   (I) An Internet IPsec protocol [R2408] to negotiate, establish,\n      modify,\
    \ and delete security associations, and to exchange key\n      generation and\
    \ authentication data, independent of the details of\n      any specific key generation\
    \ technique, key establishment protocol,\n      encryption algorithm, or authentication\
    \ mechanism.\n      (C) ISAKMP supports negotiation of security associations for\n\
    \      protocols at all TCP/IP layers. By centralizing management of\n      security\
    \ associations, ISAKMP reduces duplicated functionality\n      within each protocol.\
    \ ISAKMP can also reduce connection setup\n      time, by negotiating a whole\
    \ stack of services at once. Strong\n      authentication is required on ISAKMP\
    \ exchanges, and a digital\n      signature algorithm based on asymmetric cryptography\
    \ is used\n      within ISAKMP's authentication component.\n   $ Internet Society\
    \ (ISOC)\n      (I) A professional society concerned with Internet development\n\
    \      (including technical Internet Standards); with how the Internet is\n  \
    \    and can be used; and with social, political, and technical issues\n     \
    \ that result. The ISOC Board of Trustees approves appointments to\n      the\
    \ IAB from among nominees submitted by the IETF nominating\n      committee. [R2026]\n\
    \   $ Internet Standard\n      (I) A specification, approved by the IESG and published\
    \ as an RFC,\n      that is stable and well-understood, is technically competent,\
    \ has\n      multiple, independent, and interoperable implementations with\n \
    \     substantial operational experience, enjoys significant public\n      support,\
    \ and is recognizably useful in some or all parts of the\n      Internet. [R2026]\
    \ (See: RFC.)\n      (C) The Internet Standards Process is an activity of the\
    \ ISOC and\n      is organized and managed by the IAB and the IESG. The process\
    \ is\n      concerned with all protocols, procedures, and conventions used in\n\
    \      or by the Internet, whether or not they are part of the Internet\n    \
    \  Protocol Suite. The \"Internet Standards Track\" has three levels of\n    \
    \  increasing maturity: Proposed Standard, Draft Standard, and\n      Standard.\
    \ (See: (standards levels under) ISO.)\n   $ Internet Standards document (ISD)\n\
    \      (C) In this Glossary, this term refers to an RFC, Internet-Draft,\n   \
    \   or other item that is produced as part of the Internet Standards\n      Process\
    \ [R2026]. However, neither the term nor the abbreviation is\n      widely accepted\
    \ and, therefore, SHOULD NOT be used in an ISD\n      unless it is accompanied\
    \ by an explanation like this. (See:\n      Internet Standard.)\n   $ internet\
    \ vs. Internet\n      1. (I) Not capitalized: A popular abbreviation for \"internetwork\"\
    .\n      2. (I) Capitalized: \"The Internet\" is the single, interconnected,\n\
    \      worldwide system of commercial, government, educational, and other\n  \
    \    computer networks that share the set of protocols specified by the\n    \
    \  IAB [R2026] and the name and address spaces managed by the ICANN.\n      (C)\
    \ The protocol set is named the \"Internet Protocol Suite\". It\n      also is\
    \ popularly known as \"TCP/IP\", because TCP and IP are two of\n      its fundamental\
    \ components. These protocols enable a user of any\n      one of the networks\
    \ in the Internet to communicate with, or use\n      services located on, any\
    \ of the other networks.\n      (C) Although the Internet does have architectural\
    \ principles\n      [R1958], no Internet Standard formally defines a layered reference\n\
    \      model for the IPS that is similar to the OSIRM. However, Internet\n   \
    \   community documents do refer (inconsistently) to layers:\n      application,\
    \ socket, transport, internetwork, network, data link,\n      and physical. In\
    \ this Glossary, Internet layers are referred to by\n      name to avoid confusing\
    \ them with OSIRM layers, which are referred\n      to by number.\n   $ internetwork\n\
    \      (I) A system of interconnected networks; a network of networks.\n     \
    \ Usually shortened to \"internet\". (See: internet vs. Internet.)\n      (C)\
    \ An internet is usually built using OSI layer 3 gateways to\n      connect a\
    \ set of subnetworks. When the subnetworks differ in the\n      OSI layer 3 protocol\
    \ service they provide, the gateways sometimes\n      implement a uniform internetwork\
    \ protocol (e.g., IP) that operates\n      at the top of layer 3 and hides the\
    \ underlying heterogeneity from\n      hosts that use communication services provided\
    \ by the internet.\n      (See: router.)\n   $ intranet\n      (I) A computer\
    \ network, especially one based on Internet\n      technology, that an organization\
    \ uses for its own internal, and\n      usually private, purposes and that is\
    \ closed to outsiders. (See:\n      extranet, virtual private network.)\n   $\
    \ intruder\n      (I) An entity that gains or attempts to gain access to a system\
    \ or\n      system resource without having authorization to do so. (See:\n   \
    \   cracker.)\n   $ intrusion\n      See: security intrusion.\n   $ intrusion\
    \ detection\n      (I) A security service that monitors and analyzes system events\n\
    \      for the purpose of finding, and providing real-time or near real-\n   \
    \   time warning of, attempts to access system resources in an\n      unauthorized\
    \ manner.\n   $ invalidity date\n      (N) An X.509 CRL entry extension that \"\
    indicates the date at which\n      it is known or suspected that the [revoked\
    \ certificate's private\n      key] was compromised or that the certificate should\
    \ otherwise be\n      considered invalid\" [X509].\n      (C) This date may be\
    \ earlier than the revocation date in the CRL\n      entry, and may even be earlier\
    \ than the date of issue of earlier\n      CRLs. However, the invalidity date\
    \ is not, by itself, sufficient\n      for purposes of non-repudiation service.\
    \ For example, to\n      fraudulently repudiate a validly-generated signature,\
    \ a private\n      key holder may falsely claim that the key was compromised at\
    \ some\n      time in the past.\n   $ IP\n      See: Internet Protocol.\n   $\
    \ IP address\n      (I) A computer's internetwork address that is assigned for\
    \ use by\n      the Internet Protocol and other protocols.\n      (C) An IP version\
    \ 4 [R0791] address is written as a series of four\n      8-bit numbers separated\
    \ by periods. For example, the address of\n      the host named \"rosslyn.bbn.com\"\
    \ is 192.1.7.10.\n      (C) An IP version 6 [R2373] address is written as x:x:x:x:x:x:x:x,\n\
    \      where each \"x\" is the hexadecimal value of one of the eight 16-bit\n\
    \      parts of the address. For example, 1080:0:0:0:8:800:200C:417A and\n   \
    \   FEDC:BA98:7654:3210:FEDC:BA98:7654:3210.\n   $ IP Security Option\n      See:\
    \ Internet Protocol Security Option.\n   $ IPRA\n      See: Internet Policy Registration\
    \ Authority.\n   $ IPsec\n      See: Internet Protocol security.\n   $ IPsec Key\
    \ Exchange (IKE)\n      (I) An Internet, IPsec, key-establishment protocol [R2409]\
    \ (partly\n      based on OAKLEY) that is intended for putting in place\n    \
    \  authenticated keying material for use with ISAKMP and for other\n      security\
    \ associations, such as in AH and ESP.\n   $ IPSO\n      See: Internet Protocol\
    \ Security Option.\n   $ ISAKMP\n      See: Internet Security Association and\
    \ Key Management Protocol.\n   $ ISD\n      See: Internet Standards document.\n\
    \   $ ISO\n      (I) International Organization for Standardization, a voluntary,\n\
    \      non-treaty, non-government organization, established in 1947, with\n  \
    \    voting members that are designated standards bodies of\n      participating\
    \ nations and non-voting observer organizations. (See:\n      ANSI, ITU-T.)\n\
    \      (C) Legally, ISO is a Swiss, non-profit, private organization. ISO\n  \
    \    and the IEC (the International Electrotechnical Commission) form\n      the\
    \ specialized system for worldwide standardization. National\n      bodies that\
    \ are members of ISO or IEC participate in developing\n      international standards\
    \ through ISO and IEC technical committees\n      that deal with particular fields\
    \ of activity. Other international\n      governmental and non-governmental organizations,\
    \ in liaison with\n      ISO and IEC, also take part. (ANSI is the U.S. voting\
    \ member of\n      ISO. ISO is a class D member of ITU-T.)\n      (C) The ISO\
    \ standards development process has four levels of\n      increasing maturity:\
    \ Working Draft (WD), Committee Draft (CD),\n      Draft International Standard\
    \ (DIS), and International Standard\n      (IS). (See: (standards track levels\
    \ under) Internet Standard.) In\n      information technology, ISO and IEC have\
    \ a joint technical\n      committee, ISO/IEC JTC 1. DISs adopted by JTC 1 are\
    \ circulated to\n      national bodies for voting, and publication as an IS requires\n\
    \      approval by at least 75% of the national bodies casting a vote.\n   $ ISOC\n\
    \      See: Internet Society.\n   $ issue (a digital certificate or CRL)\n   \
    \   (I) Generate and sign a digital certificate (or CRL) and, usually,\n     \
    \ distribute it and make it available to potential certificate users\n      (or\
    \ CRL users). (See: certificate creation.)\n      (C) The ABA Guidelines [ABA]\
    \ explicitly limit this term to\n      certificate creation, and exclude the act\
    \ of publishing. In\n      general usage, however, \"issuing\" a digital certificate\
    \ (or CRL)\n      includes not only certificate creation but also making it\n\
    \      available to potential users, such as by storing it in a\n      repository\
    \ or other directory or otherwise publishing it.\n   $ issuer\n      1. (I) \"\
    Issuer\" of a certificate or CRL: The CA that signs the\n      digital certificate\
    \ or CRL.\n      (C) An X.509 certificate always includes the issuer's name. The\n\
    \      name may include a common name value.\n      2. (N) \"Issuer\" of a payment\
    \ card: SET usage: \"The financial\n      institution or its agent that issues\
    \ the unique primary account\n      number to the cardholder for the payment card\
    \ brand.\" [SET2]\n      (C) The institution that establishes the account for\
    \ a cardholder\n      and issues the payment card also guarantees payment for\
    \ authorized\n      transactions that use the card in accordance with card brand\n\
    \      regulations and local legislation. [SET1]\n   $ ITAR\n      See: International\
    \ Traffic in Arms Regulations.\n   $ ITSEC\n      See: Information Technology\
    \ System Evaluation Criteria.\n   $ ITU-T\n      (N) International Telecommunications\
    \ Union, Telecommunication\n      Standardization Sector (formerly \"CCITT\"),\
    \ a United Nations treaty\n      organization that is composed mainly of postal,\
    \ telephone, and\n      telegraph authorities of the member countries and that\
    \ publishes\n      standards called \"Recommendations\". (See: X.400, X.500.)\n\
    \      (C) The Department of State represents the United States. ITU-T\n     \
    \ works on many kinds of communication systems. ITU-T cooperates\n      with ISO\
    \ on communication protocol standards, and many\n      Recommendations in that\
    \ area are also published as an ISO standard\n      with an ISO name and number.\n\
    \   $ IV\n      See: initialization value.\n   $ KDC\n      See: Key Distribution\
    \ Center.\n   $ KEA\n      See: Key Exchange Algorithm.\n   $ KEK\n      See:\
    \ key-encrypting key.\n   $ Kerberos\n      (N) A system developed at the Massachusetts\
    \ Institute of\n      Technology that depends on passwords and symmetric cryptography\n\
    \      (DES) to implement ticket-based, peer entity authentication\n      service\
    \ and access control service distributed in a client-server\n      network environment.\
    \ [R1510, Stei]\n      (C) Kerberos was developed by Project Athena and is named\
    \ for the\n      three-headed dog guarding Hades.\n   $ key\n      See: cryptographic\
    \ key.\n   $ key agreement (algorithm or protocol)\n      (I) A key establishment\
    \ method (especially one involving\n      asymmetric cryptography) by which two\
    \ or more entities, without\n      prior arrangement except a public exchange\
    \ of data (such as public\n      keys), each computes the same key value. I.e.,\
    \ each can\n      independently generate the same key value, but that key cannot\
    \ be\n      computed by other entities. (See: Diffie-Hellman, key\n      establishment,\
    \ Key Exchange Algorithm, key transport.)\n      (O) \"A method for negotiating\
    \ a key value on line without\n      transferring the key, even in an encrypted\
    \ form, e.g., the Diffie-\n      Hellman technique.\" [X509]\n      (O) \"The\
    \ procedure whereby two different parties generate shared\n      symmetric keys\
    \ such that any of the shared symmetric keys is a\n      function of the information\
    \ contributed by all legitimate\n      participants, so that no party [alone]\
    \ can predetermine the value\n      of the key.\" [A9042]\n      (C) For example,\
    \ a message originator and the intended recipient\n      can each use their own\
    \ private key and the other's public key with\n      the Diffie-Hellman algorithm\
    \ to first compute a shared secret\n      value and, from that value, derive a\
    \ session key to encrypt the\n      message.\n   $ key authentication\n      (N)\
    \ \"The assurance of the legitimate participants in a key\n      agreement that\
    \ no non-legitimate party possesses the shared\n      symmetric key.\" [A9042]\n\
    \   $ key center\n      (I) A centralized key distribution process (used in symmetric\n\
    \      cryptography), usually a separate computer system, that uses key-\n   \
    \   encrypting keys (master keys) to encrypt and distribute session\n      keys\
    \ needed in a community of users.\n      (C) An ANSI standard [A9017] defines\
    \ two types of key center: key\n      distribution center and key translation\
    \ center.\n   $ key confirmation\n      (N) \"The assurance of the legitimate\
    \ participants in a key\n      establishment protocol that the intended parties\
    \ sharing the\n      symmetric key actually possess the shared symmetric key.\"\
    \ [A9042]\n   $ key distribution\n      (I) A process that delivers a cryptographic\
    \ key from the location\n      where it is generated to the locations where it\
    \ is used in a\n      cryptographic algorithm. (See: key management.)\n   $ key\
    \ distribution center (KDC)\n      (I) A type of key center (used in symmetric\
    \ cryptography) that\n      implements a key distribution protocol to provide\
    \ keys (usually,\n      session keys) to two (or more) entities that wish to communicate\n\
    \      securely. (See: key translation center.)\n      (C) A KDC distributes keys\
    \ to Alice and Bob, who (a) wish to\n      communicate with each other but do\
    \ not currently share keys, (b)\n      each share a KEK with the KDC, and (c)\
    \ may not be able to generate\n      or acquire keys by themselves. Alice requests\
    \ the keys from the\n      KDC. The KDC generates or acquires the keys and makes\
    \ two\n      identical sets. The KDC encrypts one set in the KEK it shares with\n\
    \      Alice, and sends that encrypted set to Alice. The KDC encrypts the\n  \
    \    second set in the KEK it shares with Bob, and either sends that\n      encrypted\
    \ set to Alice for her to forward to Bob, or sends it\n      directly to Bob (although\
    \ the latter option is not supported in\n      the ANSI standard [A9017]).\n \
    \  $ key encapsulation\n      See: (secondary definition under) key recovery.\n\
    \   $ key-encrypting key (KEK)\n      (I) A cryptographic key that is used to\
    \ encrypt other keys, either\n      DEKs or other KEKs, but usually is not used\
    \ to encrypt application\n      data.\n   $ key escrow\n      See: (secondary\
    \ definition under) key recovery.\n   $ key establishment (algorithm or protocol)\n\
    \      (I) A process that combines the key generation and key\n      distribution\
    \ steps needed to set up or install a secure\n      communication association.\
    \ (See: key agreement, key transport.)\n      (O) \"The procedure to share a symmetric\
    \ key among different\n      parties by either key agreement or key transport.\"\
    \ [A9042]\n      (C) Key establishment involves either key agreement or key\n\
    \      transport:\n       - Key transport: One entity generates a secret key and\
    \ securely\n         sends it to the other entity. (Or each entity generates a\n\
    \         secret value and securely sends it to the other entity, where\n    \
    \     the two values are combined to form a secret key.)\n       - Key agreement:\
    \ No secret is sent from one entity to another.\n         Instead, both entities,\
    \ without prior arrangement except a\n         public exchange of data, compute\
    \ the same secret value. I.e.,\n         each can independently generate the same\
    \ value, but that value\n         cannot be computed by other entities.\n   $\
    \ Key Exchange Algorithm (KEA)\n      (N) A key agreement algorithm [NIST] that\
    \ is similar to the\n      Diffie-Hellman algorithm, uses 1024-bit asymmetric\
    \ keys, and was\n      developed and formerly classified at the \"Secret\" level\
    \ by NSA.\n      (See: CAPSTONE, CLIPPER, FORTEZZA, SKIPJACK.)\n      (C) On 23\
    \ June 1998, the NSA announced that KEA had been\n      declassified.\n   $ key\
    \ generation\n      (I) A process that creates the sequence of symbols that comprise\
    \ a\n      cryptographic key. (See: key management.)\n   $ key generator\n   \
    \   1. (I) An algorithm that uses mathematical rules to\n      deterministically\
    \ produce a pseudo-random sequence of\n      cryptographic key values.\n     \
    \ 2. (I) An encryption device that incorporates a key generation\n      mechanism\
    \ and applies the key to plaintext (e.g., by exclusive OR-\n      ing the key\
    \ bit string with the plaintext bit string) to produce\n      ciphertext.\n  \
    \ $ key length\n      (I) The number of symbols (usually bits) needed to be able\
    \ to\n      represent any of the possible values of a cryptographic key. (See:\n\
    \      key space.)\n   $ key lifetime\n      (N) MISSI usage: An attribute of\
    \ a MISSI key pair that specifies a\n      time span that bounds the validity\
    \ period of any MISSI X.509\n      public-key certificate that contains the public\
    \ component of the\n      pair. (See: cryptoperiod.)\n   $ key management\n  \
    \    (I) The process of handling and controlling cryptographic keys and\n    \
    \  related material (such as initialization values) during their life\n      cycle\
    \ in a cryptographic system, including ordering, generating,\n      distributing,\
    \ storing, loading, escrowing, archiving, auditing,\n      and destroying the\
    \ material. (See: key distribution, key escrow,\n      keying material, public-key\
    \ infrastructure.)\n      (O) \"The generation, storage, distribution, deletion,\
    \ archiving\n      and application of keys in accordance with a security policy.\"\
    \n      [I7498 Part 2]\n      (O) \"The activities involving the handling of cryptographic\
    \ keys\n      and other related security parameters (e.g., IVs, counters) during\n\
    \      the entire life cycle of the keys, including their generation,\n      storage,\
    \ distribution, entry and use, deletion or destruction, and\n      archiving.\"\
    \ [FP140]\n   $ Key Management Protocol (KMP)\n      (N) A protocol to establish\
    \ a shared symmetric key between a pair\n      (or a group) of users. (One version\
    \ of KMP was developed by SDNS,\n      and another by SILS.)\n   $ key material\
    \ identifier (KMID)\n      (N) MISSI usage: A 64-bit identifier that is assigned\
    \ to a key\n      pair when the public key is bound in a MISSI X.509 public-key\n\
    \      certificate.\n   $ key pair\n      (I) A set of mathematically related\
    \ keys--a public key and a\n      private key--that are used for asymmetric cryptography\
    \ and are\n      generated in a way that makes it computationally infeasible to\n\
    \      derive the private key from knowledge of the public key (e.g.,\n      see:\
    \ Diffie-Hellman, Rivest-Shamir-Adleman).\n      (C) A key pair's owner discloses\
    \ the public key to other system\n      entities so they can use the key to encrypt\
    \ data, verify a digital\n      signature, compute a protected checksum, or generate\
    \ a key in a\n      key agreement algorithm. The matching private key is kept\
    \ secret\n      by the owner, who uses it to decrypt data, generate a digital\n\
    \      signature, verify a protected checksum, or generate a key in a key\n  \
    \    agreement algorithm.\n   $ key recovery\n      1. (I) A process for learning\
    \ the value of a cryptographic key\n      that was previously used to perform\
    \ some cryptographic operation.\n      (See: cryptanalysis.)\n      2. (I) Techniques\
    \ that provide an intentional, alternate (i.e.,\n      secondary) means to access\
    \ the key used for data confidentiality\n      service in an encrypted association.\
    \ [DOD4]\n      (C) We assume that the encryption mechanism has a primary means\
    \ of\n      obtaining the key through a key establishment algorithm or\n     \
    \ protocol. For the secondary means, there are two classes of key\n      recovery\
    \ techniques--key escrow and key encapsulation:\n       - \"Key escrow\": A key\
    \ recovery technique for storing knowledge of\n         a cryptographic key or\
    \ parts thereof in the custody of one or\n         more third parties called \"\
    escrow agents\", so that the key can\n         be recovered and used in specified\
    \ circumstances.\n         Key escrow is typically implemented with split knowledge\n\
    \         techniques. For example, the Escrowed Encryption Standard\n        \
    \ [FP185] entrusts two components of a device-unique split key to\n         separate\
    \ escrow agents. The agents provide the components only\n         to someone legally\
    \ authorized to conduct electronic\n         surveillance of telecommunications\
    \ encrypted by that specific\n         device. The components are used to reconstruct\
    \ the device-\n         unique key, and it is used to obtain the session key needed\
    \ to\n         decrypt communications.\n       - \"Key encapsulation\": A key\
    \ recovery technique for storing\n         knowledge of a cryptographic key by\
    \ encrypting it with another\n         key and ensuring that that only certain\
    \ third parties called\n         \"recovery agents\" can perform the decryption\
    \ operation to\n         retrieve the stored key.\n         Key encapsulation\
    \ typically allows direct retrieval of the\n         secret key used to provide\
    \ data confidentiality.\n   $ key space\n      (I) The range of possible values\
    \ of a cryptographic key; or the\n      number of distinct transformations supported\
    \ by a particular\n      cryptographic algorithm. (See: key length.)\n   $ key\
    \ translation center\n      (I) A type of key center (used in a symmetric cryptography)\
    \ that\n      implements a key distribution protocol to convey keys between two\n\
    \      (or more) parties who wish to communicate securely. (See: key\n      distribution\
    \ center.)\n      (C) A key translation center translates keys for future\n  \
    \    communication between Bob and Alice, who (a) wish to communicate\n      with\
    \ each other but do not currently share keys, (b) each share a\n      KEK with\
    \ the center, and (c) have the ability to generate or\n      acquire keys by themselves.\
    \ Alice generates or acquires a set of\n      keys for communication with Bob.\
    \ Alice encrypts the set in the KEK\n      she shares with the center and sends\
    \ the encrypted set to the\n      center. The center decrypts the set, reencrypts\
    \ the set in the KEK\n      it shares with Bob, and either sends that encrypted\
    \ set to Alice\n      for her to forward to Bob, or sends it directly to Bob (although\n\
    \      direct distribution is not supported in the ANSI standard\n      [A9017]).\n\
    \   $ key transport (algorithm or protocol)\n      (I) A key establishment method\
    \ by which a secret key is generated\n      by one entity in a communication association\
    \ and securely sent to\n      another entity in the association. (See: key agreement.)\n\
    \      (O) \"The procedure to send a symmetric key from one party to other\n \
    \     parties. As a result, all legitimate participants share a common\n     \
    \ symmetric key in such a way that the symmetric key is determined\n      entirely\
    \ by one party.\" [A9042]\n      (C) For example, a message originator can generate\
    \ a random\n      session key and then use the Rivest-Shamir-Adleman algorithm\
    \ to\n      encrypt that key with the public key of the intended recipient.\n\
    \   $ key update\n      (I) Derive a new key from an existing key. (See: certificate\n\
    \      rekey.)\n   $ key validation\n      (N) \"The procedure for the receiver\
    \ of a public key to check that\n      the key conforms to the arithmetic requirements\
    \ for such a key in\n      order to thwart certain types of attacks.\" [A9042]\n\
    \   $ keyed hash\n      (I) A cryptographic hash (e.g., [R1828]) in which the\
    \ mapping to a\n      hash result is varied by a second input parameter that is\
    \ a\n      cryptographic key. (See: checksum.)\n      (C) If the input data object\
    \ is changed, a new hash result cannot\n      be correctly computed without knowledge\
    \ of the secret key. Thus,\n      the secret key protects the hash result so it\
    \ can be used as a\n      checksum even when there is a threat of an active attack\
    \ on the\n      data. There are least two forms of keyed hash:\n       - A function\
    \ based on a keyed encryption algorithm. (E.g., see:\n         Data Authentication\
    \ Code.)\n      -  A function based on a keyless hash that is enhanced by\n  \
    \       combining (e.g., by concatenating) the input data object\n         parameter\
    \ with a key parameter before mapping to the hash\n         result. (E.g., see:\
    \ HMAC.)\n   $ keying material\n      (I) Data (such as keys, key pairs, and initialization\
    \ values)\n      needed to establish and maintain a cryptographic security\n \
    \     association.\n   $ KMID\n      See: key material identifier.\n   $ known-plaintext\
    \ attack\n      (I) A cryptanalysis technique in which the analyst tries to\n\
    \      determine the key from knowledge of some plaintext-ciphertext\n      pairs\
    \ (although the analyst may also have other clues, such as the\n      knowing\
    \ the cryptographic algorithm).\n   $ L2F\n      See: Layer 2 Forwarding Protocol.\n\
    \   $ L2TP\n      See: Layer 2 Tunneling Protocol.\n   $ label\n      See: security\
    \ label.\n   $ Language of Temporal Ordering Specification (LOTOS)\n      (N)\
    \ A language (ISO 8807-1990) for formal specification of\n      computer network\
    \ protocols; describes the order in which events\n      occur.\n   $ lattice model\n\
    \      (I) A security model for flow control in a system, based on the\n     \
    \ lattice that is formed by the finite security levels in a system\n      and\
    \ their partial ordering. [Denn] (See: flow control, security\n      level, security\
    \ model.)\n      (C) The model describes the semantic structure formed by a finite\n\
    \      set of security levels, such as those used in military\n      organizations.\n\
    \      (C) A lattice is a finite set together with a partial ordering on\n   \
    \   its elements such that for every pair of elements there is a least\n     \
    \ upper bound and a greatest lower bound. For example, a lattice is\n      formed\
    \ by a finite set S of security levels -- i.e., a set S of all\n      ordered\
    \ pairs (x, c), where x is one of a finite set X of\n      hierarchically ordered\
    \ classification levels (X1, ..., Xm), and c\n      is a (possibly empty) subset\
    \ of a finite set C of non-hierarchical\n      categories (C1, ..., Cn) -- together\
    \ with the \"dominate\" relation.\n      (See: dominate.)\n   $ Law Enforcement\
    \ Access Field (LEAF)\n      (N) A data item that is automatically embedded in\
    \ data encrypted\n      by devices (e.g., see: CLIPPER chip) that implement the\
    \ Escrowed\n      Encryption Standard.\n   $ Layer 2 Forwarding Protocol (L2F)\n\
    \      (N) An Internet protocol (originally developed by Cisco\n      Corporation)\
    \ that uses tunneling of PPP over IP to create a\n      virtual extension of a\
    \ dial-up link across a network, initiated by\n      the dial-up server and transparent\
    \ to the dial-up user. (See:\n      L2TP.)\n   $ Layer 2 Tunneling Protocol (L2TP)\n\
    \      (N) An Internet client-server protocol that combines aspects of\n     \
    \ PPTP and L2F and supports tunneling of PPP over an IP network or\n      over\
    \ frame relay or other switched network. (See: virtual private\n      network.)\n\
    \      (C) PPP can in turn encapsulate any OSI layer 3 protocol. Thus,\n     \
    \ L2TP does not specify security services; it depends on protocols\n      layered\
    \ above and below it to provide any needed security.\n   $ LDAP\n      See: Lightweight\
    \ Directory Access Protocol.\n   $ least privilege\n      (I) The principle that\
    \ a security architecture should be designed\n      so that each system entity\
    \ is granted the minimum system resources\n      and authorizations that the entity\
    \ needs to do its work. (See:\n      economy of mechanism.)\n      (C) This principle\
    \ tends to limit damage that can be caused by an\n      accident, error, or unauthorized\
    \ act.\n   $ Lightweight Directory Access Protocol (LDAP)\n      (N) A client-server\
    \ protocol that supports basic use of the X.500\n      Directory (or other directory\
    \ servers) without incurring the\n      resource requirements of the full Directory\
    \ Access Protocol (DAP).\n      [R1777]\n      (C) Designed for simple management\
    \ and browser applications that\n      provide simple read/write interactive directory\
    \ service. Supports\n      both simple authentication and strong authentication\
    \ of the client\n      to the directory server.\n   $ link\n      (I) World Wide\
    \ Web usage: See: hyperlink.\n      (I) Subnetwork usage: A point-to-point communication\
    \ channel\n      connecting two subnetwork relays (especially one between two\n\
    \      packet switches) that is implemented at OSI layer 2. (See: link\n     \
    \ encryption.)\n      (C) The relay computers assume that links are logically\
    \ passive.\n      If a computer at one end of a link sends a sequence of bits,\
    \ the\n      sequence simply arrives at the other end after a finite time,\n \
    \     although some bits may have been changed either accidentally\n      (errors)\
    \ or by active wiretapping.\n   $ link-by-link encryption\n   $ link encryption\n\
    \      (I) Stepwise protection of data that flows between two points in a\n  \
    \    network, provided by encrypting data separately on each network\n      link,\
    \ i.e., by encrypting data when it leaves a host or subnetwork\n      relay and\
    \ decrypting when it arrives at the next host or relay.\n      Each link may use\
    \ a different key or even a different algorithm.\n      [R1455] (See: end-to-end\
    \ encryption.)\n   $ logic bomb\n      (I) Malicious logic that activates when\
    \ specified conditions are\n      met. Usually intended to cause denial of service\
    \ or otherwise\n      damage system resources. (See: Trojan horse, virus, worm.)\n\
    \   $ login\n      (I) The act of a system entity gaining access to a session\
    \ in\n      which the entity can use system resources; usually accomplished by\n\
    \      providing a user name and password to an access control system\n      that\
    \ authenticates the user.\n      (C) Derives from \"log\" file\", a security audit\
    \ trail that records\n      security events, such as the beginning of sessions,\
    \ and who\n      initiates them.\n   $ LOTOS\n      See: Language of Temporal\
    \ Ordering Specification.\n   $ MAC\n      See: mandatory access control, Message\
    \ Authentication Code.\n   $ malicious logic\n      (I) Hardware, software, or\
    \ firmware that is intentionally included\n      or inserted in a system for a\
    \ harmful purpose. (See: logic bomb,\n      Trojan horse, virus, worm.)\n   $\
    \ malware\n      (I) A contraction of \"malicious software\". (See: malicious\
    \ logic.)\n      (D) ISDs SHOULD NOT use this term because it is not listed in\
    \ most\n      dictionaries and could confuse international readers.\n   $ man-in-the-middle\n\
    \      (I) A form of active wiretapping attack in which the attacker\n      intercepts\
    \ and selectively modifies communicated data in order to\n      masquerade as\
    \ one or more of the entities involved in a\n      communication association.\
    \ (See: hijack attack, piggyback attack.)\n      (C) For example, suppose Alice\
    \ and Bob try to establish a session\n      key by using the Diffie-Hellman algorithm\
    \ without data origin\n      authentication service. A \"man in the middle\" could\
    \ (a) block\n      direct communication between Alice and Bob and then (b) masquerade\n\
    \      as Alice sending data to Bob, (c) masquerade as Bob sending data\n    \
    \  to Alice, (d) establish separate session keys with each of them,\n      and\
    \ (e) function as a clandestine proxy server between them in\n      order to capture\
    \ or modify sensitive information that Alice and\n      Bob think they are sending\
    \ only to each other.\n   $ mandatory access control (MAC)\n      (I) An access\
    \ control service that enforces a security policy\n      based on comparing (a)\
    \ security labels (which indicate how\n      sensitive or critical system resources\
    \ are) with (b) security\n      clearances (which indicate system entities are\
    \ eligible to access\n      certain resources). (See: discretionary access control,\
    \ rule-based\n      security policy.)\n      (C) This kind of access control is\
    \ called \"mandatory\" because an\n      entity that has clearance to access a\
    \ resource may not, just by\n      its own volition, enable another entity to\
    \ access that resource.\n      (O) \"A means of restricting access to objects\
    \ based on the\n      sensitivity (as represented by a label) of the information\n\
    \      contained in the objects and the formal authorization (i.e.,\n      clearance)\
    \ of subjects to access information of such sensitivity.\"\n      [DOD1]\n   $\
    \ manipulation detection code\n      (D) ISDs SHOULD NOT use this term as a synonym\
    \ for \"checksum\"\n      because the word \"manipulation\" implies protection\
    \ against active\n      attacks, which an ordinary checksum might not provide.\
    \ Instead, if\n      such protection is intended, use \"protected checksum\" or\
    \ some\n      particular type thereof, depending on which is meant. If such\n\
    \      protection is not intended, use \"error detection code\" or some\n    \
    \  specific type of checksum that is not protected.\n   $ masquerade attack\n\
    \      (I) A type of attack in which one system entity illegitimately\n      poses\
    \ as (assumes the identity of) another entity. (See: spoofing\n      attack.)\n\
    \   $ MCA\n      See: merchant certificate authority.\n   $ MD2\n      (N) A cryptographic\
    \ hash [R1319] that produces a 128-bit hash\n      result, was designed by Ron\
    \ Rivest, and is similar to MD4 and MD5\n      but slower. (See: message digest.)\n\
    \   $ MD4\n      (N) A cryptographic hash [R1320] that produces a 128-bit hash\n\
    \      result and was designed by Ron Rivest. (See: message digest and\n     \
    \ SHA-1.)\n   $ MD5\n      (N) A cryptographic hash [R1321] that produces a 128-bit\
    \ hash\n      result and was designed by Ron Rivest to be an improved version\
    \ of\n      MD4.\n   $ merchant\n      (O) SET usage: \"A seller of goods, services,\
    \ and/or other\n      information who accepts payment for these items electronically.\"\
    \n      [SET2] A merchant may also provide electronic selling services\n     \
    \ and/or electronic delivery of items for sale. With SET, the\n      merchant\
    \ can offer its cardholders secure electronic interactions,\n      but a merchant\
    \ that accepts payment cards is required to have a\n      relationship with an\
    \ acquirer. [SET1, SET2]\n   $ merchant certificate\n      (O) SET usage: A public-key\
    \ certificate issued to a merchant.\n      Sometimes used to refer to a pair of\
    \ such certificates where one\n      is for digital signature use and the other\
    \ is for encryption.\n   $ merchant certification authority (MCA)\n      (O) SET\
    \ usage: A CA that issues digital certificates to merchants\n      and is operated\
    \ on behalf of a payment card brand, an acquirer, or\n      another party according\
    \ to brand rules. Acquirers verify and\n      approve requests for merchant certificates\
    \ prior to issuance by\n      the MCA. An MCA does not issue a CRL, but does distribute\
    \ CRLs\n      issued by root CAs, brand CAs, geopolitical CAs, and payment\n \
    \     gateway CAs. [SET2]\n   $ mesh PKI\n      (I) A non-hierarchical PKI architecture\
    \ in which there are several\n      trusted CAs rather than a single root. Each\
    \ certificate user bases\n      path validations on the public key of one of the\
    \ trusted CAs,\n      usually the one that issued that user's own public-key\n\
    \      certificate. Rather than having superior-to-subordinate\n      relationships\
    \ between CAs, the relationships are peer-to-peer, and\n      CAs issue cross-certificates\
    \ to each other. (See: hierarchical\n      PKI, trust-file PKI.)\n   $ message\
    \ authentication code vs. Message Authentication Code (MAC)\n      1. (N) Capitalized:\
    \ \"(The) Message Authentication Code\" refers to\n      an ANSI standard for\
    \ a checksum that is computed with a keyed hash\n      that is based on DES. [A9009]\
    \ (Also known as the U.S. Government\n      standard Data Authentication Code.\
    \ [FP113])\n      (C) The ANSI standard MAC algorithm is equivalent to cipher\
    \ block\n      chaining with IV = 0.\n      2. (D) Not capitalized: ISDs SHOULD\
    \ NOT use the uncapitalized form\n      \"message authentication code\", because\
    \ this term mixes concepts in\n      a potentially misleading way. Instead, use\
    \ \"checksum\", \"error\n      detection code\", \"hash\", \"keyed hash\", \"\
    Message Authentication\n      Code\", or \"protected checksum\", depending on\
    \ what is meant. (See:\n      authentication code.)\n      (C) In the uncapitalized\
    \ form, the word \"message\" is misleading\n      because it implies that the\
    \ mechanism is particularly suitable for\n      or limited to electronic mail\
    \ (see: Message Handling Systems), the\n      word \"authentication\" is misleading\
    \ because the mechanism\n      primarily serves a data integrity function rather\
    \ than an\n      authentication function, and the word \"code\" is misleading\
    \ because\n      it implies that either encoding or encryption is involved or\
    \ that\n      the term refers to computer software.\n   $ message digest\n   \
    \   (D) ISDs SHOULD NOT use this term as a synonym for \"hash result\"\n     \
    \ because it unnecessarily duplicates the meaning of the other, more\n      general\
    \ term and mixes concepts in a potentially misleading way.\n      (See: cryptographic\
    \ hash, Message Handling System.)\n   $ Message Handling Systems\n      (I) A\
    \ ITU-T/ISO system concept, which encompasses the notion of\n      electronic\
    \ mail but defines more comprehensive OSI systems and\n      services that enable\
    \ users to exchange messages on a store-and-\n      forward basis. (The ISO equivalent\
    \ is \"Message Oriented Text\n      Interchange System\".) (See: X.400.)\n   $\
    \ message indicator\n      (D) ISDs SHOULD NOT use this term as a synonym for\
    \ \"initialization\n      value\" because it mixes concepts in a potentially misleading\
    \ way.\n   $ message integrity check\n   $ message integrity code\n      (D) ISDs\
    \ SHOULD NOT use these terms because they mix concepts in a\n      potentially\
    \ misleading way. (The word \"message\" is misleading\n      because it suggests\
    \ that the mechanism is particularly suitable\n      for or limited to electronic\
    \ mail. The word \"code\" is misleading\n      because it suggests that either\
    \ encoding or encryption is\n      involved, or that the term refers to computer\
    \ software.) Instead,\n      use \"checksum\", \"error detection code\", \"hash\"\
    , \"keyed hash\",\n      \"Message Authentication Code\", or \"protected checksum\"\
    , depending\n      on what is meant.\n   $ Message Security Protocol (MSP)\n \
    \     (N) A secure message handling protocol [SDNS7] for use with X.400\n    \
    \  and Internet mail protocols. Developed by NSA's SDNS program and\n      used\
    \ in the U.S. Defense Message System.\n   $ MHS\n      See: message handling system.\n\
    \   $ MIME\n      See: Multipurpose Internet Mail Extensions.\n   $ MIME Object\
    \ Security Services (MOSS)\n      (I) An Internet protocol [R1848] that applies\
    \ end-to-end\n      encryption and digital signature to MIME message content,\
    \ using\n      symmetric cryptography for encryption and asymmetric cryptography\n\
    \      for key distribution and signature. MOSS is based on features and\n   \
    \   specifications of PEM. (See: S/MIME.)\n   $ Minimum Interoperability Specification\
    \ for PKI Components (MISPC)\n      (N) A technical description to provide a basis\
    \ for interoperation\n      between PKI components from different vendors; consists\
    \ primarily\n      of a profile of certificate and CRL extensions and a set of\n\
    \      transactions for PKI operation. [MISPC]\n   $ MISPC\n      See: Minimum\
    \ Interoperability Specification for PKI Components.\n   $ MISSI\n      (N) Multilevel\
    \ Information System Security Initiative, an NSA\n      program to encourage development\
    \ of interoperable, modular\n      products for constructing secure network information\
    \ systems in\n      support of a wide variety of Government missions. (See: MSP.)\n\
    \   $ MISSI user\n      (O) MISSI usage: A system entity that is the subject of\
    \ one or\n      more MISSI X.509 public-key certificates issued under a MISSI\n\
    \      certification hierarchy. (See: personality.)\n      (C) MISSI users include\
    \ both end users and the authorities that\n      issue certificates. A MISSI user\
    \ is usually a person but may be a\n      machine or other automated process.\
    \ Some machines are required to\n      operate non-stop. To avoid downtime needed\
    \ to exchange the\n      FORTEZZA cards of machine operators at shift changes,\
    \ the machines\n      may be issued their own cards, as if they were persons.\n\
    \   $ mode\n   $ mode of operation\n      (I) Encryption usage: A technique for\
    \ enhancing the effect of a\n      cryptographic algorithm or adapting the algorithm\
    \ for an\n      application, such as applying a block cipher to a sequence of\
    \ data\n      blocks or a data stream. (See: electronic codebook, cipher block\n\
    \      chaining, cipher feedback, output feedback.)\n      (I) System operation\
    \ usage: A type of security policy that states\n      the range of classification\
    \ levels of information that a system is\n      permitted to handle and the range\
    \ of clearances and authorizations\n      of users who are permitted to access\
    \ the system. (See: dedicated\n      security mode, multilevel security mode,\
    \ partitioned security\n      mode, system high security mode.)\n   $ modulus\n\
    \      (I) The defining constant in modular arithmetic, and usually a\n      part\
    \ of the public key in asymmetric cryptography that is based on\n      modular\
    \ arithmetic. (See: Diffie-Hellman, Rivest-Shamir-Adleman.)\n   $ Morris Worm\n\
    \      (I) A worm program written by Robert T. Morris, Jr. that flooded\n    \
    \  the ARPANET in November, 1988, causing problems for thousands of\n      hosts.\
    \ (See: worm.)\n   $ MOSS\n      See: MIME Object Security Services.\n   $ MSP\n\
    \      See: Message Security Protocol.\n   $ multilevel secure (MLS)\n      (I)\
    \ A class of system that has system resources (particularly\n      stored information)\
    \ at more than one security level (i.e., has\n      different types of sensitive\
    \ resources) and that permits\n      concurrent access by users who differ in\
    \ security clearance and\n      need-to-know, but is able to prevent each user\
    \ from accessing\n      resources for which the user lacks authorization.\n  \
    \ $ multilevel security mode\n      (I) A mode of operation of an information\
    \ system, that allows two\n      or more classification levels of information\
    \ to be processed\n      concurrently within the same system when not all users\
    \ have a\n      clearance or formal access authorization for all data handled\
    \ by\n      the system.\n      (C) This mode is defined formally in U.S. Department\
    \ of Defense\n      policy regarding system accreditation [DOD2], but the term\
    \ is also\n      used outside the Defense Department and outside the Government.\n\
    \   $ Multipurpose Internet Mail Extensions (MIME)\n      (I) An Internet protocol\
    \ [R2045] that enhances the basic format of\n      Internet electronic mail messages\
    \ [R0822] to be able to use\n      character sets other than US-ASCII for textual\
    \ headers and text\n      content, and to carry non-textual and multi-part content.\
    \ (See:\n      S/MIME.)\n   $ mutual suspicion\n      (I) The state that exists\
    \ between two interacting system entities\n      in which neither entity can trust\
    \ the other to function correctly\n      with regard to some security requirement.\n\
    \   $ National Computer Security Center (NCSC)\n      (N) A U.S. Department of\
    \ Defense organization, housed in NSA, that\n      has responsibility for encouraging\
    \ widespread availability of\n      trusted computer systems throughout the Federal\
    \ Government. It has\n      established criteria for, and performs evaluations\
    \ of, computer\n      and network systems that have a trusted computing base.\
    \ (See:\n      Evaluated Products List, Rainbow Series, TCSEC.)\n   $ National\
    \ Information Assurance Partnership (NIAP)\n      (N) An organization created\
    \ by NIST and NSA to enhance the quality\n      of commercial products for information\
    \ security and increase\n      consumer confidence in those products through objective\
    \ evaluation\n      and testing methods.\n      (C) NIAP is registered, through\
    \ the U.S. Department of Defense, as\n      a National Performance Review Reinvention\
    \ Laboratory. NIAP\n      functions include the following:\n       - Developing\
    \ tests, test methods, and other tools that developers\n         and testing laboratories\
    \ may use to improve and evaluate\n         security products.\n       - Collaborating\
    \ with industry and others on research and testing\n         programs.\n     \
    \  - Using the Common Criteria to develop protection profiles and\n         associated\
    \ test sets for security products and systems.\n       - Cooperating with the\
    \ NIST National Voluntary Laboratory\n         Accreditation Program to develop\
    \ a program to accredit private-\n         sector laboratories for the testing\
    \ of information security\n         products using the Common Criteria.\n    \
    \   - Working to establish a formal, international mutual recognition\n      \
    \   scheme for a Common Criteria-based evaluation.\n   $ National Institute of\
    \ Standards and Technology (NIST)\n      (N) A U.S. Department of Commerce agency\
    \ that promotes U.S.\n      economic growth by working with industry to develop\
    \ and apply\n      technology, measurements, and standards. Has primary Government\n\
    \      responsibility for INFOSEC standards for unclassified but\n      sensitive\
    \ information. (See: ANSI, DES, DSA, DSS, FIPS, NIAP,\n      NSA.)\n   $ National\
    \ Security Agency (NSA)\n      (N) A U.S. Department of Defense intelligence agency\
    \ that has\n      primary Government responsibility for INFOSEC for classified\n\
    \      information and for unclassified but sensitive information handled\n  \
    \    by national security systems. (See: FORTEZZA, KEA, MISSI, NIAP,\n      NIST,\
    \ SKIPJACK.)\n   $ need-to-know\n      (I) The necessity for access to, knowledge\
    \ of, or possession of\n      specific information required to carry out official\
    \ duties.\n      (C) This criterion is used in security procedures that require\
    \ a\n      custodian of sensitive information, prior to disclosing the\n     \
    \ information to someone else, to establish that the intended\n      recipient\
    \ has proper authorization to access the information.\n   $ network\n      See:\
    \ computer network.\n   $ NIAP\n      See: National Information Assurance Partnership.\n\
    \   $ NIST\n      See: National Institute of Standards and Technology.\n   $ NLSP\n\
    \      Network Layer Security Protocol. An OSI protocol (IS0 11577) for\n    \
    \  end-to-end encryption services at the top of OSI layer 3. NLSP is\n      derived\
    \ from an SDNS protocol, SP3, but is much more complex.\n   $ no-lone zone\n \
    \     (I) A room or other space to which no person may have\n      unaccompanied\
    \ access and that, when occupied, is required to be\n      occupied by two or\
    \ more appropriately authorized persons. (See:\n      dual control.)\n   $ nonce\n\
    \      (I) A random or non-repeating value that is included in data\n      exchanged\
    \ by a protocol, usually for the purpose of guaranteeing\n      liveness and thus\
    \ detecting and protecting against replay attacks.\n   $ non-critical\n      See:\
    \ critical (extension of certificate).\n   $ non-repudiation service\n      (I)\
    \ A security service that provide protection against false\n      denial of involvement\
    \ in a communication. (See: repudiation.)\n      (C) Non-repudiation service does\
    \ not and cannot prevent an entity\n      from repudiating a communication. Instead,\
    \ the service provides\n      evidence that can be stored and later presented\
    \ to a third party\n      to resolve disputes that arise if and when a communication\
    \ is\n      repudiated by one of the entities involved. There are two basic\n\
    \      kinds of non-repudiation service:\n       - \"Non-repudiation with proof\
    \ of origin\" provides the recipient\n         of data with evidence that proves\
    \ the origin of the data, and\n         thus protects the recipient against an\
    \ attempt by the\n         originator to falsely deny sending the data. This service\
    \ can\n         be viewed as a stronger version of an data origin\n         authentication\
    \ service, in that it proves authenticity to a\n         third party.\n      \
    \ - \"Non-repudiation with proof of receipt\" provides the originator\n      \
    \   of data with evidence that proves the data was received as\n         addressed,\
    \ and thus protects the originator against an attempt\n         by the recipient\
    \ to falsely deny receiving the data.\n      (C) Phases of a Non-Repudiation Service:\
    \ Ford [For94, For97] uses\n      the term \"critical action\" to refer to the\
    \ act of communication\n      that is the subject of the service:\n      --------\
    \   --------   --------   --------   --------   . --------\n      Phase 1:   Phase\
    \ 2:   Phase 3:   Phase 4:   Phase 5:   . Phase 6:\n      Request    Generate\
    \   Transfer   Verify     Retain     . Resolve\n      Service    Evidence   Evidence\
    \   Evidence   Evidence   . Dispute\n      --------   --------   --------   --------\
    \   --------   . --------\n      Service    Critical   Evidence   Evidence   Archive\
    \    . Evidence\n      Request => Action  => Stored  => Is      => Evidence  \
    \ . Is\n      Is Made    Occurs     For Later  Tested     In Case    . Verified\n\
    \                 and        Use |          ^      Critical   .     ^\n      \
    \           Evidence       v          |      Action Is  .     |\n            \
    \     Is         +-------------------+ Repudiated .     |\n                 Generated\
    \  |Verifiable Evidence|------> ... . ----+\n                            +-------------------+\n\
    \      Phase / Explanation\n      -------------------\n      1. Before the critical\
    \ action, the service requester asks, either\n         implicitly or explicitly,\
    \ to have evidence of the action be\n         generated.\n      2. When the critical\
    \ action occurs, evidence is generated by a\n         process involving the potential\
    \ repudiator and possibly also a\n         trusted third party.\n      3. The\
    \ evidence is transferred to the requester, or stored by a\n         third party,\
    \ for later use if needed.\n      4. The entity that holds the evidence tests\
    \ to be sure that it\n         will suffice if a dispute arises.\n      5. The\
    \ evidence is retained for possible future retrieval and use.\n      6. In this\
    \ phase, which occurs only if the critical action is\n         repudiated, the\
    \ evidence is retrieved from storage, presented,\n         and verified to resolve\
    \ the dispute.\n   $ no-PIN ORA (NORA)\n      (O) MISSI usage: An organizational\
    \ RA that operates in a mode in\n      which the ORA performs no card management\
    \ functions and,\n      therefore, does not require knowledge of either the SSO\
    \ PIN or\n      user PIN for an end user's FORTEZZA PC card.\n   $ NORA\n    \
    \  See: no-PIN ORA.\n   $ notarization\n      (I) Registration of data under the\
    \ authority or in the care of a\n      trusted third party, thus making it possible\
    \ to provide subsequent\n      assurance of the accuracy of characteristics claimed\
    \ for the data,\n      such as content, origin, time, and delivery. [I7498 Part\
    \ 2] (See:\n      digital notary.)\n   $ NULL encryption algorithm\n      (I)\
    \ An algorithm [R2410] that does nothing to transform plaintext\n      data; i.e.,\
    \ a no-op. It originated because of IPsec ESP, which\n      always specifies the\
    \ use of an encryption algorithm to provide\n      confidentiality. The NULL encryption\
    \ algorithm is a convenient way\n      to represent the option of not applying\
    \ encryption in ESP (or in\n      any other context where this is needed).\n \
    \  $ OAKLEY\n      (I) A key establishment protocol (proposed for IPsec but\n\
    \      superseded by IKE) based on the Diffie-Hellman algorithm and\n      designed\
    \ to be a compatible component of ISAKMP. [R2412]\n      (C) OAKLEY establishes\
    \ a shared key with an assigned identifier\n      and associated authenticated\
    \ identities for parties. I.e., OAKLEY\n      provides authentication service\
    \ to ensure the entities of each\n      other's identity, even if the Diffie-Hellman\
    \ exchange is\n      threatened by active wiretapping. Also, provides public-key\n\
    \      forward secrecy for the shared key and supports key updates,\n      incorporation\
    \ of keys distributed by out-of-band mechanisms, and\n      user-defined abstract\
    \ group structures for use with Diffie-\n      Hellman.\n   $ object\n      (I)\
    \ Trusted computer system modeling usage: A system element that\n      contains\
    \ or receives information. (See: Bell-LaPadula Model,\n      trusted computer\
    \ system.)\n   $ object identifier (OID)\n      (I) An official, globally unique\
    \ name for a thing, written as a\n      sequence of integers (which are formed\
    \ and assigned as defined in\n      the ASN.1 standard) and used to reference\
    \ the thing in abstract\n      specifications and during negotiation of security\
    \ services in a\n      protocol.\n      (O) \"A value (distinguishable from all\
    \ other such values) which is\n      associated with an object.\" [X680]\n   \
    \   (C) Objects named by OIDs are leaves of the object identifier tree\n     \
    \ (which is similar to but different from the X.500 Directory\n      Information\
    \ Tree). Each arc (i.e., each branch of the tree) is\n      labeled with a non-negative\
    \ integer. An OID is the sequence of\n      integers on the path leading from\
    \ the root of the tree to a named\n      object.\n      (C) The OID tree has three\
    \ arcs immediately below the root: {0}\n      for use by ITU-T, {1} for use by\
    \ ISO, and {2} for use by both\n      jointly. Below ITU-T are four arcs, where\
    \ {0 0} is for ITU-T\n      recommendations. Below {0 0} are 26 arcs, one for\
    \ each series of\n      recommendations starting with the letters A to Z, and\
    \ below these\n      are arcs for each recommendation. Thus, the OID for ITU-T\n\
    \      Recommendation X.509 is {0 0 24 509}. Below ISO are four arcs,\n      where\
    \ {1 0 }is for ISO standards, and below these are arcs for\n      each ISO standard.\
    \ Thus, the OID for ISO/IEC 9594-8 (the ISO\n      number for X.509) is {1 0 9594\
    \ 8}.\n      (C) The following are additional examples: ANSI registers\n     \
    \ organization names below the branch {joint-iso-ccitt(2)\n      country(16) US(840)\
    \ organization(1)}. The NIST CSOR records PKI\n      objects below the branch\
    \ {joint-iso-ccitt(2) country(16) us(840)\n      gov(101) csor(3) pki(4)}. The\
    \ U.S. Department of Defense registers\n      INFOSEC objects below the branch\
    \ {joint-iso-ccitt(2) country(16)\n      us(840) organization(1) gov(101) dod(2)\
    \ infosec(1)}. The OID for\n      the PKIX private extension is defined in an\
    \ arc below the arc for\n      the PKIX name space, as {iso(1) identified-organization(3)\
    \ dod(6)\n      internet(1) security(5) mechanisms(5) pkix(7) 1 1}.\n   $ object\
    \ reuse\n      (N) \"The reassignment and reuse of a storage medium (e.g., page\n\
    \      frame, disk sector, magnetic tape) that once contained one or more\n  \
    \    [information] objects. To be securely reused and assigned to a new\n    \
    \  subject, storage media must contain no residual data (magnetic\n      remanence)\
    \ from the object(s) previously contained in the media.\"\n      [NCS04]\n   $\
    \ OCSP\n      See: On-line Certificate Status Protocol.\n   $ octet\n      (I)\
    \ A data unit of eight bits. (See: byte.)\n      (c) This term is used in networking\
    \ (especially in OSI standards)\n      in preference to \"byte\", because some\
    \ systems use \"byte\" for data\n      storage units of a size other than eight.\n\
    \   $ OFB\n      See: output feedback.\n   $ ohnosecond\n      (C) That minuscule\
    \ fraction of time in which you realize that your\n      private key has been\
    \ compromised.\n   $ OID\n      See: object identifier.\n   $ On-line Certificate\
    \ Status Protocol (OCSP)\n      (I) An Internet protocol used by a client to obtain\
    \ from a server\n      the validity status and other information concerning a\
    \ digital\n      certificate.\n      (C) In some applications, such as those involving\
    \ high-value\n      commercial transactions, it may be necessary to obtain certificate\n\
    \      revocation status that is more timely than is possible with CRLs\n    \
    \  or to obtain other kinds of status information. OCSP may be used\n      to\
    \ determine the current revocation status of a digital\n      certificate, in\
    \ lieu of or as a supplement to checking against a\n      periodic CRL. An OCSP\
    \ client issues a status request to an OCSP\n      server and suspends acceptance\
    \ of the certificate in question\n      until the server provides a response.\n\
    \   $ one-time pad\n      (I) An encryption algorithm in which the key is a random\
    \ sequence\n      of symbols and each symbol is used for encryption only one time--\n\
    \      to encrypt only one plaintext symbol to produce only one\n      ciphertext\
    \ symbol--and a copy of the key is used similarly for\n      decryption.\n   \
    \   (C) To ensure one-time use, the copy of the key used for\n      encryption\
    \ is destroyed after use, as is the copy used for\n      decryption. This is the\
    \ only encryption algorithm that is truly\n      unbreakable, even given unlimited\
    \ resources for cryptanalysis\n      [Schn], but key management costs and synchronization\
    \ problems make\n      it impractical except in special situations.\n   $ one-time\
    \ password\n   $ One-Time Password (OTP)\n      1. Not capitalized: A \"one-time\
    \ password\" is a simple\n      authentication technique in which each password\
    \ is used only once\n      as authentication information that verifies an identity.\
    \ This\n      technique counters the threat of a replay attack that uses\n   \
    \   passwords captured by wiretapping.\n      2. Capitalized: \"One-Time Password\"\
    \ is an Internet protocol\n      [R1938] that is based on S/KEY and uses a cryptographic\
    \ hash\n      function to generate one-time passwords for use as authentication\n\
    \      information in system login and in other processes that need\n      protection\
    \ against replay attacks.\n   $ one-way encryption\n      (I) Irreversible transformation\
    \ of plaintext to ciphertext, such\n      that the plaintext cannot be recovered\
    \ from the ciphertext by\n      other than exhaustive procedures even if the cryptographic\
    \ key is\n      known. (See: encryption.)\n   $ one-way function\n      (I) \"\
    A (mathematical) function, f, which is easy to compute, but\n      which for a\
    \ general value y in the range, it is computationally\n      difficult to find\
    \ a value x in the domain such that f(x) = y.\n      There may be a few values\
    \ of y for which finding x is not\n      computationally difficult.\" [X509]\n\
    \      (D) ISDs SHOULD NOT use this term as a synonym for \"cryptographic\n  \
    \    hash\".\n   $ open security environment\n      (O) U.S. Department of Defense\
    \ usage: A system environment that\n      meets at least one of the following\
    \ conditions: (a) Application\n      developers (including maintainers) do not\
    \ have sufficient\n      clearance or authorization to provide an acceptable presumption\n\
    \      that they have not introduced malicious logic. (b) Configuration\n    \
    \  control does not provide sufficient assurance that applications\n      and\
    \ the equipment are protected against the introduction of\n      malicious logic\
    \ prior to and during the operation of system\n      applications. [NCS04] (See:\
    \ closed security environment.)\n   $ Open Systems Interconnection (OSI) Reference\
    \ Model (OSIRM)\n      (N) A joint ISO/ITU-T standard [I7498 Part 1] for a seven-layer,\n\
    \      architectural communication framework for interconnection of\n      computers\
    \ in networks.\n      (C) OSI-based standards include communication protocols\
    \ that are\n      mostly incompatible with the Internet Protocol Suite, but also\n\
    \      include security models, such as X.509, that are used in the\n      Internet.\n\
    \      (C) The OSIRM layers, from highest to lowest, are (7) Application,\n  \
    \    (6) Presentation, (5) Session, (4) Transport, (3) Network, (2)\n      Data\
    \ Link, and (1) Physical. In this Glossary, these layers are\n      referred to\
    \ by number to avoid confusing them with Internet\n      Protocol Suite layers,\
    \ which are referred to by name.\n      (C) Some unknown person described how\
    \ the OSI layers correspond to\n      the seven deadly sins:\n      7. Wrath:\
    \ Application is always angry at the mess it sees below\n         itself. (Hey!\
    \ Who is it to be pointing fingers?)\n      6. Sloth: Presentation is too lazy\
    \ to do anything productive by\n         itself.\n      5. Lust: Session is always\
    \ craving and demanding what truly\n         belongs to Application's functionality.\n\
    \      4. Avarice: Transport wants all of the end-to-end functionality.\n    \
    \     (Of course, it deserves it, but life isn't fair.)\n      3. Gluttony: (Connection-Oriented)\
    \ Network is overweight and\n         overbearing after trying too often to eat\
    \ Transport's lunch.\n      2. Envy: Poor Data Link is always starved for attention.\
    \ (With\n         Asynchronous Transfer Mode, maybe now it is feeling less\n \
    \        neglected.)\n      1. Pride: Physical has managed to avoid much of the\
    \ controversy,\n         and nearly all of the embarrassment, suffered by the\
    \ others.\n      (C) John G. Fletcher described how the OSI layers also correspond\n\
    \      to Snow White's dwarf friends:\n      7. Doc: Application acts as if it\
    \ is in charge, but sometimes\n         muddles its syntax.\n      6. Sleepy:\
    \ Presentation is indolent, being guilty of the sin of\n         Sloth.\n    \
    \  5. Dopey: Session is confused because its charter is not very\n         clear.\n\
    \      4. Grumpy: Transport is irritated because Network has encroached\n    \
    \     on Transport's turf.\n      3. Happy: Network smiles for the same reason\
    \ that Transport is\n         irritated.\n      2. Sneezy: Data Link makes loud\
    \ noises in the hope of attracting\n         attention.\n      1. Bashful: Physical\
    \ quietly does its work, unnoticed by the\n         others.\n   $ operational\
    \ integrity\n      (I) A synonym for \"system integrity\"; emphasizes the actual\n\
    \      performance of system functions rather than just the ability to\n     \
    \ perform them.\n   $ operations security (OPSEC)\n      (I) A process to identify,\
    \ control, and protect evidence of the\n      planning and execution of sensitive\
    \ activities and operations, and\n      thereby prevent potential adversaries\
    \ from gaining knowledge of\n      capabilities and intentions.\n   $ OPSEC\n\
    \      See: operations security.\n   $ ORA\n      See: organizational registration\
    \ authority.\n   $ Orange Book\n      (D) ISDs SHOULD NOT use this term as a synonym\
    \ for \"Trusted\n      Computer System Evaluation Criteria\" [CSC001, DOD1]. Instead,\
    \ use\n      the full, proper name of the document or, in subsequent\n      references,\
    \ the abbreviation \"TCSEC\". (See: (usage note under)\n      Green Book.)\n \
    \  $ organizational certificate\n      (O) MISSI usage: A type of MISSI X.509\
    \ public-key certificate that\n      is issued to support organizational message\
    \ handling for the U.S.\n      Government's Defense Message System.\n   $ organizational\
    \ registration authority (ORA)\n      (I) General usage: An RA for an organization.\n\
    \      (O) MISSI usage: The MISSI implementation of RA. A MISSI end\n      entity\
    \ that (a) assists a PCA, CA, or SCA to register other end\n      entities, by\
    \ gathering, verifying, and entering data and\n      forwarding it to the signing\
    \ authority and (b) may also assist\n      with card management functions. An\
    \ ORA is a local administrative\n      authority, and the term refers both to\
    \ the office or role, and to\n      the person who fills that office. An ORA does\
    \ not sign\n      certificates, CRLs, or CKLs. (See: no-PIN ORA, SSO-PIN ORA,\
    \ user-\n      PIN ORA.)\n   $ origin authentication\n   $ origin authenticity\n\
    \      (D) ISDs SHOULD NOT use these terms because they look like\n      careless\
    \ use of an internationally standardized term. Instead, use\n      \"data origin\
    \ authentication\" or \"peer entity authentication\",\n      depending which is\
    \ meant.\n   $ OSI\n   $ OSIRM\n      See: Open Systems Interconnection Reference\
    \ Model.\n   $ OTP\n      See: One-Time Password.\n   $ out of band\n      (I)\
    \ Transfer of information using a channel that is outside (i.e.,\n      separate\
    \ from) the channel that is normally used. (See: covert\n      channel.)\n   \
    \   (C) Out-of-band mechanisms are often used to distribute shared\n      secrets\
    \ (e.g., a symmetric key) or other sensitive information\n      items (e.g., a\
    \ root key) that are needed to initialize or\n      otherwise enable the operation\
    \ of cryptography or other security\n      mechanisms. (See: key distribution.)\n\
    \   $ output feedback (OFB)\n      (N) A block cipher mode [FP081] that modifies\
    \ electronic codebook\n      mode to operate on plaintext segments of variable\
    \ length less than\n      or equal to the block length.\n      (C) This mode operates\
    \ by directly using the algorithm's\n      previously generated output block as\
    \ the algorithm's next input\n      block (i.e., by \"feeding back\" the output\
    \ block) and combining\n      (exclusive OR-ing) the output block with the next\
    \ plaintext\n      segment (of block length or less) to form the next ciphertext\n\
    \      segment.\n   $ outside attack\n   $ outsider attack\n      See: (secondary\
    \ definition under) attack.\n   $ P1363\n      See: IEEE P1363.\n   $ PAA\n  \
    \    See: policy approving authority.\n   $ packet filter\n      See: (secondary\
    \ definition under) filtering router.\n   $ pagejacking\n      (I) A contraction\
    \ of \"Web page hijacking\". A masquerade attack in\n      which the attacker\
    \ copies (steals) a home page or other material\n      from the target server,\
    \ rehosts the page on a server the attacker\n      controls, and causes the rehosted\
    \ page to be indexed by the major\n      Web search services, thereby diverting\
    \ browsers from the target\n      server to the attacker's server.\n      (D)\
    \ ISDs SHOULD NOT use this term without including a definition,\n      because\
    \ the term is not listed in most dictionaries and could\n      confuse international\
    \ readers. (See: (usage note under) Green\n      Book.)\n   $ PAN\n      See:\
    \ primary account number.\n   $ PAP\n      See: Password Authentication Protocol.\n\
    \   $ partitioned security mode\n      (N) A mode of operation of an information\
    \ system, wherein all\n      users have the clearance, but not necessarily formal\
    \ access\n      authorization and need-to-know, for all information handled by\
    \ the\n      system. This mode is defined in U.S. Department of Defense policy\n\
    \      regarding system accreditation. [DoD2]\n   $ passive attack\n      See:\
    \ (secondary definition under) attack.\n   $ passive wiretapping\n      See: (secondary\
    \ definition under) wiretapping.\n   $ password\n      (I) A secret data value,\
    \ usually a character string, that is used\n      as authentication information.\
    \ (See: challenge-response.)\n      (C) A password is usually matched with a user\
    \ identifier that is\n      explicitly presented in the authentication process,\
    \ but in some\n      cases the identity may be implicit.\n      (C) Using a password\
    \ as authentication information assumes that\n      the password is known only\
    \ by the system entity whose identity is\n      being authenticated. Therefore,\
    \ in a network environment where\n      wiretapping is possible, simple authentication\
    \ that relies on\n      transmission of static (i.e., repetitively used) passwords\
    \ as\n      cleartext is inadequate. (See: one-time password, strong\n      authentication.)\n\
    \   $ Password Authentication Protocol (PAP)\n      (I) A simple authentication\
    \ mechanism in PPP. In PAP, a user\n      identifier and password are transmitted\
    \ in cleartext. [R1334]\n      (See: CHAP.)\n   $ password sniffing\n      (I)\
    \ Passive wiretapping, usually on a local area network, to gain\n      knowledge\
    \ of passwords. (See: (usage note under) sniffing.)\n   $ path discovery\n   \
    \   (I) For a digital certificate, the process of finding a set of\n      public-key\
    \ certificates that comprise a certification path from a\n      trusted key to\
    \ that specific certificate.\n   $ path validation\n      (I) The process of validating\
    \ (a) all of the digital certificates\n      in a certification path and (b) the\
    \ required relationships between\n      those certificates, thus validating the\
    \ contents of the last\n      certificate on the path. (See: certificate validation.)\n\
    \   $ payment card\n      (N) SET usage: Collectively refers \"to credit cards,\
    \ debit cards,\n      charge cards, and bank cards issued by a financial institution\
    \ and\n      which reflects a relationship between the cardholder and the\n  \
    \    financial institution.\" [SET2]\n   $ payment gateway\n      (O) SET usage:\
    \ A system operated by an acquirer, or a third party\n      designated by an acquirer,\
    \ for the purpose of providing electronic\n      commerce services to the merchants\
    \ in support of the acquirer, and\n      which interfaces to the acquirer to support\
    \ the authorization,\n      capture, and processing of merchant payment messages,\
    \ including\n      payment instructions from cardholders. [SET1, SET2]\n   $ payment\
    \ gateway certification authority (SET PCA)\n      (O) SET usage: A CA that issues\
    \ digital certificates to payment\n      gateways and is operated on behalf of\
    \ a payment card brand, an\n      acquirer, or another party according to brand\
    \ rules. A SET PCA\n      issues a CRL for compromised payment gateway certificates.\
    \ [SET2]\n      (See: PCA.)\n   $ PC card\n      (N) A type of credit card-sized,\
    \ plug-in peripheral device that\n      was originally developed to provide memory\
    \ expansion for portable\n      computers, but is also used for other kinds of\
    \ functional\n      expansion. (See: FORTEZZA, PCMCIA.)\n      (C) The international\
    \ PC Card Standard defines a non-proprietary\n      form factor in three standard\
    \ sizes--Types I, II and III--each of\n      which have a 68-pin interface between\
    \ the card and the socket into\n      which it plugs.  All three types have the\
    \ same length and width,\n      roughly the size of a credit card, but differ\
    \ in their thickness\n      from 3.3 to 10.5 mm. Examples include storage modules,\
    \ modems,\n      device interface adapters, and cryptographic modules.\n   $ PCA\n\
    \      (D) ISDs SHOULD NOT use this acronym without a qualifying\n      adjective\
    \ because that would be ambiguous. (See: Internet policy\n      certification\
    \ authority, (MISSI) policy creation authority, (SET)\n      payment gateway certification\
    \ authority.)\n   $ PCMCIA\n      (N) Personal Computer Memory Card International\
    \ Association, a\n      group of manufacturers, developers, and vendors, founded\
    \ in 1989\n      to standardize plug-in peripheral memory cards for personal\n\
    \      computers and now extended to deal with any technology that works\n   \
    \   in the PC card form factor. (See: PC card.)\n   $ peer entity authentication\n\
    \      (I) \"The corroboration that a peer entity in an association is the\n \
    \     one claimed.\" [I7498 Part 2] (See: authentication.)\n   $ peer entity authentication\
    \ service\n      (I) A security service that verifies an identity claimed by or\
    \ for\n      a system entity in an association. (See: authentication,\n      authentication\
    \ service.)\n      (C) This service is used at the establishment of, or at times\n\
    \      during, an association to confirm the identity of one entity to\n     \
    \ another, thus protecting against a masquerade by the first entity.\n      However,\
    \ unlike data origin authentication service, this service\n      requires an association\
    \ to exist between the two entities, and the\n      corroboration provided by\
    \ the service is valid only at the current\n      time that the service is provided.\n\
    \      (C) See: \"relationship between data integrity service and\n      authentication\
    \ services\" under data integrity service.\n   $ PEM\n      See: Privacy Enhanced\
    \ Mail.\n   $ penetration\n      (I) Successful, repeatable, unauthorized access\
    \ to a protected\n      system resource. (See: attack, violation.)\n   $ penetration\
    \ test\n      (I) A system test, often part of system certification, in which\n\
    \      evaluators attempt to circumvent the security features of the\n      system.\
    \ [NCS04]\n      (C) Penetration testing may be performed under various constraints\n\
    \      and conditions. However, for a TCSEC evaluation, testers are\n      assumed\
    \ to have all system design and implementation\n      documentation, including\
    \ source code, manuals, and circuit\n      diagrams, and to work under no greater\
    \ constraints than those\n      applied to ordinary users.\n   $ perfect forward\
    \ secrecy\n      See: (discussion under) public-key forward secrecy.\n   $ perimeter\n\
    \      See: security perimeter.\n   $ periods processing\n      (I) A mode of\
    \ system operation in which information of different\n      sensitivities is processed\
    \ at distinctly different times by the\n      same system, with the system being\
    \ properly purged or sanitized\n      between periods. (See: color change.)\n\
    \   $ permission\n      (I) A synonym for \"authorization\", but \"authorization\"\
    \ is\n      preferred in the PKI context. (See: privilege.)\n   $ personal identification\
    \ number (PIN)\n      (I) A character string used as a password to gain access\
    \ to a\n      system resource. (See: authentication information.)\n      (C) Despite\
    \ the words \"identification\" and \"number\", a PIN seldom\n      serves as a\
    \ user identifier, and a PIN's characters are not\n      necessarily all numeric.\
    \ A better name for this concept would have\n      been \"personal authentication\
    \ system string (PASS)\".\n      (C) Retail banking applications commonly use\
    \ 4-digit PINs.\n      FORTEZZA PC card's use up to 12 characters for user or\
    \ SSO PINs.\n   $ personality\n   $ personality label\n      (O) MISSI usage:\
    \ A set of MISSI X.509 public-key certificates that\n      have the same subject\
    \ DN, together with their associated private\n      keys and usage specifications,\
    \ that is stored on a FORTEZZA PC\n      card to support a role played by the\
    \ card's user.\n      (C) When a card's user selects a personality to use in a\
    \ FORTEZZA-\n      aware application, the data determines behavior traits (the\n\
    \      personality) of the application. A card's user may have multiple\n    \
    \  personalities on the card. Each has a \"personality label\", a user-\n    \
    \  friendly character string that applications can display to the\n      user\
    \ for selecting or changing the personality to be used. For\n      example, a\
    \ military user's card might contain three personalities:\n      GENERAL HALFTRACK,\
    \ COMMANDER FORT SWAMPY, and NEW YEAR'S EVE PARTY\n      CHAIRMAN. Each personality\
    \ includes one or more certificates of\n      different types (such as DSA versus\
    \ RSA), for different purposes\n      (such as digital signature versus encryption),\
    \ or with different\n      authorizations.\n   $ personnel security\n      (I)\
    \ Procedures to ensure that persons who access a system have\n      proper clearance,\
    \ authorization, and need-to-know as required by\n      the system's security\
    \ policy.\n   $ PGP(trademark)\n      See: Pretty Good Privacy.\n   $ Photuris\n\
    \      (I) A UDP-based, key establishment protocol for session keys,\n      designed\
    \ for use with the IPsec protocols AH and ESP. Superseded\n      by IKE.\n   $\
    \ phreaking\n      (I) A contraction of \"telephone breaking\". An attack on or\n\
    \      penetration of a telephone system or, by extension, any other\n      communication\
    \ or information system. [Raym]\n      (D) ISDs SHOULD NOT use this term because\
    \ it is not listed in most\n      dictionaries and could confuse international\
    \ readers.\n   $ physical security\n      (I) Tangible means of preventing unauthorized\
    \ physical access to a\n      system. E.g., fences, walls, and other barriers;\
    \ locks, safes, and\n      vaults; dogs and armed guards; sensors and alarm bells.\
    \ [FP031,\n      R1455]\n   $ piggyback attack\n      (I) A form of active wiretapping\
    \ in which the attacker gains\n      access to a system via intervals of inactivity\
    \ in another user's\n      legitimate communication connection. Sometimes called\
    \ a \"between-\n      the-lines\" attack. (See: hijack attack, man-in-the-middle\
    \ attack.)\n   $ PIN\n      See: personal identification number.\n   $ ping of\
    \ death\n      (I) An attack that sends an improperly large ICMP [R0792] echo\n\
    \      request packet (a \"ping\") with the intent of overflowing the input\n\
    \      buffers of the destination machine and causing it to crash.\n   $ ping\
    \ sweep\n      (I) An attack that sends ICMP [R0792] echo requests (\"pings\"\
    ) to a\n      range of IP addresses, with the goal of finding hosts that can be\n\
    \      probed for vulnerabilities.\n   $ PKCS\n      See: Public-Key Cryptography\
    \ Standards.\n   $ PKCS #7\n      (N) A standard [PKC07, R2315] from the PKCS\
    \ series; defines a\n      syntax for data that may have cryptography applied\
    \ to it, such as\n      for digital signatures and digital envelopes.\n   $ PKCS\
    \ #10\n      (N) A standard [PKC10] from the PKCS series; defines a syntax for\n\
    \      requests for public-key certificates. (See: certification\n      request.)\n\
    \      (C) A PKCS #10 request contains a DN and a public key, and may\n      contain\
    \ other attributes, and is signed by the entity making the\n      request. The\
    \ request is sent to a CA, who converts it to an X.509\n      public-key certificate\
    \ (or some other form) and returns it,\n      possibly in PKCS #7 format.\n  \
    \ $ PKCS #11\n      (N) A standard [PKC11] from the PKCS series; defines a software\n\
    \      CAPI called Cryptoki (pronounced \"crypto-key\"; short for\n      \"cryptographic\
    \ token interface\") for devices that hold\n      cryptographic information and\
    \ perform cryptographic functions.\n   $ PKI\n      See: public-key infrastructure.\n\
    \   $ PKIX\n      (I) (1.) A contraction of \"Public-Key Infrastructure (X.509)\"\
    , the\n      name of the IETF working group that is specifying an architecture\n\
    \      and set of protocols needed to support an X.509-based PKI for the\n   \
    \   Internet. (2.) A collective name for that architecture and set of\n      protocols.\n\
    \      (C) The goal of PKIX is to facilitate the use of X.509 public-key\n   \
    \   certificates in multiple Internet applications and to promote\n      interoperability\
    \ between different implementations that use those\n      certificates. The resulting\
    \ PKI is intended to provide a framework\n      that supports a range of trust\
    \ and hierarchy environments and a\n      range of usage environments. PKIX specifies\
    \ (a) profiles of the v3\n      X.509 public-key certificate standards and the\
    \ v2 X.509 CRL\n      standards for the Internet; (b) operational protocols used\
    \ by\n      relying parties to obtain information such as certificates or\n  \
    \    certificate status; (c) management protocols used by system\n      entities\
    \ to exchange information needed for proper management of\n      the PKI; and\
    \ (d) information about certificate policies and CPSs,\n      covering the areas\
    \ of PKI security not directly addressed in the\n      rest of PKIX.\n   $ PKIX\
    \ private extension\n      (I) PKIX defines a private extension to identify an\
    \ on-line\n      verification service supporting the issuing CA.\n   $ plaintext\n\
    \      (I) Data that is input to and transformed by an encryption\n      process,\
    \ or that is output by a decryption process.\n      (C) Usually, the plaintext\
    \ input to an encryption operation is\n      cleartext. But in some cases, the\
    \ input is ciphertext that was\n      output from another encryption operation.\
    \ (See: superencryption.)\n   $ Point-to-Point Protocol (PPP)\n      (I) An Internet\
    \ Standard protocol [R1661] for encapsulation and\n      full-duplex transportation\
    \ of network layer (mainly OSI layer 3)\n      protocol data packets over a link\
    \ between two peers, and for\n      multiplexing different network layer protocols\
    \ over the same link.\n      Includes optional negotiation to select and use a\
    \ peer entity\n      authentication protocol to authenticate the peers to each\
    \ other\n      before they exchange network layer data. (See: CHAP, EAP, PAP.)\n\
    \   $ Point-to-Point Tunneling Protocol (PPTP)\n      (I) An Internet client-server\
    \ protocol (originally developed by\n      Ascend and Microsoft) that enables\
    \ a dial-up user to create a\n      virtual extension of the dial-up link across\
    \ a network by\n      tunneling PPP over IP. (See: L2TP.)\n      (C) PPP can encapsulate\
    \ any Internet Protocol Suite network layer\n      protocol (or OSI layer 3 protocol).\
    \ Therefore, PPTP does not\n      specify security services; it depends on protocols\
    \ above and below\n      it to provide any needed security. PPTP makes it possible\
    \ to\n      divorce the location of the initial dial-up server (i.e., the PPTP\n\
    \      Access Concentrator, the client, which runs on a special-purpose\n    \
    \  host) from the location at which the dial-up protocol (PPP)\n      connection\
    \ is terminated and access to the network is provided\n      (i.e., the PPTP Network\
    \ Server, which runs on a general-purpose\n      host).\n   $ policy\n      (D)\
    \ ISDs SHOULD NOT use this word as an abbreviation for either\n      \"security\
    \ policy\" or \"certificate policy\". Instead, to avoid\n      misunderstanding,\
    \ use the fully qualified term, at least at the\n      point of first usage.\n\
    \   $ policy approving authority (PAA)\n      (O) MISSI usage: The top-level signing\
    \ authority of a MISSI\n      certification hierarchy. The term refers both to\
    \ that\n      authoritative office or role and to the person who plays that\n\
    \      role. (See: root registry.)\n      (C) A PAA registers MISSI PCAs and signs\
    \ their X.509 public-key\n      certificates. A PAA issues CRLs but does not issue\
    \ a CKL. A PAA\n      may issue cross-certificates to other PAAs.\n   $ policy\
    \ certification authority (Internet PCA)\n      (I) An X.509-compliant CA at the\
    \ second level of the Internet\n      certification hierarchy, under the Internet\
    \ Policy Registration\n      Authority (IPRA). Each PCA operates in accordance\
    \ with its\n      published security policy (see: certification practice statement)\n\
    \      and within constraints established by the IPRA for all PCAs.\n      [R1422].\
    \ (See: policy creation authority.)\n   $ policy creation authority (MISSI PCA)\n\
    \      (O) MISSI usage: The second level of a MISSI certification\n      hierarchy;\
    \ the administrative root of a security policy domain of\n      MISSI users and\
    \ other, subsidiary authorities. The term refers\n      both to that authoritative\
    \ office or role and to the person who\n      fills that office. (See: policy\
    \ certification authority.)\n      (C) A MISSI PCA's certificate is issued by\
    \ a policy approving\n      authority. The PCA registers the CAs in its domain,\
    \ defines their\n      configurations, and issues their X.509 public-key certificates.\n\
    \      (The PCA may also issue certificates for SCAs, ORAs, and other end\n  \
    \    entities, but a PCA does not usually do this.) The PCA\n      periodically\
    \ issues CRLs and CKLs for its domain.\n   $ Policy Management Authority\n   \
    \   (N) Canadian usage: An organization responsible for PKI oversight\n      and\
    \ policy management in the Government of Canada.\n   $ policy mapping\n      (I)\
    \ \"Recognizing that, when a CA in one domain certifies a CA in\n      another\
    \ domain, a particular certificate policy in the second\n      domain may be considered\
    \ by the authority of the first domain to\n      be equivalent (but not necessarily\
    \ identical in all respects) to a\n      particular certificate policy in the\
    \ first domain.\" [X509]\n   $ POP3\n      See: Post Office Protocol, version\
    \ 3.\n   $ POP3 APOP\n      (I) A POP3 \"command\" (better described as a transaction\
    \ type, or a\n      protocol-within-a-protocol) by which a POP3 client optionally\
    \ uses\n      a keyed hash (based on MD5) to authenticate itself to a POP3\n \
    \     server and, depending on the server implementation, to protect\n      against\
    \ replay attacks. (See: CRAM, POP3 AUTH, IMAP4\n      AUTHENTICATE.)\n      (C)\
    \ The server includes a unique timestamp in its greeting to the\n      client.\
    \ The subsequent APOP command sent by the client to the\n      server contains\
    \ the client's name and the hash result of applying\n      MD5 to a string formed\
    \ from both the timestamp and a shared secret\n      that is known only to the\
    \ client and the server. APOP was designed\n      to provide as an alternative\
    \ to using POP3's USER and PASS (i.e.,\n      password) command pair, in which\
    \ the client sends a cleartext\n      password to the server.\n   $ POP3 AUTH\n\
    \      (I) A \"command\" [R1734] (better described as a transaction type,\n  \
    \    or a protocol-within-a-protocol) in POP3, by which a POP3 client\n      optionally\
    \ proposes a mechanism to a POP3 server to authenticate\n      the client to the\
    \ server and provide other security services.\n      (See: POP3 APOP, IMAP4 AUTHENTICATE.)\n\
    \      (C) If the server accepts the proposal, the command is followed by\n  \
    \    performing a challenge-response authentication protocol and,\n      optionally,\
    \ negotiating a protection mechanism for subsequent POP3\n      interactions.\
    \ The security mechanisms used by POP3 AUTH are those\n      used by IMAP4.\n\
    \   $ port scan\n      (I) An attack that sends client requests to a range of\
    \ server port\n      addresses on a host, with the goal of finding an active port\
    \ and\n      exploiting a known vulnerability of that service.\n   $ POSIX\n \
    \     (N) Portable Operating System Interface for Computer Environments,\n   \
    \   a standard [FP151, IS9945-1] (originally IEEE Standard P1003.1)\n      that\
    \ defines an operating system interface and environment to\n      support application\
    \ portability at the source code level. It is\n      intended to be used by both\
    \ application developers and system\n      implementers.\n      (C) P1003.1 supports\
    \ security functionality like those on most\n      UNIX systems, including discretionary\
    \ access control and\n      privilege. IEEE Draft Standard P1003.6.1 specifies\
    \ additional\n      functionality not provided in the base standard, including\
    \ (a)\n      discretionary access control, (b) audit trail mechanisms, (c)\n \
    \     privilege mechanisms, (d) mandatory access control, and (e)\n      information\
    \ label mechanisms.\n   $ Post Office Protocol, version 3 (POP3)\n      (I) An\
    \ Internet Standard protocol [R1939] by which a client\n      workstation can\
    \ dynamically access a mailbox on a server host to\n      retrieve mail messages\
    \ that the server has received and is holding\n      for the client. (See: IMAP4.)\n\
    \      (C) POP3 has mechanisms for optionally authenticating a client to\n   \
    \   a server and providing other security services. (See: POP3 APOP,\n      POP3\
    \ AUTH.)\n   $ PPP\n      See: Point-to-Point Protocol.\n   $ PPTP\n      See:\
    \ Point-to-Point Tunneling Protocol.\n   $ pre-authorization\n      (I) A capability\
    \ of a CAW that enables certification requests to\n      be automatically validated\
    \ against data provided in advance to the\n      CA by an authorizing entity.\n\
    \   $ Pretty Good Privacy(trademark) (PGP(trademark))\n      (O) Trademarks of\
    \ Network Associates, Inc., referring to a\n      computer program (and related\
    \ protocols) that uses cryptography to\n      provide data security for electronic\
    \ mail and other applications\n      on the Internet. (See: MOSS, PEM, S/MIME.)\n\
    \      (C) PGP encrypts messages with IDEA in CFB mode, distributes the\n    \
    \  IDEA keys by encrypting them with RSA, and creates digital\n      signatures\
    \ on messages with MD5 and RSA. To establish ownership of\n      public keys,\
    \ PGP depends on the web of trust. (See: Privacy\n      Enhanced Mail.)\n   $\
    \ primary account number (PAN)\n      (O) SET usage: \"The assigned number that\
    \ identifies the card\n      issuer and cardholder. This account number is composed\
    \ of an\n      issuer identification number, an individual account number\n  \
    \    identification, and an accompanying check digit as defined by ISO\n     \
    \ 7812-1985.\" [SET2, IS7812] (See: bank identification number.)\n      (C) The\
    \ PAN is embossed, encoded, or both on a magnetic-strip-\n      based credit card.\
    \ The PAN identifies the issuer to which a\n      transaction is to be routed\
    \ and the account to which it is to be\n      applied unless specific instructions\
    \ indicate otherwise. The\n      authority that assigns the bank identification\
    \ number part of the\n      PAN is the American Bankers Association.\n   $ privacy\n\
    \      (I) The right of an entity (normally a person), acting in its own\n   \
    \   behalf, to determine the degree to which it will interact with its\n     \
    \ environment, including the degree to which the entity is willing\n      to share\
    \ information about itself with others. (See: anonymity.)\n      (O) \"The right\
    \ of individuals to control or influence what\n      information related to them\
    \ may be collected and stored and by\n      whom and to whom that information\
    \ may be disclosed.\" [I7498 Part\n      2]\n      (D) ISDs SHOULD NOT use this\
    \ term as a synonym for \"data\n      confidentiality\" or \"data confidentiality\
    \ service\", which are\n      different concepts. Privacy is a reason for security\
    \ rather than a\n      kind of security. For example, a system that stores personal\
    \ data\n      needs to protect the data to prevent harm, embarrassment,\n    \
    \  inconvenience, or unfairness to any person about whom data is\n      maintained,\
    \ and to protect the person's privacy. For that reason,\n      the system may\
    \ need to provide data confidentiality service.\n   $ Privacy Enhanced Mail (PEM)\n\
    \      (I) An Internet protocol to provide data confidentiality, data\n      integrity,\
    \ and data origin authentication for electronic mail.\n      [R1421, R1422]. (See:\
    \ MOSS, MSP, PGP, S/MIME.)\n      (C) PEM encrypts messages with DES in CBC mode,\
    \ provides key\n      distribution of DES keys by encrypting them with RSA, and\
    \ signs\n      messages with RSA over either MD2 or MD5. To establish ownership\n\
    \      of public keys, PEM uses a certification hierarchy, with X.509\n      public-key\
    \ certificates and X.509 CRLs that are signed with RSA\n      and MD2. (See: Pretty\
    \ Good Privacy.)\n      (C) PEM is designed to be compatible with a wide range\
    \ of key\n      management methods, but is limited to specifying security services\n\
    \      only for text messages and, like MOSS, has not been widely\n      implemented\
    \ in the Internet.\n   $ private component\n      (I) A synonym for \"private\
    \ key\".\n      (D) In most cases, ISDs SHOULD NOT use this term; to avoid\n \
    \     confusing readers, use \"private key\" instead. However, the term\n    \
    \  MAY be used when specifically discussing a key pair; e.g., \"A key\n      pair\
    \ has a public component and a private component.\"\n   $ private extension\n\
    \      See: (secondary definition under) extension.\n   $ private key\n      (I)\
    \ The secret component of a pair of cryptographic keys used for\n      asymmetric\
    \ cryptography. (See: key pair, public key.)\n      (O) \"(In a public key cryptosystem)\
    \ that key of a user's key pair\n      which is known only by that user.\" [X509]\n\
    \   $ privilege\n      (I) An authorization or set of authorizations to perform\
    \ security-\n      relevant functions, especially in the context of a computer\n\
    \      operating system.\n   $ privilege management infrastructure\n      (N)\
    \ \"The complete set of processes required to provide an\n      authorization\
    \ service\", i.e., processes concerned with attribute\n      certificates. [FPDAM]\
    \ (See: PKI.)\n      (D) ISDs SHOULD NOT use this term and its definition because\
    \ the\n      definition is vague, and there is no consensus on an alternate\n\
    \      definition.\n   $ privileged process\n      (I) An computer process that\
    \ is authorized (and, therefore,\n      trusted) to perform some security-relevant\
    \ functions that ordinary\n      processes are not. (See: privilege, trusted process.)\n\
    \   $ procedural security\n      (D) ISDs SHOULD NOT use this term as a synonym\
    \ for \"administrative\n      security\". Any type of security may involve procedures;\
    \ therefore,\n      the term may be misleading. Instead, use \"administrative\n\
    \      security\", \"communication security\", \"computer security\",\n      \"\
    emanations security\", \"personnel security\", \"physical security\",\n      or\
    \ whatever specific type is meant. (See: security architecture.)\n   $ proprietary\n\
    \      (I) Refers to information (or other property) that is owned by an\n   \
    \   individual or organization and for which the use is restricted by\n      that\
    \ entity.\n   $ protected checksum\n      (I) A checksum that is computed for\
    \ a data object by means that\n      protect against active attacks that would\
    \ attempt to change the\n      checksum to make it match changes made to the data\
    \ object. (See:\n      digital signature, keyed hash, (discussion under) checksum.\n\
    \   $ protected distribution system\n      (I) A wireline or fiber-optic system\
    \ that includes sufficient\n      safeguards (acoustic, electric, electromagnetic,\
    \ and physical) to\n      permit its use for unencrypted transmission of (cleartext)\
    \ data.\n   $ protection authority\n      See: (secondary definition under) Internet\
    \ Protocol Security\n      Option.\n   $ protection ring\n      (I) One of a hierarchy\
    \ of privileged operation modes of a system\n      that gives certain access rights\
    \ to processes authorized to\n      operate in that mode.\n   $ protocol\n   \
    \   (I) A set of rules (i.e., formats and procedures) to implement and\n     \
    \ control some type of association (e.g., communication) between\n      systems.\
    \ (E.g., see: Internet Protocol.)\n      (C) In particular, a series of ordered\
    \ steps involving computing\n      and communication that are performed by two\
    \ or more system\n      entities to achieve a joint objective. [A9042]\n   $ protocol\
    \ suite\n      (I) A complementary collection of communication protocols used\
    \ in\n      a computer network. (See: Internet, OSI.)\n   $ proxy server\n   \
    \   (I) A computer process--often used as, or as part of, a firewall--\n     \
    \ that relays a protocol between client and server computer systems,\n      by\
    \ appearing to the client to be the server and appearing to the\n      server\
    \ to be the client. (See: SOCKS.)\n      (C) In a firewall, a proxy server usually\
    \ runs on a bastion host,\n      which may support proxies for several protocols\
    \ (e.g., FTP, HTTP,\n      and TELNET). Instead of a client in the protected enclave\n\
    \      connecting directly to an external server, the internal client\n      connects\
    \ to the proxy server which in turn connects to the\n      external server. The\
    \ proxy server waits for a request from inside\n      the firewall, forwards the\
    \ request to the remote server outside\n      the firewall, gets the response,\
    \ then sends the response back to\n      the client. The proxy may be transparent\
    \ to the clients, or they\n      may need to connect first to the proxy server,\
    \ and then use that\n      association to also initiate a connection to the real\
    \ server.\n      (C) Proxies are generally preferred over SOCKS for their ability\n\
    \      to perform caching, high-level logging, and access control. A\n      proxy\
    \ can provide security service beyond that which is normally\n      part of the\
    \ relayed protocol, such as access control based on peer\n      entity authentication\
    \ of clients, or peer entity authentication of\n      servers when clients do\
    \ not have that capability. A proxy at OSI\n      layer 7 can also provide finer-grained\
    \ security service than can a\n      filtering router at OSI layer 3. For example,\
    \ an FTP proxy could\n      permit transfers out of, but not into, a protected\
    \ network.\n   $ pseudo-random\n      (I) A sequence of values that appears to\
    \ be random (i.e.,\n      unpredictable) but is actually generated by a deterministic\n\
    \      algorithm. (See: random.)\n   $ pseudo-random number generator\n      (I)\
    \ A process used to deterministically generate a series of\n      numbers (usually\
    \ integers) that appear to be random according to\n      certain statistical tests,\
    \ but actually are pseudo-random.\n      (C) Pseudo-random number generators are\
    \ usually implemented in\n      software.\n   $ public component\n      (I) A\
    \ synonym for \"public key\".\n      (D) In most cases, ISDs SHOULD NOT use this\
    \ term; to avoid\n      confusing readers, use \"private key\" instead. However,\
    \ the term\n      MAY be used when specifically discussing a key pair; e.g., \"\
    A key\n      pair has a public component and a private component.\"\n   $ public\
    \ key\n      (I) The publicly-disclosable component of a pair of cryptographic\n\
    \      keys used for asymmetric cryptography. (See: key pair, private\n      key.)\n\
    \      (O) \"(In a public key cryptosystem) that key of a user's key pair\n  \
    \    which is publicly known.\" [X509]\n   $ public-key certificate\n      (I)\
    \ A digital certificate that binds a system entity's identity to\n      a public\
    \ key value, and possibly to additional data items; a\n      digitally-signed\
    \ data structure that attests to the ownership of a\n      public key. (See: X.509\
    \ public-key certificate.)\n      (C) The digital signature on a public-key certificate\
    \ is\n      unforgeable. Thus, the certificate can be published, such as by\n\
    \      posting it in a directory, without the directory having to protect\n  \
    \    the certificate's data integrity.\n      (O) \"The public key of a user,\
    \ together with some other\n      information, rendered unforgeable by encipherment\
    \ with the private\n      key of the certification authority which issued it.\"\
    \ [X509]\n   $ public-key cryptography\n      (I) The popular synonym for \"asymmetric\
    \ cryptography\".\n   $ Public-Key Cryptography Standards (PKCS)\n      (I) A\
    \ series of specifications published by RSA Laboratories for\n      data structures\
    \ and algorithm usage for basic applications of\n      asymmetric cryptography.\
    \ (See: PKCS #7, PKCS #10, PKCS #11.)\n      (C) The PKCS were begun in 1991 in\
    \ cooperation with industry and\n      academia, originally including Apple, Digital,\
    \ Lotus, Microsoft,\n      Northern Telecom, Sun, and MIT. Today, the specifications\
    \ are\n      widely used, but they are not sanctioned by an official standards\n\
    \      organization, such as ANSI, ITU-T, or IETF. RSA Laboratories\n      retains\
    \ sole decision-making authority over the PKCS.\n   $ public-key forward secrecy\
    \ (PFS)\n      (I) For a key agreement protocol based on asymmetric cryptography,\n\
    \      the property that ensures that a session key derived from a set of\n  \
    \    long-term public and private keys will not be compromised if one\n      of\
    \ the private keys is compromised in the future.\n      (C) Some existing RFCs\
    \ use the term \"perfect forward secrecy\" but\n      either do not define it\
    \ or do not define it precisely. While\n      preparing this Glossary, we tried\
    \ to find a good definition for\n      that term, but found this to be a muddled\
    \ area. Experts did not\n      agree. For all practical purposes, the literature\
    \ defines \"perfect\n      forward secrecy\" by stating the Diffie-Hellman algorithm.\
    \ The term\n      \"public-key forward secrecy\" (suggested by Hilarie Orman)\
    \ and the\n      \"I\" definition stated for it here were crafted to be compatible\n\
    \      with current Internet documents, yet be narrow and leave room for\n   \
    \   improved terminology.\n      (C) Challenge to the Internet security community:\
    \ We need a\n      taxonomy--a family of mutually exclusive and collectively\n\
    \      exhaustive terms and definitions to cover the basic properties\n      discussed\
    \ here--for the full range of cryptographic algorithms and\n      protocols used\
    \ in Internet Standards:\n      (C) Involvement of session keys vs. long-term\
    \ keys: Experts\n      disagree about the basic ideas involved.\n       - One\
    \ concept of \"forward secrecy\" is that, given observations of\n      the operation\
    \ of a key establishment protocol up to time t, and\n      given some of the session\
    \ keys derived from those protocol runs,\n      you cannot derive unknown past\
    \ session keys or future session\n      keys.\n       - A related property is\
    \ that, given observations of the protocol\n      and knowledge of the derived\
    \ session keys, you cannot derive one\n      or more of the long-term private\
    \ keys.\n       - The \"I\" definition presented above involves a third concept\
    \ of\n      \"forward secrecy\" that refers to the effect of the compromise of\n\
    \      long-term keys.\n       - All three concepts involve the idea that a compromise\
    \ of \"this\"\n      encryption key is not supposed to compromise the \"next\"\
    \ one. There\n      also is the idea that compromise of a single key will compromise\n\
    \      only the data protected by the single key. In Internet literature,\n  \
    \    the focus has been on protection against decryption of back\n      traffic\
    \ in the event of a compromise of secret key material held\n      by one or both\
    \ parties to a communication.\n      (C) Forward vs. backward: Experts are unhappy\
    \ with the word\n      \"forward\", because compromise of \"this\" encryption\
    \ key also is not\n      supposed to compromise the \"previous\" one, which is\
    \ \"backward\"\n      rather than forward. In S/KEY, if the key used at time t\
    \ is\n      compromised, then all keys used prior to that are compromised. If\n\
    \      the \"long-term\" key (i.e., the base of the hashing scheme) is\n     \
    \ compromised, then all keys past and future are compromised; thus,\n      you\
    \ could say that S/KEY has neither forward nor backward secrecy.\n      (C) Asymmetric\
    \ cryptography vs. symmetric: Experts disagree about\n      forward secrecy in\
    \ the context of symmetric cryptographic systems.\n      In the absence of asymmetric\
    \ cryptography, compromise of any long-\n      term key seems to compromise any\
    \ session key derived from the\n      long-term key. For example, Kerberos isn't\
    \ forward secret, because\n      compromising a client's password (thus compromising\
    \ the key shared\n      by the client and the authentication server) compromises\
    \ future\n      session keys shared by the client and the ticket-granting server.\n\
    \      (C) Ordinary forward secrecy vs. \"perfect\" forward secret: Experts\n\
    \      disagree about the difference between these two. Some say there is\n  \
    \    no difference, and some say that the initial naming was\n      unfortunate\
    \ and suggest dropping the word \"perfect\". Some suggest\n      using \"forward\
    \ secrecy\" for the case where one long-term private\n      key is compromised,\
    \ and adding \"perfect\" for when both private\n      keys (or, when the protocol\
    \ is multi-party, all private keys) are\n      compromised.\n      (C) Acknowledgements:\
    \ Bill Burr, Burt Kaliski, Steve Kent, Paul\n      Van Oorschot, Michael Wiener,\
    \ and, especially, Hilarie Orman\n      contributed ideas to this discussion.\n\
    \   $ public-key infrastructure (PKI)\n      (I) A system of CAs (and, optionally,\
    \ RAs and other supporting\n      servers and agents) that perform some set of\
    \ certificate\n      management, archive management, key management, and token\n\
    \      management functions for a community of users in an application of\n  \
    \    asymmetric cryptography. (See: hierarchical PKI, mesh PKI,\n      security\
    \ management infrastructure, trust-file PKI.)\n      (O) PKIX usage: The set of\
    \ hardware, software, people, policies,\n      and procedures needed to create,\
    \ manage, store, distribute, and\n      revoke digital certificates based on asymmetric\
    \ cryptography.\n      (C) The core PKI functions are (a) to register users and\
    \ issue\n      their public-key certificates, (b) to revoke certificates when\n\
    \      required, and (c) to archive data needed to validate certificates\n   \
    \   at a much later time. Key pairs for data confidentiality may be\n      generated\
    \ (and perhaps escrowed) by CAs or RAs, but requiring a\n      PKI client to generate\
    \ its own digital signature key pair helps\n      maintain system integrity of\
    \ the cryptographic system, because\n      then only the client ever possesses\
    \ the private key it uses. Also,\n      an authority may be established to approve\
    \ or coordinate CPSs,\n      which are security policies under which components\
    \ of a PKI\n      operate.\n      (C) A number of other servers and agents may\
    \ support the core PKI,\n      and PKI clients may obtain services from them.\
    \ The full range of\n      such services is not yet fully understood and is evolving,\
    \ but\n      supporting roles may include archive agent, certified delivery\n\
    \      agent, confirmation agent, digital notary, directory, key escrow\n    \
    \  agent, key generation agent, naming agent who ensures that issuers\n      and\
    \ subjects have unique identifiers within the PKI, repository,\n      ticket-granting\
    \ agent, and time stamp agent.\n   $ RA\n      See: registration authority.\n\
    \   $ RA domains\n      (I) A capability of a CAW that allows a CA to divide the\n\
    \      responsibility for certification requests among multiple RAs.\n      (C)\
    \ This capability might be used to restrict access to private\n      authorization\
    \ data that is provided with a certification request,\n      and to distribute\
    \ the responsibility to review and approve\n      certification requests in high\
    \ volume environments. RA domains\n      might segregate certification requests\
    \ according to an attribute\n      of the certificate subject, such as an organizational\
    \ unit.\n   $ RADIUS\n      See: Remote Authentication Dial-In User Service.\n\
    \   $ Rainbow Series\n      (O) A set of more than 30 technical and policy documents\
    \ with\n      colored covers, issued by the NCSC, that discuss in detail the\n\
    \      TCSEC and provide guidance for meeting and applying the criteria.\n   \
    \   (See: Green Book, Orange Book, Red Book, Yellow Book.)\n   $ random\n    \
    \  (I) General usage: In mathematics, random means \"unpredictable\". A\n    \
    \  sequence of values is called random if each successive value is\n      obtained\
    \ merely by chance and does not depend on the preceding\n      values of the sequence,\
    \ and a selected individual value is called\n      random if each of the values\
    \ in the total population of\n      possibilities has equal probability of being\
    \ selected. [Knuth]\n      (See: cryptographic key, pseudo-random, random number\
    \ generator.)\n      (I) Security usage: In cryptography and other security\n\
    \      applications, random means not only unpredictable, but also\n      \"unguessable\"\
    . When selecting data values to use for cryptographic\n      keys, \"the requirement\
    \ is for data that an adversary has a very\n      low probability of guessing\
    \ or determining.\" It is not sufficient\n      to use data that \"only meets\
    \ traditional statistical tests for\n      randomness or which is based on limited\
    \ range sources, such as\n      clocks. Frequently such random quantities are\
    \ determinable [i.e.,\n      guessable] by an adversary searching through an embarrassingly\n\
    \      small space of possibilities.\" [R1750]\n   $ random number generator\n\
    \      (I) A process used to generate an unpredictable, uniformly\n      distributed\
    \ series of numbers (usually integers). (See: pseudo-\n      random, random.)\n\
    \      (C) True random number generators are hardware-based devices that\n   \
    \   depend on the output of a \"noisy diode\" or other physical\n      phenomena.\
    \ [R1750]\n   $ RBAC\n      See: Role-Based Access Control.\n   $ RC2\n   $ RC4\n\
    \      See: Rivest Cipher #2, Rivest Cipher #4.\n   $ realm\n      (O) Kerberos\
    \ usage: The domain of authority of a Kerberos server\n      (consisting of an\
    \ authentication server and a ticket-granting\n      server), including the Kerberized\
    \ clients and the Kerberized\n      application servers\n   $ RED\n      (I) Designation\
    \ for information system equipment or facilities\n      that handle (and for data\
    \ that contains) only plaintext (or,\n      depending on the context, classified\
    \ information), and for such\n      data itself. This term derives from U.S. Government\
    \ COMSEC\n      terminology. (See: BLACK, RED/BLACK separation.)\n   $ Red Book\n\
    \      (D) ISDs SHOULD NOT use this term as a synonym for \"Trusted\n      Network\
    \ Interpretation of the Trusted Computer System Evaluation\n      Criteria\" [NCS05].\
    \ Instead, use the full proper name of the\n      document or, in subsequent references,\
    \ a more conventional\n      abbreviation. (See: TCSEC, Rainbow Series, (usage\
    \ note under)\n      Green Book.)\n   $ RED/BLACK separation\n      (I) An architectural\
    \ concept for cryptographic systems that\n      strictly separates the parts of\
    \ a system that handle plaintext\n      (i.e., RED information) from the parts\
    \ that handle ciphertext\n      (i.e., BLACK information). This term derives from\
    \ U.S. Government\n      COMSEC terminology. (See: BLACK, RED.)\n   $ reference\
    \ monitor\n      (I) \"An access control concept that refers to an abstract machine\n\
    \      that mediates all accesses to objects by subjects.\" [NCS04] (See:\n  \
    \    security kernel.)\n      (C) A reference monitor should be (a) complete (i.e.,\
    \ it mediates\n      every access), (b) isolated (i.e., it cannot be modified\
    \ by other\n      system entities), and (c) verifiable (i.e., small enough to\
    \ be\n      subjected to analysis and tests to ensure that it is correct).\n \
    \  $ reflection attack\n      (I) A type of replay attack in which transmitted\
    \ data is sent back\n      to its originator.\n   $ register\n   $ registration\n\
    \      (I) An administrative act or process whereby an entity's name and\n   \
    \   other attributes are established for the first time at a CA, prior\n     \
    \ to the CA issuing a digital certificate that has the entity's name\n      as\
    \ the subject. (See: registration authority.)\n      (C) Registration may be accomplished\
    \ either directly, by the CA,\n      or indirectly, by a separate RA. An entity\
    \ is presented to the CA\n      or RA, and the authority either records the name(s)\
    \ claimed for\n      the entity or assigns the entity's name(s). The authority\
    \ also\n      determines and records other attributes of the entity that are to\n\
    \      be bound in a certificate (such as a public key or authorizations)\n  \
    \    or maintained in the authority's database (such as street address\n     \
    \ and telephone number). The authority is responsible, possibly\n      assisted\
    \ by an RA, for authenticating the entity's identity and\n      verifying the\
    \ correctness of the other attributes, in accordance\n      with the CA's CPS.\n\
    \      (C) Among the registration issues that a CPS may address are the\n    \
    \  following [R2527]:\n       - How a claimed identity and other attributes are\
    \ verified.\n       - How organization affiliation or representation is verified.\n\
    \       - What forms of names are permitted, such as X.500 DN, domain\n      \
    \   name, or IP address.\n       - Whether names are required to be meaningful\
    \ or unique, and\n         within what domain.\n       - How naming disputes are\
    \ resolved, including the role of\n         trademarks.\n       - Whether certificates\
    \ are issued to entities that are not\n         persons.\n       - Whether a person\
    \ is required to appear before the CA or RA, or\n         can instead be represented\
    \ by an agent.\n       - Whether and how an entity proves possession of the private\
    \ key\n         matching a public key.\n   $ registration authority (RA)\n   \
    \   (I) An optional PKI entity (separate from the CAs) that does not\n      sign\
    \ either digital certificates or CRLs but has responsibility\n      for recording\
    \ or verifying some or all of the information\n      (particularly the identities\
    \ of subjects) needed by a CA to issue\n      certificates and CRLs and to perform\
    \ other certificate management\n      functions. (See: organizational registration\
    \ authority,\n      registration.)\n      (C) Sometimes, a CA may perform all\
    \ certificate management\n      functions for all end users for which the CA signs\
    \ certificates.\n      Other times, such as in a large or geographically dispersed\n\
    \      community, it may be necessary or desirable to offload secondary\n    \
    \  CA functions and delegate them to an assistant, while the CA\n      retains\
    \ the primary functions (signing certificates and CRLs). The\n      tasks that\
    \ are delegated to an RA by a CA may include personal\n      authentication, name\
    \ assignment, token distribution, revocation\n      reporting, key generation,\
    \ and archiving. An RA is an optional PKI\n      component, separate from the\
    \ CA, that is assigned secondary\n      functions. The duties assigned to RAs\
    \ vary from case to case but\n      may include the following:\n       - Verifying\
    \ a subject's identity, i.e., performing personal\n         authentication functions.\n\
    \       - Assigning a name to a subject. (See: distinguished name.)\n       -\
    \ Verifying that a subject is entitled to have the attributes\n         requested\
    \ for a certificate.\n       - Verifying that a subject possesses the private\
    \ key that matches\n         the public key requested for a certificate.\n   \
    \    - Performing functions beyond mere registration, such as\n         generating\
    \ key pairs, distributing tokens, and handling\n         revocation reports. (Such\
    \ functions may be assigned to a PKI\n         element that is separate from both\
    \ the CA and the RA.)\n      (I) PKIX usage: An optional PKI component, separate\
    \ from the\n      CA(s). The functions that the RA performs will vary from case\
    \ to\n      case but may include identity authentication and name assignment,\n\
    \      key generation and archiving of key pairs, token distribution, and\n  \
    \    revocation reporting. [R2510]\n      (O) SET usage: \"An independent third-party\
    \ organization that\n      processes payment card applications for multiple payment\
    \ card\n      brands and forwards applications to the appropriate financial\n\
    \      institutions.\" [SET2]\n   $ regrade\n      (I) Deliberately change the\
    \ classification level of information in\n      an authorized manner.\n   $ rekey\n\
    \      (I) Change the value of a cryptographic key that is being used in\n   \
    \   an application of a cryptographic system. (See: certificate\n      rekey.)\n\
    \      (C) For example, rekey is required at the end of a cryptoperiod or\n  \
    \    key lifetime.\n   $ reliability\n      (I) The ability of a system to perform\
    \ a required function under\n      stated conditions for a specified period of\
    \ time. (See:\n      availability, survivability.)\n   $ relying party\n     \
    \ (N) A synonym for \"certificate user\". Used in a legal context to\n      mean\
    \ a recipient of a certificate who acts in reliance on that\n      certificate.\
    \ (See: ABA Guidelines.)\n   $ Remote Authentication Dial-In User Service (RADIUS)\n\
    \      (I) An Internet protocol [R2138] for carrying dial-in users'\n      authentication\
    \ information and configuration information between a\n      shared, centralized\
    \ authentication server (the RADIUS server) and\n      a network access server\
    \ (the RADIUS client) that needs to\n      authenticate the users of its network\
    \ access ports. (See: TACACS.)\n      (C) A user of the RADIUS client presents\
    \ authentication\n      information to the client, and the client passes that\
    \ information\n      to the RADIUS server. The server authenticates the client\
    \ using a\n      shared secret value, then checks the user's authentication\n\
    \      information, and finally returns to the client all authorization\n    \
    \  and configuration information needed by the client to deliver\n      service\
    \ to the user.\n   $ renew\n      See: certificate renewal.\n   $ replay attack\n\
    \      (I) An attack in which a valid data transmission is maliciously or\n  \
    \    fraudulently repeated, either by the originator or by an adversary\n    \
    \  who intercepts the data and retransmits it, possibly as part of a\n      masquerade\
    \ attack. (See: active wiretapping.)\n   $ repository\n      (I) A system for\
    \ storing and distributing digital certificates and\n      related information\
    \ (including CRLs, CPSs, and certificate\n      policies) to certificate users.\
    \ (See: directory.)\n      (O) \"A trustworthy system for storing and retrieving\
    \ certificates\n      or other information relevant to certificates.\" [ABA]\n\
    \      (C) A certificate is published to those who might need it by\n      putting\
    \ it in a repository. The repository usually is a publicly\n      accessible,\
    \ on-line server. In the Federal Public-key\n      Infrastructure, for example,\
    \ the expected repository is a\n      directory that uses LDAP, but also may be\
    \ the X.500 Directory that\n      uses DAP, or an HTTP server, or an FTP server\
    \ that permits\n      anonymous login.\n   $ repudiation\n      (I) Denial by\
    \ a system entity that was involved in an association\n      (especially an association\
    \ that transfers information) of having\n      participated in the relationship.\
    \ (See: accountability, non-\n      repudiation service.)\n      (O) \"Denial\
    \ by one of the entities involved in a communication of\n      having participated\
    \ in all or part of the communication.\" [I7498\n      Part 2]\n   $ Request for\
    \ Comment (RFC)\n      (I) One of the documents in the archival series that is\
    \ the\n      official channel for ISDs and other publications of the Internet\n\
    \      Engineering Steering Group, the Internet Architecture Board, and\n    \
    \  the Internet community in general. [R2026, R2223] (See: Internet\n      Standard.)\n\
    \      (C) This term is *not* a synonym for \"Internet Standard\".\n   $ residual\
    \ risk\n      (I) The risk that remains after countermeasures have been applied.\n\
    \   $ restore\n      See: card restore.\n   $ revocation\n      See: certificate\
    \ revocation.\n   $ revocation date\n      (N) In an X.509 CRL entry, a date-time\
    \ field that states when the\n      certificate revocation occurred, i.e., when\
    \ the CA declared the\n      digital certificate to be invalid. (See: invalidity\
    \ date.)\n      (C) The revocation date may not resolve some disputes because,\
    \ in\n      the worst case, all signatures made during the validity period of\n\
    \      the certificate may have to be considered invalid. However, it may\n  \
    \    be desirable to treat a digital signature as valid even though the\n    \
    \  private key used to sign was compromised after the signing. If\n      more\
    \ is known about when the compromise actually occurred, a\n      second date-time,\
    \ an \"invalidity date\", can be included in an\n      extension of the CRL entry.\n\
    \   $ revocation list\n      See: certificate revocation list.\n   $ revoke\n\
    \      See: certificate revocation.\n   $ RFC\n      See: Request for Comment.\n\
    \   $ risk\n      (I) An expectation of loss expressed as the probability that\
    \ a\n      particular threat will exploit a particular vulnerability with a\n\
    \      particular harmful result.\n      (O) SET usage: \"The possibility of loss\
    \ because of one or more\n      threats to information (not to be confused with\
    \ financial or\n      business risk).\" [SET2]\n   $ risk analysis\n   $ risk\
    \ assessment\n      (I) A process that systematically identifies valuable system\n\
    \      resources and threats to those resources, quantifies loss\n      exposures\
    \ (i.e., loss potential) based on estimated frequencies\n      and costs of occurrence,\
    \ and (optionally) recommends how to\n      allocate resources to countermeasures\
    \ so as to minimize total\n      exposure.\n      (C) The analysis lists risks\
    \ in order of cost and criticality,\n      thereby determining where countermeasures\
    \ should be applied first.\n      It is usually financially and technically infeasible\
    \ to counteract\n      all aspects of risk, and so some residual risk will remain,\
    \ even\n      after all available countermeasures have been deployed. [FP031,\n\
    \      R2196]\n   $ risk management\n      (I) The process of identifying, controlling,\
    \ and eliminating or\n      minimizing uncertain events that may affect system\
    \ resources.\n      (See: risk analysis.)\n   $ Rivest Cipher #2 (RC2)\n     \
    \ (N) A proprietary, variable-key-length block cipher invented by\n      Ron Rivest\
    \ for RSA Data Security, Inc. (now a wholly-owned\n      subsidiary of Security\
    \ Dynamics, Inc.).\n   $ Rivest Cipher #4 (RC4)\n      (N) A proprietary, variable-key-length\
    \ stream cipher invented by\n      Ron Rivest for RSA Data Security, Inc. (now\
    \ a wholly-owned\n      subsidiary of Security Dynamics, Inc.).\n   $ Rivest-Shamir-Adleman\
    \ (RSA)\n      (N) An algorithm for asymmetric cryptography, invented in 1977\
    \ by\n      Ron Rivest, Adi Shamir, and Leonard Adleman [RSA78, Schn].\n     \
    \ (C) RSA uses exponentiation modulo the product of two large prime\n      numbers.\
    \ The difficulty of breaking RSA is believed to be\n      equivalent to the difficulty\
    \ of factoring integers that are the\n      product of two large prime numbers\
    \ of approximately equal size.\n      (C) To create an RSA key pair, randomly\
    \ choose two large prime\n      numbers, p and q, and compute the modulus, n =\
    \ pq. Randomly choose\n      a number e, the public exponent, that is less than\
    \ n and\n      relatively prime to (p-1)(q-1). Choose another number d, the\n\
    \      private exponent, such that ed-1 evenly divides (p-1)(q-1). The\n     \
    \ public key is the set of numbers (n,e), and the private key is the\n      set\
    \ (n,d).\n      (C) It is assumed to be difficult to compute the private key (n,d)\n\
    \      from the public key (n,e). However, if n can be factored into p\n     \
    \ and q, then the private key d can be computed easily. Thus, RSA\n      security\
    \ depends on the assumption that it is computationally\n      difficult to factor\
    \ a number that is the product of two large\n      prime numbers. (Of course,\
    \ p and q are treated as part of the\n      private key, or else destroyed after\
    \ computing n.)\n      (C) For encryption of a message, m, to be sent to Bob,\
    \ Alice uses\n      Bob's public key (n,e) to compute m**e (mod n) = c. She sends\
    \ c to\n      Bob. Bob computes c**d (mod n) = m. Only Bob knows d, so only Bob\n\
    \      can compute c**d (mod n) = m to recover m.\n      (C) To provide data origin\
    \ authentication of a message, m, to be\n      sent to Bob, Alice computes m**d\
    \ (mod n) = s, where (d,n) is\n      Alice's private key. She sends m and s to\
    \ Bob. To recover the\n      message that only Alice could have sent, Bob computes\
    \ s**e (mod n)\n      = m, where (e,n) is Alice's public key.\n      (C) To ensure\
    \ data integrity in addition to data origin\n      authentication requires extra\
    \ computation steps in which Alice and\n      Bob use a cryptographic hash function\
    \ h (as explained for digital\n      signature). Alice computes the hash value\
    \ h(m) = v, and then\n      encrypts v with her private key to get s. She sends\
    \ m and s. Bob\n      receives m' and s', either of which might have been changed\
    \ from\n      the m and s that Alice sent. To test this, he decrypts s' with\n\
    \      Alice's public key to get v'. He then computes h(m') = v\". If v'\n   \
    \   equals v\", Bob is assured that m' is the same m that Alice sent.\n   $ role-based\
    \ access control (RBAC)\n      (I) A form of identity-based access control where\
    \ the system\n      entities that are identified and controlled are functional\n\
    \      positions in an organization or process.\n   $ root\n      (I) A CA that\
    \ is directly trusted by an end entity. Acquiring the\n      value of a root CA's\
    \ public key involves an out-of-band procedure.\n      (I) Hierarchical PKI usage:\
    \ The CA that is the highest level (most\n      trusted) CA in a certification\
    \ hierarchy; i.e., the authority upon\n      whose public key all certificate\
    \ users base their trust. (See: top\n      CA.)\n      (C) In a hierarchical PKI,\
    \ a root issues public-key certificates\n      to one or more additional CAs that\
    \ form the second highest level.\n      Each of these CAs may issue certificates\
    \ to more CAs at the third\n      highest level, and so on. To initialize operation\
    \ of a\n      hierarchical PKI, the root's initial public key is securely\n  \
    \    distributed to all certificate users in a way that does not depend\n    \
    \  on the PKI's certification relationships. The root's public key\n      may\
    \ be distributed simply as a numerical value, but typically is\n      distributed\
    \ in a self-signed certificate in which the root is the\n      subject. The root's\
    \ certificate is signed by the root itself\n      because there is no higher authority\
    \ in a certification hierarchy.\n      The root's certificate is then the first\
    \ certificate in every\n      certification path.\n      (O) MISSI usage: A name\
    \ previously used for a MISSI policy\n      creation authority, which is not a\
    \ root as defined above for\n      general usage, but is a CA at the second level\
    \ of the MISSI\n      hierarchy, immediately subordinate to a MISSI policy approving\n\
    \      authority.\n      (O) UNIX usage: A user account (also called \"superuser\"\
    ) that has\n      all privileges (including all security-related privileges) and\n\
    \      thus can manage the system and its other user accounts.\n   $ root certificate\n\
    \      (I) A certificate for which the subject is a root.\n      (I) Hierarchical\
    \ PKI usage: The self-signed public-key certificate\n      at the top of a certification\
    \ hierarchy.\n   $ root key\n      (I) A public key for which the matching private\
    \ key is held by a\n      root.\n   $ root registry\n      (O) MISSI usage: A\
    \ name previously used for a MISSI policy\n      approving authority.\n   $ router\n\
    \      (I) A computer that is a gateway between two networks at OSI layer\n  \
    \    3 and that relays and directs data packets through that\n      internetwork.\
    \ The most common form of router operates on IP\n      packets. (See: bridge.)\n\
    \      (I) Internet usage: In the context of the Internet protocol suite,\n  \
    \    a networked computer that forwards Internet Protocol packets that\n     \
    \ are not addressed to the computer itself. (See: host.)\n   $ RSA\n      See:\
    \ Rivest-Shamir-Adleman.\n   $ rule-based security policy\n      (I) \"A security\
    \ policy based on global rules imposed for all\n      users. These rules usually\
    \ rely on comparison of the sensitivity\n      of the resource being accessed\
    \ and the possession of corresponding\n      attributes of users, a group of users,\
    \ or entities acting on\n      behalf of users.\" [I7498 Part 2] (See: identity-based\
    \ security\n      policy.)\n   $ safety\n      (I) The property of a system being\
    \ free from risk of causing harm\n      to system entities and outside entities.\n\
    \   $ SAID\n      See: security association identifier.\n   $ salt\n      (I)\
    \ A random value that is concatenated with a password before\n      applying the\
    \ one-way encryption function used to protect passwords\n      that are stored\
    \ in the database of an access control system. (See:\n      initialization value.)\n\
    \      (C) Salt protects a password-based access control system against a\n  \
    \    dictionary attack.\n   $ sanitize\n      (I) Delete sensitive data from a\
    \ file, a device, or a system; or\n      modify data so as to be able to downgrade\
    \ its classification\n      level.\n   $ SASL\n      See: Simple Authentication\
    \ and Security Layer.\n   $ SCA\n      See: subordinate certification authority.\n\
    \   $ scavenging\n      See: (secondary definition under) threat consequence.\n\
    \   $ screening router\n      (I) A synonym for \"filtering router\".\n   $ SDE\n\
    \      See: Secure Data Exchange.\n   $ SDNS\n      See: Secure Data Network System.\n\
    \   $ seal\n      (O) To use cryptography to provide data integrity service for\
    \ a\n      data object. (See: sign, wrap.)\n      (D) ISDs SHOULD NOT use this\
    \ definition; instead, use language\n      that is more specific with regard to\
    \ the mechanism(s) used, such\n      as \"sign\" when the mechanism is digital\
    \ signature.\n   $ secret\n      (I) (1.) Adjective: The condition of information\
    \ being protected\n      from being known by any system entities except those\
    \ who are\n      intended to know it. (2.) Noun: An item of information that is\n\
    \      protected thusly.\n      (C) This term applies to symmetric keys, private\
    \ keys, and\n      passwords.\n   $ secret-key cryptography\n      (I) A synonym\
    \ for \"symmetric cryptography\".\n   $ Secure Data Exchange (SDE)\n      (N)\
    \ A local area network security protocol defined by the IEEE\n      802.10 standard.\n\
    \   $ Secure Data Network System (SDNS)\n      (N) An NSA program that developed\
    \ security protocols for\n      electronic mail (Message Security Protocol), OSI\
    \ layer 3 (SP3),\n      OSI layer 4 (SP4), and key management (KMP).\n   $ Secure\
    \ Hash Standard (SHS)\n      (N) The U.S. Government standard [FP180] that specifies\
    \ the Secure\n      Hash Algorithm (SHA-1), a cryptographic hash function that\n\
    \      produces a 160-bit output (hash result) for input data of any\n      length\
    \ < 2**64 bits.\n   $ Secure Hypertext Transfer Protocol (Secure-HTTP, S-HTTP)\n\
    \      (I) A Internet protocol for providing client-server security\n      services\
    \ for HTTP communications. (See: https.)\n      (C) S-HTTP was originally specified\
    \ by CommerceNet, a coalition of\n      businesses interested in developing the\
    \ Internet for commercial\n      uses. Several message formats may be incorporated\
    \ into S-HTTP\n      clients and servers, particularly CMS and MOSS. S-HTTP supports\n\
    \      choice of security policies, key management mechanisms, and\n      cryptographic\
    \ algorithms through option negotiation between\n      parties for each transaction.\
    \ S-HTTP supports both asymmetric and\n      symmetric key operation modes. S-HTTP\
    \ attempts to avoid presuming\n      a particular trust model, but it attempts\
    \ to facilitate multiply-\n      rooted hierarchical trust and anticipates that\
    \ principals may have\n      many public key certificates.\n   $ Secure/MIME (S/MIME)\n\
    \      (I) Secure/Multipurpose Internet Mail Extensions, an Internet\n      protocol\
    \ [R2633] to provide encryption and digital signatures for\n      Internet mail\
    \ messages.\n   $ Secure Sockets Layer (SSL)\n      (N) An Internet protocol (originally\
    \ developed by Netscape\n      Communications, Inc.) that uses connection-oriented\
    \ end-to-end\n      encryption to provide data confidentiality service and data\n\
    \      integrity service for traffic between a client (often a web\n      browser)\
    \ and a server, and that can optionally provide peer entity\n      authentication\
    \ between the client and the server. (See: Transport\n      Layer Security.)\n\
    \      (C) SSL is layered below HTTP and above a reliable transport\n      protocol\
    \ (TCP). SSL is independent of the application it\n      encapsulates, and any\
    \ higher level protocol can layer on top of\n      SSL transparently. However,\
    \ many Internet applications might be\n      better served by IPsec.\n      (C)\
    \ SSL has two layers: (a) SSL's lower layer, the SSL Record\n      Protocol, is\
    \ layered on top of the transport protocol and\n      encapsulates higher level\
    \ protocols. One such encapsulated\n      protocol is SSL Handshake Protocol.\
    \ (b) SSL's upper layer provides\n      asymmetric cryptography for server authentication\
    \ (verifying the\n      server's identity to the client) and optional client\n\
    \      authentication (verifying the client's identity to the server),\n     \
    \ and also enables them to negotiate a symmetric encryption\n      algorithm and\
    \ secret session key (to use for data confidentiality)\n      before the application\
    \ protocol transmits or receives data. A\n      keyed hash provides data integrity\
    \ service for encapsulated data.\n   $ secure state\n      (I) A system condition\
    \ in which no subject can access any object\n      in an unauthorized manner.\
    \ (See: (secondary definition under)\n      Bell-LaPadula Model, clean system.)\n\
    \   $ security\n      (I) (1.) Measures taken to protect a system. (2.) The condition\
    \ of\n      a system that results from the establishment and maintenance of\n\
    \      measures to protect the system. (3.) The condition of system\n      resources\
    \ being free from unauthorized access and from\n      unauthorized or accidental\
    \ change, destruction, or loss.\n   $ security architecture\n      (I) A plan\
    \ and set of principles that describe (a) the security\n      services that a\
    \ system is required to provide to meet the needs of\n      its users, (b) the\
    \ system elements required to implement the\n      services, and (c) the performance\
    \ levels required in the elements\n      to deal with the threat environment.\
    \ (See: (discussion under)\n      security policy.)\n      (C) A security architecture\
    \ is the result of applying the system\n      engineering process. A complete\
    \ system security architecture\n      includes administrative security, communication\
    \ security, computer\n      security, emanations security, personnel security,\
    \ and physical\n      security (e.g., see: [R2179]). A complete security architecture\n\
    \      needs to deal with both intentional, intelligent threats and\n      accidental\
    \ kinds of threats.\n   $ security association\n      (I) A relationship established\
    \ between two or more entities to\n      enable them to protect data they exchange.\
    \ The relationship is\n      used to negotiate characteristics of protection mechanisms,\
    \ but\n      does not include the mechanisms themselves. (See: association.)\n\
    \      (C) A security association describes how entities will use\n      security\
    \ services. The relationship is represented by a set of\n      information that\
    \ is shared between the entities and is agreed upon\n      and considered a contract\
    \ between them.\n      (O) IPsec usage: A simplex (uni-directional) logical connection\n\
    \      created for security purposes and implemented with either AH or\n     \
    \ ESP (but not both). The security services offered by a security\n      association\
    \ depend on the protocol selected, the IPsec mode\n      (transport or tunnel),\
    \ the endpoints, and the election of optional\n      services within the protocol.\
    \ A security association is identified\n      by a triple consisting of (a) a\
    \ destination IP address, (b) a\n      protocol (AH or ESP) identifier, and (c)\
    \ a Security Parameter\n      Index.\n   $ security association identifier (SAID)\n\
    \      (I) A data field in a security protocol (such as NLSP or SDE),\n      used\
    \ to identify the security association to which a protocol data\n      unit is\
    \ bound. The SAID value is usually used to select a key for\n      decryption\
    \ or authentication at the destination. (See: Security\n      Parameter Index.)\n\
    \   $ security audit\n      (I) An independent review and examination of a system's\
    \ records\n      and activities to determine the adequacy of system controls,\n\
    \      ensure compliance with established security policy and procedures,\n  \
    \    detect breaches in security services, and recommend any changes\n      that\
    \ are indicated for countermeasures. [I7498 Part 2, NCS01]\n      (C) The basic\
    \ audit objective is to establish accountability for\n      system entities that\
    \ initiate or participate in security-relevant\n      events and actions. Thus,\
    \ means are needed to generate and record\n      a security audit trail and to\
    \ review and analyze the audit trail\n      to discover and investigate attacks\
    \ and security compromises.\n   $ security audit trail\n      (I) A chronological\
    \ record of system activities that is sufficient\n      to enable the reconstruction\
    \ and examination of the sequence of\n      environments and activities surrounding\
    \ or leading to an\n      operation, procedure, or event in a security-relevant\
    \ transaction\n      from inception to final results. [NCS04] (See: security audit.)\n\
    \   $ security class\n      (D) A synonym for \"security level\". For consistency,\
    \ ISDs SHOULD\n      use \"security level\" instead of \"security class\".\n \
    \  $ security clearance\n      (I) A determination that a person is eligible,\
    \ under the standards\n      of a specific security policy, for authorization\
    \ to access\n      sensitive information or other system resources. (See: clearance\n\
    \      level.)\n   $ security compromise\n      (I) A security violation in which\
    \ a system resource is exposed, or\n      is potentially exposed, to unauthorized\
    \ access. (See: data\n      compromise, violation.)\n   $ security domain\n  \
    \    See: domain.\n   $ security environment\n      (I) The set of external entities,\
    \ procedures, and conditions that\n      affect secure development, operation,\
    \ and maintenance of a system.\n   $ security event\n      (I) A occurrence in\
    \ a system that is relevant to the security of\n      the system. (See: security\
    \ incident.)\n      (C) The term includes both events that are security incidents\
    \ and\n      those that are not. In a CA workstation, for example, a list of\n\
    \      security events might include the following:\n       - Performing a cryptographic\
    \ operation, e.g., signing a digital\n         certificate or CRL.\n       - Performing\
    \ a cryptographic card operation: creation, insertion,\n         removal, or backup.\n\
    \       - Performing a digital certificate lifecycle operation: rekey,\n     \
    \    renewal, revocation, or update.\n       - Posting information to an X.500\
    \ Directory.\n       - Receiving a key compromise notification.\n       - Receiving\
    \ an improper certification request.\n       - Detecting an alarm condition reported\
    \ by a cryptographic\n         module.\n       - Logging the operator in or out.\n\
    \       - Failing a built-in hardware self-test or a software system\n       \
    \  integrity check.\n   $ security fault analysis\n      (I) A security analysis,\
    \ usually performed on hardware at a logic\n      gate level, gate-by-gate, to\
    \ determine the security properties of\n      a device when a hardware fault is\
    \ encountered.\n   $ security gateway\n      (I) A gateway that separates trusted\
    \ (or relatively more trusted)\n      hosts on the internal network side from\
    \ untrusted (or less\n      trusted) hosts on the external network side. (See:\
    \ firewall and\n      guard.)\n      (O) IPsec usage: \"An intermediate system\
    \ that implements IPsec\n      protocols.\" [R2401] Normally, AH or ESP is implemented\
    \ to serve a\n      set of internal hosts, providing security services for the\
    \ hosts\n      when they communicate with other, external hosts or gateways that\n\
    \      also implement IPsec.\n   $ security incident\n      (I) A security event\
    \ that involves a security violation. (See:\n      CERT, GRIP, security event,\
    \ security intrusion, security\n      violation.)\n      (C) In other words, a\
    \ security-relevant system event in which the\n      system's security policy\
    \ is disobeyed or otherwise breached.\n      (O) \"Any adverse event which compromises\
    \ some aspect of computer\n      or network security.\" [R2350]\n      (D) ISDs\
    \ SHOULD NOT use this \"O\" definition because (a) a security\n      incident\
    \ may occur without actually being harmful (i.e., adverse)\n      and (b) this\
    \ Glossary defines \"compromise\" more narrowly in\n      relation to unauthorized\
    \ access.\n   $ security intrusion\n      (I) A security event, or a combination\
    \ of multiple security\n      events, that constitutes a security incident in\
    \ which an intruder\n      gains, or attempts to gain, access to a system (or\
    \ system\n      resource) without having authorization to do so.\n   $ security\
    \ kernel\n      (I) \"The hardware, firmware, and software elements of a trusted\n\
    \      computing base that implement the reference monitor concept. It\n     \
    \ must mediate all accesses, be protected from modification, and be\n      verifiable\
    \ as correct.\" [NCS04] (See: reference monitor.)\n      (C) That is, a security\
    \ kernel is an implementation of a reference\n      monitor for a given hardware\
    \ base.\n   $ security label\n      (I) A marking that is bound to a system resource\
    \ and that names or\n      designates the security-relevant attributes of that\
    \ resource.\n      [I7498 Part 2, R1457]\n      (C) The recommended definition\
    \ is usefully broad, but usually the\n      term is understood more narrowly as\
    \ a marking that represents the\n      security level of an information object,\
    \ i.e., a marking that\n      indicates how sensitive an information object is.\
    \ [NCS04]\n      (C) System security mechanisms interpret security labels according\n\
    \      to applicable security policy to determine how to control access\n    \
    \  to the associated information, otherwise constrain its handling,\n      and\
    \ affix appropriate security markings to visible (printed and\n      displayed)\
    \ images thereof. [FP188]\n   $ security level\n      (I) The combination of a\
    \ hierarchical classification level and a\n      set of non-hierarchical category\
    \ designations that represents how\n      sensitive information is. (See: (usage\
    \ note under) classification\n      level, dominate, lattice model.)\n   $ security\
    \ management infrastructure (SMI)\n      (I) System elements and activities that\
    \ support security policy by\n      monitoring and controlling security services\
    \ and mechanisms,\n      distributing security information, and reporting security\
    \ events.\n      The associated functions are as follows [I7498-4]:\n       -\
    \ Controlling (granting or restricting) access to system\n      resources: This\
    \ includes verifying authorizations and\n      identities, controlling access\
    \ to sensitive security data, and\n      modifying access priorities and procedures\
    \ in the event of\n      attacks.\n       - Retrieving (gathering) and archiving\
    \ (storing) security\n      information: This includes logging security events\
    \ and\n      analyzing the log, monitoring and profiling usage, and\n      reporting\
    \ security violations.\n       - Managing and controlling the encryption process:\
    \ This includes\n      performing the functions of key management and reporting\
    \ on key\n      management problems. (See: public-key infrastructure.)\n   $ security\
    \ mechanism\n      (I) A process (or a device incorporating such a process) that\
    \ can\n      be used in a system to implement a security service that is\n   \
    \   provided by or within the system. (See: (discussion under)\n      security\
    \ policy.)\n      (C) Some examples of security mechanisms are authentication\n\
    \      exchange, checksum, digital signature, encryption, and traffic\n      padding.\n\
    \   $ security model\n      (I) A schematic description of a set of entities and\
    \ relationships\n      by which a specified set of security services are provided\
    \ by or\n      within a system. (See: (discussion under) security policy.)\n \
    \     (C) An example is the Bell-LaPadula Model.\n   $ security parameters index\
    \ (SPI)\n      (I) IPsec usage: The type of security association identifier used\n\
    \      in IPsec protocols. A 32-bit value used to distinguish among\n      different\
    \ security associations terminating at the same\n      destination (IP address)\
    \ and using the same IPsec security\n      protocol (AH or ESP). Carried in AH\
    \ and ESP to enable the\n      receiving system to determine under which security\
    \ association to\n      process a received packet.\n   $ security perimeter\n\
    \      (I) The boundary of the domain in which a security policy or\n      security\
    \ architecture applies; i.e., the boundary of the space in\n      which security\
    \ services protect system resources.\n   $ security policy\n      (I) A set of\
    \ rules and practices that specify or regulate how a\n      system or organization\
    \ provides security services to protect\n      sensitive and critical system resources.\
    \ (See: identity-based\n      security policy, rule-based security policy, security\n\
    \      architecture, security mechanism, security model.)\n      (O) \"The set\
    \ of rules laid down by the security authority\n      governing the use and provision\
    \ of security services and\n      facilities.\" [X509]\n      (C) Ravi Sandhu\
    \ notes that security policy is one of four layers\n      of the security engineering\
    \ process (as shown in the following\n      diagram). Each layer provides a different\
    \ view of security,\n      ranging from what services are needed to how services\
    \ are\n      implemented.\n         What Security Services Should Be Provided?\n\
    \          ^\n          | + - - - - - - - - - - - +\n          | | Security Policy\
    \       |\n          | + - - - - - - - - - - - +    + - - - - - - - - - - - -\
    \ - - +\n          | | Security Model        |    | A \"top-level specification\"\
    \ |\n          | + - - - - - - - - - - - + <- | is at a level below \"model\"\
    \ |\n          | | Security Architecture |    | but above \"architecture\".  \
    \ |\n          | + - - - - - - - - - - - +    + - - - - - - - - - - - - - - +\n\
    \          | | Security Mechanism    |\n          | + - - - - - - - - - - - +\n\
    \          v\n         How Are Security Services Implemented?\n   $ Security Protocol\
    \ 3 (SP3)\n      (O) A protocol [SDNS3] developed by SDNS to provide connectionless\n\
    \      data security at the top of OSI layer 3. (See: NLSP.)\n   $ Security Protocol\
    \ 4 (SP4)\n      (O) A protocol [SDNS4] developed by SDNS to provide either\n\
    \      connectionless or end-to-end connection-oriented data security at\n   \
    \   the bottom of OSI layer 4. (See: TLSP.)\n   $ security-relevant event\n  \
    \    See: security event.\n   $ security service\n      (I) A processing or communication\
    \ service that is provided by a\n      system to give a specific kind of protection\
    \ to system resources.\n      (See: access control service, audit service, availability\
    \ service,\n      data confidentiality service, data integrity service, data origin\n\
    \      authentication service, non-repudiation service, peer entity\n      authentication\
    \ service, system integrity service.)\n      (O) \"A service, provided by a layer\
    \ of communicating open systems,\n      which ensures adequate security of the\
    \ systems or the data\n      transfers.\" [I7498 Part 2]\n      (C) Security services\
    \ implement security policies, and are\n      implemented by security mechanisms.\n\
    \   $ security situation\n      (I) ISAKMP usage: The set of all security-relevant\
    \ information--\n      e.g., network addresses, security classifications, manner\
    \ of\n      operation (normal or emergency)--that is needed to decide the\n  \
    \    security services that are required to protect the association\n      that\
    \ is being negotiated.\n   $ security token\n      See: token.\n   $ security\
    \ violation\n      (I) An act or event that disobeys or otherwise breaches security\n\
    \      policy. (See: compromise, penetration, security incident.)\n   $ self-signed\
    \ certificate\n      (I) A public-key certificate for which the public key bound\
    \ by the\n      certificate and the private key used to sign the certificate are\n\
    \      components of the same key pair, which belongs to the signer.\n      (See:\
    \ root certificate.)\n      (C) In a self-signed X.509 public-key certificate,\
    \ the issuer's DN\n      is the same as the subject's DN.\n   $ semantic security\n\
    \      (I) An attribute of a encryption algorithm that is a formalization\n  \
    \    of the notion that the algorithm not only hides the plaintext but\n     \
    \ also reveals no partial information about the plaintext. Whatever\n      is\
    \ efficiently computable about the plaintext when given the\n      ciphertext,\
    \ is also efficiently computable without the ciphertext.\n      (See: indistinguishability.)\n\
    \   $ sensitive (information)\n      (I) Information is sensitive if disclosure,\
    \ alteration,\n      destruction, or loss of the information would adversely affect\
    \ the\n      interests or business of its owner or user. (See: critical.)\n  \
    \ $ separation of duties\n      (I) The practice of dividing the steps in a system\
    \ function among\n      different individuals, so as to keep a single individual\
    \ from\n      subverting the process. (See: dual control, administrative\n   \
    \   security.)\n   $ serial number\n      See: certificate serial number.\n  \
    \ $ server\n      (I) A system entity that provides a service in response to\n\
    \      requests from other system entities called clients.\n   $ session key\n\
    \      (I) In the context of symmetric encryption, a key that is\n      temporary\
    \ or is used for a relatively short period of time. (See:\n      ephemeral key,\
    \ key distribution center, master key.)\n      (C) Usually, a session key is used\
    \ for a defined period of\n      communication between two computers, such as\
    \ for the duration of a\n      single connection or transaction set, or the key\
    \ is used in an\n      application that protects relatively large amounts of data\
    \ and,\n      therefore, needs to be rekeyed frequently.\n   $ SET\n      See:\
    \ SET Secure Electronic Transaction(trademark).\n   $ SET private extension\n\
    \      (O) One of the private extensions defined by SET for X.509\n      certificates.\
    \ Carries information about hashed root key,\n      certificate type, merchant\
    \ data, cardholder certificate\n      requirements, encryption support for tunneling,\
    \ or message support\n      for payment instructions.\n   $ SET qualifier\n  \
    \    (O) A certificate policy qualifier that provides information about\n    \
    \  the location and content of a SET certificate policy.\n      (C) In addition\
    \ to the policies and qualifiers inherited from its\n      own certificate, each\
    \ CA in the SET certification hierarchy may\n      add one qualifying statement\
    \ to the root policy when the CA issues\n      a certificate. The additional qualifier\
    \ is a certificate policy\n      for that CA. Each policy in a SET certificate\
    \ may have these\n      qualifiers:\n       - A URL where a copy of the policy\
    \ statement may be found.\n       - An electronic mail address where a copy of\
    \ the policy statement\n         may be found.\n       - A hash result of the\
    \ policy statement, computed using the\n         indicated algorithm.\n      \
    \ - A statement declaring any disclaimers associated with the\n         issuing\
    \ of the certificate.\n   $ SET Secure Electronic Transaction(trademark) or SET(trademark)\n\
    \      (N) A protocol developed jointly by MasterCard International and\n    \
    \  Visa International and published as an open standard to provide\n      confidentiality\
    \ of transaction information, payment integrity, and\n      authentication of\
    \ transaction participants for payment card\n      transactions over unsecured\
    \ networks, such as the Internet. [SET1]\n      (See: acquirer, brand, cardholder,\
    \ dual signature, electronic\n      commerce, issuer, merchant, payment gateway,\
    \ third party.)\n      (C) This term and acronym are trademarks of SETCo. MasterCard\
    \ and\n      Visa announced the SET standard on 1 February 1996. On 19 December\n\
    \      1997, MasterCard and Visa formed SET Secure Electronic Transaction\n  \
    \    LLC (commonly referred to as \"SETCo\") to implement the SET 1.0\n      specification.\
    \ A memorandum of understanding adds American Express\n      and JCB Credit Card\
    \ Company as co-owners of SETCo.\n   $ SETCo\n      See: (secondary definition\
    \ under) SET Secure Electronic\n      Transaction.\n   $ SHA-1\n      See: Secure\
    \ Hash Standard.\n   $ shared secret\n      (I) A synonym for \"keying material\"\
    \ or \"cryptographic key\".\n   $ S-HTTP\n      See: Secure HTTP.\n   $ sign\n\
    \      (I) Create a digital signature for a data object.\n   $ signature\n   \
    \   See: digital signature, electronic signature.\n   $ signature certificate\n\
    \      (I) A public-key certificate that contains a public key that is\n     \
    \ intended to be used for verifying digital signatures, rather than\n      for\
    \ encrypting data or performing other cryptographic functions.\n      (C) A v3\
    \ X.509 public-key certificate may have a \"keyUsage\"\n      extension which\
    \ indicates the purpose for which the certified\n      public key is intended.\n\
    \   $ signer\n      (N) A human being or an organization entity that uses its\
    \ private\n      key to create a digital signature for a data object. [ABA]\n\
    \   $ SILS\n      See: Standards for Interoperable LAN/MAN Security.\n   $ simple\
    \ authentication\n      (I) An authentication process that uses a password as\
    \ the\n      information needed to verify an identity claimed for an entity.\n\
    \      (See: strong authentication.)\n      (O) \"Authentication by means of simple\
    \ password arrangements.\"\n      [X509]\n   $ Simple Authentication and Security\
    \ Layer (SASL)\n      (I) An Internet specification [R2222] for adding authentication\n\
    \      service to connection-based protocols. To use SASL, a protocol\n      includes\
    \ a command for authenticating a user to a server and for\n      optionally negotiating\
    \ protection of subsequent protocol\n      interactions. The command names a registered\
    \ security mechanism.\n      SASL mechanisms include Kerberos, GSSAPI, S/KEY,\
    \ and others. Some\n      protocols that use SASL are IMAP4 and POP3.\n   $ Simple\
    \ Key-management for Internet Protocols (SKIP)\n      (I) A key distribution protocol\
    \ that uses hybrid encryption to\n      convey session keys that are used to encrypt\
    \ data in IP packets.\n      [R2356] (See: IKE, IPsec.)\n      (C) SKIP uses the\
    \ Diffie-Hellman algorithm (or could use another\n      key agreement algorithm)\
    \ to generate a key-encrypting key for use\n      between two entities. A session\
    \ key is used with a symmetric\n      algorithm to encrypt data in one or more\
    \ IP packets that are to be\n      sent from one of the entities to the other.\
    \ The KEK is used with a\n      symmetric algorithm to encrypt the session key,\
    \ and the encrypted\n      session key is placed in a SKIP header that is added\
    \ to each IP\n      packet that is encrypted with that session key.\n   $ Simple\
    \ Mail Transfer Protocol (SMTP)\n      (I) A TCP-based, application-layer, Internet\
    \ Standard protocol\n      [R0821] for moving electronic mail messages from one\
    \ computer to\n      another.\n   $ Simple Network Management Protocol (SNMP)\n\
    \      (I) A UDP-based, application-layer, Internet Standard protocol\n      [R2570,\
    \ R2574] for conveying management information between\n      managers and agents.\n\
    \      (C) SNMP version 1 uses cleartext passwords for authentication and\n  \
    \    access control. (See: community string.) Version 2 adds\n      cryptographic\
    \ mechanisms based on DES and MD5. Version 3 provides\n      enhanced, integrated\
    \ support for security services, including data\n      confidentiality, data integrity,\
    \ data origin authentication, and\n      message timeliness and limited replay\
    \ protection.\n   $ simple security property\n      See: (secondary definition\
    \ under) Bell-LaPadula Model.\n   $ single sign-on\n      (I) A system that enables\
    \ a user to access multiple computer\n      platforms (usually a set of hosts\
    \ on the same network) or\n      application systems after being authenticated\
    \ just one time. (See:\n      Kerberos.)\n      (C) Typically, a user logs in\
    \ just once, and then is transparently\n      granted access to a variety of permitted\
    \ resources with no further\n      login being required until after the user logs\
    \ out. Such a system\n      has the advantages of being user friendly and enabling\n\
    \      authentication to be managed consistently across an entire\n      enterprise,\
    \ and has the disadvantage of requiring all hosts and\n      applications to trust\
    \ the same authentication mechanism.\n   $ situation\n      See: security situation.\n\
    \   $ S/Key\n      (I) A security mechanism that uses a cryptographic hash function\n\
    \      to generate a sequence of 64-bit, one-time passwords for remote\n     \
    \ user login. [R1760]\n      (C) The client generates a one-time password by applying\
    \ the MD4\n      cryptographic hash function multiple times to the user's secret\n\
    \      key. For each successive authentication of the user, the number of\n  \
    \    hash applications is reduced by one. (Thus, an intruder using\n      wiretapping\
    \ cannot compute a valid password from knowledge of one\n      previously used.)\
    \ The server verifies a password by hashing the\n      currently presented password\
    \ (or initialization value) one time\n      and comparing the hash result with\
    \ the previously presented\n      password.\n   $ SKIP\n      See: Simple Key-management\
    \ for IP.\n   $ SKIPJACK\n      (N) A Type II block cipher [NIST] with a block\
    \ size of 64 bits and\n      a key size of 80 bits, that was developed by NSA\
    \ and formerly\n      classified at the U.S. Department of Defense \"Secret\"\
    \ level. (See:\n      CAPSTONE, CLIPPER, FORTEZZA, Key Exchange Algorithm.)\n\
    \      (C) On 23 June 1998, NSA announced that SKIPJACK had been\n      declassified.\n\
    \   $ slot\n      (O) MISSI usage: One of the FORTEZZA PC card storage areas that\n\
    \      are each able to hold an X.509 certificate and additional data\n      that\
    \ is associated with the certificate, such as the matching\n      private key.\n\
    \   $ smart card\n      (I) A credit-card sized device containing one or more\
    \ integrated\n      circuit chips, which perform the functions of a computer's\
    \ central\n      processor, memory, and input/output interface. (See: PC card.)\n\
    \      (C) Sometimes this term is used rather strictly to mean a card\n      that\
    \ closely conforms to the dimensions and appearance of the kind\n      of plastic\
    \ credit card issued by banks and merchants. At other\n      times, the term is\
    \ used loosely to include cards that are larger\n      than credit cards, especially\
    \ cards that are thicker, such as PC\n      cards.\n      (C) A \"smart token\"\
    \ is a device that conforms to the definition of\n      smart card except that\
    \ rather than having standard credit card\n      dimensions, the token is packaged\
    \ in some other form, such as a\n      dog tag or door key shape.\n   $ smart\
    \ token\n      See: (secondary definition under) smart card.\n   $ SMI\n     \
    \ See: security management infrastructure.\n   $ S/MIME\n      See: Secure/MIME.\n\
    \   $ SMTP\n      See: Simple Mail Transfer Protocol.\n   $ smurf\n      (I) Software\
    \ that mounts a denial-of-service attack (\"smurfing\")\n      by exploiting IP\
    \ broadcast addressing and ICMP ping packets to\n      cause flooding. (See: flood,\
    \ ICMP flood.)\n      (D) ISDs SHOULD NOT use this term because it is not listed\
    \ in most\n      dictionaries and could confuse international readers.\n     \
    \ (C) A smurf program builds a network packet that appears to\n      originate\
    \ from another address, that of the \"victim\", either a\n      host or an IP\
    \ router. The packet contains an ICMP ping message\n      that is addressed to\
    \ an IP broadcast address, i.e., to all IP\n      addresses in a given network.\
    \ The echo responses to the ping\n      message return to the victim's address.\
    \ The goal of smurfing may\n      be either to deny service at a particular host\
    \ or to flood all or\n      part of an IP network.\n   $ sniffing\n      (C) A\
    \ synonym for \"passive wiretapping\". (See: password sniffing.)\n      (D) ISDs\
    \ SHOULD NOT use this term because it unnecessarily\n      duplicates the meaning\
    \ of a term that is better established. (See:\n      (usage note under) Green\
    \ Book.\n   $ SNMP\n      See: Simple Network Management Protocol.\n   $ social\
    \ engineering\n      (I) A euphemism for non-technical or low-technology means--such\
    \ as\n      lies, impersonation, tricks, bribes, blackmail, and threats--used\n\
    \      to attack information systems. (See: masquerade attack.)\n      (D) ISDs\
    \ SHOULD NOT use this term because it is vague; instead,\n      use a term that\
    \ is specific with regard to the means of attack.\n   $ SOCKS\n      (I) An Internet\
    \ protocol [R1928] that provides a generalized proxy\n      server that enables\
    \ client-server applications--such as TELNET,\n      FTP, and HTTP; running over\
    \ either TCP or UDP--to use the services\n      of a firewall.\n      (C) SOCKS\
    \ is layered under the application layer and above the\n      transport layer.\
    \ When a client inside a firewall wishes to\n      establish a connection to an\
    \ object that is reachable only through\n      the firewall, it uses TCP to connect\
    \ to the SOCKS server,\n      negotiates with the server for the authentication\
    \ method to be\n      used, authenticates with the chosen method, and then sends\
    \ a relay\n      request. The SOCKS server evaluates the request, typically based\n\
    \      on source and destination addresses, and either establishes the\n     \
    \ appropriate connection or denies it.\n   $ soft TEMPEST\n      (O) The use of\
    \ software techniques to reduce the radio frequency\n      information leakage\
    \ from computer displays and keyboards. [Kuhn]\n      (See: TEMPEST.)\n   $ software\n\
    \      (I) Computer programs (which are stored in and executed by\n      computer\
    \ hardware) and associated data (which also is stored in\n      the hardware)\
    \ that may be dynamically written or modified during\n      execution. (See: firmware,\
    \ hardware.)\n   $ SORA\n      See: SSO-PIN ORA.\n   $ source authentication\n\
    \      (D) ISDs SHOULD NOT use this term because it is ambiguous. If the\n   \
    \   intent is to authenticate the original creator or packager of data\n     \
    \ received, then say \"data origin authentication\". If the intent is\n      to\
    \ authenticate the identity of the sender of data, then say \"peer\n      entity\
    \ authentication\". (See: data origin authentication, peer\n      entity authentication).\n\
    \   $ source integrity\n      (I) The degree of confidence that can be placed\
    \ in information\n      based on the trustworthiness of its sources. (See: integrity.)\n\
    \   $ SP3\n      See: Security Protocol 3.\n   $ SP4\n      See: Security Protocol\
    \ 4.\n   $ spam\n      (I) (1.) Verb: To indiscriminately send unsolicited, unwanted,\n\
    \      irrelevant, or inappropriate messages, especially commercial\n      advertising\
    \ in mass quantities. (2.) Noun: electronic \"junk mail\".\n      [R2635]\n  \
    \    (D) This term SHOULD NOT be written in upper-case letters, because\n    \
    \  SPAM(trademark) is a trademark of Hormel Foods Corporation. Hormel\n      says,\
    \ \"We do not object to use of this slang term [spam] to\n      describe [unsolicited\
    \ commercial email (UCE)], although we do\n      object to the use of our product\
    \ image in association with that\n      term. Also, if the term is to be used,\
    \ it should be used in all\n      lower-case letters to distinguish it from our\
    \ trademark SPAM,\n      which should be used with all uppercase letters.\"\n\
    \      (C) In sufficient volume, spam can cause denial of service. (See:\n   \
    \   flooding.) According to the SPAM Web site, the term was adopted as\n     \
    \ a result of the Monty Python skit in which a group of Vikings sang\n      a\
    \ chorus of 'SPAM, SPAM, SPAM . . .' in an increasing crescendo,\n      drowning\
    \ out other conversation. Hence, the analogy applied\n      because UCE was drowning\
    \ out normal discourse on the Internet.\n   $ SPC\n      See: software publisher\
    \ certificate.\n   $ SPI\n      See: Security Parameters Index.\n   $ split key\n\
    \      (I) A cryptographic key that is divided into two or more separate\n   \
    \   data items that individually convey no knowledge of the whole key\n      that\
    \ results from combining the items. (See: dual control, split\n      knowledge.)\n\
    \   $ split knowledge\n      (I) A security technique in which two or more entities\
    \ separately\n      hold data items that individually convey no knowledge of the\n\
    \      information that results from combining the items. (See: dual\n      control,\
    \ split key.)\n      (O) \"A condition under which two or more entities separately\
    \ have\n      key components which individually convey no knowledge of the\n \
    \     plaintext key which will be produced when the key components are\n     \
    \ combined in the cryptographic module.\" [FP140]\n   $ spoofing attack\n    \
    \  (I) A synonym for \"masquerade attack\".\n   $ SSH\n      (I) A protocol for\
    \ secure remote login and other secure network\n      services over an insecure\
    \ network.\n      (C) Consists of three major components:\n       - Transport\
    \ layer protocol: Provides server authentication,\n         confidentiality, and\
    \ integrity. It may optionally also provide\n         compression. The transport\
    \ layer will typically be run over a\n         TCP/IP connection, but might also\
    \ be used on top of any other\n         reliable data stream.\n       - User authentication\
    \ protocol: Authenticates the client-side\n         user to the server. It runs\
    \ over the transport layer protocol.\n       - Connection protocol: Multiplexes\
    \ the encrypted tunnel into\n         several logical channels. It runs over the\
    \ user authentication\n         protocol.\n   $ SSL\n      See: Secure Sockets\
    \ Layer, Standard Security Label.\n   $ SSO\n      See: system security officer.\n\
    \   $ SSO PIN\n      (O) MISSI usage: One of two personal identification numbers\
    \ that\n      control access to the functions and stored data of a FORTEZZA PC\n\
    \      card. Knowledge of the SSO PIN enables the card user to perform\n     \
    \ the FORTEZZA functions intended for use by an end user and also\n      the functions\
    \ intended for use by a MISSI certification authority.\n      (See: user PIN.)\n\
    \   $ SSO-PIN ORA (SORA)\n      (O) MISSI usage: A MISSI organizational RA that\
    \ operates in a mode\n      in which the ORA performs all card management functions\
    \ and,\n      therefore, requires knowledge of the SSO PIN for an end user's\n\
    \      FORTEZZA PC card.\n   $ Standards for Interoperable LAN/MAN Security (SILS)\n\
    \      (N) (1.) The IEEE 802.10 standards committee. (2.) A developing\n     \
    \ set of IEEE standards, which has eight parts: (a) Model, including\n      security\
    \ management, (b) Secure Data Exchange protocol, (c) Key\n      Management, (d)\
    \ [has been incorporated in (a)], (e) SDE Over\n      Ethernet 2.0, (f) SDE Sublayer\
    \ Management, (g) SDE Security\n      Labels, and (h) SDE PICS Conformance. Parts\
    \ b, e, f, g, and h are\n      incorporated in IEEE Standard 802.10-1998.\n  \
    \ $ star property\n      (I) (Written \"*-property\".) See: \"confinement property\"\
    \ under\n      Bell-LaPadula Model.\n   $ Star Trek attack\n      (C) An attack\
    \ that penetrates your system where no attack has ever\n      gone before.\n \
    \  $ steganography\n      (I) Methods of hiding the existence of a message or\
    \ other data.\n      This is different than cryptography, which hides the meaning\
    \ of a\n      message but does not hide the message itself. (See: cryptology.)\n\
    \      (C) An example of a steganographic method is \"invisible\" ink.\n     \
    \ (See: digital watermark.)\n   $ storage channel\n      See: (secondary definition\
    \ under) covert channel.\n   $ stream cipher\n      (I) An encryption algorithm\
    \ that breaks plaintext into a stream of\n      successive bits (or characters)\
    \ and encrypts the n-th plaintext\n      bit with the n-th element of a parallel\
    \ key stream, thus\n      converting the plaintext bit stream into a ciphertext\
    \ bit stream.\n      [Schn] (See: block cipher.)\n   $ strong authentication\n\
    \      (I) An authentication process that uses cryptography--particularly\n  \
    \    public-key certificates--to verify the identity claimed for an\n      entity.\
    \ (See: X.509.)\n      (O) \"Authentication by means of cryptographically derived\n\
    \      credentials.\" [X509]\n   $ subject\n      1. (I) In a computer system:\
    \ A system entity that causes\n      information to flow among objects or changes\
    \ the system state;\n      technically, a process-domain pair. (See: Bell-LaPadula\
    \ Model.)\n      2. (I) Of a certificate: The entity name that is bound to the\
    \ data\n      items in a digital certificate, and particularly a name that is\n\
    \      bound to a key value in a public-key certificate.\n   $ subnetwork\n  \
    \    (N) An OSI term for a system of packet relays and connecting links\n    \
    \  that implement the lower three protocol layers of the OSIRM to\n      provide\
    \ a communication service that interconnects attached end\n      systems. Usually\
    \ the relays operate at OSI layer 3 and are all of\n      the same type (e.g.,\
    \ all X.25 packet switches, or all interface\n      units in an IEEE 802.3 LAN).\
    \ (See: gateway, internet, router.)\n   $ subordinate certification authority\
    \ (SCA)\n      (I) A CA whose public-key certificate is issued by another\n  \
    \    (superior) CA. (See: certification hierarchy.)\n      (O) MISSI usage: The\
    \ fourth-highest (bottom) level of a MISSI\n      certification hierarchy; a MISSI\
    \ CA whose public-key certificate\n      is signed by a MISSI CA rather than by\
    \ a MISSI PCA. A MISSI SCA is\n      the administrative authority for a subunit\
    \ of an organization,\n      established when it is desirable to organizationally\
    \ distribute or\n      decentralize the CA service. The term refers both to that\n\
    \      authoritative office or role, and to the person who fills that\n      office.\
    \ A MISSI SCA registers end users and issues their\n      certificates and may\
    \ also register ORAs, but may not register\n      other CAs. An SCA periodically\
    \ issues a CRL.\n   $ subordinate distinguished name\n      (I) An X.500 DN is\
    \ subordinate to another X.500 DN if it begins\n      with a set of attributes\
    \ that is the same as the entire second DN\n      except for the terminal attribute\
    \ of the second DN (which is\n      usually the name of a CA). For example, the\
    \ DN <C=FooLand, O=Gov,\n      OU=Treasurer, CN=DukePinchpenny> is subordinate\
    \ to the DN\n      <C=FooLand, O=Gov, CN=KingFooCA>.\n   $ superencryption\n \
    \     (I) An encryption operation for which the plaintext input to be\n      transformed\
    \ is the ciphertext output of a previous encryption\n      operation.\n   $ survivability\n\
    \      (I) The ability of a system to remain in operation or existence\n     \
    \ despite adverse conditions, including both natural occurrences,\n      accidental\
    \ actions, and attacks on the system. (See: availability,\n      reliability.)\n\
    \   $ symmetric cryptography\n      (I) A branch of cryptography involving algorithms\
    \ that use the\n      same key for two different steps of the algorithm (such\
    \ as\n      encryption and decryption, or signature creation and signature\n \
    \     verification). (See: asymmetric cryptography.)\n      (C) Symmetric cryptography\
    \ has been used for thousands of years\n      [Kahn]. A modern example of a symmetric\
    \ encryption algorithm is\n      the U.S. Government's Data Encryption Algorithm.\
    \ (See: DEA, DES.)\n      (C) Symmetric cryptography is sometimes called \"secret-key\n\
    \      cryptography\" (versus public-key cryptography) because the\n      entities\
    \ that share the key, such as the originator and the\n      recipient of a message,\
    \ need to keep the key secret. For example,\n      when Alice wants to ensure\
    \ confidentiality for data she sends to\n      Bob, she encrypts the data with\
    \ a secret key, and Bob uses the\n      same key to decrypt. Keeping the shared\
    \ key secret entails both\n      cost and risk when the key is distributed to\
    \ both Alice and Bob.\n      Thus, symmetric cryptography has a key management\
    \ disadvantage\n      compared to asymmetric cryptography.\n   $ symmetric key\n\
    \      (I) A cryptographic key that is used in a symmetric cryptographic\n   \
    \   algorithm.\n   $ SYN flood\n      (I) A denial of service attack that sends\
    \ a host more TCP SYN\n      packets (request to synchronize sequence numbers,\
    \ used when\n      opening a connection) than the protocol implementation can\
    \ handle.\n      (See: flooding.)\n   $ system\n      (C) In this Glossary, the\
    \ term is mainly used as an abbreviation\n      for \"automated information system\"\
    .\n   $ system entity\n      (I) An active element of a system--e.g., an automated\
    \ process, a\n      subsystem, a person or group of persons--that incorporates\
    \ a\n      specific set of capabilities.\n   $ system high\n      (I) The highest\
    \ security level supported by a system at a\n      particular time or in a particular\
    \ environment. (See: system high\n      security mode.)\n   $ system high security\
    \ mode\n      (I) A mode of operation of an information system, wherein all\n\
    \      users having access to the system possess a security clearance or\n   \
    \   authorization, but not necessarily a need-to-know, for all data\n      handled\
    \ by the system. (See: mode of operation.)\n      (C) This mode is defined formally\
    \ in U.S. Department of Defense\n      policy regarding system accreditation [DOD2],\
    \ but the term is\n      widely used outside the Defense Department and outside\
    \ the\n      Government.\n   $ system integrity\n      (I) \"The quality that\
    \ a system has when it can perform its\n      intended function in a unimpaired\
    \ manner, free from deliberate or\n      inadvertent unauthorized manipulation.\"\
    \ [NCS04] (See: system\n      integrity service.)\n   $ system integrity service\n\
    \      (I) A security service that protects system resources in a\n      verifiable\
    \ manner against unauthorized or accidental change, loss,\n      or destruction.\
    \ (See: system integrity.)\n   $ system low\n      (I) The lowest security level\
    \ supported by a system at a\n      particular time or in a particular environment.\
    \ (See: system\n      high.)\n   $ system resource\n      (I) Data contained in\
    \ an information system; or a service provided\n      by a system; or a system\
    \ capability, such as processing power or\n      communication bandwidth; or an\
    \ item of system equipment (i.e., a\n      system component--hardware, firmware,\
    \ software, or documentation);\n      or a facility that houses system operations\
    \ and equipment.\n   $ system security officer (SSO)\n      (I) A person responsible\
    \ for enforcement or administration of the\n      security policy that applies\
    \ to the system.\n   $ system verification\n      See: (secondary definition under)\
    \ verification.\n   $ TACACS\n   $ TACACS+\n      See: Terminal Access Controller\
    \ (TAC) Access Control System.\n   $ tamper\n      (I) Make an unauthorized modification\
    \ in a system that alters the\n      system's functioning in a way that degrades\
    \ the security services\n      that the system was intended to provide.\n   $\
    \ TCB\n      See: trusted computing base.\n   $ TCP\n      See: Transmission Control\
    \ Protocol.\n   $ TCP/IP\n      (I) A synonym for \"Internet Protocol Suite\"\
    , in which the\n      Transmission Control Protocol (TCP) and the Internet Protocol\
    \ (IP)\n      are important parts.\n   $ TCSEC\n      See: Trusted Computer System\
    \ Evaluation Criteria.\n   $ TELNET\n      (I) A TCP-based, application-layer,\
    \ Internet Standard protocol\n      [R0854] for remote login from one host to\
    \ another.\n   $ TEMPEST\n      (O) A nickname for specifications and standards\
    \ for limiting the\n      strength of electromagnetic emanations from electrical\
    \ and\n      electronic equipment and thus reducing vulnerability to\n      eavesdropping.\
    \ This term originated in the U.S. Department of\n      Defense. [Army, Kuhn,\
    \ Russ] (See: emanation security, soft\n      tempest.)\n      (D) ISDs SHOULD\
    \ NOT use this term as a synonym for\n      \"electromagnetic emanations security\"\
    .\n   $ Terminal Access Controller (TAC) Access Control System (TACACS)\n    \
    \  (I) A UDP-based authentication and access control protocol [R1492]\n      in\
    \ which a network access server receives an identifier and\n      password from\
    \ a remote terminal and passes them to a separate\n      authentication server\
    \ for verification.\n      (C) TACACS was developed for ARPANET and has evolved\
    \ for use in\n      commercial equipment. TACs were a type of network access server\n\
    \      computer used to connect terminals to the early Internet, usually\n   \
    \   using dial-up modem connections. TACACS used centralized\n      authentication\
    \ servers and served not only network access servers\n      like TACs but also\
    \ routers and other networked computing devices.\n      TACs are no longer in\
    \ use, but TACACS+ is. [R1983]\n       - \"XTACACS\": The name of Cisco Corporation's\
    \ implementation,\n         which enhances and extends the original TACACS.\n\
    \       - \"TACACS+\": A TCP-based protocol that improves on TACACS and\n    \
    \     XTACACS by separating the functions of authentication,\n         authorization,\
    \ and accounting and by encrypting all traffic\n         between the network access\
    \ server and authentication server. It\n         is extensible to allow any authentication\
    \ mechanism to be used\n         with TACACS+ clients.\n   $ TESS\n      See:\
    \ The Exponential Encryption System.\n   $ The Exponential Encryption System (TESS)\n\
    \      (I) A system of separate but cooperating cryptographic mechanisms\n   \
    \   and functions for the secure authenticated exchange of\n      cryptographic\
    \ keys, the generation of digital signatures, and the\n      distribution of public\
    \ keys. TESS employs asymmetric cryptography,\n      based on discrete exponentiation,\
    \ and a structure of self-\n      certified public keys. [R1824]\n   $ threat\n\
    \      (I) A potential for violation of security, which exists when there\n  \
    \    is a circumstance, capability, action, or event that could breach\n     \
    \ security and cause harm. (See: attack, threat action, threat\n      consequence.)\n\
    \      (C) That is, a threat is a possible danger that might exploit a\n     \
    \ vulnerability. A threat can be either \"intentional\" (i.e.,\n      intelligent;\
    \ e.g., an individual cracker or a criminal\n      organization) or \"accidental\"\
    \ (e.g., the possibility of a computer\n      malfunctioning, or the possibility\
    \ of an \"act of God\" such as an\n      earthquake, a fire, or a tornado).\n\
    \      (C) In some contexts, such as the following, the term is used\n      narrowly\
    \ to refer only to intelligent threats:\n      (N) U. S. Government usage: The\
    \ technical and operational\n      capability of a hostile entity to detect, exploit,\
    \ or subvert\n      friendly information systems and the demonstrated, presumed,\
    \ or\n      inferred intent of that entity to conduct such activity.\n   $ threat\
    \ action\n      (I) An assault on system security. (See: attack, threat, threat\n\
    \      consequence.)\n      (C) A complete security architecture deals with both\
    \ intentional\n      acts (i.e. attacks) and accidental events [FIPS31]. Various\
    \ kinds\n      of threat actions are defined as subentries under \"threat\n  \
    \    consequence\".\n   $ threat analysis\n      (I) An analysis of the probability\
    \ of occurrences and consequences\n      of damaging actions to a system.\n  \
    \ $ threat consequence\n      (I) A security violation that results from a threat\
    \ action.\n      Includes disclosure, deception, disruption, and usurpation. (See:\n\
    \      attack, threat, threat action.)\n      (C) The following subentries describe\
    \ four kinds of threat\n      consequences, and also list and describe the kinds\
    \ of threat\n      actions that cause each consequence. Threat actions that are\n\
    \      accidental events are marked by \"*\".\n      1. \"(Unauthorized) Disclosure\"\
    \ (a threat consequence): A\n         circumstance or event whereby an entity\
    \ gains access to data\n         for which the entity is not authorized. (See:\
    \ data\n         confidentiality.) The following threat actions can cause\n  \
    \       unauthorized disclosure:\n         A. \"Exposure\": A threat action whereby\
    \ sensitive data is\n            directly released to an unauthorized entity.\
    \ This includes:\n            a. \"Deliberate Exposure\": Intentional release\
    \ of sensitive\n               data to an unauthorized entity.\n            b.\
    \ \"Scavenging\": Searching through data residue in a system\n               to\
    \ gain unauthorized knowledge of sensitive data.\n            c* \"Human error\"\
    : Human action or inaction that\n               unintentionally results in an\
    \ entity gaining unauthorized\n               knowledge of sensitive data.\n \
    \           d* \"Hardware/software error\". System failure that results in\n \
    \              an entity gaining unauthorized knowledge of sensitive\n       \
    \        data.\n         B. \"Interception\": A threat action whereby an unauthorized\n\
    \            entity directly accesses sensitive data traveling between\n     \
    \       authorized sources and destinations. This includes:\n            a. \"\
    Theft\": Gaining access to sensitive data by stealing a\n               shipment\
    \ of a physical medium, such as a magnetic tape or\n               disk, that\
    \ holds the data.\n            b. \"Wiretapping (passive)\": Monitoring and recording\
    \ data\n               that is flowing between two points in a communication\n\
    \               system. (See: wiretapping.)\n            c. \"Emanations analysis\"\
    : Gaining direct knowledge of\n               communicated data by monitoring\
    \ and resolving a signal\n               that is emitted by a system and that\
    \ contains the data\n               but is not intended to communicate the data.\
    \ (See:\n               emanation.)\n         C. \"Inference\": A threat action\
    \ whereby an unauthorized entity\n            indirectly accesses sensitive data\
    \ (but not necessarily the\n            data contained in the communication) by\
    \ reasoning from\n            characteristics or byproducts of communications.\
    \ This\n            includes:\n            a. Traffic analysis: Gaining knowledge\
    \ of data by observing\n               the characteristics of communications that\
    \ carry the\n               data. (See: (main Glossary entry for) traffic analysis.)\n\
    \            b. \"Signals analysis\": Gaining indirect knowledge of\n        \
    \       communicated data by monitoring and analyzing a signal\n             \
    \  that is emitted by a system and that contains the data\n               but\
    \ is not intended to communicate the data. (See:\n               emanation.)\n\
    \         D. \"Intrusion\": A threat action whereby an unauthorized entity\n \
    \           gains access to sensitive data by circumventing a system's\n     \
    \       security protections. This includes:\n            a. \"Trespass\": Gaining\
    \ unauthorized physical access to\n               sensitive data by circumventing\
    \ a system's protections.\n            b. \"Penetration\": Gaining unauthorized\
    \ logical access to\n               sensitive data by circumventing a system's\
    \ protections.\n            c. \"Reverse engineering\": Acquiring sensitive data\
    \ by\n               disassembling and analyzing the design of a system\n    \
    \           component.\n            d. Cryptanalysis: Transforming encrypted data\
    \ into plaintext\n               without having prior knowledge of encryption\
    \ parameters\n               or processes. (See: (main Glossary entry for)\n \
    \              cryptanalysis.)\n      2. \"Deception\" (a threat consequence):\
    \ A circumstance or event\n         that may result in an authorized entity receiving\
    \ false data\n         and believing it to be true. The following threat actions\
    \ can\n         cause deception:\n         A. \"Masquerade\": A threat action\
    \ whereby an unauthorized entity\n            gains access to a system or performs\
    \ a malicious act by\n            posing as an authorized entity. (See: (main\
    \ Glossary entry\n            for) masquerade attack.)\n            a. \"Spoof\"\
    : Attempt by an unauthorized entity to gain access\n               to a system\
    \ by posing as an authorized user.\n            b. \"Malicious logic\": In context\
    \ of masquerade, any\n               hardware, firmware, or software (e.g., Trojan\
    \ horse) that\n               appears to perform a useful or desirable function,\
    \ but\n               actually gains unauthorized access to system resources or\n\
    \               tricks a user into executing other malicious logic. (See:\n  \
    \             (main Glossary entry for) malicious logic.)\n         B. \"Falsification\"\
    : A threat action whereby false data deceives\n            an authorized entity.\
    \ (See: active wiretapping.)\n            a. \"Substitution\": Altering or replacing\
    \ valid data with\n               false data that serves to deceive an authorized\
    \ entity.\n            b. \"Insertion\": Introducing false data that serves to\n\
    \               deceive an authorized entity.\n         C. \"Repudiation\": A\
    \ threat action whereby an entity deceives\n            another by falsely denying\
    \ responsibility for an act. (See:\n            non-repudiation service, (main\
    \ Glossary entry for)\n            repudiation.)\n            a. \"False denial\
    \ of origin\": Action whereby the originator\n               of data denies responsibility\
    \ for its generation.\n            b. \"False denial of receipt\": Action whereby\
    \ the recipient\n               of data denies receiving and possessing the data.\n\
    \      3. \"Disruption\" (a threat consequence): A circumstance or event\n   \
    \      that interrupts or prevents the correct operation of system\n         services\
    \ and functions. (See: denial of service.) The following\n         threat actions\
    \ can cause disruption:\n         A. \"Incapacitation\": A threat action that\
    \ prevents or\n            interrupts system operation by disabling a system component.\n\
    \            a. \"Malicious logic\": In context of incapacitation, any\n     \
    \          hardware, firmware, or software (e.g., logic bomb)\n              \
    \ intentionally introduced into a system to destroy system\n               functions\
    \ or resources. (See: (main Glossary entry for)\n               malicious logic.)\n\
    \            b. \"Physical destruction\": Deliberate destruction of a\n      \
    \         system component to interrupt or prevent system\n               operation.\n\
    \            c* \"Human error\": Action or inaction that unintentionally\n   \
    \            disables a system component.\n            d* \"Hardware or software\
    \ error\": Error that causes failure\n               of a system component and\
    \ leads to disruption of system\n               operation.\n            e* \"\
    Natural disaster\": Any \"act of God\" (e.g., fire, flood,\n               earthquake,\
    \ lightning, or wind) that disables a system\n               component. [FP031\
    \ section 2]\n         B. \"Corruption\": A threat action that undesirably alters\
    \ system\n            operation by adversely modifying system functions or data.\n\
    \            a. \"Tamper\": In context of corruption, deliberate alteration\n\
    \               of a system's logic, data, or control information to\n       \
    \        interrupt or prevent correct operation of system\n               functions.\n\
    \            b. \"Malicious logic\": In context of corruption, any\n         \
    \      hardware, firmware, or software (e.g., a computer virus)\n            \
    \   intentionally introduced into a system to modify system\n               functions\
    \ or data. (See: (main Glossary entry for)\n               malicious logic.)\n\
    \            c* \"Human error\": Human action or inaction that\n             \
    \  unintentionally results in the alteration of system\n               functions\
    \ or data.\n            d* \"Hardware or software error\": Error that results\
    \ in the\n               alteration of system functions or data.\n           \
    \ e* \"Natural disaster\": Any \"act of God\" (e.g., power surge\n           \
    \    caused by lightning) that alters system functions or\n               data.\
    \ [FP031 section 2]\n         C. \"Obstruction\": A threat action that interrupts\
    \ delivery of\n            system services by hindering system operations.\n \
    \           a. \"Interference\": Disruption of system operations by\n        \
    \       blocking communications or user data or control\n               information.\n\
    \            b. \"Overload\": Hindrance of system operation by placing\n     \
    \          excess burden on the performance capabilities of a system\n       \
    \        component. (See: flooding.)\n      4. \"Usurpation\" (a threat consequence):\
    \ A circumstance or event\n         that results in control of system services\
    \ or functions by an\n         unauthorized entity. The following threat actions\
    \ can cause\n         usurpation:\n         A. \"Misappropriation\": A threat\
    \ action whereby an entity\n            assumes unauthorized logical or physical\
    \ control of a system\n            resource.\n            a. \"Theft of service\"\
    : Unauthorized use of service by an\n               entity.\n            b. \"\
    Theft of functionality\": Unauthorized acquisition of\n               actual hardware,\
    \ software, or firmware of a system\n               component.\n            c.\
    \ \"Theft of data\": Unauthorized acquisition and use of\n               data.\n\
    \         B. \"Misuse\": A threat action that causes a system component to\n \
    \           perform a function or service that is detrimental to system\n    \
    \        security.\n            a. \"Tamper\": In context of misuse, deliberate\
    \ alteration of\n               a system's logic, data, or control information\
    \ to cause\n               the system to perform unauthorized functions or services.\n\
    \            b. \"Malicious logic\": In context of misuse, any hardware,\n   \
    \            software, or firmware intentionally introduced into a\n         \
    \      system to perform or control execution of an unauthorized\n           \
    \    function or service.\n            c. \"Violation of permissions\": Action\
    \ by an entity that\n               exceeds the entity's system privileges by\
    \ executing an\n               unauthorized function.\n   $ thumbprint\n     \
    \ (I) A pattern of curves formed by the ridges on the tip of a\n      thumb. (See:\
    \ biometric authentication, fingerprint.)\n      (D) ISDs SHOULD NOT use this\
    \ term as a synonym for \"hash result\"\n      because that meaning mixes concepts\
    \ in a potentially misleading\n      way.\n   $ ticket\n      (I) A synonym for\
    \ \"capability\". (See: Kerberos.)\n      (C) A ticket is usually granted by a\
    \ centralized access control\n      server (ticket-granting agent) to authorize\
    \ access to a system\n      resource for a limited time. Tickets have been implemented\
    \ with\n      symmetric cryptography, but can also be implemented as attribute\n\
    \      certificates using asymmetric cryptography.\n   $ timing channel\n    \
    \  See: (secondary definition under) covert channel.\n   $ TLS\n      See: Transport\
    \ Layer Security. (See: TLSP.)\n   $ TLSP\n      See: Transport Layer Security\
    \ Protocol. (See: TLS.)\n   $ token\n      1. (I) General usage: An object that\
    \ is used to control access and\n      is passed between cooperating entities\
    \ in a protocol that\n      synchronizes use of a shared resource. Usually, the\
    \ entity that\n      currently holds the token has exclusive access to the resource.\n\
    \      2. (I) Authentication usage: A data object or a portable, user-\n     \
    \ controlled, physical device used to verify an identity in an\n      authentication\
    \ process. (See: authentication information, dongle.)\n      3. (I) Cryptographic\
    \ usage: See: cryptographic token.\n      4. (O) SET usage: \"A portable device\
    \ [e.g., smart card or PCMCIA\n      card] specifically designed to store cryptographic\
    \ information and\n      possibly perform cryptographic functions in a secure\
    \ manner.\"\n      [SET2]\n   $ token backup\n      (I) A token management operation\
    \ that stores sufficient\n      information in a database (e.g., in a CAW) to\
    \ recreate or restore\n      a security token (e.g., a smart card) if it is lost\
    \ or damaged.\n   $ token copy\n      (I) A token management operation that copies\
    \ all the personality\n      information from one security token to another. However,\
    \ unlike in\n      a token restore operation, the second token is initialized\
    \ with\n      its own, different local security values such as PINs and storage\n\
    \      keys.\n   $ token management\n      (I) The process of initializing security\
    \ tokens (e.g., see: smart\n      card), loading data into the tokens, and controlling\
    \ the tokens\n      during their life cycle. May include performing key management\
    \ and\n      certificate management functions; generating and installing PINs;\n\
    \      loading user personality data; performing card backup, card copy,\n   \
    \   and card restore operations; and updating firmware.\n   $ token restore\n\
    \      (I) A token management operation that loads a security token with\n   \
    \   data for the purpose of recreating (duplicating) the contents\n      previously\
    \ held by that or another token.\n   $ token storage key\n      (I) A cryptography\
    \ key used to protect data that is stored on a\n      security token.\n   $ top\
    \ CA\n      (I) A CA that is the highest level (i.e., is the most trusted CA)\n\
    \      in a certification hierarchy. (See: root.)\n   $ top-level specification\n\
    \      (I) \"A non-procedural description of system behavior at the most\n   \
    \   abstract level; typically a functional specification that omits\n      all\
    \ implementation details.\" [NCS04] (See: (discussion under)\n      security policy.)\n\
    \      (C) A top-level specification may be descriptive or formal:\n       - \"\
    Descriptive top-level specification\": One that is written in a\n      natural\
    \ language like English or an informal design notation.\n       - \"Formal top-level\
    \ specification\": One that is written in a\n      formal mathematical language\
    \ to enable theorems to be proven that\n      show that the specification correctly\
    \ implements a set of formal\n      requirements or a formal security model. (See:\
    \ correctness proof.)\n   $ traffic analysis\n      (I) Inference of information\
    \ from observable characteristics of\n      data flow(s), even when the data is\
    \ encrypted or otherwise not\n      directly available. Such characteristics include\
    \ the identities\n      and locations of the source(s) and destination(s), and\
    \ the\n      presence, amount, frequency, and duration of occurrence. (See:\n\
    \      wiretapping.)\n      (O) \"The inference of information from observation\
    \ of traffic\n      flows (presence, absence, amount, direction, and frequency).\"\
    \n      [I7498 Part 2]\n   $ traffic flow confidentiality\n      (I) A data confidentiality\
    \ service to protect against traffic\n      analysis.\n      (O) \"A confidentiality\
    \ service to protect against traffic\n      analysis.\" [I7498 Part 2]\n   $ traffic\
    \ padding\n      (I) \"The generation of spurious instances of communication,\n\
    \      spurious data units, and/or spurious data within data units.\"\n      [I7498\
    \ Part 2]\n   $ tranquillity property\n      See: (secondary definition under)\
    \ Bell-LaPadula Model.\n   $ Transmission Control Protocol (TCP)\n      (I) An\
    \ Internet Standard protocol [R0793] that reliably delivers a\n      sequence\
    \ of datagrams (discrete sets of bits) from one computer to\n      another in\
    \ a computer network. (See: TCP/IP.)\n      (C) TCP is designed to fit into a\
    \ layered hierarchy of protocols\n      that support internetwork applications.\
    \ TCP assumes it can obtain\n      a simple, potentially unreliable datagram service\
    \ (such as the\n      Internet Protocol) from the lower-layer protocols.\n   $\
    \ Transport Layer Security (TLS)\n      (I) TLS Version 1.0 is an Internet protocol\
    \ [R2246] based-on and\n      very similar to SSL Version 3.0. (See: TLSP.)\n\
    \      (C) The TLS protocol is misnamed, because it operates well above\n    \
    \  the transport layer (OSI layer 4).\n   $ Transport Layer Security Protocol\
    \ (TLSP)\n      (I) An end-to-end encryption protocol(ISO Standard 10736) that\n\
    \      provides security services at the bottom of OSI layer 4, i.e.,\n      directly\
    \ above layer 3. (See: TLS.)\n      (C) TLSP evolved directly from the SP4 protocol\
    \ of SDNS.\n   $ transport mode vs. tunnel mode\n      (I) IPsec usage: Two ways\
    \ to apply IPsec protocols (AH and ESP) to\n      protect communications:\n  \
    \     - \"Transport mode\": The protection applies to (i.e., the IPsec\n     \
    \    protocol encapsulates) the packets of upper-layer protocols,\n         the\
    \ ones that are carried above IP.\n       - \"Tunnel mode\": The protection applies\
    \ to (i.e., the IPsec\n         protocol encapsulates) IP packets.\n      (C)\
    \ A transport mode security association is always between two\n      hosts. In\
    \ a tunnel mode security association, each end may be\n      either a host or\
    \ a gateway. Whenever either end of an IPsec\n      security association is a\
    \ security gateway, the association is\n      required to be in tunnel mode.\n\
    \   $ trap door\n      (I) A hidden computer flaw known to an intruder, or a hidden\n\
    \      computer mechanism (usually software) installed by an intruder,\n     \
    \ who can activate the trap door to gain access to the computer\n      without\
    \ being blocked by security services or mechanisms. (See:\n      back door, Trojan\
    \ horse.)\n   $ triple DES\n      (I) A block cipher, based on DES, that transforms\
    \ each 64-bit\n      plaintext block by applying the Data Encryption Algorithm\
    \ three\n      successive times, using either two or three different keys, for\
    \ an\n      effective key length of 112 or 168 bits. [A9052] (See: DES.)\n   \
    \   (C) IPsec usage: The algorithm variation proposed for ESP uses a\n      168-bit\
    \ key, consisting of three independent 56-bit quantities\n      used by the Data\
    \ Encryption Algorithm, and a 64-bit initialization\n      value. Each datagram\
    \ contains an IV to ensure that each received\n      datagram can be decrypted\
    \ even when other datagrams are dropped or\n      a sequence of datagrams is reordered\
    \ in transit. [R1851]\n   $ triple-wrapped\n      (I) S/MIME usage: Data that\
    \ has been signed with a digital\n      signature, and then encrypted, and then\
    \ signed again. [R2634]\n   $ Trojan horse\n      (I) A computer program that\
    \ appears to have a useful function, but\n      also has a hidden and potentially\
    \ malicious function that evades\n      security mechanisms, sometimes by exploiting\
    \ legitimate\n      authorizations of a system entity that invokes the program.\n\
    \   $ trust\n      1. (I) Information system usage: The extent to which someone\
    \ who\n      relies on a system can have confidence that the system meets its\n\
    \      specifications, i.e., that the system does what it claims to do\n     \
    \ and does not perform unwanted functions. (See: trust level.)\n      (C) \"trusted\
    \ vs. trustworthy\": In discussing a system or system\n      process or object,\
    \ this Glossary (and industry usage) prefers the\n      term \"trusted\" to describe\
    \ a system that operates as expected,\n      according to design and policy. When\
    \ the trust can also be\n      guaranteed in some convincing way, such as through\
    \ formal analysis\n      or code review, the system is termed \"trustworthy\"\
    ; this differs\n      from the ABA Guidelines definition (see: trustworthy system).\n\
    \      2. (I) PKI usage: A relationship between a certificate user and a\n   \
    \   CA in which the user acts according to the assumption that the CA\n      creates\
    \ only valid digital certificates.\n      (O) \"Generally, an entity can be said\
    \ to 'trust' a second entity\n      when it (the first entity) makes the assumption\
    \ that the second\n      entity will behave exactly as the first entity expects.\
    \ This trust\n      may apply only for some specific function. The key role of\
    \ trust\n      in [X.509] is to describe the relationship between an entity and\
    \ a\n      [certification] authority; an entity shall be certain that it can\n\
    \      trust the certification authority to create only valid and\n      reliable\
    \ certificates.\" [X509]\n   $ trust chain\n      (D) ISDs SHOULD NOT use this\
    \ term as a synonym for \"certification\n      path\" because it mixes concepts\
    \ in a potentially misleading way.\n      (See: trust.)\n   $ trust-file PKI\n\
    \      (I) A non-hierarchical PKI in which each certificate user has a\n     \
    \ local file (which is used by application software) of public-key\n      certificates\
    \ that the user trusts as starting points (i.e., roots)\n      for certification\
    \ paths. (See: hierarchical PKI, mesh PKI, root,\n      web of trust.)\n     \
    \ (C) For example, popular browsers are distributed with an initial\n      file\
    \ of trusted certificates, which often are self-signed\n      certificates. Users\
    \ can add certificates to the file or delete\n      from it. The file may be directly\
    \ managed by the user, or the\n      user's organization may manage it from a\
    \ centralized server.\n   $ trust hierarchy\n      (D) ISDs SHOULD NOT use this\
    \ term as a synonym for \"certification\n      hierarchy\" because this term mixes\
    \ concepts (see: trust) in a\n      potentially misleading way and duplicates\
    \ the meaning of another,\n      standardized term. (See: trust, web of trust.)\n\
    \   $ trust level\n      (I) A characterization of a standard of security protection\
    \ to be\n      met by a computer system.\n      (C) The TCSEC defines eight trust\
    \ levels. From the lowest to the\n      highest, they are D, C1, C2, B1, B2, B3,\
    \ and A1. A trust level is\n      based not only on the presence of security mechanisms\
    \ but also on\n      the use of systems engineering discipline to properly structure\n\
    \      the system and implementation analysis to ensure that the system\n    \
    \  provides an appropriate degree of trust.\n   $ trusted\n      See: (discussion\
    \ under) trust.\n   $ trusted certificate\n      (I) A certificate upon which\
    \ a certificate user relies as being\n      valid without the need for validation\
    \ testing; especially a\n      public-key certificate that is used to provide\
    \ the first public\n      key in a certification path. (See: certification path,\
    \ root\n      certificate, validation.)\n      (C) A trusted public-key certificate\
    \ might be (a) the root\n      certificate in a hierarchical PKI, (b) the certificate\
    \ of the CA\n      that issued the user's own certificate in a mesh PKI, or (c)\n\
    \      any certificate accepted by the user in a trust-file PKI.\n   $ trusted\
    \ computer system\n      (I) Multilevel security usage: \"A system that employs\
    \ sufficient\n      hardware and software assurance measures to allow its use\
    \ for\n      simultaneous processing of a range of sensitive or classified\n \
    \     information.\" [NCS04] (See: (discussion under) trust.)\n   $ Trusted Computer\
    \ System Evaluation Criteria (TCSEC)\n      (N) A standard for evaluating the\
    \ security provided by operating\n      systems [CSC001, DOD1]. Informally called\
    \ the \"Orange Book\"\n      because of the color of its cover; first document\
    \ in the Rainbow\n      Series. (See: Common Criteria, (usage note under) Green\
    \ Book,\n      Orange Book, trust level.)\n   $ trusted computing base (TCB)\n\
    \      (I) \"The totality of protection mechanisms within a computer\n      system,\
    \ including hardware, firmware, and software, the\n      combination of which\
    \ is responsible for enforcing a security\n      policy.\" [NCS04] (See: (discussion\
    \ of \"trusted\" under) trust.)\n   $ trusted distribution\n      (I) \"A trusted\
    \ method for distributing the TCB hardware, software,\n      and firmware components,\
    \ both originals and updates, that provides\n      methods for protecting the\
    \ TCB from modification during\n      distribution and for detection of any changes\
    \ to the TCB that may\n      occur.\" [NCS04]\n   $ trusted key\n      (I) A public\
    \ key upon which a user relies; especially a public key\n      that can be used\
    \ as the first public key in a certification path.\n      (See: certification\
    \ path, root key, validation.)\n      (C) A trusted public key might be (a) the\
    \ root key in a\n      hierarchical PKI, (b) the key of the CA that issued the\
    \ user's own\n      certificate in a mesh PKI, or (c) any key accepted by the\
    \ user in\n      a trust-file PKI.\n   $ trusted path\n      (I) COMPUSEC usage:\
    \ A mechanism by which a computer system user\n      can communicate directly\
    \ and reliably with the trusted computing\n      base (TCB) and that can only\
    \ be activated by the user or the TCB\n      and cannot be imitated by untrusted\
    \ software within the computer.\n      [NCS04]\n      (I) COMSEC usage: A mechanism\
    \ by which a person or process can\n      communicate directly with a cryptographic\
    \ module and that can only\n      be activated by the person, process, or module,\
    \ and cannot be\n      imitated by untrusted software within the module. [FP140]\n\
    \   $ trusted process\n      (I) A system process that has privileges that enable\
    \ it to affect\n      the state of system security and that can, therefore, through\n\
    \      incorrect or malicious execution, violate the system's security\n     \
    \ policy. (See: privileged process, (discussion of \"trusted\" under)\n      trust.)\n\
    \   $ trusted subnetwork\n      (I) A subnetwork containing hosts and routers\
    \ that trust each\n      other not to engage in active or passive attacks. (There\
    \ also is\n      an assumption that the underlying communication channels--e.g.,\n\
    \      telephone lines, or a LAN--are protected from attack by some\n      means.)\n\
    \   $ trusted system\n      See: (discussion under) trust, trusted computer system,\n\
    \      trustworthy system.\n   $ Trusted Systems Interoperability Group (TSIG)\n\
    \      (N) A forum of computer vendors, system integrators, and users\n      devoted\
    \ to promoting interoperability of trusted computer systems.\n      TSIG meetings\
    \ are open to all persons who are working in the\n      INFOSEC area.\n   $ trustworthy\
    \ system\n      (O) ABA usage: \"Computer hardware, software, and procedures that:\n\
    \      (a) are reasonably secure from intrusion and misuse; (b) provide a\n  \
    \    reasonably reliable level of availability, reliability, and\n      correct\
    \ operation; (c) are reasonably suited to performing their\n      intended functions;\
    \ and (d) adhere to generally accepted security\n      principles.\" [ABA] This\
    \ differs somewhat from other industry\n      usage. (See: (discussion of \"trusted\
    \ vs. trustworthy\" under)\n      trust.)\n   $ TSIG\n      See: Trusted System\
    \ Interoperability Group.\n   $ tunnel\n      (I) A communication channel created\
    \ in a computer network by\n      encapsulating (carrying, layering) a communication\
    \ protocol's data\n      packets in (on top of) a second protocol that normally\
    \ would be\n      carried above, or at the same layer as, the first one. (See:\
    \ L2TP,\n      VPN.)\n      (C) Tunneling can involve almost any OSI or TCP/IP\
    \ protocol\n      layers; for example, a TCP connection between two hosts could\n\
    \      conceivably be tunneled through email messages across the\n      Internet.\
    \ Most often, a tunnel is a logical point-to-point link--\n      i.e., an OSI\
    \ layer 2 connection--created by encapsulating the\n      layer 2 protocol in\
    \ a transport protocol (such as TCP), in a\n      network or internetwork layer\
    \ protocol (such as IP), or in another\n      link layer protocol. Often, encapsulation\
    \ is accomplished with an\n      extra, intermediate protocol, i.e., a tunneling\
    \ protocol (such as\n      L2TP) that is layered between the tunneled layer 2\
    \ protocol and\n      the encapsulating protocol.\n      (C) Tunneling can move\
    \ data between computers that use a protocol\n      not supported by the network\
    \ connecting them. Tunneling also can\n      enable a computer network to use\
    \ the services of a second network\n      as though the second network were a\
    \ set of point-to-point links\n      between the first network's nodes. (See:\
    \ virtual private network.)\n      (O) SET usage: The name of a SET private extension\
    \ that indicates\n      whether the CA or the payment gateway supports passing\
    \ encrypted\n      messages to the cardholder through the merchant. If so, the\n\
    \      extension lists OIDs of symmetric encryption algorithms that are\n    \
    \  supported.\n   $ tunnel mode\n      (I) IPsec usage: See: transport mode vs.\
    \ tunnel mode.\n   $ two-person control\n      (I) The close surveillance and\
    \ control of a system, process, or\n      materials (especially with regard to\
    \ cryptography) at all times by\n      a minimum of two appropriately authorized\
    \ persons, each capable of\n      detecting incorrect and unauthorized procedures\
    \ with respect to\n      the tasks to be performed and each familiar with established\n\
    \      security requirements. (See: dual control, no-lone zone.)\n   $ Type I\
    \ cryptography\n      (O) A cryptographic algorithm or device approved by NSA\
    \ for\n      protecting classified information.\n   $ Type II cryptography\n \
    \     (O) A cryptographic algorithm or device approved by NSA for\n      protecting\
    \ sensitive unclassified information (as specified in\n      section 2315 of Title\
    \ 10 United States Code, or section 3502(2) of\n      Title 44, United States\
    \ Code.)\n   $ Type III cryptography\n      (O) A cryptographic algorithm or device\
    \ approved as a Federal\n      Information Processing Standard.\n   $ UDP\n  \
    \    See: User Datagram Protocol.\n   $ unclassified\n      (I) Not classified.\n\
    \   $ unencrypted\n      (I) Not encrypted.\n   $ unforgeable\n      (I) Cryptographic\
    \ usage: The property of a cryptographic data\n      structure (i.e., a data structure\
    \ that is defined using one or\n      more cryptographic functions) that makes\
    \ it computationally\n      infeasible to construct (i.e., compute) an unauthorized\
    \ but\n      correct value of the structure without having knowledge of one of\n\
    \      more keys. (E.g., see: digital certificate.)\n      (C) This definition\
    \ is narrower than general English usage, where\n      \"unforgeable\" means unable\
    \ to be fraudulently created or\n      duplicated. In that broader sense, anyone\
    \ can forge a digital\n      certificate containing any set of data items whatsoever\
    \ by\n      generating the to-be-signed certificate and signing it with any\n\
    \      private key whatsoever. But for PKI purposes, the forged data\n      structure\
    \ is invalid if it is not signed with the true private key\n      of the claimed\
    \ issuer; thus, the forgery will be detected when a\n      certificate user uses\
    \ the true public key of the claimed issuer to\n      verify the signature.\n\
    \   $ uniform resource identifier (URI)\n      (I) A type of formatted identifier\
    \ that encapsulates the name of\n      an Internet object, and labels it with\
    \ an identification of the\n      name space, thus producing a member of the universal\
    \ set of names\n      in registered name spaces and of addresses referring to\
    \ registered\n      protocols or name spaces. [R1630]\n      (C) URIs are used\
    \ in HTML to identify the target of hyperlinks. In\n      common practice, URIs\
    \ include uniform resource locators [R2368]\n      and relative URLs, and may\
    \ be URNs. [R1808]\n   $ uniform resource locator (URL)\n      (I) A type of formatted\
    \ identifier that describes the access\n      method and location of an information\
    \ resource object on the\n      Internet. [R1738]\n      (C) A URL is a URI that\
    \ provides explicit instructions on how to\n      access the named object. For\
    \ example,\n      \"ftp://bbnarchive.bbn.com/foo/bar/picture/cambridge.zip\" is\
    \ a URL.\n      The part before the colon specifies the access scheme or protocol,\n\
    \      and the part after the colon is interpreted according to that\n      access\
    \ method. Usually, two slashes after the colon indicate the\n      host name of\
    \ a server (written as a domain name). In an FTP or\n      HTTP URL, the host\
    \ name is followed by the path name of a file on\n      the server. The last (optional)\
    \ part of a URL may be either a\n      fragment identifier that indicates a position\
    \ in the file, or a\n      query string.\n   $ uniform resource name (URN)\n \
    \     (I) A URI that has an institutional commitment to persistence and\n    \
    \  availability.\n   $ untrusted process\n      (I) A system process that is not\
    \ able to affect the state of\n      system security through incorrect or malicious\
    \ operation, usually\n      because its operation is confined by a security kernel.\
    \ (See:\n      trusted process.)\n   $ UORA\n      See: user-PIN ORA.\n   $ update\n\
    \      See: certificate update and key update.\n   $ URI\n      See: uniform resource\
    \ identifier.\n   $ URL\n      See: uniform resource locator.\n   $ URN\n    \
    \  See: uniform resource name.\n   $ user\n      (I) A person, organization entity,\
    \ or automated process that\n      accesses a system, whether authorized to do\
    \ so or not. (See:\n      [R2504].)\n      (C) Any ISD that uses this term SHOULD\
    \ provide an explicit\n      definition, because this term is used in many ways\
    \ and can easily\n      be misunderstood.\n   $ User Datagram Protocol (UDP)\n\
    \      (I) An Internet Standard protocol [R0768] that provides a datagram\n  \
    \    mode of packet-switched computer communication in an internetwork.\n    \
    \  (C) UDP is a transport layer protocol, and it assumes that IP is\n      the\
    \ underlying protocol. UDP enables application programs to send\n      transaction-oriented\
    \ data to other programs with minimal protocol\n      mechanism. UDP does not\
    \ provide reliable delivery, flow control,\n      sequencing, or other end-to-end\
    \ services that TCP provides.\n   $ user identifier\n      (I) A character string\
    \ or symbol that is used in a system to\n      uniquely name a specific user or\
    \ group of users.\n      (C) Often verified by a password in an authentication\
    \ process.\n   $ user PIN\n      (O) MISSI usage: One of two personal identification\
    \ numbers that\n      control access to the functions and stored data of a FORTEZZA\
    \ PC\n      card. Knowledge of the user PIN enables the card user to perform\n\
    \      the FORTEZZA functions that are intended for use by an end user.\n    \
    \  (See: SSO PIN.)\n   $ user-PIN ORA (UORA)\n      (O) A MISSI organizational\
    \ RA that operates in a mode in which the\n      ORA performs only the subset\
    \ of card management functions that are\n      possible with knowledge of the\
    \ user PIN for a FORTEZZA PC card.\n      (See: no-PIN ORA, SSO-PIN ORA.)\n  \
    \ $ usurpation\n      See: (secondary definition under) threat consequence.\n\
    \   $ UTCTime\n      (N) The ASN.1 data type \"UTCTime\" contains a calendar date\n\
    \      (YYMMDD) and a time to a precision of either one minute (HHMM) or\n   \
    \   one second (HHMMSS), where the time is either (a) Coordinated\n      Universal\
    \ Time or (b) the local time followed by an offset that\n      enables Coordinated\
    \ Universal Time to be calculated. Note: UTCTime\n      has the Year 2000 problem.\
    \ (See: Coordinated Universal Time,\n      GeneralizedTime.)\n   $ v1 certificate\n\
    \      (C) Ambiguously refers to either an X.509 public-key certificate\n    \
    \  in its version 1 format, or an X.509 attribute certificate in its\n      version\
    \ 1 format. However, many people who use this term are not\n      aware that X.509\
    \ specifies attribute certificates that do not\n      contain a public key. Therefore,\
    \ ISDs MAY use this term as an\n      abbreviation for \"version 1 X.509 public-key\
    \ certificate\", but\n      only after using the full term at the first instance.\n\
    \      (D) ISDs SHOULD NOT use this term as an abbreviation for \"version\n  \
    \    1 X.509 attribute certificate\".\n   $ v1 CRL\n      (I) An abbreviation\
    \ for \"X.509 CRL in version 1 format\".\n      (C) ISDs should use this abbreviation\
    \ only after using the full\n      term at its first occurrence and defining the\
    \ abbreviation.\n   $ v2 certificate\n      (I) An abbreviation for \"X.509 public-key\
    \ certificate in version 2\n      format\".\n      (C) ISDs should use this abbreviation\
    \ only after using the full\n      term at its first occurrence and defining the\
    \ abbreviation.\n   $ v2 CRL\n      (I) An abbreviation for \"X.509 CRL in version\
    \ 2 format\".\n      (C) ISDs should use this abbreviation only after using the\
    \ full\n      term at its first occurrence and defining the abbreviation.\n  \
    \ $ v3 certificate\n      (I) An abbreviation for \"X.509 public-key certificate\
    \ in version 3\n      format\".\n      (C) ISDs should use this abbreviation only\
    \ after using the full\n      term at its first occurrence and defining the abbreviation.\n\
    \   $ valid certificate\n      (I) A digital certificate for which the binding\
    \ of the data items\n      can be trusted; one that can be validated successfully.\
    \ (See:\n      validate vs. verify.)\n   $ valid signature\n      (D) ISDs SHOULD\
    \ NOT use this term; instead, use \"authentic\n      signature\". This Glossary\
    \ recommends saying \"validate the\n      certificate\" and \"verify the signature\"\
    ; therefore, it would be\n      inconsistent to say that a signature is \"valid\"\
    . (See: validate\n      vs. verify.)\n   $ validate vs. verify\n      (C) The\
    \ PKI community uses words inconsistently when describing\n      what a certificate\
    \ user does to make certain that a digital\n      certificate can be trusted.\
    \ Usually, we say \"verify the signature\"\n      but say \"validate the certificate\"\
    ; i.e., we \"verify\" atomic\n      truths but \"validate\" data structures, relationships,\
    \ and systems\n      that are composed of or depend on verified items. Too often,\n\
    \      however, verify and validate are used interchangeably.\n      ISDs SHOULD\
    \ comply with the following two rules to ensure\n      consistency and to align\
    \ Internet security terminology with\n      ordinary English:\n       - Rule 1:\
    \ Use \"validate\" when referring to a process intended to\n         establish\
    \ the soundness or correctness of a construct. (E.g.,\n         see: certificate\
    \ validation.)\n       - Rule 2: Use \"verify\" when referring to a process intended\
    \ to\n         test or prove the truth or accuracy of a fact or value. (E.g.,\n\
    \         see: authenticate.)\n      The rationale for Rule 1 is that \"valid\"\
    \ derives from a word that\n      means \"strong\" in Latin. Thus, to validate\
    \ means to make sure that\n      a construction is sound. A certificate user validates\
    \ a public-key\n      certificate to establish trust in the binding that the certificate\n\
    \      asserts between an identity and a key. (To validate can also mean\n   \
    \   to officially approve something; e.g., NIST validates\n      cryptographic\
    \ modules for conformance with FIPS PUB 140-1.)\n      The rationale for Rule\
    \ 2 is that \"verify\" derives from a word that\n      means \"true\" in Latin.\
    \ Thus, to verify means to prove the truth of\n      an assertion by examining\
    \ evidence or performing tests. To verify\n      an identity, an authentication\
    \ process examines identification\n      information that is presented or generated.\
    \ To validate a\n      certificate, a certificate user verifies the digital signature\
    \ on\n      the certificate by performing calculations; verifies that the\n  \
    \    current time is within the certificate's validity period; and may\n     \
    \ need to validate a certification path involving additional\n      certificates.\n\
    \   $ validation\n      See: validate vs. verify.\n   $ validity period\n    \
    \  (I) A data item in a digital certificate that specifies the time\n      period\
    \ for which the binding between data items (especially\n      between the subject\
    \ name and the public key value in a public-key\n      certificate) is valid,\
    \ except if the certificate appears on a CRL\n      or the key appears on a CKL.\n\
    \   $ value-added network (VAN)\n      (I) A computer network or subnetwork (which\
    \ is usually a\n      commercial enterprise) that transmits, receives, and stores\
    \ EDI\n      transactions on behalf of its customers.\n      (C) A VAN may also\
    \ provide additional services, ranging from EDI\n      format translation, to\
    \ EDI-to-FAX conversion, to integrated\n      business systems.\n   $ VAN\n  \
    \    See: value-added network.\n   $ verification\n      1. System verification:\
    \ The process of comparing two levels of\n      system specification for proper\
    \ correspondence, such as comparing\n      a security policy with a top-level\
    \ specification, a top-level\n      specification with source code, or source\
    \ code with object code.\n      [NCS04]\n      2. Identification verification:\
    \ Presenting information to\n      establish the truth of a claimed identity.\n\
    \   $ verify\n      See: validate vs. verify.\n   $ violation\n      See: security\
    \ violation.\n   $ virtual private network (VPN)\n      (I) A restricted-use,\
    \ logical (i.e., artificial or simulated)\n      computer network that is constructed\
    \ from the system resources of\n      a relatively public, physical (i.e., real)\
    \ network (such as the\n      Internet), often by using encryption (located at\
    \ hosts or\n      gateways), and often by tunneling links of the virtual network\n\
    \      across the real network.\n      (C) For example, if a corporation has LANs\
    \ at several different\n      sites, each connected to the Internet by a firewall,\
    \ the\n      corporation could create a VPN by (a) using encrypted tunnels to\n\
    \      connect from firewall to firewall across the Internet and (b) not\n   \
    \   allowing any other traffic through the firewalls. A VPN is\n      generally\
    \ less expensive to build and operate than a dedicated\n      real network, because\
    \ the virtual network shares the cost of\n      system resources with other users\
    \ of the real network.\n   $ virus\n      (I) A hidden, self-replicating section\
    \ of computer software,\n      usually malicious logic, that propagates by infecting--i.e.,\n\
    \      inserting a copy of itself into and becoming part of--another\n      program.\
    \ A virus cannot run by itself; it requires that its host\n      program be run\
    \ to make the virus active.\n   $ VPN\n      See: virtual private network.\n \
    \  $ vulnerability\n      (I) A flaw or weakness in a system's design, implementation,\
    \ or\n      operation and management that could be exploited to violate the\n\
    \      system's security policy.\n      (C) Most systems have vulnerabilities\
    \ of some sort, but this does\n      not mean that the systems are too flawed\
    \ to use. Not every threat\n      results in an attack, and not every attack succeeds.\
    \ Success\n      depends on the degree of vulnerability, the strength of attacks,\n\
    \      and the effectiveness of any countermeasures in use. If the\n      attacks\
    \ needed to exploit a vulnerability are very difficult to\n      carry out, then\
    \ the vulnerability may be tolerable. If the\n      perceived benefit to an attacker\
    \ is small, then even an easily\n      exploited vulnerability may be tolerable.\
    \ However, if the attacks\n      are well understood and easily made, and if the\
    \ vulnerable system\n      is employed by a wide range of users, then it is likely\
    \ that there\n      will be enough benefit for someone to make an attack.\n  \
    \ $ W3\n      See: World Wide Web.\n   $ war dialer\n      (I) A computer program\
    \ that automatically dials a series of\n      telephone numbers to find lines\
    \ connected to computer systems, and\n      catalogs those numbers so that a cracker\
    \ can try to break into the\n      systems.\n   $ Wassenaar Arrangement\n    \
    \  (N) The Wassenaar Arrangement on Export Controls for Conventional\n      Arms\
    \ and Dual-Use Goods and Technologies is a global, multilateral\n      agreement\
    \ approved by 33 countries in July 1996 to contribute to\n      regional and international\
    \ security and stability, by promoting\n      information exchange concerning,\
    \ and greater responsibility in,\n      transfers of arms and dual-use items,\
    \ thus preventing\n      destabilizing accumulations. (See: International Traffic\
    \ in Arms\n      Regulations.)\n      (C) The Arrangement began operations in\
    \ September 1996. The\n      participating countries are Argentina, Australia,\
    \ Austria,\n      Belgium, Bulgaria, Canada, Czech Republic, Denmark, Finland,\n\
    \      France, Germany, Greece, Hungary, Ireland, Italy, Japan,\n      Luxembourg,\
    \ Netherlands, New Zealand, Norway, Poland, Portugal,\n      Republic of Korea,\
    \ Romania, Russian Federation, Slovak Republic,\n      Spain, Sweden, Switzerland,\
    \ Turkey, Ukraine, United Kingdom, and\n      United States. Participants meet\
    \ on a regular basis in Vienna,\n      where the Arrangement has its headquarters.\n\
    \      Participating countries seek through their national policies to\n     \
    \ ensure that transfers do not contribute to the development or\n      enhancement\
    \ of military capabilities that undermine the goals of\n      the arrangement,\
    \ and are not diverted to support such\n      capabilities. The countries maintain\
    \ effective export controls for\n      items on the agreed lists, which are reviewed\
    \ periodically to\n      account for technological developments and experience\
    \ gained.\n      Through transparency and exchange of views and information,\n\
    \      suppliers of arms and dual-use items can develop common\n      understandings\
    \ of the risks associated with their transfer and\n      assess the scope for\
    \ coordinating national control policies to\n      combat these risks. Members\
    \ provide semi-annual notification of\n      arms transfers, covering seven categories\
    \ derived from the UN\n      Register of Conventional Arms. Members also report\
    \ transfers or\n      denials of transfers of certain controlled dual-use items.\n\
    \      However, the decision to transfer or deny transfer of any item is\n   \
    \   the sole responsibility of each participating country. All\n      measures\
    \ undertaken with respect to the arrangement are in\n      accordance with national\
    \ legislation and policies and are\n      implemented on the basis of national\
    \ discretion.\n   $ watermarking\n      See: digital watermarking.\n   $ web of\
    \ trust\n      (O) PGP usage: A trust-file PKI technique used in PGP for building\n\
    \      a file of validated public keys by making personal judgments about\n  \
    \    being able to trust certain people to be holding properly\n      certified\
    \ keys of other people. (See: certification hierarchy,\n      mesh PKI.)\n   $\
    \ web server\n      (I) A software process that runs on a host computer connected\
    \ to\n      the Internet to respond to HTTP requests for documents from client\n\
    \      web browsers.\n   $ web vs. Web\n      1. (I) Capitalized: ISDs SHOULD\
    \ capitalize \"Web\" when using the\n      term (as either a noun or an adjective)\
    \ to refer specifically to\n      the World Wide Web. (Similarly, see: internet\
    \ vs. Internet.)\n      2. (C) Not capitalized: ISDs SHOULD NOT capitalize \"\
    web\" when\n      using the term (usually as an adjective) to refer generically\
    \ to\n      technology--such as web browsers, web servers, HTTP, and HTML--\n\
    \      that is used in the Web or similar networks.\n      (C) IETF documents\
    \ SHOULD spell out \"World Wide Web\" fully at the\n      first instance of usage\
    \ and SHOULD Use \"Web\" and \"web\" especially\n      carefully where confusion\
    \ with the PGP \"web of trust\" is possible.\n   $ wiretapping\n      (I) An attack\
    \ that intercepts and accesses data and other\n      information contained in\
    \ a flow in a communication system.\n      (C) Although the term originally referred\
    \ to making a mechanical\n      connection to an electrical conductor that links\
    \ two nodes, it is\n      now used to refer to reading information from any sort\
    \ of medium\n      used for a link or even directly from a node, such as gateway\
    \ or\n      subnetwork switch.\n      (C) \"Active wiretapping\" attempts to alter\
    \ the data or otherwise\n      affect the flow; \"passive wiretapping\" only attempts\
    \ to observe\n      the flow and gain knowledge of information it contains. (See:\n\
    \      active attack, end-to-end encryption, passive attack.)\n   $ work factor\n\
    \      (I) General security usage: The estimated amount of effort or time\n  \
    \    that can be expected to be expended by a potential intruder to\n      penetrate\
    \ a system, or defeat a particular countermeasure, when\n      using specified\
    \ amounts of expertise and resources.\n      (I) Cryptography usage: The estimated\
    \ amount of computing time and\n      power needed to break a cryptographic system.\n\
    \   $ World Wide Web (\"the Web\", WWW, W3)\n      (N) The global, hypermedia-based\
    \ collection of information and\n      services that is available on Internet\
    \ servers and is accessed by\n      browsers using Hypertext Transfer Protocol\
    \ and other information\n      retrieval mechanisms. (See: web vs. Web, [R2084].)\n\
    \   $ worm\n      (I) A computer program that can run independently, can propagate\
    \ a\n      complete working version of itself onto other hosts on a network,\n\
    \      and may consume computer resources destructively. (See: Morris\n      Worm,\
    \ virus.)\n   $ wrap\n      (O) To use cryptography to provide data confidentiality\
    \ service\n      for a data object. (See: encrypt, seal.)\n      (D) ISDs SHOULD\
    \ NOT use this term with this definition because it\n      duplicates the meaning\
    \ of other, standard terms. Instead, use\n      \"encrypt\" or use a term that\
    \ is specific with regard to the\n      mechanism used.\n   $ WWW\n      See:\
    \ World Wide Web.\n   $ X.400\n      (N) An ITU-T Recommendation [X400] that is\
    \ one part of a joint\n      ITU-T/ISO multi-part standard (X.400-X.421) that\
    \ defines the\n      Message Handling Systems. (The ISO equivalent is IS 10021,\
    \ parts\n      1-7.) (See: Message Handling Systems.)\n   $ X.500\n   $ X.500\
    \ Directory\n      (N) An ITU-T Recommendation [X500] that is one part of a joint\n\
    \      ITU-T/ISO multi-part standard (X.500-X.525) that defines the X.500\n  \
    \    Directory, a conceptual collection of systems that provide\n      distributed\
    \ directory capabilities for OSI entities, processes,\n      applications, and\
    \ services. (The ISO equivalent is IS 9594-1 and\n      related standards, IS\
    \ 9594-x.) (See: directory vs. Directory,\n      X.509.)\n      (C) The X.500\
    \ Directory is structured as a tree (the Directory\n      Information Tree), and\
    \ information is stored in directory entries.\n      Each entry is a collection\
    \ of information about one object, and\n      each object has a DN. A directory\
    \ entry is composed of attributes,\n      each with a type and one or more values.\
    \ For example, if a PKI\n      uses the Directory to distribute certificates,\
    \ then the X.509\n      public-key certificate of an end user is normally stored\
    \ as a\n      value of an attribute of type \"userCertificate\" in the Directory\n\
    \      entry that has the DN that is the subject of the certificate.\n   $ X.509\n\
    \      (N) An ITU-T Recommendation [X509] that defines a framework to\n      provide\
    \ and support data origin authentication and peer entity\n      authentication\
    \ services, including formats for X.509 public-key\n      certificates, X.509\
    \ attribute certificates, and X.509 CRLs. (The\n      ISO equivalent is IS 9498-4.)\
    \ (See: X.500.)\n      (C) X.509 describes two levels of authentication: simple\n\
    \      authentication based on a password, and strong authentication\n      based\
    \ on a public-key certificate.\n   $ X.509 attribute certificate\n      (N) An\
    \ attribute certificate in the version 1 (v1) format defined\n      by X.509.\
    \ (The v1 designation for an X.509 attribute certificate\n      is disjoint from\
    \ the v1 designation for an X.509 public-key\n      certificate, and from the\
    \ v1 designation for an X.509 CRL.)\n      (C) An X.509 attribute certificate\
    \ has a subject field, but the\n      attribute certificate is a separate data\
    \ structure from that\n      subject's public-key certificate. A subject may have\
    \ multiple\n      attribute certificates associated with each of its public-key\n\
    \      certificates, and an attribute certificate may be issued by a\n      different\
    \ CA than the one that issued the associated public-key\n      certificate.\n\
    \      (C) An X.509 attribute certificate contains a sequence of data\n      items\
    \ and has a digital signature that is computed from that\n      sequence. In addition\
    \ to the signature, an attribute certificate\n      contains items 1 through 9\
    \ listed below:\n      1. version                Identifies v1.\n      2. subject\
    \                Is one of the following:\n         2a. baseCertificateID   -\
    \ Issuer and serial number of an\n                                   X.509 public-key\
    \ certificate.\n         2b. subjectName         - DN of the subject.\n      3.\
    \ issuer                 DN of the issuer (the CA who signed).\n      4. signature\
    \              OID of algorithm that signed the cert.\n      5. serialNumber \
    \          Certificate serial number;\n                                an integer\
    \ assigned by the issuer.\n      6. attCertValidityPeriod  Validity period; a\
    \ pair of UTCTime\n                                values: \"not before\" and\
    \ \"not after\".\n      7. attributes             Sequence of attributes describing\
    \ the\n                                subject.\n      8. issuerUniqueId     \
    \    Optional, when a DN is not sufficient.\n      9. extensions             Optional.\n\
    \   $ X.509 authority revocation list\n      (N) An ARL in one of the formats\
    \ defined by X.509--version 1 (v1)\n      or version 2 (v2). A specialized kind\
    \ of certificate revocation\n      list.\n   $ X.509 certificate\n      (N) Either\
    \ an X.509 public-key certificate or an X.509 attribute\n      certificate.\n\
    \      (C) This Glossary uses the term with the precise meaning\n      recommended\
    \ here. However, some who use the term may not be aware\n      that X.509 specifies\
    \ attribute certificates that do not contain a\n      public key. Even among those\
    \ who are aware, this term is commonly\n      used as an abbreviation to mean\
    \ \"X.509 public-key certificate\".\n      ISDs MAY use the term as an abbreviation\
    \ for \"X.509 public-key\n      certificate\", but only after using the full term\
    \ at the first\n      instance.\n      (D) ISDs SHOULD NOT use this term as an\
    \ abbreviation to mean\n      \"X.509 attribute certificate\".\n   $ X.509 certificate\
    \ revocation list (CRL)\n      (N) A CRL in one of the formats defined by X.509--version\
    \ 1 (v1)\n      or version 2 (v2). (The v1 and v2 designations for an X.509 CRL\n\
    \      are disjoint from the v1 and v2 designations for an X.509 public-\n   \
    \   key certificate, and from the v1 designation for an X.509\n      attribute\
    \ certificate.) (See: certificate revocation.)\n      (C) ISDs SHOULD NOT refer\
    \ to an X.509 CRL as a digital\n      certificate, but note that an X.509 CRL\
    \ does meet this Glossary's\n      definition of \"digital certificate\". Like\
    \ a digital certificate,\n      an X.509 CRL makes an assertion and is signed\
    \ by a CA. But instead\n      of binding a key or other attributes to a subject,\
    \ an X.509 CRL\n      asserts that certain previously-issued X.509 certificates\
    \ have\n      been revoked.\n      (C) An X.509 CRL contains a sequence of data\
    \ items and has a\n      digital signature computed on that sequence. In addition\
    \ to the\n      signature, both v1 and v2 contain items 2 through 6b listed below.\n\
    \      Version 2 contains item 1 and may optionally contain 6c and 7.\n      1.\
    \ version                Optional. If present, identifies v2.\n      2. signature\
    \              OID of the algorithm that signed CRL.\n      3. issuer        \
    \         DN of the issuer (the CA who signed).\n      4. thisUpdate         \
    \    A UTCTime value.\n      5. nextUpdate             A UTCTime value.\n    \
    \  6. revokedCertificates    3-tuples of 6a, 6b, and (optional) 6c:\n        \
    \ 6a. userCertificate    A certificate's serial number.\n         6b. revocationDate\
    \     UTCTime value for the revocation date.\n         6c. crlEntryExtensions\
    \ Optional.\n      7. crlExtensions          Optional.\n   $ X.509 public-key\
    \ certificate\n      (N) A public-key certificate in one of the formats defined\
    \ by\n      X.509--version 1 (v1), version 2 (v2), or version 3 (v3). (The v1\n\
    \      and v2 designations for an X.509 public-key certificate are\n      disjoint\
    \ from the v1 and v2 designations for an X.509 CRL, and\n      from the v1 designation\
    \ for an X.509 attribute certificate.)\n      (C) An X.509 public-key certificate\
    \ contains a sequence of data\n      items and has a digital signature computed\
    \ on that sequence. In\n      addition to the signature, all three versions contain\
    \ items 1\n      through 7 listed below. Only v2 and v3 certificates may also\n\
    \      contain items 8 and 9, and only v3 may contain item 10.\n      1. version\
    \                 Identifies v1, v2, or v3.\n      2. serialNumber           \
    \ Certificate serial number;\n                                 an integer assigned\
    \ by the issuer.\n      3. signature               OID of algorithm that was used\
    \ to\n                                 sign the certificate.\n      4. issuer\
    \                  DN of the issuer (the CA who signed).\n      5. validity  \
    \              Validity period; a pair of UTCTime\n                          \
    \       values: \"not before\" and \"not after\".\n      6. subject          \
    \       DN of entity who owns the public key.\n      7. subjectPublicKeyInfo \
    \   Public key value and algorithm OID.\n      8. issuerUniqueIdentifier  Defined\
    \ for v2, v3; optional.\n      9. subjectUniqueIdentifier Defined for v2, v2;\
    \ optional.\n      10. extensions             Defined only for v3; optional.\n\
    \   $ XTACACS\n      See: (secondary definition under) Terminal Access Controller\
    \ (TAC)\n      Access Control System.\n   $ Yellow Book\n      (D) ISDs SHOULD\
    \ NOT use this term as a synonym for \"Computer\n      Security Requirements:\
    \ Guidance for Applying the Department of\n      Defense Trusted Computer System\
    \ Evaluation Criteria in Specific\n      Environments\" [CSC3]. Instead, use the\
    \ full proper name of the\n      document or, in subsequent references, a conventional\n\
    \      abbreviation. (See: (usage note under) Green Book, Rainbow\n      Series.)\n\
    \   $ zeroize\n      (I) Use erasure or other means to render stored data unusable\
    \ and\n      unrecoverable, particularly a key stored in a cryptographic module\n\
    \      or other device.\n      (O) Erase electronically stored data by altering\
    \ the contents of\n      the data storage so as to prevent the recovery of the\
    \ data.\n      [FP140]\n"
- title: 4. References
  contents:
  - "4. References\n   This Glossary focuses on the Internet Standards Process. Therefore,\n\
    \   this set of references emphasizes international, governmental, and\n   industry\
    \ standards documents; only a few other texts are listed. RFCs\n   are listed,\
    \ but not Internet-Drafts, because the latter are not an\n   archival document\
    \ series and should not be cited or quoted in an RFC.\n   [A3092]  American National\
    \ Standards Institute, \"American National\n            Standard Data Encryption\
    \ Algorithm\", ANSI X3.92-1981, 30 Dec\n            1980.\n   [A9009]  ---, \"\
    Financial Institution Message Authentication\n            (Wholesale)\", ANSI\
    \ X9.9-1986, 15 Aug 1986.\n   [A9017]  ---, \"Financial Institution Key Management\
    \ (Wholesale)\",\n            X9.17, 4 Apr 1985. [Defines procedures for the manual\
    \ and\n            automated management of keying material and uses DES to\n \
    \           provide key management for a variety of operational\n            environments.]\n\
    \   [A9042]  ---, \"Public key Cryptography for the Financial Service\n      \
    \      Industry: Agreement of Symmetric Keys Using Diffie-Hellman\n          \
    \  and MQV Algorithms\", X9.42, 29 Jan 1999.\n   [A9052]  ---, \"Triple Data Encryption\
    \ Algorithm Modes of Operation\",\n            X9.52-1998, ANSI approval 9 Nov\
    \ 1998.\n   [A9062]  ---, \"Public Key Cryptography for the Financial Services\n\
    \            Industry: The Elliptic Curve Digital Signature Algorithm\n      \
    \      (ECDSA)\", X9.62-1998, ANSI approval 7 Jan 1999.\n   [ABA]    American\
    \ Bar Association, \"Digital Signature Guidelines:\n            Legal Infrastructure\
    \ for Certification Authorities and\n            Secure Electronic Commerce\"\
    , Chicago, IL, 1 Aug 1996.\n   [ACM]    Association for Computing Machinery, \"\
    Communications of the\n            ACM\", Jul 1998 issue with: Minerva M. Yeung,\
    \ \"Digital\n            Watermarking\"; Nasir Memom and Ping Wah Wong, \"Protecting\n\
    \            Digital Media Content\"; and Scott Craver, Boon-Lock Yeo, and\n \
    \           Minerva Yeung, \"Technical Trials and Legal Tribulations\".\n   [Army]\
    \   U.S. Army Corps of Engineers, \"Electromagnetic Pulse (EMP)\n            and\
    \ Tempest Protection for Facilities\", EP 1110-3-2, 31 Dec\n            1990.\n\
    \   [B7799]  British Standards Institution, \"Information Security\n         \
    \   Management, Part 1: Code of Practice for Information\n            Security\
    \ Management\", BS 7799-1:1999, effective 15 May 1999.\n            ---, ---,\
    \ \"Part 2: Specification for Information Security\n            Management Systems\"\
    , BS 7799-2:1999, effective 15 May 1999.\n   [Bell]   D. E. Bell and L. J. LaPadula,\
    \ \"Secure Computer Systems:\n            Mathematical Foundations and Model\"\
    , M74-244, The MITRE\n            Corporation, Bedford, MA, May 1973. (Available\
    \ as AD-771543,\n            National Technical Information Service, Springfield,\
    \ VA.)\n   [CCIB]   Common Criteria Implementation Board, \"Common Criteria for\n\
    \            Information Technology Security Evaluation, Part 1:\n           \
    \ Introduction and General Model\", ver. 2.1, CCIB-99-01, Aug\n            1999.\n\
    \   [CIPSO]  Trusted Systems Interoperability Working Group, \"Common IP\n   \
    \         Security Option\", ver. 2.3, 9 Mar 1993. [A \"work in\n            progress\"\
    \ that is probably defunct.]\n   [CSC1]   U.S. Department of Defense Computer\
    \ Security Center,\n            \"Department of Defense Trusted Computer System\
    \ Evaluation\n            Criteria\", CSC-STD-001-83, 15 Aug 1983. (Superseded\
    \ by\n            [DOD1].)\n   [CSC2]   ---, \"Department of Defense Password\
    \ Management Guideline\",\n            CSC-STD-002-85, 12 Apr 1985.\n   [CSC3]\
    \   ---, \"Computer Security Requirements: Guidance for Applying\n           \
    \ the Department of Defense Trusted Computer System Evaluation\n            Criteria\
    \ in Specific Environments\", CSC-STD-003-85, 25 Jun\n            1985.\n   [CSOR]\
    \   U.S. Department of Commerce, \"General Procedures for\n            Registering\
    \ Computer Security Objects\", National Institute\n            of Standards Interagency\
    \ Report 5308, Dec 1993.\n   [Denn]   D. E. Denning, \"A Lattice Model of Secure\
    \ Information Flow\",\n            in \"Communications of the ACM\", vol. 19,\
    \ no. 5, May 1976,\n            pp. 236-243.\n   [DH76]   W. Diffie and M. H.\
    \ Hellman, \"New Directions in\n            Cryptography\" in \"IEEE Transactions\
    \ on Information Theory\",\n            vol. IT-22, no. 6, Nov 1976, pp. 644-654.\n\
    \   [DOD1]   U.S. Department of Defense, \"Department of Defense Trusted\n   \
    \         Computer System Evaluation Criteria\", DoD 5200.28-STD, 26\n       \
    \     Dec 1985. (Supersedes [CSC1].)\n   [DOD2]   ---, Directive 5200.28, \"Security\
    \ Requirements for Automated\n            Information Systems (AISs)\", 21 Mar\
    \ 1988.\n   [DOD3]   ---, \"X.509 Certificate Policy\", ver. 2, Mar 1999.\n  \
    \ [DOD4]   ---, \"NSA Key Recovery Assessment Criteria\", 8 Jun 1998.\n   [ElGa]\
    \   T. El Gamal, \"A Public-Key Cryptosystem and a Signature\n            Scheme\
    \ Based on Discrete Logarithms\" in \"IEEE Transactions\n            on Information\
    \ Theory\", vol. IT-31, no. 4, 1985, pp. 469-\n            472.\n   [EMV1]   Europay\
    \ International S.A., MasterCard International\n            Incorporated, and\
    \ Visa International Service Association,\n            \"EMV '96 Integrated Circuit\
    \ Card Specification for Payment\n            Systems\", ver. 3.1.1, 31 May 1998.\n\
    \   [EMV2]   ---, \"EMV '96 Integrated Circuit Card Terminal Specification\n \
    \           for Payment Systems\", ver. 3.1.1, 31 May 1998.\n   [EMV3]   ---,\
    \ EMV '96 Integrated Circuit Card Application\n            Specification for Payment\
    \ Systems\", ver. 3.1.1, 31 May 1998.\n   [For94]  W. Ford, \"Computer Communications\
    \ Security: Principles,\n            Standard Protocols and Techniques\", ISBN\
    \ 0-13-799453-2,\n            1994.\n   [For97]  W. Ford and M. Baum, \"Secure\
    \ Electronic Commerce: Building\n            the Infrastructure for Digital Signatures\
    \ and Encryption\",\n            ISBN 0-13-476342-4, 1994.\n   [FP031]  U.S. Department\
    \ of Commerce, \"Guidelines for Automatic Data\n            Processing Physical\
    \ Security and Risk Management\", Federal\n            Information Processing\
    \ Standards Publication (FIPS PUB) 31,\n            Jun 1974.\n   [FP039]  ---,\
    \ \"Glossary for Computer Systems Security\", FIPS PUB 39,\n            15 Feb\
    \ 1976.\n   [FP046]  ---, \"Data Encryption Standard (DES)\", FIPS PUB 46-2, 30\
    \ Dec\n            1993.\n   [FP081]  ---, \"DES Modes of Operation\", FIPS PUB\
    \ 81, 2 Dec 1980.\n   [FP102]  ---, \"Guideline for Computer Security Certification\
    \ and\n            Accreditation\", FIPS PUB 102, 27 Sep 1983.\n   [FP113]  ---,\
    \ \"Computer Data Authentication\", FIPS PUB 113, 30 May\n            1985.\n\
    \   [FP140]  ---, \"Security Requirements for Cryptographic Modules\", FIPS\n\
    \            PUB 140-1, 11 Jan 1994.\n   [FP151]  ---, \"Portable Operating System\
    \ Interface (POSIX)--System\n            Application Program Interface [C Language]\"\
    , FIPS PUB 151-2,\n            12 May 1993\n   [FP180]  ---, \"Secure Hash Standard\"\
    , FIPS PUB 180-1, 17 Apr 1995.\n   [FP185]  ---, \"Escrowed Encryption Standard\"\
    , FIPS PUB 185, 9 Feb\n            1994.\n   [FP186]  ---, \"Digital Signature\
    \ Standard (DSS)\", FIPS PUB 186, 19\n            May 1994.\n   [FP188]  ---,\
    \ \"Standard Security Label for Information Transfer\",\n            FIPS PUB\
    \ 188, 6 Sep 1994.\n   [FPDAM]  Collaborative ITU and ISO/IEC meeting on the Directory,\n\
    \            \"Final Proposed Draft Amendment on Certificate Extensions\",\n \
    \           April 1999. (This draft proposes changes to [X.509].)\n   [FPKI] \
    \  U.S. Department of Commerce, \"Public Key Infrastructure\n            (PKI)\
    \ Technical Specifications: Part A--Technical Concept of\n            Operations\"\
    , National Institute of Standards, 4 Sep 1998.\n   [I3166]  International Standards\
    \ Organization, \"Codes for the\n            Representation of Names of countries\
    \ and Their Subdivisions\n            --Part 1: Country Codes\", ISO 3166-1:1997.\n\
    \            ---, --- \"Part 2: Country Subdivision Codes\", ISO/DIS 3166-\n \
    \           2.\n            ---, --- \"Part 3: Codes for Formerly Used Names of\n\
    \            Countries\", ISO/DIS 3166-3.\n   [I7498]  ---, \"Information Processing\
    \ Systems--Open Systems\n            Interconnection Reference Model--[Part 1:]\
    \ Basic Reference\n            Model\", ISO/IEC 7498-1. (Equivalent to ITU-T Recommendation\n\
    \            X.200.)\n            ---, --- \"Part 2: Security Architecture\",\
    \ ISO/IEC 7499-2.\n            ---, --- \"Part 4: Management Framework\", ISO/IEC\
    \ 7498-4.\n   [I7812]  ---, \"Identification cards--Identification of Issuers--Part\n\
    \            1: Numbering System\", ISO/IEC 7812-1:1993\n            ---, ---\
    \ \"Part 2: Application and Registration Procedures\",\n            ISO/IEC 7812-2:1993.\n\
    \   [I9945]  ---, \"Portable Operating System Interface for Computer\n       \
    \     Environments\", ISO/IEC 9945-1:1990.\n   [I15408] ---, \"Information Technology--Security\
    \ Techniques--\n            Evaluation criteria for IT Security--Part 1: Introduction\n\
    \            and General Model\", ISO/IEC 15408-1:1999.\n   [ITSEC]  \"Information\
    \ Technology Security Evaluation Criteria\n            (ITSEC): Harmonised Criteria\
    \ of France, Germany, the\n            Netherlands, and the United Kingdom\",\
    \ ver. 1.2, U.K.\n            Department of Trade and Industry, Jun 1991.\n  \
    \ [Kahn]   David Kahn, \"The Codebreakers: The Story of Secret Writing\",\n  \
    \          The Macmillan Company, New York, 1967.\n   [Knuth]  D. E. Knuth, Chapter\
    \ 3 (\"Random Numbers\") in Volume 2\n            (\"Seminumerical Algorithms\"\
    ) of \"The Art of Computer\n            Programming\", Addison-Wesley, Reading,\
    \ MA, 1969.\n   [Kuhn]   Markus G. Kuhn and Ross J. Anderson, \"Soft Tempest:\
    \ Hidden\n            Data Transmission Using Electromagnetic Emanations\", in\n\
    \            David Aucsmith, ed., \"Information Hiding, Second\n            International\
    \ Workshop, IH'98\", Portland, Oregon, USA, 15-17\n            Apr 1998, LNCS\
    \ 1525, Springer-Verlag, ISBN 3-540-65386-4,\n            pp. 124-142.\n   [MISPC]\
    \  U.S. Department of Commerce, \"Minimum Interoperability\n            Specification\
    \ for PKI Components (MISPC), Version 1\",\n            National Institute of\
    \ Standards Special Publication 800-15,\n            Sep 1997.\n   [NCS01]  National\
    \ Computer Security Center, \"A Guide to Understanding\n            Audit in Trusted\
    \ Systems\", NCSC-TG-001, 1 Jun 1988. (Part of\n            the Rainbow Series.)\n\
    \   [NCS04]  ---, \"Glossary of Computer Security Terms\", NCSC-TG-004,\n    \
    \        ver. 1, 21 Oct 1988. (Part of the Rainbow Series.)\n   [NCS05]  ---,\
    \ \"Trusted Network Interpretation of the Trusted Computer\n            System\
    \ Evaluation Criteria\", NCSC-TG-005, ver. 1, 31 Jul\n            1987. (Part\
    \ of the Rainbow Series.)\n   [NCS25]  ---, \"A Guide to Understanding Data Remanence\
    \ in Automated\n            Information Systems\", NCSC-TG-025, ver. 2, Sep 1991.\
    \ (Part\n            of the Rainbow Series.)\n   [NIST]   National Institute of\
    \ Standards and Technology, \"SKIPJACK\n            and KEA Algorithm Specifications\"\
    , ver. 2, 29 May 1998.\n            (http://csrc.nist.gov/encryption/skipjack-kea.htm)\n\
    \   [PGP]    Simson Garfinkel, \"PGP: Pretty Good Privacy\", O'Reilly &\n    \
    \        Associates, Inc., Sebastopol, CA, 1995.\n   [PKCS]   Burton S. Kaliski,\
    \ Jr., \"An Overview of the PKCS Standards\",\n            RSA Data Security,\
    \ Inc., 3 Jun 1991.\n   [PKC07]  RSA Laboratories, \"PKCS #7: Cryptographic Message\
    \ Syntax\n            Standard\", ver. 1.5, RSA Laboratories Technical Note, 1\
    \ Nov\n            1993.\n   [PKC10]  ---, \"PKCS #10: Certification Request Syntax\
    \ Standard\", ver.\n            1.0, RSA Laboratories Technical Note, 1 Nov 1993.\n\
    \   [PKC11]  ---, \"PKCS #11: Cryptographic Token Interface Standard\",\n    \
    \        ver. 1.0, 28 Apr 1995.\n   [R0768]  Postel, J., \"User Datagram Protocol\"\
    , STD 6, RFC 768, August\n            1980.\n   [R0791]  Postel, J., \"Internet\
    \ Protocol\", STD 5, RFC 791, September\n            1981.\n   [R0792]  Postel,\
    \ J., \"Internet Control Message Protocol\", STD 5, RFC\n            792, September\
    \ 1981. [See: RFC 1885.]\n   [R0793]  Postel, J., ed., \"Transmission Control\
    \ Protocol\", STD 7, RFC\n            793, September 1981.\n   [R0821]  Postel,\
    \ J., \"Simple Mail Transfer Protocol\", STD 10, RFC\n            821, August\
    \ 1982.\n   [R0822]  Crocker, D., \"Standard for the Format of ARPA Internet Text\n\
    \            Messages\", STD 11, RFC 822, August 1982.\n   [R0854]  Postel, J.\
    \ and J. Reynolds, \"TELNET Protocol Specification\",\n            STD 8, RFC\
    \ 854, May 1983.\n   [R0959]  Postel, J. and J. Reynolds, \"File Transfer Protocol\
    \ (FTP)\",\n            STD 9, RFC 959, October 1985.\n   [R1034]  Mockapetris,\
    \ P., \"Domain Names--Concepts and Facilities\",\n            STD 13, RFC 1034,\
    \ November 1987.\n   [R1157]  Case, J., Fedor, M., Schoffstall, M. and J. Davin,\
    \ \"A Simple\n            Network Management Protocol (SNMP)\" [version 1], STD\
    \ 15, RFC\n            1157, May 1990.\n   [R1208]  Jacobsen O. and D. Lynch,\
    \ \"A Glossary of Networking Terms\",\n            RFC 1208, March 1991.\n   [R1319]\
    \  Kaliski, B., \"The MD2 Message-Digest Algorithm\", RFC 1319,\n            April\
    \ 1992.\n   [R1320]  Rivest, R., \"The MD4 Message-Digest Algorithm\", RFC 1320,\n\
    \            April 1992.\n   [R1321]  Rivest, R., \"The MD5 Message-Digest Algorithm\"\
    , RFC 1321,\n            April 1992.\n   [R1334]  Lloyd, B. and W. Simpson, \"\
    PPP Authentication Protocols\",\n            RFC 1334, October 1992.\n   [R1413]\
    \  St. Johns, M., \"Identification Protocol\", RFC 1413, February\n          \
    \  1993.\n   [R1421]  Linn, J., \"Privacy Enhancement for Internet Electronic\
    \ Mail,\n            Part I: Message Encryption and Authentication Procedures\"\
    ,\n            RFC 1421, February 1993.\n   [R1422]  Kent, S., \"Privacy Enhancement\
    \ for Internet Electronic Mail,\n            Part II: Certificate-Based Key Management\"\
    , RFC 1422,\n            February 1993.\n   [R1455]  Eastlake, D., \"Physical\
    \ Link Security Type of Service\", RFC\n            1455, May 1993.\n   [R1457]\
    \  Housley, R., \"Security Label Framework for the Internet\",\n            RFC\
    \ 1457, May 1993.\n   [R1492]  Finseth, C., \"An Access Control Protocol, Sometimes\
    \ Called\n            TACACS\", RFC 1492, July 1993.\n   [R1507]  Kaufman, C.,\
    \ \"DASS: Distributed Authentication Security\n            Service\", RFC 1507,\
    \ September 1993.\n   [R1510]  Kohl, J. and C. Neuman, \"The Kerberos Network\
    \ Authentication\n            Service (V5)\", RFC 1510, September 1993.\n   [R1591]\
    \  Kohl, J. and C. Neuman, \"Domain Name System Structure and\n            Delegation\"\
    , March 1994.\n   [R1630]  Berners-Lee, T., \"Universal Resource Identifiers in\
    \ WWW\",\n            RFC 1630, June 1994.\n   [R1661]  Simpson, W., ed., \" The\
    \ Point-to-Point Protocol (PPP)\", STD\n            51, RFC 1661, July 1994.\n\
    \   [R1731]  Myers, J., \"IMAP4 Authentication Mechanisms\", RFC 1731,\n     \
    \       December 1994.\n   [R1734]  Myers, J., \"POP3 AUTHentication Command\"\
    , RFC 1734, December\n            1994.\n   [R1738]  Myers, J., Masinter, L. and\
    \ M. McCahill, ed's., \"Uniform\n            Resource Locators (URL)\", RFC 1738,\
    \ December 1994.\n   [R1750]  Eastlake, D., Crocker, S. and J. Schiller, \"Randomness\n\
    \            Recommendations for Security\", RFC 1750, December 1994.\n   [R1777]\
    \  Yeong, W., Howes, T. and S. Kille, \"Lightweight Directory\n            Access\
    \ Protocol\", RFC 1777, March 1995.\n   [R1808]  Fielding, R., \"Relative Uniform\
    \ Resource Locators\", RFC\n            1808, June 1995.\n   [R1824]  Danisch,\
    \ H., \"The Exponential Security System TESS: An\n            Identity-Based Cryptographic\
    \ Protocol for Authenticated Key-\n            Exchange (E.I.S.S.-Report 1995/4)\"\
    , RFC 1824, August 1995.\n   [R1828]  Metzger, P. and W. Simpson, \"IP Authentication\
    \ using Keyed\n            MD5\", RFC 1828, August 1995.\n   [R1829]  Karn, P.,\
    \ Metzger, P. and W. Simpson, \"The ESP DES-CBC\n            Transform\", RFC\
    \ 1829, August 1995.\n   [R1848]  Crocker, S., Freed, N., Galvin, J. and S. Murphy,\
    \ \"MIME\n            Object Security Services\", RFC 1848, October 1995.\n  \
    \ [R1851]  Karn, P., Metzger, P. and W. Simpson, \"The ESP Triple DES\n      \
    \      Transform\", RFC 1851, September 1995.\n   [R1866]  Berners-Lee, T., \"\
    Hypertext Markup Language--2.0\", RFC 1866,\n            November 1995.\n   [R1885]\
    \  Conta, A. and S. Deering, \"Internet Control Message Protocol\n           \
    \ (ICMPv6) for the Internet Protocol Version 6 (IPv6)\n            Specification\"\
    , RFC 1885, December 1995.\n   [R1928]  Leech, M., Ganis, M., Lee, Y., Kuris,\
    \ R., Koblas, D. and L.\n            Jones, \"SOCKS Protocol Version 5\", RFC\
    \ 1928, March 1996.\n   [R1938]  Haller, N. and C. Metzion, \"A One-Time Password\
    \ System\", RFC\n            1938, May 1996.\n   [R1939]  Myers, J. and M. Rose,\
    \ \"Post Office Protocol - Version 3\",\n            STD 53, RFC 1939, May 1996.\n\
    \   [R1958]  Carpenter, B., ed., \"Architectural Principles of the\n         \
    \   Internet\", RFC 1958, June 1996.\n   [R1983]  Malkin, G., ed., \"Internet\
    \ Users' Glossary\", FYI 18, RFC\n            1983, August 1996.\n   [R1994] \
    \ Simpson, W. \"PPP Challenge Handshake Authentication Protocol\n            (CHAP)\"\
    , RFC 1994, August 1996.\n   [R2023]  Postel, J. and J. Reynolds, \"Instructions\
    \ to RFC Authors\",\n            RFC 2023, October 1997.\n   [R2026]  Bradner,\
    \ S., \"The Internet Standards Process--Revision 3\",\n            BCP 9, RFC\
    \ 2026, March 1994.\n   [R2045]  Freed, N. and N. Borenstein, \"Multipurpose Internet\
    \ Mail\n            Extensions (MIME) Part One: Format of Internet Message\n \
    \           Bodies\", RFC 2045, November 1996.\n   [R2060]  Crispin, M., \"Internet\
    \ Message Access Protocol--Version 4\n            Revision 1\", RFC 2060, December\
    \ 1996.\n   [R2065]  Eastlake, D., 3rd, \"Domain Name System Security Extensions\"\
    ,\n            RFC 2065, January 1997.\n   [R2078]  Linn, J., \"Generic Security\
    \ Service Application Program\n            Interface, Version 2\", RFC 2078, January\
    \ 1997.\n   [R2084]  Bossert, G., Cooper, S. and W. Drummond, \"Considerations\
    \ for\n            Web Transaction Security\", RFC 2084, January 1997.\n   [R2104]\
    \  Krawczyk, H., Bellare, M. and R. Canetti, \"HMAC: Keyed-\n            Hashing\
    \ for Message Authentication\", RFC 2104, February\n            1997.\n   [R2119]\
    \  Bradner, S., \"Key Words for Use in RFCs To Indicate\n            Requirement\
    \ Levels\", BCP 14, RFC 2119, March 1997.\n   [R2138]  Rigney, C., Rubens, A.,\
    \ Simpson, W. and S. Willens, \"Remote\n            Authentication Dial In User\
    \ Service (RADIUS)\", RFC 2138,\n            April 1997.\n   [R2137]  Eastlake,\
    \ D., \"Secure Domain Name System Dynamic Update\",\n            RFC 2137, April\
    \ 1997.\n   [R2179]  Gwinn, A., \"Network Security For Trade Shows\", RFC 2179,\n\
    \            July 1997.\n   [R2195]  Klensin, J., Catoe, R. and P. Krumviede,\
    \ \"IMAP/POP AUTHorize\n            Extension for Simple Challenge/Response\"\
    , RFC 2195, Sepember\n            1997.\n   [R2196]  Fraser, B., \"Site Security\
    \ Handbook\", FYI 8, RFC 2196,\n            Sepember 1997.\n   [R2202]  Cheng,\
    \ P. and R. Glenn, \"Test Cases for HMAC-MD5 and HMAC-\n            SHA-1\", RFC\
    \ 2202, Sepember 1997.\n   [R2222]  Myers, J., \"Simple Authentication and Security\
    \ Layer\n            (SASL)\", RFC 2222, October 1997.\n   [R2223]  Postel, J.,\
    \ \"Instructions to RFC Authors\", RFC 2223, October\n            1997.\n   [R2246]\
    \  Dierks, T. and C. Allen, \"The TLS Protocol, Version 1.0\",\n            RFC\
    \ 2246, January 1999.\n   [R2284]  Blunk, L. and J. Vollbrecht, \"PPP Extensible\
    \ Authentication\n            Protocol (EAP)\", RFC 2284, March 1998.\n   [R2315]\
    \  Kaliski, B., \"PKCS #7: Cryptographic Message Syntax, Version\n           \
    \ 1.5\", RFC 2315, March 1998.\n   [R2323]  Ramos, A., \"IETF Identification and\
    \ Security Guidelines\",\n            RFC 2323, 1 April 1998. [Intended for humorous\
    \ entertainment\n            (\"please laugh loud and hard\"); does not contain\
    \ serious\n            security information.]\n   [R2350]  Brownlee, N. and E.\
    \ Guttman, \"Expectations for Computer\n            Security Incident Response\"\
    , RFC 2350, June 1998.\n   [R2356]  Montenegro, C. and V. Gupta, \"Sun's SKIP\
    \ Firewall Traversal\n            for Mobile IP\", RFC 2356, June 1998.\n   [R2373]\
    \  Hinden, R. and S. Deering, \"IP Version 6 Addressing\n            Architecture\"\
    , RFC 2373, July 2998.\n   [R2401]  Kent, S. and R. Atkinson, \"Security Architecture\
    \ for the\n            Internet Protocol\", RFC 2401, November 1998.\n   [R2402]\
    \  Kent, S. and R. Atkinson, \"IP Authentication Header\", RFC\n            2402,\
    \ November 1998.\n   [R2403]  Madson, C. and R. Glenn, \"The Use of HMAC-MD5-96\
    \ within ESP\n            and AH\", RFC 2403, November 1998.\n   [R2404]  Madson,\
    \ C. and R. Glenn, \"The Use of HMAC-SHA-1-96 within\n            ESP and AH\"\
    , RFC 2404, November 1998.\n   [R2405]  Madson, C. and N. Doraswamy, \"The ESP\
    \ DES-CBC Cipher\n            Algorithm With Explicit IV\", RFC 2405, November\
    \ 1998.\n   [R2406]  Kent, S. and R. Atkinson, \"IP Encapsulating Security Payload\n\
    \            (ESP)\", RFC 2406, November 1998.\n   [R2407]  Piper, D., \"The Internet\
    \ IP Security Domain of\n            Interpretation for ISAKMP\", RFC 2407, November\
    \ 1998.\n   [R2408]  Maughan, D., Schertler, M., Schneider, M. and J. Turner,\n\
    \            \"Internet Security Association and Key Management Protocol\n   \
    \         (ISAKMP)\", RFC 2408, November 1998.\n   [R2409]  Harkins, D. and D.\
    \ Carrel, \"The Internet Key Exchange\n            (IKE)\", RFC 2409, November\
    \ 1998.\n   [R2410]  Glenn, R. and S. Kent, \"The NULL Encryption Algorithm and\n\
    \            Its Use With IPsec\", RFC 2410, November 1998.\n   [R2412]  Orman,\
    \ H., \"The OAKLEY Key Determination Protocol\", RFC\n            2412, November\
    \ 1998.\n   [R2451]  Pereira, R. and R. Adams, \"The ESP CBC-Mode Cipher\n   \
    \         Algorithms\", RFC 2451, November 1998.\n   [R2460]  Deering, S. and\
    \ R. Hinden, \"Internet Protocol, Version 6\n            (IPv6) Specification\"\
    , RFC 2460, December 1998.\n   [R2504]  Guttman, E., Leong, L. and G. Malkin,\
    \ \"Users' Security\n            Handbook\", RFC 2504, February 1999.\n   [R2510]\
    \  Adams, C. and S. Farrell, \"Internet X.509 Public Key\n            Infrastructure\
    \ Certificate Management Protocols\", RFC 2510,\n            March 1999.\n   [R2527]\
    \  Chokhani, S. and W. Ford, \"Internet X.509 Public Key\n            Infrastructure,\
    \ Certificate Policy and Certification\n            Practices Framework\", RFC\
    \ 2527, March 1999.\n   [R2536]  EastLake, D., \"DSA KEYs and SIGs in the Domain\
    \ Name System\n            (DNS)\", RFC 2536, March 1999.\n   [R2570]  Case, J.,\
    \ Mundy, R., Partain, D. and B. Stewart,\n            \"Introduction to Version\
    \ 3 of the Internet-Standard Network\n            Management Framework\", RFC\
    \ 2570, April 1999.\n   [R2574]  Blumenthal, U. and B. Wijnen, \"User-based Security\
    \ Model\n            (USM) for Version 3 of the Simple Network Management\n  \
    \          Protocol (SNMPv3)\", RFC 2574, April 1999.\n   [R2612]  Adams, C. and\
    \ J. Gilchrist, \"The CAST-256 Encryption\n            Algorithm\", RFC 2612,\
    \ June 1999.\n   [R2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter,\n\
    \            L., Leach, P. and T. Berners-Lee, \"Hypertext Transfer\n        \
    \    Protocol-- HTTP/1.1\", RFC 2616, June 1999.\n   [R2628]  Smyslov, V., \"\
    Simple Cryptographic Program Interface\", RFC\n            2628, June 1999.\n\
    \   [R2630]  Housley, R., \"Cryptographic Message Syntax\", RFC 2630, June\n \
    \           1999.\n   [R2631]  Rescorla, E., \"Diffie-Hellman Key Agreement Method\"\
    , RFC\n            2631, June 1999.\n   [R2633]  Ramsdell, B., ed., \"S/MIME Version\
    \ 3 Message Specification\",\n            RFC 2633, June 1999.\n   [R2634]  Hoffman,\
    \ P., ed., \"Enhanced Security Services for S/MIME\",\n            RFC 2634, June\
    \ 1999.\n   [R2635]  Hambridge, S. and A. Lunde, \"Don't Spew: A Set of Guidelines\n\
    \            for Mass Unsolicited Mailings and Postings\", RFC 2635, June\n  \
    \          1999.\n   [Raym]   E. S. Raymond, ed., \"The On-Line Hacker Jargon\
    \ File\", ver.\n            4.0.0, 24 Jul 1996. (Also available as \"The New Hacker's\n\
    \            Dictionary\", 2nd edition, MIT Press, Sep 1993, ISBN 0-262-\n   \
    \         18154-1. See: http://www.tuxedo.org/jargon/ for the latest\n       \
    \     version.)\n   [Russ]   D. Russell and G. T. Gangemi Sr., Chapter 10 (\"\
    TEMPEST\") in\n            \"Computer Security Basics\", ISBN 0-937175-71-4, 1991.\n\
    \   [Schn]   B. Schneier, \"Applied Cryptography\", John Wiley & Sons,\n     \
    \       Inc., New York, 1994.\n   [SDNS3]  U.S. Department of Defense, National\
    \ Security Agency,\n            \"Secure Data Network Systems, Security Protocol\
    \ 3 (SP3)\",\n            document SDN.301, Revision 1.5, 15 May 1989.\n   [SDNS4]\
    \  ---, ---, \"Security Protocol 4 (SP4)\", document SDN.401,\n            Revision\
    \ 1.2, 12 Jul 1988.\n   [SDNS7]  ---, ---, \"Secure data Network System, Message\
    \ Security\n            Protocol (MSP)\", document SDN.701, Revision 4.0, 7 Jun\
    \ 1996,\n            with Corrections to Message Security Protocol, SDN.701, Rev\n\
    \            4.0\", 96-06-07, 30 Aug, 1996.\n   [SET1]   MasterCard and Visa,\
    \ \"SET Secure Electronic Transaction\n            Specification, Book 1: Business\
    \ Description\", ver. 1.0, 31\n            May 1997.\n   [SET2]   ---, \"SET Secure\
    \ Electronic Transaction Specification, Book\n            2: Programmer's Guide\"\
    , ver. 1.0, 31 May 1997.\n   [Stei]   J. Steiner, C. Neuman, and J. Schiller,\
    \ \"Kerberos: An\n            Authentication Service for Open Network Systems\"\
    \ in \"Usenix\n            Conference Proceedings\", Feb 1988.\n   [X400]   International\
    \ Telecommunications Union--Telecommunication\n            Standardization Sector\
    \ (formerly \"CCITT\"), Recommendation\n            X.400, \"Message Handling\
    \ Services: Message Handling System\n            and Service Overview\".\n   [X500]\
    \   ---, Recommendation X.500, \"Information Technology--Open\n            Systems\
    \ Interconnection--The Directory: Overview of\n            Concepts, Models, and\
    \ Services\". (Equivalent to ISO 9594-1.)\n   [X501]   ---, Recommendation X.501,\
    \ \"Information Technology--Open\n            Systems Interconnection--The Directory:\
    \ Models\".\n   [X509]   ---, Recommendation X.509, \"Information Technology--Open\n\
    \            Systems Interconnection--The Directory: Authentication\n        \
    \    Framework\". (Equivalent to ISO 9594-8.)\n   [X519]   ---, Recommendation\
    \ X.519, \"Information Technology--Open\n            Systems Interconnection--The\
    \ Directory: Protocol\n            Specifications\".\n   [X520]   ---, Recommendation\
    \ X.520, \"Information Technology--Open\n            Systems Interconnection--The\
    \ Directory: Selected Attribute\n            Types\".\n   [X680]   ---, Recommendation\
    \ X.680, \"Information Technology--Abstract\n            Syntax Notation One (ASN.1)--Specification\
    \ of Basic\n            Notation\", 15 Nov 1994. (Equivalent to ISO/IEC 8824-1.)\n\
    \   [X690]   ---, Recommendation X.690, \"Information Technology--ASN.1\n    \
    \        Encoding Rules--Specification of Basic Encoding Rules (BER),\n      \
    \      Canonical Encoding Rules (CER) and Distinguished Encoding\n           \
    \ Rules (DER)\", 15 Nov 1994. (Equivalent to ISO/IEC 8825-1.)\n"
- title: 5. Security Considerations
  contents:
  - "5. Security Considerations\n   This document only defines security terms and\
    \ recommends how to use\n   them. It does not describe in detail the vulnerabilities\
    \ of, threats\n   to, or mechanisms that protect specific Internet protocols.\n"
- title: 6. Acknowledgments
  contents:
  - "6. Acknowledgments\n   Pat Cain, Mike Kong, and Charles Lynn provided meticulous\
    \ comments on\n   an early draft.\n"
- title: 7. Author's Address
  contents:
  - "7. Author's Address\n   Please address all comments to:\n   Robert W. Shirey\
    \                   GTE / BBN Technologies\n   EMail: rshirey@bbn.com        \
    \     Suite 1200, Mail Stop 30/12B2\n   Phone: +1 (703) 284-4641           1300\
    \ Seventeenth Street North\n   Fax:   +1 (703) 284-2766           Arlington, VA\
    \  22209-3801 USA\n"
- title: 8. Full Copyright Statement
  contents:
  - "8. Full Copyright Statement\n   Copyright (C) The Internet Society (2000).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
