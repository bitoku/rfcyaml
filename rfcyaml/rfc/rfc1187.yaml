- title: __initial_text__
  contents:
  - '                   Bulk Table Retrieval with the SNMP

    '
- title: 1.  Status of this Memo
  contents:
  - "1.  Status of this Memo\n   This memo reports an interesting family of algorithms\
    \ for bulk table\n   retrieval using the Simple Network Management Protocol (SNMP).\
    \  This\n   memo describes an Experimental Protocol for the Internet community,\n\
    \   and requests discussion and suggestions for improvements.  This memo\n   does\
    \ not specify a standard for the Internet community.  Please refer\n   to the\
    \ current edition of the \"IAB Official Protocol Standards\" for\n   the standardization\
    \ state and status of this protocol.  Distribution\n   of this memo is unlimited.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Status of this Memo ..................................\
    \    1\n   2. Abstract .............................................    1\n  \
    \ 3. Bulk Table Retrieval with the SNMP ...................    2\n   4. The Pipelined\
    \ Algorithm ..............................    3\n   4.1 The Maximum Number of\
    \ Active Threads ................    4\n   4.2 Retransmissions .....................................\
    \    4\n   4.3 Some Definitions ....................................    4\n  \
    \ 4.4 Top-Level ...........................................    5\n   4.5 Wait\
    \ for Events .....................................    6\n   4.6 Finding the Median\
    \ between two OIDs .................    8\n   4.7 Experience with the Pipelined\
    \ Algorithm .............   10\n   4.8 Dynamic Range of Timeout Values .....................\
    \   10\n   4.9 Incorrect Agent Implementations .....................   10\n  \
    \ 5. The Parallel Algorithm ...............................   11\n   5.1 Experience\
    \ with the Parallel Algorithm ..............   11\n   6. Acknowledgements .....................................\
    \   11\n   7. References ...........................................   12\n  \
    \ Security Considerations..................................   12\n   Authors'\
    \ Addresses.......................................   12\n"
- title: 2.  Abstract
  contents:
  - "2.  Abstract\n   This memo reports an interesting family of algorithms for bulk\
    \ table\n   retrieval using the Simple Network Management Protocol (RFC 1157)\
    \ [1].\n   The reader is expected to be familiar with both the Simple Network\n\
    \   Management Protocol and SNMP's powerful get-next operator.  Please\n   send\
    \ comments to: Marshall T. Rose <mrose@psi.com>.\n"
- title: 3.  Bulk Table Retrieval with the SNMP
  contents:
  - "3.  Bulk Table Retrieval with the SNMP\n   Empirical evidence has shown that\
    \ SNMP's powerful get-next operator is\n   effective for table traversal, particularly\
    \ when the management\n   station is interested in well-defined subsets of a particular\
    \ table.\n   There has been some concern that bulk table retrieval can not be\n\
    \   efficiently accomplished using the powerful get-next operator.  Recent\n \
    \  experience suggests otherwise.\n   In the simplest case, using the powerful\
    \ get-next operator, one can\n   traverse an entire table by retrieving one object\
    \ at a time.  For\n   example, to traverse the entire ipRoutingTable, the management\
    \ station\n   starts with:\n                  get-next (ipRouteDest)\n   which\
    \ might return\n                  ipRouteDest.0.0.0.0\n   The management station\
    \ then continues invoking the powerful get-next\n   operator, using the value\
    \ provided by the previous response, e.g.,\n                  get-next (ipRouteDest.0.0.0.0)\n\
    \   As this sequence continues, each column of the ipRoutingTable can be\n   retrieved,\
    \ e.g.,\n                  get-next (ipRouteDest.192.33.4.0)\n   which might return\n\
    \                  ipRouteIfIndex.0.0.0.0\n   Eventually, a response is returned\
    \ which is outside the table, e.g.,\n                  get-next (ipRouteMask.192.33.4.0)\n\
    \   which might return\n                  ipNetToMediaIfIndex.192.33.4.1\n   So,\
    \ using this scheme, O(rows x columns) management operations are\n   required\
    \ to retrieve the entire table.\n   This approach is obviously sub-optimal as\
    \ the powerful get-next\n   operator can be given several operands.  Thus, the\
    \ first step is to\n   retrieve an entire row of the table with each operation,\
    \ e.g.,\n              get-next (ipRouteDest, ipRouteIfIndex, ..., ipRouteMask)\n\
    \   which might return\n                  ipRouteDest.0.0.0.0\n              \
    \    ipRouteIfIndex.0.0.0.0\n                  ipRouteMask.0.0.0.0\n   The management\
    \ station can then continue invoking the powerful get-\n   next operator, using\
    \ the results of the previous operation as the\n   operands to the next operation.\
    \  Using this scheme O(rows) management\n   operations are required to retrieve\
    \ the entire table.\n   Some have suggested that this is a weakness of the SNMP,\
    \ in that\n   O(rows) serial operations is time-expensive.  The problem with such\n\
    \   arguments however is that implicit emphasis on the word \"serial\".  In\n\
    \   fact, there is nothing to prevent a clever management station from\n   invoking\
    \ the powerful get-next operation several times, each with\n   different operands,\
    \ in order to achieve parallelism and pipelining in\n   the network.  Note that\
    \ this approach requires no changes in the\n   SNMP, nor does it add any significant\
    \ burden to the agent.\n"
- title: 4.  The Pipelined Algorithm
  contents:
  - "4.  The Pipelined Algorithm\n   Let us now consider an algorithm for bulk table\
    \ retrieval with the\n   SNMP.  In the interests of brevity, the \"pipelined algorithm\"\
    \ will\n   retrieve only a single column from the table; without loss of\n   generality,\
    \ the pipelined algorithm can be easily extended to\n   retrieve all columns.\n\
    \   The algorithm operates by adopting a multi-threaded approach: each\n   thread\
    \ generates its own stream of get-next requests and processes\n   the resulting\
    \ stream of responses.  For a given thread, a request\n   will correspond to a\
    \ different row in the table.\n   Overall retrieval efficiency is improved by\
    \ being able to keep\n   several transactions in transit, and by having the agent\
    \ and\n   management station process transactions simultaneously.\n   The algorithm\
    \ will adapt itself to varying network conditions and\n   topologies as well as\
    \ varying loads on the agent.  It does this both\n   by varying the number of\
    \ threads that are active (i.e., the number of\n   transactions that are being\
    \ processed and in transit) and by varying\n   the retransmission timeout.  These\
    \ parameters are varied based on the\n   transaction round-trip-time and on the\
    \ loss/timeout of transactions.\n"
- title: 4.1.  The Maximum Number of Active Threads
  contents:
  - "4.1.  The Maximum Number of Active Threads\n   One part of the pipelined algorithm\
    \ which must be dynamic to get best\n   results is the determination of how many\
    \ threads to have active at a\n   time.  With only one thread active, the pipelined\
    \ algorithm\n   degenerates to the serial algorithm mentioned earlier.  With more\n\
    \   threads than necessary, there is a danger of overrunning the agent,\n   whose\
    \ only recourse is to drop requests, which is wasteful.  The\n   ideal number\
    \ is just enough to have the next request arrive at the\n   agent, just as it\
    \ finishes processing the previous request.  This\n   obviously depends on the\
    \ round-trip time, which not only varies\n   dynamically depending on network\
    \ topology and traffic-load, but can\n   also be different for different tables\
    \ in the same agent.\n   With too few threads active, the round-trip time barely\
    \ increases\n   with each increase in the number of active threads; with too many,\n\
    \   the round-trip time increases by the amount of time taken by the\n   agent\
    \ to process one request.  The number is dynamically estimated by\n   calculating\
    \ the round-trip-time divided by the number of active\n   threads; whenever this\
    \ value takes on a new minimum value, the limit\n   on the number of threads is\
    \ adjusted to be the number of threads\n   active at the time the corresponding\
    \ request was sent (plus one to\n   allow for loss of requests).\n"
- title: 4.2.  Retransmissions
  contents:
  - "4.2.  Retransmissions\n   When there are no gateways between the manager and\
    \ agent, the\n   likelihood of in-order arrival of requests and responses is quite\n\
    \   high.  At present, the decision to retransmit is based solely on the\n   timeout.\
    \  One possible optimization is for the manager to remember\n   the order in which\
    \ requests are sent, and correlate this to incoming\n   responses.  If one thread\
    \ receives a response before another thread\n   which sent an earlier request,\
    \ then lossage could be assumed, and a\n   retransmission made immediately.\n"
- title: 4.3.  Some Definitions
  contents:
  - "4.3.  Some Definitions\n   To begin, let us define a \"thread\" as some state\
    \ information kept in\n   the management station which corresponds to a portion\
    \ of the table to\n   be retrieved.  A thread has several bits of information\
    \ associated\n   with it:\n      (1)  the range of SNMP request-ids which this\
    \ thread can use,\n           along with the last request-id used;\n      (2)\
    \  last SNMP message sent, the number of times it has been\n           (re)sent,\
    \ the time it was (re)sent;\n      (3)  the inclusive lower-bound and exclusive\
    \ upper-bound of\n           the object-instance for the portion of the table\
    \ that\n           this thread will retrieve, along with the current\n       \
    \    object-instance being used;\n      (4)  the number of threads which were\
    \ active at the time it\n           was last sent;\n   When a thread is created,\
    \ it automatically sends a get-next message\n   using its inclusive lower-bound\
    \ OID.  Further, it is placed at the\n   end of the \"thread queue\".\n   Let\
    \ us also define an OID as a concrete representation of an object\n   identifier\
    \ which contains two parts:\n      (1)  the number of sub-identifiers present,\
    \ \"nelem\";\n      (2)  the sub-identifiers themselves in an array, \"elems\"\
    ,\n           indexed from 1 up to (and including) \"nelem\".\n"
- title: 4.4.  Top-Level
  contents:
  - "4.4.  Top-Level\n   The top-level consists of starting three threads, and then\
    \ entering a\n   loop.  As long as there are existing threads, the top-level waits\
    \ for\n   events (described next), and then acts upon the incoming messages.\n\
    \   For each thread which received a response, a check is made to see if\n   the\
    \ OID of the response is greater than or equal to the exclusive\n   upper-bound\
    \ of the thread.  If so, the portion of the table\n   corresponding to the thread\
    \ has been completely retrieved, so the\n   thread is destroyed.\n   Otherwise,\
    \ the variable bindings in the response are stored.\n   Following this, if a new\
    \ thread should be created, then the portion\n   of the table corresponding to\
    \ the thread is split accordingly.\n   Regardless, another powerful get-next operator\
    \ is issued on behalf of\n   the thread.\n   The initial starting positions (column,\
    \ column.127, and column.192),\n   were selected to form optimal partitions for\
    \ tables which are indexed\n   by IP addresses.  The algorithm could easily be\
    \ modified to choose\n   other partitions; however, it must be stressed that the\
    \ current\n   choices work for any tabular object.\n      pipelined_algorithm\
    \ (column)\n      OID  column;\n      {\n          timeout ::= some initial value;\n\
    \          start new thread for [column, column.127);\n          start new thread\
    \ for [column.127, column.192);\n          start new thread for [column.192, column+1);\n\
    \          while (threads exist) {\n             wait for events;\n          \
    \   foreach (thread that has an incoming message,\n                      examined\
    \ in order from the thread queue) {\n                 OID     a;\n           \
    \      if (message's OID >= thread's upper-bound) {\n                     destroy\
    \ thread;\n                     continue;\n                 }\n              \
    \   store variable-bindings from message;\n                 if (number of simultaneous\
    \ threads does NOT\n                             exceed a maximum number\n   \
    \                       && NOT backoff\n                          && (a ::= oid_median\
    \ (message's OID,\n                                                thread's\n\
    \                                                    upper-bound))) {\n      \
    \                start new thread for [a, thread's upper-bound);\n           \
    \           thread's upper-bound ::= a;\n                      place thread at\
    \ end of thread queue;\n                      backoff ::= TRUE;\n            \
    \      }\n                  do another get-next for thread;\n              }\n\
    \          }\n      }\n"
- title: 4.5.  Wait for Events
  contents:
  - "4.5.  Wait for Events\n   Waiting for events consists of waiting a small amount\
    \ of time or\n   until at least one message is received.\n   Any messages encountered\
    \ are then collated with the appropriate\n   thread.  In addition, the largest\
    \ round-trip time for\n   request/responses is measured, and the maximum number\
    \ of active\n   threads is calculated.\n   Next, the timeout is adjusted: if no\
    \ responses were received, then\n   the timeout is doubled; otherwise, a timeout-adjustment\
    \ is calculated\n   as 1.5 times the largest observed round-trip time.  If the\
    \ timeout-\n   adjustment is greater than the current timeout, the current timeout\n\
    \   is set to the timeout-adjustment.  Otherwise, the current timeout is\n   averaged\
    \ with the timeout-adjustment.\n   Finally, if at least one thread did not receive\
    \ a response, then the\n   thread is identified which has waited the longest.\
    \  If the elapsed\n   time (with noise factor) since the last request (or retransmission)\n\
    \   is greater than the current timeout value, another retransmission is\n   attempted.\n\
    \   wait for events ()\n   {\n       backoff ::= TRUE, maxrtt ::= 0;\n       find\
    \ the thread which has been waiting the longest\n           for a response;\n\
    \       timedelta = timeout\n                       - time since request was sent\
    \ for thread;\n       wait up to timedelta seconds or until some messages arrive;\n\
    \       if (least one message arrived) {\n           discard any messages which\
    \ aren't responses;\n           foreach (response which corresponds to a thread)\
    \ {\n               if (the response is a duplicate)\n                   drop\
    \ it and continue;\n               if (this response is for a message that was\n\
    \                       not retransmitted) {\n                  if (the round-trip\
    \ time is larger than maxrtt)\n                       set maxrtt to the new round-trip\
    \ time;\n                   if (round-trip time / number of active threads\n \
    \                        < minimum previous round-trip time / number\n       \
    \                       of active threads) {\n                       set new minimum\
    \ round-trip time per number of\n                           active threads\n \
    \                      set new maximum number of threads\n                  }\n\
    \                   backoff ::= FALSE;\n               }\n           }\n     \
    \  }\n       if (backoff)\n           double timeout;\n       elsif (maxrtt >\
    \ 0) {\n          timeadjust ::= maxrtt * 3 / 2;\n           if (timeadjust >\
    \ timeout)\n               timeout ::= timeadjust; backoff ::= TRUE;\n       \
    \    else\n               timeout ::= (timeout + timeadjust) / 2;\n       }\n\
    \       if (timeout exceeds some threshold)\n          set timeout to that threshold;\n\
    \      elsif (timeout is smaller than some threshold)\n           set timeout\
    \ to that threshold;\n       if (at least one thread didn't receive a response)\
    \ {\n           find the thread which has been waiting the longest\n         \
    \      for a response,\n               and determine the elapsed time since a\
    \ message\n               was sent;\n           if (the elapsed time with noise\
    \ is greater than timeout) {\n               if (the number of retransmissions\
    \ for this thread\n                       exceeds a threshold)\n             \
    \      abort the algorithm;\n               retransmit the request;\n        \
    \       backoff ::= TRUE;\n           }\n       }\n  }\n"
- title: 4.6.  Finding the Median between two OIDs
  contents:
  - "4.6.  Finding the Median between two OIDs\n   The object identifier space is\
    \ neither uniform nor continuous.  As\n   such, it is not always possible to choose\
    \ an object identifier which\n   is lexicographically-between two arbitrary object\
    \ identifiers.  In\n   view of this, the pipelined algorithm makes a best-effort\
    \ attempt.\n   Starting from the beginning, each sub-identifier of the two OIDs\
    \ is\n   scanned until a difference is encountered.  At this point there are\n\
    \   several possible conditions:\n      (1)  The upper OID has run out of sub-identifiers.\
    \  In this\n           case, either the two OIDs are are identical or the lower\n\
    \           OID is greater than the upper OID (an interface error),\n        \
    \   so no OID is returned.\n      (2)  The lower OID has run out of sub-identifiers.\
    \  In this\n           case, the first subsequent non-zero sub-identifier from\n\
    \           the upper OID is located.  If no such sub-identifier is\n        \
    \   found, then no OID exists between the lower and upper\n           OIDs, and\
    \ no OID is returned.  Otherwise, a copy of the\n           upper OID is made,\
    \ but truncated at this non-zero\n           sub-identifier, which is subsequently\
    \ halved, and the\n           resulting OID is returned.\n      (3)  Otherwise,\
    \ a copy of the lower OID is made, but truncated\n           at the point of difference.\
    \  This last sub-identifier is\n           then set to the arithmetic mean of\
    \ the difference.  In\n           the case where the difference is only 1 (so\
    \ the last\n           sub-identifier remains the same) then a new sub-\n    \
    \       identifier is added, taking care to be larger than a\n           possible\
    \ sub-identifier present in the lower OID.\n           Regardless, the resulting\
    \ OID is returned.\n       oid_median (lower, upper)\n       OID     lower,\n\
    \               upper;\n       {\n           for (i ::= 1; i < upper:nelem; i++)\
    \ {\n               if (i > lower:nelem) {\n                   while (upper:elems[i]\
    \ == 0)\n                       if (++i > upper:nelem)\n                     \
    \      return NULL;\n                   median ::= copy of upper;\n          \
    \         median:nelem ::= i;\n                   median:elems[i] ::= upper:elems[i]\
    \ / 2;\n                   return median;\n              }\n              if (lower:elems[i]\
    \ == upper:elems[i])\n                  continue;\n               median ::= copy\
    \ of lower;\n               median:nelem ::= i;\n               median:elems[i]\
    \ ::= (lower:elems[i]+upper:elems[i])/2;\n               if (median:elems[i] ==\
    \ lower:elems[i]) {\n                   median:nelem ::= (i + 1);\n          \
    \        if (lower:nelem < i)\n                      median:elems[median:nelem]\
    \ ::= 127;\n                   elsif ((x ::= lower:elems[i + 1]) >= 16383)\n \
    \                     median:elems[median:nelem] ::= x + 16383;\n            \
    \       elsif (x >= 4095)\n                      median:elems[median:nelem] ::=\
    \ x + 4095;\n                   elsif (x >= 1023)\n                       median:elems[median:nelem]\
    \ ::= x + 1023;\n                   elsif (x >= 255)\n                       median:elems[median:nelem]\
    \ ::= x + 255;\n                   else median:elems[median:nelem] ::=\n     \
    \                                           (x / 2) + 128;\n               }\n\
    \                return median;\n           }\n           return NULL;\n     \
    \  }\n"
- title: 4.7.  Experience with the Pipelined Algorithm
  contents:
  - "4.7.  Experience with the Pipelined Algorithm\n   This pipelined algorithm has\
    \ been implemented and some\n   experimentation has been performed.  It would\
    \ be premature to provide\n   extensive performance figures at this time, as the\
    \ pipelined\n   algorithm is still being tuned, and is implemented only in a\n\
    \   prototype setting.  However, on tables of size O(2500), performance\n   of\
    \ 121 entries/second has been observed.  In contrast, the serial\n   algorithm\
    \ has performance of roughly 56 entries/second for the same\n   table.\n"
- title: 4.8.  Dynamic Range of Timeout Values
  contents:
  - "4.8.  Dynamic Range of Timeout Values\n   It should be noted that the pipelined\
    \ algorithm takes a simplistic\n   approach with the timeout value: it does not\
    \ maintain a history of\n   the value and act accordingly.\n   For example, if\
    \ the timeout reaches the maximum timeout limit, and\n   then latches for some\
    \ period of time, this indicates a resource\n   (either the network or the agent)\
    \ is saturated.  Unfortunately, a\n   solution is difficult: an elegant approach\
    \ would be to combine two\n   threads (but it is quite possible that no two consecutive\
    \ threads\n   exist when this determination is made).  Another approach might\
    \ be to\n   delay the transmission for threads which are ready to issue a new\n\
    \   get-next operation.\n   Similarly, if the timeout drops to the minimum value\
    \ and subsequently\n   latches, more threads should be started.\n"
- title: 4.9.  Incorrect Agent Implementations
  contents:
  - "4.9.  Incorrect Agent Implementations\n   An interesting result is that many\
    \ agents do not properly implement\n   the powerful get-next operator.  In particular,\
    \ when a get-next\n   request contains an operand with an arbitrarily-generated\
    \ suffix,\n   some agent implementations will handle this improperly, and\n  \
    \ ultimately return a result which is lexicographically less than the\n   operand!\n\
    \   A typical cause of this is when the instance-identifier for a\n   columnar\
    \ object is formed by a MAC or IP address, so each octet of\n   the address forms\
    \ a sub-identifier of the instance-identifier.  In\n   such circumstances, the\
    \ incorrect agent implementations compare\n   against only the least significant\
    \ octet of the sub-identifiers in\n   the operand, instead of the full value of\
    \ the sub-identifiers.\n   Upon encountering such an interaction, the pipelined\
    \ algorithm\n   implementation declares the thread dead (noting a possible gap\
    \ in the\n   table), and continues.\n"
- title: 5.  The Parallel Algorithm
  contents:
  - "5.  The Parallel Algorithm\n   One interesting optimization is to view the problem\
    \ in two steps: in\n   the first step, one column of the table is traversed to\
    \ determine the\n   full range of instances identifiers meaningful in the table.\n\
    \   (Indeed, although as described above, the pipelined algorithm\n   retrieves\
    \ a single column, the prototype implementation can retrieve\n   multiple columns).\
    \  In the second step, additional columns can be\n   retrieved using the SNMP\
    \ get operation, since the instance\n   identifiers are already known.  Further,\
    \ the manager can dynamically\n   determine how many variables can be placed in\
    \ a single SNMP get\n   operation in order to minimize the number of requests.\
    \  Of course,\n   since the agent's execution of the get operation is often less\n\
    \   expensive than execution of the powerful get-next operation, when\n   multiple\
    \ columns are request, this two-step process requires less\n   execution time\
    \ on the agent.\n   A second algorithm can be developed, the \"parallel algorithm\"\
    .  At\n   present, each thread is mapped onto a single SNMP operation.  A\n  \
    \ powerful insight is to suggest mapping several threads onto a single\n   SNMP\
    \ operation: the manager must dynamically determine how many\n   variables can\
    \ be placed in a single powerful get-next operation.\n   This has the advantage\
    \ of reducing traffic, at the expense of\n   requiring the agent to utilize more\
    \ resources for each request.\n   Earlier it was noted that the serial retrieval\
    \ of objects could be\n   viewed as a degenerate case of the pipelined algorithm,\
    \ in which the\n   number of active threads was one.  Similarly, the pipelined\
    \ algorithm\n   is a special case of the parallel algorithm, in which the number\
    \ of\n   threads per SNMP operation is one.\n"
- title: 5.1.  Experience with the Parallel Algorithm
  contents:
  - "5.1.  Experience with the Parallel Algorithm\n   The parallel algorithm has been\
    \ implemented and some experimentation\n   has been performed.  It would be premature\
    \ to provide extensive\n   performance figures at this time, as the algorithm\
    \ is still being\n   tuned, and is implemented only in a prototype setting.  However,\
    \ on\n   tables of size O(2500), performance of 320 entries/second has been\n\
    \   observed, a performance improvement of 571% over the serial\n   algorithm.\n"
- title: 6.  Acknowledgements
  contents:
  - "6.  Acknowledgements\n   A lot of the ideas on pipelining are motivated by Van\
    \ Jacobson's work\n   on adaptive timers in TCP.  The parallelization modifications\
    \ were\n   originally suggested by Jeffrey D. Case.\n   Finally, the comments\
    \ of the following individual is acknowledged:\n      Frank Kastenholz, Racal-Interlan\n"
- title: 7.  References
  contents:
  - "7.  References\n   [1] Case, J., Fedor, M., Schoffstall, M., and J. Davin, Simple\n\
    \       Network Management Protocol (SNMP), RFC 1157, SNMP Research,\n       Performance\
    \ Systems International, Performance Systems\n       International, MIT Laboratory\
    \ for Computer Science, May 1990.\n"
- title: Security Considerations
  contents:
  - "Security Considerations\n   Security issues are not discussed in this memo.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Marshall T. Rose\n   PSI, Inc.\n   PSI California Office\n\
    \   P.O. Box 391776\n   Mountain View, CA 94039\n   Phone: (415) 961-3380\n  \
    \ EMail: mrose@PSI.COM\n   Keith McCloghrie\n   Hughes LAN Systems\n   1225 Charleston\
    \ Road\n   Mountain View, CA 94043\n   Phone: (415) 966-7934\n   EMail: KZM@HLS.COM\n\
    \   James R. Davin\n   MIT Laboratory for Computer Science, NE43-507\n   545 Technology\
    \ Square\n   Cambridge, MA 02139\n   Phone:  (617) 253-6020\n   EMail:  jrd@ptt.lcs.mit.edu\n"
