- title: __initial_text__
  contents:
  - '                      DHCPv6 Failover Requirements

    '
- title: Abstract
  contents:
  - "Abstract\n   The DHCPv6 protocol, defined in RFC 3315, allows for multiple servers\n\
    \   to operate on a single network; however, it does not define any way\n   the\
    \ servers could share information about currently active clients\n   and their\
    \ leases.  Some sites are interested in running multiple\n   servers in such a\
    \ way as to provide increased availability in case of\n   server failure.  In\
    \ order for this to work reliably, the cooperating\n   primary and secondary servers\
    \ must maintain a consistent database of\n   the lease information.  RFC 3315\
    \ allows for, but does not define, any\n   redundancy or failover mechanisms.\
    \  This document outlines\n   requirements for DHCPv6 failover, enumerates related\
    \ problems, and\n   discusses the proposed scope of work to be conducted.  This\
    \ document\n   does not define a DHCPv6 failover protocol.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7031.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2013 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Definitions .....................................................3\n  \
    \ 3. Scope of Work ...................................................5\n    \
    \  3.1. Alternatives to Failover ...................................5\n      \
    \     3.1.1. Short-Lived Addresses ...............................5\n        \
    \   3.1.2. Redundant Servers ...................................6\n          \
    \ 3.1.3. Distributed Databases ...............................6\n           3.1.4.\
    \ Load Balancing ......................................7\n   4. Failover Scenarios\
    \ ..............................................7\n      4.1. Hot Standby Model\
    \ ..........................................7\n      4.2. Geographically Distributed\
    \ Failover ........................7\n      4.3. Load Balancing .............................................8\n\
    \      4.4. 1-to-1, m-to-1, and m-to-n Models ..........................8\n  \
    \    4.5. Split Prefixes .............................................8\n    \
    \  4.6. Long-Lived Connections .....................................8\n      4.7.\
    \ Partial Server Communication Loss ..........................9\n   5. Principles\
    \ of DHCPv6 Failover ...................................9\n      5.1. Failure\
    \ Modes ..............................................9\n           5.1.1. Server\
    \ Failure .....................................10\n           5.1.2. Network Partition\
    \ ..................................10\n      5.2. Synchronization Mechanisms\
    \ ................................11\n           5.2.1. Lockstep ...........................................11\n\
    \           5.2.2. Lazy Updates .......................................12\n  \
    \ 6. DHCPv4 and DHCPv6 Failover Comparison ..........................12\n   7.\
    \ DHCPv6 Failover Requirements ...................................13\n      7.1.\
    \ Features out of Scope .....................................14\n   8. Security\
    \ Considerations ........................................15\n   9. Acknowledgements\
    \ ...............................................15\n   10. References ....................................................16\n\
    \      10.1. Normative References .....................................16\n  \
    \    10.2. Informative References ...................................16\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The DHCPv6 protocol, defined in [RFC3315], allows for multiple\n\
    \   servers to be operating on a single network; however, it does not\n   define\
    \ how the servers can share the same address and prefix\n   delegation pools and\
    \ allow a client to seamlessly extend its existing\n   leases when the original\
    \ server is down.  [RFC3315] provides for\n   these capabilities but does not\
    \ document how the servers cooperate\n   and communicate to provide this capability.\
    \  Some sites are\n   interested in running multiple servers in such a way as\
    \ to provide\n   redundancy in case of server failure.  In order for this to work\n\
    \   reliably, the cooperating primary and secondary servers must maintain\n  \
    \ a consistent database of the lease information.\n   This document discusses\
    \ failover implementations scenarios, failure\n   modes, and synchronization approaches\
    \ to provide background to the\n   list of requirements for a DHCPv6 failover\
    \ protocol.  It then defines\n   a minimum set of requirements that failover must\
    \ provide to be\n   useful, while acknowledging that additional features may be\
    \ specified\n   as extensions.  This document does not define a DHCPv6 failover\n\
    \   protocol.\n   The failover model, to which these requirements apply, will\
    \ initially\n   be a pairwise \"hot standby\" model (see Section 4.1) with a primary\n\
    \   server used in normal operation switching over to a backup secondary\n   server\
    \ in the event of failure.  Optionally, a secondary server may\n   provide failover\
    \ service for multiple primary servers.  However, the\n   requirements will not\
    \ preclude a future load-balancing extension\n   where there is a symmetric failover\
    \ relationship.\n   The DHCPv6 failover concept borrows heavily from its DHCPv4\n\
    \   counterpart [DHCPV4-FAILOVER] that never completed the\n   standardization\
    \ process but has several successful, operationally\n   proven vendor-specific\
    \ implementations.  For a discussion about\n   commonalities and differences,\
    \ see Section 6.\n"
- title: 2.  Definitions
  contents:
  - "2.  Definitions\n   This section defines terms that are relevant to DHCPv6 failover.\n\
    \   Definitions from [RFC3315] are included by reference.  In particular,\n  \
    \ \"client\" means any device, e.g., end-user host, CPE (Customer\n   Premises\
    \ Equipment), or other router that implements client\n   functionality of the\
    \ DHCPv6 protocol.  A \"server\" is a DHCPv6 server,\n   unless explicitly noted\
    \ otherwise.  A \"relay\" is a DHCPv6 relay.\n   Binding (or client binding):\
    \  a group of server data records\n      containing the information the server\
    \ has about the addresses in\n      an IA (Identity Association, see Section 10\
    \ of [RFC3315]) or\n      configuration information explicitly assigned to the\
    \ client.\n      Configuration information that has been returned to a client\n\
    \      through a policy -- for example, the information returned to all\n    \
    \  clients on the same link -- does not require a binding.\n   DNS Update:  the\
    \ capability to update a DNS server's name database\n      using the on-the-wire\
    \ protocol defined in [RFC2136].  Clients and\n      servers can negotiate the\
    \ scope of such updates as defined in\n      [RFC4704].\n   Failover:  the ability\
    \ of one partner to continue offering services\n      provided by another partner,\
    \ with minimal or no impact on clients.\n   FQDN: a fully qualified domain name.\
    \  A fully qualified domain name\n      generally is a host name with at least\
    \ one domain label under the\n      top-level domain.  For example, \"dhcp.example.org\"\
    \ is a fully\n      qualified domain name.\n   High Availability:  a desired property\
    \ of DHCPv6 servers to continue\n      providing services despite experiencing\
    \ unwanted events such as\n      server crashes, link failures, or network partitions.\n\
    \   Load Balancing:  the ability for two or more servers to each process\n   \
    \   some portion of the client request traffic in a conflict-free\n      fashion.\n\
    \   Lease:  an IPv6 address, an IPv6 prefix, or other resource that was\n    \
    \  assigned (\"leased\") by a server to a specific client.  A lease may\n    \
    \  include additional information, like associated fully qualified\n      domain\
    \ name (FQDN) and/or information about associated DNS\n      updates.  A client\
    \ obtains a lease for a specified period of time\n      (valid lifetime).\n  \
    \ Partner:  A \"partner\", for the purpose of this document, refers to a\n   \
    \   failover server, typically the other failover server in a failover\n     \
    \ relationship.\n   Stable Storage:  each DHCP server is required to keep its\
    \ lease\n      database in some form of storage (known as \"stable storage\")\
    \ that\n      will be consistent throughout reboots, crashes, and power\n    \
    \  failures.\n   Partner Failure:  A power outage, unexpected shutdown, crash,\
    \ or\n      other type of failure that renders a partner unable to continue\n\
    \      its operation.\n"
- title: 3.  Scope of Work
  contents:
  - "3.  Scope of Work\n   In order to fit within the IETF process effectively and\
    \ efficiently,\n   the standardization effort for DHCPv6 failover is expected\
    \ to proceed\n   with the creation of documents of increasing specificity.\n \
    \  Requirements document:\n      It begins with this document specifying the requirements\
    \ for\n      DHCPv6 failover.\n   Design document:\n      A later document is\
    \ expected to address the design of the DHCPv6\n      failover protocol.\n   Protocol\
    \ document:\n      If sufficient interest exists, a later document is expected\
    \ to\n      address the protocol details required to implement the DHCPv6\n  \
    \    failover protocol itself.\n   The goal of this partitioning is, in part,\
    \ to ease the validation,\n   review, and approval of the DHCPv6 failover protocol\
    \ by presenting it\n   in comprehensible parts to the larger community.\n   Additional\
    \ documents describing extensions may also be defined.\n   DHCPv6 failover requirements\
    \ are presented in Section 7.\n"
- title: 3.1.  Alternatives to Failover
  contents:
  - "3.1.  Alternatives to Failover\n   There are many scenarios in which a failover\
    \ capability would be\n   useful.  However, there are often much simpler approaches\
    \ that will\n   meet the required goals.  This section documents examples where\n\
    \   failover is not really needed.\n"
- title: 3.1.1.  Short-Lived Addresses
  contents:
  - "3.1.1.  Short-Lived Addresses\n   There are cases when IPv6 addresses are used\
    \ only for a short time,\n   but there is a need to have high degree of confidence\
    \ that those\n   addresses will be served.  A notable example is PXE (Preboot\n\
    \   eXecution Environment) [RFC5970].  This is a mechanism for obtaining\n   configuration\
    \ early in the process of bootstrapping over the network.\n   The PXE BIOS acquires\
    \ an address in order to load the operating\n   system image and continue booting.\
    \  Address and possibly other\n   configuration parameters are used during the\
    \ boot process and are\n   discarded thereafter.  Any lack of available DHCPv6\
    \ service at this\n   time will prevent such devices from booting.\n   Instead\
    \ of deploying failover, it is better to use the much simpler\n   preference mechanism,\
    \ defined in [RFC3315].  For example, consider\n   two or more servers with each\
    \ having a distinct preference set (e.g.,\n   10 and 20).  Both will answer a\
    \ client's request.  The client should\n   choose the one with the larger preference\
    \ value.  In case of failure\n   of the most preferred server, the next server\
    \ will keep responding to\n   clients' queries.  This approach is simple to deploy\
    \ but does not\n   offer lease stability, i.e., in case of server failure, clients'\n\
    \   addresses and prefixes will change.\n"
- title: 3.1.2.  Redundant Servers
  contents:
  - "3.1.2.  Redundant Servers\n   In some cases, the desire to deploy failover is\
    \ motivated by high\n   availability, i.e., to continue providing services despite\
    \ server\n   failure.  If there are no additional requirements, that goal may\
    \ be\n   fulfilled with simply deploying two or more independent servers on\n\
    \   the same link.\n   There are several well-documented approaches showing how\
    \ such a\n   deployment could work.  They are discussed in detail in [RFC6853].\n\
    \   Each of those approaches is simpler to deploy and maintain than full\n   failover.\n"
- title: 3.1.3.  Distributed Databases
  contents:
  - "3.1.3.  Distributed Databases\n   Some servers may allow their lease database\
    \ to be stored in external\n   databases.  Another possible alternative to failover\
    \ is to configure\n   two servers to connect to the same distributed database.\n\
    \   Care should be taken to understand how inconsistencies are solved in\n   such\
    \ database backends and how such conflict resolutions affect\n   DHCPv6 server\
    \ operation.\n   It is also essential to use only a database that provides equivalent\n\
    \   reliability and failover capability.  Otherwise, the single point of\n   failure\
    \ is only moved to a different location (database rather than\n   DHCPv6 server).\
    \  Such a configuration does not improve redundancy but\n   significantly complicates\
    \ deployment.\n   A common misconception regarding database-based redundancy is\
    \ the\n   assumption that a conflict resolution after recovering from a network\n\
    \   partition is not necessary.  To explain that fallacy, let's consider\n   an\
    \ example where there is a very small pool with only one address.\n   There are\
    \ two servers, each connected to a co-located database node\n   (i.e., running\
    \ on the same hardware).  Network partition occurs.\n   Each server is operating\
    \ but has lost connection to its partner.  Two\n   clients request an address,\
    \ one from each server.  Each server\n   consults its database and discovers that\
    \ only one address is\n   available, so it is assigned to the client.  Unfortunately,\
    \ each\n   server assigned the same address to a different client.  Making the\n\
    \   scenario more realistic (millions of addresses rather than one) just\n   decreased\
    \ failure probability, but it did not eliminate the\n   underlying issue.\n  \
    \ Any solution that involves a distributed database implementation of\n   DHCPv6\
    \ failover must take into account the requirements for security.\n   See Section\
    \ 8 for additional information.\n"
- title: 3.1.4.  Load Balancing
  contents:
  - "3.1.4.  Load Balancing\n   Sometimes the desire to deploy more than one server\
    \ is based on the\n   assumption that they will share the client traffic.  Administrators\n\
    \   that are interested in such a capability are advised to deploy a\n   load-balancing\
    \ mechanism, defined in [LOAD-BALANCING].\n"
- title: 4.  Failover Scenarios
  contents:
  - "4.  Failover Scenarios\n   The following sections provide several examples of\
    \ deployment\n   scenarios and use cases that may be associated with capabilities\n\
    \   commonly referred to as \"failover\".  These scenarios may be in or out\n\
    \   of scope for the DHCPv6 failover protocol to which this document's\n   requirements\
    \ apply; they are enumerated here to provide a common\n   basis for discussion.\n"
- title: 4.1.  Hot Standby Model
  contents:
  - "4.1.  Hot Standby Model\n   In the simplest case, there are two partners that\
    \ are connected to\n   the same network.  Only one of the partners (\"primary\"\
    ) provides\n   services to clients.  In case of its failure, the second partner\n\
    \   (\"secondary\") continues handling services previously handled by the\n  \
    \ first partner.  As both servers are connected to the same network, a\n   partner\
    \ that fails to communicate with its partner while also\n   receiving requests\
    \ from clients may assume with high probability that\n   its partner is down and\
    \ the network is functional.  This assumption\n   may affect its operation.\n"
- title: 4.2.  Geographically Distributed Failover
  contents:
  - "4.2.  Geographically Distributed Failover\n   Servers may be physically located\
    \ in separate locations.  A common\n   example of such a topology is where a service\
    \ provider has at least a\n   regional high performance network between geographically\
    \ distributed\n   data centers.  In such a scenario, one server is located in\
    \ one data\n   center, and its failover partner is located in another remote data\n\
    \   center.  In this scenario, when one partner finds that it cannot\n   communicate\
    \ with the other partner, it does not necessarily mean that\n   the other partner\
    \ is down.\n"
- title: 4.3.  Load Balancing
  contents:
  - "4.3.  Load Balancing\n   A desire to have more than one server in a network may\
    \ also be\n   created by the desire to have incoming traffic be handled by several\n\
    \   servers.  This decreases the load each server must endure when all\n   servers\
    \ are operational.  Although such a capability does not,\n   strictly, require\
    \ failover -- it is clear that failover makes such an\n   architecture more straightforward.\n\
    \   Note that in a load-balancing situation that includes failover, each\n   individual\
    \ server must be able to handle the full load normally\n   handled by both servers\
    \ working together, or there is not a true\n   increase in availability.\n"
- title: 4.4.  1-to-1, m-to-1, and m-to-n Models
  contents:
  - "4.4.  1-to-1, m-to-1, and m-to-n Models\n   A failover relationship for a specific\
    \ network is provided by two\n   failover partners.  Those partners communicate\
    \ with each other and\n   back up all pools.  This scenario is sometimes referred\
    \ to as the\n   1-to-1 model and is considered relatively simple.  In larger\n\
    \   networks, one server may be participating in several failover\n   relationships,\
    \ i.e., it provides failover for several address or\n   prefix pools, each served\
    \ by separate partners.  Such a scenario can\n   be referred to as m-to-1.  The\
    \ most complex scenario, m-to-n, assumes\n   that each partner participates in\
    \ multiple failover relationships.\n"
- title: 4.5.  Split Prefixes
  contents:
  - "4.5.  Split Prefixes\n   Due to the extensive IPv6 address space, it is possible\
    \ to provide\n   semi-redundant service by splitting the available pool of addressees\n\
    \   into two or more non-overlapping pools, with each server handling its\n  \
    \ own smaller pool.  Several versions of such a scenario are discussed\n   in\
    \ [RFC6853].\n"
- title: 4.6.  Long-Lived Connections
  contents:
  - "4.6.  Long-Lived Connections\n   Certain nodes may maintain long-lived connections.\
    \  Since the IPv6\n   address space is large, techniques exist (e.g., [RFC6853])\
    \ that use\n   the easy availability of IPv6 addresses in order to provide increased\n\
    \   DHCPv6 availability.  However, these approaches do not generally\n   provide\
    \ for stable IPv6 addresses for DHCPv6 clients should the\n   server with which\
    \ the client is interacting become unavailable.\n   The obvious benefit of stable\
    \ addresses is the ability to update DNS\n   infrequently.  While DNS can be updated\
    \ every time an IPv6 address\n   changes, it introduces delays, and (depending\
    \ on DNS configuration)\n   old entries may be cached for prolonged periods of\
    \ time.\n   The other benefit of having a stable address is that many monitoring\n\
    \   solutions provide statistics on a per-IP basis, so IP changes make\n   measuring\
    \ characteristics of a given box more difficult.\n"
- title: 4.7.  Partial Server Communication Loss
  contents:
  - "4.7.  Partial Server Communication Loss\n   There is a scenario where the DHCPv6\
    \ server may be configured to\n   serve clients on one network adapter and communicate\
    \ with a partner\n   server (server-to-server traffic) on a different network\
    \ adapter.  In\n   this scenario, if the server loses connectivity on the network\n\
    \   adapter used to communicate with the clients because of network\n   adapter\
    \ (hardware) failure, there is no intimation of the loss of\n   service to the\
    \ partner in the DHCPv6 failover protocol.  Since the\n   servers are able to\
    \ communicate with each other, the partner remains\n   ignorant of the loss of\
    \ service to clients.\n"
- title: 5.  Principles of DHCPv6 Failover
  contents:
  - "5.  Principles of DHCPv6 Failover\n   This section describes important issues\
    \ that will affect any DHCPv6\n   failover protocol.  This section is not intended\
    \ to define\n   implementation details but rather describes high-level concepts\
    \ and\n   issues that are important to DHCPv6 failover.  These issues form a\n\
    \   basis for later documents that will deal with the solutions to these\n   issues.\n\
    \   The general failover concept assumes that there are backup servers\n   that\
    \ can provide service in case of a primary server failure.  In\n   theory, there\
    \ could be more than one backup server that could take up\n   the role if such\
    \ a need arises.  However, having more than two\n   servers introduces a very\
    \ difficult issue of synchronizing between\n   partners.  In the case of just\
    \ a pair of cooperating servers, the\n   notification and processes can result\
    \ in only one of two states:\n   fully successful (got response from a partner)\
    \ and total failure (no\n   response, failure event occurred).  Were there more\
    \ than two partners\n   participating in a relationship, there would be intermediate,\n\
    \   inconsistent states where some partners had updated their state and\n   some\
    \ had not.  This would greatly complicate the protocol design and\n   would give\
    \ little advantage in return.  Therefore, an approach that\n   assumes a pair\
    \ of cooperating servers was chosen.\n"
- title: 5.1.  Failure Modes
  contents:
  - "5.1.  Failure Modes\n   This section documents failure modes.  This requirements\
    \ document\n   does not make any claims whether those two failures are\n   distinguishable\
    \ by a server.\n"
- title: 5.1.1.  Server Failure
  contents:
  - "5.1.1.  Server Failure\n   Servers may become unresponsive due to a software\
    \ crash, hardware\n   failure, power outage, or any number of other reasons. \
    \ The failover\n   partner will detect such an event due to lack of responses\
    \ from the\n   down partner.  In this failure mode, the assumption is that the\n\
    \   server is the only equipment that is off-line and all other network\n   equipment\
    \ is operating normally.  In particular, communication\n   between other nodes\
    \ is not interrupted.\n   When working under the assumption that this is the only\
    \ type of\n   failure that can happen, the server may safely assume that its\n\
    \   partner unreachability means that it is down, so other nodes\n   (clients,\
    \ in particular) are not able to reach it either, and no\n   services are provided.\n\
    \   It should be noted that recovery after the failed server is brought\n   back\
    \ on-line is straightforward, due to the fact that it just needs\n   to download\
    \ current information from the lease database of the\n   healthy partner and there\
    \ is no conflict resolution required.\n   This is by far the most common failure\
    \ mode between two failover\n   partners.\n   When the two servers are located\
    \ physically close to each other,\n   possibly in the same room, the probability\
    \ that a failure to\n   communicate between failover partners is due to server\
    \ failure is\n   increased.\n"
- title: 5.1.2.  Network Partition
  contents:
  - "5.1.2.  Network Partition\n   Another possible cause of partner unreachability\
    \ is a failure in the\n   network that connects the two servers.  This may be\
    \ caused by failure\n   of any kind of network equipment: router, switch, physical\
    \ cables, or\n   optic fibers.  As a result of such a failure, the network is\
    \ split\n   into two or more disjoint sections (partitions) that are not able\
    \ to\n   communicate with each other.  Such an event is called \"network\n   partition\"\
    .  If failover partners are located in different\n   partitions, they won't be\
    \ able to communicate with each other.\n   Nevertheless, each partner may still\
    \ be able to serve clients that\n   happen to be part of the same partition.\n\
    \   If this failure mode is taken into consideration, a server can't\n   assume\
    \ that partner unreachability automatically means that its\n   partner is down.\
    \  They must consider the fact that the partner may\n   continue operating and\
    \ interacting with a subset of the clients.  The\n   only valid assumption is\
    \ that the partner also detected the network\n   partition event and follows procedures\
    \ specified for such a\n   situation.\n   It should be noted that recovery after\
    \ a partitioned network is\n   rejoined is significantly more complicated than\
    \ recovery from a\n   server failure event.  As both servers may have kept serving\
    \ clients,\n   they have two separate lease databases, and they need to agree\
    \ on the\n   state of each lease (or follow any other algorithm to bring their\n\
    \   lease databases into agreement).\n   This failure mode is more likely (though\
    \ still rare) in the situation\n   where two servers are in physically distant\
    \ locations with multiple\n   network elements between them.  This is the case\
    \ in geographically\n   distributed failover (see Section 4.2).\n"
- title: 5.2.  Synchronization Mechanisms
  contents:
  - "5.2.  Synchronization Mechanisms\n   Partners must exchange information about\
    \ changes made to the lease\n   database.  There are at least two types of synchronization\
    \ methods\n   that may be used (see Sections 5.2.1 and 5.2.2).  These concepts\
    \ are\n   related to distributed databases, so some familiarity with\n   distributed\
    \ database technology is useful to better understand this\n   topic.\n"
- title: 5.2.1.  Lockstep
  contents:
  - "5.2.1.  Lockstep\n   When a server receives a REQUEST message from a client,\
    \ it consults\n   its lease database and assigns requested addresses and/or prefixes.\n\
    \   To make sure that its partner maintains a consistent database, it\n   then\
    \ sends information about a new or just updated lease to the\n   partner and waits\
    \ for the partner's response.  After the response\n   from its partner is received,\
    \ the REPLY message is transmitted to the\n   client.\n   This approach has the\
    \ benefit of having a completely consistent lease\n   database between partners\
    \ at all times.  Unfortunately, there is\n   typically a significant performance\
    \ penalty for this approach as each\n   response sent to a client is delayed by\
    \ the total sum of the delays\n   caused by two transmissions between partners\
    \ and the processing by\n   the second partner.  The second partner is expected\
    \ to update its own\n   copy of the lease database in permanent storage, so this\
    \ delay is not\n   negligible, even in fast networks.\n   Due to the advent of\
    \ fast SSD (solid state disk) and battery-backed\n   RAM (random access memory)\
    \ disk technology, this write performance\n   penalty can be limited to some degree.\n"
- title: 5.2.2.  Lazy Updates
  contents:
  - "5.2.2.  Lazy Updates\n   Another approach to synchronizing the lease databases\
    \ is to transmit\n   the REPLY message to the client before completing the update\
    \ to the\n   partner.  The server sends the REPLY to the client immediately after\n\
    \   assigning appropriate addresses and/or prefixes and initiates the\n   partner\
    \ update at a later time, depending on the algorithm chosen.\n   Another variation\
    \ of this approach is to initiate transmission to the\n   partner but not wait\
    \ for its response before sending the REPLY to the\n   client.\n   This approach\
    \ has the benefit of a minimal impact on server response\n   times; it is thus\
    \ much better from a performance perspective.\n   However, it makes the lease\
    \ databases loosely synchronized between\n   partners.  This makes the synchronization\
    \ more complex (particularly\n   the re-integration after a network partition\
    \ event), as there may be\n   cases where one client has been given a lease on\
    \ an address or prefix\n   of which the partner is not aware (e.g., if the server\
    \ crashes after\n   sending the REPLY to the client but before sending update\
    \ information\n   to its partner).\n"
- title: 6.  DHCPv4 and DHCPv6 Failover Comparison
  contents:
  - "6.  DHCPv4 and DHCPv6 Failover Comparison\n   There are significant similarities\
    \ between existing DHCPv4 and\n   envisaged DHCPv6 failovers.  In particular,\
    \ both serve IP addresses\n   to clients, require maintaining consistent databases\
    \ among partners,\n   need to perform consistent DNS updates, must be able take\
    \ over\n   bindings offered by a failed partner, and must be able to resume\n\
    \   operation after the partner is recovered.  DNS conflict resolution\n   works\
    \ on the same principles in both DHCPv4 and DHCPv6.\n   Nevertheless, there are\
    \ significant differences.  IPv6 introduced\n   prefix delegation [RFC3633], which\
    \ is a crucial element of the DHCPv6\n   protocol.  IPv6 also introduced the concept\
    \ of deprecated addresses\n   with separate preferred and valid lifetimes, both\
    \ configured via\n   DHCPv6.  Negative response (NACK) in DHCPv4 has been replaced\
    \ with\n   the ability in DHCPv6 to provide a corrected response in a REPLY\n\
    \   message, which differs from a REQUEST.\n   Also, the typical large address\
    \ space (close to 2^64 addresses on /64\n   prefixes expected to be available\
    \ on most networks) may make managing\n   address assignment significantly different\
    \ from DHCPv4 failover.  In\n   DHCPv4, it was not possible to use a hash or calculated\
    \ technique to\n   divide the significantly more limited address space, and therefore,\n\
    \   much of the protocol that deals with pool balancing and rebalancing\n   might\
    \ not be necessary and can be done mathematically.  Also, because\n   of the much\
    \ lower degree of contention for IP addresses, the DHCPv6\n   failover protocol\
    \ does not need to be tuned to support rapid\n   reclamation of IPv6 addresses\
    \ following the loss of a failover peer's\n   database.\n   However, DHCPv6 prefix\
    \ delegation is similar to IPv4 addressing in\n   terms of the number of available\
    \ leases, and therefore, techniques\n   for pool balancing and rebalancing and\
    \ more rapid reclamation of\n   prefixes allocated by a failed peer will be needed.\n"
- title: 7.  DHCPv6 Failover Requirements
  contents:
  - "7.  DHCPv6 Failover Requirements\n   This section summarizes the requirements\
    \ for DHCPv6 failover.\n   Certain capabilities may be useful in some, but not\
    \ all, scenarios.\n   Such additional features will be considered optional parts\
    \ of\n   failover and will be defined in separate documents.  As such, this\n\
    \   document can be considered an attempt to define requirements for the\n   DHCPv6\
    \ failover \"core\" protocol.\n   The core of the DHCPv6 failover protocol is\
    \ expected to provide the\n   following properties:\n   1.  The number of supported\
    \ partners must be exactly two, i.e., there\n       are at most two servers that\
    \ are aware of a specific lease.\n   2.  For each prefix or address pool, a server\
    \ must not participate in\n       more than one failover relationship.\n   3.\
    \  The defined protocol must support the m-to-1 model (i.e., one\n       server\
    \ may form more than one relationship), but an\n       implementation may choose\
    \ to implement only the 1-to-1 model\n       (i.e., everything from one server\
    \ is backed on another).\n   4.  One partner must be able to continue serving\
    \ leases offered by\n       the other partner.  This property is also sometimes\
    \ called \"lease\n       stability\".  The failure of either failover partner\
    \ should have\n       minimal or no impact on client connectivity.  In particular,\
    \ it\n       must not force the client to change addresses and/or change\n   \
    \    prefixes delegated to it.  Lease stability has the aim of\n       avoiding\
    \ disturbance to long-lived connections.\n   5.  Prefix delegation must be supported.\n\
    \   6.  Use of the failover protocol must not introduce significant\n       performance\
    \ impact on server response times.  Therefore,\n       synchronization between\
    \ partners must be done using some form of\n       lazy updates (see Section 5.2.2).\n\
    \   7.  The pair of failover servers must be able to recover from a\n       server\
    \ down failure (see Section 5.1.1).\n   8.  The pair of failover servers must\
    \ be able to recover from a\n       network partition event (see Section 5.1.2).\n\
    \   9.  The design must allow secure communication between the failover\n    \
    \   partners.\n   10. The definition of extensions to this core protocol should\
    \ be\n       allowed, when possible.\n   Depending on the specific nature of the\
    \ failure, the recovery\n   procedures mentioned in points 7 and 8 may require\
    \ manual\n   intervention.\n   High availability is a property of the protocol\
    \ that allows clients\n   to receive DHCPv6 services despite the failure of individual\
    \ DHCPv6\n   servers.  In particular, it means the server that takes over\n  \
    \ providing service to clients from its failed partner will continue\n   serving\
    \ the same addresses and/or prefixes.  This property is also\n   called \"lease\
    \ stability\".\n   Although progress on a standardized interoperable DHCPv4 failover\n\
    \   protocol has stalled, vendor-specific DHCPv4 failover protocols have\n   been\
    \ deployed that meet these requirements to a large extent.\n   Accordingly, it\
    \ would be appropriate to take into account the likely\n   coexistence of DHCPv4\
    \ and DHCPv6 failover solutions.  In particular,\n   certain features that are\
    \ common to both IPv4 and IPv6\n   implementations, such as the DNS Update mechanism,\
    \ should be taken\n   into consideration to ensure compatible operation.\n"
- title: 7.1.  Features out of Scope
  contents:
  - "7.1.  Features out of Scope\n   The following features are explicitly out of\
    \ scope.\n   1.  Load Balancing - This capability is considered an extension and\n\
    \       may be defined in a separate document.  It must not be part of\n     \
    \  the core protocol but rather defined as an extension.  The\n       primary\
    \ reason for this the desire to limit the complexity of the\n       core protocol.\
    \  See [LOAD-BALANCING].\n   2.  Configuration synchronization - Two failover\
    \ partners are\n       expected to maintain the same configuration.  Mismatched\n\
    \       configuration between partners is a frequent problem in failover\n   \
    \    solutions.  Unfortunately, that is an open-ended problem, since\n       different\
    \ servers have very different configuration data models.\n   3.  m-to-n model\
    \ (see Section 4.4).\n   4.  Servers participating in multiple failover relationships\
    \ for any\n       given prefix or address pool.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   The design must provide a mechanism whereby each\
    \ peer in a failover\n   relationship can identify the other peer, authenticate\
    \ that\n   identification, and validate that the identified peer is the one with\n\
    \   which communication is intended.  This mechanism should also\n   optionally\
    \ provide support for confidentiality.\n   The protocol specification, when it\
    \ is written, should provide\n   operational guidelines in the case of authentication\
    \ mechanisms that\n   require access to network servers that have the potential\
    \ to be\n   unreachable (e.g., what to do if a partner is reachable but the\n\
    \   remote Certificate Authority is unreachable due to a network\n   partition\
    \ event).\n   The security considerations for the design itself will be discussed\n\
    \   in the design document.\n"
- title: 9.  Acknowledgements
  contents:
  - "9.  Acknowledgements\n   This document extensively uses concepts, definitions\
    \ and other parts\n   of [DHCPV4-FAILOVER].  Thanks to Bernie Volz and Shawn Routhier\
    \ for\n   their frequent reviews and substantial contributions.  The authors\n\
    \   would also like to thank Qin Wu, Jean-Francois Tremblay, Frank\n   Sweetser,\
    \ Jiang Sheng, Yu Fu, Greg Rabil, Vithalprasad Gaitonde,\n   Krzysztof Nowicki,\
    \ Steinar Haug, Elwyn Davies, Ted Lemon, Benoit\n   Claise, Stephen Farrell, Michal\
    \ Hoeft, and Krzysztof Gierlowski for\n   their comments and feedback.\n   This\
    \ work has been partially supported by the Department of Computer\n   Communications\
    \ (a division of Gdansk University of Technology) and\n   the National Centre\
    \ for Research and Development (Poland) under the\n   European Regional Development\
    \ Fund, Grant No.  POIG.01.01.02-00-045 /\n   09-00 (Future Internet Engineering\
    \ Project).\n"
- title: 10.  References
  contents:
  - '10.  References

    '
- title: 10.1.  Normative References
  contents:
  - "10.1.  Normative References\n   [RFC3315]  Droms, R., Bound, J., Volz, B., Lemon,\
    \ T., Perkins, C.,\n              and M. Carney, \"Dynamic Host Configuration\
    \ Protocol for\n              IPv6 (DHCPv6)\", RFC 3315, July 2003.\n   [RFC3633]\
    \  Troan, O. and R. Droms, \"IPv6 Prefix Options for Dynamic\n              Host\
    \ Configuration Protocol (DHCP) version 6\", RFC 3633,\n              December\
    \ 2003.\n   [RFC4704]  Volz, B., \"The Dynamic Host Configuration Protocol for\n\
    \              IPv6 (DHCPv6) Client Fully Qualified Domain Name (FQDN)\n     \
    \         Option\", RFC 4704, October 2006.\n"
- title: 10.2.  Informative References
  contents:
  - "10.2.  Informative References\n   [DHCPV4-FAILOVER]\n              Droms, R.,\
    \ Kinnear, K., Stapp, M., Volz, B., Gonczi, S.,\n              Rabil, G., Dooley,\
    \ M., and A. Kapur, \"DHCP Failover\n              Protocol\", Work in Progress,\
    \ March 2003.\n   [LOAD-BALANCING]\n              Kostur, A., \"DHC Load Balancing\
    \ Algorithm for DHCPv6\",\n              Work in Progress, December 2012.\n  \
    \ [RFC2136]  Vixie, P., Thomson, S., Rekhter, Y., and J. Bound,\n            \
    \  \"Dynamic Updates in the Domain Name System (DNS UPDATE)\",\n             \
    \ RFC 2136, April 1997.\n   [RFC5970]  Huth, T., Freimann, J., Zimmer, V., and\
    \ D. Thaler, \"DHCPv6\n              Options for Network Boot\", RFC 5970, September\
    \ 2010.\n   [RFC6853]  Brzozowski, J., Tremblay, J., Chen, J., and T. Mrugalski,\n\
    \              \"DHCPv6 Redundancy Deployment Considerations\", BCP 180,\n   \
    \           RFC 6853, February 2013.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Tomek Mrugalski\n   Internet Systems Consortium, Inc.\n\
    \   950 Charter Street\n   Redwood City, CA  94063\n   USA\n   Phone: +1 650 423\
    \ 1345\n   EMail: tomasz.mrugalski@gmail.com\n   Kim Kinnear\n   Cisco Systems,\
    \ Inc.\n   1414 Massachusetts Ave.\n   Boxborough, Massachusetts  01719\n   USA\n\
    \   Phone: +1 (978) 936-0000\n   EMail: kkinnear@cisco.com\n"
