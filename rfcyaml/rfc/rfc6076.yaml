- contents:
  - '           Basic Telephony SIP End-to-End Performance Metrics

    '
  title: __initial_text__
- contents:
  - "Abstract\n   This document defines a set of metrics and their usage to evaluate\n
    \  the performance of end-to-end Session Initiation Protocol (SIP) for\n   telephony
    services in both production and testing environments.  The\n   purpose of this
    document is to combine a standard set of common\n   metrics, allowing interoperable
    performance measurements, easing the\n   comparison of industry implementations.\n"
  title: Abstract
- contents:
  - "Status of This Memo\n   This is an Internet Standards Track document.\n   This
    document is a product of the Internet Engineering Task Force\n   (IETF).  It represents
    the consensus of the IETF community.  It has\n   received public review and has
    been approved for publication by the\n   Internet Engineering Steering Group (IESG).
    \ Further information on\n   Internet Standards is available in Section 2 of RFC
    5741.\n   Information about the current status of this document, any errata,\n
    \  and how to provide feedback on it may be obtained at\n   http://www.rfc-editor.org/info/rfc6076.\n"
  title: Status of This Memo
- contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified
    as the\n   document authors.  All rights reserved.\n   This document is subject
    to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n
    \  (http://trustee.ietf.org/license-info) in effect on the date of\n   publication
    of this document.  Please review these documents\n   carefully, as they describe
    your rights and restrictions with respect\n   to this document.  Code Components
    extracted from this document must\n   include Simplified BSD License text as described
    in Section 4.e of\n   the Trust Legal Provisions and are provided without warranty
    as\n   described in the Simplified BSD License.\n   This document may contain
    material from IETF Documents or IETF\n   Contributions published or made publicly
    available before November\n   10, 2008.  The person(s) controlling the copyright
    in some of this\n   material may not have granted the IETF Trust the right to
    allow\n   modifications of such material outside the IETF Standards Process.\n
    \  Without obtaining an adequate license from the person(s) controlling\n   the
    copyright in such materials, this document may not be modified\n   outside the
    IETF Standards Process, and derivative works of it may\n   not be created outside
    the IETF Standards Process, except to format\n   it for publication as an RFC
    or to translate it into languages other\n   than English.\n"
  title: Copyright Notice
- contents:
  - "Table of Contents\n   1. Introduction and Scope ..........................................3\n
    \  2. Terminology .....................................................4\n   3.
    Time Interval Measurement and Reporting .........................5\n   4. SIP
    Performance Metrics .........................................7\n      4.1. Registration
    Request Delay (RRD) ...........................8\n      4.2. Ineffective Registration
    Attempts (IRAs) ...................9\n      4.3. Session Request Delay (SRD) ...............................10\n
    \          4.3.1. Successful Session Setup SRD .......................11\n           4.3.2.
    Failed Session Setup SRD ...........................12\n      4.4. Session Disconnect
    Delay (SDD) ............................13\n      4.5. Session Duration Time (SDT)
    ...............................15\n           4.5.1. Successful Session Duration
    SDT ....................15\n           4.5.2. Failed Session Completion SDT ......................17\n
    \     4.6. Session Establishment Ratio (SER) .........................18\n      4.7.
    Session Establishment Effectiveness Ratio (SEER) ..........19\n      4.8. Ineffective
    Session Attempts (ISAs) .......................20\n      4.9. Session Completion
    Ratio (SCR) ............................21\n   5. Additional Considerations ......................................23\n
    \     5.1. Metric Correlations .......................................23\n      5.2.
    Back-to-Back User Agent (B2BUA) ...........................23\n      5.3. Authorization
    and Authentication ..........................23\n      5.4. Forking ...................................................24\n
    \     5.5. Data Collection ...........................................24\n      5.6.
    Testing Documentation .....................................25\n   6. Conclusions
    ....................................................25\n   7. Security Considerations
    ........................................25\n   8. Contributors ...................................................26\n
    \  9. Acknowledgements ...............................................26\n   10.
    References ....................................................26\n      10.1.
    Normative References .....................................26\n      10.2. Informative
    References ...................................27\n"
  title: Table of Contents
- contents:
  - "1.  Introduction and Scope\n   SIP has become a widely used standard among many
    service providers,\n   vendors, and end users in the telecommunications industry.
    \ Although\n   there are many different standards for measuring the performance
    of\n   telephony signaling protocols, such as Signaling System 7 (SS7), none\n
    \  of the metrics specifically address SIP.\n   The scope of this document is
    limited to the definitions of a\n   standard set of metrics for measuring and
    reporting SIP performance\n   from an end-to-end perspective in a telephony environment.
    \ The\n   metrics introduce a common foundation for understanding and\n   quantifying
    performance expectations between service providers,\n   vendors, and the users
    of services based on SIP.  The intended\n   audience for this document can be
    found among network operators, who\n   often collect information on the responsiveness
    of the network to\n   customer requests for services.\n   Measurements of the
    metrics described in this document are affected\n   by variables external to SIP.
    \ The following is a non-exhaustive list\n   of examples:\n   o  Network connectivity\n
    \  o  Switch and router performance\n   o  Server processes and hardware performance\n
    \  This document defines a list of pertinent metrics for varying aspects\n   of
    a telephony environment.  They may be used individually or as a\n   set based
    on the usage of SIP within the context of a given\n   telecommunications service.\n
    \  The metrics defined in this document DO NOT take into consideration\n   the
    impairment or failure of actual application processing of a\n   request or response.
    \ The metrics do not distinguish application\n   processing time from other sources
    of delay, such as packet transfer\n   delay.\n   Metrics designed to quantify
    single device application processing\n   performance are beyond the scope of this
    document.\n   This document does not provide any numerical objectives or acceptance\n
    \  threshold values for the SIP performance metrics defined below, as\n   these
    items are beyond the scope of IETF activities, in general.\n   The metrics defined
    in this document are applicable in scenarios\n   where the SIP messages launched
    (into a network under test) are\n   dedicated messages for testing purposes, or
    where the messages are\n   user-initiated and a portion of the live is traffic
    present.  These\n   two scenarios are sometimes referred to as active and passive\n
    \  measurement, respectively.\n"
  title: 1.  Introduction and Scope
- contents:
  - "2.  Terminology\n   The following terms and conventions will be used throughout
    this\n   document:\n   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\",
    \"SHALL NOT\",\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\"
    in this\n   document are to be interpreted as described in RFC 2119 [RFC2119].\n
    \  End-to-End - This is described as two or more elements utilized for\n   initiating
    a request, receiving the request, and responding to the\n   request.  It encompasses
    elements as necessary to be involved in a\n   session dialog between the originating
    user agent client (UAC),\n   destination user agent server (UAS), and any interim
    proxies (may\n   also include back-to-back user agents (B2BUAs)).  This may be\n
    \  relative to a single operator's set of elements or may extend to\n   encompass
    all elements (if beyond a single operator's network)\n   associated with a session.\n
    \  Session - As described in RFC 3261 [RFC3261], SIP is used primarily\n   to
    request, create, and conclude sessions.  \"These sessions include\n   Internet
    telephone calls, multimedia distribution, and multimedia\n   conferences\".  The
    metrics within this document measure the\n   performance associated with the SIP
    dialogs necessary to establish\n   these sessions; therefore, they are titled
    as Session Request Delay,\n   Session Disconnect Delay, etc.  Although the titles
    of many of the\n   metrics include this term, they are specifically measuring
    the\n   signaling aspects only.  Each session is identified by a unique\n   \"Call-ID\",
    \"To\", and \"From\" header field tag.\n   Session Establishment - Session establishment
    occurs when a 200 OK\n   response from the target UA has been received, in response
    to the\n   originating UA's INVITE setup request, indicating the session setup\n
    \  request was successful.\n   Session Setup - As referenced within the sub-sections
    of Section 4.2\n   in this document, session setup is the set of messages and
    included\n   parameters directly related to the process of a UA requesting to\n
    \  establish a session with a corresponding UA.  This is also described\n   as
    a set of steps in order to establish \"ringing\" [RFC3261].\n"
  title: 2.  Terminology
- contents:
  - "3.  Time Interval Measurement and Reporting\n   Many of the metrics defined in
    this memo utilize a clock to assess\n   the time interval between two events.
    \ This section defines time-\n   related terms and reporting requirements.\n   t1
    - start time\n   This is the time instant (when a request is sent) that begins
    a\n   continuous time interval.  t1 occurs when the designated request has\n   been
    processed by the SIP application and the first bit of the\n   request packet has
    been sent from the UA or proxy (and is externally\n   observable at some logical
    or physical interface).\n   t1 represents the time at which each request-response
    test begins,\n   and SHALL be used to designate the time of day when a particular\n
    \  measurement was conducted (e.g., the Session Request Delay at \"t1\"\n   (at
    some specific UA interface) was measured to be X ms).\n   t4 - end time\n   This
    is the time instant that concludes the continuous time interval\n   begun when
    the related request is sent.  t4 occurs when the last bit\n   of the designated
    response is received by the SIP application at the\n   requesting device (and
    is externally observable at some logical or\n   physical interface).\n      Note:
    The designations t2 and t3 are reserved for future use at\n      another interface
    involved in satisfying a request.\n   Section 10.1 of [RFC2330] describes time-related
    issues in\n   measurements, and defines the errors that can be attributed to the\n
    \  clocks themselves.  These definitions are used in the material below.\n   Time-of-Day
    Accuracy\n   As defined above, t1 is associated with the start of a request and\n
    \  also serves as the time-of-day stamp associated with a single\n   specific
    measurement.  The clock offset [RFC2330] is the difference\n   between t1 and
    a recognized primary source of time, such as UTC\n   (offset = t1 - UTC).\n   When
    measurement results will be correlated with other results or\n   information using
    time-of-day stamps, then the time clock that\n   supplies t1 SHOULD be synchronized
    to a primary time source, to\n   minimize the clock's offset.  The clocks used
    at the different\n   measurement points SHOULD be synchronized to each other,
    to minimize\n   the relative offset (as defined in RFC2330).  The clock's offset
    and\n   the relative offset MUST be reported with each measurement.\n   Time Interval
    Accuracy\n   The accuracy of the t4-t1 interval is also critical to maintain and\n
    \  report.  The difference between a clock's offsets at t1 and t4 is one\n   source
    of error for the measurement and is associated with the\n   clock's skew [RFC2330].\n
    \  A stable and reasonably accurate clock is needed to make the time\n   interval
    measurements required by this memo.  This source of error\n   SHOULD be constrained
    to less than +/- 1 ms, implying 1-part-per-1000\n   frequency accuracy for a 1-second
    interval.  This implies that\n   greater stability is required as the length of
    the t4-t1 increases,\n   in order to constrain the error to be less than +/- 1
    ms.\n   There are other important aspects of clock operation:\n   1.  Synchronization
    protocols require some ability to make\n       adjustments to the local clock.
    \ However, these adjustments\n       (clock steps or slewing) can cause large
    errors if they occur\n       during the t1 to t4 measurement interval.  Clock
    correction\n       SHOULD be suspended during a t1 to t4 measurement interval,\n
    \      unless the time interval accuracy requirement above will be met.\n       Alternatively,
    a measurement SHOULD NOT be performed during clock\n       correction, unless
    the time interval accuracy requirement above\n       will be met.\n   2.  If a
    free-running clock is used to make the time interval\n       measurement, then
    the time of day reported with the measurement\n       (which is normally timestamp
    t1) SHOULD be derived from a\n       different clock that meets the time-of-day
    accuracy requirements\n       described above.\n   The physical operation of reading
    time from a clock may be\n   constrained by the delay to service the interrupt.
    \ Therefore, if the\n   accuracy of the time stamp read at t1 or t4 includes the
    interrupt\n   delay, this source of error SHOULD be known and included in the
    error\n   assessment.\n"
  title: 3.  Time Interval Measurement and Reporting
- contents:
  - "4.  SIP Performance Metrics\n   In regard to all of the following metrics, t1
    begins with the first\n   associated SIP message sent by either UA, and is not
    reset if the UA\n   must retransmit the same message, within the same transaction,\n
    \  multiple times.  The first associated SIP message indicates the t1\n   associated
    with the user or application expectation relative to the\n   request.\n   Some
    metrics are calculated using messages from different\n   transactions in order
    to measure across actions such as redirection\n   and failure recovery.  The end
    time is typically based on a\n   successful end-to-end provisional response, a
    successful final\n   response, or a failure final response for which there is
    no recovery.\n   The individual metrics detail which message to base the end time
    on.\n   The authentication method used to establish the SIP dialog will\n   change
    the message exchanges.  The example message exchanges used do\n   not attempt
    to describe all of the various authentication types.\n   Since authentication
    is frequently used, SIP Digest authentication\n   was used for example purposes.\n
    \  In regard to all of the metrics, the accuracy and granularity of the\n   output
    values are related to the accuracy and granularity of the\n   input values.  Some
    of the metrics below are defined by a ratio.\n   When the denominator of this
    ratio is 0, the metric is undefined.\n   While these metrics do not specify the
    sample size, this should be\n   taken into consideration.  These metrics will
    provide a better\n   indication of performance with larger sample sets.  For example,
    some\n   SIP Service Providers (SSPs) [RFC5486] may choose to collect input\n
    \  over an hourly, daily, weekly, or monthly timeframe, while another\n   SSP
    may choose to perform metric calculations over a varying set of\n   SIP dialogs.\n"
  - contents:
    - "4.1.  Registration Request Delay (RRD)\n   Registration Request Delay (RRD)
      is a measurement of the delay in\n   responding to a UA REGISTER request.  RRD
      SHALL be measured and\n   reported only for successful REGISTER requests, while
      Ineffective\n   Registration Attempts (Section 4.2) SHALL be reported for failures.\n
      \  This metric is measured at the originating UA.  The output value of\n   this
      metric is numerical and SHOULD be stated in units of\n   milliseconds.  The
      RRD is calculated using the following formula:\n      RRD = Time of Final Response
      - Time of REGISTER Request\n   In a successful registration attempt, RRD is
      defined as the time\n   interval from when the first bit of the initial REGISTER
      message\n   containing the necessary information is passed by the originating
      UA\n   to the intended registrar, until the last bit of the 200 OK is\n   received
      indicating the registration attempt has completed\n   successfully.  This dialog
      includes an expected authentication\n   challenge prior to receiving the 200
      OK as described in the following\n   registration flow examples.\n   The following
      message exchange provides an example of identifiable\n   events necessary for
      inputs in calculating RRD during a successful\n   registration completion:\n
      \                 UA1                 Registrar\n                   |                      |\n
      \                  |REGISTER              |\n            t1---->|--------------------->|\n
      \              /\\  |                   401|\n               ||  |<---------------------|\n
      \             RRD  |REGISTER              |\n               ||  |--------------------->|\n
      \              \\/  |                   200|\n            t4---->|<---------------------|\n
      \                  |                      |\n      Note: Networks with elements
      using primarily Digest authentication\n      will exhibit different RRD characteristics
      than networks with\n      elements primarily using other authentication mechanisms
      (such as\n      Identity).  Operators monitoring RRD in networks with a mixture
      of\n      authentication schemes should take note that the RRD measurements\n
      \     will likely have a multimodal distribution.\n"
    title: 4.1.  Registration Request Delay (RRD)
  - contents:
    - "4.2.  Ineffective Registration Attempts (IRAs)\n   Ineffective registration
      attempts are utilized to detect failures or\n   impairments causing the inability
      of a registrar to receive a UA\n   REGISTER request.  This metric is measured
      at the originating UA.\n   The output value of this metric is numerical and
      SHOULD be reported\n   as a percentage of registration attempts.\n   This metric
      is calculated as a percentage of total REGISTER requests.\n   The IRA percentage
      is calculated using the following formula:\n                          # of IRAs\n
      \       IRA % = ----------------------------- x 100\n                 Total
      # of REGISTER Requests\n   A failed registration attempt is defined as a final
      failure response\n   to the initial REGISTER request.  It usually indicates
      a failure\n   received from the destination registrar or interim proxies, or\n
      \  failure due to a timeout of the REGISTER request at the originating\n   UA.
      \ A failure response is described as a 4XX (excluding 401, 402,\n   and 407
      non-failure challenge response codes), 5XX, or possible 6XX\n   message.  A
      timeout failure is identified by the Timer F expiring.\n   IRAs may be used
      to detect problems in downstream signaling\n   functions, which may be impairing
      the REGISTER message from reaching\n   the intended registrar; or, it may indicate
      a registrar has become\n   overloaded and is unable to respond to the request.\n
      \  The following message exchange provides a timeout example of an\n   identifiable
      event necessary for input as a failed registration\n   attempt:\n                  UA1
      \               Registrar\n                   |                      |\n                   |REGISTER
      \             |\n                   |--------------------->|\n                   |REGISTER
      \             |\n                   |--------------------->|\n                   |REGISTER
      \             |\n                   |--------------------->|\n                   |
      \                     |\n      Failure ---->|***Timer F Expires    |\n                   |
      \                     |\n   In the previous message exchange, UA1 retries a
      REGISTER request\n   multiple times before the timer expires, indicating the
      failure.\n   Only the first REGISTER request MUST be used for input to the\n
      \  calculation and an IRA.  Subsequent REGISTER retries are identified\n   by
      the same transaction identifier (the same topmost Via header field\n   branch
      parameter value) and MUST be ignored for purposes of metric\n   calculation.
      \ This ensures an accurate representation of the metric\n   output.\n   The
      following message exchange provides a registrar servicing failure\n   example
      of an identifiable event necessary for input as a failed\n   registration attempt:\n
      \                 UA1                Registrar\n                   |                      |\n
      \                  |REGISTER              |\n                   |--------------------->|\n
      \                  |                      |\n                   |                      |\n
      \                  |                      |\n                   |                      |\n
      \                  |                   503|\n      Failure ---->|<---------------------|\n
      \                  |                      |\n"
    title: 4.2.  Ineffective Registration Attempts (IRAs)
  - contents:
    - "4.3.  Session Request Delay (SRD)\n   Session Request Delay (SRD) is utilized
      to detect failures or\n   impairments causing delays in responding to a UA session
      request.\n   SRD is measured for both successful and failed session setup requests\n
      \  as this metric usually relates to a user experience; however, SRD for\n   session
      requests ending in a failure MUST NOT be combined in the same\n   result with
      successful requests.  The duration associated with\n   success and failure responses
      will likely vary substantially, and the\n   desired output time associated with
      each will be significantly\n   different in many cases.  This metric is similar
      to Post-Selection\n   Delay defined in [E.721], and it is measured at the originating
      UA\n   only.  The output value of this metric MUST indicate whether the\n   output
      is for successful or failed session requests and SHOULD be\n   stated in units
      of seconds.  The SRD is calculated using the\n   following formula:\n      SRD
      = Time of Status Indicative Response - Time of INVITE\n"
    - contents:
      - "4.3.1.  Successful Session Setup SRD\n   In a successful request attempt,
        SRD is defined as the time interval\n   from when the first bit of the initial
        INVITE message containing the\n   necessary information is sent by the originating
        user agent to the\n   intended mediation or destination agent, until the last
        bit of the\n   first provisional response is received indicating an audible
        or\n   visual status of the initial session setup request.  (Note: In some\n
        \  cases, the initial INVITE may be forked.  Section 5.4 provides\n   information
        for consideration on forking.)  In SIP, the message\n   indicating status
        would be a non-100 Trying provisional message\n   received in response to
        an INVITE request.  In some cases, a non-100\n   Trying provisional message
        is not received, but rather a 200 message\n   is received as the first status
        message instead.  In these\n   situations, the 200 message would be used to
        calculate the interval.\n   In most circumstances, this metric relies on receiving
        a non-100\n   Trying message.  The use of the Provisional Response ACKnowledgement\n
        \  (PRACK) method [RFC3262] MAY improve the quality and consistency of\n   the
        results.\n   The following message exchange provides an example of identifiable\n
        \  events necessary for inputs in calculating SRD during a successful\n   session
        setup request without a redirect (i.e., 3XX message):\n                  UA1
        \                   UA2\n                   |                      |\n                   |INVITE
        \               |\n            t1---->|--------------------->|\n               /\\
        \ |                      |\n               ||  |                      |\n
        \             SRD  |                      |\n               ||  |                      |\n
        \              \\/  |                   180|\n            t4---->|<---------------------|\n
        \                  |                      |\n   The following message exchange
        provides an example of identifiable\n   events necessary for inputs in calculating
        SRD during a successful\n   session setup with a redirect (e.g., 302 Moved
        Temporarily):\n                  UA1             Redirect Server              UA2\n
        \                  |                      |                     |\n                   |INVITE
        \               |                     |\n            t1---->|--------------------->|
        \                    |\n               /\\  |                   302|                     |\n
        \              ||  |<---------------------|                     |\n               ||
        \ |ACK                   |                     |\n              SRD  |--------------------->|
        \                    |\n               ||  |INVITE                                      |\n
        \              ||  |------------------------------------------->|\n               \\/
        \ |                                         180|\n            t4---->|<-------------------------------------------|\n"
      title: 4.3.1.  Successful Session Setup SRD
    - contents:
      - "4.3.2.  Failed Session Setup SRD\n   In a failed request attempt, SRD is
        defined as the time interval from\n   when the first bit of the initial INVITE
        message containing the\n   necessary information is sent by the originating
        agent or user to the\n   intended mediation or destination agent, until the
        last bit of the\n   first provisional response or a failure indication response.
        \ A\n   failure response is described as a 4XX (excluding 401, 402, and 407\n
        \  non-failure challenge response codes), 5XX, or possible 6XX message.\n
        \  A change in the metric output might indicate problems in downstream\n   signaling
        functions, which may be impairing the INVITE message from\n   reaching the
        intended UA or may indicate changes in end-point\n   behavior.  While this
        metric calculates the delay associated with a\n   failed session request,
        the metric Ineffective Session Attempts\n   (Section 4.8) is used for calculating
        a ratio of session attempt\n   failures.\n   The following message exchange
        provides an example of identifiable\n   events necessary for inputs in calculating
        SRD during a failed\n   session setup attempt without a redirect (i.e., 3XX
        message):\n                  UA1                    UA2\n                   |
        \                     |\n                   |INVITE                |\n            t1---->|--------------------->|\n
        \              /\\  |                      |\n               ||  |                      |\n
        \             SRD  |                      |\n               ||  |                      |\n
        \              \\/  |                   480|\n            t4---->|<---------------------|\n
        \                  |                      |\n   The following message exchange
        provides an example of identifiable\n   events necessary for inputs in calculating
        SRD during a failed\n   session setup attempt with a redirect (e.g., 302 Moved
        Temporarily):\n                  UA1             Redirect Server              UA2\n
        \                  |                      |                     |\n                   |INVITE
        \               |                     |\n            t1---->|--------------------->|
        \                    |\n               /\\  |                   302|                     |\n
        \              ||  |<---------------------|                     |\n               ||
        \ |ACK                   |                     |\n              SRD  |--------------------->|
        \                    |\n               ||  |INVITE                                      |\n
        \              ||  |------------------------------------------->|\n               \\/
        \ |                                         480|\n            t4---->|<-------------------------------------------|\n"
      title: 4.3.2.  Failed Session Setup SRD
    title: 4.3.  Session Request Delay (SRD)
  - contents:
    - "4.4.  Session Disconnect Delay (SDD)\n   This metric is utilized to detect
      failures or impairments delaying\n   the time necessary to end a session.  SDD
      is measured for both\n   successful and failed session disconnects; however,
      SDD for session\n   disconnects ending in a failure MUST NOT be combined in
      the same\n   result with successful disconnects.  The duration associated with\n
      \  success and failure results will likely vary substantially, and the\n   desired
      output time associated with each will be significantly\n   different in many
      cases.  It can be measured from either end-point UA\n   involved in the SIP
      dialog.  The output value of this metric is\n   numerical and SHOULD be stated
      in units of milliseconds.  The SDD is\n   calculated using the following formula:\n
      \     SDD = Time of 2XX or Timeout - Time of Completion Message (BYE)\n   SDD
      is defined as the interval between the first bit of the sent\n   session completion
      message, such as a BYE, and the last bit of the\n   subsequently received 2XX
      response.  In some cases, a recoverable\n   error response, such as a 503 Retry-After,
      may be received.  In such\n   situations, these responses should not be used
      as the end time for\n   this metric calculation.  Instead, the successful (2XX)
      response\n   related to the recovery message is used.  The following message\n
      \  exchanges provide an example of identifiable events necessary for\n   inputs
      in calculating SDD during a successful session completion:\n   Measuring SDD
      at the originating UA (UA1) -\n                  UA1                    UA2\n
      \                  |                      |\n                   |INVITE                |\n
      \                  |--------------------->|\n                   |                   180|\n
      \                  |<---------------------|\n                   |                   200|\n
      \                  |<---------------------|\n                   |ACK                   |\n
      \                  |--------------------->|\n                   |BYE                   |\n
      \           t1---->|--------------------->|\n               /\\  |                      |\n
      \              ||  |                      |\n              SDD  |                      |\n
      \              ||  |                      |\n               \\/  |                   200|\n
      \           t4---->|<---------------------|\n   Measuring SDD at the target
      UA (UA2) -\n                  UA1                    UA2\n                   |
      \                     |\n                   |INVITE                |\n                   |--------------------->|\n
      \                  |                   180|\n                   |<---------------------|\n
      \                  |                   200|\n                   |<---------------------|\n
      \                  |ACK                   |\n                   |--------------------->|\n
      \                  |                   BYE|\n                   |<---------------------|<----t1\n
      \                  |                      |  /\\\n                   |                      |
      \ ||\n                   |                      | SDD\n                   |
      \                     |  ||\n                   |200                   |  \\/\n
      \                  |--------------------->|<----t4\n   In some cases, no response
      is received after a session completion\n   message is sent and potentially retried.
      \ In this case, the\n   completion message, such as a BYE, results in a Timer
      F expiration.\n   Sessions ending in this manner SHOULD be excluded from the
      metric\n   calculation.\n"
    title: 4.4.  Session Disconnect Delay (SDD)
  - contents:
    - "4.5.  Session Duration Time (SDT)\n   This metric is used to detect problems
      (e.g., poor audio quality)\n   causing short session durations.  SDT is measured
      for both successful\n   and failed session completions.  It can be measured
      from either end-\n   point UA involved in the SIP dialog.  This metric is similar
      to Call\n   Hold Time, and it is traditionally calculated as Average Call Hold\n
      \  Time (ACHT) in telephony applications of SIP.  The output value of\n   this
      metric is numerical and SHOULD be stated in units of seconds.\n   The SDT is
      calculated using the following formula:\n      SDT = Time of BYE or Timeout
      - Time of 200 OK response to INVITE\n   This metric does not calculate the duration
      of sessions leveraging\n   early media.  For example, some automated response
      systems only use\n   early media by responding with a SIP 183 Session Progress
      message\n   with the Session Description Protocol (SDP) connecting the\n   originating
      UA with the automated message.  Usually, in these\n   sessions the originating
      UA never receives a 200 OK, and the message\n   exchange ends with the originating
      UA sending a CANCEL.\n"
    - contents:
      - "4.5.1.  Successful Session Duration SDT\n   In a successful session completion,
        SDT is calculated as an average\n   and is defined as the duration of a dialog
        defined by the interval\n   between receipt of the first bit of a 200 OK response
        to an INVITE,\n   and receipt of the last bit of an associated BYE message
        indicating\n   dialog completion.  Retransmissions of the 200 OK and ACK messages\n
        \  due to network impairments do not reset the metric timers.\n   The following
        message exchanges provide an example of identifiable\n   events necessary
        for inputs in calculating SDT during a successful\n   session completion.
        \ (The message exchanges are changed between the\n   originating and target
        UAs to provide varying examples.):\n   Measuring SDT at the originating UA
        (UA1) -\n                  UA1                    UA2\n                   |
        \                     |\n                   |INVITE                |\n                   |--------------------->|\n
        \                  |                   180|\n                   |<---------------------|\n
        \                  |                   200|\n            t1---->|<---------------------|\n
        \              /\\  |ACK                   |\n               ||  |--------------------->|\n
        \              ||  |                      |\n              SDT  |                      |\n
        \              ||  |                      |\n               ||  |                      |\n
        \              \\/  |                   BYE|\n            t4---->|<---------------------|\n
        \                  |                      |\n   When measuring SDT at the
        target UA (UA2), it is defined by the\n   interval between sending the first
        bit of a 200 OK response to an\n   INVITE, and receipt of the last bit of
        an associated BYE message\n   indicating dialog completion.  If UA2 initiates
        the BYE, then it is\n   defined by the interval between sending the first
        bit of a 200 OK\n   response to an INVITE, and sending the first bit of an
        associated BYE\n   message indicating dialog completion.  This is illustrated
        in the\n   following example message exchange:\n                  UA1                    UA2\n
        \                  |                      |\n                   |INVITE                |\n
        \                  |--------------------->|\n                   |                   180|\n
        \                  |<---------------------|\n                   |                   200|\n
        \                  |<---------------------|<----t1\n                   |ACK
        \                  |  /\\\n                   |--------------------->|  ||\n
        \                  |                      |  ||\n                   |                      |
        \ SDT\n                   |                      |  ||\n                   |
        \                     |  ||\n                   |                   BYE|  \\/\n
        \                  |<---------------------|<----t4\n                   |                      |\n
        \  (In these two examples, t1 is the same even if either UA receives the\n
        \  BYE instead of sending it.)\n"
      title: 4.5.1.  Successful Session Duration SDT
    - contents:
      - "4.5.2.  Failed Session Completion SDT\n   In some cases, no response is received
        after a session completion\n   message is sent and potentially retried.  In
        this case, SDT is\n   defined as the interval between receiving the first
        bit of a 200 OK\n   response to an INVITE, and the resulting Timer F expiration.
        \ The\n   following message exchanges provide an example of identifiable events\n
        \  necessary for inputs in calculating SDT during a failed session\n   completion
        attempt:\n   Measuring SDT at the originating UA (UA1) -\n                  UA1
        \                   UA2\n                   |                      |\n                   |INVITE
        \               |\n                   |--------------------->|\n                   |
        \                  180|\n                   |<---------------------|\n                   |
        \                  200|\n            t1---->|<---------------------|\n               /\\
        \ |ACK                   |\n               ||  |--------------------->|\n
        \              ||  |BYE                   |\n              SDT  |--------------------->|\n
        \              ||  |BYE                   |\n               ||  |--------------------->|\n
        \              \\/  |                      |\n            t4---->|***Timer
        F Expires    |\n   When measuring SDT at UA2, SDT is defined as the interval
        between\n   sending the first bit of a 200 OK response to an INVITE, and the\n
        \  resulting Timer F expiration.  This is illustrated in the following\n   example
        message exchange:\n                  UA1                    UA2\n                   |
        \                     |\n                   |INVITE                |\n                   |--------------------->|\n
        \                  |                   180|\n                   |<---------------------|\n
        \                  |                   200|\n                   |<---------------------|<----t1\n
        \                  |                   ACK|  /\\\n                   |--------------------->|
        \ ||\n                   |                   BYE|  ||\n                   |<---------------------|
        \ SDT\n                   |                   BYE|  ||\n                   |<---------------------|
        \ ||\n                   |                      |  \\/\n                   |
        \   Timer F Expires***|<----t4\n   Note that in the presence of message loss
        and retransmission, the\n   value of this metric measured at UA1 may differ
        from the value\n   measured at UA2 up to the value of Timer F.\n"
      title: 4.5.2.  Failed Session Completion SDT
    title: 4.5.  Session Duration Time (SDT)
  - contents:
    - "4.6.  Session Establishment Ratio (SER)\n   This metric is used to detect the
      ability of a terminating UA or\n   downstream proxy to successfully establish
      sessions per new session\n   INVITE requests.  SER is defined as the ratio of
      the number of new\n   session INVITE requests resulting in a 200 OK response,
      to the total\n   number of attempted INVITE requests less INVITE requests resulting
      in\n   a 3XX response.  This metric is similar to the Answer Seizure Ratio\n
      \  (ASR) defined in [E.411].  It is measured at the originating UA only.\n   The
      output value of this metric is numerical and SHOULD be adjusted\n   to indicate
      a percentage of successfully established sessions.  The\n   SER is calculated
      using the following formula:\n                # of INVITE Requests w/ associated
      200 OK\n   SER = --------------------------------------------------------- x
      100\n             (Total # of INVITE Requests) -\n                       (#
      of INVITE Requests w/ 3XX Response)\n   The following message exchange provides
      an example of identifiable\n   events necessary for inputs in determining session
      establishment as\n   described above:\n                           UA1                 UA2\n
      \                           |                   |\n                            |INVITE
      \            |\n               +----------->|------------------>|\n               |
      \           |                180|\n               |            |<------------------|\n
      \     Session Established   |                   |\n               |            |
      \                  |\n               |            |                200|\n               +----------->|<------------------|\n
      \                           |                   |\n   The following is an example
      message exchange including a SIP 302\n   Redirect response.\n                            UA1
      \                UA2                 UA3\n                             |                   |
      \                  |\n                             |INVITE             |                   |\n
      \               +----------->|------------------>|                   |\n                |
      \           |                   |                   |\n      INVITE w/ 3XX Response
      |                   |                   |\n                |            |                302|
      \                  |\n                +----------->|<------------------|                   |\n
      \                            |                   |                   |\n                             |INVITE
      \                                |\n                +----------->|-------------------------------------->|\n
      \               |            |                                       |\n                |
      \           |                                    180|\n       Session Established
      \  |<--------------------------------------|\n                |            |
      \                                      |\n                |            |                                    200|\n
      \               +----------->|<--------------------------------------|\n                             |
      \                                      |\n"
    title: 4.6.  Session Establishment Ratio (SER)
  - contents:
    - "4.7.  Session Establishment Effectiveness Ratio (SEER)\n   This metric is complimentary
      to SER, but is intended to exclude the\n   potential effects of an individual
      user of the target UA from the\n   metric.  SEER is defined as the ratio of
      the number of INVITE\n   requests resulting in a 200 OK response and INVITE
      requests resulting\n   in a 480, 486, 600, or 603; to the total number of attempted
      INVITE\n   requests less INVITE requests resulting in a 3XX response.  The\n
      \  response codes 480, 486, 600, and 603 were chosen because they\n   clearly
      indicate the effect of an individual user of the UA.  It is\n   possible an
      individual user could cause a negative effect on the UA.\n   For example, they
      may have misconfigured the UA, causing a response\n   code not directly related
      to an SSP, but this cannot be easily\n   determined from an intermediary B2BUA
      somewhere between the\n   originating and terminating UAs.  With this in consideration,\n
      \  response codes such as 401, 407, and 420 (not an exhaustive list)\n   were
      not included in the numerator of the metric.  This metric is\n   similar to
      the Network Effectiveness Ratio (NER) defined in [E.411].\n   It is measured
      at the originating UA only.  The output value of this\n   metric is numerical
      and SHOULD be adjusted to indicate a percentage\n   of successfully established
      sessions less common UAS failures.\n   The SEER is calculated using the following
      formula:\n   SEER =\n    # of INVITE Requests w/ associated 200, 480, 486, 600,
      or 603\n    ------------------------------------------------------------- x
      100\n            (Total # of INVITE Requests) -\n                      (# of
      INVITE Requests w/ 3XX Response)\n   Reference the example flows in Section
      4.6.\n"
    title: 4.7.  Session Establishment Effectiveness Ratio (SEER)
  - contents:
    - "4.8.  Ineffective Session Attempts (ISAs)\n   Ineffective session attempts
      occur when a proxy or agent internally\n   releases a setup request with a failed
      or overloaded condition.  This\n   metric is similar to Ineffective Machine
      Attempts (IMAs) in telephony\n   applications of SIP, and was adopted from Telcordia
      GR-512-CORE\n   [GR-512].  The output value of this metric is numerical and
      SHOULD be\n   adjusted to indicate a percentage of ineffective session attempts.\n
      \  The following failure responses provide a guideline for this\n   criterion:\n
      \  o  408 Request Timeout\n   o  500 Server Internal Error\n   o  503 Service
      Unavailable\n   o  504 Server Time-out\n   This set was derived in a similar
      manner as described in Section 4.7.\n   In addition, 408 failure responses may
      indicate an overloaded state\n   with a downstream element; however, there are
      situations other than\n   overload that may cause an increase in 408 responses.\n
      \  This metric is calculated as a percentage of total session setup\n   requests.
      \ The ISA percentage is calculated using the following\n   formula:\n                            #
      of ISAs\n          ISA % = ----------------------------- x 100\n                   Total
      # of Session Requests\n   The following dialog [RFC3665] provides an example
      describing message\n   exchanges of an ineffective session attempt:\n          UA1
      \          Proxy 1          Proxy 2             UA2\n           |                |
      \               |                |\n           |INVITE          |                |
      \               |\n           |--------------->|                |                |\n
      \          |             407|                |                |\n           |<---------------|
      \               |                |\n           |ACK             |                |
      \               |\n           |--------------->|                |                |\n
      \          |INVITE          |                |                |\n           |--------------->|INVITE
      \         |                |\n           |             100|--------------->|INVITE
      \         |\n           |<---------------|             100|--------------->|\n
      \          |                |<---------------|                |\n           |
      \               |                |INVITE          |\n           |                |
      \               |--------------->|\n           |                |                |
      \               |\n           |                |                |INVITE          |\n
      \          |                |                |--------------->|\n           |
      \               |                |                |\n           |                |
      \            408|                |\n           |             408|<---------------|
      \               |\n           |<---------------|ACK             |                |\n
      \          |                |--------------->|                |\n           |ACK
      \            |                |                |\n           |--------------->|
      \               |                |\n"
    title: 4.8.  Ineffective Session Attempts (ISAs)
  - contents:
    - "4.9.  Session Completion Ratio (SCR)\n   A session completion is defined as
      a SIP dialog, which completes\n   without failing due to a lack of response
      from an intended proxy or\n   UA.  This metric is similar to the Call Completion
      Ratio (CCR) in\n   telephony applications of SIP.  The output value of this
      metric is\n   numerical and SHOULD be adjusted to indicate a percentage of\n
      \  successfully completed sessions.\n   This metric is calculated as a percentage
      of total sessions completed\n   successfully.  The SCR percentage is calculated
      using the following\n   formula:\n                   # of Successfully Completed
      Sessions\n         SCR % = --------------------------------------- x 100\n                        Total
      # of Session Requests\n   The following dialog [RFC3665] provides an example
      describing the\n   necessary message exchanges of a successful session completion:\n
      \         UA1           Proxy 1          Proxy 2             UA2\n           |
      \               |                |                |\n           |INVITE          |
      \               |                |\n           |--------------->|                |
      \               |\n           |             407|                |                |\n
      \          |<---------------|                |                |\n           |ACK
      \            |                |                |\n           |--------------->|
      \               |                |\n           |INVITE          |                |
      \               |\n           |--------------->|INVITE          |                |\n
      \          |             100|--------------->|INVITE          |\n           |<---------------|
      \            100|--------------->|\n           |                |<---------------|
      \               |\n           |                |                |             180|\n
      \          |                |            180 |<---------------|\n           |
      \            180|<---------------|                |\n           |<---------------|
      \               |             200|\n           |                |             200|<---------------|\n
      \          |             200|<---------------|                |\n           |<---------------|
      \               |                |\n           |ACK             |                |
      \               |\n           |--------------->|ACK             |                |\n
      \          |                |--------------->|ACK             |\n           |
      \               |                |--------------->|\n           |                Both
      Way RTP Media                |\n           |<================================================>|\n
      \          |                |                |             BYE|\n           |
      \               |             BYE|<---------------|\n           |             BYE|<---------------|
      \               |\n           |<---------------|                |                |\n
      \          |200             |                |                |\n           |--------------->|200
      \            |                |\n           |                |--------------->|200
      \            |\n           |                |                |--------------->|\n
      \          |                |                |                |\n"
    title: 4.9.  Session Completion Ratio (SCR)
  title: 4.  SIP Performance Metrics
- contents:
  - '5.  Additional Considerations

    '
  - contents:
    - "5.1.  Metric Correlations\n   These metrics may be used to determine the performance
      of a domain\n   and/or user.  The following is an example subset of dimensions
      for\n   providing further granularity per metric:\n   o  To \"user\"\n   o  From
      \"user\"\n   o  Bi-direction \"user\"\n   o  To \"domain\"\n   o  From \"domain\"\n
      \  o  Bi-direction \"domain\"\n"
    title: 5.1.  Metric Correlations
  - contents:
    - "5.2.  Back-to-Back User Agent (B2BUA)\n   A B2BUA may impact the ability to
      collect these metrics with an end-\n   to-end perspective.  It is necessary
      to realize that a B2BUA may act\n   as an originating UAC and terminating UAS,
      or it may act as a proxy.\n   In some cases, it may be necessary to consider
      information collected\n   from both sides of the B2BUA in order to determine
      the end-to-end\n   perspective.  In other cases, the B2BUA may act simply as
      a proxy\n   allowing data to be derived as necessary for the input into any
      of\n   the listed calculations.\n"
    title: 5.2.  Back-to-Back User Agent (B2BUA)
  - contents:
    - "5.3.  Authorization and Authentication\n   During the process of setting up
      a SIP dialog, various authentication\n   methods may be utilized.  These authentication
      methods will add to\n   the duration as measured by the metrics, and the length
      of time will\n   vary based on those methods.  The failures of these authentication\n
      \  methods will also be captured by these metrics, since SIP is\n   ultimately
      used to indicate the success or failure of the\n   authorization and/or authentication
      attempt.  The metrics in\n   Section 3 are inclusive of the duration associated
      with this process,\n   even if the method is external to SIP.  This was included\n
      \  purposefully, due to its inherent impact on the protocol and the\n   subsequent
      SIP dialogs.\n"
    title: 5.3.  Authorization and Authentication
  - contents:
    - "5.4.  Forking\n   Forking SHOULD be considered when determining the messages
      associated\n   with the input values for the described metrics.  If all of the\n
      \  forked dialogs were used in the metric calculations, the numbers\n   would
      skew dramatically.  There are two different points of forking,\n   and each
      MUST be considered.  First, forking may occur at a proxy\n   downstream from
      the UA that is being used for metric input values.\n   The downstream proxy
      is responsible for forking a message.  Then,\n   this proxy will send provisional
      (e.g., 180) messages received from\n   the requests and send the accepted (e.g.,
      200) response to the UA.\n   Second, in the cases where the originating UA or
      proxy is forking the\n   messages, then it MUST parse the message exchanges
      necessary for\n   input into the metrics.  For example, it MAY utilize the first
      INVITE\n   or set of INVITE messages sent and the first accepted 200 OK.  Tags\n
      \  will identify this dialog as distinct from the other 200 OK\n   responses,
      which are acknowledged, and an immediate BYE is sent.  The\n   application responsible
      for capturing and/or understanding the input\n   values MUST utilize these tags
      to distinguish between dialog\n   requests.\n   Note that if an INVITE is forked
      before reaching its destination,\n   multiple early dialogs are likely, and
      multiple confirmed dialogs are\n   possible (though unlikely).  When this occurs,
      an SRD measurement\n   should be taken for each dialog that is created (early
      or confirmed).\n"
    title: 5.4.  Forking
  - contents:
    - "5.5.  Data Collection\n   The input necessary for these calculations may be
      collected in a\n   number of different manners.  It may be collected or retrieved
      from\n   call detail records (CDRs) or raw signaling information generated by\n
      \  a proxy or UA.  When using records, time synchronization MUST be\n   considered
      between applicable elements.\n   If these metrics are calculated at individual
      elements (such as\n   proxies or endpoints) instead of by a centralized management
      system,\n   and the individual elements use different measurement sample sizes,\n
      \  then the metrics reported for the same event at those elements may\n   differ
      significantly.\n   The information may also be transmitted through the use of
      network\n   management protocols like the Simple Network Management Protocol\n
      \  (SNMP) and via future extensions to the SIP Management Information\n   Base
      (MIB) modules [RFC4780], or through a potential undefined new\n   performance
      metric event package [RFC3265] retrieved via SUBSCRIBE\n   requests.\n   Data
      may be collected for a sample of calls or all calls, and may\n   also be derived
      from test call scenarios.  These metrics are flexible\n   based on the needs
      of the application.\n   For consistency in calculation of the metrics, elements
      should expect\n   to reveal event inputs for use by a centralized management
      system,\n   which would calculate the metrics based on a varying set sample
      size\n   of inputs received from elements compliant with this specification.\n"
    title: 5.5.  Data Collection
  - contents:
    - "5.6.  Testing Documentation\n   In some cases, these metrics will be used to
      provide output values to\n   signify the performance level of a specific SIP-based
      element.  When\n   using these metrics in a test environment, the environment
      MUST be\n   accurately documented for the purposes of replicating any output\n
      \  values in future testing and/or validation.\n"
    title: 5.6.  Testing Documentation
  title: 5.  Additional Considerations
- contents:
  - "6.  Conclusions\n   This document provides a description of common performance
    metrics\n   and their defined use with SIP.  The use of these metrics will\n   provide
    a common viewpoint across all vendors, service providers, and\n   users.  These
    metrics will likely be utilized in production telephony\n   SIP environments for
    providing input regarding Key Performance\n   Indicators (KPI) and Service Level
    Agreement (SLA) indications;\n   however, they may also be used for testing end-to-end
    SIP-based\n   service environments.\n"
  title: 6.  Conclusions
- contents:
  - "7.  Security Considerations\n   Security should be considered in the aspect of
    securing the relative\n   data utilized in providing input to the above calculations.
    \ All\n   other aspects of security should be considered as described in\n   RFC
    3261 [RFC3261].\n   Implementers of these metrics MUST realize that these metrics
    could\n   be used to describe characteristics of customer and user usage\n   patterns,
    and privacy should be considered when collecting,\n   transporting, and storing
    them.\n"
  title: 7.  Security Considerations
- contents:
  - "8.  Contributors\n   The following people made substantial contributions to this
    work:\n      Carol Davids         Illinois Institute of Technology\n      Marian
    Delkinov      Ericsson\n      Adam Uzelac          Global Crossing\n      Jean-Francois
    Mule   CableLabs\n      Rich Terpstra        Level 3 Communications\n"
  title: 8.  Contributors
- contents:
  - "9.  Acknowledgements\n   We would like to thank Robert Sparks, John Hearty, and
    Dean Bayless\n   for their efforts in reviewing the document and providing insight\n
    \  regarding clarification of certain aspects described throughout the\n   document.
    \ We also thank Dan Romascanu for his insightful comments\n   and Vijay Gurbani
    for agreeing to perform the role of document\n   shepherd.\n"
  title: 9.  Acknowledgements
- contents:
  - '10.  References

    '
  - contents:
    - "10.1.  Normative References\n   [RFC2119]   Bradner, S., \"Key words for use
      in RFCs to Indicate\n               Requirement Levels\", BCP 14, RFC 2119,
      March 1997.\n   [RFC3261]   Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston,\n
      \              A., Peterson, J., Sparks, R., Handley, M., and E.\n               Schooler,
      \"SIP: Session Initiation Protocol\", RFC 3261,\n               June 2002.\n
      \  [RFC3262]   Rosenberg, J. and H. Schulzrinne, \"Reliability of\n               Provisional
      Responses in Session Initiation Protocol\n               (SIP)\", RFC 3262,
      June 2002.\n   [RFC3265]   Roach, A., \"Session Initiation Protocol (SIP)-Specific\n
      \              Event Notification\", RFC 3265, June 2002.\n   [RFC3665]   Johnston,
      A., Donovan, S., Sparks, R., Cunningham, C.,\n               and K. Summers,
      \"Session Initiation Protocol (SIP) Basic\n               Call Flow Examples\",
      BCP 75, RFC 3665, December 2003.\n   [RFC4780]   Lingle, K., Mule, J-F., Maeng,
      J., and D. Walker,\n               \"Management Information Base for the Session
      Initiation\n               Protocol (SIP)\", RFC 4780, April 2007.\n"
    title: 10.1.  Normative References
  - contents:
    - "10.2.  Informative References\n   [E.411]     ITU-T, \"Series E: Overall Network
      Operation, Telephone\n               Service, Service Operation and Human Factors\",
      E.411 ,\n               March 2000.\n   [E.721]     ITU-T, \"Series E: Overall
      Network Operation, Telephone\n               Service, Service Operation and
      Human Factors\", E.721 ,\n               May 1999.\n   [GR-512]    Telcordia,
      \"LSSGR: Reliability, Section 12\", GR-512-\n               CORE Issue 2, January
      1998.\n   [RFC2330]   Paxson, V., Almes, G., Mahdavi, J., and M. Mathis,\n               \"Framework
      for IP Performance Metrics\", RFC 2330,\n               May 1998.\n   [RFC5486]
      \  Malas, D. and D. Meyer, \"Session Peering for Multimedia\n               Interconnect
      (SPEERMINT) Terminology\", RFC 5486,\n               March 2009.\n"
    title: 10.2.  Informative References
  title: 10.  References
- contents:
  - "Authors' Addresses\n   Daryl Malas\n   CableLabs\n   858 Coal Creek Circle\n
    \  Louisville, CO  80027\n   US\n   Phone: +1 303 661 3302\n   EMail: d.malas@cablelabs.com\n
    \  Al Morton\n   AT&T Labs\n   200 Laurel Avenue South\n   Middletown, NJ  07748\n
    \  US\n   Phone: +1 732 420 1571\n   EMail: acmorton@att.com\n"
  title: Authors' Addresses
