- title: __initial_text__
  contents:
  - '                 NETBLT: A Bulk Data Transfer Protocol

    '
- title: 1. Status
  contents:
  - "1. Status\n   This document is a description of, and a specification for, the\n\
    \   NETBLT protocol.  It is a revision of the specification published in\n   NIC\
    \ RFC-969.  The protocol has been revised after extensive research\n   into NETBLT's\
    \ performance over long-delay, high-bandwidth satellite\n   channels.  Most of\
    \ the changes in the protocol specification have to\n   do with the computation\
    \ and use of data timers in a multiple\n   buffering data transfer model.\n  \
    \ This document is published for discussion and comment, and does not\n   constitute\
    \ a standard.  The proposal may change and certain parts of\n   the protocol have\
    \ not yet been specified; implementation of this\n   document is therefore not\
    \ advised.\n"
- title: 2. Introduction
  contents:
  - "2. Introduction\n   NETBLT (NETwork BLock Transfer) is a transport level protocol\n\
    \   intended for the rapid transfer of a large quantity of data between\n   computers.\
    \  It provides a transfer that is reliable and flow\n   controlled, and is designed\
    \ to provide maximum throughput over a wide\n   variety of networks.  Although\
    \ NETBLT currently runs on top of the\n   Internet Protocol (IP), it should be\
    \ able to operate on top of any\n   datagram protocol similar in function to IP.\n\
    \   NETBLT's motivation is to achieve higher throughput than other\n   protocols\
    \ might offer.  The protocol achieves this goal by trying to\n   minimize the\
    \ effect of several network-related problems: network\n   congestion, delays over\
    \ satellite links, and packet loss.\n   Its transmission rate-control algorithms\
    \ deal well with network\n   congestion; its multiple-buffering capability allows\
    \ high throughput\n   over long-delay satellite channels, and its various\n  \
    \ timeout/retransmit algorithms minimize the effect of packet loss\n   during\
    \ a transfer.  Most importantly, NETBLT's features give it good\n   performance\
    \ over long-delay channels without impairing performance\n   over high-speed LANs.\n\
    \   The protocol works by opening a connection between two \"clients\" (the\n\
    \   \"sender\" and the \"receiver\"), transferring the data in a series of\n \
    \  large data aggregates called \"buffers\", and then closing the\n   connection.\
    \  Because the amount of data to be transferred can be very\n   large, the client\
    \ is not required to provide at once all the data to\n   the protocol module.\
    \  Instead, the data is provided by the client in\n   buffers.  The NETBLT layer\
    \ transfers each buffer as a sequence of\n   packets; since each buffer is composed\
    \ of a large number of packets,\n   the per-buffer interaction between NETBLT\
    \ and its client is far more\n   efficient than a per-packet interaction would\
    \ be.\n   In its simplest form, a NETBLT transfer works as follows:  the\n   sending\
    \ client loads a buffer of data and calls down to the NETBLT\n   layer to transfer\
    \ it.  The NETBLT layer breaks the buffer up into\n   packets and sends these\
    \ packets across the network in Internet\n   datagrams.  The receiving NETBLT\
    \ layer loads these packets into a\n   matching buffer provided by the receiving\
    \ client.  When the last\n   packet in the buffer has arrived, the receiving NETBLT\
    \ checks to see\n   that all packets in that buffer have been correctly received.\
    \  If\n   some packets are missing, the receiving NETBLT requests that they be\n\
    \   resent.  When the buffer has been completely transmitted, the\n   receiving\
    \ client is notified by its NETBLT layer.  The receiving\n   client disposes of\
    \ the buffer and provides a new buffer to receive\n   more data.  The receiving\
    \ NETBLT notifies the sender that the new\n   buffer is ready, and the sender\
    \ prepares and sends the next buffer in\n   the same manner.  This continues until\
    \ all the data has been sent; at\n   that time the sender notifies the receiver\
    \ that the transmission has\n   been completed.  The connection is then closed.\n\
    \   As described above, the NETBLT protocol is \"lock-step\".  Action halts\n\
    \   after a buffer is transmitted, and begins again after confirmation is\n  \
    \ received from the receiver of data.  NETBLT provides for multiple\n   buffering,\
    \ a transfer model in which the sending NETBLT can transmit\n   new buffers while\
    \ earlier buffers are waiting for confirmation from\n   the receiving NETBLT.\
    \  Multiple buffering makes packet flow\n   essentially continuous and markedly\
    \ improves performance.\n   The remainder of this document describes NETBLT in\
    \ detail.  The next\n   sections describe the philosophy behind a number of protocol\n\
    \   features:  packetization, flow control, transfer reliability, and\n   connection\
    \ management. The final sections describe NETBLT's packet\n   formats.\n"
- title: 3. Buffers and Packets
  contents:
  - "3. Buffers and Packets\n   NETBLT is designed to permit transfer of a very large\
    \ amounts of data\n   between two clients.  During connection setup the sending\
    \ NETBLT can\n   inform the receiving NETBLT of the transfer size; the maximum\n\
    \   transfer length is 2**32 bytes.  This limit should permit any\n   practical\
    \ application.  The transfer size parameter is for the use of\n   the receiving\
    \ client; the receiving NETBLT makes no use of it.  A\n   NETBLT receiver accepts\
    \ data until told by the sender that the\n   transfer is complete.\n   The data\
    \ to be sent must be broken up into buffers by the client.\n   Each buffer must\
    \ be the same size, save for the last buffer.  During\n   connection setup, the\
    \ sending and receiving NETBLTs negotiate the\n   buffer size, based on limits\
    \ provided by the clients.  Buffer sizes\n   are in bytes only; the client is\
    \ responsible for placing data in\n   buffers on byte boundaries.\n   NETBLT has\
    \ been designed and should be implemented to work with\n   buffers of any size.\
    \  The only fundamental limitation on buffer size\n   should be the amount of\
    \ memory available to the client.  Buffers\n   should be as large as possible\
    \ since this minimizes the number of\n   buffer transmissions and therefore improves\
    \ performance.\n   NETBLT is designed to require a minimum amount of memory, allowing\n\
    \   the client to allocate as much memory as possible for buffer storage.\n  \
    \ In particular, NETBLT does not keep buffer copies for retransmission\n   purposes.\
    \  Instead, data to be retransmitted is recopied directly\n   from the client\
    \ buffer.  This means that the client cannot release\n   buffer storage piece\
    \ by piece as the buffer is sent, but this has not\n   been a problem in preliminary\
    \ NETBLT implementations.\n   Buffers are broken down by the NETBLT layer into\
    \ sequences of DATA\n   packets.  As with the buffer size, the DATA packet size\
    \ is negotiated\n   between the sending and receiving NETBLTs during connection\
    \ setup.\n   Unlike buffer size, DATA packet size is visible only to the NETBLT\n\
    \   layer.\n   All DATA packets save the last packet in a buffer must be the same\n\
    \   size.  Packets should be as large as possible, since NETBLT's\n   performance\
    \ is directly related to packet size.  At the same time,\n   the packets should\
    \ not be so large as to cause internetwork\n   fragmentation, since this normally\
    \ causes performance degradation.\n   All buffers save the last buffer must be\
    \ the same size; the last\n   buffer can be any size required to complete the\
    \ transfer.  Since the\n   receiving NETBLT does not know the transfer size in\
    \ advance, it needs\n   some way of identifying the last packet in each buffer.\
    \  For this\n   reason, the last packet of every buffer is not a DATA packet but\n\
    \   rather an LDATA packet.  DATA and LDATA packets are identical save\n   for\
    \ the packet type.\n"
- title: 4. Flow Control
  contents:
  - "4. Flow Control\n   NETBLT uses two strategies for flow control, one internal\
    \ and one at\n   the client level.\n   The sending and receiving NETBLTs transmit\
    \ data in buffers; client\n   flow control is therefore at a buffer level.  Before\
    \ a buffer can be\n   transmitted, NETBLT confirms that both clients have set\
    \ up matching\n   buffers, that one is ready to send data, and that the other\
    \ is ready\n   to receive data.  Either client can therefore control the flow\
    \ of\n   data by not providing a new buffer.  Clients cannot stop a buffer\n \
    \  transfer once it is in progress.\n   Since buffers can be quite large, there\
    \ has to be another method for\n   flow control that is used during a buffer transfer.\
    \  The NETBLT layer\n   provides this form of flow control.\n   There are several\
    \ flow control problems that could arise while a\n   buffer is being transmitted.\
    \  If the sending NETBLT is transferring\n   data faster than the receiving NETBLT\
    \ can process it, the receiver's\n   ability to buffer unprocessed packets could\
    \ be overflowed, causing\n   packet loss.  Similarly, a slow gateway or intermediate\
    \ network could\n   cause packets to collect and overflow network packet buffer\
    \ space.\n   Packets will then be lost within the network.  This problem is\n\
    \   particularly acute for NETBLT because NETBLT buffers will generally\n   be\
    \ quite large, and therefore composed of many packets.\n   A traditional solution\
    \ to packet flow control is a window system, in\n   which the sending end is permitted\
    \ to send only a certain number of\n   packets at a time.  Unfortunately, flow\
    \ control using windows tends\n   to result in low throughput.  Windows must be\
    \ kept small in order to\n   avoid overflowing hosts and gateways, and cannot\
    \ easily be updated,\n   since an end-to-end exchange is required for each window\
    \ change.\n   To permit high throughput over a variety of networks and gateways,\n\
    \   NETBLT uses a novel flow control method: rate control.  The\n   transmission\
    \ rate is negotiated by the sending and receiving NETBLTs\n   during connection\
    \ setup and after each buffer transmission.  The\n   sender uses timers, rather\
    \ than messages from the receiver, to\n   maintain the negotiated rate.\n   In\
    \ its simplest form, rate control specifies a minimum time period\n   per packet\
    \ transmission.  This can cause performance problems for\n   several reasons.\
    \  First, the transmission time for a single packet is\n   very small, frequently\
    \ smaller than the granularity of the timing\n   mechanism.  Also, the overhead\
    \ required to maintain timing mechanisms\n   on a per packet basis is relatively\
    \ high and lowers performance.\n   The solution is to control the transmission\
    \ rate of groups of\n   packets, rather than single packets.  The sender transmits\
    \ a burst of\n   packets over a negotiated time interval, then sends another burst.\n\
    \   In this way, the overhead decreases by a factor of the burst size,\n   and\
    \ the per-burst transmission time is long enough that timing\n   mechanisms will\
    \ work properly.  NETBLT's rate control therefore has\n   two parts, a burst size\
    \ and a burst rate, with (burst size)/(burst\n   rate) equal to the average transmission\
    \ time per packet.\n   The burst size and burst rate should be based not only\
    \ on the packet\n   transmission and processing speed which each end can handle,\
    \ but also\n   on the capacities of any intermediate gateways or networks.\n \
    \  Following are some intuitive values for packet size, buffer size,\n   burst\
    \ size, and burst rate.\n   Packet sizes can be as small as 128 bytes.  Performance\
    \ with packets\n   this small is almost always bad, because of the high per-packet\n\
    \   processing overhead.  Even the default Internet Protocol packet size\n   of\
    \ 576 bytes is barely big enough for adequate performance.  Most\n   networks\
    \ do not support packet sizes much larger than one or two\n   thousand bytes,\
    \ and packets of this size can also get fragmented when\n   traveling over intermediate\
    \ networks, lowering performance.\n   The size of a NETBLT buffer is limited only\
    \ by the amount of memory\n   available to a client.  Theoretically, buffers of\
    \ 100 Kbytes or more\n   are possible.  This would mean the transmission of 50\
    \ to 100 packets\n   per buffer.\n   The burst size and burst rate are obviously\
    \ very machine dependent.\n   There is a certain amount of transmission overhead\
    \ in the sending and\n   receiving machines associated with maintaining timers\
    \ and scheduling\n   processes.  This overhead can be minimized by sending packets\
    \ in\n   large bursts.  There are also limitations imposed on the burst size\n\
    \   by the number of available packet buffers in the operating system\n   kernel.\
    \ On most modern operating systems, a burst size of between\n   five and ten packets\
    \ should reduce the overhead to an acceptable\n   level.  A preliminary NETBLT\
    \ implementation for the IBM PC/AT sends\n   packets in bursts of five.  It could\
    \ send more, but is limited by the\n   available memory.\n   The burst rate is\
    \ in part determined by the granularity of the\n   sender's timing mechanism,\
    \ and in part by the processing speed of the\n   receiver and any intermediate\
    \ gateways.  It is also directly related\n   to the burst size.  Burst rates from\
    \ 20 to 45 milliseconds per 5-\n   packet burst have been tried on the IBM PC/AT\
    \ and Symbolics 3600\n   NETBLT implementations with good results within a single\
    \ local-area\n   network.  This value clearly depends on the network bandwidth\
    \ and\n   packet buffering available.\n   All NETBLT flow control parameters (packet\
    \ size, buffer size, burst\n   size, and burst rate) are negotiated during connection\
    \ setup.  The\n   negotiation process is the same for all parameters.  The client\n\
    \   initiating the connection (the active end) proposes and sends a set\n   of\
    \ values for each parameter in its connection request.  The other\n   client (the\
    \ passive end) compares these values with the highest-\n   performance values\
    \ it can support.  The passive end can then modify\n   any of the parameters,\
    \ but only by making them more restrictive.  The\n   modified parameters are then\
    \ sent back to the active end in its\n   response message.\n   The burst size\
    \ and burst rate can also be re-negotiated after each\n   buffer transmission\
    \ to adjust the transfer rate according to the\n   performance observed from transferring\
    \ the previous buffer.  The\n   receiving end sends burst size and burst rate\
    \ values in its OK\n   messages (described later).  The sender compares these\
    \ values with\n   the values it can support.  Again, it may then modify any of\
    \ the\n   parameters, but only by making them more restrictive.  The modified\n\
    \   parameters are then communicated to the receiver in a NULL-ACK\n   packet,\
    \ described later.\n   Obviously each of the parameters depend on many factors\
    \ -- gateway\n   and host processing speeds, available memory, timer granularity\
    \ --\n   some of which cannot be checked by either client.  Each client must\n\
    \   therefore try to make as best a guess as it can, tuning for\n   performance\
    \ on subsequent transfers.\n"
- title: 5. The NETBLT Transfer Model
  contents:
  - "5. The NETBLT Transfer Model\n   Each NETBLT transfer has three stages, connection\
    \ setup, data\n   transfer, and connection close.  The stages are described in\
    \ detail\n   below, along with methods for insuring that each stage completes\n\
    \   reliably.\n"
- title: 5.1. Connection Setup
  contents:
  - "5.1. Connection Setup\n   A NETBLT connection is set up by an exchange of two\
    \ packets between\n   the active NETBLT and the passive NETBLT.  Note that either\
    \ NETBLT\n   can send or receive data; the words \"active\" and \"passive\" are\
    \ only\n   used to differentiate the end making the connection request from the\n\
    \   end responding to the connection request.  The active end sends an\n   OPEN\
    \ packet; the passive end acknowledges the OPEN packet in one of\n   two ways.\
    \  It can either send a REFUSED packet, indicating that the\n   connection cannot\
    \ be completed for some reason, or it can complete\n   the connection setup by\
    \ sending a RESPONSE packet.  At this point the\n   transfer can begin.\n   As\
    \ discussed in the previous section, the OPEN and RESPONSE packets\n   are used\
    \ to negotiate flow control parameters.  Other parameters used\n   in the data\
    \ transfer are also negotiated.  These parameters are (1)\n   the maximum number\
    \ of buffers that can be sending at any one time,\n   and (2) whether or not DATA\
    \ packet data will be checksummed.  NETBLT\n   automatically checksums all non-DATA/LDATA\
    \ packets.  If the\n   negotiated checksum flag is set to TRUE (1), both the header\
    \ and the\n   data of a DATA/LDATA packet are checksummed; if set to FALSE (0),\n\
    \   only the header is checksummed.  The checksum value is the bitwise\n   negation\
    \ of the ones-complement sum of the 16-bit words being\n   checksummed.\n   Finally,\
    \ each end transmits its death-timeout value in seconds in\n   either the OPEN\
    \ or the RESPONSE packet.  The death-timeout value will\n   be used to determine\
    \ the frequency with which to send KEEPALIVE\n   packets during idle periods of\
    \ an opened connection (death timers and\n   KEEPALIVE packets are described in\
    \ the following section).\n   The active end specifies a passive client through\
    \ a client-specific\n   \"well-known\" 16 bit port number on which the passive\
    \ end listens.\n   The active end identifies itself through a 32 bit Internet\
    \ address\n   and a unique 16 bit port number.\n   In order to allow the active\
    \ and passive ends to communicate\n   miscellaneous useful information, an unstructured,\
    \ variable-length\n   field is provided in OPEN and RESPONSE packets for any client-\n\
    \   specific information that may be required.  In addition, a \"reason\n   for\
    \ refusal\" field is provided in REFUSED packets.\n   Recovery for lost OPEN and\
    \ RESPONSE packets is provided by the use of\n   timers.  The active end sets\
    \ a timer when it sends an OPEN packet.\n   When the timer expires, another OPEN\
    \ packet is sent, until some\n   predetermined maximum number of OPEN packets\
    \ have been sent.  The\n   timer is cleared upon receipt of a RESPONSE packet.\n\
    \   To prevent duplication of OPEN and RESPONSE packets, the OPEN packet\n   contains\
    \ a 32 bit connection unique ID that must be returned in the\n   RESPONSE packet.\
    \  This prevents the initiator from confusing the\n   response to the current\
    \ request with the response to an earlier\n   connection request (there can only\
    \ be one connection between any two\n   ports).  Any OPEN or RESPONSE packet with\
    \ a destination port matching\n   that of an open connection has its unique ID\
    \ checked.  If the unique\n   ID of the packet matches the unique ID of the connection,\
    \ then the\n   packet type is checked.  If it is a RESPONSE packet, it is treated\
    \ as\n   a duplicate and ignored.  If it is an OPEN packet, the passive NETBLT\n\
    \   sends another RESPONSE (assuming that a previous RESPONSE packet was\n   sent\
    \ and lost, causing the initiating NETBLT to retransmit its OPEN\n   packet).\
    \  A non-matching unique ID must be treated as an attempt to\n   open a second\
    \ connection between the same port pair and is rejected\n   by sending an ABORT\
    \ message.\n"
- title: 5.2. Data Transfer
  contents:
  - "5.2. Data Transfer\n   The simplest model of data transfer proceeds as follows.\
    \  The sending\n   client sets up a buffer full of data.  The receiving NETBLT\
    \ sends a\n   GO message inside a CONTROL packet to the sender, signifying that\
    \ it\n   too has set up a buffer and is ready to receive data.  Once the GO\n\
    \   message is received, the sender transmits the buffer as a series of\n   DATA\
    \ packets followed by an LDATA packet.  When the last packet in\n   the buffer\
    \ has been received, the receiver sends a RESEND message\n   inside a CONTROL\
    \ packet containing a list of packets that were not\n   received.  The sender\
    \ resends these packets.  This process continues\n   until there are no missing\
    \ packets.  At that time the receiver sends\n   an OK message inside a CONTROL\
    \ packet, sets up another buffer to\n   receive data, and sends another GO message.\
    \  The sender, having\n   received the OK message, sets up another buffer, waits\
    \ for the GO\n   message, and repeats the process.\n   The above data transfer\
    \ model is effectively a lock-step protocol,\n   and causes time to be wasted\
    \ while the sending NETBLT waits for\n   permission to send a new buffer.  A more\
    \ efficient transfer model\n   uses multiple buffering to increase performance.\
    \  Multiple buffering\n   is a technique in which the sender and receiver allocate\
    \ and transmit\n   buffers in a manner that allows error recovery or successful\n\
    \   transmission confirmation of previous buffers to be concurrent with\n   transmission\
    \ of the current buffer.\n   During the connection setup phase, one of the negotiated\
    \ parameters\n   is the number of concurrent buffers permitted during the transfer.\n\
    \   If there is more than one buffer available, transfer of the next\n   buffer\
    \ may start right after the current buffer finishes.  This is\n   illustrated\
    \ in the following example:\n   Assume two buffers A and B in a multiple-buffer\
    \ transfer, with A\n   preceding B. When A has been transferred and the sending\
    \ NETBLT is\n   waiting for either an OK or a RESEND message for it, the sending\n\
    \   NETBLT can start sending B immediately, keeping data flowing at a\n   stable\
    \ rate.  If the receiver of data sends an OK for A, all is well;\n   if it receives\
    \ a RESEND, the missing packets specified in the RESEND\n   message are retransmitted.\n\
    \   In the multiple-buffer transfer model, all packets to be sent are\n   re-ordered\
    \ by buffer number (lowest number first), with the transfer\n   rate specified\
    \ by the burst size and burst rate.  Since buffer\n   numbers increase monotonically,\
    \ packets from an earlier buffer will\n   always precede packets from a later\
    \ buffer.\n   Having several buffers transmitting concurrently is actually not\
    \ that\n   much more complicated than transmitting a single buffer at a time.\n\
    \   The key is to visualize each buffer as a finite state machine;\n   several\
    \ buffers are merely a group of finite state machines, each in\n   one of several\
    \ states.  The transfer process consists of moving\n   buffers through various\
    \ states until the entire transmission has\n   completed.\n   There are several\
    \ obvious flaws in the data transfer model as\n   described above.  First, what\
    \ if the GO, OK, or RESEND messages are\n   lost?  The sender cannot act on a\
    \ packet it has not received, so the\n   protocol will hang.  Second, if an LDATA\
    \ packet is lost, how does the\n   receiver know when the buffer has been transmitted?\
    \  Solutions for\n   each of these problems are presented below.\n"
- title: 5.2.1. Recovering from Lost Control Messages
  contents:
  - "5.2.1. Recovering from Lost Control Messages\n   NETBLT solves the problem of\
    \ lost OK, GO, and RESEND messages in two\n   ways.  First, it makes use of a\
    \ control timer.  The receiver can send\n   one or more control messages (OK,\
    \ GO, or RESEND) within a single\n   CONTROL packet.  Whenever the receiver sends\
    \ a control packet, it\n   sets a control timer.  This timer is either \"reset\"\
    \ (set again) or\n   \"cleared\" (deactivated), under the following conditions:\n\
    \   When the control timer expires, the receiving NETBLT resends the\n   control\
    \ packet and resets the timer.  The receiving NETBLT continues\n   to resend control\
    \ packets in response to control timer's expiration\n   until either the control\
    \ timer is cleared or the receiving NETBLT's\n   death timer (described later)\
    \ expires (at which time it shuts down\n   the connection).\n   Each control message\
    \ includes a sequence number which starts at one\n   and increases by one for\
    \ each control message sent.  The sending\n   NETBLT checks the sequence number\
    \ of every incoming control message\n   against all other sequence numbers it\
    \ has received.  It stores the\n   highest sequence number below which all other\
    \ received sequence\n   numbers are consecutive (in following paragraphs this\
    \ is called the\n   high-acknowledged-sequence-number) and returns this number\
    \ in every\n   packet flowing back to the receiver.  The receiver is permitted\
    \ to\n   clear its control timer when it receives a packet from the sender\n \
    \  with a high-acknowledged-sequence-number greater than or equal to the\n   highest\
    \ sequence number in the control packet just sent.\n   Ideally, a NETBLT implementation\
    \ should be able to cope with out-of-\n   sequence control messages, perhaps collecting\
    \ them for later\n   processing, or even processing them immediately.  If an incoming\n\
    \   control message \"fills\" a \"hole\" in a group of message sequence\n   numbers,\
    \ the implementation could even be clever enough to detect\n   this and adjust\
    \ its outgoing sequence value accordingly.\n   The sending NETBLT, upon receiving\
    \ a CONTROL packet, should act on\n   the packet as quickly as possible.  It either\
    \ sets up a new buffer\n   (upon receipt of an OK message for a previous buffer),\
    \ marks data for\n   resending (upon receipt of a RESEND message), or prepares\
    \ a buffer\n   for sending (upon receipt of a GO message).  If the sending NETBLT\
    \ is\n   not in a position to send data, it should send a NULL-ACK packet,\n \
    \  which contains its high-acknowledged-sequence-number (this permits\n   the\
    \ receiving NETBLT to acknowledge any outstanding control\n   messages), and wait\
    \ until it can send more data.  In all of these\n   cases, the system overhead\
    \ for a response to the incoming control\n   message should be small and relatively\
    \ constant.\n   The small amount of message-processing overhead allows accurate\n\
    \   control timers to be set for all types of control messages with a\n   single,\
    \ simple algorithm -- the network round-trip transit time, plus\n   a variance\
    \ factor.  This is more efficient than schemes used by other\n   protocols, where\
    \ timer value calculation has been a problem because\n   the processing time for\
    \ a particular packet can vary greatly\n   depending on the packet type.\n   Control\
    \ timer value estimation is extremely important in a high-\n   performance protocol\
    \ like NETBLT.  A long control timer causes the\n   receiving NETBLT to wait for\
    \ long periods of time before\n   retransmitting unacknowledged messages.  A short\
    \ control timer value\n   causes the sending NETBLT to receive many duplicate\
    \ control messages\n   (which it can reject, but which takes time).\n   In addition\
    \ to the use of control timers, NETBLT reduces lost control\n   messages by using\
    \ a single long-lived control packet; the packet is\n   treated like a FIFO queue,\
    \ with new control messages added on at the\n   end and acknowledged control messages\
    \ removed from the front.  The\n   implementation places control messages in the\
    \ control packet and\n   transmits the entire control packet, consisting of any\
    \ unacknowledged\n   control messages plus new messages just added.  The entire\
    \ control\n   packet is also transmitted whenever the control timer expires. \
    \ Since\n   control packet transmissions are fairly frequent, unacknowledged\n\
    \   messages may be transmitted several times before they are finally\n   acknowledged.\
    \  This redundant transmission of control messages\n   provides automatic recovery\
    \ for most control message losses over a\n   noisy channel.\n   This scheme places\
    \ some burdens on the receiver of the control\n   messages.  It must be able to\
    \ quickly reject duplicate control\n   messages, since a given message may be\
    \ retransmitted several times\n   before its acknowledgement is received and it\
    \ is removed from the\n   control packet.  Typically this is fairly easy to do;\
    \ the sender of\n   data merely throws away any control messages with sequence\
    \ numbers\n   lower than its high-acknowledged-sequence-number.\n   Another problem\
    \ with this scheme is that the control packet may\n   become larger than the maximum\
    \ allowable packet size if too many\n   control messages are placed into it. \
    \ This has not been a problem in\n   the current NETBLT implementations: a typical\
    \ control packet size is\n   1000 bytes; RESEND control messages average about\
    \ 20 bytes in length,\n   GO messages are 8 bytes long, and OK messages are 16\
    \ bytes long.\n   This allows 50-80 control messages to be placed in the control\n\
    \   packet, more than enough for reasonable transfers.  Other\n   implementations\
    \ can provide for multiple control packets if a single\n   control packet may\
    \ not be sufficient.\n   The control timer value must be carefully estimated.\
    \  It can have as\n   its initial value an arbitrary number.  Subsequent control\
    \ packets\n   should have their timer values based on the network round-trip\n\
    \   transit time (i.e. the time between sending the control packet and\n   receiving\
    \ the acknowledgment of all messages in the control packet)\n   plus a variance\
    \ factor.  The timer value should be continually\n   updated, based on a smoothed\
    \ average of collected round-trip transit\n   times.\n"
- title: 5.2.2. Recovering from Lost LDATA Packets
  contents:
  - "5.2.2. Recovering from Lost LDATA Packets\n   NETBLT solves the problem of LDATA\
    \ packet loss by using a data timer\n   for each buffer at the receiving end.\
    \  The simplest data timer model\n   has a data timer set when a buffer is ready\
    \ to be received; if the\n   data timer expires, the receiving NETBLT assumes\
    \ a lost LDATA packet\n   and sends a RESEND message requesting all missing DATA\
    \ packets in the\n   buffer.  When all packets have been received, the timer is\
    \ cleared.\n   Data timer values are not based on network round-trip transit time;\n\
    \   instead they are based on the amount of time taken to transfer a\n   buffer\
    \ (as determined by the number of DATA packet bursts in the\n   buffer times the\
    \ burst rate) plus a variance factor <1>.\n   Obviously an accurate estimation\
    \ of the data timer value is very\n   important.  A short data timer value causes\
    \ the receiving NETBLT to\n   send unnecessary RESEND packets.  This causes serious\
    \ performance\n   degradation since the sending NETBLT has to stop what it is\
    \ doing and\n   resend a number of DATA packets.\n   Data timer setting and clearing\
    \ turns out to be fairly complicated,\n   particularly in a multiple-buffering\
    \ transfer model.  In\n   understanding how and when data timers are set and cleared,\
    \ it is\n   helpful to visualize each buffer as a finite-state machine and take\
    \ a\n   look at the various states.\n   The state sequence for a sending buffer\
    \ is simple.  When a GO message\n   for the buffer is received, the buffer is\
    \ created, filled with data,\n   and placed in a SENDING state.  When an OK for\
    \ that buffer has been\n   received, it goes into a SENT state and is disposed\
    \ of.\n   The state sequence for a receiving buffer is a little more\n   complicated.\
    \  Assume existence of a buffer A. When a control message\n   for A is sent, the\
    \ buffer moves into state ACK-WAIT (it is waiting\n   for acknowledgement of the\
    \ control message).\n   As soon as the control message has been acknowledged,\
    \ buffer A moves\n   from the ACK-WAIT state into the ACKED state (it is now waiting\
    \ for\n   DATA packets to arrive).  At this point, A's data timer is set and\n\
    \   the control message removed from the control packet.  Estimation of\n   the\
    \ data timer value at this point is quite difficult.  In a\n   multiple-buffer\
    \ transfer model, the receiving NETBLT can send several\n   GO messages at once.\
    \  A single DATA packet from the sending NETBLT\n   could acknowledge all the\
    \ GO messages, causing several buffers to\n   start up data timers.  Clearly each\
    \ of the data timers must be set in\n   a manner that takes into account each\
    \ buffer's place in the order of\n   transmission.  Packets for a buffer A - 1\
    \ will always be transmitted\n   before packets in A, so A's data timer must take\
    \ into account the\n   arrival of all of A - 1's DATA packets as well as arrival\
    \ of its own\n   DATA packets.  This means that the timer values become increasingly\n\
    \   less accurate for higher-numbered buffers.  Because this data timer\n   value\
    \ can be quite inaccurate, it is called a \"loose\" data timer.\n   The loose\
    \ data timer value is recalculated later (using the same\n   algorithm, but with\
    \ updated information), giving a \"tight\" timer, as\n   described below.\n  \
    \ When the first DATA packet for A arrives, A moves from the ACKED\n   state to\
    \ the RECEIVING state and its data timer is set to a new\n   \"tight\" value.\
    \  The tight timer value is calculated in the same\n   manner as the loose timer,\
    \ but it is more accurate since we have\n   moved forward in time and those buffers\
    \ numbered lower than A have\n   presumably been dealt with (or their packets\
    \ would have arrived\n   before A's), leaving fewer packets to arrive between\
    \ the setting of\n   the data timer and the arrival of the last DATA packet in\
    \ A.\n   The receiving NETBLT also sets the tight data timers of any buffers\n\
    \   numbered lower than A that are also in the ACKED state.  This is done\n  \
    \ as an optimization: we know that buffers are processed in order,\n   lowest\
    \ number first.  If a buffer B numbered lower than A is in the\n   ACKED state,\
    \ its DATA packets should arrive before A's.  Since A's\n   have arrived first,\
    \ B's must have gotten lost.  Since B's loose data\n   timer has not expired (it\
    \ would then have sent a RESEND message and\n   be in the ACK-WAIT state), we\
    \ set the tight timer, allowing the\n   missing packets to be detected earlier.\
    \  An immediate RESEND is not\n   sent because it is possible that A's packet\
    \ was re-ordered before B's\n   by the network, and that B's packets may arrive\
    \ shortly.\n   When all DATA packets for A have been received, it moves from the\n\
    \   RECEIVING state to the RECEIVED state and is disposed of.  Had any\n   packets\
    \ been missing, A's data timer would have expired and A would\n   have moved into\
    \ the ACK-WAIT state after sending a RESEND message.\n   The state progression\
    \ would then move as in the above example.\n   The control and data timer system\
    \ can be summarized as follows:\n   normally, the receiving NETBLT is working\
    \ under one of two types of\n   timers, a control timer or a data timer.  There\
    \ is one data timer per\n   buffer transmission and one control timer per control\
    \ packet.  The\n   data timer is active while its buffer is in either the ACKED\
    \ (loose\n   data timer value is used) or the RECEIVING (tight data timer value\
    \ is\n   used) states; a control timer is active whenever the receiving NETBLT\n\
    \   has any unacknowledged control messages in its control packet.\n"
- title: 5.2.3. Death Timers and Keepalive Packets
  contents:
  - "5.2.3. Death Timers and Keepalive Packets\n   The above system still leaves a\
    \ few problems.  If the sending NETBLT\n   is not ready to send, it sends a single\
    \ NULL-ACK packet to clear any\n   outstanding control timers at the receiving\
    \ end.  After this the\n   receiver will wait.  The sending NETBLT could die and\
    \ the receiver,\n   with its control timer cleared, would hang.  Also, the above\
    \ system\n   puts timers only on the receiving NETBLT.  The sending NETBLT has\
    \ no\n   timers; if the receiving NETBLT dies, the sending NETBLT will hang\n\
    \   while waiting for control messages to arrive.\n   The solution to the above\
    \ two problems is the use of a death timer\n   and a keepalive packet for both\
    \ the sending and receiving NETBLTs.\n   As soon as the connection is opened,\
    \ each end sets a death timer;\n   this timer is reset every time a packet is\
    \ received.  When a NETBLT's\n   death timer expires, it can assume the other\
    \ end has died and can\n   close the connection.\n   It is possible that the sending\
    \ or receiving NETBLTs will have to\n   wait for long periods while their respective\
    \ clients get buffer space\n   and load their buffers with data.  Since a NETBLT\
    \ waiting for buffer\n   space is in a perfectly valid state, the protocol must\
    \ have some\n   method for preventing the other end's death timer from expiring.\
    \  The\n   solution is to use a KEEPALIVE packet, which is sent repeatedly at\n\
    \   fixed intervals when a NETBLT cannot send other packets.  Since the\n   death\
    \ timer is reset whenever a packet is received, it will never\n   expire as long\
    \ as the other end sends packets.\n   The frequency with which KEEPALIVE packets\
    \ are transmitted is\n   computed as follows:  At connection startup, each NETBLT\
    \ chooses a\n   death-timer value and sends it to the other end in either the\
    \ OPEN or\n   the RESPONSE packet.  The other end takes the death-timeout value\
    \ and\n   uses it to compute a frequency with which to send KEEPALIVE packets.\n\
    \   The KEEPALIVE frequency should be high enough that several KEEPALIVE\n   packets\
    \ can be lost before the other end's death timer expires (e.g.\n   death timer\
    \ value divided by four).\n   The death timer value is relatively easy to estimate.\
    \  Since it is\n   continually reset, it need not be based on the transfer size.\n\
    \   Instead, it should be based at least in part on the type of\n   application\
    \ using NETBLT.  User applications should have smaller\n   death timeout values\
    \ to avoid forcing humans to wait long periods of\n   time for a death timeout\
    \ to occur.  Machine applications can have\n   longer timeout values.\n"
- title: 5.3. Closing the Connection
  contents:
  - "5.3. Closing the Connection\n   There are three ways to close a connection: a\
    \ connection close, a\n   \"quit\", or an \"abort\".\n"
- title: 5.3.1. Successful Transfer
  contents:
  - "5.3.1. Successful Transfer\n   After a successful data transfer, NETBLT closes\
    \ the connection.  When\n   the sender is transmitting the last buffer of data,\
    \ it sets a \"last-\n   buffer\" flag on every DATA packet in the buffer.  This\
    \ means that no\n   NEW data will be transmitted.  The receiver knows the transfer\
    \ has\n   completed successfully when all of the following are true: (1) it has\n\
    \   received DATA packets with a \"last-buffer\" flag set, (2) all its\n   control\
    \ messages have been acknowledged, and (3) it has no\n   outstanding buffers with\
    \ missing packets.  At that point, the\n   receiver is permitted to close its\
    \ half of the connection.  The\n   sender knows the transfer has completed when\
    \ the following are true:\n   (1) it has transmitted DATA packets with a \"last-buffer\"\
    \ flag set and\n   (2) it has received OK messages for all its buffers.  At that\
    \ point,\n   it \"dallies\" for a predetermined period of time before closing\
    \ its\n   half of the connection.  If the NULL-ACK packet acknowledging the\n\
    \   receiver's last OK message was lost, the receiver has time to\n   retransmit\
    \ the OK message, receive a new NULL-ACK, and recognize a\n   successful transfer.\
    \  The dally timer value MUST be based on the\n   receiver's control timer value;\
    \ it must be long enough to allow the\n   receiver's control timer to expire so\
    \ that the OK message can be re-\n   sent.  For this reason, all OK messages contain\
    \ (in addition to new\n   burst size and burst rate values), the receiver's current\
    \ control\n   timer value in milliseconds.  The sender uses this value to compute\n\
    \   its dally timer value.\n   Since the dally timer value may be quite large,\
    \ the receiving NETBLT\n   is permitted to \"short-circuit\" the sending NETBLT's\
    \ dally timer by\n   transmitting a DONE packet.  The DONE packet is transmitted\
    \ when the\n   receiver knows the transfer has been successfully completed.  When\n\
    \   the sender receives a DONE packet, it is allowed to clear its dally\n   timer\
    \ and close its half of the connection immediately.  The DONE\n   packet is not\
    \ reliably transmitted, since failure to receive it only\n   means that the sending\
    \ NETBLT will take longer time to close its half\n   of the connection (as it\
    \ waits for its dally timer to clear)\n"
- title: 5.3.2. Client QUIT
  contents:
  - "5.3.2. Client QUIT\n   During a NETBLT transfer, one client may send a QUIT packet\
    \ to the\n   other if it thinks that the other client is malfunctioning.  Since\n\
    \   the QUIT occurs at a client level, the QUIT transmission can only\n   occur\
    \ between buffer transmissions.  The NETBLT receiving the QUIT\n   packet can\
    \ take no action other than immediately notifying its client\n   and transmitting\
    \ a QUITACK packet.  The QUIT sender must time out and\n   retransmit until a\
    \ QUITACK has been received or its death timer\n   expires.  The sender of the\
    \ QUITACK dallies before quitting, so that\n   it can respond to a retransmitted\
    \ QUIT.\n"
- title: 5.3.3. NETBLT ABORT
  contents:
  - "5.3.3. NETBLT ABORT\n   An ABORT takes place when a NETBLT layer thinks that\
    \ it or its\n   opposite is malfunctioning.  Since the ABORT originates in the\
    \ NETBLT\n   layer, it can be sent at any time.  The ABORT implies that the NETBLT\n\
    \   layer is malfunctioning, so no transmit reliability is expected, and\n   the\
    \ sender can immediately close it connection.\n"
- title: 6. Protocol Layering Structure
  contents:
  - "6. Protocol Layering Structure\n   NETBLT is implemented directly on top of the\
    \ Internet Protocol (IP).\n   It has been assigned an official protocol number\
    \ of 30 (decimal).\n"
- title: 7. Planned Enhancements
  contents:
  - "7. Planned Enhancements\n   As currently specified, NETBLT has no algorithm for\
    \ determining its\n   rate-control parameters (burst rate, burst size, etc.).\
    \  In initial\n   performance testing, these parameters have been set by the person\n\
    \   performing the test.  We are now exploring ways to have NETBLT set\n   and\
    \ adjust its rate-control parameters automatically.\n"
- title: 8. Packet Formats
  contents:
  - "8. Packet Formats\n   NETBLT packets are divided into three categories, all of\
    \ which share\n   a common packet header.  First, there are those packets that\
    \ travel\n   only from data sender to receiver; these contain the high-\n   acknowledged-sequence-numbers\
    \ which the receiver uses for control\n   message transmission reliability.  These\
    \ packets are the NULL-ACK,\n   DATA, and LDATA packets.  Second, there is a packet\
    \ that travels only\n   from receiver to sender.  This is the CONTROL packet;\
    \ each CONTROL\n   packet can contain an arbitrary number of control messages\
    \ (GO, OK,\n   or RESEND), each with its own sequence number.  Finally, there\
    \ are\n   those packets which either have special ways of insuring reliability,\n\
    \   or are not reliably transmitted.  These are the OPEN, RESPONSE,\n   REFUSED,\
    \ QUIT, QUITACK, DONE, KEEPALIVE, and ABORT packets.  Of\n   these, all save the\
    \ DONE packet can be sent by both sending and\n   receiving NETBLTs.\n   All packets\
    \ are \"longword-aligned\", i.e. all packets are a multiple\n   of 4 bytes in\
    \ length and all 4-byte fields start on a longword\n   boundary.  All arbitrary-length\
    \ string fields are terminated with at\n   least one null byte, with extra null\
    \ bytes added at the end to create\n   a field that is a multiple of 4 bytes long.\n\
    \   Packet Formats for NETBLT\n   OPEN (type 0) and RESPONSE (type 1):\n     \
    \                 1                   2                   3\n    1 2 3 4 5 6 7\
    \ 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Checksum            |    Version    |     Type      |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Length              |           Local Port          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        Foreign Port           | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                       Connection Unique ID                    |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                         Buffer Size                           |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                       Transfer Size                           |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        DATA packet size       |          Burst Size           |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Burst Rate          |       Death Timer Value       |\n   +---------------+---------------+---------------+---------------+\n\
    \   |       Reserved (MBZ)      |C|M| Maximum # Outstanding Buffers |\n   +---------------+---------------+---------------+---------------+\n\
    \   | Client String ...\n   +---------------+---------------+---------------\n\
    \                                     Longword Alignment Padding    |\n      \
    \              ---------------+-------------------------------+\n   Checksum:\
    \ packet checksum (algorithm is described in the section\n   \"Connection Setup\"\
    )\n   Version: the NETBLT protocol version number\n   Type: the NETBLT packet\
    \ type number (OPEN = 0, RESPONSE = 1,\n   etc.)\n   Length: the total length\
    \ (NETBLT header plus data, if present)\n   of the NETBLT packet in bytes\n  \
    \ Local Port: the local NETBLT's 16-bit port number\n   Foreign Port: the foreign\
    \ NETBLT's 16-bit port number\n   Connection UID: the 32 bit connection UID specified\
    \ in the\n   section \"Connection Setup\".\n   Buffer size: the size in bytes\
    \ of each NETBLT buffer (save the\n   last)\n   Transfer size: (optional) the\
    \ size in bytes of the transfer.\n   This is for client information only; the\
    \ receiving NETBLT should\n   NOT make use of it.\n   Data packet size: length\
    \ of each DATA packet in bytes\n   Burst Size: Number of DATA packets in a burst\n\
    \   Burst Rate: Transmit time in milliseconds of a single burst\n   Death timer:\
    \ Packet sender's death timer value in seconds\n   \"M\": the transfer mode (0\
    \ = READ, 1 = WRITE)\n   \"C\": the DATA packet data checksum flag (0 = do not\
    \ checksum\n   DATA packet data, 1 = do)\n   Maximum Outstanding Buffers: maximum\
    \ number of buffers that can\n   be transferred before waiting for an OK message\
    \ from the\n   receiving NETBLT.\n   Client string: an arbitrary, null-terminated,\
    \ longword-aligned\n   string for use by NETBLT clients.\n   KEEPALIVE (type 2),\
    \ QUITACK (type 4), and DONE (type 11)\n                      1              \
    \     2                   3\n    1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3\
    \ 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Checksum            |    Version    |     Type      |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Length              |           Local Port          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        Foreign Port           | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   QUIT (type 3), ABORT (type 5), and REFUSED (type 10)\n                   \
    \   1                   2                   3\n    1 2 3 4 5 6 7 8 9 0 1 2 3 4\
    \ 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Checksum            |    Version    |     Type      |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Length              |           Local Port          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        Foreign Port           | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   | Reason for QUIT/ABORT/REFUSE...\n   +---------------+---------------+---------------\n\
    \                                     Longword Alignment Padding    |\n      \
    \              ---------------+-------------------------------+\n   DATA (type\
    \ 6) and LDATA (type 7):\n                      1                   2        \
    \           3\n    1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0\
    \ 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Checksum            |    Version    |     Type      |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Length              |           Local Port          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        Foreign Port           | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                       Buffer Number                           |\n   +---------------+---------------+---------------+---------------+\n\
    \   | High Consecutive Seq Num Rcvd |         Packet Number         |\n   +---------------+---------------+---------------+---------------+\n\
    \   |    Data Area Checksum Value   |      Reserved (MBZ)         |L|\n   +---------------+---------------+---------------+---------------+\n\
    \   Buffer number: a 32 bit unique number assigned to every buffer.\n   Numbers\
    \ are monotonically increasing.\n   High Consecutive Sequence Number Received:\
    \ Highest control\n   message sequence number below which all sequence numbers\
    \ received\n   are consecutive.\n   Packet number: monotonically increasing DATA\
    \ packet identifier\n   Data Area Checksum Value: Checksum of the DATA packet's\
    \ data.\n   Algorithm used is the same as that used to compute checksums of\n\
    \   other NETBLT packets.\n   \"L\" is a flag set when the buffer that this DATA\
    \ packet belongs\n   to is the last buffer in the transfer.\n   NULL-ACK (type\
    \ 8)\n                      1                   2                   3\n    1 2\
    \ 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Checksum            |    Version    |     Type      |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Length              |           Local Port          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        Foreign Port           | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   | High Consecutive Seq Num Rcvd |        New Burst Size         |\n   +---------------+---------------+---------------+---------------+\n\
    \   |       New Burst Rate          |  Longword Alignment Padding   |\n   +---------------+---------------+---------------+---------------+\n\
    \   High Consecutive Sequence Number Received: same as in DATA/LDATA\n   packet\n\
    \   New Burst Size:  Burst size as negotiated from value given by\n   receiving\
    \ NETBLT in OK message\n   New burst rate: Burst rate as negotiated from value\
    \ given\n   by receiving NETBLT in OK message.  Value is in milliseconds.\n  \
    \ CONTROL (type 9):\n                      1                   2             \
    \      3\n    1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n\
    \   +---------------+---------------+---------------+---------------+\n   |  \
    \         Checksum            |    Version    |     Type      |\n   +---------------+---------------+---------------+---------------+\n\
    \   |           Length              |           Local Port          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |        Foreign Port           | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   Followed by any number of messages, each of which is longword\n   aligned,\
    \ with the following formats:\n   GO message (type 0):\n                     \
    \ 1                   2                   3\n    1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\
    \ 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |    Type       | Word Padding  |       Sequence Number         |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                        Buffer Number                          |\n   +---------------+---------------+---------------+---------------+\n\
    \   Type: message type (GO = 0, OK = 1, RESEND = 2)\n   Sequence number: A 16\
    \ bit unique message number.  Sequence\n   numbers must be monotonically increasing,\
    \ starting from 1.\n   Buffer number: as in DATA/LDATA packet\n   OK message (type\
    \ 1):\n                      1                   2                   3\n    1\
    \ 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |    Type       | Word Padding  |       Sequence Number         |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                        Buffer Number                          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |    New Offered Burst Size     |   New Offered Burst Rate      |\n   +---------------+---------------+---------------+---------------+\n\
    \   | Current control timer value   | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   New offered burst size: burst size for subsequent buffer\n   transfers, possibly\
    \ based on performance information for previous\n   buffer transfers.\n   New\
    \ offered burst rate: burst rate for subsequent buffer\n   transfers, possibly\
    \ based on performance information for previous\n   buffer transfers.  Rate is\
    \ in milliseconds.\n   Current control timer value: Receiving NETBLT's control\
    \ timer\n   value in milliseconds.\n   RESEND Message (type 2):\n            \
    \          1                   2                   3\n    1 2 3 4 5 6 7 8 9 0\
    \ 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2\n   +---------------+---------------+---------------+---------------+\n\
    \   |    Type       | Word Padding  |       Sequence Number         |\n   +---------------+---------------+---------------+---------------+\n\
    \   |                        Buffer Number                          |\n   +---------------+---------------+---------------+---------------+\n\
    \   |  Number of Missing Packets    | Longword Alignment Padding    |\n   +---------------+---------------+---------------+---------------+\n\
    \   |       Packet Number (2 bytes) ...\n   +---------------+---------------+----------\n\
    \                                   |    Padding (if necessary)     |\n      \
    \                  -----------+---------------+---------------+\n   Packet number:\
    \  the 16 bit data packet identifier found in each\n   DATA packet.\n"
- title: 'NOTES:'
  contents:
  - "NOTES:\n   <1>  When the buffer size is large, the variances in the round trip\n\
    \   delays of many packets may cancel each other out; this means the\n   variance\
    \ value need not be very big.  This expectation will be\n   explored in further\
    \ testing.\n"
