- title: __initial_text__
  contents:
  - '                     IP Flow Anonymization Support

    '
- title: Abstract
  contents:
  - "Abstract\n   This document describes anonymization techniques for IP flow data\
    \ and\n   the export of anonymized data using the IP Flow Information Export\n\
    \   (IPFIX) protocol.  It categorizes common anonymization schemes and\n   defines\
    \ the parameters needed to describe them.  It provides\n   guidelines for the\
    \ implementation of anonymized data export and\n   storage over IPFIX, and describes\
    \ an information model and Options-\n   based method for anonymization metadata\
    \ export within the IPFIX\n   protocol or storage in IPFIX Files.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for examination, experimental implementation, and\n   evaluation.\n\
    \   This document defines an Experimental Protocol for the Internet\n   community.\
    \  This document is a product of the Internet Engineering\n   Task Force (IETF).\
    \  It represents the consensus of the IETF\n   community.  It has received public\
    \ review and has been approved for\n   publication by the Internet Engineering\
    \ Steering Group (IESG).  Not\n   all documents approved by the IESG are a candidate\
    \ for any level of\n   Internet Standard; see Section 2 of RFC 5741.\n   Information\
    \ about the current status of this document, any errata,\n   and how to provide\
    \ feedback on it may be obtained at\n   http://www.rfc-editor.org/info/rfc6235.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \      1.1. IPFIX Protocol Overview ....................................4\n  \
    \    1.2. IPFIX Documents Overview ...................................5\n    \
    \  1.3. Anonymization within the IPFIX Architecture ................5\n      1.4.\
    \ Supporting Experimentation with Anonymization ..............6\n   2. Terminology\
    \ .....................................................6\n   3. Categorization\
    \ of Anonymization Techniques ......................7\n   4. Anonymization of\
    \ IP Flow Data ...................................8\n      4.1. IP Address Anonymization\
    \ ..................................10\n           4.1.1. Truncation .........................................11\n\
    \           4.1.2. Reverse Truncation .................................11\n  \
    \         4.1.3. Permutation ........................................11\n    \
    \       4.1.4. Prefix-Preserving Pseudonymization .................12\n      4.2.\
    \ MAC Address Anonymization .................................12\n           4.2.1.\
    \ Truncation .........................................13\n           4.2.2. Reverse\
    \ Truncation .................................13\n           4.2.3. Permutation\
    \ ........................................14\n           4.2.4. Structured Pseudonymization\
    \ ........................14\n      4.3. Timestamp Anonymization ...................................15\n\
    \           4.3.1. Precision Degradation ..............................15\n  \
    \         4.3.2. Enumeration ........................................16\n    \
    \       4.3.3. Random Shifts ......................................16\n      4.4.\
    \ Counter Anonymization .....................................16\n           4.4.1.\
    \ Precision Degradation ..............................17\n           4.4.2. Binning\
    \ ............................................17\n           4.4.3. Random Noise\
    \ Addition ..............................17\n      4.5. Anonymization of Other\
    \ Flow Fields ........................18\n           4.5.1. Binning ............................................18\n\
    \           4.5.2. Permutation ........................................18\n  \
    \ 5. Parameters for the Description of Anonymization Techniques .....19\n    \
    \  5.1. Stability .................................................19\n      5.2.\
    \ Truncation Length .........................................19\n      5.3. Bin\
    \ Map ...................................................20\n      5.4. Permutation\
    \ ...............................................20\n      5.5. Shift Amount ..............................................20\n\
    \   6. Anonymization Export Support in IPFIX ..........................20\n  \
    \    6.1. Anonymization Records and the Anonymization\n           Options Template\
    \ ..........................................21\n      6.2. Recommended Information\
    \ Elements for Anonymization\n           Metadata ..................................................23\n\
    \           6.2.1. informationElementIndex ............................23\n  \
    \         6.2.2. anonymizationTechnique .............................23\n    \
    \       6.2.3. anonymizationFlags .................................25\n   7. Applying\
    \ Anonymization Techniques to IPFIX Export and Storage ..27\n      7.1. Arrangement\
    \ of Processes in IPFIX Anonymization ...........28\n      7.2. IPFIX-Specific\
    \ Anonymization Guidelines ...................30\n           7.2.1. Appropriate\
    \ Use of Information Elements for\n                  Anonymized Data ....................................30\n\
    \           7.2.2. Export of Perimeter-Based Anonymization Policies ...31\n  \
    \         7.2.3. Anonymization of Header Data .......................32\n    \
    \       7.2.4. Anonymization of Options Data ......................32\n      \
    \     7.2.5. Special-Use Address Space Considerations ...........34\n        \
    \   7.2.6. Protecting Out-of-Band Configuration and\n                  Management\
    \ Data ....................................34\n   8. Examples .......................................................34\n\
    \   9. Security Considerations ........................................39\n  \
    \ 10. IANA Considerations ...........................................41\n   11.\
    \ Acknowledgments ...............................................41\n   12. References\
    \ ....................................................41\n      12.1. Normative\
    \ References .....................................41\n      12.2. Informative\
    \ References ...................................42\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The standardization of an IP Flow Information Export (IPFIX)\
    \ protocol\n   [RFC5101] and associated representations removes a technical barrier\n\
    \   to the sharing of IP flow data across organizational boundaries and\n   with\
    \ network operations, security, and research communities for a\n   wide variety\
    \ of purposes.  However, with wider dissemination comes\n   greater risks to the\
    \ privacy of the users of networks under\n   measurement, and to the security\
    \ of those networks.  While it is not\n   a complete solution to the issues posed\
    \ by distribution of IP flow\n   information, anonymization (i.e., the deletion\
    \ or transformation of\n   information that is considered sensitive and that could\
    \ be used to\n   reveal the identity of subjects involved in a communication)\
    \ is an\n   important tool for the protection of privacy within network\n   measurement\
    \ infrastructures.\n   This document presents a mechanism for representing anonymized\
    \ data\n   within IPFIX and guidelines for using it.  It is not intended as a\n\
    \   general statement on the applicability of specific flow data\n   anonymization\
    \ techniques to specific situations or as a\n   recommendation of any particular\
    \ application of anonymization to flow\n   data export.  Exporters or publishers\
    \ of anonymized data must take\n   care that the applied anonymization technique\
    \ is appropriate for the\n   data source, the purpose, and the risk of deanonymization\
    \ of a given\n   application.\n   It begins with a categorization of anonymization\
    \ techniques.  It then\n   describes the applicability of each technique to commonly\n\
    \   anonymizable fields of IP flow data, organized by information element\n  \
    \ data type and semantics as in [RFC5102]; enumerates the parameters\n   required\
    \ by each of the applicable anonymization techniques; and\n   provides guidelines\
    \ for the use of each of these techniques in\n   accordance with current best\
    \ practices in data protection.  Finally,\n   it specifies a mechanism for exporting\
    \ anonymized data and binding\n   anonymization metadata to Templates and Options\
    \ Templates using IPFIX\n   Options.\n"
- title: 1.1.  IPFIX Protocol Overview
  contents:
  - "1.1.  IPFIX Protocol Overview\n   In the IPFIX protocol, { type, length, value\
    \ } tuples are expressed\n   in Templates containing { type, length } pairs, specifying\
    \ which\n   { value } fields are present in data records conforming to the\n \
    \  Template, giving great flexibility as to what data is transmitted.\n   Since\
    \ Templates are sent very infrequently compared with Data\n   Records, this results\
    \ in significant bandwidth savings.  Various\n   different data formats may be\
    \ transmitted simply by sending new\n   Templates specifying the { type, length\
    \ } pairs for the new data\n   format.  See [RFC5101] for more information.\n\
    \   The IPFIX information model [RFC5102] defines a large number of\n   standard\
    \ Information Elements (IEs) that provide the necessary\n   { type } information\
    \ for Templates.  The use of standard elements\n   enables interoperability among\
    \ different vendors' implementations.\n   Additionally, non-standard enterprise-specific\
    \ elements may be\n   defined for private use.\n"
- title: 1.2.  IPFIX Documents Overview
  contents:
  - "1.2.  IPFIX Documents Overview\n   \"Specification of the IP Flow Information\
    \ Export (IPFIX) Protocol for\n   the Exchange of IP Traffic Flow Information\"\
    \ [RFC5101] and its\n   associated documents define the IPFIX protocol, which\
    \ provides\n   network engineers and administrators with access to IP traffic\
    \ flow\n   information.\n   \"Architecture for IP Flow Information Export\" [RFC5470]\
    \ defines the\n   architecture for the export of measured IP flow information\
    \ out of an\n   IPFIX Exporting Process to an IPFIX Collecting Process, and the\
    \ basic\n   terminology used to describe the elements of this architecture, per\n\
    \   the requirements defined in \"Requirements for IP Flow Information\n   Export\"\
    \ [RFC3917].  The IPFIX Protocol document [RFC5101] then covers\n   the details\
    \ of the method for transporting IPFIX Data Records and\n   Templates via a congestion-aware\
    \ transport protocol from an IPFIX\n   Exporting Process to an IPFIX Collecting\
    \ Process.\n   \"Information Model for IP Flow Information Export\" [RFC5102]\n\
    \   describes the Information Elements used by IPFIX, including details\n   on\
    \ Information Element naming, numbering, and data type encoding.\n   Finally,\
    \ \"IP Flow Information Export (IPFIX) Applicability\" [RFC5472]\n   describes\
    \ the various applications of the IPFIX protocol and their\n   use of information\
    \ exported via IPFIX and relates the IPFIX\n   architecture to other measurement\
    \ architectures and frameworks.\n   Additionally, \"Specification of the IP Flow\
    \ Information Export\n   (IPFIX) File Format\" [RFC5655] describes a file format\
    \ based upon the\n   IPFIX protocol for the storage of flow data.\n   This document\
    \ references the Protocol and Architecture documents for\n   terminology and extends\
    \ the IPFIX Information Model to provide new\n   Information Elements for anonymization\
    \ metadata.  The anonymization\n   techniques described herein are equally applicable\
    \ to the IPFIX\n   protocol and data stored in IPFIX Files.\n"
- title: 1.3.  Anonymization within the IPFIX Architecture
  contents:
  - "1.3.  Anonymization within the IPFIX Architecture\n   According to [RFC5470],\
    \ IPFIX Message anonymization is optionally\n   performed as the final operation\
    \ before handing the Message to the\n   transport protocol for export.  While\
    \ no provision is made in the\n   architecture for anonymization metadata as in\
    \ Section 6, this\n   arrangement does allow for the rewriting necessary for comprehensive\n\
    \   anonymization of IPFIX export as in Section 7.  The development of\n   the\
    \ IPFIX Mediation [RFC6183] framework and the IPFIX File Format\n   [RFC5655]\
    \ expand upon this initial architectural allowance for\n   anonymization by adding\
    \ to the list of places that anonymization may\n   be applied.  The former specifies\
    \ IPFIX Mediators, which rewrite\n   existing IPFIX Messages, and the latter specifies\
    \ a method for\n   storage of IPFIX data in files.\n   More detail on the applicable\
    \ architectural arrangements for\n   anonymization can be found in Section 7.1\n"
- title: 1.4.  Supporting Experimentation with Anonymization
  contents:
  - "1.4.  Supporting Experimentation with Anonymization\n   The status of this document\
    \ is Experimental, reflecting the\n   experimental nature of anonymization export\
    \ support.  Research on\n   network trace anonymization techniques and attacks\
    \ against them is\n   ongoing.  Indeed, there is increasing evidence that anonymization\n\
    \   applied to network trace or flow data on its own is insufficient for\n   many\
    \ data protection applications as in [Bur10].  Therefore, this\n   document explicitly\
    \ does not recommend any particular technique or\n   implementation thereof.\n\
    \   The intention of this document is to provide a common basis for\n   interoperable\
    \ exchange of anonymized data, furthering research in\n   this area, both on anonymization\
    \ techniques themselves as well as to\n   the application of anonymized data to\
    \ network measurement.  To that\n   end, the classification in Section 3 and anonymization\
    \ export support\n   in Section 6 can be used to describe and export information\
    \ even\n   about data anonymized using techniques that are unacceptably weak for\n\
    \   general application to production datasets on their own.\n   While the specification\
    \ herein is designed to be independent of the\n   anonymization techniques applied\
    \ and the implementation thereof, open\n   research in this area may necessitate\
    \ future updates to the\n   specification.  Assuming the future successful application\
    \ of this\n   specification to anonymized data publication and exchange, it may\
    \ be\n   brought back to the IPFIX working group for further development and\n\
    \   publication on the Standards Track.\n"
- title: 2.  Terminology
  contents:
  - "2.  Terminology\n   Terms used in this document that are defined in the Terminology\n\
    \   section of the IPFIX Protocol [RFC5101] document are to be\n   interpreted\
    \ as defined there.  In addition, this document defines the\n   following terms:\n\
    \   Anonymization Record:   A record, defined by the Anonymization\n      Options\
    \ Template in Section 6.1, that defines the properties of\n      the anonymization\
    \ applied to a single Information Element within a\n      single Template or Options\
    \ Template.\n   Anonymized Data Record:   A Data Record within a Data Set containing\n\
    \      at least one Information Element with anonymized values.  The\n      Information\
    \ Element(s) within the Template or Options Template\n      describing this Data\
    \ Record SHOULD have a corresponding\n      Anonymization Record.\n   Intermediate\
    \ Anonymization Process:   An intermediate process that\n      takes Data Records\
    \ and transforms them into Anonymized Data\n      Records.\n   Note that there\
    \ is an explicit difference in this document between a\n   \"Data Set\" (which\
    \ is defined as in [RFC5101]) and a \"data set\".  When\n   in lower case, this\
    \ term refers to any collection of data (usually,\n   within the context of this\
    \ document, flow or packet data) that may\n   contain identifying information\
    \ and is therefore subject to\n   anonymization.\n   Note also that when the term\
    \ Template is used in this document,\n   unless otherwise noted, it applies both\
    \ to Templates and Options\n   Templates as defined in [RFC5101].  Specifically,\
    \ Anonymization\n   Records may apply to both Templates and Options Templates.\n\
    \   The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\"\
    ,\n   \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in\
    \ this\n   document are to be interpreted as described in RFC 2119 [RFC2119].\n"
- title: 3.  Categorization of Anonymization Techniques
  contents:
  - "3.  Categorization of Anonymization Techniques\n   Anonymization, as described\
    \ by this document, is the modification of\n   a dataset in order to protect the\
    \ identity of the people or entities\n   described by the dataset from disclosure.\
    \  With respect to network\n   traffic data, anonymization generally attempts\
    \ to preserve some set\n   of properties of the network traffic useful for a given\
    \ application\n   or applications, while ensuring the data cannot be traced back\
    \ to the\n   specific networks, hosts, or users generating the traffic.\n   Anonymization\
    \ may be broadly classified according to two properties:\n   recoverability and\
    \ countability.  All anonymization techniques map\n   the real space of identifiers\
    \ or values into a separate, anonymized\n   space, according to some function.\
    \  A technique is said to be\n   recoverable when the function used is invertible\
    \ or can otherwise be\n   reversed and a real identifier can be recovered from\
    \ a given\n   replacement identifier.  \"Recoverability\" as used within this\n\
    \   categorization does not refer to recoverability under attack; that\n   is,\
    \ techniques wherein the function used can only be reversed using\n   additional\
    \ information, such as an encryption key, or knowledge of\n   injected traffic\
    \ within the dataset, are not considered to be\n   recoverable.\n   Countability\
    \ compares the dimension of the anonymized space (N) to\n   the dimension of the\
    \ real space (M), and denotes how the count of\n   unique values is preserved\
    \ by the anonymization function.  If the\n   anonymized space is smaller than\
    \ the real space, then the function is\n   said to generalize the input, mapping\
    \ more than one input point to\n   each anonymous value (e.g., as with aggregation).\
    \  By definition,\n   generalization is not recoverable.\n   If the dimensions\
    \ of the anonymized and real spaces are the same,\n   such that the count of unique\
    \ values is preserved, then the function\n   is said to be a direct substitution\
    \ function.  If the dimension of\n   the anonymized space is larger, such that\
    \ each real value maps to a\n   set of anonymized values, then the function is\
    \ said to be a set\n   substitution function.  Note that with set substitution\
    \ functions,\n   the sets of anonymized values are not necessarily disjoint. \
    \ Either\n   direct or set substitution functions are said to be one-way if there\n\
    \   exists no non-brute force method for recovering the real data point\n   from\
    \ an anonymized one in isolation (i.e., if the only way to recover\n   the data\
    \ point is to attack the anonymized data set as a whole, e.g.,\n   through fingerprinting\
    \ or data injection).\n   This classification is summarized in the table below.\n\
    \   +------------------------+-----------------+------------------------+\n  \
    \ | Recoverability /       | Recoverable     | Non-recoverable        |\n   |\
    \ Countability           |                 |                        |\n   +------------------------+-----------------+------------------------+\n\
    \   | N < M                  | N.A.            | Generalization         |\n  \
    \ | N = M                  | Direct          | One-way Direct         |\n   |\
    \                        | Substitution    | Substitution           |\n   | N\
    \ > M                  | Set             | One-way Set            |\n   |    \
    \                    | Substitution    | Substitution           |\n   +------------------------+-----------------+------------------------+\n"
- title: 4.  Anonymization of IP Flow Data
  contents:
  - "4.  Anonymization of IP Flow Data\n   In anonymizing IP flow data as treated\
    \ by this document, the goal is\n   generally two-way address untraceability:\
    \ to remove the ability to\n   assert that endpoint X contacted endpoint Y at\
    \ time T.  Address\n   untraceability is important as IP addresses are the most\
    \ suitable\n   field in IP flow records to identify real-world entities.  Each\
    \ IP\n   address is associated with an interface on a network host and can\n \
    \  potentially be identified with a single user.  Additionally, IP\n   addresses\
    \ are structured identifiers; that is, partial IP address\n   prefixes may be\
    \ used to identify networks just as full IP addresses\n   identify hosts.  This\
    \ leads IP flow data anonymization to be\n   concerned first and foremost with\
    \ IP address anonymization.\n   Any form of aggregation that combines flows from\
    \ multiple endpoints\n   into a single record (e.g., aggregation by subnetwork,\
    \ aggregation\n   removing addressing completely) may also provide address\n \
    \  untraceability; however, anonymization by aggregation is out of scope\n   for\
    \ this document.  Additionally, of potential interest in this\n   problem space\
    \ but out of scope are anonymization techniques that are\n   applied over multiple\
    \ fields or multiple records in a way that\n   introduces dependencies among anonymized\
    \ fields or records.  This\n   document is concerned solely with anonymization\
    \ techniques applied at\n   the resolution of single fields within a flow record.\n\
    \   Even so, attacks against these anonymization techniques use entire\n   flows\
    \ and relationships between hosts and flows within a given\n   dataset.  Therefore,\
    \ fields that may not necessarily be identifying\n   by themselves may be anonymized\
    \ in order to increase the anonymity of\n   the dataset as a whole.\n   Due to\
    \ the restricted semantics of IP flow data, there is a\n   relatively limited\
    \ set of specific anonymization techniques available\n   on flow data, though\
    \ each falls into the broad categories discussed\n   in the previous section.\
    \  Each type of field that may commonly appear\n   in a flow record may have its\
    \ own applicable specific techniques.\n   As with IP addresses, Media Access Control\
    \ (MAC) addresses uniquely\n   identify devices on the network; while they are\
    \ not often available\n   in traffic data collected at Layer 3, and cannot be\
    \ used to locate\n   devices within the network, some traces may contain sub-IP\
    \ data\n   including MAC address data.  Hardware addresses may be mappable to\n\
    \   device serial numbers, and to the entities or individuals who\n   purchased\
    \ the devices, when combined with external databases.  MAC\n   addresses are also\
    \ often used in constructing IPv6 addresses (see\n   Section 2.5.1 of [RFC4291])\
    \ and as such may be used to reconstruct\n   the low-order bits of anonymized\
    \ IPv6 addresses in certain\n   circumstances.  Therefore, MAC address anonymization\
    \ is also\n   important.\n   Port numbers identify abstract entities (applications)\
    \ as opposed to\n   real-world entities, but they can be used to classify hosts\
    \ and user\n   behavior.  Passive port fingerprinting, both of well-known and\n\
    \   ephemeral ports, can be used to determine the operating system\n   running\
    \ on a host.  Relative data volumes by port can also be used to\n   determine\
    \ the host's function (workstation, web server, etc.); this\n   information can\
    \ be used to identify hosts and users.\n   While not identifiers in and of themselves,\
    \ timestamps and counters\n   can reveal the behavior of the hosts and users on\
    \ a network.  Any\n   given network activity is recognizable by a pattern of relative\
    \ time\n   differences and data volumes in the associated sequence of flows,\n\
    \   even without host address information.  Therefore, they can be used\n   to\
    \ identify hosts and users.  Timestamps and counters are also\n   vulnerable to\
    \ traffic injection attacks, where traffic with a known\n   pattern is injected\
    \ into a network under measurement, and this\n   pattern is later identified in\
    \ the anonymized dataset.\n   The simplest and most extreme form of anonymization,\
    \ which can be\n   applied to any field of a flow record, is black-marker anonymization,\n\
    \   or complete deletion of a given field.  Note that black-marker\n   anonymization\
    \ is equivalent to simply not exporting the field(s) in\n   question.\n   While\
    \ black-marker anonymization completely protects the data in the\n   deleted fields\
    \ from the risk of disclosure, it also reduces the\n   utility of the anonymized\
    \ dataset as a whole.  Techniques that retain\n   some information while reducing\
    \ (though not eliminating) the\n   disclosure risk will be extensively discussed\
    \ in the following\n   sections; note that the techniques specifically applicable\
    \ to IP\n   addresses, timestamps, ports, and counters will be discussed in\n\
    \   separate sections.\n"
- title: 4.1.  IP Address Anonymization
  contents:
  - "4.1.  IP Address Anonymization\n   Since IP addresses are the most common identifiers\
    \ within flow data\n   that can be used to directly identify a person, organization,\
    \ or\n   host, most of the work on flow and trace data anonymization has gone\n\
    \   into IP address anonymization techniques.  Indeed, the aim of most\n   attacks\
    \ against anonymization is to recover the map from anonymized\n   IP addresses\
    \ to original IP addresses thereby identifying the\n   identified hosts.  Therefore,\
    \ there is a wide range of IP address\n   anonymization schemes that fit into\
    \ the following categories.\n       +------------------------------------+---------------------+\n\
    \       | Scheme                             | Action              |\n       +------------------------------------+---------------------+\n\
    \       | Truncation                         | Generalization      |\n       |\
    \ Reverse Truncation                 | Generalization      |\n       | Permutation\
    \                        | Direct Substitution |\n       | Prefix-preserving Pseudonymization\
    \ | Direct Substitution |\n       +------------------------------------+---------------------+\n"
- title: 4.1.1.  Truncation
  contents:
  - "4.1.1.  Truncation\n   Truncation removes \"n\" of the least significant bits\
    \ from an IP\n   address, replacing them with zeroes.  In effect, it replaces\
    \ a host\n   address with a network address for some fixed netblock; for IPv4\n\
    \   addresses, 8-bit truncation corresponds to replacement with a /24\n   network\
    \ address.  Truncation is a non-reversible generalization\n   scheme.  Note that\
    \ while truncation is effective for making hosts\n   non-identifiable, it preserves\
    \ information that can be used to\n   identify an organization, a geographic region,\
    \ a country, or a\n   continent.\n   Truncation to an address length of 0 is equivalent\
    \ to black-marker\n   anonymization.  Complete removal of IP address information\
    \ is only\n   recommended for analysis tasks that have no need to separate flow\n\
    \   data by host or network; e.g., as a first stage to per-application\n   (port)\
    \ or time-series total volume analyses.\n"
- title: 4.1.2.  Reverse Truncation
  contents:
  - "4.1.2.  Reverse Truncation\n   Reverse truncation removes \"n\" of the most significant\
    \ bits from an\n   IP address, replacing them with zeroes.  Reverse truncation\
    \ is a non-\n   reversible generalization scheme.  Reverse truncation is effective\n\
    \   for making networks unidentifiable, partially or completely removing\n   information\
    \ that can be used to identify an organization, a\n   geographic region, a country,\
    \ or a continent (or Regional Internet\n   Registry (RIR) region of responsibility).\
    \  However, it may cause\n   ambiguity when applied to data collected from more\
    \ than one network,\n   since it treats all the hosts with the same address on\
    \ different\n   networks as if they are the same host.  It is not particularly\
    \ useful\n   when publishing data where the network of origin is known or can\
    \ be\n   easily guessed by virtue of the identity of the publisher.\n   Like truncation,\
    \ reverse truncation to an address length of 0 is\n   equivalent to black-marker\
    \ anonymization.\n"
- title: 4.1.3.  Permutation
  contents:
  - "4.1.3.  Permutation\n   Permutation is a direct substitution technique, replacing\
    \ each IP\n   address with an address selected from the set of possible IP\n \
    \  addresses, such that each anonymized address represents a unique\n   original\
    \ address.  The selection function is often random, though it\n   is not necessarily\
    \ so.  Permutation does not preserve any structural\n   information about a network,\
    \ but it does preserve the unique count of\n   IP addresses.  Any application\
    \ that requires more structure than\n   host-uniqueness will not be able to use\
    \ permuted IP addresses.\n   There are many variations of permutation functions,\
    \ each of which has\n   trade-offs in performance, security, and guarantees of\
    \ non-collision;\n   evaluating these trade-offs is implementation independent.\
    \  However,\n   in general, permutation functions applied to anonymization SHOULD\
    \ be\n   difficult to reverse without knowing the parameters (e.g., a secret\n\
    \   key for Hashed Message Authentication Code (HMAC).  Given the\n   relatively\
    \ small space of IPv4 addresses in particular, hash\n   functions applied without\
    \ additional parameters could be reversed\n   through brute force if the hash\
    \ function is known, and SHOULD NOT be\n   used as permutation functions.  Permutation\
    \ functions may guarantee\n   non-collision (i.e., that each anonymized address\
    \ represents a unique\n   original address), but need not; however, the probability\
    \ of\n   collision SHOULD be low.  Nevertheless, we treat even permutations\n\
    \   with low but nonzero collision probability as a direct substitution.\n   Beyond\
    \ these guidelines, recommendations for specific permutation\n   functions are\
    \ out of scope for this document.\n"
- title: 4.1.4.  Prefix-Preserving Pseudonymization
  contents:
  - "4.1.4.  Prefix-Preserving Pseudonymization\n   Prefix-preserving pseudonymization\
    \ is a direct substitution\n   technique, like permutation but further restricted\
    \ such that the\n   structure of subnets is preserved at each level while anonymizing\
    \ IP\n   addresses.  If two real IP addresses match on a prefix of \"n\" bits,\n\
    \   the two anonymized IP addresses will match on a prefix of \"n\" bits as\n\
    \   well.  This is useful when relationships among networks must be\n   preserved\
    \ for a given analysis task, but introduces structure into\n   the anonymized\
    \ data that can be exploited in attacks against the\n   anonymization technique.\n\
    \   Scanning in Internet background traffic can cause particular problems\n  \
    \ with this technique: if a scanner uses a predictable and known\n   sequence\
    \ of addresses, this information can be used to reverse the\n   substitution.\
    \  The low-order portion of the address can be left\n   unanonymized as a partial\
    \ defense against this attack.\n"
- title: 4.2.  MAC Address Anonymization
  contents:
  - "4.2.  MAC Address Anonymization\n   Flow data containing sub-IP information can\
    \ also contain identifying\n   information in the form of the hardware (MAC) address.\
    \  While MAC\n   address information cannot be used to locate a node within a\
    \ network,\n   it can be used to directly and uniquely identify a specific device.\n\
    \   Vendors or organizations within the supply chain may then have the\n   information\
    \ necessary to identify the entity or individual that\n   purchased the device.\n\
    \   MAC address information is not as structured as IP address\n   information.\
    \  EUI-48 and EUI-64 MAC addresses contain an\n   Organizational Unique Identifier\
    \ (OUI) in the three most significant\n   bytes of the address; this OUI additionally\
    \ contains bits noting\n   whether the address is locally or globally administered.\
    \  Beyond\n   this, there is no standard relationship among the OUIs assigned\
    \ to a\n   given vendor.\n   Note that MAC address information also appears within\
    \ IPv6 addresses\n   as the EAP-64 address, or EAP-48 address encoded as an EAP-64\n\
    \   address, is used as the least significant 64 bits of the IPv6 address\n  \
    \ in the case of link-local addressing or stateless autoconfiguration;\n   the\
    \ considerations and techniques in this section may then apply to\n   such IPv6\
    \ addresses as well.\n           +-----------------------------+---------------------+\n\
    \           | Scheme                      | Action              |\n          \
    \ +-----------------------------+---------------------+\n           | Truncation\
    \                  | Generalization      |\n           | Reverse Truncation  \
    \        | Generalization      |\n           | Permutation                 | Direct\
    \ Substitution |\n           | Structured Pseudonymization | Direct Substitution\
    \ |\n           +-----------------------------+---------------------+\n"
- title: 4.2.1.  Truncation
  contents:
  - "4.2.1.  Truncation\n   Truncation removes \"n\" of the least significant bits\
    \ from a MAC\n   address, replacing them with zeroes.  In effect, it retains bits\
    \ of\n   OUI, which identifies the manufacturer, while removing the least\n  \
    \ significant bits identifying the particular device.  Truncation of 24\n   bits\
    \ of an EAP-48 or 40 bits of an EAP-64 address zeroes out the\n   device identifier\
    \ while retaining the OUI.\n   Truncation is effective for making device manufacturers\
    \ partially or\n   completely identifiable within a dataset while deleting unique\
    \ host\n   identifiers; this can be used to retain and aggregate MAC-layer\n \
    \  behavior by vendor.\n   Truncation to an address length of 0 is equivalent\
    \ to black-marker\n   anonymization.\n"
- title: 4.2.2.  Reverse Truncation
  contents:
  - "4.2.2.  Reverse Truncation\n   Reverse truncation removes \"n\" of the most significant\
    \ bits from a\n   MAC address, replacing them with zeroes.  Reverse truncation\
    \ is a\n   non-reversible generalization scheme.  This has the effect of\n   removing\
    \ bits of the OUI, which identify manufacturers, before\n   removing the least\
    \ significant bits.  Reverse truncation of 24 bits\n   zeroes out the OUI.\n \
    \  Reverse truncation is effective for making device manufacturers\n   partially\
    \ or completely unidentifiable within a dataset.  However, it\n   may cause ambiguity\
    \ by introducing the possibility of truncated MAC\n   address collision.  Also,\
    \ note that the utility of removing\n   manufacturer information is not particularly\
    \ well covered by the\n   literature.\n   Reverse truncation to an address length\
    \ of 0 is equivalent to black-\n   marker anonymization.\n"
- title: 4.2.3.  Permutation
  contents:
  - "4.2.3.  Permutation\n   Permutation is a direct substitution technique, replacing\
    \ each MAC\n   address with an address selected from the set of possible MAC\n\
    \   addresses, such that each anonymized address represents a unique\n   original\
    \ address.  The selection function is often random, though it\n   is not necessarily\
    \ so.  Permutation does not preserve any structural\n   information about a network,\
    \ but it does preserve the unique count of\n   devices on the network.  Any application\
    \ that requires more structure\n   than host-uniqueness will not be able to use\
    \ permuted MAC addresses.\n   There are many variations of permutation functions,\
    \ each of which has\n   trade-offs in performance, security, and guarantees of\
    \ non-collision;\n   evaluating these trade-offs is implementation independent.\
    \  However,\n   in general, permutation functions applied to anonymization SHOULD\
    \ be\n   difficult to reverse without knowing the parameters (e.g., a secret\n\
    \   key for HMAC).  While the EAP-48 space is larger than the IPv4\n   address\
    \ space, hash functions applied without additional parameters\n   could be reversed\
    \ through brute force if the hash function is known,\n   and SHOULD NOT be used\
    \ as permutation functions.  Permutation\n   functions may guarantee non-collision\
    \ (i.e., that each anonymized\n   address represents a unique original address),\
    \ but need not; however,\n   the probability of collision SHOULD be low.  Nevertheless,\
    \ we treat\n   even permutations with low but nonzero collision probability as\
    \ a\n   direct substitution.  Beyond these guidelines, recommendations for\n \
    \  specific permutation functions are out of scope for this document.\n"
- title: 4.2.4.  Structured Pseudonymization
  contents:
  - "4.2.4.  Structured Pseudonymization\n   Structured pseudonymization for MAC addresses\
    \ is a direct\n   substitution technique, like permutation, but restricted such\
    \ that\n   the OUI (the most significant three bytes) is permuted separately\n\
    \   from the node identifier, the remainder.  This is useful when the\n   uniqueness\
    \ of OUIs must be preserved for a given analysis task, but\n   introduces structure\
    \ into the anonymized data that can be exploited\n   in attacks against the anonymization\
    \ technique.\n"
- title: 4.3.  Timestamp Anonymization
  contents:
  - "4.3.  Timestamp Anonymization\n   The particular time at which a flow began or\
    \ ended is not\n   particularly identifiable information, but it can be used as\
    \ part of\n   attacks against other anonymization techniques or for user profiling,\n\
    \   e.g., as in [Mur07].  Timestamps can be used in traffic injection\n   attacks,\
    \ which use known information about a set of traffic generated\n   or otherwise\
    \ known by an attacker to recover mappings of other\n   anonymized fields, as\
    \ well as to identify certain activity by\n   response delay and size fingerprinting,\
    \ which compares response sizes\n   and inter-flow times in anonymized data to\
    \ known values.  Note that\n   these attacks have been shown to be relatively\
    \ robust against\n   timestamp anonymization techniques (see [Bur10]), so the\
    \ techniques\n   presented in this section are relatively weak and should be used\
    \ with\n   care.\n          +-----------------------+----------------------------+\n\
    \          | Scheme                | Action                     |\n          +-----------------------+----------------------------+\n\
    \          | Precision Degradation | Generalization             |\n          |\
    \ Enumeration           | Direct or Set Substitution |\n          | Random Shifts\
    \         | Direct Substitution        |\n          +-----------------------+----------------------------+\n"
- title: 4.3.1.  Precision Degradation
  contents:
  - "4.3.1.  Precision Degradation\n   Precision Degradation is a generalization technique\
    \ that removes the\n   most precise components of a timestamp, accounting for\
    \ all events\n   occurring in each given interval (e.g., one millisecond for\n\
    \   millisecond level degradation) as simultaneous.  This has the effect\n   of\
    \ potentially collapsing many timestamps into one.  With this\n   technique, time\
    \ precision is reduced and sequencing may be lost, but\n   the information regarding\
    \ at which time the event occurred is\n   preserved.  The anonymized data may\
    \ not be generally useful for\n   applications that require strict sequencing\
    \ of flows.\n   Note that flow meters with low time precision (e.g., second\n\
    \   precision, or millisecond precision on high-capacity networks)\n   perform\
    \ the equivalent of precision degradation anonymization by\n   their design.\n\
    \   Also, note that degradation to a very low precision (e.g., on the\n   order\
    \ of minutes, hours, or days) is commonly used in analyses\n   operating on time-series\
    \ aggregated data, and may also be described\n   as binning; though the time scales\
    \ are longer and applicability more\n   restricted, in principle, this is the\
    \ same operation.\n   Precision degradation to infinitely low precision is equivalent\
    \ to\n   black-marker anonymization.  Removal of timestamp information is only\n\
    \   recommended for analysis tasks that have no need to separate flows in\n  \
    \ time, for example, for counting total volumes or unique occurrences\n   of other\
    \ flow keys in an entire dataset.\n"
- title: 4.3.2.  Enumeration
  contents:
  - "4.3.2.  Enumeration\n   Enumeration is a substitution function that retains the\
    \ chronological\n   order in which events occurred while eliminating time information.\n\
    \   Timestamps are substituted by equidistant timestamps (or numbers)\n   starting\
    \ from a randomly chosen start value.  The resulting data is\n   useful for applications\
    \ requiring strict sequencing, but not for\n   those requiring good timing information\
    \ (e.g., delay- or jitter-\n   measurement for quality-of-service (QoS) applications\
    \ or service-\n   level agreement (SLA) validation).\n   Note that enumeration\
    \ is functionally equivalent to precision\n   degradation in any environment into\
    \ which traffic can be regularly\n   injected to serve as a clock at the precision\
    \ of the frequency of the\n   injected flows.\n"
- title: 4.3.3.  Random Shifts
  contents:
  - "4.3.3.  Random Shifts\n   Random time shifts add a random offset to every timestamp\
    \ within a\n   dataset.  Therefore, this reversible substitution technique retains\n\
    \   duration and inter-event interval information as well as the\n   chronological\
    \ order of flows.  Random time shifts are quite weak and\n   relatively easy to\
    \ reverse in the presence of external knowledge\n   about traffic on the measured\
    \ network.\n"
- title: 4.4.  Counter Anonymization
  contents:
  - "4.4.  Counter Anonymization\n   Counters (such as packet and octet volumes per\
    \ flow) are subject to\n   fingerprinting and injection attacks against anonymization\
    \ or for\n   user profiling as timestamps are.  Data sets with anonymized counters\n\
    \   are useful only for analysis tasks for which relative or imprecise\n   magnitudes\
    \ of activity are useful.  Counter information can also be\n   completely removed,\
    \ but this is only recommended for analysis tasks\n   that have no need to evaluate\
    \ the removed counter, for example, for\n   counting only unique occurrences of\
    \ other flow keys.\n          +-----------------------+----------------------------+\n\
    \          | Scheme                | Action                     |\n          +-----------------------+----------------------------+\n\
    \          | Precision Degradation | Generalization             |\n          |\
    \ Binning               | Generalization             |\n          | Random noise\
    \ addition | Direct or Set Substitution |\n          +-----------------------+----------------------------+\n"
- title: 4.4.1.  Precision Degradation
  contents:
  - "4.4.1.  Precision Degradation\n   As with precision degradation in timestamps,\
    \ precision degradation of\n   counters removes lower-order bits of the counters,\
    \ treating all the\n   counters in a given range as having the same value.  Depending\
    \ on the\n   precision reduction, this loses information about the relationships\n\
    \   between sizes of similarly sized flows, but keeps relative magnitude\n   information.\
    \  Precision degradation to an infinitely low precision is\n   equivalent to black-marker\
    \ anonymization.\n"
- title: 4.4.2.  Binning
  contents:
  - "4.4.2.  Binning\n   Binning can be seen as a special case of precision degradation;\
    \ the\n   operation is identical, except for in precision degradation the\n  \
    \ counter ranges are uniform, and in binning, they need not be.  For\n   example,\
    \ consider separating unopened TCP connections from\n   potentially opened TCP\
    \ connections.  Here, packet counters per flow\n   would be binned into two bins,\
    \ one for 1-2 packet flows, and one for\n   flows with 3 or more packets.  Binning\
    \ schemes are generally chosen\n   to keep precisely the amount of information\
    \ required in a counter for\n   a given analysis task.  Note that, also unlike\
    \ precision degradation,\n   the bin label need not be within the bin's range.\
    \  Binning counters\n   to a single bin is equivalent to black-marker anonymization.\n"
- title: 4.4.3.  Random Noise Addition
  contents:
  - "4.4.3.  Random Noise Addition\n   Random noise addition adds a random amount\
    \ to a counter in each flow;\n   this is used to keep relative magnitude information\
    \ and minimize the\n   disruption to size relationship information while avoiding\n\
    \   fingerprinting attacks against anonymization.  Note that there is no\n   guarantee\
    \ that random noise addition will maintain ranking order by a\n   counter among\
    \ members of a set.  Random noise addition is\n   particularly useful when the\
    \ derived analysis data will not be\n   presented in such a way as to require\
    \ the lower-order bits of the\n   counters.\n"
- title: 4.5.  Anonymization of Other Flow Fields
  contents:
  - "4.5.  Anonymization of Other Flow Fields\n   Other fields, particularly port\
    \ numbers and protocol numbers, can be\n   used to partially identify the applications\
    \ that generated the\n   traffic in a given flow trace.  This information can\
    \ be used in\n   fingerprinting attacks, and may be of interest on its own (e.g.,\
    \ to\n   reveal that a certain application with suspected vulnerabilities is\n\
    \   running on a given network).  These fields are generally anonymized\n   using\
    \ one of two techniques.\n                   +-------------+---------------------+\n\
    \                   | Scheme      | Action              |\n                  \
    \ +-------------+---------------------+\n                   | Binning     | Generalization\
    \      |\n                   | Permutation | Direct Substitution |\n         \
    \          +-------------+---------------------+\n"
- title: 4.5.1.  Binning
  contents:
  - "4.5.1.  Binning\n   Binning is a generalization technique mapping a set of potentially\n\
    \   non-uniform ranges into a set of arbitrarily labeled bins.  Common\n   bin\
    \ arrangements depend on the field type and the analysis\n   application.  For\
    \ example, an IP protocol bin arrangement may\n   preserve 1, 6, and 17 for ICMP,\
    \ UDP, and TCP traffic, and bin all\n   other protocols into a single bin, to\
    \ mitigate the use of uncommon\n   protocols in fingerprinting attacks.  Another\
    \ example arrangement may\n   bin source and destination ports into low (0-1023)\
    \ and high (1024-\n   65535) bins in order to tell service from ephemeral ports\
    \ without\n   identifying individual applications.\n   Binning other flow key\
    \ fields to a single bin is equivalent to black-\n   marker anonymization.  Removal\
    \ of other flow key information is only\n   recommended for analysis tasks that\
    \ have no need to differentiate\n   flows on the removed keys, for example, for\
    \ total traffic counts or\n   unique counts of other flow keys.\n"
- title: 4.5.2.  Permutation
  contents:
  - "4.5.2.  Permutation\n   Permutation is a direct substitution technique, replacing\
    \ each value\n   with an value selected from the set of possible range, such that\
    \ each\n   anonymized value represents a unique original value.  This is used\
    \ to\n   preserve the count of unique values without preserving information\n\
    \   about, or the ordering of, the values themselves.\n   While permutation ideally\
    \ guarantees that each anonymized value\n   represents a unique original value,\
    \ such may require significant\n   state in the Intermediate Anonymization Process.\
    \  Therefore,\n   permutation may be implemented by hashing for performance reasons,\n\
    \   with hash functions that may have relatively small collision\n   probabilities.\
    \  Such techniques are still essentially direct\n   substitution techniques, despite\
    \ the nonzero error probability.\n"
- title: 5.  Parameters for the Description of Anonymization Techniques
  contents:
  - "5.  Parameters for the Description of Anonymization Techniques\n   This section\
    \ details the abstract parameters used to describe the\n   anonymization techniques\
    \ examined in the previous section, on a per-\n   parameter basis.  These parameters\
    \ and their export safety inform the\n   design of the IPFIX anonymization metadata\
    \ export specified in the\n   following section.\n"
- title: 5.1.  Stability
  contents:
  - "5.1.  Stability\n   A stable anonymization will always map a given value in the\
    \ real\n   space to a given value in the anonymized space, while an unstable\n\
    \   anonymization will change this mapping over time; a completely\n   unstable\
    \ anonymization is essentially indistinguishable from black-\n   marker anonymization.\
    \  Any given anonymization technique may be\n   applied with a varying range of\
    \ stability.  Stability is important\n   for assessing the comparability of anonymized\
    \ information in\n   different datasets, or in the same dataset over different\
    \ time\n   periods.  In practice, an anonymization may also be stable for every\n\
    \   dataset published by a particular producer to a particular consumer,\n   stable\
    \ for a stated time period within a dataset or across datasets,\n   or stable\
    \ only for a single dataset.\n   If no information about stability is available,\
    \ users of anonymized\n   data MAY assume that the techniques used are stable\
    \ across the entire\n   dataset, but unstable across datasets.  Note that stability\
    \ presents\n   a risk-utility trade-off, as completely stable anonymization can\
    \ be\n   used for longer-term trend analysis tasks but also presents more risk\n\
    \   of attack given the stable mapping.  Information about the stability\n   of\
    \ a mapping SHOULD be exported along with the anonymized data.\n"
- title: 5.2.  Truncation Length
  contents:
  - "5.2.  Truncation Length\n   Truncation and precision degradation are described\
    \ by the truncation\n   length or the amount of data still remaining in the anonymized\
    \ field\n   after anonymization.\n   Truncation length can generally be inferred\
    \ from a given dataset, and\n   need not be specially exported or protected. \
    \ For bit-level\n   truncation, the truncated bits are generally inferable by\
    \ the least\n   significant bit set for an instance of an Information Element\n\
    \   described by a given Template (or the most significant bit set, in\n   the\
    \ case of reverse truncation).  For precision degradation, the\n   truncation\
    \ is inferable from the maximum precision given.  Note that\n   while this inference\
    \ method is generally applicable, it is data\n   dependent: there is no guarantee\
    \ that it will recover the exact\n   truncation length used to prepare the data.\n\
    \   In the special case of IP address export with variable (per-record)\n   truncation,\
    \ the truncation MAY be expressed by exporting the prefix\n   length alongside\
    \ the address.\n"
- title: 5.3.  Bin Map
  contents:
  - "5.3.  Bin Map\n   Binning is described by the specification of a bin mapping\
    \ function.\n   This function can be generally expressed in terms of an associative\n\
    \   array that maps each point in the original space to a bin, although\n   from\
    \ an implementation standpoint most bin functions are much simpler\n   and more\
    \ efficient.\n   Since the bin map for a bin mapping function is in essence the\
    \ bin\n   mapping key, and can be used to partially deanonymize binned data,\n\
    \   depending on the degree of generalization, information about the bin\n   mapping\
    \ function SHOULD NOT be exported.\n"
- title: 5.4.  Permutation
  contents:
  - "5.4.  Permutation\n   Like binning, permutation is described by the specification\
    \ of a\n   permutation function.  In the general case, this can be expressed in\n\
    \   terms of an associative array that maps each point in the original\n   space\
    \ to a point in the anonymized space.  Unlike binning, each point\n   in the anonymized\
    \ space corresponds to a single, unique point in the\n   original space.\n   Since\
    \ the parameters of the permutation function are in essence key-\n   like (indeed,\
    \ for cryptographic permutation functions, they are the\n   keys themselves),\
    \ information about the permutation function or its\n   parameters SHOULD NOT\
    \ be exported.\n"
- title: 5.5.  Shift Amount
  contents:
  - "5.5.  Shift Amount\n   Shifting requires an amount by which to shift each value.\
    \  Since the\n   shift amount is the only key to a shift function, and can be\
    \ used to\n   trivially deanonymize data protected by shifting, information about\n\
    \   the shift amount SHOULD NOT be exported.\n"
- title: 6.  Anonymization Export Support in IPFIX
  contents:
  - "6.  Anonymization Export Support in IPFIX\n   Anonymized data exported via IPFIX\
    \ SHOULD be annotated with\n   anonymization metadata, which details which fields\
    \ described by which\n   Templates are anonymized, and provides appropriate information\
    \ on the\n   anonymization techniques used.  This metadata SHOULD be exported\
    \ in\n   Data Records described by the recommended Options Templates described\n\
    \   in this section; these Options Templates use the additional\n   Information\
    \ Elements described in the following subsection.\n   Note that fields anonymized\
    \ using the black-marker (removal)\n   technique do not require any special metadata\
    \ support: black-marker\n   anonymized fields SHOULD NOT be exported at all, by\
    \ omitting the\n   corresponding Information Elements from Template describing\
    \ the Data\n   Set.  In the case where application requirements dictate that a\n\
    \   black-marker anonymized field must remain in a Template, then an\n   Exporting\
    \ Process MAY export black-marker anonymized fields with\n   their native length\
    \ as all-zeros, but only in cases where enough\n   contextual information exists\
    \ within the record to differentiate a\n   black-marker anonymized field exported\
    \ in this way from a real zero\n   value.\n"
- title: 6.1.  Anonymization Records and the Anonymization Options Template
  contents:
  - "6.1.  Anonymization Records and the Anonymization Options Template\n   The Anonymization\
    \ Options Template describes Anonymization Records,\n   which allow anonymization\
    \ metadata to be exported inline over IPFIX\n   or stored in an IPFIX File, by\
    \ binding information about\n   anonymization techniques to Information Elements\
    \ within defined\n   Templates or Options Templates.  IPFIX Exporting Processes\
    \ SHOULD\n   export anonymization records for any Template describing exported\n\
    \   anonymized Data Records; IPFIX Collecting Processes and processes\n   downstream\
    \ from them MAY use anonymization records to treat\n   anonymized data differently\
    \ depending on the applied technique.\n   Anonymization Records contain ancillary\
    \ information bound to a\n   Template, so many of the considerations for Templates\
    \ apply to\n   Anonymization Records as well.  First, reliability is important:\
    \ an\n   Exporting Process SHOULD export Anonymization Records after the\n   Templates\
    \ they describe have been exported, and SHOULD export\n   anonymization records\
    \ reliably if supported by the underlying\n   transport (i.e., without partial\
    \ reliability when using Stream\n   Control Transmission Protocol (SCTP)).\n \
    \  Anonymization Records MUST be handled by Collecting Processes as\n   scoped\
    \ to the Template to which they apply within the Transport\n   Session in which\
    \ they are sent.  When a Template is withdrawn via a\n   Template Withdrawal Message\
    \ or expires during a UDP transport\n   session, the accompanying Anonymization\
    \ Records are withdrawn or\n   expire as well and do not apply to subsequent Templates\
    \ with the same\n   Template ID within the Session unless re-exported.\n   The\
    \ Stability Class within the anonymizationFlags IE can be used to\n   declare\
    \ that a given anonymization technique's mapping will remain\n   stable across\
    \ multiple sessions, but this does not mean that\n   anonymization technique information\
    \ given in the Anonymization\n   Records themselves persist across Sessions. \
    \ Each new Transport\n   Session MUST contain new Anonymization Records for each\
    \ Template\n   describing anonymized Data Sets.\n   SCTP per-stream export [IPFIX-PERSTREAM]\
    \ may be used to ease\n   management of Anonymization Records if appropriate for\
    \ the\n   application.\n   The fields of the Anonymization Options Template are\
    \ as follows:\n   +-------------------------+-----------------------------------------+\n\
    \   | IE                      | Description                             |\n  \
    \ +-------------------------+-----------------------------------------+\n   |\
    \ templateId [scope]      | The Template ID of the Template or      |\n   |  \
    \                       | Options Template containing the         |\n   |    \
    \                     | Information Element described by this   |\n   |      \
    \                   | anonymization record.  This Information |\n   |        \
    \                 | Element MUST be defined as a Scope      |\n   |          \
    \               | Field.                                  |\n   | informationElementId\
    \    | The Information Element identifier of   |\n   | [scope]               \
    \  | the Information Element described by    |\n   |                         |\
    \ this anonymization record.  This        |\n   |                         | Information\
    \ Element MUST be defined as  |\n   |                         | a Scope Field.\
    \  Exporting Processes     |\n   |                         | MUST clear then Enterprise\
    \ bit of the   |\n   |                         | informationElementId and Collecting\
    \     |\n   |                         | Processes SHOULD ignore it; information\
    \ |\n   |                         | about enterprise-specific Information   |\n\
    \   |                         | Elements is exported via the            |\n  \
    \ |                         | privateEnterpriseNumber Information     |\n   |\
    \                         | Element.                                |\n   | privateEnterpriseNumber\
    \ | The Private Enterprise Number of the    |\n   | [scope] [optional]      |\
    \ enterprise-specific Information Element |\n   |                         | described\
    \ by this anonymization record. |\n   |                         | This Information\
    \ Element MUST be        |\n   |                         | defined as a Scope\
    \ Field if present.  A |\n   |                         | privateEnterpriseNumber\
    \ of 0 signifies  |\n   |                         | that the Information Element\
    \ is         |\n   |                         | IANA-registered.              \
    \          |\n   | informationElementIndex | The Information Element index of\
    \ the    |\n   | [scope] [optional]      | instance of the Information Element\
    \     |\n   |                         | described by this anonymization record\
    \  |\n   |                         | identified by the informationElementId  |\n\
    \   |                         | within the Template.  Optional; need    |\n  \
    \ |                         | only be present when describing         |\n   |\
    \                         | Templates that have multiple instances  |\n   |  \
    \                       | of the same Information Element.  This  |\n   |    \
    \                     | Information Element MUST be defined as  |\n   |      \
    \                   | a Scope Field if present.  This         |\n   |        \
    \                 | Information Element is defined in       |\n   |          \
    \               | Section 6.2.                            |\n   | anonymizationFlags\
    \      | Flags describing the mapping stability  |\n   |                     \
    \    | and specialized modifications to the    |\n   |                       \
    \  | Anonymization Technique in use.  SHOULD |\n   |                         |\
    \ be present.  This Information Element   |\n   |                         | is\
    \ defined in Section 6.2.3.            |\n   | anonymizationTechnique  | The technique\
    \ used to anonymize the     |\n   |                         | data.  MUST be present.\
    \  This           |\n   |                         | Information Element is defined\
    \ in       |\n   |                         | Section 6.2.2.                  \
    \        |\n   +-------------------------+-----------------------------------------+\n"
- title: 6.2.  Recommended Information Elements for Anonymization Metadata
  contents:
  - '6.2.  Recommended Information Elements for Anonymization Metadata

    '
- title: 6.2.1.  informationElementIndex
  contents:
  - "6.2.1.  informationElementIndex\n   Description:   A zero-based index of an Information\
    \ Element\n      referenced by informationElementId within a Template referenced\
    \ by\n      templateId; used to disambiguate scope for templates containing\n\
    \      multiple identical Information Elements.\n   Abstract Data Type:   unsigned16\n\
    \   Data Type Semantics:   identifier\n   ElementId:   287\n   Status:   Current\n"
- title: 6.2.2.  anonymizationTechnique
  contents:
  - "6.2.2.  anonymizationTechnique\n   Description:   A description of the anonymization\
    \ technique applied\n      to a referenced Information Element within a referenced\
    \ Template.\n      Each technique may be applicable only to certain Information\n\
    \      Elements and recommended only for certain Information Elements;\n     \
    \ these restrictions are noted in the table below.\n   +-------+---------------------------+-----------------+-------------+\n\
    \   | Value | Description               | Applicable to   | Recommended |\n  \
    \ |       |                           |                 | for         |\n   +-------+---------------------------+-----------------+-------------+\n\
    \   | 0     | Undefined: the Exporting  | all             | all         |\n  \
    \ |       | Process makes no          |                 |             |\n   |\
    \       | representation as to      |                 |             |\n   |  \
    \     | whether or not the        |                 |             |\n   |    \
    \   | defined field is          |                 |             |\n   |      \
    \ | anonymized.  While the    |                 |             |\n   |       |\
    \ Collecting Process MAY    |                 |             |\n   |       | assume\
    \ that the field is  |                 |             |\n   |       | not anonymized,\
    \ it is not |                 |             |\n   |       | guaranteed not to\
    \ be.     |                 |             |\n   |       | This is the default\
    \       |                 |             |\n   |       | anonymization technique.\
    \  |                 |             |\n   | 1     | None: the values exported |\
    \ all             | all         |\n   |       | are real.                 |  \
    \               |             |\n   | 2     | Precision                 | all\
    \             | all         |\n   |       | Degradation/Truncation:   |      \
    \           |             |\n   |       | the values exported are   |        \
    \         |             |\n   |       | anonymized using simple   |          \
    \       |             |\n   |       | precision degradation or  |            \
    \     |             |\n   |       | truncation.  The new      |              \
    \   |             |\n   |       | precision or number of    |                \
    \ |             |\n   |       | truncated bits is         |                 |\
    \             |\n   |       | implicit in the exported  |                 |  \
    \           |\n   |       | data and can be deduced   |                 |    \
    \         |\n   |       | by the Collecting         |                 |      \
    \       |\n   |       | Process.                  |                 |        \
    \     |\n   | 3     | Binning: the values       | all             | all      \
    \   |\n   |       | exported are anonymized   |                 |            \
    \ |\n   |       | into bins.                |                 |             |\n\
    \   | 4     | Enumeration: the values   | all             | timestamps  |\n  \
    \ |       | exported are anonymized   |                 |             |\n   |\
    \       | by enumeration.           |                 |             |\n   | 5\
    \     | Permutation: the values   | all             | identifiers |\n   |    \
    \   | exported are anonymized   |                 |             |\n   |      \
    \ | by permutation.           |                 |             |\n   | 6     |\
    \ Structured Permutation:   | addresses       |             |\n   |       | the\
    \ values exported are   |                 |             |\n   |       | anonymized\
    \ by             |                 |             |\n   |       | permutation,\
    \ preserving   |                 |             |\n   |       | bit-level structure\
    \ as    |                 |             |\n   |       | appropriate; this    \
    \     |                 |             |\n   |       | represents             \
    \   |                 |             |\n   |       | prefix-preserving IP     \
    \ |                 |             |\n   |       | address anonymization or  |\
    \                 |             |\n   |       | structured MAC address    |  \
    \               |             |\n   |       | anonymization.            |    \
    \             |             |\n   | 7     | Reverse Truncation: the   | addresses\
    \       |             |\n   |       | values exported are       |            \
    \     |             |\n   |       | anonymized using reverse  |              \
    \   |             |\n   |       | truncation.  The number   |                \
    \ |             |\n   |       | of truncated bits is      |                 |\
    \             |\n   |       | implicit in the exported  |                 |  \
    \           |\n   |       | data, and can be deduced  |                 |    \
    \         |\n   |       | by the Collecting         |                 |      \
    \       |\n   |       | Process.                  |                 |        \
    \     |\n   | 8     | Noise: the values         | non-identifiers | counters \
    \   |\n   |       | exported are anonymized   |                 |            \
    \ |\n   |       | by adding random noise to |                 |             |\n\
    \   |       | each value.               |                 |             |\n  \
    \ | 9     | Offset: the values        | all             | timestamps  |\n   |\
    \       | exported are anonymized   |                 |             |\n   |  \
    \     | by adding a single offset |                 |             |\n   |    \
    \   | to all values.            |                 |             |\n   +-------+---------------------------+-----------------+-------------+\n\
    \   Abstract Data Type:   unsigned16\n   Data Type Semantics:   identifier\n \
    \  ElementId:   286\n   Status:   Current\n"
- title: 6.2.3.  anonymizationFlags
  contents:
  - "6.2.3.  anonymizationFlags\n   Description:   A flag word describing specialized\
    \ modifications to\n      the anonymization policy in effect for the anonymization\
    \ technique\n      applied to a referenced Information Element within a referenced\n\
    \      Template.  When flags are clear (0), the normal policy (as\n      described\
    \ by anonymizationTechnique) applies without modification.\n      MSB   14  13\
    \  12  11  10   9   8   7   6   5   4   3   2   1  LSB\n      +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n\
    \      |                Reserved                       |LOR|PmA|   SC  |\n   \
    \   +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n      \
    \                      anonymizationFlags IE\n   +--------+----------+-----------------------------------------------+\n\
    \   | bit(s) | name     | description                                   |\n  \
    \ | (LSB = |          |                                               |\n   |\
    \ 0)     |          |                                               |\n   +--------+----------+-----------------------------------------------+\n\
    \   | 0-1    | SC       | Stability Class: see the Stability Class      |\n  \
    \ |        |          | table below, and Section 5.1.                 |\n   |\
    \ 2      | PmA      | Perimeter Anonymization: when set (1), source |\n   |  \
    \      |          | Information Elements as described in          |\n   |    \
    \    |          | [RFC5103] are interpreted as external         |\n   |      \
    \  |          | addresses, and destination Information        |\n   |        |\
    \          | Elements as described in [RFC5103] are        |\n   |        |  \
    \        | interpreted as internal addresses, for the    |\n   |        |    \
    \      | purposes of associating                       |\n   |        |      \
    \    | anonymizationTechnique to Information         |\n   |        |        \
    \  | Elements only; see Section 7.2.2 for details. |\n   |        |          |\
    \ This bit MUST NOT be set when associated with |\n   |        |          | a\
    \ non-endpoint (i.e., source or destination)  |\n   |        |          | Information\
    \ Element.  SHOULD be consistent    |\n   |        |          | within a record\
    \ (i.e., if a source            |\n   |        |          | Information Element\
    \ has this flag set, the    |\n   |        |          | corresponding destination\
    \ element SHOULD have |\n   |        |          | this flag set, and vice versa.)\
    \               |\n   | 3      | LOR      | Low-Order Unchanged: when set (1),\
    \ the        |\n   |        |          | low-order bits of the anonymized Information\
    \  |\n   |        |          | Element contain real data.  This modification |\n\
    \   |        |          | is intended for the anonymization of          |\n  \
    \ |        |          | network-level addresses while leaving         |\n   |\
    \        |          | host-level addresses intact in order to       |\n   |  \
    \      |          | preserve host level-structure, which could    |\n   |    \
    \    |          | otherwise be used to reverse anonymization.   |\n   |      \
    \  |          | MUST NOT be set when associated with a        |\n   |        |\
    \          | truncation-based anonymizationTechnique.      |\n   | 4-15   | Reserved\
    \ | Reserved for future use: SHOULD be cleared    |\n   |        |          |\
    \ (0) by the Exporting Process and MUST be      |\n   |        |          | ignored\
    \ by the Collecting Process.            |\n   +--------+----------+-----------------------------------------------+\n\
    \      The Stability Class portion of this flags word describes the\n      stability\
    \ class of the anonymization technique applied to a\n      referenced Information\
    \ Element within a referenced Template.\n      Stability classes refer to the\
    \ stability of the parameters of the\n      anonymization technique, and therefore\
    \ the comparability of the\n      mapping between the real and anonymized values\
    \ over time.  This\n      determines which anonymized datasets may be compared\
    \ with each\n      other.  Values are as follows:\n   +-----+-----+-------------------------------------------------------+\n\
    \   | Bit | Bit | Description                                           |\n  \
    \ | 1   | 0   |                                                       |\n   +-----+-----+-------------------------------------------------------+\n\
    \   | 0   | 0   | Undefined: the Exporting Process makes no             |\n  \
    \ |     |     | representation as to how stable the mapping is, or    |\n   |\
    \     |     | over what time period values of this field will       |\n   |  \
    \   |     | remain comparable; while the Collecting Process MAY   |\n   |    \
    \ |     | assume Session level stability, Session level         |\n   |     |\
    \     | stability is not guaranteed.  Processes SHOULD assume |\n   |     |  \
    \   | this is the case in the absence of stability class    |\n   |     |    \
    \ | information; this is the default stability class.     |\n   | 0   | 1   |\
    \ Session: the Exporting Process will ensure that the   |\n   |     |     | parameters\
    \ of the anonymization technique are stable  |\n   |     |     | during the Transport\
    \ Session.  All the values of the  |\n   |     |     | described Information Element\
    \ for each Record         |\n   |     |     | described by the referenced Template\
    \ within the       |\n   |     |     | Transport Session are comparable.  The\
    \ Exporting      |\n   |     |     | Process SHOULD endeavor to ensure at least\
    \ this       |\n   |     |     | stability class.                            \
    \          |\n   | 1   | 0   | Exporter-Collector Pair: the Exporting Process\
    \ will   |\n   |     |     | ensure that the parameters of the anonymization \
    \      |\n   |     |     | technique are stable across Transport Sessions over\
    \   |\n   |     |     | time with the given Collecting Process, but may use  \
    \ |\n   |     |     | different parameters for different Collecting         |\n\
    \   |     |     | Processes.  Data exported to different Collecting     |\n  \
    \ |     |     | Processes are not comparable.                         |\n   |\
    \ 1   | 1   | Stable: the Exporting Process will ensure that the    |\n   |  \
    \   |     | parameters of the anonymization technique are stable  |\n   |    \
    \ |     | across Transport Sessions over time, regardless of    |\n   |     |\
    \     | the Collecting Process to which it is sent.           |\n   +-----+-----+-------------------------------------------------------+\n\
    \   Abstract Data Type:   unsigned16\n   Data Type Semantics:   flags\n   ElementId:\
    \   285\n   Status:   Current\n"
- title: 7.  Applying Anonymization Techniques to IPFIX Export and Storage
  contents:
  - "7.  Applying Anonymization Techniques to IPFIX Export and Storage\n   When exporting\
    \ or storing anonymized flow data using IPFIX, certain\n   interactions between\
    \ the IPFIX protocol and the anonymization\n   techniques in use must be considered;\
    \ these are treated in the\n   subsections below.\n"
- title: 7.1.  Arrangement of Processes in IPFIX Anonymization
  contents:
  - "7.1.  Arrangement of Processes in IPFIX Anonymization\n   Anonymization may be\
    \ applied to IPFIX data at three stages within the\n   collection infrastructure:\
    \ on initial export, at a mediator, or after\n   collection, as shown in Figure\
    \ 1.  Each of these locations has\n   specific considerations and applicability.\n\
    \               +==========================================+\n               |\
    \ Exporting Process                        |\n               +==========================================+\n\
    \                 |                                      |\n                 |\
    \    (Anonymized at Original Exporter) |\n                 V                 \
    \                     |\n               +=============================+      \
    \    |\n               | Mediator                    |          |\n          \
    \     +=============================+          |\n                 |         \
    \                             |\n                 | (Anonymizing Mediator)   \
    \            |\n                 V                                      V\n  \
    \             +==========================================+\n               | Collecting\
    \ Process                       |\n               +==========================================+\n\
    \                       |\n                       | (Anonymizing CP/File Writer)\n\
    \                       V\n               +--------------------+\n           \
    \    | IPFIX File Storage |\n               +--------------------+\n         \
    \       Figure 1: Potential Anonymization Locations\n   Anonymization is generally\
    \ performed before the wider dissemination\n   or repurposing of a dataset, e.g.,\
    \ adapting operational measurement\n   data for research.  Therefore, direct anonymization\
    \ of flow data on\n   initial export is only applicable in certain restricted\n\
    \   circumstances: when the Exporting Process (EP) is \"publishing\" data\n  \
    \ to a Collecting Process (CP) directly, and the Exporting Process and\n   Collecting\
    \ Process are operated by different entities.  Note that\n   certain guidelines\
    \ in Section 7.2.3 with respect to timestamp\n   anonymization may not apply in\
    \ this case, as the Collecting Process\n   may be able to deduce certain timing\
    \ information from the time at\n   which each Message is received.\n   A much\
    \ more flexible arrangement is to anonymize data within a\n   Mediator [RFC6183].\
    \  Here, original data is sent to a Mediator, which\n   performs the anonymization\
    \ function and re-exports the anonymized\n   data.  Such a Mediator could be located\
    \ at the administrative domain\n   boundary of the initial Exporting Process operator,\
    \ exporting\n   anonymized data to other consumers outside the organization. \
    \ In this\n   case, the original Exporter SHOULD use TLS [RFC5246] as specified\
    \ in\n   [RFC5101] to secure the channel to the Mediator, and the Mediator\n \
    \  should follow the guidelines in Section 7.2, to mitigate the risk of\n   original\
    \ data disclosure.\n   When data is to be published as an anonymized dataset in\
    \ an IPFIX\n   File [RFC5655], the anonymization may be done at the final Collecting\n\
    \   Process before storage and dissemination, as well.  In this case, the\n  \
    \ Collector should follow the guidelines in Section 7.2, especially as\n   regards\
    \ File-specific Options in Section 7.2.4\n   In each of these data flows, the\
    \ anonymization of records is\n   undertaken by an Intermediate Anonymization\
    \ Process (IAP); the data\n   flows into and out of this IAP are shown in Figure\
    \ 2 below.\n   packets --+                     +- IPFIX Messages -+\n        \
    \     |                     |                  |\n             V             \
    \        V                  V\n   +==================+ +====================+\
    \ +=============+\n   | Metering Process | | Collecting Process | | File Reader\
    \ |\n   +==================+ +====================+ +=============+\n        \
    \     |      Non-anonymized | Records          |\n             V             \
    \        V                  V\n   +=========================================================+\n\
    \   |          Intermediate Anonymization Process (IAP)       |\n   +=========================================================+\n\
    \             | Anonymized     ^            Anonymized |\n             | Records\
    \        |               Records |\n             V                |          \
    \             V\n   +===================+    Anonymization      +=============+\n\
    \   | Exporting Process |<--- Parameters ------>| File Writer |\n   +===================+\
    \                       +=============+\n             |                      \
    \                  |\n             +------------> IPFIX Messages <----------+\n\
    \          Figure 2: Data Flows through the Anonymization Process\n   Anonymization\
    \ parameters must also be available to the Exporting\n   Process and/or File Writer\
    \ in order to ensure header data is also\n   appropriately anonymized as in Section\
    \ 7.2.3.\n   Following each of the data flows through the IAP, we describe five\n\
    \   basic types of anonymization arrangements within this framework in\n   Figure\
    \ 3.  In addition to the three arrangements described in detail\n   above, anonymization\
    \ can also be done at a collocated Metering\n   Process (MP) and File Writer (FW)\
    \ (see Section 7.3.2 of [RFC5655]),\n   or at a file manipulator, which combines\
    \ a File Writer with a File\n   Reader (FR) (see Section 7.3.7 of [RFC5655]).\n\
    \         +----+  +-----+  +----+\n pkts -> | MP |->| IAP |->| EP |-> Anonymization\
    \ on Original Exporter\n         +----+  +-----+  +----+\n         +----+  +-----+\
    \  +----+\n pkts -> | MP |->| IAP |->| FW |-> Anonymizing collocated MP/File Writer\n\
    \         +----+  +-----+  +----+\n         +----+  +-----+  +----+\n"
- title: IPFIX -> | CP |->| IAP |->| EP |-> Anonymizing Mediator (Masq. Proxy)
  contents:
  - "IPFIX -> | CP |->| IAP |->| EP |-> Anonymizing Mediator (Masq. Proxy)\n     \
    \    +----+  +-----+  +----+\n         +----+  +-----+  +----+\n"
- title: IPFIX -> | CP |->| IAP |->| FW |-> Anonymizing collocated CP/File Writer
  contents:
  - "IPFIX -> | CP |->| IAP |->| FW |-> Anonymizing collocated CP/File Writer\n  \
    \       +----+  +-----+  +----+\n         +----+  +-----+  +----+\n"
- title: IPFIX -> | FR |->| IAP |->| FW |-> Anonymizing file manipulator
  contents:
  - "IPFIX -> | FR |->| IAP |->| FW |-> Anonymizing file manipulator\n File    +----+\
    \  +-----+  +----+\n        Figure 3: Possible Anonymization Arrangements in the\
    \ IPFIX\n                               Architecture\n   Note that anonymization\
    \ may occur at more than one location within a\n   given collection infrastructure,\
    \ to provide varying levels of\n   anonymization, disclosure risk, or data utility\
    \ for specific\n   purposes.\n"
- title: 7.2.  IPFIX-Specific Anonymization Guidelines
  contents:
  - "7.2.  IPFIX-Specific Anonymization Guidelines\n   In implementing and deploying\
    \ the anonymization techniques described\n   in this document, implementors should\
    \ note that IPFIX already\n   provides features that support anonymized data export,\
    \ and use these\n   where appropriate.  Care must also be taken that data structures\n\
    \   supporting the operation of the protocol itself do not leak data that\n  \
    \ could be used to reverse the anonymization applied to the flow data.\n   Such\
    \ data structures may appear in the header, or within the data\n   stream itself,\
    \ especially as options data.  Each of these and their\n   impact on specific\
    \ anonymization techniques is noted in a separate\n   subsection below.\n"
- title: 7.2.1.  Appropriate Use of Information Elements for Anonymized Data
  contents:
  - "7.2.1.  Appropriate Use of Information Elements for Anonymized Data\n   Note,\
    \ as in Section 6 above, that black-marker anonymized fields\n   SHOULD NOT be\
    \ exported at all; the absence of the field in a given\n   Data Set is implicitly\
    \ declared by not including the corresponding\n   Information Element in the Template\
    \ describing that Data Set.\n   When using precision degradation of timestamps,\
    \ Exporting Processes\n   SHOULD export timing information using Information Elements\
    \ of an\n   appropriate precision, as explained in Section 4.5 of [RFC5153]. \
    \ For\n   example, timestamps measured in millisecond-level precision and\n  \
    \ degraded to second-level precision should use flowStartSeconds and\n   flowEndSeconds,\
    \ not flowStartMilliseconds and flowEndMilliseconds.\n   When exporting anonymized\
    \ data and anonymization metadata, Exporting\n   Processes SHOULD ensure that\
    \ the combination of Information Element\n   and declared anonymization technique\
    \ are compatible.  Specifically,\n   the applicable and recommended Information\
    \ Element types and\n   semantics for each technique are noted in the description\
    \ of the\n   anonymizationTechnique Information Element in Section 6.2.2.  In\
    \ this\n   description, a timestamp is an Information Element with the data type\n\
    \   dateTimeSeconds, dataTimeMilliseconds, dateTimeMicroseconds, or\n   dateTimeNanoseconds;\
    \ an address is an Information Element with the\n   data type ipv4Address, ipv6Address,\
    \ or macAddress; and an identifier\n   is an Information Element with identifier\
    \ data type semantics.\n   Exporting Process MUST NOT export Anonymization Options\
    \ records\n   binding techniques to Information Elements to which they are not\n\
    \   applicable, and SHOULD NOT export Anonymization Options records\n   binding\
    \ techniques to Information Elements for which they are not\n   recommended.\n"
- title: 7.2.2.  Export of Perimeter-Based Anonymization Policies
  contents:
  - "7.2.2.  Export of Perimeter-Based Anonymization Policies\n   Data collected from\
    \ a single network may require different\n   anonymization policies for addresses\
    \ internal and external to the\n   network.  For example, internal addresses could\
    \ be subject to simple\n   permutation, while external addresses could be aggregated\
    \ into\n   networks by truncation.  When exporting anonymized perimeter\n   bidirectional\
    \ flow (biflow) data as in Section 5.2 of [RFC5103], this\n   arrangement may\
    \ be easily represented by specifying one technique for\n   source endpoint information\
    \ (which represents the external endpoint\n   in a perimeter biflow) and one technique\
    \ for destination endpoint\n   information (which represents the internal address\
    \ in a perimeter\n   biflow).\n   However, it can also be useful to represent\
    \ perimeter-based\n   anonymization policies with unidirectional flow (uniflow),\
    \ or non-\n   perimeter biflow data.  In this case, the Perimeter Anonymization\
    \ bit\n   (bit 2) in the anonymizationFlags Information Element describing the\n\
    \   anonymized address Information Elements can be set to change the\n   meaning\
    \ of \"source\" and \"destination\" of Information Elements to mean\n   \"external\"\
    \ and \"internal\" as with perimeter biflows, but only with\n   respect to anonymization\
    \ policies.\n"
- title: 7.2.3.  Anonymization of Header Data
  contents:
  - "7.2.3.  Anonymization of Header Data\n   Each IPFIX Message contains a Message\
    \ Header; within this Message\n   Header are contained two fields which may be\
    \ used to break certain\n   anonymization techniques: the Export Time, and the\
    \ Observation Domain\n   ID.\n   Export of IPFIX Messages containing anonymized\
    \ timestamp data where\n   the original Export Time Message header has some relationship\
    \ to the\n   anonymized timestamps SHOULD anonymize the Export Time header field\n\
    \   so that the Export Time is consistent with the anonymized timestamp\n   data.\
    \  Otherwise, relationships between export and flow time could be\n   used to\
    \ partially or totally reverse timestamp anonymization.  When\n   anonymizing\
    \ timestamps and the Export Time header field SHOULD avoid\n   times too far in\
    \ the past or future; while [RFC5101] does not make\n   any allowance for Export\
    \ Time error detection, it is sensible that\n   Collecting Processes may interpret\
    \ Messages with seemingly\n   nonsensical Export Times as erroneous.  Specific\
    \ limits are\n   implementation dependent, but this issue may cause interoperability\n\
    \   issues when anonymizing the Export Time header field.\n   The similarity in\
    \ size between an Observation Domain ID and an IPv4\n   address (32 bits) may\
    \ lead to a temptation to use an IPv4 interface\n   address on the Metering or\
    \ Exporting Process as the Observation\n   Domain ID.  If this address bears some\
    \ relation to the IP addresses\n   in the flow data (e.g., shares a network prefix\
    \ with internal\n   addresses) and the IP addresses in the flow data are anonymized\
    \ in a\n   structure-preserving way, then the Observation Domain ID may be used\n\
    \   to break the IP address anonymization.  Use of an IPv4 interface\n   address\
    \ on the Metering or Exporting Process as the Observation\n   Domain ID is NOT\
    \ RECOMMENDED in this case.\n"
- title: 7.2.4.  Anonymization of Options Data
  contents:
  - "7.2.4.  Anonymization of Options Data\n   IPFIX uses the Options mechanism to\
    \ export, among other things,\n   metadata about exported flows and the flow collection\
    \ infrastructure.\n   As with the IPFIX Message Header, certain Options recommended\
    \ in\n   [RFC5101] and [RFC5655] containing flow timestamps and network\n   addresses\
    \ of Exporting and Collecting Processes may be used to break\n   certain anonymization\
    \ techniques.  When using these Options along\n   anonymized data export and storage,\
    \ values within the Options that\n   could be used to break the anonymization\
    \ SHOULD themselves be\n   anonymized or omitted.\n   The Exporting Process Reliability\
    \ Statistics Options Template,\n   recommended in [RFC5101], contains an Exporting\
    \ Process ID field,\n   which may be an exportingProcessIPv4Address Information\
    \ Element or an\n   exportingProcessIPv6Address Information Element.  If the Exporting\n\
    \   Process address bears some relation to the IP addresses in the flow\n   data\
    \ (e.g., shares a network prefix with internal addresses) and the\n   IP addresses\
    \ in the flow data are anonymized in a structure-\n   preserving way, then the\
    \ Exporting Process address may be used to\n   break the IP address anonymization.\
    \  Exporting Processes exporting\n   anonymized data in this situation SHOULD\
    \ mitigate the risk of attack\n   either by omitting Options described by the\
    \ Exporting Process\n   Reliability Statistics Options Template or by anonymizing\
    \ the\n   Exporting Process address using a similar technique to that used to\n\
    \   anonymize the IP addresses in the exported data.\n   Similarly, the Export\
    \ Session Details Options Template and Message\n   Details Options Template specified\
    \ for the IPFIX File Format\n   [RFC5655] may contain the exportingProcessIPv4Address\
    \ Information\n   Element or the exportingProcessIPv6Address Information Element\
    \ to\n   identify an Exporting Process from which a flow record was received,\n\
    \   and the collectingProcessIPv4Address Information Element or the\n   collectingProcessIPv6Address\
    \ Information Element to identify the\n   Collecting Process which received it.\
    \  If the Exporting Process or\n   Collecting Process address bears some relation\
    \ to the IP addresses in\n   the dataset (e.g., shares a network prefix with internal\
    \ addresses)\n   and the IP addresses in the dataset are anonymized in a structure-\n\
    \   preserving way, then the Exporting Process or Collecting Process\n   address\
    \ may be used to break the IP address anonymization.  Since\n   these Options\
    \ Templates are primarily intended for storing IPFIX\n   Transport Session data\
    \ for auditing, replay, and testing purposes, it\n   is NOT RECOMMENDED that storage\
    \ of anonymized data include these\n   Options Templates in order to mitigate\
    \ the risk of attack.\n   The Message Details Options Template specified for the\
    \ IPFIX File\n   Format [RFC5655] also contains the collectionTimeMilliseconds\n\
    \   Information Element.  As with the Export Time Message Header field,\n   if\
    \ the exported dataset contains anonymized timestamp information,\n   and the\
    \ collectionTimeMilliseconds Information Element in a given\n   Message has some\
    \ relationship to the anonymized timestamp\n   information, then this relationship\
    \ can be exploited to reverse the\n   timestamp anonymization.  Since this Options\
    \ Template is primarily\n   intended for storing IPFIX Transport Session data\
    \ for auditing,\n   replay, and testing purposes, it is NOT RECOMMENDED that storage\
    \ of\n   anonymized data include this Options Template in order to mitigate\n\
    \   the risk of attack.\n   Since the Time Window Options Template specified for\
    \ the IPFIX File\n   Format [RFC5655] refers to the timestamps within the dataset\
    \ to\n   provide partial table of contents information for an IPFIX File,\n  \
    \ Options described by this Template SHOULD be written using the\n   anonymized\
    \ timestamps instead of the original ones.\n"
- title: 7.2.5.  Special-Use Address Space Considerations
  contents:
  - "7.2.5.  Special-Use Address Space Considerations\n   When anonymizing data for\
    \ transport or storage using IPFIX containing\n   anonymized IP addresses, and\
    \ the analysis purpose permits doing so,\n   it is RECOMMENDED to filter out or\
    \ leave unanonymized data containing\n   the special-use IPv4 addresses enumerated\
    \ in [RFC5735] or the\n   special-use IPv6 addresses enumerated in [RFC5156].\
    \  Data containing\n   these addresses (e.g. 0.0.0.0 and 169.254.0.0/16 for link-local\n\
    \   autoconfiguration in IPv4 space) are often associated with specific,\n   well-known\
    \ behavioral patterns.  Detection of these patterns in\n   anonymized data can\
    \ lead to deanonymization of these special-use\n   addresses, which increases\
    \ the chance of a complete reversal of\n   anonymization by an attacker, especially\
    \ of prefix-preserving\n   techniques.\n"
- title: 7.2.6.  Protecting Out-of-Band Configuration and Management Data
  contents:
  - "7.2.6.  Protecting Out-of-Band Configuration and Management Data\n   Special\
    \ care should be taken when exporting or sharing anonymized\n   data to avoid\
    \ information leakage via the configuration or management\n   planes of the IPFIX\
    \ Device containing the Exporting Process or the\n   File Writer.  For example,\
    \ adding noise to counters is useless if the\n   receiver can deduce the values\
    \ in the counters from Simple Network\n   Management Protocol (SNMP) information,\
    \ and concealing the network\n   under test is similarly useless if such information\
    \ is available in a\n   configuration document.  As the specifics of these concerns\
    \ are\n   largely implementation and deployment dependent, specific mitigation\n\
    \   is out of scope for this document.  The general ground rule is that\n   information\
    \ of similar type to that anonymized SHOULD NOT be made\n   available to the receiver\
    \ by any means, whether in the Data Records,\n   in IPFIX protocol structures\
    \ such as Message Headers, or out of band.\n"
- title: 8.  Examples
  contents:
  - "8.  Examples\n   In this example, consider the export or storage of an anonymized\
    \ IPv4\n   dataset from a single network described by a simple Template\n   containing\
    \ a timestamp in seconds, a five-tuple, and packet and octet\n   counters.  The\
    \ Template describing each record in this Data Set is\n   shown in Figure 4.\n\
    \                        1                   2                   3\n    0 1 2\
    \ 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Set ID = 2           |          Length =  40         |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |      Template ID = 256        |        Field Count = 8        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| flowStartSeconds        150 |       Field Length =  4       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| sourceIPv4Address         8 |       Field Length =  4       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| destinationIPv4Address   12 |       Field Length =  4       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| sourceTransportPort       7 |       Field Length =  2       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| destinationTransportPort 11 |       Field Length =  2       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| packetDeltaCount          2 |       Field Length =  4       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| octetDeltaCount           1 |       Field Length =  4       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |0| protocolIdentifier        4 |       Field Length =  1       |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \                      Figure 4: Example Flow Template\n   Suppose that this Data\
    \ Set is anonymized according to the following\n   policy:\n   o  IP addresses\
    \ within the network are protected by reverse\n      truncation.\n   o  IP addresses\
    \ outside the network are protected by prefix-\n      preserving anonymization.\n\
    \   o  Octet counts are exported using degraded precision in order to\n      provide\
    \ minimal protection against fingerprinting attacks.\n   o  All other fields are\
    \ exported unanonymized.\n   In order to export Anonymization Records for this\
    \ Template and\n   policy, first, the Anonymization Options Template shown in\
    \ Figure 5\n   is exported.  For this example, the optional privateEnterpriseNumber\n\
    \   and informationElementIndex Information Elements are omitted, because\n  \
    \ they are not used.\n                        1                   2          \
    \         3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0\
    \ 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n  \
    \ |          Set ID = 3           |          Length =  26         |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |      Template ID = 257        |        Field Count = 4        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |    Scope Field Count = 2      |0| templateID              145 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |       Field Length = 2        |0| informationElementId    303 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |       Field Length = 2        |0| anonymizationFlags      285 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |       Field Length = 2        |0| anonymizationTechnique  286 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |       Field Length = 2        |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \             Figure 5: Example Anonymization Options Template\n   Following the\
    \ Anonymization Options Template comes a Data Set\n   containing Anonymization\
    \ Records.  This dataset has an entry for each\n   Information Element Specifier\
    \ in Template 256 describing the flow\n   records.  This Data Set is shown in\
    \ Figure 6.  Note that\n   sourceIPv4Address and destinationIPv4Address have the\
    \ Perimeter\n   Anonymization (0x0004) flag set in anonymizationFlags, meaning\
    \ that\n   source address should be treated as network-external, and the\n   destination\
    \ address as network-internal.\n                        1                   2\
    \                   3\n    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\
    \ 6 7 8 9 0 1\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Set ID = 257         |          Length =  68         |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | flowStartSeconds       IE 150 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | no flags               0x0000 | Not Anonymized              1 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | sourceIPv4Address        IE 8 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | Perimeter, Session SC  0x0005 | Structured Permutation      6 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | destinationIPv4Address  IE 12 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | Perimeter, Stable      0x0007 | Reverse Truncation          7 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | sourceTransportPort      IE 7 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | no flags               0x0000 | Not Anonymized              1 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | dest.TransportPort      IE 11 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | no flags               0x0000 | Not Anonymized              1 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | packetDeltaCount         IE 2 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | no flags               0x0000 | Not Anonymized              1 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | octetDeltaCount          IE 1 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | Stable                 0x0003 | Precision Degradation       2 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   |          Template 256         | protocolIdentifier      IE 4  |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \   | no flags               0x0000 | Not Anonymized              1 |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \                  Figure 6: Example Anonymization Records\n   Following the Anonymization\
    \ Records come the Data Sets containing the\n   anonymized data, exported according\
    \ to the Template in Figure 4.\n   Bringing it all together, consider an IPFIX\
    \ Message containing three\n   real data records and the necessary templates to\
    \ export them, shown\n   in Figure 7.  (Note that the scale of this message is\
    \ 8-bytes per\n   line, for compactness; lines of dots '. . . . . ' represent\
    \ shifting\n   of the example bit structure for clarity.)\n             1    \
    \     2         3         4         5         6\n   0 2 4 6 8 0 2 4 6 8 0 2 4\
    \ 6 8 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 2\n  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \  | 0x000a        | length 135    | export time 1271227717        | msg\n  |\
    \ sequence 0                    | domain 1                      | hdr\n  | SetID\
    \ 2       | length 40     | tid 256       | fields 8      | tmpl\n  | IE 150 \
    \       | length 4      | IE 8          | length 4      | set\n  | IE 12     \
    \    | length 4      | IE 7          | length 2      |\n  | IE 11         | length\
    \ 2      | IE 2          | length 4      |\n  | IE 1          | length 4     \
    \ | IE 4          | length 1      |\n  | SetID 256     | length 79     | time\
    \ 1271227681               | data\n  | sip 192.0.2.3                 | dip 198.51.100.7\
    \              | set\n  | sp 53         | dp 53         | packets 1          \
    \           |\n  | bytes 74                      | prt 17  | . . . . . . . . .\
    \ . .\n  | time 1271227682               | sip 198.51.100.7              |\n \
    \ | dip 192.0.2.88                | sp 5091       | dp 80         |\n  | packets\
    \ 60                    | bytes 2896                    |\n  | prt 6   | . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n  | time 1271227683       \
    \        | sip 198.51.100.7              |\n  | dip 203.0.113.9              \
    \ | sp 5092       | dp 80         |\n  | packets 44                    | bytes\
    \ 2037                    |\n  | prt 6   |\n  +---------+\n                  \
    \    Figure 7: Example Real Message\n   The corresponding anonymized message is\
    \ then shown in Figure 8.  The\n   Options Template Set describing Anonymization\
    \ Records and the\n   Anonymization Records themselves are added; IP addresses\
    \ and byte\n   counts are anonymized as declared.\n             1         2  \
    \       3         4         5         6\n   0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 2\
    \ 4 6 8 0 2 4 6 8 0 2 4 6 8 0 2\n  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\
    \  | 0x000a        | length 233    | export time 1271227717        | msg\n  |\
    \ sequence 0                    | domain 1                      | hdr\n  | SetID\
    \ 2       | length 40     | tid 256       | fields 8      | tmpl\n  | IE 150 \
    \       | length 4      | IE 8          | length 4      | set\n  | IE 12     \
    \    | length 4      | IE 7          | length 2      |\n  | IE 11         | length\
    \ 2      | IE 2          | length 4      |\n  | IE 1          | length 4     \
    \ | IE 4          | length 1      |\n  | SetID 3       | length 30     | tid 257\
    \       | fields 4      | opt\n  | scope 2       | . . . . . . . . . . . . . .\
    \ . . . . . . . . . . tmpl\n  | IE 145        | length 2      | IE 303       \
    \ | length 2      | set\n  | IE 285        | length 2      | IE 286        | length\
    \ 2      |\n  | SetID 257     | length 68     | . . . . . . . . . . . . . . .\
    \ . anon\n  | tid 256       | IE 150        | flags 0       | tech 1        |\
    \ recs\n  | tid 256       | IE 8          | flags 5       | tech 6        |\n\
    \  | tid 256       | IE 12         | flags 7       | tech 7        |\n  | tid\
    \ 256       | IE 7          | flags 0       | tech 1        |\n  | tid 256   \
    \    | IE 11         | flags 0       | tech 1        |\n  | tid 256       | IE\
    \ 2          | flags 0       | tech 1        |\n  | tid 256       | IE 1     \
    \     | flags 3       | tech 2        |\n  | tid 256       | IE41          | flags\
    \ 0       | tech 1        |\n  | SetID 256     | length 79     | time 1271227681\
    \               | data\n  | sip 254.202.119.209           | dip 0.0.0.7      \
    \             | set\n  | sp 53         | dp 53         | packets 1           \
    \          |\n  | bytes 100                     | prt 17  | . . . . . . . . .\
    \ . .\n  | time 1271227682               | sip 0.0.0.7                   |\n \
    \ | dip 254.202.119.6             | sp 5091       | dp 80         |\n  | packets\
    \ 60                    | bytes 2900                    |\n  | prt 6   | . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n  | time 1271227683       \
    \        | sip 0.0.0.7                   |\n  | dip 2.19.199.176             \
    \ | sp 5092       | dp 80         |\n  | packets 60                    | bytes\
    \ 2000                    |\n  | prt 6   |\n  +---------+\n                Figure\
    \ 8: Corresponding Anonymized Message\n"
- title: 9.  Security Considerations
  contents:
  - "9.  Security Considerations\n   This document provides guidelines for exporting\
    \ metadata about\n   anonymized data in IPFIX, or storing metadata about anonymized\
    \ data\n   in IPFIX Files.  It is not intended as a general statement on the\n\
    \   applicability of specific flow data anonymization techniques.\n   Exporters\
    \ or publishers of anonymized data must take care that the\n   applied anonymization\
    \ technique is appropriate for the data source,\n   the purpose, and the risk\
    \ of deanonymization of a given application.\n   Research in anonymization techniques,\
    \ and techniques for\n   deanonymization, is ongoing, and currently \"safe\" anonymization\n\
    \   techniques may be rendered unsafe by future developments.\n   We note specifically\
    \ that anonymization is not a replacement for\n   encryption for confidentiality.\
    \  It is only appropriate for\n   protecting identifying information in data to\
    \ be used for purposes in\n   which the protected data is irrelevant.  Confidentiality\
    \ in export is\n   best served by using TLS [RFC5246] or Datagram Transport Layer\n\
    \   Security (DTLS) [RFC4347] as in the Security Considerations section\n   of\
    \ [RFC5101], and in long-term storage by implementation-specific\n   protection\
    \ applied as in the Security Considerations section of\n   [RFC5655].  Indeed,\
    \ confidentiality and anonymization are not\n   mutually exclusive, as encryption\
    \ for confidentiality may be applied\n   to anonymized data export or storage,\
    \ as well, when the anonymized\n   data is not intended for public release.\n\
    \   We note as well that care should be taken even with well-anonymized\n   data,\
    \ and anonymized data should still be treated as privacy\n   sensitive.  Anonymization\
    \ reduces the risk of misuse, but is not a\n   complete solution to the problem\
    \ of protecting end-user privacy in\n   network flow trace analysis.\n   When\
    \ using pseudonymization techniques that have a mutable mapping,\n   there is\
    \ an inherent trade-off in the stability of the map between\n   long-term comparability\
    \ and security of the dataset against\n   deanonymization.  In general, deanonymization\
    \ attacks are more\n   effective given more information, so the longer a given\
    \ mapping is\n   valid, the more information can be applied to deanonymization.\
    \  The\n   specific details of this are technique-dependent and therefore out\
    \ of\n   the scope of this document.\n   When releasing anonymized data, publishers\
    \ need to ensure that data\n   that could be used in deanonymization is not leaked\
    \ through a side\n   channel.  The entire workflow (hardware, software, operational\n\
    \   policies and procedures, etc.) for handling anonymized data must be\n   evaluated\
    \ for risk of data leakage.  While most of these possible\n   side channels are\
    \ out of scope for this document, guidelines for\n   reducing the risk of information\
    \ leakage specific to the IPFIX export\n   protocol are provided in Section 7.2.\n\
    \   Note as well that the Security Considerations section of [RFC5101]\n   applies\
    \ as well to the export of anonymized data, and the Security\n   Considerations\
    \ section of [RFC5655] to the storage of anonymized\n   data, or the publication\
    \ of anonymized traces.\n"
- title: 10.  IANA Considerations
  contents:
  - "10.  IANA Considerations\n   This document specifies the creation of several\
    \ new IPFIX Information\n   Elements in the IPFIX Information Element registry\
    \ available from the\n   IANA site (http://www.iana.org), as defined in Section\
    \ 6.2.  IANA has\n   assigned the following Information Element numbers for their\n\
    \   respective Information Elements as specified below:\n   o  Information Element\
    \ number 285 for the anonymizationFlags\n      Information Element.\n   o  Information\
    \ Element number 286 for the anonymizationTechnique\n      Information Element.\n\
    \   o  Information Element number 287 for the informationElementIndex\n      Information\
    \ Element.\n"
- title: 11.  Acknowledgments
  contents:
  - "11.  Acknowledgments\n   We thank Paul Aitken and John McHugh for their comments\
    \ and insight,\n   and Carsten Schmoll, Benoit Claise, Lothar Braun, Dan Romascanu,\n\
    \   Stewart Bryant, and Sean Turner for their reviews.  Special thanks to\n  \
    \ the FP7 PRISM and DEMONS projects for their material support of this\n   work.\n"
- title: 12.  References
  contents:
  - '12.  References

    '
- title: 12.1.  Normative References
  contents:
  - "12.1.  Normative References\n   [RFC5101]  Claise, B., \"Specification of the\
    \ IP Flow Information\n              Export (IPFIX) Protocol for the Exchange\
    \ of IP Traffic\n              Flow Information\", RFC 5101, January 2008.\n \
    \  [RFC5102]  Quittek, J., Bryant, S., Claise, B., Aitken, P., and J.\n      \
    \        Meyer, \"Information Model for IP Flow Information Export\",\n      \
    \        RFC 5102, January 2008.\n   [RFC5103]  Trammell, B. and E. Boschi, \"\
    Bidirectional Flow Export\n              Using IP Flow Information Export (IPFIX)\"\
    , RFC 5103,\n              January 2008.\n   [RFC5655]  Trammell, B., Boschi,\
    \ E., Mark, L., Zseby, T., and A.\n              Wagner, \"Specification of the\
    \ IP Flow Information Export\n              (IPFIX) File Format\", RFC 5655, October\
    \ 2009.\n   [RFC2119]  Bradner, S., \"Key words for use in RFCs to Indicate\n\
    \              Requirement Levels\", BCP 14, RFC 2119, March 1997.\n   [RFC5735]\
    \  Cotton, M. and L. Vegoda, \"Special Use IPv4 Addresses\",\n              BCP\
    \ 153, RFC 5735, January 2010.\n   [RFC5156]  Blanchet, M., \"Special-Use IPv6\
    \ Addresses\", RFC 5156,\n              April 2008.\n"
- title: 12.2.  Informative References
  contents:
  - "12.2.  Informative References\n   [RFC5470]  Sadasivan, G., Brownlee, N., Claise,\
    \ B., and J. Quittek,\n              \"Architecture for IP Flow Information Export\"\
    , RFC 5470,\n              March 2009.\n   [RFC5472]  Zseby, T., Boschi, E., Brownlee,\
    \ N., and B. Claise, \"IP\n              Flow Information Export (IPFIX) Applicability\"\
    , RFC 5472,\n              March 2009.\n   [RFC6183]  Kobayashi, A., Claise, B.,\
    \ Muenz, G., and K. Ishibashi,\n              \"IP Flow Information Export (IPFIX)\
    \ Mediation: Framework\",\n              RFC 6183, April 2011.\n   [IPFIX-PERSTREAM]\n\
    \              Claise, B., Aitken, P., Johnson, A., and G. Muenz, \"IPFIX\n  \
    \            Export per SCTP Stream\", Work in Progress, May 2010.\n   [RFC5153]\
    \  Boschi, E., Mark, L., Quittek, J., Stiemerling, M., and P.\n              Aitken,\
    \ \"IP Flow Information Export (IPFIX) Implementation\n              Guidelines\"\
    , RFC 5153, April 2008.\n   [RFC3917]  Quittek, J., Zseby, T., Claise, B., and\
    \ S. Zander,\n              \"Requirements for IP Flow Information Export (IPFIX)\"\
    ,\n              RFC 3917, October 2004.\n   [RFC4291]  Hinden, R. and S. Deering,\
    \ \"IP Version 6 Addressing\n              Architecture\", RFC 4291, February\
    \ 2006.\n   [RFC4347]  Rescorla, E. and N. Modadugu, \"Datagram Transport Layer\n\
    \              Security\", RFC 4347, April 2006.\n   [RFC5246]  Dierks, T. and\
    \ E. Rescorla, \"The Transport Layer Security\n              (TLS) Protocol Version\
    \ 1.2\", RFC 5246, August 2008.\n   [Bur10]    Burkhart, M., Schatzmann, D., Trammell,\
    \ B., and E. Boschi,\n              \"The Role of Network Trace Anonymization\
    \ Under Attack\",\n               ACM Computer Communications Review, vol. 40,\
    \ no. 1, pp.\n              6-11, January 2010.\n   [Mur07]    Murdoch, S. and\
    \ P. Zielinski, \"Sampled Traffic Analysis by\n              Internet-Exchange-Level\
    \ Adversaries\", Proceedings of the\n              7th Workshop on Privacy Enhancing\
    \ Technologies, Ottawa,\n              Canada, June 2007.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Elisa Boschi\n   Swiss Federal Institute of Technology\
    \ Zurich\n   Gloriastrasse 35\n   8092 Zurich\n   Switzerland\n   EMail: boschie@tik.ee.ethz.ch\n\
    \   Brian Trammell\n   Swiss Federal Institute of Technology Zurich\n   Gloriastrasse\
    \ 35\n   8092 Zurich\n   Switzerland\n   Phone: +41 44 632 70 13\n   EMail: trammell@tik.ee.ethz.ch\n"
