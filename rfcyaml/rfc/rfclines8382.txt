Shared Bottleneck Detection for Coupled Congestion Control for RTP Media Abstract
This document describes a mechanism to detect whether end to end data flows share a common bottleneck.
This mechanism relies on summary statistics that are calculated based on continuous measurements and used as input to a grouping algorithm that runs wherever the knowledge is needed.
In the Internet, it is not normally known whether flows (e.g., TCP connections or UDP data streams) traverse the same bottlenecks.
Even flows that have the same sender and receiver may take different paths and may or may not share a bottleneck.
Flows that share a bottleneck link usually compete with one another for their share of the capacity.
This competition has the potential to increase packet loss and delays.
This is especially relevant for interactive applications that communicate simultaneously with multiple peers (such as multi party video).
For RTP media applications such as RTCWEB, [RTP COUPLED CC] describes a scheme that combines the congestion controllers of flows in order to honor their priorities and avoid unnecessary packet loss as well as delay.
This mechanism relies on some form of Shared Bottleneck Detection (SBD); here, a measurement  based SBD approach is described.
The mechanism groups flows that have similar statistical characteristics together.
Section 3.3.1 describes a simple method for achieving this; however, a major part of this document is concerned with collecting suitable statistics for this purpose.
The current Internet is unable to explicitly inform endpoints as to which flows share bottlenecks, so endpoints need to infer this from whatever information is available to them.
The mechanism described here currently utilizes packet loss and packet delay but is not restricted to these.
As Explicit Congestion Notification (ECN) becomes more prevalent, it too will become a valuable base signal that can be correlated to detect shared bottlenecks.
Packet Loss Packet loss is often a relatively infrequent indication that a flow traverses a bottleneck.
Therefore, on its own it is of limited use for SBD; however, it is a valuable supplementary measure when it is more prevalent (refer to [RFC7680],
Section 2.5 for measuring packet loss).
Packet Delay End to end delay measurements include noise from every device along the path, in addition to the delay perturbation at the bottleneck device.
The noise is often significantly increased if the round trip time is used.
The cleanest signal is obtained by using One Way Delay (OWD) (refer to [RFC7679], Section 3 for a definition of OWD).
Measuring absolute OWD is difficult, since it requires both the sender and receiver clocks to be synchronized.
However, since the statistics being collected are relative to the mean OWD, a relative OWD measurement is sufficient.
Clock skew is not usually significant over the time intervals used by this SBD mechanism (see [RFC6817], Appendix A.2 for a discussion on clock skew and OWD measurements).
However, in circumstances where it is significant, Section 5.2 outlines a way of adjusting the calculations to cater to it.
Each packet arriving at the bottleneck buffer may experience very different queue lengths and, therefore, different waiting times.
A single OWD sample does not, therefore, characterize the path well.
However, multiple OWD measurements do reflect the distribution of delays experienced at the bottleneck.
Path Lag Flows that share a common bottleneck may traverse different paths, and these paths will often have different base delays.
This makes it difficult to correlate changes in delay or loss.
This technique uses the long term shape of the delay distribution as a base for comparison to counter this.
The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in BCP 14
when, and only when, they appear in all capitals, as shown here.
Making T too large can limit the efficacy of freq est.
It will also increase the response time of the mechanism.
Making T too small will make the metrics noisier.
N and M   N should be large enough to provide a stable estimate of oscillations in OWD.
Often, M N is just fine, though having M<N may be beneficial in certain circumstances.
M T needs to be long enough to provide stable estimates of skewness and MAD.
When F M, recent and older measurements are considered equal.
Making F<M can increase the responsiveness of the SBD mechanism.
If F is too small, statistics will be too noisy.
Lower values of c s require bottlenecks to be more congested to be considered for grouping by the mechanism.
c s should be set within the range of  0.2 to  0.1
low enough so that lightly loaded paths do not give a false indication.
When pkt loss is high, it becomes a better indicator of congestion than skew est.
It should be large enough to avoid constant switching in the determination but low enough to ensure that grouping is not attempted when there is no bottleneck and the delay and loss signals cannot be relied upon.
Making it smaller will yield higher but noisier values for freq est.
Making it too large will render it ineffective for determining groups.
mad p f p d.
Adjusting these is a compromise between false grouping of flows that do not share a bottleneck and false splitting of flows that do.
Making them larger can help if the measures are very noisy, but reducing the noise in the statistical measures by adjusting T and N M may be a better solution.
Recommended Parameter Values [Hayes LCN14] uses T 350ms and N 50.
The other parameters have been tightened to reflect minor enhancements to the algorithm outlined in Section 4:
c s 0.1, p f p d 0.1, p s 0.15,
p mad 0.1, p v 0.7.
M 30, F 20, and c h 0.3 are additional parameters defined in that document.
These are values that seem to work well over a wide range of practical Internet conditions.
The mechanism described in this document is based on the observation that when flows traverse a common bottleneck, each flow's distribution of packet delay measurements has similar shape characteristics.
These shape characteristics are described using three key summary statistics   1.
variability estimate (var est; see Section 3.2.3) 2.
skewness estimate (skew est; see Section 3.2.2) 3.
oscillation estimate (freq est; see Section 3.2.4)   with packet loss (pkt loss; see Section 3.2.5) used as a supplementary statistic.
Summary statistics help to address both the noise and the path lag problems by describing the general shape over a relatively long period of time.
Each summary statistic portrays a "view" of the bottleneck link characteristics, and when used together, they provide a robust discrimination for grouping flows.
An RTP media device may be both a sender and a receiver.
SBD can be performed at either a sender or a receiver, or both.
In Figure 1, there are two possible locations for shared bottleneck detection: the sender side and the receiver side.
Sender side: Consider a situation where host H1 sends media streams to hosts H2 and H3, and L1 is a shared bottleneck.
H2 and H3 measure the OWD and packet loss and periodically send either this raw data or the calculated summary statistics to H1 every T.  H1, having this knowledge, can determine the shared bottleneck and accordingly control the send rates.
Receiver side: Consider that H2 is also sending media to H3, and L3 is a shared bottleneck.
If H3 sends summary statistics to H1 and H2, neither H1 nor H2 alone obtains enough knowledge to detect this shared bottleneck; H3 can, however, determine it by combining the summary statistics related to H1 and H2, respectively.
There are three possible scenarios, each with different feedback requirements: 1.
Both summary statistic calculations and SBD are performed at senders only.
When sender based congestion control is implemented, this method is RECOMMENDED.
Summary statistics are calculated on the receivers, and SBD is performed at the senders.
Summary statistic calculations are performed on receivers, and SBD is performed at both senders and receivers (beyond the scope of this document, but allows cooperative detection of bottlenecks).
All three possibilities are discussed for completeness in this document; however, it is expected that feedback will take the form of scenario 1 and operate in conjunction with sender based congestion control mechanisms.
When All the Logic Is Placed at the Sender
Having the sender calculate the summary statistics and determine the shared bottlenecks based on them has the advantage of placing most of the functionality in one place   the sender.
For every packet, the sender requires accurate relative OWD measurements of adequate precision, along with an indication of lost packets (or the proportion of packets lost over an interval).
A method to provide such measurement data with the RTP Control Protocol (RTCP) is described in [RTCP CC FEEDBACK].
Sums, var base T, and skew base T are calculated incrementally as relative OWD measurements are determined from the feedback messages.
When the mechanism has received sufficient measurements to cover the base time interval T for all flows, the summary statistics (see Section 3.2) are calculated for that T interval and flows are grouped (see Section 3.3.1).
The exact timing of these calculations will depend on the frequency of the feedback message.
When the Statistics Are Calculated at the Receiver and SBD
Is Performed at the Sender
This scenario minimizes feedback but requires receivers to send selected summary statistics at an agreed upon regular interval.
We envisage the following exchange of information to initialize the system:
An initialization message from the sender to the receiver will contain the following information:
A list of which key metrics should be collected and relayed back to the sender out of a possibly extensible set (pkt loss, var est, skew est, and freq est).
The grouping algorithm described in this document requires all four of these metrics, and receivers MUST be able to provide them, but future algorithms may be able to exploit other metrics (e.g., metrics based on explicit network signals).
The values of T, N, and M, and the necessary resolution and precision of the relayed statistics.
A response message from the receiver acknowledges this message with a list of key metrics it supports (subset of the sender's list) and is able to relay back to the sender.
This initialization exchange may be repeated to finalize the set of metrics that will be used.
All agreed upon metrics need to be supported by all receivers.
It is also recommended that an identifier for the SBD algorithm version be included in the initialization message from the sender, so that potential advances in SBD technology can be easily deployed.
For reference, the mechanism outlined in this document has the identifier "SBD 01".
After initialization, the agreed upon summary statistics are fed back to the sender (nominally every T).
When Bottlenecks Can Be Determined at Both Senders and Receivers
This type of mechanism is currently beyond the scope of the SBD algorithm described in this document.
It is mentioned here to ensure that sender/receiver cooperative shared bottleneck determination mechanisms that are more advanced remain possible in the future.
It is envisaged that such a mechanism would be initialized in a manner similar to that described in Section 3.1.2.
After initialization, both summary statistics and shared bottleneck determinations should be exchanged, nominally every T. 3.2.
Key Metrics and Their Calculation Measurements are calculated over a base interval (T) and summarized over N or M such intervals.
All summary statistics can be calculated incrementally.
The mean delay is not a useful signal for comparisons between flows, since flows may traverse quite different paths and clocks will not necessarily be synchronized.
However, it is a base measure for the three summary statistics.
The mean delay, E T(OWD), is the average OWD measured over T. To facilitate the other calculations, the last N E T(OWD)
values will need to be stored in a cyclic buffer along with the moving average of E T(OWD):
mean delay   E M(E T(OWD))
<  N.  Setting M to be less than N allows the mechanism to be more responsive to changes, but potentially at the expense of a higher error rate (see Section 4.1 for a discussion on improving the responsiveness of the mechanism).
Skewness Estimate Skewness is difficult to calculate efficiently and accurately.
Ideally, it should be calculated over the entire period (M T) from the mean OWD over that period.
However, this would require storing every delay measurement over the period.
Instead, an estimate is made over M T based on a calculation
every T using the previous T's calculation of mean delay.
The base for the skewness calculation is estimated using a counter initialized every T.
It increments for OWD samples below the mean and decrements for OWD above the mean.
So, for each OWD sample: if (OWD < mean delay)
if (OWD > mean delay)
mean delay does not include the mean of the current T interval to enable it to be calculated iteratively.
skew est   sum MT(skew base T) / num MT(OWD) where skew est is a number between  1 and 1.
Note: Care must be taken when implementing the comparisons to ensure that rounding does not bias skew est.
It is important that the mean is calculated with a higher precision than the samples.
Variability Estimate Mean Absolute Deviation (MAD) is a robust variability measure that copes well with different send rates.
It can be implemented in an online manner as follows:
sum T( OWD E T(OWD) ) where  x  is the absolute value of x E T(OWD) is the mean OWD calculated in the previous T var est
MAD MT   sum MT(var base T) / num MT(OWD)
An estimate of the low frequency oscillation of the delay signal is calculated by counting and normalizing the significant mean, E T(OWD), crossings of mean delay: freq est   number of crossings / N where we define a significant mean crossing as a crossing that extends p v   var est from mean delay.
In our experiments, we have found that p v   0.7 is a good value.
freq est is a number between 0 and 1.
freq est can be approximated incrementally as follows:  With each new calculation of E T(OWD), a decision is made as to whether this value of E T(OWD) significantly crosses the current long term mean, mean delay, with respect to the previous significant mean crossing.
A cyclic buffer, last N crossings, records a 1 if there is a significant mean crossing; otherwise, it records a 0.
The counter, number of crossings, is incremented when there is a significant mean crossing and decremented when a non zero value is removed from the last N crossings.
This approximation of freq est was not used in [Hayes LCN14], which calculated freq est
every T using the current E N(E T(OWD)).
Our tests show that this approximation of freq est yields results that are almost identical to when the full calculation is performed every T. 3.2.5.
The proportion of packets lost over the period NT is used as a supplementary measure: pkt loss   sum NT(lost packets) / sum NT(total packets)
Note: When pkt loss is low, it is very variable; however, when pkt loss is high, it becomes a stable measure for making grouping decisions.
The following grouping algorithm is RECOMMENDED for the use of SBD with coupled congestion control for RTP media [RTP COUPLED CC] and is sufficient and efficient for small to moderate numbers of flows.
For very large numbers of flows (e.g., hundreds), a more complex clustering algorithm may be substituted.
Since no single metric is precise enough to group flows (due to noise), the algorithm uses multiple metrics.
Each metric offers a different "view" of the bottleneck link characteristics, and used together they enable a more precise grouping of flows than would otherwise be possible.
Flows determined to be transiting a bottleneck are successively divided into groups based on freq est, var est, skew est, and pkt loss.
The first step is to determine which flows are transiting a bottleneck.
This is important, since if a flow is not transiting a bottleneck its delay based metrics will not describe the bottleneck but will instead describe the "noise" from the rest of the path.
Skewness, with the proportion of packet loss as a supplementary measure, is used to do this: 1.
skew est < c h & PB )
pkt loss > p l
The parameter c s controls how sensitive the mechanism is in detecting a bottleneck.
c s   0.0 was used in [Hayes LCN14].
A value of c s   0.1 is a little more sensitive, and c s    0.1 is a little less sensitive.
c h controls the hysteresis on flows that were grouped as transiting a bottleneck the previous time.
If the test result is TRUE, PB TRUE; otherwise, PB FALSE.
These flows (i.e., flows transiting a bottleneck) are then progressively divided into groups based on the freq est, var est, and skew est summary statistics.
The process proceeds according to the following steps: 2.
Group flows whose difference in sorted freq est is less than a threshold:
diff(freq est) < p f 3.
The threshold, (p mad   var est), is with respect to the highest value in the difference.
the groups obtained in step 3 by grouping flows whose difference in sorted skew est is less than a threshold:
diff(skew est) < p s 5.
When packet loss is high enough to be reliable (pkt loss > p l), subdivide the groups obtained in step 4 by grouping flows whose difference is less than a threshold:
The threshold, (p d   pkt loss), is with respect to the highest value in the difference.
This procedure involves sorting estimates from highest to lowest.
It is simple to implement and is efficient for small numbers of flows (up to 10 20).
Figure 2 illustrates this algorithm.
Simple grouping algorithm Figure 2 3.3.2.
Using the Flow Group Signal Grouping decisions can be made every T from the second T; however, they will not attain their full design accuracy until after the 2 Nth T interval.
We recommend that grouping decisions not be made until 2 M T intervals.
Network conditions, and even the congestion controllers, can cause bottlenecks to fluctuate.
A coupled congestion controller MAY decide only to couple groups that remain stable, say grouped together 90% of the time, depending on its objectives.
Recommendations concerning this are beyond the scope of this document and will be specific to the coupled congestion controller's objectives.
Enhancements to the Basic SBD Algorithm The SBD algorithm as specified in Section 3 was found to work well for a broad variety of conditions.
The following enhancements to the basic mechanisms have been found to significantly improve the algorithm's performance under some circumstances and SHOULD be implemented.
These "tweaks" are described separately to keep the main description succinct.
Reducing Lag and Improving Responsiveness
This section describes how to improve the responsiveness of the basic algorithm.
Measurement based shared bottleneck detection makes decisions in the present based on what has been measured in the past.
This means that there is always a lag in responding to changing conditions.
This mechanism is based on summary statistics taken over (N T) seconds.
This mechanism can be made more responsive to changing conditions by: 1.
Reducing N and/or M, but at the expense of having metrics that are less accurate, and/or 2.
Exploiting the fact that measurements that are more recent are more valuable than older measurements and weighting them accordingly.
Although measurements that are more recent are more valuable, older measurements are still needed to gain an accurate estimate of the distribution descriptor we are measuring.
Unfortunately, the simple exponentially weighted moving average weights drop off too quickly for our requirements and have an infinite tail.
A simple linearly declining weighted moving average also does not provide enough weight to the measurements that are most recent.
We propose a piecewise linear distribution of weights, such that the first section (samples 1:F) is flat as in a simple moving average, and the second section (samples F 1:M) is linearly declining weights to the end of the averaging window.
We choose integer weights; this allows incremental calculation without introducing rounding errors.
Improving the Response of the Skewness Estimate
The weighted moving average for skew est, based on skew est as defined in Section 3.2.2, can be calculated as follows:
where numsampT is an array of the number of OWD samples in each T (i.e., num T(OWD)), and numsampT(1) is the most recent; skew base T(1) is the most recent calculation of skew base T; 1:F refers to the integer values 1 through to F, and [(M F):1] refers to an array of the integer values (M F) declining through to 1; and ".
" is the array scalar dot product operator.
F skewbase   0, W D
buffer of length M, initialized to 0 numsampT   buffer of length M, initialized to 0 Steps per iteration:
((M F 1) F skewbase
Improving the Response of the Variability Estimate
Similarly, the weighted moving average for var est can be calculated as follows: var est
((M F 1) sum(var base
where numsampT is an array of the number of OWD samples in each T (i.e., num T(OWD)), and numsampT(1) is the most recent; skew base T(1) is the most recent calculation of skew base T; 1:F refers to the integer values 1 through to F, and [(M F):1] refers to an array of the integer values (M F) declining through to 1; and ".
" is the array scalar dot product operator.
When removing oscillation noise (see Section 4.2), this calculation must be adjusted to allow for invalid var base T records.
var est can be calculated incrementally in the same way as skew est as shown in Section 4.1.1.
However, note that the buffer numsampT is used for both calculations, so the operations on it should not be repeated.
When a path has no bottleneck, var est will be very small and the recorded significant mean crossings will be the result of path noise.
Thus, up to N 1 meaningless mean crossings can be a source of error at the point where a link becomes a bottleneck and flows traversing it begin to be grouped.
To remove this source of noise from freq est: 1.
Set the current var base T   NaN (a value representing an invalid record, i.e., Not a Number) for flows that are deemed to not be transiting a bottleneck by the first grouping test that is based on skew est (see Section 3.3.1).
Then, var est   sum MT(var base T !
For freq est, only record a significant mean crossing if a given flow is deemed to be transiting a bottleneck.
These three changes can help to remove the non bottleneck noise from freq est.
This section discusses the OWD measurements required for this algorithm to detect shared bottlenecks.
The SBD mechanism described in this document relies on differences between OWD measurements to avoid the practical problems with measuring absolute OWD (see [Hayes LCN14], Section III.C).
Since all summary statistics are relative to the mean OWD and sender/receiver clock offsets should be approximately constant over the measurement periods, the offset is subtracted out in the calculation.
The SBD mechanism requires timing information precise enough to be able to make comparisons.
As a rule of thumb, the time resolution should be less than one hundredth of a typical path's range of delays.
In general, the coarser the time resolution, the more care that needs to be taken to ensure that rounding errors do not bias the skewness calculation.
Frequent timing information in millisecond resolution as described by [RTCP CC FEEDBACK] should be sufficient for the sender to calculate relative OWD.
Clock Skew Generally, sender and receiver clock skew will be too small to cause significant errors in the estimators.
skew est and freq est are the most sensitive to this type of noise due to their use of a mean OWD calculated over a longer interval.
In circumstances where clock skew is high, basing skew est only on the previous T's mean and ignoring freq est provide a noisier but reliable signal.
A more sophisticated method is to estimate the effect the clock skew is having on the summary statistics and then adjust statistics accordingly.
There are a number of techniques in the literature, including [Zhang Infocom02].
The algorithm described in this memo has so far been evaluated using simulations and small scale experiments.
Real network tests using RTP Media Congestion Avoidance Techniques
(RMCAT) congestion control algorithms will help confirm the default parameter choice.
For example, the time interval T may need to be made longer if the packet rate is very low.
Implementers and testers are invited to document their findings in an Internet Draft.
This document has no IANA actions.
The security considerations of RFC 3550 [RFC3550], RFC 4585 [RFC4585], and RFC 5124
[RFC5124] are expected to apply.
Non authenticated RTCP packets carrying OWD measurements, shared bottleneck indications, and/or summary statistics could allow attackers to alter the bottleneck sharing characteristics for private gain or disruption of other parties' communication.
When using SBD for coupled congestion control as described in [RTP COUPLED CC], the security considerations of [RTP COUPLED CC] apply.
