- title: __initial_text__
  contents:
  - ''
- title: Independent Submission                                       J. Bankoski
  contents:
  - "Independent Submission                                       J. Bankoski\n  \
    \                 VP8 Data Format and Decoding Guide\n"
- title: Abstract
  contents:
  - "Abstract\n   This document describes the VP8 compressed video data format,\n\
    \   together with a discussion of the decoding procedure for the format.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This is a contribution to\
    \ the RFC Series, independently of any other\n   RFC stream.  The RFC Editor has\
    \ chosen to publish this document at\n   its discretion and makes no statement\
    \ about its value for\n   implementation or deployment.  Documents approved for\
    \ publication by\n   the RFC Editor are not a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc6386.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2011 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................4\n\
    \   2. Format Overview .................................................5\n  \
    \ 3. Compressed Frame Types ..........................................7\n   4.\
    \ Overview of Compressed Data Format ..............................8\n   5. Overview\
    \ of the Decoding Process ................................9\n   6. Description\
    \ of Algorithms ......................................14\n   7. Boolean Entropy\
    \ Decoder ........................................16\n      7.1. Underlying Theory\
    \ of Coding ...............................17\n      7.2. Practical Algorithm\
    \ Description ...........................18\n      7.3. Actual Implementation\
    \ .....................................20\n   8. Compressed Data Components .....................................25\n\
    \      8.1. Tree Coding Implementation ................................27\n  \
    \    8.2. Tree Coding Example .......................................28\n   9.\
    \ Frame Header ...................................................30\n      9.1.\
    \ Uncompressed Data Chunk ...................................30\n      9.2. Color\
    \ Space and Pixel Type (Key Frames Only) ..............33\n      9.3. Segment-Based\
    \ Adjustments .................................34\n      9.4. Loop Filter Type\
    \ and Levels ...............................35\n      9.5. Token Partition and\
    \ Partition Data Offsets ................36\n      9.6. Dequantization Indices\
    \ ....................................37\n      9.7. Refresh Golden Frame and\
    \ Altref Frame .....................38\n      9.8. Refresh Last Frame Buffer .................................39\n\
    \      9.9. DCT Coefficient Probability Update ........................39\n  \
    \    9.10. Remaining Frame Header Data (Non-Key Frame) ..............40\n    \
    \  9.11. Remaining Frame Header Data (Key Frame) ..................41\n   10.\
    \ Segment-Based Feature Adjustments .............................41\n   11. Key\
    \ Frame Macroblock Prediction Records .......................42\n      11.1. mb_skip_coeff\
    \ ............................................42\n      11.2. Luma Modes ...............................................42\n\
    \      11.3. Subblock Mode Contexts ...................................45\n  \
    \    11.4. Chroma Modes .............................................46\n    \
    \  11.5. Subblock Mode Probability Table ..........................47\n   12.\
    \ Intraframe Prediction .........................................50\n      12.1.\
    \ mb_skip_coeff ............................................51\n      12.2. Chroma\
    \ Prediction ........................................51\n      12.3. Luma Prediction\
    \ ..........................................54\n   13. DCT Coefficient Decoding\
    \ ......................................60\n      13.1. Macroblock without Non-Zero\
    \ Coefficient Values ...........61\n      13.2. Coding of Individual Coefficient\
    \ Values ..................61\n      13.3. Token Probabilities ......................................63\n\
    \      13.4. Token Probability Updates ................................68\n  \
    \    13.5. Default Token Probability Table ..........................73\n   14.\
    \ DCT and WHT Inversion and Macroblock Reconstruction ...........76\n      14.1.\
    \ Dequantization ...........................................76\n      14.2. Inverse\
    \ Transforms .......................................78\n      14.3. Implementation\
    \ of the WHT Inversion ......................78\n      14.4. Implementation of\
    \ the DCT Inversion ......................81\n      14.5. Summation of Predictor\
    \ and Residue .......................83\n   15. Loop Filter ...................................................84\n\
    \      15.1. Filter Geometry and Overall Procedure ....................85\n  \
    \    15.2. Simple Filter ............................................87\n    \
    \  15.3. Normal Filter ............................................91\n      15.4.\
    \ Calculation of Control Parameters ........................95\n   16. Interframe\
    \ Macroblock Prediction Records ......................97\n      16.1. Intra-Predicted\
    \ Macroblocks ..............................97\n      16.2. Inter-Predicted Macroblocks\
    \ ..............................98\n      16.3. Mode and Motion Vector Contexts\
    \ ..........................99\n      16.4. Split Prediction ........................................105\n\
    \   17. Motion Vector Decoding .......................................108\n  \
    \    17.1. Coding of Each Component ................................108\n    \
    \  17.2. Probability Updates .....................................110\n   18.\
    \ Interframe Prediction ........................................113\n      18.1.\
    \ Bounds on, and Adjustment of, Motion Vectors ............113\n      18.2. Prediction\
    \ Subblocks ....................................115\n      18.3. Sub-Pixel Interpolation\
    \ .................................115\n      18.4. Filter Properties .......................................118\n\
    \   19. Annex A: Bitstream Syntax ....................................120\n  \
    \    19.1. Uncompressed Data Chunk .................................121\n    \
    \  19.2. Frame Header ............................................122\n      19.3.\
    \ Macroblock Data .........................................130\n   20. Attachment\
    \ One: Reference Decoder Source Code ................133\n      20.1. bit_ops.h\
    \ ...............................................133\n      20.2. bool_decoder.h\
    \ ..........................................133\n      20.3. dequant_data.h ..........................................137\n\
    \      20.4. dixie.c .................................................138\n  \
    \    20.5. dixie.h .................................................151\n    \
    \  20.6. dixie_loopfilter.c ......................................158\n      20.7.\
    \ dixie_loopfilter.h ......................................170\n      20.8. idct_add.c\
    \ ..............................................171\n      20.9. idct_add.h ..............................................174\n\
    \      20.10. mem.h ..................................................175\n  \
    \    20.11. modemv.c ...............................................176\n    \
    \  20.12. modemv.h ...............................................192\n      20.13.\
    \ modemv_data.h ..........................................193\n      20.14. predict.c\
    \ ..............................................198\n      20.15. predict.h ..............................................231\n\
    \      20.16. tokens.c ...............................................232\n  \
    \    20.17. tokens.h ...............................................242\n    \
    \  20.18. vp8_prob_data.h ........................................243\n      20.19.\
    \ vpx_codec_internal.h ...................................252\n      20.20. vpx_decoder.h\
    \ ..........................................263\n      20.21. vpx_decoder_compat.h\
    \ ...................................271\n      20.22. vpx_image.c ............................................285\n\
    \      20.23. vpx_image.h ............................................291\n  \
    \    20.24. vpx_integer.h ..........................................298\n    \
    \  20.25. AUTHORS File ...........................................299\n      20.26.\
    \ LICENSE ................................................301\n      20.27. PATENTS\
    \ ................................................302\n   21. Security Considerations\
    \ ......................................302\n   22. References ...................................................303\n\
    \      22.1. Normative Reference .....................................303\n  \
    \    22.2. Informative References ..................................303\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This document describes the VP8 compressed video data format,\n\
    \   together with a discussion of the decoding procedure for the format.\n   It\
    \ is intended to be used in conjunction with, and as a guide to, the\n   reference\
    \ decoder source code provided in Attachment One\n   (Section 20).  If there are\
    \ any conflicts between this narrative and\n   the reference source code, the\
    \ reference source code should be\n   considered correct.  The bitstream is defined\
    \ by the reference source\n   code and not this narrative.\n   Like many modern\
    \ video compression schemes, VP8 is based on\n   decomposition of frames into\
    \ square subblocks of pixels, prediction\n   of such subblocks using previously\
    \ constructed blocks, and adjustment\n   of such predictions (as well as synthesis\
    \ of unpredicted blocks)\n   using a discrete cosine transform (hereafter abbreviated\
    \ as DCT).  In\n   one special case, however, VP8 uses a Walsh-Hadamard transform\n\
    \   (hereafter abbreviated as WHT) instead of a DCT.\n   Roughly speaking, such\
    \ systems reduce datarate by exploiting the\n   temporal and spatial coherence\
    \ of most video signals.  It is more\n   efficient to specify the location of\
    \ a visually similar portion of a\n   prior frame than it is to specify pixel\
    \ values.  The frequency\n   segregation provided by the DCT and WHT facilitates\
    \ the exploitation\n   of both spatial coherence in the original signal and the\
    \ tolerance of\n   the human visual system to moderate losses of fidelity in the\n\
    \   reconstituted signal.\n   VP8 augments these basic concepts with, among other\
    \ things,\n   sophisticated usage of contextual probabilities.  The result is\
    \ a\n   significant reduction in datarate at a given quality.\n   Unlike some\
    \ similar schemes (the older MPEG formats, for example),\n   VP8 specifies exact\
    \ values for reconstructed pixels.  Specifically,\n   the specification for the\
    \ DCT and WHT portions of the reconstruction\n   does not allow for any \"drift\"\
    \ caused by truncation of fractions.\n   Rather, the algorithm is specified using\
    \ fixed-precision integer\n   operations exclusively.  This greatly facilitates\
    \ the verification of\n   the correctness of a decoder implementation and also\
    \ avoids\n   difficult-to-predict visual incongruities between such\n   implementations.\n\
    \   It should be remarked that, in a complete video playback system, the\n   displayed\
    \ frames may or may not be identical to the reconstructed\n   frames.  Many systems\
    \ apply a final level of filtering (commonly\n   referred to as postprocessing)\
    \ to the reconstructed frames prior to\n   viewing.  Such postprocessing has no\
    \ effect on the decoding and\n   reconstruction of subsequent frames (which are\
    \ predicted using the\n   completely specified reconstructed frames) and is beyond\
    \ the scope of\n   this document.  In practice, the nature and extent of this\
    \ sort of\n   postprocessing is dependent on both the taste of the user and on\
    \ the\n   computational facilities of the playback environment.\n   The key words\
    \ \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\"\
    , \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\n   document\
    \ are to be interpreted as described in RFC 2119 [RFC2119].\n"
- title: 2.  Format Overview
  contents:
  - "2.  Format Overview\n   VP8 works exclusively with an 8-bit YUV 4:2:0 image format.\
    \  In this\n   format, each 8-bit pixel in the two chroma planes (U and V)\n \
    \  corresponds positionally to a 2x2 block of 8-bit luma pixels in the\n   Y plane;\
    \ coordinates of the upper left corner of the Y block are of\n   course exactly\
    \ twice the coordinates of the corresponding chroma\n   pixels.  When we refer\
    \ to pixels or pixel distances without\n   specifying a plane, we are implicitly\
    \ referring to the Y plane or to\n   the complete image, both of which have the\
    \ same (full) resolution.\n   As is usually the case, the pixels are simply a\
    \ large array of bytes\n   stored in rows from top to bottom, each row being stored\
    \ from left to\n   right.  This \"left to right\" then \"top to bottom\" raster-scan\
    \ order\n   is reflected in the layout of the compressed data as well.\n   Provision\
    \ has been made in the VP8 bitstream header for the support\n   of a secondary\
    \ YUV color format, in the form of a reserved bit.\n   Occasionally, at very low\
    \ datarates, a compression system may decide\n   to reduce the resolution of the\
    \ input signal to facilitate efficient\n   compression.  The VP8 data format supports\
    \ this via optional\n   upscaling of its internal reconstruction buffer prior\
    \ to output (this\n   is completely distinct from the optional postprocessing\
    \ discussed\n   earlier, which has nothing to do with decoding per se).  This\n\
    \   upsampling restores the video frames to their original resolution.\n   In\
    \ other words, the compression/decompression system can be viewed as\n   a \"\
    black box\", where the input and output are always at a given\n   resolution.\
    \  The compressor might decide to \"cheat\" and process the\n   signal at a lower\
    \ resolution.  In that case, the decompressor needs\n   the ability to restore\
    \ the signal to its original resolution.\n   Internally, VP8 decomposes each output\
    \ frame into an array of\n   macroblocks.  A macroblock is a square array of pixels\
    \ whose Y\n   dimensions are 16x16 and whose U and V dimensions are 8x8.\n   Macroblock-level\
    \ data in a compressed frame occurs (and must be\n   processed) in a raster order\
    \ similar to that of the pixels comprising\n   the frame.\n   Macroblocks are\
    \ further decomposed into 4x4 subblocks.  Every\n   macroblock has 16 Y subblocks,\
    \ 4 U subblocks, and 4 V subblocks.  Any\n   subblock-level data (and processing\
    \ of such data) again occurs in\n   raster order, this time in raster order within\
    \ the containing\n   macroblock.\n   As discussed in further detail below, data\
    \ can be specified at the\n   levels of both macroblocks and their subblocks.\n\
    \   Pixels are always treated, at a minimum, at the level of subblocks,\n   which\
    \ may be thought of as the \"atoms\" of the VP8 algorithm.  In\n   particular,\
    \ the 2x2 chroma blocks corresponding to 4x4 Y subblocks\n   are never treated\
    \ explicitly in the data format or in the algorithm\n   specification.\n   The\
    \ DCT and WHT always operate at a 4x4 resolution.  The DCT is used\n   for the\
    \ 16Y, 4U, and 4V subblocks.  The WHT is used (with some but\n   not all prediction\
    \ modes) to encode a 4x4 array comprising the\n   average intensities of the 16\
    \ Y subblocks of a macroblock.  These\n   average intensities are, up to a constant\
    \ normalization factor,\n   nothing more than the 0th DCT coefficients of the\
    \ Y subblocks.  This\n   \"higher-level\" WHT is a substitute for the explicit\
    \ specification of\n   those coefficients, in exactly the same way as the DCT\
    \ of a subblock\n   substitutes for the specification of the pixel values comprising\
    \ the\n   subblock.  We consider this 4x4 array as a second-order subblock\n \
    \  called Y2, and think of a macroblock as containing 24 \"real\"\n   subblocks\
    \ and, sometimes, a 25th \"virtual\" subblock.  This is dealt\n   with further\
    \ in Section 13.\n   The frame layout used by the reference decoder may be found\
    \ in the\n   file vpx_image.h (Section 20.23).\n"
- title: 3.  Compressed Frame Types
  contents:
  - "3.  Compressed Frame Types\n   There are only two types of frames in VP8.\n \
    \  Intraframes (also called key frames and, in MPEG terminology,\n   I-frames)\
    \ are decoded without reference to any other frame in a\n   sequence; that is,\
    \ the decompressor reconstructs such frames\n   beginning from its \"default\"\
    \ state.  Key frames provide random access\n   (or seeking) points in a video\
    \ stream.\n   Interframes (also called prediction frames and, in MPEG terminology,\n\
    \   P-frames) are encoded with reference to prior frames, specifically\n   all\
    \ prior frames up to and including the most recent key frame.\n   Generally speaking,\
    \ the correct decoding of an interframe depends on\n   the correct decoding of\
    \ the most recent key frame and all ensuing\n   frames.  Consequently, the decoding\
    \ algorithm is not tolerant of\n   dropped frames: In an environment in which\
    \ frames may be dropped or\n   corrupted, correct decoding will not be possible\
    \ until a key frame is\n   correctly received.\n   In contrast to MPEG, there\
    \ is no use of bidirectional prediction.  No\n   frame is predicted using frames\
    \ temporally subsequent to it; there is\n   no analog to an MPEG B-frame.\n  \
    \ Secondly, VP8 augments these notions with that of alternate\n   prediction frames,\
    \ called golden frames and altref frames\n   (alternative reference frames). \
    \ Blocks in an interframe may be\n   predicted using blocks in the immediately\
    \ previous frame as well as\n   the most recent golden frame or altref frame.\
    \  Every key frame is\n   automatically golden and altref, and any interframe\
    \ may optionally\n   replace the most recent golden or altref frame.\n   Golden\
    \ frames and altref frames may also be used to partially\n   overcome the intolerance\
    \ to dropped frames discussed above: If a\n   compressor is configured to code\
    \ golden frames only with reference to\n   the prior golden frame (and key frame),\
    \ then the \"substream\" of key\n   and golden frames may be decoded regardless\
    \ of loss of other\n   interframes.  Roughly speaking, the implementation requires\
    \ (on the\n   compressor side) that golden frames subsume and recode any context\n\
    \   updates effected by the intervening interframes.  A typical\n   application\
    \ of this approach is video conferencing, in which\n   retransmission of a prior\
    \ golden frame and/or a delay in playback\n   until receipt of the next golden\
    \ frame is preferable to a larger\n   retransmit and/or delay until the next key\
    \ frame.\n"
- title: 4.  Overview of Compressed Data Format
  contents:
  - "4.  Overview of Compressed Data Format\n   The input to a VP8 decoder is a sequence\
    \ of compressed frames whose\n   order matches their order in time.  Issues such\
    \ as the duration of\n   frames, the corresponding audio, and synchronization\
    \ are generally\n   provided by the playback environment and are irrelevant to\
    \ the\n   decoding process itself; however, to aid in fast seeking, a start\n\
    \   code is included in the header of each key frame.\n   The decoder is simply\
    \ presented with a sequence of compressed frames\n   and produces a sequence of\
    \ decompressed (reconstructed) YUV frames\n   corresponding to the input sequence.\
    \  As stated in the Introduction,\n   the exact pixel values in the reconstructed\
    \ frame are part of VP8's\n   specification.  This document specifies the layout\
    \ of the compressed\n   frames and gives unambiguous algorithms for the correct\
    \ production of\n   reconstructed frames.\n   The first frame presented to the\
    \ decompressor is of course a key\n   frame.  This may be followed by any number\
    \ of interframes; the\n   correct reconstruction of each frame depends on all\
    \ prior frames up\n   to the key frame.  The next key frame restarts this process:\
    \ The\n   decompressor resets to its default initial condition upon reception\n\
    \   of a key frame, and the decoding of a key frame (and its ensuing\n   interframes)\
    \ is completely independent of any prior decoding.\n   At the highest level, every\
    \ compressed frame has three or more\n   pieces.  It begins with an uncompressed\
    \ data chunk comprising\n   10 bytes in the case of key frames and 3 bytes for\
    \ interframes.  This\n   is followed by two or more blocks of compressed data\
    \ (called\n   partitions).  These compressed data partitions begin and end on\
    \ byte\n   boundaries.\n   The first compressed partition has two subsections:\n\
    \   1.  Header information that applies to the frame as a whole.\n   2.  Per-macroblock\
    \ information specifying how each macroblock is\n       predicted from the already-reconstructed\
    \ data that is available\n       to the decompressor.\n   As stated above, the\
    \ macroblock-level information occurs in raster-\n   scan order.\n   The rest\
    \ of the partitions contain, for each block, the DCT/WHT\n   coefficients (quantized\
    \ and logically compressed) of the residue\n   signal to be added to the predicted\
    \ block values.  It typically\n   accounts for roughly 70% of the overall datarate.\
    \  VP8 supports\n   packing the compressed DCT/WHT coefficients' data from macroblock\n\
    \   rows into separate partitions.  If there is more than one partition\n   for\
    \ these coefficients, the sizes of the partitions -- except the\n   last partition\
    \ -- in bytes are also present in the bitstream right\n   after the above first\
    \ partition.  Each of the sizes is a 3-byte data\n   item written in little endian\
    \ format.  These sizes provide the\n   decoder direct access to all DCT/WHT coefficient\
    \ partitions, which\n   enables parallel processing of the coefficients in a decoder.\n\
    \   The separate partitioning of the prediction data and coefficient data\n  \
    \ also allows flexibility in the implementation of a decompressor: An\n   implementation\
    \ may decode and store the prediction information for\n   the whole frame and\
    \ then decode, transform, and add the residue\n   signal to the entire frame,\
    \ or it may simultaneously decode both\n   partitions, calculating prediction\
    \ information and adding in the\n   residue signal for each block in order.  The\
    \ length field in the\n   frame tag, which allows decoding of the second partition\
    \ to begin\n   before the first partition has been completely decoded, is necessary\n\
    \   for the second \"block-at-a-time\" decoder implementation.\n   All partitions\
    \ are decoded using separate instances of the boolean\n   entropy decoder described\
    \ in Section 7.  Although some of the data\n   represented within the partitions\
    \ is conceptually \"flat\" (a bit is\n   just a bit with no probabilistic expectation\
    \ one way or the other),\n   because of the way such coders work, there is never\
    \ a direct\n   correspondence between a \"conceptual bit\" and an actual physical\
    \ bit\n   in the compressed data partitions.  Only in the 3- or 10-byte\n   uncompressed\
    \ chunk described above is there such a physical\n   correspondence.\n   A related\
    \ matter is that seeking within a partition is not supported.\n   The data must\
    \ be decompressed and processed (or at least stored) in\n   the order in which\
    \ it occurs in the partition.\n   While this document specifies the ordering of\
    \ the partition data\n   correctly, the details and semantics of this data are\
    \ discussed in a\n   more logical fashion to facilitate comprehension.  For example,\
    \ the\n   frame header contains updates to many probability tables used in\n \
    \  decoding per-macroblock data.  The per-macroblock data is often\n   described\
    \ before the layouts of the probabilities and their updates,\n   even though this\
    \ is the opposite of their order in the bitstream.\n"
- title: 5.  Overview of the Decoding Process
  contents:
  - "5.  Overview of the Decoding Process\n   A VP8 decoder needs to maintain four\
    \ YUV frame buffers whose\n   resolutions are at least equal to that of the encoded\
    \ image.  These\n   buffers hold the current frame being reconstructed, the immediately\n\
    \   previous reconstructed frame, the most recent golden frame, and the\n   most\
    \ recent altref frame.\n   Most implementations will wish to \"pad\" these buffers\
    \ with\n   \"invisible\" pixels that extend a moderate number of pixels beyond\
    \ all\n   four edges of the visible image.  This simplifies interframe\n   prediction\
    \ by allowing all (or most) prediction blocks -- which are\n   not guaranteed\
    \ to lie within the visible area of a prior frame -- to\n   address usable image\
    \ data.\n   Regardless of the amount of padding chosen, the invisible rows above\n\
    \   (or below) the image are filled with copies of the top (or bottom)\n   row\
    \ of the image; the invisible columns to the left (or right) of the\n   image\
    \ are filled with copies of the leftmost (or rightmost) visible\n   row; and the\
    \ four invisible corners are filled with copies of the\n   corresponding visible\
    \ corner pixels.  The use of these prediction\n   buffers (and suggested sizes\
    \ for the halo) will be elaborated on in\n   the discussion of motion vectors,\
    \ interframe prediction, and\n   sub-pixel interpolation later in this document.\n\
    \   As will be seen in the description of the frame header, the image\n   dimensions\
    \ are specified (and can change) with every key frame.\n   These buffers (and\
    \ any other data structures whose size depends on\n   the size of the image) should\
    \ be allocated (or re-allocated)\n   immediately after the dimensions are decoded.\n\
    \   Leaving most of the details for later elaboration, the following is\n   an\
    \ outline of the decoding process.\n   First, the frame header (the beginning\
    \ of the first data partition)\n   is decoded.  Altering or augmenting the maintained\
    \ state of the\n   decoder, this provides the context in which the per-macroblock\
    \ data\n   can be interpreted.\n   The macroblock data occurs (and must be processed)\
    \ in raster-scan\n   order.  This data comes in two or more parts.  The first\
    \ (prediction\n   or mode) part comes in the remainder of the first data partition.\n\
    \   The other parts comprise the data partition(s) for the DCT/WHT\n   coefficients\
    \ of the residue signal.  For each macroblock, the\n   prediction data must be\
    \ processed before the residue.\n   Each macroblock is predicted using one (and\
    \ only one) of four\n   possible frames.  All macroblocks in a key frame, and\
    \ all intra-coded\n   macroblocks in an interframe, are predicted using the already-decoded\n\
    \   macroblocks in the current frame.  Macroblocks in an interframe may\n   also\
    \ be predicted using the previous frame, the golden frame, or the\n   altref frame.\
    \  Such macroblocks are said to be inter-coded.\n   The purpose of prediction\
    \ is to use already-constructed image data to\n   approximate the portion of the\
    \ original image being reconstructed.\n   The effect of any of the prediction\
    \ modes is then to write a\n   macroblock-sized prediction buffer containing this\
    \ approximation.\n   Regardless of the prediction method, the residue DCT signal\
    \ is\n   decoded, dequantized, reverse-transformed, and added to the\n   prediction\
    \ buffer to produce the (almost final) reconstruction value\n   of the macroblock,\
    \ which is stored in the correct position of the\n   current frame buffer.\n \
    \  The residue signal consists of 24 (sixteen Y, four U, and four V) 4x4\n   quantized\
    \ and losslessly compressed DCT transforms approximating the\n   difference between\
    \ the original macroblock in the uncompressed source\n   and the prediction buffer.\
    \  For most prediction modes, the 0th\n   coefficients of the sixteen Y subblocks\
    \ are expressed via a 25th WHT\n   of the second-order virtual Y2 subblock discussed\
    \ above.\n   Intra-prediction exploits the spatial coherence of frames.  The 16x16\n\
    \   luma (Y) and 8x8 chroma (UV) components are predicted independently\n   of\
    \ each other using one of four simple means of pixel propagation,\n   starting\
    \ from the already-reconstructed (16-pixel-long luma, 8-pixel-\n   long chroma)\
    \ row above, and column to the left of, the current\n   macroblock.  The four\
    \ methods are:\n   1.  Copying the row from above throughout the prediction buffer.\n\
    \   2.  Copying the column from the left throughout the prediction\n       buffer.\n\
    \   3.  Copying the average value of the row and column throughout the\n     \
    \  prediction buffer.\n   4.  Extrapolation from the row and column using the\
    \ (fixed) second\n       difference (horizontal and vertical) from the upper left\
    \ corner.\n   Additionally, the sixteen Y subblocks may be predicted independently\n\
    \   of each other using one of ten different modes, four of which are 4x4\n  \
    \ analogs of those described above, augmented with six \"diagonal\"\n   prediction\
    \ methods.  There are two types of predictions, one intra\n   and one prediction\
    \ (among all the modes), for which the residue\n   signal does not use the Y2\
    \ block to encode the DC portion of the\n   sixteen 4x4 Y subblock DCTs.  This\
    \ \"independent Y subblock\" mode has\n   no effect on the 8x8 chroma prediction.\n\
    \   Inter-prediction exploits the temporal coherence between nearby\n   frames.\
    \  Except for the choice of the prediction frame itself, there\n   is no difference\
    \ between inter-prediction based on the previous frame\n   and that based on the\
    \ golden frame or altref frame.\n   Inter-prediction is conceptually very simple.\
    \  While, for reasons of\n   efficiency, there are several methods of encoding\
    \ the relationship\n   between the current macroblock and corresponding sections\
    \ of the\n   prediction frame, ultimately each of the sixteen Y subblocks is\n\
    \   related to a 4x4 subblock of the prediction frame, whose position in\n   that\
    \ frame differs from the current subblock position by a (usually\n   small) displacement.\
    \  These two-dimensional displacements are called\n   motion vectors.\n   The\
    \ motion vectors used by VP8 have quarter-pixel precision.\n   Prediction of a\
    \ subblock using a motion vector that happens to have\n   integer (whole number)\
    \ components is very easy: The 4x4 block of\n   pixels from the displaced block\
    \ in the previous, golden, or altref\n   frame is simply copied into the correct\
    \ position of the current\n   macroblock's prediction buffer.\n   Fractional displacements\
    \ are conceptually and implementationally more\n   complex.  They require the\
    \ inference (or synthesis) of sample values\n   that, strictly speaking, do not\
    \ exist.  This is one of the most basic\n   problems in signal processing, and\
    \ readers conversant with that\n   subject will see that the approach taken by\
    \ VP8 provides a good\n   balance of robustness, accuracy, and efficiency.\n \
    \  Leaving the details for the implementation discussion below, the\n   pixel\
    \ interpolation is calculated by applying a kernel filter (using\n   reasonable-precision\
    \ integer math) three pixels on either side, both\n   horizontally and vertically,\
    \ of the pixel to be synthesized.  The\n   resulting 4x4 block of synthetic pixels\
    \ is then copied into position\n   exactly as in the case of integer displacements.\n\
    \   Each of the eight chroma subblocks is handled similarly.  Their\n   motion\
    \ vectors are never specified explicitly; instead, the motion\n   vector for each\
    \ chroma subblock is calculated by averaging the\n   vectors of the four Y subblocks\
    \ that occupy the same area of the\n   frame.  Since chroma pixels have twice\
    \ the diameter (and four times\n   the area) of luma pixels, the calculated chroma\
    \ motion vectors have\n   1/8-pixel resolution, but the procedure for copying\
    \ or generating\n   pixels for each subblock is essentially identical to that\
    \ done in the\n   luma plane.\n   After all the macroblocks have been generated\
    \ (predicted and\n   corrected with the DCT/WHT residue), a filtering step (the\
    \ loop\n   filter) is applied to the entire frame.  The purpose of the loop\n\
    \   filter is to reduce blocking artifacts at the boundaries between\n   macroblocks\
    \ and between subblocks of the macroblocks.  The term \"loop\n   filter\" is used\
    \ because this filter is part of the \"coding loop\";\n   that is, it affects\
    \ the reconstructed frame buffers that are used to\n   predict ensuing frames.\
    \  This is distinguished from the\n   postprocessing filters discussed earlier,\
    \ which affect only the\n   viewed video and do not \"feed into\" subsequent frames.\n\
    \   Next, if signaled in the data, the current frame may replace the\n   golden\
    \ frame prediction buffer and/or the altref frame buffer.\n   The halos of the\
    \ frame buffers are next filled as specified above.\n   Finally, at least as far\
    \ as decoding is concerned, the (references\n   to) the \"current\" and \"last\"\
    \ frame buffers should be exchanged in\n   preparation for the next frame.\n \
    \  Various processes may be required (or desired) before viewing the\n   generated\
    \ frame.  As discussed in the frame dimension information\n   below, truncation\
    \ and/or upscaling of the frame may be required.\n   Some playback systems may\
    \ require a different frame format (RGB,\n   YUY2, etc.).  Finally, as mentioned\
    \ in the Introduction, further\n   postprocessing or filtering of the image prior\
    \ to viewing may be\n   desired.  Since the primary purpose of this document is\
    \ a decoding\n   specification, the postprocessing is not specified in this document.\n\
    \   While the basic ideas of prediction and correction used by VP8 are\n   straightforward,\
    \ many of the details are quite complex.  The\n   management of probabilities\
    \ is particularly elaborate.  Not only do\n   the various modes of intra-prediction\
    \ and motion vector specification\n   have associated probabilities, but they,\
    \ together with the coding of\n   DCT coefficients and motion vectors, often base\
    \ these probabilities\n   on a variety of contextual information (calculated from\
    \ what has been\n   decoded so far), as well as on explicit modification via the\
    \ frame\n   header.\n   The \"top-level\" of decoding and frame reconstruction\
    \ is implemented\n   in the reference decoder file dixie.c (Section 20.4).\n \
    \  This concludes our summary of decoding and reconstruction; we\n   continue\
    \ by discussing the individual aspects in more depth.\n   A reasonable \"divide\
    \ and conquer\" approach to implementation of a\n   decoder is to begin by decoding\
    \ streams composed exclusively of key\n   frames.  After that works reliably,\
    \ interframe handling can be added\n   more easily than if complete functionality\
    \ were attempted\n   immediately.  In accordance with this, we first discuss components\n\
    \   needed to decode key frames (most of which are also used in the\n   decoding\
    \ of interframes) and conclude with topics exclusive to\n   interframes.\n"
- title: 6.  Description of Algorithms
  contents:
  - "6.  Description of Algorithms\n   As the intent of this document, together with\
    \ the reference decoder\n   source code, is to specify a platform-independent\
    \ procedure for the\n   decoding and reconstruction of a VP8 video stream, many\
    \ (small)\n   algorithms must be described exactly.\n   Due to its near-universality,\
    \ terseness, ability to easily describe\n   calculation at specific precisions,\
    \ and the fact that On2's reference\n   VP8 decoder is written in C, these algorithm\
    \ fragments are written\n   using the C programming language, augmented with a\
    \ few simple\n   definitions below.\n   The standard (and best) reference for\
    \ C is [Kernighan].\n   Many code fragments will be presented in this document.\
    \  Some will be\n   nearly identical to corresponding sections of the reference\
    \ decoder;\n   others will differ.  Roughly speaking, there are three reasons\
    \ for\n   such differences:\n   1.  For reasons of efficiency, the reference decoder\
    \ version may be\n       less obvious.\n   2.  The reference decoder often uses\
    \ large data structures to\n       maintain context that need not be described\
    \ or used here.\n   3.  The authors of this document felt that a different expression\
    \ of\n       the same algorithm might facilitate exposition.\n   Regardless of\
    \ the chosen presentation, the calculation effected by\n   any of the algorithms\
    \ described here is identical to that effected by\n   the corresponding portion\
    \ of the reference decoder.\n   All VP8 decoding algorithms use integer math.\
    \  To facilitate\n   specification of arithmetic precision, we define the following\
    \ types.\n   ---- Begin code block --------------------------------------\n  \
    \ typedef   signed char  int8; /* signed int exactly 8 bits wide */\n   typedef\
    \ unsigned char uint8; /* unsigned \"\" */\n   typedef short int16;         /*\
    \ signed int exactly 16 bits wide */\n   typedef unsigned int16 uint16; /* unsigned\
    \ \"\" */\n   /* int32 is a signed integer type at least 32 bits wide */\n   typedef\
    \ long int32; /* guaranteed to work on all systems */\n   typedef int  int32;\
    \ /* will be more efficient on some systems */\n   typedef unsigned int32 uint32;\n\
    \   /* unsigned integer type, at least 16 bits wide, whose exact size\n      is\
    \ most convenient to whatever processor we are using */\n   typedef unsigned int\
    \ uint;\n   /* While pixels themselves are 8-bit unsigned integers,\n      pixel\
    \ arithmetic often occurs at 16- or 32-bit precision and\n      the results need\
    \ to be \"saturated\" or clamped to an 8-bit\n      range. */\n   typedef uint8\
    \ Pixel;\n   Pixel clamp255(int32 v) { return v < 0? 0 : (v < 255? v : 255);}\n\
    \   /*  As is elaborated in the discussion of the bool_decoder below,\n      \
    \ VP8 represents probabilities as unsigned 8-bit numbers. */\n   typedef uint8\
    \ Prob;\n   ---- End code block ----------------------------------------\n   We\
    \ occasionally need to discuss mathematical functions involving\n   honest-to-goodness\
    \ \"infinite precision\" real numbers.  The DCT is\n   first described via the\
    \ cosine function cos; the ratio of the lengths\n   of the circumference and diameter\
    \ of a circle is denoted pi; at one\n   point, we take a (base 1/2) logarithm,\
    \ denoted log; and pow(x, y)\n   denotes x raised to the power y.  If x = 2 and\
    \ y is a small\n   non-negative integer, pow(2, y) may be expressed in C as 1\
    \ << y.\n   Finally, we sometimes need to divide signed integers by powers of\n\
    \   two; that is, we occasionally right-shift signed numbers.  The\n   behavior\
    \ of such shifts (i.e., the propagation of the sign bit) is,\n   perhaps surprisingly,\
    \ not defined by the C language itself and is\n   left up to individual compilers.\
    \  Because of the utility of this\n   frequently needed operation, it is at least\
    \ arguable that it should\n   be defined by the language (to naturally propagate\
    \ the sign bit) and,\n   at a minimum, should be correctly implemented by any\
    \ reasonable\n   compiler.  In the interest of strict portability, we attempt\
    \ to call\n   attention to these shifts when they arise.\n"
- title: 7.  Boolean Entropy Decoder
  contents:
  - "7.  Boolean Entropy Decoder\n   As discussed in the overview above, essentially\
    \ the entire VP8 data\n   stream is encoded using a boolean entropy coder.\n \
    \  An understanding of the bool_decoder is critical to the\n   implementation\
    \ of a VP8 decompressor, so we discuss the bool_decoder\n   in detail.  It is\
    \ easier to comprehend the bool_decoder in\n   conjunction with the bool_encoder\
    \ used by the compressor to write the\n   compressed data partitions.\n   The\
    \ bool_encoder encodes (and the bool_decoder decodes) one bool\n   (zero-or-one\
    \ boolean value) at a time.  Its purpose is to losslessly\n   compress a sequence\
    \ of bools for which the probability of their being\n   zero or one can be well-estimated\
    \ (via constant or previously coded\n   information) at the time they are written,\
    \ using identical\n   corresponding probabilities at the time they are read.\n\
    \   As the reader is probably aware, if a bool is much more likely to be\n   zero\
    \ than one (for instance), it can, on average, be faithfully\n   encoded using\
    \ much less than one bit per value.  The bool_encoder\n   exploits this.\n   In\
    \ the 1940s, [Shannon] proved that there is a lower bound for the\n   average\
    \ datarate of a faithful encoding of a sequence of bools (whose\n   probability\
    \ distributions are known and are independent of each\n   other) and also that\
    \ there are encoding algorithms that approximate\n   this lower bound as closely\
    \ as one wishes.\n   If we encode a sequence of bools whose probability of being\
    \ zero is p\n   (and whose probability of being 1 is 1-p), the lowest possible\n\
    \   datarate per value is\n   plog(p) + (1-p)log(1-p);\n   taking the logarithms\
    \ to the base 1/2 expresses the datarate in bits/\n   value.\n   We give two simple\
    \ examples.  At one extreme, if p = 1/2, then log(p)\n   = log(1-p) = 1, and the\
    \ lowest possible datarate per bool is 1/2 +\n   1/2 = 1; that is, we cannot do\
    \ any better than simply literally\n   writing out bits.  At another extreme,\
    \ if p is very small, say p =\n   1/1024, then log(p)=10, log(1-p) is roughly\
    \ .0014, and the lowest\n   possible datarate is approximately 10/1024 + .0014,\
    \ roughly 1/100 of\n   a bit per bool.\n   Because most of the bools in the VP8\
    \ datastream have zero-\n   probabilities nowhere near 1/2, the compression provided\
    \ by the\n   bool_encoder is critical to the performance of VP8.\n   The boolean\
    \ coder used by VP8 is a variant of an arithmetic coder.\n   An excellent discussion\
    \ of arithmetic coding (and other lossless\n   compression techniques) can be\
    \ found in [Bell].\n"
- title: 7.1.  Underlying Theory of Coding
  contents:
  - "7.1.  Underlying Theory of Coding\n   The basic idea used by the boolean coder\
    \ is to consider the entire\n   data stream (either of the partitions in our case)\
    \ as the binary\n   expansion of a single number x with 0 <= x < 1.  The bits\
    \ (or bytes)\n   in x are of course written from high to low order, and if b[j]\
    \ (B[j])\n   is the j^(th) bit (byte) in the partition, the value x is simply\
    \ the\n   sum (starting with j = 1) of pow(2, -j) * b[j] or pow(256, -j) *\n \
    \  B[j].\n   Before the first bool is coded, all values of x are possible.\n \
    \  The coding of each bool restricts the possible values of x in\n   proportion\
    \ to the probability of what is coded.  If p1 is the\n   probability of the first\
    \ bool being zero and a zero is coded, the\n   range of possible values of x is\
    \ restricted to 0 <= x < p1.  If a one\n   is coded, the range becomes p1 <= x\
    \ < 1.\n   The coding continues by repeating the same idea.  At every stage,\n\
    \   there is an interval a <= x < b of possible values of x.  If p is the\n  \
    \ probability of a zero being coded at this stage and a zero is coded,\n   the\
    \ interval becomes a <= x < a + (p(b-a)).  If a one is coded, the\n   possible\
    \ values of x are restricted to a + (p(b-a)) <= x < b.\n   Assuming that only\
    \ finitely many values are to be coded, after the\n   encoder has received the\
    \ last bool, it can write as its output any\n   value x that lies in the final\
    \ interval.  VP8 simply writes the left\n   endpoint of the final interval.  Consequently,\
    \ the output it would\n   make if encoding were to stop at any time either increases\
    \ or stays\n   the same as each bool is encoded.\n   Decoding parallels encoding.\
    \  The decoder is presented with the\n   number x, which has only the initial\
    \ restriction 0 <= x < 1.  To\n   decode the first bool, the decoder is given\
    \ the first probability p1.\n   If x < p1, a zero is decoded; if x >= p1, a one\
    \ is decoded.  In\n   either case, the new restriction on x -- that is, the interval\
    \ of\n   possible values of x -- is remembered.\n   Decoding continues in exactly\
    \ the same way: If a <= x < b is the\n   current interval and we are to decode\
    \ a bool with zero-probability p,\n   we return a zero if a <= x < a + (p(b-a))\
    \ and a one if a + (p(b-a))\n   <= x < b.  In either case, the new restriction\
    \ is remembered in\n   preparation for decoding the next bool.\n   The process\
    \ outlined above uses real numbers of infinite precision to\n   express the probabilities\
    \ and ranges.  It is true that, if one could\n   actualize this process and coded\
    \ a large number of bools whose\n   supplied probabilities matched their value\
    \ distributions, the\n   datarate achieved would approach the theoretical minimum\
    \ as the\n   number of bools encoded increased.\n   Unfortunately, computers operate\
    \ at finite precision, and an\n   approximation to the theoretically perfect process\
    \ described above is\n   necessary.  Such approximation increases the datarate\
    \ but, at quite\n   moderate precision and for a wide variety of data sets, this\
    \ increase\n   is negligible.\n   The only conceptual limitations are, first,\
    \ that coder probabilities\n   must be expressed at finite precision and, second,\
    \ that the decoder\n   be able to detect each individual modification to the value\
    \ interval\n   via examination of a fixed amount of input.  As a practical matter,\n\
    \   many of the implementation details stem from the fact that the coder\n   can\
    \ function using only a small \"window\" to incrementally read or\n   write the\
    \ arbitrarily precise number x.\n"
- title: 7.2.  Practical Algorithm Description
  contents:
  - "7.2.  Practical Algorithm Description\n   VP8's boolean coder works with 8-bit\
    \ probabilities p.  The range of\n   such p is 0 <= p <= 255; the actual probability\
    \ represented by p is\n   p/256.  Also, the coder is designed so that decoding\
    \ of a bool\n   requires no more than an 8-bit comparison, and so that the state\
    \ of\n   both the encoder and decoder can be easily represented using a small\n\
    \   number of unsigned 16-bit integers.\n   The details are most easily understood\
    \ if we first describe the\n   algorithm using bit-at-a-time input and output.\
    \  Aside from the\n   ability to maintain a position in this bitstream and write/read\
    \ bits,\n   the encoder also needs the ability to add 1 to the bits already\n\
    \   output; after writing n bits, adding 1 to the existing output is the\n   same\
    \ thing as adding pow(2, -n) to x.\n   Together with the bit position, the encoder\
    \ must maintain two\n   unsigned 8-bit numbers, which we call \"bottom\" and \"\
    range\".  Writing\n   w for the n bits already written and S = pow(2, - n - 8)\
    \ for the\n   scale of the current bit position one byte out, we have the following\n\
    \   constraint on all future values v of w (including the final value\n   v =\
    \ x):\n   w + ( S * bottom ) <= v < w + ( S * ( bottom + range ) )\n   Thus, appending\
    \ bottom to the already-written bits w gives the left\n   endpoint of the interval\
    \ of possible values, appending bottom + range\n   gives the right endpoint, and\
    \ range itself (scaled to the current\n   output position) is the length of the\
    \ interval.\n   So that our probabilistic encodings are reasonably accurate, we\
    \ do\n   not let range vary by more than a factor of two: It stays within the\n\
    \   bounds 128 <= range <= 255.\n   The process for encoding a boolean value val\
    \ whose probability of\n   being zero is prob / 256 -- and whose probability of\
    \ being one is\n   ( 256 - prob ) / 256 -- with 1 <= prob <= 255 is as follows.\n\
    \   Using an unsigned 16-bit multiply followed by an unsigned right\n   shift,\
    \ we calculate an unsigned 8-bit split value:\n   split = 1 + (((range - 1) *\
    \ probability)]] >> 8)\n   split is approximately ( prob / 256 ) * range and lies\
    \ within the\n   bounds 1 <= split <= range - 1.  These bounds ensure the correctness\n\
    \   of the decoding procedure described below.\n   If the incoming boolean val\
    \ to be encoded is false, we leave the left\n   interval endpoint bottom alone\
    \ and reduce range, replacing it by\n   split.  If the incoming val is true, we\
    \ move up the left endpoint to\n   bottom + split, propagating any carry to the\
    \ already-written value w\n   (this is where we need the ability to add 1 to w),\
    \ and reduce range\n   to range - split.\n   Regardless of the value encoded,\
    \ range has been reduced and now has\n   the bounds 1 <= range <= 254.  If range\
    \ < 128, the encoder doubles it\n   and shifts the high-order bit out of bottom\
    \ to the output as it also\n   doubles bottom, repeating this process one bit\
    \ at a time until 128 <=\n   range <= 255.  Once this is completed, the encoder\
    \ is ready to accept\n   another bool, maintaining the constraints described above.\n\
    \   After encoding the last bool, the partition may be completed by\n   appending\
    \ bottom to the bitstream.\n   The decoder mimics the state of the encoder.  It\
    \ maintains, together\n   with an input bit position, two unsigned 8-bit numbers,\
    \ a range\n   identical to that maintained by the encoder and a value.  Decoding\n\
    \   one bool at a time, the decoder (in effect) tracks the same left\n   interval\
    \ endpoint as does the encoder and subtracts it from the\n   remaining input.\
    \  Appending the unread portion of the bitstream to\n   the 8-bit value gives\
    \ the difference between the actual value encoded\n   and the known left endpoint.\n\
    \   The decoder is initialized by setting range = 255 and reading the\n   first\
    \ 16 input bits into value.  The decoder maintains range and\n   calculates split\
    \ in exactly the same way as does the encoder.\n   To decode a bool, it compares\
    \ value to split; if value < split, the\n   bool is zero, and range is replaced\
    \ with split.  If value >= split,\n   the bool is one, range is replaced with\
    \ range - split, and value is\n   replaced with value - split.\n   Again, range\
    \ is doubled one bit at a time until it is at least 128.\n   The value is doubled\
    \ in parallel, shifting a new input bit into the\n   bottom each time.\n   Writing\
    \ Value for value together with the unread input bits and Range\n   for range\
    \ extended indefinitely on the right by zeros, the condition\n   Value < Range\
    \ is maintained at all times by the decoder.  In\n   particular, the bits shifted\
    \ out of value as it is doubled are always\n   zero.\n"
- title: 7.3.  Actual Implementation
  contents:
  - "7.3.  Actual Implementation\n   The C code below gives complete implementations\
    \ of the encoder and\n   decoder described above.  While they are logically identical\
    \ to the\n   \"bit-at-a-time\" versions, they internally buffer a couple of extra\n\
    \   bytes of the bitstream.  This allows I/O to be done (more\n   practically)\
    \ a byte at a time and drastically reduces the number of\n   carries the encoder\
    \ has to propagate into the already-written data.\n   Another (logically equivalent)\
    \ implementation may be found in the\n   reference decoder file bool_decoder.h\
    \ (Section 20.2).\n   ---- Begin code block --------------------------------------\n\
    \   /* Encoder first */\n   typedef struct {\n     uint8 *output;  /* ptr to next\
    \ byte to be written */\n     uint32 range;   /* 128 <= range <= 255 */\n    \
    \ uint32 bottom;  /* minimum value of remaining output */\n     int bit_count;\
    \  /* # of shifts before an output byte\n                        is available\
    \ */\n   } bool_encoder;\n   /* Must set initial state of encoder before writing\
    \ any bools. */\n   void init_bool_encoder(bool_encoder *e, uint8 *start_partition)\n\
    \   {\n     e->output = start_partition;\n     e->range = 255;\n     e->bottom\
    \ = 0;\n     e->bit_count = 24;\n   }\n   /* Encoding very rarely produces a carry\
    \ that must be propagated\n      to the already-written output.  The arithmetic\
    \ guarantees that\n      the propagation will never go beyond the beginning of\
    \ the\n      output.  Put another way, the encoded value x is always less\n  \
    \    than one. */\n   void add_one_to_output(uint8 *q)\n   {\n     while (*--q\
    \ == 255)\n       *q = 0;\n     ++*q;\n   }\n   /* Main function writes a bool_value\
    \ whose probability of being\n      zero is (expected to be) prob/256. */\n  \
    \ void write_bool(bool_encoder *e, Prob prob, int bool_value)\n   {\n     /* split\
    \ is approximately (range * prob) / 256 and,\n        crucially, is strictly bigger\
    \ than zero and strictly\n        smaller than range */\n     uint32 split = 1\
    \ + (((e->range - 1) * prob) >> 8);\n     if (bool_value) {\n       e->bottom\
    \ += split; /* move up bottom of interval */\n       e->range -= split;  /* with\
    \ corresponding decrease in range */\n     } else\n       e->range = split;  \
    \ /* decrease range, leaving bottom alone */\n     while (e->range < 128)\n  \
    \   {\n       e->range <<= 1;\n       if (e->bottom & (1 << 31))  /* detect carry\
    \ */\n         add_one_to_output(e->output);\n       e->bottom <<= 1;        /*\
    \ before shifting bottom */\n       if (!--e->bit_count) {  /* write out high\
    \ byte of bottom ... */\n         *e->output++ = (uint8) (e->bottom >> 24);\n\
    \         e->bottom &= (1 << 24) - 1;  /* ... keeping low 3 bytes */\n       \
    \  e->bit_count = 8;            /* 8 shifts until next output */\n       }\n \
    \    }\n   }\n   /* Call this function (exactly once) after encoding the last\n\
    \      bool value for the partition being written */\n   void flush_bool_encoder(bool_encoder\
    \ *e)\n   {\n     int c = e->bit_count;\n     uint32 v = e->bottom;\n     if (v\
    \ & (1 << (32 - c)))   /* propagate (unlikely) carry */\n       add_one_to_output(e->output);\n\
    \     v <<= c & 7;               /* before shifting remaining output */\n    \
    \ c >>= 3;                   /* to top of internal buffer */\n     while (--c\
    \ >= 0)\n       v <<= 8;\n     c = 4;\n     while (--c >= 0) {    /* write remaining\
    \ data, possibly padded */\n       *e->output++ = (uint8) (v >> 24);\n       v\
    \ <<= 8;\n     }\n   }\n   /* Decoder state exactly parallels that of the encoder.\n\
    \      \"value\", together with the remaining input, equals the\n      complete\
    \ encoded number x less the left endpoint of the\n      current coding interval.\
    \ */\n   typedef struct {\n     uint8   *input;     /* pointer to next compressed\
    \ data byte */\n     uint32  range;      /* always identical to encoder's range\
    \ */\n     uint32  value;      /* contains at least 8 significant bits */\n  \
    \   int     bit_count;  /* # of bits shifted out of\n                        \
    \    value, at most 7 */\n   } bool_decoder;\n   /* Call this function before\
    \ reading any bools from the\n      partition. */\n   void init_bool_decoder(bool_decoder\
    \ *d, uint8 *start_partition)\n   {\n     {\n       int i = 0;\n       d->value\
    \ = 0;           /* value = first 2 input bytes */\n       while (++i <= 2)\n\
    \         d->value = (d->value << 8)  |  *start_partition++;\n     }\n     d->input\
    \ = start_partition;  /* ptr to next byte to be read */\n     d->range = 255;\
    \           /* initial range is full */\n     d->bit_count = 0;         /* have\
    \ not yet shifted out any bits */\n   }\n   /* Main function reads a bool encoded\
    \ at probability prob/256,\n      which of course must agree with the probability\
    \ used when the\n      bool was written. */\n   int read_bool(bool_decoder *d,\
    \ Prob prob)\n   {\n     /* range and split are identical to the corresponding\
    \ values\n        used by the encoder when this bool was written */\n     uint32\
    \  split = 1 + (((d->range - 1) * prob) >> 8);\n     uint32  SPLIT = split <<\
    \ 8;\n     int     retval;           /* will be 0 or 1 */\n     if (d->value >=\
    \ SPLIT) {  /* encoded a one */\n       retval = 1;\n       d->range -= split;\
    \  /* reduce range */\n       d->value -= SPLIT;  /* subtract off left endpoint\
    \ of interval */\n     } else {              /* encoded a zero */\n       retval\
    \ = 0;\n       d->range = split;  /* reduce range, no change in left endpoint\
    \ */\n     }\n     while (d->range < 128) {  /* shift out irrelevant value bits\
    \ */\n       d->value <<= 1;\n       d->range <<= 1;\n       if (++d->bit_count\
    \ == 8) {  /* shift in new bits 8 at a time */\n         d->bit_count = 0;\n \
    \        d->value |= *d->input++;\n       }\n     }\n     return retval;\n   }\n\
    \   /* Convenience function reads a \"literal\", that is, a \"num_bits\"-\n  \
    \    wide unsigned value whose bits come high- to low-order, with\n      each\
    \ bit encoded at probability 128 (i.e., 1/2). */\n   uint32 read_literal(bool_decoder\
    \ *d, int num_bits)\n   {\n     uint32 v = 0;\n     while (num_bits--)\n     \
    \  v = (v << 1) + read_bool(d, 128);\n     return v;\n   }\n   /* Variant reads\
    \ a signed number */\n   int32 read_signed_literal(bool_decoder *d, int num_bits)\n\
    \   {\n     int32 v = 0;\n     if (!num_bits)\n       return 0;\n     if (read_bool(d,\
    \ 128))\n       v = -1;\n     while (--num_bits)\n       v = (v << 1) + read_bool(d,\
    \ 128);\n     return v;\n   }\n   ---- End code block ----------------------------------------\n"
- title: 8.  Compressed Data Components
  contents:
  - "8.  Compressed Data Components\n   At the lowest level, VP8's compressed data\
    \ is simply a sequence of\n   probabilistically encoded bools.  Most of this data\
    \ is composed of\n   (slightly) larger semantic units fashioned from bools, which\
    \ we\n   describe here.\n   We sometimes use these descriptions in C expressions\
    \ within data\n   format specifications.  In this context, they refer to the return\n\
    \   value of a call to an appropriate bool_decoder d, reading (as always)\n  \
    \ from its current reference point.\n   +--------------+-------+--------------------------------------------+\n\
    \   | Call         | Alt.  | Return                                     |\n  \
    \ +--------------+-------+--------------------------------------------+\n   |\
    \ Bool(p)      | B(p)  | Bool with probability p/256 of being 0.    |\n   |  \
    \            |       | Return value of read_bool(d, p).           |\n   |    \
    \          |       |                                            |\n   | Flag \
    \        | F     | A one-bit flag (same thing as a B(128) or  |\n   |        \
    \      |       | an L(1)).  Abbreviated F.  Return value of |\n   |          \
    \    |       | read_bool(d, 128).                         |\n   |            \
    \  |       |                                            |\n   | Lit(n)       |\
    \ L(n)  | Unsigned n-bit number encoded as n flags   |\n   |              |  \
    \     | (a \"literal\").  Abbreviated L(n).  The     |\n   |              |  \
    \     | bits are read from high to low order.      |\n   |              |    \
    \   | Return value of read_literal(d, n).        |\n   |              |      \
    \ |                                            |\n   | SignedLit(n) |       |\
    \ Signed n-bit number encoded similarly to   |\n   |              |       | an\
    \ L(n).  Return value of                  |\n   |              |       | read_signed_literal(d,\
    \ n).  These are      |\n   |              |       | rare.                   \
    \                   |\n   |              |       |                           \
    \                 |\n   | P(8)         |       | An 8-bit probability.  No different\
    \ from   |\n   |              |       | an L(8), but we sometimes use this   \
    \      |\n   |              |       | notation to emphasize that a probability\
    \   |\n   |              |       | is being coded.                           \
    \ |\n   |              |       |                                            |\n\
    \   | P(7)         |       | A 7-bit specification of an 8-bit          |\n  \
    \ |              |       | probability.  Coded as an L(7) number x;   |\n   |\
    \              |       | the resulting 8-bit probability is x ? x   |\n   |  \
    \            |       | << 1 : 1.                                  |\n   |    \
    \          |       |                                            |\n   | F?  X\
    \        |       | A flag that, if true, is followed by a     |\n   |        \
    \      |       | piece of data X.                           |\n   |          \
    \    |       |                                            |\n   | F?  X:Y    \
    \  |       | A flag that, if true, is followed by X     |\n   |              |\
    \       | and, if false, is followed by Y.  Also     |\n   |              |  \
    \     | used to express a value where Y is an      |\n   |              |    \
    \   | implicit default (not encoded in the data  |\n   |              |      \
    \ | stream), as in F?  P(8):255, which         |\n   |              |       |\
    \ expresses an optional probability: If the  |\n   |              |       | flag\
    \ is true, the probability is specified |\n   |              |       | as an 8-bit\
    \ literal, while if the flag is  |\n   |              |       | false, the probability\
    \ defaults to 255.    |\n   |              |       |                         \
    \                   |\n   | B(p)?  X     | B(p)? | Variants of the above using\
    \ a boolean      |\n   |              | X:Y   | indicator whose probability is\
    \ not         |\n   |              |       | necessarily 128.                \
    \           |\n   |              |       |                                   \
    \         |\n   | T            |       | Tree-encoded value from small alphabet.\
    \    |\n   +--------------+-------+--------------------------------------------+\n\
    \   The last type requires elaboration.  We often wish to encode\n   something\
    \ whose value is restricted to a small number of\n   possibilities (the alphabet).\n\
    \   This is done by representing the alphabet as the leaves of a small\n   binary\
    \ tree.  The (non-leaf) nodes of the tree have associated\n   probabilities p\
    \ and correspond to calls to read_bool(d, p).  We think\n   of a zero as choosing\
    \ the left branch below the node and a one as\n   choosing the right branch.\n\
    \   Thus, every value (leaf) whose tree depth is x is decoded after\n   exactly\
    \ x calls to read_bool.\n   A tree representing an encoding of an alphabet of\
    \ n possible values\n   always contains n-1 non-leaf nodes, regardless of its\
    \ shape (this is\n   easily seen by induction on n).\n   There are many ways that\
    \ a given alphabet can be so represented.  The\n   choice of tree has little impact\
    \ on datarate but does affect decoder\n   performance.  The trees used by VP8\
    \ are chosen to (on average)\n   minimize the number of calls to read_bool.  This\
    \ amounts to shaping\n   the tree so that values that are more probable have smaller\
    \ tree\n   depth than do values that are less probable.\n   Readers familiar with\
    \ Huffman coding will notice that, given an\n   alphabet together with probabilities\
    \ for each value, the associated\n   Huffman tree minimizes the expected number\
    \ of calls to read_bool.\n   Such readers will also realize that the coding method\
    \ described here\n   never results in higher datarates than does the Huffman method\
    \ and,\n   indeed, often results in much lower datarates.  Huffman coding is,\
    \ in\n   fact, nothing more than a special case of this method in which each\n\
    \   node probability is fixed at 128 (i.e., 1/2).\n"
- title: 8.1.  Tree Coding Implementation
  contents:
  - "8.1.  Tree Coding Implementation\n   We give a suggested implementation of a\
    \ tree data structure followed\n   by a couple of actual examples of its usage\
    \ by VP8.\n   It is most convenient to represent the values using small positive\n\
    \   integers, typically an enum counting up from zero.  The largest\n   alphabet\
    \ (used to code DCT coefficients, described in Section 13)\n   that is tree-coded\
    \ by VP8 has only 12 values.  The tree for this\n   alphabet adds 11 interior\
    \ nodes and so has a total of 23 positions.\n   Thus, an 8-bit number easily accommodates\
    \ both a tree position and a\n   return value.\n   A tree may then be compactly\
    \ represented as an array of (pairs of)\n   8-bit integers.  Each (even) array\
    \ index corresponds to an interior\n   node of the tree; the 0th index of course\
    \ corresponds to the root of\n   the tree.  The array entries come in pairs corresponding\
    \ to the left\n   (0) and right (1) branches of the subtree below the interior\
    \ node.\n   We use the convention that a positive (even) branch entry is the\n\
    \   index of a deeper interior node, while a nonpositive entry v\n   corresponds\
    \ to a leaf whose value is -v.\n   The node probabilities associated to a tree-coded\
    \ value are stored in\n   an array whose indices are half the indices of the corresponding\
    \ tree\n   positions.  The length of the probability array is one less than the\n\
    \   size of the alphabet.\n   Here is C code implementing the foregoing.  The\
    \ advantages of our\n   data structure should be noted.  Aside from the smallness\
    \ of the\n   structure itself, the tree-directed reading algorithm is essentially\n\
    \   a single line of code.\n   ---- Begin code block --------------------------------------\n\
    \   /* A tree specification is simply an array of 8-bit integers. */\n   typedef\
    \ int8 tree_index;\n   typedef const tree_index Tree[];\n   /* Read and return\
    \ a tree-coded value at the current decoder\n      position. */\n   int treed_read(\n\
    \     bool_decoder * const d, /* bool_decoder always returns a 0 or 1 */\n   \
    \  Tree t,                 /* tree specification */\n     const Prob p[]     /*\
    \ corresponding interior node probabilities */\n   ) {\n     register tree_index\
    \ i = 0;   /* begin at root */\n     /* Descend tree until leaf is reached */\n\
    \     while ((i = t[ i + read_bool(d, p[i>>1])]) > 0) {}\n     return -i;    \
    \ /* return value is negation of nonpositive index */\n   }\n   ---- End code\
    \ block ----------------------------------------\n   Tree-based decoding is implemented\
    \ in the reference decoder file\n   bool_decoder.h (Section 20.2).\n"
- title: 8.2.  Tree Coding Example
  contents:
  - "8.2.  Tree Coding Example\n   As a multi-part example, without getting too far\
    \ into the semantics\n   of macroblock decoding (which is of course taken up below),\
    \ we look\n   at the \"mode\" coding for intra-predicted macroblocks.\n   It so\
    \ happens that, because of a difference in statistics, the Y (or\n   luma) mode\
    \ encoding uses two different trees: one for key frames and\n   another for interframes.\
    \  This is the only instance in VP8 of the\n   same dataset being coded by different\
    \ trees under different\n   circumstances.  The UV (or chroma) modes are a proper\
    \ subset of the Y\n   modes and, as such, have their own decoding tree.\n   ----\
    \ Begin code block --------------------------------------\n   typedef enum\n \
    \  {\n       DC_PRED, /* predict DC using row above and column to the left */\n\
    \       V_PRED,  /* predict rows using row above */\n       H_PRED,  /* predict\
    \ columns using column to the left */\n       TM_PRED, /* propagate second differences\
    \ a la \"True Motion\" */\n       B_PRED,  /* each Y subblock is independently\
    \ predicted */\n       num_uv_modes = B_PRED,  /* first four modes apply to chroma\
    \ */\n       num_ymodes   /* all modes apply to luma */\n   }\n   intra_mbmode;\n\
    \   /* The aforementioned trees together with the implied codings as\n      comments.\n\
    \      Actual (i.e., positive) indices are always even.\n      Value (i.e., nonpositive)\
    \ indices are arbitrary. */\n   const tree_index ymode_tree [2 * (num_ymodes -\
    \ 1)] =\n   {\n    -DC_PRED, 2,        /* root: DC_PRED = \"0\", \"1\" subtree\
    \ */\n     4, 6,              /* \"1\" subtree has 2 descendant subtrees */\n\
    \      -V_PRED, -H_PRED, /* \"10\" subtree: V_PRED = \"100\",\n              \
    \             H_PRED = \"101\" */\n      -TM_PRED, -B_PRED /* \"11\" subtree:\
    \ TM_PRED = \"110\",\n                           B_PRED = \"111\" */\n   };\n\
    \   const tree_index kf_ymode_tree [2 * (num_ymodes - 1)] =\n   {\n    -B_PRED,\
    \ 2,            /* root: B_PRED = \"0\", \"1\" subtree */\n     4, 6,        \
    \         /* \"1\" subtree has 2 descendant subtrees */\n      -DC_PRED, -V_PRED,\
    \   /* \"10\" subtree: DC_PRED = \"100\",\n                              V_PRED\
    \ = \"101\" */\n      -H_PRED, -TM_PRED    /* \"11\" subtree: H_PRED = \"110\"\
    ,\n                              TM_PRED = \"111\" */\n   };\n   const tree_index\
    \ uv_mode_tree [2 * (num_uv_modes - 1)] =\n   {\n    -DC_PRED, 2,          /*\
    \ root: DC_PRED = \"0\", \"1\" subtree */\n     -V_PRED, 4,          /* \"1\"\
    \ subtree:  V_PRED = \"10\",\n                             \"11\" subtree */\n\
    \      -H_PRED, -TM_PRED   /* \"11\" subtree: H_PRED = \"110\",\n            \
    \                 TM_PRED = \"111\" */\n   };\n   /* Given a bool_decoder d, a\
    \ Y mode might be decoded as follows. */\n   const Prob pretend_its_huffman [num_ymodes\
    \ - 1] =\n     { 128, 128, 128, 128};\n   Ymode = (intra_mbmode) treed_read(d,\
    \ ymode_tree,\n     pretend_its_huffman);\n   ---- End code block ----------------------------------------\n\
    \   Since it greatly facilitates re-use of reference code, and since\n   there\
    \ is no real reason to do otherwise, it is strongly suggested\n   that any decoder\
    \ implementation use exactly the same enumeration\n   values and probability table\
    \ layouts as those described in this\n   document (and in the reference code)\
    \ for all tree-coded data in VP8.\n"
- title: 9.  Frame Header
  contents:
  - "9.  Frame Header\n   The uncompressed data chunk at the start of each frame and\
    \ at the\n   first part of the first data partition contains information\n   pertaining\
    \ to the frame as a whole.  We list the fields in the order\n   of occurrence.\
    \  Most of the header decoding occurs in the reference\n   decoder file dixie.c\
    \ (Section 20.4).\n"
- title: 9.1.  Uncompressed Data Chunk
  contents:
  - "9.1.  Uncompressed Data Chunk\n   The uncompressed data chunk comprises a common\
    \ (for key frames and\n   interframes) 3-byte frame tag that contains four fields,\
    \ as follows:\n   1.  A 1-bit frame type (0 for key frames, 1 for interframes).\n\
    \   2.  A 3-bit version number (0 - 3 are defined as four different\n       profiles\
    \ with different decoding complexity; other values may be\n       defined for\
    \ future variants of the VP8 data format).\n   3.  A 1-bit show_frame flag (0\
    \ when current frame is not for display,\n       1 when current frame is for display).\n\
    \   4.  A 19-bit field containing the size of the first data partition in\n  \
    \     bytes.\n   The version number setting enables or disables certain features\
    \ in\n   the bitstream, as follows:\n            +---------+-------------------------+-------------+\n\
    \            | Version | Reconstruction Filter   | Loop Filter |\n           \
    \ +---------+-------------------------+-------------+\n            | 0       |\
    \ Bicubic                 | Normal      |\n            |         |           \
    \              |             |\n            | 1       | Bilinear             \
    \   | Simple      |\n            |         |                         |       \
    \      |\n            | 2       | Bilinear                | None        |\n  \
    \          |         |                         |             |\n            |\
    \ 3       | None                    | None        |\n            |         | \
    \                        |             |\n            | Other   | Reserved for\
    \ future use |             |\n            +---------+-------------------------+-------------+\n\
    \   The reference software also adjusts the loop filter based on version\n   number,\
    \ as per the table above.  Version number 1 implies a \"simple\"\n   loop filter,\
    \ and version numbers 2 and 3 imply no loop filter.\n   However, the \"simple\"\
    \ filter setting in this context has no effect\n   whatsoever on the decoding\
    \ process, and the \"no loop filter\" setting\n   only forces the reference encoder\
    \ to set filter level equal to 0.\n   Neither affect the decoding process.  In\
    \ decoding, the only loop\n   filter settings that matter are those in the frame\
    \ header.\n   For key frames, the frame tag is followed by a further 7 bytes of\n\
    \   uncompressed data, as follows:\n   ---- Begin code block --------------------------------------\n\
    \   Start code byte 0     0x9d\n   Start code byte 1     0x01\n   Start code byte\
    \ 2     0x2a\n   16 bits      :     (2 bits Horizontal Scale << 14) | Width (14\
    \ bits)\n   16 bits      :     (2 bits Vertical Scale << 14) | Height (14 bits)\n\
    \   ---- End code block ----------------------------------------\n   The following\
    \ source code segment illustrates validation of the start\n   code and reading\
    \ the width, height, and scale factors for a key\n   frame.\n   ---- Begin code\
    \ block --------------------------------------\n   unsigned char *c = pbi->source+3;\n\
    \   // vet via sync code\n   if (c[0]!=0x9d||c[1]!=0x01||c[2]!=0x2a)\n       return\
    \ -1;\n   ---- End code block ----------------------------------------\n   Where\
    \ pbi->source points to the beginning of the frame.\n   The following code reads\
    \ the image dimension from the bitstream:\n   ---- Begin code block --------------------------------------\n\
    \   pc->Width      = swap2(*(unsigned short*)(c+3))&0x3fff;\n   pc->horiz_scale\
    \ = swap2(*(unsigned short*)(c+3))>>14;\n   pc->Height     = swap2(*(unsigned\
    \ short*)(c+5))&0x3fff;\n   pc->vert_scale  = swap2(*(unsigned short*)(c+5))>>14;\n\
    \   ---- End code block ----------------------------------------\n   Where the\
    \ swap2 macro takes care of the endian on a different\n   platform:\n   ---- Begin\
    \ code block --------------------------------------\n   #if defined(__ppc__) ||\
    \ defined(__ppc64__)\n   # define swap2(d)  \\\n     ((d&0x000000ff)<<8) |  \\\
    \n     ((d&0x0000ff00)>>8)\n   #else\n     # define swap2(d) d\n   #endif\n  \
    \ ---- End code block ----------------------------------------\n   While each\
    \ frame is encoded as a raster scan of 16x16 macroblocks,\n   the frame dimensions\
    \ are not necessarily evenly divisible by 16.  In\n   this case, write ew = 16\
    \ - (width & 15) and eh = 16 - (height & 15)\n   for the excess width and height,\
    \ respectively.  Although they are\n   encoded, the last ew columns and eh rows\
    \ are not actually part of the\n   image and should be discarded before final\
    \ output.  However, these\n   \"excess pixels\" should be maintained in the internal\
    \ reconstruction\n   buffer used to predict ensuing frames.\n   The scaling specifications\
    \ for each dimension are encoded as follows.\n             +-------+--------------------------------------+\n\
    \             | Value | Scaling                              |\n             +-------+--------------------------------------+\n\
    \             | 0     | No upscaling (the most common case). |\n             |\
    \       |                                      |\n             | 1     | Upscale\
    \ by 5/4.                      |\n             |       |                     \
    \                 |\n             | 2     | Upscale by 5/3.                  \
    \    |\n             |       |                                      |\n      \
    \       | 3     | Upscale by 2.                        |\n             +-------+--------------------------------------+\n\
    \   Upscaling does not affect the reconstruction buffer, which should be\n   maintained\
    \ at the encoded resolution.  Any reasonable method of\n   upsampling (including\
    \ any that may be supported by video hardware in\n   the playback environment)\
    \ may be used.  Since scaling has no effect\n   on decoding, we do not discuss\
    \ it any further.\n   As discussed in Section 5, allocation (or re-allocation)\
    \ of data\n   structures (such as the reconstruction buffer) whose size depends\
    \ on\n   dimension will be triggered here.\n"
- title: 9.2.  Color Space and Pixel Type (Key Frames Only)
  contents:
  - "9.2.  Color Space and Pixel Type (Key Frames Only)\n           +-------+------------------------------------------+\n\
    \           | Field | Value                                    |\n           +-------+------------------------------------------+\n\
    \           | L(1)  | 1-bit color space type specification     |\n           |\
    \       |                                          |\n           | L(1)  | 1-bit\
    \ pixel value clamping specification |\n           +-------+------------------------------------------+\n\
    \   The color space type bit is encoded as follows:\n   o  0 - YUV color space\
    \ similar to the YCrCb color space defined in\n      [ITU-R_BT.601]\n   o  1 -\
    \ Reserved for future use\n   The pixel value clamping type bit is encoded as\
    \ follows:\n   o  0 - Decoders are required to clamp the reconstructed pixel values\n\
    \      to between 0 and 255 (inclusive).\n   o  1 - Reconstructed pixel values\
    \ are guaranteed to be between 0 and\n      255; no clamping is necessary.\n \
    \  Information in this subsection does not appear in interframes.\n"
- title: 9.3.  Segment-Based Adjustments
  contents:
  - "9.3.  Segment-Based Adjustments\n   This subsection contains probability and\
    \ value information for\n   implementing segment adaptive adjustments to default\
    \ decoder\n   behavior.  The data in this subsection is used in the decoding of\
    \ the\n   ensuing per-segment information and applies to the entire frame.\n \
    \  When segment adaptive adjustments are enabled, each macroblock will\n   be\
    \ assigned a segment ID.  Macroblocks with the same segment ID\n   belong to the\
    \ same segment and have the same adaptive adjustments\n   over default baseline\
    \ values for the frame.  The adjustments can be\n   quantizer level or loop filter\
    \ strength.\n   The context for decoding this feature at the macroblock level\
    \ is\n   provided by a subsection in the frame header, which contains:\n   1.\
    \  A segmentation_enabled flag that enables the feature for this\n       frame\
    \ if set to 1, and disables it if set to 0.  The following\n       fields occur\
    \ if the feature is enabled.\n   2.  L(1) indicates if the segment map is updated\
    \ for the current\n       frame (update_mb_segmentation_map).\n   3.  L(1) indicates\
    \ if the segment feature data items are updated for\n       the current frame\
    \ (update_segment_feature_data).\n   4.  If Item 3 above (update_segment_feature_data)\
    \ is 1, the following\n       fields occur:\n       a.  L(1), the mode of segment\
    \ feature data\n           (segment_feature_mode), can be absolute-value mode\
    \ (0) or\n           delta value mode (1).\n       b.  Segment feature data items\
    \ are decoded segment by segment for\n           each segment feature.  For every\
    \ data item, a one-bit flag\n           indicates whether the item is 0, or a\
    \ non-zero value to be\n           decoded.  If the value is non-zero, then the\
    \ value is decoded\n           as a magnitude L(n), followed by a one-bit sign\
    \ (L(1) -- 0\n           for positive and 1 for negative).  The length n can be\
    \ looked\n           up from a pre-defined length table for all feature data.\n\
    \   5.  If the L(1) flag as noted in Item 2 above is set to 1, the\n       probabilities\
    \ of the decoding tree for the segment map are\n       decoded from the bitstream.\
    \  Each probability is decoded with a\n       one-bit flag indicating whether\
    \ the probability is the default\n       value of 255 (flag is set to 0), or an\
    \ 8-bit value, L(8), from\n       the bitstream.\n   The layout and semantics\
    \ supporting this feature at the macroblock\n   level are described in Section\
    \ 10.\n"
- title: 9.4.  Loop Filter Type and Levels
  contents:
  - "9.4.  Loop Filter Type and Levels\n   VP8 supports two types of loop filters\
    \ having different computational\n   complexity.  The following bits occur in\
    \ the header to support the\n   selection of the baseline type, strength, and\
    \ sharpness behavior of\n   the loop filter used for the current frame.\n    \
    \                   +-------+-------------------+\n                       | Index\
    \ | Description       |\n                       +-------+-------------------+\n\
    \                       | L(1)  | filter_type       |\n                      \
    \ |       |                   |\n                       | L(6)  | loop_filter_level\
    \ |\n                       |       |                   |\n                  \
    \     | L(3)  | sharpness_level   |\n                       +-------+-------------------+\n\
    \   The meaning of these numbers will be further explained in Section 15.\n  \
    \ VP8 has a feature in the bitstream that enables adjustment of the\n   loop filter\
    \ level based on a macroblock's prediction mode and\n   reference frame.  The\
    \ per-macroblock adjustment is done through delta\n   values against the default\
    \ loop filter level for the current frame.\n   This subsection contains flag and\
    \ value information for implementing\n   per-macroblock loop filter level adjustment\
    \ to default decoder\n   behavior.  The data in this section is used in the decoding\
    \ of the\n   ensuing per-macroblock information and applies to the entire frame.\n\
    \   L(1) is a one-bit flag indicating if the macroblock loop filter\n   adjustment\
    \ is on for the current frame.  0 means that such a feature\n   is not supported\
    \ in the current frame, and 1 means this feature is\n   enabled for the current\
    \ frame.\n   Whether the adjustment is based on a reference frame or encoding\n\
    \   mode, the adjustment of the loop filter level is done via a delta\n   value\
    \ against a baseline loop filter value.  The delta values are\n   updated for\
    \ the current frame if an L(1) bit,\n   mode_ref_lf_delta_update, takes the value\
    \ 1.  There are two groups of\n   delta values: One group of delta values is for\
    \ reference frame-based\n   adjustments, and the other group is for mode-based\
    \ adjustments.  The\n   number of delta values in the two groups is MAX_REF_LF_DELTAS\
    \ and\n   MAX_MODE_LF_DELTAS, respectively.  For every value within the two\n\
    \   groups, there is a one-bit L(1) to indicate if the particular value\n   is\
    \ updated.  When one is updated (1), it is transmitted as a six-bit-\n   magnitude\
    \ L(6) followed by a one-bit sign flag (L(1) -- 0 for\n   positive and 1 for negative).\n"
- title: 9.5.  Token Partition and Partition Data Offsets
  contents:
  - "9.5.  Token Partition and Partition Data Offsets\n   VP8 allows DCT coefficients\
    \ to be packed into multiple partitions,\n   besides the first partition with\
    \ header and per-macroblock prediction\n   information, so the decoder can perform\
    \ parallel decoding in an\n   efficient manner.  A two-bit L(2) is used to indicate\
    \ the number of\n   coefficient data partitions within a compressed frame.  The\
    \ two bits\n   are defined in the following table:\n                 +-------+-------+----------------------+\n\
    \                 | Bit 1 | Bit 0 | Number of Partitions |\n                 +-------+-------+----------------------+\n\
    \                 | 0     | 0     | 1                    |\n                 |\
    \       |       |                      |\n                 | 0     | 1     | 2\
    \                    |\n                 |       |       |                   \
    \   |\n                 | 1     | 0     | 4                    |\n           \
    \      |       |       |                      |\n                 | 1     | 1\
    \     | 8                    |\n                 +-------+-------+----------------------+\n\
    \   Offsets are embedded in the bitstream to provide the decoder direct\n   access\
    \ to token partitions.  If the number of data partitions is\n   greater than 1,\
    \ the size of each partition (except the last) is\n   written in 3 bytes (24 bits).\
    \  The size of the last partition is the\n   remainder of the data not used by\
    \ any of the previous partitions.\n   The partitioned data are consecutive in\
    \ the bitstream, so the size\n   can also be used to calculate the offset of each\
    \ partition.  The\n   following pseudocode illustrates how the size/offset is\
    \ defined by\n   the three bytes in the bitstream.\n   ---- Begin code block --------------------------------------\n\
    \   Offset/size  =  (uint32)(byte0) + ((uint32)(byte1)<<8)\n     + ((uint32)(byte2)<<16);\n\
    \   ---- End code block ----------------------------------------\n"
- title: 9.6.  Dequantization Indices
  contents:
  - "9.6.  Dequantization Indices\n   All residue signals are specified via a quantized\
    \ 4x4 DCT applied to\n   the Y, U, V, or Y2 subblocks of a macroblock.  As detailed\
    \ in\n   Section 14, before inverting the transform, each decoded coefficient\n\
    \   is multiplied by one of six dequantization factors, the choice of\n   which\
    \ depends on the plane (Y, chroma = U or V, Y2) and coefficient\n   position (DC\
    \ = coefficient 0, AC = coefficients 1-15).  The six\n   values are specified\
    \ using 7-bit indices into six corresponding fixed\n   tables (the tables are\
    \ given in Section 14).\n   The first 7-bit index gives the dequantization table\
    \ index for\n   Y-plane AC coefficients, called yac_qi.  It is always coded and\
    \ acts\n   as a baseline for the other 5 quantization indices, each of which is\n\
    \   represented by a delta from this baseline index.  Pseudocode for\n   reading\
    \ the indices follows:\n   ---- Begin code block --------------------------------------\n\
    \   yac_qi     = L(7);           /* Y ac index always specified */\n   ydc_delta\
    \  = F? delta(): 0;  /* Y dc delta specified if\n                            \
    \       flag is true */\n   y2dc_delta = F? delta(): 0;  /* Y2 dc delta specified\
    \ if\n                                   flag is true */\n   y2ac_delta = F? delta():\
    \ 0;  /* Y2 ac delta specified if\n                                   flag is\
    \ true */\n   uvdc_delta = F? delta(): 0;  /* chroma dc delta specified\n    \
    \                               if flag is true */\n   uvac_delta = F? delta():\
    \ 0;  /* chroma ac delta specified\n                                   if flag\
    \ is true */\n   ---- End code block ----------------------------------------\n\
    \   Where delta() is the process to read 5 bits from the bitstream to\n   determine\
    \ a signed delta value:\n       +-------+--------------------------------------------------+\n\
    \       | Index | Description                                      |\n       +-------+--------------------------------------------------+\n\
    \       | L(4)  | Magnitude of delta                               |\n       |\
    \       |                                                  |\n       | L(1)  |\
    \ Sign of delta, 0 for positive and 1 for negative |\n       +-------+--------------------------------------------------+\n"
- title: 9.7.  Refresh Golden Frame and Altref Frame
  contents:
  - "9.7.  Refresh Golden Frame and Altref Frame\n   For key frames, both the golden\
    \ frame and the altref frame are\n   refreshed/ replaced by the current reconstructed\
    \ frame, by default.\n   For non-key frames, VP8 uses two bits to indicate whether\
    \ the two\n   frame buffers are refreshed, using the reconstructed current frame:\n\
    \   +-------+----------------------------------------------------------+\n   |\
    \ Index | Description                                              |\n   +-------+----------------------------------------------------------+\n\
    \   | L(1)  | Whether golden frame is refreshed (0 for no, 1 for yes). |\n   |\
    \       |                                                          |\n   | L(1)\
    \  | Whether altref frame is refreshed (0 for no, 1 for yes). |\n   +-------+----------------------------------------------------------+\n\
    \   When the flag for the golden frame is 0, VP8 uses 2 more bits in the\n   bitstream\
    \ to indicate whether the buffer (and which buffer) is copied\n   to the golden\
    \ frame, or if no buffer is copied:\n           +-------+------------------------------------------+\n\
    \           | Index | Description                              |\n           +-------+------------------------------------------+\n\
    \           | L(2)  | Buffer copy flag for golden frame buffer |\n           +-------+------------------------------------------+\n\
    \   Where:\n   o  0 means no buffer is copied to the golden frame\n   o  1 means\
    \ last_frame is copied to the golden frame\n   o  2 means alt_ref_frame is copied\
    \ to the golden frame\n   Similarly, when the flag for altref is 0, VP8 uses 2\
    \ bits in the\n   bitstream to indicate which buffer is copied to alt_ref_frame.\n\
    \           +-------+------------------------------------------+\n           |\
    \ Index | Description                              |\n           +-------+------------------------------------------+\n\
    \           | L(2)  | Buffer copy flag for altref frame buffer |\n           +-------+------------------------------------------+\n\
    \   Where:\n   o  0 means no buffer is copied to the altref frame\n   o  1 means\
    \ last_frame is copied to the altref frame\n   o  2 means golden_frame is copied\
    \ to the altref frame\n   Two bits are transmitted for ref_frame_sign_bias for\
    \ golden_frame and\n   alt_ref_frame, respectively.\n                +-------+---------------------------------+\n\
    \                | Index | Description                     |\n               \
    \ +-------+---------------------------------+\n                | L(1)  | Sign\
    \ bias flag for golden frame |\n                |       |                    \
    \             |\n                | L(1)  | Sign bias flag for altref frame |\n\
    \                +-------+---------------------------------+\n   These values\
    \ are used to control the sign of the motion vectors when\n   a golden frame or\
    \ an altref frame is used as the reference frame for\n   a macroblock.\n"
- title: 9.8.  Refresh Last Frame Buffer
  contents:
  - "9.8.  Refresh Last Frame Buffer\n   VP8 uses one bit, L(1), to indicate if the\
    \ last frame reference\n   buffer is refreshed using the constructed current frame.\
    \  On a key\n   frame, this bit is overridden, and the last frame buffer is always\n\
    \   refreshed.\n"
- title: 9.9.  DCT Coefficient Probability Update
  contents:
  - "9.9.  DCT Coefficient Probability Update\n   This field contains updates to the\
    \ probability tables used to decode\n   DCT coefficients.  For each of the probabilities\
    \ in the tables, there\n   is an L(1) flag indicating if the probability is updated\
    \ for the\n   current frame, and if the L(1) flag is set to 1, there follows an\n\
    \   additional 8-bit value representing the new probability value.  These\n  \
    \ tables are maintained across interframes but are of course replaced\n   with\
    \ their defaults at the beginning of every key frame.\n   The layout and semantics\
    \ of this field will be taken up in\n   Section 13.\n"
- title: 9.10.  Remaining Frame Header Data (Non-Key Frame)
  contents:
  - "9.10.  Remaining Frame Header Data (Non-Key Frame)\n   +-------+-----------------------------------------------------------+\n\
    \   | Index | Description                                               |\n  \
    \ +-------+-----------------------------------------------------------+\n   |\
    \ L(1)  | mb_no_skip_coeff.  This flag indicates at the frame level |\n   |  \
    \     | if skipping of macroblocks with no non-zero coefficients  |\n   |    \
    \   | is enabled.  If it is set to 0, then prob_skip_false is   |\n   |      \
    \ | not read and mb_skip_coeff is forced to 0 for all         |\n   |       |\
    \ macroblocks (see Sections 11.1 and 12.1).                 |\n   |       |  \
    \                                                         |\n   | L(8)  | prob_skip_false\
    \ = probability used for decoding a         |\n   |       | macroblock-level flag,\
    \ which indicates if a macroblock    |\n   |       | has any non-zero coefficients.\
    \  Only read if              |\n   |       | mb_no_skip_coeff is 1.          \
    \                          |\n   |       |                                   \
    \                        |\n   | L(8)  | prob_intra = probability that a macroblock\
    \ is \"intra\"     |\n   |       | predicted (that is, predicted from the already-encoded\
    \    |\n   |       | portions of the current frame), as opposed to \"inter\" \
    \    |\n   |       | predicted (that is, predicted from the contents of a    \
    \  |\n   |       | prior frame).                                             |\n\
    \   |       |                                                           |\n  \
    \ | L(8)  | prob_last = probability that an inter-predicted           |\n   |\
    \       | macroblock is predicted from the immediately previous     |\n   |  \
    \     | frame, as opposed to the most recent golden frame or      |\n   |    \
    \   | altref frame.                                             |\n   |      \
    \ |                                                           |\n   | L(8)  |\
    \ prob_gf = probability that an inter-predicted macroblock  |\n   |       | is\
    \ predicted from the most recent golden frame, as        |\n   |       | opposed\
    \ to the altref frame.                              |\n   |       |          \
    \                                                 |\n   | F     | If true, followed\
    \ by four L(8)s updating the              |\n   |       | probabilities for the\
    \ different types of intra-prediction |\n   |       | for the Y plane.  These\
    \ probabilities correspond to the   |\n   |       | four interior nodes of the\
    \ decoding tree for intra-Y      |\n   |       | modes in an interframe, that\
    \ is, the even positions in    |\n   |       | the ymode_tree array given above.\
    \                         |\n   |       |                                    \
    \                       |\n   | F     | If true, followed by three L(8)s updating\
    \ the             |\n   |       | probabilities for the different types of intra-prediction\
    \ |\n   |       | for the chroma planes.  These probabilities correspond to |\n\
    \   |       | the even positions in the uv_mode_tree array given above. |\n  \
    \ |       |                                                           |\n   |\
    \ X     | Motion vector probability update.  Details are given in   |\n   |  \
    \     | Section 17.2, \"Probability Updates\".                      |\n   +-------+-----------------------------------------------------------+\n\
    \   Decoding of this portion of the frame header is handled in the\n   reference\
    \ decoder file dixie.c (Section 20.4).\n"
- title: 9.11.  Remaining Frame Header Data (Key Frame)
  contents:
  - "9.11.  Remaining Frame Header Data (Key Frame)\n   +-------+-----------------------------------------------------------+\n\
    \   | Index | Description                                               |\n  \
    \ +-------+-----------------------------------------------------------+\n   |\
    \ L(1)  | mb_no_skip_coeff.  This flag indicates at the frame level |\n   |  \
    \     | if skipping of macroblocks with no non-zero coefficients  |\n   |    \
    \   | is enabled.  If it is set to 0, then prob_skip_false is   |\n   |      \
    \ | not read and mb_skip_coeff is forced to 0 for all         |\n   |       |\
    \ macroblocks (see Sections 11.1 and 12.1).                 |\n   |       |  \
    \                                                         |\n   | L(8)  | prob_skip_false\
    \ = Probability used for decoding a         |\n   |       | macroblock-level flag,\
    \ which indicates if a macroblock    |\n   |       | has any non-zero coefficients.\
    \  Only read if              |\n   |       | mb_no_skip_coeff is 1.          \
    \                          |\n   +-------+-----------------------------------------------------------+\n\
    \   Decoding of this portion of the frame header is handled in the\n   reference\
    \ decoder file modemv.c (Section 20.11).\n   This completes the layout of the\
    \ frame header.  The remainder of the\n   first data partition consists of macroblock-level\
    \ prediction data.\n   After the frame header is processed, all probabilities\
    \ needed to\n   decode the prediction and residue data are known and will not\
    \ change\n   until the next frame.\n"
- title: 10.  Segment-Based Feature Adjustments
  contents:
  - "10.  Segment-Based Feature Adjustments\n   Every macroblock may optionally override\
    \ some of the default\n   behaviors of the decoder.  Specifically, VP8 uses segment-based\n\
    \   adjustments to support changing quantizer level and loop filter level\n  \
    \ for a macroblock.  When the segment-based adjustment feature is\n   enabled\
    \ for a frame, each macroblock within the frame is coded with a\n   segment_id.\
    \  This effectively segments all the macroblocks in the\n   current frame into\
    \ a number of different segments.  Macroblocks\n   within the same segment behave\
    \ exactly the same for quantizer and\n   loop filter level adjustments.\n   If\
    \ both the segmentation_enabled and update_mb_segmentation_map flags\n   in subsection\
    \ B of the frame header take a value of 1, the prediction\n   data for each (intra-\
    \ or inter-coded) macroblock begins with a\n   specification of segment_id for\
    \ the current macroblock.  It is\n   decoded using this simple tree ...\n   ----\
    \ Begin code block --------------------------------------\n   const tree_index\
    \ mb_segment_tree [2 * (4-1)] =\n     {\n       2,  4,     /* root: \"0\", \"\
    1\" subtrees */\n       -0, -1,    /* \"00\" = 0th value, \"01\" = 1st value */\n\
    \        -2, -3    /* \"10\" = 2nd value, \"11\" = 3rd value */\n     }\n   ----\
    \ End code block ----------------------------------------\n   ... combined with\
    \ a 3-entry probability table,\n   mb_segment_tree_probs[3].  The macroblock's\
    \ segment_id is used later\n   in the decoding process to look into the segment_feature_data\
    \ table\n   and determine how the quantizer and loop filter levels are adjusted.\n\
    \   The decoding of segment_id, together with the parsing of\n   intra-prediction\
    \ modes (which is taken up next), is implemented in\n   the reference decoder\
    \ file modemv.c.\n"
- title: 11.  Key Frame Macroblock Prediction Records
  contents:
  - "11.  Key Frame Macroblock Prediction Records\n   After specifying the features\
    \ described above, the macroblock\n   prediction record next specifies the prediction\
    \ mode used for the\n   macroblock.\n"
- title: 11.1.  mb_skip_coeff
  contents:
  - "11.1.  mb_skip_coeff\n   The single bool flag is decoded using prob_skip_false\
    \ if and only if\n   mb_no_skip_coeff is set to 1 (see Sections 9.10 and 9.11).\
    \  If\n   mb_no_skip_coeff is set to 0, then this value defaults to 0.\n"
- title: 11.2.  Luma Modes
  contents:
  - "11.2.  Luma Modes\n   First comes the luma specification of type intra_mbmode,\
    \ coded using\n   the kf_ymode_tree, as described in Section 8 and repeated here\
    \ for\n   convenience:\n   ---- Begin code block --------------------------------------\n\
    \   typedef enum\n   {\n       DC_PRED, /* predict DC using row above and column\
    \ to the left */\n       V_PRED,  /* predict rows using row above */\n       H_PRED,\
    \  /* predict columns using column to the left */\n       TM_PRED, /* propagate\
    \ second differences a la \"True Motion\" */\n       B_PRED,  /* each Y subblock\
    \ is independently predicted */\n       num_uv_modes = B_PRED,  /* first four\
    \ modes apply to chroma */\n       num_ymodes   /* all modes apply to luma */\n\
    \   }\n   intra_mbmode;\n   const tree_index kf_ymode_tree [2 * (num_ymodes -\
    \ 1)] =\n   {\n    -B_PRED, 2,            /* root: B_PRED = \"0\", \"1\" subtree\
    \ */\n     4, 6,                 /* \"1\" subtree has 2 descendant subtrees */\n\
    \      -DC_PRED, -V_PRED,   /* \"10\" subtree: DC_PRED = \"100\",\n          \
    \                    V_PRED = \"101\" */\n      -H_PRED, -TM_PRED    /* \"11\"\
    \ subtree: H_PRED = \"110\",\n                              TM_PRED = \"111\"\
    \ */\n   };\n   ---- End code block ----------------------------------------\n\
    \   For key frames, the Y mode is decoded using a fixed probability array\n  \
    \ as follows:\n   ---- Begin code block --------------------------------------\n\
    \   const Prob kf_ymode_prob [num_ymodes - 1] = { 145, 156, 163, 128};\n   Ymode\
    \ = (intra_mbmode) treed_read(d, kf_ymode_tree, kf_ymode_prob);\n   ---- End code\
    \ block ----------------------------------------\n   d is of course the bool_decoder\
    \ being used to read the first data\n   partition.\n   If the Ymode is B_PRED,\
    \ it is followed by a (tree-coded) mode for\n   each of the 16 Y subblocks.  The\
    \ 10 subblock modes and their coding\n   tree are as follows:\n   ---- Begin code\
    \ block --------------------------------------\n   typedef enum\n   {\n      \
    \ B_DC_PRED,  /* predict DC using row above and column\n                     \
    \ to the left */\n       B_TM_PRED,  /* propagate second differences a la\n  \
    \                    \"True Motion\" */\n       B_VE_PRED,  /* predict rows using\
    \ row above */\n       B_HE_PRED,  /* predict columns using column to the left\
    \ */\n       B_LD_PRED,  /* southwest (left and down) 45 degree diagonal\n   \
    \                   prediction */\n       B_RD_PRED,  /* southeast (right and\
    \ down) \"\" */\n       B_VR_PRED,  /* SSE (vertical right) diagonal prediction\
    \ */\n       B_VL_PRED,  /* SSW (vertical left) \"\" */\n       B_HD_PRED,  /*\
    \ ESE (horizontal down) \"\" */\n       B_HU_PRED,  /* ENE (horizontal up) \"\"\
    \ */\n       num_intra_bmodes\n   }\n   intra_bmode;\n   /* Coding tree for the\
    \ above, with implied codings as comments */\n   const tree_index bmode_tree [2\
    \ * (num_intra_bmodes - 1)] =\n   {\n    -B_DC_PRED, 2,                   /* B_DC_PRED\
    \ = \"0\" */\n     -B_TM_PRED, 4,                  /* B_TM_PRED = \"10\" */\n\
    \      -B_VE_PRED, 6,                 /* B_VE_PRED = \"110\" */\n       8, 12,\n\
    \        -B_HE_PRED, 10,              /* B_HE_PRED = \"11100\" */\n         -B_RD_PRED,\
    \ -B_VR_PRED,     /* B_RD_PRED = \"111010\",\n                               \
    \         B_VR_PRED = \"111011\" */\n        -B_LD_PRED, 14,              /* B_LD_PRED\
    \ = \"111110\" */\n          -B_VL_PRED, 16,            /* B_VL_PRED = \"1111110\"\
    \ */\n            -B_HD_PRED, -B_HU_PRED   /* HD = \"11111110\",\n           \
    \                             HU = \"11111111\" */\n   };\n   ---- End code block\
    \ ----------------------------------------\n   The first four modes are smaller\
    \ versions of the similarly named\n   16x16 modes above, albeit with slightly\
    \ different numbering.  The\n   last six \"diagonal\" modes are unique to luma\
    \ subblocks.\n"
- title: 11.3.  Subblock Mode Contexts
  contents:
  - "11.3.  Subblock Mode Contexts\n   The coding of subblock modes in key frames\
    \ uses the modes already\n   coded for the subblocks to the left of and above\
    \ the subblock to\n   select a probability array for decoding the current subblock\
    \ mode.\n   This is our first instance of contextual prediction, and there are\n\
    \   several caveats associated with it:\n   1.  The adjacency relationships between\
    \ subblocks are based on the\n       normal default raster placement of the subblocks.\n\
    \   2.  The adjacent subblocks need not lie in the current macroblock.\n     \
    \  The subblocks to the left of the left-edge subblocks 0, 4, 8, and\n       12\
    \ are the right-edge subblocks 3, 7, 11, and 15, respectively,\n       of the\
    \ (already coded) macroblock immediately to the left.\n       Similarly, the subblocks\
    \ above the top-edge subblocks 0, 1, 2,\n       and 3 are the bottom-edge subblocks\
    \ 12, 13, 14, and 15 of the\n       already-coded macroblock immediately above\
    \ us.\n   3.  For macroblocks on the top row or left edge of the image, some of\n\
    \       the predictors will be non-existent.  Such predictors are taken\n    \
    \   to have had the value B_DC_PRED, which, perhaps conveniently,\n       takes\
    \ the value 0 in the enumeration above.  A simple management\n       scheme for\
    \ these contexts might maintain a row of above\n       predictors and four left\
    \ predictors.  Before decoding the frame,\n       the entire row is initialized\
    \ to B_DC_PRED; before decoding each\n       row of macroblocks, the four left\
    \ predictors are also set to\n       B_DC_PRED.  After decoding a macroblock,\
    \ the bottom four subblock\n       modes are copied into the row predictor (at\
    \ the current position,\n       which then advances to be above the next macroblock),\
    \ and the\n       right four subblock modes are copied into the left predictor.\n\
    \   4.  Many macroblocks will of course be coded using a 16x16 luma\n       prediction\
    \ mode.  For the purpose of predicting ensuing subblock\n       modes (only),\
    \ such macroblocks derive a subblock mode, constant\n       throughout the macroblock,\
    \ from the 16x16 luma mode as follows:\n       DC_PRED uses B_DC_PRED, V_PRED\
    \ uses B_VE_PRED, H_PRED uses\n       B_HE_PRED, and TM_PRED uses B_TM_PRED.\n\
    \   5.  Although we discuss interframe modes in Section 16, we remark\n      \
    \ here that, while interframes do use all the intra-coding modes\n       described\
    \ here and below, the subblock modes in an interframe are\n       coded using\
    \ a single constant probability array that does not\n       depend on any context.\n\
    \   The dependence of subblock mode probability on the nearby subblock\n   mode\
    \ context is most easily handled using a three-dimensional\n   constant array:\n\
    \   ---- Begin code block --------------------------------------\n   const Prob\
    \ kf_bmode_prob [num_intra_bmodes] [num_intra_bmodes]\n     [num_intra_bmodes-1];\n\
    \   ---- End code block ----------------------------------------\n   The outer\
    \ two dimensions of this array are indexed by the already-\n   coded subblock\
    \ modes above and to the left of the current block,\n   respectively.  The inner\
    \ dimension is a typical tree probability list\n   whose indices correspond to\
    \ the even indices of the bmode_tree above.\n   The mode for the j^(th) luma subblock\
    \ is then\n   ---- Begin code block --------------------------------------\n \
    \  Bmode = (intra_bmode) treed_read(d, bmode_tree, kf_bmode_prob\n     [A] [L]);\n\
    \   ---- End code block ----------------------------------------\n   Where the\
    \ 4x4 Y subblock index j varies from 0 to 15 in raster order,\n   and A and L\
    \ are the modes used above and to the left of the j^(th)\n   subblock.\n   The\
    \ contents of the kf_bmode_prob array are given at the end of this\n   section.\n"
- title: 11.4.  Chroma Modes
  contents:
  - "11.4.  Chroma Modes\n   After the Y mode (and optional subblock mode) specification\
    \ comes the\n   chroma mode.  The chroma modes are a subset of the Y modes and\
    \ are\n   coded using the uv_mode_tree, as described in Section 8 and repeated\n\
    \   here for convenience:\n   ---- Begin code block --------------------------------------\n\
    \   const tree_index uv_mode_tree [2 * (num_uv_modes - 1)] =\n   {\n    -DC_PRED,\
    \ 2,           /* root: DC_PRED = \"0\", \"1\" subtree */\n     -V_PRED, 4,  \
    \         /* \"1\" subtree:  V_PRED = \"10\",\n                              \"\
    11\" subtree */\n      -H_PRED, -TM_PRED    /* \"11\" subtree: H_PRED = \"110\"\
    ,\n                              TM_PRED = \"111\" */\n   };\n   ---- End code\
    \ block ----------------------------------------\n   As for the Y modes (in a\
    \ key frame), the chroma modes are coded using\n   a fixed, contextless probability\
    \ table:\n   ---- Begin code block --------------------------------------\n  \
    \ const Prob kf_uv_mode_prob [num_uv_modes - 1] = { 142, 114, 183};\n   uv_mode\
    \ = (intra_mbmode) treed_read(d, uv_mode_tree,\n     kf_uv_mode_prob);\n   ----\
    \ End code block ----------------------------------------\n   This completes the\
    \ description of macroblock prediction coding for\n   key frames.  As will be\
    \ discussed in Section 16, the coding of intra\n   modes within interframes is\
    \ similar, but not identical, to that\n   described here (and in the reference\
    \ code) for prediction modes and,\n   indeed, for all tree-coded data in VP8.\n"
- title: 11.5.  Subblock Mode Probability Table
  contents:
  - "11.5.  Subblock Mode Probability Table\n   Finally, here is the fixed probability\
    \ table used to decode subblock\n   modes in key frames.\n   ---- Begin code block\
    \ --------------------------------------\n   const Prob kf_bmode_prob [num_intra_bmodes]\
    \ [num_intra_bmodes]\n     [num_intra_bmodes-1] =\n   {\n     {\n       { 231,\
    \ 120,  48,  89, 115, 113, 120, 152, 112},\n       { 152, 179,  64, 126, 170,\
    \ 118,  46,  70,  95},\n       { 175,  69, 143,  80,  85,  82,  72, 155, 103},\n\
    \       {  56,  58,  10, 171, 218, 189,  17,  13, 152},\n       { 144,  71,  10,\
    \  38, 171, 213, 144,  34,  26},\n       { 114,  26,  17, 163,  44, 195,  21,\
    \  10, 173},\n       { 121,  24,  80, 195,  26,  62,  44,  64,  85},\n       {\
    \ 170,  46,  55,  19, 136, 160,  33, 206,  71},\n       {  63,  20,   8, 114,\
    \ 114, 208,  12,   9, 226},\n       {  81,  40,  11,  96, 182,  84,  29,  16,\
    \  36}\n     },\n     {\n       { 134, 183,  89, 137,  98, 101, 106, 165, 148},\n\
    \       {  72, 187, 100, 130, 157, 111,  32,  75,  80},\n       {  66, 102, 167,\
    \  99,  74,  62,  40, 234, 128},\n       {  41,  53,   9, 178, 241, 141,  26,\
    \   8, 107},\n       { 104,  79,  12,  27, 217, 255,  87,  17,   7},\n       {\
    \  74,  43,  26, 146,  73, 166,  49,  23, 157},\n       {  65,  38, 105, 160,\
    \  51,  52,  31, 115, 128},\n       {  87,  68,  71,  44, 114,  51,  15, 186,\
    \  23},\n       {  47,  41,  14, 110, 182, 183,  21,  17, 194},\n       {  66,\
    \  45,  25, 102, 197, 189,  23,  18,  22}\n     },\n     {\n       {  88,  88,\
    \ 147, 150,  42,  46,  45, 196, 205},\n       {  43,  97, 183, 117,  85,  38,\
    \  35, 179,  61},\n       {  39,  53, 200,  87,  26,  21,  43, 232, 171},\n  \
    \     {  56,  34,  51, 104, 114, 102,  29,  93,  77},\n       { 107,  54,  32,\
    \  26,  51,   1,  81,  43,  31},\n       {  39,  28,  85, 171,  58, 165,  90,\
    \  98,  64},\n       {  34,  22, 116, 206,  23,  34,  43, 166,  73},\n       {\
    \  68,  25, 106,  22,  64, 171,  36, 225, 114},\n       {  34,  19,  21, 102,\
    \ 132, 188,  16,  76, 124},\n       {  62,  18,  78,  95,  85,  57,  50,  48,\
    \  51}\n     },\n     {\n       { 193, 101,  35, 159, 215, 111,  89,  46, 111},\n\
    \       {  60, 148,  31, 172, 219, 228,  21,  18, 111},\n       { 112, 113,  77,\
    \  85, 179, 255,  38, 120, 114},\n       {  40,  42,   1, 196, 245, 209,  10,\
    \  25, 109},\n       { 100,  80,   8,  43, 154,   1,  51,  26,  71},\n       {\
    \  88,  43,  29, 140, 166, 213,  37,  43, 154},\n       {  61,  63,  30, 155,\
    \  67,  45,  68,   1, 209},\n       { 142,  78,  78,  16, 255, 128,  34, 197,\
    \ 171},\n       {  41,  40,   5, 102, 211, 183,   4,   1, 221},\n       {  51,\
    \  50,  17, 168, 209, 192,  23,  25,  82}\n     },\n     {\n       { 125,  98,\
    \  42,  88, 104,  85, 117, 175,  82},\n       {  95,  84,  53,  89, 128, 100,\
    \ 113, 101,  45},\n       {  75,  79, 123,  47,  51, 128,  81, 171,   1},\n  \
    \     {  57,  17,   5,  71, 102,  57,  53,  41,  49},\n       { 115,  21,   2,\
    \  10, 102, 255, 166,  23,   6},\n       {  38,  33,  13, 121,  57,  73,  26,\
    \   1,  85},\n       {  41,  10,  67, 138,  77, 110,  90,  47, 114},\n       {\
    \ 101,  29,  16,  10,  85, 128, 101, 196,  26},\n       {  57,  18,  10, 102,\
    \ 102, 213,  34,  20,  43},\n       { 117,  20,  15,  36, 163, 128,  68,   1,\
    \  26}\n     },\n     {\n       { 138,  31,  36, 171,  27, 166,  38,  44, 229},\n\
    \       {  67,  87,  58, 169,  82, 115,  26,  59, 179},\n       {  63,  59,  90,\
    \ 180,  59, 166,  93,  73, 154},\n       {  40,  40,  21, 116, 143, 209,  34,\
    \  39, 175},\n       {  57,  46,  22,  24, 128,   1,  54,  17,  37},\n       {\
    \  47,  15,  16, 183,  34, 223,  49,  45, 183},\n       {  46,  17,  33, 183,\
    \   6,  98,  15,  32, 183},\n       {  65,  32,  73, 115,  28, 128,  23, 128,\
    \ 205},\n       {  40,   3,   9, 115,  51, 192,  18,   6, 223},\n       {  87,\
    \  37,   9, 115,  59,  77,  64,  21,  47}\n     },\n     {\n       { 104,  55,\
    \  44, 218,   9,  54,  53, 130, 226},\n       {  64,  90,  70, 205,  40,  41,\
    \  23,  26,  57},\n       {  54,  57, 112, 184,   5,  41,  38, 166, 213},\n  \
    \     {  30,  34,  26, 133, 152, 116,  10,  32, 134},\n       {  75,  32,  12,\
    \  51, 192, 255, 160,  43,  51},\n       {  39,  19,  53, 221,  26, 114,  32,\
    \  73, 255},\n       {  31,   9,  65, 234,   2,  15,   1, 118,  73},\n       {\
    \  88,  31,  35,  67, 102,  85,  55, 186,  85},\n       {  56,  21,  23, 111,\
    \  59, 205,  45,  37, 192},\n       {  55,  38,  70, 124,  73, 102,   1,  34,\
    \  98}\n     },\n     {\n       { 102,  61,  71,  37,  34,  53,  31, 243, 192},\n\
    \       {  69,  60,  71,  38,  73, 119,  28, 222,  37},\n       {  68,  45, 128,\
    \  34,   1,  47,  11, 245, 171},\n       {  62,  17,  19,  70, 146,  85,  55,\
    \  62,  70},\n       {  75,  15,   9,   9,  64, 255, 184, 119,  16},\n       {\
    \  37,  43,  37, 154, 100, 163,  85, 160,   1},\n       {  63,   9,  92, 136,\
    \  28,  64,  32, 201,  85},\n       {  86,   6,  28,   5,  64, 255,  25, 248,\
    \   1},\n       {  56,   8,  17, 132, 137, 255,  55, 116, 128},\n       {  58,\
    \  15,  20,  82, 135,  57,  26, 121,  40}\n     },\n     {\n       { 164,  50,\
    \  31, 137, 154, 133,  25,  35, 218},\n       {  51, 103,  44, 131, 131, 123,\
    \  31,   6, 158},\n       {  86,  40,  64, 135, 148, 224,  45, 183, 128},\n  \
    \     {  22,  26,  17, 131, 240, 154,  14,   1, 209},\n       {  83,  12,  13,\
    \  54, 192, 255,  68,  47,  28},\n       {  45,  16,  21,  91,  64, 222,   7,\
    \   1, 197},\n       {  56,  21,  39, 155,  60, 138,  23, 102, 213},\n       {\
    \  85,  26,  85,  85, 128, 128,  32, 146, 171},\n       {  18,  11,   7,  63,\
    \ 144, 171,   4,   4, 246},\n       {  35,  27,  10, 146, 174, 171,  12,  26,\
    \ 128}\n     },\n     {\n       { 190,  80,  35,  99, 180,  80, 126,  54,  45},\n\
    \       {  85, 126,  47,  87, 176,  51,  41,  20,  32},\n       { 101,  75, 128,\
    \ 139, 118, 146, 116, 128,  85},\n       {  56,  41,  15, 176, 236,  85,  37,\
    \   9,  62},\n       { 146,  36,  19,  30, 171, 255,  97,  27,  20},\n       {\
    \  71,  30,  17, 119, 118, 255,  17,  18, 138},\n       { 101,  38,  60, 138,\
    \  55,  70,  43,  26, 142},\n       { 138,  45,  61,  62, 219,   1,  81, 188,\
    \  64},\n       {  32,  41,  20, 117, 151, 142,  20,  21, 163},\n       { 112,\
    \  19,  12,  61, 195, 128,  48,   4,  24}\n     }\n   };\n   ---- End code block\
    \ ----------------------------------------\n"
- title: 12.  Intraframe Prediction
  contents:
  - "12.  Intraframe Prediction\n   Intraframe prediction uses already-coded macroblocks\
    \ within the\n   current frame to approximate the contents of the current macroblock.\n\
    \   It applies to intra-coded macroblocks in an interframe and to all\n   macroblocks\
    \ in a key frame.\n   Relative to the current macroblock \"M\", the already-coded\
    \ macroblocks\n   include all macroblocks above M together with the macroblocks\
    \ on the\n   same row as, and to the left of, M, though at most four of these\n\
    \   macroblocks are actually used: the block \"A\" directly above M, the\n   blocks\
    \ immediately to the left and right of A, and the block\n   immediately to the\
    \ left of M.\n   Each of the prediction modes (i.e., means of extrapolation from\n\
    \   already-calculated values) uses fairly simple arithmetic on pixel\n   values\
    \ whose positions, relative to the current position, are defined\n   by the mode.\n\
    \   The chroma (U and V) and luma (Y) predictions are independent of each\n  \
    \ other.\n   The relative addressing of pixels applied to macroblocks on the upper\n\
    \   row or left column of the frame will sometimes cause pixels outside\n   the\
    \ visible frame to be referenced.  Usually such out-of-bounds\n   pixels have\
    \ an assumed value of 129 for pixels to the left of the\n   leftmost column of\
    \ the visible frame and 127 for pixels above the top\n   row of the visible frame\
    \ (including the special case of the pixel\n   above and to the left of the top-left\
    \ pixel in the visible frame).\n   Exceptions to this (associated to certain modes)\
    \ will be noted below.\n   The already-coded macroblocks referenced by intra-prediction\
    \ have\n   been \"reconstructed\", that is, have been predicted and residue-\n\
    \   adjusted (as described in Section 14), but have not been loop-\n   filtered.\
    \  While it does process the edges between individual\n   macroblocks and individual\
    \ subblocks, loop filtering (described in\n   Section 15) is applied to the frame\
    \ as a whole, after all of the\n   macroblocks have been reconstructed.\n"
- title: 12.1.  mb_skip_coeff
  contents:
  - "12.1.  mb_skip_coeff\n   The single bool flag is decoded using prob_skip_false\
    \ if and only if\n   mb_no_skip_coeff is set to 1 (see Sections 9.10 and 9.11).\
    \  If\n   mb_no_skip_coeff is set to 0, then this value defaults to 0.\n"
- title: 12.2.  Chroma Prediction
  contents:
  - "12.2.  Chroma Prediction\n   The chroma prediction is a little simpler than the\
    \ luma prediction,\n   so we treat it first.  Each of the chroma modes treats\
    \ U and V\n   identically; that is, the U and V prediction values are calculated\
    \ in\n   parallel, using the same relative addressing and arithmetic in each\n\
    \   of the two planes.\n   The modes extrapolate prediction values using the 8-pixel\
    \ row \"A\"\n   lying immediately above the block (that is, the bottom chroma\
    \ row of\n   the macroblock immediately above the current macroblock) and the\n\
    \   8-pixel column \"L\" immediately to the left of the block (that is, the\n\
    \   rightmost chroma column of the macroblock immediately to the left of\n   the\
    \ current macroblock).\n   Vertical prediction (chroma mode V_PRED) simply fills\
    \ each 8-pixel\n   row of the 8x8 chroma block with a copy of the \"above\" row\
    \ (A).  If\n   the current macroblock lies on the top row of the frame, all 8\
    \ of the\n   pixel values in A are assigned the value 127.\n   Similarly, horizontal\
    \ prediction (H_PRED) fills each 8-pixel column\n   of the 8x8 chroma block with\
    \ a copy of the \"left\" column (L).  If the\n   current macroblock is in the\
    \ left column of the frame, all 8 pixel\n   values in L are assigned the value\
    \ 129.\n   DC prediction (DC_PRED) fills the 8x8 chroma block with a single\n\
    \   value.  In the generic case of a macroblock lying below the top row\n   and\
    \ right of the leftmost column of the frame, this value is the\n   average of\
    \ the 16 (genuinely visible) pixels in the (union of the)\n   above row A and\
    \ left column L.\n   Otherwise, if the current macroblock lies on the top row\
    \ of the\n   frame, the average of the 8 pixels in L is used; if it lies in the\n\
    \   left column of the frame, the average of the 8 pixels in A is used.\n   Note\
    \ that the averages used in these exceptional cases are not the\n   same as those\
    \ that would be arrived at by using the out-of-bounds A\n   and L values defined\
    \ for V_PRED and H_PRED.  In the case of the\n   leftmost macroblock on the top\
    \ row of the frame, the 8x8 block is\n   simply filled with the constant value\
    \ 128.\n   For DC_PRED, apart from the exceptional case of the top-left\n   macroblock,\
    \ we are averaging either 16 or 8 pixel values to get a\n   single prediction\
    \ value that fills the 8x8 block.  The rounding is\n   done as follows:\n   ----\
    \ Begin code block --------------------------------------\n   int sum;  /* sum\
    \ of 8 or 16 pixels at (at least) 16-bit precision */\n   int shf;  /* base 2\
    \ logarithm of the number of pixels (3 or 4) */\n   Pixel DCvalue = (sum + (1\
    \ << (shf-1))) >> shf;\n   ---- End code block ----------------------------------------\n\
    \   Because the summands are all valid pixels, no \"clamp\" is necessary in\n\
    \   the calculation of DCvalue.\n   The remaining \"True Motion\" (TM_PRED) chroma\
    \ mode gets its name from\n   an older technique of video compression used by\
    \ On2 Technologies, to\n   which it bears some relation.  In addition to the row\
    \ \"A\" and column\n   \"L\", TM_PRED uses the pixel \"P\" above and to the left\
    \ of the chroma\n   block.\n   The following figure gives an example of how TM_PRED\
    \ works:\n   ---- Begin code block --------------------------------------\n  \
    \ |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n   | P   | A0  | A1\
    \  | A2  | A3  | A4  | A5  | A6  | A7  |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L0  | X00 | X01 | X02 | X03 | X04 | X05 | X06 | X07 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L1  | X10 | X11 | X12 | X13 | X14 | X15 | X16 | X17 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L2  | X20 | X21 | X22 | X23 | X24 | X25 | X26 | X27 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L3  | X30 | X31 | X32 | X33 | X34 | X35 | X36 | X37 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L4  | X40 | X41 | X42 | X43 | X44 | X45 | X46 | X47 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L5  | X50 | X51 | X52 | X53 | X54 | X55 | X56 | X57 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L6  | X60 | X61 | X62 | X63 | X64 | X65 | X66 | X67 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   | L7  | X70 | X71 | X72 | X73 | X74 | X75 | X76 | X77 |\n   |-----|-----|-----|-----|-----|-----|-----|-----|-----|\n\
    \   ---- End code block ----------------------------------------\n   Where P,\
    \ As, and Ls represent reconstructed pixel values from\n   previously coded blocks,\
    \ and X00 through X77 represent predicted\n   values for the current block.  TM_PRED\
    \ uses the following equation to\n   calculate X_ij:\n   X_ij = L_i + A_j - P\
    \ (i, j=0, 1, 2, 3)\n   The exact algorithm is as follows:\n   ---- Begin code\
    \ block --------------------------------------\n   void TMpred(\n       Pixel\
    \ b[8][8],      /* chroma (U or V) prediction block */\n       const Pixel A[8],\
    \   /* row of already-constructed pixels\n                              above\
    \ block */\n       const Pixel L[8],   /* column of \"\" just to the left of\n\
    \                              block */\n       const Pixel P       /* pixel just\
    \ to the left of A and\n                              above L*/\n   ) {\n    \
    \   int r = 0;          /* row */\n       do {\n           int c = 0;      /*\
    \ column */\n           do {\n               b[r][c] = clamp255(L[r]+ A[c] - P);\n\
    \           } while (++c < 8);\n       } while (++r < 8);\n   }\n   ---- End code\
    \ block ----------------------------------------\n   Note that the process could\
    \ equivalently be described as propagating\n   the vertical differences between\
    \ pixels in L (starting from P), using\n   the pixels from A to start each column.\n\
    \   An implementation of chroma intra-prediction may be found in the\n   reference\
    \ decoder file predict.c (Section 20.14).\n   Unlike DC_PRED, for macroblocks\
    \ on the top row or left edge, TM_PRED\n   does use the out-of-bounds values of\
    \ 127 and 129 (respectively)\n   defined for V_PRED and H_PRED.\n"
- title: 12.3.  Luma Prediction
  contents:
  - "12.3.  Luma Prediction\n   The prediction processes for the first four 16x16\
    \ luma modes\n   (DC_PRED, V_PRED, H_PRED, and TM_PRED) are essentially identical\
    \ to\n   the corresponding chroma prediction processes described above, the\n\
    \   only difference being that we are predicting a single 16x16 luma\n   block\
    \ instead of two 8x8 chroma blocks.\n   Thus, the row \"A\" and column \"L\" here\
    \ contain 16 pixels, the DC\n   prediction is calculated using 16 or 32 pixels\
    \ (and shf is 4 or 5),\n   and we of course fill the entire prediction buffer,\
    \ that is, 16 rows\n   (or columns) containing 16 pixels each.  The reference\
    \ implementation\n   of 16x16 luma prediction is also in predict.c.\n   In the\
    \ remaining luma mode (B_PRED), each 4x4 Y subblock is\n   independently predicted\
    \ using one of ten modes (listed, along with\n   their encodings, in Section 11).\n\
    \   Also, unlike the full-macroblock modes already described, some of the\n  \
    \ subblock modes use prediction pixels above and to the right of the\n   current\
    \ subblock.  In detail, each 4x4 subblock \"B\" is predicted\n   using (at most)\
    \ the 4-pixel column \"L\" immediately to the left of B\n   and the 8-pixel row\
    \ \"A\" immediately above B, consisting of the 4\n   pixels above B followed by\
    \ the 4 adjacent pixels above and to the\n   right of B, together with the single\
    \ pixel \"P\" immediately to the\n   left of A (and immediately above L).\n  \
    \ For the purpose of subblock intra-prediction, the pixels immediately\n   to\
    \ the left and right of a pixel in a subblock are the same as the\n   pixels immediately\
    \ to the left and right of the corresponding pixel\n   in the frame buffer \"\
    F\".  Vertical offsets behave similarly: The\n   above row A lies immediately\
    \ above B in F, and the adjacent pixels in\n   the left column L are separated\
    \ by a single row in F.\n   Because entire macroblocks (as opposed to their constituent\n\
    \   subblocks) are reconstructed in raster-scan order, for subblocks\n   lying\
    \ along the right edge (and not along the top row) of the current\n   macroblock,\
    \ the four \"extra\" prediction pixels in A above and to the\n   right of B have\
    \ not yet actually been constructed.\n   Subblocks 7, 11, and 15 are affected.\
    \  All three of these subblocks\n   use the same extra pixels as does subblock\
    \ 3 (at the upper right\n   corner of the macroblock), namely the 4 pixels immediately\
    \ above and\n   to the right of subblock 3.  Writing (R,C) for a frame buffer\n\
    \   position offset from the upper left corner of the current macroblock\n   by\
    \ R rows and C columns, the extra pixels for all the right-edge\n   subblocks\
    \ (3, 7, 11, and 15) are at positions (-1,16), (-1,17),\n   (-1,18), and (-1,19).\
    \  For the rightmost macroblock in each\n   macroblock row except the top row,\
    \ the extra pixels shall use the\n   same value as the pixel at position (-1,15),\
    \ which is the rightmost\n   visible pixel on the line immediately above the macroblock\
    \ row.  For\n   the top macroblock row, all the extra pixels assume a value of\
    \ 127.\n   The details of the prediction modes are most easily described in\n\
    \   code.\n   ---- Begin code block --------------------------------------\n \
    \  /* Result pixels are often averages of two or three predictor\n      pixels.\
    \  The following subroutines are used to calculate\n      these averages.  Because\
    \ the arguments are valid pixels, no\n      clamping is necessary.  An actual\
    \ implementation would\n      probably use inline functions or macros. */\n  \
    \ /* Compute weighted average centered at y w/adjacent x, z */\n   Pixel avg3(Pixel\
    \ x, Pixel y, Pixel z) {\n     return (x + y + y + z + 2) >> 2;}\n   /* Weighted\
    \ average of 3 adjacent pixels centered at p */\n   Pixel avg3p(const Pixel *p)\
    \ { return avg3(p[-1], p[0], p[1]);}\n   /* Simple average of x and y */\n   Pixel\
    \ avg2(Pixel x, Pixel y) { return (x + y + 1) >> 1;}\n   /* Average of p[0] and\
    \ p[1] may be considered to be a synthetic\n      pixel lying between the two,\
    \ that is, one half-step past p. */\n   Pixel avg2p(const Pixel *p) { return avg2(p[0],\
    \ p[1]);}\n   void subblock_intra_predict(\n       Pixel B[4][4],     /* Y subblock\
    \ prediction buffer */\n       const Pixel *A,    /* A[0]...A[7] = above row,\
    \ A[-1] = P */\n       const Pixel *L,    /* L[0]...L[3] = left column, L[-1]\
    \ = P */\n       intra_bmode mode   /* enum is in Section 11.2 */\n   ) {\n  \
    \     Pixel E[9];        /* 9 already-constructed edge pixels */\n       E[0]\
    \ = L[3];  E[1] = L[2];  E[2] = L[1];  E[3] = L[0];\n       E[4] = A[-1];    \
    \  /* == L[-1] == P */\n       E[5] = A[0];  E[6] = A[1];  E[7] = A[2];  E[8]\
    \ = A[3];\n     switch(mode) {\n       /* First four modes are similar to corresponding\n\
    \          full-block modes. */\n       case B_DC_PRED:\n       {\n          \
    \ int v = 4;      /* DC sum/avg, 4 is rounding adjustment */\n           int i\
    \ = 0;  do { v += A[i] + L[i];}  while (++i < 4);\n           v >>= 3;       \
    \ /* averaging 8 pixels */\n           i = 0;  do {    /* fill prediction buffer\
    \ with constant DC\n                              value */\n               int\
    \ j = 0;  do { B[i][j] = v;}  while (++j < 4);\n           } while (++i < 4);\n\
    \           break;\n       }\n       case B_TM_PRED: /* just like 16x16 TM_PRED\
    \ */\n       {\n           int r = 0;  do {\n               int c = 0;  do {\n\
    \                   B[r][c] = clamp255(L[r] + A[c] - A[-1]);\n               }\
    \ while (++c < 4);\n           } while (++r < 4);\n           break;\n       }\n\
    \       case B_VE_PRED: /* like 16x16 V_PRED except using averages */\n      \
    \ {\n           int c = 0;  do { /* all 4 rows = smoothed top row */\n       \
    \        B[0][c] = B[1][c] = B[2][c] = B[3][c] = avg3p(A + c);\n           } while\
    \ (++c < 4);\n           break;\n       }\n       case B_HE_PRED: /* like 16x16\
    \ H_PRED except using averages */\n       {\n           /* Bottom row is exceptional\
    \ because L[4] does not exist */\n           int v = avg3(L[2], L[3], L[3]);\n\
    \           int r = 3;  while (1) {  /* all 4 columns = smoothed left\n      \
    \                                 column */\n               B[r][0] = B[r][1]\
    \ = B[r][2] = B[r][3] = v;\n               if (--r < 0)\n                   break;\n\
    \               v = avg3p(L + r);  /* upper 3 rows use average of\n          \
    \                            3 pixels */\n           }\n           break;\n  \
    \     }\n       /* The remaining six \"diagonal\" modes subdivide the\n      \
    \    prediction buffer into diagonal lines.  All the pixels\n          on each\
    \ line are assigned the same value; this value is\n          (a smoothed or synthetic\
    \ version of) an\n          already-constructed predictor value lying on the same\n\
    \          line.  For clarity, in the comments, we express the\n          positions\
    \ of these predictor pixels relative to the\n          upper left corner of the\
    \ destination array B.\n          These modes are unique to subblock prediction\
    \ and have\n          no full-block analogs.  The first two use lines at\n   \
    \       +|- 45 degrees from horizontal (or, equivalently,\n          vertical),\
    \ that is, lines whose slopes are +|- 1. */\n       case B_LD_PRED:    /* southwest\
    \ (left and down) step =\n                             (-1, 1) or (1,-1) */\n\
    \           /* avg3p(A + j) is the \"smoothed\" pixel at (-1,j) */\n         \
    \  B[0][0] = avg3p(A + 1);\n           B[0][1] = B[1][0] = avg3p(A + 2);\n   \
    \        B[0][2] = B[1][1] = B[2][0] = avg3p(A + 3);\n           B[0][3] = B[1][2]\
    \ = B[2][1] = B[3][0] = avg3p(A + 4);\n           B[1][3] = B[2][2] = B[3][1]\
    \ = avg3p(A + 5);\n           B[2][3] = B[3][2] = avg3p(A + 6);\n           B[3][3]\
    \ = avg3(A[6], A[7], A[7]); /* A[8] does not exist */\n           break;\n   \
    \    case B_RD_PRED: /* southeast (right and down) step =\n                  \
    \        (1,1) or (-1,-1) */\n           B[3][0] = avg3p(E + 1);  /* predictor\
    \ is from (2, -1) */\n           B[3][1] = B[2][0] = avg3p(E + 2);  /* (1, -1)\
    \ */\n           B[3][2] = B[2][1] = B[1][0] = avg3p(E + 3);  /* (0, -1) */\n\
    \           B[3][3] = B[2][2] = B[1][1] = B[0][0] =\n             avg3p(E + 4);\
    \  /* (-1, -1) */\n           B[2][3] = B[1][2] = B[0][1] = avg3p(E + 5);  /*\
    \ (-1, 0) */\n           B[1][3] = B[0][2] = avg3p(E + 6);  /* (-1, 1) */\n  \
    \         B[0][3] = avg3p(E + 7);  /* (-1, 2) */\n           break;\n       /*\
    \ The remaining 4 diagonal modes use lines whose slopes are\n          +|- 2 and\
    \ +|- 1/2.  The angles of these lines are roughly\n          +|- 27 degrees from\
    \ horizontal or vertical.\n          Unlike the 45 degree diagonals, here we often\
    \ need to\n          \"synthesize\" predictor pixels midway between two actual\n\
    \          predictors using avg2p(p), which we think of as returning\n       \
    \   the pixel \"at\" p[1/2]. */\n       case B_VR_PRED:    /* SSE (vertical right)\
    \ step =\n                             (2,1) or (-2,-1) */\n           B[3][0]\
    \ = avg3p(E + 2);  /* predictor is from (1, -1) */\n           B[2][0] = avg3p(E\
    \ + 3);  /* (0, -1) */\n           B[3][1] = B[1][0] = avg3p(E + 4);  /* (-1,\
    \   -1) */\n           B[2][1] = B[0][0] = avg2p(E + 4);  /* (-1, -1/2) */\n \
    \          B[3][2] = B[1][1] = avg3p(E + 5);  /* (-1,    0) */\n           B[2][2]\
    \ = B[0][1] = avg2p(E + 5);  /* (-1,  1/2) */\n           B[3][3] = B[1][2] =\
    \ avg3p(E + 6);  /* (-1,    1) */\n           B[2][3] = B[0][2] = avg2p(E + 6);\
    \  /* (-1,  3/2) */\n           B[1][3] = avg3p(E + 7);  /* (-1, 2) */\n     \
    \      B[0][3] = avg2p(E + 7);  /* (-1, 5/2) */\n           break;\n       case\
    \ B_VL_PRED:    /* SSW (vertical left) step =\n                             (2,-1)\
    \ or (-2,1) */\n           B[0][0] = avg2p(A);  /* predictor is from (-1, 1/2)\
    \ */\n           B[1][0] = avg3p(A + 1);  /* (-1, 1) */\n           B[2][0] =\
    \ B[0][1] = avg2p(A + 1);  /* (-1, 3/2) */\n           B[1][1] = B[3][0] = avg3p(A\
    \ + 2);  /* (-1,   2) */\n           B[2][1] = B[0][2] = avg2p(A + 2);  /* (-1,\
    \ 5/2) */\n           B[3][1] = B[1][2] = avg3p(A + 3);  /* (-1,   3) */\n   \
    \        B[2][2] = B[0][3] = avg2p(A + 3);  /* (-1, 7/2) */\n           B[3][2]\
    \ = B[1][3] = avg3p(A + 4);  /* (-1,   4) */\n           /* Last two values do\
    \ not strictly follow the pattern. */\n           B[2][3] = avg3p(A + 5);  /*\
    \ (-1, 5) [avg2p(A + 4) =\n                                        (-1,9/2)] */\n\
    \           B[3][3] = avg3p(A + 6);  /* (-1, 6) [avg3p(A + 5) =\n            \
    \                            (-1,5)] */\n           break;\n       case B_HD_PRED:\
    \    /* ESE (horizontal down) step =\n                             (1,2) or (-1,-2)\
    \ */\n           B[3][0] = avg2p(E);  /* predictor is from (5/2, -1) */\n    \
    \       B[3][1] = avg3p(E + 1);  /* (2, -1) */\n           B[2][0] = B[3][2] =\
    \ svg2p(E + 1);  /* ( 3/2, -1) */\n           B[2][1] = B[3][3] = avg3p(E + 2);\
    \  /* (   1, -1) */\n           B[2][2] = B[1][0] = avg2p(E + 2);  /* ( 1/2, -1)\
    \ */\n           B[2][3] = B[1][1] = avg3p(E + 3);  /* (   0, -1) */\n       \
    \    B[1][2] = B[0][0] = avg2p(E + 3);  /* (-1/2, -1) */\n           B[1][3] =\
    \ B[0][1] = avg3p(E + 4);  /* (  -1, -1) */\n           B[0][2] = avg3p(E + 5);\
    \  /* (-1, 0) */\n           B[0][3] = avg3p(E + 6);  /* (-1, 1) */\n        \
    \   break;\n       case B_HU_PRED:    /* ENE (horizontal up) step = (1,-2)\n \
    \                            or (-1,2) */\n           B[0][0] = avg2p(L);  /*\
    \ predictor is from (1/2, -1) */\n           B[0][1] = avg3p(L + 1);  /* (1, -1)\
    \ */\n           B[0][2] = B[1][0] = avg2p(L + 1);  /* (3/2, -1) */\n        \
    \   B[0][3] = B[1][1] = avg3p(L + 2);  /* (  2, -1) */\n           B[1][2] = B[2][0]\
    \ = avg2p(L + 2);  /* (5/2, -1) */\n           B[1][3] = B[2][1] = avg3(L[2],\
    \ L[3], L[3]);  /* (3, -1) */\n           /* Not possible to follow pattern for\
    \ much of the bottom\n              row because no (nearby) already-constructed\
    \ pixels lie\n              on the diagonals in question. */\n           B[2][2]\
    \ = B[2][3] = B[3][0] = B[3][1] = B[3][2] = B[3][3]\n             = L[3];\n  \
    \   }\n   }\n   ---- End code block ----------------------------------------\n\
    \   The reference decoder implementation of subblock intra-prediction may\n  \
    \ be found in predict.c (Section 20.14).\n"
- title: 13.  DCT Coefficient Decoding
  contents:
  - "13.  DCT Coefficient Decoding\n   The second data partition consists of an encoding\
    \ of the quantized\n   DCT (and WHT) coefficients of the residue signal.  As discussed\
    \ in\n   the format overview (Section 2), for each macroblock, the residue is\n\
    \   added to the (intra- or inter-generated) prediction buffer to produce\n  \
    \ the final (except for loop filtering) reconstructed macroblock.\n   VP8 works\
    \ exclusively with 4x4 DCTs and WHTs, applied to the 24 (or\n   25 with the Y2\
    \ subblock) 4x4 subblocks of a macroblock.  The ordering\n   of macroblocks within\
    \ any of the \"residue\" partitions in general\n   follows the same raster scan\
    \ as used in the first \"prediction\"\n   partition.\n   For all intra- and inter-prediction\
    \ modes apart from B_PRED (intra:\n   whose Y subblocks are independently predicted)\
    \ and SPLITMV (inter),\n   each macroblock's residue record begins with the Y2\
    \ component of the\n   residue, coded using a WHT.  B_PRED and SPLITMV coded macroblocks\n\
    \   omit this WHT and specify the 0th DCT coefficient in each of the 16 Y\n  \
    \ subblocks.\n   After the optional Y2 block, the residue record continues with\
    \ 16\n   DCTs for the Y subblocks, followed by 4 DCTs for the U subblocks,\n \
    \  ending with 4 DCTs for the V subblocks.  The subblocks occur in the\n   usual\
    \ order.\n   The DCTs and WHT are tree-coded using a 12-element alphabet whose\n\
    \   members we call \"tokens\".  Except for the end-of-block token (which\n  \
    \ sets the remaining subblock coefficients to zero and is followed by\n   the\
    \ next block), each token (sometimes augmented with data\n   immediately following\
    \ the token) specifies the value of the single\n   coefficient at the current\
    \ (implicit) position and is followed by a\n   token applying to the next (implicit)\
    \ position.\n   For all the Y and chroma subblocks, the ordering of the coefficients\n\
    \   follows a so-called zig-zag order.  DCTs begin at coefficient 1 if Y2\n  \
    \ is present, and begin at coefficient 0 if Y2 is absent.  The WHT for\n   a Y2\
    \ subblock always begins at coefficient 0.\n"
- title: 13.1.  Macroblock without Non-Zero Coefficient Values
  contents:
  - "13.1.  Macroblock without Non-Zero Coefficient Values\n   If the flag within\
    \ macroblock (MB) MODE_INFO indicates that a\n   macroblock does not have any\
    \ non-zero coefficients, the decoding\n   process of DCT coefficients is skipped\
    \ for the macroblock.\n"
- title: 13.2.  Coding of Individual Coefficient Values
  contents:
  - "13.2.  Coding of Individual Coefficient Values\n   The coding of coefficient\
    \ tokens is the same for the DCT and WHT, and\n   for the remainder of this section\
    \ \"DCT\" should be taken to mean\n   either DCT or WHT.\n   All tokens (except\
    \ end-of-block) specify either a single unsigned\n   value or a range of unsigned\
    \ values (immediately) followed by a\n   simple probabilistic encoding of the\
    \ offset of the value from the\n   base of that range.\n   Non-zero values (of\
    \ either type) are then followed by a flag\n   indicating the sign of the coded\
    \ value (negative if 1, positive\n   if 0).\n   Below are the tokens and decoding\
    \ tree.\n   ---- Begin code block --------------------------------------\n   typedef\
    \ enum\n   {\n       DCT_0,      /* value 0 */\n       DCT_1,      /* 1 */\n \
    \      DCT_2,      /* 2 */\n       DCT_3,      /* 3 */\n       DCT_4,      /*\
    \ 4 */\n       dct_cat1,   /* range 5 - 6  (size 2) */\n       dct_cat2,   /*\
    \ 7 - 10   (4) */\n       dct_cat3,   /* 11 - 18  (8) */\n       dct_cat4,   /*\
    \ 19 - 34  (16) */\n       dct_cat5,   /* 35 - 66  (32) */\n       dct_cat6, \
    \  /* 67 - 2048  (1982) */\n       dct_eob,    /* end of block */\n       num_dct_tokens\
    \   /* 12 */\n   }\n   dct_token;\n   const tree_index coeff_tree [2 * (num_dct_tokens\
    \ - 1)] =\n   {\n    -dct_eob, 2,               /* eob = \"0\"   */\n     -DCT_0,\
    \ 4,                /* 0   = \"10\"  */\n      -DCT_1, 6,               /* 1 \
    \  = \"110\" */\n       8, 12,\n        -DCT_2, 10,            /* 2   = \"11100\"\
    \ */\n         -DCT_3, -DCT_4,       /* 3   = \"111010\", 4 = \"111011\" */\n\
    \        14, 16,\n         -dct_cat1, -dct_cat2, /* cat1 =  \"111100\",\n    \
    \                              cat2 = \"111101\" */\n        18, 20,\n       \
    \  -dct_cat3, -dct_cat4, /* cat3 = \"1111100\",\n                            \
    \      cat4 = \"1111101\" */\n         -dct_cat5, -dct_cat6  /* cat4 = \"1111110\"\
    ,\n                                  cat4 = \"1111111\" */\n   };\n   ---- End\
    \ code block ----------------------------------------\n   In general, all DCT\
    \ coefficients are decoded using the same tree.\n   However, if the preceding\
    \ coefficient is a DCT_0, decoding will skip\n   the first branch, since it is\
    \ not possible for dct_eob to follow a\n   DCT_0.\n   The tokens dct_cat1 ...\
    \ dct_cat6 specify ranges of unsigned values,\n   the value within the range being\
    \ formed by adding an unsigned offset\n   (whose width is 1, 2, 3, 4, 5, or 11\
    \ bits, respectively) to the base\n   of the range, using the following algorithm\
    \ and fixed probability\n   tables.\n   ---- Begin code block --------------------------------------\n\
    \   uint DCTextra(bool_decoder *d, const Prob *p)\n   {\n       uint v = 0;\n\
    \       do { v += v + read_bool(d, *p);}  while (*++p);\n       return v;\n  \
    \ }\n   const Prob Pcat1[] = { 159, 0};\n   const Prob Pcat2[] = { 165, 145, 0};\n\
    \   const Prob Pcat3[] = { 173, 148, 140, 0};\n   const Prob Pcat4[] = { 176,\
    \ 155, 140, 135, 0};\n   const Prob Pcat5[] = { 180, 157, 141, 134, 130, 0};\n\
    \   const Prob Pcat6[] =\n       { 254, 254, 243, 230, 196, 177, 153, 140, 133,\
    \ 130, 129, 0};\n   ---- End code block ----------------------------------------\n\
    \   If v -- the unsigned value decoded using the coefficient tree,\n   possibly\
    \ augmented by the process above -- is non-zero, its sign is\n   set by simply\
    \ reading a flag:\n   ---- Begin code block --------------------------------------\n\
    \   if (read_bool(d, 128))\n       v = -v;\n   ---- End code block ----------------------------------------\n"
- title: 13.3.  Token Probabilities
  contents:
  - "13.3.  Token Probabilities\n   The probability specification for the token tree\
    \ (unlike that for the\n   \"extra bits\" described above) is rather involved.\
    \  It uses three\n   pieces of context to index a large probability table, the\
    \ contents of\n   which may be incrementally modified in the frame header.  The\
    \ full\n   (non-constant) probability table is laid out as follows.\n   ---- Begin\
    \ code block --------------------------------------\n   Prob coeff_probs [4] [8]\
    \ [3] [num_dct_tokens-1];\n   ---- End code block ----------------------------------------\n\
    \   Working from the outside in, the outermost dimension is indexed by\n   the\
    \ type of plane being decoded:\n   o  0 - Y beginning at coefficient 1 (i.e.,\
    \ Y after Y2)\n   o  1 - Y2\n   o  2 - U or V\n   o  3 - Y beginning at coefficient\
    \ 0 (i.e., Y in the absence of Y2).\n   The next dimension is selected by the\
    \ position of the coefficient\n   being decoded.  That position, c, steps by ones\
    \ up to 15, starting\n   from zero for block types 1, 2, or 3 and starting from\
    \ one for block\n   type 0.  The second array index is then\n   ---- Begin code\
    \ block --------------------------------------\n   coeff_bands [c]\n   ---- End\
    \ code block ----------------------------------------\n   Where:\n   ---- Begin\
    \ code block --------------------------------------\n   const int coeff_bands\
    \ [16] = {\n        0, 1, 2, 3, 6, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7\n   };\n  \
    \ ---- End code block ----------------------------------------\n   is a fixed\
    \ mapping of position to \"band\".\n   The third dimension is the trickiest. \
    \ Roughly speaking, it measures\n   the \"local complexity\" or extent to which\
    \ nearby coefficients are\n   non-zero.\n   For the first coefficient (DC, unless\
    \ the block type is 0), we\n   consider the (already encoded) blocks within the\
    \ same plane (Y2, Y,\n   U, or V) above and to the left of the current block.\
    \  The context\n   index is then the number (0, 1, or 2) of these blocks that\
    \ had at\n   least one non-zero coefficient in their residue record.  Specifically\n\
    \   for Y2, because macroblocks above and to the left may or may not have\n  \
    \ a Y2 block, the block above is determined by the most recent\n   macroblock\
    \ in the same column that has a Y2 block, and the block to\n   the left is determined\
    \ by the most recent macroblock in the same row\n   that has a Y2 block.\n   Beyond\
    \ the first coefficient, the context index is determined by the\n   absolute value\
    \ of the most recently decoded coefficient (necessarily\n   within the current\
    \ block) and is 0 if the last coefficient was a\n   zero, 1 if it was plus or\
    \ minus one, and 2 if its absolute value\n   exceeded one.\n   Note that the intuitive\
    \ meaning of this measure changes as\n   coefficients are decoded.  For example,\
    \ prior to the first token, a\n   zero means that the neighbors are empty, suggesting\
    \ that the current\n   block may also be empty.  After the first token, because\
    \ an end-of-\n   block token must have at least one non-zero value before it,\
    \ a zero\n   means that we just decoded a zero and hence guarantees that a\n \
    \  non-zero coefficient will appear later in this block.  However, this\n   shift\
    \ in meaning is perfectly okay because the complete context\n   depends also on\
    \ the coefficient band (and since band 0 is occupied\n   exclusively by position\
    \ 0).\n   As with other contexts used by VP8, the \"neighboring block\" context\n\
    \   described here needs a special definition for subblocks lying along\n   the\
    \ top row or left edge of the frame.  These \"non-existent\"\n   predictors above\
    \ and to the left of the image are simply taken to be\n   empty -- that is, taken\
    \ to contain no non-zero coefficients.\n   The residue decoding of each macroblock\
    \ then requires, in each of two\n   directions (above and to the left), an aggregate\
    \ coefficient\n   predictor consisting of a single Y2 predictor, two predictors\
    \ for\n   each of U and V, and four predictors for Y.  In accordance with the\n\
    \   scan-ordering of macroblocks, a decoder needs to maintain a single\n   \"\
    left\" aggregate predictor and a row of \"above\" aggregate predictors.\n   Before\
    \ decoding any residue, these maintained predictors may simply\n   be cleared,\
    \ in compliance with the definition of \"non-existent\"\n   prediction.  After\
    \ each block is decoded, the two predictors\n   referenced by the block are replaced\
    \ with the (empty or non-empty)\n   state of the block, in preparation for the\
    \ later decoding of the\n   blocks below and to the right of the block just decoded.\n\
    \   The fourth, and final, dimension of the token probability array is of\n  \
    \ course indexed by (half) the position in the token tree structure, as\n   are\
    \ all tree probability arrays.\n   The pseudocode below illustrates the decoding\
    \ process.  Note that\n   criteria, functions, etc. delimited with ** are either\
    \ dependent on\n   decoder architecture or are elaborated on elsewhere in this\
    \ document.\n   ---- Begin code block --------------------------------------\n\
    \   int block[16] = { 0 }; /* current 4x4 block coeffs */\n   int firstCoeff =\
    \ 0;\n   int plane;\n   int ctx2;\n   int ctx3 = 0; /* the 3rd context referred\
    \ to in above description */\n   Prob *probTable;\n   int token;\n   int sign;\n\
    \   int absValue;\n   int extraBits;\n   bool prevCoeffWasZero = false;\n   bool\
    \ currentBlockHasCoeffs = false;\n   /* base coeff abs values per each category,\
    \ elem #0 is\n      DCT_VAL_CATEGORY1, * #1 is DCT_VAL_CATEGORY2, etc. */\n  \
    \ int categoryBase[6] = { 5, 7, 11, 19, 35, 67 };\n   /* Determine plane to use\
    \ */\n   if ( **current_block_is_Y2_block** )       plane = 0;\n   else if ( **current_block_is_chroma**\
    \ )   plane = 2;\n   else if ( **current_macroblock_has_Y2** ) plane = 1;\n  \
    \ else                                      plane = 3;\n   /* For luma blocks\
    \ of a \"Y2 macroblock\" we skip coeff index #0 */\n   if ( plane == 1 )\n   \
    \    firstCoeff++;\n   /* Determine whether neighbor 4x4 blocks have coefficients.\n\
    \      This is dependent on the plane we are currently decoding;\n      i.e.,\
    \ we check only coefficients from the same plane as the\n      current block.\
    \ */\n   if ( **left_neighbor_block_has_coefficients(plane)** )\n       ctx3++;\n\
    \   if ( **above_neighbor_block_has_coefficients(plane)** )\n       ctx3++;\n\
    \   for( i = firstCoeff; i < 16; ++i )\n   {\n       ctx2 = coeff_bands[i];\n\
    \       probTable = coeff_probs[plane][ctx2][ctx3];\n       /* skip first code\
    \ (dct_eob) if previous token was DCT_0 */\n       if ( prevCoeffWasZero )\n \
    \          token = treed_read ( d, **coeff_tree_without_eob**,\n             probTable\
    \ );\n       else\n           token = treed_read ( d, coeff_tree, probTable );\n\
    \       if ( token == dct_eob )\n           break;\n       if ( token != DCT_0\
    \ )\n       {\n           currentBlockHasCoeffs = true;\n     if ( **token_has_extra_bits(token)**\
    \ )\n     {\n         extraBits = DCTextra( token );\n         absValue =\n  \
    \           categoryBase[**token_to_cat_index(token)**] +\n       extraBits;\n\
    \     }\n     else\n     {\n         absValue = **token_to_abs_value(token)**;\n\
    \     }\n     sign = read_bool(d, 128);\n           block[i] = sign ? -absValue\
    \ : absValue;\n       }\n       else\n       {\n           absValue = 0;\n   \
    \    }\n       /* Set contexts and stuff for next coeff */\n       if ( absValue\
    \ == 0 )         ctx3 = 0;\n       else if ( absValue == 1 )   ctx3 = 1;\n   \
    \    else                        ctx3 = 2;\n       prevCoeffWasZero = true;\n\
    \   }\n   /* Store current block status to decoder internals */\n   **block_has_coefficients[currentMb][currentBlock]**\
    \ =\n     currentBlockHasCoeffs;\n   ---- End code block ----------------------------------------\n\
    \   While we have in fact completely described the coefficient decoding\n   procedure,\
    \ the reader will probably find it helpful to consult the\n   reference implementation,\
    \ which can be found in the file tokens.c\n   (Section 20.16).\n"
- title: 13.4.  Token Probability Updates
  contents:
  - "13.4.  Token Probability Updates\n   As mentioned above, the token-decoding probabilities\
    \ may change from\n   frame to frame.  After detection of a key frame, they are\
    \ of course\n   set to their defaults as shown in Section 13.5; this must occur\n\
    \   before decoding the remainder of the header, as both key frames and\n   interframes\
    \ may adjust these probabilities.\n   The layout and semantics of the coefficient\
    \ probability update record\n   (Section I of the frame header) are straightforward.\
    \  For each\n   position in the coeff_probs array there occurs a fixed-probability\n\
    \   bool indicating whether or not the corresponding probability should\n   be\
    \ updated.  If the bool is true, there follows a P(8) replacing that\n   probability.\
    \  Note that updates are cumulative; that is, a\n   probability updated on one\
    \ frame is in effect for all ensuing frames\n   until the next key frame, or until\
    \ the probability is explicitly\n   updated by another frame.\n   The algorithm\
    \ to effect the foregoing is simple:\n   ---- Begin code block --------------------------------------\n\
    \   int i = 0;  do {\n    int j = 0;  do {\n     int k = 0;  do {\n      int t\
    \ = 0;  do {\n           if (read_bool(d, coeff_update_probs [i] [j] [k] [t]))\n\
    \               coeff_probs [i] [j] [k] [t] = read_literal(d, 8);\n      } while\
    \ (++t < num_dct_tokens - 1);\n     } while (++k < 3);\n    } while (++j < 8);\n\
    \   } while (++i < 4);\n   ---- End code block ----------------------------------------\n\
    \   The (constant) update probabilities are as follows:\n   ---- Begin code block\
    \ --------------------------------------\n   const Prob coeff_update_probs [4]\
    \ [8] [3] [num_dct_tokens-1] =\n   {\n    {\n     {\n      { 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255}\n     },\n     {\n      { 176, 246, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n      { 223, 241, 252, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 249, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n   \
    \  {\n      { 255, 244, 252, 255, 255, 255, 255, 255, 255, 255, 255},\n      {\
    \ 234, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 253, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 246,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 239, 253, 254, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 254, 255, 254, 255, 255, 255, 255, 255,\
    \ 255, 255, 255}\n     },\n     {\n      { 255, 248, 254, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n      { 251, 255, 254, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n    \
    \ },\n     {\n      { 255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 251, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 254,\
    \ 255, 254, 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      {\
    \ 255, 254, 253, 255, 254, 255, 255, 255, 255, 255, 255},\n      { 250, 255, 254,\
    \ 255, 254, 255, 255, 255, 255, 255, 255},\n      { 254, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n\
    \     }\n    },\n    {\n     {\n      { 217, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n      { 225, 252, 241, 253, 255, 255, 254, 255, 255, 255, 255},\n\
    \      { 234, 250, 241, 250, 253, 255, 253, 254, 255, 255, 255}\n     },\n   \
    \  {\n      { 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      {\
    \ 223, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 238, 253, 254,\
    \ 254, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 248,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 249, 254, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255}\n     },\n     {\n      { 255, 253, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n      { 247, 254, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n    \
    \ },\n     {\n      { 255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      {\
    \ 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 253, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 254, 253, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 250, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n      { 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n\
    \     },\n     {\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n     }\n    },\n    {\n \
    \    {\n      { 186, 251, 250, 255, 255, 255, 255, 255, 255, 255, 255},\n    \
    \  { 234, 251, 244, 254, 255, 255, 255, 255, 255, 255, 255},\n      { 251, 251,\
    \ 243, 253, 254, 255, 254, 255, 255, 255, 255}\n     },\n     {\n      { 255,\
    \ 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 236, 253, 254, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n      { 251, 253, 253, 254, 254, 255, 255,\
    \ 255, 255, 255, 255}\n     },\n     {\n      { 255, 254, 254, 255, 255, 255,\
    \ 255, 255, 255, 255, 255},\n      { 254, 254, 254, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n\
    \     },\n     {\n      { 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 254,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      {\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 254, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n\
    \     },\n     {\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      {\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255}\n     }\n    },\n    {\n     {\n      { 248, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n      { 250, 254, 252, 254, 255, 255,\
    \ 255, 255, 255, 255, 255},\n      { 248, 254, 249, 253, 255, 255, 255, 255, 255,\
    \ 255, 255}\n     },\n     {\n      { 255, 253, 253, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n      { 246, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 252, 254, 251, 254, 254, 255, 255, 255, 255, 255, 255}\n     },\n   \
    \  {\n      { 255, 254, 252, 255, 255, 255, 255, 255, 255, 255, 255},\n      {\
    \ 248, 254, 253, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 253, 255, 254,\
    \ 254, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 251,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 245, 251, 254, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 253, 253, 254, 255, 255, 255, 255, 255,\
    \ 255, 255, 255}\n     },\n     {\n      { 255, 251, 253, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n      { 252, 253, 254, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n      { 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n    \
    \ },\n     {\n      { 255, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \      { 249, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255,\
    \ 255, 254, 255, 255, 255, 255, 255, 255, 255, 255}\n     },\n     {\n      {\
    \ 255, 255, 253, 255, 255, 255, 255, 255, 255, 255, 255},\n      { 250, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255}\n     },\n     {\n      { 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n      { 254, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n      { 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}\n\
    \     }\n    }\n   };\n   ---- End code block ----------------------------------------\n"
- title: 13.5.  Default Token Probability Table
  contents:
  - "13.5.  Default Token Probability Table\n   The default token probabilities are\
    \ as follows.\n   ---- Begin code block --------------------------------------\n\
    \   const Prob default_coeff_probs [4] [8] [3] [num_dct_tokens - 1] =\n   {\n\
    \    {\n     {\n      { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},\n\
    \      { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},\n      { 128,\
    \ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128}\n     },\n     {\n      {\
    \ 253, 136, 254, 255, 228, 219, 128, 128, 128, 128, 128},\n      { 189, 129, 242,\
    \ 255, 227, 213, 255, 219, 128, 128, 128},\n      { 106, 126, 227, 252, 214, 209,\
    \ 255, 255, 128, 128, 128}\n     },\n     {\n      {   1,  98, 248, 255, 236,\
    \ 226, 255, 255, 128, 128, 128},\n      { 181, 133, 238, 254, 221, 234, 255, 154,\
    \ 128, 128, 128},\n      {  78, 134, 202, 247, 198, 180, 255, 219, 128, 128, 128}\n\
    \     },\n     {\n      {   1, 185, 249, 255, 243, 255, 128, 128, 128, 128, 128},\n\
    \      { 184, 150, 247, 255, 236, 224, 128, 128, 128, 128, 128},\n      {  77,\
    \ 110, 216, 255, 236, 230, 128, 128, 128, 128, 128}\n     },\n     {\n      {\
    \   1, 101, 251, 255, 241, 255, 128, 128, 128, 128, 128},\n      { 170, 139, 241,\
    \ 252, 236, 209, 255, 255, 128, 128, 128},\n      {  37, 116, 196, 243, 228, 255,\
    \ 255, 255, 128, 128, 128}\n     },\n     {\n      {   1, 204, 254, 255, 245,\
    \ 255, 128, 128, 128, 128, 128},\n      { 207, 160, 250, 255, 238, 128, 128, 128,\
    \ 128, 128, 128},\n      { 102, 103, 231, 255, 211, 171, 128, 128, 128, 128, 128}\n\
    \     },\n     {\n      {   1, 152, 252, 255, 240, 255, 128, 128, 128, 128, 128},\n\
    \      { 177, 135, 243, 255, 234, 225, 128, 128, 128, 128, 128},\n      {  80,\
    \ 129, 211, 255, 194, 224, 128, 128, 128, 128, 128}\n     },\n     {\n      {\
    \   1,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128},\n      { 246,   1, 255,\
    \ 128, 128, 128, 128, 128, 128, 128, 128},\n      { 255, 128, 128, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n     }\n    },\n    {\n     {\n      { 198,  35, 237,\
    \ 223, 193, 187, 162, 160, 145, 155,  62},\n      { 131,  45, 198, 221, 172, 176,\
    \ 220, 157, 252, 221,   1},\n      {  68,  47, 146, 208, 149, 167, 221, 162, 255,\
    \ 223, 128}\n     },\n     {\n      {   1, 149, 241, 255, 221, 224, 255, 255,\
    \ 128, 128, 128},\n      { 184, 141, 234, 253, 222, 220, 255, 199, 128, 128, 128},\n\
    \      {  81,  99, 181, 242, 176, 190, 249, 202, 255, 255, 128}\n     },\n   \
    \  {\n      {   1, 129, 232, 253, 214, 197, 242, 196, 255, 255, 128},\n      {\
    \  99, 121, 210, 250, 201, 198, 255, 202, 128, 128, 128},\n      {  23,  91, 163,\
    \ 242, 170, 187, 247, 210, 255, 255, 128}\n     },\n     {\n      {   1, 200,\
    \ 246, 255, 234, 255, 128, 128, 128, 128, 128},\n      { 109, 178, 241, 255, 231,\
    \ 245, 255, 255, 128, 128, 128},\n      {  44, 130, 201, 253, 205, 192, 255, 255,\
    \ 128, 128, 128}\n     },\n     {\n      {   1, 132, 239, 251, 219, 209, 255,\
    \ 165, 128, 128, 128},\n      {  94, 136, 225, 251, 218, 190, 255, 255, 128, 128,\
    \ 128},\n      {  22, 100, 174, 245, 186, 161, 255, 199, 128, 128, 128}\n    \
    \ },\n     {\n      {   1, 182, 249, 255, 232, 235, 128, 128, 128, 128, 128},\n\
    \      { 124, 143, 241, 255, 227, 234, 128, 128, 128, 128, 128},\n      {  35,\
    \  77, 181, 251, 193, 211, 255, 205, 128, 128, 128}\n     },\n     {\n      {\
    \   1, 157, 247, 255, 236, 231, 255, 255, 128, 128, 128},\n      { 121, 141, 235,\
    \ 255, 225, 227, 255, 255, 128, 128, 128},\n      {  45,  99, 188, 251, 195, 217,\
    \ 255, 224, 128, 128, 128}\n     },\n     {\n      {   1,   1, 251, 255, 213,\
    \ 255, 128, 128, 128, 128, 128},\n      { 203,   1, 248, 255, 255, 128, 128, 128,\
    \ 128, 128, 128},\n      { 137,   1, 177, 255, 224, 255, 128, 128, 128, 128, 128}\n\
    \     }\n    },\n    {\n     {\n      { 253,   9, 248, 251, 207, 208, 255, 192,\
    \ 128, 128, 128},\n      { 175,  13, 224, 243, 193, 185, 249, 198, 255, 255, 128},\n\
    \      {  73,  17, 171, 221, 161, 179, 236, 167, 255, 234, 128}\n     },\n   \
    \  {\n      {   1,  95, 247, 253, 212, 183, 255, 255, 128, 128, 128},\n      {\
    \ 239,  90, 244, 250, 211, 209, 255, 255, 128, 128, 128},\n      { 155,  77, 195,\
    \ 248, 188, 195, 255, 255, 128, 128, 128}\n     },\n     {\n      {   1,  24,\
    \ 239, 251, 218, 219, 255, 205, 128, 128, 128},\n      { 201,  51, 219, 255, 196,\
    \ 186, 128, 128, 128, 128, 128},\n      {  69,  46, 190, 239, 201, 218, 255, 228,\
    \ 128, 128, 128}\n     },\n     {\n      {   1, 191, 251, 255, 255, 128, 128,\
    \ 128, 128, 128, 128},\n      { 223, 165, 249, 255, 213, 255, 128, 128, 128, 128,\
    \ 128},\n      { 141, 124, 248, 255, 255, 128, 128, 128, 128, 128, 128}\n    \
    \ },\n     {\n      {   1,  16, 248, 255, 255, 128, 128, 128, 128, 128, 128},\n\
    \      { 190,  36, 230, 255, 236, 255, 128, 128, 128, 128, 128},\n      { 149,\
    \   1, 255, 128, 128, 128, 128, 128, 128, 128, 128}\n     },\n     {\n      {\
    \   1, 226, 255, 128, 128, 128, 128, 128, 128, 128, 128},\n      { 247, 192, 255,\
    \ 128, 128, 128, 128, 128, 128, 128, 128},\n      { 240, 128, 255, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n     },\n     {\n      {   1, 134, 252, 255, 255,\
    \ 128, 128, 128, 128, 128, 128},\n      { 213,  62, 250, 255, 255, 128, 128, 128,\
    \ 128, 128, 128},\n      {  55,  93, 255, 128, 128, 128, 128, 128, 128, 128, 128}\n\
    \     },\n     {\n      { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},\n\
    \      { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},\n      { 128,\
    \ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128}\n     }\n    },\n    {\n \
    \    {\n      { 202,  24, 213, 235, 186, 191, 220, 160, 240, 175, 255},\n    \
    \  { 126,  38, 182, 232, 169, 184, 228, 174, 255, 187, 128},\n      {  61,  46,\
    \ 138, 219, 151, 178, 240, 170, 255, 216, 128}\n     },\n     {\n      {   1,\
    \ 112, 230, 250, 199, 191, 247, 159, 255, 255, 128},\n      { 166, 109, 228, 252,\
    \ 211, 215, 255, 174, 128, 128, 128},\n      {  39,  77, 162, 232, 172, 180, 245,\
    \ 178, 255, 255, 128}\n     },\n     {\n      {   1,  52, 220, 246, 198, 199,\
    \ 249, 220, 255, 255, 128},\n      { 124,  74, 191, 243, 183, 193, 250, 221, 255,\
    \ 255, 128},\n      {  24,  71, 130, 219, 154, 170, 243, 182, 255, 255, 128}\n\
    \     },\n     {\n      {   1, 182, 225, 249, 219, 240, 255, 224, 128, 128, 128},\n\
    \      { 149, 150, 226, 252, 216, 205, 255, 171, 128, 128, 128},\n      {  28,\
    \ 108, 170, 242, 183, 194, 254, 223, 255, 255, 128}\n     },\n     {\n      {\
    \   1,  81, 230, 252, 204, 203, 255, 192, 128, 128, 128},\n      { 123, 102, 209,\
    \ 247, 188, 196, 255, 233, 128, 128, 128},\n      {  20,  95, 153, 243, 164, 173,\
    \ 255, 203, 128, 128, 128}\n     },\n     {\n      {   1, 222, 248, 255, 216,\
    \ 213, 128, 128, 128, 128, 128},\n      { 168, 175, 246, 252, 235, 205, 255, 255,\
    \ 128, 128, 128},\n      {  47, 116, 215, 255, 211, 212, 255, 255, 128, 128, 128}\n\
    \     },\n     {\n      {   1, 121, 236, 253, 212, 214, 255, 255, 128, 128, 128},\n\
    \      { 141,  84, 213, 252, 201, 202, 255, 219, 128, 128, 128},\n      {  42,\
    \  80, 160, 240, 162, 185, 255, 205, 128, 128, 128}\n     },\n     {\n      {\
    \   1,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128},\n      { 244,   1, 255,\
    \ 128, 128, 128, 128, 128, 128, 128, 128},\n      { 238,   1, 255, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n     }\n    }\n   };\n   ---- End code block ----------------------------------------\n"
- title: 14.  DCT and WHT Inversion and Macroblock Reconstruction
  contents:
  - '14.  DCT and WHT Inversion and Macroblock Reconstruction

    '
- title: 14.1.  Dequantization
  contents:
  - "14.1.  Dequantization\n   After decoding the DCTs/WHTs as described above, each\
    \ (quantized)\n   coefficient in each subblock is multiplied by one of six\n \
    \  dequantization factors, the choice of factor depending on the plane\n   (Y2,\
    \ Y, or chroma) and position (DC = coefficient zero, AC = any\n   other coefficient).\
    \  If the current macroblock has overridden the\n   quantizer level (as described\
    \ in Section 10), then the six factors\n   are looked up from two dequantization\
    \ tables with appropriate scaling\n   and clamping using the single index supplied\
    \ by the override.\n   Otherwise, the frame-level dequantization factors (as described\
    \ in\n   Section 9.6) are used.  In either case, the multiplies are computed\n\
    \   and stored using 16-bit signed integers.\n   The two dequantization tables,\
    \ which may also be found in the\n   reference decoder file dequant_data.h (Section\
    \ 20.3), are as follows.\n   ---- Begin code block --------------------------------------\n\
    \   static const int dc_qlookup[QINDEX_RANGE] =\n   {\n       4,   5,   6,   7,\
    \   8,   9,  10,  10,   11,  12,  13,  14,  15,\n      16,  17,  17,  18,  19,\
    \  20,  20,  21,   21,  22,  22,  23,  23,\n      24,  25,  25,  26,  27,  28,\
    \  29,  30,   31,  32,  33,  34,  35,\n      36,  37,  37,  38,  39,  40,  41,\
    \  42,   43,  44,  45,  46,  46,\n      47,  48,  49,  50,  51,  52,  53,  54,\
    \   55,  56,  57,  58,  59,\n      60,  61,  62,  63,  64,  65,  66,  67,   68,\
    \  69,  70,  71,  72,\n      73,  74,  75,  76,  76,  77,  78,  79,   80,  81,\
    \  82,  83,  84,\n      85,  86,  87,  88,  89,  91,  93,  95,   96,  98, 100,\
    \ 101, 102,\n      104, 106, 108, 110, 112, 114, 116, 118, 122, 124, 126, 128,\
    \ 130,\n      132, 134, 136, 138, 140, 143, 145, 148, 151, 154, 157,\n   };\n\
    \   static const int ac_qlookup[QINDEX_RANGE] =\n   {\n       4,   5,   6,   7,\
    \   8,   9,  10,  11,  12,  13,  14,  15,  16,\n      17,  18,  19,  20,  21,\
    \  22,  23,  24,  25,  26,  27,  28,  29,\n      30,  31,  32,  33,  34,  35,\
    \  36,  37,  38,  39,  40,  41,  42,\n      43,  44,  45,  46,  47,  48,  49,\
    \  50,  51,  52,  53,  54,  55,\n      56,  57,  58,  60,  62,  64,  66,  68,\
    \  70,  72,  74,  76,  78,\n      80,  82,  84,  86,  88,  90,  92,  94,  96,\
    \  98, 100, 102, 104,\n     106, 108, 110, 112, 114, 116, 119, 122, 125, 128,\
    \ 131, 134, 137,\n     140, 143, 146, 149, 152, 155, 158, 161, 164, 167, 170,\
    \ 173, 177,\n     181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225,\
    \ 229,\n     234, 239, 245, 249, 254, 259, 264, 269, 274, 279, 284,\n   };\n \
    \  ---- End code block ----------------------------------------\n   Lookup values\
    \ from the above two tables are directly used in the DC\n   and AC coefficients\
    \ in Y1, respectively.  For Y2 and chroma, values\n   from the above tables undergo\
    \ either scaling or clamping before the\n   multiplies.  Details regarding these\
    \ scaling and clamping processes\n   can be found in related lookup functions\
    \ in dixie.c (Section 20.4).\n"
- title: 14.2.  Inverse Transforms
  contents:
  - "14.2.  Inverse Transforms\n   If the Y2 residue block exists (i.e., the macroblock\
    \ luma mode is not\n   SPLITMV or B_PRED), it is inverted first (using the inverse\
    \ WHT) and\n   the element of the result at row i, column j is used as the 0th\n\
    \   coefficient of the Y subblock at position (i, j), that is, the Y\n   subblock\
    \ whose index is (i * 4) + j.  As discussed in Section 13, if\n   the luma mode\
    \ is B_PRED or SPLITMV, the 0th Y coefficients are part\n   of the residue signal\
    \ for the subblocks themselves.\n   In either case, the inverse transforms for\
    \ the sixteen Y subblocks\n   and eight chroma subblocks are computed next.  All\
    \ 24 of these\n   inversions are independent of each other; their results may\
    \ (at least\n   conceptually) be stored in 24 separate 4x4 arrays.\n   As is done\
    \ by the reference decoder, an implementation may wish to\n   represent the prediction\
    \ and residue buffers as macroblock-sized\n   arrays (that is, a 16x16 Y buffer\
    \ and two 8x8 chroma buffers).\n   Regarding the inverse DCT implementation given\
    \ below, this requires a\n   simple adjustment to the address calculation for\
    \ the resulting\n   residue pixels.\n"
- title: 14.3.  Implementation of the WHT Inversion
  contents:
  - "14.3.  Implementation of the WHT Inversion\n   As previously discussed (see Sections\
    \ 2 and 13), for macroblocks\n   encoded using prediction modes other than B_PRED\
    \ and SPLITMV, the DC\n   values derived from the DCT transform on the 16 Y blocks\
    \ are\n   collected to construct a 25th block of a macroblock (16 Y, 4 U, 4 V\n\
    \   constitute the 24 blocks).  This 25th block is transformed using a\n   Walsh-Hadamard\
    \ transform (WHT).\n   The inputs to the inverse WHT (that is, the dequantized\n\
    \   coefficients), the intermediate \"horizontally detransformed\" signal,\n \
    \  and the completely detransformed residue signal are all stored as\n   arrays\
    \ of 16-bit signed integers.\n   Following the tradition of specifying bitstream\
    \ format using the\n   decoding process, we specify the inverse WHT in the decoding\
    \ process\n   using the following C-style source code:\n   ---- Begin code block\
    \ --------------------------------------\n   void vp8_short_inv_walsh4x4_c(short\
    \ *input, short *output)\n   {\n     int i;\n     int a1, b1, c1, d1;\n     int\
    \ a2, b2, c2, d2;\n     short *ip = input;\n     short *op = output;\n     int\
    \ temp1, temp2;\n     for(i=0;i<4;i++)\n     {\n       a1 = ip[0] + ip[12];\n\
    \       b1 = ip[4] + ip[8];\n       c1 = ip[4] - ip[8];\n       d1 = ip[0] - ip[12];\n\
    \       op[0] = a1 + b1;\n       op[4] = c1 + d1;\n       op[8] = a1 - b1;\n \
    \      op[12]= d1 - c1;\n       ip++;\n       op++;\n     }\n     ip = output;\n\
    \     op = output;\n     for(i=0;i<4;i++)\n     {\n       a1 = ip[0] + ip[3];\n\
    \       b1 = ip[1] + ip[2];\n       c1 = ip[1] - ip[2];\n       d1 = ip[0] - ip[3];\n\
    \       a2 = a1 + b1;\n       b2 = c1 + d1;\n       c2 = a1 - b1;\n       d2 =\
    \ d1 - c1;\n       op[0] = (a2+3)>>3;\n       op[1] = (b2+3)>>3;\n       op[2]\
    \ = (c2+3)>>3;\n       op[3] = (d2+3)>>3;\n       ip+=4;\n       op+=4;\n    \
    \ }\n   }\n   ---- End code block ----------------------------------------\n \
    \  In the case that there is only one non-zero DC value in input, the\n   inverse\
    \ transform can be simplified to the following:\n   ---- Begin code block --------------------------------------\n\
    \   void vp8_short_inv_walsh4x4_1_c(short *input, short *output)\n   {\n     int\
    \ i;\n     int a1;\n     short *op=output;\n     a1 = ((input[0] + 3)>>3);\n \
    \    for(i=0;i<4;i++)\n     {\n       op[0] = a1;\n       op[1] = a1;\n      \
    \ op[2] = a1;\n       op[3] = a1;\n       op+=4;\n     }\n   }\n   ---- End code\
    \ block ----------------------------------------\n   It should be noted that a\
    \ conforming decoder should implement the\n   inverse transform using exactly\
    \ the same rounding to achieve bit-wise\n   matching output to the output of the\
    \ process specified by the above\n   C source code.\n   The reference decoder\
    \ WHT inversion may be found in the file\n   idct_add.c (Section 20.8).\n"
- title: 14.4.  Implementation of the DCT Inversion
  contents:
  - "14.4.  Implementation of the DCT Inversion\n   All of the DCT inversions are\
    \ computed in exactly the same way.  In\n   principle, VP8 uses a classical 2-D\
    \ inverse discrete cosine\n   transform, implemented as two passes of 1-D inverse\
    \ DCT.  The 1-D\n   inverse DCT was calculated using a similar algorithm to what\
    \ was\n   described in [Loeffler].  However, the paper only provided the\n   8-point\
    \ and 16-point version of the algorithms, which was adapted by\n   On2 to perform\
    \ the 4-point 1-D DCT.\n   Accurate calculation of 1-D DCT of the above algorithm\
    \ requires\n   infinite precision.  VP8 of course can use only a finite-precision\n\
    \   approximation.  Also, the inverse DCT used by VP8 takes care of\n   normalization\
    \ of the standard unitary transform; that is, every\n   dequantized coefficient\
    \ has roughly double the size of the\n   corresponding unitary coefficient.  However,\
    \ at all but the highest\n   datarates, the discrepancy between transmitted and\
    \ ideal coefficients\n   is due almost entirely to (lossy) compression and not\
    \ to errors\n   induced by finite-precision arithmetic.\n   The inputs to the\
    \ inverse DCT (that is, the dequantized\n   coefficients), the intermediate \"\
    horizontally detransformed\" signal,\n   and the completely detransformed residue\
    \ signal are all stored as\n   arrays of 16-bit signed integers.  The details\
    \ of the computation are\n   as follows.\n   It should also be noted that this\
    \ implementation makes use of the\n   16-bit fixed-point version of two multiplication\
    \ constants:\n   sqrt(2) * cos (pi/8)\n   sqrt(2) * sin (pi/8)\n   Because the\
    \ first constant is bigger than 1, to maintain the same\n   16-bit fixed-point\
    \ precision as the second one, we make use of the\n   fact that\n   x * a = x\
    \ + x*(a-1)\n   therefore\n   x * sqrt(2) * cos (pi/8) = x + x * (sqrt(2) * cos(pi/8)-1)\n\
    \   ---- Begin code block --------------------------------------\n   /* IDCT implementation\
    \ */\n   static const int cospi8sqrt2minus1=20091;\n   static const int sinpi8sqrt2\
    \      =35468;\n   void short_idct4x4llm_c(short *input, short *output, int pitch)\n\
    \   {\n     int i;\n     int a1, b1, c1, d1;\n     short *ip=input;\n     short\
    \ *op=output;\n     int temp1, temp2;\n     int shortpitch = pitch>>1;\n     for(i=0;i<4;i++)\n\
    \     {\n       a1 = ip[0]+ip[8];\n       b1 = ip[0]-ip[8];\n       temp1 = (ip[4]\
    \ * sinpi8sqrt2)>>16;\n       temp2 = ip[12]+((ip[12] * cospi8sqrt2minus1)>>16);\n\
    \       c1 = temp1 - temp2;\n       temp1 = ip[4] + ((ip[4] * cospi8sqrt2minus1)>>16);\n\
    \       temp2 = (ip[12] * sinpi8sqrt2)>>16;\n       d1 = temp1 + temp2;\n    \
    \   op[shortpitch*0] = a1+d1;\n       op[shortpitch*3] = a1-d1;\n       op[shortpitch*1]\
    \ = b1+c1;\n       op[shortpitch*2] = b1-c1;\n       ip++;\n       op++;\n   \
    \  }\n     ip = output;\n     op = output;\n     for(i=0;i<4;i++)\n     {\n  \
    \     a1 = ip[0]+ip[2];\n       b1 = ip[0]-ip[2];\n       temp1 = (ip[1] * sinpi8sqrt2)>>16;\n\
    \       temp2 = ip[3]+((ip[3] * cospi8sqrt2minus1)>>16);\n       c1 = temp1 -\
    \ temp2;\n       temp1 = ip[1] + ((ip[1] * cospi8sqrt2minus1)>>16);\n       temp2\
    \ = (ip[3] * sinpi8sqrt2)>>16;\n       d1 = temp1 + temp2;\n       op[0] = (a1+d1+4)>>3;\n\
    \       op[3] = (a1-d1+4)>>3;\n       op[1] = (b1+c1+4)>>3;\n       op[2] = (b1-c1+4)>>3;\n\
    \       ip+=shortpitch;\n       op+=shortpitch;\n     }\n   }\n   ---- End code\
    \ block ----------------------------------------\n   The reference decoder DCT\
    \ inversion may be found in the file\n   idct_add.c (Section 20.8).\n"
- title: 14.5.  Summation of Predictor and Residue
  contents:
  - "14.5.  Summation of Predictor and Residue\n   Finally, the prediction and residue\
    \ signals are summed to form the\n   reconstructed macroblock, which, except for\
    \ loop filtering (taken up\n   next), completes the decoding process.\n   The\
    \ summing procedure is fairly straightforward, having only a couple\n   of details.\
    \  The prediction and residue buffers are both arrays of\n   16-bit signed integers.\
    \  Each individual (Y, U, and V pixel) result\n   is calculated first as a 32-bit\
    \ sum of the prediction and residue,\n   and is then saturated to 8-bit unsigned\
    \ range (using, say, the\n   clamp255 function defined above) before being stored\
    \ as an 8-bit\n   unsigned pixel value.\n   VP8 also supports a mode where the\
    \ encoding of a bitstream guarantees\n   all reconstructed pixel values between\
    \ 0 and 255; compliant\n   bitstreams of such requirements have the clamp_type\
    \ bit in the frame\n   header set to 1.  In such a case, the clamp255 function\
    \ is no longer\n   required.\n   The summation process is the same, regardless\
    \ of the (intra or inter)\n   mode of prediction in effect for the macroblock.\
    \  The reference\n   decoder implementation of reconstruction may be found in\
    \ the file\n   idct_add.c.\n"
- title: 15.  Loop Filter
  contents:
  - "15.  Loop Filter\n   Loop filtering is the last stage of frame reconstruction\
    \ and the\n   next-to-last stage of the decoding process.  The loop filter is\n\
    \   applied to the entire frame after the summation of predictor and\n   residue\
    \ signals, as described in Section 14.\n   The purpose of the loop filter is to\
    \ eliminate (or at least reduce)\n   visually objectionable artifacts associated\
    \ with the semi-\n   independence of the coding of macroblocks and their constituent\n\
    \   subblocks.\n   As was discussed in Section 5, the loop filter is \"integral\"\
    \ to\n   decoding, in that the results of loop filtering are used in the\n   prediction\
    \ of subsequent frames.  Consequently, a functional decoder\n   implementation\
    \ must perform loop filtering exactly as described here.\n   This is distinct\
    \ from any postprocessing that may be applied only to\n   the image immediately\
    \ before display; such postprocessing is entirely\n   at the option of the implementor\
    \ (and/or user) and has no effect on\n   decoding per se.\n   The baseline frame-level\
    \ parameters controlling the loop filter are\n   defined in the frame header (Section\
    \ 9.4) along with a mechanism for\n   adjustment based on a macroblock's prediction\
    \ mode and/or reference\n   frame.  The first is a flag (filter_type) selecting\
    \ the type of\n   filter (normal or simple); the other two are numbers\n   (loop_filter_level\
    \ and sharpness_level) that adjust the strength or\n   sensitivity of the filter.\
    \  As described in Sections 9.3 and 10,\n   loop_filter_level may also be overridden\
    \ on a per-macroblock basis\n   using segmentation.\n   Loop filtering is one\
    \ of the more computationally intensive aspects\n   of VP8 decoding.  This is\
    \ the reason for the existence of the\n   optional, less-demanding simple filter\
    \ type.\n   Note carefully that loop filtering must be skipped entirely if\n \
    \  loop_filter_level at either the frame header level or macroblock\n   override\
    \ level is 0.  In no case should the loop filter be run with a\n   value of 0;\
    \ it should instead be skipped.\n   We begin by discussing the aspects of loop\
    \ filtering that are\n   independent of the controlling parameters and type of\
    \ filter chosen.\n"
- title: 15.1.  Filter Geometry and Overall Procedure
  contents:
  - "15.1.  Filter Geometry and Overall Procedure\n   The Y, U, and V planes are processed\
    \ independently and identically.\n   The loop filter acts on the edges between\
    \ adjacent macroblocks and on\n   the edges between adjacent subblocks of a macroblock.\
    \  All such edges\n   are horizontal or vertical.  For each pixel position on\
    \ an edge, a\n   small number (two or three) of pixels adjacent to either side\
    \ of the\n   position are examined and possibly modified.  The displacements of\n\
    \   these pixels are at a right angle to the edge orientation; that is,\n   for\
    \ a horizontal edge, we treat the pixels immediately above and\n   below the edge\
    \ position, and for a vertical edge, we treat the pixels\n   immediately to the\
    \ left and right of the edge.\n   We call this collection of pixels associated\
    \ to an edge position a\n   segment; the length of a segment is 2, 4, 6, or 8.\
    \  Excepting that\n   the normal filter uses slightly different algorithms for,\
    \ and either\n   filter may apply different control parameters to, the edges between\n\
    \   macroblocks and those between subblocks, the treatment of edges is\n   quite\
    \ uniform: All segments straddling an edge are treated\n   identically; there\
    \ is no distinction between the treatment of\n   horizontal and vertical edges,\
    \ whether between macroblocks or between\n   subblocks.\n   As a consequence,\
    \ adjacent subblock edges within a macroblock may be\n   concatenated and processed\
    \ in their entirety.  There is a single\n   8-pixel-long vertical edge horizontally\
    \ centered in each of the U and\n   V blocks (the concatenation of upper and lower\
    \ 4-pixel edges between\n   chroma subblocks), and three 16-pixel-long vertical\
    \ edges at\n   horizontal positions 1/4, 1/2, and 3/4 the width of the luma\n\
    \   macroblock, each representing the concatenation of four 4-pixel\n   sub-edges\
    \ between pairs of Y subblocks.\n   The macroblocks comprising the frame are processed\
    \ in the usual\n   raster-scan order.  Each macroblock is \"responsible for\"\
    \ the\n   inter-macroblock edges immediately above and to the left of it (but\n\
    \   not the edges below and to the right of it), as well as the edges\n   between\
    \ its subblocks.\n   For each macroblock M, there are four filtering steps, which\
    \ are,\n   (almost) in order:\n   1.  If M is not on the leftmost column of macroblocks,\
    \ filter across\n       the left (vertical) inter-macroblock edge of M.\n   2.\
    \  Filter across the vertical subblock edges within M.\n   3.  If M is not on\
    \ the topmost row of macroblocks, filter across the\n       top (horizontal) inter-macroblock\
    \ edge of M.\n   4.  Filter across the horizontal subblock edges within M.\n \
    \  We write MY, MU, and MV for the planar constituents of M, that is,\n   the\
    \ 16x16 luma block, 8x8 U block, and 8x8 V block comprising M.\n   In step 1,\
    \ for each of the three blocks MY, MU, and MV, we filter\n   each of the (16 luma\
    \ or 8 chroma) segments straddling the column\n   separating the block from the\
    \ block immediately to the left of it,\n   using the inter-macroblock filter and\
    \ controls associated to the\n   loop_filter_level and sharpness_level.\n   In\
    \ step 4, we filter across the (three luma and one each for U and V)\n   vertical\
    \ subblock edges described above, this time using the\n   inter-subblock filter\
    \ and controls.\n   Steps 2 and 4 are skipped for macroblocks that satisfy both\
    \ of the\n   following two conditions:\n   1.  Macroblock coding mode is neither\
    \ B_PRED nor SPLITMV; and\n   2.  There is no DCT coefficient coded for the whole\
    \ macroblock.\n   For these macroblocks, loop filtering for edges between subblocks\n\
    \   internal to a macroblock is effectively skipped.  This skip strategy\n   significantly\
    \ reduces VP8 loop-filtering complexity.\n   Edges between macroblocks and those\
    \ between subblocks are treated\n   with different control parameters (and, in\
    \ the case of the normal\n   filter, with different algorithms).  Except for pixel\
    \ addressing,\n   there is no distinction between the treatment of vertical and\n\
    \   horizontal edges.  Luma edges are always 16 pixels long, chroma edges\n  \
    \ are always 8 pixels long, and the segments straddling an edge are\n   treated\
    \ identically; this of course facilitates vector processing.\n   Because many\
    \ pixels belong to segments straddling two or more edges,\n   and so will be filtered\
    \ more than once, the order in which edges are\n   processed given above must\
    \ be respected by any implementation.\n   Within a single edge, however, the segments\
    \ straddling that edge are\n   disjoint, and the order in which these segments\
    \ are processed is\n   immaterial.\n   Before taking up the filtering algorithms\
    \ themselves, we should\n   emphasize a point already made: Even though the pixel\
    \ segments\n   associated to a macroblock are antecedent to the macroblock (that\
    \ is,\n   lie within the macroblock or in already-constructed macroblocks), a\n\
    \   macroblock must not be filtered immediately after its\n   \"reconstruction\"\
    \ (described in Section 14).  Rather, the loop filter\n   applies after all the\
    \ macroblocks have been \"reconstructed\" (i.e.,\n   had their predictor summed\
    \ with their residue); correct decoding is\n   predicated on the fact that already-constructed\
    \ portions of the\n   current frame referenced via intra-prediction (described\
    \ in\n   Section 12) are not yet filtered.\n"
- title: 15.2.  Simple Filter
  contents:
  - "15.2.  Simple Filter\n   Having described the overall procedure of, and pixels\
    \ affected by,\n   the loop filter, we turn our attention to the treatment of\
    \ individual\n   segments straddling edges.  We begin by describing the simple\
    \ filter,\n   which, as the reader might guess, is somewhat simpler than the normal\n\
    \   filter.\n   Note that the simple filter only applies to luma edges.  Chroma\
    \ edges\n   are left unfiltered.\n   Roughly speaking, the idea of loop filtering\
    \ is, within limits, to\n   reduce the difference between pixels straddling an\
    \ edge.  Differences\n   in excess of a threshold (associated to the loop_filter_level)\
    \ are\n   assumed to be \"natural\" and are unmodified; differences below the\n\
    \   threshold are assumed to be artifacts of quantization and the\n   (partially)\
    \ separate coding of blocks, and are reduced via the\n   procedures described\
    \ below.  While the loop_filter_level is in\n   principle arbitrary, the levels\
    \ chosen by a VP8 compressor tend to be\n   correlated to quantizer levels.\n\
    \   Most of the filtering arithmetic is done using 8-bit signed operands\n   (having\
    \ a range of -128 to +127, inclusive), supplemented by 16-bit\n   temporaries\
    \ holding results of multiplies.\n   Sums and other temporaries need to be \"\
    clamped\" to a valid signed\n   8-bit range:\n   ---- Begin code block --------------------------------------\n\
    \   int8 c(int v)\n   {\n       return (int8) (v < -128 ? -128 : (v < 128 ? v\
    \ : 127));\n   }\n   ---- End code block ----------------------------------------\n\
    \   Since pixel values themselves are unsigned 8-bit numbers, we need to\n   convert\
    \ between signed and unsigned values:\n   ---- Begin code block --------------------------------------\n\
    \   /* Convert pixel value (0 <= v <= 255) to an 8-bit signed\n      number. */\n\
    \   int8 u2s(Pixel v) { return (int8) (v - 128);}\n   /* Clamp, then convert signed\
    \ number back to pixel value. */\n   Pixel s2u(int v) { return (Pixel) (c(v) +\
    \ 128);}\n   ---- End code block ----------------------------------------\n  \
    \ Filtering is often predicated on absolute-value thresholds.  The\n   following\
    \ function is the equivalent of the standard library function\n   abs, whose prototype\
    \ is found in the standard header file stdlib.h.\n   For us, the argument v is\
    \ always the difference between two pixels\n   and lies in the range -255 <= v\
    \ <= +255.\n   ---- Begin code block --------------------------------------\n\
    \   int abs(int v) { return v < 0?  -v : v;}\n   ---- End code block ----------------------------------------\n\
    \   An actual implementation would of course use inline functions or\n   macros\
    \ to accomplish these trivial procedures (which are used by both\n   the normal\
    \ and simple loop filters).  An optimal implementation would\n   probably express\
    \ them in machine language, perhaps using single\n   instruction, multiple data\
    \ (SIMD) vector instructions.  On many SIMD\n   processors, the saturation accomplished\
    \ by the above clamping\n   function is often folded into the arithmetic instructions\
    \ themselves,\n   obviating the explicit step taken here.\n   To simplify the\
    \ specification of relative pixel positions, we use the\n   word \"before\" to\
    \ mean \"immediately above\" (for a vertical segment\n   straddling a horizontal\
    \ edge) or \"immediately to the left of\" (for a\n   horizontal segment straddling\
    \ a vertical edge), and the word \"after\"\n   to mean \"immediately below\" or\
    \ \"immediately to the right of\".\n   Given an edge, a segment, and a limit value,\
    \ the simple loop filter\n   computes a value based on the four pixels that straddle\
    \ the edge (two\n   either side).  If that value is below a supplied limit, then,\
    \ very\n   roughly speaking, the two pixel values are brought closer to each\n\
    \   other, \"shaving off\" something like a quarter of the difference.  The\n\
    \   same procedure is used for all segments straddling any type of edge,\n   regardless\
    \ of the nature (inter-macroblock, inter-subblock, luma, or\n   chroma) of the\
    \ edge; only the limit value depends on the edge type.\n   The exact procedure\
    \ (for a single segment) is as follows; the\n   subroutine common_adjust is used\
    \ by both the simple filter presented\n   here and the normal filters discussed\
    \ in Section 15.3.\n   ---- Begin code block --------------------------------------\n\
    \   int8 common_adjust(\n       int use_outer_taps,   /* filter is 2 or 4 taps\
    \ wide */\n       const Pixel *P1,    /* pixel before P0 */\n       Pixel *P0,\
    \          /* pixel before edge */\n       Pixel *Q0,          /* pixel after\
    \ edge */\n       const Pixel *Q1     /* pixel after Q0 */\n   ) {\n       cint8\
    \ p1 = u2s(*P1);   /* retrieve and convert all 4 pixels */\n       cint8 p0 =\
    \ u2s(*P0);\n       cint8 q0 = u2s(*Q0);\n       cint8 q1 = u2s(*Q1);\n      \
    \ /* Disregarding clamping, when \"use_outer_taps\" is false,\n          \"a\"\
    \ is 3*(q0-p0).  Since we are about to divide \"a\" by\n          8, in this case\
    \ we end up multiplying the edge\n          difference by 5/8.\n          When\
    \ \"use_outer_taps\" is true (as for the simple filter),\n          \"a\" is p1\
    \ - 3*p0 + 3*q0 - q1, which can be thought of as\n          a refinement of 2*(q0\
    \ - p0), and the adjustment is\n          something like (q0 - p0)/4. */\n   \
    \    int8 a = c((use_outer_taps? c(p1 - q1) : 0) + 3*(q0 - p0));\n       /* b\
    \ is used to balance the rounding of a/8 in the case where\n          the \"fractional\"\
    \ part \"f\" of a/8 is exactly 1/2. */\n       cint8 b = (c(a + 3)) >> 3;\n  \
    \     /* Divide a by 8, rounding up when f >= 1/2.\n          Although not strictly\
    \ part of the C language,\n          the right shift is assumed to propagate the\
    \ sign bit. */\n       a = c(a + 4) >> 3;\n       /* Subtract \"a\" from q0, \"\
    bringing it closer\" to p0. */\n       *Q0 = s2u(q0 - a);\n       /* Add \"a\"\
    \ (with adjustment \"b\") to p0, \"bringing it closer\"\n          to q0.\n  \
    \        The clamp of \"a+b\", while present in the reference decoder,\n     \
    \     is superfluous; we have -16 <= a <= 15 at this point. */\n       *P0 = s2u(p0\
    \ + b);\n       return a;\n   }\n   ---- End code block ----------------------------------------\n\
    \   ---- Begin code block --------------------------------------\n   void simple_segment(\n\
    \       uint8 edge_limit,   /* do nothing if edge difference\n               \
    \               exceeds limit */\n       const Pixel *P1,    /* pixel before P0\
    \ */\n       Pixel *P0,          /* pixel before edge */\n       Pixel *Q0,  \
    \        /* pixel after edge */\n       const Pixel *Q1     /* pixel after Q0\
    \ */\n   ) {\n       if ((abs(*P0 - *Q0)*2 + abs(*P1 - *Q1)/2) <= edge_limit))\n\
    \           common_adjust(1, P1, P0, Q0, Q1);   /* use outer taps */\n   }\n \
    \  ---- End code block ----------------------------------------\n   We make a\
    \ couple of remarks about the rounding procedure above.  When\n   b is zero (that\
    \ is, when the \"fractional part\" of a is not 1/2), we\n   are (except for clamping)\
    \ adding the same number to p0 as we are\n   subtracting from q0.  This preserves\
    \ the average value of p0 and q0,\n   but the resulting difference between p0\
    \ and q0 is always even; in\n   particular, the smallest non-zero gradation +-1\
    \ is not possible here.\n   When b is one, the value we add to p0 (again except\
    \ for clamping) is\n   one less than the value we are subtracting from q0.  In\
    \ this case,\n   the resulting difference is always odd (and the small gradation\
    \ +-1\n   is possible), but the average value is reduced by 1/2, yielding, for\n\
    \   instance, a very slight darkening in the luma plane.  (In the very\n   unlikely\
    \ event of appreciable darkening after a large number of\n   interframes, a compressor\
    \ would of course eventually compensate for\n   this in the selection of predictor\
    \ and/or residue.)\n   The derivation of the edge_limit value used above, which\
    \ depends on\n   the loop_filter_level and sharpness_level, as well as the type\
    \ of\n   edge being processed, will be taken up after we describe the normal\n\
    \   loop filtering algorithm below.\n"
- title: 15.3.  Normal Filter
  contents:
  - "15.3.  Normal Filter\n   The normal loop filter is a refinement of the simple\
    \ loop filter; all\n   of the general discussion above applies here as well. \
    \ In particular,\n   the functions c, u2s, s2u, abs, and common_adjust are used\
    \ by both\n   the normal and simple filters.\n   As mentioned above, the normal\
    \ algorithms for inter-macroblock and\n   inter-subblock edges differ.  Nonetheless,\
    \ they have a great deal in\n   common: They use similar threshold algorithms\
    \ to disable the filter\n   and to detect high internal edge variance (which influences\
    \ the\n   filtering algorithm).  Both algorithms also use, at least\n   conditionally,\
    \ the simple filter adjustment procedure described\n   above.\n   The common thresholding\
    \ algorithms are as follows.\n   ---- Begin code block --------------------------------------\n\
    \   /* All functions take (among other things) a segment (of length\n      at\
    \ most 4 + 4 = 8) symmetrically straddling an edge.\n      The pixel values (or\
    \ pointers) are always given in order,\n      from the \"beforemost\" to the \"\
    aftermost\".  So, for a\n      horizontal edge (written \"|\"), an 8-pixel segment\
    \ would be\n      ordered p3 p2 p1 p0 | q0 q1 q2 q3. */\n   /* Filtering is disabled\
    \ if the difference between any two\n      adjacent \"interior\" pixels in the\
    \ 8-pixel segment exceeds\n      the relevant threshold (I).  A more complex thresholding\n\
    \      calculation is done for the group of four pixels that\n      straddle the\
    \ edge, in line with the calculation in\n      simple_segment() above. */\n  \
    \ int filter_yes(\n       uint8 I,        /* limit on interior differences */\n\
    \       uint8 E,        /* limit at the edge */\n       cint8 p3, cint8 p2, cint8\
    \ p1, cint8 p0, /* pixels before\n                                           \
    \       edge */\n       cint8 q0, cint8 q1, cint8 q2, cint8 q3  /* pixels after\n\
    \                                                  edge */\n   ) {\n       return\
    \  (abs(p0 - q0)*2 + abs(p1 - q1)/2) <= E\n           &&  abs(p3 - p2) <= I  &&\
    \  abs(p2 - p1) <= I  &&\n             abs(p1 - p0) <= I\n           &&  abs(q3\
    \ - q2) <= I  &&  abs(q2 - q1) <= I  &&\n             abs(q1 - q0) <= I;\n   }\n\
    \   ---- End code block ----------------------------------------\n   ---- Begin\
    \ code block --------------------------------------\n   /* Filtering is altered\
    \ if (at least) one of the differences\n      on either side of the edge exceeds\
    \ a threshold (we have\n      \"high edge variance\"). */\n   int hev(\n     \
    \  uint8 threshold,\n       cint8 p1, cint8 p0, /* pixels before edge */\n   \
    \    cint8 q0, cint8 q1  /* pixels after edge */\n   ) {\n       return abs(p1\
    \ - p0) > threshold  ||  abs(q1 - q0) > threshold;\n   }\n   ---- End code block\
    \ ----------------------------------------\n   The subblock filter is a variant\
    \ of the simple filter.  In fact, if\n   we have high edge variance, the adjustment\
    \ is exactly as for the\n   simple filter.  Otherwise, the simple adjustment (without\
    \ outer taps)\n   is applied, and the two pixels one step in from the edge pixels\
    \ are\n   adjusted by roughly half the amount by which the two edge pixels are\n\
    \   adjusted; since the edge adjustment here is essentially 3/8 the edge\n   difference,\
    \ the inner adjustment is approximately 3/16 the edge\n   difference.\n   ----\
    \ Begin code block --------------------------------------\n   void subblock_filter(\n\
    \       uint8 hev_threshold,     /* detect high edge variance */\n       uint8\
    \ interior_limit,    /* possibly disable filter */\n       uint8 edge_limit,\n\
    \       cint8 *P3, cint8 *P2, int8 *P1, int8 *P0,   /* pixels before\n       \
    \                                               edge */\n       int8 *Q0, int8\
    \ *Q1, cint8 *Q2, cint8 *Q3    /* pixels after\n                             \
    \                         edge */\n   ) {\n       cint8 p3 = u2s(*P3), p2 = u2s(*P2),\
    \ p1 = u2s(*P1),\n         p0 = u2s(*P0);\n       cint8 q0 = u2s(*Q0), q1 = u2s(*Q1),\
    \ q2 = u2s(*Q2),\n         q3 = u2s(*Q3);\n       if (filter_yes(interior_limit,\
    \ edge_limit, q3, q2, q1, q0,\n         p0, p1, p2, p3))\n       {\n         \
    \  const int hv = hev(hev_threshold, p1, p0, q0, q1);\n           cint8 a = (common_adjust(hv,\
    \ P1, P0, Q0, Q1) + 1) >> 1;\n           if (!hv) {\n               *Q1 = s2u(q1\
    \ - a);\n               *P1 = s2u(p1 + a);\n           }\n       }\n   }\n   ----\
    \ End code block ----------------------------------------\n   The inter-macroblock\
    \ filter has potentially wider scope.  If the edge\n   variance is high, it performs\
    \ the simple adjustment (using the outer\n   taps, just like the simple filter\
    \ and the corresponding case of the\n   normal subblock filter).  If the edge\
    \ variance is low, we begin with\n   the same basic filter calculation and apply\
    \ multiples of it to pixel\n   pairs symmetric about the edge; the magnitude of\
    \ adjustment decays as\n   we move away from the edge and six of the pixels in\
    \ the segment are\n   affected.\n   ---- Begin code block --------------------------------------\n\
    \   void MBfilter(\n       uint8 hev_threshold,     /* detect high edge variance\
    \ */\n       uint8 interior_limit,    /* possibly disable filter */\n       uint8\
    \ edge_limit,\n       cint8 *P3, int8 *P2, int8 *P1, int8 *P0,  /* pixels before\n\
    \                                                    edge */\n       int8 *Q0,\
    \ int8 *Q1, int8 *Q2, cint8 *Q3   /* pixels after\n                          \
    \                          edge */\n   ) {\n       cint8 p3 = u2s(*P3), p2 = u2s(*P2),\
    \ p1 = u2s(*P1),\n         p0 = u2s(*P0);\n       cint8 q0 = u2s(*Q0), q1 = u2s(*Q1),\
    \ q2 = u2s(*Q2),\n         q3 = u2s(*Q3);\n       if (filter_yes(interior_limit,\
    \ edge_limit, q3, q2, q1, q0,\n         p0, p1, p2, p3))\n       {\n         \
    \  if (!hev(hev_threshold, p1, p0, q0, q1))\n           {\n               /* Same\
    \ as the initial calculation in \"common_adjust\",\n                  w is something\
    \ like twice the edge difference */\n               const int8 w = c(c(p1 - q1)\
    \ + 3*(q0 - p0));\n               /* 9/64 is approximately 9/63 = 1/7, and 1<<7\
    \ = 128 =\n                  2*64.  So this a, used to adjust the pixels adjacent\n\
    \                  to the edge, is something like 3/7 the edge\n             \
    \     difference. */\n               int8 a = c((27*w + 63) >> 7);\n         \
    \      *Q0 = s2u(q0 - a);  *P0 = s2u(p0 + a);\n               /* Next two are\
    \ adjusted by 2/7 the edge difference */\n               a = c((18*w + 63) >>\
    \ 7);\n               *Q1 = s2u(q1 - a);  *P1 = s2u(p1 + a);\n               /*\
    \ Last two are adjusted by 1/7 the edge difference */\n               a = c((9*w\
    \ + 63) >> 7);\n               *Q2 = s2u(q2 - a);  *P2 = s2u(p2 + a);\n      \
    \     } else                      /* if hev, do simple filter */\n           \
    \    common_adjust(1, P1, P0, Q0, Q1);   /* using outer\n                    \
    \                                   taps */\n       }\n   }\n   ---- End code\
    \ block ----------------------------------------\n"
- title: 15.4.  Calculation of Control Parameters
  contents:
  - "15.4.  Calculation of Control Parameters\n   We conclude the discussion of loop\
    \ filtering by showing how the\n   thresholds supplied to the procedures above\
    \ are derived from the two\n   control parameters sharpness_level (an unsigned\
    \ 3-bit number having\n   maximum value 7) and loop_filter_level (an unsigned\
    \ 6-bit number\n   having maximum value 63).\n   While the sharpness_level is\
    \ constant over the frame, individual\n   macroblocks may override the loop_filter_level\
    \ with one of four\n   possibilities supplied in the frame header (as described\
    \ in\n   Section 10).\n   Both the simple and normal filters disable filtering\
    \ if a value\n   derived from the four pixels that straddle the edge (2 either\
    \ side)\n   exceeds a threshold / limit value.\n   ---- Begin code block --------------------------------------\n\
    \   /* Luma and Chroma use the same inter-macroblock edge limit */\n   uint8 mbedge_limit\
    \ = ((loop_filter_level + 2) * 2) +\n     interior_limit;\n   /* Luma and Chroma\
    \ use the same inter-subblock edge limit */\n   uint8 sub_bedge_limit = (loop_filter_level\
    \ * 2) + interior_limit;\n   ---- End code block ----------------------------------------\n\
    \   The remaining thresholds are used only by the normal filters.  The\n   filter-disabling\
    \ interior difference limit is the same for all edges\n   (luma, chroma, inter-subblock,\
    \ inter-macroblock) and is given by the\n   following.\n   ---- Begin code block\
    \ --------------------------------------\n   uint8 interior_limit = loop_filter_level;\n\
    \   if (sharpness_level)\n   {\n       interior_limit  >>=  sharpness_level >\
    \ 4 ?  2 : 1;\n       if (interior_limit > 9 - sharpness_level)\n           interior_limit\
    \ = 9 - sharpness_level;\n   }\n   if (!interior_limit)\n       interior_limit\
    \ = 1;\n   ---- End code block ----------------------------------------\n   Finally,\
    \ we give the derivation of the high edge-variance threshold,\n   which is also\
    \ the same for all edge types.\n   ---- Begin code block --------------------------------------\n\
    \   uint8 hev_threshold = 0;\n   if (we_are_decoding_akey_frame)   /* current\
    \ frame is a key frame */\n   {\n       if (loop_filter_level >= 40)\n       \
    \    hev_threshold = 2;\n       else if (loop_filter_level >= 15)\n          \
    \ hev_threshold = 1;\n   }\n   else                            /* current frame\
    \ is an interframe */\n   {\n       if (loop_filter_level >= 40)\n           hev_threshold\
    \ = 3;\n       else if (loop_filter_level >= 20)\n           hev_threshold = 2;\n\
    \       else if (loop_filter_level >= 15)\n           hev_threshold = 1;\n   }\n\
    \   ---- End code block ----------------------------------------\n"
- title: 16.  Interframe Macroblock Prediction Records
  contents:
  - "16.  Interframe Macroblock Prediction Records\n   We describe the layout and\
    \ semantics of the prediction records for\n   macroblocks in an interframe.\n\
    \   After the feature specification (which is described in Section 10 and\n  \
    \ is identical for intraframes and interframes), there comes a\n   Bool(prob_intra),\
    \ which indicates inter-prediction (i.e., prediction\n   from prior frames) when\
    \ true and intra-prediction (i.e., prediction\n   from already-coded portions\
    \ of the current frame) when false.  The\n   zero-probability prob_intra is set\
    \ by field J of the frame header.\n"
- title: 16.1.  Intra-Predicted Macroblocks
  contents:
  - "16.1.  Intra-Predicted Macroblocks\n   For intra-prediction, the layout of the\
    \ prediction data is\n   essentially the same as the layout for key frames, although\
    \ the\n   contexts used by the decoding process are slightly different.\n   As\
    \ discussed in Section 8, the \"outer\" Y mode here uses a different\n   tree\
    \ from that used in key frames, repeated here for convenience.\n   ---- Begin\
    \ code block --------------------------------------\n   const tree_index ymode_tree\
    \ [2 * (num_ymodes - 1)] =\n   {\n    -DC_PRED, 2,           /* root: DC_PRED\
    \ = \"0\", \"1\" subtree */\n     4, 6,                 /* \"1\" subtree has 2\
    \ descendant subtrees */\n      -V_PRED, -H_PRED,    /* \"10\" subtree:  V_PRED\
    \ = \"100\",\n                              H_PRED = \"101\" */\n      -TM_PRED,\
    \ -B_PRED    /* \"11\" subtree:  TM_PRED = \"110\",\n                        \
    \      B_PRED = \"111\" */\n   };\n   ---- End code block ----------------------------------------\n\
    \   The probability table used to decode this tree is variable.  As\n   described\
    \ in Section 11, it (along with the similarly treated UV\n   table) can be updated\
    \ by field J of the frame header.  Similar to the\n   coefficient-decoding probabilities,\
    \ such updates are cumulative and\n   affect all ensuing frames until the next\
    \ key frame or explicit\n   update.  The default probabilities for the Y and UV\
    \ tables are:\n   ---- Begin code block --------------------------------------\n\
    \   Prob ymode_prob [num_ymodes - 1] = { 112, 86, 140, 37};\n   Prob uv_mode_prob\
    \ [num_uv_modes - 1] = { 162, 101, 204};\n   ---- End code block ----------------------------------------\n\
    \   These defaults must be restored after detection of a key frame.\n   Just as\
    \ for key frames, if the Y mode is B_PRED, there next comes an\n   encoding of\
    \ the intra_bpred mode used by each of the sixteen Y\n   subblocks.  These encodings\
    \ use the same tree as does that for key\n   frames but, in place of the contexts\
    \ used in key frames, these\n   encodings use the single fixed probability table.\n\
    \   ---- Begin code block --------------------------------------\n   const Prob\
    \ bmode_prob [num_intra_bmodes - 1] = {\n       120, 90, 79, 133, 87, 85, 80,\
    \ 111, 151\n   };\n   ---- End code block ----------------------------------------\n\
    \   Last comes the chroma mode, again coded using the same tree as that\n   used\
    \ for key frames, this time using the dynamic uv_mode_prob table\n   described\
    \ above.\n   The calculation of the intra-prediction buffer is identical to that\n\
    \   described for key frames in Section 12.\n"
- title: 16.2.  Inter-Predicted Macroblocks
  contents:
  - "16.2.  Inter-Predicted Macroblocks\n   Otherwise (when the above bool is true),\
    \ we are using\n   inter-prediction (which of course only happens for interframes),\
    \ to\n   which we now restrict our attention.\n   The next datum is then another\
    \ bool, B(prob_last), selecting the\n   reference frame.  If 0, the reference\
    \ frame is the previous frame\n   (the last frame); if 1, another bool (prob_gf)\
    \ selects the reference\n   frame between the golden frame (0) and the altref\
    \ frame (1).  The\n   probabilities prob_last and prob_gf are set in field J of\
    \ the frame\n   header.\n   Together with setting the reference frame, the purpose\
    \ of inter-mode\n   decoding is to set a motion vector for each of the sixteen\
    \ Y\n   subblocks of the current macroblock.  These settings then define the\n\
    \   calculation of the inter-prediction buffer (detailed in Section 18).\n   While\
    \ the net effect of inter-mode decoding is straightforward, the\n   implementation\
    \ is somewhat complex; the (lossless) compression\n   achieved by this method\
    \ justifies the complexity.\n   After the reference frame selector comes the mode\
    \ (or motion vector\n   reference) applied to the macroblock as a whole, coded\
    \ using the\n   following enumeration and tree.  Setting mv_nearest = num_ymodes\
    \ is a\n   convenience that allows a single variable to unambiguously hold an\n\
    \   inter- or intra-prediction mode.\n   ---- Begin code block --------------------------------------\n\
    \   typedef enum\n   {\n       mv_nearest = num_ymodes, /* use \"nearest\" motion\
    \ vector\n                                   for entire MB */\n       mv_near,\
    \                 /* use \"next nearest\" \"\" */\n       mv_zero,           \
    \      /* use zero \"\" */\n       mv_new,                  /* use explicit offset\
    \ from\n                                   implicit \"\" */\n       mv_split,\
    \                /* use multiple motion vectors */\n       num_mv_refs = mv_split\
    \ + 1 - mv_nearest\n   }\n   mv_ref;\n   const tree_index mv_ref_tree [2 * (num_mv_refs\
    \ - 1)] =\n   {\n    -mv_zero, 2,                /* zero = \"0\" */\n     -mv_nearest,\
    \ 4,            /* nearest = \"10\" */\n      -mv_near, 6,              /* near\
    \ = \"110\" */\n        -mv_new, -mv_split      /* new = \"1110\", split = \"\
    1111\" */\n   };\n   ---- End code block ----------------------------------------\n"
- title: 16.3.  Mode and Motion Vector Contexts
  contents:
  - "16.3.  Mode and Motion Vector Contexts\n   The probability table used to decode\
    \ the mv_ref, along with three\n   reference motion vectors used by the selected\
    \ mode, is calculated via\n   a survey of the already-decoded motion vectors in\
    \ (up to) 3 nearby\n   macroblocks.\n   The algorithm generates a sorted list\
    \ of distinct motion vectors\n   adjacent to the search site.  The best_mv is\
    \ the vector with the\n   highest score.  The mv_nearest is the non-zero vector\
    \ with the\n   highest score.  The mv_near is the non-zero vector with the next\n\
    \   highest score.  The number of motion vectors coded using the SPLITMV\n   mode\
    \ is scored using the same weighting and is returned with the\n   scores of the\
    \ best, nearest, and near vectors.\n   The three adjacent macroblocks above, left,\
    \ and above-left are\n   considered in order.  If the macroblock is intra-coded,\
    \ no action is\n   taken.  Otherwise, the motion vector is compared to other previously\n\
    \   found motion vectors to determine if it has been seen before, and if\n   so\
    \ contributes its weight to that vector; otherwise, it enters a new\n   vector\
    \ in the list.  The above and left vectors have twice the weight\n   of the above-left\
    \ vector.\n   As is the case with many contexts used by VP8, it is possible for\n\
    \   macroblocks near the top or left edges of the image to reference\n   blocks\
    \ that are outside the visible image.  VP8 provides a border of\n   1 macroblock\
    \ filled with 0x0 motion vectors left of the left edge,\n   and a border filled\
    \ with 0,0 motion vectors of 1 macroblocks above\n   the top edge.\n   Much of\
    \ the process is more easily described in C than in English.\n   The reference\
    \ code for this can be found in modemv.c (Section 20.11).\n   The calculation\
    \ of reference vectors, probability table, and,\n   finally, the inter-prediction\
    \ mode itself is implemented as follows.\n   ---- Begin code block --------------------------------------\n\
    \   typedef union\n   {\n       unsigned int as_int;\n       MV           as_mv;\n\
    \   } int_mv;        /* facilitates rapid equality tests */\n   static void mv_bias(MODE_INFO\
    \ *x,int refframe, int_mv *mvp,\n     int * ref_frame_sign_bias)\n   {\n     \
    \  MV xmv;\n       xmv = x->mbmi.mv.as_mv;\n       if ( ref_frame_sign_bias[x->mbmi.ref_frame]\
    \ !=\n         ref_frame_sign_bias[refframe] )\n       {\n           xmv.row*=-1;\n\
    \           xmv.col*=-1;\n       }\n       mvp->as_mv = xmv;\n   }\n   ---- End\
    \ code block ----------------------------------------\n   ---- Begin code block\
    \ --------------------------------------\n   void vp8_clamp_mv(MV *mv, const MACROBLOCKD\
    \ *xd)\n   {\n       if ( mv->col < (xd->mb_to_left_edge - LEFT_TOP_MARGIN) )\n\
    \           mv->col = xd->mb_to_left_edge - LEFT_TOP_MARGIN;\n       else if (\
    \ mv->col > xd->mb_to_right_edge + RIGHT_BOTTOM_MARGIN )\n           mv->col =\
    \ xd->mb_to_right_edge + RIGHT_BOTTOM_MARGIN;\n       if ( mv->row < (xd->mb_to_top_edge\
    \ - LEFT_TOP_MARGIN) )\n           mv->row = xd->mb_to_top_edge - LEFT_TOP_MARGIN;\n\
    \       else if ( mv->row > xd->mb_to_bottom_edge + RIGHT_BOTTOM_MARGIN )\n  \
    \         mv->row = xd->mb_to_bottom_edge + RIGHT_BOTTOM_MARGIN;\n   }\n   ----\
    \ End code block ----------------------------------------\n   In the function\
    \ vp8_find_near_mvs(), the vectors \"nearest\" and \"near\"\n   are used by the\
    \ corresponding modes.\n   The vector best_mv is used as a base for explicitly\
    \ coded motion\n   vectors.\n   The first three entries in the return value cnt\
    \ are (in order)\n   weighted census values for \"zero\", \"nearest\", and \"\
    near\" vectors.\n   The final value indicates the extent to which SPLITMV was\
    \ used by the\n   neighboring macroblocks.  The largest possible \"weight\" value\
    \ in each\n   case is 5.\n   ---- Begin code block --------------------------------------\n\
    \   void vp8_find_near_mvs\n   (\n       MACROBLOCKD *xd,\n       const MODE_INFO\
    \ *here,\n       MV *nearest,\n       MV *near,\n       MV *best_mv,\n       int\
    \ cnt[4],\n       int refframe,\n       int * ref_frame_sign_bias\n   )\n   {\n\
    \       const MODE_INFO *above = here - xd->mode_info_stride;\n       const MODE_INFO\
    \ *left = here - 1;\n       const MODE_INFO *aboveleft = above - 1;\n       int_mv\
    \            near_mvs[4];\n       int_mv           *mv = near_mvs;\n       int\
    \             *cntx = cnt;\n       enum {CNT_ZERO, CNT_NEAREST, CNT_NEAR, CNT_SPLITMV};\n\
    \       /* Zero accumulators */\n       mv[0].as_int = mv[1].as_int = mv[2].as_int\
    \ = 0;\n       cnt[0] = cnt[1] = cnt[2] = cnt[3] = 0;\n       /* Process above\
    \ */\n       if (above->mbmi.ref_frame != INTRA_FRAME) {\n           if (above->mbmi.mv.as_int)\
    \ {\n               (++mv)->as_int = above->mbmi.mv.as_int;\n               mv_bias(above,\
    \ refframe, mv, ref_frame_sign_bias);\n               ++cntx;\n           }\n\
    \           *cntx += 2;\n       }\n       /* Process left */\n       if (left->mbmi.ref_frame\
    \ != INTRA_FRAME) {\n           if (left->mbmi.mv.as_int) {\n               int_mv\
    \ this_mv;\n               this_mv.as_int = left->mbmi.mv.as_int;\n          \
    \     mv_bias(left, refframe, &this_mv, ref_frame_sign_bias);\n              \
    \ if (this_mv.as_int != mv->as_int) {\n                   (++mv)->as_int = this_mv.as_int;\n\
    \                   ++cntx;\n               }\n               *cntx += 2;\n  \
    \         } else\n               cnt[CNT_ZERO] += 2;\n       }\n       /* Process\
    \ above left */\n       if (aboveleft->mbmi.ref_frame != INTRA_FRAME) {\n    \
    \       if (aboveleft->mbmi.mv.as_int) {\n               int_mv this_mv;\n   \
    \            this_mv.as_int = aboveleft->mbmi.mv.as_int;\n               mv_bias(aboveleft,\
    \ refframe, &this_mv,\n                 ref_frame_sign_bias);\n              \
    \ if (this_mv.as_int != mv->as_int) {\n                   (++mv)->as_int = this_mv.as_int;\n\
    \                   ++cntx;\n               }\n               *cntx += 1;\n  \
    \         } else\n               cnt[CNT_ZERO] += 1;\n       }\n       /* If we\
    \ have three distinct MVs ... */\n       if (cnt[CNT_SPLITMV]) {\n           /*\
    \ See if above-left MV can be merged with NEAREST */\n           if (mv->as_int\
    \ == near_mvs[CNT_NEAREST].as_int)\n               cnt[CNT_NEAREST] += 1;\n  \
    \     }\n       cnt[CNT_SPLITMV] = ((above->mbmi.mode == SPLITMV)\n          \
    \                  + (left->mbmi.mode == SPLITMV)) * 2\n                     \
    \      + (aboveleft->mbmi.mode == SPLITMV);\n       /* Swap near and nearest if\
    \ necessary */\n       if (cnt[CNT_NEAR] > cnt[CNT_NEAREST]) {\n           int\
    \ tmp;\n           tmp = cnt[CNT_NEAREST];\n           cnt[CNT_NEAREST] = cnt[CNT_NEAR];\n\
    \           cnt[CNT_NEAR] = tmp;\n           tmp = near_mvs[CNT_NEAREST].as_int;\n\
    \           near_mvs[CNT_NEAREST].as_int = near_mvs[CNT_NEAR].as_int;\n      \
    \     near_mvs[CNT_NEAR].as_int = tmp;\n       }\n       /* Use near_mvs[0] to\
    \ store the \"best\" MV */\n       if (cnt[CNT_NEAREST] >= cnt[CNT_ZERO])\n  \
    \         near_mvs[CNT_ZERO] = near_mvs[CNT_NEAREST];\n       /* Set up return\
    \ values */\n       *best_mv = near_mvs[0].as_mv;\n       *nearest = near_mvs[CNT_NEAREST].as_mv;\n\
    \       *near = near_mvs[CNT_NEAR].as_mv;\n       vp8_clamp_mv(nearest, xd);\n\
    \       vp8_clamp_mv(near, xd);\n       vp8_clamp_mv(best_mv, xd); //TODO: Move\
    \ this up before\n                                    the copy\n   }\n   ----\
    \ End code block ----------------------------------------\n   The mv_ref probability\
    \ table (mv_ref_p) is then derived from the\n   census as follows.\n   ---- Begin\
    \ code block --------------------------------------\n   const int vp8_mode_contexts[6][4]\
    \ =\n   {\n     {   7,     1,     1,   143,   },\n     {  14,    18,    14,  \
    \ 107,   },\n     { 135,    64,    57,    68,   },\n     {  60,    56,   128,\
    \    65,   },\n     { 159,   134,   128,    34,   },\n     { 234,   188,   128,\
    \    28,   },\n   }\n   ---- End code block ----------------------------------------\n\
    \   ---- Begin code block --------------------------------------\n   vp8_prob\
    \ *vp8_mv_ref_probs(vp8_prob mv_ref_p[VP8_MVREFS-1],\n     int cnt[4])\n   {\n\
    \       mv_ref_p[0] = vp8_mode_contexts [cnt[0]] [0];\n       mv_ref_p[1] = vp8_mode_contexts\
    \ [cnt[1]] [1];\n       mv_ref_p[2] = vp8_mode_contexts [cnt[2]] [2];\n      \
    \ mv_ref_p[3] = vp8_mode_contexts [cnt[3]] [3];\n       return p;\n   }\n   ----\
    \ End code block ----------------------------------------\n   Once mv_ref_p is\
    \ established, the mv_ref is decoded as usual.\n   ---- Begin code block --------------------------------------\n\
    \     mvr = (mv_ref) treed_read(d, mv_ref_tree, mv_ref_p);\n   ---- End code block\
    \ ----------------------------------------\n   For the first four inter-coding\
    \ modes, the same motion vector is used\n   for all the Y subblocks.  The first\
    \ three modes use an implicit\n   motion vector.\n   +------------+------------------------------------------------------+\n\
    \   | Mode       | Instruction                                          |\n  \
    \ +------------+------------------------------------------------------+\n   |\
    \ mv_nearest | Use the nearest vector returned by                   |\n   |  \
    \          | vp8_find_near_mvs.                                   |\n   |    \
    \        |                                                      |\n   | mv_near\
    \    | Use the near vector returned by vp8_find_near_mvs.   |\n   |          \
    \  |                                                      |\n   | mv_zero    |\
    \ Use a zero vector; that is, predict the current      |\n   |            | macroblock\
    \ from the corresponding macroblock in the  |\n   |            | prediction frame.\
    \                                    |\n   |            |                    \
    \                                  |\n   | NEWMV      | This mode is followed\
    \ by an explicitly coded motion  |\n   |            | vector (the format of which\
    \ is described in the next |\n   |            | section) that is added (component-wise)\
    \ to the       |\n   |            | best_mv reference vector returned by find_near_mvs\
    \   |\n   |            | and applied to all 16 subblocks.                    \
    \ |\n   +------------+------------------------------------------------------+\n"
- title: 16.4.  Split Prediction
  contents:
  - "16.4.  Split Prediction\n   The remaining mode (SPLITMV) causes multiple vectors\
    \ to be applied to\n   the Y subblocks.  It is immediately followed by a partition\n\
    \   specification that determines how many vectors will be specified and\n   how\
    \ they will be assigned to the subblocks.  The possible partitions,\n   with indicated\
    \ subdivisions and coding tree, are as follows.\n   ---- Begin code block --------------------------------------\n\
    \   typedef enum\n   {\n       mv_top_bottom,   /* two pieces {0...7} and {8...15}\
    \ */\n       mv_left_right,   /* {0,1,4,5,8,9,12,13} and\n                   \
    \        {2,3,6,7,10,11,14,15} */\n       mv_quarters,    /* {0,1,4,5}, {2,3,6,7},\
    \ {8,9,12,13},\n                          {10,11,14,15} */\n       MV_16,    \
    \      /* every subblock gets its own vector\n                          {0} ...\
    \ {15} */\n       mv_num_partitions\n   }\n   MVpartition;\n   const tree_index\
    \ mvpartition_tree [2 * (mvnum_partition - 1)] =\n   {\n    -MV_16, 2,       \
    \                  /* MV_16 = \"0\" */\n     -mv_quarters, 4,                \
    \  /* mv_quarters = \"10\" */\n      -mv_top_bottom, -mv_left_right   /* top_bottom\
    \ = \"110\",\n                                          left_right = \"111\" */\n\
    \   };\n   ---- End code block ----------------------------------------\n   The\
    \ partition is decoded using a fixed, constant probability table:\n   ---- Begin\
    \ code block --------------------------------------\n   const Prob mvpartition_probs\
    \ [mvnum_partition - 1] =\n     { 110, 111, 150};\n   part = (MVpartition) treed_read(d,\
    \ mvpartition_tree,\n     mvpartition_probs);\n   ---- End code block ----------------------------------------\n\
    \   After the partition come two (for mv_top_bottom or mv_left_right),\n   four\
    \ (for mv_quarters), or sixteen (for MV_16) subblock\n   inter-prediction modes.\
    \  These modes occur in the order indicated by\n   the partition layouts (given\
    \ as comments to the MVpartition enum) and\n   are coded as follows.  (As was\
    \ done for the macroblock-level modes,\n   we offset the mode enumeration so that\
    \ a single variable may\n   unambiguously hold either an intra- or inter-subblock\
    \ mode.)\n   Prior to decoding each subblock, a decoding tree context is chosen\
    \ as\n   illustrated in the code snippet below.  The context is based on the\n\
    \   immediate left and above subblock neighbors, and whether they are\n   equal,\
    \ are zero, or a combination of those.\n   ---- Begin code block --------------------------------------\n\
    \   typedef enum\n   {\n       LEFT4x4 = num_intra_bmodes,   /* use already-coded\
    \ MV to\n                                        my left */\n       ABOVE4x4,\
    \             /* use already-coded MV above me */\n       ZERO4x4,           \
    \   /* use zero MV */\n       NEW4x4,               /* explicit offset from \"\
    best\" */\n       num_sub_mv_ref\n   };\n   sub_mv_ref;\n   const tree_index sub_mv_ref_tree\
    \ [2 * (num_sub_mv_ref - 1)] =\n   {\n    -LEFT4X4, 2,           /* LEFT = \"\
    0\" */\n     -ABOVE4X4, 4,         /* ABOVE = \"10\" */\n      -ZERO4X4, -NEW4X4\
    \    /* ZERO = \"110\", NEW = \"111\" */\n   };\n   /* Choose correct decoding\
    \ tree context\n    * Function parameters are left subblock neighbor MV and above\n\
    \    * subblock neighbor MV */\n   int vp8_mvCont(MV *l, MV*a)\n   {\n       int\
    \ lez = (l->row == 0 && l->col == 0);   /* left neighbor\n                   \
    \                                 is zero */\n       int aez = (a->row == 0 &&\
    \ a->col == 0);   /* above neighbor\n                                        \
    \            is zero */\n       int lea = (l->row == a->row && l->col == a->col);\
    \  /* left\n                                neighbor equals above neighbor */\n\
    \       if (lea && lez)\n           return SUBMVREF_LEFT_ABOVE_ZED; /* =4 */\n\
    \       if (lea)\n           return SUBMVREF_LEFT_ABOVE_SAME; /* =3 */\n     \
    \  if (aez)\n           return SUBMVREF_ABOVE_ZED; /* =2 */\n       if (lez)\n\
    \           return SUBMVREF_LEFT_ZED; /* =1*/\n       return SUBMVREF_NORMAL;\
    \ /* =0 */\n   }\n   /* Constant probabilities and decoding procedure. */\n  \
    \ const Prob sub_mv_ref_prob [5][num_sub_mv_ref - 1] = {\n       { 147,136,18\
    \ },\n       { 106,145,1  },\n       { 179,121,1  },\n       { 223,1  ,34 },\n\
    \       { 208,1  ,1  }\n   };\n       sub_ref = (sub_mv_ref) treed_read(d, sub_mv_ref_tree,\n\
    \         sub_mv_ref_prob[context]);\n   ---- End code block ----------------------------------------\n\
    \   The first two sub-prediction modes simply copy the already-coded\n   motion\
    \ vectors used by the blocks above and to the left of the\n   subblock at the\
    \ upper left corner of the current subset (i.e.,\n   collection of subblocks being\
    \ predicted).  These prediction blocks\n   need not lie in the current macroblock\
    \ and, if the current subset\n   lies at the top or left edges of the frame, need\
    \ not lie in the\n   frame.  In this latter case, their motion vectors are taken\
    \ to be\n   zero, as are subblock motion vectors within an intra-predicted\n \
    \  macroblock.  Also, to ensure the correctness of prediction within\n   this\
    \ macroblock, all subblocks lying in an already-decoded subset of\n   the current\
    \ macroblock must have their motion vectors set.\n   ZERO4x4 uses a zero motion\
    \ vector and predicts the current subset\n   using the corresponding subset from\
    \ the prediction frame.\n   NEW4x4 is exactly like NEWMV except that NEW4x4 is\
    \ applied only to\n   the current subset.  It is followed by a two-dimensional\
    \ motion\n   vector offset (described in the next section) that is added to the\n\
    \   best vector returned by the earlier call to find_near_mvs to form the\n  \
    \ motion vector in effect for the subset.\n   Parsing of both inter-prediction\
    \ modes and motion vectors (described\n   next) can be found in the reference\
    \ decoder file modemv.c\n   (Section 20.11).\n"
- title: 17.  Motion Vector Decoding
  contents:
  - "17.  Motion Vector Decoding\n   As discussed above, motion vectors appear in\
    \ two places in the VP8\n   datastream: applied to whole macroblocks in NEWMV\
    \ mode and applied to\n   subsets of macroblocks in NEW4x4 mode.  The format of\
    \ the vectors is\n   identical in both cases.\n   Each vector has two pieces:\
    \ a vertical component (row) followed by a\n   horizontal component (column).\
    \  The row and column use separate\n   coding probabilities but are otherwise\
    \ represented identically.\n"
- title: 17.1.  Coding of Each Component
  contents:
  - "17.1.  Coding of Each Component\n   Each component is a signed integer V representing\
    \ a vertical or\n   horizontal luma displacement of V quarter-pixels (and a chroma\n\
    \   displacement of V eighth-pixels).  The absolute value of V, if\n   non-zero,\
    \ is followed by a boolean sign.  V may take any value\n   between -1023 and +1023,\
    \ inclusive.\n   The absolute value A is coded in one of two different ways according\n\
    \   to its size.  For 0 <= A <= 7, A is tree-coded, and for 8 <= A <=\n   1023,\
    \ the bits in the binary expansion of A are coded using\n   independent boolean\
    \ probabilities.  The coding of A begins with a\n   bool specifying which range\
    \ is in effect.\n   Decoding a motion vector component then requires a 19-position\n\
    \   probability table, whose offsets, along with the procedure used to\n   decode\
    \ components, are as follows:\n   ---- Begin code block --------------------------------------\n\
    \   typedef enum\n   {\n       mvpis_short,         /* short (<= 7) vs long (>=\
    \ 8) */\n       MVPsign,             /* sign for non-zero */\n       MVPshort,\
    \            /* 8 short values = 7-position tree */\n       MVPbits = MVPshort\
    \ + 7,      /* 8 long value bits\n                                       w/independent\
    \ probs */\n       MVPcount = MVPbits + 10      /* 19 probabilities in total */\n\
    \   }\n   MVPindices;\n   typedef Prob MV_CONTEXT [MVPcount];    /* Decoding spec\
    \ for\n                                             a single component */\n  \
    \ /* Tree used for small absolute values (has expected\n      correspondence).\
    \ */\n   const tree_index small_mvtree [2 * (8 - 1)] =\n   {\n    2, 8,      \
    \    /* \"0\" subtree, \"1\" subtree */\n     4, 6,         /* \"00\" subtree,\
    \ \"01\" subtree */\n      -0, -1,      /* 0 = \"000\", 1 = \"001\" */\n     \
    \ -2, -3,      /* 2 = \"010\", 3 = \"011\" */\n     10, 12,       /* \"10\" subtree,\
    \ \"11\" subtree */\n      -4, -5,      /* 4 = \"100\", 5 = \"101\" */\n     \
    \ -6, -7       /* 6 = \"110\", 7 = \"111\" */\n   };\n   /* Read MV component\
    \ at current decoder position, using\n      supplied probs. */\n   int read_mvcomponent(bool_decoder\
    \ *d, const MV_CONTEXT *mvc)\n   {\n       const Prob * const p = (const Prob\
    \ *) mvc;\n       int A = 0;\n       if (read_bool(d, p [mvpis_short]))    /*\
    \ 8 <= A <= 1023 */\n       {\n           /* Read bits 0, 1, 2 */\n          \
    \ int i = 0;\n           do { A += read_bool(d, p [MVPbits + i]) << i;}\n    \
    \         while (++i < 3);\n           /* Read bits 9, 8, 7, 6, 5, 4 */\n    \
    \       i = 9;\n           do { A += read_bool(d, p [MVPbits + i]) << i;}\n  \
    \           while (--i > 3);\n           /* We know that A >= 8 because it is\
    \ coded long,\n              so if A <= 15, bit 3 is one and is not\n        \
    \      explicitly coded. */\n           if (!(A & 0xfff0)  ||  read_bool(d, p\
    \ [MVPbits + 3]))\n               A += 8;\n       }\n       else    /* 0 <= A\
    \ <= 7 */\n           A = treed_read(d, small_mvtree, p + MVPshort);\n       return\
    \ A && read_bool(r, p [MVPsign]) ?  -A : A;\n   }\n   ---- End code block ----------------------------------------\n"
- title: 17.2.  Probability Updates
  contents:
  - "17.2.  Probability Updates\n   The decoder should maintain an array of two MV_CONTEXTs\
    \ for decoding\n   row and column components, respectively.  These MV_CONTEXTs\
    \ should be\n   set to their defaults every key frame.  Each individual probability\n\
    \   may be updated every interframe (by field J of the frame header)\n   using\
    \ a constant table of update probabilities.  Each optional update\n   is of the\
    \ form B?  P(7), that is, a bool followed by a 7-bit\n   probability specification\
    \ if true.\n   As with other dynamic probabilities used by VP8, the updates remain\n\
    \   in effect until the next key frame or until replaced via another\n   update.\n\
    \   In detail, the probabilities should then be managed as follows.\n   ---- Begin\
    \ code block --------------------------------------\n   /* Never-changing table\
    \ of update probabilities for each\n      individual probability used in decoding\
    \ motion vectors. */\n   const MV_CONTEXT vp8_mv_update_probs[2] =\n   {\n   \
    \  {\n       237,\n       246,\n       253, 253, 254, 254, 254, 254, 254,\n  \
    \     254, 254, 254, 254, 254, 250, 250, 252, 254, 254\n     },\n     {\n    \
    \   231,\n       243,\n       245, 253, 254, 254, 254, 254, 254,\n       254,\
    \ 254, 254, 254, 254, 251, 251, 254, 254, 254\n     }\n   };\n   /* Default MV\
    \ decoding probabilities. */\n   const MV_CONTEXT default_mv_context[2] =\n  \
    \ {\n     {                       // row\n       162,                    // is\
    \ short\n       128,                    // sign\n         225, 146, 172, 147,\
    \ 214,  39, 156,      // short tree\n       128, 129, 132,  75, 145, 178, 206,\
    \ 239, 254, 254 // long bits\n     },\n     {                       // same for\
    \ column\n       164,                    // is short\n       128,\n       204,\
    \ 170, 119, 235, 140, 230, 228,\n       128, 130, 130,  74, 148, 180, 203, 236,\
    \ 254, 254 // long bits\n     }\n   };\n   /* Current MV decoding probabilities,\
    \ set to above defaults\n      every key frame. */\n   MV_CONTEXT mvc [2];   \
    \  /* always row, then column */\n   /* Procedure for decoding a complete motion\
    \ vector. */\n   typedef struct { int16 row, col;}  MV;  /* as in previous section\
    \ */\n   MV read_mv(bool_decoder *d)\n   {\n       MV v;\n       v.row = (int16)\
    \ read_mvcomponent(d, mvc);\n       v.col = (int16) read_mvcomponent(d, mvc +\
    \ 1);\n       return v;\n   }\n   /* Procedure for updating MV decoding probabilities,\
    \ called\n      every interframe with \"d\" at the appropriate position in\n \
    \     the frame header. */\n   void update_mvcontexts(bool_decoder *d)\n   {\n\
    \       int i = 0;\n       do {                      /* component = row, then\
    \ column */\n           const Prob *up = mv_update_probs[i];    /* update probs\n\
    \                                                      for component */\n    \
    \       Prob *p = mvc[i];                  /* start decode tbl \"\" */\n     \
    \      Prob * const pstop = p + MVPcount; /* end decode tbl \"\" */\n        \
    \   do {\n               if (read_bool(d, *up++))     /* update this position\
    \ */\n               {\n                   const Prob x = read_literal(d, 7);\n\
    \                   *p = x? x<<1 : 1;\n               }\n           } while (++p\
    \ < pstop);              /* next position */\n       } while (++i < 2);      \
    \                /* next component */\n   }\n   ---- End code block ----------------------------------------\n\
    \   This completes the description of the motion-vector decoding\n   procedure\
    \ and, with it, the procedure for decoding interframe\n   macroblock prediction\
    \ records.\n"
- title: 18.  Interframe Prediction
  contents:
  - "18.  Interframe Prediction\n   Given an inter-prediction specification for the\
    \ current macroblock,\n   that is, a reference frame together with a motion vector\
    \ for each of\n   the sixteen Y subblocks, we describe the calculation of the\n\
    \   prediction buffer for the macroblock.  Frame reconstruction is then\n   completed\
    \ via the previously described processes of residue summation\n   (Section 14)\
    \ and loop filtering (Section 15).\n   The management of inter-predicted subblocks\
    \ and sub-pixel\n   interpolation may be found in the reference decoder file predict.c\n\
    \   (Section 20.14).\n"
- title: 18.1.  Bounds on, and Adjustment of, Motion Vectors
  contents:
  - "18.1.  Bounds on, and Adjustment of, Motion Vectors\n   Since each motion vector\
    \ is differentially encoded from a neighboring\n   block or macroblock and the\
    \ only clamp is to ensure that the\n   referenced motion vector represents a valid\
    \ location inside a\n   reference frame buffer, it is technically possible within\
    \ the VP8\n   format for a block or macroblock to have arbitrarily large motion\n\
    \   vectors, up to the size of the input image plus the extended border\n   areas.\
    \  For practical reasons, VP8 imposes a motion vector size range\n   limit of\
    \ -4096 to 4095 full pixels, regardless of image size (VP8\n   defines 14 raw\
    \ bits for width and height; 16383x16383 is the maximum\n   possible image size).\
    \  Bitstream-compliant encoders and decoders\n   shall enforce this limit.\n \
    \  Because the motion vectors applied to the chroma subblocks have\n   1/8-pixel\
    \ resolution, the synthetic pixel calculation, outlined in\n   Section 5 and detailed\
    \ below, uses this resolution for the luma\n   subblocks as well.  In accordance,\
    \ the stored luma motion vectors are\n   all doubled, each component of each luma\
    \ vector becoming an even\n   integer in the range -2046 to +2046, inclusive.\n\
    \   The vector applied to each chroma subblock is calculated by averaging\n  \
    \ the vectors for the 4 luma subblocks occupying the same visible area\n   as\
    \ the chroma subblock in the usual correspondence; that is, the\n   vector for\
    \ U and V block 0 is the average of the vectors for the Y\n   subblocks { 0, 1,\
    \ 4, 5}, chroma block 1 corresponds to Y blocks { 2,\n   3, 6, 7}, chroma block\
    \ 2 to Y blocks { 8, 9, 12, 13}, and chroma\n   block 3 to Y blocks { 10, 11,\
    \ 14, 15}.\n   In detail, each of the two components of the vectors for each of\
    \ the\n   chroma subblocks is calculated from the corresponding luma vector\n\
    \   components as follows:\n   ---- Begin code block --------------------------------------\n\
    \   int avg(int c1, int c2, int c3, int c4)\n   {\n       int s = c1 + c2 + c3\
    \ + c4;\n       /* The shift divides by 8 (not 4) because chroma pixels\n    \
    \      have twice the diameter of luma pixels.  The handling\n          of negative\
    \ motion vector components is slightly\n          cumbersome because, strictly\
    \ speaking, right shifts\n          of negative numbers are not well-defined in\
    \ C. */\n       return s >= 0 ?  (s + 4) >> 3 : -((-s + 4) >> 3);\n   }\n   ----\
    \ End code block ----------------------------------------\n   Furthermore, if\
    \ the version number in the frame tag specifies only\n   full-pel chroma motion\
    \ vectors, then the fractional parts of both\n   components of the vector are\
    \ truncated to zero, as illustrated in the\n   following pseudocode (assuming\
    \ 3 bits of fraction for both luma and\n   chroma vectors):\n   ---- Begin code\
    \ block --------------------------------------\n       x = x & (~7);\n       y\
    \ = y & (~7);\n   ---- End code block ----------------------------------------\n\
    \   Earlier in this document we described the vp8_clamp_mv() function to\n   limit\
    \ \"nearest\" and \"near\" motion vector predictors inside specified\n   margins\
    \ within the frame boundaries.  Additional clamping is\n   performed for NEWMV\
    \ macroblocks, for which the final motion vector is\n   clamped again after combining\
    \ the \"best\" predictor and the\n   differential vector decoded from the stream.\n\
    \   However, the secondary clamping is not performed for SPLITMV\n   macroblocks,\
    \ meaning that any subblock's motion vector within the\n   SPLITMV macroblock\
    \ may point outside the clamping zone.  These\n   non-clamped vectors are also\
    \ used when determining the decoding tree\n   context for subsequent subblocks'\
    \ modes in the vp8_mvCont() function.\n"
- title: 18.2.  Prediction Subblocks
  contents:
  - "18.2.  Prediction Subblocks\n   The prediction calculation for each subblock\
    \ is then as follows.\n   Temporarily disregarding the fractional part of the\
    \ motion vector\n   (that is, rounding \"up\" or \"left\" by right-shifting each\
    \ component\n   3 bits with sign propagation) and adding the origin (upper left\n\
    \   position) of the (16x16 luma or 8x8 chroma) current macroblock gives\n   us\
    \ an origin in the Y, U, or V plane of the predictor frame (either\n   the golden\
    \ frame or previous frame).\n   Considering that origin to be the upper left corner\
    \ of a (luma or\n   chroma) macroblock, we need to specify the relative positions\
    \ of the\n   pixels associated to that subblock, that is, any pixels that might\
    \ be\n   involved in the sub-pixel interpolation processes for the subblock.\n"
- title: 18.3.  Sub-Pixel Interpolation
  contents:
  - "18.3.  Sub-Pixel Interpolation\n   The sub-pixel interpolation is effected via\
    \ two one-dimensional\n   convolutions.  These convolutions may be thought of\
    \ as operating on a\n   two-dimensional array of pixels whose origin is the subblock\
    \ origin,\n   that is the origin of the prediction macroblock described above\
    \ plus\n   the offset to the subblock.  Because motion vectors are arbitrary,\
    \ so\n   are these \"prediction subblock origins\".\n   The integer part of the\
    \ motion vector is subsumed in the origin of\n   the prediction subblock; the\
    \ 16 (synthetic) pixels we need to\n   construct are given by 16 offsets from\
    \ the origin.  The integer part\n   of each of these offsets is the offset of\
    \ the corresponding pixel\n   from the subblock origin (using the vertical stride).\
    \  To these\n   integer parts is added a constant fractional part, which is simply\n\
    \   the difference between the actual motion vector and its integer\n   truncation\
    \ used to calculate the origins of the prediction macroblock\n   and subblock.\
    \  Each component of this fractional part is an integer\n   between 0 and 7, representing\
    \ a forward displacement in eighths of a\n   pixel.\n   It is these fractional\
    \ displacements that determine the filtering\n   process.  If they both happen\
    \ to be zero (that is, we had a \"whole\n   pixel\" motion vector), the prediction\
    \ subblock is simply copied into\n   the corresponding piece of the current macroblock's\
    \ prediction\n   buffer.  As discussed in Section 14, the layout of the macroblock's\n\
    \   prediction buffer can depend on the specifics of the reconstruction\n   implementation\
    \ chosen.  Of course, the vertical displacement between\n   lines of the prediction\
    \ subblock is given by the stride, as are all\n   vertical displacements used\
    \ here.\n   Otherwise, at least one of the fractional displacements is non-zero.\n\
    \   We then synthesize the missing pixels via a horizontal, followed by a\n  \
    \ vertical, one-dimensional interpolation.\n   The two interpolations are essentially\
    \ identical.  Each uses a (at\n   most) six-tap filter (the choice of which of\
    \ course depends on the\n   one-dimensional offset).  Thus, every calculated pixel\
    \ references at\n   most three pixels before (above or to the left of) it and\
    \ at most\n   three pixels after (below or to the right of) it.  The horizontal\n\
    \   interpolation must calculate two extra rows above and three extra\n   rows\
    \ below the 4x4 block, to provide enough samples for the vertical\n   interpolation\
    \ to proceed.\n   Depending on the reconstruction filter type given in the version\n\
    \   number field in the frame tag, either a bicubic or a bilinear tap set\n  \
    \ is used.\n   The exact implementation of subsampling is as follows.\n   ----\
    \ Begin code block --------------------------------------\n   /* Filter taps taken\
    \ to 7-bit precision.\n      Because DC is always passed, taps always sum to 128.\
    \ */\n   const int BilinearFilters[8][6] =\n   {\n       { 0, 0, 128,   0, 0,\
    \ 0 },\n       { 0, 0, 112,  16, 0, 0 },\n       { 0, 0,  96,  32, 0, 0 },\n \
    \      { 0, 0,  80,  48, 0, 0 },\n       { 0, 0,  64,  64, 0, 0 },\n       { 0,\
    \ 0,  48,  80, 0, 0 },\n       { 0, 0,  32,  96, 0, 0 },\n       { 0, 0,  16,\
    \ 112, 0, 0 }\n   };\n   const int filters [8] [6] = {        /* indexed by displacement\
    \ */\n       { 0,  0,  128,    0,   0,  0 },  /* degenerate whole-pixel */\n \
    \      { 0, -6,  123,   12,  -1,  0 },  /* 1/8 */\n       { 2, -11, 108,   36,\
    \  -8,  1 },  /* 1/4 */\n       { 0, -9,   93,   50,  -6,  0 },  /* 3/8 */\n \
    \      { 3, -16,  77,   77, -16,  3 },  /* 1/2 is symmetric */\n       { 0, -6,\
    \   50,   93,  -9,  0 },  /* 5/8 = reverse of 3/8 */\n       { 1, -8,   36,  108,\
    \ -11,  2 },  /* 3/4 = reverse of 1/4 */\n       { 0, -1,   12,  123,  -6,  0\
    \ }   /* 7/8 = reverse of 1/8 */\n   };\n   /* One-dimensional synthesis of a\
    \ single sample.\n      Filter is determined by fractional displacement */\n \
    \  Pixel interp(\n       const int fil[6],   /* filter to apply */\n       const\
    \ Pixel *p,     /* origin (rounded \"before\") in\n                          \
    \    prediction area */\n       const int s         /* size of one forward step\
    \ \"\" */\n   ) {\n       int32 a = 0;\n       int i = 0;\n       p -= s + s;\
    \         /* move back two positions */\n       do {\n           a += *p * fil[i];\n\
    \           p += s;\n       }  while (++i < 6);\n       return clamp255((a + 64)\
    \ >> 7);    /* round to nearest\n                                            \
    \  8-bit value */\n   }\n   /* First do horizontal interpolation, producing intermediate\n\
    \      buffer. */\n   void Hinterp(\n       Pixel temp[9][4],   /* 9 rows of 4\
    \ (intermediate)\n                              destination values */\n      \
    \ const Pixel *p,     /* subblock origin in prediction\n                     \
    \         frame */\n       int s,              /* vertical stride to be used in\n\
    \                              prediction frame */\n       uint hfrac,       \
    \  /* 0 <= horizontal displacement <= 7 */\n       uint bicubic        /* 1=bicubic\
    \ filter, 0=bilinear */\n   ) {\n       const int * const fil = bicubic ? filters\
    \ [hfrac] :\n         BilinearFilters[hfrac];\n       int r = 0;  do         \
    \     /* for each row */\n       {\n           int c = 0;  do          /* for\
    \ each destination sample */\n           {\n               /* Pixel separation\
    \ = one horizontal step = 1 */\n               temp[r][c] = interp(fil, p + c,\
    \ 1);\n           }\n           while (++c < 4);\n       }\n       while (p +=\
    \ s, ++r < 9);    /* advance p to next row */\n   }\n   /* Finish with vertical\
    \ interpolation, producing final results.\n      Input array \"temp\" is of course\
    \ that computed above. */\n   void Vinterp(\n       Pixel final[4][4],  /* 4 rows\
    \ of 4 (final) destination values */\n       const Pixel temp[9][4],\n       uint\
    \ vfrac,         /* 0 <= vertical displacement <= 7 */\n       uint bicubic  \
    \      /* 1=bicubic filter, 0=bilinear */\n   ) {\n       const int * const fil\
    \ = bicubic ? filters [vfrac] :\n         BilinearFilters[vfrac];\n       int\
    \ r = 0;  do              /* for each row */\n       {\n           int c = 0;\
    \  do          /* for each destination sample */\n           {\n             \
    \  /* Pixel separation = one vertical step = width\n                  of array\
    \ = 4 */\n               final[r][c] = interp(fil, temp[r] + c, 4);\n        \
    \   }\n           while (++c < 4);\n       }\n       while (++r < 4);\n   }\n\
    \   ---- End code block ----------------------------------------\n"
- title: 18.4.  Filter Properties
  contents:
  - "18.4.  Filter Properties\n   We discuss briefly the rationale behind the choice\
    \ of filters.  Our\n   approach is necessarily cursory; a genuinely accurate discussion\n\
    \   would require a couple of books.  Readers unfamiliar with signal\n   processing\
    \ may or may not wish to skip this.\n   All digital signals are of course sampled\
    \ in some fashion.  The case\n   where the inter-sample spacing (say in time for\
    \ audio samples, or\n   space for pixels) is uniform, that is, the same at all\
    \ positions, is\n   particularly common and amenable to analysis.  Many aspects\
    \ of the\n   treatment of such signals are best-understood in the frequency domain\n\
    \   via Fourier Analysis, particularly those aspects of the signal that\n   are\
    \ not changed by shifts in position, especially when those\n   positional shifts\
    \ are not given by a whole number of samples.\n   Non-integral translates of a\
    \ sampled signal are a textbook example of\n   the foregoing.  In our case of\
    \ non-integral motion vectors, we wish\n   to say what the underlying image \"\
    really is\" at these pixels;\n   although we don't have values for them, we feel\
    \ that it makes sense\n   to talk about them.  The correctness of this feeling\
    \ is predicated on\n   the underlying signal being band-limited, that is, not\
    \ containing any\n   energy in spatial frequencies that cannot be faithfully rendered\
    \ at\n   the pixel resolution at our disposal.  In one dimension, this range\n\
    \   of \"OK\" frequencies is called the Nyquist band; in our two-\n   dimensional\
    \ case of integer-grid samples, this range might be termed\n   a Nyquist rectangle.\
    \  The finer the grid, the more we know about the\n   image, and the wider the\
    \ Nyquist rectangle.\n   It turns out that, for such band-limited signals, there\
    \ is indeed an\n   exact mathematical formula to produce the correct sample value\
    \ at an\n   arbitrary point.  Unfortunately, this calculation requires the\n \
    \  consideration of every single sample in the image, as well as needing\n   to\
    \ operate at infinite precision.  Also, strictly speaking, all band-\n   limited\
    \ signals have infinite spatial (or temporal) extent, so\n   everything we are\
    \ discussing is really some sort of approximation.\n   It is true that the theoretically\
    \ correct subsampling procedure, as\n   well as any approximation thereof, is\
    \ always given by a translation-\n   invariant weighted sum (or filter) similar\
    \ to that used by VP8.  It\n   is also true that the reconstruction error made\
    \ by such a filter can\n   be simply represented as a multiplier in the frequency\
    \ domain; that\n   is, such filters simply multiply the Fourier transform of any\
    \ signal\n   to which they are applied by a fixed function associated to the\n\
    \   filter.  This fixed function is usually called the frequency response\n  \
    \ (or transfer function); the ideal subsampling filter has a frequency\n   response\
    \ equal to one in the Nyquist rectangle and zero everywhere\n   else.\n   Another\
    \ basic fact about approximations to \"truly correct\"\n   subsampling is that\
    \ the wider the subrectangle (within the Nyquist\n   rectangle) of spatial frequencies\
    \ one wishes to \"pass\" (that is,\n   correctly render) or, put more accurately,\
    \ the closer one wishes to\n   approximate the ideal transfer function, the more\
    \ samples of the\n   original signal must be considered by the subsampling, and\
    \ the wider\n   the calculation precision necessitated.\n   The filters chosen\
    \ by VP8 were chosen, within the constraints of 4 or\n   6 taps and 7-bit precision,\
    \ to do the best possible job of handling\n   the low spatial frequencies near\
    \ the 0th DC frequency along with\n   introducing no resonances (places where\
    \ the absolute value of the\n   frequency response exceeds one).\n   The justification\
    \ for the foregoing has two parts.  First, resonances\n   can produce extremely\
    \ objectionable visible artifacts when, as often\n   happens in actual compressed\
    \ video streams, filters are applied\n   repeatedly.  Second, the vast majority\
    \ of energy in real-world images\n   lies near DC and not at the high end.\n \
    \  To get slightly more specific, the filters chosen by VP8 are the best\n   resonance-free\
    \ 4- or 6-tap filters possible, where \"best\" describes\n   the frequency response\
    \ near the origin: The response at 0 is required\n   to be 1, and the graph of\
    \ the response at 0 is as flat as possible.\n   To provide an intuitively more\
    \ obvious point of reference, the \"best\"\n   2-tap filter is given by simple\
    \ linear interpolation between the\n   surrounding actual pixels.\n   Finally,\
    \ it should be noted that, because of the way motion vectors\n   are calculated,\
    \ the (shorter) 4-tap filters (used for odd fractional\n   displacements) are\
    \ applied in the chroma plane only.  Human color\n   perception is notoriously\
    \ poor, especially where higher spatial\n   frequencies are involved.  The shorter\
    \ filters are easier to\n   understand mathematically, and the difference between\
    \ them and a\n   theoretically slightly better 6-tap filter is negligible where\
    \ chroma\n   is concerned.\n"
- title: '19.  Annex A: Bitstream Syntax'
  contents:
  - "19.  Annex A: Bitstream Syntax\n   This annex presents the bitstream syntax in\
    \ a tabular form.  All the\n   information elements have been introduced and explained\
    \ in the\n   previous sections but are collected here for a quick reference. \
    \ Each\n   syntax element is briefly described after the tabular representation\n\
    \   along with a reference to the corresponding paragraph in the main\n   document.\
    \  The meaning of each syntax element value is not repeated\n   here.\n   The\
    \ top-level hierarchy of the bitstream is introduced in Section 4.\n   Definition\
    \ of syntax element coding types can be found in Section 8.\n   The types used\
    \ in the representation in this annex are:\n   o  f(n), n-bit value from stream\
    \ (n successive bits, not boolean\n      encoded)\n   o  L(n), n-bit number encoded\
    \ as n booleans (with equal probability\n      of being 0 or 1)\n   o  B(p), bool\
    \ with probability p of being 0\n   o  T, tree-encoded value\n"
- title: 19.1.  Uncompressed Data Chunk
  contents:
  - "19.1.  Uncompressed Data Chunk\n   | Frame Tag                              \
    \           | Type  |\n   | -------------------------------------------------\
    \ | ----- |\n   | frame_tag                                         | f(24) |\n\
    \   | if (key_frame) {                                  |       |\n   |     start_code\
    \                                    | f(24) |\n   |     horizontal_size_code\
    \                          | f(16) |\n   |     vertical_size_code            \
    \                | f(16) |\n   | }                                           \
    \      |       |\n   The 3-byte frame tag can be parsed as follows:\n   ---- Begin\
    \ code block --------------------------------------\n   unsigned char *c = pbi->source;\n\
    \   unsigned int tmp;\n   tmp = (c[2] << 16) | (c[1] << 8) | c[0];\n   key_frame\
    \ = tmp & 0x1;\n   version = (tmp >> 1) & 0x7;\n   show_frame = (tmp >> 4) & 0x1;\n\
    \   first_part_size = (tmp >> 5) & 0x7FFFF;\n   ---- End code block ----------------------------------------\n\
    \   Where:\n   o  key_frame indicates whether the current frame is a key frame\n\
    \      or not.\n   o  version determines the bitstream version.\n   o  show_frame\
    \ indicates whether the current frame is meant to be\n      displayed or not.\n\
    \   o  first_part_size determines the size of the first partition\n      (control\
    \ partition), excluding the uncompressed data chunk.\n   The start_code is a constant\
    \ 3-byte pattern having value 0x9d012a.\n   The latter part of the uncompressed\
    \ chunk (after the start_code) can\n   be parsed as follows:\n   ---- Begin code\
    \ block --------------------------------------\n   unsigned char *c = pbi->source\
    \ + 6;\n   unsigned int tmp;\n   tmp = (c[1] << 8) | c[0];\n   width = tmp & 0x3FFF;\n\
    \   horizontal_scale = tmp >> 14;\n   tmp = (c[3] << 8) | c[2];\n   height = tmp\
    \ & 0x3FFF;\n   vertical_scale = tmp >> 14;\n   ---- End code block ----------------------------------------\n"
- title: 19.2.  Frame Header
  contents:
  - "19.2.  Frame Header\n   | Frame Header                                      |\
    \ Type  |\n   | ------------------------------------------------- | ----- |\n\
    \   | if (key_frame) {                                  |       |\n   |   color_space\
    \                                     | L(1)  |\n   |   clamping_type        \
    \                           | L(1)  |\n   | }                                \
    \                 |       |\n   | segmentation_enabled                       \
    \       | L(1)  |\n   | if (segmentation_enabled)                         |  \
    \     |\n   |   update_segmentation()                           |       |\n  \
    \ | filter_type                                       | L(1)  |\n   | loop_filter_level\
    \                                 | L(6)  |\n   | sharpness_level            \
    \                       | L(3)  |\n   | mb_lf_adjustments()                  \
    \             |       |\n   | log2_nbr_of_dct_partitions                     \
    \   | L(2)  |\n   | quant_indices()                                   |      \
    \ |\n   | if (key_frame)                                    |       |\n   |  \
    \ refresh_entropy_probs                           | L(1)  |\n   | else {     \
    \                                       |       |\n   |   refresh_golden_frame\
    \                            | L(1)  |\n   |   refresh_alternate_frame       \
    \                  | L(1)  |\n   |   if (!refresh_golden_frame)              \
    \        |       |\n   |     copy_buffer_to_golden                         | L(2)\
    \  |\n   |   if (!refresh_alternate_frame)                   |       |\n   | \
    \    copy_buffer_to_alternate                      | L(2)  |\n   |   sign_bias_golden\
    \                                | L(1)  |\n   |   sign_bias_alternate       \
    \                      | L(1)  |\n   |   refresh_entropy_probs               \
    \            | L(1)  |\n   |   refresh_last                                  \
    \  | L(1)  |\n   | }                                                 |       |\n\
    \   | token_prob_update()                               |       |\n   | mb_no_skip_coeff\
    \                                  | L(1)  |\n   | if (mb_no_skip_coeff)     \
    \                        |       |\n   |   prob_skip_false                   \
    \              | L(8)  |\n   | if (!key_frame) {                             \
    \    |       |\n   |   prob_intra                                      | L(8)\
    \  |\n   |   prob_last                                       | L(8)  |\n   | \
    \  prob_gf                                         | L(8)  |\n   |   intra_16x16_prob_update_flag\
    \                    | L(1)  |\n   |   if (intra_16x16_prob_update_flag) {   \
    \          |       |\n   |     for (i = 0; i < 4; i++)                       |\
    \       |\n   |       intra_16x16_prob                            | L(8)  |\n\
    \   |   }                                               |       |\n   |   intra_chroma\
    \ prob_update_flag                   | L(1)  |\n   |   if (intra_chroma_prob_update_flag)\
    \ {            |       |\n   |     for (i = 0; i < 3; i++)                   \
    \    |       |\n   |       intra_chroma_prob                           | L(8)\
    \  |\n   |   }                                               |       |\n   | \
    \  mv_prob_update()                                |       |\n   | }         \
    \                                        |       |\n   o  color_space defines\
    \ the YUV color space of the sequence\n      (Section 9.2)\n   o  clamping_type\
    \ specifies if the decoder is required to clamp the\n      reconstructed pixel\
    \ values (Section 9.2)\n   o  segmentation_enabled enables the segmentation feature\
    \ for the\n      current frame (Section 9.3)\n   o  filter_type determines whether\
    \ the normal or the simple loop\n      filter is used (Sections 9.4, 15)\n   o\
    \  loop_filter_level controls the deblocking filter\n      (Sections 9.4, 15)\n\
    \   o  sharpness_level controls the deblocking filter (Sections 9.4, 15)\n   o\
    \  log2_nbr_of_dct_partitions determines the number of separate\n      partitions\
    \ containing the DCT coefficients of the macroblocks\n      (Section 9.5)\n  \
    \ o  refresh_entropy_probs determines whether updated token\n      probabilities\
    \ are used only for this frame or until further update\n   o  refresh_golden_frame\
    \ determines if the current decoded frame\n      refreshes the golden frame (Section\
    \ 9.7)\n   o  refresh_alternate_frame determines if the current decoded frame\n\
    \      refreshes the alternate reference frame (Section 9.7)\n   o  copy_buffer_to_golden\
    \ determines if the golden reference is\n      replaced by another reference (Section\
    \ 9.7)\n   o  copy_buffer_to_alternate determines if the alternate reference is\n\
    \      replaced by another reference (Section 9.7)\n   o  sign_bias_golden controls\
    \ the sign of motion vectors when the\n      golden frame is referenced (Section\
    \ 9.7)\n   o  sign_bias_alternate controls the sign of motion vectors when the\n\
    \      alternate frame is referenced (Section 9.7)\n   o  refresh_last determines\
    \ if the current decoded frame refreshes the\n      last frame reference buffer\
    \ (Section 9.8)\n   o  mb_no_skip_coeff enables or disables the skipping of macroblocks\n\
    \      containing no non-zero coefficients (Section 9.10)\n   o  prob_skip_false\
    \ indicates the probability that the macroblock is\n      not skipped (flag indicating\
    \ skipped macroblock is false)\n      (Section 9.10)\n   o  prob_intra indicates\
    \ the probability of an intra macroblock\n      (Section 9.10)\n   o  prob_last\
    \ indicates the probability that the last reference frame\n      is used for inter-prediction\
    \ (Section 9.10)\n   o  prob_gf indicates the probability that the golden reference\
    \ frame\n      is used for inter-prediction (Section 9.10)\n   o  intra_16x16_prob_update_flag\
    \ indicates if the branch probabilities\n      used in the decoding of the luma\
    \ intra-prediction mode are updated\n      (Section 9.10)\n   o  intra_16x16_prob\
    \ indicates the branch probabilities of the luma\n      intra-prediction mode\
    \ decoding tree\n   o  intra_chroma_prob_update_flag indicates if the branch\n\
    \      probabilities used in the decoding of the chroma intra-prediction\n   \
    \   mode are updated (Section 9.10)\n   o  intra_chroma_prob indicates the branch\
    \ probabilities of the chroma\n      intra-prediction mode decoding tree\n   |\
    \ update_segmentation()                             | Type  |\n   | -------------------------------------------------\
    \ | ----- |\n   | update_mb_segmentation_map                        | L(1)  |\n\
    \   | update_segment_feature_data                       | L(1)  |\n   | if (update_segment_feature_data)\
    \ {                |       |\n   |   segment_feature_mode                    \
    \        | L(1)  |\n   |   for (i = 0; i < 4; i++) {                       | \
    \      |\n   |     quantizer_update                              | L(1)  |\n \
    \  |     if (quantizer_update) {                       |       |\n   |       quantizer_update_value\
    \                      | L(7)  |\n   |       quantizer_update_sign           \
    \            | L(1)  |\n   |     }                                           \
    \  |       |\n   |   }                                               |       |\n\
    \   |   for (i = 0; i < 4; i++) {                       |       |\n   |     loop_filter_update\
    \                            | L(1)  |\n   |     if (loop_filter_update) {   \
    \                  |       |\n   |       lf_update_value                     \
    \        | L(6)  |\n   |       lf_update_sign                              | L(1)\
    \  |\n   |     }                                             |       |\n   | \
    \  }                                               |       |\n   | }         \
    \                                        |       |\n   | if (update_mb_segmentation_map)\
    \ {                 |       |\n   |   for (i = 0; i < 3; i++) {              \
    \         |       |\n   |     segment_prob_update                           |\
    \ L(1)  |\n   |     if (segment_prob_update)                      |       |\n\
    \   |       segment_prob                                | L(8)  |\n   |   }  \
    \                                             |       |\n   | }              \
    \                                   |       |\n   o  update_mb_segmentation_map\
    \ determines if the MB segmentation map\n      is updated in the current frame\
    \ (Section 9.3)\n   o  update_segment_feature_data indicates if the segment feature\
    \ data\n      is updated in the current frame (Section 9.3)\n   o  segment_feature_mode\
    \ indicates the feature data update mode, 0 for\n      delta and 1 for the absolute\
    \ value (Section 9.3)\n   o  quantizer_update indicates if the quantizer value\
    \ is updated for\n      the i^(th) segment (Section 9.3)\n   o  quantizer_update_value\
    \ indicates the update value for the segment\n      quantizer (Section 9.3)\n\
    \   o  quantizer_update_sign indicates the update sign for the segment\n     \
    \ quantizer (Section 9.3)\n   o  loop_filter_update indicates if the loop filter\
    \ level value is\n      updated for the i^(th) segment (Section 9.3)\n   o  lf_update_value\
    \ indicates the update value for the loop filter\n      level (Section 9.3)\n\
    \   o  lf_update_sign indicates the update sign for the loop filter level\n  \
    \    (Section 9.3)\n   o  segment_prob_update indicates whether the branch probabilities\n\
    \      used to decode the segment_id in the MB header are decoded from\n     \
    \ the stream or use the default value of 255 (Section 9.3)\n   o  segment_prob\
    \ indicates the branch probabilities of the segment_id\n      decoding tree (Section\
    \ 9.3)\n   | mb_lf_adjustments()                               | Type  |\n   |\
    \ ------------------------------------------------- | ----- |\n   | loop_filter_adj_enable\
    \                            | L(1)  |\n   | if (loop_filter_adj_enable) {   \
    \                  |       |\n   |   mode_ref_lf_delta_update                \
    \        | L(1)  |\n   |   if (mode_ref_lf_delta_update) {                 | \
    \      |\n   |     for (i = 0; i < 4; i++) {                     |       |\n \
    \  |       ref_frame_delta_update_flag                 | L(1)  |\n   |       if\
    \ (ref_frame_delta_update_flag) {          |       |\n   |         delta_magnitude\
    \                           | L(6)  |\n   |         delta_sign               \
    \                 | L(1)  |\n   |       }                                    \
    \       |       |\n   |     }                                             |  \
    \     |\n   |     for (i = 0; i < 4; i++) {                     |       |\n  \
    \ |       mb_mode_delta_update_flag                   | L(1)  |\n   |       if\
    \ (mb_mode_delta_update_flag) {            |       |\n   |         delta_magnitude\
    \                           | L(6)  |\n   |         delta_sign               \
    \                 | L(1)  |\n   |       }                                    \
    \       |       |\n   |     }                                             |  \
    \     |\n   |   }                                               |       |\n  \
    \ | }                                                 |       |\n   o  loop_filter_adj_enable\
    \ indicates if the MB-level loop filter\n      adjustment (based on the used reference\
    \ frame and coding mode) is\n      on for the current frame (Section 9.4)\n  \
    \ o  mode_ref_lf_delta_update indicates if the delta values used in an\n     \
    \ adjustment are updated in the current frame (Section 9.4)\n   o  ref_frame_delta_update_flag\
    \ indicates if the adjustment delta\n      value corresponding to a certain used\
    \ reference frame is updated\n      (Section 9.4)\n   o  delta_magnitude is the\
    \ absolute value of the delta value\n   o  delta_sign is the sign of the delta\
    \ value\n   o  mb_mode_delta_update_flag indicates if the adjustment delta value\n\
    \      corresponding to a certain MB prediction mode is updated\n      (Section\
    \ 9.4)\n   | quant_indices()                                   | Type  |\n   |\
    \ ------------------------------------------------- | ----- |\n   | y_ac_qi  \
    \                                         | L(7)  |\n   | y_dc_delta_present \
    \                               | L(1)  |\n   | if (y_dc_delta_present) {    \
    \                     |       |\n   |   y_dc_delta_magnitude                 \
    \           | L(4)  |\n   |   y_dc_delta_sign                                \
    \ | L(1)  |\n   | }                                                 |       |\n\
    \   | y2_dc_delta_present                               | L(1)  |\n   | if (y2_dc_delta_present)\
    \ {                        |       |\n   |   y2_dc_delta_magnitude           \
    \                | L(4)  |\n   |   y2_dc_delta_sign                          \
    \      | L(1)  |\n   | }                                                 |   \
    \    |\n   | y2_ac_delta_present                               | L(1)  |\n   |\
    \ if (y2_ac_delta_present) {                        |       |\n   |   y2_ac_delta_magnitude\
    \                           | L(4)  |\n   |   y2_ac_delta_sign               \
    \                 | L(1)  |\n   | }                                          \
    \       |       |\n   | uv_dc_delta_present                               | L(1)\
    \  |\n   | if (uv_dc_delta_present) {                        |       |\n   | \
    \  uv_dc_delta_magnitude                           | L(4)  |\n   |   uv_dc_delta_sign\
    \                                | L(1)  |\n   | }                           \
    \                      |       |\n   | uv_ac_delta_present                   \
    \            | L(1)  |\n   | if (uv_ac_delta_present) {                      \
    \  |       |\n   |   uv_ac_delta_magnitude                           | L(4)  |\n\
    \   |   uv_ac_delta_sign                                | L(1)  |\n   | }    \
    \                                             |       |\n   o  y_ac_qi is the\
    \ dequantization table index used for the luma AC\n      coefficients (and other\
    \ coefficient groups if no delta value is\n      present) (Section 9.6)\n   o\
    \  y_dc_delta_present indicates if the stream contains a delta value\n      that\
    \ is added to the baseline index to obtain the luma DC\n      coefficient dequantization\
    \ index (Section 9.6)\n   o  y_dc_delta_magnitude is the magnitude of the delta\
    \ value\n      (Section 9.6)\n   o  y_dc_delta_sign is the sign of the delta value\
    \ (Section 9.6)\n   o  y2_dc_delta_present indicates if the stream contains a\
    \ delta value\n      that is added to the baseline index to obtain the Y2 block\
    \ DC\n      coefficient dequantization index (Section 9.6)\n   o  y2_ac_delta_present\
    \ indicates if the stream contains a delta value\n      that is added to the baseline\
    \ index to obtain the Y2 block AC\n      coefficient dequantization index (Section\
    \ 9.6)\n   o  uv_dc_delta_present indicates if the stream contains a delta value\n\
    \      that is added to the baseline index to obtain the chroma DC\n      coefficient\
    \ dequantization index (Section 9.6)\n   o  uv_ac_delta_present indicates if the\
    \ stream contains a delta value\n      that is added to the baseline index to\
    \ obtain the chroma AC\n      coefficient dequantization index (Section 9.6)\n\
    \   | token_prob_update()                               | Type  |\n   | -------------------------------------------------\
    \ | ----- |\n   | for (i = 0; i < 4; i++) {                         |       |\n\
    \   |   for (j = 0; j < 8; j++) {                       |       |\n   |     for\
    \ (k = 0; k < 3; k++) {                     |       |\n   |       for (l = 0;\
    \ l < 11; l++) {                  |       |\n   |         coeff_prob_update_flag\
    \                    | L(1)  |\n   |         if (coeff_prob_update_flag)     \
    \          |       |\n   |           coeff_prob                              |\
    \ L(8)  |\n   |       }                                           |       |\n\
    \   |     }                                             |       |\n   |   }  \
    \                                             |       |\n   | }              \
    \                                   |       |\n   o  coeff_prob_update_flag indicates\
    \ if the corresponding branch\n      probability is updated in the current frame\
    \ (Section 13.4)\n   o  coeff_prob is the new branch probability (Section 13.4)\n\
    \   | mv_prob_update()                                  | Type  |\n   | -------------------------------------------------\
    \ | ----- |\n   | for (i = 0; i < 2; i++) {                         |       |\n\
    \   |   for (j = 0; j < 19; j++) {                      |       |\n   |     mv_prob_update_flag\
    \                           | L(1)  |\n   |     if (mv_prob_update_flag)     \
    \                 |       |\n   |       prob                                 \
    \       | L(7)  |\n   |   }                                               |  \
    \     |\n   | }                                                 |       |\n  \
    \ o  mv_prob_update_flag indicates if the corresponding MV decoding\n      probability\
    \ is updated in the current frame (Section 17.2)\n   o  prob is the updated probability\
    \ (Section 17.2)\n"
- title: 19.3.  Macroblock Data
  contents:
  - "19.3.  Macroblock Data\n   | Macroblock Data                                \
    \   | Type  |\n   | ------------------------------------------------- | -----\
    \ |\n   | macroblock_header()                               |       |\n   | residual_data()\
    \                                   |       |\n   | macroblock_header()      \
    \                         | Type  |\n   | -------------------------------------------------\
    \ | ----- |\n   | if (update_mb_segmentation_map)                   |       |\n\
    \   |   segment_id                                      | T     |\n   | if (mb_no_skip_coeff)\
    \                             |       |\n   |   mb_skip_coeff                \
    \                   | B(p)  |\n   | if (!key_frame)                          \
    \         |       |\n   |   is_inter_mb                                     |\
    \ B(p)  |\n   | if (is_inter_mb) {                                |       |\n\
    \   |   mb_ref_frame_sel1                               | B(p)  |\n   |   if (mb_ref_frame_sel1)\
    \                          |       |\n   |     mb_ref_frame_sel2             \
    \                | B(p)  |\n   |   mv_mode                                   \
    \      | T     |\n   |   if (mv_mode == SPLITMV) {                       |   \
    \    |\n   |     mv_split_mode                                 | T     |\n   |\
    \     for (i = 0; i < numMvs; i++) {                |       |\n   |       sub_mv_mode\
    \                                 | T     |\n   |       if (sub_mv_mode == NEWMV4x4)\
    \ {              |       |\n   |         read_mvcomponent()                  \
    \      |       |\n   |         read_mvcomponent()                        |   \
    \    |\n   |       }                                           |       |\n   |\
    \     }                                             |       |\n   |   } else if\
    \ (mv_mode == NEWMV) {                  |       |\n   |     read_mvcomponent()\
    \                            |       |\n   |     read_mvcomponent()          \
    \                  |       |\n   |   }                                       \
    \        |       |\n   | } else { /* intra mb */                           | \
    \      |\n   |   intra_y_mode                                    | T     |\n \
    \  |   if (intra_y_mode == B_PRED) {                   |       |\n   |     for\
    \ (i = 0; i < 16; i++)                      |       |\n   |       intra_b_mode\
    \                                | T     |\n   |   }                         \
    \                      |       |\n   |   intra_uv_mode                       \
    \            | T     |\n   | }                                               \
    \  |       |\n   o  segment_id indicates to which segment the macroblock belongs\n\
    \      (Section 10)\n   o  mb_skip_coeff indicates whether the macroblock contains\
    \ any coded\n      coefficients or not (Section 11.1)\n   o  is_inter_mb indicates\
    \ whether the macroblock is intra- or inter-\n      coded (Section 16)\n   o \
    \ mb_ref_frame_sel1 selects the reference frame to be used; last\n      frame\
    \ (0), golden/alternate (1) (Section 16.2)\n   o  mb_ref_frame_sel2 selects whether\
    \ the golden (0) or alternate\n      reference frame (1) is used (Section 16.2)\n\
    \   o  mv_mode determines the macroblock motion vector mode\n      (Section 16.2)\n\
    \   o  mv_split_mode gives the macroblock partitioning specification and\n   \
    \   determines the number of motion vectors used (numMvs)\n      (Section 16.2)\n\
    \   o  sub_mv_mode determines the sub-macroblock motion vector mode for\n    \
    \  macroblocks coded using the SPLITMV motion vector mode\n      (Section 16.2)\n\
    \   o  intra_y_mode selects the luminance intra-prediction mode\n      (Section\
    \ 16.1)\n   o  intra_b_mode selects the sub-macroblock luminance prediction mode\n\
    \      for macroblocks coded using B_PRED mode (Section 16.1)\n   o  intra_uv_mode\
    \ selects the chrominance intra-prediction mode\n      (Section 16.1)\n   | residual_data()\
    \                                   | Type  |\n   | -------------------------------------------------\
    \ | ----- |\n   | if (!mb_skip_coeff) {                             |       |\n\
    \   |   if ( (is_inter_mb && mv_mode != SPLITMV) ||     |       |\n   |      \
    \  (!is_inter_mb && intra_y_mode != B_PRED) ) |       |\n   |     residual_block()\
    \ /* Y2 */                     |       |\n   |   for (i = 0; i < 24; i++)    \
    \                    |       |\n   |     residual_block() /* 16 Y, 4 U, 4 V */\
    \         |       |\n   | }                                                 |\
    \       |\n   | residual_block()                                  | Type  |\n\
    \   | ------------------------------------------------- | ----- |\n   | for (i\
    \ = firstCoeff; i < 16; i++) {               |       |\n   |   token         \
    \                                  | T     |\n   |   if (token == EOB) break;\
    \                        |       |\n   |   if (token_has_extra_bits)         \
    \              |       |\n   |     extra_bits                                \
    \    | L(n)  |\n   |   if (coefficient != 0)                           |     \
    \  |\n   |     sign                                          | L(1)  |\n   | }\
    \                                                 |       |\n   o  firstCoeff\
    \ is 1 for luma blocks of macroblocks containing Y2\n      subblock; otherwise\
    \ 0\n   o  token defines the value of the coefficient, the value range of the\n\
    \      coefficient, or the end of block (Section 13.2)\n   o  extra_bits determines\
    \ the value of the coefficient within the\n      value range defined by the token\
    \ (Section 13.2)\n   o  sign indicates the sign of the coefficient (Section 13.2)\n"
- title: '20.  Attachment One: Reference Decoder Source Code'
  contents:
  - '20.  Attachment One: Reference Decoder Source Code

    '
- title: 20.1.  bit_ops.h
  contents:
  - "20.1.  bit_ops.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef BIT_OPS_H\n\
    \   #define BIT_OPS_H\n   /* Evaluates to a mask with n bits set */\n   #define\
    \ BITS_MASK(n) ((1<<(n))-1)\n   /* Returns len bits, with the LSB at position\
    \ bit */\n   #define BITS_GET(val, bit, len) (((val)>>(bit))&BITS_MASK(len))\n\
    \   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.2.  bool_decoder.h
  contents:
  - "20.2.  bool_decoder.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef BOOL_DECODER_H\n\
    \   #define BOOL_DECODER_H\n   #include <stddef.h>\n   struct bool_decoder\n \
    \  {\n       const unsigned char *input;      /* next compressed data byte */\n\
    \       size_t               input_len;  /* length of the input buffer */\n  \
    \     unsigned int         range;      /* identical to encoder's\n           \
    \                              * range */\n       unsigned int         value;\
    \      /* contains at least 8\n                                         * significant\
    \ bits */\n       int                  bit_count;  /* # of bits shifted out of\n\
    \                                         * value, max 7 */\n   };\n   static\
    \ void\n   init_bool_decoder(struct bool_decoder *d,\n                     const\
    \ unsigned char *start_partition,\n                     size_t               sz)\n\
    \   {\n       if (sz >= 2)\n       {\n           d->value = (start_partition[0]\
    \ << 8) /* first 2 input\n                                                 * bytes\
    \ */\n                      | start_partition[1];\n           d->input = start_partition\
    \ + 2;      /* ptr to next byte */\n           d->input_len = sz - 2;\n      \
    \ }\n       else\n       {\n           d->value = 0;\n           d->input = NULL;\n\
    \           d->input_len = 0;\n       }\n       d->range = 255;    /* initial\
    \ range is full */\n       d->bit_count = 0;  /* have not yet shifted out any\
    \ bits */\n   }\n   static int bool_get(struct bool_decoder *d, int probability)\n\
    \   {\n       /* range and split are identical to the corresponding values\n \
    \         used by the encoder when this bool was written */\n       unsigned int\
    \  split = 1 + (((d->range - 1) * probability) >> 8);\n       unsigned int  SPLIT\
    \ = split << 8;\n       int           retval;           /* will be 0 or 1 */\n\
    \       if (d->value >= SPLIT)    /* encoded a one */\n       {\n           retval\
    \ = 1;\n           d->range -= split;  /* reduce range */\n           d->value\
    \ -= SPLIT;  /* subtract off left endpoint of\n                              \
    \  * interval */\n       }\n       else                  /* encoded a zero */\n\
    \       {\n           retval = 0;\n           d->range = split; /* reduce range,\
    \ no change in left\n                              * endpoint */\n       }\n \
    \      while (d->range < 128)    /* shift out irrelevant value bits */\n     \
    \  {\n           d->value <<= 1;\n           d->range <<= 1;\n           if (++d->bit_count\
    \ == 8)  /* shift in new bits 8 at a time */\n           {\n               d->bit_count\
    \ = 0;\n               if (d->input_len)\n               {\n                 \
    \  d->value |= *d->input++;\n                   d->input_len--;\n            \
    \   }\n           }\n       }\n       return retval;\n   }\n   static int bool_get_bit(struct\
    \ bool_decoder *br)\n   {\n       return bool_get(br, 128);\n   }\n   static int\
    \ bool_get_uint(struct bool_decoder *br, int bits)\n   {\n       int z = 0;\n\
    \       int bit;\n       for (bit = bits - 1; bit >= 0; bit--)\n       {\n   \
    \        z |= (bool_get_bit(br) << bit);\n       }\n       return z;\n   }\n \
    \  static int bool_get_int(struct bool_decoder *br, int bits)\n   {\n       int\
    \ z = 0;\n       int bit;\n       for (bit = bits - 1; bit >= 0; bit--)\n    \
    \   {\n           z |= (bool_get_bit(br) << bit);\n       }\n       return bool_get_bit(br)\
    \ ? -z : z;\n   }\n   static int bool_maybe_get_int(struct bool_decoder *br, int\
    \ bits)\n   {\n       return bool_get_bit(br) ? bool_get_int(br, bits) : 0;\n\
    \   }\n   static int\n   bool_read_tree(struct bool_decoder *bool,\n         \
    \         const int           *t,\n                  const unsigned char *p)\n\
    \   {\n       int i = 0;\n       while ((i = t[ i + bool_get(bool, p[i>>1])])\
    \ > 0);\n       return -i;\n   }\n   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.3.  dequant_data.h
  contents:
  - "20.3.  dequant_data.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   static const int dc_q_lookup[128]\
    \ =\n   {\n       4,    5,    6,    7,    8,    9,    10,   10,\n       11,  \
    \ 12,   13,   14,   15,   16,   17,   17,\n       18,   19,   20,   20,   21,\
    \   21,   22,   22,\n       23,   23,   24,   25,   25,   26,   27,   28,\n  \
    \     29,   30,   31,   32,   33,   34,   35,   36,\n       37,   37,   38,  \
    \ 39,   40,   41,   42,   43,\n       44,   45,   46,   46,   47,   48,   49,\
    \   50,\n       51,   52,   53,   54,   55,   56,   57,   58,\n       59,   60,\
    \   61,   62,   63,   64,   65,   66,\n       67,   68,   69,   70,   71,   72,\
    \   73,   74,\n       75,   76,   76,   77,   78,   79,   80,   81,\n       82,\
    \   83,   84,   85,   86,   87,   88,   89,\n       91,   93,   95,   96,   98,\
    \   100,  101,  102,\n       104,  106,  108,  110,  112,  114,  116,  118,\n\
    \       122,  124,  126,  128,  130,  132,  134,  136,\n       138,  140,  143,\
    \  145,  148,  151,  154,  157\n   };\n   static const int ac_q_lookup[128] =\n\
    \   {\n       4,    5,    6,    7,    8,    9,    10,   11,\n       12,   13,\
    \   14,   15,   16,   17,   18,   19,\n       20,   21,   22,   23,   24,   25,\
    \   26,   27,\n       28,   29,   30,   31,   32,   33,   34,   35,\n       36,\
    \   37,   38,   39,   40,   41,   42,   43,\n       44,   45,   46,   47,   48,\
    \   49,   50,   51,\n       52,   53,   54,   55,   56,   57,   58,   60,\n  \
    \     62,   64,   66,   68,   70,   72,   74,   76,\n       78,   80,   82,  \
    \ 84,   86,   88,   90,   92,\n       94,   96,   98,   100,  102,  104,  106,\
    \  108,\n       110,  112,  114,  116,  119,  122,  125,  128,\n       131,  134,\
    \  137,  140,  143,  146,  149,  152,\n       155,  158,  161,  164,  167,  170,\
    \  173,  177,\n       181,  185,  189,  193,  197,  201,  205,  209,\n       213,\
    \  217,  221,  225,  229,  234,  239,  245,\n       249,  254,  259,  264,  269,\
    \  274,  279,  284\n   };\n   ---- End code block ----------------------------------------\n"
- title: 20.4.  dixie.c
  contents:
  - "20.4.  dixie.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #include \"vpx_codec_internal.h\"\
    \n   #include \"bit_ops.h\"\n   #include \"dixie.h\"\n   #include \"vp8_prob_data.h\"\
    \n   #include \"dequant_data.h\"\n   #include \"modemv.h\"\n   #include \"tokens.h\"\
    \n   #include \"predict.h\"\n   #include \"dixie_loopfilter.h\"\n   #include <string.h>\n\
    \   #include <assert.h>\n   enum\n   {\n       FRAME_HEADER_SZ = 3,\n       KEYFRAME_HEADER_SZ\
    \ = 7\n   };\n   #define ARRAY_COPY(a,b) {\\\n       assert(sizeof(a)==sizeof(b));memcpy(a,b,sizeof(a));}\n\
    \   static void\n   decode_entropy_header(struct vp8_decoder_ctx    *ctx,\n  \
    \                       struct bool_decoder       *bool,\n                   \
    \      struct vp8_entropy_hdr    *hdr)\n   {\n       int i, j, k, l;\n       /*\
    \ Read coefficient probability updates */\n       for (i = 0; i < BLOCK_TYPES;\
    \ i++)\n           for (j = 0; j < COEFF_BANDS; j++)\n               for (k =\
    \ 0; k < PREV_COEFF_CONTEXTS; k++)\n                   for (l = 0; l < ENTROPY_NODES;\
    \ l++)\n                       if (bool_get(bool,\n                          \
    \          k_coeff_entropy_update_probs\n                                    \
    \    [i][j][k][l]))\n                           hdr->coeff_probs[i][j][k][l] =\n\
    \                               bool_get_uint(bool, 8);\n       /* Read coefficient\
    \ skip mode probability */\n       hdr->coeff_skip_enabled = bool_get_bit(bool);\n\
    \       if (hdr->coeff_skip_enabled)\n           hdr->coeff_skip_prob = bool_get_uint(bool,\
    \ 8);\n       /* Parse interframe probability updates */\n       if (!ctx->frame_hdr.is_keyframe)\n\
    \       {\n           hdr->prob_inter = bool_get_uint(bool, 8);\n           hdr->prob_last\
    \  = bool_get_uint(bool, 8);\n           hdr->prob_gf    = bool_get_uint(bool,\
    \ 8);\n           if (bool_get_bit(bool))\n               for (i = 0; i < 4; i++)\n\
    \                   hdr->y_mode_probs[i] = bool_get_uint(bool, 8);\n         \
    \  if (bool_get_bit(bool))\n               for (i = 0; i < 3; i++)\n         \
    \          hdr->uv_mode_probs[i] = bool_get_uint(bool, 8);\n           for (i\
    \ = 0; i < 2; i++)\n               for (j = 0; j < MV_PROB_CNT; j++)\n       \
    \            if (bool_get(bool, k_mv_entropy_update_probs[i][j]))\n          \
    \         {\n                       int x = bool_get_uint(bool, 7);\n        \
    \               hdr->mv_probs[i][j] = x ? x << 1 : 1;\n                   }\n\
    \       }\n   }\n   static void\n   decode_reference_header(struct vp8_decoder_ctx\
    \    *ctx,\n                           struct bool_decoder       *bool,\n    \
    \                       struct vp8_reference_hdr  *hdr)\n   {\n       unsigned\
    \ int key = ctx->frame_hdr.is_keyframe;\n       hdr->refresh_gf    = key ? 1 :\
    \ bool_get_bit(bool);\n       hdr->refresh_arf   = key ? 1 : bool_get_bit(bool);\n\
    \       hdr->copy_gf       = key ? 0 : !hdr->refresh_gf\n                    \
    \        ? bool_get_uint(bool, 2) : 0;\n       hdr->copy_arf      = key ? 0 :\
    \ !hdr->refresh_arf\n                            ? bool_get_uint(bool, 2) : 0;\n\
    \       hdr->sign_bias[GOLDEN_FRAME] = key ? 0 : bool_get_bit(bool);\n       hdr->sign_bias[ALTREF_FRAME]\
    \ = key ? 0 : bool_get_bit(bool);\n       hdr->refresh_entropy = bool_get_bit(bool);\n\
    \       hdr->refresh_last  = key ? 1 : bool_get_bit(bool);\n   }\n   static void\n\
    \   decode_quantizer_header(struct vp8_decoder_ctx    *ctx,\n                \
    \           struct bool_decoder       *bool,\n                           struct\
    \ vp8_quant_hdr      *hdr)\n   {\n       int update;\n       int last_q = hdr->q_index;\n\
    \       hdr->q_index = bool_get_uint(bool, 7);\n       update = last_q != hdr->q_index;\n\
    \       update |= (hdr->y1_dc_delta_q = bool_maybe_get_int(bool, 4));\n      \
    \ update |= (hdr->y2_dc_delta_q = bool_maybe_get_int(bool, 4));\n       update\
    \ |= (hdr->y2_ac_delta_q = bool_maybe_get_int(bool, 4));\n       update |= (hdr->uv_dc_delta_q\
    \ = bool_maybe_get_int(bool, 4));\n       update |= (hdr->uv_ac_delta_q = bool_maybe_get_int(bool,\
    \ 4));\n       hdr->delta_update = update;\n   }\n   static void\n   decode_and_init_token_partitions(struct\
    \ vp8_decoder_ctx    *ctx,\n                                    struct bool_decoder\
    \       *bool,\n                                    const unsigned char      \
    \ *data,\n                                    unsigned int               sz,\n\
    \                                    struct vp8_token_hdr      *hdr)\n   {\n \
    \      int i;\n       hdr->partitions = 1 << bool_get_uint(bool, 2);\n       if\
    \ (sz < 3 *(hdr->partitions - 1))\n           vpx_internal_error(&ctx->error,\
    \ VPX_CODEC_CORRUPT_FRAME,\n                              \"Truncated packet found\
    \ parsing partition\"\n                              \" lengths.\");\n       sz\
    \ -= 3 * (hdr->partitions - 1);\n       for (i = 0; i < hdr->partitions; i++)\n\
    \       {\n           if (i < hdr->partitions - 1)\n           {\n           \
    \    hdr->partition_sz[i] = (data[2] << 16)\n                                \
    \      | (data[1] << 8) | data[0];\n               data += 3;\n           }\n\
    \           else\n               hdr->partition_sz[i] = sz;\n           if (sz\
    \ < hdr->partition_sz[i])\n               vpx_internal_error(&ctx->error, VPX_CODEC_CORRUPT_FRAME,\n\
    \                                  \"Truncated partition %d\", i);\n         \
    \  sz -= hdr->partition_sz[i];\n       }\n       for (i = 0; i < ctx->token_hdr.partitions;\
    \ i++)\n       {\n           init_bool_decoder(&ctx->tokens[i].bool, data,\n \
    \                            ctx->token_hdr.partition_sz[i]);\n           data\
    \ += ctx->token_hdr.partition_sz[i];\n       }\n   }\n   static void\n   decode_loopfilter_header(struct\
    \ vp8_decoder_ctx    *ctx,\n                            struct bool_decoder  \
    \     *bool,\n                            struct vp8_loopfilter_hdr *hdr)\n  \
    \ {\n       if (ctx->frame_hdr.is_keyframe)\n           memset(hdr, 0, sizeof(*hdr));\n\
    \       hdr->use_simple    = bool_get_bit(bool);\n       hdr->level         =\
    \ bool_get_uint(bool, 6);\n       hdr->sharpness     = bool_get_uint(bool, 3);\n\
    \       hdr->delta_enabled = bool_get_bit(bool);\n       if (hdr->delta_enabled\
    \ && bool_get_bit(bool))\n       {\n           int i;\n           for (i = 0;\
    \ i < BLOCK_CONTEXTS; i++)\n               hdr->ref_delta[i] = bool_maybe_get_int(bool,\
    \ 6);\n           for (i = 0; i < BLOCK_CONTEXTS; i++)\n               hdr->mode_delta[i]\
    \ = bool_maybe_get_int(bool, 6);\n       }\n   }\n   static void\n   decode_segmentation_header(struct\
    \ vp8_decoder_ctx *ctx,\n                              struct bool_decoder   \
    \ *bool,\n                              struct vp8_segment_hdr *hdr)\n   {\n \
    \      if (ctx->frame_hdr.is_keyframe)\n           memset(hdr, 0, sizeof(*hdr));\n\
    \       hdr->enabled = bool_get_bit(bool);\n       if (hdr->enabled)\n       {\n\
    \           int i;\n           hdr->update_map = bool_get_bit(bool);\n       \
    \    hdr->update_data = bool_get_bit(bool);\n           if (hdr->update_data)\n\
    \           {\n               hdr->abs = bool_get_bit(bool);\n               for\
    \ (i = 0; i < MAX_MB_SEGMENTS; i++)\n                   hdr->quant_idx[i] = bool_maybe_get_int(bool,\
    \ 7);\n               for (i = 0; i < MAX_MB_SEGMENTS; i++)\n                \
    \   hdr->lf_level[i] = bool_maybe_get_int(bool, 6);\n           }\n          \
    \ if (hdr->update_map)\n           {\n               for (i = 0; i < MB_FEATURE_TREE_PROBS;\
    \ i++)\n                   hdr->tree_probs[i] = bool_get_bit(bool)\n         \
    \                               ? bool_get_uint(bool, 8)\n                   \
    \                     : 255;\n           }\n       }\n       else\n       {\n\
    \           hdr->update_map = 0;\n           hdr->update_data = 0;\n       }\n\
    \   }\n   static void\n   dequant_global_init(struct dequant_factors dqf[MAX_MB_SEGMENTS])\n\
    \   {\n       int i;\n       for (i = 0; i < MAX_MB_SEGMENTS; i++)\n         \
    \  dqf[i].quant_idx = -1;\n   }\n   static int\n   clamp_q(int q)\n   {\n    \
    \   if (q < 0) return 0;\n       else if (q > 127) return 127;\n       return\
    \ q;\n   }\n   static int\n   dc_q(int q)\n   {\n       return dc_q_lookup[clamp_q(q)];\n\
    \   }\n   static int\n   ac_q(int q)\n   {\n       return ac_q_lookup[clamp_q(q)];\n\
    \   }\n   static void\n   dequant_init(struct dequant_factors        factors[MAX_MB_SEGMENTS],\n\
    \                const struct vp8_segment_hdr *seg,\n                const struct\
    \ vp8_quant_hdr   *quant_hdr)\n   {\n       int i, q;\n       struct dequant_factors\
    \ *dqf = factors;\n       for (i = 0; i < (seg->enabled ? MAX_MB_SEGMENTS : 1);\
    \ i++)\n       {\n           q = quant_hdr->q_index;\n           if (seg->enabled)\n\
    \               q = (!seg->abs) ? q + seg->quant_idx[i]\n                    \
    \           : seg->quant_idx[i];\n           if (dqf->quant_idx != q || quant_hdr->delta_update)\n\
    \           {\n               dqf->factor[TOKEN_BLOCK_Y1][0] =\n             \
    \      dc_q(q + quant_hdr->y1_dc_delta_q);\n               dqf->factor[TOKEN_BLOCK_Y1][1]\
    \ =\n                   ac_q(q);\n               dqf->factor[TOKEN_BLOCK_UV][0]\
    \ =\n                   dc_q(q + quant_hdr->uv_dc_delta_q);\n               dqf->factor[TOKEN_BLOCK_UV][1]\
    \ =\n                   ac_q(q + quant_hdr->uv_ac_delta_q);\n               dqf->factor[TOKEN_BLOCK_Y2][0]\
    \ =\n                   dc_q(q + quant_hdr->y2_dc_delta_q) * 2;\n            \
    \   dqf->factor[TOKEN_BLOCK_Y2][1] =\n                   ac_q(q + quant_hdr->y2_ac_delta_q)\
    \ * 155 / 100;\n               if (dqf->factor[TOKEN_BLOCK_Y2][1] < 8)\n     \
    \              dqf->factor[TOKEN_BLOCK_Y2][1] = 8;\n               if (dqf->factor[TOKEN_BLOCK_UV][0]\
    \ > 132)\n                   dqf->factor[TOKEN_BLOCK_UV][0] = 132;\n         \
    \      dqf->quant_idx = q;\n           }\n           dqf++;\n       }\n   }\n\
    \   static void\n   decode_frame(struct vp8_decoder_ctx *ctx,\n              \
    \  const unsigned char    *data,\n                unsigned int            sz)\n\
    \   {\n       vpx_codec_err_t  res;\n       struct bool_decoder  bool;\n     \
    \  int                  i, row, partition;\n       ctx->saved_entropy_valid =\
    \ 0;\n       if ((res = vp8_parse_frame_header(data, sz, &ctx->frame_hdr)))\n\
    \           vpx_internal_error(&ctx->error, res,\n                           \
    \   \"Failed to parse frame header\");\n       if (ctx->frame_hdr.is_experimental)\n\
    \           vpx_internal_error(&ctx->error, VPX_CODEC_UNSUP_BITSTREAM,\n     \
    \                         \"Experimental bitstreams not supported.\");\n     \
    \  data += FRAME_HEADER_SZ;\n       sz -= FRAME_HEADER_SZ;\n       if (ctx->frame_hdr.is_keyframe)\n\
    \       {\n           data += KEYFRAME_HEADER_SZ;\n           sz -= KEYFRAME_HEADER_SZ;\n\
    \           ctx->mb_cols = (ctx->frame_hdr.kf.w + 15) / 16;\n           ctx->mb_rows\
    \ = (ctx->frame_hdr.kf.h + 15) / 16;\n       }\n       /* Start the bitreader\
    \ for the header/entropy partition */\n       init_bool_decoder(&bool, data, ctx->frame_hdr.part0_sz);\n\
    \       /* Skip the colorspace and clamping bits */\n       if (ctx->frame_hdr.is_keyframe)\n\
    \           if (bool_get_uint(&bool, 2))\n               vpx_internal_error(\n\
    \                   &ctx->error, VPX_CODEC_UNSUP_BITSTREAM,\n                \
    \   \"Reserved bits not supported.\");\n       decode_segmentation_header(ctx,\
    \ &bool, &ctx->segment_hdr);\n       decode_loopfilter_header(ctx, &bool, &ctx->loopfilter_hdr);\n\
    \       decode_and_init_token_partitions(ctx,\n                              \
    \          &bool,\n                                        data + ctx->frame_hdr.part0_sz,\n\
    \                                        sz - ctx->frame_hdr.part0_sz,\n     \
    \                                   &ctx->token_hdr);\n       decode_quantizer_header(ctx,\
    \ &bool, &ctx->quant_hdr);\n       decode_reference_header(ctx, &bool, &ctx->reference_hdr);\n\
    \       /* Set keyframe entropy defaults.  These get updated on keyframes\n  \
    \      * regardless of the refresh_entropy setting.\n        */\n       if (ctx->frame_hdr.is_keyframe)\n\
    \       {\n           ARRAY_COPY(ctx->entropy_hdr.coeff_probs,\n             \
    \         k_default_coeff_probs);\n           ARRAY_COPY(ctx->entropy_hdr.mv_probs,\n\
    \                      k_default_mv_probs);\n           ARRAY_COPY(ctx->entropy_hdr.y_mode_probs,\n\
    \                      k_default_y_mode_probs);\n           ARRAY_COPY(ctx->entropy_hdr.uv_mode_probs,\n\
    \                      k_default_uv_mode_probs);\n       }\n       if (!ctx->reference_hdr.refresh_entropy)\n\
    \       {\n           ctx->saved_entropy = ctx->entropy_hdr;\n           ctx->saved_entropy_valid\
    \ = 1;\n       }\n       decode_entropy_header(ctx, &bool, &ctx->entropy_hdr);\n\
    \       vp8_dixie_modemv_init(ctx);\n       vp8_dixie_tokens_init(ctx);\n    \
    \   vp8_dixie_predict_init(ctx);\n       dequant_init(ctx->dequant_factors, &ctx->segment_hdr,\n\
    \                    &ctx->quant_hdr);\n       for (row = 0, partition = 0; row\
    \ < ctx->mb_rows; row++)\n       {\n           vp8_dixie_modemv_process_row(\n\
    \               ctx, &bool, row, 0, ctx->mb_cols);\n           vp8_dixie_tokens_process_row(ctx,\
    \ partition, row, 0,\n                                        ctx->mb_cols);\n\
    \           vp8_dixie_predict_process_row(ctx, row, 0, ctx->mb_cols);\n      \
    \     if (ctx->loopfilter_hdr.level && row)\n               vp8_dixie_loopfilter_process_row(ctx,\
    \ row - 1, 0,\n                                                ctx->mb_cols);\n\
    \           if (++partition == ctx->token_hdr.partitions)\n               partition\
    \ = 0;\n       }\n       if (ctx->loopfilter_hdr.level)\n           vp8_dixie_loopfilter_process_row(\n\
    \               ctx, row - 1, 0, ctx->mb_cols);\n       ctx->frame_cnt++;\n  \
    \     if (!ctx->reference_hdr.refresh_entropy)\n       {\n           ctx->entropy_hdr\
    \ = ctx->saved_entropy;\n           ctx->saved_entropy_valid = 0;\n       }\n\
    \       /* Handle reference frame updates */\n       if (ctx->reference_hdr.copy_arf\
    \ == 1)\n       {\n           vp8_dixie_release_ref_frame(ctx->ref_frames[ALTREF_FRAME]);\n\
    \           ctx->ref_frames[ALTREF_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[LAST_FRAME]);\n\
    \       }\n       else if (ctx->reference_hdr.copy_arf == 2)\n       {\n     \
    \      vp8_dixie_release_ref_frame(ctx->ref_frames[ALTREF_FRAME]);\n         \
    \  ctx->ref_frames[ALTREF_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[GOLDEN_FRAME]);\n\
    \       }\n       if (ctx->reference_hdr.copy_gf == 1)\n       {\n           vp8_dixie_release_ref_frame(ctx->ref_frames[GOLDEN_FRAME]);\n\
    \           ctx->ref_frames[GOLDEN_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[LAST_FRAME]);\n\
    \       }\n       else if (ctx->reference_hdr.copy_gf == 2)\n       {\n      \
    \     vp8_dixie_release_ref_frame(ctx->ref_frames[GOLDEN_FRAME]);\n          \
    \ ctx->ref_frames[GOLDEN_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[ALTREF_FRAME]);\n\
    \       }\n       if (ctx->reference_hdr.refresh_gf)\n       {\n           vp8_dixie_release_ref_frame(ctx->ref_frames[GOLDEN_FRAME]);\n\
    \           ctx->ref_frames[GOLDEN_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[CURRENT_FRAME]);\n\
    \       }\n       if (ctx->reference_hdr.refresh_arf)\n       {\n           vp8_dixie_release_ref_frame(ctx->ref_frames[ALTREF_FRAME]);\n\
    \           ctx->ref_frames[ALTREF_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[CURRENT_FRAME]);\n\
    \       }\n       if (ctx->reference_hdr.refresh_last)\n       {\n           vp8_dixie_release_ref_frame(ctx->ref_frames[LAST_FRAME]);\n\
    \           ctx->ref_frames[LAST_FRAME] =\n               vp8_dixie_ref_frame(ctx->ref_frames[CURRENT_FRAME]);\n\
    \       }\n   }\n   void\n   vp8_dixie_decode_init(struct vp8_decoder_ctx *ctx)\n\
    \   {\n       dequant_global_init(ctx->dequant_factors);\n   }\n   #define CHECK_FOR_UPDATE(lval,rval,update_flag)\
    \ do {\\\n           unsigned int old = lval; \\\n           update_flag |= (old\
    \ != (lval = rval)); \\\n       } while (0)\n   vpx_codec_err_t\n   vp8_parse_frame_header(const\
    \ unsigned char   *data,\n                          unsigned int           sz,\n\
    \                          struct vp8_frame_hdr  *hdr)\n   {\n       unsigned\
    \ long raw;\n       if (sz < 10)\n           return VPX_CODEC_CORRUPT_FRAME;\n\
    \       /* The frame header is defined as a three-byte little endian\n       \
    \ * value\n        */\n       raw = data[0] | (data[1] << 8) | (data[2] << 16);\n\
    \       hdr->is_keyframe     = !BITS_GET(raw, 0, 1);\n       hdr->version    \
    \     = BITS_GET(raw, 1, 2);\n       hdr->is_experimental = BITS_GET(raw, 3, 1);\n\
    \       hdr->is_shown        = BITS_GET(raw, 4, 1);\n       hdr->part0_sz    \
    \    = BITS_GET(raw, 5, 19);\n       if (sz <= hdr->part0_sz + (hdr->is_keyframe\
    \ ? 10 : 3))\n           return VPX_CODEC_CORRUPT_FRAME;\n       hdr->frame_size_updated\
    \ = 0;\n       if (hdr->is_keyframe)\n       {\n           unsigned int update\
    \ = 0;\n           /* Keyframe header consists of a three-byte sync code\n   \
    \         * followed by the width and height and associated scaling\n        \
    \    * factors.\n            */\n           if (data[3] != 0x9d || data[4] !=\
    \ 0x01 || data[5] != 0x2a)\n               return VPX_CODEC_UNSUP_BITSTREAM;\n\
    \           raw = data[6] | (data[7] << 8)\n                 | (data[8] << 16)\
    \ | (data[9] << 24);\n           CHECK_FOR_UPDATE(hdr->kf.w,       BITS_GET(raw,\
    \  0, 14),\n                            update);\n           CHECK_FOR_UPDATE(hdr->kf.scale_w,\
    \ BITS_GET(raw, 14,  2),\n                            update);\n           CHECK_FOR_UPDATE(hdr->kf.h,\
    \       BITS_GET(raw, 16, 14),\n                            update);\n       \
    \    CHECK_FOR_UPDATE(hdr->kf.scale_h, BITS_GET(raw, 30,  2),\n              \
    \              update);\n           hdr->frame_size_updated = update;\n      \
    \     if (!hdr->kf.w || !hdr->kf.h)\n               return VPX_CODEC_UNSUP_BITSTREAM;\n\
    \       }\n       return VPX_CODEC_OK;\n   }\n   vpx_codec_err_t\n   vp8_dixie_decode_frame(struct\
    \ vp8_decoder_ctx *ctx,\n                          const unsigned char    *data,\n\
    \                          unsigned int            sz)\n   {\n       volatile\
    \ struct vp8_decoder_ctx *ctx_ = ctx;\n       ctx->error.error_code = VPX_CODEC_OK;\n\
    \       ctx->error.has_detail = 0;\n       if (!setjmp(ctx->error.jmp))\n    \
    \       decode_frame(ctx, data, sz);\n       return ctx_->error.error_code;\n\
    \   }\n   void\n   vp8_dixie_decode_destroy(struct vp8_decoder_ctx *ctx)\n   {\n\
    \       vp8_dixie_predict_destroy(ctx);\n       vp8_dixie_tokens_destroy(ctx);\n\
    \       vp8_dixie_modemv_destroy(ctx);\n   }\n   ---- End code block ----------------------------------------\n"
- title: 20.5.  dixie.h
  contents:
  - "20.5.  dixie.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef DIXIE_H\n \
    \  #define DIXIE_H\n   #include \"vpx_codec_internal.h\"\n   #include \"bool_decoder.h\"\
    \n   struct vp8_frame_hdr\n   {\n       unsigned int is_keyframe;      /* Frame\
    \ is a keyframe */\n       unsigned int is_experimental;  /* Frame is a keyframe\
    \ */\n       unsigned int version;          /* Bitstream version */\n       unsigned\
    \ int is_shown;         /* Frame is to be displayed. */\n       unsigned int part0_sz;\
    \         /* Partition 0 length, in bytes */\n       struct vp8_kf_hdr\n     \
    \  {\n           unsigned int w;        /* Width */\n           unsigned int h;\
    \        /* Height */\n           unsigned int scale_w;  /* Scaling factor, Width\
    \ */\n           unsigned int scale_h;  /* Scaling factor, Height */\n       }\
    \ kf;\n       unsigned int frame_size_updated; /* Flag to indicate a resolution\n\
    \                                         * update.\n                        \
    \                 */\n   };\n   enum\n   {\n       MB_FEATURE_TREE_PROBS = 3,\n\
    \       MAX_MB_SEGMENTS = 4\n   };\n   struct vp8_segment_hdr\n   {\n       unsigned\
    \ int         enabled;\n       unsigned int         update_data;\n       unsigned\
    \ int         update_map;\n       unsigned int         abs;    /* 0=deltas, 1=absolute\
    \ values */\n       unsigned int         tree_probs[MB_FEATURE_TREE_PROBS];\n\
    \       int                  lf_level[MAX_MB_SEGMENTS];\n       int          \
    \        quant_idx[MAX_MB_SEGMENTS];\n   };\n   enum\n   {\n       BLOCK_CONTEXTS\
    \ = 4\n   };\n   struct vp8_loopfilter_hdr\n   {\n       unsigned int        \
    \ use_simple;\n       unsigned int         level;\n       unsigned int       \
    \  sharpness;\n       unsigned int         delta_enabled;\n       int        \
    \          ref_delta[BLOCK_CONTEXTS];\n       int                  mode_delta[BLOCK_CONTEXTS];\n\
    \   };\n   enum\n   {\n       MAX_PARTITIONS = 8\n   };\n   struct vp8_token_hdr\n\
    \   {\n       unsigned int        partitions;\n       unsigned int        partition_sz[MAX_PARTITIONS];\n\
    \   };\n   struct vp8_quant_hdr\n   {\n       unsigned int       q_index;\n  \
    \     int                delta_update;\n       int                y1_dc_delta_q;\n\
    \       int                y2_dc_delta_q;\n       int                y2_ac_delta_q;\n\
    \       int                uv_dc_delta_q;\n       int                uv_ac_delta_q;\n\
    \   };\n   struct vp8_reference_hdr\n   {\n       unsigned int refresh_last;\n\
    \       unsigned int refresh_gf;\n       unsigned int refresh_arf;\n       unsigned\
    \ int copy_gf;\n       unsigned int copy_arf;\n       unsigned int sign_bias[4];\n\
    \       unsigned int refresh_entropy;\n   };\n   enum\n   {\n       BLOCK_TYPES\
    \        = 4,\n       PREV_COEFF_CONTEXTS = 3,\n       COEFF_BANDS         = 8,\n\
    \       ENTROPY_NODES      = 11,\n   };\n   typedef unsigned char coeff_probs_table_t[BLOCK_TYPES][COEFF_BANDS]\n\
    \   [PREV_COEFF_CONTEXTS]\n   [ENTROPY_NODES];\n   enum\n   {\n       MV_PROB_CNT\
    \ = 2 + 8 - 1 + 10 /* from entropymv.h */\n   };\n   typedef unsigned char mv_component_probs_t[MV_PROB_CNT];\n\
    \   struct vp8_entropy_hdr\n   {\n       coeff_probs_table_t   coeff_probs;\n\
    \       mv_component_probs_t  mv_probs[2];\n       unsigned int          coeff_skip_enabled;\n\
    \       unsigned char         coeff_skip_prob;\n       unsigned char         y_mode_probs[4];\n\
    \       unsigned char         uv_mode_probs[3];\n       unsigned char        \
    \ prob_inter;\n       unsigned char         prob_last;\n       unsigned char \
    \        prob_gf;\n   };\n   enum reference_frame\n   {\n       CURRENT_FRAME,\n\
    \       LAST_FRAME,\n       GOLDEN_FRAME,\n       ALTREF_FRAME,\n       NUM_REF_FRAMES\n\
    \   };\n   enum prediction_mode\n   {\n       /* 16x16 intra modes */\n      \
    \ DC_PRED, V_PRED, H_PRED, TM_PRED, B_PRED,\n       /* 16x16 inter modes */\n\
    \       NEARESTMV, NEARMV, ZEROMV, NEWMV, SPLITMV,\n       MB_MODE_COUNT,\n  \
    \     /* 4x4 intra modes */\n       B_DC_PRED = 0, B_TM_PRED, B_VE_PRED, B_HE_PRED,\
    \ B_LD_PRED,\n       B_RD_PRED, B_VR_PRED, B_VL_PRED, B_HD_PRED, B_HU_PRED,\n\
    \       /* 4x4 inter modes */\n       LEFT4X4, ABOVE4X4, ZERO4X4, NEW4X4,\n  \
    \     B_MODE_COUNT\n   };\n   enum splitmv_partitioning\n   {\n       SPLITMV_16X8,\n\
    \       SPLITMV_8X16,\n       SPLITMV_8X8,\n       SPLITMV_4X4\n   };\n   typedef\
    \ short filter_t[6];\n   typedef union mv\n   {\n       struct\n       {\n   \
    \        int16_t x, y;\n       }  d;\n       uint32_t               raw;\n   }\
    \ mv_t;\n   struct mb_base_info\n   {\n       unsigned char y_mode     : 4;\n\
    \       unsigned char uv_mode    : 4;\n       unsigned char segment_id : 2;\n\
    \       unsigned char ref_frame  : 2;\n       unsigned char skip_coeff : 1;\n\
    \       unsigned char need_mc_border : 1;\n       enum splitmv_partitioning  partitioning\
    \ : 2;\n       union mv      mv;\n       unsigned int  eob_mask;\n   };\n   struct\
    \ mb_info\n   {\n       struct mb_base_info base;\n       union\n       {\n  \
    \         union mv              mvs[16];\n           enum prediction_mode  modes[16];\n\
    \       } split;\n   };\n   /* A \"token entropy context\" has 4 Y values, 2 U,\
    \ 2 V, and 1 Y2 */\n   typedef int token_entropy_ctx_t[4 + 2 + 2 + 1];\n   struct\
    \ token_decoder\n   {\n       struct bool_decoder  bool;\n       token_entropy_ctx_t\
    \  left_token_entropy_ctx;\n       short               *coeffs;\n   };\n   enum\
    \ token_block_type\n   {\n       TOKEN_BLOCK_Y1,\n       TOKEN_BLOCK_UV,\n   \
    \    TOKEN_BLOCK_Y2,\n       TOKEN_BLOCK_TYPES,\n   };\n   struct dequant_factors\n\
    \   {\n       int   quant_idx;\n       short factor[TOKEN_BLOCK_TYPES][2]; /*\
    \ [ Y1, UV, Y2 ]\n                                            * [ DC, AC ] */\n\
    \   };\n   struct ref_cnt_img\n   {\n       vpx_image_t  img;\n       unsigned\
    \ int ref_cnt;\n   };\n   struct vp8_decoder_ctx\n   {\n       struct vpx_internal_error_info\
    \  error;\n       unsigned int                    frame_cnt;\n       struct vp8_frame_hdr\
    \            frame_hdr;\n       struct vp8_segment_hdr          segment_hdr;\n\
    \       struct vp8_loopfilter_hdr       loopfilter_hdr;\n       struct vp8_token_hdr\
    \            token_hdr;\n       struct vp8_quant_hdr            quant_hdr;\n \
    \      struct vp8_reference_hdr        reference_hdr;\n       struct vp8_entropy_hdr\
    \          entropy_hdr;\n       struct vp8_entropy_hdr          saved_entropy;\n\
    \       unsigned int                    saved_entropy_valid;\n       unsigned\
    \ int                    mb_rows;\n       unsigned int                    mb_cols;\n\
    \       struct mb_info                 *mb_info_storage;\n       struct mb_info\
    \                **mb_info_rows_storage;\n       struct mb_info              \
    \  **mb_info_rows;\n       token_entropy_ctx_t            *above_token_entropy_ctx;\n\
    \       struct token_decoder            tokens[MAX_PARTITIONS];\n       struct\
    \ dequant_factors          dequant_factors[MAX_MB_SEGMENTS];\n       struct ref_cnt_img\
    \              frame_strg[NUM_REF_FRAMES];\n       struct ref_cnt_img        \
    \     *ref_frames[NUM_REF_FRAMES];\n       ptrdiff_t                       ref_frame_offsets[4];\n\
    \       const filter_t                 *subpixel_filters;\n   };\n   void\n  \
    \ vp8_dixie_decode_init(struct vp8_decoder_ctx *ctx);\n   void\n   vp8_dixie_decode_destroy(struct\
    \ vp8_decoder_ctx *ctx);\n   vpx_codec_err_t\n   vp8_parse_frame_header(const\
    \ unsigned char   *data,\n                          unsigned int           sz,\n\
    \                          struct vp8_frame_hdr  *hdr);\n   vpx_codec_err_t\n\
    \   vp8_dixie_decode_frame(struct vp8_decoder_ctx *ctx,\n                    \
    \      const unsigned char    *data,\n                          unsigned int \
    \           sz);\n   #define CLAMP_255(x) ((x)<0?0:((x)>255?255:(x)))\n   #endif\n\
    \   ---- End code block ----------------------------------------\n"
- title: 20.6.  dixie_loopfilter.c
  contents:
  - "20.6.  dixie_loopfilter.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #include \"dixie.h\"\
    \n   #include \"dixie_loopfilter.h\"\n   #define ABS(x) ((x) >= 0 ? (x) : -(x))\n\
    \   #define p3 pixels[-4*stride]\n   #define p2 pixels[-3*stride]\n   #define\
    \ p1 pixels[-2*stride]\n   #define p0 pixels[-1*stride]\n   #define q0 pixels[\
    \ 0*stride]\n   #define q1 pixels[ 1*stride]\n   #define q2 pixels[ 2*stride]\n\
    \   #define q3 pixels[ 3*stride]\n   #define static\n   static int\n   saturate_int8(int\
    \ x)\n   {\n       if (x < -128)\n           return -128;\n       if (x > 127)\n\
    \           return 127;\n       return x;\n   }\n   static int\n   saturate_uint8(int\
    \ x)\n   {\n       if (x < 0)\n           return 0;\n       if (x > 255)\n   \
    \        return 255;\n       return x;\n   }\n   static int\n   high_edge_variance(unsigned\
    \ char *pixels,\n                      int            stride,\n              \
    \        int            hev_threshold)\n   {\n       return ABS(p1 - p0) > hev_threshold\
    \ ||\n              ABS(q1 - q0) > hev_threshold;\n   }\n   static int\n   simple_threshold(unsigned\
    \ char *pixels,\n                    int            stride,\n                \
    \    int            filter_limit)\n   {\n       return (ABS(p0 - q0) * 2 + (ABS(p1\
    \ - q1) >> 1)) <= filter_limit;\n   }\n   static int\n   normal_threshold(unsigned\
    \ char *pixels,\n                    int            stride,\n                \
    \    int            edge_limit,\n                    int            interior_limit)\n\
    \   {\n       int E = edge_limit;\n       int I = interior_limit;\n       return\
    \ simple_threshold(pixels, stride, 2 * E + I)\n              && ABS(p3 - p2) <=\
    \ I && ABS(p2 - p1) <= I\n              && ABS(p1 - p0) <= I && ABS(q3 - q2) <=\
    \ I\n              && ABS(q2 - q1) <= I && ABS(q1 - q0) <= I;\n   }\n   static\
    \ void\n   filter_common(unsigned char *pixels,\n                 int        \
    \    stride,\n                 int            use_outer_taps)\n   {\n       int\
    \ a, f1, f2;\n       a = 3 * (q0 - p0);\n       if (use_outer_taps)\n        \
    \   a += saturate_int8(p1 - q1);\n       a = saturate_int8(a);\n       f1 = ((a\
    \ + 4 > 127) ? 127 : a + 4) >> 3;\n       f2 = ((a + 3 > 127) ? 127 : a + 3) >>\
    \ 3;\n       p0 = saturate_uint8(p0 + f2);\n       q0 = saturate_uint8(q0 - f1);\n\
    \       if (!use_outer_taps)\n       {\n           /* This handles the case of\
    \ subblock_filter()\n            * (from the bitstream guide.\n            */\n\
    \           a = (f1 + 1) >> 1;\n           p1 = saturate_uint8(p1 + a);\n    \
    \       q1 = saturate_uint8(q1 - a);\n       }\n   }\n   static void\n   filter_mb_edge(unsigned\
    \ char *pixels,\n                  int            stride)\n   {\n       int w,\
    \ a;\n       w = saturate_int8(saturate_int8(p1 - q1) + 3 * (q0 - p0));\n    \
    \   a = (27 * w + 63) >> 7;\n       p0 = saturate_uint8(p0 + a);\n       q0 =\
    \ saturate_uint8(q0 - a);\n       a = (18 * w + 63) >> 7;\n       p1 = saturate_uint8(p1\
    \ + a);\n       q1 = saturate_uint8(q1 - a);\n       a = (9 * w + 63) >> 7;\n\
    \       p2 = saturate_uint8(p2 + a);\n       q2 = saturate_uint8(q2 - a);\n  \
    \ }\n   static void\n   filter_mb_v_edge(unsigned char *src,\n               \
    \     int            stride,\n                    int            edge_limit,\n\
    \                    int            interior_limit,\n                    int \
    \           hev_threshold,\n                    int            size)\n   {\n \
    \      int i;\n       for (i = 0; i < 8 * size; i++)\n       {\n           if\
    \ (normal_threshold(src, 1, edge_limit, interior_limit))\n           {\n     \
    \          if (high_edge_variance(src, 1, hev_threshold))\n                  \
    \ filter_common(src, 1, 1);\n               else\n                   filter_mb_edge(src,\
    \ 1);\n           }\n           src += stride;\n       }\n   }\n   static void\n\
    \   filter_subblock_v_edge(unsigned char *src,\n                          int\
    \            stride,\n                          int            edge_limit,\n \
    \                         int            interior_limit,\n                   \
    \       int            hev_threshold,\n                          int         \
    \   size)\n   {\n       int i;\n       for (i = 0; i < 8 * size; i++)\n      \
    \ {\n           if (normal_threshold(src, 1, edge_limit, interior_limit))\n  \
    \             filter_common(src, 1,\n                             high_edge_variance(src,\
    \ 1, hev_threshold));\n           src += stride;\n       }\n   }\n   static void\n\
    \   filter_mb_h_edge(unsigned char *src,\n                    int            stride,\n\
    \                    int            edge_limit,\n                    int     \
    \       interior_limit,\n                    int            hev_threshold,\n \
    \                   int            size)\n   {\n       int i;\n       for (i =\
    \ 0; i < 8 * size; i++)\n       {\n           if (normal_threshold(src, stride,\
    \ edge_limit,\n                                interior_limit))\n           {\n\
    \               if (high_edge_variance(src, stride, hev_threshold))\n        \
    \           filter_common(src, stride, 1);\n               else\n            \
    \       filter_mb_edge(src, stride);\n           }\n           src += 1;\n   \
    \    }\n   }\n   static void\n   filter_subblock_h_edge(unsigned char *src,\n\
    \                          int            stride,\n                          int\
    \            edge_limit,\n                          int            interior_limit,\n\
    \                          int            hev_threshold,\n                   \
    \       int            size)\n   {\n       int i;\n       for (i = 0; i < 8 *\
    \ size; i++)\n       {\n           if (normal_threshold(src, stride, edge_limit,\n\
    \                                interior_limit))\n               filter_common(src,\
    \ stride,\n                             high_edge_variance(src, stride,\n    \
    \                                            hev_threshold));\n           src\
    \ += 1;\n       }\n   }\n   static void\n   filter_v_edge_simple(unsigned char\
    \ *src,\n                        int            stride,\n                    \
    \    int            filter_limit)\n   {\n       int i;\n       for (i = 0; i <\
    \ 16; i++)\n       {\n           if (simple_threshold(src, 1, filter_limit))\n\
    \               filter_common(src, 1, 1);\n           src += stride;\n       }\n\
    \   }\n   static void\n   filter_h_edge_simple(unsigned char *src,\n         \
    \               int            stride,\n                        int          \
    \  filter_limit)\n   {\n       int i;\n       for (i = 0; i < 16; i++)\n     \
    \  {\n           if (simple_threshold(src, stride, filter_limit))\n          \
    \     filter_common(src, stride, 1);\n           src += 1;\n       }\n   }\n \
    \  static void\n   calculate_filter_parameters(struct vp8_decoder_ctx *ctx,\n\
    \                               struct mb_info         *mbi,\n               \
    \                int                    *edge_limit_,\n                      \
    \         int                    *interior_limit_,\n                         \
    \      int                    *hev_threshold_)\n   {\n       int filter_level,\
    \ interior_limit, hev_threshold;\n       /* Reference code/spec seems to conflate\
    \ filter_level and\n        * edge_limit\n        */\n       filter_level = ctx->loopfilter_hdr.level;\n\
    \       if (ctx->segment_hdr.enabled)\n       {\n           if (!ctx->segment_hdr.abs)\n\
    \               filter_level +=\n                   ctx->segment_hdr.lf_level[mbi->base.segment_id];\n\
    \           else\n               filter_level =\n                   ctx->segment_hdr.lf_level[mbi->base.segment_id];\n\
    \       }\n       if (filter_level > 63)\n           filter_level = 63;\n    \
    \   else if (filter_level < 0)\n           filter_level = 0;\n       if (ctx->loopfilter_hdr.delta_enabled)\n\
    \       {\n           filter_level +=\n               ctx->loopfilter_hdr.ref_delta[mbi->base.ref_frame];\n\
    \           if (mbi->base.ref_frame == CURRENT_FRAME)\n           {\n        \
    \       if (mbi->base.y_mode == B_PRED)\n                   filter_level += ctx->loopfilter_hdr.mode_delta[0];\n\
    \           }\n           else if (mbi->base.y_mode == ZEROMV)\n             \
    \  filter_level += ctx->loopfilter_hdr.mode_delta[1];\n           else if (mbi->base.y_mode\
    \ == SPLITMV)\n               filter_level += ctx->loopfilter_hdr.mode_delta[3];\n\
    \           else\n               filter_level += ctx->loopfilter_hdr.mode_delta[2];\n\
    \       }\n       if (filter_level > 63)\n           filter_level = 63;\n    \
    \   else if (filter_level < 0)\n           filter_level = 0;\n       interior_limit\
    \ = filter_level;\n       if (ctx->loopfilter_hdr.sharpness)\n       {\n     \
    \      interior_limit >>= ctx->loopfilter_hdr.sharpness > 4 ? 2 : 1;\n       \
    \    if (interior_limit > 9 - ctx->loopfilter_hdr.sharpness)\n               interior_limit\
    \ = 9 - ctx->loopfilter_hdr.sharpness;\n       }\n       if (interior_limit <\
    \ 1)\n           interior_limit = 1;\n       hev_threshold = (filter_level >=\
    \ 15);\n       if (filter_level >= 40)\n           hev_threshold++;\n       if\
    \ (filter_level >= 20 && !ctx->frame_hdr.is_keyframe)\n           hev_threshold++;\n\
    \       *edge_limit_ = filter_level;\n       *interior_limit_ = interior_limit;\n\
    \       *hev_threshold_ = hev_threshold;\n   }\n   static void\n   filter_row_normal(struct\
    \ vp8_decoder_ctx *ctx,\n                     unsigned int            row,\n \
    \                    unsigned int            start_col,\n                    \
    \ unsigned int            num_cols)\n   {\n       unsigned char  *y, *u, *v;\n\
    \       int             stride, uv_stride;\n       struct mb_info *mbi;\n    \
    \   unsigned int    col;\n       /* Adjust pointers based on row, start_col */\n\
    \       stride    = ctx->ref_frames[CURRENT_FRAME]->img.stride[PLANE_Y];\n   \
    \    uv_stride = ctx->ref_frames[CURRENT_FRAME]->img.stride[PLANE_U];\n      \
    \ y = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_Y];\n       u = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_U];\n\
    \       v = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_V];\n       y +=\
    \ (stride * row + start_col) * 16;\n       u += (uv_stride * row + start_col)\
    \ * 8;\n       v += (uv_stride * row + start_col) * 8;\n       mbi = ctx->mb_info_rows[row]\
    \ + start_col;\n       for (col = start_col; col < start_col + num_cols; col++)\n\
    \       {\n           int edge_limit, interior_limit, hev_threshold;\n       \
    \    /* TODO: Only need to recalculate every MB if segmentation is\n         \
    \   * enabled.\n            */\n           calculate_filter_parameters(ctx, mbi,\
    \ &edge_limit,\n                                       &interior_limit, &hev_threshold);\n\
    \           if (edge_limit)\n           {\n               if (col)\n         \
    \      {\n                   filter_mb_v_edge(y, stride, edge_limit + 2,\n   \
    \                                 interior_limit, hev_threshold, 2);\n       \
    \            filter_mb_v_edge(u, uv_stride, edge_limit + 2,\n                \
    \                    interior_limit, hev_threshold, 1);\n                   filter_mb_v_edge(v,\
    \ uv_stride, edge_limit + 2,\n                                    interior_limit,\
    \ hev_threshold, 1);\n               }\n               /* NOTE: This conditional\
    \ is actually dependent on the\n                * number of coefficients decoded,\
    \ not the skip flag as\n                * coded in the bitstream.  The tokens\
    \ task is expected\n                * to set 31 if there is *any* non-zero data.\n\
    \                */\n               if (mbi->base.eob_mask\n                 \
    \  || mbi->base.y_mode == SPLITMV\n                   || mbi->base.y_mode == B_PRED)\n\
    \               {\n                   filter_subblock_v_edge(y + 4, stride, edge_limit,\n\
    \                                          interior_limit, hev_threshold,\n  \
    \                                        2);\n                   filter_subblock_v_edge(y\
    \ + 8, stride, edge_limit,\n                                          interior_limit,\
    \ hev_threshold,\n                                          2);\n            \
    \       filter_subblock_v_edge(y + 12, stride, edge_limit,\n                 \
    \                         interior_limit, hev_threshold,\n                   \
    \                       2);\n                   filter_subblock_v_edge(u + 4,\
    \ uv_stride, edge_limit,\n                                          interior_limit,\
    \ hev_threshold,\n                                          1);\n            \
    \       filter_subblock_v_edge(v + 4, uv_stride, edge_limit,\n               \
    \                           interior_limit, hev_threshold,\n                 \
    \                         1);\n               }\n               if (row)\n   \
    \            {\n                   filter_mb_h_edge(y, stride, edge_limit + 2,\n\
    \                                    interior_limit, hev_threshold, 2);\n    \
    \               filter_mb_h_edge(u, uv_stride, edge_limit + 2,\n             \
    \                       interior_limit, hev_threshold, 1);\n                 \
    \  filter_mb_h_edge(v, uv_stride, edge_limit + 2,\n                          \
    \          interior_limit, hev_threshold, 1);\n               }\n            \
    \   if (mbi->base.eob_mask\n                   || mbi->base.y_mode == SPLITMV\n\
    \                   || mbi->base.y_mode == B_PRED)\n               {\n       \
    \            filter_subblock_h_edge(y + 4 * stride, stride,\n                \
    \                          edge_limit, interior_limit,\n                     \
    \                     hev_threshold, 2);\n                   filter_subblock_h_edge(y\
    \ + 8 * stride, stride,\n                                          edge_limit,\
    \ interior_limit,\n                                          hev_threshold, 2);\n\
    \                   filter_subblock_h_edge(y + 12 * stride, stride,\n        \
    \                                  edge_limit, interior_limit,\n             \
    \                             hev_threshold, 2);\n                   filter_subblock_h_edge(u\
    \ + 4 * uv_stride, uv_stride,\n                                          edge_limit,\
    \ interior_limit,\n                                          hev_threshold, 1);\n\
    \                   filter_subblock_h_edge(v + 4 * uv_stride, uv_stride,\n   \
    \                                       edge_limit, interior_limit,\n        \
    \                                  hev_threshold, 1);\n               }\n    \
    \       }\n           y += 16;\n           u += 8;\n           v += 8;\n     \
    \      mbi++;\n       }\n   }\n   static void\n   filter_row_simple(struct vp8_decoder_ctx\
    \ *ctx,\n                     unsigned int            row,\n                 \
    \    unsigned int            start_col,\n                     unsigned int   \
    \         num_cols)\n   {\n       unsigned char  *y;\n       int             stride;\n\
    \       struct mb_info *mbi;\n       unsigned int    col;\n       /* Adjust pointers\
    \ based on row, start_col */\n       stride    = ctx->ref_frames[CURRENT_FRAME]->img.stride[PLANE_Y];\n\
    \       y = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_Y];\n       y +=\
    \ (stride * row + start_col) * 16;\n       mbi = ctx->mb_info_rows[row] + start_col;\n\
    \       for (col = start_col; col < start_col + num_cols; col++)\n       {\n \
    \          int edge_limit, interior_limit, hev_threshold;\n           /* TODO:\
    \ Only need to recalculate every MB if segmentation is\n            * enabled.\n\
    \            */\n           calculate_filter_parameters(ctx, mbi, &edge_limit,\n\
    \                                       &interior_limit, &hev_threshold);\n  \
    \         if (edge_limit)\n           {\n               /* NOTE: This conditional\
    \ is actually dependent on the\n                * number of coefficients decoded,\
    \ not the skip flag as\n                * coded in the bitstream.  The tokens\
    \ task is expected\n                * to set 31 if there is *any* non-zero data.\n\
    \                */\n               int filter_subblocks = (mbi->base.eob_mask\n\
    \                                       || mbi->base.y_mode == SPLITMV\n     \
    \                                  || mbi->base.y_mode == B_PRED);\n         \
    \      int mb_limit = (edge_limit + 2) * 2 + interior_limit;\n               int\
    \ b_limit = edge_limit * 2 + interior_limit;\n               if (col)\n      \
    \             filter_v_edge_simple(y, stride, mb_limit);\n               if (filter_subblocks)\n\
    \               {\n                   filter_v_edge_simple(y + 4, stride, b_limit);\n\
    \                   filter_v_edge_simple(y + 8, stride, b_limit);\n          \
    \         filter_v_edge_simple(y + 12, stride, b_limit);\n               }\n \
    \              if (row)\n                   filter_h_edge_simple(y, stride, mb_limit);\n\
    \               if (filter_subblocks)\n               {\n                   filter_h_edge_simple(y\
    \ + 4 * stride, stride,\n                                        b_limit);\n \
    \                  filter_h_edge_simple(y + 8 * stride, stride,\n            \
    \                            b_limit);\n                   filter_h_edge_simple(y\
    \ + 12 * stride, stride,\n                                        b_limit);\n\
    \               }\n           }\n           y += 16;\n           mbi++;\n    \
    \   }\n   }\n   void\n   vp8_dixie_loopfilter_process_row(struct vp8_decoder_ctx\
    \ *ctx,\n                                    unsigned int            row,\n  \
    \                                  unsigned int            start_col,\n      \
    \                              unsigned int            num_cols)\n   {\n     \
    \  if (ctx->loopfilter_hdr.use_simple)\n           filter_row_simple(ctx, row,\
    \ start_col, num_cols);\n       else\n           filter_row_normal(ctx, row, start_col,\
    \ num_cols);\n   }\n   ---- End code block ----------------------------------------\n"
- title: 20.7.  dixie_loopfilter.h
  contents:
  - "20.7.  dixie_loopfilter.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef DIXIE_LOOPFILTER_H\n\
    \   #define DIXIE_LOOPFILTER_H\n   void\n   vp8_dixie_loopfilter_process_row(struct\
    \ vp8_decoder_ctx *ctx,\n                                    unsigned int    \
    \        row,\n                                    unsigned int            start_col,\n\
    \                                    unsigned int            num_cols);\n   #endif\n\
    \   ---- End code block ----------------------------------------\n"
- title: 20.8.  idct_add.c
  contents:
  - "20.8.  idct_add.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #include \"dixie.h\"\
    \n   #include \"idct_add.h\"\n   #include <assert.h>\n   void\n   vp8_dixie_walsh(const\
    \ short *input, short *output)\n   {\n       int i;\n       int a1, b1, c1, d1;\n\
    \       int a2, b2, c2, d2;\n       const short *ip = input;\n       short *op\
    \ = output;\n       for (i = 0; i < 4; i++)\n       {\n           a1 = ip[0] +\
    \ ip[12];\n           b1 = ip[4] + ip[8];\n           c1 = ip[4] - ip[8];\n  \
    \         d1 = ip[0] - ip[12];\n           op[0] = a1 + b1;\n           op[4]\
    \ = c1 + d1;\n           op[8] = a1 - b1;\n           op[12] = d1 - c1;\n    \
    \       ip++;\n           op++;\n       }\n       ip = output;\n       op = output;\n\
    \       for (i = 0; i < 4; i++)\n       {\n           a1 = ip[0] + ip[3];\n  \
    \         b1 = ip[1] + ip[2];\n           c1 = ip[1] - ip[2];\n           d1 =\
    \ ip[0] - ip[3];\n           a2 = a1 + b1;\n           b2 = c1 + d1;\n       \
    \    c2 = a1 - b1;\n           d2 = d1 - c1;\n           op[0] = (a2 + 3) >> 3;\n\
    \           op[1] = (b2 + 3) >> 3;\n           op[2] = (c2 + 3) >> 3;\n      \
    \     op[3] = (d2 + 3) >> 3;\n           ip += 4;\n           op += 4;\n     \
    \  }\n   }\n   #define cospi8sqrt2minus1 20091\n   #define sinpi8sqrt2       35468\n\
    \   #define rounding          0\n   static void\n   idct_columns(const short *input,\
    \ short *output)\n   {\n       int i;\n       int a1, b1, c1, d1;\n       const\
    \ short *ip = input;\n       short *op = output;\n       int temp1, temp2;\n \
    \      int shortpitch = 4;\n       for (i = 0; i < 4; i++)\n       {\n       \
    \    a1 = ip[0] + ip[8];\n           b1 = ip[0] - ip[8];\n           temp1 = (ip[4]\
    \ * sinpi8sqrt2 + rounding) >> 16;\n           temp2 = ip[12] +\n            \
    \   ((ip[12] * cospi8sqrt2minus1 + rounding) >> 16);\n           c1 = temp1 -\
    \ temp2;\n           temp1 = ip[4] +\n               ((ip[4] * cospi8sqrt2minus1\
    \ + rounding) >> 16);\n           temp2 = (ip[12] * sinpi8sqrt2 + rounding) >>\
    \ 16;\n           d1 = temp1 + temp2;\n           op[shortpitch*0] = a1 + d1;\n\
    \           op[shortpitch*3] = a1 - d1;\n           op[shortpitch*1] = b1 + c1;\n\
    \           op[shortpitch*2] = b1 - c1;\n           ip++;\n           op++;\n\
    \       }\n   }\n   void\n   vp8_dixie_idct_add(unsigned char        *recon,\n\
    \                      const unsigned char  *predict,\n                      int\
    \                   stride,\n                      const short          *coeffs)\n\
    \   {\n       int i;\n       int a1, b1, c1, d1, temp1, temp2;\n       short tmp[16];\n\
    \       idct_columns(coeffs, tmp);\n       coeffs = tmp;\n       for (i = 0; i\
    \ < 4; i++)\n       {\n           a1 = coeffs[0] + coeffs[2];\n           b1 =\
    \ coeffs[0] - coeffs[2];\n           temp1 = (coeffs[1] * sinpi8sqrt2 + rounding)\
    \ >> 16;\n           temp2 = coeffs[3] +\n               ((coeffs[3] * cospi8sqrt2minus1\
    \ + rounding) >> 16);\n           c1 = temp1 - temp2;\n           temp1 = coeffs[1]\
    \ +\n               ((coeffs[1] * cospi8sqrt2minus1 + rounding) >> 16);\n    \
    \       temp2 = (coeffs[3] * sinpi8sqrt2 + rounding) >> 16;\n           d1 = temp1\
    \ + temp2;\n           recon[0] = CLAMP_255(predict[0] + ((a1 + d1 + 4) >> 3));\n\
    \           recon[3] = CLAMP_255(predict[3] + ((a1 - d1 + 4) >> 3));\n       \
    \    recon[1] = CLAMP_255(predict[1] + ((b1 + c1 + 4) >> 3));\n           recon[2]\
    \ = CLAMP_255(predict[2] + ((b1 - c1 + 4) >> 3));\n           coeffs += 4;\n \
    \          recon += stride;\n           predict += stride;\n       }\n   }\n \
    \  ---- End code block ----------------------------------------\n"
- title: 20.9.  idct_add.h
  contents:
  - "20.9.  idct_add.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef IDCT_ADD_H\n\
    \   #define IDCT_ADD_H\n   void\n   vp8_dixie_idct_add_init(struct vp8_decoder_ctx\
    \ *ctx);\n   void\n   vp8_dixie_idct_add(unsigned char        *recon,\n      \
    \                const unsigned char  *predict,\n                      int   \
    \                stride,\n                      const short          *coeffs);\n\
    \   void\n   vp8_dixie_walsh(const short *in, short *out);\n   void\n   vp8_dixie_idct_add_process_row(struct\
    \ vp8_decoder_ctx *ctx,\n                                  short             \
    \     *coeffs,\n                                  unsigned int            row,\n\
    \                                  unsigned int            start_col,\n      \
    \                            unsigned int            num_cols);\n   #endif\n \
    \  ---- End code block ----------------------------------------\n"
- title: 20.10.  mem.h
  contents:
  - "20.10.  mem.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef VPX_PORTS_MEM_H\n\
    \   #define VPX_PORTS_MEM_H\n   #include \"vpx_config.h\"\n   #include \"vpx_integer.h\"\
    \n   #if defined(__GNUC__) && __GNUC__\n   #define DECLARE_ALIGNED(n,typ,val)\
    \  typ val __attribute__ \\\n       ((aligned (n)))\n   #elif defined(_MSC_VER)\n\
    \   #define DECLARE_ALIGNED(n,typ,val)  __declspec(align(n)) typ val\n   #else\n\
    \   #warning No alignment directives known for this compiler.\n   #define DECLARE_ALIGNED(n,typ,val)\
    \  typ val\n   #endif\n   #endif\n   /* Declare an aligned array on the stack,\
    \ for situations where the\n    * stack pointer may not have the alignment we\
    \ expect.  Creates an\n    * array with a modified name, then defines val to be\
    \ a pointer, and\n    * aligns that pointer within the array.\n    */\n   #define\
    \ DECLARE_ALIGNED_ARRAY(a,typ,val,n)\\\n   typ val##_[(n)+(a)/sizeof(typ)+1];\\\
    \n   typ *val = (typ*)((((intptr_t)val##_)+(a)-1)&((intptr_t)-(a)))\n   /* Indicates\
    \ that the usage of the specified variable has been\n    * audited to assure that\
    \ it's safe to use uninitialized.  Silences\n    * 'may be used uninitialized'\
    \ warnings on gcc.\n    */\n   #if defined(__GNUC__) && __GNUC__\n   #define UNINITIALIZED_IS_SAFE(x)\
    \ x=x\n   #else\n   #define UNINITIALIZED_IS_SAFE(x) x\n   #endif\n   ---- End\
    \ code block ----------------------------------------\n"
- title: 20.11.  modemv.c
  contents:
  - "20.11.  modemv.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #include \"dixie.h\"\
    \n   #include \"modemv_data.h\"\n   #include <stdlib.h>\n   #include <assert.h>\n\
    \   struct mv_clamp_rect\n   {\n       int to_left, to_right, to_top, to_bottom;\n\
    \   };\n   static union mv\n           clamp_mv(union mv raw, const struct mv_clamp_rect\
    \ *bounds)\n   {\n       union mv newmv;\n       newmv.d.x = (raw.d.x < bounds->to_left)\n\
    \                   ? bounds->to_left : raw.d.x;\n       newmv.d.x = (raw.d.x\
    \ > bounds->to_right)\n                   ? bounds->to_right : newmv.d.x;\n  \
    \     newmv.d.y = (raw.d.y < bounds->to_top)\n                   ? bounds->to_top\
    \ : raw.d.y;\n       newmv.d.y = (raw.d.y > bounds->to_bottom)\n             \
    \      ? bounds->to_bottom : newmv.d.y;\n       return newmv;\n   }\n   static\
    \ int\n   read_segment_id(struct bool_decoder *bool,\n                   struct\
    \ vp8_segment_hdr *seg)\n   {\n       return bool_get(bool, seg->tree_probs[0])\n\
    \              ? 2 + bool_get(bool, seg->tree_probs[2])\n              : bool_get(bool,\
    \ seg->tree_probs[1]);\n   }\n   static enum prediction_mode\n   above_block_mode(const\
    \ struct mb_info *this,\n                    const struct mb_info *above,\n  \
    \                  unsigned int b)\n   {\n       if (b < 4)\n       {\n      \
    \     switch (above->base.y_mode)\n           {\n           case DC_PRED:\n  \
    \             return B_DC_PRED;\n           case V_PRED:\n               return\
    \ B_VE_PRED;\n           case H_PRED:\n               return B_HE_PRED;\n    \
    \       case TM_PRED:\n               return B_TM_PRED;\n           case B_PRED:\n\
    \               return above->split.modes[b+12];\n           default:\n      \
    \         assert(0);\n           }\n       }\n       return this->split.modes[b-4];\n\
    \   }\n   static enum prediction_mode\n   left_block_mode(const struct mb_info\
    \ *this,\n                   const struct mb_info *left,\n                   unsigned\
    \ int b)\n   {\n       if (!(b & 3))\n       {\n           switch (left->base.y_mode)\n\
    \           {\n           case DC_PRED:\n               return B_DC_PRED;\n  \
    \         case V_PRED:\n               return B_VE_PRED;\n           case H_PRED:\n\
    \               return B_HE_PRED;\n           case TM_PRED:\n               return\
    \ B_TM_PRED;\n           case B_PRED:\n               return left->split.modes[b+3];\n\
    \           default:\n               assert(0);\n           }\n       }\n    \
    \   return this->split.modes[b-1];\n   }\n   static void\n   decode_kf_mb_mode(struct\
    \ mb_info      *this,\n                     struct mb_info      *left,\n     \
    \                struct mb_info      *above,\n                     struct bool_decoder\
    \ *bool)\n   {\n       int y_mode, uv_mode;\n       y_mode = bool_read_tree(bool,\
    \ kf_y_mode_tree, kf_y_mode_probs);\n       if (y_mode == B_PRED)\n       {\n\
    \           unsigned int i;\n           for (i = 0; i < 16; i++)\n           {\n\
    \               enum prediction_mode a = above_block_mode(this, above,\n     \
    \                                                    i);\n               enum\
    \ prediction_mode l = left_block_mode(this, left, i);\n               enum prediction_mode\
    \ b;\n               b = bool_read_tree(bool, b_mode_tree,\n                 \
    \                 kf_b_mode_probs[a][l]);\n               this->split.modes[i]\
    \ = b;\n           }\n       }\n       uv_mode = bool_read_tree(bool, uv_mode_tree,\
    \ kf_uv_mode_probs);\n       this->base.y_mode = y_mode;\n       this->base.uv_mode\
    \ = uv_mode;\n       this->base.mv.raw = 0;\n       this->base.ref_frame = 0;\n\
    \   }\n   static void\n   decode_intra_mb_mode(struct mb_info         *this,\n\
    \                        struct vp8_entropy_hdr *hdr,\n                      \
    \  struct bool_decoder    *bool)\n   {\n       /* Like decode_kf_mb_mode, but\
    \ with probabilities transmitted in\n        * the bitstream and no context on\
    \ the above/left block mode.\n        */\n       int y_mode, uv_mode;\n      \
    \ y_mode = bool_read_tree(bool, y_mode_tree, hdr->y_mode_probs);\n       if (y_mode\
    \ == B_PRED)\n       {\n           unsigned int i;\n           for (i = 0; i <\
    \ 16; i++)\n           {\n               enum prediction_mode b;\n           \
    \    b = bool_read_tree(bool, b_mode_tree,\n                                 \
    \ default_b_mode_probs);\n               this->split.modes[i] = b;\n         \
    \  }\n       }\n       uv_mode = bool_read_tree(bool, uv_mode_tree, hdr->uv_mode_probs);\n\
    \       this->base.y_mode = y_mode;\n       this->base.uv_mode = uv_mode;\n  \
    \     this->base.mv.raw = 0;\n       this->base.ref_frame = CURRENT_FRAME;\n \
    \  }\n   static int\n   read_mv_component(struct bool_decoder *bool,\n       \
    \              const unsigned char  mvc[MV_PROB_CNT])\n   {\n       enum {IS_SHORT,\
    \ SIGN, SHORT, BITS = SHORT + 8 - 1,\n             LONG_WIDTH = 10};\n       int\
    \ x = 0;\n       if (bool_get(bool, mvc[IS_SHORT])) /* Large */\n       {\n  \
    \         int i = 0;\n           for (i = 0; i < 3; i++)\n               x +=\
    \ bool_get(bool, mvc[BITS + i]) << i;\n           /* Skip bit 3, which is sometimes\
    \ implicit */\n           for (i = LONG_WIDTH - 1; i > 3; i--)\n             \
    \  x += bool_get(bool, mvc[BITS + i]) << i;\n           if (!(x & 0xFFF0)  ||\
    \  bool_get(bool, mvc[BITS + 3]))\n               x += 8;\n       }\n       else\
    \   /* small */\n           x = bool_read_tree(bool, small_mv_tree, mvc + SHORT);\n\
    \       if (x && bool_get(bool, mvc[SIGN]))\n           x = -x;\n       return\
    \ x << 1;\n   }\n   static mv_t\n   above_block_mv(const struct mb_info *this,\n\
    \                  const struct mb_info *above,\n                  unsigned int\
    \          b)\n   {\n       if (b < 4)\n       {\n           if (above->base.y_mode\
    \ == SPLITMV)\n               return above->split.mvs[b+12];\n           return\
    \ above->base.mv;\n       }\n       return this->split.mvs[b-4];\n   }\n   static\
    \ mv_t\n   left_block_mv(const struct mb_info *this,\n                 const struct\
    \ mb_info *left,\n                 unsigned int          b)\n   {\n       if (!(b\
    \ & 3))\n       {\n           if (left->base.y_mode == SPLITMV)\n            \
    \   return left->split.mvs[b+3];\n           return left->base.mv;\n       }\n\
    \       return this->split.mvs[b-1];\n   }\n   static enum prediction_mode\n \
    \  submv_ref(struct bool_decoder *bool, union mv l, union mv a)\n   {\n      \
    \ enum subblock_mv_ref\n       {\n           SUBMVREF_NORMAL,\n           SUBMVREF_LEFT_ZED,\n\
    \           SUBMVREF_ABOVE_ZED,\n           SUBMVREF_LEFT_ABOVE_SAME,\n      \
    \     SUBMVREF_LEFT_ABOVE_ZED\n       };\n       int lez = !(l.raw);\n       int\
    \ aez = !(a.raw);\n       int lea = l.raw == a.raw;\n       enum subblock_mv_ref\
    \ ctx = SUBMVREF_NORMAL;\n       if (lea && lez)\n           ctx = SUBMVREF_LEFT_ABOVE_ZED;\n\
    \       else if (lea)\n           ctx = SUBMVREF_LEFT_ABOVE_SAME;\n       else\
    \ if (aez)\n           ctx = SUBMVREF_ABOVE_ZED;\n       else if (lez)\n     \
    \      ctx = SUBMVREF_LEFT_ZED;\n       return bool_read_tree(bool, submv_ref_tree,\n\
    \                             submv_ref_probs2[ctx]);\n   }\n   static void\n\
    \   read_mv(struct bool_decoder  *bool,\n           union mv             *mv,\n\
    \           mv_component_probs_t  mvc[2])\n   {\n       mv->d.y = read_mv_component(bool,\
    \ mvc[0]);\n       mv->d.x = read_mv_component(bool, mvc[1]);\n   }\n   static\
    \ void\n   mv_bias(const struct mb_info *mb,\n           const unsigned int  \
    \ sign_bias[3],\n           enum reference_frame ref_frame,\n           union\
    \ mv             *mv)\n   {\n       if (sign_bias[mb->base.ref_frame] ^ sign_bias[ref_frame])\n\
    \       {\n           mv->d.x *= -1;\n           mv->d.y *= -1;\n       }\n  \
    \ }\n   enum near_mv_v\n   {\n       CNT_BEST = 0,\n       CNT_ZEROZERO = 0,\n\
    \       CNT_NEAREST,\n       CNT_NEAR,\n       CNT_SPLITMV\n   };\n   static void\n\
    \   find_near_mvs(const struct mb_info   *this,\n                 const struct\
    \ mb_info   *left,\n                 const struct mb_info   *above,\n        \
    \         const unsigned int      sign_bias[3],\n                 union  mv  \
    \             near_mvs[4],\n                 int                     cnt[4])\n\
    \   {\n       const struct mb_info *aboveleft = above - 1;\n       union  mv \
    \            *mv = near_mvs;\n       int                   *cntx = cnt;\n    \
    \   /* Zero accumulators */\n       mv[0].raw = mv[1].raw = mv[2].raw = 0;\n \
    \      cnt[0] = cnt[1] = cnt[2] = cnt[3] = 0;\n       /* Process above */\n  \
    \     if (above->base.ref_frame != CURRENT_FRAME)\n       {\n           if (above->base.mv.raw)\n\
    \           {\n               (++mv)->raw = above->base.mv.raw;\n            \
    \   mv_bias(above, sign_bias, this->base.ref_frame, mv);\n               ++cntx;\n\
    \           }\n           *cntx += 2;\n       }\n       /* Process left */\n \
    \      if (left->base.ref_frame != CURRENT_FRAME)\n       {\n           if (left->base.mv.raw)\n\
    \           {\n               union mv this_mv;\n               this_mv.raw =\
    \ left->base.mv.raw;\n               mv_bias(left, sign_bias, this->base.ref_frame,\
    \ &this_mv);\n               if (this_mv.raw != mv->raw)\n               {\n \
    \                  (++mv)->raw = this_mv.raw;\n                   ++cntx;\n  \
    \             }\n               *cntx += 2;\n           }\n           else\n \
    \              cnt[CNT_ZEROZERO] += 2;\n       }\n       /* Process above left\
    \ */\n       if (aboveleft->base.ref_frame != CURRENT_FRAME)\n       {\n     \
    \      if (aboveleft->base.mv.raw)\n           {\n               union mv this_mv;\n\
    \               this_mv.raw = aboveleft->base.mv.raw;\n               mv_bias(aboveleft,\
    \ sign_bias, this->base.ref_frame,\n                       &this_mv);\n      \
    \         if (this_mv.raw != mv->raw)\n               {\n                   (++mv)->raw\
    \ = this_mv.raw;\n                   ++cntx;\n               }\n             \
    \  *cntx += 1;\n           }\n           else\n               cnt[CNT_ZEROZERO]\
    \ += 1;\n       }\n       /* If we have three distinct MVs ... */\n       if (cnt[CNT_SPLITMV])\n\
    \       {\n           /* See if above-left MV can be merged with NEAREST */\n\
    \           if (mv->raw == near_mvs[CNT_NEAREST].raw)\n               cnt[CNT_NEAREST]\
    \ += 1;\n       }\n       cnt[CNT_SPLITMV] = ((above->base.y_mode == SPLITMV)\n\
    \                           + (left->base.y_mode == SPLITMV)) * 2\n          \
    \                + (aboveleft->base.y_mode == SPLITMV);\n       /* Swap near and\
    \ nearest if necessary */\n       if (cnt[CNT_NEAR] > cnt[CNT_NEAREST])\n    \
    \   {\n           int tmp;\n           tmp = cnt[CNT_NEAREST];\n           cnt[CNT_NEAREST]\
    \ = cnt[CNT_NEAR];\n           cnt[CNT_NEAR] = tmp;\n           tmp = near_mvs[CNT_NEAREST].raw;\n\
    \           near_mvs[CNT_NEAREST].raw = near_mvs[CNT_NEAR].raw;\n           near_mvs[CNT_NEAR].raw\
    \ = tmp;\n       }\n       /* Use near_mvs[CNT_BEST] to store the \"best\" MV.\
    \  Note that this\n        * storage shares the same address as near_mvs[CNT_ZEROZERO].\n\
    \        */\n       if (cnt[CNT_NEAREST] >= cnt[CNT_BEST])\n           near_mvs[CNT_BEST]\
    \ = near_mvs[CNT_NEAREST];\n   }\n   static void\n   decode_split_mv(struct mb_info\
    \         *this,\n                   const struct mb_info   *left,\n         \
    \          const struct mb_info   *above,\n                   struct vp8_entropy_hdr\
    \ *hdr,\n                   union  mv              *best_mv,\n               \
    \    struct bool_decoder    *bool)\n   {\n       const int *partition;\n     \
    \  int        j, k, mask, partition_id;\n       partition_id = bool_read_tree(bool,\
    \ split_mv_tree,\n                                     split_mv_probs);\n    \
    \   partition = mv_partitions[partition_id];\n       this->base.partitioning =\
    \ partition_id;\n       for (j = 0, mask = 0; mask < 65535; j++)\n       {\n \
    \          union mv mv, left_mv, above_mv;\n           enum prediction_mode subblock_mode;\n\
    \           /* Find the first subblock in this partition. */\n           for (k\
    \ = 0; j != partition[k]; k++);\n           /* Decode the next MV */\n       \
    \    left_mv = left_block_mv(this, left, k);\n           above_mv = above_block_mv(this,\
    \ above, k);\n           subblock_mode = submv_ref(bool, left_mv,  above_mv);\n\
    \           switch (subblock_mode)\n           {\n           case LEFT4X4:\n \
    \              mv = left_mv;\n               break;\n           case ABOVE4X4:\n\
    \               mv = above_mv;\n               break;\n           case ZERO4X4:\n\
    \               mv.raw = 0;\n               break;\n           case NEW4X4:\n\
    \               read_mv(bool, &mv, hdr->mv_probs);\n               mv.d.x += best_mv->d.x;\n\
    \               mv.d.y += best_mv->d.y;\n               break;\n           default:\n\
    \               assert(0);\n           }\n           /* Fill the MVs for this\
    \ partition */\n           for (; k < 16; k++)\n               if (j == partition[k])\n\
    \               {\n                   this->split.mvs[k] = mv;\n             \
    \      mask |= 1 << k;\n               }\n       }\n   }\n   static int\n   need_mc_border(union\
    \ mv mv, int l, int t, int b_w, int w, int h)\n   {\n       int b, r;\n      \
    \ /* Get distance to edge for top-left pixel */\n       l += (mv.d.x >> 3);\n\
    \       t += (mv.d.y >> 3);\n       /* Get distance to edge for bottom-right pixel\
    \ */\n       r = w - (l + b_w);\n       b = h - (t + b_w);\n       return (l >>\
    \ 1 < 2 || r >> 1 < 3 || t >> 1 < 2 || b >> 1 < 3);\n   }\n   static void\n  \
    \ decode_mvs(struct vp8_decoder_ctx       *ctx,\n              struct mb_info\
    \               *this,\n              const struct mb_info         *left,\n  \
    \            const struct mb_info         *above,\n              const struct\
    \ mv_clamp_rect   *bounds,\n              struct bool_decoder          *bool)\n\
    \   {\n       struct vp8_entropy_hdr *hdr = &ctx->entropy_hdr;\n       union mv\
    \          near_mvs[4];\n       union mv          clamped_best_mv;\n       int\
    \               mv_cnts[4];\n       unsigned char     probs[4];\n       enum {BEST,\
    \ NEAREST, NEAR};\n       int x, y, w, h, b;\n       this->base.ref_frame = bool_get(bool,\
    \ hdr->prob_last)\n                              ? 2 + bool_get(bool, hdr->prob_gf)\n\
    \                              : 1;\n       find_near_mvs(this, this - 1, above,\n\
    \                     ctx->reference_hdr.sign_bias, near_mvs, mv_cnts);\n    \
    \   probs[0] = mv_counts_to_probs[mv_cnts[0]][0];\n       probs[1] = mv_counts_to_probs[mv_cnts[1]][1];\n\
    \       probs[2] = mv_counts_to_probs[mv_cnts[2]][2];\n       probs[3] = mv_counts_to_probs[mv_cnts[3]][3];\n\
    \       this->base.y_mode = bool_read_tree(bool, mv_ref_tree, probs);\n      \
    \ this->base.uv_mode = this->base.y_mode;\n       this->base.need_mc_border =\
    \ 0;\n       x = (-bounds->to_left - 128) >> 3;\n       y = (-bounds->to_top -\
    \ 128) >> 3;\n       w = ctx->mb_cols * 16;\n       h = ctx->mb_rows * 16;\n \
    \      switch (this->base.y_mode)\n       {\n       case NEARESTMV:\n        \
    \   this->base.mv = clamp_mv(near_mvs[NEAREST], bounds);\n           break;\n\
    \       case NEARMV:\n           this->base.mv = clamp_mv(near_mvs[NEAR], bounds);\n\
    \           break;\n       case ZEROMV:\n           this->base.mv.raw = 0;\n \
    \          return; //skip need_mc_border check\n       case NEWMV:\n         \
    \  clamped_best_mv = clamp_mv(near_mvs[BEST], bounds);\n           read_mv(bool,\
    \ &this->base.mv, hdr->mv_probs);\n           this->base.mv.d.x += clamped_best_mv.d.x;\n\
    \           this->base.mv.d.y += clamped_best_mv.d.y;\n           break;\n   \
    \    case SPLITMV:\n       {\n           union mv          chroma_mv[4] = {{{0}}};\n\
    \           clamped_best_mv = clamp_mv(near_mvs[BEST], bounds);\n           decode_split_mv(this,\
    \ left, above, hdr, &clamped_best_mv,\n                           bool);\n   \
    \        this->base.mv = this->split.mvs[15];\n           for (b = 0; b < 16;\
    \ b++)\n           {\n               chroma_mv[(b>>1&1) + (b>>2&2)].d.x +=\n \
    \                  this->split.mvs[b].d.x;\n               chroma_mv[(b>>1&1)\
    \ + (b>>2&2)].d.y +=\n                   this->split.mvs[b].d.y;\n           \
    \    if (need_mc_border(this->split.mvs[b],\n               x + (b & 3) * 4, y\
    \ + (b & ~3), 4, w, h))\n               {\n                   this->base.need_mc_border\
    \ = 1;\n                   break;\n               }\n           }\n          \
    \ for (b = 0; b < 4; b++)\n           {\n               chroma_mv[b].d.x += 4\
    \ + 8 * (chroma_mv[b].d.x >> 31);\n               chroma_mv[b].d.y += 4 + 8 *\
    \ (chroma_mv[b].d.y >> 31);\n               chroma_mv[b].d.x /= 4;\n         \
    \      chroma_mv[b].d.y /= 4;\n               //note we're passing in non-subsampled\
    \ coordinates\n               if (need_mc_border(chroma_mv[b],\n             \
    \  x + (b & 1) * 8, y + (b >> 1) * 8, 16, w, h))\n               {\n         \
    \          this->base.need_mc_border = 1;\n                   break;\n       \
    \        }\n           }\n           return; //skip need_mc_border check\n   \
    \    }\n       default:\n           assert(0);\n       }\n       if (need_mc_border(this->base.mv,\
    \ x, y, 16, w, h))\n           this->base.need_mc_border = 1;\n   }\n   void\n\
    \   vp8_dixie_modemv_process_row(struct vp8_decoder_ctx *ctx,\n   struct bool_decoder\
    \    *bool,\n   int                     row,\n   int                     start_col,\n\
    \   int                     num_cols)\n   {\n       struct mb_info       *above,\
    \ *this;\n       unsigned int          col;\n       struct mv_clamp_rect  bounds;\n\
    \       this = ctx->mb_info_rows[row] + start_col;\n       above = ctx->mb_info_rows[row\
    \ - 1] + start_col;\n       /* Calculate the eighth-pel MV bounds using a 1 MB\
    \ border. */\n       bounds.to_left   = -((start_col + 1) << 7);\n       bounds.to_right\
    \  = (ctx->mb_cols - start_col) << 7;\n       bounds.to_top    = -((row + 1) <<\
    \ 7);\n       bounds.to_bottom = (ctx->mb_rows - row) << 7;\n       for (col =\
    \ start_col; col < start_col + num_cols; col++)\n       {\n           if (ctx->segment_hdr.update_map)\n\
    \               this->base.segment_id = read_segment_id(bool,\n              \
    \ &ctx->segment_hdr);\n           if (ctx->entropy_hdr.coeff_skip_enabled)\n \
    \              this->base.skip_coeff = bool_get(bool,\n               ctx->entropy_hdr.coeff_skip_prob);\n\
    \           if (ctx->frame_hdr.is_keyframe)\n           {\n               if (!ctx->segment_hdr.update_map)\n\
    \                   this->base.segment_id = 0;\n               decode_kf_mb_mode(this,\
    \ this - 1, above, bool);\n           }\n           else\n           {\n     \
    \          if (bool_get(bool, ctx->entropy_hdr.prob_inter))\n                \
    \   decode_mvs(ctx, this, this - 1, above, &bounds,\n                        \
    \      bool);\n               else\n                   decode_intra_mb_mode(this,\
    \ &ctx->entropy_hdr, bool);\n               bounds.to_left -= 16 << 3;\n     \
    \          bounds.to_right -= 16 << 3;\n           }\n           /* Advance to\
    \ next mb */\n           this++;\n           above++;\n       }\n   }\n   void\n\
    \   vp8_dixie_modemv_init(struct vp8_decoder_ctx *ctx)\n   {\n       unsigned\
    \ int    mbi_w, mbi_h, i;\n       struct mb_info *mbi;\n       mbi_w = ctx->mb_cols\
    \ + 1; /* For left border col */\n       mbi_h = ctx->mb_rows + 1; /* For above\
    \ border row */\n       if (ctx->frame_hdr.frame_size_updated)\n       {\n   \
    \        free(ctx->mb_info_storage);\n           ctx->mb_info_storage = NULL;\n\
    \           free(ctx->mb_info_rows_storage);\n           ctx->mb_info_rows_storage\
    \ = NULL;\n       }\n       if (!ctx->mb_info_storage)\n           ctx->mb_info_storage\
    \ = calloc(mbi_w * mbi_h,\n           sizeof(*ctx->mb_info_storage));\n      \
    \ if (!ctx->mb_info_rows_storage)\n           ctx->mb_info_rows_storage = calloc(mbi_h,\n\
    \           sizeof(*ctx->mb_info_rows_storage));\n       /* Set up row pointers\
    \ */\n       mbi = ctx->mb_info_storage + 1;\n       for (i = 0; i < mbi_h; i++)\n\
    \       {\n           ctx->mb_info_rows_storage[i] = mbi;\n           mbi += mbi_w;\n\
    \       }\n       ctx->mb_info_rows = ctx->mb_info_rows_storage + 1;\n   }\n \
    \  void\n   vp8_dixie_modemv_destroy(struct vp8_decoder_ctx *ctx)\n   {\n    \
    \   free(ctx->mb_info_storage);\n       ctx->mb_info_storage = NULL;\n       free(ctx->mb_info_rows_storage);\n\
    \       ctx->mb_info_rows_storage = NULL;\n   }\n   ---- End code block ----------------------------------------\n"
- title: 20.12.  modemv.h
  contents:
  - "20.12.  modemv.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef MODEMV_H\n\
    \   #define MODEMV_H\n   void\n   vp8_dixie_modemv_init(struct vp8_decoder_ctx\
    \ *ctx);\n   void\n   vp8_dixie_modemv_destroy(struct vp8_decoder_ctx *ctx);\n\
    \   void\n   vp8_dixie_modemv_process_row(struct vp8_decoder_ctx *ctx,\n     \
    \                           struct bool_decoder    *bool,\n                  \
    \              int                     row,\n                                int\
    \                     start_col,\n                                int        \
    \             num_cols);\n   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.13.  modemv_data.h
  contents:
  - "20.13.  modemv_data.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   static const unsigned\
    \ char kf_y_mode_probs[] = { 145, 156, 163, 128};\n   static const unsigned char\
    \ kf_uv_mode_probs[] = { 142, 114, 183};\n   static const unsigned char kf_b_mode_probs[10][10][9]\
    \ =\n   {\n     { /* above mode 0 */\n       { /* left mode 0 */ 231, 120,  48,\
    \  89, 115, 113, 120, 152, 112},\n       { /* left mode 1 */ 152, 179,  64, 126,\
    \ 170, 118,  46,  70,  95},\n       { /* left mode 2 */ 175,  69, 143,  80,  85,\
    \  82,  72, 155, 103},\n       { /* left mode 3 */  56,  58,  10, 171, 218, 189,\
    \  17,  13, 152},\n       { /* left mode 4 */ 144,  71,  10,  38, 171, 213, 144,\
    \  34,  26},\n       { /* left mode 5 */ 114,  26,  17, 163,  44, 195,  21,  10,\
    \ 173},\n       { /* left mode 6 */ 121,  24,  80, 195,  26,  62,  44,  64,  85},\n\
    \       { /* left mode 7 */ 170,  46,  55,  19, 136, 160,  33, 206,  71},\n  \
    \     { /* left mode 8 */  63,  20,   8, 114, 114, 208,  12,   9, 226},\n    \
    \   { /* left mode 9 */  81,  40,  11,  96, 182,  84,  29,  16,  36}\n     },\n\
    \     { /* above mode 1 */\n       { /* left mode 0 */ 134, 183,  89, 137,  98,\
    \ 101, 106, 165, 148},\n       { /* left mode 1 */  72, 187, 100, 130, 157, 111,\
    \  32,  75,  80},\n       { /* left mode 2 */  66, 102, 167,  99,  74,  62,  40,\
    \ 234, 128},\n       { /* left mode 3 */  41,  53,   9, 178, 241, 141,  26,  \
    \ 8, 107},\n       { /* left mode 4 */ 104,  79,  12,  27, 217, 255,  87,  17,\
    \   7},\n       { /* left mode 5 */  74,  43,  26, 146,  73, 166,  49,  23, 157},\n\
    \       { /* left mode 6 */  65,  38, 105, 160,  51,  52,  31, 115, 128},\n  \
    \     { /* left mode 7 */  87,  68,  71,  44, 114,  51,  15, 186,  23},\n    \
    \   { /* left mode 8 */  47,  41,  14, 110, 182, 183,  21,  17, 194},\n      \
    \ { /* left mode 9 */  66,  45,  25, 102, 197, 189,  23,  18,  22}\n     },\n\
    \     { /* above mode 2 */\n       { /* left mode 0 */  88,  88, 147, 150,  42,\
    \  46,  45, 196, 205},\n       { /* left mode 1 */  43,  97, 183, 117,  85,  38,\
    \  35, 179,  61},\n       { /* left mode 2 */  39,  53, 200,  87,  26,  21,  43,\
    \ 232, 171},\n       { /* left mode 3 */  56,  34,  51, 104, 114, 102,  29,  93,\
    \  77},\n       { /* left mode 4 */ 107,  54,  32,  26,  51,   1,  81,  43,  31},\n\
    \       { /* left mode 5 */  39,  28,  85, 171,  58, 165,  90,  98,  64},\n  \
    \     { /* left mode 6 */  34,  22, 116, 206,  23,  34,  43, 166,  73},\n    \
    \   { /* left mode 7 */  68,  25, 106,  22,  64, 171,  36, 225, 114},\n      \
    \ { /* left mode 8 */  34,  19,  21, 102, 132, 188,  16,  76, 124},\n       {\
    \ /* left mode 9 */  62,  18,  78,  95,  85,  57,  50,  48,  51}\n     },\n  \
    \   { /* above mode 3 */\n       { /* left mode 0 */ 193, 101,  35, 159, 215,\
    \ 111,  89,  46, 111},\n       { /* left mode 1 */  60, 148,  31, 172, 219, 228,\
    \  21,  18, 111},\n       { /* left mode 2 */ 112, 113,  77,  85, 179, 255,  38,\
    \ 120, 114},\n       { /* left mode 3 */  40,  42,   1, 196, 245, 209,  10,  25,\
    \ 109},\n       { /* left mode 4 */ 100,  80,   8,  43, 154,   1,  51,  26,  71},\n\
    \       { /* left mode 5 */  88,  43,  29, 140, 166, 213,  37,  43, 154},\n  \
    \     { /* left mode 6 */  61,  63,  30, 155,  67,  45,  68,   1, 209},\n    \
    \   { /* left mode 7 */ 142,  78,  78,  16, 255, 128,  34, 197, 171},\n      \
    \ { /* left mode 8 */  41,  40,   5, 102, 211, 183,   4,   1, 221},\n       {\
    \ /* left mode 9 */  51,  50,  17, 168, 209, 192,  23,  25,  82}\n     },\n  \
    \   { /* above mode 4 */\n       { /* left mode 0 */ 125,  98,  42,  88, 104,\
    \  85, 117, 175,  82},\n       { /* left mode 1 */  95,  84,  53,  89, 128, 100,\
    \ 113, 101,  45},\n       { /* left mode 2 */  75,  79, 123,  47,  51, 128,  81,\
    \ 171,   1},\n       { /* left mode 3 */  57,  17,   5,  71, 102,  57,  53,  41,\
    \  49},\n       { /* left mode 4 */ 115,  21,   2,  10, 102, 255, 166,  23,  \
    \ 6},\n       { /* left mode 5 */  38,  33,  13, 121,  57,  73,  26,   1,  85},\n\
    \       { /* left mode 6 */  41,  10,  67, 138,  77, 110,  90,  47, 114},\n  \
    \     { /* left mode 7 */ 101,  29,  16,  10,  85, 128, 101, 196,  26},\n    \
    \   { /* left mode 8 */  57,  18,  10, 102, 102, 213,  34,  20,  43},\n      \
    \ { /* left mode 9 */ 117,  20,  15,  36, 163, 128,  68,   1,  26}\n     },\n\
    \     { /* above mode 5 */\n       { /* left mode 0 */ 138,  31,  36, 171,  27,\
    \ 166,  38,  44, 229},\n       { /* left mode 1 */  67,  87,  58, 169,  82, 115,\
    \  26,  59, 179},\n       { /* left mode 2 */  63,  59,  90, 180,  59, 166,  93,\
    \  73, 154},\n       { /* left mode 3 */  40,  40,  21, 116, 143, 209,  34,  39,\
    \ 175},\n       { /* left mode 4 */  57,  46,  22,  24, 128,   1,  54,  17,  37},\n\
    \       { /* left mode 5 */  47,  15,  16, 183,  34, 223,  49,  45, 183},\n  \
    \     { /* left mode 6 */  46,  17,  33, 183,   6,  98,  15,  32, 183},\n    \
    \   { /* left mode 7 */  65,  32,  73, 115,  28, 128,  23, 128, 205},\n      \
    \ { /* left mode 8 */  40,   3,   9, 115,  51, 192,  18,   6, 223},\n       {\
    \ /* left mode 9 */  87,  37,   9, 115,  59,  77,  64,  21,  47}\n     },\n  \
    \   { /* above mode 6 */\n       { /* left mode 0 */ 104,  55,  44, 218,   9,\
    \  54,  53, 130, 226},\n       { /* left mode 1 */  64,  90,  70, 205,  40,  41,\
    \  23,  26,  57},\n       { /* left mode 2 */  54,  57, 112, 184,   5,  41,  38,\
    \ 166, 213},\n       { /* left mode 3 */  30,  34,  26, 133, 152, 116,  10,  32,\
    \ 134},\n       { /* left mode 4 */  75,  32,  12,  51, 192, 255, 160,  43,  51},\n\
    \       { /* left mode 5 */  39,  19,  53, 221,  26, 114,  32,  73, 255},\n  \
    \     { /* left mode 6 */  31,   9,  65, 234,   2,  15,   1, 118,  73},\n    \
    \   { /* left mode 7 */  88,  31,  35,  67, 102,  85,  55, 186,  85},\n      \
    \ { /* left mode 8 */  56,  21,  23, 111,  59, 205,  45,  37, 192},\n       {\
    \ /* left mode 9 */  55,  38,  70, 124,  73, 102,   1,  34,  98}\n     },\n  \
    \   { /* above mode 7 */\n       { /* left mode 0 */ 102,  61,  71,  37,  34,\
    \  53,  31, 243, 192},\n       { /* left mode 1 */  69,  60,  71,  38,  73, 119,\
    \  28, 222,  37},\n       { /* left mode 2 */  68,  45, 128,  34,   1,  47,  11,\
    \ 245, 171},\n       { /* left mode 3 */  62,  17,  19,  70, 146,  85,  55,  62,\
    \  70},\n       { /* left mode 4 */  75,  15,   9,   9,  64, 255, 184, 119,  16},\n\
    \       { /* left mode 5 */  37,  43,  37, 154, 100, 163,  85, 160,   1},\n  \
    \     { /* left mode 6 */  63,   9,  92, 136,  28,  64,  32, 201,  85},\n    \
    \   { /* left mode 7 */  86,   6,  28,   5,  64, 255,  25, 248,   1},\n      \
    \ { /* left mode 8 */  56,   8,  17, 132, 137, 255,  55, 116, 128},\n       {\
    \ /* left mode 9 */  58,  15,  20,  82, 135,  57,  26, 121,  40}\n     },\n  \
    \   { /* above mode 8 */\n       { /* left mode 0 */ 164,  50,  31, 137, 154,\
    \ 133,  25,  35, 218},\n       { /* left mode 1 */  51, 103,  44, 131, 131, 123,\
    \  31,   6, 158},\n       { /* left mode 2 */  86,  40,  64, 135, 148, 224,  45,\
    \ 183, 128},\n       { /* left mode 3 */  22,  26,  17, 131, 240, 154,  14,  \
    \ 1, 209},\n       { /* left mode 4 */  83,  12,  13,  54, 192, 255,  68,  47,\
    \  28},\n       { /* left mode 5 */  45,  16,  21,  91,  64, 222,   7,   1, 197},\n\
    \       { /* left mode 6 */  56,  21,  39, 155,  60, 138,  23, 102, 213},\n  \
    \     { /* left mode 7 */  85,  26,  85,  85, 128, 128,  32, 146, 171},\n    \
    \   { /* left mode 8 */  18,  11,   7,  63, 144, 171,   4,   4, 246},\n      \
    \ { /* left mode 9 */  35,  27,  10, 146, 174, 171,  12,  26, 128}\n     },\n\
    \     { /* above mode 9 */\n       { /* left mode 0 */ 190,  80,  35,  99, 180,\
    \  80, 126,  54,  45},\n       { /* left mode 1 */  85, 126,  47,  87, 176,  51,\
    \  41,  20,  32},\n       { /* left mode 2 */ 101,  75, 128, 139, 118, 146, 116,\
    \ 128,  85},\n       { /* left mode 3 */  56,  41,  15, 176, 236,  85,  37,  \
    \ 9,  62},\n       { /* left mode 4 */ 146,  36,  19,  30, 171, 255,  97,  27,\
    \  20},\n       { /* left mode 5 */  71,  30,  17, 119, 118, 255,  17,  18, 138},\n\
    \       { /* left mode 6 */ 101,  38,  60, 138,  55,  70,  43,  26, 142},\n  \
    \     { /* left mode 7 */ 138,  45,  61,  62, 219,   1,  81, 188,  64},\n    \
    \   { /* left mode 8 */  32,  41,  20, 117, 151, 142,  20,  21, 163},\n      \
    \ { /* left mode 9 */ 112,  19,  12,  61, 195, 128,  48,   4,  24}\n     }\n \
    \  };\n   static const int kf_y_mode_tree[] =\n   {\n     -B_PRED, 2,\n     4,\
    \ 6,\n     -DC_PRED, -V_PRED,\n     -H_PRED, -TM_PRED\n   };\n   static const\
    \ int y_mode_tree[] =\n   {\n     -DC_PRED, 2,\n     4, 6,\n     -V_PRED, -H_PRED,\n\
    \     -TM_PRED, -B_PRED\n   };\n   static const int uv_mode_tree[6] =\n   {\n\
    \     -DC_PRED, 2,\n     -V_PRED, 4,\n     -H_PRED, -TM_PRED\n   };\n   static\
    \ const int b_mode_tree[18] =\n   {\n     -B_DC_PRED, 2,               /* 0 =\
    \ DC_NODE */\n     -B_TM_PRED, 4,               /* 1 = TM_NODE */\n     -B_VE_PRED,\
    \ 6,               /* 2 = VE_NODE */\n     8, 12,                       /* 3 =\
    \ COM_NODE */\n     -B_HE_PRED, 10,              /* 4 = HE_NODE */\n     -B_RD_PRED,\
    \ -B_VR_PRED,      /* 5 = RD_NODE */\n     -B_LD_PRED, 14,              /* 6 =\
    \ LD_NODE */\n     -B_VL_PRED, 16,              /* 7 = VL_NODE */\n     -B_HD_PRED,\
    \ -B_HU_PRED       /* 8 = HD_NODE */\n   };\n   static const int small_mv_tree[14]\
    \ =\n   {\n     2, 8,\n     4, 6,\n     -0, -1,\n     -2, -3,\n     10, 12,\n\
    \     -4, -5,\n     -6, -7\n   };\n   static const int mv_ref_tree[8] =\n   {\n\
    \     -ZEROMV, 2,\n     -NEARESTMV, 4,\n     -NEARMV, 6,\n     -NEWMV, -SPLITMV\n\
    \   };\n   static const int submv_ref_tree[6] =\n   {\n     -LEFT4X4, 2,\n   \
    \  -ABOVE4X4, 4,\n     -ZERO4X4, -NEW4X4\n   };\n   static const int split_mv_tree[6]\
    \ =\n   {\n     -3, 2,\n     -2, 4,\n     -0, -1\n   };\n   static const unsigned\
    \ char default_b_mode_probs[] =\n   { 120,  90,  79, 133,  87,  85,  80, 111,\
    \ 151};\n   static const unsigned char mv_counts_to_probs[6][4] =\n   {\n    \
    \ {   7,   1,   1, 143 },\n     {  14,  18,  14, 107 },\n     { 135,  64,  57,\
    \  68 },\n     {  60,  56, 128,  65 },\n     { 159, 134, 128,  34 },\n     { 234,\
    \ 188, 128,  28 }\n   };\n   static const unsigned char split_mv_probs[3] =\n\
    \   { 110, 111, 150};\n   static const unsigned char submv_ref_probs2[5][3] =\n\
    \   {\n     { 147, 136, 18 },\n     { 106, 145,  1 },\n     { 179, 121,  1 },\n\
    \     { 223,   1, 34 },\n     { 208,   1,  1 }\n   };\n   const static int mv_partitions[4][16]\
    \ =\n   {\n     {0, 0, 0, 0, 0, 0, 0, 0, 1, 1,  1,  1,  1,  1,  1,  1 },\n   \
    \  {0, 0, 1, 1, 0, 0, 1, 1, 0, 0,  1,  1,  0,  0,  1,  1 },\n     {0, 0, 1, 1,\
    \ 0, 0, 1, 1, 2, 2,  3,  3,  2,  2,  3,  3 },\n     {0, 1, 2, 3, 4, 5, 6, 7, 8,\
    \ 9, 10, 11, 12, 13, 14, 15 }\n   };\n   ---- End code block ----------------------------------------\n"
- title: 20.14.  predict.c
  contents:
  - "20.14.  predict.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #include \"dixie.h\"\
    \n   #include \"predict.h\"\n   #include \"idct_add.h\"\n   #include \"mem.h\"\
    \n   #include <assert.h>\n   #include <string.h>\n   enum\n   {\n       BORDER_PIXELS\
    \     = 16,\n   };\n   static const filter_t sixtap_filters[8] =\n   {\n     \
    \  { 0,   0, 128,    0,   0,  0 },\n       { 0,  -6, 123,   12,  -1,  0 },\n \
    \      { 2, -11, 108,   36,  -8,  1 },\n       { 0,  -9,  93,   50,  -6,  0 },\n\
    \       { 3, -16,  77,   77, -16,  3 },\n       { 0,  -6,  50,   93,  -9,  0 },\n\
    \       { 1,  -8,  36,  108, -11,  2 },\n       { 0,  -1,  12,  123,  -6,  0 }\n\
    \   };\n   static const filter_t bilinear_filters[8] =\n   {\n       { 0,  0,\
    \  128,    0,   0,  0 },\n       { 0,  0,  112,   16,   0,  0 },\n       { 0,\
    \  0,   96,   32,   0,  0 },\n       { 0,  0,   80,   48,   0,  0 },\n       {\
    \ 0,  0,   64,   64,   0,  0 },\n       { 0,  0,   48,   80,   0,  0 },\n    \
    \   { 0,  0,   32,   96,   0,  0 },\n       { 0,  0,   16,  112,   0,  0 }\n \
    \  };\n   static void\n   predict_h_nxn(unsigned char *predict,\n            \
    \     int            stride,\n                 int            n)\n   {\n     \
    \  unsigned char *left = predict - 1;\n       int            i, j;\n       for\
    \ (i = 0; i < n; i++)\n           for (j = 0; j < n; j++)\n               predict[i\
    \ *stride + j] = left[i * stride];\n   }\n   static void\n   predict_v_nxn(unsigned\
    \ char *predict,\n                 int            stride,\n                 int\
    \            n)\n   {\n       unsigned char *above = predict - stride;\n     \
    \  int            i, j;\n       for (i = 0; i < n; i++)\n           for (j = 0;\
    \ j < n; j++)\n               predict[i *stride + j] = above[j];\n   }\n   static\
    \ void\n   predict_tm_nxn(unsigned char *predict,\n                  int     \
    \       stride,\n                  int            n)\n   {\n       /* Transposes\
    \ the left column to the top row for later\n        * consumption by the idct/recon\
    \ stage\n        */\n       unsigned char *left = predict - 1;\n       unsigned\
    \ char *above = predict - stride;\n       unsigned char  p = above[-1];\n    \
    \   int            i, j;\n       for (j = 0; j < n; j++)\n       {\n         \
    \  for (i = 0; i < n; i++)\n               predict[i] = CLAMP_255(*left + above[i]\
    \ - p);\n           predict += stride;\n           left += stride;\n       }\n\
    \   }\n   static void\n   predict_dc_nxn(unsigned char *predict,\n           \
    \       int            stride,\n                  int            n)\n   {\n  \
    \     unsigned char *left = predict - 1;\n       unsigned char *above = predict\
    \ - stride;\n       int            i, j, dc = 0;\n       for (i = 0; i < n; i++)\n\
    \       {\n           dc += *left + above[i];\n           left += stride;\n  \
    \     }\n       switch (n)\n       {\n       case 16:\n           dc = (dc + 16)\
    \ >> 5;\n           break;\n       case  8:\n           dc = (dc + 8) >> 4;\n\
    \           break;\n       case  4:\n           dc = (dc + 4) >> 3;\n        \
    \   break;\n       }\n       for (i = 0; i < n; i++)\n           for (j = 0; j\
    \ < n; j++)\n               predict[i *stride + j] = dc;\n   }\n   static void\n\
    \   predict_ve_4x4(unsigned char *predict,\n                  int            stride)\n\
    \   {\n       unsigned char *above = predict - stride;\n       int           \
    \ i, j;\n       predict[0] = (above[-1] + 2 * above[0] + above[1] + 2) >> 2;\n\
    \       predict[1] = (above[ 0] + 2 * above[1] + above[2] + 2) >> 2;\n       predict[2]\
    \ = (above[ 1] + 2 * above[2] + above[3] + 2) >> 2;\n       predict[3] = (above[\
    \ 2] + 2 * above[3] + above[4] + 2) >> 2;\n       for (i = 1; i < 4; i++)\n  \
    \         for (j = 0; j < 4; j++)\n               predict[i *stride + j] = predict[j];\n\
    \   }\n   static void\n   predict_he_4x4(unsigned char *predict,\n           \
    \       int            stride)\n   {\n       unsigned char *left = predict - 1;\n\
    \       predict[0] =\n       predict[1] =\n       predict[2] =\n       predict[3]\
    \ = (left[-stride] + 2 * left[0] +\n                     left[stride] + 2) >>\
    \ 2;\n       predict += stride;\n       left += stride;\n       predict[0] =\n\
    \       predict[1] =\n       predict[2] =\n       predict[3] = (left[-stride]\
    \ + 2 * left[0] +\n                     left[stride] + 2) >> 2;\n       predict\
    \ += stride;\n       left += stride;\n       predict[0] =\n       predict[1] =\n\
    \       predict[2] =\n       predict[3] = (left[-stride] + 2 * left[0] +\n   \
    \                  left[stride] + 2) >> 2;\n       predict += stride;\n      \
    \ left += stride;\n       predict[0] =\n       predict[1] =\n       predict[2]\
    \ =\n       predict[3] = (left[-stride] + 2 * left[0] + left[0] + 2) >> 2;\n \
    \  }\n   static void\n   predict_ld_4x4(unsigned char *predict,\n            \
    \      int            stride)\n   {\n       unsigned char *above = predict - stride;\n\
    \       int            pred0, pred1, pred2, pred3, pred4, pred5, pred6;\n    \
    \   predict[0] = pred0 = (above[0] + 2 * above[1] +\n                        \
    \     above[2] + 2) >> 2;\n       predict[1] = pred1 = (above[1] + 2 * above[2]\
    \ +\n                             above[3] + 2) >> 2;\n       predict[2] = pred2\
    \ = (above[2] + 2 * above[3] +\n                             above[4] + 2) >>\
    \ 2;\n       predict[3] = pred3 = (above[3] + 2 * above[4] +\n               \
    \              above[5] + 2) >> 2;\n       predict += stride;\n       predict[0]\
    \ = pred1;\n       predict[1] = pred2;\n       predict[2] = pred3;\n       predict[3]\
    \ = pred4 = (above[4] + 2 * above[5] +\n                             above[6]\
    \ + 2) >> 2;\n       predict += stride;\n       predict[0] = pred2;\n       predict[1]\
    \ = pred3;\n       predict[2] = pred4;\n       predict[3] = pred5 = (above[5]\
    \ + 2 * above[6] +\n                             above[7] + 2) >> 2;\n       predict\
    \ += stride;\n       predict[0] = pred3;\n       predict[1] = pred4;\n       predict[2]\
    \ = pred5;\n       predict[3] = pred6 = (above[6] + 2 * above[7] +\n         \
    \                    above[7] + 2) >> 2;\n   }\n   static void\n   predict_rd_4x4(unsigned\
    \ char *predict,\n                  int            stride)\n   {\n       unsigned\
    \ char *left = predict - 1;\n       unsigned char *above = predict - stride;\n\
    \       int            pred0, pred1, pred2, pred3, pred4, pred5, pred6;\n    \
    \   predict[0] = pred0 =\n           (left[ 0] + 2 * above[-1] + above[0] + 2)\
    \ >> 2;\n       predict[1] = pred1 =\n           (above[-1] + 2 * above[ 0] +\
    \ above[1] + 2) >> 2;\n       predict[2] = pred2 =\n           (above[ 0] + 2\
    \ * above[ 1] + above[2] + 2) >> 2;\n       predict[3] = pred3 =\n           (above[\
    \ 1] + 2 * above[ 2] + above[3] + 2) >> 2;\n       predict += stride;\n      \
    \ predict[0] = pred4 =\n           (left[stride] + 2 * left[0] + above[-1] + 2)\
    \ >> 2;\n       predict[1] = pred0;\n       predict[2] = pred1;\n       predict[3]\
    \ = pred2;\n       predict += stride;\n       predict[0] = pred5 =\n         \
    \  (left[stride*2] + 2 * left[stride] + left[0] + 2) >> 2;\n       predict[1]\
    \ = pred4;\n       predict[2] = pred0;\n       predict[3] = pred1;\n       predict\
    \ += stride;\n       predict[0] = pred6 = (left[stride*3] + 2 * left[stride*2]\
    \ +\n                             left[stride] + 2) >> 2;\n       predict[1] =\
    \ pred5;\n       predict[2] = pred4;\n       predict[3] = pred0;\n   }\n   static\
    \ void\n   predict_vr_4x4(unsigned char *predict,\n                  int     \
    \       stride)\n   {\n       unsigned char *left = predict - 1;\n       unsigned\
    \ char *above = predict - stride;\n       int            pred0, pred1, pred2,\
    \ pred3, pred4, pred5, pred6,\n                      pred7, pred8, pred9;\n  \
    \     predict[0] = pred0 = (above[-1] + above[0] + 1) >> 1;\n       predict[1]\
    \ = pred1 = (above[ 0] + above[1] + 1) >> 1;\n       predict[2] = pred2 = (above[\
    \ 1] + above[2] + 1) >> 1;\n       predict[3] = pred3 = (above[ 2] + above[3]\
    \ + 1) >> 1;\n       predict += stride;\n       predict[0] = pred4 = (left[ 0]\
    \ + 2 * above[-1] +\n                             above[0] + 2) >> 2;\n      \
    \ predict[1] = pred5 = (above[-1] + 2 * above[ 0] +\n                        \
    \     above[1] + 2) >> 2;\n       predict[2] = pred6 = (above[ 0] + 2 * above[\
    \ 1] +\n                             above[2] + 2) >> 2;\n       predict[3] =\
    \ pred7 = (above[ 1] + 2 * above[ 2] +\n                             above[3]\
    \ + 2) >> 2;\n       predict += stride;\n       predict[0] = pred8 =\n       \
    \    (left[stride] + 2 * left[0] + above[-1] + 2) >> 2;\n       predict[1] = pred0;\n\
    \       predict[2] = pred1;\n       predict[3] = pred2;\n       predict += stride;\n\
    \       predict[0] = pred9 =\n           (left[stride*2] + 2 * left[stride] +\
    \ left[0] + 2) >> 2;\n       predict[1] = pred4;\n       predict[2] = pred5;\n\
    \       predict[3] = pred6;\n   }\n   static void\n   predict_vl_4x4(unsigned\
    \ char *predict,\n                  int            stride)\n   {\n       unsigned\
    \ char *above = predict - stride;\n       int            pred0, pred1, pred2,\
    \ pred3, pred4, pred5, pred6,\n                      pred7, pred8, pred9;\n  \
    \     predict[0] = pred0 = (above[0] + above[1] + 1) >> 1;\n       predict[1]\
    \ = pred1 = (above[1] + above[2] + 1) >> 1;\n       predict[2] = pred2 = (above[2]\
    \ + above[3] + 1) >> 1;\n       predict[3] = pred3 = (above[3] + above[4] + 1)\
    \ >> 1;\n       predict += stride;\n       predict[0] = pred4 = (above[0] + 2\
    \ * above[1] +\n                             above[2] + 2) >> 2;\n       predict[1]\
    \ = pred5 = (above[1] + 2 * above[2] +\n                             above[3]\
    \ + 2) >> 2;\n       predict[2] = pred6 = (above[2] + 2 * above[3] +\n       \
    \                      above[4] + 2) >> 2;\n       predict[3] = pred7 = (above[3]\
    \ + 2 * above[4] +\n                             above[5] + 2) >> 2;\n       predict\
    \ += stride;\n       predict[0] = pred1;\n       predict[1] = pred2;\n       predict[2]\
    \ = pred3;\n       predict[3] = pred8 = (above[4] + 2 * above[5] +\n         \
    \                    above[6] + 2) >> 2;\n       predict += stride;\n       predict[0]\
    \ = pred5;\n       predict[1] = pred6;\n       predict[2] = pred7;\n       predict[3]\
    \ = pred9 = (above[5] + 2 * above[6] +\n                             above[7]\
    \ + 2) >> 2;\n   }\n   static void\n   predict_hd_4x4(unsigned char *predict,\n\
    \                  int            stride)\n   {\n       unsigned char *left =\
    \ predict - 1;\n       unsigned char *above = predict - stride;\n       int  \
    \          pred0, pred1, pred2, pred3, pred4, pred5, pred6,\n                \
    \      pred7, pred8, pred9;\n       predict[0] = pred0 = (left[ 0] + above[-1]\
    \ + 1) >> 1;\n       predict[1] = pred1 = (left[ 0] + 2 * above[-1] +\n      \
    \                       above[0] + 2) >> 2;\n       predict[2] = pred2 = (above[-1]\
    \ + 2 * above[ 0] +\n                             above[1] + 2) >> 2;\n      \
    \ predict[3] = pred3 = (above[ 0] + 2 * above[ 1] +\n                        \
    \     above[2] + 2) >> 2;\n       predict += stride;\n       predict[0] = pred4\
    \ = (left[stride] + left[0] + 1) >> 1;\n       predict[1] = pred5 = (left[stride]\
    \ + 2 * left[0] +\n                             above[-1] + 2) >> 2;\n       predict[2]\
    \ = pred0;\n       predict[3] = pred1;\n       predict += stride;\n       predict[0]\
    \ = pred6 = (left[stride*2] + left[stride] + 1) >> 1;\n       predict[1] = pred7\
    \ = (left[stride*2] + 2 * left[stride] +\n                             left[0]\
    \ + 2) >> 2;\n       predict[2] = pred4;\n       predict[3] = pred5;\n       predict\
    \ += stride;\n       predict[0] = pred8 = (left[stride*3] + left[stride*2] + 1)\
    \ >> 1;\n       predict[1] = pred9 = (left[stride*3] + 2 * left[stride*2] +\n\
    \                             left[stride] + 2) >> 2;\n       predict[2] = pred6;\n\
    \       predict[3] = pred7;\n   }\n   static void\n   predict_hu_4x4(unsigned\
    \ char *predict,\n                  int            stride)\n   {\n       unsigned\
    \ char *left = predict - 1;\n       int            pred0, pred1, pred2, pred3,\
    \ pred4, pred5, pred6;\n       predict[0] = pred0 = (left[stride*0] +\n      \
    \                       left[stride*1] + 1) >> 1;\n       predict[1] = pred1 =\
    \ (left[stride*0] + 2 * left[stride*1] +\n                             left[stride*2]\
    \ + 2) >> 2;\n       predict[2] = pred2 = (left[stride*1] + left[stride*2] + 1)\
    \ >> 1;\n       predict[3] = pred3 = (left[stride*1] + 2 * left[stride*2] +\n\
    \                             left[stride*3] + 2) >> 2;\n       predict += stride;\n\
    \       predict[0] = pred2;\n       predict[1] = pred3;\n       predict[2] = pred4\
    \ = (left[stride*2] + left[stride*3] + 1) >> 1;\n       predict[3] = pred5 = (left[stride*2]\
    \ + 2 * left[stride*3] +\n                             left[stride*3] + 2) >>\
    \ 2;\n       predict += stride;\n       predict[0] = pred4;\n       predict[1]\
    \ = pred5;\n       predict[2] = pred6 = left[stride*3];\n       predict[3] = pred6;\n\
    \       predict += stride;\n       predict[0] = pred6;\n       predict[1] = pred6;\n\
    \       predict[2] = pred6;\n       predict[3] = pred6;\n   }\n   static void\n\
    \   predict_h_16x16(unsigned char *predict, int stride)\n   {\n       predict_h_nxn(predict,\
    \ stride, 16);\n   }\n   static void\n   predict_v_16x16(unsigned char *predict,\
    \ int stride)\n   {\n       predict_v_nxn(predict, stride, 16);\n   }\n   static\
    \ void\n   predict_tm_16x16(unsigned char *predict, int stride)\n   {\n      \
    \ predict_tm_nxn(predict, stride, 16);\n   }\n   static void\n   predict_h_8x8(unsigned\
    \ char *predict, int stride)\n   {\n       predict_h_nxn(predict, stride, 8);\n\
    \   }\n   static void\n   predict_v_8x8(unsigned char *predict, int stride)\n\
    \   {\n       predict_v_nxn(predict, stride, 8);\n   }\n   static void\n   predict_tm_8x8(unsigned\
    \ char *predict, int stride)\n   {\n       predict_tm_nxn(predict, stride, 8);\n\
    \   }\n   static void\n   predict_tm_4x4(unsigned char *predict, int stride)\n\
    \   {\n       predict_tm_nxn(predict, stride, 4);\n   }\n   static void\n   copy_down(unsigned\
    \ char           *recon,\n             int                      stride)\n   {\n\
    \       /* Copy the four pixels above-right of subblock 3 to\n        * above-right\
    \ of subblocks 7, 11, and 15\n        */\n       uint32_t tmp, *copy = (void *)(recon\
    \ + 16 - stride);\n       stride = stride / sizeof(unsigned int);\n       tmp\
    \ = *copy;\n       copy += stride * 4;\n       *copy = tmp;\n       copy += stride\
    \ * 4;\n       *copy = tmp;\n       copy += stride * 4;\n       *copy = tmp;\n\
    \   }\n   static void\n   b_pred(unsigned char  *predict,\n          int     \
    \        stride,\n          struct mb_info *mbi,\n          short          *coeffs)\n\
    \   {\n       int i;\n       copy_down(predict, stride);\n       for (i = 0; i\
    \ < 16; i++)\n       {\n           unsigned char *b_predict = predict + (i & 3)\
    \ * 4;\n           switch (mbi->split.modes[i])\n           {\n           case\
    \ B_DC_PRED:\n               predict_dc_nxn(b_predict, stride, 4);\n         \
    \      break;\n           case B_TM_PRED:\n               predict_tm_4x4(b_predict,\
    \ stride);\n               break;\n           case B_VE_PRED:\n              \
    \ predict_ve_4x4(b_predict, stride);\n               break;\n           case B_HE_PRED:\n\
    \               predict_he_4x4(b_predict, stride);\n               break;\n  \
    \         case B_LD_PRED:\n               predict_ld_4x4(b_predict, stride);\n\
    \               break;\n           case B_RD_PRED:\n               predict_rd_4x4(b_predict,\
    \ stride);\n               break;\n           case B_VR_PRED:\n              \
    \ predict_vr_4x4(b_predict, stride);\n               break;\n           case B_VL_PRED:\n\
    \               predict_vl_4x4(b_predict, stride);\n               break;\n  \
    \         case B_HD_PRED:\n               predict_hd_4x4(b_predict, stride);\n\
    \               break;\n           case B_HU_PRED:\n               predict_hu_4x4(b_predict,\
    \ stride);\n               break;\n           default:\n               assert(0);\n\
    \           }\n           vp8_dixie_idct_add(b_predict, b_predict, stride, coeffs);\n\
    \           coeffs += 16;\n           if ((i & 3) == 3)\n           {\n      \
    \         predict += stride * 4;\n           }\n       }\n   }\n   static void\n\
    \   fixup_dc_coeffs(struct mb_info *mbi,\n                   short          *coeffs)\n\
    \   {\n       short y2[16];\n       int   i;\n       vp8_dixie_walsh(coeffs +\
    \ 24 * 16, y2);\n       for (i = 0; i < 16; i++)\n           coeffs[i*16] = y2[i];\n\
    \   }\n   static void\n   predict_intra_luma(unsigned char   *predict,\n     \
    \                 int              stride,\n                      struct mb_info\
    \  *mbi,\n                      short           *coeffs)\n   {\n       if (mbi->base.y_mode\
    \ == B_PRED)\n           b_pred(predict, stride, mbi, coeffs);\n       else\n\
    \       {\n           int i;\n           switch (mbi->base.y_mode)\n         \
    \  {\n           case DC_PRED:\n               predict_dc_nxn(predict, stride,\
    \ 16);\n               break;\n           case V_PRED:\n               predict_v_16x16(predict,\
    \ stride);\n               break;\n           case H_PRED:\n               predict_h_16x16(predict,\
    \ stride);\n               break;\n           case TM_PRED:\n               predict_tm_16x16(predict,\
    \ stride);\n               break;\n           default:\n               assert(0);\n\
    \           }\n           fixup_dc_coeffs(mbi, coeffs);\n           for (i = 0;\
    \ i < 16; i++)\n           {\n               vp8_dixie_idct_add(predict, predict,\
    \ stride, coeffs);\n               coeffs += 16;\n               predict += 4;\n\
    \               if ((i & 3) == 3)\n                   predict += stride * 4 -\
    \ 16;\n           }\n       }\n   }\n   static void\n   predict_intra_chroma(unsigned\
    \ char   *predict_u,\n                        unsigned char   *predict_v,\n  \
    \                      int              stride,\n                        struct\
    \ mb_info  *mbi,\n                        short           *coeffs)\n   {\n   \
    \    int i;\n       switch (mbi->base.uv_mode)\n       {\n       case DC_PRED:\n\
    \           predict_dc_nxn(predict_u, stride, 8);\n           predict_dc_nxn(predict_v,\
    \ stride, 8);\n           break;\n       case V_PRED:\n           predict_v_8x8(predict_u,\
    \ stride);\n           predict_v_8x8(predict_v, stride);\n           break;\n\
    \       case H_PRED:\n           predict_h_8x8(predict_u, stride);\n         \
    \  predict_h_8x8(predict_v, stride);\n           break;\n       case TM_PRED:\n\
    \           predict_tm_8x8(predict_u, stride);\n           predict_tm_8x8(predict_v,\
    \ stride);\n           break;\n       default:\n           assert(0);\n      \
    \ }\n       coeffs += 16 * 16;\n       for (i = 16; i < 20; i++)\n       {\n \
    \          vp8_dixie_idct_add(predict_u, predict_u, stride, coeffs);\n       \
    \    coeffs += 16;\n           predict_u += 4;\n           if (i & 1)\n      \
    \         predict_u += stride * 4 - 8;\n       }\n       for (i = 20; i < 24;\
    \ i++)\n       {\n           vp8_dixie_idct_add(predict_v, predict_v, stride,\
    \ coeffs);\n           coeffs += 16;\n           predict_v += 4;\n           if\
    \ (i & 1)\n               predict_v += stride * 4 - 8;\n       }\n   }\n   static\
    \ void\n   sixtap_horiz(unsigned char       *output,\n                int    \
    \              output_stride,\n                const unsigned char *reference,\n\
    \                int                  reference_stride,\n                int \
    \                 cols,\n                int                  rows,\n        \
    \        const filter_t       filter\n               )\n   {\n       int r, c,\
    \ temp;\n       for (r = 0; r < rows; r++)\n       {\n           for (c = 0; c\
    \ < cols; c++)\n           {\n               temp = (reference[-2] * filter[0])\
    \ +\n                      (reference[-1] * filter[1]) +\n                   \
    \   (reference[ 0] * filter[2]) +\n                      (reference[ 1] * filter[3])\
    \ +\n                      (reference[ 2] * filter[4]) +\n                   \
    \   (reference[ 3] * filter[5]) +\n                      64;\n               temp\
    \ >>= 7;\n               output[c] = CLAMP_255(temp);\n               reference++;\n\
    \           }\n           reference += reference_stride - cols;\n           output\
    \ += output_stride;\n       }\n   }\n   static void\n   sixtap_vert(unsigned char\
    \       *output,\n               int                  output_stride,\n       \
    \        const unsigned char *reference,\n               int                 \
    \ reference_stride,\n               int                  cols,\n             \
    \  int                  rows,\n               const filter_t       filter\n  \
    \            )\n   {\n       int r, c, temp;\n       for (r = 0; r < rows; r++)\n\
    \       {\n           for (c = 0; c < cols; c++)\n           {\n             \
    \  temp = (reference[-2*reference_stride] * filter[0]) +\n                   \
    \   (reference[-1*reference_stride] * filter[1]) +\n                      (reference[\
    \ 0*reference_stride] * filter[2]) +\n                      (reference[ 1*reference_stride]\
    \ * filter[3]) +\n                      (reference[ 2*reference_stride] * filter[4])\
    \ +\n                      (reference[ 3*reference_stride] * filter[5]) +\n  \
    \                    64;\n               temp >>= 7;\n               output[c]\
    \ = CLAMP_255(temp);\n               reference++;\n           }\n           reference\
    \ += reference_stride - cols;\n           output += output_stride;\n       }\n\
    \   }\n   static void\n   sixtap_2d(unsigned char       *output,\n           \
    \  int                  output_stride,\n             const unsigned char *reference,\n\
    \             int                  reference_stride,\n             int       \
    \           cols,\n             int                  rows,\n             int \
    \                 mx,\n             int                  my,\n             const\
    \ filter_t       filters[8]\n            )\n   {\n       DECLARE_ALIGNED(16, unsigned\
    \ char, temp[16*(16+5)]);\n       sixtap_horiz(temp, 16,\n                   \
    \ reference - 2 * reference_stride, reference_stride,\n                    cols,\
    \ rows + 5, filters[mx]);\n       sixtap_vert(output, output_stride,\n       \
    \            temp + 2 * 16, 16,\n                   cols, rows, filters[my]);\n\
    \   }\n   struct img_index\n   {\n       unsigned char *y, *u, *v;\n       int\
    \            stride, uv_stride;\n   };\n   static const unsigned char *\n   filter_block(unsigned\
    \ char        *output,\n                const unsigned char  *reference,\n   \
    \             int                   stride,\n                const union mv  \
    \     *mv,\n                const filter_t        filters[8])\n   {\n       int\
    \ mx, my;\n       /* Handle 0,0 as a special case.  TODO: Does this make it any\n\
    \        * faster?\n        */\n       if (!mv->raw)\n           return reference;\n\
    \       mx = mv->d.x & 7;\n       my = mv->d.y & 7;\n       reference += ((mv->d.y\
    \ >> 3) * stride) + (mv->d.x >> 3);\n       if (mx | my)\n       {\n         \
    \  sixtap_2d(output, stride, reference, stride, 4, 4, mx, my,\n              \
    \       filters);\n           reference = output;\n       }\n       return reference;\n\
    \   }\n   static void\n   recon_1_block(unsigned char        *output,\n      \
    \           const unsigned char  *reference,\n                 int           \
    \        stride,\n                 const union mv       *mv,\n               \
    \  const filter_t        filters[8],\n                 short                *coeffs,\n\
    \                 struct mb_info       *mbi,\n                 int           \
    \        b\n                )\n   {\n       const unsigned char *predict;\n  \
    \     predict = filter_block(output, reference, stride, mv, filters);\n      \
    \ vp8_dixie_idct_add(output, predict, stride, coeffs + 16 * b);\n   }\n   static\
    \ mv_t\n   calculate_chroma_splitmv(struct mb_info *mbi,\n                   \
    \         int             b,\n                            int             full_pixel)\n\
    \   {\n       int temp;\n       union mv mv;\n       temp = mbi->split.mvs[b].d.x\
    \ +\n              mbi->split.mvs[b+1].d.x +\n              mbi->split.mvs[b+4].d.x\
    \ +\n              mbi->split.mvs[b+5].d.x;\n       if (temp < 0)\n          \
    \ temp -= 4;\n       else\n           temp += 4;\n       mv.d.x = temp / 8;\n\
    \       temp = mbi->split.mvs[b].d.y +\n              mbi->split.mvs[b+1].d.y\
    \ +\n              mbi->split.mvs[b+4].d.y +\n              mbi->split.mvs[b+5].d.y;\n\
    \       if (temp < 0)\n           temp -= 4;\n       else\n           temp +=\
    \ 4;\n       mv.d.y = temp / 8;\n       if (full_pixel)\n       {\n          \
    \ mv.d.x &= ~7;\n           mv.d.y &= ~7;\n       }\n       return mv;\n   }\n\
    \   /* Note: We rely on the reconstructed border having the same stride\n    *\
    \ as the reference buffer because the filter_block can't adjust the\n    * stride\
    \ with its return value, only the reference pointer.\n    */\n   static void\n\
    \   build_mc_border(unsigned char       *dst,\n                   const unsigned\
    \ char *src,\n                   int                  stride,\n              \
    \     int                  x,\n                   int                  y,\n  \
    \                 int                  b_w,\n                   int          \
    \        b_h,\n                   int                  w,\n                  \
    \ int                  h\n                  )\n   {\n       const unsigned char\
    \ *ref_row;\n       /* Get a pointer to the start of the real data for this row\
    \ */\n       ref_row = src - x - y * stride;\n       if (y >= h)\n           ref_row\
    \ += (h - 1) * stride;\n       else if (y > 0)\n           ref_row += y * stride;\n\
    \       do\n       {\n           int left, right = 0, copy;\n           left =\
    \ x < 0 ? -x : 0;\n           if (left > b_w)\n               left = b_w;\n  \
    \         if (x + b_w > w)\n               right = x + b_w - w;\n           if\
    \ (right > b_w)\n               right = b_w;\n           copy = b_w - left - right;\n\
    \           if (left)\n               memset(dst, ref_row[0], left);\n       \
    \    if (copy)\n               memcpy(dst + left, ref_row + x + left, copy);\n\
    \           if (right)\n               memset(dst + left + copy, ref_row[w-1],\
    \ right);\n           dst += stride;\n           y++;\n           if (y < h &&\
    \ y > 0)\n               ref_row += stride;\n       }\n       while (--b_h);\n\
    \   }\n   static void\n   recon_1_edge_block(unsigned char        *output,\n \
    \                     unsigned char        *emul_block,\n                    \
    \  const unsigned char  *reference,\n                      int               \
    \    stride,\n                      const union mv       *mv,\n              \
    \        const filter_t        filters[8],\n                      short      \
    \          *coeffs,\n                      struct mb_info       *mbi,\n      \
    \                int                   x,\n                      int         \
    \          y,\n                      int                   w,\n              \
    \        int                   h,\n                      int                 \
    \  start_b\n                     )\n   {\n       const unsigned char *predict;\n\
    \       int                  b = start_b;\n       const int            b_w = 4;\n\
    \       const int            b_h = 4;\n       x += mv->d.x >> 3;\n       y +=\
    \ mv->d.y >> 3;\n       /* Need two pixels left/above, 3 right/below for 6-tap\
    \ */\n       if (x < 2 || x + b_w - 1 + 3 >= w || y < 2 ||\n           y + b_h\
    \ - 1 + 3 >= h)\n       {\n           reference += (mv->d.x >> 3) + (mv->d.y >>\
    \ 3) * stride;\n           build_mc_border(emul_block,\n                     \
    \      reference - 2 - 2 * stride, stride,\n                           x - 2,\
    \ y - 2, b_w + 5, b_h + 5, w, h);\n           reference = emul_block + 2 * stride\
    \ + 2;\n           reference -= (mv->d.x >> 3) + (mv->d.y >> 3) * stride;\n  \
    \     }\n       predict = filter_block(output, reference, stride, mv, filters);\n\
    \       vp8_dixie_idct_add(output, predict, stride, coeffs + 16 * b);\n   }\n\
    \   static void\n   predict_inter_emulated_edge(struct vp8_decoder_ctx  *ctx,\n\
    \                               struct img_index        *img,\n              \
    \                 short                   *coeffs,\n                         \
    \      struct mb_info          *mbi,\n                               int     \
    \                 mb_col,\n                               int                \
    \      mb_row)\n   {\n       /* TODO: Move this into its own buffer.  This only\
    \ works because\n        * we still have a border allocated.\n        */\n   \
    \    unsigned char *emul_block = ctx->frame_strg[0].img.img_data;\n       unsigned\
    \ char *reference;\n       unsigned char *output;\n       ptrdiff_t      reference_offset;\n\
    \       int            w, h, x, y, b;\n       union mv       chroma_mv[4];\n \
    \      unsigned char *u = img->u, *v = img->v;\n       int            full_pixel\
    \ = ctx->frame_hdr.version == 3;\n       x = mb_col * 16;\n       y = mb_row *\
    \ 16;\n       w = ctx->mb_cols * 16;\n       h = ctx->mb_rows * 16;\n       output\
    \ = img->y;\n       reference_offset = ctx->ref_frame_offsets[mbi->base.ref_frame];\n\
    \       reference = output + reference_offset;\n       if (mbi->base.y_mode !=\
    \ SPLITMV)\n       {\n           union mv uvmv;\n           uvmv = mbi->base.mv;\n\
    \           uvmv.d.x = (uvmv.d.x + 1 + (uvmv.d.x >> 31) * 2) / 2;\n          \
    \ uvmv.d.y = (uvmv.d.y + 1 + (uvmv.d.y >> 31) * 2) / 2;\n           if (full_pixel)\n\
    \           {\n               uvmv.d.x &= ~7;\n               uvmv.d.y &= ~7;\n\
    \           }\n           chroma_mv[0] = uvmv;\n           chroma_mv[1] = uvmv;\n\
    \           chroma_mv[2] = uvmv;\n           chroma_mv[3] = uvmv;\n       }\n\
    \       else\n       {\n           chroma_mv[0] = calculate_chroma_splitmv(mbi,\
    \  0, full_pixel);\n           chroma_mv[1] = calculate_chroma_splitmv(mbi,  2,\
    \ full_pixel);\n           chroma_mv[2] = calculate_chroma_splitmv(mbi,  8, full_pixel);\n\
    \           chroma_mv[3] = calculate_chroma_splitmv(mbi, 10, full_pixel);\n  \
    \     }\n       /* Luma */\n       for (b = 0; b < 16; b++)\n       {\n      \
    \     union mv *ymv;\n           if (mbi->base.y_mode != SPLITMV)\n          \
    \     ymv = &mbi->base.mv;\n           else\n               ymv = mbi->split.mvs\
    \ + b;\n           recon_1_edge_block(output, emul_block, reference,\n       \
    \        img->stride, ymv, ctx->subpixel_filters, coeffs,\n               mbi,\
    \ x, y, w, h, b);\n           x += 4;\n           output += 4;\n           reference\
    \ += 4;\n           if ((b & 3) == 3)\n           {\n               x -= 16;\n\
    \               y += 4;\n               output += 4 * img->stride - 16;\n    \
    \           reference += 4 * img->stride - 16;\n           }\n       }\n     \
    \  x = mb_col * 16;\n       y = mb_row * 16;\n       /* Chroma */\n       x >>=\
    \ 1;\n       y >>= 1;\n       w >>= 1;\n       h >>= 1;\n       for (b = 0; b\
    \ < 4; b++)\n       {\n           recon_1_edge_block(u, emul_block, u + reference_offset,\n\
    \                              img->uv_stride,\n                             \
    \ &chroma_mv[b], ctx->subpixel_filters,\n                              coeffs,\
    \ mbi, x, y, w, h, b + 16);\n           recon_1_edge_block(v, emul_block, v +\
    \ reference_offset,\n                              img->uv_stride,\n         \
    \                     &chroma_mv[b], ctx->subpixel_filters,\n                \
    \              coeffs, mbi, x, y, w, h, b + 20);\n           u += 4;\n       \
    \    v += 4;\n           x += 4;\n           if (b & 1)\n           {\n      \
    \         x -= 8;\n               y += 4;\n               u += 4 * img->uv_stride\
    \ - 8;\n               v += 4 * img->uv_stride - 8;\n           }\n       }\n\
    \   }\n   static void\n   predict_inter(struct vp8_decoder_ctx  *ctx,\n      \
    \           struct img_index        *img,\n                 short            \
    \       *coeffs,\n                 struct mb_info          *mbi)\n   {\n     \
    \  unsigned char *y = img->y;\n       unsigned char *u = img->u;\n       unsigned\
    \ char *v = img->v;\n       ptrdiff_t      reference_offset;\n       union mv\
    \       chroma_mv[4];\n       int            full_pixel = ctx->frame_hdr.version\
    \ == 3;\n       int b;\n       if (mbi->base.y_mode != SPLITMV)\n       {\n  \
    \         union mv             uvmv;\n           uvmv = mbi->base.mv;\n      \
    \     uvmv.d.x = (uvmv.d.x + 1 + (uvmv.d.x >> 31) * 2) / 2;\n           uvmv.d.y\
    \ = (uvmv.d.y + 1 + (uvmv.d.y >> 31) * 2) / 2;\n           if (full_pixel)\n \
    \          {\n               uvmv.d.x &= ~7;\n               uvmv.d.y &= ~7;\n\
    \           }\n           chroma_mv[0] =\n               chroma_mv[1] =\n    \
    \               chroma_mv[2] =\n                       chroma_mv[3] = uvmv;\n\
    \       }\n       else\n       {\n           chroma_mv[0] = calculate_chroma_splitmv(mbi,\
    \  0, full_pixel);\n           chroma_mv[1] = calculate_chroma_splitmv(mbi,  2,\
    \ full_pixel);\n           chroma_mv[2] = calculate_chroma_splitmv(mbi,  8, full_pixel);\n\
    \           chroma_mv[3] = calculate_chroma_splitmv(mbi, 10, full_pixel);\n  \
    \     }\n       reference_offset = ctx->ref_frame_offsets[mbi->base.ref_frame];\n\
    \       for (b = 0; b < 16; b++)\n       {\n           union mv *ymv;\n      \
    \     if (mbi->base.y_mode != SPLITMV)\n               ymv = &mbi->base.mv;\n\
    \           else\n               ymv = mbi->split.mvs + b;\n           recon_1_block(y,\
    \ y + reference_offset, img->stride,\n                         ymv, ctx->subpixel_filters,\
    \ coeffs, mbi, b);\n           y += 4;\n           if ((b & 3) == 3)\n       \
    \        y += 4 * img->stride - 16;\n       }\n       for (b = 0; b < 4; b++)\n\
    \       {\n           recon_1_block(u, u + reference_offset,\n               \
    \          img->uv_stride, &chroma_mv[b],\n                         ctx->subpixel_filters,\
    \ coeffs, mbi, b + 16);\n           recon_1_block(v, v + reference_offset,\n \
    \                        img->uv_stride, &chroma_mv[b],\n                    \
    \     ctx->subpixel_filters, coeffs, mbi, b + 20);\n           u += 4;\n     \
    \      v += 4;\n           if (b & 1)\n           {\n               u += 4 * img->uv_stride\
    \ - 8;\n               v += 4 * img->uv_stride - 8;\n           }\n       }\n\
    \   }\n   void\n   vp8_dixie_release_ref_frame(struct ref_cnt_img *rcimg)\n  \
    \ {\n       if (rcimg)\n       {\n           assert(rcimg->ref_cnt);\n       \
    \    rcimg->ref_cnt--;\n       }\n   }\n   struct ref_cnt_img *\n   vp8_dixie_ref_frame(struct\
    \ ref_cnt_img *rcimg)\n   {\n       rcimg->ref_cnt++;\n       return rcimg;\n\
    \   }\n   struct ref_cnt_img *\n   vp8_dixie_find_free_ref_frame(struct ref_cnt_img\
    \ *frames)\n   {\n       int i;\n       for (i = 0; i < NUM_REF_FRAMES; i++)\n\
    \           if (frames[i].ref_cnt == 0)\n           {\n               frames[i].ref_cnt\
    \ = 1;\n               return &frames[i];\n           }\n       assert(0);\n \
    \      return NULL;\n   }\n   static void\n   fixup_left(unsigned char       \
    \ *predict,\n              int                   width,\n              int   \
    \                stride,\n              unsigned int          row,\n         \
    \     enum prediction_mode  mode)\n   {\n       /* The left column of out-of-frame\
    \ pixels is taken to be 129,\n        * unless we're doing DC_PRED, in which case\
    \ we duplicate the\n        * above row, unless this is also row 0, in which case\
    \ we use\n        * 129.\n        */\n       unsigned char *left = predict - 1;\n\
    \       int i;\n       if (mode == DC_PRED && row)\n       {\n           unsigned\
    \ char *above = predict - stride;\n           for (i = 0; i < width; i++)\n  \
    \         {\n               *left = above[i];\n               left += stride;\n\
    \           }\n       }\n       else\n       {\n           /* Need to re-set the\
    \ above row, in case the above MB was\n            * DC_PRED.\n            */\n\
    \           left -= stride;\n           for (i = -1; i < width; i++)\n       \
    \    {\n               *left = 129;\n               left += stride;\n        \
    \   }\n       }\n   }\n   static void\n   fixup_above(unsigned char        *predict,\n\
    \               int                   width,\n               int             \
    \      stride,\n               unsigned int          col,\n               enum\
    \ prediction_mode  mode)\n   {\n       /* The above row of out-of-frame pixels\
    \ is taken to be 127,\n        * unless we're doing DC_PRED, in which case we\
    \ duplicate the\n        * left col, unless this is also col 0, in which case\
    \ we use\n        * 127.\n        */\n       unsigned char *above = predict -\
    \ stride;\n       int i;\n       if (mode == DC_PRED && col)\n       {\n     \
    \      unsigned char *left = predict - 1;\n           for (i = 0; i < width; i++)\n\
    \           {\n               above[i] = *left;\n               left += stride;\n\
    \           }\n       }\n       else\n           /* Need to re-set the left col,\
    \ in case the last MB was\n            * DC_PRED.\n            */\n          \
    \ memset(above - 1, 127, width + 1);\n       memset(above + width, 127, 4); //\
    \ for above-right subblock modes\n   }\n   void\n   vp8_dixie_predict_init(struct\
    \ vp8_decoder_ctx *ctx)\n   {\n       int i;\n       unsigned char *this_frame_base;\n\
    \       if (ctx->frame_hdr.frame_size_updated)\n       {\n           for (i =\
    \ 0; i < NUM_REF_FRAMES; i++)\n           {\n               unsigned int w = ctx->mb_cols\
    \ * 16 + BORDER_PIXELS * 2;\n               unsigned int h = ctx->mb_rows * 16\
    \ + BORDER_PIXELS * 2;\n               vpx_img_free(&ctx->frame_strg[i].img);\n\
    \               ctx->frame_strg[i].ref_cnt = 0;\n               ctx->ref_frames[i]\
    \ = NULL;\n               if (!vpx_img_alloc(&ctx->frame_strg[i].img,\n      \
    \                            IMG_FMT_I420, w, h, 16))\n                   vpx_internal_error(&ctx->error,\
    \ VPX_CODEC_MEM_ERROR,\n                                      \"Failed to allocate\
    \ %dx%d\"\n                                      \" framebuffer\",\n         \
    \                             w, h);\n               vpx_img_set_rect(&ctx->frame_strg[i].img,\
    \ BORDER_PIXELS,\n                   BORDER_PIXELS, ctx->frame_hdr.kf.w,\n   \
    \                ctx->frame_hdr.kf.h);\n           }\n           if (ctx->frame_hdr.version)\n\
    \               ctx->subpixel_filters = bilinear_filters;\n           else\n \
    \              ctx->subpixel_filters = sixtap_filters;\n       }\n       /* Find\
    \ a free framebuffer to predict into */\n       if (ctx->ref_frames[CURRENT_FRAME])\n\
    \           vp8_dixie_release_ref_frame(ctx->ref_frames[CURRENT_FRAME]);\n   \
    \    ctx->ref_frames[CURRENT_FRAME] =\n           vp8_dixie_find_free_ref_frame(ctx->frame_strg);\n\
    \       this_frame_base = ctx->ref_frames[CURRENT_FRAME]->img.img_data;\n    \
    \   /* Calculate offsets to the other reference frames */\n       for (i = 0;\
    \ i < NUM_REF_FRAMES; i++)\n       {\n           struct ref_cnt_img  *ref = ctx->ref_frames[i];\n\
    \           ctx->ref_frame_offsets[i] =\n               ref ? ref->img.img_data\
    \ - this_frame_base : 0;\n       }\n       /* TODO: No need to do this on every\
    \ frame... */\n   }\n   void\n   vp8_dixie_predict_destroy(struct vp8_decoder_ctx\
    \ *ctx)\n   {\n       int i;\n       for (i = 0; i < NUM_REF_FRAMES; i++)\n  \
    \     {\n           vpx_img_free(&ctx->frame_strg[i].img);\n           ctx->frame_strg[i].ref_cnt\
    \ = 0;\n           ctx->ref_frames[i] = NULL;\n       }\n   }\n   void\n   vp8_dixie_predict_process_row(struct\
    \ vp8_decoder_ctx *ctx,\n                                 unsigned int       \
    \     row,\n                                 unsigned int            start_col,\n\
    \                                 unsigned int            num_cols)\n   {\n  \
    \     struct img_index img;\n       struct mb_info *mbi;\n       unsigned int\
    \    col;\n       short          *coeffs;\n       /* Adjust pointers based on\
    \ row, start_col */\n       img.stride =\n           ctx->ref_frames[CURRENT_FRAME]->img.stride[PLANE_Y];\n\
    \       img.uv_stride =\n           ctx->ref_frames[CURRENT_FRAME]->img.stride[PLANE_U];\n\
    \       img.y = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_Y];\n       img.u\
    \ = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_U];\n       img.v = ctx->ref_frames[CURRENT_FRAME]->img.planes[PLANE_V];\n\
    \       img.y += (img.stride * row + start_col) * 16;\n       img.u += (img.uv_stride\
    \ * row + start_col) * 8;\n       img.v += (img.uv_stride * row + start_col) *\
    \ 8;\n       mbi = ctx->mb_info_rows[row] + start_col;\n       coeffs = ctx->tokens[row\
    \ &\n           (ctx->token_hdr.partitions - 1)].coeffs +\n           25 * 16\
    \ * start_col;\n       /* Fix up the out-of-frame pixels */\n       if (start_col\
    \ == 0)\n       {\n           fixup_left(img.y, 16, img.stride, row, mbi->base.y_mode);\n\
    \           fixup_left(img.u, 8, img.uv_stride, row, mbi->base.uv_mode);\n   \
    \        fixup_left(img.v, 8, img.uv_stride, row, mbi->base.uv_mode);\n      \
    \     if (row == 0)\n               *(img.y - img.stride - 1) = 127;\n       }\n\
    \       for (col = start_col; col < start_col + num_cols; col++)\n       {\n \
    \          if (row == 0)\n           {\n               fixup_above(img.y, 16,\
    \ img.stride, col,\n                           mbi->base.y_mode);\n          \
    \     fixup_above(img.u, 8, img.uv_stride, col,\n                           mbi->base.uv_mode);\n\
    \               fixup_above(img.v, 8, img.uv_stride, col,\n                  \
    \         mbi->base.uv_mode);\n           }\n           if (mbi->base.y_mode <=\
    \ B_PRED)\n           {\n               predict_intra_luma(img.y, img.stride,\
    \ mbi, coeffs);\n               predict_intra_chroma(img.u, img.v, img.uv_stride,\
    \ mbi,\n                                    coeffs);\n           }\n         \
    \  else\n           {\n               if (mbi->base.y_mode != SPLITMV) // && !=\
    \ BPRED\n                   fixup_dc_coeffs(mbi, coeffs);\n               if (mbi->base.need_mc_border)\n\
    \                   predict_inter_emulated_edge(ctx, &img, coeffs, mbi,\n    \
    \                                           col, row);\n               else\n\
    \                   predict_inter(ctx, &img, coeffs, mbi);\n           }\n   \
    \        /* Advance to the next macroblock */\n           mbi++;\n           img.y\
    \ += 16;\n           img.u += 8;\n           img.v += 8;\n           coeffs +=\
    \ 25 * 16;\n       }\n       if (col == ctx->mb_cols)\n       {\n           /*\
    \ Extend the last row by four pixels for intra-prediction.\n            * This\
    \ will be propagated later by copy_down.\n            */\n           uint32_t\
    \ *extend = (uint32_t *)(img.y + 15 * img.stride);\n           uint32_t  val =\
    \ 0x01010101 * img.y[-1 + 15 * img.stride];\n           *extend = val;\n     \
    \  }\n   }\n   ---- End code block ----------------------------------------\n"
- title: 20.15.  predict.h
  contents:
  - "20.15.  predict.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef PREDICT_H\n\
    \   #define PREDICT_H\n   void\n   vp8_dixie_predict_init(struct vp8_decoder_ctx\
    \ *ctx);\n   void\n   vp8_dixie_predict_destroy(struct vp8_decoder_ctx *ctx);\n\
    \   void\n   vp8_dixie_predict_process_row(struct vp8_decoder_ctx *ctx,\n    \
    \                             unsigned int            row,\n                 \
    \                unsigned int            start_col,\n                        \
    \         unsigned int            num_cols);\n   void\n   vp8_dixie_release_ref_frame(struct\
    \ ref_cnt_img *rcimg);\n   struct ref_cnt_img *\n   vp8_dixie_ref_frame(struct\
    \ ref_cnt_img *rcimg);\n   struct ref_cnt_img *\n   vp8_dixie_find_free_ref_frame(struct\
    \ ref_cnt_img *frames);\n   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.16.  tokens.c
  contents:
  - "20.16.  tokens.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #include \"vpx_codec_internal.h\"\
    \n   #include \"dixie.h\"\n   #include \"tokens.h\"\n   #include <stdlib.h>\n\
    \   #include <string.h>\n   #include <malloc.h>\n   enum\n   {\n       EOB_CONTEXT_NODE,\n\
    \       ZERO_CONTEXT_NODE,\n       ONE_CONTEXT_NODE,\n       LOW_VAL_CONTEXT_NODE,\n\
    \       TWO_CONTEXT_NODE,\n       THREE_CONTEXT_NODE,\n       HIGH_LOW_CONTEXT_NODE,\n\
    \       CAT_ONE_CONTEXT_NODE,\n       CAT_THREEFOUR_CONTEXT_NODE,\n       CAT_THREE_CONTEXT_NODE,\n\
    \       CAT_FIVE_CONTEXT_NODE\n   };\n   enum\n   {\n       ZERO_TOKEN,\n    \
    \   ONE_TOKEN,\n       TWO_TOKEN,\n       THREE_TOKEN,\n       FOUR_TOKEN,\n \
    \      DCT_VAL_CATEGORY1,\n       DCT_VAL_CATEGORY2,\n       DCT_VAL_CATEGORY3,\n\
    \       DCT_VAL_CATEGORY4,\n       DCT_VAL_CATEGORY5,\n       DCT_VAL_CATEGORY6,\n\
    \       DCT_EOB_TOKEN,\n       MAX_ENTROPY_TOKENS\n   };\n   struct extrabits\n\
    \   {\n       short         min_val;\n       short         length;\n       unsigned\
    \ char probs[12];\n   };\n   static const unsigned int left_context_index[25]\
    \ =\n   {\n       0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,\n       4, 4,\
    \ 5, 5, 6, 6, 7, 7, 8\n   };\n   static const unsigned int above_context_index[25]\
    \ =\n   {\n       0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n       4, 5,\
    \ 4, 5, 6, 7, 6, 7, 8\n   };\n   #define X(n) ((n) * PREV_COEFF_CONTEXTS * ENTROPY_NODES)\n\
    \   static const unsigned int bands_x[16] =\n   {\n       X(0), X(1), X(2), X(3),\
    \ X(6), X(4), X(5), X(6),\n       X(6), X(6), X(6), X(6), X(6), X(6), X(6), X(7)\n\
    \   };\n   #undef X\n   static const struct extrabits extrabits[MAX_ENTROPY_TOKENS]\
    \ =\n   {\n       { 0, -1, {  0,   0,   0,   0,   0,   0,\n                  \
    \ 0,   0,   0,   0,   0,   0 } }, //ZERO_TOKEN\n       { 1, 0,  {  0,   0,   0,\
    \   0,   0,   0,\n                   0,   0,   0,   0,   0,   0 } }, //ONE_TOKEN\n\
    \       { 2, 0,  {  0,   0,   0,   0,   0,   0,\n                   0,   0,  \
    \ 0,   0,   0,   0 } }, //TWO_TOKEN\n       { 3, 0,  {  0,   0,   0,   0,   0,\
    \   0,\n                   0,   0,   0,   0,   0,   0 } }, //THREE_TOKEN\n   \
    \    { 4, 0,  {  0,   0,   0,   0,   0,   0,\n                   0,   0,   0,\
    \   0,   0,   0 } }, //FOUR_TOKEN\n       { 5, 0,  {159,   0,   0,   0,   0, \
    \  0,\n                   0,   0,   0,   0,   0,   0 } }, //DCT_VAL_CATEGORY1\n\
    \       { 7, 1,  {145, 165,   0,   0,   0,   0,\n                   0,   0,  \
    \ 0,   0,   0,   0 } }, //DCT_VAL_CATEGORY2\n       {11, 2,  {140, 148, 173, \
    \  0,   0,   0,\n                   0,   0,   0,   0,   0,   0 } }, //DCT_VAL_CATEGORY3\n\
    \       {19, 3,  {135, 140, 155, 176,   0,   0,\n                   0,   0,  \
    \ 0,   0,   0,   0 } }, //DCT_VAL_CATEGORY4\n       {35, 4,  {130, 134, 141, 157,\
    \ 180,   0,\n                   0,   0,   0,   0,   0,   0 } }, //DCT_VAL_CATEGORY5\n\
    \       {67, 10, {129, 130, 133, 140, 153, 177,\n                 196, 230, 243,\
    \ 254, 254,   0 } }, //DCT_VAL_CATEGORY6\n       { 0, -1, {  0,   0,   0,   0,\
    \   0,   0,\n                   0,   0,   0,   0,   0,   0 } }, // EOB TOKEN\n\
    \   };\n   static const unsigned int zigzag[16] =\n   {\n       0,  1,  4,  8,\
    \  5,  2,  3,  6,  9, 12, 13, 10,  7, 11, 14, 15\n   };\n   #define DECODE_AND_APPLYSIGN(value_to_sign)\
    \ \\\n       v = (bool_get_bit(bool) ? -value_to_sign \\\n                   \
    \            : value_to_sign) * dqf[!!c];\n   #define DECODE_AND_BRANCH_IF_ZERO(probability,branch)\
    \ \\\n       if (!bool_get(bool, probability)) goto branch;\n   #define DECODE_AND_LOOP_IF_ZERO(probability,branch)\
    \ \\\n       if (!bool_get(bool, probability)) \\\n       { \\\n           prob\
    \ = type_probs; \\\n           if (c<15) {\\\n               ++c; \\\n       \
    \        prob += bands_x[c]; \\\n               goto branch; \\\n           }\\\
    \n           else \\\n               goto BLOCK_FINISHED; /* for malformed input\
    \ */\\\n       }\n   #define DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val) \\\n\
    \       DECODE_AND_APPLYSIGN(val) \\\n       prob = type_probs + (ENTROPY_NODES*2);\
    \ \\\n       if (c < 15){\\\n           b_tokens[zigzag[c]] = v; \\\n        \
    \   ++c; \\\n           goto DO_WHILE; }\\\n       b_tokens[zigzag[15]] = v; \\\
    \n       goto BLOCK_FINISHED;\n   #define DECODE_EXTRABIT_AND_ADJUST_VAL(t,bits_count)\\\
    \n       val += bool_get(bool, extrabits[t].probs[bits_count]) << \\\n       bits_count;\n\
    \   static int\n   decode_mb_tokens(struct bool_decoder  *bool,\n            \
    \        token_entropy_ctx_t   left,\n                    token_entropy_ctx_t\
    \   above,\n                    short                *tokens,\n              \
    \      enum prediction_mode  mode,\n                    coeff_probs_table_t  \
    \ probs,\n                    short                 factor[TOKEN_BLOCK_TYPES][2])\n\
    \   {\n       int            i, stop, type;\n       int            c, t, v;\n\
    \       int            val, bits_count;\n       int            eob_mask;\n   \
    \    short         *b_tokens;   // tokens for this block\n       unsigned char\
    \ *type_probs; // probabilities for this block type\n       unsigned char *prob;\n\
    \       short         *dqf;\n       eob_mask = 0;\n       if (mode != B_PRED &&\
    \ mode != SPLITMV)\n       {\n           i = 24;\n           stop = 24;\n    \
    \       type = 1;\n           b_tokens = tokens + 24 * 16;\n           dqf = factor[TOKEN_BLOCK_Y2];\n\
    \       }\n       else\n       {\n           i = 0;\n           stop = 16;\n \
    \          type = 3;\n           b_tokens = tokens;\n           dqf = factor[TOKEN_BLOCK_Y1];\n\
    \       }\n       /* Save a pointer to the coefficient probs for the current type.\n\
    \        * Need to repeat this whenever type changes.\n        */\n       type_probs\
    \ = probs[type][0][0];\n   BLOCK_LOOP:\n       t = left[left_context_index[i]]\
    \ + above[above_context_index[i]];\n       c = !type; /* all blocks start at 0\
    \ except type 0, which starts\n                   * at 1. */\n       prob = type_probs;\n\
    \       prob += t * ENTROPY_NODES;\n   DO_WHILE:\n       prob += bands_x[c];\n\
    \       DECODE_AND_BRANCH_IF_ZERO(prob[EOB_CONTEXT_NODE],\n         BLOCK_FINISHED);\n\
    \   CHECK_0_:\n       DECODE_AND_LOOP_IF_ZERO(prob[ZERO_CONTEXT_NODE], CHECK_0_);\n\
    \       DECODE_AND_BRANCH_IF_ZERO(prob[ONE_CONTEXT_NODE],\n                  \
    \               ONE_CONTEXT_NODE_0_);\n       DECODE_AND_BRANCH_IF_ZERO(prob[LOW_VAL_CONTEXT_NODE],\n\
    \                                 LOW_VAL_CONTEXT_NODE_0_);\n       DECODE_AND_BRANCH_IF_ZERO(prob[HIGH_LOW_CONTEXT_NODE],\n\
    \                                 HIGH_LOW_CONTEXT_NODE_0_);\n       DECODE_AND_BRANCH_IF_ZERO(prob[CAT_THREEFOUR_CONTEXT_NODE],\n\
    \                                 CAT_THREEFOUR_CONTEXT_NODE_0_);\n       DECODE_AND_BRANCH_IF_ZERO(prob[CAT_FIVE_CONTEXT_NODE],\n\
    \                                 CAT_FIVE_CONTEXT_NODE_0_);\n       val = extrabits[DCT_VAL_CATEGORY6].min_val;\n\
    \       bits_count = extrabits[DCT_VAL_CATEGORY6].length;\n       do\n       {\n\
    \           DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY6,\n             bits_count);\n\
    \           bits_count --;\n       }\n       while (bits_count >= 0);\n      \
    \ DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val);\n   CAT_FIVE_CONTEXT_NODE_0_:\n\
    \       val = extrabits[DCT_VAL_CATEGORY5].min_val;\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY5,\
    \ 4);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY5, 3);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY5,\
    \ 2);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY5, 1);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY5,\
    \ 0);\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val);\n   CAT_THREEFOUR_CONTEXT_NODE_0_:\n\
    \       DECODE_AND_BRANCH_IF_ZERO(prob[CAT_THREE_CONTEXT_NODE],\n            \
    \                     CAT_THREE_CONTEXT_NODE_0_);\n       val = extrabits[DCT_VAL_CATEGORY4].min_val;\n\
    \       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY4, 3);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY4,\
    \ 2);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY4, 1);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY4,\
    \ 0);\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val);\n   CAT_THREE_CONTEXT_NODE_0_:\n\
    \       val = extrabits[DCT_VAL_CATEGORY3].min_val;\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY3,\
    \ 2);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY3, 1);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY3,\
    \ 0);\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val);\n   HIGH_LOW_CONTEXT_NODE_0_:\n\
    \       DECODE_AND_BRANCH_IF_ZERO(prob[CAT_ONE_CONTEXT_NODE],\n              \
    \                   CAT_ONE_CONTEXT_NODE_0_);\n       val = extrabits[DCT_VAL_CATEGORY2].min_val;\n\
    \       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY2, 1);\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY2,\
    \ 0);\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val);\n   CAT_ONE_CONTEXT_NODE_0_:\n\
    \       val = extrabits[DCT_VAL_CATEGORY1].min_val;\n       DECODE_EXTRABIT_AND_ADJUST_VAL(DCT_VAL_CATEGORY1,\
    \ 0);\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(val);\n   LOW_VAL_CONTEXT_NODE_0_:\n\
    \       DECODE_AND_BRANCH_IF_ZERO(prob[TWO_CONTEXT_NODE],\n                  \
    \               TWO_CONTEXT_NODE_0_);\n       DECODE_AND_BRANCH_IF_ZERO(prob[THREE_CONTEXT_NODE],\n\
    \                                 THREE_CONTEXT_NODE_0_);\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(4);\n\
    \   THREE_CONTEXT_NODE_0_:\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(3);\n\
    \   TWO_CONTEXT_NODE_0_:\n       DECODE_SIGN_WRITE_COEFF_AND_CHECK_EXIT(2);\n\
    \   ONE_CONTEXT_NODE_0_:\n       DECODE_AND_APPLYSIGN(1);\n       prob = type_probs\
    \ + ENTROPY_NODES;\n       if (c < 15)\n       {\n           b_tokens[zigzag[c]]\
    \ = v;\n           ++c;\n           goto DO_WHILE;\n       }\n       b_tokens[zigzag[15]]\
    \ = v;\n   BLOCK_FINISHED:\n       eob_mask |= (c > 1) << i;\n       t = (c !=\
    \ !type);   // any non-zero data?\n       eob_mask |= t << 31;\n       left[left_context_index[i]]\
    \ = above[above_context_index[i]] = t;\n       b_tokens += 16;\n       i++;\n\
    \       if (i < stop)\n           goto BLOCK_LOOP;\n       if (i == 25)\n    \
    \   {\n           type = 0;\n           i = 0;\n           stop = 16;\n      \
    \     type_probs = probs[type][0][0];\n           b_tokens = tokens;\n       \
    \    dqf = factor[TOKEN_BLOCK_Y1];\n           goto BLOCK_LOOP;\n       }\n  \
    \     if (i == 16)\n       {\n           type = 2;\n           type_probs = probs[type][0][0];\n\
    \           stop = 24;\n           dqf = factor[TOKEN_BLOCK_UV];\n           goto\
    \ BLOCK_LOOP;\n       }\n       return eob_mask;\n   }\n   static void\n   reset_row_context(token_entropy_ctx_t\
    \ *left)\n   {\n       memset(left, 0, sizeof(*left));\n   }\n   static void\n\
    \   reset_above_context(token_entropy_ctx_t *above, unsigned int cols)\n   {\n\
    \       memset(above, 0, cols * sizeof(*above));\n   }\n   static void\n   reset_mb_context(token_entropy_ctx_t\
    \  *left,\n                    token_entropy_ctx_t  *above,\n                \
    \    enum prediction_mode  mode)\n   {\n       /* Reset the macroblock context\
    \ on the left and right.  We have\n        * to preserve the context of the second\
    \ order block if this mode\n        * would not have updated it.\n        */\n\
    \       memset(left, 0, sizeof((*left)[0]) * 8);\n       memset(above, 0, sizeof((*above)[0])\
    \ * 8);\n       if (mode != B_PRED && mode != SPLITMV)\n       {\n           (*left)[8]\
    \ = 0;\n           (*above)[8] = 0;\n       }\n   }\n   void\n   vp8_dixie_tokens_process_row(struct\
    \ vp8_decoder_ctx *ctx,\n                                unsigned int        \
    \    partition,\n                                unsigned int            row,\n\
    \                                unsigned int            start_col,\n        \
    \                        unsigned int            num_cols)\n   {\n       struct\
    \ token_decoder *tokens = &ctx->tokens[partition];\n       short             \
    \ coeffs = tokens->coeffs + 25 * 16 * start_col;\n       unsigned int       col;\n\
    \       token_entropy_ctx_t  *above = ctx->above_token_entropy_ctx\n         \
    \                            + start_col;\n       token_entropy_ctx_t  *left =\
    \ &tokens->left_token_entropy_ctx;\n       struct mb_info       *mbi = ctx->mb_info_rows[row]\
    \ + start_col;\n       if (row == 0)\n           reset_above_context(above, num_cols);\n\
    \       if (start_col == 0)\n           reset_row_context(left);\n       for (col\
    \ = start_col; col < start_col + num_cols; col++)\n       {\n           memset(coeffs,\
    \ 0, 25 * 16 * sizeof(short));\n           if (mbi->base.skip_coeff)\n       \
    \    {\n               reset_mb_context(left, above, mbi->base.y_mode);\n    \
    \           mbi->base.eob_mask = 0;\n           }\n           else\n         \
    \  {\n               struct dequant_factors *dqf;\n               dqf = ctx->dequant_factors\
    \  + mbi->base.segment_id;\n               mbi->base.eob_mask =\n            \
    \       decode_mb_tokens(&tokens->bool,\n                                    *left,\
    \ *above,\n                                    coeffs,\n                     \
    \               mbi->base.y_mode,\n                                    ctx->entropy_hdr.coeff_probs,\n\
    \                                    dqf->factor);\n           }\n           above++;\n\
    \           mbi++;\n           coeffs += 25 * 16;\n       }\n   }\n   void\n \
    \  vp8_dixie_tokens_init(struct vp8_decoder_ctx *ctx)\n   {\n       unsigned int\
    \  partitions = ctx->token_hdr.partitions;\n       if (ctx->frame_hdr.frame_size_updated)\n\
    \       {\n           unsigned int i;\n           unsigned int coeff_row_sz =\n\
    \               ctx->mb_cols * 25 * 16 * sizeof(short);\n           for (i = 0;\
    \ i < partitions; i++)\n           {\n               free(ctx->tokens[i].coeffs);\n\
    \               ctx->tokens[i].coeffs = memalign(16, coeff_row_sz);\n        \
    \       if (!ctx->tokens[i].coeffs)\n                   vpx_internal_error(&ctx->error,\
    \ VPX_CODEC_MEM_ERROR,\n                                      NULL);\n       \
    \    }\n           free(ctx->above_token_entropy_ctx);\n           ctx->above_token_entropy_ctx\
    \ =\n               calloc(ctx->mb_cols,\n               sizeof(*ctx->above_token_entropy_ctx));\n\
    \           if (!ctx->above_token_entropy_ctx)\n               vpx_internal_error(&ctx->error,\n\
    \               VPX_CODEC_MEM_ERROR, NULL);\n       }\n   }\n   void\n   vp8_dixie_tokens_destroy(struct\
    \ vp8_decoder_ctx *ctx)\n   {\n       int i;\n       for (i = 0; i < MAX_PARTITIONS;\
    \ i++)\n           free(ctx->tokens[i].coeffs);\n       free(ctx->above_token_entropy_ctx);\n\
    \   }\n   ---- End code block ----------------------------------------\n"
- title: 20.17.  tokens.h
  contents:
  - "20.17.  tokens.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef TOKENS_H\n\
    \   #define TOKENS_H\n   void\n   vp8_dixie_tokens_init(struct vp8_decoder_ctx\
    \ *ctx);\n   void\n   vp8_dixie_tokens_destroy(struct vp8_decoder_ctx *ctx);\n\
    \   void\n   vp8_dixie_tokens_process_row(struct vp8_decoder_ctx *ctx,\n     \
    \                           unsigned int            partition,\n             \
    \                   unsigned int            row,\n                           \
    \     unsigned int            start_col,\n                                unsigned\
    \ int            num_cols);\n   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.18.  vp8_prob_data.h
  contents:
  - "20.18.  vp8_prob_data.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   static const\n   unsigned\
    \ char k_coeff_entropy_update_probs[BLOCK_TYPES][COEFF_BANDS]\n   [PREV_COEFF_CONTEXTS]\n\
    \   [ENTROPY_NODES] =\n   {\n       {\n           {\n               {255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255},\n               {255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n               {255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n           },\n           {\n         \
    \      {176, 246, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n            \
    \   {223, 241, 252, 255, 255, 255, 255, 255, 255, 255, 255},\n               {249,\
    \ 253, 253, 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n        \
    \   {\n               {255, 244, 252, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \               {234, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n   \
    \            {253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      \
    \     },\n           {\n               {255, 246, 254, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n               {239, 253, 254, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n               {254, 255, 254, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n           },\n           {\n               {255, 248, 254, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n               {251, 255, 254, 255, 255, 255,\
    \ 255, 255, 255, 255, 255},\n               {255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n           },\n           {\n               {255, 253,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255},\n               {251, 254, 254,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n               {254, 255, 254, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n           },\n           {\n         \
    \      {255, 254, 253, 255, 254, 255, 255, 255, 255, 255, 255},\n            \
    \   {250, 255, 254, 255, 254, 255, 255, 255, 255, 255, 255},\n               {254,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n        \
    \   {\n               {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \               {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n   \
    \            {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      \
    \     },\n       },\n       {\n           {\n               {217, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n               {225, 252, 241, 253, 255,\
    \ 255, 254, 255, 255, 255, 255},\n               {234, 250, 241, 250, 253, 255,\
    \ 253, 254, 255, 255, 255},\n           },\n           {\n               {255,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n               {223, 254,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255},\n               {238, 253, 254,\
    \ 254, 255, 255, 255, 255, 255, 255, 255},\n           },\n           {\n    \
    \           {255, 248, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n       \
    \        {249, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n          \
    \     {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n\
    \           {\n               {255, 253, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n               {247, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \               {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n   \
    \        },\n           {\n               {255, 253, 254, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n               {252, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n               {255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n           },\n           {\n               {255, 254, 254, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n               {253, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n               {255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255},\n           },\n           {\n               {255,\
    \ 254, 253, 255, 255, 255, 255, 255, 255, 255, 255},\n               {250, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255},\n               {254, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n           {\n    \
    \           {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n       \
    \        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n          \
    \     {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n\
    \       },\n       {\n           {\n               {186, 251, 250, 255, 255, 255,\
    \ 255, 255, 255, 255, 255},\n               {234, 251, 244, 254, 255, 255, 255,\
    \ 255, 255, 255, 255},\n               {251, 251, 243, 253, 254, 255, 254, 255,\
    \ 255, 255, 255},\n           },\n           {\n               {255, 253, 254,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n               {236, 253, 254, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n               {251, 253, 253, 254, 254,\
    \ 255, 255, 255, 255, 255, 255},\n           },\n           {\n              \
    \ {255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n               {254,\
    \ 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n               {255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n           {\n\
    \               {255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n   \
    \            {254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n      \
    \         {254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n         \
    \  },\n           {\n               {255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n               {254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n               {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \           },\n           {\n               {255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n               {255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n               {255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n           },\n           {\n               {255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n               {255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n               {255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255},\n           },\n           {\n               {255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n               {255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255, 255},\n               {255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n       },\n       {\n\
    \           {\n               {248, 255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n               {250, 254, 252, 254, 255, 255, 255, 255, 255, 255, 255},\n\
    \               {248, 254, 249, 253, 255, 255, 255, 255, 255, 255, 255},\n   \
    \        },\n           {\n               {255, 253, 253, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n               {246, 253, 253, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n               {252, 254, 251, 254, 254, 255, 255, 255, 255,\
    \ 255, 255},\n           },\n           {\n               {255, 254, 252, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n               {248, 254, 253, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n               {253, 255, 254, 254, 255, 255,\
    \ 255, 255, 255, 255, 255},\n           },\n           {\n               {255,\
    \ 251, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n               {245, 251,\
    \ 254, 255, 255, 255, 255, 255, 255, 255, 255},\n               {253, 253, 254,\
    \ 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n           {\n    \
    \           {255, 251, 253, 255, 255, 255, 255, 255, 255, 255, 255},\n       \
    \        {252, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n          \
    \     {255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},\n           },\n\
    \           {\n               {255, 252, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255},\n               {249, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n\
    \               {255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255},\n   \
    \        },\n           {\n               {255, 255, 253, 255, 255, 255, 255,\
    \ 255, 255, 255, 255},\n               {250, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255},\n               {255, 255, 255, 255, 255, 255, 255, 255, 255,\
    \ 255, 255},\n           },\n           {\n               {255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255, 255},\n               {254, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255, 255},\n               {255, 255, 255, 255, 255, 255,\
    \ 255, 255, 255, 255, 255},\n           },\n       },\n   };\n   static const\n\
    \   unsigned char k_default_y_mode_probs        [] =\n   { 112,  86, 140,  37};\n\
    \   static const\n   unsigned char k_default_uv_mode_probs       [] =\n   { 162,\
    \ 101, 204};\n   static const\n   unsigned char k_default_coeff_probs [BLOCK_TYPES][COEFF_BANDS]\n\
    \   [PREV_COEFF_CONTEXTS][ENTROPY_NODES] =\n   {\n       { /* block type 0 */\n\
    \           { /* coeff band 0 */\n               { 128, 128, 128, 128, 128, 128,\
    \ 128, 128, 128, 128, 128},\n               { 128, 128, 128, 128, 128, 128, 128,\
    \ 128, 128, 128, 128},\n               { 128, 128, 128, 128, 128, 128, 128, 128,\
    \ 128, 128, 128}\n           },\n           { /* coeff band 1 */\n           \
    \    { 253, 136, 254, 255, 228, 219, 128, 128, 128, 128, 128},\n             \
    \  { 189, 129, 242, 255, 227, 213, 255, 219, 128, 128, 128},\n               {\
    \ 106, 126, 227, 252, 214, 209, 255, 255, 128, 128, 128}\n           },\n    \
    \       { /* coeff band 2 */\n               {   1,  98, 248, 255, 236, 226, 255,\
    \ 255, 128, 128, 128},\n               { 181, 133, 238, 254, 221, 234, 255, 154,\
    \ 128, 128, 128},\n               {  78, 134, 202, 247, 198, 180, 255, 219, 128,\
    \ 128, 128}\n           },\n           { /* coeff band 3 */\n               {\
    \   1, 185, 249, 255, 243, 255, 128, 128, 128, 128, 128},\n               { 184,\
    \ 150, 247, 255, 236, 224, 128, 128, 128, 128, 128},\n               {  77, 110,\
    \ 216, 255, 236, 230, 128, 128, 128, 128, 128}\n           },\n           { /*\
    \ coeff band 4 */\n               {   1, 101, 251, 255, 241, 255, 128, 128, 128,\
    \ 128, 128},\n               { 170, 139, 241, 252, 236, 209, 255, 255, 128, 128,\
    \ 128},\n               {  37, 116, 196, 243, 228, 255, 255, 255, 128, 128, 128}\n\
    \           },\n           { /* coeff band 5 */\n               {   1, 204, 254,\
    \ 255, 245, 255, 128, 128, 128, 128, 128},\n               { 207, 160, 250, 255,\
    \ 238, 128, 128, 128, 128, 128, 128},\n               { 102, 103, 231, 255, 211,\
    \ 171, 128, 128, 128, 128, 128}\n           },\n           { /* coeff band 6 */\n\
    \               {   1, 152, 252, 255, 240, 255, 128, 128, 128, 128, 128},\n  \
    \             { 177, 135, 243, 255, 234, 225, 128, 128, 128, 128, 128},\n    \
    \           {  80, 129, 211, 255, 194, 224, 128, 128, 128, 128, 128}\n       \
    \    },\n           { /* coeff band 7 */\n               {   1,   1, 255, 128,\
    \ 128, 128, 128, 128, 128, 128, 128},\n               { 246,   1, 255, 128, 128,\
    \ 128, 128, 128, 128, 128, 128},\n               { 255, 128, 128, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n           }\n       },\n       { /* block type 1\
    \ */\n           { /* coeff band 0 */\n               { 198,  35, 237, 223, 193,\
    \ 187, 162, 160, 145, 155,  62},\n               { 131,  45, 198, 221, 172, 176,\
    \ 220, 157, 252, 221,   1},\n               {  68,  47, 146, 208, 149, 167, 221,\
    \ 162, 255, 223, 128}\n           },\n           { /* coeff band 1 */\n      \
    \         {   1, 149, 241, 255, 221, 224, 255, 255, 128, 128, 128},\n        \
    \       { 184, 141, 234, 253, 222, 220, 255, 199, 128, 128, 128},\n          \
    \     {  81,  99, 181, 242, 176, 190, 249, 202, 255, 255, 128}\n           },\n\
    \           { /* coeff band 2 */\n               {   1, 129, 232, 253, 214, 197,\
    \ 242, 196, 255, 255, 128},\n               {  99, 121, 210, 250, 201, 198, 255,\
    \ 202, 128, 128, 128},\n               {  23,  91, 163, 242, 170, 187, 247, 210,\
    \ 255, 255, 128}\n           },\n           { /* coeff band 3 */\n           \
    \    {   1, 200, 246, 255, 234, 255, 128, 128, 128, 128, 128},\n             \
    \  { 109, 178, 241, 255, 231, 245, 255, 255, 128, 128, 128},\n               {\
    \  44, 130, 201, 253, 205, 192, 255, 255, 128, 128, 128}\n           },\n    \
    \       { /* coeff band 4 */\n               {   1, 132, 239, 251, 219, 209, 255,\
    \ 165, 128, 128, 128},\n               {  94, 136, 225, 251, 218, 190, 255, 255,\
    \ 128, 128, 128},\n               {  22, 100, 174, 245, 186, 161, 255, 199, 128,\
    \ 128, 128}\n           },\n           { /* coeff band 5 */\n               {\
    \   1, 182, 249, 255, 232, 235, 128, 128, 128, 128, 128},\n               { 124,\
    \ 143, 241, 255, 227, 234, 128, 128, 128, 128, 128},\n               {  35,  77,\
    \ 181, 251, 193, 211, 255, 205, 128, 128, 128}\n           },\n           { /*\
    \ coeff band 6 */\n               {   1, 157, 247, 255, 236, 231, 255, 255, 128,\
    \ 128, 128},\n               { 121, 141, 235, 255, 225, 227, 255, 255, 128, 128,\
    \ 128},\n               {  45,  99, 188, 251, 195, 217, 255, 224, 128, 128, 128}\n\
    \           },\n           { /* coeff band 7 */\n               {   1,   1, 251,\
    \ 255, 213, 255, 128, 128, 128, 128, 128},\n               { 203,   1, 248, 255,\
    \ 255, 128, 128, 128, 128, 128, 128},\n               { 137,   1, 177, 255, 224,\
    \ 255, 128, 128, 128, 128, 128}\n           }\n       },\n       { /* block type\
    \ 2 */\n           { /* coeff band 0 */\n               { 253,   9, 248, 251,\
    \ 207, 208, 255, 192, 128, 128, 128},\n               { 175,  13, 224, 243, 193,\
    \ 185, 249, 198, 255, 255, 128},\n               {  73,  17, 171, 221, 161, 179,\
    \ 236, 167, 255, 234, 128}\n           },\n           { /* coeff band 1 */\n \
    \              {   1,  95, 247, 253, 212, 183, 255, 255, 128, 128, 128},\n   \
    \            { 239,  90, 244, 250, 211, 209, 255, 255, 128, 128, 128},\n     \
    \          { 155,  77, 195, 248, 188, 195, 255, 255, 128, 128, 128}\n        \
    \   },\n           { /* coeff band 2 */\n               {   1,  24, 239, 251,\
    \ 218, 219, 255, 205, 128, 128, 128},\n               { 201,  51, 219, 255, 196,\
    \ 186, 128, 128, 128, 128, 128},\n               {  69,  46, 190, 239, 201, 218,\
    \ 255, 228, 128, 128, 128}\n           },\n           { /* coeff band 3 */\n \
    \              {   1, 191, 251, 255, 255, 128, 128, 128, 128, 128, 128},\n   \
    \            { 223, 165, 249, 255, 213, 255, 128, 128, 128, 128, 128},\n     \
    \          { 141, 124, 248, 255, 255, 128, 128, 128, 128, 128, 128}\n        \
    \   },\n           { /* coeff band 4 */\n               {   1,  16, 248, 255,\
    \ 255, 128, 128, 128, 128, 128, 128},\n               { 190,  36, 230, 255, 236,\
    \ 255, 128, 128, 128, 128, 128},\n               { 149,   1, 255, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n           },\n           { /* coeff band 5 */\n \
    \              {   1, 226, 255, 128, 128, 128, 128, 128, 128, 128, 128},\n   \
    \            { 247, 192, 255, 128, 128, 128, 128, 128, 128, 128, 128},\n     \
    \          { 240, 128, 255, 128, 128, 128, 128, 128, 128, 128, 128}\n        \
    \   },\n           { /* coeff band 6 */\n               {   1, 134, 252, 255,\
    \ 255, 128, 128, 128, 128, 128, 128},\n               { 213,  62, 250, 255, 255,\
    \ 128, 128, 128, 128, 128, 128},\n               {  55,  93, 255, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n           },\n           { /* coeff band 7 */\n \
    \              { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},\n   \
    \            { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},\n     \
    \          { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128}\n        \
    \   }\n       },\n       { /* block type 3 */\n           { /* coeff band 0 */\n\
    \               { 202,  24, 213, 235, 186, 191, 220, 160, 240, 175, 255},\n  \
    \             { 126,  38, 182, 232, 169, 184, 228, 174, 255, 187, 128},\n    \
    \           {  61,  46, 138, 219, 151, 178, 240, 170, 255, 216, 128}\n       \
    \    },\n           { /* coeff band 1 */\n               {   1, 112, 230, 250,\
    \ 199, 191, 247, 159, 255, 255, 128},\n               { 166, 109, 228, 252, 211,\
    \ 215, 255, 174, 128, 128, 128},\n               {  39,  77, 162, 232, 172, 180,\
    \ 245, 178, 255, 255, 128}\n           },\n           { /* coeff band 2 */\n \
    \              {   1,  52, 220, 246, 198, 199, 249, 220, 255, 255, 128},\n   \
    \            { 124,  74, 191, 243, 183, 193, 250, 221, 255, 255, 128},\n     \
    \          {  24,  71, 130, 219, 154, 170, 243, 182, 255, 255, 128}\n        \
    \   },\n           { /* coeff band 3 */\n               {   1, 182, 225, 249,\
    \ 219, 240, 255, 224, 128, 128, 128},\n               { 149, 150, 226, 252, 216,\
    \ 205, 255, 171, 128, 128, 128},\n               {  28, 108, 170, 242, 183, 194,\
    \ 254, 223, 255, 255, 128}\n           },\n           { /* coeff band 4 */\n \
    \              {   1,  81, 230, 252, 204, 203, 255, 192, 128, 128, 128},\n   \
    \            { 123, 102, 209, 247, 188, 196, 255, 233, 128, 128, 128},\n     \
    \          {  20,  95, 153, 243, 164, 173, 255, 203, 128, 128, 128}\n        \
    \   },\n           { /* coeff band 5 */\n               {   1, 222, 248, 255,\
    \ 216, 213, 128, 128, 128, 128, 128},\n               { 168, 175, 246, 252, 235,\
    \ 205, 255, 255, 128, 128, 128},\n               {  47, 116, 215, 255, 211, 212,\
    \ 255, 255, 128, 128, 128}\n           },\n           { /* coeff band 6 */\n \
    \              {   1, 121, 236, 253, 212, 214, 255, 255, 128, 128, 128},\n   \
    \            { 141,  84, 213, 252, 201, 202, 255, 219, 128, 128, 128},\n     \
    \          {  42,  80, 160, 240, 162, 185, 255, 205, 128, 128, 128}\n        \
    \   },\n           { /* coeff band 7 */\n               {   1,   1, 255, 128,\
    \ 128, 128, 128, 128, 128, 128, 128},\n               { 244,   1, 255, 128, 128,\
    \ 128, 128, 128, 128, 128, 128},\n               { 238,   1, 255, 128, 128, 128,\
    \ 128, 128, 128, 128, 128}\n           }\n       }\n   };\n   static const\n \
    \  unsigned char k_mv_entropy_update_probs[2][MV_PROB_CNT] =\n   {\n       {\n\
    \           237,\n           246,\n           253, 253, 254, 254, 254, 254, 254,\n\
    \           254, 254, 254, 254, 254, 250, 250, 252, 254, 254\n       },\n    \
    \   {\n           231,\n           243,\n           245, 253, 254, 254, 254, 254,\
    \ 254,\n           254, 254, 254, 254, 254, 251, 251, 254, 254, 254\n       }\n\
    \   };\n   static const\n   unsigned char k_default_mv_probs[2][MV_PROB_CNT] =\n\
    \   {\n       {                                                  // row\n    \
    \       162,                                           // is short\n         \
    \  128,                                           // sign\n           225, 146,\
    \ 172, 147, 214,  39, 156,             // short tree\n           128, 129, 132,\
    \  75, 145, 178, 206, 239, 254, 254 // long bits\n       },\n       {\n      \
    \     164,\n           128,\n           204, 170, 119, 235, 140, 230, 228,\n \
    \          128, 130, 130,  74, 148, 180, 203, 236, 254, 254\n       }\n   };\n\
    \   ---- End code block ----------------------------------------\n"
- title: 20.19.  vpx_codec_internal.h
  contents:
  - "20.19.  vpx_codec_internal.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   /*!\\file vpx_codec_internal.h\n\
    \    * \\brief Describes the decoder algorithm interface for algorithm\n    *\
    \        implementations.\n    *\n    * This file defines the private structures\
    \ and data types that are\n    * only relevant to implementing an algorithm, as\
    \ opposed to using\n    * it.\n    *\n    * To create a decoder algorithm class,\
    \ an interface structure is put\n    * into the global namespace:\n    *     <pre>\n\
    \    *     my_codec.c:\n    *       vpx_codec_iface_t my_codec = {\n    *    \
    \       \"My Codec v1.0\",\n    *           VPX_CODEC_ALG_ABI_VERSION,\n    *\
    \           ...\n    *       };\n    *     </pre>\n    *\n    * An application\
    \ instantiates a specific decoder instance by using\n    * vpx_codec_init() and\
    \ a pointer to the algorithm's interface\n    * structure:\n    *     <pre>\n\
    \    *     my_app.c:\n    *       extern vpx_codec_iface_t my_codec;\n    *  \
    \     {\n    *           vpx_codec_ctx_t algo;\n    *           res = vpx_codec_init(&algo,\
    \ &my_codec);\n    *       }\n    *     </pre>\n    *\n    * Once initialized,\
    \ the instance is managed using other functions\n    * from the vpx_codec_* family.\n\
    \    */\n   #ifndef VPX_CODEC_INTERNAL_H\n   #define VPX_CODEC_INTERNAL_H\n  \
    \ #include \"vpx_decoder.h\"\n   #include <stdarg.h>\n   /*!\\brief Current ABI\
    \ version number\n    *\n    * \\internal\n    * If this file is altered in any\
    \ way that changes the Application\n    * Binary Interface (ABI), this value must\
    \ be bumped.  Examples\n    * include, but are not limited to, changing types,\
    \ removing or\n    * reassigning enums, adding/removing/rearranging fields to\n\
    \    * structures.\n    */\n   #define VPX_CODEC_INTERNAL_ABI_VERSION (3)\n  \
    \ typedef struct vpx_codec_alg_priv  vpx_codec_alg_priv_t;\n   /*!\\brief init\
    \ function pointer prototype\n    *\n    * Performs algorithm-specific initialization\
    \ of the decoder context.\n    * This function is called by the generic vpx_codec_init()\
    \ wrapper\n    * function, so plugins implementing this interface may trust the\n\
    \    * input parameters to be properly initialized.\n    *\n    * \\param[in]\
    \ ctx   Pointer to this instance's context\n    * \\retval #VPX_CODEC_OK\n   \
    \ *     The input stream was recognized and decoder initialized.\n    * \\retval\
    \ #VPX_CODEC_MEM_ERROR\n    *     Memory operation failed.\n    */\n   typedef\
    \ vpx_codec_err_t (*vpx_codec_init_fn_t)(vpx_codec_ctx_t *ctx);\n   /*!\\brief\
    \ destroy function pointer prototype\n    *\n    * Performs algorithm-specific\
    \ destruction of the decoder context.\n    * This function is called by the generic\
    \ vpx_codec_destroy() wrapper\n    * function, so plugins implementing this interface\
    \ may trust the\n    * input parameters to be properly initialized.\n    *\n \
    \   * \\param[in] ctx   Pointer to this instance's context\n    * \\retval #VPX_CODEC_OK\n\
    \    *     The input stream was recognized and decoder initialized.\n    * \\\
    retval #VPX_CODEC_MEM_ERROR\n    *     Memory operation failed.\n    */\n   typedef\
    \ vpx_codec_err_t (*vpx_codec_destroy_fn_t)(\n       vpx_codec_alg_priv_t *ctx);\n\
    \   /*!\\brief parse stream info function pointer prototype\n    *\n    * Performs\
    \ high level parsing of the bitstream.  This function is\n    * called by the\
    \ generic vpx_codec_parse_stream() wrapper function,\n    * so plugins implementing\
    \ this interface may trust the input\n    * parameters to be properly initialized.\n\
    \    *\n    * \\param[in]      data    Pointer to a block of data to parse\n \
    \   * \\param[in]      data_sz Size of the data buffer\n    * \\param[in,out]\
    \  si      Pointer to stream info to update.  The\n    *                     \
    \    size member \\ref MUST be properly\n    *                         initialized,\
    \ but \\ref MAY be clobbered by\n    *                         the algorithm.\
    \  This parameter \\ref MAY\n    *                         be NULL.\n    *\n \
    \   * \\retval #VPX_CODEC_OK\n    *     Bitstream is parsable and stream information\
    \ updated\n    */\n   typedef vpx_codec_err_t (*vpx_codec_peek_si_fn_t)(\n   \
    \    const uint8_t         *data,\n       unsigned int           data_sz,\n  \
    \     vpx_codec_stream_info_t *si);\n   /*!\\brief Return information about the\
    \ current stream.\n    *\n    * Returns information about the stream that has\
    \ been parsed during\n    * decoding.\n    *\n    * \\param[in]      ctx     Pointer\
    \ to this instance's context\n    * \\param[in,out]  si      Pointer to stream\
    \ info to update.  The\n    *                         size member \\ref MUST be\
    \ properly\n    *                         initialized, but \\ref MAY be clobbered\
    \ by\n    *                         the algorithm.  This parameter \\ref MAY\n\
    \    *                         be NULL.\n    *\n    * \\retval #VPX_CODEC_OK\n\
    \    *     Bitstream is parsable and stream information updated\n    */\n   typedef\
    \ vpx_codec_err_t (*vpx_codec_get_si_fn_t)(\n       vpx_codec_alg_priv_t    *ctx,\n\
    \       vpx_codec_stream_info_t *si);\n   /*!\\brief control function pointer\
    \ prototype\n    *\n    * This function is used to exchange algorithm-specific\
    \ data with the\n    * decoder instance.  This can be used to implement features\
    \ specific\n    * to a particular algorithm.\n    *\n    * This function is called\
    \ by the generic vpx_codec_control() wrapper\n    * function, so plugins implementing\
    \ this interface may trust the\n    * input parameters to be properly initialized.\
    \  However, this\n    * interface does not provide type safety for the exchanged\
    \ data or\n    * assign meanings to the control codes.  Those details should be\n\
    \    * specified in the algorithm's header file.  In particular, the\n    * ctrl_id\
    \ parameter is guaranteed to exist in the algorithm's\n    * control mapping table,\
    \ and the data parameter may be NULL.\n    *\n    *\n    * \\param[in]     ctx\
    \       Pointer to this instance's context\n    * \\param[in]     ctrl_id   Algorithm-specific\
    \ control identifier\n    * \\param[in,out] data      Data to exchange with algorithm\
    \ instance.\n    *\n    * \\retval #VPX_CODEC_OK\n    *     The internal state\
    \ data was deserialized.\n    */\n   typedef vpx_codec_err_t (*vpx_codec_control_fn_t)(\n\
    \       vpx_codec_alg_priv_t  *ctx,\n       int                   ctrl_id,\n \
    \      va_list               ap);\n   /*!\\brief control function pointer mapping\n\
    \    *\n    * This structure stores the mapping between control identifiers and\n\
    \    * implementing functions.  Each algorithm provides a list of these\n    *\
    \ mappings.  This list is searched by the vpx_codec_control()\n    * wrapper function\
    \ to determine which function to invoke.  The\n    * special value {0, NULL} is\
    \ used to indicate end-of-list, and must\n    * be present.  The special value\
    \ {0, <non-null>} can be used as a\n    * catch-all mapping.  This implies that\
    \ ctrl_id values chosen by the\n    * algorithm \\ref MUST be non-zero.\n    */\n\
    \   typedef const struct\n   {\n       int                    ctrl_id;\n     \
    \  vpx_codec_control_fn_t   fn;\n   } vpx_codec_ctrl_fn_map_t;\n   /*!\\brief\
    \ decode data function pointer prototype\n    *\n    * Processes a buffer of coded\
    \ data.  If the processing results in a\n    * new decoded frame becoming available,\
    \ #VPX_CODEC_CB_PUT_SLICE and\n    * #VPX_CODEC_CB_PUT_FRAME events are generated\
    \ as appropriate.\n    * This function is called by the generic vpx_codec_decode()\
    \ wrapper\n    * function, so plugins implementing this interface may trust the\n\
    \    * input parameters to be properly initialized.\n    *\n    * \\param[in]\
    \ ctx         Pointer to this instance's context\n    * \\param[in] data     \
    \   Pointer to this block of new coded data.\n    *                        If\
    \ NULL, a #VPX_CODEC_CB_PUT_FRAME event is\n    *                        posted\
    \ for the previously decoded frame.\n    * \\param[in] data_sz     Size of the\
    \ coded data, in bytes.\n    *\n    * \\return Returns #VPX_CODEC_OK if the coded\
    \ data was processed\n    *         completely and future pictures can be decoded\
    \ without\n    *         error.  Otherwise, see the descriptions of the other\
    \ error\n    *         codes in ::vpx_codec_err_t for recoverability\n    *  \
    \       capabilities.\n    */\n   typedef vpx_codec_err_t (*vpx_codec_decode_fn_t)(\n\
    \       vpx_codec_alg_priv_t  *ctx,\n       const uint8_t         *data,\n   \
    \    unsigned int     data_sz,\n       void        *user_priv,\n       long  \
    \       deadline);\n   /*!\\brief Decoded frames iterator\n    *\n    * Iterates\
    \ over a list of the frames available for display.  The\n    * iterator storage\
    \ should be initialized to NULL to start the\n    * iteration.  Iteration is complete\
    \ when this function returns NULL.\n    *\n    * The list of available frames\
    \ becomes valid upon completion of the\n    * vpx_codec_decode call, and remains\
    \ valid until the next call to\n    * vpx_codec_decode.\n    *\n    * \\param[in]\
    \     ctx      Pointer to this instance's context\n    * \\param[in out] iter\
    \     Iterator storage, initialized to NULL\n    *\n    * \\return Returns a pointer\
    \ to an image, if one is ready for\n    *         display.  Frames produced will\
    \ always be in PTS\n    *         (presentation time stamp) order.\n    */\n \
    \  typedef vpx_image_t*(*vpx_codec_get_frame_fn_t)(\n       vpx_codec_alg_priv_t\
    \ *ctx,\n       vpx_codec_iter_t     *iter);\n   /*\\brief External Memory Allocation\
    \ memory map get iterator\n    *\n    * Iterates over a list of the memory maps\
    \ requested by the decoder.\n    * The iterator storage should be initialized\
    \ to NULL to start the\n    * iteration.  Iteration is complete when this function\
    \ returns NULL.\n    *\n    * \\param[in out] iter     Iterator storage, initialized\
    \ to NULL\n    *\n    * \\return Returns a pointer to a memory segment descriptor,\
    \ or NULL\n    *         to indicate end-of-list.\n    */\n   typedef vpx_codec_err_t\
    \ (*vpx_codec_get_mmap_fn_t)(\n       const vpx_codec_ctx_t      *ctx,\n     \
    \  vpx_codec_mmap_t           *mmap,\n       vpx_codec_iter_t           *iter);\n\
    \   /*\\brief External Memory Allocation memory map set iterator\n    *\n    *\
    \ Sets a memory descriptor inside the decoder instance.\n    *\n    * \\param[in]\
    \ ctx      Pointer to this instance's context\n    * \\param[in] mmap     Memory\
    \ map to store.\n    *\n    * \\retval #VPX_CODEC_OK\n    *     The memory map\
    \ was accepted and stored.\n    * \\retval #VPX_CODEC_MEM_ERROR\n    *     The\
    \ memory map was rejected.\n    */\n   typedef vpx_codec_err_t (*vpx_codec_set_mmap_fn_t)(\n\
    \       vpx_codec_ctx_t         *ctx,\n       const vpx_codec_mmap_t  *mmap);\n\
    \   typedef vpx_codec_err_t (*vpx_codec_encode_fn_t)(\n       vpx_codec_alg_priv_t\
    \  *ctx,\n       const vpx_image_t     *img,\n       vpx_codec_pts_t        pts,\n\
    \       unsigned long          duration,\n       vpx_enc_frame_flags_t  flags,\n\
    \       unsigned long          deadline);\n   typedef const vpx_codec_cx_pkt_t*(*vpx_codec_get_cx_data_fn_t)(\n\
    \       vpx_codec_alg_priv_t *ctx,\n       vpx_codec_iter_t     *iter);\n   typedef\
    \ vpx_codec_err_t\n   (*vpx_codec_enc_config_set_fn_t)(\n       vpx_codec_alg_priv_t\
    \       *ctx,\n       const vpx_codec_enc_cfg_t  *cfg);\n   typedef vpx_fixed_buf_t\
    \ *\n   (*vpx_codec_get_global_headers_fn_t)(vpx_codec_alg_priv_t   *ctx);\n \
    \  typedef vpx_image_t *\n   (*vpx_codec_get_preview_frame_fn_t)(vpx_codec_alg_priv_t\
    \   *ctx);\n   /*!\\brief usage configuration mapping\n    *\n    * This structure\
    \ stores the mapping between usage identifiers and\n    * configuration structures.\
    \  Each algorithm provides a list of these\n    * mappings.  This list is searched\
    \ by the\n    * vpx_codec_enc_config_default() wrapper function to determine which\n\
    \    * config to return.  The special value {-1, {0}} is used to indicate\n  \
    \  * end-of-list, and must be present.  At least one mapping must be\n    * present,\
    \ in addition to the end-of-list.\n    *\n    */\n   typedef const struct\n  \
    \ {\n       int                 usage;\n       vpx_codec_enc_cfg_t cfg;\n   }\
    \ vpx_codec_enc_cfg_map_t;\n   #define NOT_IMPLEMENTED 0\n   /*!\\brief Decoder\
    \ algorithm interface\n    *\n    * All decoders \\ref MUST expose a variable\
    \ of this type.\n    */\n   struct vpx_codec_iface\n   {\n       const char  \
    \             *name;\n       int                       abi_version;\n       vpx_codec_caps_t\
    \          caps;\n       vpx_codec_init_fn_t       init;\n       vpx_codec_destroy_fn_t\
    \    destroy;\n       vpx_codec_ctrl_fn_map_t  *ctrl_maps;\n       vpx_codec_get_mmap_fn_t\
    \   get_mmap;\n       vpx_codec_set_mmap_fn_t   set_mmap;\n       struct\n   \
    \    {\n           vpx_codec_peek_si_fn_t    peek_si;\n           vpx_codec_get_si_fn_t\
    \     get_si;\n           vpx_codec_decode_fn_t     decode;\n           vpx_codec_get_frame_fn_t\
    \  get_frame;\n       } dec;\n       struct\n       {\n           vpx_codec_enc_cfg_map_t\
    \           *cfg_maps;\n           vpx_codec_encode_fn_t              encode;\n\
    \           vpx_codec_get_cx_data_fn_t         get_cx_data;\n           vpx_codec_enc_config_set_fn_t\
    \      cfg_set;\n           vpx_codec_get_global_headers_fn_t  get_glob_hdrs;\n\
    \           vpx_codec_get_preview_frame_fn_t   get_preview;\n       } enc;\n \
    \  };\n   /*!\\brief Callback function pointer / user data pair storage */\n \
    \  typedef struct vpx_codec_priv_cb_pair\n   {\n       union\n       {\n     \
    \      vpx_codec_put_frame_cb_fn_t    put_frame;\n           vpx_codec_put_slice_cb_fn_t\
    \    put_slice;\n       };\n       void                            *user_priv;\n\
    \   } vpx_codec_priv_cb_pair_t;\n   /*!\\brief Instance private storage\n    *\n\
    \    * This structure is allocated by the algorithm's init function.  It\n   \
    \ * can be extended in one of two ways.  First, a second, algorithm\n    * specific\
    \ structure can be allocated and the priv member pointed to\n    * it.  Alternatively,\
    \ this structure can be made the first member of\n    * the algorithm-specific\
    \ structure, and the pointer casted to the\n    * proper type.\n    */\n   struct\
    \ vpx_codec_priv\n   {\n       unsigned int                    sz;\n       vpx_codec_iface_t\
    \              *iface;\n       struct vpx_codec_alg_priv      *alg_priv;\n   \
    \    const char                     *err_detail;\n       vpx_codec_flags_t   \
    \            init_flags;\n       struct\n       {\n           vpx_codec_priv_cb_pair_t\
    \    put_frame_cb;\n           vpx_codec_priv_cb_pair_t    put_slice_cb;\n   \
    \    } dec;\n       struct\n       {\n           struct vpx_fixed_buf        cx_data_dst_buf;\n\
    \           unsigned int                cx_data_pad_before;\n           unsigned\
    \ int                cx_data_pad_after;\n           vpx_codec_cx_pkt_t       \
    \   cx_data_pkt;\n       } enc;\n   };\n   #undef VPX_CTRL_USE_TYPE\n   #define\
    \ VPX_CTRL_USE_TYPE(id, typ) \\\n       static typ id##__value(va_list args) \\\
    \n       {return va_arg(args, typ);} \\\n       static typ id##__convert(void\
    \ *x)\\\n       {\\\n           union\\\n           {\\\n               void *x;\\\
    \n               typ   d;\\\n           } u;\\\n           u.x = x;\\\n      \
    \     return u.d;\\\n       }\n   #undef VPX_CTRL_USE_TYPE_DEPRECATED\n   #define\
    \ VPX_CTRL_USE_TYPE_DEPRECATED(id, typ) \\\n       static typ id##__value(va_list\
    \ args) \\\n       {return va_arg(args, typ);} \\\n       static typ id##__convert(void\
    \ *x)\\\n       {\\\n           union\\\n           {\\\n               void *x;\\\
    \n               typ   d;\\\n           } u;\\\n           u.x = x;\\\n      \
    \     return u.d;\\\n       }\n   #define CAST(id, arg) id##__value(arg)\n   #define\
    \ RECAST(id, x) id##__convert(x)\n   /* Internal Utility Functions\n    *\n  \
    \  * The following functions are intended to be used inside algorithms\n    *\
    \ as utilities for manipulating vpx_codec_* data structures.\n    */\n   struct\
    \ vpx_codec_pkt_list\n   {\n       unsigned int            cnt;\n       unsigned\
    \ int            max;\n       struct vpx_codec_cx_pkt pkts[1];\n   };\n   #define\
    \ vpx_codec_pkt_list_decl(n)\\\n       union {struct vpx_codec_pkt_list head;\\\
    \n           struct {struct vpx_codec_pkt_list head;\\\n               struct\
    \ vpx_codec_cx_pkt    pkts[n];} alloc;}\n   #define vpx_codec_pkt_list_init(m)\\\
    \n       (m)->alloc.head.cnt = 0,\\\n       (m)->alloc.head.max = \\\n       sizeof((m)->alloc.pkts)\
    \ / sizeof((m)->alloc.pkts[0])\n   int\n   vpx_codec_pkt_list_add(struct vpx_codec_pkt_list\
    \ *,\n                          const struct vpx_codec_cx_pkt *);\n   const vpx_codec_cx_pkt_t*\n\
    \   vpx_codec_pkt_list_get(struct vpx_codec_pkt_list *list,\n                \
    \          vpx_codec_iter_t           *iter);\n   #include <stdio.h>\n   #include\
    \ <setjmp.h>\n   struct vpx_internal_error_info\n   {\n       vpx_codec_err_t\
    \  error_code;\n       int              has_detail;\n       char             detail[80];\n\
    \       int              setjmp;\n       jmp_buf          jmp;\n   };\n   static\
    \ void vpx_internal_error(struct vpx_internal_error_info *info,\n            \
    \                      vpx_codec_err_t                 error,\n              \
    \                    const char                     *fmt,\n                  \
    \                ...)\n   {\n       va_list ap;\n       info->error_code = error;\n\
    \       info->has_detail = 0;\n       if (fmt)\n       {\n           size_t  sz\
    \ = sizeof(info->detail);\n           info->has_detail = 1;\n           va_start(ap,\
    \ fmt);\n           vsnprintf(info->detail, sz - 1, fmt, ap);\n           va_end(ap);\n\
    \           info->detail[sz-1] = '\\0';\n       }\n       if (info->setjmp)\n\
    \           longjmp(info->jmp, info->error_code);\n   }\n   #endif\n   ---- End\
    \ code block ----------------------------------------\n"
- title: 20.20.  vpx_decoder.h
  contents:
  - "20.20.  vpx_decoder.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   /*!\\defgroup decoder\
    \ Decoder Algorithm Interface\n    * \\ingroup codec\n    * This abstraction allows\
    \ applications using this decoder to easily\n    * support multiple video formats\
    \ with minimal code duplication.\n    * This section describes the interface common\
    \ to all decoders.\n    * @{\n    */\n   /*!\\file vpx_decoder.h\n    * \\brief\
    \ Describes the decoder algorithm interface to applications.\n    *\n    * This\
    \ file describes the interface between an application and a\n    * video decoder\
    \ algorithm.\n    *\n    */\n   #ifdef __cplusplus\n   extern \"C\" {\n   #endif\n\
    \   #ifndef VPX_DECODER_H\n   #define VPX_DECODER_H\n   #include \"vpx_codec.h\"\
    \n       /*!\\brief Current ABI version number\n        *\n        * \\internal\n\
    \        * If this file is altered in any way that changes the ABI, this\n   \
    \     * value must be bumped.  Examples include, but are not limited\n       \
    \ * to, changing types, removing or reassigning enums,\n        * adding/removing/rearranging\
    \ fields to structures\n        */\n   #define VPX_DECODER_ABI_VERSION (2 + VPX_CODEC_ABI_VERSION)\n\
    \       /*! \\brief Decoder capabilities bitfield\n        *\n        *  Each\
    \ decoder advertises the capabilities it supports as part\n        *  of its ::vpx_codec_iface_t\
    \ interface structure.  Capabilities\n        *  are extra interfaces or functionality,\
    \ and are not required\n        *  to be supported by a decoder.\n        *\n\
    \        *  The available flags are specified by VPX_CODEC_CAP_* defines.\n  \
    \      */\n   #define VPX_CODEC_CAP_PUT_SLICE  0x10000 /**< Will issue put_slice\n\
    \       callbacks */\n   #define VPX_CODEC_CAP_PUT_FRAME  0x20000 /**< Will issue\
    \ put_frame\n       callbacks */\n   #define VPX_CODEC_CAP_POSTPROC   0x40000\
    \ /**< Can postprocess decoded\n       frame */\n       /*! \\brief Initialization-time\
    \ Feature Enabling\n        *\n        *  Certain codec features must be known\
    \ at initialization time,\n        *  to allow for proper memory allocation.\n\
    \        *\n        *  The available flags are specified by VPX_CODEC_USE_* defines.\n\
    \        */\n   #define VPX_CODEC_USE_POSTPROC   0x10000 /**< Postprocess decoded\n\
    \       frame */\n       /*!\\brief Stream properties\n        *\n        * This\
    \ structure is used to query or set properties of the\n        * decoded stream.\
    \  Algorithms may extend this structure with\n        * data specific to their\
    \ bitstream by setting the sz member\n        * appropriately.\n        */\n \
    \      typedef struct vpx_codec_stream_info\n       {\n           unsigned int\
    \ sz;    /**< Size of this structure */\n           unsigned int w;     /**< Width\
    \ (or 0 for unknown/default) */\n           unsigned int h;     /**< Height (or\
    \ 0 for unknown/default) */\n           unsigned int is_kf; /**< Current frame\
    \ is a keyframe */\n       } vpx_codec_stream_info_t;\n       /* REQUIRED FUNCTIONS\n\
    \        *\n        * The following functions are required to be implemented for\
    \ all\n        * decoders.  They represent the base case functionality expected\n\
    \        * of all decoders.\n        */\n       /*!\\brief Initialization Configurations\n\
    \        *\n        * This structure is used to pass init time configuration options\n\
    \        * to the decoder.\n        */\n       typedef struct vpx_codec_dec_cfg\n\
    \       {\n           unsigned int threads; /**< Maximum number of threads to\
    \ use,\n               default 1 */\n           unsigned int w;      /**< Width\
    \ */\n           unsigned int h;      /**< Height */\n       } vpx_codec_dec_cfg_t;\
    \ /**< alias for struct vpx_codec_dec_cfg */\n       /*!\\brief Initialize a decoder\
    \ instance\n        *\n        * Initializes a decoder context using the given\
    \ interface.\n        * Applications should call the vpx_codec_dec_init convenience\n\
    \        * macro instead of this function directly, to ensure that the\n     \
    \   * ABI version number parameter is properly initialized.\n        *\n     \
    \   * In XMA mode (activated by setting VPX_CODEC_USE_XMA in the\n        * flags\
    \ parameter), the storage pointed to by the cfg parameter\n        * must be kept\
    \ readable and stable until all memory maps have\n        * been set.\n      \
    \  *\n        * \\param[in]    ctx     Pointer to this instance's context.\n \
    \       * \\param[in]    iface   Pointer to the algorithm interface to\n     \
    \   *                       use.\n        * \\param[in]    cfg     Configuration\
    \ to use, if known.  May be\n        *                       NULL.\n        *\
    \ \\param[in]    flags   Bitfield of VPX_CODEC_USE_* flags\n        * \\param[in]\
    \    ver     ABI version number.  Must be set to\n        *                  \
    \     VPX_DECODER_ABI_VERSION\n        * \\retval #VPX_CODEC_OK\n        *   \
    \  The decoder algorithm initialized.\n        * \\retval #VPX_CODEC_MEM_ERROR\n\
    \        *     Memory allocation failed.\n        */\n       vpx_codec_err_t vpx_codec_dec_init_ver(\n\
    \           vpx_codec_ctx_t      *ctx,\n           vpx_codec_iface_t    *iface,\n\
    \           vpx_codec_dec_cfg_t  *cfg,\n           vpx_codec_flags_t     flags,\n\
    \           int                   ver);\n       /*!\\brief Convenience macro for\
    \ vpx_codec_dec_init_ver()\n        *\n        * Ensures the ABI version parameter\
    \ is properly set.\n        */\n   #define vpx_codec_dec_init(ctx, iface, cfg,\
    \ flags) \\\n       vpx_codec_dec_init_ver(ctx, iface, cfg, flags, \\\n      \
    \ VPX_DECODER_ABI_VERSION)\n       /*!\\brief Parse stream info from a buffer\n\
    \        *\n        * Performs high level parsing of the bitstream.  Construction\
    \ of\n        * a decoder context is not necessary.  Can be used to determine\n\
    \        * if the bitstream is of the proper format, and to extract\n        *\
    \ information from the stream.\n        *\n        * \\param[in]      iface  \
    \ Pointer to the algorithm interface\n        * \\param[in]      data    Pointer\
    \ to a block of data to parse\n        * \\param[in]      data_sz Size of the\
    \ data buffer\n        * \\param[in,out]  si      Pointer to stream info to update.\
    \  The\n        *                         size member\n        *             \
    \            \\ref MUST be properly initialized, but\n        *              \
    \           \\ref MAY be clobbered by the\n        *                         algorithm.\
    \  This parameter \\ref MAY be\n        *                         NULL.\n    \
    \    *\n        * \\retval #VPX_CODEC_OK\n        *     Bitstream is parsable\
    \ and stream information updated\n        */\n       vpx_codec_err_t vpx_codec_peek_stream_info(\n\
    \           vpx_codec_iface_t       *iface,\n           const uint8_t        \
    \   *data,\n           unsigned int             data_sz,\n           vpx_codec_stream_info_t\
    \ *si);\n       /*!\\brief Return information about the current stream.\n    \
    \    *\n        * Returns information about the stream that has been parsed\n\
    \        * during decoding.\n        *\n        * \\param[in]      ctx     Pointer\
    \ to this instance's context\n        * \\param[in,out]  si      Pointer to stream\
    \ info to update.  The\n        *                         size member \\ref MUST\
    \ be properly\n        *                         initialized, but \\ref MAY be\
    \ clobbered\n        *                         by the algorithm.  This parameter\
    \ \\ref\n        *                         MAY be NULL.\n        *\n        *\
    \ \\retval #VPX_CODEC_OK\n        *     Bitstream is parsable and stream information\
    \ updated\n        */\n       vpx_codec_err_t vpx_codec_get_stream_info(\n   \
    \        vpx_codec_ctx_t         *ctx,\n           vpx_codec_stream_info_t *si);\n\
    \       /*!\\brief Decode data\n        *\n        * Processes a buffer of coded\
    \ data.  If the processing results\n        * in a new decoded frame becoming\
    \ available, PUT_SLICE and\n        * PUT_FRAME events may be generated, as appropriate.\
    \  Encoded\n        * data \\ref MUST be passed in DTS (decode time stamp) order.\n\
    \        * Frames produced will always be in PTS (presentation time\n        *\
    \ stamp) order.\n        *\n        * \\param[in] ctx          Pointer to this\
    \ instance's context\n        * \\param[in] data         Pointer to this block\
    \ of new coded\n        *                         data.  If NULL, a\n        *\
    \                         VPX_CODEC_CB_PUT_FRAME event is posted\n        *  \
    \                       for the previously decoded frame.\n        * \\param[in]\
    \ data_sz      Size of the coded data, in bytes.\n        * \\param[in] user_priv\
    \    Application-specific data to associate\n        *                       \
    \  with this frame.\n        * \\param[in] deadline     Soft deadline the decoder\
    \ should\n        *                         attempt to meet, in us.  Set to zero\n\
    \        *                         for unlimited.\n        *\n        * \\return\
    \ Returns #VPX_CODEC_OK if the coded data was processed\n        *         completely\
    \ and future pictures can be decoded without\n        *         error.  Otherwise,\
    \ see the descriptions of the other\n        *         error codes in ::vpx_codec_err_t\
    \ for recoverability\n        *         capabilities.\n        */\n       vpx_codec_err_t\
    \ vpx_codec_decode(vpx_codec_ctx_t    *ctx,\n                                \
    \        const uint8_t        *data,\n                                       \
    \ unsigned int            data_sz,\n                                        void\
    \               *user_priv,\n                                        long    \
    \            deadline);\n       /*!\\brief Decoded frames iterator\n        *\n\
    \        * Iterates over a list of the frames available for display.  The\n  \
    \      * iterator storage should be initialized to NULL to start the\n       \
    \ * iteration.  Iteration is complete when this function returns\n        * NULL.\n\
    \        *\n        * The list of available frames becomes valid upon completion\
    \ of\n        * the vpx_codec_decode call, and remains valid until the next\n\
    \        * call to vpx_codec_decode.\n        *\n        * \\param[in]     ctx\
    \      Pointer to this instance's context\n        * \\param[in,out] iter    \
    \ Iterator storage, initialized to NULL\n        *\n        * \\return Returns\
    \ a pointer to an image, if one is ready for\n        *         display.  Frames\
    \ produced will always be in PTS\n        *         (presentation time stamp)\
    \ order.\n        */\n       vpx_image_t *vpx_codec_get_frame(vpx_codec_ctx_t\
    \  *ctx,\n                                        vpx_codec_iter_t *iter);\n \
    \      /*!\\defgroup cap_put_frame Frame-Based Decoding Functions\n        *\n\
    \        * The following functions are required to be implemented for all\n  \
    \      * decoders that advertise the VPX_CODEC_CAP_PUT_FRAME\n        * capability.\
    \  Calling these functions for codecs that don't\n        * advertise this capability\
    \ will result in an error code being\n        * returned, usually VPX_CODEC_ERROR\n\
    \        * @{\n        */\n       /*!\\brief put frame callback prototype\n  \
    \      *\n        * This callback is invoked by the decoder to notify the\n  \
    \      * application of the availability of decoded image data.\n        */\n\
    \       typedef void (*vpx_codec_put_frame_cb_fn_t)(\n           void        *user_priv,\n\
    \           const vpx_image_t *img);\n       /*!\\brief Register for notification\
    \ of frame completion.\n        *\n        * Registers a given function to be\
    \ called when a decoded frame\n        * is available.\n        *\n        * \\\
    param[in] ctx          Pointer to this instance's context\n        * \\param[in]\
    \ cb           Pointer to the callback function\n        * \\param[in] user_priv\
    \    User's private data\n        *\n        * \\retval #VPX_CODEC_OK\n      \
    \  *     Callback successfully registered.\n        * \\retval #VPX_CODEC_ERROR\n\
    \        *     Decoder context not initialized, or algorithm not capable\n   \
    \     *     of posting slice completion.\n        */\n       vpx_codec_err_t vpx_codec_register_put_frame_cb(\n\
    \           vpx_codec_ctx_t             *ctx,\n           vpx_codec_put_frame_cb_fn_t\
    \  cb,\n           void                        *user_priv);\n       /*!@} - end\
    \ defgroup cap_put_frame */\n       /*!\\defgroup cap_put_slice Slice-Based Decoding\
    \ Functions\n        *\n        * The following functions are required to be implemented\
    \ for all\n        * decoders that advertise the VPX_CODEC_CAP_PUT_SLICE\n   \
    \     * capability.  Calling these functions for codecs that don't\n        *\
    \ advertise this capability will result in an error code being\n        * returned,\
    \ usually VPX_CODEC_ERROR\n        * @{\n        */\n       /*!\\brief put slice\
    \ callback prototype\n        *\n        * This callback is invoked by the decoder\
    \ to notify the\n        * application of the availability of partially decoded\
    \ image\n        * data.\n        */\n       typedef void (*vpx_codec_put_slice_cb_fn_t)(\n\
    \           void         *user_priv,\n           const vpx_image_t      *img,\n\
    \           const vpx_image_rect_t *valid,\n           const vpx_image_rect_t\
    \ *update);\n       /*!\\brief Register for notification of slice completion.\n\
    \        *\n        * Registers a given function to be called when a decoded slice\n\
    \        * is available.\n        *\n        * \\param[in] ctx          Pointer\
    \ to this instance's context\n        * \\param[in] cb           Pointer to the\
    \ callback function\n        * \\param[in] user_priv    User's private data\n\
    \        *\n        * \\retval #VPX_CODEC_OK\n        *     Callback successfully\
    \ registered.\n        * \\retval #VPX_CODEC_ERROR\n        *     Decoder context\
    \ not initialized, or algorithm not capable\n        *     of posting slice completion.\n\
    \        */\n       vpx_codec_err_t vpx_codec_register_put_slice_cb(\n       \
    \    vpx_codec_ctx_t             *ctx,\n           vpx_codec_put_slice_cb_fn_t\
    \  cb,\n           void                        *user_priv);\n       /*!@} - end\
    \ defgroup cap_put_slice*/\n       /*!@} - end defgroup decoder*/\n   #endif\n\
    \   #ifdef __cplusplus\n   }\n   #endif\n   #if !defined(VPX_CODEC_DISABLE_COMPAT)\
    \ || !VPX_CODEC_DISABLE_COMPAT\n   #include \"vpx_decoder_compat.h\"\n   #endif\n\
    \   ---- End code block ----------------------------------------\n"
- title: 20.21.  vpx_decoder_compat.h
  contents:
  - "20.21.  vpx_decoder_compat.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    * Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n  \
    \  *\n    * Use of this source code is governed by a BSD-style license\n    *\
    \ that can be found in the LICENSE file in the root of the source\n    * tree.\
    \  An additional intellectual property rights grant can be\n    * found in the\
    \ file PATENTS.  All contributing project authors may\n    * be found in the AUTHORS\
    \ file in the root of the source tree.\n    */\n   /*!\\defgroup decoder Common\
    \ Decoder Algorithm Interface\n    * This abstraction allows applications using\
    \ this decoder to easily\n    * support multiple video formats with minimal code\
    \ duplication.\n    * This section describes the interface common to all codecs.\n\
    \    * @{\n    */\n   /*!\\file\n    * \\brief Provides a compatibility layer\
    \ between version 1 and 2 of\n    * this API.\n    *\n    * This interface has\
    \ been deprecated.  Only existing code should\n    * make use of this interface,\
    \ and therefore, it is only thinly\n    * documented.  Existing code should be\
    \ ported to the vpx_codec_*\n    * API.\n    */\n   #ifdef __cplusplus\n   extern\
    \ \"C\" {\n   #endif\n   #ifndef VPX_DECODER_COMPAT_H\n   #define VPX_DECODER_COMPAT_H\n\
    \       /*!\\brief Decoder algorithm return codes */\n       typedef enum {\n\
    \           /*!\\brief Operation completed without error */\n           VPX_DEC_OK\
    \ = VPX_CODEC_OK,\n           /*!\\brief Unspecified error */\n           VPX_DEC_ERROR\
    \ = VPX_CODEC_ERROR,\n           /*!\\brief Memory operation failed */\n     \
    \      VPX_DEC_MEM_ERROR = VPX_CODEC_MEM_ERROR,\n           /*!\\brief ABI version\
    \ mismatch */\n           VPX_DEC_ABI_MISMATCH = VPX_CODEC_ABI_MISMATCH,\n   \
    \        /*!\\brief The given bitstream is not supported.\n            *\n   \
    \         * The bitstream was unable to be parsed at the highest\n           \
    \ * level.  The decoder is unable to proceed.  This error \\ref\n            *\
    \ SHOULD be treated as fatal to the stream.\n            */\n           VPX_DEC_UNSUP_BITSTREAM\
    \ = VPX_CODEC_UNSUP_BITSTREAM,\n           /*!\\brief Encoded bitstream uses an\
    \ unsupported feature\n            *\n            * The decoder does not implement\
    \ a feature required by the\n            * encoder.  This return code should only\
    \ be used for\n            * features that prevent future pictures from being\
    \ properly\n            * decoded.  This error \\ref MAY be treated as fatal to\
    \ the\n            * stream or \\ref MAY be treated as fatal to the current\n\
    \            * Group of Pictures (GOP).\n            */\n           VPX_DEC_UNSUP_FEATURE\
    \ = VPX_CODEC_UNSUP_FEATURE,\n           /*!\\brief The coded data for this stream\
    \ is corrupt or\n            * incomplete\n            *\n            * There\
    \ was a problem decoding the current frame.  This\n            * return code should\
    \ only be used for failures that prevent\n            * future pictures from being\
    \ properly decoded.  This error\n            * \\ref MAY be treated as fatal to\
    \ the stream or \\ref MAY be\n            * treated as fatal to the current GOP.\
    \  If decoding is\n            * continued for the current GOP, artifacts may\
    \ be present.\n            */\n           VPX_DEC_CORRUPT_FRAME = VPX_CODEC_CORRUPT_FRAME,\n\
    \           /*!\\brief An application-supplied parameter is not valid.\n     \
    \       *\n            */\n           VPX_DEC_INVALID_PARAM = VPX_CODEC_INVALID_PARAM,\n\
    \           /*!\\brief An iterator reached the end of list.\n            *\n \
    \           */\n           VPX_DEC_LIST_END = VPX_CODEC_LIST_END\n       }\n \
    \      vpx_dec_err_t;\n       /*! \\brief Decoder capabilities bitfield\n    \
    \    *\n        *  Each decoder advertises the capabilities it supports as part\n\
    \        *  of its ::vpx_dec_iface_t interface structure.  Capabilities\n    \
    \    *  are extra interfaces or functionality, and are not required\n        *\
    \  to be supported by a decoder.\n        *\n        *  The available flags are\
    \ specified by VPX_DEC_CAP_* defines.\n        */\n       typedef int vpx_dec_caps_t;\n\
    \   #define VPX_DEC_CAP_PUT_SLICE  0x0001 /**< Will issue put_slice\n        \
    \                                    callbacks */\n   #define VPX_DEC_CAP_PUT_FRAME\
    \  0x0002 /**< Will issue put_frame\n                                        \
    \    callbacks */\n   #define VPX_DEC_CAP_XMA        0x0004 /**< Supports External\
    \ Memory\n                                            Allocation */\n       /*!\\\
    brief Stream properties\n        *\n        * This structure is used to query\
    \ or set properties of the\n        * decoded stream.  Algorithms may extend this\
    \ structure with\n        * data specific to their bitstream by setting the sz\
    \ member\n        * appropriately.\n        */\n   #if 1\n       typedef vpx_codec_stream_info_t\
    \ vpx_dec_stream_info_t;\n   #else\n       typedef struct\n       {\n        \
    \   unsigned int sz;    /**< Size of this structure */\n           unsigned int\
    \ w;     /**< Width (or 0 for unknown/default) */\n           unsigned int h;\
    \     /**< Height (or 0 for unknown/default) */\n           unsigned int is_kf;\
    \ /**< Current frame is a keyframe */\n       } vpx_dec_stream_info_t;\n   #endif\n\
    \       /*!\\brief Decoder interface structure.\n        *\n        * Contains\
    \ function pointers and other data private to the\n        * decoder implementation.\
    \  This structure is opaque to the\n        * application.\n        */\n     \
    \  typedef const struct vpx_codec_iface vpx_dec_iface_t;\n       typedef     \
    \  struct vpx_codec_priv  vpx_dec_priv_t;\n       /*!\\brief Iterator\n      \
    \  *\n        * Opaque storage used for iterating over lists.\n        */\n  \
    \     typedef vpx_codec_iter_t vpx_dec_iter_t;\n       /*!\\brief Decoder context\
    \ structure\n        *\n        * All decoders \\ref MUST support this context\
    \ structure fully.\n        * In general, this data should be considered private\
    \ to the\n        * decoder algorithm, and not be manipulated or examined by the\n\
    \        * calling application.  Applications may reference the 'name'\n     \
    \   * member to get a printable description of the algorithm.\n        */\n  \
    \ #if 1\n       typedef vpx_codec_ctx_t vpx_dec_ctx_t;\n   #else\n       typedef\
    \ struct\n       {\n           const char          *name;  /**< Printable interface\
    \ name */\n           vpx_dec_iface_t     *iface; /**< Interface pointers */\n\
    \           vpx_dec_err_t        err;   /**< Last returned error */\n        \
    \   vpx_dec_priv_t      *priv;  /**< Algorithm private storage */\n       } vpx_dec_ctx_t;\n\
    \   #endif\n       /*!\\brief Return the build configuration\n        *\n    \
    \    * Returns a printable string containing an encoded version of\n        *\
    \ the build configuration.  This may be useful to vpx support.\n        *\n  \
    \      */\n       const char *vpx_dec_build_config(void) DEPRECATED;\n       /*!\\\
    brief Return the name for a given interface\n        *\n        * Returns a human\
    \ readable string for name of the given decoder\n        * interface.\n      \
    \  *\n        * \\param[in]    iface     Interface pointer\n        *\n      \
    \  */\n       const char *vpx_dec_iface_name(\n           vpx_dec_iface_t *iface)\
    \ DEPRECATED;\n       /*!\\brief Convert error number to printable string\n  \
    \      *\n        * Returns a human readable string for the last error returned\n\
    \        * by the algorithm.  The returned error will be one line and\n      \
    \  * will not contain any newline characters.\n        *\n        *\n        *\
    \ \\param[in]    err     Error number.\n        *\n        */\n       const char\
    \ *vpx_dec_err_to_string(vpx_dec_err_t  err) DEPRECATED;\n       /*!\\brief Retrieve\
    \ error synopsis for decoder context\n        *\n        * Returns a human readable\
    \ string for the last error returned by\n        * the algorithm.  The returned\
    \ error will be one line and will\n        * not contain any newline characters.\n\
    \        *\n        *\n        * \\param[in]    ctx     Pointer to this instance's\
    \ context.\n        *\n        */\n       const char *vpx_dec_error(vpx_dec_ctx_t\
    \  *ctx) DEPRECATED;\n       /*!\\brief Retrieve detailed error information for\
    \ decoder context\n        *\n        * Returns a human readable string providing\
    \ detailed information\n        * about the last error.\n        *\n        *\
    \ \\param[in]    ctx     Pointer to this instance's context.\n        *\n    \
    \    * \\retval NULL\n        *     No detailed information is available.\n  \
    \      */\n       const char *vpx_dec_error_detail(vpx_dec_ctx_t  *ctx) DEPRECATED;\n\
    \       /* REQUIRED FUNCTIONS\n        *\n        * The following functions are\
    \ required to be implemented for all\n        * decoders.  They represent the\
    \ base case functionality expected\n        * of all decoders.\n        */\n \
    \      /*!\\brief Initialize a decoder instance\n        *\n        * Initializes\
    \ a decoder context using the given interface.\n        * Applications should\
    \ call the vpx_dec_init convenience macro\n        * instead of this function\
    \ directly, to ensure that the ABI\n        * version number parameter is properly\
    \ initialized.\n        *\n        * \\param[in]   ctx    Pointer to this instance's\
    \ context.\n        * \\param[in]   iface  Pointer to the algorithm interface\
    \ to use.\n        * \\param[in]   ver    ABI version number.  Must be set to\n\
    \        *                       VPX_DECODER_ABI_VERSION\n        * \\retval #VPX_DEC_OK\n\
    \        *     The decoder algorithm initialized.\n        * \\retval #VPX_DEC_MEM_ERROR\n\
    \        *     Memory allocation failed.\n        */\n       vpx_dec_err_t vpx_dec_init_ver(\n\
    \           vpx_dec_ctx_t    *ctx,\n           vpx_dec_iface_t  *iface,\n    \
    \       int               ver) DEPRECATED;\n   #define vpx_dec_init(ctx, iface)\
    \ \\\n       vpx_dec_init_ver(ctx, iface, VPX_DECODER_ABI_VERSION)\n       /*!\\\
    brief Destroy a decoder instance\n        *\n        * Destroys a decoder context,\
    \ freeing any associated memory\n        * buffers.\n        *\n        * \\param[in]\
    \ ctx   Pointer to this instance's context\n        *\n        * \\retval #VPX_DEC_OK\n\
    \        *     The decoder algorithm initialized.\n        * \\retval #VPX_DEC_MEM_ERROR\n\
    \        *     Memory allocation failed.\n        */\n       vpx_dec_err_t vpx_dec_destroy(vpx_dec_ctx_t\
    \ *ctx) DEPRECATED;\n       /*!\\brief Get the capabilities of an algorithm.\n\
    \        *\n        * Retrieves the capabilities bitfield from the algorithm's\n\
    \        * interface.\n        *\n        * \\param[in] iface   Pointer to the\
    \ algorithm interface\n        *\n        */\n       vpx_dec_caps_t vpx_dec_get_caps(\n\
    \           vpx_dec_iface_t *iface) DEPRECATED;\n       /*!\\brief Parse stream\
    \ info from a buffer\n        *\n        * Performs high level parsing of the\
    \ bitstream.  Construction of\n        * a decoder context is not necessary. \
    \ Can be used to determine\n        * if the bitstream is of the proper format,\
    \ and to extract\n        * information from the stream.\n        *\n        *\
    \ \\param[in]      iface   Pointer to the algorithm interface\n        * \\param[in]\
    \      data    Pointer to a block of data to parse\n        * \\param[in]    \
    \  data_sz Size of the data buffer\n        * \\param[in,out]  si      Pointer\
    \ to stream info to update.  The\n        *                         size member\
    \ \\ref MUST be properly\n        *                         initialized, but \\\
    ref MAY be\n        *                         clobbered by the algorithm.  This\n\
    \        *                         parameter \\ref MAY be NULL.\n        *\n \
    \       * \\retval #VPX_DEC_OK\n        *     Bitstream is parsable and stream\
    \ information updated\n        */\n       vpx_dec_err_t vpx_dec_peek_stream_info(\n\
    \                                vpx_dec_iface_t       *iface,\n             \
    \                   const uint8_t         *data,\n                           \
    \     unsigned int           data_sz,\n                                vpx_dec_stream_info_t\
    \ *si) DEPRECATED;\n       /*!\\brief Return information about the current stream.\n\
    \        *\n        * Returns information about the stream that has been parsed\n\
    \        * during decoding.\n        *\n        * \\param[in]      ctx     Pointer\
    \ to this instance's context\n        * \\param[in,out]  si      Pointer to stream\
    \ info to update.\n        *                         The size member \\ref MUST\
    \ be properly\n        *                         initialized, but \\ref MAY be\
    \ clobbered\n        *                         by the algorithm.  This parameter\
    \ \\ref\n        *                         MAY be NULL.\n        *\n        *\
    \ \\retval #VPX_DEC_OK\n        *     Bitstream is parsable and stream information\
    \ updated\n        */\n       vpx_dec_err_t vpx_dec_get_stream_info(\n       \
    \    vpx_dec_ctx_t         *ctx,\n           vpx_dec_stream_info_t *si) DEPRECATED;\n\
    \       /*!\\brief Control algorithm\n        *\n        * This function is used\
    \ to exchange algorithm-specific data with\n        * the decoder instance.  This\
    \ can be used to implement features\n        * specific to a particular algorithm.\n\
    \        *\n        * This wrapper function dispatches the request to the helper\n\
    \        * function associated with the given ctrl_id.  It tries to call\n   \
    \     * this function transparently, but will return #VPX_DEC_ERROR if\n     \
    \   * the request could not be dispatched.\n        *\n        * \\param[in] \
    \    ctx          Pointer to this instance's context\n        * \\param[in]  \
    \   ctrl_id      Algorithm-specific control\n        *                       \
    \      identifier\n        * \\param[in,out] data         Data to exchange with\
    \ algorithm\n        *                             instance.\n        *\n    \
    \    * \\retval #VPX_DEC_OK\n        *     The control request was processed.\n\
    \        * \\retval #VPX_DEC_ERROR\n        *     The control request was not\
    \ processed.\n        * \\retval #VPX_DEC_INVALID_PARAM\n        *     The data\
    \ was not valid.\n        */\n       vpx_dec_err_t vpx_dec_control(vpx_dec_ctx_t\
    \  *ctx,\n                                     int             ctrl_id,\n    \
    \                                 void           *data) DEPRECATED;\n       /*!\\\
    brief Decode data\n        *\n        * Processes a buffer of coded data.  If\
    \ the processing results\n        * in a new decoded frame becoming available,\n\
    \        * #VPX_DEC_CB_PUT_SLICE and #VPX_DEC_CB_PUT_FRAME events may be\n   \
    \     * generated, as appropriate.  Encoded data \\ref MUST be passed\n      \
    \  * in DTS (decode time stamp) order.  Frames produced will always\n        *\
    \ be in PTS (presentation time stamp) order.\n        *\n        * \\param[in]\
    \ ctx          Pointer to this instance's context\n        * \\param[in] data\
    \         Pointer to this block of new coded\n        *                      \
    \   data.  If NULL, a VPX_DEC_CB_PUT_FRAME\n        *                        \
    \ event is posted for the previously\n        *                         decoded\
    \ frame.\n        * \\param[in] data_sz      Size of the coded data, in bytes.\n\
    \        * \\param[in] user_priv    Application-specific data to associate\n \
    \       *                         with this frame.\n        * \\param[in] rel_pts\
    \      PTS relative to the previous frame, in\n        *                     \
    \    us.  If unknown or unavailable, set to\n        *                       \
    \  zero.\n        *\n        * \\return Returns #VPX_DEC_OK if the coded data\
    \ was processed\n        *         completely and future pictures can be decoded\
    \ without\n        *         error.  Otherwise, see the descriptions of the other\n\
    \        *         error codes in ::vpx_dec_err_t for recoverability\n       \
    \ *         capabilities.\n        */\n       vpx_dec_err_t vpx_dec_decode(\n\
    \           vpx_dec_ctx_t  *ctx,\n           uint8_t        *data,\n         \
    \  unsigned int    data_sz,\n           void           *user_priv,\n         \
    \  int             rel_pts) DEPRECATED;\n       /*!\\brief Decoded frames iterator\n\
    \        *\n        * Iterates over a list of the frames available for display.\
    \  The\n        * iterator storage should be initialized to NULL to start the\n\
    \        * iteration.  Iteration is complete when this function returns\n    \
    \    * NULL.\n        *\n        * The list of available frames becomes valid\
    \ upon completion of\n        * the vpx_dec_decode call, and remains valid until\
    \ the next call\n        * to vpx_dec_decode.\n        *\n        * \\param[in]\
    \     ctx      Pointer to this instance's context\n        * \\param[in out] iter\
    \     Iterator storage, initialized to NULL\n        *\n        * \\return Returns\
    \ a pointer to an image, if one is ready for\n        *         display.  Frames\
    \ produced will always be in PTS\n        *         (presentation time stamp)\
    \ order.\n        */\n       vpx_image_t *vpx_dec_get_frame(vpx_dec_ctx_t  *ctx,\n\
    \                                      vpx_dec_iter_t *iter) DEPRECATED;\n   \
    \    /*!\\defgroup cap_put_frame Frame-Based Decoding Functions\n        *\n \
    \       * The following functions are required to be implemented for all\n   \
    \     * decoders that advertise the VPX_DEC_CAP_PUT_FRAME capability.\n      \
    \  * Calling these functions for codecs that don't advertise this\n        * capability\
    \ will result in an error code being returned,\n        * usually VPX_DEC_ERROR\
    \ @{\n        */\n       /*!\\brief put frame callback prototype\n        *\n\
    \        * This callback is invoked by the decoder to notify the\n        * application\
    \ of the availability of decoded image data.\n        */\n       typedef void\
    \ (*vpx_dec_put_frame_cb_fn_t)(\n               void          *user_priv,\n  \
    \             const vpx_image_t *img);\n       /*!\\brief Register for notification\
    \ of frame completion.\n        *\n        * Registers a given function to be\
    \ called when a decoded frame\n        * is available.\n        *\n        * \\\
    param[in] ctx          Pointer to this instance's context\n        * \\param[in]\
    \ cb           Pointer to the callback function\n        * \\param[in] user_priv\
    \    User's private data\n        *\n        * \\retval #VPX_DEC_OK\n        *\
    \     Callback successfully registered.\n        * \\retval #VPX_DEC_ERROR\n \
    \       *     Decoder context not initialized, or algorithm not capable\n    \
    \    *     of posting slice completion.\n        */\n       vpx_dec_err_t vpx_dec_register_put_frame_cb(\n\
    \               vpx_dec_ctx_t             *ctx,\n               vpx_dec_put_frame_cb_fn_t\
    \  cb,\n               void                      *user_priv) DEPRECATED;\n   \
    \    /*!@} - end defgroup cap_put_frame */\n       /*!\\defgroup cap_put_slice\
    \ Slice-Based Decoding Functions\n        *\n        * The following functions\
    \ are required to be implemented for all\n        * decoders that advertise the\
    \ VPX_DEC_CAP_PUT_SLICE capability.\n        * Calling these functions for codecs\
    \ that don't advertise this\n        * capability will result in an error code\
    \ being returned,\n        * usually VPX_DEC_ERROR\n        * @{\n        */\n\
    \       /*!\\brief put slice callback prototype\n        *\n        * This callback\
    \ is invoked by the decoder to notify the\n        * application of the availability\
    \ of partially decoded image\n        * data.\n        */\n       typedef void\
    \ (*vpx_dec_put_slice_cb_fn_t)(void        *user_priv,\n               const vpx_image_t\
    \      *img,\n               const vpx_image_rect_t *valid,\n               const\
    \ vpx_image_rect_t *update);\n       /*!\\brief Register for notification of slice\
    \ completion.\n        *\n        * Registers a given function to be called when\
    \ a decoded slice\n        * is available.\n        *\n        * \\param[in] ctx\
    \          Pointer to this instance's context\n        * \\param[in] cb      \
    \     Pointer to the callback function\n        * \\param[in] user_priv    User's\
    \ private data\n        *\n        * \\retval #VPX_DEC_OK\n        *     Callback\
    \ successfully registered.\n        * \\retval #VPX_DEC_ERROR\n        *     Decoder\
    \ context not initialized, or algorithm not capable\n        *     of posting\
    \ slice completion.\n        */\n       vpx_dec_err_t vpx_dec_register_put_slice_cb(vpx_dec_ctx_t\
    \   *ctx,\n               vpx_dec_put_slice_cb_fn_t  cb,\n               void\
    \                      *user_priv) DEPRECATED;\n       /*!@} - end defgroup cap_put_slice*/\n\
    \       /*!\\defgroup cap_xma External Memory Allocation Functions\n        *\n\
    \        * The following functions are required to be implemented for all\n  \
    \      * decoders that advertise the VPX_DEC_CAP_XMA capability.\n        * Calling\
    \ these functions for codecs that don't advertise this\n        * capability will\
    \ result in an error code being returned,\n        * usually VPX_DEC_ERROR\n \
    \       * @{\n        */\n       /*!\\brief Memory Map Entry\n        *\n    \
    \    * This structure is used to contain the properties of a memory\n        *\
    \ segment.  It is populated by the decoder in the request phase,\n        * and\
    \ by the calling application once the requested allocation\n        * has been\
    \ performed.\n        */\n   #if 1\n   #define VPX_DEC_MEM_ZERO     0x1  /**<\
    \ Segment must be zeroed by\n                                          allocation\
    \ */\n   #define VPX_DEC_MEM_WRONLY   0x2  /**< Segment need not be\n        \
    \                                  readable */\n   #define VPX_DEC_MEM_FAST  \
    \   0x4  /**< Place in fast memory, if\n                                     \
    \     available */\n       typedef struct vpx_codec_mmap vpx_dec_mmap_t;\n   #else\n\
    \       typedef struct vpx_dec_mmap\n       {\n           /*\n            * The\
    \ following members are set by the codec when requesting\n            * a segment\n\
    \            */\n           unsigned int   id;     /**< identifier for the segment's\n\
    \                                       contents */\n           unsigned long\
    \  sz;     /**< size of the segment, in bytes */\n           unsigned int   align;\
    \  /**< required alignment of the\n                                       segment,\
    \ in bytes */\n           unsigned int   flags;  /**< bitfield containing segment\n\
    \                                       properties */\n   #define VPX_DEC_MEM_ZERO\
    \     0x1  /**< Segment must be zeroed by\n                                  \
    \        allocation */\n   #define VPX_DEC_MEM_WRONLY   0x2  /**< Segment need\
    \ not be\n                                          readable */\n   #define VPX_DEC_MEM_FAST\
    \     0x4  /**< Place in fast memory, if\n                                   \
    \       available */\n           /* The following members are to be filled in\
    \ by the\n            * allocation function */\n           void          *base;\
    \   /**< pointer to the allocated\n                                       segment\
    \ */\n           void (*dtor)(struct vpx_dec_mmap *map);  /**< destructor to\n\
    \                                                         call */\n          \
    \ void          *priv;   /**< allocator private storage */\n       } vpx_dec_mmap_t;\n\
    \   #endif\n       /*!\\brief Initialize a decoder instance in external allocation\n\
    \        * mode\n        *\n        * Initializes a decoder context using the\
    \ given interface.\n        * Applications should call the vpx_dec_xma_init convenience\n\
    \        * macro instead of this function directly, to ensure that the\n     \
    \   * ABI version number parameter is properly initialized.\n        *\n     \
    \   * \\param[in]    ctx     Pointer to this instance's context.\n        * \\\
    param[in]    iface   Pointer to the algorithm interface to\n        *        \
    \               use.\n        * \\param[in]    ver     ABI version number.  Must\
    \ be set to\n        *                       VPX_DECODER_ABI_VERSION\n       \
    \ * \\retval #VPX_DEC_OK\n        *     The decoder algorithm initialized.\n \
    \       * \\retval #VPX_DEC_ERROR\n        *     Decoder does not support XMA\
    \ mode.\n        */\n       vpx_dec_err_t vpx_dec_xma_init_ver(vpx_dec_ctx_t \
    \   *ctx,\n                                          vpx_dec_iface_t  *iface,\n\
    \                                          int           ver) DEPRECATED;\n  \
    \ #define vpx_dec_xma_init(ctx, iface) \\\n       vpx_dec_xma_init_ver(ctx, iface,\
    \ VPX_DECODER_ABI_VERSION)\n       /*!\\brief Iterate over the list of segments\
    \ to allocate.\n        *\n        * Iterates over a list of the segments to allocate.\
    \  The\n        * iterator storage should be initialized to NULL to start the\n\
    \        * iteration.  Iteration is complete when this function returns\n    \
    \    * VPX_DEC_LIST_END.  The amount of memory needed to allocate is\n       \
    \ * dependent upon the size of the encoded stream.  This means\n        * that\
    \ the stream info structure must be known at allocation\n        * time.  It can\
    \ be populated with the vpx_dec_peek_stream_info()\n        * function.  In cases\
    \ where the stream to be decoded is not\n        * available at allocation time,\
    \ a fixed size must be requested.\n        * The decoder will not be able to decode\
    \ streams larger than the\n        * size used at allocation time.\n        *\n\
    \        * \\param[in]      ctx     Pointer to this instance's context.\n    \
    \    * \\param[out]     mmap    Pointer to the memory map entry to\n        *\
    \                         populate.\n        * \\param[in]      si      Pointer\
    \ to the stream info.\n        * \\param[in out]  iter    Iterator storage, initialized\
    \ to NULL\n        *\n        * \\retval #VPX_DEC_OK\n        *     The memory\
    \ map entry was populated.\n        * \\retval #VPX_DEC_ERROR\n        *     Decoder\
    \ does not support XMA mode.\n        * \\retval #VPX_DEC_MEM_ERROR\n        *\
    \     Unable to determine segment size from stream info.\n        */\n       vpx_dec_err_t\
    \ vpx_dec_get_mem_map(\n           vpx_dec_ctx_t                *ctx,\n      \
    \     vpx_dec_mmap_t               *mmap,\n           const vpx_dec_stream_info_t\
    \  *si,\n           vpx_dec_iter_t               *iter) DEPRECATED;\n       /*!\\\
    brief Identify allocated segments to decoder instance\n        *\n        * Stores\
    \ a list of allocated segments in the decoder.  Segments\n        * \\ref MUST\
    \ be passed in the order they are read from\n        * vpx_dec_get_mem_map(),\
    \ but may be passed in groups of any\n        * size.  Segments \\ref MUST be\
    \ set only once.  The allocation\n        * function \\ref MUST ensure that the\
    \ vpx_dec_mmap_t::base member\n        * is non-NULL.  If the segment requires\
    \ cleanup handling (e.g.,\n        * calling free() or close()) then the vpx_dec_mmap_t::dtor\n\
    \        * member \\ref MUST be populated.\n        *\n        * \\param[in] \
    \     ctx       Pointer to this instance's context.\n        * \\param[in]   \
    \   mmaps     Pointer to the first memory map\n        *                     \
    \      entry in the list.\n        * \\param[in]      num_maps  Number of entries\
    \ being set at this\n        *                           time\n        *\n   \
    \     * \\retval #VPX_DEC_OK\n        *     The segment was stored in the decoder\
    \ context.\n        * \\retval #VPX_DEC_ERROR\n        *     Decoder does not\
    \ support XMA mode.\n        * \\retval #VPX_DEC_MEM_ERROR\n        *     Segment\
    \ base address was not set, or segment was already\n        * stored.\n      \
    \  */\n       vpx_dec_err_t  vpx_dec_set_mem_map(\n           vpx_dec_ctx_t  \
    \ *ctx,\n           vpx_dec_mmap_t  *mmaps,\n           unsigned int     num_maps)\
    \ DEPRECATED;\n       /*!@} - end defgroup cap_xma*/\n       /*!@} - end defgroup\
    \ decoder*/\n   #endif\n   #ifdef __cplusplus\n   }\n   #endif\n   ---- End code\
    \ block ----------------------------------------\n"
- title: 20.22.  vpx_image.c
  contents:
  - "20.22.  vpx_image.c\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    * Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n  \
    \  *\n    * Use of this source code is governed by a BSD-style license\n    *\
    \ that can be found in the LICENSE file in the root of the source\n    * tree.\
    \  An additional intellectual property rights grant can be\n    * found in the\
    \ file PATENTS.  All contributing project authors may\n    * be found in the AUTHORS\
    \ file in the root of the source tree.\n    */\n   #include <stdlib.h>\n   #include\
    \ <string.h>\n   #include \"vpx/vpx_image.h\"\n   static vpx_image_t *img_alloc_helper(vpx_image_t\
    \  *img,\n                                        vpx_img_fmt_t fmt,\n       \
    \                                 unsigned int  d_w,\n                       \
    \                 unsigned int  d_h,\n                                       \
    \ unsigned int  stride_align,\n                                        unsigned\
    \ char      *img_data)\n   {\n       unsigned int  h, w, s, xcs, ycs, bps;\n \
    \      int           align;\n       /* Treat align==0 like align==1 */\n     \
    \  if (!stride_align)\n           stride_align = 1;\n       /* Validate alignment\
    \ (must be power of 2) */\n       if (stride_align & (stride_align - 1))\n   \
    \        goto fail;\n       /* Get sample size for this format */\n       switch\
    \ (fmt)\n       {\n       case VPX_IMG_FMT_RGB32:\n       case VPX_IMG_FMT_RGB32_LE:\n\
    \       case VPX_IMG_FMT_ARGB:\n       case VPX_IMG_FMT_ARGB_LE:\n           bps\
    \ = 32;\n           break;\n       case VPX_IMG_FMT_RGB24:\n       case VPX_IMG_FMT_BGR24:\n\
    \           bps = 24;\n           break;\n       case VPX_IMG_FMT_RGB565:\n  \
    \     case VPX_IMG_FMT_RGB565_LE:\n       case VPX_IMG_FMT_RGB555:\n       case\
    \ VPX_IMG_FMT_RGB555_LE:\n       case VPX_IMG_FMT_UYVY:\n       case VPX_IMG_FMT_YUY2:\n\
    \       case VPX_IMG_FMT_YVYU:\n           bps = 16;\n           break;\n    \
    \   case VPX_IMG_FMT_I420:\n       case VPX_IMG_FMT_YV12:\n       case VPX_IMG_FMT_VPXI420:\n\
    \       case VPX_IMG_FMT_VPXYV12:\n           bps = 12;\n           break;\n \
    \      default:\n           bps = 16;\n           break;\n       }\n       /*\
    \ Get chroma shift values for this format */\n       switch (fmt)\n       {\n\
    \       case VPX_IMG_FMT_I420:\n       case VPX_IMG_FMT_YV12:\n       case VPX_IMG_FMT_VPXI420:\n\
    \       case VPX_IMG_FMT_VPXYV12:\n           xcs = 1;\n           break;\n  \
    \     default:\n           xcs = 0;\n           break;\n       }\n       switch\
    \ (fmt)\n       {\n       case VPX_IMG_FMT_I420:\n       case VPX_IMG_FMT_YV12:\n\
    \       case VPX_IMG_FMT_VPXI420:\n       case VPX_IMG_FMT_VPXYV12:\n        \
    \   ycs = 1;\n           break;\n       default:\n           ycs = 0;\n      \
    \     break;\n       }\n       /* Calculate storage sizes given the chroma subsampling\
    \ */\n       align = (1 << xcs) - 1;\n       w = (d_w + align) & ~align;\n   \
    \    align = (1 << ycs) - 1;\n       h = (d_h + align) & ~align;\n       s = (fmt\
    \ & VPX_IMG_FMT_PLANAR) ? w : bps * w / 8;\n       s = (s + stride_align - 1)\
    \ & ~(stride_align - 1);\n       /* Allocate the new image */\n       if (!img)\n\
    \       {\n           img = (vpx_image_t *)calloc(1, sizeof(vpx_image_t));\n \
    \          if (!img)\n               goto fail;\n           img->self_allocd =\
    \ 1;\n       }\n       else\n       {\n           memset(img, 0, sizeof(vpx_image_t));\n\
    \       }\n       img->img_data = img_data;\n       if (!img_data)\n       {\n\
    \           img->img_data = malloc((fmt & VPX_IMG_FMT_PLANAR) ?\n            \
    \ h * w * bps / 8 : h * s);\n           img->img_data_owner = 1;\n       }\n \
    \      if (!img->img_data)\n           goto fail;\n       img->fmt = fmt;\n  \
    \     img->w = w;\n       img->h = h;\n       img->x_chroma_shift = xcs;\n   \
    \    img->y_chroma_shift = ycs;\n       img->bps = bps;\n       /* Calculate strides\
    \ */\n       img->stride[VPX_PLANE_Y] = img->stride[VPX_PLANE_ALPHA] = s;\n  \
    \     img->stride[VPX_PLANE_U] = img->stride[VPX_PLANE_V] = s >> xcs;\n      \
    \ /* Default viewport to entire image */\n       if (!vpx_img_set_rect(img, 0,\
    \ 0, d_w, d_h))\n           return img;\n   fail:\n       vpx_img_free(img);\n\
    \       return NULL;\n   }\n   vpx_image_t *vpx_img_alloc(vpx_image_t  *img,\n\
    \                              vpx_img_fmt_t fmt,\n                          \
    \    unsigned int  d_w,\n                              unsigned int  d_h,\n  \
    \                            unsigned int  stride_align)\n   {\n       return\
    \ img_alloc_helper(img, fmt, d_w, d_h, stride_align, NULL);\n   }\n   vpx_image_t\
    \ *vpx_img_wrap(vpx_image_t  *img,\n                             vpx_img_fmt_t\
    \ fmt,\n                             unsigned int  d_w,\n                    \
    \         unsigned int  d_h,\n                             unsigned int  stride_align,\n\
    \                             unsigned char       *img_data)\n   {\n       return\
    \ img_alloc_helper(img, fmt, d_w, d_h, stride_align,\n         img_data);\n  \
    \ }\n   int vpx_img_set_rect(vpx_image_t  *img,\n                        unsigned\
    \ int  x,\n                        unsigned int  y,\n                        unsigned\
    \ int  w,\n                        unsigned int  h)\n   {\n       unsigned char\
    \      *data;\n       if (x + w <= img->w && y + h <= img->h)\n       {\n    \
    \       img->d_w = w;\n           img->d_h = h;\n           /* Calculate plane\
    \ pointers */\n           if (!(img->fmt & VPX_IMG_FMT_PLANAR))\n           {\n\
    \               img->planes[VPX_PLANE_PACKED] =\n                   img->img_data\
    \ + x * img->bps / 8 + y *\n                     img->stride[VPX_PLANE_PACKED];\n\
    \           }\n           else\n           {\n               data = img->img_data;\n\
    \               if (img->fmt & VPX_IMG_FMT_HAS_ALPHA)\n               {\n    \
    \               img->planes[VPX_PLANE_ALPHA] =\n                       data +\
    \ x + y * img->stride[VPX_PLANE_ALPHA];\n                   data += img->h * img->stride[VPX_PLANE_ALPHA];\n\
    \               }\n               img->planes[VPX_PLANE_Y] =\n               \
    \  data + x + y * img->stride[VPX_PLANE_Y];\n               data += img->h * img->stride[VPX_PLANE_Y];\n\
    \               if (!(img->fmt & VPX_IMG_FMT_UV_FLIP))\n               {\n   \
    \                img->planes[VPX_PLANE_U] = data\n                           \
    \               + (x >> img->x_chroma_shift)\n                               \
    \           + (y >> img->y_chroma_shift) *\n                                 \
    \           img->stride[VPX_PLANE_U];\n                   data += (img->h >> img->y_chroma_shift)\
    \ *\n                                            img->stride[VPX_PLANE_U];\n \
    \                  img->planes[VPX_PLANE_V] = data\n                         \
    \                 + (x >> img->x_chroma_shift)\n                             \
    \             + (y >> img->y_chroma_shift) *\n                               \
    \             img->stride[VPX_PLANE_V];\n               }\n               else\n\
    \               {\n                   img->planes[VPX_PLANE_V] = data\n      \
    \                                    + (x >> img->x_chroma_shift)\n          \
    \                                + (y >> img->y_chroma_shift) *\n            \
    \                                img->stride[VPX_PLANE_V];\n                 \
    \  data += (img->h >> img->y_chroma_shift) *\n                               \
    \             img->stride[VPX_PLANE_V];\n                   img->planes[VPX_PLANE_U]\
    \ = data\n                                          + (x >> img->x_chroma_shift)\n\
    \                                          + (y >> img->y_chroma_shift) *\n  \
    \                                          img->stride[VPX_PLANE_U];\n       \
    \        }\n           }\n           return 0;\n       }\n       return -1;\n\
    \   }\n   void vpx_img_flip(vpx_image_t *img)\n   {\n       /* Note: In the calculation\
    \ pointer adjustment calculation, we\n        * want the rhs to be promoted to\
    \ a signed type.  Section 6.3.1.8\n        * of the ISO C99 standard [ISO-C99]\
    \ indicates that if the\n        * adjustment parameter is unsigned, the stride\
    \ parameter will be\n        * promoted to unsigned, causing errors when the lhs\
    \ is a larger\n        * type than the rhs.\n        */\n       img->planes[VPX_PLANE_Y]\
    \ += (signed)\n         (img->d_h - 1) * img->stride[VPX_PLANE_Y];\n       img->stride[VPX_PLANE_Y]\
    \ = -img->stride[VPX_PLANE_Y];\n       img->planes[VPX_PLANE_U] += (signed)\n\
    \         ((img->d_h >> img->y_chroma_shift) - 1)\n                          \
    \     * img->stride[VPX_PLANE_U];\n       img->stride[VPX_PLANE_U] = -img->stride[VPX_PLANE_U];\n\
    \       img->planes[VPX_PLANE_V] += (signed)\n                               ((img->d_h\
    \ >> img->y_chroma_shift) - 1) *\n                               img->stride[VPX_PLANE_V];\n\
    \       img->stride[VPX_PLANE_V] = -img->stride[VPX_PLANE_V];\n       img->planes[VPX_PLANE_ALPHA]\
    \ += (signed)\n         (img->d_h - 1) * img->stride[VPX_PLANE_ALPHA];\n     \
    \  img->stride[VPX_PLANE_ALPHA] = -img->stride[VPX_PLANE_ALPHA];\n   }\n   void\
    \ vpx_img_free(vpx_image_t *img)\n   {\n       if (img)\n       {\n          \
    \ if (img->img_data && img->img_data_owner)\n               free(img->img_data);\n\
    \           if (img->self_allocd)\n               free(img);\n       }\n   }\n\
    \   ---- End code block ----------------------------------------\n"
- title: 20.23.  vpx_image.h
  contents:
  - "20.23.  vpx_image.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    * Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n  \
    \  *\n    * Use of this source code is governed by a BSD-style license\n    *\
    \ that can be found in the LICENSE file in the root of the source\n    * tree.\
    \  An additional intellectual property rights grant can be\n    * found in the\
    \ file PATENTS.  All contributing project authors may\n    * be found in the AUTHORS\
    \ file in the root of the source tree.\n    */\n   /*!\\file\n    * \\brief Describes\
    \ the vpx image descriptor and associated\n    * operations\n    *\n    */\n \
    \  #ifdef __cplusplus\n   extern \"C\" {\n   #endif\n   #ifndef VPX_IMAGE_H\n\
    \   #define VPX_IMAGE_H\n       /*!\\brief Current ABI version number\n      \
    \  *\n        * \\internal\n        * If this file is altered in any way that\
    \ changes the ABI, this\n        * value must be bumped.  Examples include, but\
    \ are not limited\n        * to, changing types, removing or reassigning enums,\n\
    \        * adding/removing/rearranging fields to structures\n        */\n   #define\
    \ VPX_IMAGE_ABI_VERSION (1) /**<\\hideinitializer*/\n   #define VPX_IMG_FMT_PLANAR\
    \     0x100  /**< Image is a planar\n                                        \
    \      format */\n   #define VPX_IMG_FMT_UV_FLIP    0x200  /**< V plane precedes\
    \ U plane\n                                              in memory */\n   #define\
    \ VPX_IMG_FMT_HAS_ALPHA  0x400  /**< Image has an alpha channel\n            \
    \                                  component */\n       /*!\\brief List of supported\
    \ image formats */\n       typedef enum vpx_img_fmt {\n           VPX_IMG_FMT_NONE,\n\
    \           VPX_IMG_FMT_RGB24,      /**< 24 bit per pixel packed RGB */\n    \
    \       VPX_IMG_FMT_RGB32,      /**< 32 bit per pixel packed 0RGB */\n       \
    \    VPX_IMG_FMT_RGB565,     /**< 16 bit per pixel, 565 */\n           VPX_IMGFMT_RGB555,\
    \      /**< 16 bit per pixel, 555 */\n           VPX_IMG_FMT_UYVY,       /**<\
    \ UYVY packed YUV */\n           VPX_IMG_FMT_YUY2,       /**< YUYV packed YUV\
    \ */\n           VPX_IMG_FMT_YVYU,       /**< YVYU packed YUV */\n           VPX_IMG_FMT_BGR24,\
    \      /**< 24 bit per pixel packed BGR */\n           VPX_IMG_FMT_RGB32_LE, \
    \  /**< 32 bit packed BGR0 */\n           VPX_IMG_FMT_ARGB,       /**< 32 bit\
    \ packed ARGB, alpha=255 */\n           VPX_IMG_FMT_ARGB_LE,    /**< 32 bit packed\
    \ BGRA, alpha=255 */\n           VPX_IMG_FMT_RGB565_LE,  /**< 16 bit per pixel,\n\
    \                                        gggbbbbb rrrrrggg */\n           VPX_IMG_FMT_RGB555_LE,\
    \  /**< 16 bit per pixel,\n                                        gggbbbbb 0rrrrrgg\
    \ */\n           VPX_IMG_FMT_YV12    = VPX_IMG_FMT_PLANAR |\n             VPX_IMG_FMT_UV_FLIP\
    \ | 1, /**< planar YVU */\n           VPX_IMG_FMT_I420    = VPX_IMG_FMT_PLANAR\
    \ | 2,\n           VPX_IMG_FMT_VPXYV12 = VPX_IMG_FMT_PLANAR |\n             VPX_IMG_FMT_UV_FLIP\
    \ | 3, /** < planar 4:2:0 format with\n                                      \
    \      vpx color space */\n           VPX_IMG_FMT_VPXI420 = VPX_IMG_FMT_PLANAR\
    \ | 4   /** < planar\n             4:2:0 format with vpx color space */\n    \
    \   }\n       vpx_img_fmt_t; /**< alias for enum vpx_img_fmt */\n   #if !defined(VPX_CODEC_DISABLE_COMPAT)\
    \ || !VPX_CODEC_DISABLE_COMPAT\n   /** \\deprecated Use #VPX_IMG_FMT_PLANAR */\n\
    \   #define IMG_FMT_PLANAR         VPX_IMG_FMT_PLANAR\n   /** \\deprecated Use\
    \ #VPX_IMG_FMT_UV_FLIP */\n   #define IMG_FMT_UV_FLIP        VPX_IMG_FMT_UV_FLIP\n\
    \   /** \\deprecated Use #VPX_IMG_FMT_HAS_ALPHA */\n   #define IMG_FMT_HAS_ALPHA\
    \      VPX_IMG_FMT_HAS_ALPHA\n       /*!\\brief Deprecated list of supported image\
    \ formats\n        * \\deprecated New code should use #vpx_img_fmt\n        */\n\
    \   #define img_fmt   vpx_img_fmt\n       /*!\\brief alias for enum img_fmt.\n\
    \        * \\deprecated New code should use #vpx_img_fmt_t\n        */\n   #define\
    \ img_fmt_t vpx_img_fmt_t\n   /** \\deprecated Use #VPX_IMG_FMT_NONE */\n   #define\
    \ IMG_FMT_NONE       VPX_IMG_FMT_NONE\n   /** \\deprecated Use #VPX_IMG_FMT_RGB24\
    \ */\n   #define IMG_FMT_RGB24      VPX_IMG_FMT_RGB24\n   /** \\deprecated Use\
    \ #VPX_IMG_FMT_RGB32 */\n   #define IMG_FMT_RGB32      VPX_IMG_FMT_RGB32\n   /**\
    \ \\deprecated Use #VPX_IMG_FMT_RGB565 */\n   #define IMG_FMT_RGB565     VPX_IMG_FMT_RGB565\n\
    \   /** \\deprecated Use #VPX_IMG_FMT_RGB555 */\n   #define IMG_FMT_RGB555   \
    \  VPX_IMG_FMT_RGB555\n   /** \\deprecated Use #VPX_IMG_FMT_UYVY */\n   #define\
    \ IMG_FMT_UYVY       VPX_IMG_FMT_UYVY\n   /** \\deprecated Use #VPX_IMG_FMT_YUY2\
    \ */\n   #define IMG_FMT_YUY2       VPX_IMG_FMT_YUY2\n   /** \\deprecated Use\
    \ #VPX_IMG_FMT_YVYU */\n   #define IMG_FMT_YVYU       VPX_IMG_FMT_YVYU\n   /**\
    \ \\deprecated Use #VPX_IMG_FMT_BGR24 */\n   #define IMG_FMT_BGR24      VPX_IMG_FMT_BGR24\n\
    \   /**< \\deprecated Use #VPX_IMG_FMT_RGB32_LE */\n   #define IMG_FMT_RGB32_LE\
    \   VPX_IMG_FMT_RGB32_LE\n   /** \\deprecated Use #VPX_IMG_FMT_ARGB */\n   #define\
    \ IMG_FMT_ARGB       VPX_IMG_FMT_ARGB\n   /** \\deprecated Use #VPX_IMG_FMT_ARGB_LE\
    \ */\n   #define IMG_FMT_ARGB_LE    VPX_IMG_FMT_ARGB_LE\n   /** \\deprecated Use\
    \ #VPX_IMG_FMT_RGB565_LE */\n   #define IMG_FMT_RGB565_LE  VPX_IMG_FMT_RGB565_LE\n\
    \   /** \\deprecated Use #VPX_IMG_FMT_RGB555_LE */\n   #define IMG_FMT_RGB555_LE\
    \  VPX_IMG_FMT_RGB555_LE\n   /** \\deprecated Use #VPX_IMG_FMT_YV12 */\n   #define\
    \ IMG_FMT_YV12       VPX_IMG_FMT_YV12\n   /** \\deprecated Use #VPX_IMG_FMT_I420\
    \ */\n   #define IMG_FMT_I420       VPX_IMG_FMT_I420\n   /** \\deprecated Use\
    \ #VPX_IMG_FMT_VPXYV12 */\n   #define IMG_FMT_VPXYV12    VPX_IMG_FMT_VPXYV12\n\
    \   /** \\deprecated Use #VPX_IMG_FMT_VPXI420 */\n   #define IMG_FMT_VPXI420 \
    \   VPX_IMG_FMT_VPXI420\n   #endif /* VPX_CODEC_DISABLE_COMPAT */\n       /**\\\
    brief Image Descriptor */\n       typedef struct vpx_image\n       {\n       \
    \    vpx_img_fmt_t fmt; /**< Image Format */\n           /* Image storage dimensions\
    \ */\n           unsigned int  w;   /**< Stored image width */\n           unsigned\
    \ int  h;   /**< Stored image height */\n           /* Image display dimensions\
    \ */\n           unsigned int  d_w;   /**< Displayed image width */\n        \
    \   unsigned int  d_h;   /**< Displayed image height */\n           /* Chroma\
    \ subsampling info */\n           unsigned int  x_chroma_shift;   /**< subsampling\
    \ order, X */\n           unsigned int  y_chroma_shift;   /**< subsampling order,\
    \ Y */\n           /* Image data pointers. */\n   #define VPX_PLANE_PACKED 0 \
    \ /**< To be used for all packed formats */\n   #define VPX_PLANE_Y      0  /**<\
    \ Y (Luminance) plane */\n   #define VPX_PLANE_U      1  /**< U (Chroma) plane\
    \ */\n   #define VPX_PLANE_V      2  /**< V (Chroma) plane */\n   #define VPX_PLANE_ALPHA\
    \  3  /**< A (Transparency) plane */\n   #if !defined(VPX_CODEC_DISABLE_COMPAT)\
    \ || !VPX_CODEC_DISABLE_COMPAT\n   #define PLANE_PACKED     VPX_PLANE_PACKED\n\
    \   #define PLANE_Y          VPX_PLANE_Y\n   #define PLANE_U          VPX_PLANE_U\n\
    \   #define PLANE_V          VPX_PLANE_V\n   #define PLANE_ALPHA      VPX_PLANE_ALPHA\n\
    \   #endif\n           unsigned char *planes[4];  /**< pointer to the top-left\
    \ pixel\n           q                               for each plane */\n      \
    \     int    stride[4];  /**< stride between rows for each plane */\n        \
    \   int    bps; /**< bits per sample (for packed formats) */\n           /* The\
    \ following member may be set by the application to\n            * associate data\
    \ with this image.\n            */\n           void   *user_priv; /**< may be\
    \ set by the application to\n                                    associate data\
    \ with this image. */\n           /* The following members should be treated as\
    \ private. */\n           unsigned char *img_data;       /**< private */\n   \
    \        int      img_data_owner; /**< private */\n           int      self_allocd;\
    \    /**< private */\n       } vpx_image_t; /**< alias for struct vpx_image */\n\
    \       /**\\brief Representation of a rectangle on a surface */\n       typedef\
    \ struct vpx_image_rect\n       {\n           unsigned int x; /**< leftmost column\
    \ */\n           unsigned int y; /**< topmost row */\n           unsigned int\
    \ w; /**< width */\n           unsigned int h; /**< height */\n       } vpx_image_rect_t;\
    \ /**< alias for struct vpx_image_rect */\n       /*!\\brief Open a descriptor,\
    \ allocating storage for the\n        * underlying image\n        *\n        *\
    \ Returns a descriptor for storing an image of the given format.\n        * The\
    \ storage for the descriptor is allocated on the heap.\n        *\n        * \\\
    param[in]    img       Pointer to storage for descriptor.\n        *         \
    \                If this parameter is NULL, the storage\n        *           \
    \              for the descriptor will be allocated\n        *               \
    \          on the heap.\n        * \\param[in]    fmt       Format for the image\n\
    \        * \\param[in]    d_w       Width of the image\n        * \\param[in]\
    \    d_h       Height of the image\n        * \\param[in]    align     Alignment,\
    \ in bytes, of each row in\n        *                         the image.\n   \
    \     *\n        * \\return Returns a pointer to the initialized image descriptor.\n\
    \        *         If the img parameter is non-null, the value of the img\n  \
    \      *         parameter will be returned.\n        */\n       vpx_image_t *vpx_img_alloc(vpx_image_t\
    \  *img,\n                                  vpx_img_fmt_t fmt,\n             \
    \                     unsigned int d_w,\n                                  unsigned\
    \ int d_h,\n                                  unsigned int align);\n       /*!\\\
    brief Open a descriptor, using existing storage for the\n        * underlying\
    \ image\n        *\n        * Returns a descriptor for storing an image of the\
    \ given format.\n        * The storage for descriptor has been allocated elsewhere,\
    \ and a\n        * descriptor is desired to \"wrap\" that storage.\n        *\n\
    \        * \\param[in]    img       Pointer to storage for descriptor.\n     \
    \   *                         If this parameter is NULL, the storage\n       \
    \ *                         for the descriptor will be\n        *            \
    \             allocated on the heap.\n        * \\param[in]    fmt       Format\
    \ for the image\n        * \\param[in]    d_w       Width of the image\n     \
    \   * \\param[in]    d_h       Height of the image\n        * \\param[in]    align\
    \     Alignment, in bytes, of each row in\n        *                         the\
    \ image.\n        * \\param[in]    img_data  Storage to use for the image\n  \
    \      *\n        * \\return Returns a pointer to the initialized image descriptor.\n\
    \        *         If the img parameter is non-null, the value of the img\n  \
    \      *         parameter will be returned.\n        */\n       vpx_image_t *vpx_img_wrap(vpx_image_t\
    \  *img,\n                                 vpx_img_fmt_t fmt,\n              \
    \                   unsigned int d_w,\n                                 unsigned\
    \ int d_h,\n                                 unsigned int align,\n           \
    \                      unsigned char      *img_data);\n       /*!\\brief Set the\
    \ rectangle identifying the displayed portion of\n        * the image\n      \
    \  *\n        * Updates the displayed rectangle (aka viewport) on the image\n\
    \        * surface to match the specified coordinates and size.\n        *\n \
    \       * \\param[in]    img       Image descriptor\n        * \\param[in]   \
    \ x         leftmost column\n        * \\param[in]    y         topmost row\n\
    \        * \\param[in]    w         width\n        * \\param[in]    h        \
    \ height\n        *\n        * \\return 0 if the requested rectangle is valid,\
    \ non-zero\n        * otherwise.\n        */\n       int vpx_img_set_rect(vpx_image_t\
    \  *img,\n                            unsigned int  x,\n                     \
    \       unsigned int  y,\n                            unsigned int  w,\n     \
    \                       unsigned int  h);\n       /*!\\brief Flip the image vertically\
    \ (top for bottom)\n        *\n        * Adjusts the image descriptor's pointers\
    \ and strides to make\n        * the image be referenced upside-down.\n      \
    \  *\n        * \\param[in]    img       Image descriptor\n        */\n      \
    \ void vpx_img_flip(vpx_image_t *img);\n       /*!\\brief Close an image descriptor\n\
    \        *\n        * Frees all allocated storage associated with an image\n \
    \       * descriptor.\n        *\n        * \\param[in]    img       Image descriptor\n\
    \        */\n       void vpx_img_free(vpx_image_t *img);\n   #endif\n   #ifdef\
    \ __cplusplus\n   }\n   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.24.  vpx_integer.h
  contents:
  - "20.24.  vpx_integer.h\n   ---- Begin code block --------------------------------------\n\
    \   /*\n    *  Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n \
    \   *\n    *  Use of this source code is governed by a BSD-style license\n   \
    \ *  that can be found in the LICENSE file in the root of the source\n    *  tree.\
    \  An additional intellectual property rights grant can be\n    *  found in the\
    \ file PATENTS.  All contributing project authors may\n    *  be found in the\
    \ AUTHORS file in the root of the source tree.\n    */\n   #ifndef VPX_INTEGER_H\n\
    \   #define VPX_INTEGER_H\n   /* get ptrdiff_t, size_t, wchar_t, NULL */\n   #include\
    \ <stddef.h>\n   #if defined(_MSC_VER) || defined(VPX_EMULATE_INTTYPES)\n   typedef\
    \ signed char  int8_t;\n   typedef signed short int16_t;\n   typedef signed int\
    \   int32_t;\n   typedef unsigned char  uint8_t;\n   typedef unsigned short uint16_t;\n\
    \   typedef unsigned int   uint32_t;\n   #if defined(_MSC_VER)\n   typedef signed\
    \ __int64   int64_t;\n   typedef unsigned __int64 uint64_t;\n   #define PRId64\
    \ \"I64d\"\n   #endif\n   #ifdef HAVE_ARMV6\n   typedef unsigned int int_fast16_t;\n\
    \   #else\n   typedef signed short int_fast16_t;\n   #endif\n   typedef signed\
    \ char int_fast8_t;\n   typedef unsigned char uint_fast8_t;\n   #ifndef _UINTPTR_T_DEFINED\n\
    \   typedef unsigned int   uintptr_t;\n   #endif\n   #else\n   /* Most platforms\
    \ have the C99 standard integer types. */\n   #if defined(__cplusplus) && !defined(__STDC_FORMAT_MACROS)\n\
    \   #define __STDC_FORMAT_MACROS\n   #endif\n   #include <stdint.h>\n   #include\
    \ <inttypes.h>\n   #endif\n   #endif\n   ---- End code block ----------------------------------------\n"
- title: 20.25.  AUTHORS File
  contents:
  - "20.25.  AUTHORS File\n   Aaron Watry <awatry@gmail.com>\n   Adrian Grange <agrange@google.com>\n\
    \   Alex Converse <alex.converse@gmail.com>\n   Andoni Morales Alastruey <ylatuya@gmail.com>\n\
    \   Andres Mejia <mcitadel@gmail.com>\n   Attila Nagy <attilanagy@google.com>\n\
    \   Fabio Pedretti <fabio.ped@libero.it>\n   Frank Galligan <fgalligan@google.com>\n\
    \   Fredrik Soederquist <fs@opera.com>\n   Fritz Koenig <frkoenig@google.com>\n\
    \   Gaute Strokkenes <gaute.strokkenes@broadcom.com>\n   Giuseppe Scrivano <gscrivano@gnu.org>\n\
    \   Guillermo Ballester Valor <gbvalor@gmail.com>\n   Henrik Lundin <hlundin@google.com>\n\
    \   James Berry <jamesberry@google.com>\n   James Zern <jzern@google.com>\n  \
    \ Jan Kratochvil <jan.kratochvil@redhat.com>\n   Jeff Muizelaar <jmuizelaar@mozilla.com>\n\
    \   Jim Bankoski <jimbankoski@google.com>\n   Johann Koenig <johannkoenig@google.com>\n\
    \   John Koleszar <jkoleszar@google.com>\n   Justin Clift <justin@salasaga.org>\n\
    \   Justin Lebar <justin.lebar@gmail.com>\n   Luca Barbato <lu_zero@gentoo.org>\n\
    \   Makoto Kato <makoto.kt@gmail.com>\n   Martin Ettl <ettl.martin78@googlemail.com>\n\
    \   Michael Kohler <michaelkohler@live.com>\n   Mikhal Shemer <mikhal@google.com>\n\
    \   Pascal Massimino <pascal.massimino@gmail.com>\n   Patrik Westin <patrik.westin@gmail.com>\n\
    \   Paul Wilkins <paulwilkins@google.com>\n   Pavol Rusnak <stick@gk2.sk>\n  \
    \ Philip Jaegenstedt <philipj@opera.com>\n   Scott LaVarnway <slavarnway@google.com>\n\
    \   Tero Rintaluoma <teror@google.com>\n   Timothy B. Terriberry <tterribe@xiph.org>\n\
    \   Tom Finegan <tomfinegan@google.com>\n   Yaowu Xu <yaowu@google.com>\n   Yunqing\
    \ Wang <yunqingwang@google.com>\n   Google Inc.\n   The Mozilla Foundation\n \
    \  The Xiph.Org Foundation\n"
- title: 20.26.  LICENSE
  contents:
  - "20.26.  LICENSE\n   Copyright (c) 2010, 2011, Google Inc.  All rights reserved.\n\
    \   Redistribution and use in source and binary forms, with or without\n   modification,\
    \ are permitted provided that the following conditions\n   are met:\n   o  Redistributions\
    \ of source code must retain the above copyright\n      notice, this list of conditions\
    \ and the following disclaimer.\n   o  Redistributions in binary form must reproduce\
    \ the above copyright\n      notice, this list of conditions and the following\
    \ disclaimer in\n      the documentation and/or other materials provided with\
    \ the\n      distribution.\n   o  Neither the name of Google nor the names of\
    \ its contributors may\n      be used to endorse or promote products derived from\
    \ this software\n      without specific prior written permission.\n   THIS SOFTWARE\
    \ IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n   \"AS IS\" AND ANY\
    \ EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n   LIMITED TO, THE IMPLIED\
    \ WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n   A PARTICULAR PURPOSE ARE DISCLAIMED.\
    \  IN NO EVENT SHALL THE COPYRIGHT\n   HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY\
    \ DIRECT, INDIRECT,\n   INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\
    \ (INCLUDING,\n   BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\
    \ LOSS\n   OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED\n\
    \   AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n   LIABILITY,\
    \ OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY\n   WAY OUT OF THE\
    \ USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n   POSSIBILITY OF SUCH DAMAGE.\n"
- title: 20.27.  PATENTS
  contents:
  - "20.27.  PATENTS\n   Additional IP Rights Grant (Patents)\n   \"This implementation\"\
    \ means the copyrightable works distributed by\n   Google as part of the WebM\
    \ Project.\n   Google hereby grants to you a perpetual, worldwide, non-exclusive,\n\
    \   no-charge, royalty-free, irrevocable (except as stated in this\n   section)\
    \ patent license to make, have made, use, offer to sell, sell,\n   import, transfer,\
    \ and otherwise run, modify and propagate the\n   contents of this implementation\
    \ of VP8, where such license applies\n   only to those patent claims, both currently\
    \ owned by Google and\n   acquired in the future, licensable by Google that are\
    \ necessarily\n   infringed by this implementation of VP8.  This grant does not\
    \ include\n   claims that would be infringed only as a consequence of further\n\
    \   modification of this implementation.  If you or your agent or\n   exclusive\
    \ licensee institute or order or agree to the institution of\n   patent litigation\
    \ against any entity (including a cross-claim or\n   counterclaim in a lawsuit)\
    \ alleging that this implementation of VP8\n   or any code incorporated within\
    \ this implementation of VP8\n   constitutes direct or contributory patent infringement,\
    \ or inducement\n   of patent infringement, then any patent rights granted to\
    \ you under\n   this License for this implementation of VP8 shall terminate as\
    \ of the\n   date such litigation is filed.\n"
- title: 21.  Security Considerations
  contents:
  - "21.  Security Considerations\n   A VP8 decoder should take appropriate security\
    \ considerations into\n   account, as outlined in [RFC4732] and [RFC3552].  It\
    \ is extremely\n   important that a decoder be robust against malicious payloads.\n\
    \   Malicious payloads must not cause the decoder to overrun its\n   allocated\
    \ memory or to consume inordinate resources.  Although\n   encoder issues are\
    \ typically rarer, the same applies to an encoder.\n   Malicious stream data must\
    \ not cause the encoder to misbehave, as\n   this might allow an attacker access\
    \ to transcoding gateways.\n"
- title: 22.  References
  contents:
  - '22.  References

    '
- title: 22.1.  Normative Reference
  contents:
  - "22.1.  Normative Reference\n   [RFC2119]   Bradner, S., \"Key words for use in\
    \ RFCs to Indicate\n               Requirement Levels\", BCP 14, RFC 2119, March\
    \ 1997.\n"
- title: 22.2.  Informative References
  contents:
  - "22.2.  Informative References\n   [Bell]      Bell, T., Cleary, J., and I. Witten,\
    \ \"Text Compression\",\n               1990.\n   [ISO-C99]   International Organization\
    \ for Standardization,\n               \"Information technology --  Programming\
    \ languages -- C\",\n               ISO/IEC 9899:1999, 1999.\n   [ITU-R_BT.601]\n\
    \               International Telecommunication Union, \"ITU BT.601-7:\n     \
    \          Studio encoding parameters of digital television for\n            \
    \   standard 4:3 and wide screen 16:9 aspect ratios\",\n               March 2011.\n\
    \   [Kernighan] Kernighan, B. and D. Ritchie, \"The C Programming Language\n \
    \              (2nd edition)\", April 1988.\n   [Loeffler]  Loeffler, C., Ligtenberg\
    \ , A., and G. Moschytz,\n               \"Practical Fast 1-D DCT Algorithms with\
    \ 11\n               Multiplications\", May 1989.\n   [RFC3552]   Rescorla, E.\
    \ and B. Korver, \"Guidelines for Writing RFC\n               Text on Security\
    \ Considerations\", BCP 72, RFC 3552,\n               July 2003.\n   [RFC4732]\
    \   Handley, M., Ed., Rescorla, E., Ed., and IAB, \"Internet\n               Denial-of-Service\
    \ Considerations\", RFC 4732,\n               December 2006.\n   [Shannon]   Shannon,\
    \ C., \"A Mathematical Theory of Communication\",\n               Bell System\
    \ Technical Journal Vol. 27, pp. 379-423 and\n               623-656, July and\
    \ October 1948.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   James Bankoski\n   Google Inc.\n   EMail: jimbankoski@google.com\n\
    \   John Koleszar\n   Google Inc.\n   EMail: jkoleszar@google.com\n   Lou Quillio\n\
    \   Google Inc.\n   EMail: louquillio@google.com\n   Janne Salonen\n   Google\
    \ Inc.\n   EMail: jsalonen@google.com\n   Paul Wilkins\n   Google Inc.\n   EMail:\
    \ paulwilkins@google.com\n   Yaowu Xu\n   Google Inc.\n   EMail: yaowu@google.com\n"
