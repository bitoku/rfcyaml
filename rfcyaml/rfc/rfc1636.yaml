- title: __initial_text__
  contents:
  - "                       Report of IAB Workshop on\n                 Security in\
    \ the Internet Architecture\n                          February 8-10, 1994\n"
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  This memo\n   does not specify an Internet standard of any kind.  Distribution\
    \ of\n   this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document is a report on an Internet architecture workshop,\n\
    \   initiated by the IAB and held at USC Information Sciences Institute\n   on\
    \ February 8-10, 1994.  This workshop generally focused on security\n   issues\
    \ in the Internet architecture.\n   This document should be regarded as a set\
    \ of working notes containing\n   ideas about security that were developed by\
    \ Internet experts in a\n   broad spectrum of areas, including routing, mobility,\
    \ realtime\n   service, and provider requirements, as well as security.  It contains\n\
    \   some significant diversity of opinions on some important issues.\n   This\
    \ memo is offered as one input in the process of developing viable\n   security\
    \ mechanisms and procedures for the Internet.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. INTRODUCTION ..................................................\
    \  2\n   2. OVERVIEW ......................................................  4\n\
    \      2.1  Strategic and Political Issues ...........................  4\n  \
    \    2.2  Security Issues ..........................................  4\n    \
    \  2.3  DNS Names for Certificates ...............................  7\n   3. FIREWALL\
    \ ARCHITECTURE .........................................  9\n      3.1  Introduction\
    \ .............................................  9\n      3.2  Application-Layer\
    \ Firewalls .............................. 11\n      3.3  IP-Layer Firewalls .......................................\
    \ 12\n   4. SECURE QOS FORWARDING ......................................... 21\n\
    \      4.1  The Requirement for Setup ................................ 21\n  \
    \    4.2  Securing the Setup Process. .............................. 22\n    \
    \  4.3  Validating an LLID ....................................... 24\n      4.4\
    \  Dynamics of Setup ........................................ 28\n      4.5  Receiver-Initiated\
    \ Setup ................................. 30\n      4.6  Other Issues .............................................\
    \ 30\n   5. AN AUTHENTICATION SERVICE ..................................... 35\n\
    \      5.1  Names and Credentials .................................... 36\n  \
    \    5.2  Identity-Based Authorization ............................. 37\n    \
    \  5.3  Choosing Credentials ..................................... 38\n   6. OTHER\
    \ ISSUES .................................................. 39\n      6.1  Privacy\
    \ and Authentication of Multicast Groups ........... 39\n      6.2  Secure Plug-and-Play\
    \ a Must .............................. 41\n      6.3  A Short-Term Confidentiality\
    \ Mechanism ................... 42\n   7. CONCLUSIONS ...................................................\
    \ 44\n      7.1  Suggested Short-Term Actions ............................. 44\n\
    \      7.2  Suggested Medium-Term Actions ............................ 46\n  \
    \    7.3  Suggested Long-Term Actions .............................. 46\n   APPENDIX\
    \ A -- Workshop Organization .............................. 48\n   Security Considerations\
    \ .......................................... 52\n   Authors' Addresses ...............................................\
    \ 52\n"
- title: 1. INTRODUCTION
  contents:
  - "1. INTRODUCTION\n   The Internet Architecture Board (IAB) holds occasional workshops\n\
    \   designed to consider long-term issues and strategies for the\n   Internet,\
    \ and to suggest future directions for the Internet\n   architecture.  This long-term\
    \ planning function of the IAB is\n   complementary to the ongoing engineering\
    \ efforts performed by working\n   groups of the Internet Engineering Task Force\
    \ (IETF), under the\n   leadership of the Internet Engineering Steering Group\
    \ (IESG) and area\n   directorates.\n   An IAB-initiated workshop on the role\
    \ of security in the Internet\n   Architecture was held on February 8-10, 1994\
    \ at the Information\n   Sciences Institute of the University of Southern California,\
    \ in\n   Marina del Rey, California.  This RFC reports the results of the\n  \
    \ workshop.\n   In addition to the IAB members, attendees at this meeting included\n\
    \   the IESG Area Directors for the relevant areas (Internet, Transport,\n   Security,\
    \ and IPng) and a group of 15 other experts in the following\n   areas:  IPng,\
    \ routing, mobility, realtime service, and security (see\n   Appendix for a list\
    \ of attendees).  The IAB explicitly tried to\n   balance the number of attendees\
    \ from each area of expertise.\n   Logistics limited the attendance to about 30,\
    \ which unfortunately\n   meant that many highly qualified experts were omitted\
    \ from the\n   invitation list.\n   In summary, the objectives of this workshop\
    \ were (1) to explore the\n   interconnections between security and the rest of\
    \ the Internet\n   architecture, and (2) to develop recommendations for the Internet\n\
    \   community on future directions with respect to security.  These\n   objectives\
    \ arose from a conviction in the IAB that the two most\n   important problem areas\
    \ for the Internet architecture are scaling and\n   security.  While the scaling\
    \ problems have led to a flood of\n   activities on IPng, there has been less\
    \ effort devoted to security.\n   Although some came to the workshop eager to\
    \ discuss short-term\n   security issues in the Internet, the workshop program\
    \ was designed to\n   focus more on long-term issues and broad principles.  Thus,\
    \ the\n   meeting began with the following ground rule: valid topics of\n   discussion\
    \ should involve both security and at least one from the\n   list: (a) routing\
    \ (unicast and multicast), (b) mobility, and (c)\n   realtime service.  As a basis\
    \ for initial discussion, the invitees\n   met via email to generate a set of\
    \ scenarios (see Appendix)\n   satisfying this ground rule.\n   The 30 attendees\
    \ were divided into three \"breakout\" groups, with each\n   group including experts\
    \ in all the areas.  The meeting was then\n   structured as plenary meetings alternating\
    \ with parallel breakout\n   group sessions (see the agenda in Appendix).  On\
    \ the third day, the\n   groups produced text summarizing the results of their\
    \ discussions.\n   This memo is composed of that text, somewhat rearranged and\
    \ edited\n   into a single document.\n   The meeting process determined the character\
    \ of this document.  It\n   should be regarded as a set of working notes produced\
    \ by mostly-\n   autonomous groups, containing some diversity of opinions as well\
    \ as\n   duplication of ideas.  It is not the output of the \"security\n   community\"\
    , but instead represents ideas about security developed by\n   a broad spectrum\
    \ of Internet experts.  It is offered as a step in a\n   process of developing\
    \ viable security mechanisms and procedures for\n   the Internet.\n"
- title: 2. OVERVIEW
  contents:
  - "2. OVERVIEW\n   2.1  Strategic and Political Issues\n      Despite the workshop\
    \ emphasis on architectural issues, there was\n      considerable discussion of\
    \ the real-politik of security.\n      For a number of years, the IETF, with IAB\
    \ backing, has worked on\n      developing PEM, which provides email security\
    \ with a great deal of\n      functionality.  A question was repeatedly raised\
    \ at the workshop:\n      why has user acceptance of PEM been slow?  A number\
    \ of answers to\n      this question were suggested.\n      (a)  High-quality\
    \ implementations have been slow in coming.\n      (b)  The use of a patented\
    \ technology, the RSA algorithm, violates\n           social conventions of the\
    \ Internet.\n      (c)  Export restrictions dampen vendor enthusiasm.\n      (d)\
    \  PEM currently depends upon a certificate hierarchy for its\n           names,\
    \ and certificates form a new and complex name space.\n           There is no\
    \ organizational infrastructure in place for creat-\n           ing and managing\
    \ this name space.\n      (e)  There is no directory infrastructure available\
    \ for looking up\n           certificates.\n           The decision to use X.500\
    \ has been a complete failure, due to\n           the slow deployment of X.500\
    \ in the Internet.  Because of UDP\n           packet size restrictions, it is\
    \ not currently feasible to\n           store certificates in the DNS, even if\
    \ the DNS were expanded\n           to hold records for individual email users.\n\
    \      It seems probable that more than one, and possibly all, of these\n    \
    \  reasons are at work to discourage PEM adoption.\n      The baleful comment\
    \ about eating: \"Everything I enjoy is either\n      immoral, illegal, or fattening\"\
    \ seems to apply to the cryptography\n      technology that is required for Internet\
    \ security.\n   2.2  Security Issues\n      Almost everyone agrees that the Internet\
    \ needs more and better\n      security.  However, that may mean different things\
    \ to different\n      people.  Four top-level requirements for Internet security\
    \ were\n      identified: end-to-end security, end-system security, secure QOS,\n\
    \      and secure network infrastructure.\n      A.   End-to-End Security\n  \
    \         One requirement is to support confidentiality, authentication\n    \
    \       and integrity for end-to-end communications.  These security\n       \
    \    services are best provided on an end-to-end basis, in order\n           to\
    \ minimize the number of network components that users must\n           trust.\
    \  Here the \"end\" may be the end system itself, or a\n           proxy (e.g.,\
    \ a firewall) acting on behalf of an end system.\n           For point-to-point\
    \ applications, the workshop felt that\n           existing security techniques\
    \ are well suited to support\n           confidentiality, authentication and integrity\
    \ services\n           efficiently.  These existing techniques include symmetric\n\
    \           encryption applied on an end-to-end basis, message digest\n      \
    \     functions, and key management algorithms.  Current work in\n           these\
    \ areas in the IETF include the PEM and Common\n           Authentication Technologies\
    \ working groups.\n           The group favored a strategic direction for coping\
    \ with\n           export restrictions:  separate authentication from privacy\n\
    \           (i.e., confidentiality).  This will allow work to proceed on\n   \
    \        authentication for the Internet, despite government\n           restrictions\
    \ on export of privacy technology.  Conversely, it\n           will allow easy\
    \ deployment of privacy without authentication,\n           where this is appropriate.\n\
    \           The workshop explored the implications of multicasting for\n     \
    \      end-to-end security.  Some of the unicast security techniques\n       \
    \    can be applied directly to multicast applications, while\n           others\
    \ must be modified.  Section 6.2 contains the results of\n           these discussions;\
    \ in summary, the conclusions were:\n           a)   Existing technology is adequate\
    \ to support\n                confidentiality, authentication, and integrity at\
    \ the\n                level of an entire multicast group.  Supporting\n     \
    \           authentication and integrity at the level of an\n                individual\
    \ multicast source is performance-limited and\n                will require technology\
    \ advances.\n           b)   End-to-end controls should be based on end system\
    \ or\n                user identifiers, not low level identifiers or locator\n\
    \                information.  This requirement should spawn engineering\n   \
    \             work which consists of applying known key distribution\n       \
    \         and cryptographic techniques.\n      B.   End-System Security\n    \
    \       Every host has its own security defenses, but the strength of\n      \
    \     these defenses depends upon the care that is taken in\n           administering\
    \ them.  Careful host security administration\n           means plugging security\
    \ holes in the kernel and applications\n           as well as enforcing discipline\
    \ on users to set good (hard to\n           crack) passwords.\n           Good\
    \ security administration is labor-intensive, and\n           therefore organizations\
    \ often find it difficult to maintain\n           the security of a large number\
    \ of internal machines.  To\n           protect their machines from outside subversion,\
    \ organizations\n           often erect an outer security wall or \"perimeter\"\
    .  Machines\n           inside the perimeter communicate with the rest of the\n\
    \           Internet only through a small set of carefully managed\n         \
    \  machines called \"firewalls\".  Firewalls may operate at the\n           application\
    \ layer, in which case they are application relays,\n           or at the IP layer,\
    \ in which case they are firewall routers.\n           The workshop spent considerable\
    \ time on the architecture of\n           firewall routers.  The results are contained\
    \ in Section 3.\n      C.   Secure QOS\n           The Internet is being extended\
    \ to provide quality-of-service\n           capabilities; this is the topic called\
    \ \"realtime service\" in\n           the workshop.  These extensions raise a\
    \ new set of security\n           issues for the architecture, to assure that\
    \ users are not\n           allowed to attach to resources they are not authorized\
    \ to\n           use, both to prevent theft of resources and to prevent denial\n\
    \           of service due to unauthorized traffic.  The resources to be\n   \
    \        protected include link shares, service classes or queues,\n         \
    \  multicast trees, and so on.  These resources are used as\n           virtual\
    \ channels within the network, where each virtual\n           channel is intended\
    \ to be used by a particular subset or\n           \"class\" of packets.\n   \
    \        Secure QOS, i.e., protection against improper virtual channel\n     \
    \      usage, is a form of access control mechanism.  In general it\n        \
    \   will be based on some form of state establishment (setup)\n           that\
    \ defines authorized \"classes\".  This setup may be done\n           via management\
    \ configuration (typically in advance and for\n           aggregates of users),\
    \ or it may be done dynamically via\n           control information in packets\
    \ or special messages (typically\n           at the time of use by the source\
    \ or receiver(s) of the\n           flow/data).  In addition to state establishment,\
    \ some form of\n           authentication will be needed to assure that successive\n\
    \           packets belong to the established class.  The general case to\n  \
    \         be solved is the multicast group, since in general the\n           multicast\
    \ problem includes the two-party case as a subset.\n           The workshop developed\
    \ an approach to the secure QOS problem,\n           which appears in Section\
    \ 4 below.\n      D.   Secure Network Infrastructure\n           Network operation\
    \ depends upon the management and control\n           protocols used to configure\
    \ and operate the network\n           infrastructure, including routers and DNS\
    \ servers.  An attack\n           on the network infrastructure may cause denial-of-service\n\
    \           from the user viewpoint, but from the network operators'\n       \
    \    viewpoint, security from attack requires authentication and\n           integrity\
    \ for network control and management messages.\n           Securing the routing\
    \ protocols seems to be a straightforward\n           engineering task.  The workshop\
    \ concluded the following.\n           a)   All routing information exchanges\
    \ should be\n                authenticated between neighboring routers.\n    \
    \       b)   The sources of all route information should be\n                authenticated.\n\
    \           c)   Although authenticating the authority of an injector of\n   \
    \             route information is feasible, authentication of\n             \
    \   operations on that routing information (e.g.,\n                aggregation)\
    \ requires further consideration.\n           Securing router management protocols\
    \ (e.g., SNMP, Telnet,\n           TFTP) is urgent, because of the currently active\
    \ threats.\n           Fortunately, the design task should be a straightforward\n\
    \           application of existing authentication mechanisms.\n           Securing\
    \ DNS is an important issue, but it did not receive\n           much attention\
    \ at the workshop.\n   2.3  DNS Names for Certificates\n      As noted in Section\
    \ 2.1, work on PEM has assumed the use of X.509\n      distinguished names as\
    \ the basis for issuing certificates, with\n      public-key encryption.  The\
    \ most controversial discussion at the\n      workshop concerned the possibility\
    \ of using DNS (i.e., domain)\n      names instead of X.509 distinguished names\
    \ as (at least) an\n      interim basis for Internet security.\n      The argument\
    \ in favor of DNS names is that they are simple and\n      well understood in\
    \ the Internet world.  It is easy for a computer\n      operating in the Internet\
    \ to be identified this way, and users who\n      receive email on such machines\
    \ already have DNS mailbox names.  In\n      contrast, introducing X.509 distinguished\
    \ names for security will\n      add a new layer of names.  Most importantly,\
    \ there is an existing\n      administrative model for assigning DNS names.  There\
    \ is no\n      administrative infrastructure for assigning X.509 distinguished\n\
    \      names, and generating them may be too complex for early\n      acceptance.\
    \  The advocates of DNS names for certificates hope that\n      using DNS names\
    \ would encourage the widespread use of security in\n      the Internet.  It is\
    \ expected that DNS names can be replaced later\n      by a more capable naming\
    \ mechanism such as X.509-based\n      certificates.\n      The basic argument\
    \ against DNS names as a basis for security is\n      that they are too \"weak\"\
    .  Their use may lead to confusion in many\n      instances, and this confusion\
    \ can only grow as more organizations\n      and individuals attach to the Internet.\
    \  Some commercial email\n      systems employ numeric mailbox names, and in many\
    \ organizations\n      there are uncertainties such as whether \"bumber@foo.edu\"\
    \ belongs\n      to Bill Umber or Tom Bumber.  While it is feasible to make DNS\n\
    \      names more descriptive, there is a concern that the existing\n      infrastructure,\
    \ with millions of short, non-descriptive names,\n      will be an impediment\
    \ to adoption of more descriptive names.\n      It was noted that the question\
    \ of what name space to use for\n      certificates is independent of the problem\
    \ of building an\n      infrastructure for retrieving those names.  Because of\
    \ UDP packet\n      size restrictions, it would not be feasible to store certificates\n\
    \      in the DNS without significant changes, even if the DNS were\n      expanded\
    \ to hold records for individual email users.\n      The group was unable to reach\
    \ a consensus on the issue of using\n      DNS names for security; further discussion\
    \ in the Internet\n      community is needed.\n"
- title: 3. FIREWALL ARCHITECTURE
  contents:
  - "3. FIREWALL ARCHITECTURE\n   3.1  Introduction\n      A firewall may be used\
    \ to isolate a specific connected segment of\n      Internet topology.  When such\
    \ a segment has multiple links to the\n      rest of the Internet, coordinated\
    \ firewall machines are required\n      on all the links.\n      Firewalls may\
    \ be implemented at different layers in the protocol\n      stack.  They are most\
    \ commonly implemented at the application\n      layer by forwarding (application)\
    \ gateways, or at the IP\n      (Internet) layer by filtering routers.  Section\
    \ 3.2 discusses\n      application gateways.  Section 3.3 concerns Internet-layer\n\
    \      firewalls, which filter IP datagrams entering or leaving a\n      security\
    \ perimeter.\n      The general architectural model for a firewall should separate\n\
    \      policy, i.e., determining whether or not the requester of a\n      service\
    \ should be granted access to that service, from control,\n      i.e., limiting\
    \ access to resources to those who have been granted\n      access.\n      3.1.1\
    \  The Use for Firewalls\n         Firewalls are a very emotional topic in the\
    \ Internet community.\n         Some community members feel the firewall concept\
    \ is very\n         powerful because firewalls aggregate security functions in\
    \ a\n         single place, simplifying management, installation and\n       \
    \  configuration.  Others feel that firewalls are damaging for the\n         same\
    \ reason: they provide \"a hard, crunchy outside with a soft\n         chewy center\"\
    , i.e., firewalls foster a false sense of\n         security, leading to lax security\
    \ within the firewall\n         perimeter.  They observe that much of the \"computer\
    \ crime\" in\n         corporate environments is perpetrated by insiders, immune\
    \ to\n         the perimeter defense strategy.  Firewall advocates counter\n \
    \        that firewalls are important as an additional safeguard; they\n     \
    \    should not be regarded as a substitute for careful security\n         management\
    \ within the perimeter.  Firewall detractors are also\n         concerned about\
    \ the difficulty of using firewalls, requiring\n         multiple logins and other\
    \ out-of-band mechanisms, and their\n         interference with the usability\
    \ and vitality of the Internet.\n         However, firewalls are a fact of life\
    \ in the Internet today.\n         They have been constructed for pragmatic reasons\
    \ by\n         organizations interested in a higher level of security than may\n\
    \         be possible without them.  This section will try to outline\n      \
    \   some of the advantages and disadvantages of firewalls, and some\n        \
    \ instances where they are useful.\n         Consider a large organization of\
    \ thousands of hosts.  If every\n         host is allowed to communicate directly\
    \ with the outside world,\n         attackers will attempt to penetrate the organization\
    \ by finding\n         the weakest host in the organization, breaching its defenses,\n\
    \         and then using the resources of that host to extend the\n         penetration\
    \ further within the organization.  In some sense,\n         firewalls are not\
    \ so much a solution to a security problem as\n         they are a reaction to\
    \ a more basic software\n         engineering/administration problem: configuring\
    \ a large number\n         of host systems for good security.  If this more basic\
    \ problem\n         could be solved, firewalls would generally be unnecessary.\n\
    \         It is interesting to consider the effect that implementing a\n     \
    \    firewall has upon various individuals in the organization.\n         Consider\
    \ first the effect upon an organization's most secure\n         host.  This host\
    \ basically receives little or no extra\n         protection, because its own\
    \ perimeter defenses are as strong or\n         stronger than the firewall.  In\
    \ addition, the firewall will\n         probably reduce the connectivity available\
    \ to this host, as\n         well as the reliability of the communications path\
    \ to the\n         outside world, resulting in inconvenience to the user(s) of\n\
    \         this host.  From this (most secure) user's point of view, the\n    \
    \     firewall is a loss.\n         On the other hand, a host with poor security\
    \ can \"hide\" behind\n         the firewall.  In exchange for a more limited\
    \ ability to\n         communicate with the outside world, this host can benefit\
    \ from\n         the higher level of security provided by the firewall, which\
    \ is\n         assumed to be based upon the best security available in the\n \
    \        entire  organization.  If this host only wants to communicate\n     \
    \    with other hosts inside the organization, the outside\n         communications\
    \ limitations imposed by the firewall may not even\n         be noticed.  From\
    \ this host's viewpoint, better security has\n         been gained at little or\
    \ no cost.\n         Finally, consider the point of view of the organization as\
    \ a\n         whole.  A firewall allows the extension of the best security in\n\
    \         the organization across the whole organization.  This is a\n       \
    \  benefit (except in the case where all host perimeter defenses\n         in\
    \ the organization are equal).  Centralized access control\n         also becomes\
    \ possible, which may be either a benefit or a cost,\n         depending upon\
    \ the organization.  The \"secure\" hosts within the\n         organization may\
    \ perceive a loss, while the \"unsecure\" hosts\n         receive a benefit. \
    \ The cost/benefit ratio to the organization\n         as a whole thus depends\
    \ upon the relative numbers of \"secure\"\n         and \"unsecure\" hosts in\
    \ the organization.\n         Consider some cases where firewalls do not make\
    \ sense.  An\n         individual can be thought of as an organization of one\
    \ host.\n         The security of all the host(s) is thus (trivially) identical,\n\
    \         and by definition the best available to the organization.  In\n    \
    \     this case the choice of firewall is simple.  Does this\n         individual\
    \ wish to communicate with the outside or not?  If\n         not, then the \"\
    perfect\" firewall is implemented (by complete\n         disconnection).  If yes,\
    \ then the host perimeter will be the\n         same as the firewall perimeter,\
    \ so a firewall becomes\n         unnecessary.\n         Another interesting case\
    \ is an organization that consists of\n         individuals with few shared interests.\
    \  This might be the case\n         of a service provider that sells public access\
    \ to the network.\n         An unrelated community of subscribers should probably\
    \ be\n         considered as individuals, rather than an organization.\n     \
    \    Firewalls for the whole organization may make little sense in\n         this\
    \ case.\n         To summarize, the benefit of a firewall depends upon the nature\n\
    \         of the organization it protects.  A firewall can be used to\n      \
    \   extend the best available protection within the organization\n         across\
    \ the entire organization, and thus be of benefit to large\n         organizations\
    \ with large numbers of poorly administered hosts.\n         A firewall may produce\
    \ little or no perceived benefit, however,\n         to the individuals within\
    \ an organization who have strong host\n         perimeters already.\n   3.2 \
    \ Application-Layer Firewalls\n      An application-layer firewall can be represented\
    \ by the following\n      diagram.\n          C <---> F <---> S\n      Here the\
    \ requesting client C opens its transport connection to the\n      firewall F\
    \ rather than directly to the desired server S.  One\n      mechanism for redirecting\
    \ C's request to F's IP address rather\n      than S's could be based on the DNS.\
    \  When C attempts to resolve\n      S's name, its DNS lookup would return a \"\
    service redirection\"\n      record (analogous to an MX record) for S.  The service\
    \ redirection\n      record would return the IP address of F.\n      C enters\
    \ some authentication conversation to identify itself to F,\n      and specifies\
    \ its intention to request a specific service from S.\n      F then decides if\
    \ C is authorized to invoke this service.  If C is\n      authorized, F initiates\
    \ a transport layer connection to S and\n      begins the operation, passing requests\
    \ and responses between C and\n      S.\n      A major advantage of this scenario\
    \ over an IP-layer firewall is\n      that raw IP datagrams are never passed through\
    \ the firewall.\n      Because the firewall operates at the application layer,\
    \ it has the\n      opportunity to handle and verify all data passing through\
    \ it, and\n      it may be more secure against illicit rendezvous attacks (see\n\
    \      below).\n      Application layer firewalls also have important disadvantages.\n\
    \      For full benefit, an application level firewall must be coded\n      specifically\
    \ for each application.  This severely limits the\n      deployment of new applications.\
    \  The firewall also represents a\n      new point of failure; if it ceases to\
    \ be reachable, the\n      application fails.  Application layer firewalls also\
    \ may affect\n      performance more than IP-layer firewalls, depending on specific\n\
    \      mechanisms in use.\n   3.3  IP-Layer Firewalls\n      Our model of an IP-layer\
    \ firewall is a multi-ported IP router that\n      applies a set of rules to each\
    \ incoming IP datagram, to decide\n      whether it will be forwarded.  It is\
    \ said to \"filter\" IP\n      datagrams, based on information available in the\
    \ packet headers.\n      A firewall router generally has a set of filtering rules,\
    \ each of\n      which specifies a \"packet profile\" and an \"action\".  The\
    \ packet\n      profile specifies values for particular header fields, e.g.,\n\
    \      source and destination IP address, protocol number, and other\n      suitable\
    \ source and destination identifying information (for\n      instance, port numbers).\
    \  The set of possible information that may\n      be used to match packets is\
    \ called an \"association\".  The exact\n      nature of an association is an\
    \ open issue.\n      The high-speed datagram forwarding path in the firewall processes\n\
    \      every arriving packet against all the packet profiles of all\n      active\
    \ rules, and when a profile matches, it applies the\n      corresponding action.\
    \  Typical actions may include forwarding,\n      dropping, sending a failure\
    \ response, or logging for exception\n      tracking.  There may be a default\
    \ rule for use when no other rule\n      matches, which would probably specify\
    \ a drop action.\n      In addition to the packet profile, some firewalls may\
    \ also use\n      some cryptographic information to authenticate the packet, as\n\
    \      described below in section 3.3.2.\n      3.3.1  Policy Control Level\n\
    \         This section presents a model for the control of a firewall\n      \
    \   router, with some examples of specific mechanisms that might be\n        \
    \ used.\n         1.   A client C attempts to access a service S.  (Client here\n\
    \              can mean either a person or a process - that also is an\n     \
    \         issue to be resolved.)\n         2.   The initiation of access to that\
    \ service may result in an\n              attempt to cross one or more boundaries\
    \ of protection via\n              firewall router(s).\n         3.   The policy\
    \ control level sets filters in the firewall\n              router(s), to permit\
    \ or deny that attempt.\n         The policy control level consists of two distinct\
    \ functions,\n         authentication and authorization.  Authentication is the\n\
    \         function of verifying the claimed identity of a user.  The\n       \
    \  authentication function should be distributed across the\n         Internet,\
    \ so that a user in one organization can be\n         authenticated to another\
    \ organization.  Once a user is\n         authenticated, it is then the job of\
    \ the authorization service\n         local to the resource being requested to\
    \ determine if that user\n         is authorized to access that resource.  If\
    \ authorization is\n         granted, the filter in the firewall can be updated\
    \ to permit\n         that access.\n         As an aid to understanding the issues,\
    \ we introduce a\n         particular detailed mechanism.  We emphasize that this\n\
    \         mechanism is intended only as an illustrative example; actual\n    \
    \     engineering of the mechanism will no doubt lead to many\n         changes.\
    \  Our mechanism is illustrated by the following sketch.\n         Here a user\
    \ wishes to connect from a computer C behind firewall\n         F1, to a server\
    \ S behind firewall F2.  A1 is a particular\n         authentication server and\
    \ Z1 is a particular authorization\n         server.\n                C <------->\
    \ F1 <-------> F2 <-------> S\n                 \\          /\n              \
    \    \\_____   /\n                   \\    \\ /\n                    A1  Z1\n\
    \         C attempts to initiate its conversation by sending an initial\n    \
    \     packet to S.  C uses a normal DNS lookup to resolve S's name,\n        \
    \ and uses normal IP routing mechanisms.  C's packet reaches\n         firewall\
    \ router F1, which rejects the packet because it does\n         not match any\
    \ acceptable packet profile.  F1 returns an\n         \"Authentication Required\"\
    \ error indication to C, including a\n         list of authentication/authorization\
    \ servers that F1 trusts.\n         This indication might be a new type of ICMP\
    \ Destination\n         Unreachable packet, or some other mechanism for communicating\n\
    \         with C.\n         When C receives the error indication, authenticates\
    \ itself with\n         A1, one of the authentication servers listed in the error\n\
    \         indication, after validating A1's identity.  C then requests\n     \
    \    authorization from server Z1 (using a ticket provided by A1),\n         informs\
    \ Z1 of the application it wishes to perform, and\n         provides a profile\
    \ for the packets it wishes to pass through\n         F1.  Z1 then performs an\
    \ authorization function to decide\n         whether to allow C to penetrate F1.\
    \  If C is to be allowed, Z1\n         then informs the firewall F1 to allow packets\
    \ matching the\n         packet profile to pass through the firewall F1.\n   \
    \      After C's packets penetrate F1, they may again be rejected by a\n     \
    \    second firewall F2.  C could perform the same procedures with\n         authentication\
    \ server A2 and authorization server Z2, which F2\n         trusts.  This is illustrated\
    \ by the following schematic diagram\n         of the sequence of events.\n  \
    \        ----------+--------+--------+------------+------------+----\n       \
    \  |    C     |   A1   |   Z1   |    F1      |     F2     |  S\n          ----------+--------+--------+------------+------------+----\n\
    \         | Sends pkt|        |        |            |            |\n         |\
    \ to S  ----------------------->Intercept;|            |\n         |         \
    \ |        |        | requires   |            |\n         |          |       \
    \ |        |authenticat'n            |\n         |   <-------------------------------\
    \      |            |\n         |Auth'cate |        |        |            |  \
    \          |\n         | C to A1 ---->     |        |            |           \
    \ |\n         |          |Provide |        |            |            |\n     \
    \    |    <------- ticket|        |            |            |\n         | Request\
    \  |        |        |            |            |\n         |authoriz'n|      \
    \  |        |            |            |\n         |   -------------------> Is\
    \ C|            |            |\n         |          |        |allowed?|      \
    \      |            |\n         |          |        |  OK --------->      |  \
    \          |\n         |Resend    |        |        | Set filter |           \
    \ |\n         | first pkt|        |        |            |            |\n     \
    \    | to S -------------------------->(OK)------>Intercept;|\n         |    \
    \      |        |        |            | requires   |\n         |          |  \
    \      |        |            |authenticat'n\n         |  <-------------------------------------------\
    \        |\n         | (Repeat  |        |        |            |            |\n\
    \         |procedure |        |        |            |            |\n         with\
    \ A2,Z2)|        |        |            |            |\n         |  ...     | \
    \       |        |            |            |\n         |Resend    |        | \
    \       |            |            |\n         | first pkt|        |        | \
    \           |            |\n         |   ------------------------------>(OK)--------(OK)------>\n\
    \         |          |        |        |            |            |\n         -----------+--------+--------+------------+------------+----\n\
    \         Again, we emphasize that this is only intended as a partial\n      \
    \   sketch of one possible mechanism.  It omits some significant\n         issues,\
    \ including the possibility of asymmetric routes (see\n         3.3.3 below),\
    \ and the possibility that the profiles may be\n         different in the two\
    \ directions between C and S.\n         We could imagine generalizing this to\
    \ an arbitrary sequence of\n         firewalls.  However, security requires that\
    \ each of the\n         firewalls be able to verify that data packets actually\
    \ come\n         from C.  This packet authentication problem, which is discussed\n\
    \         in the next section, could be extremely difficult if the data\n    \
    \     must traverse more than one or possibly two firewalls in\n         sequence.\n\
    \         A firewall router may require re-authentication because:\n         *\
    \    it has been added to the path by a routing change, or\n         *    it has\
    \ timed out the profile entry, or\n         *    it has been newly re-activated,\
    \ perhaps after a crash that\n              lost its list of acceptable profiles.\n\
    \         If C contacts authentication and authorization servers that S\n    \
    \     trusts, C may utilize tickets given it by these servers when\n         initiating\
    \ its use of S, and avoid re-authenticating itself to\n         S.\n         Although\
    \ the authentication server A1 and the authorization\n         server Z1 are conceptually\
    \ separate, they may run on the same\n         computer or router or even be separate\
    \ aspects of a single\n         program.  The protocol that C speaks to an An,\
    \ the protocol\n         that C speaks to a Zn, and the protocol that Zn speaks\
    \ to Fn\n         are not specified in these notes.  The authentication mechanism\n\
    \         used with An and the packet profile required by a firewall Fn\n    \
    \     are considered matters of policy.\n      3.3.2  Source Authentication\n\
    \         We next consider how to protect against spoofing the IP source\n   \
    \      address, i.e., injecting packets that are alleged from come\n         from\
    \ C but do not.  There are three classes of mechanisms to\n         prevent such\
    \ spoofing of IP-level firewalls.  The mechanisms\n         outlined here are\
    \ also discussed in Section 4.3 below.\n         o    Packet Profile Only\n  \
    \            The lowest level of security consists of allowing the IP-\n     \
    \         layer firewall to filter packets purely on the basis of\n          \
    \    the packet profile.  This is essentially the approach used\n            \
    \  by filtering routers today, with the addition of (1)\n              authentication\
    \ and authorization servers to control the\n              filtering profiles,\
    \ and (2) the automatic \"Authentication\n              Required\" notification\
    \ mechanism.  This approach provides\n              almost no security; it does\
    \ not prevent other computers\n              from spoofing packets that appear\
    \ to be transmitted by C,\n              or from taking over C's transport level\
    \ connection to S.\n         o    Sealed Packets\n              In the second\
    \ level of security, each packet is \"sealed\"\n              with a secure hash\
    \ algorithm.  An authentication server Ai\n              chooses a secret and\
    \ shares it with the source host S and\n              also with the authorization\
    \ server Zi, which shares the\n              secret with the firewall Fi.  Every\
    \ packet that C\n              transmits contains a hash value that depends upon\
    \ both the\n              contents of the packet and the secret value.  The firewall\n\
    \              Fi can compute the same hash function and verify that the\n   \
    \           packet was originated by a computer that knew the shared\n       \
    \       secret.\n              This approach does raise issues of how much C trusts\
    \ Zi\n              and Fi.  Since they know C's secret, Zi or Fi could spoof\n\
    \              C.  If C does not trust all Z's and F's in its path, a\n      \
    \        stronger mechanism (see below) is needed.\n              A more difficult\
    \ problem arises in authenticating C's\n              packets when more than one\
    \ firewall lies in the path.\n              Carrying a separate seal for each\
    \ firewall that is\n              penetrated would be costly in terms of packet\
    \ size.  On\n              the other hand, in order to use a single seal, all\
    \ the\n              firewalls would have to cooperate, and this might require\n\
    \              a much more complex mechanism than the one sketched in the\n  \
    \            previous section.  Morever, it may require mutual trust\n       \
    \       among all of the authentication servers Ai and\n              authorization\
    \ servers Zi; any of these servers could\n              undermine all the others.\
    \  Another possibility to be\n              investigated is to use hop-by-hop\
    \ rather than end-to-end\n              authentication of C's packets.  That is,\
    \ each firewall\n              would substitute into the packet the hash needed\
    \ by the\n              next firewall.\n              Multi-firewall source authentication\
    \ is a difficult\n              problem that needs more investigation.\n     \
    \    o    Packet Signatures\n              In the third level of security, each\
    \ packet is \"signed\"\n              using a public/private key algorithm.  C\
    \ shares its public\n              key with Zn, which shares it with Fn.  In this\
    \ scenario, C\n              can safely use one pair of keys for all authorization\n\
    \              servers and firewalls.  No authorization server or\n          \
    \    firewall can spoof C because they cannot sign packets\n              correctly.\n\
    \              Although packet signing gives a much higher level of\n        \
    \      security, it requires public key algorithms that are\n              patented\
    \ and currently very expensive to compute; their\n              time must be added\
    \ to that for the hash algorithm.  Also,\n              signing the hash generally\
    \ makes it larger.\n      3.3.3 Other Firewall Issues\n         o    Performance\n\
    \              An Internet-layer firewall has the advantage of generality\n  \
    \            and flexibility.  However, filtering introduces a\n             \
    \ potential performance problem.  Performance may depend\n              upon the\
    \ number and position of the packet fields used for\n              filtering,\
    \ and upon the number of rules against which a\n              packet has to be\
    \ matched.\n              Denial of service attacks require that the per-packet\
    \ rule\n              matching and the drop path be able to keep up with the\n\
    \              interface speed.\n         o    Multicasting\n              To\
    \ allow multicast traffic to penetrate a firewall, the\n              rule that\
    \ is needed should be supplied by the receiver\n              rather than the\
    \ sender.  However, this will not work with\n              the challenge mechanism\
    \ outlined in Section 3.3.1, since\n              \"Authentication Required\"\
    \ notifications would be sent to\n              the sender, not to the receiver(s).\n\
    \              Multicast conversations may use any of the three levels of\n  \
    \            security described in the previous section, but all\n           \
    \   firewalls will have to share the same secret with the\n              originator\
    \ of the data stream.  That secret would have to\n              be provided to\
    \ the receivers through other channels and\n              then passed to the firewalls\
    \ at the receivers' initiative\n              (in much the same way that resources\
    \ are reserved at\n              receiver's initiative in RSVP).\n         o \
    \   Asymmetric Routing\n              Given a client computer C utilizing a service\
    \ from another\n              computer C through a firewall F: if the packets\
    \ returning\n              from S to C take a different route than packets from\
    \ C to\n              S, they may encounter another firewall F' which has not\n\
    \              been authorized to pass packets from S to C (unlike F,\n      \
    \        which has been).  F' will challenge S rather than C, but S\n        \
    \      may not have credentials to authenticate itself with a\n              server\
    \ trusted by F'.\n              Fortunately, this asymmetric routing situation\
    \ is not a\n              problem for the common case of single homed administrative\n\
    \              domains, where any asymmetric routes converge at the\n        \
    \      firewall.\n         o    Illicit Rendezvous\n              None of these\
    \ mechanisms prevent two users on opposite\n              sides of a firewall\
    \ from rendezvousing with a custom\n              application written over a protocol\
    \ that may have been\n              authorized to run through a firewall.\n  \
    \            For example, if an organization has a policy that certain\n     \
    \         information is sensitive and must not be allowed outside\n         \
    \     its premises, a firewall will not be enough to enforce\n              this\
    \ policy if users are able to attach sensitive\n              information to mail\
    \ and send it outside to arbitrary\n              parties.  Similarly, a firewall\
    \ will not prevent all\n              problems with incoming data.  If users import\
    \ programs and\n              execute them, the programs may have Trojan horses\
    \ which\n              disclose sensitive information or modify or delete\n  \
    \            important data.  Executable code comes in many, many\n          \
    \    forms, including PostScript files, scripts for various\n              interpreters,\
    \ and even return addresses for sendmail.  A\n              firewall can detect\
    \ some of these and scan for some forms\n              of potentially hazardous\
    \ code, but it cannot stop users\n              from transforming things that\
    \ look like \"data\" into\n              programs.\n              We consider\
    \ these problems to be somewhat outside the\n              scope of the firewall\
    \ router mechanism.  It is a matter of\n              the policies implemented\
    \ by the organization owning the\n              firewalls to address these issues.\n\
    \         o    Transparency for Security Packets\n              For the mechanisms\
    \ described above to operate, the\n              \"Authentication Required\" notification\
    \ and the\n              authentication/authorization protocol that is used between\n\
    \              the client computer and the authentication and\n              authorization\
    \ servers trusted by a firewall, must be\n              passed by all firewalls\
    \ automatically.  This might be on\n              the basis of the packet profiles\
    \ involved in security.\n              Alternatively, firewall routers might serve\
    \ as\n              application-layer firewalls for these types of\n         \
    \     communications.  They could then validate the data they\n              pass\
    \ to avoid spoofing or illicit rendezvous.\n      3.3.4 Firewall-Friendly Applications\n\
    \         Firewall routers have problems with certain communication\n        \
    \ patterns where requests are initiated by the server, including\n         callbacks\
    \ and multiple connections (e.g., FTP).  It was\n         suggested that it would\
    \ be useful to have guidelines to\n         application designers to help them\
    \ to build 'firewall-friendly\n         applications'.  The following guidelines\
    \ were suggested:\n         1)   no inbound calls (the xterm problem),\n     \
    \    2)   fixed port numbers (no portmapper or tcpmux),\n         3)   integral\
    \ redirection is good (application gateways),\n         4)   no redirection in\
    \ the protocol,\n         5)   32 bit sequence numbers that are crypto-strong\
    \ random #'s,\n              and\n         6)   fixed length and number of header\
    \ fields.\n         Type fields are good, but they may not be needed if there\
    \ are\n         fixed port numbers.\n      3.3.5  Conclusions\n         Compared\
    \ to an application-layer firewall, an IP-layer firewall\n         scheme could\
    \ provide a number of benefits:\n         -    No extra authentication is required\
    \ for end hosts.\n         -    A single authentication protocol can be used for\
    \ all\n              intended applications.\n         -    An IP-layer firewall\
    \ causes less performance degradation.\n         -    An IP-layer firewall may\
    \ be able to crash and recover\n              state without disturbing open TCP\
    \ connections.\n         -    Routes can shift without disturbing open TCP connections.\n\
    \         -    There is no single point of failure.\n         -    It is independent\
    \ of application.\n         However, there are substantial difficult design issues\
    \ to be\n         solved, particularly in the areas of multiple firewalls,\n \
    \        assymmetric routes, multicasting, and performance.\n"
- title: 4. SECURE QOS FORWARDING
  contents:
  - "4. SECURE QOS FORWARDING\n   When the Internet supports special qualities-of-service\
    \ (QOS) for\n   particular packet flows, there will be a new set of security\n\
    \   problems.  There will be a need to authenticate and authorize users\n   asking\
    \ for those QOS values that are expensive in network resources,\n   and it will\
    \ be necessary to prevent theft of these resources and\n   denial-of-service attacks\
    \ by others.  This section contains a\n   conceptual model for these problems,\
    \ which we may call secure QOS\n   forwarding.  The issues here differ from end-to-end\
    \ security and\n   firewalls, because QOS forwarding security may need to be enforced\
    \ at\n   every router along a path.\n   It was noted that this is not a new problem;\
    \ it was stated and solved\n   in a theoretical way in a thesis by Radia Perlman.\n\
    \   4.1  The Requirement for Setup\n      Setup is an essential part of any QOS\
    \ mechanism.  However, it may\n      be argued that there are also good engineering\
    \ reasons for setup\n      in any Internet-layer security mechanism, even without\
    \ QOS\n      support.  In the abstract, one could imagine a pure datagram model\n\
    \      in which each IP packet separately carried the necessary\n      authorizations\
    \ for all the stages in the forwarding path.\n      Realistically, this is not\
    \ practical, since the security\n      information may be both unacceptably large\
    \ and computationally\n      demanding for inclusion in every packet.  This seems\
    \ to imply the\n      need for some form of state setup for security.\n      Thus,\
    \ we presume a two stage process that moves somewhat away from\n      the pure\
    \ datagram model.  In the first stage, the setup stage,\n      some state is established\
    \ in the routers (and other network\n      elements) that describes how a subsequent\
    \ stream of packets is to\n      be treated.  In the second stage, the classification\
    \ stage, the\n      arriving packets are matched with the correct state information\n\
    \      and processed.  The terminology in use today calls these different\n  \
    \    state descriptions \"classes\", and the process of sorting\n      \"classification\"\
    .\n      Setup can take many forms.  It could be dynamic, invoked across\n   \
    \   the network by an application as described above.  The setup\n      process\
    \ could also be the manual configuration of a router by\n      means of a protocol\
    \ such as SNMP or remote login.  For example, a\n      network link, such as a\
    \ link across the Atlantic, might be shared\n      by a number of users who purchase\
    \ it jointly.  They might\n      implement this sharing by configuring a router\
    \ with\n      specifications, or filters, which describe the sorts of packets\n\
    \      that are permitted to use each share.  Whether the setup is\n      dynamic\
    \ or manual, short-lived or semi-permanent, it has the same\n      effect: it\
    \ creates packet classes in the router and defines how\n      packets are to be\
    \ classified as they arrive.\n      Much of the current research on extensions\
    \ to IP for QOS, such as\n      realtime service, has assumed an explicit setup\
    \ phase and a\n      classification stage.  The setup stage is accomplished using\n\
    \      protocols such as RSVP or ST-II, which also specify how the\n      subsequent\
    \ classification is to be done.  Security at the setup\n      stage would thus\
    \ simply be an extension to such a protocol.  It\n      should be noted that there\
    \ are alternative proposals for realtime\n      QOS, based on an implicit setup\
    \ process.\n   4.2  Securing the Setup Process.\n      To secure the setup process,\
    \ we require that a setup request be\n      accompanied by user credentials that\
    \ provide a trustworthy\n      assurance that the requester is known and is authorized\
    \ to make\n      the request in question.  We refer to the credentials used in\
    \ the\n      setup phase as the high-level identification (HLID).\n      A simple\
    \ version of this authorization would be a password on the\n      management interface\
    \ to a router (the limitations of such a\n      password scheme are well known\
    \ and not the issue here).  In the\n      case of setup requests made by individual\
    \ applications, some\n      user-specific authorization must be assumed.\n   \
    \   While there could be any number of ways to organize the HLIDs, the\n     \
    \ objective of scaling suggests that a global framework for user\n      naming\
    \ and authentication would be useful.  The choice of naming\n      framework is\
    \ discussed further in Section 5.  Note that this\n      discussion, which concerns\
    \ controlling access to network resources\n      and security devices, is distinct\
    \ from end-to-end authentication\n      and access control; however, the same\
    \ authentication\n      infrastructure could be used for both.\n      In general,\
    \ while significant engineering effort will be required\n      to define a setup\
    \ architecture for the Internet, there is no need\n      to develop new security\
    \ techniques.  However, for the security\n      aspects of the classification\
    \ process, there are significant\n      problems related to performance and cost.\
    \  We thus focus on that\n      aspect of the overall framework in more detail.\n\
    \      Above, we defined the high-level ID (HLID) as that set of\n      information\
    \ presented as part of a setup request.  There may also\n      be a \"low-level\
    \ ID\" (LLID), sometimes called a \"cookie\", carried\n      in each packet to\
    \ drive classification.  In current proposals for\n      IP extensions for QOS,\
    \ packets are classified based on existing\n      packet fields, e.g., source\
    \ and destination addresses, ports, and\n      protocol type.\n      It is important\
    \ to note that the LLID is distinct from the address\n      of the user, at least\
    \ conceptually.  By stressing this distinction\n      we make the point that the\
    \ privileges of the user are not\n      determined by the address in use.  If\
    \ the user's address changes,\n      the privileges do not.\n      The LLID in\
    \ a packet acts as a form of tag that is used by some or\n      all routers along\
    \ a path to make decisions about the sort of QOS\n      that shall be granted\
    \ to this packet.  An LLID might refer to a\n      data stream between a single\
    \ source-destination address pair, or\n      it might be more general and encompass\
    \ a range of data streams.\n      There is no requirement that the LLID embody\
    \ a syntax that permits\n      a router to discern the QOS parameters that it\
    \ represents, but\n      there also is no prohibition against imposing such a\
    \ structure.\n      We propose that an IP datagram contain one LLID, which can\
    \ be used\n      at various stages of the network to map the packet to a class.\
    \  We\n      reject the alternative that the packet should have a variable\n \
    \     number of LLIDs, each one for a different point in the net.\n      Again,\
    \ this is not just a security comment, but it has security\n      implications.\n\
    \      The attributes of the LLID should be picked to match as broad a\n     \
    \ range of requirements as possible.\n      *    Its duration (discussed below)\
    \ must match both the needs of\n           the security protocol, balancing robustness\
    \ and efficiency,\n           and the needs of the application, which will have\
    \ to deal\n           with renewal of the setup when the LLID expires.  A useful\n\
    \           end-node facility would be a service to renew setup requests\n   \
    \        automatically.\n      *    The degree of trust must be high enough to\
    \ meet the most\n           stringent requirement we can reasonably meet.\n  \
    \    *    The granularity of the LLID structure must permit packet\n         \
    \  classification into classes fine-grained enough for any\n           resource\
    \ selection in the network.  We should therefore\n           expect that each\
    \ separate stream of packets from an\n           application will have a distinct\
    \ LLID.  There will be little\n           opportunity for aggregating multiple\
    \ streams under one LLID\n           or one authenticator.\n   4.3  Validating\
    \ an LLID\n      At a minimum, it is necessary to validate the use of an LLID\
    \ in\n      context, i.e., to ensure that it is being asserted in an\n      authorized\
    \ fashion.  Unauthorized use of an LLID could result in\n      theft of service\
    \ or denial-of-service attacks, where packets not\n      emitted by an authorized\
    \ sender are accorded the QOS treatment\n      reserved for that sender (or for\
    \ a group of which the sender is a\n      member).  Thus, use of an LLID should\
    \ be authenticated by routers\n      that make QOS decisions based on that LLID.\
    \  (Note that not all\n      routers may \"pay attention\" to the LLID.)\n   \
    \   In principle, the validity of an LLID assertion needs to be\n      checked\
    \ on every packet, though not necessarily at every router;\n      it may be possible\
    \ to restrict the checks to security perimeters.\n      At those routers that\
    \ must validate LLIDs, there is an obvious\n      concern over the performance\
    \ impact.  Therefore, a router may\n      adopt a less rigorous approach to LLID\
    \ validation.  For example, a\n      router may elect to sample a data stream\
    \ and validate some, but\n      not all, packets.  It may also elect to forward\
    \ packets first and\n      perform selective validation as a background activity.\
    \  In the\n      least stringent approach, a router might log selected packets\
    \ and\n      validate them as part of an audit activity much later.\n      There\
    \ are several candidate techniques for validating the use of\n      LLIDs.  We\
    \ have identified three basic techniques, which differ in\n      terms of computational\
    \ performance, bandwidth overhead, and\n      effectiveness (resistance to various\
    \ forms of attack).\n      *    Digital Signatures\n           The first technique\
    \ entails the use of public key\n           cryptography and digital signatures.\
    \  The sender of each\n           packet signs the packet (header and payload)\
    \ by computing a\n           one-way hash over the packet and transforming the\
    \ hash value\n           using a private key associated with the LLID.  The resulting\n\
    \           authenticator value is included in the packet header.  The\n     \
    \      binding between the public key and the LLID is established\n          \
    \ through a connection setup procedure that might make use of\n           public\
    \ keys that enjoy a much longer lifetime.  Using public\n           key technology\
    \ yields the advantage that any router can\n           validate a packet, but\
    \ no router is entrusted with data that\n           would enable it to generate\
    \ a packet with a valid\n           authenticator (i.e., which would be viewed\
    \ as valid by other\n           routers.)  This characteristic makes this technique\
    \ ideal\n           from the standpoint of the \"principle of least privilege.\"\
    \n           Public key cryptosystems such as RSA have the advantage that\n  \
    \         validation of a signature is much faster than signing, which\n     \
    \      reduces the router processing burden.  Nonetheless, this\n           approach\
    \ is not likely to be feasible for anything other than\n           selective checking\
    \ by routers, given current public key\n           algorithm performance.\n  \
    \    *    Sealing\n           The next technique is based on the use of the same\
    \ type of\n           one-way hash function used for digital signatures, but it\n\
    \           does not require signing the hash value.  Here the sender\n      \
    \     computes a one-way hash with a secret quantity (essentially a\n        \
    \   \"key\") appended to the packet.  This process is an example of\n        \
    \   what is sometimes referred to more generically as\n           cryptographic\
    \ \"sealing.\"  The inclusion of this key at the\n           end of the hash computation\
    \ results in a hash value that is\n           not predictable by any entity not\
    \ possessing the key.  The\n           resulting hash value is the authenticator\
    \ and is included in\n           the packet header.  A router validates a packet\
    \ by\n           recomputing the hash value over the received packet with the\n\
    \           same secret quantity appended.  If the transmitted hash value\n  \
    \         matches the recomputed hash value, the packet is declared\n        \
    \   valid.  Unlike the signature technique, sealing implies that\n           all\
    \ routers capable of verifying a seal are also capable of\n           generating\
    \ (forging) a seal.  Thus, this technique requires\n           that the sender\
    \ trust the routers not to misuse the key.\n           This technique has been\
    \ described in terms of a single secret\n           key shared between the sender\
    \ and all the routers that need\n           to validate packets associated with\
    \ an LLID.  A related\n           alternative strategy uses the same authenticator\
    \ technique,\n           but shares the secret key on a pairwise basis, e.g.,\
    \ between\n           the sender and the first router, between the first router\
    \ and\n           the next, etc.  This avoids the need to distribute the secret\n\
    \           key among a large group of routers, but it requires that the\n   \
    \        setup mechanism enable Router A to convince his neighbor\n          \
    \ (Router B) that Router A is authorized to represent traffic\n           on a\
    \ specific LLID or set of LLIDs.  This might best be done\n           by encapsulating\
    \ the packet inside a wrapper that both ends\n           of the link can validate.\
    \  Once this strategy is in place, it\n           may even be most efficient for\
    \ routers to aggregate traffic\n           between them, providing authentication\
    \ not on a per-LLID\n           basis, since the router pairs are prepared to\
    \ \"trust\" one\n           another to accurately represent the data stream LLIDs.\n\
    \           For a unicast data stream, the use of pairwise keying between\n  \
    \         routers does not represent a real change in the trust\n           required\
    \ of the routers or of the setup mechanism, because of\n           the symmetric\
    \ sharing of the secret key.  However, for a\n           multicast connection,\
    \ this pairwise keying approach is\n           superior in that it prevents a\
    \ router at one point in a\n           multicast tree from being able to generate\
    \ traffic that could\n           be inserted at another point in the tree.  At\
    \ worst, a router\n           can generate spurious, but authenticatable, traffic\
    \ only for\n           routers \"below\" it in the multicast tree.\n         \
    \  Note that the use of network management fault isolation\n           techniques,\
    \ e.g., sampling router traffic statistics at\n           different points along\
    \ a data stream, should permit post hoc\n           detection of packet forgery\
    \ attacks mounted by rogue routers\n           along a data stream path.  Use\
    \ of this technique could\n           provide a deterrent to such activity by\
    \ routers, further\n           arguing for the pairwise keying approach.\n   \
    \        The sealing technique is faster than the digital signature\n        \
    \   technique, because the incremental hash calculation\n           (including\
    \ the appended secret quantity) is much faster than\n           the cryptographic\
    \ transformation required to sign a hash.\n           The processing burden is\
    \ symmetric here, i.e., the sender and\n           each router devote the same\
    \ amount of processing power to\n           seal a packet and to verify the seal.\
    \  Also, a sealed hash\n           may be smaller than a signed hash, even if\
    \ the same function\n           is used in both cases.  (This is because the modulus\
    \ size of\n           the public key signature algorithm and any ancillary\n \
    \          parameters tend to increase the size of the signed hash\n         \
    \  value.)  Moreover, one could use a hash function with a\n           \"wide\"\
    \ value and truncate that value, if necessary to reduce\n           overhead;\
    \ this option is not available when the authenticator\n           is a signed\
    \ hash value.\n           As a variant on this technique, one could imagine a\n\
    \           \"clearinghouse\" that would receive, from the sender, the\n     \
    \      secret key used to generate and validate authenticators.  A\n         \
    \  router needing to validate a packet would send a copy of the\n           packet\
    \ to the clearinghouse, which would check the packet and\n           indicate\
    \ to the router whether it was a valid packet\n           associated with the\
    \ LLID in question.  Obviously, this\n           variant is viable only if the\
    \ router is performing\n           infrequent, selective packet validation.  However,\
    \ it does\n           avoid the need to share the authenticator secret among all\n\
    \           the routers that must validate packets.\n           For both of these\
    \ techniques, there is a residual\n           vulnerability to denial-of-service\
    \ attacks based on replay of\n           valid packets during the lifetime of\
    \ a data stream.  Unless\n           packets carry sequence numbers and routers\
    \ track a sequence\n           number window for each data stream, an (external)\
    \ attacker\n           can copy valid packets and replay them.  It may be easiest\
    \ to\n           protect against this form of attack by aggregating all\n    \
    \       traffic between a pair of routers into a single flow and\n           providing\
    \ replay protection for the flow as a whole, rather\n           than on a per\
    \ data stream basis.\n      *    Temporary Passwords\n           The final technique\
    \ explored in the workshop takes a very\n           different tack to packet validation.\
    \  The preceding\n           techniques compute a function of the bits in a packet\
    \ and\n           transform that value in a fashion that prevents an intruder\n\
    \           from generating packets with valid authenticators.  The\n        \
    \   ability to generate packets with valid authenticators for a\n           given\
    \ LLID requires access to a secret value that is\n           available only to\
    \ the sender, or to the sender and to routers\n           participating in a given\
    \ data stream.\n           In contrast, this third technique calls for the authenticator\n\
    \           to be a short term, secret quantity that is carried in the\n     \
    \      packet header, without benefit of further protection.  In\n           essence,\
    \ this technique incorporates a short term \"password\"\n           into each\
    \ packet header.  This approach, like its\n           predecessor, requires that\
    \ all of the routers validating the\n           LLID be privy to this authenticator.\
    \  Moreover, the\n           authenticator is visible to any other router or other\n\
    \           equipment along the path, and thus this technique is much\n      \
    \     more vulnerable than the previous ones.\n           Here the same authenticator\
    \ may be applied to all packets\n           with the same LLID, since the authenticator\
    \ is not a function\n           of the packet it authenticates.  In fact, this\
    \ suggests that\n           it is feasible to use the LLID as the authenticator.\n\
    \           However, adopting this tack would not be consistent with the\n   \
    \        two previous techniques, each of which requires an explicit,\n      \
    \     separate authenticator, and so we recommend against this\n           optimization.\n\
    \           Nonetheless, the fact that the authenticator is independent\n    \
    \       of the packet context makes it trivial to generate (forge)\n         \
    \  apparently authentic packets if the authenticator is\n           intercepted\
    \ from any legitimate packet.  Also, if the\n           authenticator can be guessed,\
    \ an attacker need not even\n           engage in passive wiretapping to defeat\
    \ this scheme.  This\n           latter observation suggests that the authenticator\
    \ must be of\n           sufficient size to make guessing unlikely, and making\
    \ the\n           LLID and the authenticator separate further supports this\n\
    \           requirement.\n           The major advantage of this approach is one\
    \ of performance.\n           The authenticator can be validated very quickly\
    \ through a\n           simple comparison.  Consistent with the need to protect\n\
    \           against guessing attacks, the authenticator need not consume\n   \
    \        a significant amount of space in the packet header.\n           The use\
    \ of a sequence number visible to the routers is an\n           interesting technique\
    \ to explore to make these somewhat\n           vulnerable methods more robust.\
    \  If each stream (each source\n           of packets) numbers its packets, then\
    \ an intruder attempting\n           to use the network resource must delete the\
    \ legitimate\n           packets, which in many cases would be difficult.  Otherwise,\n\
    \           the router being attacked would notice duplicate sequence\n      \
    \     numbers and similar anomalies.  The exact details of the\n           numbering\
    \ would have to be worked out, since for the\n           legitimate stream packets\
    \ might be lost, which would cause\n           holes in the sequence space.\n\
    \      We do not consider here the issues of collusion, in which a user\n    \
    \  with a given LLID and authenticator deliberately shares this with\n      another\
    \ unauthorized user.  This possibility should be explored,\n      to see if there\
    \ is a practical advantage to this act, and thus a\n      real threat.\n   4.4\
    \  Dynamics of Setup\n      o    Duration of LLID's\n           A key question\
    \ in the use of LLIDs is how long they remain\n           valid.  At one extreme,\
    \ they last only a very short time,\n           perhaps seconds.  This limits\
    \ the damage that can be done if\n           the authenticator for the LLID is\
    \ stolen.  At the other\n           extreme, LLIDs are semi-permanent, like credit\
    \ card numbers.\n           The techniques proposed above for securing the LLID\
    \ traded\n           strength for efficiency, under the assumption that the peril\n\
    \           was limited by the limited validity of the LLID.\n           The counterbalancing\
    \ advantage of long-term or semi-permanent\n           LLIDs is that it becomes\
    \ practical to use primitive setup\n           techniques, such as manual configuration\
    \ of routers to\n           establish packet classes.  This will be important\
    \ in the\n           short run, since deployment of security and dynamic resource\n\
    \           allocation protocols may not exactly track in time.\n           We\
    \ conclude that the correct short-term action is to design\n           LLIDs under\
    \ the assumption that they are fairly short lived,\n           and to tolerate,\
    \ in the short run, a longer period of\n           validity.  This would imply\
    \ that we will get an acceptable\n           long-term mechanism in place, which\
    \ operationally will have a\n           lower level of security at first.  As\
    \ we get better tools for\n           automatic setup, we can shorten the duration\
    \ of validity on a\n           individual basis, without replacing mechanism in\
    \ the packet\n           forwarding path.\n      o    Setup Latency\n        \
    \   The tradition of the Internet is not to impose any setup\n           latency\
    \ in the communication path between end nodes.  This\n           supports the\
    \ classic datagram model for quick transactions,\n           etc., and it is a\
    \ feature that should be preserved.\n           For setup that is done \"in advance\"\
    , either through a\n           management interface or by an end-node in the background,\
    \ the\n           issue of latency does not arise.  The latency issue occurs\n\
    \           for dynamic reservations made in response to a specific\n        \
    \   application request.\n           We observe that while latency is a key issue,\
    \ it is not\n           materially influenced by security concerns.  The designers\
    \ of\n           resource reservation protocols such as RSVP and ST-II are\n \
    \          debating the latency of these protocols today, absent\n           security.\
    \  Adding an authenticator to the request message\n           will increase the\
    \ processing needed to validate the request,\n           and might even imply\
    \ a message exchange with an\n           authentication service, but should not\
    \ substantially change\n           the real time of the setup stage, which might\
    \ already take\n           time on the order of a round-trip delay.  But the design\
    \ of\n           the high level authentication and authorization methods for\n\
    \           the setup protocol should understand that this process, while\n  \
    \         not demanding at the level of the per-packet processing, is\n      \
    \     still somewhat time-critical.\n           One way of dealing with an expensive\
    \ setup process is to set\n           up the request provisionally and perform\
    \ the validation in\n           the background. This would limit the damage from\
    \ one bad\n           setup request to a short period of time.  Note, however,\
    \ that\n           the system is still vulnerable to an attack that uses a\n \
    \          sequence of setup requests, each of which allows unauthorized\n   \
    \        usage for at least a short period of time.\n           Note also that\
    \ a denial-of-service attack can be mounted by\n           flooding the setup\
    \ process with invalid setup requests, all\n           of which need to be processed\
    \ and rejected.  This could\n           prevent a valid user from setting up any\
    \ state.  However,\n           denial-of-service attacks based upon flooding leave\
    \ very\n           large \"finger prints\"; they should not normally be an\n \
    \          important threat.  If it is a problem, it may be possible to\n    \
    \       incorporate a mechanism at the level of setup processing that\n      \
    \     is equivalent to \"fair queueing\", to limits the damage from a\n      \
    \     flooding attack at the packet level.\n   4.5  Receiver-Initiated Setup\n\
    \      Recent work on a QOS extension for the Internet, embodied in the\n    \
    \  RSVP protocol, uses the model that the receiver will reserve\n      resources.\
    \  This scheme is consistent with the current IP\n      multicast paradigm, which\
    \ requires the receiver to join the\n      multicast group.  The receiver reserves\
    \ the resources to insure\n      that the multicast traffic reaches the receiver\
    \ with the desired\n      QOS.  In this case, it is the credentials (the HLIDs)\
    \ of the\n      receivers that will be presented to the setup phase.\n      Note\
    \ that receiver initiation requires an explicit setup phase.\n      Suppose setup\
    \ were implicit, driven by pre-existing fields in the\n      packet.  Then there\
    \ would be no way to associate a packet with a\n      particular receiver, since\
    \ in multicast, the address of the\n      receiver never appears in the packet.\n\
    \      Further, it is impossible in this case to perform a setup \"in\n      advance\"\
    , unless the sender and the receiver are very tightly co-\n      ordinated; otherwise,\
    \ the receiver will not know in advance what\n      LLID will be in the packet.\
    \  It is certainly impossible, in this\n      case, for the receiver to set up\
    \ \"semi-permanent\" reservations for\n      multicast traffic coming to it. \
    \ This, again, is not a security\n      issue; the problem exists without adding\
    \ security concerns, but\n      the security architecture must take it into account.\n\
    \   4.6  Other Issues\n      4.6.1  Encrypting Firewalls and Bypass\n        \
    \ Our view of security, both end node and network protection,\n         includes\
    \ the use of firewalls, which partition the network into\n         regions of\
    \ more or less trust.  This idea has something in\n         common with the encrypting-firewall\
    \ model used in the\n         military/intelligence community: red (trusted) networks\n\
    \         partitioned from black (untrusted) networks.  The very\n         significant\
    \ difference is that, in the military model, the\n         partition uses an encryption\
    \ unit that encodes as much as\n         possible of the packet for its trip across\
    \ the black network to\n         another red network.  That is, the purpose of\
    \ the encryption\n         unit, among others, is to provide a very high degree\
    \ of\n         protection against disclosure for data housed within the red\n\
    \         networks.  In contrast, our version of a firewall is more to\n     \
    \    protect the trusted (red) region of the network from outside\n         attacks.\
    \  It is concerned both with what comes in and with what\n         goes out. \
    \ It does permit communication between a node on the\n         trusted and nodes\
    \ in the untrusted parts of the network.\n         We would like to be able to\
    \ adapt our model of secure QOS to\n         the case of military-style encrypting\
    \ firewalls.  However, this\n         use of encryption raises a problem with\
    \ our model of secure\n         resource management, discussed above, which was\
    \ based on a\n         two-stage process of setup and classification.  This model\
    \ is\n         problematic because it requires information to pass from the\n\
    \         red region to the black region in the clear.  This information\n   \
    \      includes both the setup packets themselves, if setup is done\n        \
    \ dynamically from the end node, and the classification fields\n         (the\
    \ LLIDs) in the data packets.  Obviously, this information\n         cannot be\
    \ encrypted when leaving the red region of the network,\n         since it would\
    \ then be meaningless to the black net, so that\n         the black network would\
    \ be unable to make resource allocation\n         decisions based on it.\n   \
    \      To make this sort of control scheme work, it is necessary for\n       \
    \  the encryption device to be programmed to permit certain\n         packets\
    \ and fields in packets to pass through the encryptor in\n         the clear.\
    \  This bypass of the encryption is considered highly\n         undesirable. \
    \ In a high security situation, the process\n         generating the bypassing\
    \ information might be corrupted, with\n         the result that information that\
    \ should be controlled is\n         removed from the secure network by hiding\
    \ it in the bypassed\n         fields of the packets.\n         We concluded,\
    \ however, that this bypass problem is not\n         insurmountable.  The key\
    \ idea, as in all cases of bypass, is to\n         limit, rather than wholly outlaw,\
    \ the information passing in\n         the clear.  To limit the information needed\
    \ for bypass, one can\n         either perform the setup as a management function\
    \ totally\n         within the black environment, or divide the process into two\n\
    \         stages.  The first stage, again totally in the black context,\n    \
    \     defines a limited number of setup situations.  The second stage\n      \
    \   involves sending from the red net a very small message that\n         selects\
    \ one request to be instantiated from among the pre-\n         defined set.\n\
    \         Perhaps the more difficult issue is the LLID in the packet\n       \
    \  header.  If the LLID is an explicit field (as we have discussed\n         so\
    \ far, but see below), it represents a new field in each\n         packet, with\
    \ perhaps as many as 32 bits.  Again, the solution\n         is to limit the way\
    \ this field can be used.  When the end-node\n         performs a setup, it will\
    \ specify the value of the LLID to be\n         used.  This fact can be observed\
    \ by the red/black encryption\n         unit, which can then limit the components\
    \ of this field to the\n         values currently in use.  To further improve\
    \ the situation, the\n         encryption unit might be able to aggregate a number\
    \ of flows\n         onto one flow for the purpose of crossing the black net,\
    \ which\n         would permit a further reduction in the number of distinct\n\
    \         LLIDs that must escape the red region.\n         The details of this\
    \ proposal, including some important issues\n         such as the time duration\
    \ of LLIDs in this case, must be\n         considered further.  However, the initial\
    \ conclusion that\n         bypass can be incorporated into a general resource\
    \ control\n         framework is very encouraging, since it suggests that both\n\
    \         military and commercial forms of security can be built out of\n    \
    \     the same building blocks.\n      4.6.2  The Principle of Consistent Privilege\n\
    \         A well understood principle of security is the principle of\n      \
    \   least privilege, which states that a system is most robust when\n        \
    \ it is structured to demand the least privilege from its\n         components.\n\
    \         A related rule we observe is the principle of consistent\n         privilege.\
    \  This can be illustrated simply in the case of\n         denial of service,\
    \ where it is particularly relevant.  For a\n         particular route, no assumption\
    \ of service can be justified\n         unless we trust the routers to deliver\
    \ the packets.  If a\n         router is corrupted and will not forward packets,\
    \ the only\n         solution is to find another route not involving this router.\n\
    \         We do not concern ourselves here with protocols for finding new\n  \
    \       routes in the presence of a corrupted router, since this topic\n     \
    \    is properly part of another topic, securing the network\n         infrastructure.\
    \  We only observe that either we will get\n         service from the router or\
    \ we will not.  If the router is\n         corrupted, it does not matter how it\
    \ chooses to attack us.\n         Thus, as long as the router is part of a forwarding\
    \ path (most\n         generally a multicast forwarding tree), we should not hesitate\n\
    \         to trust it in other ways, such as by giving it shared resource\n  \
    \       keys or LLID verifiers.\n         This illustrates the principle of consistent\
    \ privilege.  This\n         principle is exploited in the scheme for hop-by-hop\
    \ or pairwise\n         use of secrets to validate LLIDs in a multicast tree.\
    \  If a\n         single key is issued for the whole tree, then the privilege\
    \ is\n         not consistent.  We only need to trust a router with respect to\n\
    \         the nodes \"below\" it in the tree.  If it fails to forward\n      \
    \   traffic, it can affect only those nodes.  But if we give it the\n        \
    \ group key, then it can generate bogus traffic and inject it\n         into the\
    \ tree at any point, affecting traffic for other parts\n         of the tree.\
    \  If, on the other hand, we use pairwise keys, then\n         a corrupt node\
    \ can only generate bogus traffic with the key for\n         traffic it would\
    \ directly receive, which is the part of the\n         tree it could damage anyway.\n\
    \         Another requirement we must place on the network concerns\n        \
    \ routing.  If a firewall is in place, we must trust the routing\n         architecture\
    \ not to bypass that firewall.  One way to\n         accomplish this is to eliminate\
    \ any physical path between the\n         regions other than those that go through\
    \ the firewall.\n         Operational experience will be required to see if this\
    \ simple\n         physical limit is an acceptable constraint.\n      4.6.3  Implicit\
    \ LLID's\n         We stress the importance of a strong conceptual distinction\n\
    \         between the addresses in a packet and the LLID which is used to\n  \
    \       classify the packet.  The conceptual distinction is important,\n     \
    \    but under limited circumstances it may be possible to overload\n        \
    \ some of the packet fields and create an LLID from the current\n         packet\
    \ header.  For example, current packet classifiers for\n         IPv4, which are\
    \ not secure but which seem to work for\n         classifying the packets into\
    \ service classes, use a number of\n         the packet fields together as a form\
    \ of LLID: the source and\n         destination IP addresses and ports plus the\
    \ protocol type.\n         This sort of \"implicit\" LLID must be short-lived,\
    \ especially if\n         the host can change its IP address as it moves.  But\
    \ if the\n         LLID is established by some sort of dynamic setup protocol,\
    \ it\n         should be possible reestablish the LLID as needed.\n         The\
    \ current IPv4 header has no authenticator field to validate\n         the LLID.\
    \  An authenticator field could be optionally carried\n         in an option;\
    \ adding it gives robustness to network\n         reservations.  Any of the schemes\
    \ described above for creating\n         an authenticator could be used, except\
    \ that if the simple\n         password-style authenticator is used, it must be\
    \ an explicit\n         separate field, since the LLID cannot be picked randomly.\n\
    \      4.6.4  Security without Setup\n         As we describe this architecture,\
    \ the setup phase is an\n         essential part of the sequence.  This suggests\
    \ that the current\n         Internet, which has no setup protocols, cannot be\
    \ secured\n         against denial-of-service attacks.  It is important to explore\n\
    \         the limits of this point.  As we stressed above, setup can\n       \
    \  occur in many ways.  Routers today offer management options to\n         classify\
    \ packets based on protocol types and other fields found\n         in the header,\
    \ and to use this classification to create a few\n         fair queueing classes\
    \ that can prevent one class from\n         overloading the net to the exclusion\
    \ of the others.\n         There are two problem here.  The first is that for\
    \ a setup done\n         using a management interface, the secret that is shared\
    \ among\n         the source and the routers to validate the LLID must remain\n\
    \         valid for a long time, and it must be manually configured.  The\n  \
    \       second problem is that the granularity of the categories may be\n    \
    \     coarse.  However, it has been proposed, in a thesis by Radia\n         Perlman,\
    \ that a router might create a separate fair queueing\n         class implicitly\
    \ for each source address.  This approach, which\n         uses the addresses\
    \ as an implicit LLID, must have some form of\n         authenticator for robustness.\
    \  But if the LLID can be trusted,\n         this scheme provides classification\
    \ of traffic based only on an\n         implicit setup operation.  The granularity\
    \ of classification is\n         not sufficient to provide any QOS distinction.\
    \  The only\n         objective is to prevent the traffic from one source from\n\
    \         flooding the net to the exclusion of another.\n      4.6.5  Validating\
    \ Addresses\n         We make a claim here that if the LLID and the addresses\
    \ in the\n         packet are conceptually distinct, and if there is a suitable\n\
    \         means to validate the LLID, then there is no reason to validate\n  \
    \       the addresses.  For example, a packet constructed with a false\n     \
    \    source address does not seem to represent any security problem,\n       \
    \  if its LLID can be validated.\n         An exception to this might possibly\
    \ lie in communication with\n         mobile hosts, but it will require a complete\
    \ model of threats\n         and requirements in the mobile environment to be\
    \ sure.\n         However, we make the claim, as a starting point for discussion,\n\
    \         that if LLIDs are distinguished from addresses, many of the\n      \
    \   security concerns with mobility are mitigated and perhaps\n         removed.\
    \  This point should be validated by more detailed\n         consideration of\
    \ the mobility problem.\n   4.6  Conclusions\n      a)   It is important to conceptually\
    \ separate a LLID (Low-Level\n           IDentifier) carried in a packet from\
    \ addresses in the packet.\n      b)   There will be a single LLID carried in\
    \ each packet.  Although\n           this might imply some additional state in\
    \ the routers than if\n           multiple LLIDs were used, using only one LLID\
    \ choice is more\n           scalable.\n      c)   Hop-by-hop LLID authentication\
    \ mechanisms might provide a\n           highly scalable approach that limits\
    \ the distribution of\n           secrets.  However, the robustness limitations\
    \ must be\n           investigated thoroughly.\n      d)   Statistical sampling\
    \ or after-the-fact detection mechanisms\n           may be employed by routers\
    \ to address performance concerns.\n"
- title: 5. AN AUTHENTICATION SERVICE
  contents:
  - "5. AN AUTHENTICATION SERVICE\n   The purpose of an authentication service is\
    \ simply to verify names,\n   or more precisely to verify the origin of \"messages\"\
    .  It differs\n   from the authorization service, which determines what services\
    \ are\n   available to an authenticated name.  We expect that authentication\n\
    \   will be an Internet-wide service, while authorization will be\n   specific\
    \ to the resources to which access is being authorized.\n   This \"identification\"\
    \ function can be used in several contexts, for\n   example:\n   *    One-time\
    \ passwords: \"it is really <huitema@inria.fr> that is\n        responding to\
    \ this challenge\".\n   *    Access to a firewall: \"it is really <huitema@inria.fr>\
    \ that is\n        trying to send data to host-A at port-a\".\n   There are many\
    \ Internet objects that we may want to name, e.g.,:\n           domain names:\
    \   sophia.inria.fr\n           machine names:  jupiter.inria.fr\n           service\
    \ names:  www.sophia.inria.fr\n                           (in fact, a data base)\n\
    \           users:          huitema@sophia.inria.fr\n           processes:   \
    \   p112.huitema@sophia.inria.fr\n                           p112.sophia.inria.fr\n\
    \           universal resource locators:\n                           http//www.sophia.inria.fr:222/tmp/foobar\n\
    \   One could be tempted to believe that the authentication service will\n   only\
    \ be concerned with naming humans, as only humans are\n   \"responsible\"; a process\
    \ obtains some access rights because it is\n   acting on behalf of a person. \
    \ However, this is too reductive and\n   potentially misleading.  We may have\
    \ to authenticate \"machines\" or\n   hardware components.  For example:\n   *\
    \    When a machine boots it needs to access resources for\n        configuring\
    \ itself, but it is not yet \"used\" by a person; there\n        is no user.\n\
    \   *    On a \"distributed processor\", component CPUs may need to\n        authenticate\
    \ each other.\n   Machines do differ from users; machines cannot keep their \"\
    secrets\"\n   in the same way that people do.  However, there is a big value in\n\
    \   having a simple and extensible name space.\n   5.1  Names and Credentials\n\
    \      We make the hypothesis that the authorization services will\n      generally\
    \ use \"access control lists\" (ACLs), i.e., some definition\n      of a set of\
    \ authorized users.  A compact way to represent such a\n      set would be to\
    \ allow \"wildcard\" authorizations, e.g., \"anybody at\n      <Bellcore.com>\"\
    , or \"any machine at <INRIA.FR>\".  The\n      authentication service should\
    \ be designed to facilitate the\n      realization of the authorization service\
    \ and should support\n      \"wildcards\".\n      However, wildcards are not general\
    \ enough.  Assuming that we have\n      a hierarchical name space, a wildcarded\
    \ entry is limited to the\n      naming hierarchy.  For example, a name like\n\
    \      <huitema@sophia.inria.fr> could be matched by the wildcard\n      <*@sophia.inria.fr>\
    \ or <*.inria.fr> or <*.fr>.  This is useful as\n      long as one stays at INRIA,\
    \ but does not solve the generic\n      problem.  Suppose that an IETF file server\
    \ at CNRI is to be\n      accessible by all IAB members: its ACL will explicitly\
    \ list the\n      members by name.\n      The classic approach to naming, as exemplified\
    \ in the X.500 model,\n      is to consider that people have \"distinguished names\"\
    .  Once one\n      has discovered such a name through some \"white pages\" service,\
    \ can\n      use it as an access key in a global directory service.\n      An\
    \ individual may acquire authorizations from a variety of\n      sources.  Using\
    \ a pure, identity-based access control system, the\n      user would have to\
    \ acquire multiple identities (i.e.,\n      distinguished names), corresponding\
    \ to the roles in which she is\n      authorized to access different services.\
    \  We discuss this approach\n      in the next section.\n      An alternative\
    \ approach is for the user to have a very small\n      number of identities, and\
    \ to have the grantors of authorizations\n      issue (signed) credentials granting\
    \ permissions to the user,\n      linked to her ID.  These additional signed credentials\
    \ are known\n      as \"capabilities\".  The user can then establish her identity\n\
    \      through a generic identity credential, e.g., an X.509 certificate,\n  \
    \    and can establish authorization by presenting capabilities as\n      required.\
    \  This is somewhat analogous to a person acquiring credit\n      cards linked\
    \ to the name on a driver's license, and presenting the\n      appropriate credit\
    \ card, plus the license for picture verification\n      of identity.\n   5.2\
    \  Identity-Based Authorization\n      Let's open the wallet of an average person:\
    \ we find several\n      \"credit cards\" in it.  We all have many \"credit cards\"\
    , e.g.,\n      company cards, credit cards, airline frequent flyers memberships,\n\
    \      driver licenses.  Each of these cards is in fact a token asserting\n  \
    \    the existence of a relation: the bank certifies that checks\n      presented\
    \ by the bearer will be paid, the traffic authorities\n      certifies that the\
    \ bearer has learned how to drive, etc.  This is\n      an example of identity-based\
    \ authorization, in which an individual\n      is given different names corresponding\
    \ to different relations\n      entered into by that individual.\n      If we\
    \ imagine that the name space is based upon DNS (domain)\n      names, then for\
    \ example, the person mentioned above could be\n      authenticated with the names:\n\
    \              customer@my-big-bank.com\n              customer@frequent-flyer.airline.com\n\
    \      The model we used here is that \"the name is an association\". This\n \
    \     is consistent with name verification procedures, in which that one\n   \
    \   builds a \"chain of trust\" between the user and the \"resource\n      agent\"\
    .  By following a particular path in the trust graph, one\n      can both establish\
    \ the trust and show that the user belongs to an\n      \"authorized group\".\n\
    \      The existence of \"multiple names\" for a person may or may not\n     \
    \ imply the existence of an \"equivalence\" relation.  It may be\n      useful\
    \ to know that <huitema@sophia.inria.fr> and\n      <huitema@iab.isoc.org> are\
    \ two names for the same person, but\n      there are many cases where the user\
    \ does not want to make all his\n      tokens visible.\n   5.3  Choosing Credentials\n\
    \      Let's consider again the example of Christian Huitema accessing a\n   \
    \   file at CNRI.  He will have to interact with INRIA's outgoing\n      firewall\
    \ and with CNRI's incoming controls.  Regardless of whether\n      authorization\
    \ depends upon capabilities or upon multiple\n      association names, a different\
    \ credential may be needed in each\n      firewall on the path.  For example,\
    \ assuming multiple names are\n      used, he will use an INRIA name, <huitema@sophia.inria.fr>,\
    \ to be\n      authorized by INRIA to use network resources, and he will use an\n\
    \      IAB name, <huitema@iab.isoc.org>, to access the file server.  Thus\n  \
    \    comes an obvious problem: how does he choose the credential\n      appropriate\
    \ to a particular firewall?  More precisely, how does\n      the computer program\
    \ that manages the connection discover that it\n      should use one credential\
    \ in response to INRIA's firewall\n      challenge and another in response to\
    \ CNRI's request?\n      There are many possible answers.  The program could simply\
    \ pass\n      all the user's credentials and let the remote machine pick one.\n\
    \      This works, but poses some efficiency problems: passing all\n      possible\
    \ names is bulky, looking through many names is long.\n      Advertising many\
    \ names is also very undesirable for privacy and\n      security reasons: one\
    \ does not want remote servers to collect\n      statistics on all the credentials\
    \ that a particular user may have.\n      Another possibility is to let the agent\
    \ that requests an\n      authorization pass the set of credentials that it is\
    \ willing to\n      accept, e.g., \"I am ready to serve CNRI employees and IAB\n\
    \      members\".  This poses the same privacy and security problems as\n    \
    \  the previous solutions, although to a lesser degree.  In fact, the\n      problem\
    \ of choosing a name is the same as the generic \"trust path\"\n      model. \
    \ The name to choose is merely a path in the authentication\n      graph, and\
    \ network specialists are expected to know how to find\n      paths in graphs.\n\
    \      In the short term, it is probably possible to use a \"default name\"\n\
    \      or \"principal name\", at least for local transactions, and to count\n\
    \      on the user to \"guess\" the credential that is required by remote\n  \
    \    services.  To leave the local environment we need only the local\n      credentials;\
    \ to contact a remote server we need only the\n      destination credentials.\
    \  So we need one or maybe two credentials,\n      which may be derived from the\
    \ destination.  It will be very often\n      the case that the generic credential\
    \ is enough; then wildcards;\n      then \"FTP provided\" tokens.\n"
- title: 6. OTHER ISSUES
  contents:
  - "6. OTHER ISSUES\n   6.1  Privacy and Authentication of Multicast Groups\n   \
    \   Multicast applications are becoming an increasingly important part\n     \
    \ of Internet communications.  Packet voice, video and shared\n      whiteboard\
    \ can be powerful productivity tools for users.  For\n      these applications\
    \ to have maximum value to their users, a variety\n      of security services\
    \ will be required.\n      Existing techniques are directly applicable to providing\
    \ privacy\n      for a private teleconference.  If each member of the conference\n\
    \      shares a single key for a symmetric encryption algorithm (such as\n   \
    \   DES), existing point-to-point security techniques can be extended\n      to\
    \ protect communication within the group from outsiders.\n      However, slight\
    \ modifications to existing techniques are required\n      to accommodate the\
    \ multicast environment.  Each packet will\n      require independent cryptographic\
    \ processing to ensure that\n      packets from multiple sources can be independently\
    \ decrypted by\n      the numerous receivers, particularly in the presence of\
    \ lost\n      packets.  N-party authentication and key management will be\n  \
    \    required to establish the shared key among the proper group\n      members.\
    \  This can be done by extending existing two-party key\n      management techniques\
    \ pairwise.  For example, the conference\n      manager may provide the key to\
    \ each member following individual\n      authentication; for example, this could\
    \ be implemented trivially\n      using PEM technology.  The overhead experienced\
    \ by each host\n      computer in the conference will be similar to that of existing\n\
    \      point-to-point encryption applications,  This overhead is be low\n    \
    \  enough that, today, software encryption can offer adequate\n      performance\
    \ to secure whiteboard and voice traffic, while hardware\n      encryption is\
    \ adequate for video.\n      The nature of multicast communication adds an additional\n\
    \      requirement.  Existing multicast conferences provide gradual\n      degradation\
    \ in quality as the packet loss rate increases.  To be\n      acceptable, authentication\
    \ protocols must tolerate lost packets.\n      Techniques to accomplish this efficiently\
    \ need to be developed.\n      One initial sketch is outlined below.  Engineering\
    \ work will be\n      required to validate the practicality of this approach.\n\
    \      The use of symmetric encryption provides the members of the\n      conference\
    \ with effective protection from outsiders.  However,\n      because all members\
    \ of the conference share a single key, it does\n      not provide a means of\
    \ authenticating individual conference\n      members.  In principle, existing\
    \ techniques, based on one-way hash\n      functions coupled with digital signatures\
    \ based on asymmetric\n      encryption algorithms, can provide individual authentication.\n\
    \      One-way hash functions such as MD5 are comparable in cost to\n      symmetric\
    \ encryption.  However, digital signatures are\n      considerably more costly,\
    \ both in computation and in communication\n      size.  The degree of overhead\
    \ depends on the quality of\n      authentication required.\n      In summary,\
    \ realtime authentication at the granularity of group\n      membership is easy\
    \ and cheap, but individual authentication is\n      costly in time and space.\
    \  Over time, the costs of both\n      communications and processing are expected\
    \ to decline.  It is\n      possible that this will help make authentication at\
    \ the level of\n      individual conference participants.  There are two conflicting\n\
    \      trends:  (1) increasing CPU speeds to provide symmetric\n      encryption,\
    \ and (2) increasing communication data rates.  If both\n      technologies increase\
    \ proportionally, there will be no net gain,\n      at least if the grain size\
    \ is measured in terms of bits, rather\n      than as a period in seconds.\n \
    \     The group felt that the correct approach to end-to-end controls is\n   \
    \   the use of encryption, as discussed above.  The alternative is to\n      control\
    \ the ability of a user to join a multicast group as a\n      listener, or as\
    \ a speaker.  However, we are not comfortable with\n      the level of assurance\
    \ that we can offer if we attempt to ensure\n      end-to-end semantics using\
    \ these means.  Any passive penetration\n      of the network, i.e., any wire-tap,\
    \ can compromise the privacy of\n      the transmitted information.  We must acknowledge,\
    \ however, that\n      problems with deployment of encryption code and hardware,\
    \ and\n      especially problems of export controls, will create a pressure to\n\
    \      use the tools described in Section 4 to implement a form of end-\n    \
    \  to-end control.  Such a decision would raise no new issues in\n      security\
    \ technology.  The shared key now used for encrypting the\n      data could instead\
    \ be used as the basis for authenticating a\n      multicast group join request.\
    \  This would require modification of\n      the multicast packet format, but\
    \ nothing more.  Our concern is not\n      the technical difficulty of this approach,\
    \ but the level of\n      assurance we can offer the user.\n   6.2  Secure Plug-and-Play\
    \ a Must\n      Plug-and-play is the ability to plug a new device into a network\n\
    \      and have it obtain the information it needs to communicate with\n     \
    \ other devices, without requiring any new configuration\n      information. \
    \ Secure plug-and-play is an important Internet\n      requirement, and a central\
    \ architectural issue is whether it can\n      be made to scale well.\n      For\
    \ plug-and-play operation, a new machine that is \"plugged\" into\n      the network\
    \ needs to:\n      (1)  Obtain an locator so it can communicate with other devices\n\
    \      (2)  Register or obtain a name to be identified by (e.g., machine\n   \
    \        name)\n      (3)  Discover services available on the network (e.g., printers,\n\
    \           routers, file servers, etc.)\n      (4)  Discover other systems on\
    \ the network so it can communicate\n           with them.\n      In some environments,\
    \ no security mechanisms are required because\n      physical security and local\
    \ knowledge of the users are sufficient\n      protection.  At the other end of\
    \ the spectrum is a large network\n      with many groups of users, different\
    \ types of outside connections,\n      and levels of administrative control. \
    \ In such environments,\n      similar plug-and-play capabilities are needed,\
    \ but the new device\n      must be \"authenticated\" before it can perform these\
    \ functions.  In\n      each step in the discovery process the new device must\n\
    \      authenticate itself prior to learning about services.\n      The steps\
    \ might be:\n      -    Obtain a HLID from a smart card, smart disk, or similar\n\
    \           device.\n      -    Authenticate itself with the first plug-and-play\
    \ server using\n           its HLID, to register a name and to find the location\
    \ of\n           other services.\n      -    Discover services available on the\
    \ network (e.g., printers,\n           routers, file servers, etc.) based on its\
    \ HLID.\n      -    Discover other systems on the network so it can communicate\n\
    \           with them.\n      The problem of taking a system out of the box and\
    \ initially\n      configuring it is similar to the problem of a mobile or portable\n\
    \      machine  that a human wants to connect to a local network\n      temporarily\
    \ in order to receive services on that network.  How can\n      the local network\
    \ authenticate the human (and therefore the\n      human's machine) and know which\
    \ services this visiting machine is\n      permitted to use?\n      The human\
    \ must be endowed with a high level identifier (HLID)\n      which acts as his/her\
    \ passport and can be verified by the local\n      network.  This high level identifier\
    \ must be globally unique and\n      registered/assigned by some recognized authority.\n\
    \      When the human plugs the machine onto a local net, the machine\n      identifies\
    \ itself to the net with the human's high level\n      identifier.  If local net\
    \ has a policy of permitting anyone to\n      plug and play on its network, it\
    \ will ignore the HLID and assign\n      an address (locator), permitting the\
    \ visitor unrestricted access\n      and privileges.  More likely, the local net\
    \ will authenticate the\n      HLID prior to granting the visitor an address or\
    \ any privileges.\n      At this point, the HLID has only authenticated the visitor\
    \ to the\n      local network; the issue of which services or resources the\n\
    \      visitor is entitled to use has not been addressed.  It is\n      desirable\
    \ to develop a low-overhead approach to granting\n      authentications to new\
    \ users. This will help in the case of\n      visitors to a site, as well as new\
    \ users joining a facility.\n   6.3  A Short-Term Confidentiality Mechanism\n\
    \      Authentication has customarily been achieved using passwords.  In\n   \
    \   the absence of active attacks, the greatest threat to computer\n      system\
    \ security may be the ease with which passwords can be\n      \"snooped\" by the\
    \ promiscuous monitoring of shared-media networks.\n      There are known security\
    \ techniques for achieving authentication\n      without exposing passwords to\
    \ interception, for example the\n      techniques implemented in the well-known\
    \ Kerberos system.\n      However, authentication systems such as Kerberos currently\
    \ operate\n      only in isolation within organizational boundaries.  Developing\n\
    \      and deploying a global authentication infrastructure is an\n      important\
    \ objective, but it will take some years.  Another useful\n      approach in the\
    \ short term is the use of a challenge-response user\n      authentication scheme\
    \ (e.g., S/Key).\n      One of the groups explored another interim approach to\
    \ guarding\n      passwords: introducing a readily-used confidentiality mechanism\n\
    \      based on an encrypted TCP connection.  This would operate at the\n    \
    \  IP level to encrypt the IP payload, including the TCP header, to\n      allow\
    \ the nature as well of the contents of the communication to\n      be kept private.\
    \  It could be implemented to provide either\n      \"strict\" protection (the\
    \ connection fails if the other side cannot\n      decrypt your data stream) or\
    \ \"loose\" protection (falling back to\n      non-private TCP if decryption fails).\n\
    \      Loose protection would allow interoperability with older hosts in\n   \
    \   a seamless (non-user-intrusive) manner.\n      One-time keys may be exchanged\
    \ during the SYN handshake that\n      starts the TCP connection.  Using one-time\
    \ keys avoids a need for\n      infrastructure support and does not require trust\
    \ between the\n      organizations on the two ends of the connection.  Tieing\
    \ the key\n      exchange to the SYN handshake will avoid the possibility of having\n\
    \      the connection fully open without knowing the state of encryption\n   \
    \   on both ends of the connection.  Although it may still be\n      theoretically\
    \ possible to intercept the SYN exchange and subvert\n      the connection by\
    \ an active \"man-in-the-middle\" attack, in\n      practice such attacks on TCP\
    \ connections are quite difficult\n      unless the routing protocols have been\
    \ subverted.\n      The keys could be exchanged using a new option that specifies\
    \ the\n      key exchange protocol, the data encryption algorithm, and the key\n\
    \      to be used to decrypt the connection.  It could be possible to\n      include\
    \ multiple options in the same SYN segment, specifying\n      different encryption\
    \ models; the far end would then need to\n      acknowledge the option that it\
    \ is willing to use.  In this case,\n      the lack of an acknowledgement would\
    \ imply disinterest in\n      decrypting the datastream.  If a loose privacy policy\
    \ were in\n      force, the connection could continue even without an\n      acknowledgment.\
    \  The policy, \"strict\" or \"loose\", would be set by\n      either the user\
    \ or the default configuration for the machine.\n      One must however observe\
    \ that a TCP option can carry only a\n      limited amount of data.  Efficient\
    \ protection against crypto-\n      analysis of the Diffie-Hellmann scheme may\
    \ require the use of a\n      very long modulus, e.g., 1024 bits, which cannot\
    \ be carried in the\n      40 bytes available for TCP options.  One would thus\
    \ have either to\n      define an \"extended option\" format or to implement encryption\
    \ in a\n      separate protocol layered between TCP and IP, perhaps using a\n\
    \      version of \"IP security\".  The detailed engineering of such a\n     \
    \ solution would have to be studied by a working group.\n      A TCP connection\
    \ encryption mechanism such as that just outlined\n      requires no application\
    \ changes, although it does require kernel\n      changes.  It has important drawbacks,\
    \ including failure to provide\n      privacy for privacy for UDP, and the great\
    \ likelihood of export\n      control restrictions.  If Diffie-Hellman were used,\
    \ there would\n      also be patent issues.\n"
- title: 7. CONCLUSIONS
  contents:
  - "7. CONCLUSIONS\n   As a practical matter, security must be added to the Internet\n\
    \   incrementally.  For example, a scheme that requires, as a\n   precondition\
    \ for any improvement, changes to application code, the\n   DNS, routers and firewalls\
    \ all at once will be very hard to deploy.\n   One of the reasons the workshop\
    \ explored schemes that are local to\n   the IP layer is that we surmise that\
    \ they might be easier to deploy\n   in practice.\n   There are two competing\
    \ observations that must shape planning for\n   Internet security.  One is the\
    \ well known expression: \"the best is\n   the enemy of the good.\"  The other\
    \ is the observation that the\n   attacks are getting better.\n   Finally, it\
    \ should noted that the principle of least privilege, which\n   was mentioned\
    \ above, may be in contradiction to the principle of\n   least cost.\n   7.1 \
    \ Suggested Short-Term Actions\n      The general recommendation for short-term\
    \ Internet security policy\n      was that the IETF should make a list of desirable\
    \ short-term\n      actions and then reach out to work with other organizations\
    \ to\n      carry them out.  Other organizations include regionals, which may\n\
    \      be in a good position to provide site security counseling services\n  \
    \    to their customers, vendors and other providers, and other\n      societies.\
    \  We should also give input to the US government to\n      influence their posture\
    \ on security in the direction desired by\n      the community.\n      A suggested\
    \ preliminary list of short-term actions was developed.\n      o    Perform external\
    \ diagnostic security probes\n           Organizations should be encouraged to\
    \ use CRACK and other\n           tools to check the robustness of their own passwords.\
    \  It\n           would also be useful to run a variety of security probes from\n\
    \           outside.  Since this is a very sensitive issue, some care\n      \
    \     needs to be taken to get the proper auspices for such\n           probing.\n\
    \           Useful probe tools include:\n               ISS: Klaus (GA)\n    \
    \           SATAN: Farmer Venema\n               ICEPICK: NRL\n      o    Determine\
    \ Security-Risk Publication Channels\n           What channels should be used\
    \ for disseminating information of\n           security risks?\n      o    Encourage\
    \ use of one-time passwords.\n           Available packages: S/Key, SecurID, Enigma,\
    \ Digital Pathways.\n      o    Develop and publish guidelines for protocol developers,\
    \ for\n           security-friendliness and firewall-friendliness.\n      o  \
    \  Control topology to isolate threats\n      o    Set privacy policy:\n     \
    \      *    Always\n           *    As much as possible\n      o    Bring Site\
    \ Security Handbook up to date\n      o    Support use of Kerberos\n      The\
    \ subject of the \"Clipper chip\" came up several times, but there\n      was\
    \ not sufficient discussion of this very complex issue for this\n      grouip\
    \ to reach a recommendation.  It has been observed that there\n      are a number\
    \ of quite differing viewpoints about Clipper.\n           o    Some people accept\
    \ the government's Clipper proposal,\n                including key escrow by\
    \ the US government and the\n                requirement that encryption be in\
    \ hardware.\n           o    Some people don't mind key escrow by the government\
    \ in\n                principle, but the object to the hardware requirement.\n\
    \           o    Some people don't mind key escrow in principle, but\n       \
    \         don't want the government to hold the keys.  They would\n          \
    \      be comfortable with having the organization which owns\n              \
    \  the data hold the keys.\n           o    Some people don't want key escrow\
    \ at all.\n           o    Some people don't mind the hardware or the key escrow,\n\
    \                but they don't think this will be acceptable to other\n     \
    \           countries and thus will not work internationally.\n      This report\
    \ takes no position on any of these viewpoints.\n   7.2  Suggested Medium-Term\
    \ Actions\n      These actions require some protocol design or modification;\n\
    \      however, they use existing security technology and require no\n      research.\n\
    \      o    Authentication Protocol\n           There is a problem of the choice\
    \ of technology.  Public key\n           technology is generally deemed superior,\
    \ but it is patented\n           and can also induce relatively long computations.\
    \  Symmetric\n           key technology (Needham-Schroeder algorithm, as used\
    \ in\n           Kerberos) has some technical drawbacks but it is not\n      \
    \     patented.  A system based on symmetric keys and used only for\n        \
    \   authentication would be freely exportable without being\n           subject\
    \ to patents.\n      o    Push Kerberos\n           Engineering is needed on Kerberos\
    \ to allow it to interoperate\n           with mechanisms that use public key\
    \ cryptography.\n      o    Push PEM/RIPEM/PGP...\n      o    Develop an authenticated\
    \ DNS\n      o    Develop a key management mechanism\n      o    Set up a certificate\
    \ server infrastructure\n           Possible server mechanisms include the DNS,\
    \ Finger, SNMP,\n           Email, Web, and FTP.\n      o    Engineer authentication\
    \ for the Web\n   7.3  Suggested Long-Term Actions\n      In this category, we\
    \ have situations where a threat has been\n      identified and solutions are\
    \ imaginable, but closure has not been\n      reached on the principles.\n   \
    \   o    Executable Apps\n      o    Router sabotage counter-measures\n      o\
    \    Prevent Byzantine routing.\n      o    Proxy Computing\n      o    Decomposition\
    \ of computers\n      o    Are there \"good\" viruses?\n"
- title: APPENDIX A -- Workshop Organization
  contents:
  - "APPENDIX A -- Workshop Organization\n   The following list of attendees indicates\
    \ also the breakout group to\n   which they were assigned.\n   Breakout Groups\n\
    \   Group I.1 Leader:\n   1 Christian Huitema, INRIA        (IAB)\n   1 Steve\
    \ Bellovin, AT&T\n   1 Bob Braden, ISI                 (IAB)\n   1 John Curran,\
    \ NEARNET\n   1 Phill Gross, ANS                (IETF/IAB)\n   1 Stev Knowles,\
    \ FTP Software      (Internet AD)\n   1 Barry Leiner, USRA              (IAB)\n\
    \   1 Paul Mockapetris, ISI\n   1 Yakov Rekhter, IBM              (IAB)\n   1\
    \ Dave Sincoskie, Bellcore        (IAB)\n   Group I.2 Leader:\n   2 Steve Crocker,\
    \ TIS              (Security AD)\n   2 Jon Crowcroft\n   2 Steve Deering, PARC\n\
    \   2 Paul Francis, NTT\n   2 Van Jacobson, LBL\n   2 Phil Karn, Qualcomm\n  \
    \ 2 Allison Mankin, NRL             (Transport AD, IPng AD)\n   2 Radia Perlman,\
    \ Novell\n   2 John Romkey, ELF                (IAB)\n   2 Mike StJohns, ARPA\
    \              (IAB)\n   Group I.3 Leader:\n   3 Dave Clark, MIT\n   3 Deborah\
    \ Estrin, USC\n   3 Elise Gerich, Merit             (IAB)\n   3 Steve Kent, BBN\
    \                 (IAB)\n   3 Tony Lauck, DEC                 (IAB)\n   3 Tony\
    \ Li, CISCO\n   3 Bob Hinden, Sun                 (IESG->IAB liaison, Routing\
    \ AD)\n   3 Jun Murai, WIDE                 (IAB)\n   3 Scott Shenker, PARC\n\
    \   3 Abel Weinrib, Bellcore\n   The following were able to attend only the third\
    \ day, due to a\n   conflicting ISOC Board of Trustees meeting:\n     Scott Bradner,\
    \ Harvard           (IPng AD)\n     Jon Postel, ISI                  (IAB)\n \
    \  The workshop agenda was as follows.\n      Tues Feb 8\n          9:00 - 10:30\
    \  Plenary\n              Discuss facilities, meeting goals, agenda, organization.\n\
    \              Establish some minimal common understandings.  Assign\n       \
    \       scenarios to Breakout I groups.\n          10:30 - 13:00  Breakout I meetings\n\
    \              Each breakout group examine one or more scenarios and\n       \
    \       formulate a list of design questions.  Lunch available on\n          \
    \    11th floor.\n          13:00 - 15:00  Plenary\n              Report, discuss.\
    \  Collate and shorten list of design\n              issues.  Organize Breakout\
    \ II groups to work on these\n              issues.\n          15:00 - 17:30 \
    \ Breakout IIa meetings\n              Work on design issues.\n      Wed Feb 9\n\
    \           9:00 - 10:00   Plenary\n              Report, discuss.\n         \
    \ 10:00 - 13:30  Breakout IIb meetings\n              More work on design questions,\
    \ develop list of\n              requirements.\n          13:30 - 14:30  Plenary\n\
    \              Report, discuss.\n          15:30 - 17:30  Breakout III groups\n\
    \      Thurs Feb 10\n          9:00 - 9:30 Plenary\n          9:30 - 11:00 Breakout\
    \ Groups (wrapup)\n          11:00 - 12:00 Plenary\n              Discuss possible\
    \ short-term security recommendations\n          13:00 - 14:00  Plenary --  Discuss\
    \ short-term security issues\n          14:00 - 14:30  Plenary --  Presentation\
    \ by Steve Bellovin\n          14:30 - 16:00  Plenary --  Long- and Medium-term\n\
    \                                     Recommendations\n   The following scenarios\
    \ were used as a starting point for\n   discussions.  It distinguished security-S\
    \ (security as a service to\n   the end systems) from security-M, security as\
    \ a mechanism to support\n   other services.  The workshop was intended to be\
    \ primarily concerned\n   with interactions among the following different *services*:\n\
    \   o    Security-S\n   o    Routing\n   o    Multi-destination delivery (mcast-S)\n\
    \   o    Realtime Packet scheduling (realtime)\n   o    Mobility\n   o    Accounting\n\
    \        (and maybe large-scale?)\n   These categories were then applied to the\
    \ following scenarios:\n   S1.  Support a private teleconference among mobile\
    \ hosts connected to\n        the Internet.  [Security-S, mcast-S, realtime, mobility]\n\
    \   S2.  The group in S1 is 1/3 the Internet, i.e., there are VERY severe\n  \
    \      scaling problems.  [Security-S, mcast-S, realtime, mobility,\n        large-scale]\n\
    \   S3.  Charge for communication to support a video teleconference.\n       \
    \ [Accounting, realtime, mcast-S]\n   S4.  I am travelling with my laptop. I tune\
    \ in to radio channel IP-\n        RADIO, pick-up the beacon and start using it.\
    \  Who gets the\n        bill?  Why do they believe this is me?  Is \"me\" a piece\
    \ of\n        hardware (IP address) or a certified user (PEM certificate)?\n \
    \       [Mobility, accounting (, realtime, mcast-S)]\n   S5.  A Politically Important\
    \ Person will mcast an Internet\n        presentation, without danger of interruptions\
    \ from the audience.\n   S6.  The travel industry wants to use Internet to deliver\
    \ tickets to\n        customer premises directly in a secure way, but the customer\
    \ has\n        only dial-up capability.  [Security-S, mobility]\n   S7.  I am\
    \ traveling with my laptop and this friendly host is running\n        the autoconfiguration\
    \ protocol. I immediately get an address as\n        \"mac1.friendly.host.com\"\
    .   (What is the difference between my\n        laptop and a bona fide autoconfigured\
    \ local station?)\n        [Security-S, mobility]\n   S8.  Multiple people are\
    \ connected to a subnetwork providing mobility\n        (e.g., cellular, packet\
    \ radio). The subnetwork is connected to\n        multiple places in the \"fixed\"\
    \ backbone. How can routing be done\n        efficiently?  [Routing, mobility]\n\
    \   The following scenarios that were suggested do not fit into the\n   primary\
    \ thrust of the workshop, generally because they are single-\n   issue topics.\
    \  Most of them are pure security topics and are\n   concerned with the security\
    \ perimeter.  The last two do not fit into\n   our classification system at all.\n\
    \   S9.  XYZ corporation has two major branches on opposite ends of the\n    \
    \    world, and they want to communicate securely over the Internet,\n       \
    \ with each branch having IP-level connectivity to the other (not\n        through\
    \ application gateways).\n   S10. I am visiting XYZ corporation, with my laptop.\
    \  I want to\n        connect it to their LAN to read my email remotely over the\n\
    \        Internet.  Even though I am inside their corporate firewall,\n      \
    \  they want to be protect their machines from me.\n   S11. XYZ corporation is\
    \ trying to use the Internet to support both\n        private and public networking.\
    \  It wants to provide full\n        connectivity internally between all of its\
    \ resources, and to\n        provide public access to certain resources (analogous\
    \ of\n        anonymous ftp servers)\n   S12. The travel industry wants to use\
    \ Internet to deliver tickets to\n        customer premises directly in a secure\
    \ way.\n   S13. Some hacker is deliberately subverting routing protocols,\n  \
    \      including mobile and multicast routing.  Design counter\n        measures.\n\
    \   S14. Part of the Internet is running IPv4 and part is running IPng\n     \
    \   (i.e.  the Internet is in transition). How can we assure\n        continued\
    \ secure operation through such a transition?\n   S15. A corporation uses ATM\
    \ to connect a number of its sites. It also\n        uses Internet. It wants to\
    \ make use of the ATM as its primary\n        carrier, but also wants to utilize\
    \ other networking technologies\n        as appropriate (e.g., mobile radio).\
    \  It wants to support all\n        media (data, voice, video).\n"
- title: Security Considerations
  contents:
  - "Security Considerations\n   This memo is entirely concerned with security issues.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Bob Braden [Editor]\n   USC Information Sciences Institute\n\
    \   4676 Admiralty Way\n   Marina del Rey, CA 90292-6695\n   Phone: (310) 822-1511\n\
    \   EMail: Braden@ISI.EDU\n   David Clark\n   MIT Laboratory for Computer Science\n\
    \   545 Technology Square\n   Cambridge, MA 02139-1986\n   Phone: 617-253-6003\n\
    \   EMail: ddc@lcs.mit.edu\n   Steve Crocker\n   Trusted Information Systems,\
    \ Inc.\n   3060 Washington Road (Rte 97)\n   Glenwood, MD 21738\n   Phone: (301)\
    \ 854-6889\n   EMail: crocker@tis.com\n   Christian Huitema\n   INRIA, Sophia-Antipolis\n\
    \   2004 Route des Lucioles\n   BP 109\n   F-06561 Valbonne Cedex\n   France\n\
    \   Phone:  +33 93 65 77 15\n   EMail: Christian.Huitema@MIRSA.INRIA.FR\n"
