- title: __initial_text__
  contents:
  - ''
- title: Internet Architecture Board (IAB)                              R. Barnes
  contents:
  - "Internet Architecture Board (IAB)                              R. Barnes\n  Technical\
    \ Considerations for Internet Service Blocking and Filtering\n"
- title: Abstract
  contents:
  - "Abstract\n   The Internet is structured to be an open communications medium.\
    \  This\n   openness is one of the key underpinnings of Internet innovation, but\n\
    \   it can also allow communications that may be viewed as undesirable by\n  \
    \ certain parties.  Thus, as the Internet has grown, so have mechanisms\n   to\
    \ limit the extent and impact of abusive or objectionable\n   communications.\
    \  Recently, there has been an increasing emphasis on\n   \"blocking\" and \"\
    filtering\", the active prevention of such\n   communications.  This document\
    \ examines several technical approaches\n   to Internet blocking and filtering\
    \ in terms of their alignment with\n   the overall Internet architecture.  When\
    \ it is possible to do so, the\n   approach to blocking and filtering that is\
    \ most coherent with the\n   Internet architecture is to inform endpoints about\
    \ potentially\n   undesirable services, so that the communicants can avoid engaging\
    \ in\n   abusive or objectionable communications.  We observe that certain\n \
    \  filtering and blocking approaches can cause unintended consequences\n   to\
    \ third parties, and we discuss the limits of efficacy of various\n   approaches.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Architecture Board (IAB)\n   and represents information that\
    \ the IAB has deemed valuable to\n   provide for permanent record.  It represents\
    \ the consensus of the\n   Internet Architecture Board (IAB).  Documents approved\
    \ for\n   publication by the IAB are not a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7754.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2016 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Introduction  . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   4\n   2.  Filtering Examples  . . . . . . . . . . . . . . . . .\
    \ . . . .   5\n   3.  Characteristics of Blocking Systems . . . . . . . . . .\
    \ . . .   7\n     3.1.  The Party Who Sets Blocking Policies  . . . . . . . .\
    \ . .   8\n     3.2.  Purposes of Blocking  . . . . . . . . . . . . . . . . .\
    \ .   8\n       3.2.1.  Blacklist vs. Whitelist Model . . . . . . . . . . . .\
    \   9\n     3.3.  Intended Targets of Blocking  . . . . . . . . . . . . . .  \
    \ 9\n     3.4.  Components Used for Blocking  . . . . . . . . . . . . . .  10\n\
    \   4.  Evaluation of Blocking Design Patterns  . . . . . . . . . . .  11\n  \
    \   4.1.  Criteria for Evaluation . . . . . . . . . . . . . . . . .  11\n    \
    \   4.1.1.  Scope: What set of hosts and users are affected?  . .  12\n      \
    \ 4.1.2.  Granularity: How specific is the blocking?  Will\n               blocking\
    \ one service also block others? . . . . . . .  12\n       4.1.3.  Efficacy: How\
    \ easy is it for a resource or service to\n               avoid being blocked?\
    \  . . . . . . . . . . . . . . . .  13\n       4.1.4.  Security: How does the\
    \ blocking impact existing trust\n               infrastructures?  . . . . . .\
    \ . . . . . . . . . . . .  14\n     4.2.  Network-Based Blocking  . . . . . .\
    \ . . . . . . . . . . .  15\n       4.2.1.  Scope . . . . . . . . . . . . . .\
    \ . . . . . . . . . .  16\n       4.2.2.  Granularity . . . . . . . . . . . .\
    \ . . . . . . . . .  17\n       4.2.3.  Efficacy and Security . . . . . . . .\
    \ . . . . . . . .  17\n       4.2.4.  Summary . . . . . . . . . . . . . . . .\
    \ . . . . . . .  20\n     4.3.  Rendezvous-Based Blocking . . . . . . . . . .\
    \ . . . . . .  20\n       4.3.1.  Scope . . . . . . . . . . . . . . . . . . .\
    \ . . . . .  21\n       4.3.2.  Granularity . . . . . . . . . . . . . . . . .\
    \ . . . .  21\n       4.3.3.  Efficacy  . . . . . . . . . . . . . . . . . . .\
    \ . . .  21\n       4.3.4.  Security and Other Implications . . . . . . . . .\
    \ . .  22\n       4.3.5.  Examples  . . . . . . . . . . . . . . . . . . . . .\
    \ .  22\n       4.3.6.  Summary . . . . . . . . . . . . . . . . . . . . . . .\
    \  23\n     4.4.  Endpoint-Based Blocking . . . . . . . . . . . . . . . . .  24\n\
    \       4.4.1.  Scope . . . . . . . . . . . . . . . . . . . . . . . .  24\n  \
    \     4.4.2.  Granularity . . . . . . . . . . . . . . . . . . . . .  24\n    \
    \   4.4.3.  Efficacy  . . . . . . . . . . . . . . . . . . . . . .  25\n      \
    \ 4.4.4.  Security  . . . . . . . . . . . . . . . . . . . . . .  25\n       4.4.5.\
    \  Server Endpoints  . . . . . . . . . . . . . . . . . .  25\n       4.4.6.  Summary\
    \ . . . . . . . . . . . . . . . . . . . . . . .  26\n   5.  Security Considerations\
    \ . . . . . . . . . . . . . . . . . . .  26\n   6.  Conclusion  . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .  27\n   7.  Informative References  . .\
    \ . . . . . . . . . . . . . . . . .  28\n   IAB Members at the Time of Approval\
    \ . . . . . . . . . . . . . . .  32\n   Acknowledgments . . . . . . . . . . .\
    \ . . . . . . . . . . . . . .  33\n   Authors' Addresses  . . . . . . . . . .\
    \ . . . . . . . . . . . . .  33\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   The original design goal of the Internet was to enable communications\n\
    \   between hosts.  As this goal was met and people started using the\n   Internet\
    \ to communicate, however, it became apparent that some hosts\n   were engaging\
    \ in communications that were viewed as undesirable by\n   certain parties.  The\
    \ most famous early example of undesirable\n   communications was the Morris worm\
    \ [Morris], which used the Internet\n   to infect many hosts in 1988.  As the\
    \ Internet has evolved into a\n   rich communications medium, so too have mechanisms\
    \ to restrict\n   communications viewed as undesirable, ranging from acceptable\
    \ use\n   policies enforced through informal channels to technical blocking\n\
    \   mechanisms.\n   Efforts to restrict or deny access to Internet resources and\
    \ services\n   have evolved over time.  As noted in [RFC4084], some Internet service\n\
    \   providers perform filtering to restrict which applications their\n   customers\
    \ may use and which traffic they allow on their networks.\n   These restrictions\
    \ are often imposed with customer consent, where\n   customers may be enterprises\
    \ or individuals.  However, governments,\n   service providers, and enterprises\
    \ are increasingly seeking to block\n   or filter access to certain content, traffic,\
    \ or services without the\n   knowledge or agreement of affected users.  Where\
    \ these organizations\n   do not directly control networks themselves, they commonly\
    \ aim to\n   make use of intermediary systems to implement the blocking or\n \
    \  filtering.\n   While blocking and filtering remain highly contentious in many\
    \ cases,\n   the desire to restrict communications or access to content will\n\
    \   likely continue to exist.\n   The difference between \"blocking\" and \"filtering\"\
    \ is a matter of\n   scale and perspective.  \"Blocking\" often refers to preventing\
    \ access\n   to resources in the aggregate, while \"filtering\" refers to preventing\n\
    \   access to specific resources within an aggregate.  Both blocking and\n   filtering\
    \ can be implemented at the level of \"services\" (web hosting\n   or video streaming,\
    \ for example) or at the level of particular\n   \"content.\"  For the analysis\
    \ presented in this document, the\n   distinction between blocking and filtering\
    \ does not create\n   meaningfully different conclusions.  Hence, in the remainder\
    \ of this\n   document, we will treat the terms as being generally equivalent\
    \ and\n   applicable to restrictions on both content and services.\n   This document\
    \ aims to clarify the technical implications and trade-\n   offs of various blocking\
    \ strategies and to identify the potential for\n   different strategies to potentially\
    \ cause harmful side effects\n   (\"collateral damage\") for Internet users and\
    \ the overall Internet\n   architecture.  This analysis is limited to technical\
    \ blocking\n   mechanisms.  The scope of the analyzed blocking is limited to\n\
    \   intentional blocking, not accidental blocking due to misconfiguration\n  \
    \ or as an unintentional side effect of something else.\n   Filtering may be considered\
    \ legal, illegal, ethical, or unethical in\n   different places, at different\
    \ times, and by different parties.  This\n   document is intended for those who\
    \ are conducting filtering or are\n   considering conducting filtering and want\
    \ to understand the\n   implications of their decisions with respect to the Internet\n\
    \   architecture and the trade-offs that come with each type of filtering\n  \
    \ strategy.  This document does not present formulas on how to make\n   those\
    \ trade-offs; it is likely that filtering decisions require\n   knowledge of context-specific\
    \ details.  Whether particular forms of\n   filtering are lawful in particular\
    \ jurisdictions raises complicated\n   legal questions that are outside the scope\
    \ of this document.  For\n   similar reasons, questions about the ethics of particular\
    \ forms of\n   filtering are also out of scope.\n"
- title: 2.  Filtering Examples
  contents:
  - "2.  Filtering Examples\n   Blocking systems have evolved alongside the Internet\
    \ technologies\n   they seek to restrict.  Looking back at the history of the\
    \ Internet,\n   there have been several such systems deployed by different parties\n\
    \   and for different purposes.\n   Firewalls: Firewalls of various sorts are\
    \ very commonly employed at\n   many points in today's Internet [RFC2979].  They\
    \ can be deployed\n   either on end hosts (under user or administrator control)\
    \ or in the\n   network, typically at network boundaries.  While the Internet\n\
    \   Security Glossary [RFC4949] contains an extended definition of a\n   firewall,\
    \ informally, most people would tend to think of a firewall\n   as simply \"something\
    \ that blocks unwanted traffic\" (see [RFC4948] for\n   a discussion on many types\
    \ of unwanted traffic).  While there are\n   many sorts of firewalls, there are\
    \ several specific types of firewall\n   functionality worth noting.\n   o  Stateless\
    \ Packet Filtering: Stateless packet filters block\n      according to content-neutral\
    \ rules, e.g., blocking all inbound\n      connections or outbound connections\
    \ on certain ports, protocols,\n      or network-layer addresses.  For example,\
    \ blocking outbound\n      connections to port 25.\n   o  Stateful Packet Filtering:\
    \ More advanced configurations require\n      keeping state used to enforce flow-based\
    \ policies, e.g., blocking\n      inbound traffic for flows that have not been\
    \ established.\n   o  Deep Packet Inspection: Yet more advanced configurations\
    \ perform\n      deep packet inspection and filter or block based on the content\n\
    \      carried.  Many firewalls include web filtering capabilities (see\n    \
    \  below).\n   Web Filtering: HTTP and HTTPS are common targets for blocking and\n\
    \   filtering, typically targeted at specific URIs.  Some enterprises use\n  \
    \ HTTP blocking to block non-work-appropriate web sites, and several\n   nations\
    \ require HTTP and HTTPS filtering by their ISPs in order to\n   block content\
    \ deemed illegal.  HTTPS is a challenge for these\n   systems, because the URI\
    \ in an HTTPS request is carried inside the\n   encrypted channel.  To block access\
    \ to content made accessible via\n   HTTPS, filtering systems thus must either\
    \ block based on network- and\n   transport-layer headers (IP address and/or port),\
    \ or else obtain a\n   trust anchor certificate that is trusted by endpoints (and\
    \ thus act\n   as a man in the middle).  These filtering systems often take the\
    \ form\n   of \"portals\" or \"enterprise proxies\" presenting their own,\n  \
    \ dynamically generated HTTPS certificates.  (See further discussion in\n   Section\
    \ 5.)\n   Spam Filtering: Spam filtering is one of the oldest forms of content\n\
    \   filtering.  Spam filters evaluate messages based on a variety of\n   criteria\
    \ and information sources to decide whether a given message is\n   spam.  For\
    \ example, DNS Blacklists use the reverse DNS to flag\n   whether an IP address\
    \ is a known spam source [RFC5782].  Spam filters\n   can be installed on user\
    \ devices (e.g., in a mail client), operated\n   by a mail domain on behalf of\
    \ users, or outsourced to a third party\n   that acts as an intermediate MX proxy.\n\
    \   Domain Name Seizure: A number of approaches are used to block or\n   modify\
    \ resolution of a domain name.  One approach is to make use of\n   ICANN's Uniform\
    \ Dispute Resolution Policy (URDP) for the purposes of\n   dealing with fraudulent\
    \ use of a name.  Other authorities may require\n   that domains be blocked within\
    \ their jurisdictions.  Substantial\n   research has been performed on the value\
    \ and efficacy of such\n   seizures [Takedown08] [BlackLists14].\n   The precise\
    \ method of how domain names are seized will vary from\n   place to place.  One\
    \ approach in use is for queries to be redirected\n   to resolve to IP addresses\
    \ of the authority that hosts information\n   about the seizure.  The effectiveness\
    \ of domain seizures will\n   similarly vary based on the method.  In some cases,\
    \ the person whose\n   name was seized will simply use a new name.  In other cases,\
    \ the\n   block may only be effective within a region or when specific name\n\
    \   service infrastructure is used.\n   Seizures can also have overbroad effects,\
    \ since access to content is\n   blocked not only within the jurisdiction of the\
    \ seizure, but\n   globally, even when it may be affirmatively legal elsewhere\n\
    \   [RojaDirecta].  When domain redirection is effected via redirections\n   at\
    \ intermediate resolvers rather than at authoritative servers, it\n   directly\
    \ contradicts end-to-end assumptions in the DNS security\n   architecture [RFC4033],\
    \ potentially causing validation failures by\n   validating end-nodes.\n   Safe\
    \ Browsing: Modern web browsers provide some measures to prevent\n   users from\
    \ accessing malicious web sites.  For instance, before\n   loading a URI, current\
    \ versions of Google Chrome and Firefox use the\n   Google Safe Browsing service\
    \ to determine whether or not a given URI\n   is safe to load [SafeBrowsing].\
    \  The DNS can also be used to store\n   third party information that mark domains\
    \ as safe or unsafe\n   [RFC5782].\n   Manipulation of routing and addressing\
    \ data: Governments have\n   recently intervened in the management of IP addressing\
    \ and routing\n   information in order to maintain control over a specific set\
    \ of DNS\n   servers.  As part of an internationally coordinated response to the\n\
    \   DNSChanger malware, a Dutch court ordered the RIPE NCC to freeze the\n   accounts\
    \ of several resource holders as a means to limit the resource\n   holders' ability\
    \ to use certain address blocks [GhostClickRIPE] (also\n   see Section 4.3). \
    \ These actions have led to concerns that the number\n   resource certification\
    \ system and related secure routing technologies\n   developed by the IETF's SIDR\
    \ working group might be subject to\n   government manipulation as well [RFC6480],\
    \ potentially for the\n   purpose of denying targeted networks access to the Internet.\n\
    \   Ingress filtering: Network service providers use ingress filtering\n   [RFC2827]\
    \ [RFC3704] as a means to prevent source address spoofing\n   which is used as\
    \ a part of other attacks.\n   Data loss prevention (DLP): Enterprise and other\
    \ networks are\n   concerned with potential leaking of confidential information,\
    \ whether\n   accidental or intentional.  Some of the tools used for this are\n\
    \   similar to the main subject of this document of blocking and\n   filtering.\
    \  In particular, enterprise proxies might be part of a DLP\n   solution.\n"
- title: 3.  Characteristics of Blocking Systems
  contents:
  - "3.  Characteristics of Blocking Systems\n   At a generic level, blocking systems\
    \ can be characterized by four\n   attributes: the party who sets the blocking\
    \ policy, the purpose of\n   the blocking, the intended target of the blocking,\
    \ and the Internet\n   component(s) used as the basis of the blocking system.\n"
- title: 3.1.  The Party Who Sets Blocking Policies
  contents:
  - "3.1.  The Party Who Sets Blocking Policies\n   Parties that institute blocking\
    \ policies include governments, courts,\n   enterprises, network operators, reputation\
    \ trackers, application\n   providers, and individual end users.  A government\
    \ might create laws\n   based on cultural norms and/or their elected mandate.\
    \  Enterprises\n   might use cultural, industry, or legal norms to guide their\
    \ policies.\n   There can be several steps of translation and transformation from\
    \ the\n   original intended purpose -- first to laws, then to (government)\n \
    \  regulation, followed by high-level policies in, e.g., network\n   operators,\
    \ and from those policies to filtering architecture and\n   implementation.  Each\
    \ of those steps is a potential source of\n   unintended consequences as discussed\
    \ in this document.\n   In some cases, the policy setting entity is the same as\
    \ the entity\n   that enforces the policy.  For example, a network operator might\n\
    \   install a firewall in its own networking equipment, or a web\n   application\
    \ provider might block responses between its web server and\n   certain clients.\n\
    \   In other cases, the policy setting entity is different from the\n   entity\
    \ that enforces the policy.  Such policy might be imposed upon\n   the enforcing\
    \ entity, such as in the case of blocking initiated by\n   governments, or the\
    \ enforcing entity might explicitly choose to use\n   policy set by others, such\
    \ as in the case of a reputation system used\n   by a spam filter or safe browsing\
    \ service.  Because a policy might be\n   enforced by others, it is best if it\
    \ can be expressed in a form that\n   is independent of the enforcing technology.\n"
- title: 3.2.  Purposes of Blocking
  contents:
  - "3.2.  Purposes of Blocking\n   There are a variety of motivations to filter:\n\
    \   o  Preventing or responding to security threats.  Network operators,\n   \
    \   enterprises, application providers, and end users often block\n      communications\
    \ that are believed to be associated with security\n      threats or network attacks.\n\
    \   o  Restricting objectionable content or services.  Certain\n      communications\
    \ may be viewed as undesirable, harmful, or illegal\n      by particular governments,\
    \ enterprises, or users.  Governments may\n      seek to block communications\
    \ that are deemed to be defamation,\n      hate speech, obscenity, intellectual\
    \ property infringement, or\n      otherwise objectionable.  Enterprises may seek\
    \ to restrict\n      employees from accessing content that is not deemed to be\
    \ work\n      appropriate.  Parents may restrict their children from accessing\n\
    \      content or services targeted for adults.\n   o  Restricting access based\
    \ on business arrangements.  Some networks\n      are designed so as to only provide\
    \ access to certain content or\n      services (\"walled gardens\"), or to only\
    \ provide limited access\n      until end users pay for full Internet services\
    \ (captive portals\n      provided by hotspot operators, for example).\n"
- title: 3.2.1.  Blacklist vs. Whitelist Model
  contents:
  - "3.2.1.  Blacklist vs. Whitelist Model\n   Note that the purpose for which blocking\
    \ occurs often dictates\n   whether the blocking system operates on a blacklist\
    \ model, where\n   communications are allowed by default but a subset are blocked,\
    \ or a\n   whitelist model, where communications are blocked by default with\n\
    \   only a subset allowed.  Captive portals, walled gardens, and\n   sandboxes\
    \ used for security or network endpoint assessment usually\n   require a whitelist\
    \ model since the scope of communications allowed\n   is narrow.  Blocking for\
    \ other purposes often uses a blacklist model\n   since only individual content\
    \ or traffic is intended to be blocked.\n"
- title: 3.3.  Intended Targets of Blocking
  contents:
  - "3.3.  Intended Targets of Blocking\n   Blocking systems are instituted so as\
    \ to target particular content,\n   services, endpoints, or some combination of\
    \ these.  For example, a\n   \"content\" filtering system used by an enterprise\
    \ might block access\n   to specific URIs whose content is deemed by the enterprise\
    \ to be\n   inappropriate for the workplace.  This is distinct from a \"service\"\
    \n   filtering system that blocks all web traffic (perhaps as part of a\n   parental\
    \ control system on an end-user device) and also distinct from\n   an \"endpoint\"\
    \ filtering system in which a web application blocks\n   traffic from specific\
    \ endpoints that are suspected of malicious\n   activity.\n   As discussed in\
    \ Section 4, the design of a blocking system may affect\n   content, services,\
    \ or endpoints other than those that are the\n   intended targets.  For example,\
    \ when domain name seizures described\n   above are intended to address specific\
    \ web pages associated with\n   illegal activity, by removing the domains from\
    \ use, they affect all\n   services made available by the hosts associated with\
    \ those names,\n   including mail services and web services that may be unrelated\
    \ to the\n   illegal activity.  Depending on where the block is imposed within\
    \ the\n   DNS hierarchy, entirely unrelated organizations may be impacted.\n"
- title: 3.4.  Components Used for Blocking
  contents:
  - "3.4.  Components Used for Blocking\n   Broadly speaking, the process of delivering\
    \ an Internet service\n   involves three different components:\n   1.  Endpoints:\
    \ The actual content of the service is typically an\n       application-layer\
    \ protocol between two or more Internet hosts.\n       In many protocols, there\
    \ are two endpoints, a client and a\n       server.\n   2.  Network services:\
    \ The endpoints communicate by way of a\n       collection of IP networks that\
    \ use routing protocols to determine\n       how to deliver packets between the\
    \ endpoints.\n   3.  Rendezvous services: Service endpoints are typically identified\n\
    \       by identifiers that are more \"human-friendly\" than IP addresses.\n \
    \      Rendezvous services allow one endpoint to figure out how to\n       contact\
    \ another endpoint based on an identifier.  An example of a\n       rendezvous\
    \ service is the domain name system.  Distributed Hash\n       Tables (DHTs) have\
    \ also been used as rendezvous services.\n   Consider, for example, an HTTP transaction\
    \ fetching the content of\n   the URI <http://example.com/index.html>.  The client\
    \ endpoint is an\n   end host running a browser.  The client uses the DNS as a\
    \ rendezvous\n   service when it performs a AAAA query to obtain the IP address\
    \ for\n   the server name \"example.com\".  The client then establishes a\n  \
    \ connection to the server, and sends the actual HTTP request.  The\n   server\
    \ endpoint then responds to the HTTP request.\n   As another example, in the SIP\
    \ protocol, the two endpoints\n   communicating are IP phones, and the rendezvous\
    \ service is provided\n   by an application-layer SIP proxy as well as the DNS.\n\
    \   Blocking access to Internet content, services, or endpoints is done\n   by\
    \ controlling one or more of the components involved in the\n   provision of the\
    \ communications involved in accessing the content,\n   services, or endpoints.\
    \  In the HTTP example above, the successful\n   completion of the HTTP request\
    \ could have been prevented in several\n   ways:\n   o  [Endpoint] Preventing\
    \ the client from making the request\n   o  [Endpoint] Preventing the server from\
    \ responding to the request\n   o  [Endpoint] Preventing the client from making\
    \ the DNS request\n      needed to resolve example.com\n   o  [Network] Preventing\
    \ the request from reaching the server\n   o  [Network] Preventing the response\
    \ from reaching the client\n   o  [Network] Preventing the client from reaching\
    \ the DNS servers\n   o  [Network] Preventing the DNS responses from reaching\
    \ the client\n   o  [Rendezvous] Preventing the DNS servers from providing the\
    \ client\n      the correct IP address of the server\n   Those who desire to block\
    \ communications will typically have access\n   to only one or two components;\
    \ therefore their choices for how to\n   perform blocking will be limited.  End\
    \ users and application\n   providers can usually only control their own software\
    \ and hardware,\n   which means that they are limited to endpoint-based filtering.\
    \  Some\n   network operators offer filtering services that their customers can\n\
    \   activate individually, in which case end users might have network-\n   based\
    \ filtering systems available to them.  Network operators can\n   control their\
    \ own networks and the rendezvous services for which they\n   provide infrastructure\
    \ support (e.g., DNS resolvers) or to which they\n   may have access (e.g., SIP\
    \ proxies), but not usually endpoints.\n   Enterprises usually have access to\
    \ their own networks and endpoints\n   for filtering purposes.  Governments might\
    \ make arrangements with the\n   operators or owners of any of the three components\
    \ that exist within\n   their jurisdictions to perform filtering.\n   In the next\
    \ section, blocking systems designed according to each of\n   the three patterns\
    \ -- network services, rendezvous services, and\n   endpoints -- are evaluated\
    \ for their technical and architectural\n   implications.  The analysis is as\
    \ agnostic as possible as to who sets\n   the blocking policy (government, end\
    \ user, network operator,\n   application provider, or enterprise), but in some\
    \ cases the way in\n   which a particular blocking design pattern is used might\
    \ differ,\n   depending on the who desires a block.  For example, a network-based\n\
    \   firewall provided by an ISP that parents can elect to use for\n   parental\
    \ control purposes will likely function differently from one\n   that all ISPs\
    \ in a particular jurisdiction are required to use by the\n   local government,\
    \ even though in both cases the same component\n   (network) forms the basis of\
    \ the blocking system.\n"
- title: 4.  Evaluation of Blocking Design Patterns
  contents:
  - '4.  Evaluation of Blocking Design Patterns

    '
- title: 4.1.  Criteria for Evaluation
  contents:
  - "4.1.  Criteria for Evaluation\n   To evaluate the technical implications of each\
    \ of the blocking design\n   patterns, we compare them based on four criteria:\
    \ scope, granularity,\n   efficacy, and security.\n"
- title: '4.1.1.  Scope: What set of hosts and users are affected?'
  contents:
  - "4.1.1.  Scope: What set of hosts and users are affected?\n   The Internet is\
    \ comprised of many distinct autonomous networks and\n   applications, which means\
    \ that the impact of a blocking system will\n   only be within a defined topological\
    \ scope.  For example, blocking\n   within an access network will only affect\
    \ a well-defined set of users\n   (namely, those connected to the access network).\
    \  Blocking performed\n   by an application provider can affect users across the\
    \ entire\n   Internet.\n   Blocking systems are generally viewed as less objectionable\
    \ if the\n   scope of their impact is as narrow as possible while still being\n\
    \   effective, and as long as the impact of the blocking is within the\n   administrative\
    \ realm of the policy setting entity.  As mentioned\n   previously, enterprise\
    \ blocking systems are commonly deployed, and\n   will generally have impact on\
    \ enterprise users.  However, design\n   flaws in blocking systems may cause the\
    \ effects of blocking to be\n   overbroad.  For example, at least one service\
    \ provider blocking\n   content in accordance with a regulation has ended up blocking\
    \ content\n   for downstream service providers because it filtered routes to\n\
    \   particular systems and did not distribute the original information to\n  \
    \ downstream service providers in other jurisdictions\n   [IN-OM-filtering]. \
    \ Other service providers have accidentally leaked\n   such black hole routes\
    \ beyond the jurisdiction [NW08].  A substantial\n   amount of work has gone into\
    \ BGP security to avoid such attacks, but\n   deployment of such systems lags.\n"
- title: '4.1.2.  Granularity: How specific is the blocking?  Will blocking one'
  contents:
  - "4.1.2.  Granularity: How specific is the blocking?  Will blocking one\n     \
    \   service also block others?\n   Internet applications are built out of a collection\
    \ of loosely\n   coupled components or \"layers\".  Different layers serve different\n\
    \   purposes and rely on or offer different functions such as routing,\n   transport,\
    \ and naming (see [RFC1122], especially Section 1.1.3).  The\n   functions at\
    \ these layers are developed autonomously and almost\n   always operated by different\
    \ parties.  For example, in many networks,\n   physical and link-layer connectivity\
    \ is provided by an \"access\n   provider\", IP routing is performed by an \"\
    Internet service provider,\"\n   and application-layer services are provided by\
    \ completely separate\n   entities (e.g., web servers).  Upper-layer protocols\
    \ and applications\n   rely on combinations of lower-layer functions in order\
    \ to work.\n   Functionality at higher layers tends to be more specialized, so\
    \ that\n   many different specialized applications can make use of the same\n\
    \   generic underlying network functions.\n   As a result of this structure, actions\
    \ taken at one layer can affect\n   functionality or applications at other layers.\
    \  For example,\n   manipulating routing or naming functions to restrict access\
    \ to a\n   narrow set of resources via specific applications will likely affect\n\
    \   all applications that depend on those functions.  As with the scope\n   criteria,\
    \ blocking systems are generally viewed as less objectionable\n   when they are\
    \ highly granular and do not cause collateral damage to\n   content or services\
    \ unrelated to the target of the blocking\n   [RFC4924].\n   Even within the application\
    \ layer, the granularity of blocking can\n   vary depending on how targeted the\
    \ blocking system is designed to be.\n   Blocking all traffic associated with\
    \ a particular application\n   protocol is less granular than blocking only traffic\
    \ associated with\n   a subset of application instances that make use of that\
    \ protocol.\n   Sophisticated heuristics that make use of information about the\n\
    \   application protocol, lower-layer protocols, payload signatures,\n   source\
    \ and destination addresses, inter-packet timing, packet sizes,\n   and other\
    \ characteristics are sometimes used to narrow the subset of\n   traffic to be\
    \ blocked.\n"
- title: '4.1.3.  Efficacy: How easy is it for a resource or service to avoid'
  contents:
  - "4.1.3.  Efficacy: How easy is it for a resource or service to avoid\n       \
    \ being blocked?\n   Although blocking a resource or service might have some immediate\n\
    \   effect, efficacy must be evaluated in terms of whether it is easy to\n   circumvent.\
    \  Simply doing a one-time policy is often unlikely to have\n   lasting efficacy\
    \ (e.g., see [CleanFeed] and [BlackLists14]).\n   Experience has shown that, in\
    \ general, blacklisting requires\n   continual maintenance of the blacklist itself,\
    \ both to add new\n   entries for unwanted traffic and deleting entries when offending\n\
    \   content is removed.  Experience also shows that, depending on the\n   nature\
    \ of the block, it may be difficult to determine when to\n   unblock.  For instance,\
    \ if a host is blocked because it has been\n   compromised and used as a source\
    \ of attack, it may not be plainly\n   evident when that site has been fixed.\n\
    \   For blacklist-style blocking, the distributed and mobile nature of\n   Internet\
    \ resources limits the effectiveness of blocking actions.  A\n   service that\
    \ is blocked in one jurisdiction can often be moved or re-\n   instantiated in\
    \ another jurisdiction (see, for example,\n   [Malicious-Resolution]).  Likewise,\
    \ services that rely on blocked\n   resources can often be rapidly reconfigured\
    \ to use non-blocked\n   resources.  If a web site is prevented from using a domain\
    \ name or\n   set of IP addresses, the content can simply be moved to another\n\
    \   domain name or network, or use alternate syntaxes to express the same\n  \
    \ resource name (see the discussion of false negatives in [RFC6943]).\n   In a\
    \ process known as \"snowshoe spamming,\" a spam originator uses\n   addresses\
    \ in many different networks as sources for spam.  This\n   technique is already\
    \ widely used to spread spam generation across a\n   variety of resources and\
    \ jurisdictions to prevent spam blocking from\n   being effective.\n   In the\
    \ presence of either blacklist or whitelist systems, there are\n   several ways\
    \ in which a user or application can try to circumvent the\n   filters.\n   The\
    \ users may choose to use different sets of protocols or otherwise\n   alter their\
    \ traffic characteristics to circumvent the filters.  In\n   some cases, applications\
    \ may shift their traffic to port 80 or 443\n   when other ports are blocked.\
    \  Or, services may be tunneled within\n   other services, proxied by a collaborating\
    \ external host (e.g., an\n   anonymous redirector), or simply run over an alternate\
    \ port (e.g.,\n   port 8080 vs port 80 for HTTP).  Another means of circumvention\
    \ is\n   alteration of the service behavior to use a dynamic port negotiation\n\
    \   phase, in order to avoid use of a constant port address.\n   One of the primary\
    \ motivations for arguing that HTTP/2 should be\n   encrypted by default was that\
    \ unencrypted HTTP 1.1 traffic was\n   sometimes blocked or improperly processed.\
    \  Users or applications\n   shifting their traffic to encrypted HTTP has the\
    \ effect of\n   circumventing filters that depend on the HTTP plaintext payload.\n\
    \   If voice communication based on SIP [RFC3261] is blocked, users are\n   likely\
    \ to use applications which use proprietary protocols that allow\n   them to talk\
    \ to each other.\n   Some filtering systems are only capable of identifying IPv4\
    \ traffic\n   and therefore, by shifting to IPv6, users may be able to evade\n\
    \   filtering.  Using IPv6 with header options, using multiple layers of\n   tunnels,\
    \ or using encrypted tunnels can also make it more challenging\n   for blocking\
    \ systems to find transport ports within packets, making\n   port-based blocking\
    \ more difficult.  Thus, distribution and mobility\n   can hamper efforts to block\
    \ communications in a number of ways.\n"
- title: '4.1.4.  Security: How does the blocking impact existing trust'
  contents:
  - "4.1.4.  Security: How does the blocking impact existing trust\n        infrastructures?\n\
    \   Modern security mechanisms rely on trusted hosts communicating via a\n   secure\
    \ channel without intermediary interference.  Protocols such as\n   Transport\
    \ Layer Security (TLS) [RFC5246] and IPsec [RFC4301] are\n   designed to ensure\
    \ that each endpoint of the communication knows the\n   identity of the other\
    \ endpoint(s) and that only the endpoints of the\n   communication can access\
    \ the secured contents of the communication.\n   For example, when a user connects\
    \ to a bank's web site, TLS ensures\n   that the user's banking information is\
    \ securely communicated to the\n   bank and nobody else, ensuring the data remains\
    \ confidential while in\n   transit.\n   Some blocking strategies require intermediaries\
    \ to insert themselves\n   within the end-to-end communications path, potentially\
    \ breaking\n   security properties of Internet protocols [RFC4924].  In these\
    \ cases,\n   it can be difficult or impossible for endpoints to distinguish\n\
    \   between attackers and \"authorized\" parties conducting blocking.  For\n \
    \  example, an enterprise firewall administrator could gain access to\n   users'\
    \ personal bank accounts when users on the enterprise network\n   connect to bank\
    \ web sites.\n   Finally, one needs to evaluate whether a blocking mechanism can\
    \ be\n   used by an end user to efficiently locate blocked resources that can\n\
    \   then be accessed via other mechanisms that circumvent the blocking\n   mechanism.\
    \  For example, Clayton [CleanFeed] showed how special\n   treatment in one blocking\
    \ system could be detected by end users in\n   order to efficiently locate illegal\
    \ web sites, which was thus\n   counterproductive to the policy objective of the\
    \ blocking mechanism.\n"
- title: 4.2.  Network-Based Blocking
  contents:
  - "4.2.  Network-Based Blocking\n   Being able to block access to resources without\
    \ the consent or\n   cooperation of either endpoint is viewed as a desirable feature\
    \ by\n   some that deploy blocking systems.  Systems that have this property\n\
    \   are often implemented using intermediary devices in the network, such\n  \
    \ as firewalls or filtering systems.  These systems inspect traffic as\n   it\
    \ passes through the network, decide based on the characteristics or\n   content\
    \ of a given communication whether it should be blocked, and\n   then block or\
    \ allow the communication as desired.  For example, web\n   filtering devices\
    \ usually inspect HTTP requests to determine the URI\n   being requested, compare\
    \ that URI to a list of blacklisted or\n   whitelisted URIs, and allow the request\
    \ to proceed only if it is\n   permitted by policy.  Firewalls perform a similar\
    \ function for other\n   classes of traffic in addition to HTTP.  Some blocking\
    \ systems focus\n   on specific application-layer traffic, while others, such\
    \ as router\n   Access Control Lists (ACLs), filter traffic based on lower-layer\n\
    \   criteria (transport protocol and source or destination addresses or\n   ports).\n\
    \   Intermediary systems used for blocking are often not far from the\n   edge\
    \ of the network.  For example, many enterprise networks operate\n   firewalls\
    \ that block certain web sites, as do some residential ISPs.\n   In some cases,\
    \ this filtering is done with the consent or cooperation\n   of the affected endpoints.\
    \  PCs within an enterprise, for example,\n   might be configured to trust an\
    \ enterprise proxy, a residential ISP\n   might offer a \"safe browsing\" service,\
    \ or mail clients might\n   authorize mail servers on the local network to filter\
    \ spam on their\n   behalf.  These cases share some of the properties of the \"\
    Endpoint-\n   Based Blocking\" scenarios discussed in Section 4.4 below, since\
    \ the\n   endpoint has made an informed decision to authorize the intermediary\n\
    \   to block on its behalf and is therefore unlikely to attempt to\n   circumvent\
    \ the blocking.  From an architectural perspective, however,\n   they may create\
    \ many of the same problems as network-based filtering\n   conducted without consent.\n"
- title: 4.2.1.  Scope
  contents:
  - "4.2.1.  Scope\n   In the case of government-initiated blocking, network operators\n\
    \   subject to a specific jurisdiction may be required to block or\n   filter.\
    \  Thus, it is possible for laws to be structured to result in\n   blocking by\
    \ imposing obligations on the operators of networks within\n   a jurisdiction,\
    \ either via direct government action or by allowing\n   private actors to demand\
    \ blocking (e.g., through lawsuits).\n   Regardless of who is responsible for\
    \ a blocking policy, enforcement\n   can be done using Stateless Packet Filtering,\
    \ Stateful Packet\n   Filtering, or Deep Packet Inspection as defined in Section\
    \ 2.  While\n   network-based Stateless Packet Filtering has granularity issues\n\
    \   discussed in Section 4.2.2, network-based Stateful Packet Filtering\n   and\
    \ Deep Packet Inspection approaches often run into several\n   technical issues\
    \ that limit their viability in practice.  For\n   example, many issues arise\
    \ from the fact that an intermediary needs\n   to have access to a sufficient\
    \ amount of traffic to make its blocking\n   determinations.\n   For residential\
    \ or consumer networks with many egress points, the\n   first step to obtaining\
    \ this traffic is simply gaining access to the\n   constituent packets.  The Internet\
    \ is designed to deliver packets\n   independently from source to destination\
    \ -- not to any particular\n   point along the way.  Thus, the sequence of packets\
    \ from the sender\n   can only be reliably reconstructed at the intended receiver.\
    \  In\n   addition, inter-network routing is often asymmetric, and for\n   sufficiently\
    \ complex local networks, intra-network traffic flows can\n   be asymmetric as\
    \ well [asymmetry].  Thus, packets in the reverse\n   direction use a different\
    \ sent of paths than the forward direction.\n   This asymmetry means that an intermediary\
    \ in a network with many\n   egress points may, depending on topology and configuration,\
    \ see only\n   one half of a given communication, which may limit the scope of\
    \ the\n   communications that it can filter.  For example, a filter aimed at\n\
    \   requests destined for particular URIs cannot make accurate blocking\n   decisions\
    \ based on the URI if it is only in the data path for HTTP\n   responses and not\
    \ requests, since the URI is not included in the\n   responses.  Asymmetry may\
    \ be surmountable given a filtering system\n   with enough distributed, interconnected\
    \ filtering nodes that can\n   coordinate information about flows belonging to\
    \ the same\n   communication or transaction, but depending on the size of the\n\
    \   network this may imply significant complexity in the filtering\n   system.\
    \  Routing can sometimes be forced to be symmetric within a\n   given network\
    \ using routing configuration, NAT, or Layer 2 mechanisms\n   (e.g., MPLS), but\
    \ these mechanisms are frequently brittle, complex,\n   and costly -- and can\
    \ sometimes result in reduced network performance\n   relative to asymmetric routing.\
    \  Enterprise networks may also be less\n   susceptible to these problems if they\
    \ route all traffic through a\n   small number of egress points.\n"
- title: 4.2.2.  Granularity
  contents:
  - "4.2.2.  Granularity\n   Once an intermediary in a network has access to traffic,\
    \ it must\n   identify which packets must be filtered.  This decision is usually\n\
    \   based on some combination of information at the network layer (e.g.,\n   IP\
    \ addresses), transport layer (ports), or application layer (URIs or\n   other\
    \ content).  Deep Packet Inspection type blocking based on\n   application-layer\
    \ attributes can be potentially more granular and\n   less likely to cause collateral\
    \ damage than blocking all traffic\n   associated with a particular address, which\
    \ can impact unrelated\n   occupants of the same address.  However, more narrowly\
    \ focused\n   targeting may be more complex, less efficient, or easier to\n  \
    \ circumvent than filtering that sweeps more broadly, and those who\n   seek to\
    \ block must balance these attributes against each other when\n   choosing a blocking\
    \ system.\n"
- title: 4.2.3.  Efficacy and Security
  contents:
  - "4.2.3.  Efficacy and Security\n   Regardless of the layer at which blocking occurs,\
    \ it may be open to\n   circumvention, particularly in cases where network endpoints\
    \ have not\n   authorized the blocking.  The communicating endpoints can deny\
    \ the\n   intermediary access to attributes at any layer by using encryption\n\
    \   (see below).  IP addresses must be visible, even if packets are\n   protected\
    \ with IPsec, but blocking based on IP addresses can be\n   trivial to circumvent.\
    \  A filtered site may be able to quickly change\n   its IP address using only\
    \ a few simple steps: changing a single DNS\n   record and provisioning the new\
    \ address on its server or moving its\n   services to the new address [BT-TPB].\n\
    \   Indeed, Poort, et al. [Poort] found that \"any behavioural change in\n   response\
    \ to blocking access to The Pirate Bay has had no lasting net\n   impact on the\
    \ overall number of downloaders from illegal sources, as\n   new consumers have\
    \ started downloading from illegal sources and\n   people learn to circumvent\
    \ the blocking while new illegal sources may\n   be launched, causing file sharing\
    \ to increase again\", and that these\n   results \"are in line with a tendency\
    \ found in the literature that any\n   effects of legal action against file sharing\
    \ often fade out after a\n   period of typically six months.\"\n   If application\
    \ content is encrypted with a security protocol such as\n   IPsec or TLS, then\
    \ the intermediary will require the ability to\n   decrypt the packets to examine\
    \ application content, or resort to\n   statistical methods to guess what the\
    \ content is.  Since security\n   protocols are generally designed to provide\
    \ end-to-end security\n   (i.e., to prevent intermediaries from examining content),\
    \ the\n   intermediary would need to masquerade as one of the endpoints,\n   breaking\
    \ the authentication in the security protocol, reducing the\n   security of the\
    \ users and services affected, and interfering with\n   legitimate private communication.\
    \  Besides, various techniques that\n   use public databases with whitelisted\
    \ keys (e.g., DANE [RFC6698])\n   enable users to detect these sort of intermediaries.\
    \  Those users are\n   then likely to act as if the service is blocked.\n   If\
    \ the intermediary is unable to decrypt the security protocol, then\n   its blocking\
    \ determinations for secure sessions can only be based on\n   unprotected attributes,\
    \ such as IP addresses, protocol IDs, port\n   numbers, packet sizes, and packet\
    \ timing.  Some blocking systems\n   today still attempt to block based on these\
    \ attributes, for example\n   by blocking TLS traffic to known proxies that could\
    \ be used to tunnel\n   through the blocking system.\n   However, as the Telex\
    \ project [Telex] recently demonstrated, if an\n   endpoint cooperates with a\
    \ relay in the network (e.g., a Telex\n   station), it can create a TLS tunnel\
    \ that is indistinguishable from\n   legitimate traffic.  For example, if an ISP\
    \ used by a banking web\n   site were to operate a Telex station at one of its\
    \ routers, then a\n   blocking system would be unable to distinguish legitimate\
    \ encrypted\n   banking traffic from Telex-tunneled traffic (potentially carrying\n\
    \   content that would have been filtered).\n   Thus, in principle in a blacklist\
    \ system it is impossible to block\n   tunneled traffic through an intermediary\
    \ device without blocking all\n   secure traffic from that system.  (The only\
    \ limitation in practice is\n   the requirement for special software on the client.)\
    \  Those who\n   require that secure traffic be blocked from such sites risk blocking\n\
    \   content that would be valuable to their users, perhaps impeding\n   substantial\
    \ economic activity.  Conversely, those who are hosting a\n   myriad of content\
    \ have an incentive to see that law abiding content\n   does not end up being\
    \ blocked.\n   Governments and network operators should, however, take care not\
    \ to\n   encourage the use of insecure communications in the naming of\n   security,\
    \ as doing so will invariably expose their users to the\n   various attacks that\
    \ the security protocols were put in place to\n   prevent.\n   Some operators\
    \ may assume that only blocking access to resources\n   available via unsecure\
    \ channels is sufficient for their purposes --\n   i.e., that the size of the\
    \ user base that will be willing to use\n   secure tunnels and/or special software\
    \ to circumvent the blocking is\n   low enough to make blocking via intermediaries\
    \ worthwhile.  Under\n   that assumption, one might decide that there is no need\
    \ to control\n   secure traffic and thus that network-based blocking is an attractive\n\
    \   option.\n   However, the longer such blocking systems are in place, the more\n\
    \   likely it is that efficient and easy-to-use tunneling tools will\n   become\
    \ available.  The proliferation of the Tor network, for example,\n   and its increasingly\
    \ sophisticated blocking-avoidance techniques\n   demonstrate that there is energy\
    \ behind this trend [Tor].  Thus,\n   network-based blocking becomes less effective\
    \ over time.\n   Network-based blocking is a key contributor to the arms race\
    \ that has\n   led to the development of such tools, the result of which is to\n\
    \   create unnecessary layers of complexity in the Internet.  Before\n   content-based\
    \ blocking became common, the next best option for\n   network operators was port\
    \ blocking, the widespread use of which has\n   driven more applications and services\
    \ to use ports (80 and 443 most\n   commonly) that are unlikely to be blocked.\
    \  In turn, network\n   operators shifted to finer-grained content blocking over\
    \ port 80,\n   content providers shifted to encrypted channels, and operators\
    \ began\n   seeking to identify those channels (although doing so can be\n   resource-prohibitive,\
    \ especially if tunnel endpoints begin to change\n   frequently).  Because the\
    \ premise of network-based blocking is that\n   endpoints have incentives to circumvent\
    \ it, this cat-and-mouse game\n   is an inevitable by-product of this form of\
    \ blocking.\n   One reason above all stands as an enormous challenge to network-based\n\
    \   blocking: the Internet was designed with the premise that people will\n  \
    \ want to connect and communicate.  IP will run on anything up to and\n   including\
    \ carrier pigeons [RFC1149].  It often runs atop TLS and has\n   been made to\
    \ run on other protocols that themselves run atop IP.\n   Because of this fundamental\
    \ layering approach, nearly any authorized\n   avenue of communication can be\
    \ used as a transport.  This same\n   \"problem\" permits communications to succeed\
    \ in the most challenging\n   of environments.\n"
- title: 4.2.4.  Summary
  contents:
  - "4.2.4.  Summary\n   In sum, network-based blocking is only effective in a fairly\n\
    \   constrained set of circumstances.  First, the traffic needs to flow\n   through\
    \ the network in such a way that the intermediary device has\n   access to any\
    \ communications it intends to block.  Second, the\n   blocking system needs an\
    \ out-of-band mechanism to mitigate the risk\n   of secure protocols being used\
    \ to avoid blocking (e.g., human\n   analysts identifying IP addresses of tunnel\
    \ endpoints).  If the\n   network is sufficiently complex, or the risk of tunneling\
    \ too high,\n   then network-based blocking is unlikely to be effective, and in\
    \ any\n   case this type of blocking drives the development of increasingly\n\
    \   complex layers of circumvention.  Network-based blocking can be done\n   without\
    \ the cooperation of either endpoint to a communication, but it\n   has the serious\
    \ drawback of breaking end-to-end security assurances\n   in some cases.  The\
    \ fact that network-based blocking is premised on\n   this lack of cooperation\
    \ results in arms races that increase the\n   complexity of both application design\
    \ and network design.\n"
- title: 4.3.  Rendezvous-Based Blocking
  contents:
  - "4.3.  Rendezvous-Based Blocking\n   Internet applications often require or rely\
    \ on support from common,\n   global rendezvous services, including the DNS, certificate\n\
    \   authorities, search engines, WHOIS databases, and Internet Route\n   Registries.\
    \  These services control or register the structure and\n   availability of Internet\
    \ applications by providing data elements that\n   are used by application code.\
    \  Some applications also have their own\n   specialized rendezvous services.\
    \  For example, to establish an end-\n   to-end SIP call, the end-nodes (terminals)\
    \ rely on presence and\n   session information supplied by SIP servers.\n   Global\
    \ rendezvous services are comprised of generic technical\n   databases intended\
    \ to record certain facts about the network.  The\n   DNS, for example, stores\
    \ information about which servers provide\n   services for a given name, and the\
    \ Resource Public Key Infrastructure\n   (RPKI) stores information about which\
    \ organizations have been\n   allocated IP addresses.  To offer specialized Internet\
    \ services and\n   applications, different people rely on these generic records\
    \ in\n   different ways.  Thus, the effects of changes to the databases can be\n\
    \   much more difficult to predict than, for example, the effect of\n   shutting\
    \ down a web server (which fulfills the specific purpose of\n   serving web content).\n\
    \   Although rendezvous services are discussed as a single category, the\n   precise\
    \ characteristics and implications of blocking each kind of\n   rendezvous service\
    \ are slightly different.  This section provides\n   examples to highlight these\
    \ differences.\n"
- title: 4.3.1.  Scope
  contents:
  - "4.3.1.  Scope\n   In the case of government-initiated blocking, the operators\
    \ of\n   servers used to provide rendezvous service that are subject to a\n  \
    \ specific jurisdiction may be required to block or filter.  Thus, it\n   is possible\
    \ for laws to be structured to result in blocking by\n   imposing obligations\
    \ on the operators of rendezvous services within a\n   jurisdiction, either via\
    \ direct government action or by allowing\n   private actors to demand blocking\
    \ (e.g., through lawsuits).\n   The scope of blocking conducted by others will\
    \ depend on which\n   servers they can access.  For example, network operators\
    \ and\n   enterprises may be capable of conducting blocking using their own DNS\n\
    \   resolvers or application proxies within their networks, but not\n   authoritative\
    \ servers controlled by others.\n   However, if a service is hosted and operated\
    \ within a jurisdiction\n   where it is considered legitimate, then blocking access\
    \ at a global\n   rendezvous service (e.g., one within a jurisdiction where it\
    \ is\n   considered illegitimate) might deny services in jurisdictions where\n\
    \   they are considered legitimate.  This type of collateral damage is\n   lessened\
    \ when blocking is done at a local rendezvous server that only\n   has local impact,\
    \ rather than at a global rendezvous server with\n   global impact.\n"
- title: 4.3.2.  Granularity
  contents:
  - "4.3.2.  Granularity\n   Blocking at a global rendezvous service can be overbroad\
    \ if the\n   resources blocked support multiple services, since blocking service\n\
    \   can cause collateral damage to legitimate uses of other services.\n   For\
    \ example, a given address or domain name might host both\n   legitimate services\
    \ as well as services that some would desire to\n   block.\n"
- title: 4.3.3.  Efficacy
  contents:
  - "4.3.3.  Efficacy\n   The distributed nature of the Internet limits the efficacy\
    \ of\n   blocking based on rendezvous services.  If the Internet community\n \
    \  realizes that a blocking decision has been made and wishes to counter\n   it,\
    \ then local networks can \"patch\" the authoritative data that a\n   global rendezvous\
    \ service provides to avoid the blocking (although\n   the development of DNSSEC\
    \ and the RPKI are causing this to change by\n   requiring updates to be authorized).\
    \  In the DNS case, registrants\n   whose names get blocked can relocate their\
    \ resources to different\n   names.\n   Endpoints can also choose not to use a\
    \ particular rendezvous service.\n   They might switch to a competitor or use\
    \ an alternate mechanism (for\n   example, IP literals in URIs to circumvent DNS\
    \ filtering).\n"
- title: 4.3.4.  Security and Other Implications
  contents:
  - "4.3.4.  Security and Other Implications\n   Blocking of global rendezvous services\
    \ also has a variety of other\n   implications that may reduce the stability,\
    \ accessibility, and\n   usability of the global Internet.  Infrastructure-based\
    \ blocking may\n   erode the trust in the general Internet and encourage the development\n\
    \   of parallel or \"underground\" infrastructures causing forms of\n   Internet\
    \ fragmentation, for example.  This risk may become more acute\n   as the introduction\
    \ of security infrastructures and mechanisms such\n   as DNSSEC and RPKI \"hardens\"\
    \ the authoritative data -- including\n   blocked names or routes -- that the\
    \ existing infrastructure services\n   provide.  Those seeking to circumvent the\
    \ blocks may opt to use less-\n   secure but unblocked parallel services.  As\
    \ applied to the DNS, these\n   considerations are further discussed in RFC 2826\
    \ [RFC2826], in the\n   advisory [SAC-056] from ICANN's Security and Stability\
    \ Advisory\n   Committee (SSAC), and in the Internet Society's whitepaper on DNS\n\
    \   filtering [ISOCFiltering], but they also apply to other global\n   Internet\
    \ resources.\n"
- title: 4.3.5.  Examples
  contents:
  - "4.3.5.  Examples\n   Below we provide a few specific examples for routing, DNS,\
    \ and WHOIS\n   services.  These examples demonstrate that for these types of\n\
    \   rendezvous services (services that are often considered a global\n   commons),\
    \ jurisdiction-specific legal and ethical motivations for\n   blocking can both\
    \ have collateral effects in other jurisdictions and\n   be circumvented because\
    \ of the distributed nature of the Internet.\n   In 2008, Pakistan Telecom attempted\
    \ to deny access to YouTube within\n   Pakistan by announcing bogus routes for\
    \ YouTube address space to\n   peers in Pakistan.  YouTube was temporarily denied\
    \ service on a\n   global basis as a result of a route leak beyond the Pakistani\
    \ ISP's\n   scope, but service was restored in approximately two hours because\n\
    \   network operators around the world reconfigured their routers to\n   ignore\
    \ the bogus routes [RenesysPK].  In the context of SIDR and\n   secure routing,\
    \ a similar reconfiguration could theoretically be done\n   if a resource certificate\
    \ were to be revoked in order to block\n   routing to a given network.\n   In\
    \ the DNS realm, one of the recent cases of U.S. law enforcement\n   seizing domain\
    \ names involved RojaDirecta, a Spanish web site.  Even\n   though several of\
    \ the affected domain names belonged to Spanish\n   organizations, they were subject\
    \ to blocking by the U.S. government\n   because certain servers were operated\
    \ in the United States.\n   Government officials required the operators of the\
    \ parent zones of a\n   target name (e.g., \"com\" for \"example.com\") to direct\
    \ queries for\n   that name to a set of U.S.-government-operated name servers.\
    \  Users\n   of other services (e.g., email) under a target name would thus be\n\
    \   unable to locate the servers providing services for that name,\n   denying\
    \ them the ability to access these services.\n   Similar workarounds as those\
    \ that were used in the Pakistan Telecom\n   case are also available in the DNS\
    \ case.  If a domain name is blocked\n   by changing authoritative records, network\
    \ operators can restore\n   service simply by extending TTLs on cached pre-blocking\
    \ records in\n   recursive resolvers, or by statically configuring resolvers to\
    \ return\n   unblocked results for the affected name.  However, depending on the\n\
    \   availability of valid signature data, these types of workarounds will\n  \
    \ not work with DNSSEC-signed data.\n   The action of the Dutch authorities against\
    \ the RIPE NCC, where RIPE\n   was ordered to freeze the accounts of Internet\
    \ resource holders, is\n   of a similar character.  By controlling the account\
    \ holders' WHOIS\n   information, this type of action limited the ability of the\
    \ ISPs in\n   question to manage their Internet resources.  This example is\n\
    \   slightly different from the others because it does not immediately\n   impact\
    \ the ability of ISPs to provide connectivity.  While ISPs use\n   (and trust)\
    \ the WHOIS databases to build route filters or use the\n   databases for trouble-shooting\
    \ information, the use of the WHOIS\n   databases for those purposes is voluntary.\
    \  Thus, seizure of this\n   sort may not have any immediate effect on network\
    \ connectivity, but\n   it may impact overall trust in the common infrastructure.\
    \  It is\n   similar to the other examples in that action in one jurisdiction\
    \ can\n   have broader effects, and in that the global system may encourage\n\
    \   networks to develop their own autonomous solutions.\n"
- title: 4.3.6.  Summary
  contents:
  - "4.3.6.  Summary\n   In summary, rendezvous-based blocking can sometimes be used\
    \ to\n   immediately block a target service by removing some of the resources\n\
    \   it depends on.  However, such blocking actions can have harmful side\n   effects\
    \ due to the global nature of Internet resources and the fact\n   that many different\
    \ application-layer services rely on generic,\n   global databases for rendezvous\
    \ purposes.  The fact that Internet\n   resources can quickly shift between network\
    \ locations, names, and\n   addresses, together with the autonomy of the networks\
    \ that comprise\n   the Internet, can mean that the effects of rendezvous-based\
    \ blocking\n   can be negated on short order in some cases.  For some applications,\n\
    \   rendezvous services are optional to use, not mandatory.  Hence, they\n   are\
    \ only effective when the endpoint or the endpoint's network\n   chooses to use\
    \ them; they can be routed around by choosing not to use\n   the rendezvous service\
    \ or migrating to an alternative one.  To adapt\n   a quote by John Gilmore, \"\
    The Internet treats blocking as damage and\n   routes around it\".\n"
- title: 4.4.  Endpoint-Based Blocking
  contents:
  - "4.4.  Endpoint-Based Blocking\n   Internet users and their devices constantly\
    \ make decisions as to\n   whether to engage in particular Internet communications.\
    \  Users\n   decide whether to click on links in suspect email messages; browsers\n\
    \   advise users on sites that have suspicious characteristics; spam\n   filters\
    \ evaluate the validity of senders and messages.  If the\n   hardware and software\
    \ making these decisions can be instructed not to\n   engage in certain communications,\
    \ then the communications are\n   effectively blocked because they never happen.\n\
    \   There are several systems in place today that advise user systems\n   about\
    \ which communications they should engage in.  As discussed\n   above, several\
    \ modern browsers consult with \"Safe Browsing\" services\n   before loading a\
    \ web site in order to determine whether the site\n   could potentially be harmful.\
    \  Spam filtering is one of the oldest\n   types of filtering in the Internet;\
    \ modern filtering systems\n   typically make use of one or more \"reputation\"\
    \ or \"blacklist\"\n   databases in order to make decisions about whether a given\
    \ message or\n   sender should be blocked.  These systems typically have the property\n\
    \   that many filtering systems (browsers, Mail Transfer Agents (MTAs))\n   share\
    \ a single reputation service.  Even the absence of provisioned\n   PTR records\
    \ for an IP address may result in email messages not being\n   accepted.\n"
- title: 4.4.1.  Scope
  contents:
  - "4.4.1.  Scope\n   In an endpoint-based blocking system, blocking actions are\
    \ performed\n   autonomously, by individual endpoints or their delegates.  The\n\
    \   effects of blocking are thus usually local in scope, minimizing the\n   effects\
    \ on other users or other, legitimate services.\n"
- title: 4.4.2.  Granularity
  contents:
  - "4.4.2.  Granularity\n   Endpoint-based blocking avoids some of the limitations\
    \ of rendezvous-\n   based blocking: while rendezvous-based blocking can only\
    \ see and\n   affect the rendezvous service at hand (e.g., DNS name resolution),\n\
    \   endpoint-based blocking can potentially see into the entire\n   application,\
    \ across all layers and transactions.  This visibility can\n   provide endpoint-based\
    \ blocking systems with a much richer set of\n   information for making narrow\
    \ blocking decisions.  Support for narrow\n   granularity depends on how the application\
    \ protocol client and server\n   are designed, however.  A typical endpoint-based\
    \ firewall application\n   may have less ability to make fine-grained decisions\
    \ than an\n   application that does its own blocking (see [RFC7288] for further\n\
    \   discussion).\n"
- title: 4.4.3.  Efficacy
  contents:
  - "4.4.3.  Efficacy\n   Endpoint-based blocking deals well with mobile adversaries.\
    \  If a\n   blocked service relocates resources or uses different resources, a\n\
    \   rendezvous- or network-based blocking approach may not be able to\n   affect\
    \ the new resources (at least not immediately).  A network-based\n   blocking\
    \ system may not even be able to tell whether the new\n   resources are being\
    \ used, if the previously blocked service uses\n   secure protocols.  By contrast,\
    \ endpoint-based blocking systems can\n   detect when a blocked service's resources\
    \ have changed (because of\n   their full visibility into transactions) and adjust\
    \ blocking as\n   quickly as new blocking data can be sent out through a reputation\n\
    \   system.\n   The primary challenge to endpoint-based blocking is that it requires\n\
    \   the cooperation of endpoints.  Where this cooperation is willing,\n   this\
    \ is a fairly low barrier, requiring only reconfiguration or\n   software update.\
    \  Where cooperation is unwilling, it can be\n   challenging to enforce cooperation\
    \ for large numbers of endpoints.\n   That challenge is exacerbated when the endpoints\
    \ are a diverse set of\n   static, mobile, or visiting endpoints.  If cooperation\
    \ can be\n   achieved, endpoint-based blocking can be much more effective than\n\
    \   other approaches because it is so coherent with the Internet's\n   architectural\
    \ principles.\n"
- title: 4.4.4.  Security
  contents:
  - "4.4.4.  Security\n   Endpoint-based blocking is performed at one end of an Internet\n\
    \   communication, and thus avoids the problems related to end-to-end\n   security\
    \ mechanisms that network-based blocking runs into and the\n   challenges to global\
    \ trust infrastructures that rendezvous-based\n   blocking creates.\n"
- title: 4.4.5.  Server Endpoints
  contents:
  - "4.4.5.  Server Endpoints\n   In this discussion of endpoint-based blocking, the\
    \ focus has been on\n   the consuming side of the end-to-end communication, mostly\
    \ the client\n   side of a client-server type connection.  However, similar\n\
    \   considerations apply to the content-producing side of end-to-end\n   communications,\
    \ regardless of whether that endpoint is a server in a\n   client-server connection\
    \ or a peer in a peer-to-peer type of\n   connection.\n   For instance, for blocking\
    \ of web content, narrow targeting can be\n   achieved through whitelisting methods\
    \ like password authentication,\n   whereby passwords are available only to authorized\
    \ clients.  For\n   example, a web site might only make adult content available\
    \ to users\n   who provide credit card information, which is assumed to be a proxy\n\
    \   for age.\n   The fact that content-producing endpoints often do not take it\
    \ upon\n   themselves to block particular forms of content in response to\n  \
    \ requests from governments or other parties can sometimes motivate\n   those\
    \ latter parties to engage in blocking elsewhere within the\n   Internet.\n  \
    \ If a service is to be blocked, the best way of doing that is to\n   disable\
    \ the service at the server endpoint.\n"
- title: 4.4.6.  Summary
  contents:
  - "4.4.6.  Summary\n   Out of the three design patterns, endpoint-based blocking\
    \ is the\n   least likely to cause collateral damage to Internet services or the\n\
    \   overall Internet architecture.  Endpoint-based blocking systems can\n   potentially\
    \ see into all layers involved in a communication, allowing\n   blocking to be\
    \ narrowly targeted and can minimize unintended\n   consequences.  Adversary mobility\
    \ can be accounted for as soon as\n   reputation systems are updated with new\
    \ adversary information.  One\n   potential drawback of endpoint-based blocking\
    \ is that it requires the\n   endpoint's cooperation; implementing blocking at\
    \ an endpoint when it\n   is not in the endpoint's interest is therefore difficult\
    \ to\n   accomplish because the endpoint's user can disable the blocking or\n\
    \   switch to a different endpoint.\n"
- title: 5.  Security Considerations
  contents:
  - "5.  Security Considerations\n   The primary security concern related to Internet\
    \ service blocking is\n   the effect that it has on the end-to-end security model\
    \ of many\n   Internet security protocols.  When blocking is enforced by an\n\
    \   intermediary with respect to a given communication, the blocking\n   system\
    \ may need to obtain access to confidentiality-protected data to\n   make blocking\
    \ decisions.  Mechanisms for obtaining such access often\n   require the blocking\
    \ system to defeat the authentication mechanisms\n   built into security protocols.\n\
    \   For example, some enterprise firewalls will dynamically create TLS\n   certificates\
    \ under a trust anchor recognized by endpoints subject to\n   blocking.  These\
    \ certificates allow the firewall to authenticate as\n   any web site, so that\
    \ it can act as a man-in-the-middle on TLS\n   connections passing through the\
    \ firewall.  This is not unlike an\n   external attacker using compromised certificates\
    \ to intercept TLS\n   connections.\n   Modifications such as these obviously\
    \ make the firewall itself an\n   attack surface.  If an attacker can gain control\
    \ of the firewall or\n   compromise the key pair used by the firewall to sign\
    \ certificates,\n   the attacker will have access to the unencrypted data of all\
    \ current\n   and recorded TLS sessions for all users behind that firewall, in\
    \ a\n   way that is undetectable to users.  Besides, if the compromised key-\n\
    \   pairs can be extracted from the firewall, all users, not only those\n   behind\
    \ the firewall, that rely on that public key are vulnerable.\n   We must also\
    \ consider the possibility that a legitimate administrator\n   of such a firewall\
    \ could gain access to privacy-sensitive\n   information, such as the bank accounts\
    \ or health records of users who\n   access such secure sites through the firewall.\
    \  These privacy\n   considerations motivate legitimate use of secure end-to-end\
    \ protocols\n   that often make it difficult to enforce granular blocking policies.\n\
    \   When blocking systems are unable to inspect and surgically block\n   secure\
    \ protocols, it is tempting to completely block those protocols.\n   For example,\
    \ a web blocking system that is unable to inspect HTTPS\n   connections might\
    \ simply block any attempted HTTPS connection.\n   However, since Internet security\
    \ protocols are commonly used for\n   critical services such as online commerce\
    \ and banking, blocking these\n   protocols would block access to these services\
    \ as well, or worse,\n   force them to be conducted over insecure communication.\n\
    \   Security protocols can, of course, also be used as mechanisms for\n   blocking\
    \ services.  For example, if a blocking system can insert\n   invalid credentials\
    \ for one party in an authentication protocol, then\n   the other end will typically\
    \ terminate the connection based on the\n   authentication failure.  However,\
    \ it is typically much simpler to\n   simply block secure protocols than to exploit\
    \ those protocols for\n   service blocking.\n"
- title: 6.  Conclusion
  contents:
  - "6.  Conclusion\n   Filtering will continue to occur on the Internet.  We conclude\
    \ that,\n   whenever possible, filtering should be done on the endpoint.\n   Cooperative\
    \ endpoints are most likely to have sufficient contextual\n   knowledge to effectively\
    \ target blocking; hence, such blocking\n   minimizes unintended consequences.\
    \  It is realistic to expect that at\n   times filtering will not be done on the\
    \ endpoints.  In these cases,\n   promptly informing the endpoint that blocking\
    \ has occurred provides\n   necessary transparency to redress any errors, particularly\
    \ as they\n   relate to any collateral damage introduced by errant filters.\n\
    \   Blacklist approaches are often a game of \"cat and mouse\", where those\n\
    \   with the content move it around to avoid blocking.  Or, the content\n   may\
    \ even be naturally mirrored or cached at other legitimate sites\n   such as the\
    \ Internet Archive Wayback Machine [Wayback].  At the same\n   time, whitelists\
    \ provide similar risks because sites that had\n   \"acceptable\" content may\
    \ become targets for \"unacceptable content\",\n   and similarly, access to perfectly\
    \ inoffensive and perhaps useful or\n   productive content is unnecessarily blocked.\n\
    \   From a technical perspective, there are no perfect or even good\n   solutions\
    \ -- there is only least bad.  On that front, we posit that a\n   hybrid approach\
    \ that combines endpoint-based filtering with network\n   filtering may prove\
    \ least damaging.  An endpoint may choose to\n   participate in a filtering regime\
    \ in exchange for the network\n   providing broader unfiltered access.\n   Finally,\
    \ we note that where filtering is occurring to address content\n   that is generally\
    \ agreed to be inappropriate or illegal, strong\n   cooperation among service\
    \ providers and governments may provide\n   additional means to identify both\
    \ the victims and the perpetrators\n   through non-filtering mechanisms, such\
    \ as partnerships with the\n   finance industry to identify and limit illegal\
    \ transactions.\n"
- title: 7.  Informative References
  contents:
  - "7.  Informative References\n   [asymmetry]\n              John, W., Dusi, M.,\
    \ and K. Claffy, \"Estimating routing\n              symmetry on single links\
    \ by passive flow measurements\",\n              Proceedings of the 6th International\
    \ Wireless\n              Communications and Mobile Computing Conference, IWCMC\
    \ '10,\n              DOI 10.1145/1815396.1815506, 2010,\n              <http://www.caida.org/publications/papers/2010/\n\
    \              estimating_routing_symmetry/\n              estimating_routing_symmetry.pdf>.\n\
    \   [BlackLists14]\n              Chachra, N., McCoy, D., Savage, S., and G. Voelker,\n\
    \              \"Empirically Characterizing Domain Abuse and the Revenue\n   \
    \           Impact of Blacklisting\", Workshop on the Economics of\n         \
    \     Information Security 2014,\n              <http://www.econinfosec.org/archive/weis2014/papers/\n\
    \              Chachra-WEIS2014.pdf>.\n   [BT-TPB]   Meyer, D., \"BT blocks The\
    \ Pirate Bay\", June 2012,\n              <http://www.zdnet.com/\n           \
    \   bt-blocks-the-pirate-bay-4010026434/>.\n   [CleanFeed]\n              Clayton,\
    \ R., \"Failures in a Hybrid Content Blocking\n              System\", Fifth Privacy\
    \ Enhancing Technologies Workshop,\n              PET 2005, DOI 10.1007/11767831_6,\
    \ 2005,\n              <http://www.cl.cam.ac.uk/~rnc1/cleanfeed.pdf>.\n   [GhostClickRIPE]\n\
    \              RIPE NCC, \"RIPE NCC Blocks Registration in RIPE Registry\n   \
    \           Following Order from Dutch Police\", 2012,\n              <http://www.ripe.net/internet-coordination/news/\n\
    \              about-ripe-ncc-and-ripe/ripe-ncc-blocks-registration-in-\n    \
    \          ripe-registry-following-order-from-dutch-police>.\n   [IN-OM-filtering]\n\
    \              Citizen Lab, \"Routing Gone Wild: Documenting upstream\n      \
    \        filtering in Oman via India\", July 2012,\n              <https://citizenlab.org/2012/07/routing-gone-wild/>.\n\
    \   [ISOCFiltering]\n              Internet Society, \"DNS: Finding Solutions\
    \ to Illegal\n              On-line Activities\", 2012,\n              <http://www.internetsociety.org/what-we-do/issues/dns/\n\
    \              finding-solutions-illegal-line-activities>.\n   [Malicious-Resolution]\n\
    \              Dagon, D., Provos, N., Lee, C., and W. Lee, \"Corrupted DNS\n \
    \             Resolution Paths: The Rise of a Malicious Resolution\n         \
    \     Authority\", 2008,\n              <http://www.citi.umich.edu/u/provos/papers/\n\
    \              ndss08_dns.pdf>.\n   [Morris]   Kehoe, B., \"The Robert Morris\
    \ Internet Worm\", 1992,\n              <http://groups.csail.mit.edu/mac/classes/6.805/articles/\n\
    \              morris-worm.html>.\n   [NW08]     Marsan, C., \"YouTube/Pakistan\
    \ incident: Could something\n              similar whack your site?\", Network\
    \ World, March 2008,\n              <http://www.networkworld.com/article/2284273/software/\n\
    \              youtube-pakistan-incident--could-something-similar-whack-\n   \
    \           your-site-.html>.\n   [Poort]    Poort, J., Leenheer, J., van der\
    \ Ham, J., and C. Dumitru,\n              \"Baywatch: Two approaches to measure\
    \ the effects of\n              blocking access to The Pirate Bay\", Telecommunications\n\
    \              Policy 38:383-392, DOI 10.1016/j.telpol.2013.12.008, 2014,\n  \
    \            <http://staff.science.uva.nl/~vdham/research/\n              publications/1401-Baywatch.pdf>.\n\
    \   [RenesysPK]\n              Brown, M., \"Pakistan hijacks YouTube\", February\
    \ 2008,\n              <http://research.dyn.com/2008/02/\n              pakistan-hijacks-youtube-1/>.\n\
    \   [RFC1122]  Braden, R., Ed., \"Requirements for Internet Hosts -\n        \
    \      Communication Layers\", STD 3, RFC 1122,\n              DOI 10.17487/RFC1122,\
    \ October 1989,\n              <http://www.rfc-editor.org/info/rfc1122>.\n   [RFC1149]\
    \  Waitzman, D., \"Standard for the transmission of IP\n              datagrams\
    \ on avian carriers\", RFC 1149,\n              DOI 10.17487/RFC1149, April 1990,\n\
    \              <http://www.rfc-editor.org/info/rfc1149>.\n   [RFC2826]  Internet\
    \ Architecture Board, \"IAB Technical Comment on the\n              Unique DNS\
    \ Root\", RFC 2826, DOI 10.17487/RFC2826, May\n              2000, <http://www.rfc-editor.org/info/rfc2826>.\n\
    \   [RFC2827]  Ferguson, P. and D. Senie, \"Network Ingress Filtering:\n     \
    \         Defeating Denial of Service Attacks which employ IP Source\n       \
    \       Address Spoofing\", BCP 38, RFC 2827, DOI 10.17487/RFC2827,\n        \
    \      May 2000, <http://www.rfc-editor.org/info/rfc2827>.\n   [RFC2979]  Freed,\
    \ N., \"Behavior of and Requirements for Internet\n              Firewalls\",\
    \ RFC 2979, DOI 10.17487/RFC2979, October 2000,\n              <http://www.rfc-editor.org/info/rfc2979>.\n\
    \   [RFC3261]  Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston,\n    \
    \          A., Peterson, J., Sparks, R., Handley, M., and E.\n              Schooler,\
    \ \"SIP: Session Initiation Protocol\", RFC 3261,\n              DOI 10.17487/RFC3261,\
    \ June 2002,\n              <http://www.rfc-editor.org/info/rfc3261>.\n   [RFC3704]\
    \  Baker, F. and P. Savola, \"Ingress Filtering for Multihomed\n             \
    \ Networks\", BCP 84, RFC 3704, DOI 10.17487/RFC3704, March\n              2004,\
    \ <http://www.rfc-editor.org/info/rfc3704>.\n   [RFC4033]  Arends, R., Austein,\
    \ R., Larson, M., Massey, D., and S.\n              Rose, \"DNS Security Introduction\
    \ and Requirements\",\n              RFC 4033, DOI 10.17487/RFC4033, March 2005,\n\
    \              <http://www.rfc-editor.org/info/rfc4033>.\n   [RFC4084]  Klensin,\
    \ J., \"Terminology for Describing Internet\n              Connectivity\", BCP\
    \ 104, RFC 4084, DOI 10.17487/RFC4084,\n              May 2005, <http://www.rfc-editor.org/info/rfc4084>.\n\
    \   [RFC4301]  Kent, S. and K. Seo, \"Security Architecture for the\n        \
    \      Internet Protocol\", RFC 4301, DOI 10.17487/RFC4301,\n              December\
    \ 2005, <http://www.rfc-editor.org/info/rfc4301>.\n   [RFC4924]  Aboba, B., Ed.\
    \ and E. Davies, \"Reflections on Internet\n              Transparency\", RFC\
    \ 4924, DOI 10.17487/RFC4924, July 2007,\n              <http://www.rfc-editor.org/info/rfc4924>.\n\
    \   [RFC4948]  Andersson, L., Davies, E., and L. Zhang, \"Report from the\n  \
    \            IAB workshop on Unwanted Traffic March 9-10, 2006\",\n          \
    \    RFC 4948, DOI 10.17487/RFC4948, August 2007,\n              <http://www.rfc-editor.org/info/rfc4948>.\n\
    \   [RFC4949]  Shirey, R., \"Internet Security Glossary, Version 2\",\n      \
    \        FYI 36, RFC 4949, DOI 10.17487/RFC4949, August 2007,\n              <http://www.rfc-editor.org/info/rfc4949>.\n\
    \   [RFC5246]  Dierks, T. and E. Rescorla, \"The Transport Layer Security\n  \
    \            (TLS) Protocol Version 1.2\", RFC 5246,\n              DOI 10.17487/RFC5246,\
    \ August 2008,\n              <http://www.rfc-editor.org/info/rfc5246>.\n   [RFC5782]\
    \  Levine, J., \"DNS Blacklists and Whitelists\", RFC 5782,\n              DOI\
    \ 10.17487/RFC5782, February 2010,\n              <http://www.rfc-editor.org/info/rfc5782>.\n\
    \   [RFC6480]  Lepinski, M. and S. Kent, \"An Infrastructure to Support\n    \
    \          Secure Internet Routing\", RFC 6480, DOI 10.17487/RFC6480,\n      \
    \        February 2012, <http://www.rfc-editor.org/info/rfc6480>.\n   [RFC6698]\
    \  Hoffman, P. and J. Schlyter, \"The DNS-Based Authentication\n             \
    \ of Named Entities (DANE) Transport Layer Security (TLS)\n              Protocol:\
    \ TLSA\", RFC 6698, DOI 10.17487/RFC6698, August\n              2012, <http://www.rfc-editor.org/info/rfc6698>.\n\
    \   [RFC6943]  Thaler, D., Ed., \"Issues in Identifier Comparison for\n      \
    \        Security Purposes\", RFC 6943, DOI 10.17487/RFC6943, May\n          \
    \    2013, <http://www.rfc-editor.org/info/rfc6943>.\n   [RFC7288]  Thaler, D.,\
    \ \"Reflections on Host Firewalls\", RFC 7288,\n              DOI 10.17487/RFC7288,\
    \ June 2014,\n              <http://www.rfc-editor.org/info/rfc7288>.\n   [RojaDirecta]\n\
    \              Masnick, M., \"Homeland Security Seizes Spanish Domain Name\n \
    \             That Had Already Been Declared Legal\", 2011,\n              <http://www.techdirt.com/articles/20110201/10252412910/\n\
    \              homeland-security-seizes-spanish-domain-name-that-had-\n      \
    \        already-been-declared-legal.shtml>.\n   [SAC-056]  ICANN SSAC, \"SSAC\
    \ Advisory on Impacts of Content Blocking\n              via the Domain Name System\"\
    , October 2012,\n              <http://www.icann.org/en/groups/ssac/documents/\n\
    \              sac-056-en.pdf>.\n   [SafeBrowsing]\n              Google, \"Safe\
    \ Browsing API\", 2012,\n              <https://developers.google.com/safe-browsing/>.\n\
    \   [Takedown08]\n              Moore, T. and R. Clayton, \"The Impact of Incentives\
    \ on\n              Notice and Take-down\", Workshop on the Economics of\n   \
    \           Information Security 2008,\n              <http://www.econinfosec.org/archive/weis2008/papers/\n\
    \              MooreImpact.pdf>.\n   [Telex]    Wustrow, E., Wolchok, S., Goldberg,\
    \ I., and J. Halderman,\n              \"Telex: Anticensorship in the Network\
    \ Infrastructure\",\n              <https://telex.cc/>.\n   [Tor]      \"Tor Project:\
    \ Anonymity Online\",\n              <https://www.torproject.org/>.\n   [Wayback]\
    \  \"Internet Archive: Wayback Machine\",\n              <http://archive.org/web/>.\n"
- title: IAB Members at the Time of Approval
  contents:
  - "IAB Members at the Time of Approval\n   Jari Arkko\n   Mary Barnes\n   Marc Blanchet\n\
    \   Ralph Droms\n   Ted Hardie\n   Joe Hildebrand\n   Russ Housley\n   Erik Nordmark\n\
    \   Robert Sparks\n   Andrew Sullivan\n   Dave Thaler\n   Brian Trammell\n   Suzanne\
    \ Woolf\n"
- title: Acknowledgments
  contents:
  - "Acknowledgments\n   Thanks to the many reviewers who provided helpful comments,\n\
    \   especially Bill Herrin, Eliot Lear, Patrik Faltstrom, Pekka Savola,\n   and\
    \ Russ White.  NLnet Labs is also acknowledged as Olaf Kolkman's\n   employer\
    \ during most of this document's development.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Richard Barnes\n   Mozilla\n   Suite 300\n   650 Castro\
    \ Street\n   Mountain View, CA  94041\n   United States\n   Email: rlb@ipv.sx\n\
    \   Alissa Cooper\n   Cisco\n   707 Tasman Drive\n   Milpitas, CA  95035\n   United\
    \ States\n   Email: alcoop@cisco.com\n   Olaf Kolkman\n   Internet Society\n \
    \  Email: kolkman@isoc.org\n   Dave Thaler\n   Microsoft\n   One Microsoft Way\n\
    \   Redmond, WA  98052\n   United States\n   Email: dthaler@microsoft.com\n  \
    \ Erik Nordmark\n   Arista\n   Email: nordmark@arista.com\n"
