- contents:
  - '                      RTP Payload Format for G.719

    '
  title: __initial_text__
- contents:
  - "Status of This Memo\n   This document specifies an Internet standards track protocol
    for the\n   Internet community, and requests discussion and suggestions for\n
    \  improvements.  Please refer to the current edition of the \"Internet\n   Official
    Protocol Standards\" (STD 1) for the standardization state\n   and status of this
    protocol.  Distribution of this memo is unlimited.\n"
  title: Status of This Memo
- contents:
  - "Copyright Notice\n   Copyright (c) 2008 IETF Trust and the persons identified
    as the\n   document authors.  All rights reserved.\n   This document is subject
    to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents
    (http://trustee.ietf.org/\n   license-info) in effect on the date of publication
    of this document.\n   Please review these documents carefully, as they describe
    your rights\n   and restrictions with respect to this document.\n"
  title: Copyright Notice
- contents:
  - "Abstract\n   This document specifies the payload format for packetization of
    the\n   G.719 full-band codec encoded audio signals into the Real-time\n   Transport
    Protocol (RTP).  The payload format supports transmission\n   of multiple channels,
    multiple frames per payload, and interleaving.\n"
  title: Abstract
- contents:
  - "Table of Contents\n   1.  Introduction . . . . . . . . . . . . . . . . . . .
    . . . . . .  3\n   2.  Definitions and Conventions  . . . . . . . . . . . . .
    . . . .  3\n   3.  G.719 Description  . . . . . . . . . . . . . . . . . . . .
    . .  3\n   4.  Payload Format Capabilities  . . . . . . . . . . . . . . . . .
    \ 4\n     4.1.  Multi-Rate Encoding and Rate Adaptation  . . . . . . . . .  4\n
    \    4.2.  Support for Multi-Channel Sessions . . . . . . . . . . . .  5\n     4.3.
    \ Robustness against Packet Loss . . . . . . . . . . . . . .  5\n       4.3.1.
    \ Use of Forward Error Correction (FEC)  . . . . . . . .  5\n       4.3.2.  Use
    of Frame Interleaving  . . . . . . . . . . . . . .  6\n   5.  Payload Format .
    . . . . . . . . . . . . . . . . . . . . . . .  7\n     5.1.  RTP Header Usage
    . . . . . . . . . . . . . . . . . . . . .  8\n     5.2.  Payload Structure  .
    . . . . . . . . . . . . . . . . . . .  8\n       5.2.1.  Basic ToC Element  .
    . . . . . . . . . . . . . . . . .  9\n     5.3.  Basic Mode . . . . . . . . .
    . . . . . . . . . . . . . . . 10\n     5.4.  Interleaved Mode . . . . . . . .
    . . . . . . . . . . . . . 10\n     5.5.  Audio Data . . . . . . . . . . . . .
    . . . . . . . . . . . 11\n     5.6.  Implementation Considerations  . . . . .
    . . . . . . . . . 12\n       5.6.1.  Receiving Redundant Frames . . . . . . .
    . . . . . . . 12\n       5.6.2.  Interleaving . . . . . . . . . . . . . . . .
    . . . . . 12\n       5.6.3.  Decoding Validation  . . . . . . . . . . . . . .
    . . . 13\n   6.  Payload Examples . . . . . . . . . . . . . . . . . . . . . .
    . 13\n     6.1.  3 Mono Frames with 2 Different Bitrates  . . . . . . . . . 13\n
    \    6.2.  2 Stereo Frame-Blocks of the Same Bitrate  . . . . . . . . 14\n     6.3.
    \ 4 Mono Frames Interleaved  . . . . . . . . . . . . . . . . 15\n   7.  Payload
    Format Parameters  . . . . . . . . . . . . . . . . . . 16\n     7.1.  Media Type
    Definition  . . . . . . . . . . . . . . . . . . 16\n     7.2.  Mapping to SDP
    . . . . . . . . . . . . . . . . . . . . . . 19\n       7.2.1.  Offer/Answer Considerations
    \ . . . . . . . . . . . . . 19\n       7.2.2.  Declarative SDP Considerations
    . . . . . . . . . . . . 22\n   8.  IANA Considerations  . . . . . . . . . . .
    . . . . . . . . . . 23\n   9.  Congestion Control . . . . . . . . . . . . . .
    . . . . . . . . 23\n   10. Security Considerations  . . . . . . . . . . . . .
    . . . . . . 24\n   11. Acknowledgements . . . . . . . . . . . . . . . . . . .
    . . . . 25\n   12. References . . . . . . . . . . . . . . . . . . . . . . . .
    . . 25\n     12.1. Normative References . . . . . . . . . . . . . . . . . . .
    25\n     12.2. Informative References . . . . . . . . . . . . . . . . . . 26\n"
  title: Table of Contents
- contents:
  - "1.  Introduction\n   This document specifies the payload format for packetization
    of the\n   G.719 full-band (FB) codec encoded audio signals into the Real-time\n
    \  Transport Protocol (RTP) [RFC3550].  The payload format supports\n   transmission
    of multiple channels, multiple frames per payload, and\n   packet loss robustness
    methods using redundancy or interleaving.\n   This document starts with conventions,
    a brief description of the\n   codec, and the payload format's capabilities.  The
    payload format is\n   specified in Section 5.  Examples can be found in Section
    6.  The\n   media type and its mappings to the Session Description Protocol (SDP)\n
    \  and usage in SDP offer/answer are then specified.  The document ends\n   with
    considerations regarding congestion control and security.\n"
  title: 1.  Introduction
- contents:
  - "2.  Definitions and Conventions\n   The term \"frame-block\" is used in this
    document to describe the time-\n   synchronized set of audio frames in a multi-channel
    audio session.\n   In particular, in an N-channel session, a frame-block will
    contain N\n   audio frames, one from each of the channels, and all N speech frames\n
    \  represent exactly the same time period.\n   This document contains depictions
    of bit fields.  The most\n   significant bit is always leftmost in the figure
    on each row and has\n   the lowest enumeration.  For fields that are depicted
    over multiple\n   rows, the upper row is more significant than the next.\n   The
    key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\",\n   \"SHOULD\",
    \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\n   document
    are to be interpreted as described in RFC 2119 [RFC2119].\n"
  title: 2.  Definitions and Conventions
- contents:
  - "3.  G.719 Description\n   The ITU-T G.719 full-band codec is a transform coder
    based on\n   Modulated Lapped Transform (MLT).  G.719 is a low-complexity full-\n
    \  bandwidth codec for conversational speech and audio coding.  The\n   encoder
    input and decoder output are sampled at 48 kHz.  The codec\n   enables full-bandwidth
    from 20 Hz to 20 kHz, encoding of speech,\n   music, and general audio content
    at rates from 32 kbit/s up to 128\n   kbit/s.  The codec operates on 20-ms frames
    and has an algorithmic\n   delay of 40 ms.\n   The codec provides excellent quality
    for speech, music, and other\n   types of audio.  Some of the applications for
    which this coder is\n   suitable are:\n   o  Real-time communications such as
    video conferencing and telephony\n   o  Streaming audio\n   o  Archival and messaging\n
    \  The encoding and decoding algorithm can change the bitrate at any\n   20-ms
    frame boundary.  The encoder receives the audio sampled at 48\n   kHz.  The support
    of other sampling rates is possible by re-sampling\n   the input signal to the
    codec's sampling rate, i.e., 48 kHz; however,\n   this functionality is not part
    of the standard.\n   The encoding is performed on equally sized frames.  For each
    frame,\n   the encoder decides between two encoding modes, a transient mode and\n
    \  a stationary mode.  The decision is based on statistics derived from\n   the
    input signal.  The stationary mode uses a long MLT that leads to\n   a spectrum
    of 960 coefficients, while the transient encoding mode\n   uses a short MLT (higher
    time resolution transform) that results in 4\n   spectra (4 x 240 = 960 coefficients).
    \ The encoding of the spectrum\n   is done in two steps.  First, the spectral
    envelope is computed,\n   quantized, and Huffman encoded.  The envelope is computed
    on a non-\n   uniform frequency subdivision.  From the coded spectral envelope,
    a\n   weighted spectral envelope is derived and is used for bit allocation;\n
    \  this process is also repeated at the decoder.  Thus, only the\n   spectral
    envelope is transmitted.  The output of the bit allocation\n   is used in order
    to quantize the spectra.  In addition, for\n   stationary frames, the encoder
    estimates the amount of noise level.\n   The decoder applies the reverse operation
    upon reception of the bit\n   stream.  The non-coded coefficients (i.e., no bits
    allocated) are\n   replaced by entries of a noise codebook that is built based
    on the\n   decoded coefficients.\n"
  title: 3.  G.719 Description
- contents:
  - "4.  Payload Format Capabilities\n   This payload format has a number of capabilities,
    and this section\n   discusses them in some detail.\n"
  - contents:
    - "4.1.  Multi-Rate Encoding and Rate Adaptation\n   G.719 supports a multi-rate
      encoding capability that enables on a\n   per-frame basis variation of the encoding
      rate.  This enables support\n   for bitrate adaptation and congestion control.
      \ The possibility to\n   aggregate multiple audio frames into a single RTP payload
      is another\n   dimension of adaptation.  The RTP and payload format overhead
      can\n   thus be reduced by the aggregation at the cost of increased delay and\n
      \  reduced packet-loss robustness.\n"
    title: 4.1.  Multi-Rate Encoding and Rate Adaptation
  - contents:
    - "4.2.  Support for Multi-Channel Sessions\n   The RTP payload format defined
      in this document supports multi-\n   channel audio content (e.g., stereophonic
      or surround audio\n   sessions).  Although the G.719 codec itself does not support
      encoding\n   of multi-channel audio content into a single bit stream, it can
      be\n   used to separately encode and decode each of the individual channels.\n
      \  To transport (or store) the separately encoded multi-channel content,\n   the
      audio frames for all channels that are framed and encoded for the\n   same 20-ms
      period are logically collected in a \"frame-block\".\n   At the session setup,
      out-of-band signaling must be used to indicate\n   the number of channels in
      the payload type.  The order of the audio\n   frames within the frame-block
      depends on the number of the channels\n   and follows the definition in Section
      4.1 of the RTP/AVP profile\n   [RFC3551].  When using SDP for signaling, the
      number of channels is\n   specified in the rtpmap attribute.\n"
    title: 4.2.  Support for Multi-Channel Sessions
  - contents:
    - "4.3.  Robustness against Packet Loss\n   The payload format supports several
      means, including forward error\n   correction (FEC) and frame interleaving,
      to increase robustness\n   against packet loss.\n"
    - contents:
      - "4.3.1.  Use of Forward Error Correction (FEC)\n   Generic forward error correction
        within RTP is defined, for example,\n   in RFC 5109 [RFC5109].  Audio redundancy
        coding is defined in RFC\n   2198 [RFC2198].  Either scheme can be used to
        add redundant\n   information to the RTP packet stream and make it more resilient
        to\n   packet losses, at the expense of a higher bitrate.  Please see either\n
        \  of the RFCs for a discussion of the implications of the higher\n   bitrate
        to network congestion.\n   In addition to these media-unaware mechanisms,
        this memo specifies a\n   G.719-specific form of audio redundancy coding,
        which may be\n   beneficial in terms of packetization overhead.  Conceptually,\n
        \  previously transmitted transport frames are aggregated together with\n
        \  new ones.  A sliding window can be used to group the frames to be\n   sent
        in each payload.  However, irregular or non-consecutive patterns\n   are also
        possible by inserting NO_DATA frames between primary and\n   redundant transmissions.
        \ Figure 1 below shows an example.\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \    | f(n-2) | f(n-1) |  f(n)  | f(n+1) | f(n+2) | f(n+3) | f(n+4) |\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \     <---- p(n-1) ---->\n               <----- p(n) ----->\n                        <----
        p(n+1) ---->\n                                 <---- p(n+2) ---->\n                                          <----
        p(n+3) ---->\n                                                   <---- p(n+4)
        ---->\n              Figure 1: An example of redundant transmission\n   Here,
        each frame is retransmitted once in the following RTP payload\n   packet.
        f(n-2)...f(n+4) denote a sequence of audio frames, and\n   p(n-1)...p(n+4)
        a sequence of payload packets.\n   The mechanism described does not really
        require signaling at the\n   session setup.  However, signaling has been defined
        to allow for the\n   sender to voluntarily bind the buffering and delay requirements.
        \ If\n   nothing is signaled, the use of this mechanism is allowed and\n   unbounded.
        \ For a certain timestamp, the receiver may receive\n   multiple copies of
        a frame containing encoded audio data, even at\n   different encoding rates.
        \ The cost of this scheme is bandwidth and\n   the receiver delay necessary
        to allow the redundant copy to arrive.\n   This redundancy scheme provides
        a functionality similar to the one\n   described in RFC 2198, but it works
        only if both original frames and\n   redundant representations are G.719 frames.
        \ When the use of other\n   media coding schemes is desirable, one has to
        resort to RFC 2198.\n   The sender is responsible for selecting an appropriate
        amount of\n   redundancy based on feedback about the channel conditions, e.g.,
        in\n   the RTP Control Protocol (RTCP) [RFC3550] receiver reports.  The\n
        \  sender is also responsible for avoiding congestion, which may be\n   exacerbated
        by redundancy (see Section 9 for more details).\n"
      title: 4.3.1.  Use of Forward Error Correction (FEC)
    - contents:
      - "4.3.2.  Use of Frame Interleaving\n   To decrease protocol overhead, the
        payload design allows several\n   audio transport frames to be encapsulated
        into a single RTP packet.\n   One of the drawbacks of such an approach is
        that in the case of\n   packet loss, several consecutive frames are lost.
        \ Consecutive frame\n   loss normally renders error concealment less efficient
        and usually\n   causes clearly audible and annoying distortions in the reconstructed\n
        \  audio.  Interleaving of transport frames can improve the audio\n   quality
        in such cases by distributing the consecutive losses into a\n   number of
        isolated frame losses, which are easier to conceal.\n   However, interleaving
        and bundling several frames per payload also\n   increases end-to-end delay
        and sets higher buffering requirements.\n   Therefore, interleaving is not
        appropriate for all use cases or\n   devices.  Streaming applications should
        most likely be able to\n   exploit interleaving to improve audio quality in
        lossy transmission\n   conditions.\n   Note that this payload design supports
        the use of frame interleaving\n   as an option.  The usage of this feature
        needs to be negotiated in\n   the session setup.\n   The interleaving supported
        by this format is rather flexible.  For\n   example, a continuous pattern
        can be defined, as depicted in\n   Figure 2.\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \    | f(n-2) | f(n-1) |  f(n)  | f(n+1) | f(n+2) | f(n+3) | f(n+4) |\n   --+--------+--------+--------+--------+--------+--------+--------+--\n
        \             [ p(n)   ]\n     [ p(n+1) ]                 [ p(n+1) ]\n                       [
        p(n+2) ]                 [ p(n+2) ]\n                                         [
        p(n+3) ]\n                                                           [ p(n+4)
        ]\n   Figure 2: An example of interleaving pattern that has constant delay\n
        \  In Figure 2, the consecutive frames, denoted f(n-2) to f(n+4), are\n   aggregated
        into packets p(n) to p(n+4), each packet carrying two\n   frames.  This approach
        provides an interleaving pattern that allows\n   for constant delay in both
        the interleaving and de-interleaving\n   processes.  The de-interleaving buffer
        needs to have room for at\n   least three frames, including the one that is
        ready to be consumed.\n   The storage space for three frames is needed, for
        example, when f(n)\n   is the next frame to be decoded: since frame f(n) was
        received in\n   packet p(n+2), which also carried frame f(n+3), both these
        frames are\n   stored in the buffer.  Furthermore, frame f(n+1) received in
        the\n   previous packet, p(n+1), is also in the de-interleaving buffer.  Note\n
        \  also that in this example the buffer occupancy varies: when frame\n   f(n+1)
        is the next one to be decoded, there are only two frames,\n   f(n+1) and f(n+3),
        in the buffer.\n"
      title: 4.3.2.  Use of Frame Interleaving
    title: 4.3.  Robustness against Packet Loss
  title: 4.  Payload Format Capabilities
- contents:
  - "5.  Payload Format\n   The main purpose of the payload design for G.719 is to
    maximize the\n   potential of the codec to its fullest degree with as minimal
    overhead\n   as possible.  In the design, both basic and interleaved modes have\n
    \  been included, as the codec is suitable both for conversational and\n   other
    low-delay applications as well as streaming, where more delay\n   is acceptable.\n
    \  The main structural difference between the basic and interleaved\n   modes
    is the extension of the table of contents entries with frame\n   displacement
    fields in the interleaved mode.  The basic mode supports\n   aggregation of multiple
    consecutive frames in a payload.  The\n   interleaved mode supports aggregation
    of multiple frames that are\n   non-consecutive in time.  In both modes, it is
    possible to have\n   frames encoded with different frame types in the same payload.\n
    \  The payload format also supports the usage of G.719 for carrying\n   multi-channel
    content using one discrete encoder per channel all\n   using the same bitrate.
    \ In this case, a complete frame-block with\n   data from all channels is included
    in the RTP payload.  The data is\n   the concatenation of all the encoded audio
    frames in the order\n   specified for that number of included channels.  Also,
    interleaving\n   is done on complete frame-blocks rather than on individual audio\n
    \  frames.\n"
  - contents:
    - "5.1.  RTP Header Usage\n   The RTP timestamp corresponds to the sampling instant
      of the first\n   sample encoded for the first frame-block in the packet.  The\n
      \  timestamp clock frequency SHALL be 48000 Hz.  The timestamp is also\n   used
      to recover the correct decoding order of the frame-blocks.\n   The RTP header
      marker bit (M) SHALL be set to 1 whenever the first\n   frame-block carried
      in the packet is the first frame-block in a\n   talkspurt (see definition of
      the talkspurt in Section 4.1 of\n   [RFC3551]).  For all other packets, the
      marker bit SHALL be set to\n   zero (M=0).\n   The assignment of an RTP payload
      type for the format defined in this\n   memo is outside the scope of this document.
      \ The RTP profiles in use\n   currently mandate binding the payload type dynamically
      for this\n   payload format.  This is basically necessary because the payload
      type\n   expresses the configuration of the payload itself, i.e., basic or\n
      \  interleaved mode, and the number of channels carried.\n   The remaining RTP
      header fields are used as specified in [RFC3550].\n"
    title: 5.1.  RTP Header Usage
  - contents:
    - "5.2.  Payload Structure\n   The payload consists of one or more table of contents
      (ToC) entries\n   followed by the audio data corresponding to the ToC entries.
      \ The\n   following sections describe both the basic mode and the interleaved\n
      \  mode.  Each ToC entry MUST be padded to a byte boundary to ensure\n   octet
      alignment.  The rules regarding maximum payload size given in\n   Section 3.2
      of [RFC5405] SHOULD be followed.\n"
    - contents:
      - "5.2.1.  Basic ToC Element\n   All the different formats and modes in this
        document use a common\n   basic ToC that may be extended in the different
        options described\n   below.\n    0 1 2 3 4 5 6 7\n   +-+-+-+-+-+-+-+-+\n
        \  |F|    L    |R|R|\n   +-+-+-+-+-+-+-+-+\n                        Figure
        3: Basic TOC element\n   F (1 bit):  If set to 1, indicates that this ToC
        entry is followed by\n      another ToC entry; if set to zero, indicates that
        this ToC entry\n      is the last one in the ToC.\n   L (5 bits):  A field
        that gives the frame length of each individual\n      frame within the frame-block.\n
        \       L          length(bytes)\n       ============================\n        0
        \          0 NO_DATA\n        1-7         N/A (reserved)\n        8-22        80+10*(L-8)\n
        \      23-27        240+20*(L-23)\n       28-31        N/A (reserved)\n                Figure
        4: How to map L values to frame lengths\n      L=0 (NO_DATA) is used to indicate
        an empty frame, which is useful\n      if frames are missing (e.g., at re-packetization),
        or to insert\n      gaps when sending redundant frames together with primary
        frames in\n      the same payload.\n      The value range [1..7] and [28..31]
        inclusive is reserved for\n      future use in this document version; if these
        values occur in a\n      ToC, the entire packet SHOULD be treated as invalid
        and discarded.\n      A few examples are given below where the frame size
        and the\n      corresponding codec bitrate is computed based on the value
        L.\n         L    Bytes    Codec Bitrate(kbps)\n       ===================================\n
        \        8      80        32\n         9      90        36\n        10     100
        \       40\n        12     120        48\n        16     160        64\n        22
        \    220        88\n        23     240        96\n        25     280       112\n
        \       27     320       128\n        Figure 5: Examples of L values and corresponding
        frame lengths\n      This encoding yields a granularity of 4 kbps between
        32 and 88\n      kbps and a granularity of 8 kbps between 88 and 128 kbps
        with a\n      defined range of 32-128 kbps for the codec data.\n   R (2 bits):
        \ Reserved bits.  SHALL be set to zero on sending and\n      SHALL be ignored
        on reception.\n"
      title: 5.2.1.  Basic ToC Element
    title: 5.2.  Payload Structure
  - contents:
    - "5.3.  Basic Mode\n   The basic ToC element shown in Figure 3 is followed by
      a 1-octet\n   field for the number of frame-blocks (#frames) to form the ToC
      entry.\n   The frame-blocks field tells how many frame-blocks of the same length\n
      \  the ToC entry relates to.\n    0 1 2 3 4 5 6 7\n   +-+-+-+-+-+-+-+-+\n   |
      \   #frames    |\n   +-+-+-+-+-+-+-+-+\n                  Figure 6: Number of
      frame-blocks field\n"
    title: 5.3.  Basic Mode
  - contents:
    - "5.4.  Interleaved Mode\n   The basic ToC is followed by a 1-octet field for
      the number of frame-\n   blocks (#frames) and then the DIS fields to form a
      ToC entry in\n   interleaved mode.  The frame-blocks field tells how many frame-blocks\n
      \  of the same length the ToC relates to.  The DIS fields, one for each\n   frame-block
      indicated by the #frames field, express the interleaving\n   distance between
      audio frames carried in the payload.  If necessary\n   to achieve octet alignment,
      a 4-bit padding is added.\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \  |    #frames    | DIS1  |  ...  | DISi  |  ...  | DISn  | Padd  |\n   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \           Figure 7: Number of frame-block + interleave fields\n   DIS1...DISn
      (4 bits):  A list of n (n=#frames) displacement fields\n      indicating the
      displacement of the i:th (i=1..n) audio frame-block\n      relative to the preceding
      frame-block in the payload, in units of\n      20-ms long audio frame-blocks).
      \ The 4-bit unsigned integer\n      displacement values may be between zero
      and 15 indicating the\n      number of audio frame-blocks in decoding order
      between the\n      (i-1):th and the i:th frame in the payload.  Note that for
      the\n      first ToC entry of the payload, the value of DIS1 is meaningless.\n
      \     It SHALL be set to zero by a sender and SHALL be ignored by a\n      receiver.
      \ This frame-block's location in the decoding order is\n      uniquely defined
      by the RTP timestamp.  Note that for subsequent\n      ToC entries DIS1 indicates
      the number of frames between the last\n      frame of the previous group and
      the first frame of this group.\n   Padd (4 bits):  To ensure octet alignment,
      4 padding bits SHALL be\n      included at the end of the ToC entry in case
      there is an odd\n      number of frame-blocks in the group referenced by this
      ToC entry.\n      These bits SHALL be set to zero and SHALL be ignored by the\n
      \     receiver.  If a group containing an even number of frames is\n      referenced
      by this ToC entry, these padding bits SHALL NOT be\n      included in the payload.\n"
    title: 5.4.  Interleaved Mode
  - contents:
    - "5.5.  Audio Data\n   The audio data part follows the table of contents.  All
      the octets\n   comprising an audio frame SHALL be appended to the payload as
      a unit.\n   For each frame-block, the audio frames are concatenated in the order\n
      \  indicated by the table in Section 4.1 of [RFC3551] for the number of\n   channels
      configured for the payload type in use.  So the first\n   channel (leftmost)
      indicated comes first followed by the next\n   channel.  The audio frame-blocks
      are packetized in increasing\n   timestamp order within each group of frame-blocks
      (per ToC entry),\n   i.e., oldest frame-block first.  The groups of frame-blocks
      are\n   packetized in the same order as their corresponding ToC entries.\n   The
      audio frames are specified in ITU recommendation [ITU-T-G719].\n   The G.719
      bit stream is split into a sequence of octets and\n   transmitted in order from
      the leftmost (most significant (MSB)) bit\n   to the rightmost (least significant
      (LSB)) bit.\n"
    title: 5.5.  Audio Data
  - contents:
    - "5.6.  Implementation Considerations\n   An application implementing this payload
      format MUST understand all\n   the payload parameters specified in this specification.
      \ Any mapping\n   of the parameters to a signaling protocol MUST support all\n
      \  parameters.  So an implementation of this payload format in an\n   application
      using SDP is required to understand all the payload\n   parameters in their
      SDP-mapped form.  This requirement ensures that\n   an implementation always
      can decide whether it is capable of\n   communicating when the communicating
      entities support this version of\n   the specification.\n   Basic mode SHALL
      be implemented and the interleaved mode SHOULD be\n   implemented.  The implementation
      burden of both is rather small, and\n   supporting both ensures interoperability.
      \ However, interleaving is\n   not mandated as it has limited applicability
      for conversational\n   applications that require tight delay boundaries.\n"
    - contents:
      - "5.6.1.  Receiving Redundant Frames\n   The reception of redundant audio frames,
        i.e., more than one audio\n   frame from the same source for the same time
        slot, MUST be supported\n   by the implementation.  In the case that the receiver
        gets multiple\n   audio frames in different bitrates for the same time slot,
        it is\n   RECOMMENDED that the receiver keeps the one with the highest bitrate.\n"
      title: 5.6.1.  Receiving Redundant Frames
    - contents:
      - "5.6.2.  Interleaving\n   The use of interleaving requires further considerations.
        \ As\n   presented in the example in Section 4.3.2, a given interleaving\n
        \  pattern requires a certain amount of the de-interleaving buffer.\n   This
        buffer space, expressed in a number of transport frame slots, is\n   indicated
        by the \"interleaving\" media type parameter.  The number of\n   frame slots
        needed can be converted into actual memory requirements\n   by considering
        the 320 bytes per frame used by the highest bitrate of\n   G.719.\n   The
        information about the frame buffer size is not always sufficient\n   to determine
        when it is appropriate to start consuming frames from\n   the interleaving
        buffer.  Additional information is needed when the\n   interleaving pattern
        changes.  The \"int-delay\" media type parameter\n   is defined to convey
        this information.  It allows a sender to\n   indicate the minimal media time
        that needs to be present in the\n   buffer before the decoder can start consuming
        frames from the buffer.\n   Because the sender has full control over the interleaving
        pattern, it\n   can calculate this value.  In certain cases (for example,
        if joining\n   a multicast session with interleaving mid-session), a receiver
        may\n   initially receive only part of the packets in the interleaving\n   pattern.
        \ This initial partial reception (in frame sequence order) of\n   frames can
        yield too few frames for acceptable quality from the audio\n   decoding.  This
        problem also arises when using encryption for access\n   control, and the
        receiver does not have the previous key.  Although\n   the G.719 is robust
        and thus tolerant to a high random frame erasure\n   rate, it would have difficulties
        handling consecutive frame losses at\n   startup.  Thus, some special implementation
        considerations are\n   described.\n   In order to handle this type of startup
        efficiently, decoding can\n   start provided that:\n   1.  There are at least
        two consecutive frames available.\n   2.  More than or equal to half the frames
        are available in the time\n       period from where decoding was planned to
        start and the most\n       forward received decoding.\n   After receiving
        a number of packets, in the worst case as many\n   packets as the interleaving
        pattern covers, the previously described\n   effects disappear and normal
        decoding is resumed.  Similar issues\n   arise when a receiver leaves a session
        or has lost access to the\n   stream.  If the receiver leaves the session,
        this would be a minor\n   issue since playout is normally stopped.  The sender
        can avoid this\n   type of problem in many sessions by starting and ending
        interleaving\n   patterns correctly when risks of losses occur.  One such
        example is a\n   key-change done for access control to encrypted streams.
        \ If only\n   some keys are provided to clients and there is a risk they will\n
        \  receive content for which they do not have the key, it is recommended\n
        \  that interleaving patterns do not overlap key changes.\n"
      title: 5.6.2.  Interleaving
    - contents:
      - "5.6.3.  Decoding Validation\n   If the receiver finds a mismatch between
        the size of a received\n   payload and the size indicated by the ToC of the
        payload, the\n   receiver SHOULD discard the packet.  This is recommended
        because\n   decoding a frame parsed from a payload based on erroneous ToC
        data\n   could severely degrade the audio quality.\n"
      title: 5.6.3.  Decoding Validation
    title: 5.6.  Implementation Considerations
  title: 5.  Payload Format
- contents:
  - "6.  Payload Examples\n   A few examples to highlight the payload format follow.\n"
  - contents:
    - "6.1.  3 Mono Frames with 2 Different Bitrates\n   The first example is a payload
      consisting of 3 mono frames where the\n   first 2 frames correspond to a bitrate
      of 32 kbps (80 bytes/frame)\n   and the last is 48 kbps (120 bytes/frame).\n
      \     The first 32 bits are ToC fields.\n      Bit 0 is '1' as another ToC field
      follows.\n      Bits 1..5 are '01000' = 80 bytes/frame.\n      Bits 8..15 are
      '00000010' = 2 frame-blocks with 80 bytes/frame.\n      Bit 16 is '0', no more
      ToC follows.\n      Bits 17..21 are '01100' = 120 bytes/frame.\n      Bits 24..31
      are '00000001' = 1 frame-block with 120 bytes/frame.\n       0                   1
      \                  2                   3\n       0 1 2 3 4 5 6 7 8 9 0 1 2 3
      4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     |1|0 1 0 0 0|0 0|0 0 0 0 0 0 1 0|0|0 1 1 0 0|0 0|0 0 0 0 0 0 0 1|\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     |d(0)   frame 1                                                 |\n      .
      \                                                              .\n      |                                                         d(639)|\n
      \     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |d(0)
      \  frame 2                                                 |\n      .                                                               .\n
      \     |                                                         d(639)|\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     |d(0)   frame 3                                                 |\n      .
      \                                                              .\n      |                                                         d(959)|\n
      \     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n"
    title: 6.1.  3 Mono Frames with 2 Different Bitrates
  - contents:
    - "6.2.  2 Stereo Frame-Blocks of the Same Bitrate\n   The second example is a
      payload consisting of 2 stereo frames that\n   correspond to a bitrate of 32
      kbps (80 bytes/frame) per channel.  The\n   receiver calculates the number of
      frames in the audio block by\n   multiplying the value of the \"channels\" parameter
      (2) with the\n   #frames field value (2) to derive that there are 4 audio frames
      in\n   the payload.\n      The first 16 bits is the ToC field.\n      Bit 0
      is '0' as no ToC field follows.\n      Bits 1..5 are '01000' = 80 bytes/frame.\n
      \     Bits 8..15 are '00000010' = 2 frame-blocks with 80 bytes/frame.\n       0
      \                  1                   2                   3\n       0 1 2 3
      4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     |0|0 1 0 0 0|0 0|0 0 0 0 0 0 1 0| d(0) frame 1 left ch.         |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     .                                                               .\n      |
      \                        d(639)| d(0) frame 1 right ch.        |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     .                                                               .\n      |
      \                        d(639)| d(0) frame 2 left ch.         |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     .                                                               .\n      |
      \                        d(639)| d(0) frame 2 right ch.        |\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     |                         d(639)|\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n"
    title: 6.2.  2 Stereo Frame-Blocks of the Same Bitrate
  - contents:
    - "6.3.  4 Mono Frames Interleaved\n   The third example is a payload consisting
      of 4 mono frames that\n   correspond to a bitrate of 32 kbps (80 bytes/frame)
      interleaved.  A\n   pattern of interleaving for constant delay when aggregating
      4 frames\n   is used in the example below.  The actual packet illustrated is\n
      \  packet n, while the previous and following packets' frame-block\n   content
      is shown to illustrate the pattern.\n      Packet n-3:  1,  6, 11, 16\n      Packet
      n-2:  5, 10, 15, 20\n      Packet n-1:  9, 14, 19, 24\n      Packet   n: 13,
      18, 23, 28\n      Packet n+1: 17, 22, 27, 32\n      Packet n+2: 21, 26, 31,
      36\n      The first 32 bits are the ToC field.\n      Bit 0 is '0' as there
      is no ToC field following.\n      Bits 1..5 are '01000' = 80 bytes/frame.\n
      \     Bits 8..15 are '00000100' = 4 frame-blocks with 80 bytes/frame.\n      Bits
      16..19 are '0000' = DIS1 (0).\n      Bits 20..23 are '0100' = DIS2 (4).\n      Bits
      24..27 are '0100' = DIS3 (4).\n      Bits 28..31 are '0100' = DIS4 (4).\n       0
      \                  1                   2                   3\n       0 1 2 3
      4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     |0|0 1 0 0 0|0 0|0 0 0 0 0 1 0 0|0 0 0 0|0 1 0 0|0 1 0 0|0 1 0 0|\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     | d(0) frame 13                                                 |\n      .
      \                                                              .\n      |                                                         d(639)|\n
      \     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |
      d(0) frame 18                                                 |\n      .                                                               .\n
      \     |                                                         d(639)|\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n
      \     | d(0) frame 23                                                 |\n      .
      \                                                              .\n      |                                                         d(639)|\n
      \     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      |
      d(0) frame 28                                                 |\n      .                                                               .\n
      \     |                                                         d(639)|\n      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n"
    title: 6.3.  4 Mono Frames Interleaved
  title: 6.  Payload Examples
- contents:
  - "7.  Payload Format Parameters\n   This RTP payload format is identified using
    the media type audio/\n   G719, which is registered in accordance with [RFC4855]
    and uses the\n   template of [RFC4288].\n"
  - contents:
    - "7.1.  Media Type Definition\n   The media type for the G.719 codec is allocated
      from the IETF tree\n   since G.719 has the potential to become a widely used
      audio codec in\n   general Voice over IP (VoIP), teleconferencing, and streaming\n
      \  applications.  This media type registration covers real-time transfer\n   via
      RTP.\n   Note, any unspecified parameter MUST be ignored by the receiver to\n
      \  ensure that additional parameters can be added in any future revision\n   of
      this specification.\n   Type name: audio\n   Subtype name: G719\n   Required
      parameters: none\n   Optional parameters:\n   interleaving:  Indicates that
      interleaved mode SHALL be used for the\n      payload.  The parameter specifies
      the number of frame-block slots\n      available in a de-interleaving buffer
      (including the frame that is\n      ready to be consumed) for each source.  Its
      value is equal to one\n      plus the maximum number of frames that can precede
      any frame in\n      transmission order and follow the frame in RTP timestamp
      order.\n      The value MUST be greater than zero.  If this parameter is not\n
      \     present, interleaved mode SHALL NOT be used.\n   int-delay:  The minimal
      media time delay in milliseconds that is\n      needed to avoid underrun in
      the de-interleaving buffer before\n      starting decoding, i.e., the difference
      in RTP timestamp ticks\n      between the earliest and latest audio frame present
      in the de-\n      interleaving buffer expressed in milliseconds.  The value
      is a\n      stream property and provided per source.  The allowed values are\n
      \     zero to the largest value expressible by an unsigned 16-bit\n      integer
      (65535).  Please note that in practice, the largest value\n      that can be
      used is equal to the declared size of the interleaving\n      buffer of the
      receiver.  If the value for some reason is larger\n      than the receiver buffer
      declared by or for the receiver, this\n      value defaults to the size of the
      receiver buffer.  For sources\n      for which this value hasn't been provided,
      the value defaults to\n      the size of the receiver buffer.  The format is
      a comma-separated\n      list of synchronization source (SSRC) \":\" delay in
      ms pairs, which\n      in ABNF [RFC5234] is expressed as:\n         int-delay
      = \"int-delay:\" source-delay *(\",\" source-delay)\n         source-delay =
      SSRC \":\" delay-value\n         SSRC = 1*8HEXDIG ; The 32-bit SSRC encoded
      in hex format\n         delay-value = 1*5DIGIT ; The delay value in milliseconds\n
      \        Example: int-delay=ABCD1234:1000,4321DCB:640\n         NOTE: No white
      space allowed in the parameter before the end of\n         all the value pairs\n
      \  max-red:  The maximum duration in milliseconds that elapses between\n      the
      primary (first) transmission of a frame and any redundant\n      transmission
      that the sender will use.  This parameter allows a\n      receiver to have a
      bounded delay when redundancy is used.  Allowed\n      values are between zero
      (no redundancy will be used) and 65535.\n      If the parameter is omitted,
      no limitation on the use of\n      redundancy is present.\n   channels:  The
      number of audio channels.  The possible values (1-6)\n      and their respective
      channel order is specified in Section 4.1 of\n      [RFC3551].  If omitted,
      it has the default value of 1.\n   CBR:  Constant Bitrate (CBR) indicates the
      exact codec bitrate in\n      bits per second (not including the overhead from
      packetization,\n      RTP header, or lower layers) that the codec MUST use.
      \ \"CBR\" is to\n      be used when the dynamic rate cannot be supported (one
      case is,\n      e.g., gateway to H.320).  \"CBR\" is mostly used for gateways
      to\n      circuit switch networks.  Therefore, the \"CBR\" is the rate not\n
      \     including any FEC as specified in Section 4.3.1.  If FEC is to be\n      used,
      the \"b=\" parameter MUST be used to allow the extra bitrate\n      needed to
      send the redundant information.  It is RECOMMENDED that\n      this parameter
      is only used when necessary to establish a working\n      communication.  The
      usage of this parameter has implications for\n      congestion control that
      need to be considered; see Section 9.\n   ptime:  see [RFC4566].\n   maxptime:
      \ see [RFC4566].\n   Encoding considerations:  This media type is framed and
      binary; see\n      Section 4.8 of [RFC4288].\n   Security considerations:  See
      Section 10 of RFC 5404.\n   Interoperability considerations:  The support of
      the Interleaving\n      mode is not mandatory and needs to be negotiated.  See
      Section 7.2\n      for how to do that for SDP-based protocols.\n   Published
      specification:  RFC 5404\n   Applications that use this media type:  Real-time
      audio applications\n      like Voice over IP and teleconference, and multi-media
      streaming.\n   Additional information:  none\n   Person & email address to contact
      for further         information:\n      Ingemar Johansson\n      <ingemar.s.johansson@ericsson.com>\n
      \  Intended usage:  COMMON\n   Restrictions on usage:  This media type depends
      on RTP framing, and\n      hence is only defined for transfer via RTP [RFC3550].
      \ Transport\n      within other framing protocols is not defined at this time.\n
      \  Author:\n      Ingemar Johansson <ingemar.s.johansson@ericsson.com>\n      Magnus
      Westerlund <magnus.westerlund@ericsson.com>\n   Change controller:  IETF Audio/Video
      Transport working group\n      delegated from the IESG.\n   Additionally, note
      that file storage of G.719-encoded audio in ISO\n   base media file format is
      specified in Annex A of [ITU-T-G719].\n   Thus, media file formats such as MP4
      (audio/mp4 or video/mp4)\n   [RFC4337] and 3GP (audio/3GPP and video/3GPP) [RFC3839]
      can contain\n   G.719-encoded audio.\n"
    title: 7.1.  Media Type Definition
  - contents:
    - "7.2.  Mapping to SDP\n   The information carried in the media type specification
      has a\n   specific mapping to fields in the Session Description Protocol (SDP)\n
      \  [RFC4566], which is commonly used to describe RTP sessions.  When SDP\n   is
      used to specify sessions employing the G.719 codec, the mapping is\n   as follows:\n
      \  o  The media type (\"audio\") goes in SDP \"m=\" as the media name.\n   o
      \ The media subtype (payload format name) goes in SDP \"a=rtpmap\" as\n      the
      encoding name.  The RTP clock rate in \"a=rtpmap\" MUST be\n      48000, and
      the encoding parameter \"channels\" (Section 7.1) MUST\n      either be explicitly
      set to N or omitted, implying a default value\n      of 1.  The values of N
      that are allowed are specified in Section\n      4.1 in [RFC3551].\n   o  The
      parameters \"ptime\" and \"maxptime\" go in the SDP \"a=ptime\" and\n      \"a=maxptime\"
      attributes, respectively.\n   o  Any remaining parameters go in the SDP \"a=fmtp\"
      attribute by\n      copying them directly from the media type parameter string
      as a\n      semicolon-separated list of parameter=value pairs.\n"
    - contents:
      - "7.2.1.  Offer/Answer Considerations\n   The following considerations apply
        when using SDP offer/answer\n   procedures to negotiate the use of G.719 payload
        in RTP:\n   o  Each combination of the RTP payload transport format configuration\n
        \     parameters (\"interleaving\" and \"channels\") is unique in its bit\n
        \     pattern and not compatible with any other combination.  When\n      creating
        an offer in an application desiring to use the more\n      advanced features
        (interleaving or more than one channel), the\n      offerer is RECOMMENDED
        to also offer a payload type containing\n      only the configuration with
        a single channel.  If multiple\n      configurations are of interest to the
        application, they may all be\n      offered; however, care should be taken
        not to offer too many\n      payload types.  An SDP answerer MUST include,
        in the SDP answer\n      for a payload type, the following parameters unmodified
        from the\n      SDP offer (unless it removes the payload type): \"interleaving\"
        and\n      \"channels\".  However, the value of the \"interleaving\" parameter\n
        \     MAY be changed.  The SDP offerer and answerer MUST generate G.719\n
        \     packets as described by these parameters.\n   o  The \"interleaving\"
        and \"int-delay\" parameters' values have a\n      specific relationship that
        needs to be considered.  It also\n      depends on the directionality of the
        streams and their delivery\n      method.  The high-level explanation that
        can be understood from\n      the definition is that the value of \"interleaving\"
        declares the\n      size of the receiver buffer, while \"int-delay\" is a
        stream\n      property provided by the sender to inform how much buffer space
        it\n      in practice is using for the stream it sends.\n      *  For media
        streams that are sent over multicast, the value of\n         \"interleaving\"
        SHALL NOT be changed by the answerer.  It shall\n         either be accepted
        or the payload type deleted.  The value of\n         the \"int-delay\" parameter
        is a stream property and provided by\n         the offer/answer agent that
        intends to send media with this\n         payload type, and for each stream
        coming from that agent (one\n         or more).  The value MUST be between
        zero and what corresponds\n         to the buffer size declared by the value
        of the \"interleaving\"\n         parameter.\n      *  For unicast streams
        that the offerer declares as send-only, the\n         value of the \"interleaving\"
        parameter is the size that the\n         answerer is RECOMMENDED to use by
        the offerer.  The answerer\n         MAY change it to any allowed value.  The
        \"int-delay\" parameter\n         value will be the one the offerer intends
        to use unless the\n         answerer reduces the value of the \"interleaving\"
        parameter\n         below what is needed for that \"int-delay\" value.  If
        the\n         \"interleaving\" value in the answer is smaller than the offer's\n
        \        \"int-delay\" value, the \"int-delay\" value is per default reduced\n
        \        to be corresponding to the \"interleaving\" value.  If the\n         offerer
        is not satisfied with this, he will need to perform\n         another round
        of offer/answer.  As the answerer will not send\n         any media, it doesn't
        include any \"int-delay\" in the answer.\n      *  For unicast streams that
        the offerer declares as recvonly, the\n         value of \"interleaving\"
        in the offer will be the offerer's size\n         of the interleaving buffer.
        \ The answerer indicates its\n         preferred size of the interleaving
        buffer for any future round\n         of offer/answer.  The offerer will not
        provide any \"int-delay\"\n         parameter as it is not sending any media.
        \ The answerer is\n         recommended to include in its answer an \"int-delay\"
        parameter\n         to declare what the property is for the stream it is going
        to\n         send.  The answer is expected to be capable of selecting a\n
        \        valid parameter value that is between zero and the declared\n         maximum
        number of slots in the de-interleaving buffer.\n      *  For unicast streams
        that the offer declares as sendrecv\n         streams, the value of the \"interleaving\"
        parameter in the offer\n         will be the offerer's size of the interleaving
        buffer.  The\n         answerer will in the answer indicate the size of its
        actual\n         interleaving buffer.  It is recommended that this value is
        at\n         least as big as the offer's.  The offerer is recommended to\n
        \        include an \"int-delay\" parameter that is selected based on the\n
        \        answerer having at least as much interleaving space as the\n         offerer
        unless nothing else is known.  As the offerer's\n         interleaving buffer
        size is not yet known, this may fail, in\n         which case the default
        rule is to downgrade the value of the\n         \"int-delay\" to correspond
        to the full size of the answerer's\n         interleaving buffer.  If the
        offerer isn't satisfied with this,\n         it will need to initiate another
        round of offer/answer.  The\n         answerer is recommended in its answer
        to include an \"int-delay\"\n         parameter to declare what the property
        is for the stream(s) it\n         is going to send.  The answer is expected
        to be capable of\n         selecting a valid parameter value that is between
        zero and the\n         declared maximum number of slots in the de-interleaving
        buffer.\n   o  In most cases, the parameters \"maxptime\" and \"ptime\" will
        not\n      affect interoperability; however, the setting of the parameters\n
        \     can affect the performance of the application.  The SDP offer/\n      answer
        handling of the \"ptime\" parameter is described in\n      [RFC3264].  The
        \"maxptime\" parameter MUST be handled in the same\n      way.\n   o  The
        parameter \"max-red\" is a stream property parameter.  For\n      sendonly
        or sendrecv unicast media streams, the parameter declares\n      the limitation
        on redundancy that the stream sender will use.  For\n      recvonly streams,
        it indicates the desired value for the stream\n      sent to the receiver.
        \ The answerer MAY change the value, but is\n      RECOMMENDED to use the
        same limitation as the offer declares.  In\n      the case of multicast, the
        offerer MAY declare a limitation; this\n      SHALL be answered using the
        same value.  A media sender using this\n      payload format is RECOMMENDED
        to always include the \"max-red\"\n      parameter.  This information is likely
        to simplify the media\n      stream handling in the receiver.  This is especially
        true if no\n      redundancy will be used, in which case \"max-red\" is set
        to zero.\n   o  Any unknown parameter in an offer SHALL be removed in the
        answer.\n   o  The \"b=\" SDP parameter SHOULD be used to negotiate the maximum\n
        \     bandwidth to be used for the audio stream.  The offerer may offer\n
        \     a maximum rate and the answer may contain a lower rate.  If no\n      \"b=\"
        parameter is present in the offer or answer, it implies a\n      rate up to
        128 kbps.\n   o  The parameter \"CBR\" is a receiver capability; i.e., only
        receivers\n      that really require a constant bitrate should use it.  Usage
        of\n      this parameter has a negative impact on the possibility to perform\n
        \     congestion control; see Section 9.  For recvonly and sendrecv\n      streams,
        it indicates the desired constant bitrate that the\n      receiver wants to
        accept.  A sender MUST be able to send a\n      constant bitrate stream since
        it is a subset of the variable\n      bitrate capability.  If the offer includes
        this parameter, the\n      answerer MUST send G.719 audio at the constant
        bitrate if it is\n      within the allowed session bitrate (\"b=\" parameter).
        \ If the\n      answerer cannot support the stated CBR, this payload type
        must be\n      refused in the answer.  The answerer SHOULD only include this\n
        \     parameter if the answerer itself requires to receive at a constant\n
        \     bitrate, even if the offer did not include the \"CBR\" parameter.\n
        \     In this case, the offerer SHALL send at the constant bitrate, but\n
        \     SHALL be able to accept media at a variable bitrate.  An answerer\n
        \     is RECOMMEND to use the same CBR as in the offer, as symmetric\n      usage
        is more likely to work.  If both sides require a particular\n      CBR, there
        is the possibility of communication failure when one or\n      both sides
        can't transmit the requested rate.  In this case, the\n      agent detecting
        this issue will have to perform a second round of\n      offer/answer to try
        to find another working configuration or end\n      the established session.
        \ In case the offer contained a \"CBR\"\n      parameter but the answer does
        not, then the offerer is free to\n      transmit at any rate to the answerer,
        but the answerer is\n      restricted to the declared rate.\n"
      title: 7.2.1.  Offer/Answer Considerations
    - contents:
      - "7.2.2.  Declarative SDP Considerations\n   In declarative usage, like SDP
        in the Real Time Streaming Protocol\n   (RTSP) [RFC2326] or the Session Announcement
        Protocol (SAP)\n   [RFC2974], the parameters SHALL be interpreted as follows:\n
        \  o  The payload format configuration parameters (\"interleaving\" and\n
        \     \"channels\") are all declarative, and a participant MUST use the\n
        \     configuration(s) that is provided for the session.  More than one\n
        \     configuration may be provided if necessary by declaring multiple\n      RTP
        payload types; however, the number of types should be kept\n      small.\n
        \  o  It might not be possible to know the SSRC values that are going to\n
        \     be used by the sources at the time of sending the SDP.  This is\n      not
        a major issue as the size of the interleaving buffer can be\n      tailored
        towards the values that are actually going to be used,\n      thus ensuring
        that the default values for \"int-delay\" are not\n      resulting in too
        much extra buffering.\n   o  Any \"maxptime\" and \"ptime\" values should
        be selected with care to\n      ensure that the session's participants can
        achieve reasonable\n      performance.\n   o  The parameter \"CBR\" if included
        applies to all RTP streams using\n      that payload type for which a particular
        CBR is declared.  Usage\n      of this parameter has a negative impact on
        the possibility to\n      perform congestion control; see Section 9.\n"
      title: 7.2.2.  Declarative SDP Considerations
    title: 7.2.  Mapping to SDP
  title: 7.  Payload Format Parameters
- contents:
  - "8.  IANA Considerations\n   One media type (audio/G719) has been defined and
    registered in the\n   media types registry; see Section 7.1.\n"
  title: 8.  IANA Considerations
- contents:
  - "9.  Congestion Control\n   The general congestion control considerations for
    transporting RTP\n   data apply; see RTP [RFC3550] and any applicable RTP profile
    like AVP\n   [RFC3551].  However, the multi-rate capability of G.719 audio coding\n
    \  provides a mechanism that may help to control congestion, since the\n   bandwidth
    demand can be adjusted (within the limits of the codec) by\n   selecting a different
    encoding bitrate.\n   The number of frames encapsulated in each RTP payload highly\n
    \  influences the overall bandwidth of the RTP stream due to header\n   overhead
    constraints.  Packetizing more frames in each RTP payload\n   can reduce the number
    of packets sent and hence the header overhead,\n   at the expense of increased
    delay and reduced error robustness.  If\n   forward error correction (FEC) is
    used, the amount of FEC-induced\n   redundancy needs to be regulated such that
    the use of FEC itself does\n   not cause a congestion problem.  In other words,
    a sender SHALL NOT\n   increase the total bitrate when adding redundancy in response
    to\n   packet loss, and needs instead to adjust it down in accordance to the\n
    \  congestion control algorithm being run.  Thus, when adding\n   redundancy,
    the media bitrate will need to be reduced to provide room\n   for the redundancy.\n
    \  The \"CBR\" signaling parameter allows a receiver to lock down an RTP\n   payload
    type to use a single encoding rate.  As this prevents the\n   codec rate from
    being lowered when congestion is experienced, the\n   sender is constrained to
    either change the packetization or abort the\n   transmission.  Since these responses
    to congestion are severely\n   limited, implementations SHOULD NOT use the \"CBR\"
    parameter unless\n   they are interacting with a device that cannot support a
    variable\n   bitrate (e.g., a gateway to H.320 systems).  When using CBR mode,
    a\n   receiver MUST monitor the packet loss rate to ensure congestion is\n   not
    caused, following the guidelines in Section 2 of RFC 3551.\n"
  title: 9.  Congestion Control
- contents:
  - "10.  Security Considerations\n   RTP packets using the payload format defined
    in this specification\n   are subject to the security considerations discussed
    in the RTP\n   specification [RFC3550] and in any applicable RTP profile.  The
    main\n   security considerations for the RTP packet carrying the RTP payload\n
    \  format defined within this memo are confidentiality, integrity, and\n   source
    authenticity.  Confidentiality is achieved by encryption of\n   the RTP payload.
    \ Integrity of the RTP packets is achieved through a\n   suitable cryptographic
    integrity protection mechanism.  Such a\n   cryptographic system may also allow
    the authentication of the source\n   of the payload.  A suitable security mechanism
    for this RTP payload\n   format should provide confidentiality, integrity protection,
    and at\n   least source authentication capable of determining if an RTP packet\n
    \  is from a member of the RTP session.\n   Note that the appropriate mechanism
    to provide security to RTP and\n   payloads following this memo may vary.  It
    is dependent on the\n   application, the transport, and the signaling protocol
    employed.\n   Therefore, a single mechanism is not sufficient, although if\n   suitable,
    usage of the Secure Real-time Transport Protocol (SRTP)\n   [RFC3711] is recommended.
    \ Other mechanisms that may be used are\n   IPsec [RFC4301] and Transport Layer
    Security (TLS) [RFC5246] (RTP\n   over TCP); other alternatives may exist.\n   The
    use of interleaving in conjunction with encryption can have a\n   negative impact
    on confidentiality for a short period of time.\n   Consider the following packets
    (in brackets) containing frame numbers\n   as indicated: {10, 14, 18}, {13, 17,
    21}, {16, 20, 24} (a popular\n   continuous diagonal interleaving pattern).  The
    originator wishes to\n   deny some participants the ability to hear material starting
    at time\n   16.  Simply changing the key on the packet with the timestamp at or\n
    \  after 16, and denying that new key to those participants, does not\n   achieve
    this; frames 17, 18, and 21 have been supplied in prior\n   packets under the
    prior key, and error concealment may make the audio\n   intelligible at least
    as far as frame 18 or 19, and possibly further.\n   This RTP payload format and
    its media decoder do not exhibit any\n   significant non-uniformity in the receiver-side
    computational\n   complexity for packet processing, and thus are unlikely to pose
    a\n   denial-of-service threat due to the receipt of pathological data.\n   Nor
    does the RTP payload format contain any active content.\n"
  title: 10.  Security Considerations
- contents:
  - "11.  Acknowledgements\n   The authors would like to thank Roni Even and Anisse
    Taleb for their\n   help with this document.  We would also like to thank the
    people who\n   have provided feedback: Colin Perkins, Mark Baker, and Stephen\n
    \  Botzko.\n"
  title: 11.  Acknowledgements
- contents:
  - '12.  References

    '
  - contents:
    - "12.1.  Normative References\n   [ITU-T-G719]  ITU-T, \"Specification : ITU-T
      G.719 extension for 20\n                 kHz fullband audio\", April 2008.\n
      \  [RFC2119]     Bradner, S., \"Key words for use in RFCs to Indicate\n                 Requirement
      Levels\", BCP 14, RFC 2119, March 1997.\n   [RFC3264]     Rosenberg, J. and
      H. Schulzrinne, \"An Offer/Answer\n                 Model with Session Description
      Protocol (SDP)\",\n                 RFC 3264, June 2002.\n   [RFC3550]     Schulzrinne,
      H., Casner, S., Frederick, R., and V.\n                 Jacobson, \"RTP: A Transport
      Protocol for Real-Time\n                 Applications\", STD 64, RFC 3550, July
      2003.\n   [RFC3551]     Schulzrinne, H. and S. Casner, \"RTP Profile for Audio\n
      \                and Video Conferences with Minimal Control\", STD 65,\n                 RFC
      3551, July 2003.\n   [RFC4566]     Handley, M., Jacobson, V., and C. Perkins,
      \"SDP:\n                 Session Description Protocol\", RFC 4566, July 2006.\n
      \  [RFC5234]     Crocker, D. and P. Overell, \"Augmented BNF for Syntax\n                 Specifications:
      ABNF\", STD 68, RFC 5234, January 2008.\n   [RFC5405]     Eggert, L. and G.
      Fairhurst, \"Unicast UDP Usage\n                 Guidelines for Application
      Designers\", BCP 145,\n                 RFC 5405, November 2008.\n"
    title: 12.1.  Normative References
  - contents:
    - "12.2.  Informative References\n   [RFC2198]     Perkins, C., Kouvelas, I.,
      Hodson, O., Hardman, V.,\n                 Handley, M., Bolot, J., Vega-Garcia,
      A., and S. Fosse-\n                 Parisis, \"RTP Payload for Redundant Audio
      Data\",\n                 RFC 2198, September 1997.\n   [RFC2326]     Schulzrinne,
      H., Rao, A., and R. Lanphier, \"Real Time\n                 Streaming Protocol
      (RTSP)\", RFC 2326, April 1998.\n   [RFC2974]     Handley, M., Perkins, C.,
      and E. Whelan, \"Session\n                 Announcement Protocol\", RFC 2974,
      October 2000.\n   [RFC3711]     Baugher, M., McGrew, D., Naslund, M., Carrara,
      E., and\n                 K. Norrman, \"The Secure Real-time Transport Protocol\n
      \                (SRTP)\", RFC 3711, March 2004.\n   [RFC3839]     Castagno,
      R. and D. Singer, \"MIME Type Registrations\n                 for 3rd Generation
      Partnership Project (3GPP)\n                 Multimedia files\", RFC 3839, July
      2004.\n   [RFC4288]     Freed, N. and J. Klensin, \"Media Type Specifications\n
      \                and Registration Procedures\", BCP 13, RFC 4288,\n                 December
      2005.\n   [RFC4301]     Kent, S. and K. Seo, \"Security Architecture for the\n
      \                Internet Protocol\", RFC 4301, December 2005.\n   [RFC4337]
      \    Y Lim and D. Singer, \"MIME Type Registration for\n                 MPEG-4\",
      RFC 4337, March 2006.\n   [RFC4855]     Casner, S., \"Media Type Registration
      of RTP Payload\n                 Formats\", RFC 4855, February 2007.\n   [RFC5109]
      \    Li, A., \"RTP Payload Format for Generic Forward Error\n                 Correction\",
      RFC 5109, December 2007.\n   [RFC5246]     Dierks, T. and E. Rescorla, \"The
      Transport Layer\n                 Security (TLS) Protocol Version 1.2\", RFC
      5246,\n                 August 2008.\n"
    title: 12.2.  Informative References
  title: 12.  References
- contents:
  - "Authors' Addresses\n   Magnus Westerlund\n   Ericsson AB\n   Torshamnsgatan 21-23\n
    \  SE-164 83 Stockholm\n   SWEDEN\n   Phone: +46 10 7190000\n   EMail: magnus.westerlund@ericsson.com\n
    \  Ingemar Johansson\n   Ericsson AB\n   Laboratoriegrand 11\n   SE-971 28 Lulea\n
    \  SWEDEN\n   Phone: +46 10 7190000\n   EMail: ingemar.s.johansson@ericsson.com\n"
  title: Authors' Addresses
