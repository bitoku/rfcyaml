- title: __initial_text__
  contents:
  - '        Use Cases and Operational Experience with Multipath TCP

    '
- title: Abstract
  contents:
  - "Abstract\n   This document discusses both use cases and operational experience\n\
    \   with Multipath TCP (MPTCP) in real networks.  It lists several\n   prominent\
    \ use cases where Multipath TCP has been considered and is\n   being used.  It\
    \ also gives insight to some heuristics and decisions\n   that have helped to\
    \ realize these use cases and suggests possible\n   improvements.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Engineering Task Force\n   (IETF).  It represents the consensus\
    \ of the IETF community.  It has\n   received public review and has been approved\
    \ for publication by the\n   Internet Engineering Steering Group (IESG).  Not\
    \ all documents\n   approved by the IESG are a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 7841.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc8041.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2017 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.  Code Components\
    \ extracted from this document must\n   include Simplified BSD License text as\
    \ described in Section 4.e of\n   the Trust Legal Provisions and are provided\
    \ without warranty as\n   described in the Simplified BSD License.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................3\n\
    \   2. Use Cases .......................................................4\n  \
    \    2.1. Datacenters ................................................4\n    \
    \  2.2. Cellular/WiFi Offload ......................................5\n      2.3.\
    \ Multipath TCP Proxies ......................................8\n   3. Operational\
    \ Experience ..........................................9\n      3.1. Middlebox\
    \ Interference .....................................9\n      3.2. Congestion Control\
    \ ........................................11\n      3.3. Subflow Management ........................................12\n\
    \      3.4. Implemented Subflow Managers ..............................13\n  \
    \    3.5. Subflow Destination Port ..................................15\n    \
    \  3.6. Closing Subflows ..........................................16\n      3.7.\
    \ Packet Schedulers .........................................17\n      3.8. Segment\
    \ Size Selection ....................................18\n      3.9. Interactions\
    \ with the Domain Name System ..................19\n      3.10. Captive Portals\
    \ ..........................................20\n      3.11. Stateless Webservers\
    \ .....................................20\n      3.12. Load-Balanced Server Farms\
    \ ...............................21\n   4. Security Considerations ........................................21\n\
    \   5. References .....................................................23\n  \
    \    5.1. Normative References ......................................23\n    \
    \  5.2. Informative References ....................................23\n   Acknowledgements\
    \ ..................................................30\n   Authors' Addresses\
    \ ................................................30\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   Multipath TCP was specified in [RFC6824] and five independent\n\
    \   implementations have been developed.  As of November 2016, Multipath\n   TCP\
    \ has been or is being implemented on the following platforms:\n   o  Linux kernel\
    \ [MultipathTCP-Linux]\n   o  Apple iOS and macOS\n   o  Citrix load balancers\n\
    \   o  FreeBSD [FreeBSD-MPTCP]\n   o  Oracle Solaris\n   The first three implementations\
    \ are known to interoperate.  Three of\n   these implementations are open source\
    \ (Linux kernel, FreeBSD and\n   Apple's iOS and macOS).  Apple's implementation\
    \ is widely deployed.\n   Since the publication of [RFC6824] as an Experimental\
    \ RFC, experience\n   has been gathered by various network researchers and users\
    \ about the\n   operational issues that arise when Multipath TCP is used in today's\n\
    \   Internet.\n   When the MPTCP working group was created, several use cases\
    \ for\n   Multipath TCP were identified [RFC6182].  Since then, other use cases\n\
    \   have been proposed and some have been tested and even deployed.  We\n   describe\
    \ these use cases in Section 2.\n   Section 3 focuses on the operational experience\
    \ with Multipath TCP.\n   Most of this experience comes from the utilization of\
    \ the Multipath\n   TCP implementation in the Linux kernel [MultipathTCP-Linux].\
    \  This\n   open-source implementation has been downloaded and implemented by\n\
    \   thousands of users all over the world.  Many of these users have\n   provided\
    \ direct or indirect feedback by writing documents (scientific\n   articles or\
    \ blog messages) or posting to the mptcp-dev mailing list\n   (see https://listes-2.sipr.ucl.ac.be/sympa/arc/mptcp-dev).\
    \  This\n   Multipath TCP implementation is actively maintained and continuously\n\
    \   improved.  It is used on various types of hosts, ranging from\n   smartphones\
    \ or embedded routers to high-end servers.\n   The Multipath TCP implementation\
    \ in the Linux kernel is not, by far,\n   the most widespread deployment of Multipath\
    \ TCP.  Since September\n   2013, Multipath TCP is also supported on smartphones\
    \ and tablets\n   beginning with iOS7 [IETFJ].  There are likely hundreds of millions\n\
    \   of MPTCP-enabled devices.  This Multipath TCP implementation is\n   currently\
    \ only used to support the Siri voice recognition/control\n   application.  Some\
    \ lessons learned from this deployment are described\n   in [IETFJ].\n   Section\
    \ 3 is organized as follows.  Supporting the middleboxes was\n   one of the difficult\
    \ issues in designing the Multipath TCP protocol.\n   We explain in Section 3.1\
    \ which types of middleboxes the Linux Kernel\n   implementation of Multipath\
    \ TCP supports and how it reacts upon\n   encountering these.  Section 3.2 summarizes\
    \ the MPTCP-specific\n   congestion controls that have been implemented.  Sections\
    \ 3.3 to 3.7\n   discuss heuristics and issues with respect to subflow management\
    \ as\n   well as the scheduling across the subflows.  Section 3.8 explains\n \
    \  some problems that occurred with subflows having different Maximum\n   Segment\
    \ Size (MSS) values.  Section 3.9 presents issues with respect\n   to content\
    \ delivery networks and suggests a solution to this issue.\n   Finally, Section\
    \ 3.10 documents an issue with captive portals where\n   MPTCP will behave suboptimally.\n"
- title: 2.  Use Cases
  contents:
  - "2.  Use Cases\n   Multipath TCP has been tested in several use cases.  There\
    \ is already\n   an abundant amount of scientific literature on Multipath TCP\n\
    \   [MPTCPBIB].  Several of the papers published in the scientific\n   literature\
    \ have identified possible improvements that are worth being\n   discussed here.\n"
- title: 2.1.  Datacenters
  contents:
  - "2.1.  Datacenters\n   A first, although initially unexpected, documented use\
    \ case for\n   Multipath TCP has been in datacenters [HotNets][SIGCOMM11].  Today's\n\
    \   datacenters are designed to provide several paths between single-\n   homed\
    \ servers.  The multiplicity of these paths comes from the\n   utilization of\
    \ Equal-Cost Multipath (ECMP) and other load-balancing\n   techniques inside the\
    \ datacenter.  Most of the deployed load-\n   balancing techniques in datacenters\
    \ rely on hashes computed over the\n   five tuple.  Thus, all packets from the\
    \ same TCP connection follow\n   the same path: so they are not reordered.  The\
    \ results in [HotNets]\n   demonstrate by simulations that Multipath TCP can achieve\
    \ a better\n   utilization of the available network by using multiple subflows\
    \ for\n   each Multipath TCP session.  Although [RFC6182] assumes that at least\n\
    \   one of the communicating hosts has several IP addresses, [HotNets]\n   demonstrates\
    \ that Multipath TCP is beneficial when both hosts are\n   single-homed.  This\
    \ idea is analyzed in more details in [SIGCOMM11],\n   where the Multipath TCP\
    \ implementation in the Linux kernel is\n   modified to be able to use several\
    \ subflows from the same IP address.\n   Measurements in a public datacenter show\
    \ the quantitative benefits of\n   Multipath TCP [SIGCOMM11] in this environment.\n\
    \   Although ECMP is widely used inside datacenters, this is not the only\n  \
    \ environment where there are different paths between a pair of hosts.\n   ECMP\
    \ and other load-balancing techniques such as Link Aggregation\n   Groups (LAGs)\
    \ are widely used in today's networks; having multiple\n   paths between a pair\
    \ of single-homed hosts is becoming the norm\n   instead of the exception.  Although\
    \ these multiple paths often have\n   the same cost (from an IGP metrics viewpoint),\
    \ they do not\n   necessarily have the same performance.  For example, [IMC13c]\
    \ reports\n   the results of a long measurement study showing that load-balanced\n\
    \   Internet paths between that same pair of hosts can have huge delay\n   differences.\n"
- title: 2.2.  Cellular/WiFi Offload
  contents:
  - "2.2.  Cellular/WiFi Offload\n   A second use case that has been explored by several\
    \ network\n   researchers is the cellular/WiFi offload use case.  Smartphones\
    \ or\n   other mobile devices equipped with two wireless interfaces are a very\n\
    \   common use case for Multipath TCP.  In September 2015, this is also\n   the\
    \ largest deployment of MPTCP-enabled devices [IETFJ].  It has been\n   briefly\
    \ discussed during IETF 88 [IETF88], but there is no published\n   paper or report\
    \ that analyses this deployment.  For this reason, we\n   only discuss published\
    \ papers that have mainly used the Multipath TCP\n   implementation in the Linux\
    \ kernel for their experiments.\n   The performance of Multipath TCP in wireless\
    \ networks was briefly\n   evaluated in [NSDI12].  One experiment analyzes the\
    \ performance of\n   Multipath TCP on a client with two wireless interfaces. \
    \ This\n   evaluation shows that when the receive window is large, Multipath TCP\n\
    \   can efficiently use the two available links.  However, if the window\n   becomes\
    \ smaller, then packets sent on a slow path can block the\n   transmission of\
    \ packets on a faster path.  In some cases, the\n   performance of Multipath TCP\
    \ over two paths can become lower than the\n   performance of regular TCP over\
    \ the best performing path.  Two\n   heuristics, reinjection and penalization,\
    \ are proposed in [NSDI12] to\n   solve this identified performance problem. \
    \ These two heuristics have\n   since been used in the Multipath TCP implementation\
    \ in the Linux\n   kernel.  [CONEXT13] explored the problem in more detail and\
    \ revealed\n   some other scenarios where Multipath TCP can have difficulties\
    \ in\n   efficiently pooling the available paths.  Improvements to the\n   Multipath\
    \ TCP implementation in the Linux kernel are proposed in\n   [CONEXT13] to cope\
    \ with some of these problems.\n   The first experimental analysis of Multipath\
    \ TCP in a public wireless\n   environment was presented in [Cellnet12].  These\
    \ measurements explore\n   the ability of Multipath TCP to use two wireless networks\
    \ (real WiFi\n   and 3G networks).  Three modes of operation are compared.  The\
    \ first\n   mode of operation is the simultaneous use of the two wireless\n  \
    \ networks.  In this mode, Multipath TCP pools the available resources\n   and\
    \ uses both wireless interfaces.  This mode provides fast handover\n   from WiFi\
    \ to cellular or the opposite when the user moves.\n   Measurements presented\
    \ in [CACM14] show that the handover from one\n   wireless network to another\
    \ is not an abrupt process.  When a host\n   moves, there are regions where the\
    \ quality of one of the wireless\n   networks is weaker than the other, but the\
    \ host considers this\n   wireless network to still be up.  When a mobile host\
    \ enters such\n   regions, its ability to send packets over another wireless network\
    \ is\n   important to ensure a smooth handover.  This is clearly illustrated\n\
    \   from the packet trace discussed in [CACM14].\n   Many cellular networks use\
    \ volume-based pricing; users often prefer\n   to use unmetered WiFi networks\
    \ when available instead of metered\n   cellular networks.  [Cellnet12] implements\
    \ support for the MP_PRIO\n   option to explore two other modes of operation.\n\
    \   In the backup mode, Multipath TCP opens a TCP subflow over each\n   interface,\
    \ but the cellular interface is configured in backup mode.\n   This implies that\
    \ data flows only over the WiFi interface when both\n   interfaces are considered\
    \ to be active.  If the WiFi interface fails,\n   then the traffic switches quickly\
    \ to the cellular interface, ensuring\n   a smooth handover from the user's viewpoint\
    \ [Cellnet12].  The cost of\n   this approach is that the WiFi and cellular interfaces\
    \ are likely to\n   remain active all the time since all subflows are established\
    \ over\n   the two interfaces.\n   The single-path mode is slightly different.\
    \  This mode benefits from\n   the break-before-make capability of Multipath TCP.\
    \  When an MPTCP\n   session is established, a subflow is created over the WiFi\
    \ interface.\n   No packet is sent over the cellular interface as long as the\
    \ WiFi\n   interface remains up [Cellnet12].  This implies that the cellular\n\
    \   interface can remain idle and battery capacity is preserved.  When\n   the\
    \ WiFi interface fails, a new subflow is established over the\n   cellular interface\
    \ in order to preserve the established Multipath TCP\n   sessions.  Compared to\
    \ the backup mode described earlier,\n   measurements reported in [Cellnet12]\
    \ indicate that this mode of\n   operation is characterized by a throughput drop\
    \ while the cellular\n   interface is brought up and the subflows are reestablished.\n\
    \   From a protocol viewpoint, [Cellnet12] discusses the problem posed by\n  \
    \ the unreliability of the REMOVE_ADDR option and proposes a small\n   protocol\
    \ extension to allow hosts to reliably exchange this option.\n   It would be useful\
    \ to analyze packet traces to understand whether the\n   unreliability of the\
    \ REMOVE_ADDR option poses an operational problem\n   in real deployments.\n \
    \  Another study of the performance of Multipath TCP in wireless\n   networks\
    \ was reported in [IMC13b].  This study uses laptops connected\n   to various\
    \ cellular ISPs and WiFi hotspots.  It compares various file\n   transfer scenarios.\
    \  [IMC13b] observes that 4-path MPTCP outperforms\n   2-path MPTCP, especially\
    \ for larger files.  However, for three\n   congestion-control algorithms (LIA,\
    \ OLIA, and Reno -- see\n   Section 3.2), there is no significant performance\
    \ difference for file\n   sizes smaller than 4 MB.\n   A different study of the\
    \ performance of Multipath TCP with two\n   wireless networks is presented in\
    \ [INFOCOM14].  In this study the two\n   networks had different qualities: a\
    \ good network and a lossy network.\n   When using two paths with different packet-loss\
    \ ratios, the Multipath\n   TCP congestion-control scheme moves traffic away from\
    \ the lossy link\n   that is considered to be congested.  However, [INFOCOM14]\
    \ documents\n   an interesting scenario that is summarized hereafter.\n   client\
    \ ----------- path1 -------- server\n     |                                  |\n\
    \     +--------------- path2 ------------+\n       Figure 1: Simple network topology\n\
    \   Initially, the two paths in Figure 1 have the same quality and\n   Multipath\
    \ TCP distributes the load over both of them.  During the\n   transfer, the path2\
    \ becomes lossy, e.g., because the client moves.\n   Multipath TCP detects the\
    \ packet losses and they are retransmitted\n   over path1.  This enables the data\
    \ transfer to continue over this\n   path.  However, the subflow over path2 is\
    \ still up and transmits one\n   packet from time to time.  Although the N packets\
    \ have been\n   acknowledged over the first subflow (at the MPTCP level), they\
    \ have\n   not been acknowledged at the TCP level over the second subflow.  To\n\
    \   preserve the continuity of the sequence numbers over the second\n   subflow,\
    \ TCP will continue to retransmit these segments until either\n   they are acknowledged\
    \ or the maximum number of retransmissions is\n   reached.  This behavior is clearly\
    \ inefficient and may lead to\n   blocking since the second subflow will consume\
    \ window space to be\n   able to retransmit these packets.  [INFOCOM14] proposes\
    \ a new\n   Multipath TCP option to solve this problem.  In practice, a new TCP\n\
    \   option is probably not required.  When the client detects that the\n   data\
    \ transmitted over the second subflow has been acknowledged over\n   the first\
    \ subflow, it could decide to terminate the second subflow by\n   sending a RST\
    \ segment.  If the interface associated to this subflow\n   is still up, a new\
    \ subflow could be immediately reestablished.  It\n   would then be immediately\
    \ usable to send new data and would not be\n   forced to first retransmit the\
    \ previously transmitted data.  As of\n   this writing, this dynamic management\
    \ of the subflows is not yet\n   implemented in the Multipath TCP implementation\
    \ in the Linux kernel.\n   Some studies have started to analyze the performance\
    \ of Multipath TCP\n   on smartphones with real applications.  In contrast with\
    \ the bulk\n   transfers that are used by many publications, many deployed\n \
    \  applications do not exchange huge amounts of data and mainly use\n   small\
    \ connections.  [COMMAG2016] proposes a software testing\n   framework that allows\
    \ to automate Android applications to study their\n   interactions with Multipath\
    \ TCP.  [PAM2016] analyses a one-month\n   packet trace of all the packets exchanged\
    \ by a dozen of smartphones\n   utilized by regular users.  This analysis reveals\
    \ that short\n   connections are important on smartphones and that the main benefit\
    \ of\n   using Multipath TCP on smartphones is the ability to perform seamless\n\
    \   handovers between different wireless networks.  Long connections\n   benefit\
    \ from these handovers.\n"
- title: 2.3.  Multipath TCP Proxies
  contents:
  - "2.3.  Multipath TCP Proxies\n   As Multipath TCP is not yet widely deployed on\
    \ both clients and\n   servers, several deployments have used various forms of\
    \ proxies.  Two\n   families of solutions are currently being used or tested.\n\
    \   A first use case is when an MPTCP-enabled client wants to use several\n  \
    \ interfaces to reach a regular TCP server.  A typical use case is a\n   smartphone\
    \ that needs to use both its WiFi and its cellular interface\n   to transfer data.\
    \  Several types of proxies are possible for this use\n   case.  An HTTP proxy\
    \ deployed on a MPTCP-capable server would enable\n   the smartphone to use Multipath\
    \ TCP to access regular web servers.\n   Obviously, this solution only works for\
    \ applications that rely on\n   HTTP.  Another possibility is to use a proxy that\
    \ can convert any\n   Multipath TCP connection into a regular TCP connection.\
    \  MPTCP-\n   specific proxies have been proposed [HotMiddlebox13b] [HAMPEL].\n\
    \   Another possibility leverages the SOCKS protocol [RFC1928].  SOCKS is\n  \
    \ often used in enterprise networks to allow clients to reach external\n   servers.\
    \  For this, the client opens a TCP connection to the SOCKS\n   server that relays\
    \ it to the final destination.  If both the client\n   and the SOCKS server use\
    \ Multipath TCP, but not the final\n   destination, then Multipath TCP can still\
    \ be used on the path between\n   the clients and the SOCKS server.  At IETF 93,\
    \ Korea Telecom\n   announced that they have deployed (in June 2015) a commercial\
    \ service\n   that uses Multipath TCP on smartphones.  These smartphones access\n\
    \   regular TCP servers through a SOCKS proxy.  This enables them to\n   achieve\
    \ throughputs of up to 850 Mbps [KT].\n   Measurements performed with Android\
    \ smartphones [Mobicom15] show that\n   popular applications work correctly through\
    \ a SOCKS proxy and MPTCP-\n   enabled smartphones.  Thanks to Multipath TCP,\
    \ long-lived connections\n   can be spread over the two available interfaces.\
    \  However, for short-\n   lived connections, most of the data is sent over the\
    \ initial subflow\n   that is created over the interface corresponding to the\
    \ default route\n   and the second subflow is almost not used [PAM2016].\n   A\
    \ second use case is when Multipath TCP is used by middleboxes,\n   typically\
    \ inside access networks.  Various network operators are\n   discussing and evaluating\
    \ solutions for hybrid access networks\n   [TR-348].  Such networks arise when\
    \ a network operator controls two\n   different access network technologies, e.g.,\
    \ wired and cellular, and\n   wants to combine them to improve the bandwidth offered\
    \ to the end\n   users [HYA-ARCH].  Several solutions are currently investigated\
    \ for\n   such networks [TR-348].  Figure 2 shows the organization of such a\n\
    \   network.  When a client creates a normal TCP connection, it is\n   intercepted\
    \ by the Hybrid CPE (HPCE) that converts it in a Multipath\n   TCP connection\
    \ so that it can use the available access networks (DSL\n   and LTE in the example).\
    \  The Hybrid Access Gateway (HAG) does the\n   opposite to ensure that the regular\
    \ server sees a normal TCP\n   connection.  Some of the solutions currently discussed\
    \ for hybrid\n   networks use Multipath TCP on the HCPE and the HAG.  Other solutions\n\
    \   rely on tunnels between the HCPE and the HAG [GRE-NOTIFY].\n   client ---\
    \ HCPE ------ DSL ------- HAG --- internet --- server\n               |      \
    \                 |\n               +------- LTE -----------+\n              \
    \        Figure 2: Hybrid Access Network\n"
- title: 3.  Operational Experience
  contents:
  - '3.  Operational Experience

    '
- title: 3.1.  Middlebox Interference
  contents:
  - "3.1.  Middlebox Interference\n   The interference caused by various types of\
    \ middleboxes has been an\n   important concern during the design of the Multipath\
    \ TCP protocol.\n   Three studies on the interactions between Multipath TCP and\n\
    \   middleboxes are worth discussing.\n   The first analysis appears in [IMC11].\
    \  This paper was the main\n   motivation for Multipath TCP incorporating various\
    \ techniques to cope\n   with middlebox interference.  More specifically, Multipath\
    \ TCP has\n   been designed to cope with middleboxes that:\n   o  change source\
    \ or destination addresses\n   o  change source or destination port numbers\n\
    \   o  change TCP sequence numbers\n   o  split or coalesce segments\n   o  remove\
    \ TCP options\n   o  modify the payload of TCP segments\n   These middlebox interferences\
    \ have all been included in the MBtest\n   suite [MBTest].  This test suite is\
    \ used in [HotMiddlebox13] to\n   verify the reaction of the Multipath TCP implementation\
    \ in the Linux\n   kernel [MultipathTCP-Linux] when faced with middlebox interference.\n\
    \   The test environment used for this evaluation is a dual-homed client\n   connected\
    \ to a single-homed server.  The middlebox behavior can be\n   activated on any\
    \ of the paths.  The main results of this analysis\n   are:\n   o  the Multipath\
    \ TCP implementation in the Linux kernel is not\n      affected by a middlebox\
    \ that performs NAT or modifies TCP sequence\n      numbers\n   o  when a middlebox\
    \ removes the MP_CAPABLE option from the initial\n      SYN segment, the Multipath\
    \ TCP implementation in the Linux kernel\n      falls back correctly to regular\
    \ TCP\n   o  when a middlebox removes the DSS option from all data segments,\n\
    \      the Multipath TCP implementation in the Linux kernel falls back\n     \
    \ correctly to regular TCP\n   o  when a middlebox performs segment coalescing,\
    \ the Multipath TCP\n      implementation in the Linux kernel is still able to\
    \ accurately\n      extract the data corresponding to the indicated mapping\n\
    \   o  when a middlebox performs segment splitting, the Multipath TCP\n      implementation\
    \ in the Linux kernel correctly reassembles the data\n      corresponding to the\
    \ indicated mapping.  [HotMiddlebox13] shows,\n      in Figure 4 in Section 3.3,\
    \ a corner case with segment splitting\n      that may lead to a desynchronization\
    \ between the two hosts.\n   The interactions between Multipath TCP and real deployed\
    \ middleboxes\n   are also analyzed in [HotMiddlebox13]; a particular scenario\
    \ with the\n   FTP Application Level Gateway running on a NAT is described.\n\
    \   Middlebox interference can also be detected by analyzing packet\n   traces\
    \ on MPTCP-enabled servers.  A closer look at the packets\n   received on the\
    \ multipath-tcp.org server [TMA2015] shows that among\n   the 184,000 Multipath\
    \ TCP connections, only 125 of them were falling\n   back to regular TCP.  These\
    \ connections originated from 28 different\n   client IP addresses.  These include\
    \ 91 HTTP connections and 34 FTP\n   connections.  The FTP interference is expected\
    \ since Application\n   Level Gateways used for FTP modify the TCP payload and\
    \ the DSS\n   Checksum detects these modifications.  The HTTP interference appeared\n\
    \   only on the direction from server to client and could have been\n   caused\
    \ by transparent proxies deployed in cellular or enterprise\n   networks.  A longer\
    \ trace is discussed in [COMCOM2016] and similar\n   conclusions about the middlebox\
    \ interference are provided.\n   From an operational viewpoint, knowing that Multipath\
    \ TCP can cope\n   with various types of middlebox interference is important.\
    \  However,\n   there are situations where the network operators need to gather\n\
    \   information about where a particular middlebox interference occurs.\n   The\
    \ tracebox software [tracebox] described in [IMC13a] is an\n   extension of the\
    \ popular traceroute software that enables network\n   operators to check at which\
    \ hop a particular field of the TCP header\n   (including options) is modified.\
    \  It has been used by several network\n   operators to debug various middlebox\
    \ interference problems.\n   Experience with tracebox indicates that supporting\
    \ the ICMP extension\n   defined in [RFC1812] makes it easier to debug middlebox\
    \ problems in\n   IPv4 networks.\n   Users of the Multipath TCP implementation\
    \ have reported some\n   experience with middlebox interference.  The strangest\
    \ scenario has\n   been a middlebox that accepts the Multipath TCP options in\
    \ the SYN\n   segment but later replaces Multipath TCP options with a TCP EOL\n\
    \   option [StrangeMbox].  This causes Multipath TCP to perform a\n   fallback\
    \ to regular TCP without any impact on the application.\n"
- title: 3.2.  Congestion Control
  contents:
  - "3.2.  Congestion Control\n   Congestion control has been an important challenge\
    \ for Multipath TCP.\n   The coupled congestion-control scheme defined in [RFC6356]\
    \ in an\n   adaptation of the NewReno algorithm.  A detailed description of this\n\
    \   coupled algorithm is provided in [NSDI11].  It is the default scheme\n   in\
    \ the Linux implementation of Multipath TCP, but Linux supports\n   other schemes.\n\
    \   The second congestion-control scheme is OLIA [CONEXT12].  It is also\n   an\
    \ adaptation of the NewReno single path congestion-control scheme to\n   support\
    \ multiple paths.  Simulations [CONEXT12] and measurements\n   [CONEXT13] have\
    \ shown that it provides some performance benefits\n   compared to the default\
    \ coupled congestion-control scheme.\n   The delay-based scheme proposed in [ICNP12]\
    \ has also been ported to\n   the Multipath TCP implementation in the Linux kernel.\
    \  It has been\n   evaluated by using simulations [ICNP12] and measurements [PaaschPhD].\n\
    \   BALIA, defined in [BALIA], provides a better balance between TCP\n   friendliness,\
    \ responsiveness, and window oscillation.\n   These different congestion-control\
    \ schemes have been compared in\n   several articles.  [CONEXT13] and [PaaschPhD]\
    \ compare these\n   algorithms in an emulated environment.  The evaluation showed\
    \ that\n   the delay-based congestion-control scheme is less able to efficiently\n\
    \   use the available links than the three other schemes.\n"
- title: 3.3.  Subflow Management
  contents:
  - "3.3.  Subflow Management\n   The multipath capability of Multipath TCP comes\
    \ from the utilization\n   of one subflow per path.  The Multipath TCP architecture\
    \ [RFC6182]\n   and the protocol specification [RFC6824] define the basic usage\
    \ of\n   the subflows and the protocol mechanisms that are required to create\n\
    \   and terminate them.  However, there are no guidelines on how subflows\n  \
    \ are used during the lifetime of a Multipath TCP session.  Most of the\n   published\
    \ experiments with Multipath TCP have been performed in\n   controlled environments.\
    \  Still, based on the experience running them\n   and discussions on the mptcp-dev\
    \ mailing list, interesting lessons\n   have been learned about the management\
    \ of these subflows.\n   From a subflow viewpoint, the Multipath TCP protocol\
    \ is completely\n   symmetrical.  Both the clients and the server have the capability\
    \ to\n   create subflows.  However, in practice, the existing Multipath TCP\n\
    \   implementations have opted for a strategy where only the client\n   creates\
    \ new subflows.  The main motivation for this strategy is that\n   often the client\
    \ resides behind a NAT or a firewall, preventing\n   passive subflow openings\
    \ on the client.  Although there are\n   environments such as datacenters where\
    \ this problem does not occur,\n   as of this writing, no precise requirement\
    \ has emerged for allowing\n   the server to create new subflows.\n"
- title: 3.4.  Implemented Subflow Managers
  contents:
  - "3.4.  Implemented Subflow Managers\n   The Multipath TCP implementation in the\
    \ Linux kernel includes several\n   strategies to manage the subflows that compose\
    \ a Multipath TCP\n   session.  The basic subflow manager is the full-mesh.  As\
    \ the name\n   implies, it creates a full-mesh of subflows between the communicating\n\
    \   hosts.\n   The most frequent use case for this subflow manager is a multihomed\n\
    \   client connected to a single-homed server.  In this case, one subflow\n  \
    \ is created for each interface on the client.  The current\n   implementation\
    \ of the full-mesh subflow manager is static.  The\n   subflows are created immediately\
    \ after the creation of the initial\n   subflow.  If one subflow fails during\
    \ the lifetime of the Multipath\n   TCP session (e.g., due to excessive retransmissions\
    \ or the loss of\n   the corresponding interface), it is not always reestablished.\
    \  There\n   is ongoing work to enhance the full-mesh path manager to deal with\n\
    \   such events.\n   When the server is multihomed, using the full-mesh subflow\
    \ manager\n   may lead to a large number of subflows being established.  For\n\
    \   example, consider a dual-homed client connected to a server with\n   three\
    \ interfaces.  In this case, even if the subflows are only\n   created by the\
    \ client, six subflows will be established.  This may be\n   excessive in some\
    \ environments, in particular when the client and/or\n   the server have a large\
    \ number of interfaces.  Implementations should\n   limit the number of subflows\
    \ that are used.\n   Creating subflows between multihomed clients and servers\
    \ may\n   sometimes lead to operational issues as observed by discussions on\n\
    \   the mptcp-dev mailing list.  In some cases, the network operators\n   would\
    \ like to have a better control on how the subflows are created\n   by Multipath\
    \ TCP [MPTCP-MAX-SUB].  This might require the definition\n   of policy rules\
    \ to control the operation of the subflow manager.  The\n   two scenarios below\
    \ illustrate some of these requirements.\n                host1 ----------  switch1\
    \ ----- host2\n                  |                   |            |\n        \
    \          +--------------  switch2 --------+\n                Figure 3: Simple\
    \ Switched Network Topology\n   Consider the simple network topology shown in\
    \ Figure 3.  From an\n   operational viewpoint, a network operator could want\
    \ to create two\n   subflows between the communicating hosts.  From a bandwidth\n\
    \   utilization viewpoint, the most natural paths are host1-switch1-host2\n  \
    \ and host1-switch2-host2.  However, a Multipath TCP implementation\n   running\
    \ on these two hosts may sometimes have difficulties to obtain\n   this result.\n\
    \   To understand the difficulty, let us consider different allocation\n   strategies\
    \ for the IP addresses.  A first strategy is to assign two\n   subnets: subnetA\
    \ (resp. subnetB) contains the IP addresses of host1's\n   interface to switch1\
    \ (resp. switch2) and host2's interface to switch1\n   (resp. switch2).  In this\
    \ case, a Multipath TCP subflow manager\n   should only create one subflow per\
    \ subnet.  To enforce the\n   utilization of these paths, the network operator\
    \ would have to\n   specify a policy that prefers the subflows in the same subnet\
    \ over\n   subflows between addresses in different subnets.  It should be noted\n\
    \   that the policy should probably also specify how the subflow manager\n   should\
    \ react when an interface or subflow fails.\n   A second strategy is to use a\
    \ single subnet for all IP addresses.  In\n   this case, it becomes more difficult\
    \ to specify a policy that\n   indicates which subflows should be established.\n\
    \   The second subflow manager that is currently supported by the\n   Multipath\
    \ TCP implementation in the Linux kernel is the ndiffport\n   subflow manager.\
    \  This manager was initially created to exploit the\n   path diversity that exists\
    \ between single-homed hosts due to the\n   utilization of flow-based load-balancing\
    \ techniques [SIGCOMM11].\n   This subflow manager creates N subflows between\
    \ the same pair of IP\n   addresses.  The N subflows are created by the client\
    \ and differ only\n   in the source port selected by the client.  It was not designed\
    \ to be\n   used on multihomed hosts.\n   A more flexible subflow manager has\
    \ been proposed, implemented and\n   evaluated in [CONEXT15].  This subflow manager\
    \ exposes various kernel\n   events to a user space daemon that decides when subflows\
    \ need to be\n   created and terminated based on various policies.\n"
- title: 3.5.  Subflow Destination Port
  contents:
  - "3.5.  Subflow Destination Port\n   The Multipath TCP protocol relies on the token\
    \ contained in the\n   MP_JOIN option to associate a subflow to an existing Multipath\
    \ TCP\n   session.  This implies that there is no restriction on the source\n\
    \   address, destination address and source or destination ports used for\n  \
    \ the new subflow.  The ability to use different source and destination\n   addresses\
    \ is key to support multihomed servers and clients.  The\n   ability to use different\
    \ destination port numbers is worth discussing\n   because it has operational\
    \ implications.\n   For illustration, consider a dual-homed client that creates\
    \ a second\n   subflow to reach a single-homed server as illustrated in Figure\
    \ 4.\n           client ------- r1 --- internet --- server\n               | \
    \                  |\n               +----------r2-------+\n       Figure 4: Multihomed-Client\
    \ Connected to Single-Homed Server\n   When the Multipath TCP implementation in\
    \ the Linux kernel creates the\n   second subflow, it uses the same destination\
    \ port as the initial\n   subflow.  This choice is motivated by the fact that\
    \ the server might\n   be protected by a firewall and only accept TCP connections\
    \ (including\n   subflows) on the official port number.  Using the same destination\n\
    \   port for all subflows is also useful for operators that rely on the\n   port\
    \ numbers to track application usage in their network.\n   There have been suggestions\
    \ from Multipath TCP users to modify the\n   implementation to allow the client\
    \ to use different destination ports\n   to reach the server.  This suggestion\
    \ seems mainly motivated by\n   traffic-shaping middleboxes that are used in some\
    \ wireless networks.\n   In networks where different shaping rates are associated\
    \ with\n   different destination port numbers, this could allow Multipath TCP\
    \ to\n   reach a higher performance.  This behavior is valid according to the\n\
    \   Multipath TCP specification [RFC6824].  An application could use an\n   enhanced\
    \ socket API [SOCKET] to behave in this way.\n   However, from an implementation\
    \ point-of-view supporting different\n   destination ports for the same Multipath\
    \ TCP connection can cause\n   some issues.  A legacy implementation of a TCP\
    \ stack creates a\n   listening socket to react upon incoming SYN segments.  The\
    \ listening\n   socket is handling the SYN segments that are sent on a specific\
    \ port\n   number.  Demultiplexing incoming segments can thus be done solely by\n\
    \   looking at the IP addresses and the port numbers.  With Multipath TCP\n  \
    \ however, incoming SYN segments may have an MP_JOIN option with a\n   different\
    \ destination port.  This means that all incoming segments\n   that did not match\
    \ on an existing listening-socket or an already\n   established socket must be\
    \ parsed for an eventual MP_JOIN option.\n   This imposes an additional cost on\
    \ servers, previously not existent\n   on legacy TCP implementations.\n"
- title: 3.6.  Closing Subflows
  contents:
  - "3.6.  Closing Subflows\n                    client                       server\n\
    \                       |                           |\n   MPTCP: ESTABLISHED \
    \ |                           | MPTCP: ESTABLISHED\n   Sub: ESTABLISHED    | \
    \                          | Sub: ESTABLISHED\n                       |      \
    \                     |\n                       |         DATA_FIN          |\n\
    \   MPTCP: CLOSE-WAIT   | <------------------------ | close()   (step 1)\n   Sub:\
    \ ESTABLISHED    |         DATA_ACK          |\n                       | ------------------------>\
    \ | MPTCP: FIN-WAIT-2\n                       |                           | Sub:\
    \ ESTABLISHED\n                       |                           |\n        \
    \               |  DATA_FIN + subflow-FIN   |\n   close()/shutdown()  | ------------------------>\
    \ | MPTCP: TIME-WAIT\n   (step 2)            |        DATA_ACK           | Sub:\
    \ CLOSE-WAIT\n   MPTCP: CLOSED       | <------------------------ |\n   Sub: FIN-WAIT-2\
    \     |                           |\n                       |                \
    \           |\n                       |        subflow-FIN        |\n   MPTCP:\
    \ CLOSED       | <------------------------ | subflow-close()\n   Sub: TIME-WAIT\
    \      |        subflow-ACK        |\n   (step 3)            | ------------------------>\
    \ | MPTCP: TIME-WAIT\n                       |                           | Sub:\
    \ CLOSED\n                       |                           |\n    Figure 5:\
    \ Multipath TCP may not be able to avoid time-wait state on\n    the subflow (indicated\
    \ as Sub in the drawing), even if enforced by\n                    the application\
    \ on the client-side.\n   Figure 5 shows a very particular issue within Multipath\
    \ TCP.  Many\n   high-performance applications try to avoid TIME-WAIT state by\n\
    \   deferring the closure of the connection until the peer has sent a\n   FIN.\
    \  That way, the client on the left of Figure 5 does a passive\n   closure of\
    \ the connection, transitioning from CLOSE-WAIT to Last-ACK\n   and finally freeing\
    \ the resources after reception of the ACK of the\n   FIN.  An application running\
    \ on top of an MPTCP-enabled Linux kernel\n   might also use this approach.  The\
    \ difference here is that the\n   close() of the connection (step 1 in Figure\
    \ 5) only triggers the\n   sending of a DATA_FIN.  Nothing guarantees that the\
    \ kernel is ready\n   to combine the DATA_FIN with a subflow-FIN.  The reception\
    \ of the\n   DATA_FIN will make the application trigger the closure of the\n \
    \  connection (step 2), trying to avoid TIME-WAIT state with this late\n   closure.\
    \  This time, the kernel might decide to combine the DATA_FIN\n   with a subflow-FIN.\
    \  This decision will be fatal, as the subflow's\n   state machine will not transition\
    \ from CLOSE_WAIT to Last-ACK, but\n   rather go through FIN_WAIT-2 into TIME-WAIT\
    \ state.  The TIME-WAIT\n   state will consume resources on the host for at least\
    \ 2 MSL (Maximum\n   Segment Lifetime).  Thus, a smart application that tries\
    \ to avoid\n   TIME-WAIT state by doing late closure of the connection actually\
    \ ends\n   up with one of its subflows in TIME-WAIT state.  A high-performance\n\
    \   Multipath TCP kernel implementation should honor the desire of the\n   application\
    \ to do passive closure of the connection and successfully\n   avoid TIME-WAIT\
    \ state -- even on the subflows.\n   The solution to this problem lies in an optimistic\
    \ assumption that a\n   host doing active-closure of a Multipath TCP connection\
    \ by sending a\n   DATA_FIN will soon also send a FIN on all its subflows.  Thus,\
    \ the\n   passive closer of the connection can simply wait for the peer to send\n\
    \   exactly this FIN -- enforcing passive closure even on the subflows.\n   Of\
    \ course, to avoid consuming resources indefinitely, a timer must\n   limit the\
    \ time our implementation waits for the FIN.\n"
- title: 3.7.  Packet Schedulers
  contents:
  - "3.7.  Packet Schedulers\n   In a Multipath TCP implementation, the packet scheduler\
    \ is the\n   algorithm that is executed when transmitting each packet to decide\
    \ on\n   which subflow it needs to be transmitted.  The packet scheduler\n   itself\
    \ does not have any impact on the interoperability of Multipath\n   TCP implementations.\
    \  However, it may clearly impact the performance\n   of Multipath TCP sessions.\
    \  The Multipath TCP implementation in the\n   Linux kernel supports a pluggable\
    \ architecture for the packet\n   scheduler [PaaschPhD].  As of this writing,\
    \ two schedulers have been\n   implemented: round-robin and lowest-rtt-first.\
    \  The second scheduler\n   relies on the round-trip time (rtt) measured on each\
    \ TCP subflow and\n   sends first segments over the subflow having the lowest\
    \ round-trip\n   time.  They are compared in [CSWS14].  The experiments and\n\
    \   measurements described in [CSWS14] show that the lowest-rtt-first\n   scheduler\
    \ appears to be the best compromise from a performance\n   viewpoint.  Another\
    \ study of the packet schedulers is presented in\n   [PAMS2014].  This study relies\
    \ on simulations with the Multipath TCP\n   implementation in the Linux kernel.\
    \  They compare the lowest-rtt-\n   first with the round-robin and a random scheduler.\
    \  They show some\n   situations where the lowest-rtt-first scheduler does not\
    \ perform as\n   well as the other schedulers, but there are many scenarios where\
    \ the\n   opposite is true.  [PAMS2014] notes that \"it is highly likely that\n\
    \   the optimal scheduling strategy depends on the characteristics of the\n  \
    \ paths being used.\"\n"
- title: 3.8.  Segment Size Selection
  contents:
  - "3.8.  Segment Size Selection\n   When an application performs a write/send system\
    \ call, the kernel\n   allocates a packet buffer (sk_buff in Linux) to store the\
    \ data the\n   application wants to send.  The kernel will store at most one MSS\n\
    \   (Maximum Segment Size) of data per buffer.  As the MSS can differ\n   amongst\
    \ subflows, an MPTCP implementation must select carefully the\n   MSS used to\
    \ generate application data.  The Linux kernel\n   implementation had various\
    \ ways of selecting the MSS: minimum or\n   maximum amongst the different subflows.\
    \  However, these heuristics of\n   MSS selection can cause significant performance\
    \ issues in some\n   environments.  Consider the following example.  An MPTCP\
    \ connection\n   has two established subflows that respectively use an MSS of\
    \ 1420 and\n   1428 bytes.  If MPTCP selects the maximum, then the application\
    \ will\n   generate segments of 1428 bytes of data.  An MPTCP implementation\n\
    \   will have to split the segment in two (1420-byte and 8-byte) segments\n  \
    \ when pushing on the subflow with the smallest MSS.  The latter\n   segment will\
    \ introduce a large overhead as this single data segment\n   will use 2 slots\
    \ in the congestion window (in packets) therefore\n   reducing by roughly twice\
    \ the potential throughput (in bytes/s) of\n   this subflow.  Taking the smallest\
    \ MSS does not solve the issue as\n   there might be a case where the subflow\
    \ with the smallest MSS only\n   sends a few packets, therefore reducing the potential\
    \ throughput of\n   the other subflows.\n   The Linux implementation recently\
    \ took another approach [DetalMSS].\n   Instead of selecting the minimum and maximum\
    \ values, it now\n   dynamically adapts the MSS based on the contribution of all\
    \ the\n   subflows to the connection's throughput.  For each subflow, it\n   computes\
    \ the potential throughput achieved by selecting each MSS\n   value and by taking\
    \ into account the lost space in the congestion\n   window.  It then selects the\
    \ MSS that allows to achieve the highest\n   potential throughput.\n   Given the\
    \ prevalence of middleboxes that clamp the MSS, Multipath TCP\n   implementations\
    \ must be able to efficiently support subflows with\n   different MSS values.\
    \  The strategy described above is a possible\n   solution to this problem.\n"
- title: 3.9.  Interactions with the Domain Name System
  contents:
  - "3.9.  Interactions with the Domain Name System\n   Multihomed clients such as\
    \ smartphones can send DNS queries over any\n   of their interfaces.  When a single-homed\
    \ client performs a DNS\n   query, it receives from its local resolver the best\
    \ answer for its\n   request.  If the client is multihomed, the answer in response\
    \ to the\n   DNS query may vary with the interface over which it has been sent.\n\
    \                      cdn1\n                       |\n           client -- cellular\
    \ -- internet -- cdn3\n              |                   |\n              +-----\
    \ wifi --------+\n                       |\n                     cdn2\n      \
    \               Figure 6: Simple Network Topology\n   If the client sends a DNS\
    \ query over the WiFi interface, the answer\n   will point to the cdn2 server\
    \ while the same request sent over the\n   cellular interface will point to the\
    \ cdn1 server.  This might cause\n   problems for CDN providers that locate their\
    \ servers inside ISP\n   networks and have contracts that specify that the CDN\
    \ server will\n   only be accessed from within this particular ISP.  Assume now\
    \ that\n   both the client and the CDN servers support Multipath TCP.  In this\n\
    \   case, a Multipath TCP session from cdn1 or cdn2 would potentially use\n  \
    \ both the cellular network and the WiFi network.  Serving the client\n   from\
    \ cdn2 over the cellular interface could violate the contract\n   between the\
    \ CDN provider and the network operators.  A similar\n   problem occurs with regular\
    \ TCP if the client caches DNS replies.\n   For example, the client obtains a\
    \ DNS answer over the cellular\n   interface and then stops this interface and\
    \ starts to use its WiFi\n   interface.  If the client retrieves data from cdn1\
    \ over its WiFi\n   interface, this may also violate the contract between the\
    \ CDN and the\n   network operators.\n   A possible solution to prevent this problem\
    \ would be to modify the\n   DNS resolution on the client.  The client subnet\
    \ Extension Mechanisms\n   for DNS (EDNS) defined in [RFC7871] could be used for\
    \ this purpose.\n   When the client sends a DNS query from its WiFi interface,\
    \ it should\n   also send the client subnet corresponding to the cellular interface\n\
    \   in this request.  This would indicate to the resolver that the answer\n  \
    \ should be valid for both the WiFi and the cellular interfaces (e.g.,\n   the\
    \ cdn3 server).\n"
- title: 3.10.  Captive Portals
  contents:
  - "3.10.  Captive Portals\n   Multipath TCP enables a host to use different interfaces\
    \ to reach a\n   server.  In theory, this should ensure connectivity when at least\
    \ one\n   of the interfaces is active.  However, in practice, there are some\n\
    \   particular scenarios with captive portals that may cause operational\n   problems.\
    \  The reference environment is shown in Figure 7.\n           client -----  network1\n\
    \                |\n                +------- internet ------------- server\n \
    \                   Figure 7: Issue with Captive Portal\n   The client is attached\
    \ to two networks: network1 that provides\n   limited connectivity and the entire\
    \ Internet through the second\n   network interface.  In practice, this scenario\
    \ corresponds to an open\n   WiFi network with a captive portal for network1 and\
    \ a cellular\n   service for the second interface.  On many smartphones, the WiFi\n\
    \   interface is preferred over the cellular interface.  If the\n   smartphone\
    \ learns a default route via both interfaces, it will\n   typically prefer to\
    \ use the WiFi interface to send its DNS request\n   and create the first subflow.\
    \  This is not optimal with Multipath\n   TCP.  A better approach would probably\
    \ be to try a few attempts on\n   the WiFi interface and then, upon failure of\
    \ these attempts, try to\n   use the second interface for the initial subflow\
    \ as well.\n"
- title: 3.11.  Stateless Webservers
  contents:
  - "3.11.  Stateless Webservers\n   MPTCP has been designed to interoperate with\
    \ webservers that benefit\n   from SYN-cookies to protect against SYN-flooding\
    \ attacks [RFC4987].\n   MPTCP achieves this by echoing the keys negotiated during\
    \ the\n   MP_CAPABLE handshake in the third ACK of the three-way handshake.\n\
    \   Reception of this third ACK then allows the server to reconstruct the\n  \
    \ state specific to MPTCP.\n   However, one caveat to this mechanism is the unreliable\
    \ nature of the\n   third ACK.  Indeed, when the third ACK gets lost, the server\
    \ will not\n   be able to reconstruct the MPTCP state.  MPTCP will fall back to\n\
    \   regular TCP in this case.  This is in contrast to regular TCP.  When\n   the\
    \ client starts sending data, the first data segment also includes\n   the SYN-cookie,\
    \ which allows the server to reconstruct the TCP-state.\n   Further, this data\
    \ segment will be retransmitted by the client in\n   case it gets lost and thus\
    \ is resilient against loss.  MPTCP does not\n   include the keys in this data\
    \ segment and thus the server cannot\n   reconstruct the MPTCP state.\n   This\
    \ issue might be considered as a minor one for MPTCP.  Losing the\n   third ACK\
    \ should only happen when packet loss is high; in this case,\n   MPTCP provides\
    \ a lot of benefits as it can move traffic away from the\n   lossy link.  It is\
    \ undesirable that MPTCP has a higher chance to fall\n   back to regular TCP in\
    \ those lossy environments.\n   [MPTCP-DEPLOY] discusses this issue and suggests\
    \ a modified handshake\n   mechanism that ensures reliable delivery of the MP_CAPABLE,\
    \ following\n   the three-way handshake.  This modification will make MPTCP reliable,\n\
    \   even in lossy environments when servers need to use SYN-cookies to\n   protect\
    \ against SYN-flooding attacks.\n"
- title: 3.12.  Load-Balanced Server Farms
  contents:
  - "3.12.  Load-Balanced Server Farms\n   Large-scale server farms typically deploy\
    \ thousands of servers behind\n   a single virtual IP (VIP).  Steering traffic\
    \ to these servers is done\n   through Layer 4 load-balancers that ensure that\
    \ a TCP-flow will\n   always be routed to the same server [Presto08].\n   As Multipath\
    \ TCP uses multiple different TCP subflows to steer the\n   traffic across the\
    \ different paths, load-balancers need to ensure\n   that all these subflows are\
    \ routed to the same server.  This implies\n   that the load-balancers need to\
    \ track the MPTCP-related state,\n   allowing them to parse the token in the MP_JOIN\
    \ and assign those\n   subflows to the appropriate server.  However, server farms\
    \ typically\n   deploy several load-balancers for reliability and capacity reasons.\n\
    \   As a TCP subflow might get routed to any of these load-balancers,\n   they\
    \ would need to synchronize the MPTCP-related state -- a solution\n   that is\
    \ not feasible on a large scale.\n   The token (carried in the MP_JOIN) contains\
    \ the information\n   indicating to which MPTCP-session the subflow belongs. \
    \ As the token\n   is a hash of the key, servers are not able to generate the\
    \ token in\n   such a way that the token can provide the necessary information\
    \ to\n   the load-balancers, which would allow them to route TCP subflows to\n\
    \   the appropriate server.  [MPTCP-LOAD] discusses this issue in detail\n   and\
    \ suggests two alternative MP_CAPABLE handshakes to overcome these.\n"
- title: 4.  Security Considerations
  contents:
  - "4.  Security Considerations\n   This informational document discusses use cases\
    \ and operational\n   experience with Multipath TCP.  An extensive analysis of\
    \ the\n   remaining security issues in the Multipath TCP specification has been\n\
    \   published in [RFC7430], together with suggestions for possible\n   solutions.\n\
    \   From a security viewpoint, it is important to note that Multipath\n   TCP,\
    \ like other multipath solutions such as SCTP, has the ability to\n   send packets\
    \ belonging to a single connection over different paths.\n   This design feature\
    \ of Multipath TCP implies that middleboxes that\n   have been deployed on-path\
    \ assuming that they would observe all the\n   packets exchanged for a given connection\
    \ in both directions may not\n   function correctly anymore.  A typical example\
    \ are firewalls,\n   Intrusion Detection System (IDS) or deep packet inspections\
    \ (DPIs)\n   deployed in enterprise networks.  Those devices expect to observe\
    \ all\n   the packets from all TCP connections.  With Multipath TCP, those\n \
    \  middleboxes may not observe anymore all packets since some of them\n   may\
    \ follow a different path.  The two examples below illustrate\n   typical deployments\
    \ of such middleboxes.  The first example,\n   Figure 8, shows an MPTCP-enabled\
    \ smartphone attached to both an\n   enterprise and a cellular network.  If a\
    \ Multipath TCP connection is\n   established by the smartphone towards a server,\
    \ some of the packets\n   sent by the smartphone or the server may be transmitted\
    \ over the\n   cellular network and thus be invisible for the enterprise middlebox.\n\
    \     smartphone +----- enterprise net --- MBox----+------ server\n          \
    \      |                                 |\n                +----- cellular net\
    \  -------------+\n              Figure 8: Enterprise Middlebox May Not Observe\n\
    \                     All Packets from Multihomed Host\n   The second example,\
    \ Figure 9, shows a possible issue when multiple\n   middleboxes are deployed\
    \ inside a network.  For simplicity, we assume\n   that network1 is the default\
    \ IPv4 path while network2 is the default\n   IPv6 path.  A similar issue could\
    \ occur with per-flow load-balancing\n   such as ECMP [RFC2992].  With regular\
    \ TCP, all packets from each\n   connection would either pass through Mbox1 or\
    \ Mbox2.  With Multipath\n   TCP, the client can easily establish a subflow over\
    \ network1 and\n   another over network2 and each middlebox would only observe\
    \ a part of\n   the traffic of the end-to-end Multipath TCP connection.\n    \
    \ client ----R-- network1  --- MBox1 -----R------------- server\n            \
    \    |                            |\n                +-- network2  --- MBox2 -----+\n\
    \                      Figure 9: Interactions between\n                  Load-Balancing\
    \ and Security Middleboxes\n   In these two cases, it is possible for an attacker\
    \ to evade some\n   security measures operating on the TCP byte stream and implemented\
    \ on\n   the middleboxes by controlling the bytes that are actually sent over\n\
    \   each subflow and there are tools that ease those kinds of evasion\n   [PZ15]\
    \ [PT14].  This is not a security issue for Multipath TCP itself\n   since Multipath\
    \ TCP behaves correctly.  However, this demonstrates\n   the difficulty of enforcing\
    \ security policies by relying only on\n   on-path middleboxes instead of enforcing\
    \ them directly on the\n   endpoints.\n"
- title: 5.  References
  contents:
  - '5.  References

    '
- title: 5.1.  Normative References
  contents:
  - "5.1.  Normative References\n   [RFC6182]  Ford, A., Raiciu, C., Handley, M.,\
    \ Barre, S., and J.\n              Iyengar, \"Architectural Guidelines for Multipath\
    \ TCP\n              Development\", RFC 6182, DOI 10.17487/RFC6182, March 2011,\n\
    \              <http://www.rfc-editor.org/info/rfc6182>.\n   [RFC6824]  Ford,\
    \ A., Raiciu, C., Handley, M., and O. Bonaventure,\n              \"TCP Extensions\
    \ for Multipath Operation with Multiple\n              Addresses\", RFC 6824,\
    \ DOI 10.17487/RFC6824, January 2013,\n              <http://www.rfc-editor.org/info/rfc6824>.\n"
- title: 5.2.  Informative References
  contents:
  - "5.2.  Informative References\n   [BALIA]    Peng, Q., Walid, A., Hwang, J., and\
    \ S. Low, \"Multipath\n              TCP: analysis, design, and implementation\"\
    , IEEE/ACM\n              Trans. on Networking (TON), Volume 24, Issue 1, February\n\
    \              2016.\n   [CACM14]   Paasch, C. and O. Bonaventure, \"Multipath\
    \ TCP\",\n              Communications of the ACM, 57(4):51-57, April 2014,\n\
    \              <http://inl.info.ucl.ac.be/publications/multipath-tcp>.\n   [Cellnet12]\n\
    \              Paasch, C., Detal, G., Duchene, F., Raiciu, C., and O.\n      \
    \        Bonaventure, \"Exploring Mobile/WiFi Handover with\n              Multipath\
    \ TCP\", ACM SIGCOMM workshop on Cellular\n              Networks (Cellnet12),\
    \ August 2012,\n              <http://inl.info.ucl.ac.be/publications/\n     \
    \         exploring-mobilewifi-handover-multipath-tcp>.\n   [COMCOM2016]\n   \
    \           Tran, V., De Coninck, Q., Hesmans, B., Sadre, R., and O.\n       \
    \       Bonaventure, \"Observing real Multipath TCP traffic\",\n             \
    \ Computer Communications, DOI 10.1016/j.comcom.2016.01.014,\n              April\
    \ 2016, <http://inl.info.ucl.ac.be/publications/\n              observing-real-multipath-tcp-traffic>.\n\
    \   [COMMAG2016]\n              De Coninck, Q., Baerts, M., Hesmans, B., and O.\n\
    \              Bonaventure, \"Observing Real Smartphone Applications over\n  \
    \            Multipath TCP\", IEEE Communications Magazine Network\n         \
    \     Testing Series, 54(3), March 2016,\n              <http://inl.info.ucl.ac.be/publications/observing-real-\n\
    \              smartphone-applications-over-multipath-tcp>.\n   [CONEXT12] Khalili,\
    \ R., Gast, N., Popovic, M., Upadhyay, U., and J.\n              Leboudec, \"\
    MPTCP is not Pareto-Optimal: Performance Issues\n              and a Possible\
    \ Solution\", CoNEXT '12: Proceedings of the\n              8th international\
    \ conference on Emerging networking\n              experiments and technologies,\
    \ DOI 10.1145/2413176.2413178,\n              December 2012.\n   [CONEXT13] Paasch,\
    \ C., Khalili, R., and O. Bonaventure, \"On the\n              Benefits of Applying\
    \ Experimental Design to Improve\n              Multipath TCP\", Conference on\
    \ emerging Networking\n              EXperiments and Technologies (CoNEXT),\n\
    \              DOI 10.1145/2535372.2535403, December 2013,\n              <http://inl.info.ucl.ac.be/publications/benefits-applying-\n\
    \              experimental-design-improve-multipath-tcp>.\n   [CONEXT15] Hesmans,\
    \ B., Detal, G., Barre, S., Bauduin, R., and O.\n              Bonaventure, \"\
    SMAPP: Towards Smart Multipath TCP-enabled\n              APPlications\", Proc.\
    \ Conext 2015, Heidelberg, Germany,\n              December 2015, <http://inl.info.ucl.ac.be/publications/\n\
    \              smapp-towards-smart-multipath-tcp-enabled-applications>.\n   [CSWS14]\
    \   Paasch, C., Ferlin, S., Alay, O., and O. Bonaventure,\n              \"Experimental\
    \ evaluation of multipath TCP schedulers\",\n              CSWS '14: Proceedings\
    \ of the 2014 ACM SIGCOMM workshop on\n              Capacity sharing workshop,\
    \ DOI 10.1145/2630088.2631977,\n              August 2014.\n   [DetalMSS] Detal,\
    \ G., \"dynamically adapt mss value\", Post on the\n              mptcp-dev mailing\
    \ list, September 2014,\n              <https://listes-2.sipr.ucl.ac.be/sympa/arc/mptcp-dev/\n\
    \              2014-09/msg00130.html>.\n   [FreeBSD-MPTCP]\n              Williams,\
    \ N., \"Multipath TCP For FreeBSD Kernel Patch\n              v0.5\", <http://caia.swin.edu.au/urp/newtcp/mptcp>.\n\
    \   [GRE-NOTIFY]\n              Leymann, N., Heidemann, C., Wasserman, M., Xue,\
    \ L., and M.\n              Zhang, \"GRE Notifications for Hybrid Access\", Work\
    \ in\n              Progress, draft-lhwxz-gre-notifications-hybrid-access-01,\n\
    \              January 2015.\n   [HAMPEL]   Hampel, G., Rana, A., and T. Klein,\
    \ \"Seamless TCP mobility\n              using lightweight MPTCP proxy\", MobiWac\
    \ '13: Proceedings\n              of the 11th ACM international symposium on Mobility\n\
    \              management and wireless access,\n              DOI 10.1145/2508222.2508226,\
    \ November 2013.\n   [HotMiddlebox13]\n              Hesmans, B., Duchene, F.,\
    \ Paasch, C., Detal, G., and O.\n              Bonaventure, \"Are TCP Extensions\
    \ Middlebox-proof?\", CoNEXT\n              workshop Hot Middlebox, December 2013,\n\
    \              <http://inl.info.ucl.ac.be/publications/\n              are-tcp-extensions-middlebox-proof>.\n\
    \   [HotMiddlebox13b]\n              Detal, G., Paasch, C., and O. Bonaventure,\
    \ \"Multipath in\n              the Middle(Box)\", HotMiddlebox '13, December\
    \ 2013,\n              <http://inl.info.ucl.ac.be/publications/\n            \
    \  multipath-middlebox>.\n   [HotNets]  Raiciu, C., Pluntke, C., Barre, S., Greenhalgh,\
    \ A.,\n              Wischik, D., and M. Handley, \"Data center networking with\n\
    \              multipath TCP\", Hotnetx-IX: Proceedings of the 9th ACM\n     \
    \         SIGCOMM Workshop on Hot Topics in Networks Article No. 10,\n       \
    \       DOI 10.1145/1868447.1868457, October 2010,\n              <http://doi.acm.org/10.1145/1868447.1868457>.\n\
    \   [HYA-ARCH] Leymann, N., Heidemann, C., Wasserman, M., Xue, L., and M.\n  \
    \            Zhang, \"Hybrid Access Network Architecture\", Work in\n        \
    \      Progress, draft-lhwxz-hybrid-access-network-\n              architecture-02,\
    \ January 2015.\n   [ICNP12]   Cao, Y., Xu, M., and X. Fu, \"Delay-based congestion\n\
    \              control for multipath TCP\", 20th IEEE International\n        \
    \      Conference on Network Protocols (INCP),\n              DOI 10.1109/ICNP.2012.6459978,\
    \ October 2012.\n   [IETF88]   Stewart, L., \"IETF 88 Meeting minutes of the MPTCP\
    \ working\n              group\", November 2013, <https://www.ietf.org/proceedings/\n\
    \              88/minutes/minutes-88-mptcp>.\n   [IETFJ]    Bonaventure, O. and\
    \ S. Seo, \"Multipath TCP Deployments\",\n              IETF Journal, Vol. 12,\
    \ Issue 2, November 2016.\n   [IMC11]    Honda, M., Nishida, Y., Raiciu, C., Greenhalgh,\
    \ A.,\n              Handley, M., and H. Tokuda, \"Is it still possible to\n \
    \             extend TCP?\", IMC '11: Proceedings of the 2011 ACM SIGCOMM\n  \
    \            conference on Internet measurement conference,\n              DOI\
    \ 10.1145/2068816.2068834, November 2011,\n              <http://doi.acm.org/10.1145/2068816.2068834>.\n\
    \   [IMC13a]   Detal, G., Hesmans, B., Bonaventure, O., Vanaubel, Y., and\n  \
    \            B. Donnet, \"Revealing Middlebox Interference with\n            \
    \  Tracebox\", Proceedings of the 2013 ACM SIGCOMM conference\n              on\
    \ Internet measurement conference,\n              DOI 10.1145/2504730.2504757,\
    \ October 2013,\n              <http://inl.info.ucl.ac.be/publications/\n    \
    \          revealing-middlebox-interference-tracebox>.\n   [IMC13b]   Chen, Y.,\
    \ Lim, Y., Gibbens, R., Nahum, E., Khalili, R.,\n              and D. Towsley,\
    \ \"A measurement-based study of MultiPath\n              TCP performance over\
    \ wireless network\", ICM '13:\n              Proceedings of the 2013 conference\
    \ on Internet\n              measurement conference, DOI 10.1145/2504730.2504751,\n\
    \              October 2013,\n              <http://doi.acm.org/10.1145/2504730.2504751>.\n\
    \   [IMC13c]   Pelsser, C., Cittadini, L., Vissicchio, S., and R. Bush,\n    \
    \          \"From Paris to Tokyo: on the suitability of ping to\n            \
    \  measure latency\", IMC '13: Proceedings of the 2013\n              conference\
    \ on Internet measurement Conference,\n              DOI 10.1145/2504730.2504765,\
    \ October 2013,\n              <http://doi.acm.org/10.1145/2504730.2504765>.\n\
    \   [INFOCOM14]\n              Lim, Y., Chen, Y., Nahum, E., Towsley, D., and\
    \ K. Lee,\n              \"Cross-layer path management in multi-path transport\n\
    \              protocol for mobile devices\", IEEE INFOCOM'14,\n             \
    \ DOI 10.1109/INFOCOM.2014.6848120, April 2014.\n   [KT]       Seo, S., \"KT's\
    \ GiGA LTE\", July 2015,\n              <https://www.ietf.org/proceedings/93/slides/\n\
    \              slides-93-mptcp-3.pdf>.\n   [MBTest]   Hesmans, B., \"MBTest\"\
    , October 2013,\n              <https://bitbucket.org/bhesmans/mbtest>.\n   [Mobicom15]\n\
    \              De Coninck, Q., Baerts, M., Hesmans, B., and O.\n             \
    \ Bonaventure, \"Poster - Evaluating Android Applications\n              with\
    \ Multipath TCP\", Mobicom 2015 (Poster),\n              DOI 10.1145/2789168.2795165,\
    \ September 2015.\n   [MPTCP-DEPLOY]\n              Paasch, C., Biswas, A., and\
    \ D. Haas, \"Making Multipath TCP\n              robust for stateless webservers\"\
    , Work in Progress,\n              draft-paasch-mptcp-syncookies-02, October 2015.\n\
    \   [MPTCP-LOAD]\n              Paasch, C., Greenway, G., and A. Ford, \"Multipath\
    \ TCP\n              behind Layer-4 loadbalancers\", Work in Progress,\n     \
    \         draft-paasch-mptcp-loadbalancer-00, September 2015.\n   [MPTCP-MAX-SUB]\n\
    \              Boucadair, M. and C. Jacquenet, \"Negotiating the Maximum\n   \
    \           Number of Multipath TCP (MPTCP) Subflows\", Work in\n            \
    \  Progress draft-boucadair-mptcp-max-subflow-02, May 2016.\n   [MPTCPBIB] Bonaventure,\
    \ O., \"Multipath TCP - Annotated bibliography\",\n              Technical report,\
    \ April 2015,\n              <https://github.com/obonaventure/mptcp-bib>.\n  \
    \ [MultipathTCP-Linux]\n              Paasch, C., Barre, S., and . et al, \"Multipath\
    \ TCP - Linux\n              Kernel implementation\", <http://www.multipath-tcp.org>.\n\
    \   [NSDI11]   Wischik, D., Raiciu, C., Greenhalgh, A., and M. Handley,\n    \
    \          \"Design, implementation and evaluation of congestion\n           \
    \   control for multipath TCP\", NSDI11: In Proceedings of the\n             \
    \ 8th USENIX conference on Networked systems design\n              and implementation,\
    \ 2011.\n   [NSDI12]   Raiciu, C., Paasch, C., Barre, S., Ford, A., Honda, M.,\n\
    \              Duchene, F., Bonaventure, O., and M. Handley, \"How Hard\n    \
    \          Can It Be? Designing and Implementing a Deployable\n              Multipath\
    \ TCP\", NSDI '12: USENIX Symposium of Networked\n              Systems Design\
    \ and implementation, April 2012,\n              <http://inl.info.ucl.ac.be/publications/how-hard-can-it-\n\
    \              be-designing-and-implementing-deployable-multipath-tcp>.\n   [PaaschPhD]\n\
    \              Paasch, C., \"Improving Multipath TCP\", Ph.D. Thesis ,\n     \
    \         November 2014, <http://inl.info.ucl.ac.be/publications/\n          \
    \    improving-multipath-tcp>.\n   [PAM2016]  De Coninck, Q., Baerts, M., Hesmans,\
    \ B., and O.\n              Bonaventure, \"A First Analysis of Multipath TCP on\n\
    \              Smartphones\", 17th International Passive and Active\n        \
    \      Measurements Conference (PAM2016) volume 17, March 2016,\n            \
    \  <http://inl.info.ucl.ac.be/publications/\n              first-analysis-multipath-tcp-smartphones>.\n\
    \   [PAMS2014] Arzani, B., Gurney, A., Cheng, S., Guerin, R., and B. Loo,\n  \
    \            \"Impact of Path Selection and Scheduling Policies on MPTCP\n   \
    \           Performance\", PAMS2014, DOI 10.1109/WAINA.2014.121, May\n       \
    \       2014.\n   [Presto08] Greenberg, A., Lahiri, P., Maltz, D., Patel, P.,\
    \ and S.\n              Sengupta, \"Towards a next generation data center\n  \
    \            architecture: scalability and commoditization\", ACM\n          \
    \    PRESTO 2008, DOI 10.1145/1397718.1397732, August 2008,\n              <http://dl.acm.org/citation.cfm?id=1397732>.\n\
    \   [PT14]     Pearce, C. and P. Thomas, \"Multipath TCP Breaking Today's\n  \
    \            Networks with Tomorrow's Protocols\", Proc.\n              Blackhat\
    \ Briefings, 2014, <http://www.blackhat.com/docs/\n              us-14/materials/us-14-Pearce-Multipath-TCP-Breaking-\n\
    \              Todays-Networks-With-Tomorrows-Protocols-WP.pdf>.\n   [PZ15]  \
    \   Pearce, C. and S. Zeadally, \"Ancillary Impacts of\n              Multipath\
    \ TCP on Current and Future Network Security\",\n              IEEE Internet Computing,\
    \ vol. 19, no. 5, pp. 58-65,\n              DOI 10.1109/MIC.2015.70, September\
    \ 2015.\n   [RFC1812]  Baker, F., Ed., \"Requirements for IP Version 4 Routers\"\
    ,\n              RFC 1812, DOI 10.17487/RFC1812, June 1995,\n              <http://www.rfc-editor.org/info/rfc1812>.\n\
    \   [RFC1928]  Leech, M., Ganis, M., Lee, Y., Kuris, R., Koblas, D., and\n   \
    \           L. Jones, \"SOCKS Protocol Version 5\", RFC 1928,\n              DOI\
    \ 10.17487/RFC1928, March 1996,\n              <http://www.rfc-editor.org/info/rfc1928>.\n\
    \   [RFC2992]  Hopps, C., \"Analysis of an Equal-Cost Multi-Path\n           \
    \   Algorithm\", RFC 2992, DOI 10.17487/RFC2992, November 2000,\n            \
    \  <http://www.rfc-editor.org/info/rfc2992>.\n   [RFC4987]  Eddy, W., \"TCP SYN\
    \ Flooding Attacks and Common\n              Mitigations\", RFC 4987, DOI 10.17487/RFC4987,\
    \ August 2007,\n              <http://www.rfc-editor.org/info/rfc4987>.\n   [RFC6356]\
    \  Raiciu, C., Handley, M., and D. Wischik, \"Coupled\n              Congestion\
    \ Control for Multipath Transport Protocols\",\n              RFC 6356, DOI 10.17487/RFC6356,\
    \ October 2011,\n              <http://www.rfc-editor.org/info/rfc6356>.\n   [RFC7430]\
    \  Bagnulo, M., Paasch, C., Gont, F., Bonaventure, O., and C.\n              Raiciu,\
    \ \"Analysis of Residual Threats and Possible Fixes\n              for Multipath\
    \ TCP (MPTCP)\", RFC 7430,\n              DOI 10.17487/RFC7430, July 2015,\n \
    \             <http://www.rfc-editor.org/info/rfc7430>.\n   [RFC7871]  Contavalli,\
    \ C., van der Gaast, W., Lawrence, D., and W.\n              Kumari, \"Client\
    \ Subnet in DNS Queries\", RFC 7871,\n              DOI 10.17487/RFC7871, May\
    \ 2016,\n              <http://www.rfc-editor.org/info/rfc7871>.\n   [SIGCOMM11]\n\
    \              Raiciu, C., Barre, S., Pluntke, C., Greenhalgh, A.,\n         \
    \     Wischik, D., and M. Handley, \"Improving datacenter\n              performance\
    \ and robustness with multipath TCP\", SIGCOMM\n              '11: Proceedings\
    \ of the ACM SIGCOMM 2011 conference,\n              DOI 10.1145/2018436.2018467,\
    \ August 2011,\n              <http://doi.acm.org/10.1145/2018436.2018467>.\n\
    \   [SOCKET]   Hesmans, B. and O. Bonaventure, \"An enhanced socket API\n    \
    \          for Multipath TCP\", Proceedings of the 2016 Applied\n            \
    \  Networking Research Workshop, DOI 10.1145/2959424.2959433,\n              July\
    \ 2016, <http://doi.acm.org/10.1145/2959424.2959433>.\n   [StrangeMbox]\n    \
    \          Bonaventure, O., \"Multipath TCP through a strange\n              middlebox\"\
    , Blog post, January 2015,\n              <http://blog.multipath-tcp.org/blog/html/2015/01/30/\n\
    \              multipath_tcp_through_a_strange_middlebox.html>.\n   [TMA2015]\
    \  Hesmans, B., Tran Viet, H., Sadre, R., and O. Bonaventure,\n              \"\
    A First Look at Real Multipath TCP Traffic\", Traffic\n              Monitoring\
    \ and Analysis, 2015,\n              <http://inl.info.ucl.ac.be/publications/\n\
    \              first-look-real-multipath-tcp-traffic>.\n   [TR-348]   Broadband\
    \ Forum, ., \"TR 348 - Hybrid Access Broadband\n              Network Architecture\"\
    , Issue: 1, July 2016,\n              <https://www.broadband-forum.org/technical/download/\n\
    \              TR-348.pdf>.\n   [tracebox] Detal, G. and O. Tilmans, \"Tracebox:\
    \ A Middlebox Detection\n              Tool\", 2013, <http://www.tracebox.org>.\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   This work was partially supported by the FP7-Trilogy2 project.\
    \  We\n   would like to thank all the implementers and users of the Multipath\n\
    \   TCP implementation in the Linux kernel.  This document has benefited\n   from\
    \ the comments of John Ronan, Yoshifumi Nishida, Phil Eardley,\n   Jaehyun Hwang,\
    \ Mirja Kuehlewind, Benoit Claise, Jari Arkko, Qin Wu,\n   Spencer Dawkins, and\
    \ Ben Campbell.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Olivier Bonaventure\n   UCLouvain\n   Email: Olivier.Bonaventure@uclouvain.be\n\
    \   Christoph Paasch\n   Apple, Inc.\n   Email: cpaasch@apple.com\n   Gregory\
    \ Detal\n   Tessares\n   Email: Gregory.Detal@tessares.net\n"
