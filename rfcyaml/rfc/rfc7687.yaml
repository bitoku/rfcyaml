- title: __initial_text__
  contents:
  - ''
- title: Internet Architecture Board (IAB)                             S. Farrell
  contents:
  - "Internet Architecture Board (IAB)                             S. Farrell\n  \
    \    Report from the Strengthening the Internet (STRINT) Workshop\n"
- title: Abstract
  contents:
  - "Abstract\n   The Strengthening the Internet (STRINT) workshop assembled one\n\
    \   hundred participants in London for two days in early 2014 to discuss\n   how\
    \ the technical community, and in particular the IETF and the W3C,\n   should\
    \ react to Pervasive Monitoring and more generally how to\n   strengthen the Internet\
    \ in the face of such attacks.  The discussions\n   covered issues of terminology,\
    \ the role of user interfaces, classes\n   of mitigation, some specific use cases,\
    \ transition strategies\n   (including opportunistic encryption), and more.  The\
    \ workshop ended\n   with a few high-level recommendations, that it is believed\
    \ could be\n   implemented and could help strengthen the Internet.  This is the\n\
    \   report of that workshop.\n   Note that this document is a report on the proceedings\
    \ of the\n   workshop.  The views and positions documented in this report are\n\
    \   those of the workshop participants and do not necessarily reflect IAB\n  \
    \ views and positions.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This document is a product\
    \ of the Internet Architecture Board (IAB)\n   and represents information that\
    \ the IAB has deemed valuable to\n   provide for permanent record.  Documents\
    \ approved for publication by\n   the IAB are not a candidate for any level of\
    \ Internet Standard; see\n   Section 2 of RFC 5741.\n   Information about the\
    \ current status of this document, any errata,\n   and how to provide feedback\
    \ on it may be obtained at\n   http://www.rfc-editor.org/info/rfc7687.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2015 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1.  Context . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .   2\n   2.  Summary . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . .   3\n   3.  Workshop Goals  . . . . . . . . . . . . . . . . . . . .\
    \ . . .   4\n   4.  Workshop Structure  . . . . . . . . . . . . . . . . . . .\
    \ . .   5\n   5.  Topics  . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ .   6\n   6.  After the Workshop  . . . . . . . . . . . . . . . . . . . . .\
    \  20\n   7.  Security Considerations . . . . . . . . . . . . . . . . . . .  21\n\
    \   8.  Informative References  . . . . . . . . . . . . . . . . . . .  21\n  \
    \ Appendix A.  Logistics  . . . . . . . . . . . . . . . . . . . . .  25\n   Appendix\
    \ B.  Agenda . . . . . . . . . . . . . . . . . . . . . . .  26\n   Appendix C.\
    \  Workshop Chairs and Program Committee  . . . . . . .  29\n   Appendix D.  Participants\
    \ . . . . . . . . . . . . . . . . . . . .  29\n   Authors' Addresses  . . . .\
    \ . . . . . . . . . . . . . . . . . . .  32\n"
- title: 1.  Context
  contents:
  - "1.  Context\n   The technical plenary session at IETF 88 [vancouverplenary] concluded\n\
    \   that Pervasive Monitoring (PM) represents an attack on the Internet,\n   and\
    \ the IETF has begun to carry out the more obvious actions required\n   to try\
    \ to handle this attack.  However, there are much more complex\n   questions arising\
    \ that need further consideration before any\n   additional concrete plans can\
    \ be made.\n   The W3C (<https://www.w3.org>) and IAB (<https://www.iab.org>)\n\
    \   therefore decided to host a workshop on the topic of \"Strengthening\n   the\
    \ Internet Against Pervasive Monitoring\" [STRINT] before IETF 89 in\n   London\
    \ in March 2014.  The FP7-funded STREWS project\n   (<https://www.strews.eu/>)\
    \ organised the STRINT workshop on behalf of\n   the IAB and W3C.\n   The main\
    \ workshop goal was to discuss what can be done, especially by\n   the two standards\
    \ organisations IETF and W3C, against PM, both for\n   existing Internet protocols\
    \ (HTTP/1, SMTP, etc.) and for new ones\n   (WebRTC, HTTP/2, etc.).\n   The starting\
    \ point for the workshop was the existing IETF consensus\n   that PM is an attack\
    \ [RFC7258] (the text of which had achieved IETF\n   consensus at the time of\
    \ the workshop, even though the RFC had yet to\n   be published).\n"
- title: 2.  Summary
  contents:
  - "2.  Summary\n   The workshop was well attended (registration closed when the\
    \ maximum\n   capacity of 100 was reached, but more than 150 expressed a desire\
    \ to\n   register) and several people (about 165 at the maximum) listened to\n\
    \   the streaming audio.  The submitted papers (67 in total) were\n   generally\
    \ of good quality and all were published, except for a few\n   where authors who\
    \ couldn't take part in the workshop preferred not to\n   publish.\n   The chairs\
    \ of the workshop summarised the workshop in the final\n   session in the form\
    \ of the following recommendations:\n   1.   Well-implemented cryptography can\
    \ be effective against PM and\n        will benefit the Internet if used more,\
    \ despite its cost, which\n        is steadily decreasing anyway.\n   2.   Traffic\
    \ analysis also needs to be considered, but is less well\n        understood in\
    \ the Internet community: relevant research and\n        protocol mitigations\
    \ such as data minimisation need to be better\n        understood.\n   3.   Work\
    \ should continue on progressing the PM threat model document\n        [Barnes]\
    \ discussed in the workshop.  Subsequent work on this\n        topic resulted\
    \ in the publication of [RFC7624].\n   4.   Later, the IETF may be in a position\
    \ to start to develop an\n        update to BCP 72 [RFC3552], most likely as a\
    \ new RFC enhancing\n        that BCP and dealing with recommendations on how\
    \ to mitigate PM\n        and how to reflect that in IETF work.\n   5.   The term\
    \ \"opportunistic\" has been widely used to refer to a\n        possible mitigation\
    \ strategy for PM.  The community needs to\n        document definition(s) for\
    \ this term, as it is being used\n        differently by different people and\
    \ in different contexts.  We\n        may also be able to develop a cookbook-like\
    \ set of related\n        protocol techniques for developers.  Since the workshop,\
    \ the\n        IETF's Security area has taken up this work, most recently\n  \
    \      favouring the generic term \"Opportunistic Security\" (OS) [Kent].\n  \
    \      Subsequent work on this topic resulted in the publication of a\n      \
    \  definition of OS in [RFC7435].\n   6.   The technical community could do better\
    \ in explaining the real\n        technical downsides related to PM in terms that\
    \ policy makers\n        can understand.\n   7.   Many user interfaces (UIs) could\
    \ be better in terms of how they\n        present security state, though this\
    \ is a significantly hard\n        problem.  There may be benefits if certain\
    \ dangerous choices\n        were simply not offered anymore.  But that could\
    \ require\n        significant coordination among competing software makers;\n\
    \        otherwise, some will be considered \"broken\" by users.\n   8.   Further\
    \ discussion is needed on ways to better integrate UI\n        issues into the\
    \ processes of IETF and W3C.\n   9.   Examples of good software configurations\
    \ that can be cut-and-\n        pasted for popular software, etc., can help. \
    \ This is not\n        necessarily standards work, but maybe the standards\n \
    \       organisations can help and can work with those developing such\n     \
    \   package-specific documentation.\n   10.  The IETF and W3C can do more so that\
    \ default (\"out-of-the-box\")\n        settings for protocols better protect\
    \ security and privacy.\n   11.  Captive portals [Captive] and some firewalls,\
    \ too, can and\n        should be distinguished from real man-in-the-middle attacks.\n\
    \        This might mean establishing common conventions with makers of\n    \
    \    such middleboxes, but might also mean developing new protocols.\n       \
    \ However, the incentives for deploying such new middlebox\n        features might\
    \ not align.\n"
- title: 3.  Workshop Goals
  contents:
  - "3.  Workshop Goals\n   As stated, the STRINT workshop started from the position\
    \ [RFC7258]\n   that PM is an attack.  While some dissenting voices are expected\
    \ and\n   need to be heard, that was the baseline assumption for the workshop,\n\
    \   and the high-level goal was to provide more consideration of that and\n  \
    \ how it ought to affect future work within the IETF and W3C.\n   At the next\
    \ level down, the goals of the STRINT workshop were to:\n   o  Discuss and hopefully\
    \ come to agreement among the participants on\n      concepts in PM for both threats\
    \ and mitigation, e.g.,\n      \"opportunistic\" as the term applies to cryptography.\n\
    \   o  Discuss the PM threat model, and how that might be usefully\n      documented\
    \ for the IETF at least, e.g., via an update to BCP 72.\n      [RFC3552]\n   o\
    \  Discuss and progress common understanding in the trade-offs\n      between\
    \ mitigating and suffering PM.\n   o  Identify weak links in the chain of Web\
    \ security architecture with\n      respect to PM.\n   o  Identify potential work\
    \ items for the IETF, IAB, IRTF, and W3C\n      that would help mitigate PM.\n\
    \   o  Discuss the kinds of action outside the IETF/W3C context that\n      might\
    \ help those done within the IETF/W3C.\n"
- title: 4.  Workshop Structure
  contents:
  - "4.  Workshop Structure\n   The workshop structure was designed to maximise discussion\
    \ time.\n   There were no direct presentations of submitted papers.  Instead,\
    \ the\n   moderators of each session summarised topics that the Technical\n  \
    \ Programme Committee (TPC) had agreed based on the submitted papers.\n   These\
    \ summary presentations took at most 50% of the session and\n   usually less.\n\
    \   Because the papers would not be presented during the workshop,\n   participants\
    \ were asked to read and discuss the papers beforehand, at\n   least those relevant\
    \ to their fields of interest.  (To help people\n   choose papers to read, authors\
    \ were asked to provide short\n   abstracts.)\n   Most of the sessions had two\
    \ moderators, one to lead the discussion,\n   while the other managed the queue\
    \ of people who wanted to speak.\n   This worked well: everybody got a chance\
    \ to speak and each session\n   still ended on time.\n   The penultimate session\
    \ consisted of break-outs (which turned out to\n   be the most productive sessions\
    \ of all, most likely simply due to the\n   smaller numbers of people involved).\
    \  The subjects for the break-outs\n   were agreed during the earlier sessions,\
    \ and just before the break-\n   out session the participants collectively determined\
    \ who would attend\n   which.\n"
- title: 5.  Topics
  contents:
  - "5.  Topics\n   The following sections contain summaries of the various sessions.\n\
    \   See the minutes (see Appendix B) for more details.\n"
- title: 5.1.  Opening session
  contents:
  - "5.1.  Opening session\n   The first session discussed the goals of the workshop.\
    \  Possible\n   approaches to improving security in the light of pervasive monitoring\n\
    \   include a critical look at what metadata is actually required,\n   whether\
    \ old (less secure) devices can be replaced with new ones, what\n   are \"low-hanging\
    \ fruit\" (issues that can be handled quickly and\n   easily), and what level\
    \ of security is \"good enough\": a good solution\n   may be one that is good\
    \ for 90% of people or 90% of organisations.\n   Some participants felt that standards\
    \ are needed so that people can\n   see if their systems conform to a certain\
    \ level of security, and easy\n   to remember names are needed for those standards,\
    \ so that a buyer can\n   immediately see that a product \"conforms to the named\
    \ intended\n   standard.\"\n"
- title: 5.2.  Threats
  contents:
  - "5.2.  Threats\n   One difference between \"traditional\" attacks and pervasive\
    \ monitoring\n   is modus operandi of the attacker: typically, one determines\
    \ what\n   resources an attacker might want to target and at what cost and then\n\
    \   one defends against that threat.  But a pervasive attacker has no\n   specific\
    \ targets, other than to collect everything he can.  The\n   calculation of the\
    \ cost of losing resources vs. the cost of\n   protecting them is thus different.\
    \  And unlike someone motivated to\n   make money, a PM attacker may not be concerned\
    \ at the cost of the\n   attack (or may even prefer a higher cost, for \"empire\
    \ building\"\n   reasons).\n   The terminology used to talk about threats has\
    \ to be chosen carefully\n   (this was a common theme in several sessions), because\
    \ we need to\n   explain to people outside the technical community what they need\
    \ to\n   do or not do.  For example, authentication of endpoints doesn't so\n\
    \   much \"protect against\" man-in-the-middle (MITM) attacks as make them\n \
    \  visible.  The attacker can still mount an attack but does not remain\n   invisible\
    \ while he does so.  Somebody on either end of the\n   conversation needs to react\
    \ to the alert from the system: stop the\n   conversation or find a different\
    \ channel.\n   Paradoxically, while larger sites such as Facebook, Yahoo, and\
    \ Google\n   supervise the security of their respective services more than other\n\
    \   smaller sites, such large sites offer a much more attractive target\n   to\
    \ attack.  Avoiding overuse of such repositories for private or\n   sensitive\
    \ information may be a useful measure that increases the cost\n   of collecting\
    \ for a pervasive attacker.  This is sometimes called the\n   target-dispersal\
    \ approach.\n   Lack of interoperability between systems can lead to poorly thought\n\
    \   out work-arounds and compromises that may themselves introduce\n   vulnerabilities.\
    \  Thus, improving interoperability needs to be high\n   on the list of priorities\
    \ of standards makers and even more for\n   implementers.  Of course, testing\
    \ (such as interop testing) is, at\n   some level, part of the process of the\
    \ IETF and W3C; and the W3C is\n   currently increasing its testing efforts.\n"
- title: 5.3.  Increase Usage of Security Tools
  contents:
  - "5.3.  Increase Usage of Security Tools\n   The first session on Communication\
    \ Security (COMSEC) tools looked at\n   the question why existing security tools\
    \ aren't used more.\n   The example of the public key infrastructure used to secure\
    \ HTTP is\n   informative.  One problem is that certification authorities (CAs)\
    \ may\n   issue a certificate for any domain.  Thus, a single compromised CA\n\
    \   can be used in combination with a MITM to impersonate any server.\n   Moreover,\
    \ ongoing administration, including requesting, paying for,\n   and installing\
    \ new certificates, has proven over time to be an\n   insurmountable barrier for\
    \ many web site administrators, leading them\n   not to bother to secure their\
    \ systems.\n   Some ideas were discussed for improving the CA system, e.g., via\n\
    \   cross-certification of CAs and by means of \"certificate transparency\"\n\
    \   -- a public, permanent log of who issued which certificate [RFC6962].\n  \
    \ Using other models than the hierarchical certificate model (as\n   alternative\
    \ or in combination) may also help.  Pretty Good Privacy\n   (PGP) demonstrates\
    \ a model known as a \"web of trust\" where people\n   verify the public key of\
    \ the people they meet.  Because there is no\n   innate transitive trust in PGP,\
    \ it is appropriate only for small-\n   scale uses; an example is a team of people\
    \ working on a project.\n   Yet another model is \"trust on first use\" (TOFU).\
    \  This is used quite\n   effectively by SSH [RFC4252].  On the first connection,\
    \ one has no\n   way to verify that the received public key belongs to the server\
    \ one\n   is contacting, therefore, the key is accepted without further\n   verification.\
    \  But on the subsequent connections, one can verify that\n   the received key\
    \ is the same key as the first time.  So, a MITM has\n   to be there on all connections,\
    \ including the first; otherwise, it\n   will be detected by a key mismatch.\n\
    \   This works well for SSH, because people typically use SSH to\n   communicate\
    \ with a small number of servers over and over again.  And,\n   if they want,\
    \ they may find a separate channel to get the public key\n   (or its fingerprint).\
    \  It may also work for web servers used by small\n   groups (the server of a\
    \ sports club, a department of a company,\n   etc.), but probably works less well\
    \ for public servers that are\n   visited once or a few times or for large services\
    \ where many servers\n   may be used.\n   A similar proposal [RFC7469] for an\
    \ HTTP header introduces an aspect\n   of TOFU into HTTP: Key pinning tells HTTP\
    \ clients that for a certain\n   time after receiving this certificate, they should\
    \ not expect the\n   certificate to change.  If it does, even if the new certificate\
    \ looks\n   valid, the client should assume a security breach.\n   The Session\
    \ Initiation Protocol (SIP) [RFC3261] can require several\n   different intermediaries\
    \ in different stages of the communication to\n   deal with NAT traversal and\
    \ to handle policy.  While both hop-by-hop\n   and end-to-end encryption are specified,\
    \ in practice, many SIP\n   providers disable these functions.  The reasons for\
    \ disabling end-to-\n   end security here are understandable: to overcome lack\
    \ of\n   interoperability they often need to change protocol headers and\n   modify\
    \ protocol data.  Some workshop participants argued that SIP\n   would never have\
    \ taken off if it hadn't been possible for providers\n   to monitor and interfere\
    \ in communications in this way.  Of course,\n   that means an attacker can listen\
    \ in just as easily.\n   A new protocol for peer-to-peer communication of video\
    \ and audio (and\n   potentially other data) is WebRTC.  WebRTC reuses many of\
    \ the same\n   architectural concepts as SIP, but there is a reasonable chance\
    \ that\n   it can do better in terms of protecting users: The people\n   implementing\
    \ the protocols and offering the service have different\n   goals and interests.\
    \  In particular, the first implementers are\n   browser makers, who may have\
    \ different business models from other\n   more traditional Voice over IP providers.\n\
    \   XMPP [RFC6120] suffers from yet a different kind of problem.  It has\n   encryption\
    \ and authentication, and the OTR (\"off the record\")\n   extension even provides\
    \ what is called Perfect Forward Secrecy (PFS),\n   i.e., compromising the current\
    \ communication never gives an attacker\n   enough information to decrypt past\
    \ communications that he may have\n   recorded.  But, in practice, many people\
    \ don't use XMPP at all, but\n   rather Skype, WhatsApp, or other instant-messaging\
    \ tools with unknown\n   or no security.  The problem here seems to be one of\
    \ user awareness.\n   And though OTR does provide security, it is not well integrated\
    \ with\n   XMPP, nor is it available as a core feature of XMPP clients.\n   To\
    \ increase usage of existing solutions, some tasks can be\n   identified; though\
    \ how those map to actions for, e.g., IETF/W3C is\n   not clear:\n   o  Improvements\
    \ to the certificate system, such as certificate\n      transparency (CT).\n \
    \  o  Making it easier (cheaper, quicker) for system administrators to\n     \
    \ deploy secure solutions.\n   o  Improve awareness of the risks.  Identify which\
    \ communities\n      influence which decisions and what is the appropriate message\
    \ for\n      each.\n   o  Provide an upgrade path that doesn't break existing\
    \ systems or\n      require that everybody upgrade at the same time.  Opportunistic\n\
    \      Security may be one model for that.\n"
- title: 5.4.  Policy Issues and Non-technical Actions
  contents:
  - "5.4.  Policy Issues and Non-technical Actions\n   Previous sessions already concluded\
    \ that the problem isn't just\n   technical, such as getting the right algorithms\
    \ in the standards,\n   fixing interoperability, or educating implementers and\
    \ systems\n   administrators.  There are user interface issues and education issues\n\
    \   too.  And there are also legal issues and policy issues for\n   governments.\n\
    \   It appears that the public, in general, demands more privacy and\n   security\
    \ (e.g., for their children) but are also pessimistic about\n   getting that.\
    \  They trust that somebody assures that nothing bad\n   happens to them, but\
    \ they also expect to be spied on all the time.\n   (Perceived) threats of terrorism\
    \ gave governments a reason to allow\n   widespread surveillance, far beyond what\
    \ may previously have been\n   considered dangerous for freedom.\n   In this environment,\
    \ the technical community will have a hard time\n   developing and deploying technologies\
    \ that fully counter PM, which\n   means there has to be action in the social\
    \ and political spheres,\n   too.\n   Technology isn't the only thing that can\
    \ make life harder for\n   attackers.  Government-sponsored PM is indirectly affected\
    \ by trade\n   agreements and treaties, and thus it makes sense to lobby for those\n\
    \   to be as privacy-friendly as possible.\n   Court cases on the grounds of human\
    \ rights can also influence policy,\n   especially if they reach, for example,\
    \ the European Court of Human\n   Rights.\n   In medicine and law, it is common\
    \ to have ethics committees, not so\n   in software.  Should standards bodies\
    \ such as the IETF and W3C have\n   an ethics committee?  Standards such as the\
    \ Geolocation API\n   [w3c-geo-api] have gotten scrutiny from privacy experts,\
    \ but only in\n   an ad hoc manner.  (W3C has permanent groups to review standards\
    \ for\n   accessibility and internationalisation.  It also has a Privacy group,\n\
    \   but that currently doesn't do the same kind of systematic reviews.)\n   As\
    \ the Internet-Draft draft-barnes-pervasive-problem-00 [Barnes]\n   (which was\
    \ included as paper 44) explains, PM doesn't just monitor\n   the networks, but\
    \ also attacks at the endpoints, turning\n   organisations or people into (willing,\
    \ unwilling, or unwitting)\n   collaborators.  Note: that document later evolved\
    \ into [RFC7624].\n   One technical means of protection is thus to design protocols\
    \ such\n   that there are fewer potential collaborators, e.g., a provider of\n\
    \   cloud storage cannot hand over plaintext for content that is\n   encrypted\
    \ with a key he doesn't have, and cannot hand over names if\n   his client is\
    \ anonymous.\n   It is important to distinguish between PM and fighting crime.\
    \  PM is\n   an attack, but a judge ordering the surveillance of a suspected\n\
    \   criminal is not.  The latter, often abbreviated in this context as LI\n  \
    \ (for Lawful Intercept) is outside the scope of this workshop.\n"
- title: 5.5.  Improving the Tools
  contents:
  - "5.5.  Improving the Tools\n   An earlier session discussed why existing COMSEC\
    \ tools weren't used\n   more.  This second session on COMSEC therefore discussed\
    \ what\n   improvements and/or new tools were needed.\n   Discussion at the workshop\
    \ indicated that an important meta-tool for\n   improving existing security technology\
    \ could be Opportunistic\n   Security (OS) [Kent].  The idea is that software\
    \ is enhanced with a\n   module that tries to encrypt communications when it detects\
    \ that the\n   other end also has the same capability, but otherwise it lets the\n\
    \   communication continue in the old way.  The detailed definition of OS\n  \
    \ was being discussed by the IETF Security Area Advisory Group at the\n   time\
    \ of this workshop [SAAG_list].\n   OS would protect against a passive eavesdropper\
    \ but should also allow\n   for endpoint authentication to protect against an\
    \ active attacker (a\n   MITM).  As OS spreads, more and more communications would\
    \ be\n   encrypted (and hopefully authenticated), and thus there is less and\n\
    \   less for an eavesdropper to collect.\n   Of course, an implementation of OS\
    \ could give a false sense of\n   security as well: some connections are encrypted,\
    \ some are not.  A\n   user might see something like a padlock icon in browsers,\
    \ but there\n   was agreement at the workshop that such user interface features\
    \ ought\n   not be changed because OS is being used.\n   There is also the possibility\
    \ that a MITM intercepts the reply from a\n   server that says \"yes, I can do\
    \ encryption\" and removes it, causing\n   the client to fall back to an unencrypted\
    \ protocol.  Mitigations\n   against this can be to have other channels of finding\
    \ out a server's\n   capabilities and remembering that a server could do encryption\n\
    \   previously.\n   There is also, again, a terminology problem.  The technical\n\
    \   descriptions of OS talk about \"silent fail\" when a connection\n   couldn't\
    \ be encrypted and has to fall back to the old, unencrypted\n   protocol.  Actually,\
    \ it's not a fail; it's no worse than it was\n   before.  A successful encryption\
    \ would rather be a \"silent\n   improvement.\"\n   That raises the question of\
    \ the UI: How do you explain to a user what\n   their security options are, and,\
    \ in case an error occurs, how do you\n   explain the implications of the various\
    \ responses?\n   The people working on encryption are mathematicians and engineers,\n\
    \   and typically not the same people who know about UI.  We need to\n   involve\
    \ the experts.  We also need to distinguish between usability\n   of the UI, user\
    \ understanding, and user experience.  For an\n   e-commerce site, e.g., it is\
    \ not just important that the user's data\n   is technically safe, but also that\
    \ he feels secure.  Otherwise, he\n   still won't buy anything.\n   When talking\
    \ about users, we also need to distinguish the end user\n   (who we typically\
    \ think about when we talk about UI) from the server\n   administrators and other\
    \ technical people involved in enabling a\n   connection.  When something goes\
    \ wrong (e.g., the user's software\n   detects an invalid certificate), the message\
    \ usually goes to the end\n   user.  But, he isn't necessarily the person who\
    \ can do something\n   about it.  For example, if the problem is a certificate\
    \ that expired\n   yesterday, the options for the user are to break the connection\
    \ (the\n   safe choice, but it means he can't get his work done) or continue\n\
    \   anyway (there could be a MITM).  The server administrator, on the\n   other\
    \ hand, could actually solve the problem.\n   Encryption and authentication have\
    \ a cost, in terms of setting them\n   up, but also in terms of the time it takes\
    \ for software to do the\n   calculations.  The setup cost can be reduced with\
    \ sensible defaults,\n   predefined profiles, and cut-and-paste configurations.\
    \  And for some\n   connections, authentication without encryption could be enough,\
    \ in\n   the case that the data doesn't need to be kept secret, but it is\n  \
    \ important to know that it is the real data.  Most mail user agents\n   (UA)\
    \ already provide independent options for encryption and signing,\n   but web\
    \ servers only support authentication if the connection is also\n   encrypted.\n\
    \   On the other hand, as email also shows, it is difficult for users to\n   understand\
    \ what encryption and authentication do separately.\n   It also has to be kept\
    \ in mind that encrypting only the \"sensitive\"\n   data and not the rest decreases\
    \ the cost for an attacker, too: It\n   becomes easy to know which connections\
    \ are worth attacking.\n   Selective field confidentiality is also more prone\
    \ to lead to\n   developer error, as not all developers will know the provenance\
    \ of\n   values to be processed.\n   One problem with the TOFU model as used by\
    \ SSH (see explanation\n   above) is that it lacks a solution for key continuity:\
    \ When a key is\n   changed (which can happen, e.g., when a server is replaced\
    \ or the\n   software upgraded), there is no way to inform the client.  (In\n\
    \   practice, people use other means, such as calling people on the phone\n  \
    \ or asking their colleagues in the office, but that doesn't scale and\n   doesn't\
    \ always happen either.)  An improvement in the SSH protocol\n   could thus be\
    \ a way to transfer a new key to a client in a safe way.\n"
- title: 5.6.  Hiding Metadata
  contents:
  - "5.6.  Hiding Metadata\n   Encryption and authentication help protect the content\
    \ of messages.\n   Correctly implemented encryption is very hard to crack.  (To\
    \ get the\n   content, an attacker would rather attempt to steal the keys, corrupt\n\
    \   the encoding software, or get the content via a collaborator.  See\n   [RFC7624]\
    \ for more information on \"collaborator\".)  But encrypting\n   the content doesn't\
    \ hide the fact that you are communicating.  This\n   metadata (who talks to whom,\
    \ when, and for how long) is often as\n   interesting as the content itself, and\
    \ in some cases the size and\n   timing of messages is even an accurate predictor\
    \ of the content.  So\n   how to stop an attacker from collecting metadata, given\
    \ that much of\n   that data is actually needed by routers and other services\
    \ to deliver\n   the message to the right place?\n   It is useful to distinguish\
    \ different kinds of metadata: explicit (or\n   metadata proper) and implicit\
    \ (sometimes called traffic data).\n   Implicit metadata is things that can be\
    \ derived from a message or are\n   necessary for its delivery, such as the destination\
    \ address, the\n   size, the time, or the frequency with which messages pass.\
    \  Explicit\n   metadata is things like quality ratings, provenance, or copyright\n\
    \   data: data about the data, useful for an application, but not\n   required\
    \ to deliver the data to its endpoint.\n   A system such as Tor hides much of\
    \ the metadata by passing through\n   several servers, encrypting all the data\
    \ except that which a\n   particular server needs to see.  Each server thus knows\
    \ which server\n   a message came from and where it has to send it to, but cannot\
    \ know\n   where the previous server got it from or where the next server is\n\
    \   instructed to send it.  However, deliberately passing through\n   multiple\
    \ servers makes the communication slower than taking the most\n   direct route\
    \ and increases the amount of traffic the network as a\n   whole has to process.\n\
    \   There are three kinds of measures that can be taken to make metadata\n   harder\
    \ to get: aggregation, contraflow, and multipath (see \"Flows and\n   Pervasive\
    \ Monitoring\" [Paper4]).  New protocols should be designed\n   such that these\
    \ measures are not inadvertently disallowed, e.g.,\n   because the design assumes\
    \ that the whole of a conversation passes\n   through the same route.\n   \"Aggregation\"\
    \ means collecting conversations from multiple sources\n   into one stream.  For\
    \ example, if HTTP connections pass through a\n   proxy, all the conversations\
    \ appear to come from the proxy instead of\n   from their original sources.  (This\
    \ assumes that telltale information\n   in the headers is stripped by the proxy\
    \ or that the connection is\n   encrypted.)  It also works in the other direction:\
    \ if multiple web\n   sites are hosted on the same server, an attacker cannot\
    \ see which of\n   those web sites a user is reading.  (This assumes that the\
    \ name of\n   the site is in the path info of the URL and not in the domain name;\n\
    \   otherwise, watching DNS queries can still reveal the name.)\n   \"Contraflow\"\
    \ means routing a conversation via one or more other\n   servers than the normal\
    \ route, e.g., by using a tunnel (e.g., with\n   SSH or a VPN) to another server.\
    \  Tor is an example of this.  An\n   attacker must watch more routes and do more\
    \ effort to correlate\n   conversations.  (Again, this assumes that there is no\
    \ telltale\n   information left in the messages that leave the tunnel.)\n   \"\
    Multipath\" splits up a single conversation (or a set of related\n   conversations)\
    \ and routes the parts in different ways, e.g., sending\n   a request via a satellite\
    \ link and receiving the response via a land\n   line, or starting a conversation\
    \ on a cellular link and continuing it\n   via Wi-Fi.  This again increases the\
    \ cost for an attacker, who has to\n   monitor and correlate data traversing multiple\
    \ networks.\n   Protecting metadata automatically with technology at a lower layer\n\
    \   than the application layer is difficult.  The applications themselves\n  \
    \ need to pass less data, e.g., use anonymous temporary handles instead\n   of\
    \ permanent identifiers.  There is often no real need for people to\n   use the\
    \ same identifier on different computers (smartphone, desktop,\n   etc.) other\
    \ than that the application they use was designed that way.\n   One thing that\
    \ can be done relatively easily in the short term is to\n   go through existing\
    \ protocols to check what data they send that isn't\n   really necessary.  One\
    \ candidate mentioned for such a study was XMPP.\n   \"Fingerprinting\" is the\
    \ process of distinguishing different senders\n   of messages based on metadata\
    \ [RFC6973]: Clients can be recognised\n   (or at least grouped) because their\
    \ messages always have a\n   combination of features that other clients' messages\
    \ do not have.\n   Reducing redundant metadata and reducing the number of optional\n\
    \   features in a protocol reduces the variation between clients and thus\n  \
    \ makes fingerprinting harder.\n   Traffic analysis is a research discipline that\
    \ produces sometimes\n   surprising findings that are little known among protocol\
    \ developers.\n   Some collections of results are\n   o  a selected bibliography\
    \ on anonymity by the Free Haven Project\n      <http://freehaven.net/anonbib/>,\n\
    \   o  the yearly Symposium on Privacy Enhancing Technologies (PETS)\n      <http://www.informatik.uni-trier.de/~Ley/db/conf/pet/index.html>,\n\
    \      and\n   o  the yearly Workshop on Privacy in the Electronic Society (WPES)\n\
    \      <http://www.informatik.uni-trier.de/~Ley/db/conf/wpes/index.html>.\n  \
    \ Techniques that deliberately change the timing or size of messages,\n   such\
    \ as padding, can also help reduce traffic analysis.  Obviously,\n   they make\
    \ conversations slower and/or use more bandwidth, but in some\n   cases that is\
    \ not an issue, e.g., if the conversation is limited by\n   the speed of a human\
    \ user anyway.  HTTP/2, for example, has a built-\n   in padding mechanism.  However,\
    \ it is not easy to use these\n   techniques well and make messages harder to\
    \ recognise (as intended)\n   rather than easier.\n   Different users in different\
    \ contexts may have different security\n   needs, so maybe the priority can be\
    \ a user choice (if that can be\n   done without making high-security users stand\
    \ out from other users).\n   Although many people would not understand what their\
    \ choices are,\n   some do, such as political activists or journalists.\n"
- title: 5.7.  Deployment, Intermediaries, and Middleboxes
  contents:
  - "5.7.  Deployment, Intermediaries, and Middleboxes\n   Secure protocols have often\
    \ been designed in the past for end-to-end\n   security: Intermediaries cannot\
    \ read or modify the messages.  This is\n   the model behind TLS, for example.\n\
    \   In practice, however, people have more or less valid reasons to\n   insist\
    \ on intermediaries: companies filtering incoming and outgoing\n   traffic for\
    \ viruses, inspecting content to give priority to certain\n   applications, or\
    \ caching content to reduce bandwidth.\n   In the presence of end-to-end encryption\
    \ and authentication, these\n   intermediaries have two choices: use fake certificates\
    \ to impersonate\n   the endpoints or have access to the private keys of the endpoints.\n\
    \   The former is a MITM attack that is difficult to distinguish from a\n   more\
    \ malicious one, and the latter obviously decreases the security\n   of the endpoints\
    \ by copying supposedly confidential information and\n   concentrating credentials\
    \ in a single place.\n   As mentioned in Section 5.2 above, aggregation of data\
    \ in a single\n   place makes that place an attractive target.  And in the case\
    \ of PM,\n   even if the data is not concentrated physically in one place, it\
    \ is\n   under control of a single legal entity that can be made into a\n   collaborator.\n\
    \   The way Web communication with TLS typically works is that the client\n  \
    \ authenticates the server, but the server does not authenticate the\n   client\
    \ at the TLS layer.  (If the user needs to be identified, that\n   is mainly done\
    \ at the application layer via username and password.)\n   Thus, the presence\
    \ of a MITM (middlebox) could be detected by the\n   client (because of the incorrect\
    \ certificate), but not by the server.\n   If the client doesn't immediately close\
    \ the connection (which they do\n   not in many cases), the server may thus disclose\
    \ information that the\n   user would rather not have disclosed.\n   One widespread\
    \ example of middleboxes is captive portals, as found on\n   the Wi-Fi hotspots\
    \ in hotels, airports, etc.  Even the hotspots\n   offering free access often\
    \ intercept communications to redirect the\n   user to a login or policy page.\n\
    \   When the communication they intercept is, e.g., the automatic update\n   of\
    \ your calendar program or a chat session, the redirect obviously\n   doesn't\
    \ work: these applications don't know how to display a web\n   page.  With the\
    \ increasing use of applications, it may be a while\n   before the user actually\
    \ opens a browser.  The flood of error\n   messages may also have as a result\
    \ that the user no longer reads the\n   errors, allowing an actual malicious attack\
    \ to go unnoticed.\n   Some operating systems now come with heuristics that try\
    \ to recognise\n   captive portals and either automatically login or show their\
    \ login\n   page in a separate application.  (But, some hotspot providers\n  \
    \ apparently don't want automatic logins and actually reverse-\n   engineered\
    \ the heuristics to try and fool them.)\n   It seems some protocol is missing\
    \ in this case.  Captive portals\n   shouldn't have to do MITM attacks to be noticed.\
    \  A mechanism at the\n   link layer or an extension to DHCP that tells a connecting\
    \ device\n   about the login page may help, although that still doesn't solve\
    \ the\n   problem for devices that do not have a web browser, such as voice\n\
    \   over IP phones.  HTTP response code 511 (defined in [RFC6585]) is\n   another\
    \ attempt at a partial solution.  (It's partial because it can\n   only work at\
    \ the moment the user uses a browser to connect to a web\n   site and doesn't\
    \ use HTTPS.)\n   A practical problem with deployment of such a protocol may be\
    \ that\n   many such captive portals are very old and never updated.  The hotel\n\
    \   staff only knows how to reboot the system, and, as long as it works,\n   the\
    \ hotel has no incentive to buy a new one.  As evidence of this:\n   how many\
    \ such systems require you to get a password and the ticket\n   shows the price\
    \ as zero?  This is typically because the owner doesn't\n   know how to reconfigure\
    \ the hotspot, but he does know how to change\n   the price in his cash register.\n"
- title: 5.8.  Break-out 1 - Research
  contents:
  - "5.8.  Break-out 1 - Research\n   Despite some requests earlier in the workshop,\
    \ the research break-out\n   did not discuss clean-slate approaches.  The challenge\
    \ was rather\n   that the relationship between security research and standardisation\n\
    \   needs improvement.  Research on linkability is not yet well known in\n   the\
    \ IETF.  But, the other side of the coin needs improvement too:\n   While doing\
    \ protocol design, standardisation organisations should\n   indicate what specific\
    \ problems are in need of more research.\n   The break-out then made a nonexhaustive\
    \ list of topics that are in\n   need of further research:\n   o  The interaction\
    \ of compression and encryption as demonstrated by\n      the CRIME (\"Compression\
    \ Ratio Info-leak Made Easy\") SSL/TLS\n      vulnerability [Ristic]\n   o  A\
    \ more proactive deprecation of algorithms based on research\n      results\n\
    \   o  Mitigation for return-oriented programming attacks\n   o  How to better\
    \ obfuscate so-called \"metadata\"\n   o  How to make the existence of traffic\
    \ and their endpoints stealthy\n"
- title: 5.9.  Break-out 2 - Clients
  contents:
  - "5.9.  Break-out 2 - Clients\n   Browsers are the first clients one thinks of\
    \ when talking about\n   encrypted connections, authentication, and certificates,\
    \ but there\n   are many others.\n   Other common cases of \"false\" alarms for\
    \ MITM (after captive portals)\n   include expired and misconfigured certificates.\
    \  This is quite common\n   in intranets, when the sysadmin hasn't bothered updating\
    \ a\n   certificate and rather tells his handful of users to just \"click\n  \
    \ continue.\"  The problem is on the one hand that users may not\n   understand\
    \ the difference between this case and the same error\n   message when they connect\
    \ to a server outside the company, and on the\n   other hand that the incorrect\
    \ certificate installed by the sysadmin\n   is not easily distinguishable from\
    \ an incorrect certificate from a\n   MITM.  The error message is almost the same,\
    \ and the user may just\n   click continue again.\n   One way to get rid of such\
    \ certificates is if client software no\n   longer offers the option to continue\
    \ after a certificate error.  That\n   requires that all major clients (such as\
    \ browsers) change their\n   behaviour at the same time; otherwise, the first\
    \ one to do so will be\n   considered broken by users, because the others still\
    \ work.  Also, it\n   requires a period in which that software gives increasingly\
    \ strong\n   warnings about the cut-off date after which the connection will fail\n\
    \   with this certificate.\n   Yet another source of error messages is self-signed\
    \ certificates.\n   Such certificates are actually only errors for sites that\
    \ are not\n   expected to have them.  If a message about a self-signed certificate\n\
    \   appears when connecting to Facebook or Google, you're clearly not\n   connected\
    \ to the real Facebook or Google.  But, for a personal web\n   site, it shouldn't\
    \ cause such scary warnings.  There may be ways to\n   improve the explanations\
    \ in the error message and provide an easy way\n   to verify the certificate (by\
    \ email, phone, or some other channel)\n   and trust it.\n"
- title: 5.10.  Break-out 3 - On by Default
  contents:
  - "5.10.  Break-out 3 - On by Default\n   One step in improving security is to require\
    \ the relevant features\n   (in particular, encryption and authentication) to\
    \ be implemented in\n   compliant products: The features are labelled as \"MUST\"\
    \ in the\n   standard rather than \"MAY\".  This is sometimes referred to as\n\
    \   Mandatory To Implement (MTI) and is the current practice for IETF\n   protocols\
    \ [RFC3365].\n   But, that may not be enough to counter PM.  It may be that the\n\
    \   features are there, but not used, because only very knowledgeable\n   users\
    \ or sysadmins turn them on.  Or, it may be that implementations\n   do not actually\
    \ follow the MTI parts of specifications.  Or, it may\n   be that some security\
    \ features are implemented, but interoperability\n   for those doesn't really\
    \ work.  Or, even worse, it may be that\n   protocol designers have only followed\
    \ the letter of the MTI best\n   practice and not its spirit, with the result\
    \ that security features\n   are hard to use or make deployment harder.  One can\
    \ thus argue that\n   such features should be defined to be on by default.\n \
    \  Going further, one might argue that these features should not even be\n   options,\
    \ i.e., there should be no way to turn them off.  This is\n   sometimes called\
    \ Mandatory To Use (MTU).\n   The questions raised at this session were for what\
    \ protocols is on-\n   by-default appropriate, and how can one explain to the\
    \ developers of\n   such protocols that it is needed?\n   Of course, there would\
    \ be resistance to MTU security from\n   implementers and deployments that practice\
    \ deep packet inspection\n   (DPI) and also perhaps from some governments.  On\
    \ the other hand,\n   there may also be governments that outlaw protocols without\
    \ proper\n   encryption.\n   This break-out concluded that there could be value\
    \ in attempting to\n   document a new Best Current Practice for the IETF that\
    \ moves from the\n   current MTI position to one where security features are on\
    \ by\n   default.  Some of the workshop participants expressed interest in\n \
    \  authoring a draft for such a new BCP and progressing it through the\n   IETF\
    \ consensus process (where it would no doubt be controversial).\n"
- title: 5.11.  Break-out 4 - Measurement
  contents:
  - "5.11.  Break-out 4 - Measurement\n   There was a small break-out on the idea\
    \ of measurement as a way to\n   encourage or gamify the increased use of security\
    \ mechanisms.\n"
- title: 5.12.  Break-out 5 - Opportunistic
  contents:
  - "5.12.  Break-out 5 - Opportunistic\n   This break-out considered the use of the\
    \ term \"opportunistic\" as it\n   applies to cryptographic security and attempted\
    \ to progress the work\n   towards arriving at an agreed-upon definition for use\
    \ of that term,\n   at it applies to IETF and W3C work.\n   While various terms\
    \ had been used, with many people talking about\n   opportunistic encryption,\
    \ that usage was felt to be problematic both\n   because it conflicted with the\
    \ use of the same term in [RFC4322] and\n   because it was being used differently\
    \ in different parts of the\n   community.\n   At the session, it was felt that\
    \ the term \"opportunistic keying\" was\n   better, but, as explained above, subsequent\
    \ list discussion resulted\n   in a move to the term \"Opportunistic Security\"\
    \ (OS).\n   Aside from terminology, discussion focused on the use of Diffie-\n\
    \   Hellman (D-H) key exchange as the preferred mechanism of OS, with\n   fall\
    \ back to cleartext if D-H doesn't succeed as a counter for\n   passive attacks.\n\
    \   There was also, of course, the desire to be able to easily escalate\n   from\
    \ countering passive attacks to also handling endpoint\n   authentication and\
    \ thereby also countering MITM attacks.\n   Making OS visible to users was again\
    \ considered to be undesirable, as\n   users could not be expected to distinguish\
    \ between cleartext, OS, and\n   (one-sided or mutual) endpoint authentication.\n\
    \   Finally, it was noted that it may take some effort to establish how\n   middleboxes\
    \ might affect OS at different layers and that OS really is\n   not suitable as\
    \ the only mitigation to use for high-sensitivity\n   sessions such as financial\
    \ transactions.\n"
- title: 5.13.  Unofficial Transport/Routing Break-out
  contents:
  - "5.13.  Unofficial Transport/Routing Break-out\n   Some routing and transport\
    \ Area Directors felt a little left out by\n   all the application-layer break-outs,\
    \ so they had their own\n   brainstorm about what could be done at the transport\
    \ and routing\n   layers from which these notes resulted.\n   The LEDBAT [RFC6817]\
    \ protocol was targeted towards a bulk-transfer\n   service that is reordering-\
    \ and delay-insensitive.  Use of LEDBAT\n   could offer the following benefits\
    \ for an application:\n   a.  Because it is reordering-insensitive, traffic can\
    \ be sprayed\n       across a large number of forwarding paths.  Assuming such\n\
    \       different paths exist, this would make it more challenging to\n      \
    \ capture and analyze a full interaction.\n   b.  The application can vary the\
    \ paths by indicating per packet a\n       different flow.  In IPv6, this can\
    \ be done via different IPv6\n       flow labels.  For IPv4, this can be done\
    \ by encapsulating the IP\n       packet into UDP and varying the UDP source port.\n\
    \   c.  Since LEDBAT is delay-insensitive and applications using it would\n  \
    \     need to be as well, it would be possible to obfuscate the\n       application\
    \ signatures by varying the packet lengths and\n       frequency.\n   d.  This\
    \ can also hide the transport header (for IP in UDP).\n   e.  If the Reverse Path\
    \ Forwarding (RPF) [RFC3704] check problem can\n       be fixed, perhaps the source\
    \ could be hidden; however, such fixes\n       assume the traffic is within trusted\
    \ perimeters.\n   f.  The use of LEDBAT is orthogonal to the use of encryption\
    \ and\n       provides different benefits (harder to intercept the whole\n   \
    \    conversation, ability to obfuscate the traffic analysis), and it\n      \
    \ has different costs (longer latency, new transport protocol\n       usage) to\
    \ its users.\n   The idea of encrypting traffic from Customer Edge (CE) to CE\
    \ as part\n   of an L3VPN or such was also discussed.  This could allow hiding\
    \ of\n   addresses, including source, and headers.  From conversation with Ron\n\
    \   Bonica, it's clear that some customers already do encryption (though\n   without\
    \ hiding the source address).  So, rather than an enhancement,\n   this is an\
    \ existing mechanism for which deployment and use can be\n   encouraged.\n   Finally,\
    \ it was discussed whether it would be useful to have a means\n   of communicating\
    \ where and what layers are doing encryption on an\n   application's traffic path.\
    \  The initial idea of augmenting ICMP has\n   some issues (not visible to application,\
    \ ICMP packets frequently\n   filtered) as well as potential work (determining\
    \ how to trust the\n   report of encryption).  It would be interesting to understand\
    \ if such\n   communication is actually needed and what the requirements would\
    \ be.\n"
- title: 6.  After the Workshop
  contents:
  - "6.  After the Workshop\n   Holding the workshop just before the IETF had the\
    \ intended effect: a\n   number of people went to both the workshop and the IETF,\
    \ and they\n   took the opportunity of being together at the IETF to continue\
    \ the\n   discussions.\n   IETF working groups meeting in London took the recommendations\
    \ from\n   the workshop into account.  It was even the first item in the report\n\
    \   about the IETF meeting by the IETF chair, Jari Arkko:\n      Strengthening\
    \ the security and privacy of the Internet continued\n      to draw a lot of attention.\
    \  The STRINT workshop organised by the\n      IAB and W3C just before the IETF\
    \ attracted 100 participants and\n      over 60 papers.  Even more people would\
    \ have joined us, but there\n      was no space.  During the IETF meeting, we\
    \ continued discussing\n      the topic at various working groups.  A while ago\
    \ we created the\n      first working group specifically aimed at addressing some\
    \ of the\n      issues surrounding pervasive monitoring.  The Using TLS for\n\
    \      Applications (UTA) working group had its first meeting in London.\n   \
    \   But many other working groups also address these issues in their\n      own\
    \ work.  The TCPM working group discussed a proposal to add\n      opportunistic\
    \ keying mechanisms directly onto the TCP protocol.\n      And the DNSE BOF considered\
    \ the possibility of adding\n      confidentiality support to DNS queries.  Finally,\
    \ there is an\n      ongoing effort to review old specifications to search for\
    \ areas\n      that might benefit from taking privacy and data minimisation\n\
    \      better into account.  [Arkko1]\n   Two papers that were written for the\
    \ workshop, but not finished in\n   time, are worth mentioning, too: One by the\
    \ same Jari Arkko, titled\n   \"Privacy and Networking Functions\" [Arkko2]; and\
    \ one by Johan\n   Pouwelse, \"The Shadow Internet: liberation from Surveillance,\n\
    \   Censorship and Servers\" [Pouwelse].\n"
- title: 7.  Security Considerations
  contents:
  - "7.  Security Considerations\n   This document is all about security and privacy.\n"
- title: 8.  Informative References
  contents:
  - "8.  Informative References\n   [Arkko1]   Arkko, J., \"IETF-89 Summary\", March\
    \ 2014,\n              <http://www.ietf.org/blog/2014/03/ietf-89-summary/>.\n\
    \   [Arkko2]   Arkko, J., \"Privacy and Networking Functions\", March 2014,\n\
    \              <http://www.arkko.com/ietf/strint/\n              draft-arkko-strint-networking-functions.txt>.\n\
    \   [Barnes]   Barnes, R., Schneier, B., Jennings, C., and T. Hardie,\n      \
    \        \"Pervasive Attack: A Threat Model and Problem Statement\",\n       \
    \       Work in Progress, draft-barnes-pervasive-problem-00,\n              January\
    \ 2014.\n   [Captive]  Wikipedia, \"Captive portal\", October 2015,\n        \
    \      <https://en.wikipedia.org/w/\n              index.php?title=Captive_portal&oldid=685621201>.\n\
    \   [Kent]     Kent, S., \"Opportunistic Security as a Countermeasure to\n   \
    \           Pervasive Monitoring\", Work in Progress, draft-kent-\n          \
    \    opportunistic-security-01, April 2014.\n   [Paper4]   Hardie, T., \"Flows\
    \ and Pervasive Monitoring\",\n              STRINT Workshop, 2014,\n        \
    \      <https://www.w3.org/2014/strint/papers/4.pdf>.\n   [Pouwelse] Pouwelse,\
    \ J., \"The Shadow Internet: liberation from\n              Surveillance, Censorship\
    \ and Servers\", Work in Progress,\n              draft-pouwelse-perpass-shadow-internet-00,\
    \ February 2014.\n   [RFC3261]  Rosenberg, J., Schulzrinne, H., Camarillo, G.,\
    \ Johnston,\n              A., Peterson, J., Sparks, R., Handley, M., and E.\n\
    \              Schooler, \"SIP: Session Initiation Protocol\", RFC 3261,\n   \
    \           DOI 10.17487/RFC3261, June 2002,\n              <http://www.rfc-editor.org/info/rfc3261>.\n\
    \   [RFC3365]  Schiller, J., \"Strong Security Requirements for Internet\n   \
    \           Engineering Task Force Standard Protocols\", BCP 61,\n           \
    \   RFC 3365, DOI 10.17487/RFC3365, August 2002,\n              <http://www.rfc-editor.org/info/rfc3365>.\n\
    \   [RFC3552]  Rescorla, E. and B. Korver, \"Guidelines for Writing RFC\n    \
    \          Text on Security Considerations\", BCP 72, RFC 3552,\n            \
    \  DOI 10.17487/RFC3552, July 2003,\n              <http://www.rfc-editor.org/info/rfc3552>.\n\
    \   [RFC3704]  Baker, F. and P. Savola, \"Ingress Filtering for Multihomed\n \
    \             Networks\", BCP 84, RFC 3704, DOI 10.17487/RFC3704, March\n    \
    \          2004, <http://www.rfc-editor.org/info/rfc3704>.\n   [RFC4252]  Ylonen,\
    \ T. and C. Lonvick, Ed., \"The Secure Shell (SSH)\n              Authentication\
    \ Protocol\", RFC 4252, DOI 10.17487/RFC4252,\n              January 2006, <http://www.rfc-editor.org/info/rfc4252>.\n\
    \   [RFC4322]  Richardson, M. and D. Redelmeier, \"Opportunistic\n           \
    \   Encryption using the Internet Key Exchange (IKE)\",\n              RFC 4322,\
    \ DOI 10.17487/RFC4322, December 2005,\n              <http://www.rfc-editor.org/info/rfc4322>.\n\
    \   [RFC6120]  Saint-Andre, P., \"Extensible Messaging and Presence\n        \
    \      Protocol (XMPP): Core\", RFC 6120, DOI 10.17487/RFC6120,\n            \
    \  March 2011, <http://www.rfc-editor.org/info/rfc6120>.\n   [RFC6585]  Nottingham,\
    \ M. and R. Fielding, \"Additional HTTP Status\n              Codes\", RFC 6585,\
    \ DOI 10.17487/RFC6585, April 2012,\n              <http://www.rfc-editor.org/info/rfc6585>.\n\
    \   [RFC6817]  Shalunov, S., Hazel, G., Iyengar, J., and M. Kuehlewind,\n    \
    \          \"Low Extra Delay Background Transport (LEDBAT)\", RFC 6817,\n    \
    \          DOI 10.17487/RFC6817, December 2012,\n              <http://www.rfc-editor.org/info/rfc6817>.\n\
    \   [RFC6962]  Laurie, B., Langley, A., and E. Kasper, \"Certificate\n       \
    \       Transparency\", RFC 6962, DOI 10.17487/RFC6962, June 2013,\n         \
    \     <http://www.rfc-editor.org/info/rfc6962>.\n   [RFC6973]  Cooper, A., Tschofenig,\
    \ H., Aboba, B., Peterson, J.,\n              Morris, J., Hansen, M., and R. Smith,\
    \ \"Privacy\n              Considerations for Internet Protocols\", RFC 6973,\n\
    \              DOI 10.17487/RFC6973, July 2013,\n              <http://www.rfc-editor.org/info/rfc6973>.\n\
    \   [RFC7258]  Farrell, S. and H. Tschofenig, \"Pervasive Monitoring Is an\n \
    \             Attack\", BCP 188, RFC 7258, DOI 10.17487/RFC7258, May\n       \
    \       2014, <http://www.rfc-editor.org/info/rfc7258>.\n   [RFC7435]  Dukhovni,\
    \ V., \"Opportunistic Security: Some Protection\n              Most of the Time\"\
    , RFC 7435, DOI 10.17487/RFC7435,\n              December 2014, <http://www.rfc-editor.org/info/rfc7435>.\n\
    \   [RFC7469]  Evans, C., Palmer, C., and R. Sleevi, \"Public Key Pinning\n  \
    \            Extension for HTTP\", RFC 7469, DOI 10.17487/RFC7469, April\n   \
    \           2015, <http://www.rfc-editor.org/info/rfc7469>.\n   [RFC7624]  Barnes,\
    \ R., Schneier, B., Jennings, C., Hardie, T.,\n              Trammell, B., Huitema,\
    \ C., and D. Borkmann,\n              \"Confidentiality in the Face of Pervasive\
    \ Surveillance: A\n              Threat Model and Problem Statement\", RFC 7624,\n\
    \              DOI 10.17487/RFC7624, August 2015,\n              <http://www.rfc-editor.org/info/rfc7624>.\n\
    \   [Ristic]   Ristic, I., \"CRIME: Information Leakage Attack against\n     \
    \         SSL/TLS\", Qualys Blog,\n              <https://community.qualys.com/blogs/securitylabs/2012/\n\
    \              09/14/crime-information-leakage-attack-against-ssltls>.\n   [SAAG_list]\n\
    \              IETF, \"saag Discussion Archive\", <https://www.ietf.org/\n   \
    \           mail-archive/web/saag/current/maillist.html>.\n   [STRINT]   W3C/IAB,\
    \ \"STRINT Workshop\",\n              <https://www.w3.org/2014/strint/Overview.html>.\n\
    \   [vancouverplenary]\n              IETF, \"IETF 88 Technical Plenary Minutes\"\
    ,\n              <https://www.ietf.org/proceedings/88/minutes/\n             \
    \ minutes-88-iab-techplenary>.\n   [w3c-geo-api]\n              Popescu, A., \"\
    Geolocation API Specification\",\n              W3C Recommendation, October 2013,\n\
    \              <http://www.w3.org/TR/geolocation-API/>.\n"
- title: Appendix A.  Logistics
  contents:
  - "Appendix A.  Logistics\n   The workshop was organised by the STREWS project\n\
    \   (<https://www.strews.eu/>), which is a research project funded under\n   the\
    \ European Union's 7th Framework Programme\n   (<http://cordis.europa.eu/fp7/ict/>).\
    \  It was the first of two\n   workshops in its work plan.  The organisers were\
    \ supported by the IAB\n   and W3C, and, for the local organisation, by Telefonica\
    \ Digital\n   (<http://blog.digital.telefonica.com/>).\n   One of the suggestions\
    \ in the project description of the STREWS\n   project was to attach the first\
    \ workshop to an IETF meeting.  The\n   best opportunity was IETF 89 in London,\
    \ which began on Sunday 2 March\n   2014; see <https://www.ietf.org/meeting/89/>\
    \ for more information.\n   Telefonica Digital offered meeting rooms at its offices\
    \ in central\n   London for the preceding Friday and Saturday, just minutes away\
    \ from\n   the IETF's location.\n   The room held 100 people, which was thought\
    \ to be sufficient.  There\n   turned out to be more interest than expected and\
    \ we could have filled\n   a larger room, but 100 people is probably an upper\
    \ limit for good\n   discussions anyway.\n   Apart from the usual equipment in\
    \ the room (projector, white boards,\n   microphones, coffee), we also set up\
    \ some extra communication\n   channels:\n   o  A mailing list where participants\
    \ could discuss the agenda and the\n      published papers about three weeks in\
    \ advance of the workshop\n      itself.\n   o  Publicly advertised streaming\
    \ audio (one-way only).  At some\n      point, no less than 165 people were listening.\n\
    \   o  An IRC channel for live minute-taking, passing links and other\n      information,\
    \ and helping remote participants to follow the\n      proceedings.\n   o  An\
    \ Etherpad, where the authors of papers could provide an abstract\n      of their\
    \ submissions, to help participants who could not read all\n      66 papers in\
    \ full in advance of the workshop.  The abstracts were\n      also used on the\
    \ workshop's web site:\n      <https://www.w3.org/2014/strint/>.\n   o  A Twitter\
    \ hashtag (#strint).  Four weeks after the workshop, there\n      were still a\
    \ few new messages about events related to workshop\n      topics; see <https://twitter.com/search?q=%23strint>.\n"
- title: Appendix B.  Agenda
  contents:
  - "Appendix B.  Agenda\n   This was the final agenda of the workshop, as determined\
    \ by the TPC\n   and participants on the mailing list prior to the workshop. \
    \ The\n   included links are to the slides that the moderators used to\n   introduce\
    \ each discussion topic and to the minutes.\n"
- title: B.1.  Friday 28 February
  contents:
  - "B.1.  Friday 28 February\n   Minutes: <http://www.w3.org/2014/02/28-strint-minutes.html>\n\
    \   Workshop starts, welcome, logistics, opening/overview\n   Slides: <https://down.dsg.cs.tcd.ie/strint-slides/s0-welcome.pdf>\n\
    \   o  Goal is to plan how we respond to PM threats\n   o  Specific questions\
    \ to be discussed in sessions\n   o  Outcomes are actions for IETF, W3C, IRTF,\
    \ etc.\n   I.     Threats - What problem are we trying to solve?\n          (Presenter:\
    \ Richard Barnes; Moderator: Cullen Jennings)\n          Slides:\n          <https://down.dsg.cs.tcd.ie/strint-slides/s1-threat.pdf>\n\
    \          *  What attacks have been described?  (Attack taxonomy)\n         \
    \ *  What should we assume the attackers' capabilities are?\n          *  When\
    \ is it really \"pervasive monitoring\" and when is it\n             not?\n  \
    \        *  Scoping - what's in and what's out? (for IETF/W3C)\n   II.    COMSEC\
    \ 1 - How can we increase usage of current COMSEC tools?\n          (Presenter:\
    \ Hannes Tschofenig; Moderator: Leif Johansson)\n          Slides:\n         \
    \ <https://down.dsg.cs.tcd.ie/strint-slides/s2-comsec.pdf>\n          *  Whirlwind\
    \ catalog of current tools\n          *  Why aren't people using them?  In what\
    \ situations are /\n             aren't they used?\n          *  Securing AAA\
    \ and management protocols - why not?\n          *  How can we (IETF/W3C/community)\
    \ encourage more/better use?\n   III.   Policy - What policy/legal/other issues\
    \ need to be taken into\n          account?  (Presenter: Christine Runnegar; Moderator:\
    \ Rigo\n          Wenning)\n          Slides:\n          <https://down.dsg.cs.tcd.ie/strint-slides/s3-policy.pdf>\n\
    \          *  What non-technical activities do we need to be aware of?\n     \
    \     *  How might such non-technical activities impact on IETF/W3C?\n       \
    \   *  How might IETF/W3C activities impact those non-technical\n            \
    \ activities?\n   Saturday plan, open mic, wrap-up of the day\n"
- title: B.2.  Saturday 1 March
  contents:
  - "B.2.  Saturday 1 March\n   Minutes: <http://www.w3.org/2014/03/01-strint-minutes.html>\n\
    \   IV.  COMSEC 2 - What improvements to COMSEC tools are needed?\n        (Presenter:\
    \ Mark Nottingham; Moderator: Steve Bellovin)\n        Slides:\n        <https://down.dsg.cs.tcd.ie/strint-slides/s4-opportunistic.pdf>\n\
    \        *  Opportunistic encryption - what is it and where it might\n       \
    \    apply\n        *  Mitigations aiming to block PM vs. detect PM - when to\
    \ try\n           which?\n   V.   Metadata - How can we reduce the metadata that\
    \ protocols expose?\n        (Presenters: Alfredo Pironti, Ted Hardie; Moderator:\
    \ Alissa\n        Cooper)\n     Slides:\n     <https://down.dsg.cs.tcd.ie/strint-slides/s5-1metadata-pironti.pdf>\n\
    \     <https://down.dsg.cs.tcd.ie/strint-slides/s5-2metadata-hardie.pdf>\n   \
    \  <https://down.dsg.cs.tcd.ie/strint-slides/s5-3metadata-cooper.pdf>\n      \
    \  *  Metadata, fingerprinting, minimisation\n        *  What's out there?\n \
    \       *  How can we do better?\n   VI.  Deployment - How can we address PM in\
    \ deployment / operations?\n        (Presenter: Eliot Lear; Moderator: Barry Leiba)\n\
    \        Slides: <https://down.dsg.cs.tcd.ie/strint-slides/s6-deploy.pdf>\n  \
    \      *  \"Mega\"-commercial services (clouds, large-scale email and\n      \
    \     Online Social Networks, SIP, WebRTC)\n        *  Target dispersal - good\
    \ goal or wishful thinking?\n        *  Middleboxes: when a help and when a hindrance?\n\
    \   VII. Break-out Sessions (x 3) / Bar-Camp style (Hannes Tschofenig)\n     \
    \   *  Content to be defined during meeting, as topics come up\n        *  Sum\
    \ up at the end to gather conclusions for report\n        Break-outs:\n      \
    \  1.  Research Questions (Moderator: Kenny Paterson)\n            +  Do we need\
    \ more/different crypto tools?\n            +  How can applications make better\
    \ use of COMSEC tools?\n            +  What research topics could be handled in\
    \ IRTF?\n            +  What other research would help?\n        2.  Clients\n\
    \        3.  On by default\n        4.  Measurement\n        5.  Opportunistic\n\
    \   VIII. Break-out Reports, Open Mic & Conclusions - What are we going\n    \
    \     to do to address PM?\n         Slides: <https://www.w3.org/2014/strint/slides/summary.pdf>\n\
    \         *  Gather conclusions / recommendations / goals from earlier\n     \
    \       sessions\n"
- title: Appendix C.  Workshop Chairs and Program Committee
  contents:
  - "Appendix C.  Workshop Chairs and Program Committee\n   The workshop chairs were\
    \ three: Stephen Farrell (TCD) and Rigo\n   Wenning (W3C) from the STREWS project,\
    \ and Hannes Tschofenig (ARM)\n   from the STREWS Interest Group.\n   The Technical\
    \ Programme Committee (TPC) was charged with evaluating\n   the submitted papers.\
    \  It was made up of the members of the STREWS\n   project, the members of the\
    \ STREWS Interest Group, plus invited\n   experts: Bernard Aboba (Microsoft),\
    \ Dan Appelquist (Telefonica & W3C\n   TAG), Richard Barnes (Mozilla), Bert Bos\
    \ (W3C), Lieven Desmet (KU\n   Leuven), Karen O'Donoghue (ISOC), Russ Housley\
    \ (Vigil Security),\n   Martin Johns (SAP), Ben Laurie (Google), Eliot Lear (Cisco),\
    \ Kenny\n   Paterson (Royal Holloway), Eric Rescorla (RTFM), Wendy Seltzer (W3C),\n\
    \   Dave Thaler (Microsoft), and Sean Turner (IECA).\n"
- title: Appendix D.  Participants
  contents:
  - "Appendix D.  Participants\n   The participants to the workshop were:\n   o  Bernard\
    \ Aboba (Microsoft Corporation)\n   o  Thijs Alkemade (Adium)\n   o  Daniel Appelquist\
    \ (Telefonica Digital)\n   o  Jari Arkko (Ericsson)\n   o  Alia Atlas (Juniper\
    \ Networks)\n   o  Emmanuel Baccelli (INRIA)\n   o  Mary Barnes\n   o  Richard\
    \ Barnes (Mozilla)\n   o  Steve Bellovin (Columbia University)\n   o  Andrea Bittau\
    \ (Stanford University)\n   o  Marc Blanchet (Viagenie)\n   o  Carsten Bormann\
    \ (Uni Bremen TZI)\n   o  Bert Bos (W3C)\n   o  Ian Brown (Oxford University)\n\
    \   o  Stewart Bryant (Cisco Systems)\n   o  Randy Bush (IIJ / Dragon Research\
    \ Labs)\n   o  Kelsey Cairns (Washington State University)\n   o  Stuart Cheshire\
    \ (Apple)\n   o  Vincent Cheval (University of Birmingham)\n   o  Benoit Claise\
    \ (Cisco)\n   o  Alissa Cooper (Cisco)\n   o  Dave Crocker (Brandenburg InternetWorking)\n\
    \   o  Leslie Daigle (Internet Society)\n   o  George Danezis (University College\
    \ London)\n   o  Spencer Dawkins (Huawei)\n   o  Mark Donnelly (Painless Security)\n\
    \   o  Nick Doty (W3C)\n   o  Dan Druta (AT&T)\n   o  Peter Eckersley (Electronic\
    \ Frontier Foundation)\n   o  Lars Eggert (NetApp)\n   o  Kai Engert (Red Hat)\n\
    \   o  Monika Ermert\n   o  Stephen Farrell (Trinity College Dublin)\n   o  Barbara\
    \ Fraser (Cisco)\n   o  Virginie Galindo (gemalto)\n   o  Stefanie Gerdes (Uni\
    \ Bremen TZI)\n   o  Daniel Kahn Gillmor (ACLU)\n   o  Wendy M. Grossman\n   o\
    \  Christian Grothoff (The GNUnet Project)\n   o  Oliver Hahm (INRIA)\n   o  Joseph\
    \ Lorenzo Hall (Center for Democracy & Technology)\n   o  Phillip Hallam-Baker\n\
    \   o  Harry Halpin (W3C/MIT and IRI)\n   o  Ted Hardie (Google)\n   o  Joe Hildebrand\
    \ (Cisco Systems)\n   o  Russ Housley (Vigil Security, LLC)\n   o  Cullen Jennings\
    \ (CISCO)\n   o  Leif Johansson (SUNET)\n   o  Harold Johnson (Irdeto)\n   o \
    \ Alan Johnston (Avaya)\n   o  L. Aaron Kaplan (CERT.at)\n   o  Steve Kent (BBN\
    \ Technologies)\n   o  Achim Klabunde (European Data Protection Supervisor)\n\
    \   o  Hans Kuhn (NOC)\n   o  Christian de Larrinaga\n   o  Ben Laurie (Google)\n\
    \   o  Eliot Lear (Cisco Ssytems)\n   o  Barry Leiba (Huawei Technologies)\n \
    \  o  Sebastian Lekies (SAP AG)\n   o  Orit Levin (Microsoft Corporation)\n  \
    \ o  Carlo Von LynX (#youbroketheinternet)\n   o  Xavier Marjou (Orange)\n   o\
    \  Larry Masinter (Adobe)\n   o  John Mattsson (Ericsson)\n   o  Patrick McManus\
    \ (Mozilla)\n   o  Doug Montgomery (NIST)\n   o  Kathleen Moriarty (EMC)\n   o\
    \  Alec Muffett (Facebook)\n   o  Suhas Nandakumar (Cisco Systems)\n   o  Linh\
    \ Nguyen (ERCIM/W3C)\n   o  Linus Nordberg (NORDUnet)\n   o  Mark Nottingham\n\
    \   o  Karen O'Donoghue (Internet Society)\n   o  Piers O'Hanlon (Oxford Internet\
    \ Institute)\n   o  Kenny Paterson (Royal Holloway, University of London)\n  \
    \ o  Jon Peterson (Neustar)\n   o  Joshua Phillips (University of Birmingham)\n\
    \   o  Alfredo Pironti (INRIA)\n   o  Dana Polatin-Reuben (University of Oxford)\n\
    \   o  Prof. Johan Pouwelse (Delft University of Technology)\n   o  Max Pritikin\
    \ (Cisco)\n   o  Eric Rescorla (Mozilla)\n   o  Pete Resnick (Qualcomm Technologies,\
    \ Inc.)\n   o  Tom Ristenpart (University of Wisconsin)\n   o  Andrei Robachevsky\
    \ (Internet Society)\n   o  David Rogers (Copper Horse)\n   o  Scott Rose (NIST)\n\
    \   o  Christine Runnegar (Internet Society)\n   o  Philippe De Ryck (DistriNet\
    \ - KU Leuven)\n   o  Peter Saint-Andre (&yet)\n   o  Runa A. Sandvik (Center\
    \ for Democracy and Technology)\n   o  Jakob Schlyter\n   o  Dr. Jan Seedorf (NEC\
    \ Laboratories Europe)\n   o  Wendy Seltzer (W3C)\n   o  Melinda Shore (No Mountain\
    \ Software)\n   o  Dave Thaler (Microsoft)\n   o  Brian Trammell (ETH Zurich)\n\
    \   o  Hannes Tschofenig (ARM Limited)\n   o  Sean Turner (IECA, Inc.)\n   o \
    \ Matthias Waehlisch (Freie Universitaet Berlin)\n   o  Greg Walton (Oxford University)\n\
    \   o  Rigo Wenning (W3C)\n   o  Tara Whalen (Apple Inc.)\n   o  Greg Wood (Internet\
    \ Society)\n   o  Jiangshan Yu (University of Birmingham)\n   o  Aaron Zauner\n\
    \   o  Dacheng Zhang (Huawei)\n   o  Phil Zimmermann (Silent Circle LLC)\n   o\
    \  Juan-Carlos Zuniga (InterDigital)\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Stephen Farrell\n   Trinity College, Dublin\n   Email:\
    \ stephen.farrell@cs.tcd.ie\n   URI:   https://www.cs.tcd.ie/Stephen.Farrell/\n\
    \   Rigo Wenning\n   World Wide Web Consortium\n   2004, route des Lucioles\n\
    \   B.P. 93\n   Sophia-Antipolis  06902\n   France\n   Email: rigo@w3.org\n  \
    \ URI:   http://www.w3.org/People/Rigo/\n   Bert Bos\n   World Wide Web Consortium\n\
    \   2004, route des Lucioles\n   B.P. 93\n   Sophia-Antipolis  06902\n   France\n\
    \   Email: bert@w3.org\n   Marc Blanchet\n   Viagenie\n   246 Aberdeen\n   Quebec,\
    \ QC  G1R 2E1\n   Canada\n   Email: Marc.Blanchet@viagenie.ca\n   URI:   http://viagenie.ca\n\
    \   Hannes Tschofenig\n   ARM Ltd.\n   110 Fulbourn Rd\n   Cambridge  CB1 9NJ\n\
    \   Great Britain\n   Email: Hannes.tschofenig@gmx.net\n   URI:   http://www.tschofenig.priv.at\n"
