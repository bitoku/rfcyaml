- title: __initial_text__
  contents:
  - '           Benchmarking Methodology for Firewall Performance

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2003).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document discusses and defines a number of tests that may be\n\
    \   used to describe the performance characteristics of firewalls.  In\n   addition\
    \ to defining the tests, this document also describes specific\n   formats for\
    \ reporting the results of the tests.\n   This document is a product of the Benchmarking\
    \ Methodology Working\n   Group (BMWG) of the Internet Engineering Task Force\
    \ (IETF).\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction . . . . . . . . . . . . . . . . . . . .\
    \ . . . .  2\n   2. Requirements . . . . . . . . . . . . . . . . . . . . . . .\
    \ .  2\n   3. Scope  . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\n\
    \   4. Test setup . . . . . . . . . . . . . . . . . . . . . . . . .  3\n     \
    \ 4.1 Test Considerations. . . . . . . . . . . . . . . . . . .  4\n      4.2 Virtual\
    \ Client/Servers . . . . . . . . . . . . . . . . .  4\n      4.3 Test Traffic\
    \ Requirements. . . . . . . . . . . . . . . .  5\n      4.4 DUT/SUT Traffic Flows.\
    \ . . . . . . . . . . . . . . . . .  5\n      4.5 Multiple Client/Server Testing\
    \ . . . . . . . . . . . . .  5\n      4.6 Network Address Translation (NAT). .\
    \ . . . . . . . . . .  6\n      4.7 Rule Sets. . . . . . . . . . . . . . . . .\
    \ . . . . . . .  6\n      4.8 Web Caching. . . . . . . . . . . . . . . . . . .\
    \ . . . .  6\n      4.9 Authentication . . . . . . . . . . . . . . . . . . . .\
    \ .  7\n      4.10 TCP Stack Considerations. . . . . . . . . . . . . . . .  7\n\
    \   5. Benchmarking Tests . . . . . . . . . . . . . . . . . . . . .  7\n     \
    \ 5.1 IP throughput. . . . . . . . . . . . . . . . . . . . . .  7\n      5.2 Concurrent\
    \ TCP Connection Capacity . . . . . . . . . . .  9\n      5.3 Maximum TCP Connection\
    \ Establishment Rate. . . . . . . . 12\n      5.4 Maximum TCP Connection Tear\
    \ Down Rate. . . . . . . . . . 14\n      5.5 Denial Of Service Handling . . .\
    \ . . . . . . . . . . . . 16\n      5.6 HTTP Transfer Rate . . . . . . . . . .\
    \ . . . . . . . . . 18\n      5.7 Maximum HTTP Transaction Rate. . . . . . . .\
    \ . . . . . . 21\n      5.8 Illegal Traffic Handling . . . . . . . . . . . . .\
    \ . . . 23\n      5.9 IP Fragmentation Handling. . . . . . . . . . . . . . . .\
    \ 24\n      5.10 Latency . . . . . . . . . . . . . . . . . . . . . . . . 26\n\
    \   6. References . . . . . . . . . . . . . . . . . . . . . . . . . 29\n     \
    \ 6.1 Normative References . . . . . . . . . . . . . . . . . . 29\n      6.2 Informative\
    \ References . . . . . . . . . . . . . . . . . 30\n   7. Security Consideration\
    \ . . . . . . . . . . . . . . . . . . . 30\n   Appendix A - HyperText Transfer\
    \ Protocol (HTTP) . . . . . . . . 31\n   Appendix B - Connection Establishment\
    \ Time Measurements . . . . 31\n   Appendix C - Connection Tear Down Time Measurements\
    \ . . . . . . 32\n   Authors' Addresses  . . . . . . . . . . . . . . . . . . .\
    \ . . . 33\n   Full Copyright Statement  . . . . . . . . . . . . . . . . . . .\
    \ 34\n"
- title: 1. Introduction
  contents:
  - "1. Introduction\n   This document provides methodologies for the performance\
    \ benchmarking\n   of firewalls.  It covers four areas: forwarding, connection,\
    \ latency\n   and filtering.  In addition to defining tests, this document also\n\
    \   describes specific formats for reporting test results.\n   A previous document,\
    \ \"Benchmarking Terminology for Firewall\n   Performance\" [1], defines many\
    \ of the terms that are used in this\n   document.  The terminology document SHOULD\
    \ be consulted before\n   attempting to make use of this document.\n"
- title: 2. Requirements
  contents:
  - "2. Requirements\n   In this document, the words that are used to define the significance\n\
    \   of each particular requirement are capitalized.  These words are:\n   *  \"\
    MUST\" This word, or the words \"REQUIRED\" and \"SHALL\" mean that\n      the\
    \ item is an absolute requirement of the specification.\n   *  \"SHOULD\" This\
    \ word or the adjective \"RECOMMENDED\" means that there\n      may exist valid\
    \ reasons in particular circumstances to ignore this\n      item, but the full\
    \ implications should be understood and the case\n      carefully weighed before\
    \ choosing a different course.\n   *  \"MAY\" This word or the adjective \"OPTIONAL\"\
    \ means that this item\n      is truly optional.  One vendor may choose to include\
    \ the item\n      because a particular marketplace requires it or because it\n\
    \      enhances the product, for example; another vendor may omit the\n      same\
    \ item.\n   An implementation is not compliant if it fails to satisfy one or more\n\
    \   of the MUST requirements.  An implementation that satisfies all the\n   MUST\
    \ and all the SHOULD requirements is said to be \"unconditionally\n   compliant\"\
    ; one that satisfies all the MUST requirements but not all\n   the SHOULD requirements\
    \ is said to be \"conditionally compliant\".\n"
- title: 3. Scope
  contents:
  - "3. Scope\n   Firewalls can control access between networks.  Usually, a firewall\n\
    \   protects a private network from public or shared network(s) to which\n   it\
    \ is connected.  A firewall can be as simple as a single device that\n   filters\
    \ packets or as complex as a group of devices that combine\n   packet filtering\
    \ and application-level proxy and network translation\n   services.  This document\
    \ focuses on benchmarking firewall\n   performance, wherever possible, independent\
    \ of implementation.\n"
- title: 4. Test Setup
  contents:
  - "4. Test Setup\n   Test configurations defined in this document will be confined\
    \ to\n   dual-homed and tri-homed as shown in figure 1 and figure 2\n   respectively.\n\
    \   Firewalls employing dual-homed configurations connect two networks.\n   One\
    \ interface of the firewall is attached to the unprotected network\n   [1], typically\
    \ the public network (Internet).  The other interface is\n   connected to the\
    \ protected network [1], typically the internal LAN.\n   In the case of dual-homed\
    \ configurations, servers which are made\n   accessible to the public (Unprotected)\
    \ network are attached to the\n   private (Protected) network.\n   +----------+\
    \                                       +----------+\n   |          |    |   \
    \    +----------+        |      |          |\n   | Servers/ |----|       |   \
    \       |        |------| Servers/ |\n   | Clients  |    |       |          |\
    \        |      | Clients  |\n   |          |    |-------|  DUT/SUT |--------|\
    \      |          |\n   +----------+    |       |          |        |      +----------+\n\
    \        Protected  |       +----------+        | Unprotected\n         Network\
    \   |                           |   Network\n                       Figure 1 (Dual-Homed)\n\
    \   Tri-homed [1] configurations employ a third segment called a\n   Demilitarized\
    \ Zone (DMZ).  With tri-homed configurations, servers\n   accessible to the public\
    \ network are attached to the DMZ.  Tri-Homed\n   configurations offer additional\
    \ security by separating server(s)\n   accessible to the public network from internal\
    \ hosts.\n   +----------+                                       +----------+\n\
    \   |          |    |       +----------+        |      |          |\n   | Clients\
    \  |----|       |          |        |------| Servers/ |\n   |          |    |\
    \       |          |        |      | Clients  |\n   +----------+    |-------|\
    \  DUT/SUT |--------|      |          |\n                   |       |        \
    \  |        |      +----------+\n                   |       +----------+     \
    \   |\n         Protected |            |              | Unprotected\n        \
    \  Network               |                   Network\n                       \
    \         |\n                          -----------------\n                   \
    \                 |    DMZ\n                                    |\n          \
    \                          |\n                             +-----------+\n   \
    \                          |           |\n                             | Servers\
    \   |\n                             |           |\n                          \
    \   +-----------+\n                          Figure 2 (Tri-Homed)\n"
- title: 4.1 Test Considerations
  contents:
  - '4.1 Test Considerations

    '
- title: 4.2 Virtual Clients/Servers
  contents:
  - "4.2 Virtual Clients/Servers\n   Since firewall testing may involve data sources\
    \ which emulate\n   multiple users or hosts, the methodology uses the terms virtual\n\
    \   clients/servers.  For these firewall tests, virtual clients/servers\n   specify\
    \ application layer entities which may not be associated with a\n   unique physical\
    \ interface.  For example, four virtual clients may\n   originate from the same\
    \ data source [1].  The test report MUST\n   indicate the number of virtual clients\
    \ and virtual servers\n   participating in the test.\n"
- title: 4.3 Test Traffic Requirements
  contents:
  - "4.3 Test Traffic Requirements\n   While the function of a firewall is to enforce\
    \ access control\n   policies, the criteria by which those policies are defined\
    \ vary\n   depending on the implementation.  Firewalls may use network layer,\n\
    \   transport layer or, in many cases, application-layer criteria to make\n  \
    \ access-control decisions.\n   For the purposes of benchmarking firewall performance,\
    \ this document\n   references HTTP 1.1 or higher as the application layer entity.\
    \  The\n   methodologies MAY be used as a template for benchmarking with other\n\
    \   applications.  Since testing may involve proxy based DUT/SUTs, HTTP\n   version\
    \ considerations are discussed in appendix A.\n"
- title: 4.4 DUT/SUT Traffic Flows
  contents:
  - "4.4 DUT/SUT Traffic Flows\n   Since the number of interfaces are not fixed, the\
    \ traffic flows will\n   be dependent upon the configuration used in benchmarking\
    \ the DUT/SUT.\n   Note that the term \"traffic flows\" is associated with client-to-\n\
    \   server requests.\n   For Dual-Homed configurations, there are two unique traffic\
    \ flows:\n      Client         Server\n      ------         ------\n      Protected\
    \   -> Unprotected\n      Unprotected -> Protected\n   For Tri-Homed configurations,\
    \ there are three unique traffic flows:\n      Client         Server\n      ------\
    \         ------\n      Protected ->   Unprotected\n      Protected ->   DMZ\n\
    \      Unprotected -> DMZ\n"
- title: 4.5 Multiple Client/Server Testing
  contents:
  - "4.5 Multiple Client/Server Testing\n   One or more clients may target multiple\
    \ servers for a given\n   application.  Each virtual client MUST initiate connections\
    \ in a\n   round-robin fashion.  For example, if the test consisted of six\n \
    \  virtual clients targeting three servers, the pattern would be as\n   follows:\n\
    \      Client          Target Server (In order of request)\n      #1         \
    \     1     2     3     1...\n      #2              2     3     1     2...\n \
    \     #3              3     1     2     3...\n      #4              1     2  \
    \   3     1...\n      #5              2     3     1     2...\n      #6       \
    \       3     1     2     3...\n"
- title: 4.6 Network Address Translation (NAT)
  contents:
  - "4.6 Network Address Translation (NAT)\n   Many firewalls implement network address\
    \ translation (NAT) [1], a\n   function which translates private internet addresses\
    \ to public\n   internet addresses.  This involves additional processing on the\
    \ part\n   of the DUT/SUT and may impact performance.  Therefore, tests SHOULD\n\
    \   be ran with NAT disabled and NAT enabled to determine the performance\n  \
    \ differential, if any.  The test report MUST indicate whether NAT was\n   enabled\
    \ or disabled.\n"
- title: 4.7 Rule Sets
  contents:
  - "4.7 Rule Sets\n   Rule sets [1] are a collection of access control policies that\n\
    \   determine which packets the DUT/SUT will forward and which it will\n   reject\
    \ [1].  Since criteria by which these access control policies\n   may be defined\
    \ will vary depending on the capabilities of the\n   DUT/SUT, the following is\
    \ limited to providing guidelines for\n   configuring rule sets when benchmarking\
    \ the performance of the\n   DUT/SUT.\n   It is RECOMMENDED that a rule be entered\
    \ for each host (Virtual\n   client).  In addition, testing SHOULD be performed\
    \ using different\n   size rule sets to determine its impact on the performance\
    \ of the\n   DUT/SUT.  Rule sets MUST be configured in a manner, such that, rules\n\
    \   associated with actual test traffic are configured at the end of the\n   rule\
    \ set and not at the beginning.\n   The DUT/SUT SHOULD be configured to deny access\
    \ to all traffic which\n   was not previously defined in the rule set.  The test\
    \ report SHOULD\n   include the DUT/SUT configured rule set(s).\n"
- title: 4.8 Web Caching
  contents:
  - "4.8 Web Caching\n   Some firewalls include caching agents to reduce network load.\
    \  When\n   making a request through a caching agent, the caching agent attempts\n\
    \   to service the response from its internal memory.  The cache itself\n   saves\
    \ responses it receives, such as responses for HTTP GET requests.\n   Testing\
    \ SHOULD be performed with any caching agents on the DUT/SUT\n   disabled.\n"
- title: 4.9 Authentication
  contents:
  - "4.9 Authentication\n   Access control may involve authentication processes such\
    \ as user,\n   client or session authentication.  Authentication is usually\n\
    \   performed by devices external to the firewall itself, such as an\n   authentication\
    \ server(s) and may add to the latency of the system.\n   Any authentication processes\
    \ MUST be included as part of connection\n   setup process.\n"
- title: 4.10 TCP Stack Considerations
  contents:
  - "4.10 TCP Stack Considerations\n   Some test instruments allow configuration of\
    \ one or more TCP stack\n   parameters, thereby influencing the traffic flows\
    \ which will be\n   offered and impacting performance measurements.  While this\
    \ document\n   does not attempt to specify which TCP parameters should be\n  \
    \ configurable, any such TCP parameter(s) MUST be noted in the test\n   report.\
    \  In addition, when comparing multiple DUT/SUTs, the same TCP\n   parameters\
    \ MUST be used.\n"
- title: 5. Benchmarking Tests
  contents:
  - '5. Benchmarking Tests

    '
- title: 5.1 IP Throughput
  contents:
  - '5.1 IP Throughput

    '
- title: 5.1.1 Objective
  contents:
  - "5.1.1 Objective\n   To determine the throughput of network-layer data traversing\
    \ the\n   DUT/SUT, as defined in RFC 1242 [3].  Note that while RFC 1242 uses\n\
    \   the term frames, which is associated with the link layer, the\n   procedure\
    \ uses the term packets, since it is referencing the network\n   layer.\n"
- title: 5.1.2 Setup Parameters
  contents:
  - "5.1.2 Setup Parameters\n   The following parameters MUST be defined:\n      Packet\
    \ size - Number of bytes in the IP packet, exclusive of any\n      link layer\
    \ header or checksums.\n      Test Duration - Duration of the test, expressed\
    \ in seconds.\n"
- title: 5.1.3 Procedure
  contents:
  - "5.1.3 Procedure\n   The test instrument MUST offer unicast IP packets to the\
    \ DUT/SUT at a\n   constant rate.  The test MAY consist of either bi-directional\
    \ or\n   unidirectional traffic; for example, an emulated client may offer a\n\
    \   unicast stream of packets to an emulated server, or the test\n   instrument\
    \ may simulate a client/server exchange by offering\n   bidirectional traffic.\n\
    \   This test will employ an iterative search algorithm.  Each iteration\n   will\
    \ involve the test instrument varying the intended load until the\n   maximum\
    \ rate, at which no packet loss occurs, is found.  Since\n   backpressure mechanisms\
    \ may be employed, resulting in the intended\n   load and offered load being different,\
    \ the test SHOULD be performed\n   in either a packet based or time based manner\
    \ as described in RFC\n   2889 [5].  As with RFC 1242, the term packet is used\
    \ in place of\n   frame.  The duration of the test portion of each trial MUST\
    \ be at\n   least 30 seconds.\n   It is RECOMMENDED to perform the throughput\
    \ measurements with\n   different packet sizes.  When testing with different packet\
    \ sizes the\n   DUT/SUT configuration MUST remain the same.\n"
- title: 5.1.4 Measurement
  contents:
  - '5.1.4 Measurement

    '
- title: 5.1.4.1 Network Layer
  contents:
  - "5.1.4.1 Network Layer\n   Throughput:\n      Maximum offered load, expressed\
    \ in either bits per second or\n      packets per second, at which no packet loss\
    \ is detected.  The bits\n      to be counted are in the IP packet (header plus\
    \ payload); other\n      fields, such as link-layer headers and trailers, MUST\
    \ NOT be\n      included in the measurement.\n   Forwarding Rate:\n      Forwarding\
    \ rate, expressed in either bits per second or packets\n      per second, the\
    \ device is observed to successfully forward to the\n      correct destination\
    \ interface in response to a specified offered\n      load.  The bits to be counted\
    \ are in the IP packet (header plus\n      payload); other fields, such as link-layer\
    \ headers and trailers,\n      MUST NOT be included in the measurement.\n"
- title: 5.1.5 Reporting Format
  contents:
  - "5.1.5 Reporting Format\n   The test report MUST note the packet size(s), test\
    \ duration,\n   throughput and forwarding rate. In addition, the test report MUST\n\
    \   conform to the reporting requirements set in section 4, Test Setup.\n   If\
    \ the test involved offering packets which target more than one\n   segment (Protected,\
    \ Unprotected or DMZ), the report MUST identify the\n   results as an aggregate\
    \ throughput measurement.\n   The throughput results SHOULD be reported in the\
    \ format of a table\n   with a row for each of the tested packet sizes.  There\
    \ SHOULD be\n   columns for the packet size, the intended load, the offered load,\n\
    \   resultant throughput and forwarding rate for each test.\n   The intermediate\
    \ results of the search algorithm MAY be saved in log\n   file which includes\
    \ the packet size, test duration and for each\n   iteration:\n      - Step Iteration\n\
    \      - Pass/Fail Status\n      - Total packets offered\n      - Total packets\
    \ forwarded\n      - Intended load\n      - Offered load (If applicable)\n   \
    \   - Forwarding rate\n"
- title: 5.2 Concurrent TCP Connection Capacity
  contents:
  - '5.2 Concurrent TCP Connection Capacity

    '
- title: 5.2.1 Objective
  contents:
  - "5.2.1 Objective\n   To determine the maximum number of concurrent TCP connections\n\
    \   supported through or with the DUT/SUT, as defined in RFC 2647 [1].\n   This\
    \ test is intended to find the maximum number of entries the\n   DUT/SUT can store\
    \ in its connection table.\n"
- title: 5.2.2 Setup Parameters
  contents:
  - "5.2.2 Setup Parameters\n   The following parameters MUST be defined for all tests:\n"
- title: 5.2.2.1 Transport-Layer Setup Parameters
  contents:
  - "5.2.2.1 Transport-Layer Setup Parameters\n   Connection Attempt Rate:\n     \
    \ The aggregate rate, expressed in connections per second, at which\n      TCP\
    \ connection requests are attempted.  The rate SHOULD be set at\n      or lower\
    \ than the maximum rate at which the DUT/SUT can accept\n      connection requests.\n\
    \   Aging Time:\n      The time, expressed in seconds, the DUT/SUT will keep a\
    \ connection\n      in its connection table after receiving a TCP FIN or RST packet.\n"
- title: 5.2.2.2 Application-Layer Setup Parameters
  contents:
  - "5.2.2.2 Application-Layer Setup Parameters\n   Validation Method:\n      HTTP\
    \ 1.1 or higher MUST be used for this test for both clients and\n      servers.\
    \  The client and server MUST use the same HTTP version.\n   Object Size:\n  \
    \    Defines the number of bytes, excluding any bytes associated with\n      the\
    \ HTTP header, to be transferred in response to an HTTP 1.1 or\n      higher GET\
    \ request.\n"
- title: 5.2.3 Procedure
  contents:
  - "5.2.3 Procedure\n   This test will employ an iterative search algorithm to determine\
    \ the\n   maximum number of concurrent TCP connections supported through or\n\
    \   with the DUT/SUT.\n   For each iteration, the aggregate number of concurrent\
    \ TCP\n   connections attempted by the virtual client(s) will be varied.  The\n\
    \   destination address will be that of the server or that of the NAT\n   proxy.\
    \  The aggregate rate will be defined by connection attempt\n   rate, and will\
    \ be attempted in a round-robin fashion (See 4.5).\n   To validate all connections,\
    \ the virtual client(s) MUST request an\n   object using an HTTP 1.1 or higher\
    \ GET request.  The requests MUST be\n   initiated on each connection after all\
    \ of the TCP connections have\n   been established.\n   When testing proxy-based\
    \ DUT/SUTs, the virtual client(s) MUST request\n   two objects using HTTP 1.1\
    \ or higher GET requests.  The first GET\n   request is required for connection\
    \ time establishment [1]\n   measurements as specified in appendix B.  The second\
    \ request is used\n   for validation as previously mentioned.  When comparing\
    \ proxy and\n   non-proxy based DUT/SUTs, the test MUST be performed in the same\n\
    \   manner.\n   Between each iteration, it is RECOMMENDED that the test instrument\n\
    \   issue a TCP RST referencing each connection attempted for the\n   previous\
    \ iteration, regardless of whether or not the connection\n   attempt was successful.\
    \  The test instrument will wait for aging time\n   before continuing to the next\
    \ iteration.\n"
- title: 5.2.4 Measurements
  contents:
  - '5.2.4 Measurements

    '
- title: 5.2.4.1 Application-Layer measurements
  contents:
  - "5.2.4.1 Application-Layer measurements\n   Number of objects requested\n   Number\
    \ of objects returned\n"
- title: 5.2.4.2 Transport-Layer measurements
  contents:
  - "5.2.4.2 Transport-Layer measurements\n   Maximum concurrent connections:\n  \
    \    Total number of TCP connections open for the last successful\n      iteration\
    \ performed in the search algorithm.\n   Minimum connection establishment time:\n\
    \      Lowest TCP connection establishment time measured, as defined in\n    \
    \  appendix B.\n   Maximum connection establishment time:\n      Highest TCP connection\
    \ establishment time measured, as defined in\n      appendix B.\n   Average connection\
    \ establishment time:\n      The mean of all measurements of connection establishment\
    \ times.\n   Aggregate connection establishment time:\n      The total of all\
    \ measurements of connection establishment times.\n"
- title: 5.2.5 Reporting Format
  contents:
  - "5.2.5 Reporting Format\n   The test report MUST conform to the reporting requirements\
    \ set in\n   section 4, Test Setup.\n"
- title: '5.2.5.1 Application-Layer Reporting:'
  contents:
  - "5.2.5.1 Application-Layer Reporting:\n   The test report MUST note the object\
    \ size, number of completed\n   requests and number of completed responses.\n\
    \   The intermediate results of the search algorithm MAY be reported in a\n  \
    \ tabular format with a column for each iteration.  There SHOULD be\n   rows for\
    \ the number of requests attempted, number and percentage\n   requests completed,\
    \ number of responses attempted, number and\n   percentage of responses completed.\
    \  The table MAY be combined with\n   the transport-layer reporting, provided\
    \ that the table identify this\n   as an application layer measurement.\n   Version\
    \ information:\n      The test report MUST note the version of HTTP client(s)\
    \ and\n      server(s).\n"
- title: '5.2.5.2 Transport-Layer Reporting:'
  contents:
  - "5.2.5.2 Transport-Layer Reporting:\n   The test report MUST note the connection\
    \ attempt rate, aging time,\n   minimum TCP connection establishment time, maximum\
    \ TCP connection\n   establishment time, average connection establishment time,\
    \ aggregate\n   connection establishment time and maximum concurrent connections\n\
    \   measured.\n   The intermediate results of the search algorithm MAY be reported\
    \ in\n   the format of a table with a column for each iteration.  There SHOULD\n\
    \   be rows for the total number of TCP connections attempted, number and\n  \
    \ percentage of TCP connections completed, minimum TCP connection\n   establishment\
    \ time, maximum TCP connection establishment time,\n   average connection establishment\
    \ time and the aggregate connection\n   establishment time.\n"
- title: 5.3 Maximum TCP Connection Establishment Rate
  contents:
  - '5.3 Maximum TCP Connection Establishment Rate

    '
- title: 5.3.1 Objective
  contents:
  - "5.3.1 Objective\n   To determine the maximum TCP connection establishment rate\
    \ through or\n   with the DUT/SUT, as defined by RFC 2647 [1].  This test is intended\n\
    \   to find the maximum rate the DUT/SUT can update its connection table.\n"
- title: 5.3.2 Setup Parameters
  contents:
  - "5.3.2 Setup Parameters\n   The following parameters MUST be defined for all tests:\n"
- title: 5.3.2.1 Transport-Layer Setup Parameters
  contents:
  - "5.3.2.1 Transport-Layer Setup Parameters\n   Number of Connections:\n      Defines\
    \ the aggregate number of TCP connections that must be\n      established.\n \
    \  Aging Time:\n      The time, expressed in seconds, the DUT/SUT will keep a\
    \ connection\n      in it's state table after receiving a TCP FIN or RST packet.\n"
- title: 5.3.2.2 Application-Layer Setup Parameters
  contents:
  - "5.3.2.2 Application-Layer Setup Parameters\n   Validation Method:\n      HTTP\
    \ 1.1 or higher MUST be used for this test for both clients and\n      servers.\
    \  The client and server MUST use the same HTTP version.\n   Object Size:\n  \
    \    Defines the number of bytes, excluding any bytes associated with\n      the\
    \ HTTP header, to be transferred in response to an HTTP 1.1 or\n      higher GET\
    \ request.\n"
- title: 5.3.3 Procedure
  contents:
  - "5.3.3 Procedure\n   This test will employ an iterative search algorithm to determine\
    \ the\n   maximum rate at which the DUT/SUT can accept TCP connection requests.\n\
    \   For each iteration, the aggregate rate at which TCP connection\n   requests\
    \ are attempted by the virtual client(s) will be varied.  The\n   destination\
    \ address will be that of the server or that of the NAT\n   proxy.  The aggregate\
    \ number of connections, defined by number of\n   connections, will be attempted\
    \ in a round-robin fashion (See 4.5).\n   The same application-layer object transfers\
    \ required for validation\n   and establishment time measurements as described\
    \ in the concurrent\n   TCP connection capacity test MUST be performed.\n   Between\
    \ each iteration, it is RECOMMENDED that the test instrument\n   issue a TCP RST\
    \ referencing each connection attempted for the\n   previous iteration, regardless\
    \ of whether or not the connection\n   attempt was successful.  The test instrument\
    \ will wait for aging time\n   before continuing to the next iteration.\n"
- title: 5.3.4 Measurements
  contents:
  - '5.3.4 Measurements

    '
- title: 5.3.4.1 Application-Layer measurements
  contents:
  - "5.3.4.1 Application-Layer measurements\n   Number of objects requested\n   Number\
    \ of objects returned\n"
- title: 5.3.4.2 Transport-Layer measurements
  contents:
  - "5.3.4.2 Transport-Layer measurements\n   Highest connection rate:\n      Highest\
    \ rate, in connections per second, for which all connections\n      successfully\
    \ opened in the search algorithm.\n   Minimum connection establishment time:\n\
    \      Lowest TCP connection establishment time measured, as defined in\n    \
    \  appendix B.\n   Maximum connection establishment time:\n      Highest TCP connection\
    \ establishment time measured, as defined in\n      appendix B.\n   Average connection\
    \ establishment time:\n      The mean of all measurements of connection establishment\
    \ times.\n   Aggregate connection establishment time:\n      The total of all\
    \ measurements of connection establishment times.\n"
- title: 5.3.5 Reporting Format
  contents:
  - "5.3.5 Reporting Format\n   The test report MUST conform to the reporting requirements\
    \ set in\n   section 4, Test Setup.\n"
- title: '5.3.5.1 Application-Layer Reporting:'
  contents:
  - "5.3.5.1 Application-Layer Reporting:\n   The test report MUST note object size(s),\
    \ number of completed\n   requests and number of completed responses.\n   The\
    \ intermediate results of the search algorithm MAY be reported in a\n   tabular\
    \ format with a column for each iteration.  There SHOULD be\n   rows for the number\
    \ of requests attempted, number and percentage\n   requests completed, number\
    \ of responses attempted, number and\n   percentage of responses completed.  The\
    \ table MAY be combined with\n   the transport-layer reporting, provided that\
    \ the table identify this\n   as an application layer measurement.\n   Version\
    \ information:\n      The test report MUST note the version of HTTP client(s)\
    \ and\n      server(s).\n"
- title: '5.3.5.2 Transport-Layer Reporting:'
  contents:
  - "5.3.5.2 Transport-Layer Reporting:\n   The test report MUST note the number of\
    \ connections, aging time,\n   minimum TCP connection establishment time, maximum\
    \ TCP connection\n   establishment time, average connection establishment time,\
    \ aggregate\n   connection establishment time and highest connection rate measured.\n\
    \   The intermediate results of the search algorithm MAY be reported in\n   the\
    \ format of a table with a column for each iteration.  There SHOULD\n   be rows\
    \ for the connection attempt rate, total number of TCP\n   connections attempted,\
    \ total number of TCP connections completed,\n   minimum TCP connection establishment\
    \ time, maximum TCP connection\n   establishment time, average connection establishment\
    \ time and the\n   aggregate connection establishment time.\n"
- title: 5.4 Maximum TCP Connection Tear Down Rate
  contents:
  - '5.4 Maximum TCP Connection Tear Down Rate

    '
- title: 5.4.1 Objective
  contents:
  - "5.4.1 Objective\n   To determine the maximum TCP connection tear down rate through\
    \ or\n   with the DUT/SUT, as defined by RFC 2647 [1].\n"
- title: 5.4.2 Setup Parameters
  contents:
  - "5.4.2 Setup Parameters\n   Number of Connections:\n      Defines the number of\
    \ TCP connections that will be attempted to be\n      torn down.\n   Aging Time:\n\
    \      The time, expressed in seconds, the DUT/SUT will keep a connection\n  \
    \    in it's state table after receiving a TCP FIN or RST packet.\n   Close Method:\n\
    \      Defines method for closing TCP connections.  The test MUST be\n      performed\
    \ with either a three-way or four-way handshake.  In a\n      four-way handshake,\
    \ each side sends separate FIN and ACK messages.\n      In a three-way handshake,\
    \ one side sends a combined FIN/ACK\n      message upon receipt of a FIN.\n  \
    \ Close Direction:\n      Defines whether closing of connections are to be initiated\
    \ from\n      the client or from the server.\n"
- title: 5.4.3 Procedure
  contents:
  - "5.4.3 Procedure\n   This test will employ an iterative search algorithm to determine\
    \ the\n   maximum TCP connection tear down rate supported by the DUT/SUT.  The\n\
    \   test iterates through different TCP connection tear down rates with a\n  \
    \ fixed number of TCP connections.\n   In the case of proxy based DUT/SUTs, the\
    \ DUT/SUT will itself receive\n   the ACK in response to issuing a FIN packet\
    \ to close its side of the\n   TCP connection.  For validation purposes, the virtual\
    \ client or\n   server, whichever is applicable, MAY verify that the DUT/SUT received\n\
    \   the final ACK by re-transmitting the final ACK.  A TCP RST should be\n   received\
    \ in response to the retransmitted ACK.\n   Between each iteration, it is RECOMMENDED\
    \ that the virtual client(s)\n   or server(s), whichever is applicable, issue\
    \ a TCP RST referencing\n   each connection which was attempted to be torn down,\
    \ regardless of\n   whether or not the connection tear down attempt was successful.\
    \  The\n   test will wait for aging time before continuing to the next\n   iteration.\n"
- title: 5.4.4 Measurements
  contents:
  - "5.4.4 Measurements\n   Highest connection tear down rate:\n      Highest rate,\
    \ in connections per second, for which all TCP\n      connections were successfully\
    \ torn down in the search algorithm.\n   The following tear down time [1] measurements\
    \ MUST only include\n   connections for which both sides of the connection were\
    \ successfully\n   torn down.  For example, tear down times for connections which\
    \ are\n   left in a FINWAIT-2 [8] state should not be included:\n   Minimum connection\
    \ tear down time:\n      Lowest TCP connection tear down time measured as defined\
    \ in\n      appendix C.\n   Maximum connection tear down time:\n      Highest\
    \ TCP connection tear down time measured as defined in\n      appendix C.\n  \
    \ Average connection tear down time:\n      The mean of all measurements of connection\
    \ tear down times.\n   Aggregate connection tear down time:\n      The total of\
    \ all measurements of connection tear down times.\n"
- title: 5.4.5 Reporting Format
  contents:
  - "5.4.5 Reporting Format\n   The test report MUST note the number of connections,\
    \ aging time,\n   close method, close direction, minimum TCP connection tear down\
    \ time,\n   maximum TCP connection tear down time, average TCP connection tear\n\
    \   down time and the aggregate TCP connection tear down time and highest\n  \
    \ connection tear down rate measured. In addition, the test report MUST\n   conform\
    \ to the reporting requirements set in section 4, Test Setup.\n   The intermediate\
    \ results of the search algorithm MAY be reported in\n   the format of a table\
    \ with a column for each iteration.  There SHOULD\n   be rows for the number of\
    \ TCP tear downs attempted, number and\n   percentage of TCP connection tear downs\
    \ completed, minimum TCP\n   connection tear down time, maximum TCP connection\
    \ tear down time,\n   average TCP connection tear down time, aggregate TCP connection\
    \ tear\n   down time and validation failures, if required.\n"
- title: 5.5 Denial Of Service Handling
  contents:
  - '5.5 Denial Of Service Handling

    '
- title: 5.5.1 Objective
  contents:
  - "5.5.1 Objective\n   To determine the effect of a denial of service attack on\
    \ a DUT/SUT\n   TCP connection establishment and/or HTTP transfer rates.  The\
    \ denial\n   of service handling test MUST be run after obtaining baseline\n \
    \  measurements from sections 5.3 and/or 5.6.\n   The TCP SYN flood attack exploits\
    \ TCP's three-way handshake mechanism\n   by having an attacking source host generate\
    \ TCP SYN packets with\n   random source addresses towards a victim host, thereby\
    \ consuming that\n   host's resources.\n"
- title: 5.5.2 Setup Parameters
  contents:
  - "5.5.2 Setup Parameters\n   Use the same setup parameters as defined in section\
    \ 5.3.2 or 5.6.2,\n   depending on whether testing against the baseline TCP connection\n\
    \   establishment rate test or HTTP transfer rate test, respectfully.\n   In addition,\
    \ the following setup parameters MUST be defined:\n   SYN attack rate:\n     \
    \ Rate, expressed in packets per second, at which the server(s) or\n      NAT\
    \ proxy address is targeted with TCP SYN packets.\n"
- title: 5.5.3 Procedure
  contents:
  - "5.5.3 Procedure\n   Use the same procedure as defined in section 5.3.3 or 5.6.3,\n\
    \   depending on whether testing against the baseline TCP connection\n   establishment\
    \ rate or HTTP transfer rate test, respectfully.  In\n   addition, the test instrument\
    \ will generate TCP SYN packets targeting\n   the server(s) IP address or NAT\
    \ proxy address at a rate defined by\n   SYN attack rate.\n   The test instrument\
    \ originating the TCP SYN attack MUST be attached\n   to the unprotected network.\
    \  In addition, the test instrument MUST\n   not respond to the SYN/ACK packets\
    \ sent by target server or NAT proxy\n   in response to the SYN packet.\n   Some\
    \ firewalls employ mechanisms to guard against SYN attacks.  If\n   such mechanisms\
    \ exist on the DUT/SUT, tests SHOULD be run with these\n   mechanisms enabled\
    \ and disabled to determine how well the DUT/SUT can\n   maintain, under such\
    \ attacks, the baseline connection establishment\n   rates and HTTP transfer rates\
    \ determined in section 5.3 and section\n   5.6, respectively.\n"
- title: 5.5.4 Measurements
  contents:
  - "5.5.4 Measurements\n   Perform the same measurements as defined in section 5.3.4\
    \ or 5.6.4,\n   depending on whether testing against the baseline TCP connection\n\
    \   establishment rate test or HTTP transfer rate, respectfully.\n   In addition,\
    \ the test instrument SHOULD track TCP SYN packets\n   associated with the SYN\
    \ attack which the DUT/SUT forwards on the\n   protected or DMZ interface(s).\n"
- title: 5.5.5 Reporting Format
  contents:
  - "5.5.5 Reporting Format\n   The test SHOULD use the same reporting format as described\
    \ in section\n   5.3.5 or 5.6.5, depending on whether testing against the baseline\
    \ TCP\n   connection establishment rate test or HTTP transfer rate,\n   respectfully.\n\
    \   In addition, the report MUST indicate a denial of service handling\n   test,\
    \ SYN attack rate, number of TCP SYN attack packets transmitted\n   and the number\
    \ of TCP SYN attack packets forwarded by the DUT/SUT.\n   The report MUST indicate\
    \ whether or not the DUT has any SYN attack\n   mechanisms enabled.\n"
- title: 5.6 HTTP Transfer Rate
  contents:
  - '5.6 HTTP Transfer Rate

    '
- title: 5.6.1 Objective
  contents:
  - "5.6.1 Objective\n   To determine the transfer rate of HTTP requested object traversing\n\
    \   the DUT/SUT.\n"
- title: 5.6.2 Setup Parameters
  contents:
  - "5.6.2 Setup Parameters\n   The following parameters MUST be defined for all tests:\n"
- title: 5.6.2.1 Transport-Layer Setup Parameters
  contents:
  - "5.6.2.1 Transport-Layer Setup Parameters\n   Number of connections:\n      Defines\
    \ the aggregate number of connections attempted.  The number\n      SHOULD be\
    \ a multiple of the number of virtual clients\n      participating in the test.\n\
    \   Close Method:\n      Defines the method for closing TCP connections.  The\
    \ test MUST be\n      performed with either a three-way or four-way handshake.\
    \  In a\n      four-way handshake, each side sends separate FIN and ACK messages.\n\
    \      In a three-way handshake, one side sends a combined FIN/ACK\n      message\
    \ upon receipt of a FIN.\n   Close Direction:\n      Defines whether closing of\
    \ connections are to be initiated from\n      the client or from the server.\n"
- title: 5.6.2.2 Application-Layer Setup Parameters
  contents:
  - "5.6.2.2 Application-Layer Setup Parameters\n   Session Type:\n      The virtual\
    \ clients/servers MUST use HTTP 1.1 or higher.  The\n      client and server MUST\
    \ use the same HTTP version.\n   GET requests per connection:\n      Defines the\
    \ number of HTTP 1.1 or higher GET requests attempted\n      per connection.\n\
    \   Object Size:\n      Defines the number of bytes, excluding any bytes associated\
    \ with\n      the HTTP header, to be transferred in response to an HTTP 1.1 or\n\
    \      higher GET request.\n"
- title: 5.6.3 Procedure
  contents:
  - "5.6.3 Procedure\n   Each HTTP 1.1 or higher virtual client will request one or\
    \ more\n   objects from an HTTP 1.1 or higher server using one or more HTTP GET\n\
    \   requests over each connection.  The aggregate number of connections\n   attempted,\
    \ defined by number of connections, MUST be evenly divided\n   among all of the\
    \ participating virtual clients.\n   If the virtual client(s) make multiple HTTP\
    \ GET requests per\n   connection, it MUST request the same object size for each\
    \ GET\n   request.  Multiple iterations of this test may be run with objects of\n\
    \   different sizes.\n"
- title: 5.6.4 Measurements
  contents:
  - '5.6.4 Measurements

    '
- title: 5.6.4.1 Application-Layer measurements
  contents:
  - "5.6.4.1 Application-Layer measurements\n   Average Transfer Rate :\n      The\
    \ average transfer rate of the DUT/SUT MUST be measured and\n      shall be referenced\
    \ to the requested object(s).  The measurement\n      will start on transmission\
    \ of the first bit of the first requested\n      object and end on transmission\
    \ of the last bit of the last\n      requested object.  The average transfer rate,\
    \ in bits per second,\n      will be calculated using the following formula:\n\
    \                             OBJECTS * OBJECTSIZE * 8\n   TRANSFER RATE (bit/s)\
    \ =  --------------------------\n                                    DURATION\n\
    \   OBJECTS    - Total number of objects successfully transferred across\n   \
    \             all connections.\n   OBJECTSIZE - Object size in bytes\n   DURATION\
    \   - Aggregate transfer time based on aforementioned time\n                references.\n"
- title: 5.6.4.2 Measurements at or below the Transport-Layer
  contents:
  - "5.6.4.2 Measurements at or below the Transport-Layer\n   The following measurements\
    \ SHOULD be performed for each connection-\n   oriented protocol:\n   Goodput\
    \ [1]:\n      Goodput as defined in section 3.17 of RFC 2647.  Measurements MUST\n\
    \      only reference the protocol payload, excluding any of the protocol\n  \
    \    header.  In addition, the test instrument MUST exclude any bits\n      associated\
    \ with the connection establishment, connection tear\n      down, security associations\
    \ [1] or connection maintenance [1].\n      Since connection-oriented protocols\
    \ require that data be\n      acknowledged, the offered load [4] will be varying.\
    \  Therefore,\n      the test instrument should measure the average forwarding\
    \ rate\n      over the duration of the test.  Measurement should start on\n  \
    \    transmission of the first bit of the payload of the first datagram\n    \
    \  and end on transmission of the last bit of the payload of the last\n      datagram.\n\
    \   Number of bytes transferred - Total payload bytes transferred.\n   Number\
    \ of Timeouts - Total number of timeout events.\n   Retransmitted bytes - Total\
    \ number of retransmitted bytes.\n"
- title: 5.6.5 Reporting Format
  contents:
  - "5.6.5 Reporting Format\n   The test report MUST conform to the reporting requirements\
    \ set in\n   section 4, Test Setup.\n"
- title: 5.6.5.1 Application-Layer reporting
  contents:
  - "5.6.5.1 Application-Layer reporting\n   The test report MUST note number of GET\
    \ requests per connection and\n   object size(s).\n   The transfer rate results\
    \ SHOULD be reported in tabular form with a\n   column for each of the object\
    \ sizes tested.  There SHOULD be a row\n   for the number and percentage of completed\
    \ requests, number and\n   percentage of completed responses, and the resultant\
    \ transfer rate\n   for each iteration of the test.\n   Failure analysis:\n  \
    \    The test report SHOULD indicate the number and percentage of HTTP\n     \
    \ GET request and responses that failed to complete.\n   Version information:\n\
    \      The test report MUST note the version of HTTP client(s) and\n      server(s).\n"
- title: 5.6.5.2 Transport-Layer and below reporting
  contents:
  - "5.6.5.2 Transport-Layer and below reporting\n   The test report MUST note the\
    \ number of connections, close method,\n   close direction and the protocol for\
    \ which the measurement was made.\n   The results SHOULD be reported in tabular\
    \ form for each of the HTTP\n   object sizes tested.  There SHOULD be a row for\
    \ the total bytes\n   transferred, total timeouts, total retransmitted bytes and\
    \ and\n   resultant goodput.  Note that total bytes refers to total datagram\n\
    \   payload bytes transferred.  The table MAY be combined with the\n   application\
    \ layer reporting, provided the table clearly identifies\n   the protocol for\
    \ which the measurement was made.\n   Failure analysis:\n      The test report\
    \ SHOULD indicate the number and percentage of\n      connection establishment\
    \ failures as well as number and percentage\n      of TCP tear down failures.\n\
    \   It is RECOMMENDED that the report include a graph to plot the\n   distribution\
    \ of both connection establishment failures and connection\n   tear down failures.\
    \  The x coordinate SHOULD be the elapsed test\n   time, the y coordinate SHOULD\
    \ be the number of failures for a given\n   sampling period.  There SHOULD be\
    \ two lines on the graph, one for\n   connection failures and one for tear down\
    \ failures.  The graph MUST\n   note the sampling period.\n"
- title: 5.7 Maximum HTTP Transaction Rate
  contents:
  - '5.7 Maximum HTTP Transaction Rate

    '
- title: 5.7.1 Objective
  contents:
  - "5.7.1 Objective\n   Determine the maximum transaction rate the DUT/SUT can sustain.\
    \  This\n   test is intended to find the maximum rate at which users can access\n\
    \   objects.\n"
- title: 5.7.2 Setup Parameters
  contents:
  - '5.7.2 Setup Parameters

    '
- title: 5.7.2.1 Transport-Layer Setup Parameters
  contents:
  - "5.7.2.1 Transport-Layer Setup Parameters\n   Close Method:\n      Defines method\
    \ for closing TCP connections.  The test MUST be\n      performed with either\
    \ a three-way or four-way handshake.  In a\n      four-way handshake, each side\
    \ sends separate FIN and ACK messages.\n      In a three-way handshake, one side\
    \ sends a combined FIN/ACK\n      message upon receipt of a FIN.\n   Close Direction:\n\
    \      Defines whether closing of connections are to be initiated from\n     \
    \ the client or from the server.\n"
- title: 5.7.2.2 Application-Layer Setup Parameters
  contents:
  - "5.7.2.2 Application-Layer Setup Parameters\n   Session Type:\n      HTTP 1.1\
    \ or higher MUST be used for this test.  The client and\n      server MUST use\
    \ the same HTTP version.\n   Test Duration:\n      Time, expressed in seconds,\
    \ for which the virtual client(s) will\n      sustain the attempted GET request\
    \ rate.  It is RECOMMENDED that\n      the duration be at least 30 seconds.\n\
    \   Requests per connection:\n      Number of object requests per connection.\n\
    \   Object Size:\n      Defines the number of bytes, excluding any bytes associated\
    \ with\n      the HTTP header, to be transferred in response to an HTTP 1.1 or\n\
    \      higher GET request.\n"
- title: 5.7.3 Procedure
  contents:
  - "5.7.3 Procedure\n   This test will employ an iterative search algorithm to determine\
    \ the\n   maximum transaction rate that the DUT/SUT can sustain.\n   For each\
    \ iteration, HTTP 1.1 or higher virtual client(s) will vary\n   the aggregate\
    \ GET request rate offered to HTTP 1.1 or higher\n   server(s).  The virtual client(s)\
    \ will maintain the offered request\n   rate for the defined test duration.\n\
    \   If the virtual client(s) make multiple HTTP GET requests per\n   connection,\
    \ it MUST request the same object size for each GET\n   request.  Multiple tests\
    \ MAY be performed with different object\n   sizes.\n"
- title: 5.7.4 Measurements
  contents:
  - "5.7.4 Measurements\n   Maximum Transaction Rate:\n      The maximum rate at which\
    \ all transactions, that is all\n      requests/responses cycles, are completed.\n\
    \   Transaction Time:\n      The test instrument SHOULD measure minimum, maximum\
    \ and average\n      transaction times.  The transaction time will start when\
    \ the\n      virtual client issues the GET request and end when the requesting\n\
    \      virtual client receives the last bit of the requested object.\n"
- title: 5.7.5 Reporting Format
  contents:
  - "5.7.5 Reporting Format\n   The test report MUST conform to the reporting requirements\
    \ set in\n   section 4, Test Setup.\n"
- title: 5.7.5.1 Application-Layer reporting
  contents:
  - "5.7.5.1 Application-Layer reporting\n   The test report MUST note the test duration,\
    \ object size, requests\n   per connection, minimum transaction time, maximum\
    \ transaction time,\n   average transaction time and maximum transaction rate\
    \ measured\n   The intermediate results of the search algorithm MAY be reported\
    \ in a\n   table format with a column for each iteration.  There SHOULD be rows\n\
    \   for the GET request attempt rate, number of requests attempted,\n   number\
    \ and percentage of requests completed, number of responses\n   attempted, number\
    \ and percentage of responses completed, minimum\n   transaction time, average\
    \ transaction time and maximum transaction\n   time.\n   Version information:\n\
    \      The test report MUST note the version of HTTP client(s) and\n      server(s).\n"
- title: 5.7.5.2 Transport-Layer
  contents:
  - "5.7.5.2 Transport-Layer\n   The test report MUST note the close method, close\
    \ direction, number\n   of connections established and number of connections torn\
    \ down.\n   The intermediate results of the search algorithm MAY be reported in\
    \ a\n   table format with a column for each iteration.  There SHOULD be rows\n\
    \   for the number of connections attempted, number and percentage of\n   connections\
    \ completed, number and percentage of connection tear downs\n   completed.  The\
    \ table MAY be combined with the application layer\n   reporting, provided the\
    \ table identify this as transport layer\n   measurement.\n"
- title: 5.8  Illegal Traffic Handling
  contents:
  - '5.8  Illegal Traffic Handling

    '
- title: 5.8.1 Objective
  contents:
  - "5.8.1 Objective\n   To characterize the behavior of the DUT/SUT when presented\
    \ with a\n   combination of both legal and Illegal [1] traffic.  Note that Illegal\n\
    \   traffic does not refer to an attack, but traffic which has been\n   explicitly\
    \ defined by a rule(s) to drop.\n"
- title: 5.8.2 Setup Parameters
  contents:
  - "5.8.2 Setup Parameters\n   Setup parameters will use the same parameters as specified\
    \ in the\n   HTTP transfer rate test (Section 5.6.2).  In addition, the following\n\
    \   setup parameters MUST be defined:\n   Illegal traffic percentage:\n      Percentage\
    \ of HTTP 1.1 or higher connections which have been\n      explicitly defined\
    \ in a rule(s) to drop.\n"
- title: 5.8.3 Procedure
  contents:
  - "5.8.3 Procedure\n   Each HTTP 1.1 or higher client will request one or more objects\
    \ from\n   an HTTP 1.1 or higher server using one or more HTTP GET requests over\n\
    \   each connection.  The aggregate number of connections attempted,\n   defined\
    \ by number of connections, MUST be evenly divided among all of\n   the participating\
    \ virtual clients.\n   The virtual client(s) MUST offer the connection requests,\
    \ both legal\n   and illegal, in an evenly distributed manner.  Many firewalls\
    \ have\n   the capability to filter on different traffic criteria (IP addresses,\n\
    \   Port numbers, etc.).  Multiple iterations of this test MAY be run\n   with\
    \ the DUT/SUT configured to filter on different traffic criteria.\n"
- title: 5.8.4 Measurements
  contents:
  - "5.8.4 Measurements\n   The same measurements as defined in HTTP transfer rate\
    \ test (Section\n   5.6.4) SHOULD be performed.  Any forwarding rate measurements\
    \ MUST\n   only include bits which are associated with legal traffic.\n"
- title: 5.8.5 Reporting Format
  contents:
  - "5.8.5 Reporting Format\n   Test reporting format SHOULD be the same as specified\
    \ in the HTTP\n   transfer rate test (Section 5.6.5).\n   In addition, the report\
    \ MUST note the percentage of illegal HTTP\n   connections.\n   Failure analysis:\n\
    \      Test report MUST note the number and percentage of illegal\n      connections\
    \ that were allowed by the DUT/SUT.\n"
- title: 5.9 IP Fragmentation Handling
  contents:
  - '5.9 IP Fragmentation Handling

    '
- title: 5.9.1 Objective
  contents:
  - "5.9.1 Objective\n   To determine the performance impact when the DUT/SUT is presented\n\
    \   with IP fragmented traffic.  IP packets which have been fragmented,\n   due\
    \ to crossing a network that supports a smaller MTU (Maximum\n   Transmission\
    \ Unit) than the actual IP packet, may require the\n   firewall to perform re-assembly\
    \ prior to the rule set being applied.\n   While IP fragmentation is a common\
    \ form of attack, either on the\n   firewall itself or on internal hosts, this\
    \ test will focus on\n   determining how the additional processing associated\
    \ with the re-\n   assembly of the packets have on the forwarding rate of the\
    \ DUT/SUT.\n   RFC 1858 addresses some fragmentation attacks that get around IP\n\
    \   filtering processes used in routers and hosts.\n"
- title: 5.9.2 Setup Parameters
  contents:
  - "5.9.2 Setup Parameters\n   The following parameters MUST be defined.\n"
- title: 5.9.2.1 Non-Fragmented Traffic Parameters
  contents:
  - "5.9.2.1 Non-Fragmented Traffic Parameters\n   Setup parameters will be the same\
    \ as defined in the HTTP transfer\n   rate test (Sections 5.6.2.1 and 5.6.2.2).\n"
- title: 5.9.2.2 Fragmented Traffic Parameters
  contents:
  - "5.9.2.2 Fragmented Traffic Parameters\n   Packet size:\n      Number of bytes\
    \ in the IP/UDP packet, exclusive of link-layer\n      headers and checksums,\
    \ prior to fragmentation.\n   MTU:\n      Maximum transmission unit, expressed\
    \ in bytes.  For testing\n      purposes, this MAY be configured to values smaller\
    \ than the MTU\n      supported by the link layer.\n   Intended Load:\n      Intended\
    \ load, expressed as percentage of media utilization.\n"
- title: 5.9.3 Procedure
  contents:
  - "5.9.3 Procedure\n   Each HTTP 1.1 or higher client will request one or more objects\
    \ from\n   an HTTP 1.1 or higher server using one or more HTTP GET requests over\n\
    \   each connection.  The aggregate number of connections attempted,\n   defined\
    \ by number of connections, MUST be evenly divided among all of\n   the participating\
    \ virtual clients.  If the virtual client(s) make\n   multiple HTTP GET requests\
    \ per connection, it MUST request the same\n   object size for each GET request.\n\
    \   A test instrument attached to the unprotected side of the network,\n   will\
    \ offer a unidirectional stream of unicast fragmented IP/UDP\n   traffic, targeting\
    \ a server attached to either the protected or DMZ\n   segment. The test instrument\
    \ MUST offer the unidirectional stream\n   over the duration of the test, that\
    \ is, duration over which the HTTP\n   traffic is being offered.\n   Baseline\
    \ measurements SHOULD be performed with IP filtering deny\n   rule(s) to filter\
    \ fragmented traffic.  If the DUT/SUT has logging\n   capability, the log SHOULD\
    \ be checked to determine if it contains the\n   correct information regarding\
    \ the fragmented traffic.\n   The test SHOULD be repeated with the DUT/SUT rule\
    \ set changed to\n   allow the fragmented traffic through.  When running multiple\n\
    \   iterations of the test, it is RECOMMENDED to vary the MTU while\n   keeping\
    \ all other parameters constant.\n   Then setup the DUT/SUT to the policy or rule\
    \ set the manufacturer\n   required to be defined to protect against fragmentation\
    \ attacks and\n   repeat the measurements outlined in the baseline procedures.\n"
- title: 5.9.4 Measurements
  contents:
  - "5.9.4 Measurements\n   Test instrument SHOULD perform the same measurements as\
    \ defined in\n   HTTP test (Section 5.6.4).\n   Transmitted UDP/IP Packets:\n\
    \      Number of UDP packets transmitted by client.\n   Received UDP/IP Packets:\n\
    \      Number of UDP/IP Packets received by server.\n"
- title: 5.9.5 Reporting Format
  contents:
  - '5.9.5 Reporting Format

    '
- title: 5.9.5.1 Non-Fragmented Traffic
  contents:
  - "5.9.5.1 Non-Fragmented Traffic\n   The test report SHOULD be the same as described\
    \ in section 5.6.5.\n   Note that any forwarding rate measurements for the HTTP\
    \ traffic\n   excludes any bits associated with the fragmented traffic which may\
    \ be\n   forward by the DUT/SUT.\n"
- title: 5.9.5.2 Fragmented Traffic
  contents:
  - "5.9.5.2 Fragmented Traffic\n   The test report MUST note the packet size, MTU\
    \ size, intended load,\n   number of UDP/IP packets transmitted and number of\
    \ UDP/IP packets\n   forwarded.  The test report SHOULD also note whether or not\
    \ the\n   DUT/SUT forwarded the offered UDP/IP traffic fragmented.\n"
- title: 5.10 Latency
  contents:
  - '5.10 Latency

    '
- title: 5.10.1 Objective
  contents:
  - "5.10.1 Objective\n   To determine the latency of network-layer or application-layer\
    \ data\n   traversing the DUT/SUT. RFC 1242 [3] defines latency.\n"
- title: 5.10.2 Setup Parameters
  contents:
  - "5.10.2 Setup Parameters\n   The following parameters MUST be defined:\n"
- title: 5.10.2.1 Network-layer Measurements
  contents:
  - "5.10.2.1 Network-layer Measurements\n   Packet size, expressed as the number\
    \ of bytes in the IP packet,\n   exclusive of link-layer headers and checksums.\n\
    \   Intended load, expressed as percentage of media utilization.\n   Test duration,\
    \ expressed in seconds.\n   The test instruments MUST generate packets with unique\
    \ timestamp\n   signatures.\n"
- title: 5.10.2.2 Application-layer Measurements
  contents:
  - "5.10.2.2 Application-layer Measurements\n   Object Size:\n      Defines the number\
    \ of bytes, excluding any bytes associated with\n      the HTTP header, to be\
    \ transferred in response to an HTTP 1.1 or\n      higher GET request.  The minimum\
    \ object size supported by the\n      media SHOULD be used, but other object sizes\
    \ MAY be used as well.\n   Connection type:\n      The test instrument MUST use\
    \ one HTTP 1.1 or higher connection for\n      latency measurements.\n   Number\
    \ of objects requested.\n   Number of objects transferred.\n   Test duration,\
    \ expressed in seconds.\n   Test instruments MUST generate packets with unique\
    \ timestamp\n   signatures.\n"
- title: 5.10.3 Network-layer procedure
  contents:
  - "5.10.3 Network-layer procedure\n   A client will offer a unidirectional stream\
    \ of unicast packets to a\n   server.  The packets MUST use a connectionless protocol\
    \ like IP or\n   UDP/IP.\n   The test instrument MUST offer packets in a steady\
    \ state.  As noted\n   in the latency discussion in RFC 2544 [2], latency measurements\
    \ MUST\n   be taken at the throughput level, that is, at the highest offered\n\
    \   load with zero packet loss.  Measurements taken at the throughput\n   level\
    \ are the only ones that can legitimately be termed latency.\n   It is RECOMMENDED\
    \ that implementers use offered loads not only at the\n   throughput level, but\
    \ also at load levels that are less than or\n   greater than the throughput level.\
    \  To avoid confusion with existing\n   terminology, measurements from such tests\
    \ MUST be labeled as delay\n   rather than latency.\n   It is RECOMMENDED to perform\
    \ the latency measurements with different\n   packet sizes.  When testing with\
    \ different packet sizes the DUT/SUT\n   configuration MUST remain the same.\n\
    \   If desired, a step test MAY be used in which offered loads increment\n   or\
    \ decrement through a range of load levels.\n   The duration of the test portion\
    \ of each trial MUST be at least 30\n   seconds.\n"
- title: 5.10.4 Application layer procedure
  contents:
  - "5.10.4 Application layer procedure\n   An HTTP 1.1 or higher client will request\
    \ one or more objects from an\n   HTTP 1.1 or higher server using one or more\
    \ HTTP GET requests.  If\n   the test instrument makes multiple HTTP GET requests,\
    \ it MUST request\n   the same-sized object each time.  Multiple iterations of\
    \ this test\n   may be performed with objects of different sizes.\n   Implementers\
    \ MAY configure the test instrument to run for a fixed\n   duration.  In this\
    \ case, the test instrument MUST report the number\n   of objects requested and\
    \ returned for the duration of the test.  For\n   fixed-duration tests it is RECOMMENDED\
    \ that the duration be at least\n   30 seconds.\n"
- title: 5.10.5 Measurements
  contents:
  - "5.10.5 Measurements\n   Minimum delay:\n      The smallest delay incurred by\
    \ data traversing the DUT/SUT at the\n      network layer or application layer,\
    \ as appropriate.\n   Maximum delay:\n      The largest delay incurred by data\
    \ traversing the DUT/SUT at the\n      network layer or application layer, as\
    \ appropriate.\n   Average delay:\n      The mean of all measurements of delay\
    \ incurred by data traversing\n      the DUT/SUT at the network layer or application\
    \ layer, as\n      appropriate.\n   Delay distribution:\n      A set of histograms\
    \ of all delay measurements observed for data\n      traversing the DUT/SUT at\
    \ the network layer or application layer,\n      as appropriate.\n"
- title: 5.10.6 Network-layer reporting format
  contents:
  - "5.10.6 Network-layer reporting format\n   The test report MUST note the packet\
    \ size(s), offered load(s) and\n   test duration used. In addition, the test report\
    \ MUST conform to the\n   reporting requirements set in section 4, Test Setup.\n\
    \   The latency results SHOULD be reported in the format of a table with\n   a\
    \ row for each of the tested packet sizes.  There SHOULD be columns\n   for the\
    \ packet size, the intended rate, the offered rate, and the\n   resultant latency\
    \ or delay values for each test.\n"
- title: 5.10.7 Application-layer reporting format
  contents:
  - "5.10.7 Application-layer reporting format\n   The test report MUST note the object\
    \ size(s) and number of requests\n   and responses completed.  If applicable,\
    \ the report MUST note the\n   test duration if a fixed duration was used. In\
    \ addition, the test\n   report MUST conform to the reporting requirements set\
    \ in section 4,\n   Test Setup.\n   The latency results SHOULD be reported in\
    \ the format of a table with\n   a row for each of the object sizes.  There SHOULD\
    \ be columns for the\n   object size, the number of completed requests, the number\
    \ of\n   completed responses, and the resultant latency or delay values for\n\
    \   each test.\n   Failure analysis:\n      The test report SHOULD indicate the\
    \ number and percentage of HTTP\n      GET request or responses that failed to\
    \ complete within the test\n      duration.\n   Version information:\n      The\
    \ test report MUST note the version of HTTP client and server.\n"
- title: 6. References
  contents:
  - '6. References

    '
- title: 6.1  Normative References
  contents:
  - "6.1  Normative References\n   [1]  Newman, D., \"Benchmarking Terminology for\
    \ Firewall Devices\", RFC\n        2647, August 1999.\n   [2]  Bradner, S. and\
    \ J. McQuaid, \"Benchmarking Methodology for\n        Network Interconnect Devices\"\
    , RFC 2544, March 1999.\n   [3]  Bradner, S., \"Benchmarking Terminology for Network\n\
    \        Interconnection Devices\", RFC 1242, July 1991.\n   [4]  Mandeville,\
    \ R., \"Benchmarking Terminology for LAN Switching\n        Devices\", RFC 2285,\
    \ February 1998.\n   [5]  Mandeville, R. and J. Perser, \"Benchmarking Methodology\
    \ for LAN\n        Switching Devices\", RFC 2889, August 2000.\n"
- title: 6.2  Informative References
  contents:
  - "6.2  Informative References\n   [6]  Fielding, R., Gettys, J., Mogul, J., Frystyk,\
    \ H., Masinter, L.,\n        Leach, P. and T. Berners-Lee, \"Hypertext Transfer\
    \ Protocol -\n        HTTP/1.1\", RFC 2616, June 1999.\n   [7]  Clark, D., \"\
    IP Datagram Reassembly Algorithm\", RFC 815, July\n        1982.\n   [8]  Postel,\
    \ J., \"Transmission Control Protocol\", STD 7, RFC 793,\n        September 1981.\n"
- title: 7. Security Considerations
  contents:
  - "7. Security Considerations\n   The primary goal of this document is to provide\
    \ methodologies in\n   benchmarking firewall performance. While there is some\
    \ overlap\n   between performance and security issues, assessment of firewall\n\
    \   security is outside the scope of this document.\n"
- title: 'APPENDIX A: HTTP (HyperText Transfer Protocol)'
  contents:
  - "APPENDIX A: HTTP (HyperText Transfer Protocol)\n   The most common versions of\
    \ HTTP in use today are HTTP/1.0 and\n   HTTP/1.1 with the main difference being\
    \ in regard to persistent\n   connections.  HTTP 1.0, by default, does not support\
    \ persistent\n   connections.  A separate TCP connection is opened up for each\
    \ GET\n   request the client wants to initiate and closed after the requested\n\
    \   object transfer is completed.  While some implementations HTTP/1.0\n   supports\
    \ persistence through the use of a keep-alive, there is no\n   official specification\
    \ for how the keep-alive operates. In addition,\n   HTTP 1.0 proxies do support\
    \ persistent connection as they do not\n   recognize the connection header.\n\
    \   HTTP/1.1, by default, does support persistent connection and is\n   therefore\
    \ the version that is referenced in this methodology. Proxy\n   based DUT/SUTs\
    \ may monitor the TCP connection and after a timeout,\n   close the connection\
    \ if no activity is detected.  The duration of\n   this timeout is not defined\
    \ in the HTTP/1.1 specification and will\n   vary between DUT/SUTs.  If the DUT/SUT\
    \ closes inactive connections,\n   the aging timer on the DUT SHOULD be configured\
    \ for a duration that\n   exceeds the test time.\n   While this document cannot\
    \ foresee future changes to HTTP and it\n   impact on the methodologies defined\
    \ herein, such changes should be\n   accommodated for so that newer versions of\
    \ HTTP may be used in\n   benchmarking firewall performance.\n"
- title: 'APPENDIX B: Connection Establishment Time Measurements'
  contents:
  - "APPENDIX B: Connection Establishment Time Measurements\n   Some connection oriented\
    \ protocols, such as TCP, involve an odd\n   number of messages when establishing\
    \ a connection.  In the case of\n   proxy based DUT/SUTs, the DUT/SUT will terminate\
    \ the connection,\n   setting up a separate connection to the server.  Since,\
    \ in such\n   cases, the test instrument does not own both sides of the connection,\n\
    \   measurements will be made two different ways.  While the following\n   describes\
    \ the measurements with reference to TCP, the methodology may\n   be used with\
    \ other connection oriented protocols which involve an odd\n   number of messages.\n\
    \   When testing non-proxy based DUT/SUTs , the establishment time shall\n   be\
    \ directly measured and is considered to be from the time the first\n   bit of\
    \ the first SYN packet is transmitted by the client to the time\n   the last bit\
    \ of the final ACK in the three-way handshake is received\n   by the target server.\n\
    \   If the DUT/SUT is proxy based, the connection establishment time is\n   considered\
    \ to be from the time the first bit of the first SYN packet\n   is transmitted\
    \ by the client to the time the client transmits the\n   first bit of the first\
    \ acknowledged TCP datagram (t4-t0 in the\n   following timeline).\n      t0:\
    \ Client sends a SYN.\n      t1: Proxy sends a SYN/ACK.\n      t2: Client sends\
    \ the final ACK.\n      t3: Proxy establishes separate connection with server.\n\
    \      t4: Client sends TCP datagram to server.\n      *t5: Proxy sends ACK of\
    \ the datagram to client.\n   * While t5 is not considered part of the TCP connection\n\
    \   establishment, acknowledgement of t4 must be received for the\n   connection\
    \ to be considered successful.\n"
- title: 'APPENDIX C: Connection Tear Down Time Measurements'
  contents:
  - "APPENDIX C: Connection Tear Down Time Measurements\n   While TCP connections\
    \ are full duplex, tearing down of such\n   connections are performed in a simplex\
    \ fashion, that is, FIN segments\n   are sent by each host/device terminating\
    \ each side of the TCP\n   connection.\n   When making connection tear down times\
    \ measurements, such\n   measurements will be made from the perspective of the\
    \ entity, that\n   is, virtual client/server initiating the connection tear down\n\
    \   request.  In addition, the measurement will be performed in the same\n   manner,\
    \ independent of whether or not the DUT/SUT is proxy-based. The\n   connection\
    \ tear down will be considered the interval between the\n   transmission of the\
    \ first bit of the first TCP FIN packet transmitted\n   by the virtual client\
    \ or server, whichever is applicable, requesting\n   a connection tear down to\
    \ receipt of the last bit of the\n   corresponding ACK packet on the same virtual\
    \ client/server interface.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Brooks Hickman\n   Spirent Communications\n   26750 Agoura\
    \ Road\n   Calabasas, CA 91302\n   USA\n   Phone: + 1 818 676 2412\n   EMail:\
    \ brooks.hickman@spirentcom.com\n   David Newman\n   Network Test Inc.\n   31324\
    \ Via Colinas, Suite 113\n   Westlake Village, CA 91362-6761\n   USA\n   Phone:\
    \ + 1 818 889-0011\n   EMail: dnewman@networktest.com\n   Saldju Tadjudin\n  \
    \ Spirent Communications\n   26750 Agoura Road\n   Calabasas, CA 91302\n   USA\n\
    \   Phone: + 1 818 676 2468\n   EMail: Saldju.Tadjudin@spirentcom.com\n   Terry\
    \ Martin\n   GVNW Consulting Inc.\n   8050 SW Warm Springs Road\n   Tualatin Or.\
    \ 97062\n   USA\n   Phone: + 1 503 612 4422\n   EMail: tmartin@gvnw.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2003).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
