- title: __initial_text__
  contents:
  - "             Something a Host Could Do with Source Quench:\n               The\
    \ Source Quench Introduced Delay (SQuID)\n"
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo is intended to explore the issue of what a\
    \ host could do\n   with a source quench.  The proposal is for each source host\
    \ IP module\n   to introduce some delay between datagrams sent to the same\n \
    \  destination host.  This is an \"crazy idea paper\" and discussion is\n   essential.\
    \  Distribution of this memo is unlimited.\n"
- title: Introduction
  contents:
  - "Introduction\n   A gateway may discard Internet datagrams if it does not have\
    \ the\n   buffer space needed to queue the datagrams for output to the next\n\
    \   network on the route to the destination network.  If a gateway\n   discards\
    \ a datagram, it may send a source quench message to the\n   Internet source host\
    \ of the datagram.  A destination host may also\n   send a source quench message\
    \ if datagrams arrive too fast to be\n   processed.  The source quench message\
    \ is a request to the host to cut\n   back the rate at which it is sending traffic\
    \ to the Internet\n   destination.  The gateway may send a source quench message\
    \ for every\n   message that it discards.  On receipt of a source quench message,\
    \ the\n   source host should cut back the rate at which it is sending traffic\n\
    \   to the specified destination until it no longer receives source\n   quench\
    \ messages from the gateway.  The source host can then gradually\n   increase\
    \ the rate at which it sends traffic to the destination until\n   it again receives\
    \ source quench messages [1,2].\n   The gateway or host may send the source quench\
    \ message when it\n   approaches its capacity limit rather than waiting until\
    \ the capacity\n   is exceeded.  This means that the data datagram which triggered\
    \ the\n   source quench message may be delivered.\n"
- title: The SQuID Concept
  contents:
  - "The SQuID Concept\n   Suppose the IP module at the datagram source has a queue\
    \ of datagrams\n   to send, and the IP module has a parameter \"D\".  D is the\
    \ introduced\n   delay between sending datagrams from the queue to the network.\
    \  That\n   is, when the IP module discovers a datagram waiting to be sent to\
    \ the\n   network, it sends it to the network then waits time D before even\n\
    \   looking at the datagram queue again.  Normally, the value of D is\n   zero.\n\
    \   Imagine that when a source quench is received (or any other signal is\n  \
    \ received that the host should slow down its transmissions to the\n   network),\
    \ the value of D is increased.  As time goes by, the value of\n   D is decreased.\n"
- title: The SQuID Algorithm
  contents:
  - "The SQuID Algorithm\n          on increase event:\n               D <-- maximum\
    \ (D + K, I)\n                                        (where K = .020 second,\n\
    \                                               I = .075 second)\n          on\
    \ decrease event:\n               D <-- maximum (D - J, 0)\n                 \
    \                       (where J = .001 second)\n   An increase event is receipt\
    \ of one or more source quenches in a\n   event period E, (where E is 2.000 seconds).\n\
    \   A decrease event is when S time has passed since D was decreased and\n   there\
    \ is a datagram to send (where S is 1.000 seconds).\n   A cache of D's is kept\
    \ for the last M hosts communicated with.\n   Note that when no datagrams are\
    \ sent to a destination for some time\n   the D for that destination is not decreased,\
    \ but, if a destination is\n   not used for a long time that D for that destination\
    \ may fall out of\n   the cache.\n"
- title: Possible Refinements
  contents:
  - "Possible Refinements\n   Keep a separate outgoing queue of datagrams for each\
    \ destination\n   host, local subnet, or network.\n   Keep the cache of D's per\
    \ network or local subnet, instead of per\n   host.\n   \"I\" could be based upon\
    \ the basic speed of the slowest intervening\n   network (see Appendix A).\n \
    \  \"D\" could be limited to never go below \"I\" if the above refinement\n  \
    \ were implemented.\n   \"S\" could be based upon the round trip time.\n   \"\
    D\" could be adjusted datagram by datagram based upon the length of\n   the datagrams.\
    \  Wait longer after a long datagram.\n   The delay algorithm could be implemented\
    \ such that if a source\n   doesn't send a datagram when it is next allowed (the\
    \ introduced delay\n   interval) or for N such intervals that the source gets\
    \ a credit for\n   one and only one free (no delay) datagram.\n"
- title: Implementation Ideas
  contents:
  - "Implementation Ideas\n   Since IP does not normally keep much state information\
    \ about things,\n   we want the default or idle IP to have no state about these\
    \ D values.\n   Since the default D value is zero, let us propose that the IP\
    \ will\n   keep a list of only those destinations with non zero D's.\n   When\
    \ the IP wants to send a datagram, it searches the D-list to see\n   if the destination\
    \ is noted.  If it is not, the D value is zero, so\n   the IP sends the datagram\
    \ at once.  If the destination is listed, the\n   IP must wait D time indicated\
    \ before sending that particular\n   datagram.  It could look at a datagram addressed\
    \ to a different\n   destination, and possibly send it in the mean time.\n   When\
    \ the IP receives a source quench, it checks to see if the\n   destination in\
    \ the datagram that caused the source quench is on the\n   list.  If so, it adds\
    \ K to the D value.  If not, it appends the\n   destination to the list with the\
    \ D value set to \"I\".\n"
- title: A Closer Look At the Problem
  contents:
  - "A Closer Look At the Problem\n   Some implementations of IP send one SQ for every\
    \ N datagrams they\n   discard (for example, N=20) so the SQ messages will not\
    \ make the\n   congestion problem much worse [3].  In such situations any of the\n\
    \   sources of the 20 datagrams may get the SQ not necessarily the one\n   causing\
    \ the most traffic.  However if a host continues to send\n   datagrams at a high\
    \ rate it has a high probability of receiving a SQ\n   message sooner or later.\
    \  It is much like a speeder on a highway.\n   Not all speeders get speeding tickets\
    \ but the ones who speed most\n   often or most excessively are most likely to\
    \ be ticketed.  In this\n   case they will get a ticket and their car may be destroyed.\n\
    \   With memory becoming so inexpensive many IP nodes put an artificially\n  \
    \ low limit on the size of their queues so that through node delay will\n   not\
    \ be excessive [4].  For example, if one megabyte of data is\n   buffered to be\
    \ sent over a 56 kb/s line the last datagram will wait\n   over 2 minutes before\
    \ being sent.\n   One problem with SQ is that the IP or ICMP specification does\
    \ not\n   have a well defined event to indicate receipt of SQ to higher level\n\
    \   protocols.  Therefore many TCP implementations do not get notified\n   about\
    \ SQ events and thus do not react to SQ.  TCP is not the only\n   source of IP\
    \ datagrams either.  Other protocols should also respond\n   to SQ events in some\
    \ appropriate way.  TCP and other protocols at\n   that level should do something\
    \ about a source quench, however,\n   discussion of their behavior is beyond the\
    \ scope of this memo.  Note\n   that implementation of SQ processing at one level\
    \ of protocol should\n   not interfere with the behavior of higher level protocols.\
    \  This\n   however, is difficult to do.\n   For protocols using IP which are\
    \ trying to transfer large amounts of\n   data the data flow is most typically\
    \ very bursty.  TCP for example,\n   might send 5-10 segments into a window of\
    \ 5-10 K bytes then wait for\n   the acknowledgment of the data which opens the\
    \ window again.  NETBLT\n   as defined by RFC-998 is a rate based protocol which\
    \ has parameters\n   for burst size and burst rate.\n   One purpose of the bursts\
    \ is to allow the source computer to generate\n   several datagrams at once to\
    \ provide more efficient scheduling.  An\n   other reason is to keep the network\
    \ busy accepting data to maximize\n   effective throughput in spite of a potentially\
    \ large network round\n   trip delay.  To send a datagram then wait for an acknowledgment\
    \ is a\n   simple but not efficient protocol on a large wide area network.\n \
    \  The reasons for efficiencies obtained at the source node by\n   generating\
    \ many datagrams at once are not as applicable in an\n   intermediate IP node.\
    \  Since each datagram is potentially from a\n   different node they must all\
    \ be treated individually.  Datagrams\n   received in a burst may also overload\
    \ the queue of an intermediate\n   node losing datagrams and causing SQs to be\
    \ generated.  If the queue\n   is near a threshold and a burst comes, possibly\
    \ all of the datagrams\n   will be lost.  When datagrams arrive evenly spaced,\
    \ less datagrams\n   are likely to be lost because the inter-arrival time allows\
    \ the queue\n   a little time to empty out.  Therefore datagrams spaced with some\n\
    \   delay between them may be better for intermediate IP nodes.\n   Congestion\
    \ is most likely to occur at IP nodes which are gateways\n   between a slower\
    \ network and a faster one.  The congestion will be in\n   the send queue from\
    \ the slow network to the fast network.  An SQ\n   being returned to the sender\
    \ will return on the faster network.  (See\n   diagram below.)\n"
- title: A Gateway Source Quench Concept
  contents:
  - "A Gateway Source Quench Concept\n   In order for the SQuID algorithm to work\
    \ we rely upon the gateways to\n   send SQs to us to tell us how we are doing.\
    \  Because the loss of a\n   single datagram affects data flow so much (see lost\
    \ datagram\n   discussion in Observed Results below) it would be much better for\
    \ the\n   source IP node if it got a warning before datagrams were discarded.\n\
    \   We propose gateway IP nodes start SQing before the node is flooded at\n  \
    \ a level we call SQ Keep (SQK) but forward the datagram.  If the queue\n   level\
    \ reaches a critical level, SQ Toss level (SQT), the gateway\n   should toss datagrams\
    \ to resolve the problem unless the datagram is\n   an ICMP message.  Even ICMP\
    \ messages will be tossed if the MaxQ level\n   is reached.  Once the gateway\
    \ starts sending SQs it should continue\n   to do so until the queue level goes\
    \ below a low water mark level\n   (SQLW) as shown below.  This is analogous to\
    \ methods some operating\n   systems use to handle memory space management.\n\
    \   The gateway should try to send SQ to as many of the contributors of\n   the\
    \ congestion as possible but only once per contributor per second\n   or two.\n\
    \   Source Quench Queue Levels\n         +--------------+ MaxQ level\n       \
    \  |              |> datagrams tossed & SQed (but not ICMP msgs.)\n         +--------------+\
    \ SQT level (95%)\n         |              |\\\n         |              | > datagrams\
    \ SQed but forwarded\n         |              |/\n         +--------------+ SQK\
    \ level (70%)\n         |              |\\\n         |              | \\ datagrams\
    \ SQed but forwarded if SQK level\n         |              | / exceeded & SQLW\
    \ or lower not yet reached\n         |              |/\n         +--------------+\
    \ SQLW level (50%)\n         |              |\\\n         |              | \\\n\
    \         |              |  \\\n         |              |   \\ datagrams forwarded\n\
    \         |              |   /\n         |              |  /\n         |     \
    \         | /\n         |              |/\n         +--------------+\n"
- title: Description of the Test Model
  contents:
  - "Description of the Test Model\n   We needed some way of testing our algorithm\
    \ and its various\n   parameters.  It was important to check the interaction between\
    \ IP\n   with the SQuID algorithm and TCP.  We also wanted to try various\n  \
    \ combinations of retransmission strategy and source quench strategy\n   which\
    \ required control of the entire test network.  We therefore\n   decided to build\
    \ an Internet model.\n   Using this example configuration for illustration:\n\
    \ _______    LAN       _______     WAN      _______     LAN      _______\n"
- title: '|   1   |            |   2   |            |   3   |            |   4   |'
  contents:
  - '|   1   |            |   2   |            |   3   |            |   4   |

    '
- title: '|TCP/IP |---10 Mb/s--|  IP   |---56 kb/s--|  IP   |---10 Mb/s--|TCP/IP |'
  contents:
  - '|TCP/IP |---10 Mb/s--|  IP   |---56 kb/s--|  IP   |---10 Mb/s--|TCP/IP |

    '
- title: '|_______|            |_______|            |_______|            |_______|'
  contents:
  - "|_______|            |_______|            |_______|            |_______|\n  \
    \ A program was written in C which created queues and structures to put\n   on\
    \ the queues representing datagrams carrying data, acknowledgments\n   and SQs.\
    \  The program moved datagrams from one queue to the next\n   based upon rules\
    \ defined below\n   A client fed the TCP in node 1 data at the rate it would accept.\
    \  The\n   TCP function in node 1 would chop the data up into fixed 512 byte\n\
    \   datagrams for transmission to the IP in node 1.  When the datagrams\n   were\
    \ given to IP for transmission, a timestamp was put on it and a\n   copy of it\
    \ was put on a TCP ack-wait queue (data sent but not yet\n   acknowledged).  In\
    \ particular TCP assumed that once it handed data to\n   IP, the data was sent\
    \ immediately for purposes of retransmission\n   timeouts even though our algorithm\
    \ has IP add delay before\n   transmission.\n   Each IP node had one queue in\
    \ each direction (left and right).  For\n   each IP in the model IP would forward\
    \ datagrams at the rate of the\n   communications line going to the next node.\
    \  Thus the fifth datagram\n   on IP 2's queue going right would take 5 X 73 msec\
    \ or 365 msec before\n   it would appear at the end of IP 3's queue.  The time\
    \ to process each\n   datagram was considered to be less than the time it took\
    \ for the data\n   to be sent over the 56 kb/s lines and therefore done during\
    \ those\n   transmission times and not included in the model.  For the LAN\n \
    \  communications this is not the case but since they were not at the\n   bottleneck\
    \ of the path this processing time was ignored.  However\n   because LAN communications\
    \ are typically shared band width, the LAN\n   band width available to each IP\
    \ instance was considered to be 1 Mb/s,\n   a crude approximation.\n   When the\
    \ data arrived at node 4 the data was immediately given to the\n   TCP receive\
    \ function which validated the sequence number.  If the\n   datagram was in sequence\
    \ the datagram was turned into an ack datagram\n   and sent back to the source.\
    \  An ack datagram carries no data and\n   will move the right edge of the window,\
    \ the window size past the just\n   acked data sequence number.  The ack datagram\
    \ is assumed to be 1/8 of\n   the length of a data datagram and thus can be transmitted\
    \ from one\n   node to the next 8 times faster.  If the sequence number is less\
    \ than\n   expected (a retransmission due to a missed ack) then it too is turned\n\
    \   into an ack.  A larger sequence number datagram is queued\n   indefinitely\
    \ until the missing datagrams are received.\n   We also modeled the gateway source\
    \ quench algorithm.  When a datagram\n   was put on an IP queue the number on\
    \ the queue was compared to an SQ\n   keep level (SQK).  If it was greater, an\
    \ SQ was generated and\n   returned to the sender. If it was larger than the SQ\
    \ toss (SQT) level\n   it was also discarded.  Once SQs were generated they would\
    \ continue\n   to be sent until the queue level went below SQ Low Water (SQLW)\
    \ level\n   which was below the original SQK level.  These percentages were\n\
    \   modifiable as were many parameters.  An SQ could be lost if it\n   exceeded\
    \ the maximum queue size (MaxQ), but a source quench was never\n   sent about\
    \ tossing a source quench.\n   Upon each transition from one node to the next,\
    \ the datagram was\n   vulnerable to datagram loss due to errors.  The loss rate\
    \ could be\n   set as M losses out of N datagrams sent, thus the model allowed\
    \ for\n   multi-datagram loss bursts or single datagram losses.  We used a\n \
    \  single datagram loss rate of 1 lost datagram per 300 datagrams sent\n   for\
    \ much of our testing.  While this may seem low for Internet\n   simulation, remember\
    \ it does not include losses due to congestion.\n   Some network parameters we\
    \ used were a maximum queue length of 15\n   datagrams per IP direction left and\
    \ right.  We started sending SQ if\n   the queue was 70% full, SQK level, tossed\
    \ data datagrams, but not SQ\n   datagrams, if 95% of the queue was reached, SQT\
    \ level, and stopped\n   SQing when a 50% SQLW level was reached (see above).\n\
    \   We ignored additional SQs for 2 seconds after receipt of one SQ.\n   This\
    \ was done because some Internet nodes only send one SQ for every\n   20 datagrams\
    \ they discard even though our model sent SQs for every\n   datagram discarded.\
    \  Other IP node may send one SQ per discarded\n   packet. The SQuID algorithm\
    \ needed a way to handle both types of SQ\n   generation.  We therefore treated\
    \ one or a burst of SQs as a single\n   event and incremented our D by a larger\
    \ amount than would be\n   appropriate for responding individually to the multiple\
    \ SQs of the\n   verbose nodes.\n   The simulation did not do any fragmenting\
    \ of datagrams.  Silly window\n   syndrome was avoided.  The model did not implement\
    \ nor simulate the\n   TTL (time-to-live) function.\n   The model allowed for\
    \ a flexible topology definition with many TCP\n   source/destination pairs on\
    \ host IP nodes or gateway IP nodes with\n   various windows allowed.  An IP node\
    \ could have any number of TCPs\n   assigned to it.  Each line could have an individually\
    \ set speed.  Any\n   TCP could send to any other TCP.  The routing from one location\
    \ to\n   another was fixed.  Therefore datagrams did not arrive out of\n   sequence.\
    \  However, datagrams arrived in ascending order, but not\n   consecutively, on\
    \ a regular basis because of datagram losses.\n   Datagrams going \"left\" through\
    \ a node did not affect the queue size,\n   or SQ chances, of data going \"right\"\
    \ through the node.\n   The TCP retransmission timer algorithm used an Alpha of\
    \ .15 and a\n   Beta of 1.5.  The test was run without the benefit of the more\n\
    \   sophisticated retransmission timer algorithm proposed by Van Jacobson\n  \
    \ [5].\n   The program would display either the queue sizes of the various IP\n\
    \   nodes and the TCP under test as time passed or do a crude plot of\n   various\
    \ parameters of interest including SRTT, perceived round trip\n   time, throughput,\
    \ and the critical queue size.\n   As we observed the effects of various algorithms\
    \ for responding to SQ\n   we adapted our model to better react to SQ.  Initial\
    \ tests showed if\n   we incremented slowly and decremented quickly we observed\n\
    \   oscillations around the correct value but more of the time was spent\n   over\
    \ driving the network, thus losing datagrams, than at a value\n   which helped\
    \ the congestion situation.\n   A significant problem is the delay between when\
    \ some intermediate\n   node starts dropping datagrams and sending source quenches\
    \ to the\n   time when the source quenches arrive at the source host and can begin\n\
    \   to effect the behavior at the data source.  Because of this and the\n   possibility\
    \ that a IP might send only one SQ for each 20 datagrams\n   lost, we decided\
    \ that the increase in D per source quench should be\n   substantial (for example,\
    \ D should increase by 20 msec for every\n   source quench), and the decrease\
    \ with time should be very slow (for\n   example, D should decrease 1 msec every\
    \ second).  Note that this is\n   the opposite behavior than suggested in an early\
    \ draft by one of the\n   authors.\n   However, when many source quenches are\
    \ received (for example, when a\n   source quench is received for every datagram\
    \ dropped) in a short time\n   period the D value is increased excessively.  To\
    \ prevent D from\n   growing too large, we decided to ignore subsequent source\
    \ quenches\n   for a time (for example, 2 seconds) once we had increased D.\n\
    \   Tests were run with only one TCP sending data to learn as much as\n   possible\
    \ how an unperturbed session might run.  Other test runs would\n   introduce and\
    \ eliminate competing traffic dynamically between other\n   TCP instances on the\
    \ various nodes to see how the algorithms reacted\n   to changes in network load.\
    \  A potential flaw in the model is that\n   the defined TCPs with open windows\
    \ always tried to forward data.\n   Their clients feeding them data never paused\
    \ to think what they were\n   going to type nor got swapped out in favor of other\
    \ applications nor\n   turned the session around logically to listen to the other\
    \ end for\n   more user commands.  In other words all of the simulated TCP sessions\n\
    \   were doing file transfers.\n   The model was defined to allow many mixes of\
    \ competing algorithms for\n   responding to SQ.  It allowed comparing effective\
    \ throughput between\n   TCPs with small windows and large windows and those whose\
    \ IP would\n   introduce inter-datagram delays and those who totally ignored SQ.\
    \  It\n   also allowed comparisons with various inter-datagram increment\n   amounts\
    \ and decrement amounts.  Because of the number of possible\n   configurations\
    \ and parameter combinations only a few combinations of\n   parameters were tested.\
    \ It is hoped they were the most appropriate\n   ones upon which to concentrate.\n"
- title: Observed Results
  contents:
  - "Observed Results\n   All of our algorithms oscillate, some worse than others.\n\
    \   If we put in just the right amount of introduced delay we seem to get\n  \
    \ the best throughput.  But finding the right amount is not easy.\n   Throughput\
    \ is adversely affected, heavily, by a single lost datagram\n   at least for the\
    \ short time.  Examine what happens when a window is\n   35 datagrams wide with\
    \ an average round trip delay of 2500 msec using\n   512 byte datagrams when a\
    \ single datagram is lost at the beginning.\n   Thirty five datagrams are given\
    \ by TCP to IP and a timer is started\n   on the first datagram.  Since the first\
    \ datagram is missing, the\n   receiving TCP will not sent an acknowledgment but\
    \ will buffer all 34\n   of the out-of-sequence datagrams.  After 1.5 X 2500 msec,\
    \ or 3750\n   msec, have elapsed the datagram times out and is resent.  It arrives\n\
    \   and is acked, along with the other 34, 2500 msec later.  Before the\n   lost\
    \ datagram we might have been sending at the average rate a 56\n   kb/s line could\
    \ accept, about one every 75 msec.  After loss of the\n   datagram we send at\
    \ the rate of one in 6250 msec over 83 times\n   slower.\n   If the lost datagram\
    \ in the above example is other than the first\n   datagram the situation becomes\
    \ the same when all of the datagrams\n   before the lost datagram are acknowledged.\
    \  The example holds true\n   then for any single lost datagram in the window.\n\
    \   When SQ doesn't always cause datagram loss the sender continues to\n   send\
    \ too fast (queue size oscillates a lot).  It is important for the\n   SQ to cause\
    \ feed-back into the sending system as soon as possible,\n   therefore when the\
    \ source host IP receives an SQ it must make\n   adjustments to the send rate\
    \ for the datagrams still on the send\n   queue not just datagrams IP is requested\
    \ to send after the SQ.\n   Through network delay goes up as the network queue\
    \ lengths go up.\n   Window size affect the chance of getting SQed.  Look at our\
    \ model\n   above using a queue level of 15 for node 2 before SQs are generated\n\
    \   and a window size of 20 datagrams.  We assumed that we could send\n   data\
    \ over the LAN at a sustained average rate of 1 Mb/s or about 18\n   times as\
    \ fast as over the WAN.  When TCP sends a burst of 20\n   datagrams to node 1\
    \ they make it to node 2 in 81 msec.  The\n   transition time from node 2 to node\
    \ 3 is 73 msec, therefore, in 81\n   msec, only one datagram is forwarded to node\
    \ 3.  Thus the 17th, 18th,\n   19th, and 20th datagram are lost every time we\
    \ send a whole window.\n   More are lost when the queue is not empty.  If a sequence\
    \ of acks\n   come back in response to the sent data, the acks tend to return\
    \ at\n   the rate at which data can traverse the net thus pacing new send data\n\
    \   by opening the window at the rate which the network can accept it.\n   However\
    \ as soon as one datagram is lost all of the subsequent acks\n   are deferred\
    \ and batched until receipt of the missing data block\n   which acks all of the\
    \ datagrams and opens the window to 20 again.\n   This causes the max queue size\
    \ to be exceeded again.\n   If we assume a window smaller than the max queue size\
    \ in the\n   bottleneck node, any time we send a window's worth of data, it is\n\
    \   done independently of the current size of the queue.  The larger the\n   send\
    \ window, the larger a percentage of the stressed queue we send.\n   If we send\
    \ 50% of the stressed queue size any time that queue is more\n   than 50% we threaten\
    \ to overflow the queue.  Evenly spaced single\n   datagram bursts have the least\
    \ chance of overflowing the queue since\n   they represent the minimum percentage\
    \ of the max queue one may send.\n   When a big window opens up (that is, a missing\
    \ datagram at the head\n   of a 40 datagram send queue gets retransmitted and\
    \ acked), the\n   perceived round trip time for datagrams subsequently sent hits\
    \ a\n   minimum value then goes up linearly.  The SRTT goes down then back up\n\
    \   in a nice smooth curve.  This is caused by the fact IP will not add\n   delay\
    \ if the queue is empty and IP has not sent any datagrams to the\n   destination\
    \ for our introduced delay time.  But as many datagrams are\n   added to the IP\
    \ pre-staged send queue in bursts all have the same\n   send time as far as TCP\
    \ is concerned.  IP will delay each datagram on\n   the head of the queue by the\
    \ introduced delay amount.  The first may\n   be undelayed as just described but\
    \ all of the others are delayed by\n   their ordinal number on the queue times\
    \ the introduced delay amount.\n   It seems as though in a race between a TCP\
    \ session which delays\n   sending to IP and one who does not, the delayer will\
    \ get better\n   throughput because less datagrams are lost.  The send window\
    \ may also\n   be increased to keep the pipeline full.  If however the non delayer\n\
    \   uses windowing to reduce the chance of SQ datagram loss his\n   throughput\
    \ may possibly be better because no fair queuing algorithm\n   is in place.\n\
    \   If gateways send SQs early and don't toss data until its critical and\n  \
    \ keep sending SQs until a low water mark is hit, effective throughput\n   seems\
    \ to go up.\n   At the startup of our tests throughput was very high, then dropped\n\
    \   off quickly as the last of the window got clobbered.  Our model\n   should\
    \ have used a slow start up algorithm to minimize the startup\n   shock.  However\
    \ the learning curve to estimate the proper value for D\n   was probably quicker.\n\
    \   A large part of the perceived RTT is due to the delay getting off the\n  \
    \ TCP2IP (TCP transitional) queue when we used large windows.  If IP\n   would\
    \ invoke some back-pressure to TCP in a real implementation this\n   can be significantly\
    \ reduced.  Reducing the window would do this for\n   us at the expense of throughput.\n\
    \   After an SQ burst which tosses datagrams the sender gets in a mode\n   where\
    \ TCP may only send one or two datagrams per RTT until the queued\n   but not\
    \ acked segments fall into sequence and are acked.  This\n   assumes only the\
    \ head of the retransmission queue is retransmitted on\n   a timeout.  We can\
    \ send one datagram upon timeout.  When the ack for\n   the retransmission is\
    \ received the window opens allowing sending a\n   second.  We then wait for the\
    \ next lost datagram to time out.\n   If we stop sending data for a while but\
    \ allow D to be decreased, our\n   algorithm causes the introduced delay to dwindle\
    \ away.  We would thus\n   go through a new startup learning curve and network\
    \ oscillation\n   sequence.\n   One thing not observed often was TCP timing out\
    \ a segment before the\n   source IP even sent the datagram the first time.  As\
    \ discussed above\n   the first datagram on the queue of a large burst is delayed\
    \ minimally\n   and succeeding datagrams have linearly increasing delays.  The\n\
    \   smoothed round trip delay algorithm has a chance to adapt to the\n   perceived\
    \ increasing round trip times.\n"
- title: Unstructured Thoughts and Comments
  contents:
  - "Unstructured Thoughts and Comments\n   The further down a route a datagram traverses\
    \ before being clobbered\n   the greater the waste of network resources.  SQs\
    \ which do not destroy\n   the datagram referred to are better than ones that\
    \ do if return path\n   resources are available.\n   Any fix must be implementable\
    \ piecemeal.  A fix can not be installed\n   in all or most nodes at one time.\
    \  The SQuID algorithm fulfills this\n   requirement.  It could be implemented,\
    \ installed in one location, and\n   used effectively.\n   If it can be shown\
    \ that by using the new algorithm effective\n   throughput can be increased over\
    \ implementations which do not\n   implement it that may well be effective impetus\
    \ to get vendors to\n   implement it.\n   Once a source host has an established\
    \ average minimum inter-datagram\n   delay to a destination (see Appendix A),\
    \ this information should be\n   stored across system restarts.  This value might\
    \ be used each time\n   data is sent to the given host as a minimum inter-datagram\
    \ delay\n   value.\n   Window closing algorithms reduce the average inter-datagram\
    \ delay and\n   the burst size but do not affect the minimum inter-datagram spacing\n\
    \   by TCP.\n   Currently an IP gateway node can know if it is in a critical path\n\
    \   because its queues stay high or keep building up.  Its optimum queue\n   size\
    \ is one because it always has something to do and the through\n   node delay\
    \ is at a minimum.  It is very important that the gateway at\n   the critical\
    \ path not so discourage data flow that its queue size\n   drops to zero.  If\
    \ the gateway tosses datagrams this stops data flow\n   for TCP for a while (as\
    \ described in Observed Results above).  This\n   argues for the gateway algorithm\
    \ described above which SQs but does\n   not toss datagrams unless necessary.\
    \  Optimally we should try to have\n   a queue size somewhat larger than 1 but\
    \ less than say 50% of the max\n   queue size.  Large queues lead to large delay.\n\
    \   TCP's SRTT is made artificially large by introducing delay at IP but\n   the\
    \ perceived round trip time variance is probably smaller allowing a\n   smaller\
    \ Beta value for the timeout value.\n   So that a decrease timer is not needed\
    \ for the \"D\" decrease function,\n   upon the next sent datagram to a delayed\
    \ destination just decrease\n   the delay by the amount of time since we last\
    \ did this divided by the\n   decrease timer interval.  An alternate algorithm\
    \ would be to decrease\n   it by only one decrease unit amount if more than the\
    \ timer interval\n   has gone by.  This eliminates the problem caused by the delay,\
    \ \"D\",\n   dwindling away if we stop sending for a while.  The longer we send\n\
    \   using this \"D\", the more likely it is that it is too large a delay\n   and\
    \ the more we should decrease it.\n   It is better for the network and the sender\
    \ for our introduced delay\n   to be a little on the high side.  It minimizes\
    \ the chances of getting\n   a datagram clobbered by sending it into a congested\
    \ gateway.  A lost\n   datagram scenario described above showed that one lost\
    \ datagram can\n   reduce our effective delay by one to two orders of magnitude\n\
    \   temporarily.  Also if the delay is a little high, the net is less\n   stressed\
    \ and the queues get smaller, reducing through network delay.\n   The RTT experienced\
    \ at a given time verses the minimum RTT possible\n   for the given route does\
    \ give a good measure of congestion.  If we\n   ever get congestion control working\
    \ RTT may have little to do with\n   the amount of congestion.  Effective throughput\
    \ when compared with\n   the possible throughput (or some other measure) is the\
    \ only real\n   measure of congestion.\n   Slow startup of TCP is a good thing\
    \ and should be encouraged as an\n   additional mechanism for alleviating network\
    \ overload.\n   The network dynamics tends to bunch datagrams.  If we properly\
    \ space\n   data instead of bunching it like windowing techniques to control\n\
    \   overflow of queues then greater throughput is accomplished because\n   the\
    \ absolute rate we can send is pacing our sending not the RTT.  We\n   eliminate\
    \ \"stochastic bunching\" [6].\n   The longer the RTT the more network resources\
    \ the data takes to\n   traverse the net.\n   Should \"fair queuing\" say that\
    \ a longer route data transfer should\n   get less band width than a shorter one\
    \ (since it consumes more of the\n   net)?  Being fair locally on each node may\
    \ be unfair overall to\n   datagrams traversing many nodes.\n   If we solve congestion\
    \ problems today, we will start loading up the\n   net with more data tomorrow.\
    \  When this causes congestion in a year\n   will that type of congestion be harder\
    \ to solve than todays or is it\n   not our problem?  John Nagle suggests \"In\
    \ a large net, we may well\n   try to force congestion out to the fringes and\
    \ keep the interior of\n   the net uncongested by controlling entry to the net.\
    \  The IMP-based\n   systems work that way, or at least used to.  This has the\
    \ effect of\n   concentrating congestion at the entrance to the long-haul system.\n\
    \   That's where we want it; the Source Quench / congestion window / fair\n  \
    \ queuing set of strategies are able to handle congestion at the LAN to\n   WAN\
    \ bottleneck [7].  Our algorithm should try to push the network\n   congestion\
    \ out to the extremities and keep the interior network\n   congestion free.\n\
    \   Use of the algorithm is aesthetically appealing because the data is\n   sitting\
    \ in our local queue instead of consuming resources inside the\n   net.  We give\
    \ data to the network only when it is ready to accept it.\n   An averaged minimum\
    \ inter-datagram arrival value will give a measure\n   of the network bottleneck\
    \ speed at the receiver.  If the receiver\n   does not defer or batch together\
    \ acks the same would be learned from\n   the inter-datagram arrival time of the\
    \ acks.  A problem is that IP\n   doesn't have knowledge of the datagram contents.\
    \  However IP does\n   know from which host a datagram comes.\n   If SQuID limits\
    \ the size of its pre-net buffering properly (causes\n   back-pressure to TCP)\
    \ then artificially high RTT measurements would\n   not occur.\n   TCP might,\
    \ in the future, get a way to query IP for the current\n   introduced delay, D,\
    \ for a given destination and if the value is too\n   excessive abort or not start\
    \ a session.\n   With the new algorithm TCP could have an arbitrarily large window\
    \ to\n   send into without fear of over running queue sizes in intermediate\n\
    \   nodes (not that any TCP ever considered having this fear before).\n   Thus\
    \ it could have a window size which would allow it to always be\n   sending; keeping\
    \ the pipe full and seldom getting in the stop-and-\n   wait mode of sending.\
    \  This presupposes that the local IP is able to\n   cause some sort of back pressure\
    \ so that the local IPs queues are not\n   over run.  TCP would still be operating\
    \ in the burst mode of sending\n   but the local IP would be sending a datagram\
    \ for the TCP as often as\n   the network could accept it keeping the data flow\
    \ continuous though\n   potentially slow.\n   Experience implementing protocols\
    \ suggests avoiding timers in\n   protocols whenever possible.  IP, as currently\
    \ defined, does not use\n   timers. The SQuID algorithm uses two at the IP level.\
    \  A way to\n   eliminate the introduced delay decrease timer is to decrease the\
    \ D\n   value when we check the send queue for data to send.  We would\n   decrease\
    \ \"D\" by one \"J\" unit if \"S\" time, or more, has elapsed.  The\n   other\
    \ timer is not so easily eliminated.  If the IP implementation is\n   periodically\
    \ awakened to check for work to do, it could check the\n   time stamps of the\
    \ head of the queues to see if any datagrams have\n   waited long enough.  This\
    \ would mean we would necessarily wait too\n   long before sending, but it may\
    \ not be too large of a variance from\n   our desired rates.  The additional delay\
    \ would help congestion and\n   reduce our chances of SQ.  Another option is setting\
    \ a real timer\n   which is say 25-50% too large and hope that our periodic work\
    \ in IP\n   will allow us to notice a datagram is delayed enough, and send it.\n\
    \   Upon sending the datagram we would cancel the timer, avoiding the\n   timer\
    \ interrupt and environment swap.  In other implementations the\n   communications\
    \ interface or the link level protocol may be able to\n   provide the timing needed\
    \ without interrupts to the main processor.\n   Background tasks like some file\
    \ transfers could query IP for the\n   latest delay characteristics for a given\
    \ destination to determine if\n   it is appropriate to consume network resources\
    \ now or if it would be\n   better to wait until later.\n   We should consider\
    \ what would happen if IP, using the SQuID\n   algorithm, and TCP both introduced\
    \ delay between the datagrams.  If\n   TCPs delay was greater than IP's, then\
    \ when IP got the datagrams it\n   would forward them immediately as described\
    \ in the algorithm above.\n   This is because when the IP send queue is empty\
    \ and it has been at\n   least as long as IP wants the higher level protocol,\
    \ TCP, gets one\n   free (no delay) send.  Note also that IP will be decreasing\
    \ the\n   amount of delay it wants introduced because of the successful\n   transmissions\
    \ without SQs.  This would affect other protocols who\n   might also send to the\
    \ same destination.  If TCP sends too quickly\n   then IP will protect the network\
    \ from its indiscretion as described\n   in the basic algorithm however TCPs round\
    \ trip time estimates will be\n   much closer to reality.  A lost datagram will\
    \ thus be detected more\n   quickly.  If TCP also uses windowing to limit its\
    \ sending rate, it\n   might, because of its success with a smaller window, increase\
    \ the\n   window size increasing TCPs efficiency.\n   As this algorithm is implemented\
    \ everywhere, the SQ Keep (SQK) and SQ\n   Low Water (SQLW) queue level percentages\
    \ should be dropped to reduce\n   queue sizes and thus the through net delay.\
    \  The percentage we lower\n   SQK and SQLW to should be adjusted based upon the\
    \ percentage of time\n   the queue is empty.  The more the queue is empty the\
    \ more likely it\n   is that the node is discouraging data flow too much.  The\
    \ more time\n   the queue is not empty but not too full, the more likely it is\
    \ the\n   node is not excessively discouraging data flow.  How uniform the\n \
    \  queue size is, is a measure of how well the network citizens are\n   behaved.\n\
    \   As the congestion is pushed to the sources, gateways which are\n   bottlenecks\
    \ can more easily detect someone not playing by the rules\n   (sending datagrams\
    \ in bursts) and deal with the offender.\n"
- title: Appendix A -- Determination of the Value for the Parameter "I"
  contents:
  - "Appendix A -- Determination of the Value for the Parameter \"I\"\n   To get to\
    \ the correct value for the delay needed quickly, when an\n   event occurred and\
    \ the currently used delay was minimal, the\n   transmission time for an average\
    \ sized datagram across the slowest\n   communications link was used for a first\
    \ value.  How a real IP node\n   is to guess this value is discussed below.  In\
    \ our example the\n   transition between node 2 and node 3 is the bottleneck.\
    \ Using the 56\n   kb/s line, a 512 byte datagram would take 73 msec with no queuing\
    \ or\n   processing time is considered.  This value is defined to be the\n   minimum\
    \ inter-datagram arrival time (MIAT).  Assuming a perfect\n   network, ignoring\
    \ factors other than transmission speed, this is the\n   minimum time one could\
    \ expect between receipt of datagrams at the\n   destination, because of the slowed\
    \ data rate through the bottleneck.\n   This won't hold true if the datagrams\
    \ do not follow the same path.\n   The MIAT, minimum inter-datagram arrival time,\
    \ may be guessed at by\n   comparing the arrival timestamps of consecutive datagrams\
    \ from a\n   source of data.  Each value to be considered needs to be adjusted\
    \ up\n   or down based upon the size between the second datagram received and\n\
    \   the typical datagram size.  More simply stated, a datagram which is\n   half\
    \ the size of the average datagram can be transmitted across a\n   line in half\
    \ the time.  Therefore, double its IAT before considering\n   it for an MIAT.\
    \  If the timestamp of a datagrams is taken based upon\n   an event caused by\
    \ the start of the datagram arriving, not the\n   completion of the datagram arriving,\
    \ then the first datagram's size\n   is the limiting length and should be used\
    \ to adjust its IAT.  In\n   order to keep the algorithm simple, arrival times\
    \ for short datagram\n   could be ignored as could IATs which were orders of magnitude\
    \ too\n   large (see below).\n   Once a minimal value is found based upon looking\
    \ for small values\n   over a minute or more, the value might be time averaged\
    \ with a value\n   kept like TCP's SRTT in order to reduce the effects of a false\
    \ MIAT.\n   We could assume the limiting facility would be a 9.6 kb/s line, a\n\
    \   56-64 kb/s line, or a 1.5 Mb/s line.  These facilities would provide\n   a\
    \ MIAT of 427 msec, 73-64 msec, or 3 msec respectively, for a\n   datagram 512\
    \ bytes long.  These are almost orders of magnitude in\n   differences.  If the\
    \ MIAT a node measures is not in this range but\n   close, the value it is closest\
    \ to may be used for its MIAT from that\n   source.\n   One of the good things\
    \ about this measurement is that it is an\n   entirely passive measurement.  No\
    \ additional traffic is needed to\n   measure it.  If a source is not sending\
    \ data continuously then the\n   longer measured values won't be validated as\
    \ minimal values.  The\n   assumption is that at least sometimes the source will\
    \ send multiple\n   datagrams at a time.\n   The MIAT measurement is totally unaffected\
    \ by satellite delay\n   characteristics of any intervening facilities.  The chance\
    \ of getting\n   a valid minimal reading is affected by the number of nodes traversed,\n\
    \   but the value measured if it is valid will not be affected by the\n   number\
    \ of nodes traversed.  Stated another way, when a pair of\n   datagrams traverse\
    \ from one node to the next the datagrams are\n   susceptible to being separated\
    \ by a datagram from another source.\n   Both of these factors affect SRTT. The\
    \ value obtained requires no\n   topological knowledge of the route.\n   A potential\
    \ problem with the measurement is, it will not be the\n   proper value for some\
    \ forms of alternate routes.  If a T1 link is the\n   bottleneck route some times\
    \ and other times it is a 56 kb/s link our\n   first guess for inter-datagram\
    \ delay would be too small for the 56\n   kb/s line route.  Another problem is\
    \ that if one datagram goes via\n   one route and the next goes via another, their\
    \ inter-datagram arrival\n   difference could lead to a small false measurement.\
    \  If intervening\n   networks fragment datagrams then the measured IAT between\
    \ segments\n   could be misleading.  A solution to this problem is to ignore\n\
    \   fragmented datagram IATs.\n   This number represents the minimum inter-datagram\
    \ delay the sending\n   IP should use to send to us, the measuring site, for the\
    \ given\n   datagram size.  If we assume that the return path will be through\
    \ the\n   same facilities or the same type, then as described above this value\n\
    \   can be the first guess for inter-datagram introduced delay, \"D\" (in\n  \
    \ the algorithm).  It represents the \"I\" parameter.\n   These MIATs may be cached\
    \ on a host, subnet, or network basis.  The\n   last \"n\" hosts MIATs could be\
    \ kept.  For infrequent destinations an\n   entry per destination network would\
    \ be applicable to many\n   destinations.  If the local net is in fact a subnet,\
    \ then the other\n   local subnet MIATs could be kept.\n   If a good algorithm\
    \ is found for MIAT, comparing it to the average\n   IAT (during data transfer)\
    \ would give a good measure of the amount of\n   network traffic load.  Since\
    \ IP has no idea when the source of data\n   is sending as fast as possible, to\
    \ get a valid average, upper layer\n   protocols would have to figure this out\
    \ for themselves.  IP could\n   however provide an interface to get the current\
    \ MIAT for a given\n   destination.\n"
- title: References
  contents:
  - "References\n   [1]  Postel, Jon, \"Internet Protocol - DARPA Internet Program\n\
    \   Protocol Specification\", RFC 791, ISI, September 1981.\n   [2]  Postel, Jon,\
    \ \"Internet Control Message Protocol - DARPA Internet\n   Program Protocol Specification\"\
    , RFC 792, ISI, September 1981.\n   [3]  Karels, M., \"Re: Source Quench\", electronic\
    \ mail message to J.\n   Postel and INENG-INTEREST, Tue, 24 Feb 87.\n   [4] Nagle,\
    \ John B., \"On Packet Switches With Infinite Storage\", RFC\n   970, FACC Palo\
    \ Alto, December 1985.\n   [5] Jacobson, Van, \"Re: interpacket arrival variance\
    \ and mean\",\n   electronic mail message to TCP-IP,  Mon, 15 Jun 87 06:08:01\
    \ PDT\n   [6] Jacobson, Van, \"Re: Appropriate measures of gateway performance\"\
    \n   electronic mail message to J. Noel Chiappa  and INENG-INTEREST, Sun,\n  \
    \ 22 Mar 87 15:04:44 PST.\n   [7] Nagle, John B., \"Source quench, and congestion\
    \ generally\",\n   electronic mail message to B. Braden and INENG-INTEREST, Thu,\
    \ 5 Mar\n   87 11:08:49 PST.\n   [8] Nagle, John B., \"Congestion Control in IP/TCP\
    \ Internetworks\", RFC\n   896, FACC Palo Alto, 6 January 1984.\n"
