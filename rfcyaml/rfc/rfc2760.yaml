- title: __initial_text__
  contents:
  - '               Ongoing TCP Research Related to Satellites

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2000).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document outlines possible TCP enhancements that may allow\
    \ TCP\n   to better utilize the available bandwidth provided by networks\n   containing\
    \ satellite links.  The algorithms and mechanisms outlined\n   have not been judged\
    \ to be mature enough to be recommended by the\n   IETF.  The goal of this document\
    \ is to educate researchers as to the\n   current work and progress being done\
    \ in TCP research related to\n   satellite networks.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1         Introduction. . . . . . . . . . . . . . . . .\
    \ . . .  2\n   2         Satellite Architectures . . . . . . . . . . . . . . \
    \ 3\n   2.1       Asymmetric Satellite Networks . . . . . . . . . . .  3\n   2.2\
    \       Satellite Link as Last Hop. . . . . . . . . . . . .  3\n   2.3       Hybrid\
    \ Satellite Networks     . . . . . . . . . . .  4\n   2.4       Point-to-Point\
    \ Satellite Networks . . . . . . . . .  4\n   2.5       Multiple Satellite Hops\
    \ . . . . . . . . . . . . . .  4\n   3         Mitigations . . . . . . . . . .\
    \ . . . . . . . . . .  4\n   3.1       TCP For Transactions. . . . . . . . . .\
    \ . . . . . .  4\n   3.2       Slow Start. . . . . . . . . . . . . . . . . . .\
    \ . .  5\n   3.2.1     Larger Initial Window . . . . . . . . . . . . . . .  6\n\
    \   3.2.2     Byte Counting . . . . . . . . . . . . . . . . . . .  7\n   3.2.3\
    \     Delayed ACKs After Slow Start . . . . . . . . . . .  9\n   3.2.4     Terminating\
    \ Slow Start. . . . . . . . . . . . . . . 11\n   3.3       Loss Recovery . . .\
    \ . . . . . . . . . . . . . . . . 12\n   3.3.1     Non-SACK Based Mechanisms .\
    \ . . . . . . . . . . . . 12\n   3.3.2     SACK Based Mechanisms . . . . . . .\
    \ . . . . . . . . 13\n   3.3.3     Explicit Congestion Notification. . . . . .\
    \ . . . . 16\n   3.3.4     Detecting Corruption Loss . . . . . . . . . . . . .\
    \ 18\n   3.4       Congestion Avoidance. . . . . . . . . . . . . . . . 21\n  \
    \ 3.5       Multiple Data Connections . . . . . . . . . . . . . 22\n   3.6   \
    \    Pacing TCP Segments . . . . . . . . . . . . . . . . 24\n   3.7       TCP\
    \ Header Compression. . . . . . . . . . . . . . . 26\n   3.8       Sharing TCP\
    \ State Among Similar Connections . . . . 29\n   3.9       ACK Congestion Control.\
    \ . . . . . . . . . . . . . . 32\n   3.10      ACK Filtering . . . . . . . . .\
    \ . . . . . . . . . . 34\n   4         Conclusions . . . . . . . . . . . . . .\
    \ . . . . . . 36\n   5         Security Considerations . . . . . . . . . . . .\
    \ . . 36\n   6         Acknowledgments . . . . . . . . . . . . . . . . . . 37\n\
    \   7         References. . . . . . . . . . . . . . . . . . . . . 37\n   8   \
    \      Authors' Addresses. . . . . . . . . . . . . . . . . 43\n   9         Full\
    \ Copyright Statement. . . . . . . . . . . . . . 46\n"
- title: 1   Introduction
  contents:
  - "1   Introduction\n   This document outlines mechanisms that may help the Transmission\n\
    \   Control Protocol (TCP) [Pos81] better utilize the bandwidth provided\n   by\
    \ long-delay satellite environments.  These mechanisms may also help\n   in other\
    \ environments or for other protocols.  The proposals outlined\n   in this document\
    \ are currently being studied throughout the research\n   community.  Therefore,\
    \ these mechanisms are not mature enough to be\n   recommended for wide-spread\
    \ use by the IETF.  However, some of these\n   mechanisms may be safely used today.\
    \  It is hoped that this document\n   will stimulate further study into the described\
    \ mechanisms.  If, at\n   some point, the mechanisms discussed in this memo prove\
    \ to be safe\n   and appropriate to be recommended for general use, the appropriate\n\
    \   IETF documents will be written.\n   It should be noted that non-TCP mechanisms\
    \ that help performance over\n   satellite links do exist (e.g., application-level\
    \ changes, queueing\n   disciplines, etc.).  However, outlining these non-TCP\
    \ mitigations is\n   beyond the scope of this document and therefore is left as\
    \ future\n   work.  Additionally, there are a number of mitigations to TCP's\n\
    \   performance problems that involve very active intervention by\n   gateways\
    \ along the end-to-end path from the sender to the receiver.\n   Documenting the\
    \ pros and cons of such solutions is also left as\n   future work.\n"
- title: 2   Satellite Architectures
  contents:
  - "2   Satellite Architectures\n   Specific characteristics of satellite links and\
    \ the impact these\n   characteristics have on TCP are presented in RFC 2488 [AGS99].\
    \  This\n   section discusses several possible topologies where satellite links\n\
    \   may be integrated into the global Internet.  The mitigation outlined\n   in\
    \ section 3 will include a discussion of which environment the\n   mechanism is\
    \ expected to benefit.\n"
- title: 2.1 Asymmetric Satellite Networks
  contents:
  - "2.1 Asymmetric Satellite Networks\n   Some satellite networks exhibit a bandwidth\
    \ asymmetry, a larger data\n   rate in one direction than the reverse direction,\
    \ because of limits\n   on the transmission power and the antenna size at one\
    \ end of the\n   link.  Meanwhile, some other satellite systems are unidirectional\
    \ and\n   use a non-satellite return path (such as a dialup modem link).  The\n\
    \   nature of most TCP traffic is asymmetric with data flowing in one\n   direction\
    \ and acknowledgments in opposite direction.  However, the\n   term asymmetric\
    \ in this document refers to different physical\n   capacities in the forward\
    \ and return links.  Asymmetry has been shown\n   to be a problem for TCP [BPK97,BPK98].\n"
- title: 2.2 Satellite Link as Last Hop
  contents:
  - "2.2 Satellite Link as Last Hop\n   Satellite links that provide service directly\
    \ to end users, as\n   opposed to satellite links located in the middle of a network,\
    \ may\n   allow for specialized design of protocols used over the last hop.\n\
    \   Some satellite providers use the satellite link as a shared high\n   speed\
    \ downlink to users with a lower speed, non-shared terrestrial\n   link that is\
    \ used as a return link for requests and acknowledgments.\n   Many times this\
    \ creates an asymmetric network, as discussed above.\n"
- title: 2.3 Hybrid Satellite Networks
  contents:
  - "2.3 Hybrid Satellite Networks\n   In the more general case, satellite links may\
    \ be located at any point\n   in the network topology.  In this case, the satellite\
    \ link acts as\n   just another link between two gateways.  In this environment,\
    \ a given\n   connection may be sent over terrestrial links (including terrestrial\n\
    \   wireless), as well as satellite links.  On the other hand, a\n   connection\
    \ could also travel over only the terrestrial network or\n   only over the satellite\
    \ portion of the network.\n"
- title: 2.4 Point-to-Point Satellite Networks
  contents:
  - "2.4 Point-to-Point Satellite Networks\n   In point-to-point satellite networks,\
    \ the only hop in the network is\n   over the satellite link.  This pure satellite\
    \ environment exhibits\n   only the problems associated with the satellite links,\
    \ as outlined in\n   [AGS99].  Since this is a private network, some mitigations\
    \ that are\n   not appropriate for shared networks can be considered.\n"
- title: 2.5 Multiple Satellite Hops
  contents:
  - "2.5 Multiple Satellite Hops\n   In some situations, network traffic may traverse\
    \ multiple satellite\n   hops between the source and the destination.  Such an\
    \ environment\n   aggravates the satellite characteristics described in [AGS99].\n"
- title: 3   Mitigations
  contents:
  - "3   Mitigations\n   The following sections will discuss various techniques for\
    \ mitigating\n   the problems TCP faces in the satellite environment.  Each of\
    \ the\n   following sections will be organized as follows: First, each\n   mitigation\
    \ will be briefly outlined.  Next, research work involving\n   the mechanism in\
    \ question will be briefly discussed.  Next the\n   implementation issues of the\
    \ mechanism will be presented (including\n   whether or not the particular mechanism\
    \ presents any dangers to\n   shared networks).  Then a discussion of the mechanism's\
    \ potential\n   with regard to the topologies outlined above is given.  Finally,\
    \ the\n   relationships and possible interactions with other TCP mechanisms are\n\
    \   outlined.  The reader is expected to be familiar with the TCP\n   terminology\
    \ used in [AGS99].\n"
- title: 3.1 TCP For Transactions
  contents:
  - '3.1 TCP For Transactions

    '
- title: 3.1.1 Mitigation Description
  contents:
  - "3.1.1 Mitigation Description\n   TCP uses a three-way handshake to setup a connection\
    \ between two\n   hosts [Pos81].  This connection setup requires 1-1.5 round-trip\
    \ times\n   (RTTs), depending upon whether the data sender started the connection\n\
    \   actively or passively.  This startup time can be eliminated by using\n   TCP\
    \ extensions for transactions (T/TCP) [Bra94].  After the first\n   connection\
    \ between a pair of hosts is established, T/TCP is able to\n   bypass the three-way\
    \ handshake, allowing the data sender to begin\n   transmitting data in the first\
    \ segment sent (along with the SYN).\n   This is especially helpful for short\
    \ request/response traffic, as it\n   saves a potentially long setup phase when\
    \ no useful data is being\n   transmitted.\n"
- title: 3.1.2 Research
  contents:
  - "3.1.2 Research\n   T/TCP is outlined and analyzed in [Bra92,Bra94].\n"
- title: 3.1.3 Implementation Issues
  contents:
  - "3.1.3 Implementation Issues\n   T/TCP requires changes in the TCP stacks of both\
    \ the data sender and\n   the data receiver.  While T/TCP is safe to implement\
    \ in shared\n   networks from a congestion control perspective, several security\n\
    \   implications of sending data in the first data segment have been\n   identified\
    \ [ddKI99].\n"
- title: 3.1.4 Topology Considerations
  contents:
  - "3.1.4 Topology Considerations\n   It is expected that T/TCP will be equally beneficial\
    \ in all\n   environments outlined in section 2.\n"
- title: 3.1.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.1.5 Possible Interaction and Relationships with Other Research\n   T/TCP allows\
    \ data transfer to start more rapidly, much like using a\n   larger initial congestion\
    \ window (see section 3.2.1), delayed ACKs\n   after slow start (section 3.2.3)\
    \ or byte counting (section 3.2.2).\n"
- title: 3.2 Slow Start
  contents:
  - "3.2 Slow Start\n   The slow start algorithm is used to gradually increase the\
    \ size of\n   TCP's congestion window (cwnd) [Jac88,Ste97,APS99].  The algorithm\
    \ is\n   an important safe-guard against transmitting an inappropriate amount\n\
    \   of data into the network when the connection starts up.  However,\n   slow\
    \ start can also waste available network capacity, especially in\n   long-delay\
    \ networks [All97a,Hay97].  Slow start is particularly\n   inefficient for transfers\
    \ that are short compared to the\n   delay*bandwidth product of the network (e.g.,\
    \ WWW transfers).\n   Delayed ACKs are another source of wasted capacity during\
    \ the slow\n   start phase.  RFC 1122 [Bra89] suggests data receivers refrain\
    \ from\n   ACKing every incoming data segment.  However, every second full-sized\n\
    \   segment should be ACKed.  If a second full-sized segment does not\n   arrive\
    \ within a given timeout, an ACK must be generated (this timeout\n   cannot exceed\
    \ 500 ms).  Since the data sender increases the size of\n   cwnd based on the\
    \ number of arriving ACKs, reducing the number of\n   ACKs slows the cwnd growth\
    \ rate.  In addition, when TCP starts\n   sending, it sends 1 segment.  When using\
    \ delayed ACKs a second\n   segment must arrive before an ACK is sent.  Therefore,\
    \ the receiver\n   is always forced to wait for the delayed ACK timer to expire\
    \ before\n   ACKing the first segment, which also increases the transfer time.\n\
    \   Several proposals have suggested ways to make slow start less time\n   consuming.\
    \  These proposals are briefly outlined below and references\n   to the research\
    \ work given.\n"
- title: 3.2.1 Larger Initial Window
  contents:
  - '3.2.1 Larger Initial Window

    '
- title: 3.2.1.1 Mitigation Description
  contents:
  - "3.2.1.1 Mitigation Description\n   One method that will reduce the amount of\
    \ time required by slow start\n   (and therefore, the amount of wasted capacity)\
    \ is to increase the\n   initial value of cwnd.  An experimental TCP extension\
    \ outlined in\n   [AFP98] allows the initial size of cwnd to be increased from\
    \ 1\n   segment to that given in equation (1).\n               min (4*MSS, max\
    \ (2*MSS, 4380 bytes))               (1)\n   By increasing the initial value of\
    \ cwnd, more packets are sent during\n   the first RTT of data transmission, which\
    \ will trigger more ACKs,\n   allowing the congestion window to open more rapidly.\
    \  In addition, by\n   sending at least 2 segments initially, the first segment\
    \ does not\n   need to wait for the delayed ACK timer to expire as is the case\
    \ when\n   the initial size of cwnd is 1 segment (as discussed above).\n   Therefore,\
    \ the value of cwnd given in equation 1 saves up to 3 RTTs\n   and a delayed ACK\
    \ timeout when compared to an initial cwnd of 1\n   segment.\n   Also, we note\
    \ that RFC 2581 [APS99], a standards-track document,\n   allows a TCP to use an\
    \ initial cwnd of up to 2 segments.  This change\n   is highly recommended for\
    \ satellite networks.\n"
- title: 3.2.1.2 Research
  contents:
  - "3.2.1.2 Research\n   Several researchers have studied the use of a larger initial\
    \ window\n   in various environments.  [Nic97] and [KAGT98] show a reduction in\n\
    \   WWW page transfer time over hybrid fiber coax (HFC) and satellite\n   links\
    \ respectively.  Furthermore, it has been shown that using an\n   initial cwnd\
    \ of 4 segments does not negatively impact overall\n   performance over dialup\
    \ modem links with a small number of buffers\n   [SP98].  [AHO98] shows an improvement\
    \ in transfer time for 16 KB\n   files across the Internet and dialup modem links\
    \ when using a larger\n   initial value for cwnd.  However, a slight increase\
    \ in dropped\n   segments was also shown.  Finally, [PN98] shows improved transfer\n\
    \   time for WWW traffic in simulations with competing traffic, in\n   addition\
    \ to a small increase in the drop rate.\n"
- title: 3.2.1.3 Implementation Issues
  contents:
  - "3.2.1.3 Implementation Issues\n   The use of a larger initial cwnd value requires\
    \ changes to the\n   sender's TCP stack.  Using an initial congestion window of\
    \ 2 segments\n   is allowed by RFC 2581 [APS99].  Using an initial congestion\
    \ window\n   of 3 or 4 segments is not expected to present any danger of\n   congestion\
    \ collapse [AFP98], however may degrade performance in some\n   networks.\n"
- title: 3.2.1.4 Topology Considerations
  contents:
  - "3.2.1.4 Topology Considerations\n   It is expected that the use of a large initial\
    \ window would be\n   equally beneficial to all network architectures outlined\
    \ in section\n   2.\n"
- title: 3.2.1.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.2.1.5 Possible Interaction and Relationships with Other Research\n   Using\
    \ a fixed larger initial congestion window decreases the impact\n   of a long\
    \ RTT on transfer time (especially for short transfers) at\n   the cost of bursting\
    \ data into a network with unknown conditions.  A\n   mechanism that mitigates\
    \ bursts may make the use of a larger initial\n   congestion window more appropriate\
    \ (e.g., limiting the size of line-\n   rate bursts [FF96] or pacing the segments\
    \ in a burst [VH97a]).\n   Also, using delayed ACKs only after slow start (as\
    \ outlined in\n   section 3.2.3) offers an alternative way to immediately ACK\
    \ the first\n   segment of a transfer and open the congestion window more rapidly.\n\
    \   Finally, using some form of TCP state sharing among a number of\n   connections\
    \ (as discussed in 3.8) may provide an alternative to using\n   a fixed larger\
    \ initial window.\n"
- title: 3.2.2 Byte Counting
  contents:
  - '3.2.2 Byte Counting

    '
- title: 3.2.2.1 Mitigation Description
  contents:
  - "3.2.2.1 Mitigation Description\n   As discussed above, the wide-spread use of\
    \ delayed ACKs increases the\n   time needed by a TCP sender to increase the size\
    \ of the congestion\n   window during slow start.  This is especially harmful\
    \ to flows\n   traversing long-delay GEO satellite links.  One mechanism that\
    \ has\n   been suggested to mitigate the problems caused by delayed ACKs is the\n\
    \   use of \"byte counting\", rather than standard ACK counting\n   [All97a,All98].\
    \  Using standard ACK counting, the congestion window\n   is increased by 1 segment\
    \ for each ACK received during slow start.\n   However, using byte counting the\
    \ congestion window increase is based\n   on the number of previously unacknowledged\
    \ bytes covered by each\n   incoming ACK, rather than on the number of ACKs received.\
    \  This makes\n   the increase relative to the amount of data transmitted, rather\
    \ than\n   being dependent on the ACK interval used by the receiver.\n   Two forms\
    \ of byte counting are studied in [All98].  The first is\n   unlimited byte counting\
    \ (UBC).  This mechanism simply uses the number\n   of previously unacknowledged\
    \ bytes to increase the congestion window\n   each time an ACK arrives.  The second\
    \ form is limited byte counting\n   (LBC).  LBC limits the amount of cwnd increase\
    \ to 2 segments.  This\n   limit throttles the size of the burst of data sent\
    \ in response to a\n   \"stretch ACK\" [Pax97].  Stretch ACKs are acknowledgments\
    \ that cover\n   more than 2 segments of previously unacknowledged data.  Stretch\
    \ ACKs\n   can occur by design [Joh95] (although this is not standard), due to\n\
    \   implementation bugs [All97b,PADHV99] or due to ACK loss.  [All98]\n   shows\
    \ that LBC prevents large line-rate bursts when compared to UBC,\n   and therefore\
    \ offers fewer dropped segments and better performance.\n   In addition, UBC causes\
    \ large bursts during slow start based loss\n   recovery due to the large cumulative\
    \ ACKs that can arrive during loss\n   recovery.  The behavior of UBC during loss\
    \ recovery can cause large\n   decreases in performance and [All98] strongly recommends\
    \ UBC not be\n   deployed without further study into mitigating the large bursts.\n\
    \   Note: The standards track RFC 2581 [APS99] allows a TCP to use byte\n   counting\
    \ to increase cwnd during congestion avoidance, however not\n   during slow start.\n"
- title: 3.2.2.2 Research
  contents:
  - "3.2.2.2 Research\n   Using byte counting, as opposed to standard ACK counting,\
    \ has been\n   shown to reduce the amount of time needed to increase the value\
    \ of\n   cwnd to an appropriate size in satellite networks [All97a].  In\n   addition,\
    \ [All98] presents a simulation comparison of byte counting\n   and the standard\
    \ cwnd increase algorithm in uncongested networks and\n   networks with competing\
    \ traffic.  This study found that the limited\n   form of byte counting outlined\
    \ above can improve performance, while\n   also increasing the drop rate slightly.\n\
    \   [BPK97,BPK98] also investigated unlimited byte counting in\n   conjunction\
    \ with various ACK filtering algorithms (discussed in\n   section 3.10) in asymmetric\
    \ networks.\n"
- title: 3.2.2.3 Implementation Issues
  contents:
  - "3.2.2.3 Implementation Issues\n   Changing from ACK counting to byte counting\
    \ requires changes to the\n   data sender's TCP stack.  Byte counting violates\
    \ the algorithm for\n   increasing the congestion window outlined in RFC 2581\
    \ [APS99] (by\n   making congestion window growth more aggressive during slow\
    \ start)\n   and therefore should not be used in shared networks.\n"
- title: 3.2.2.4 Topology Considerations
  contents:
  - "3.2.2.4 Topology Considerations\n   It has been suggested by some (and roundly\
    \ criticized by others) that\n   byte counting will allow TCP to provide uniform\
    \ cwnd increase,\n   regardless of the ACKing behavior of the receiver.  In addition,\
    \ byte\n   counting also mitigates the retarded window growth provided by\n  \
    \ receivers that generate stretch ACKs because of the capacity of the\n   return\
    \ link, as discussed in [BPK97,BPK98].  Therefore, this change\n   is expected\
    \ to be especially beneficial to asymmetric networks.\n"
- title: 3.2.2.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.2.2.5 Possible Interaction and Relationships with Other Research\n   Unlimited\
    \ byte counting should not be used without a method to\n   mitigate the potentially\
    \ large line-rate bursts the algorithm can\n   cause.  Also, LBC may send bursts\
    \ that are too large for the given\n   network conditions.  In this case, LBC\
    \ may also benefit from some\n   algorithm that would lessen the impact of line-rate\
    \ bursts of\n   segments.  Also note that using delayed ACKs only after slow start\n\
    \   (as outlined in section 3.2.3) negates the limited byte counting\n   algorithm\
    \ because each ACK covers only one segment during slow start.\n   Therefore, both\
    \ ACK counting and byte counting yield the same\n   increase in the congestion\
    \ window at this point (in the first RTT).\n"
- title: 3.2.3 Delayed ACKs After Slow Start
  contents:
  - '3.2.3 Delayed ACKs After Slow Start

    '
- title: 3.2.3.1 Mitigation Description
  contents:
  - "3.2.3.1 Mitigation Description\n   As discussed above, TCP senders use the number\
    \ of incoming ACKs to\n   increase the congestion window during slow start.  And,\
    \ since delayed\n   ACKs reduce the number of ACKs returned by the receiver by\
    \ roughly\n   half, the rate of growth of the congestion window is reduced.  One\n\
    \   proposed solution to this problem is to use delayed ACKs only after\n   the\
    \ slow start (DAASS) phase.  This provides more ACKs while TCP is\n   aggressively\
    \ increasing the congestion window and less ACKs while TCP\n   is in steady state,\
    \ which conserves network resources.\n"
- title: 3.2.3.2 Research
  contents:
  - "3.2.3.2 Research\n   [All98] shows that in simulation, using delayed ACKs after\
    \ slow start\n   (DAASS) improves transfer time when compared to a receiver that\n\
    \   always generates delayed ACKs.  However, DAASS also slightly\n   increases\
    \ the loss rate due to the increased rate of cwnd growth.\n"
- title: 3.2.3.3 Implementation Issues
  contents:
  - "3.2.3.3 Implementation Issues\n   The major problem with DAASS is in the implementation.\
    \  The receiver\n   has to somehow know when the sender is using the slow start\n\
    \   algorithm.  The receiver could implement a heuristic that attempts to\n  \
    \ watch the change in the amount of data being received and change the\n   ACKing\
    \ behavior accordingly.  Or, the sender could send a message (a\n   flipped bit\
    \ in the TCP header, perhaps) indicating that it was using\n   slow start.  The\
    \ implementation of DAASS is, therefore, an open\n   issue.\n   Using DAASS does\
    \ not violate the TCP congestion control specification\n   [APS99].  However,\
    \ the standards (RFC 2581 [APS99]) currently\n   recommend using delayed acknowledgments\
    \ and DAASS goes (partially)\n   against this recommendation.\n"
- title: 3.2.3.4 Topology Considerations
  contents:
  - "3.2.3.4 Topology Considerations\n   DAASS should work equally well in all scenarios\
    \ presented in section\n   2.  However, in asymmetric networks it may aggravate\
    \ ACK congestion\n   in the return link, due to the increased number of ACKs (see\
    \ sections\n   3.9 and 3.10 for a more detailed discussion of ACK congestion).\n"
- title: 3.2.3.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.2.3.5 Possible Interaction and Relationships with Other Research\n   DAASS\
    \ has several possible interactions with other proposals made in\n   the research\
    \ community.  DAASS can aggravate congestion on the path\n   between the data\
    \ receiver and the data sender due to the increased\n   number of returning acknowledgments.\
    \  This can have an especially\n   adverse effect on asymmetric networks that\
    \ are prone to experiencing\n   ACK congestion.  As outlined in sections 3.9 and\
    \ 3.10, several\n   mitigations have been proposed to reduce the number of ACKs\
    \ that are\n   passed over a low-bandwidth return link.  Using DAASS will increase\n\
    \   the number of ACKs sent by the receiver.  The interaction between\n   DAASS\
    \ and the methods for reducing the number of ACKs is an open\n   research question.\
    \  Also, as noted in section 3.2.1.5 above, DAASS\n   provides some of the same\
    \ benefits as using a larger initial\n   congestion window and therefore it may\
    \ not be desirable to use both\n   mechanisms together.  However, this remains\
    \ an open question.\n   Finally, DAASS and limited byte counting are both used\
    \ to increase\n   the rate at which the congestion window is opened.  The DAASS\n\
    \   algorithm substantially reduces the impact limited byte counting has\n   on\
    \ the rate of congestion window increase.\n"
- title: 3.2.4 Terminating Slow Start
  contents:
  - '3.2.4 Terminating Slow Start

    '
- title: 3.2.4.1 Mitigation Description
  contents:
  - "3.2.4.1 Mitigation Description\n   The initial slow start phase is used by TCP\
    \ to determine an\n   appropriate congestion window size for the given network\
    \ conditions\n   [Jac88].  Slow start is terminated when TCP detects congestion,\
    \ or\n   when the size of cwnd reaches the size of the receiver's advertised\n\
    \   window.  Slow start is also terminated if cwnd grows beyond a certain\n  \
    \ size.  The threshold at which TCP ends slow start and begins using\n   the congestion\
    \ avoidance algorithm is called \"ssthresh\" [Jac88].  In\n   most implementations,\
    \ the initial value for ssthresh is the\n   receiver's advertised window.  During\
    \ slow start, TCP roughly doubles\n   the size of cwnd every RTT and therefore\
    \ can overwhelm the network\n   with at most twice as many segments as the network\
    \ can handle.  By\n   setting ssthresh to a value less than the receiver's advertised\n\
    \   window initially, the sender may avoid overwhelming the network with\n   twice\
    \ the appropriate number of segments.  Hoe [Hoe96] proposes using\n   the packet-pair\
    \ algorithm [Kes91] and the measured RTT to determine a\n   more appropriate value\
    \ for ssthresh.  The algorithm observes the\n   spacing between the first few\
    \ returning ACKs to determine the\n   bandwidth of the bottleneck link.  Together\
    \ with the measured RTT,\n   the delay*bandwidth product is determined and ssthresh\
    \ is set to this\n   value.  When TCP's cwnd reaches this reduced ssthresh, slow\
    \ start is\n   terminated and transmission continues using congestion avoidance,\n\
    \   which is a more conservative algorithm for increasing the size of the\n  \
    \ congestion window.\n"
- title: 3.2.4.2 Research
  contents:
  - "3.2.4.2 Research\n   It has been shown that estimating ssthresh can improve performance\n\
    \   and decrease packet loss in simulations [Hoe96].  However, obtaining\n   an\
    \ accurate estimate of the available bandwidth in a dynamic network\n   is very\
    \ challenging, especially attempting to do so on the sending\n   side of the TCP\
    \ connection [AP99].  Therefore, before this mechanism\n   is widely deployed,\
    \ bandwidth estimation must be studied in a more\n   detail.\n"
- title: 3.2.4.3 Implementation Issues
  contents:
  - "3.2.4.3 Implementation Issues\n   As outlined in [Hoe96], estimating ssthresh\
    \ requires changes to the\n   data sender's TCP stack.  As suggested in [AP99],\
    \ bandwidth estimates\n   may be more accurate when taken by the TCP receiver,\
    \ and therefore\n   both sender and receiver changes would be required.  Estimating\n\
    \   ssthresh is safe to implement in production networks from a\n   congestion\
    \ control perspective, as it can only make TCP more\n   conservative than outlined\
    \ in RFC 2581 [APS99] (assuming the TCP\n   implementation is using an initial\
    \ ssthresh of infinity as allowed by\n   [APS99]).\n"
- title: 3.2.4.4 Topology Considerations
  contents:
  - "3.2.4.4 Topology Considerations\n   It is expected that this mechanism will work\
    \ equally well in all\n   symmetric topologies outlined in section 2.  However,\
    \ asymmetric\n   links pose a special problem, as the rate of the returning ACKs\
    \ may\n   not be the bottleneck bandwidth in the forward direction.  This can\n\
    \   lead to the sender setting ssthresh too low.  Premature termination\n   of\
    \ slow start can hurt performance, as congestion avoidance opens\n   cwnd more\
    \ conservatively.  Receiver-based bandwidth estimators do not\n   suffer from\
    \ this problem.\n"
- title: 3.2.4.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.2.4.5 Possible Interaction and Relationships with Other Research\n   Terminating\
    \ slow start at the right time is useful to avoid multiple\n   dropped segments.\
    \  However, using a selective acknowledgment-based\n   loss recovery scheme (as\
    \ outlined in section 3.3.2) can drastically\n   improve TCP's ability to quickly\
    \ recover from multiple lost segments\n   Therefore, it may not be as important\
    \ to terminate slow start before\n   a large loss event occurs.  [AP99] shows\
    \ that using delayed\n   acknowledgments [Bra89] reduces the effectiveness of\
    \ sender-side\n   bandwidth estimation.  Therefore, using delayed ACKs only during\
    \ slow\n   start (as outlined in section 3.2.3) may make bandwidth estimation\n\
    \   more feasible.\n"
- title: 3.3 Loss Recovery
  contents:
  - '3.3 Loss Recovery

    '
- title: 3.3.1 Non-SACK Based Mechanisms
  contents:
  - '3.3.1 Non-SACK Based Mechanisms

    '
- title: 3.3.1.1 Mitigation Description
  contents:
  - "3.3.1.1 Mitigation Description\n   Several similar algorithms have been developed\
    \ and studied that\n   improve TCP's ability to recover from multiple lost segments\
    \ in a\n   window of data without relying on the (often long) retransmission\n\
    \   timeout.  These sender-side algorithms, known as NewReno TCP, do not\n   depend\
    \ on the availability of selective acknowledgments (SACKs)\n   [MMFR96].\n   These\
    \ algorithms generally work by updating the fast recovery\n   algorithm to use\
    \ information provided by \"partial ACKs\" to trigger\n   retransmissions.  A\
    \ partial ACK covers some new data, but not all\n   data outstanding when a particular\
    \ loss event starts.  For instance,\n   consider the case when segment N is retransmitted\
    \ using the fast\n   retransmit algorithm and segment M is the last segment sent\
    \ when\n   segment N is resent.  If segment N is the only segment lost, the ACK\n\
    \   elicited by the retransmission of segment N would be for segment M.\n   If,\
    \ however, segment N+1 was also lost, the ACK elicited by the\n   retransmission\
    \ of segment N will be N+1.  This can be taken as an\n   indication that segment\
    \ N+1 was lost and used to trigger a\n   retransmission.\n"
- title: 3.3.1.2 Research
  contents:
  - "3.3.1.2 Research\n   Hoe [Hoe95,Hoe96] introduced the idea of using partial ACKs\
    \ to\n   trigger retransmissions and showed that doing so could improve\n   performance.\
    \  [FF96] shows that in some cases using partial ACKs to\n   trigger retransmissions\
    \ reduces the time required to recover from\n   multiple lost segments.  However,\
    \ [FF96] also shows that in some\n   cases (many lost segments) relying on the\
    \ RTO timer can improve\n   performance over simply using partial ACKs to trigger\
    \ all\n   retransmissions.  [HK99] shows that using partial ACKs to trigger\n\
    \   retransmissions, in conjunction with SACK, improves performance when\n   compared\
    \ to TCP using fast retransmit/fast recovery in a satellite\n   environment. \
    \ Finally, [FH99] describes several slightly different\n   variants of NewReno.\n"
- title: 3.3.1.3 Implementation Issues
  contents:
  - "3.3.1.3 Implementation Issues\n   Implementing these fast recovery enhancements\
    \ requires changes to the\n   sender-side TCP stack.  These changes can safely\
    \ be implemented in\n   production networks and are allowed by RFC 2581 [APS99].\n"
- title: 3.3.1.4 Topology Considerations
  contents:
  - "3.3.1.4 Topology Considerations\n   It is expected that these changes will work\
    \ well in all environments\n   outlined in section 2.\n"
- title: 3.3.1.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.3.1.5 Possible Interaction and Relationships with Other Research\n   See section\
    \ 3.3.2.2.5.\n"
- title: 3.3.2 SACK Based Mechanisms
  contents:
  - '3.3.2 SACK Based Mechanisms

    '
- title: 3.3.2.1 Fast Recovery with SACK
  contents:
  - '3.3.2.1 Fast Recovery with SACK

    '
- title: 3.3.2.1.1 Mitigation Description
  contents:
  - "3.3.2.1.1 Mitigation Description\n   Fall and Floyd [FF96] describe a conservative\
    \ extension to the fast\n   recovery algorithm that takes into account information\
    \ provided by\n   selective acknowledgments (SACKs) [MMFR96] sent by the receiver.\
    \  The\n   algorithm starts after fast retransmit triggers the resending of a\n\
    \   segment.  As with fast retransmit, the algorithm cuts cwnd in half\n   when\
    \ a loss is detected.  The algorithm keeps a variable called\n   \"pipe\", which\
    \ is an estimate of the number of outstanding segments in\n   the network.  The\
    \ pipe variable is decremented by 1 segment for each\n   duplicate ACK that arrives\
    \ with new SACK information.  The pipe\n   variable is incremented by 1 for each\
    \ new or retransmitted segment\n   sent.  A segment may be sent when the value\
    \ of pipe is less than cwnd\n   (this segment is either a retransmission per the\
    \ SACK information or\n   a new segment if the SACK information indicates that\
    \ no more\n   retransmits are needed).\n   This algorithm generally allows TCP\
    \ to recover from multiple segment\n   losses in a window of data within one RTT\
    \ of loss detection.  Like\n   the forward acknowledgment (FACK) algorithm described\
    \ below, the SACK\n   information allows the pipe algorithm to decouple the choice\
    \ of when\n   to send a segment from the choice of what segment to send.\n   [APS99]\
    \ allows the use of this algorithm, as it is consistent with\n   the spirit of\
    \ the fast recovery algorithm.\n"
- title: 3.3.2.1.2 Research
  contents:
  - "3.3.2.1.2 Research\n   [FF96] shows that the above described SACK algorithm performs\
    \ better\n   than several non-SACK based recovery algorithms when 1--4 segments\n\
    \   are lost from a window of data.  [AHKO97] shows that the algorithm\n   improves\
    \ performance over satellite links.  Hayes [Hay97] shows the\n   in certain circumstances,\
    \ the SACK algorithm can hurt performance by\n   generating a large line-rate\
    \ burst of data at the end of loss\n   recovery, which causes further loss.\n"
- title: 3.3.2.1.3 Implementation Issues
  contents:
  - "3.3.2.1.3 Implementation Issues\n   This algorithm is implemented in the sender's\
    \ TCP stack.  However, it\n   relies on SACK information generated by the receiver.\
    \  This algorithm\n   is safe for shared networks and is allowed by RFC 2581 [APS99].\n"
- title: 3.3.2.1.4 Topology Considerations
  contents:
  - "3.3.2.1.4 Topology Considerations\n   It is expected that the pipe algorithm\
    \ will work equally well in all\n   scenarios presented in section 2.\n"
- title: 3.3.2.1.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.3.2.1.5 Possible Interaction and Relationships with Other Research\n   See\
    \ section 3.3.2.2.5.\n"
- title: 3.3.2.2 Forward Acknowledgments
  contents:
  - '3.3.2.2 Forward Acknowledgments

    '
- title: 3.3.2.2.1 Mitigation Description
  contents:
  - "3.3.2.2.1 Mitigation Description\n   The Forward Acknowledgment (FACK) algorithm\
    \ [MM96a,MM96b] was\n   developed to improve TCP congestion control during loss\
    \ recovery.\n   FACK uses TCP SACK options to glean additional information about\
    \ the\n   congestion state, adding more precise control to the injection of\n\
    \   data into the network during recovery.  FACK decouples the congestion\n  \
    \ control algorithms from the data recovery algorithms to provide a\n   simple\
    \ and direct way to use SACK to improve congestion control.  Due\n   to the separation\
    \ of these two algorithms, new data may be sent\n   during recovery to sustain\
    \ TCP's self-clock when there is no further\n   data to retransmit.\n   The most\
    \ recent version of FACK is Rate-Halving [MM96b], in which one\n   packet is sent\
    \ for every two ACKs received during recovery.\n   Transmitting a segment for\
    \ every-other ACK has the result of reducing\n   the congestion window in one\
    \ round trip to half of the number of\n   packets that were successfully handled\
    \ by the network (so when cwnd\n   is too large by more than a factor of two it\
    \ still gets reduced to\n   half of what the network can sustain).  Another important\
    \ aspect of\n   FACK with Rate-Halving is that it sustains the ACK self-clock\
    \ during\n   recovery because transmitting a packet for every-other ACK does not\n\
    \   require half a cwnd of data to drain from the network before\n   transmitting,\
    \ as required by the fast recovery algorithm\n   [Ste97,APS99].\n   In addition,\
    \ the FACK with Rate-Halving implementation provides\n   Thresholded Retransmission\
    \ to each lost segment.  \"Tcprexmtthresh\" is\n   the number of duplicate ACKs\
    \ required by TCP to trigger a fast\n   retransmit and enter recovery.  FACK applies\
    \ thresholded\n   retransmission to all segments by waiting until tcprexmtthresh\
    \ SACK\n   blocks indicate that a given segment is missing before resending the\n\
    \   segment.  This allows reasonable behavior on links that reorder\n   segments.\
    \  As described above, FACK sends a segment for every second\n   ACK received\
    \ during recovery.  New segments are transmitted except\n   when tcprexmtthresh\
    \ SACK blocks have been observed for a dropped\n   segment, at which point the\
    \ dropped segment is retransmitted.\n   [APS99] allows the use of this algorithm,\
    \ as it is consistent with\n   the spirit of the fast recovery algorithm.\n"
- title: 3.3.2.2.2 Research
  contents:
  - "3.3.2.2.2 Research\n   The original FACK algorithm is outlined in [MM96a].  The\
    \ algorithm\n   was later enhanced to include Rate-Halving [MM96b].  The real-world\n\
    \   performance of FACK with Rate-Halving was shown to be much closer to\n   the\
    \ theoretical maximum for TCP than either TCP Reno or the SACK-\n   based extensions\
    \ to fast recovery outlined in section 3.3.2.1\n   [MSMO97].\n"
- title: 3.3.2.2.3 Implementation Issues
  contents:
  - "3.3.2.2.3 Implementation Issues\n   In order to use FACK, the sender's TCP stack\
    \ must be modified.  In\n   addition, the receiver must be able to generate SACK\
    \ options to\n   obtain the full benefit of using FACK.  The FACK algorithm is\
    \ safe\n   for shared networks and is allowed by RFC 2581 [APS99].\n"
- title: 3.3.2.2.4 Topology Considerations
  contents:
  - "3.3.2.2.4 Topology Considerations\n   FACK is expected to improve performance\
    \ in all environments outlined\n   in section 2.  Since it is better able to sustain\
    \ its self-clock than\n   TCP Reno, it may be considerably more attractive over\
    \ long delay\n   paths.\n"
- title: 3.3.2.2.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.3.2.2.5 Possible Interaction and Relationships with Other Research\n   Both\
    \ SACK based loss recovery algorithms described above (the fast\n   recovery enhancement\
    \ and the FACK algorithm) are similar in that they\n   attempt to effectively\
    \ repair multiple lost segments from a window of\n   data.  Which of the SACK-based\
    \ loss recovery algorithms to use is\n   still an open research question.  In\
    \ addition, these algorithms are\n   similar to the non-SACK NewReno algorithm\
    \ described in section 3.3.1,\n   in that they attempt to recover from multiple\
    \ lost segments without\n   reverting to using the retransmission timer.  As has\
    \ been shown, the\n   above SACK based algorithms are more robust than the NewReno\n\
    \   algorithm.  However, the SACK algorithm requires a cooperating TCP\n   receiver,\
    \ which the NewReno algorithm does not.  A reasonable TCP\n   implementation might\
    \ include both a SACK-based and a NewReno-based\n   loss recovery algorithm such\
    \ that the sender can use the most\n   appropriate loss recovery algorithm based\
    \ on whether or not the\n   receiver supports SACKs.  Finally, both SACK-based\
    \ and non-SACK-based\n   versions of fast recovery have been shown to transmit\
    \ a large burst\n   of data upon leaving loss recovery, in some cases [Hay97].\n\
    \   Therefore, the algorithms may benefit from some burst suppression\n   algorithm.\n"
- title: 3.3.3 Explicit Congestion Notification
  contents:
  - '3.3.3 Explicit Congestion Notification

    '
- title: 3.3.3.1 Mitigation Description
  contents:
  - "3.3.3.1 Mitigation Description\n   Explicit congestion notification (ECN) allows\
    \ routers to inform TCP\n   senders about imminent congestion without dropping\
    \ segments.  Two\n   major forms of ECN have been studied.  A router employing\
    \ backward\n   ECN (BECN), transmits messages directly to the data originator\n\
    \   informing it of congestion.  IP routers can accomplish this with an\n   ICMP\
    \ Source Quench message.  The arrival of a BECN signal may or may\n   not mean\
    \ that a TCP data segment has been dropped, but it is a clear\n   indication that\
    \ the TCP sender should reduce its sending rate (i.e.,\n   the value of cwnd).\
    \  The second major form of congestion notification\n   is forward ECN (FECN).\
    \  FECN routers mark data segments with a\n   special tag when congestion is imminent,\
    \ but forward the data\n   segment.  The data receiver then echos the congestion\
    \ information\n   back to the sender in the ACK packet.  A description of a FECN\n\
    \   mechanism for TCP/IP is given in [RF99].\n   As described in [RF99], senders\
    \ transmit segments with an \"ECN-\n   Capable Transport\" bit set in the IP header\
    \ of each packet.  If a\n   router employing an active queueing strategy, such\
    \ as Random Early\n   Detection (RED) [FJ93,BCC+98], would otherwise drop this\
    \ segment, an\n   \"Congestion Experienced\" bit in the IP header is set instead.\
    \  Upon\n   reception, the information is echoed back to TCP senders using a bit\n\
    \   in the TCP header.  The TCP sender adjusts the congestion window just\n  \
    \ as it would if a segment was dropped.\n   The implementation of ECN as specified\
    \ in [RF99] requires the\n   deployment of active queue management mechanisms\
    \ in the affected\n   routers.  This allows the routers to signal congestion by\
    \ sending TCP\n   a small number of \"congestion signals\" (segment drops or ECN\n\
    \   messages), rather than discarding a large number of segments, as can\n   happen\
    \ when TCP overwhelms a drop-tail router queue.\n   Since satellite networks generally\
    \ have higher bit-error rates than\n   terrestrial networks, determining whether\
    \ a segment was lost due to\n   congestion or corruption may allow TCP to achieve\
    \ better performance\n   in high BER environments than currently possible (due\
    \ to TCP's\n   assumption that all loss is due to congestion).  While not a solution\n\
    \   to this problem, adding an ECN mechanism to TCP may be a part of a\n   mechanism\
    \ that will help achieve this goal.  See section 3.3.4 for a\n   more detailed\
    \ discussion of differentiating between corruption and\n   congestion based losses.\n"
- title: 3.3.3.2 Research
  contents:
  - "3.3.3.2 Research\n   [Flo94] shows that ECN is effective in reducing the segment\
    \ loss rate\n   which yields better performance especially for short and interactive\n\
    \   TCP connections.  Furthermore, [Flo94] also shows that ECN avoids\n   some\
    \ unnecessary, and costly TCP retransmission timeouts.  Finally,\n   [Flo94] also\
    \ considers some of the advantages and disadvantages of\n   various forms of explicit\
    \ congestion notification.\n"
- title: 3.3.3.3 Implementation Issues
  contents:
  - "3.3.3.3 Implementation Issues\n   Deployment of ECN requires changes to the TCP\
    \ implementation on both\n   sender and receiver.  Additionally, deployment of\
    \ ECN requires\n   deployment of some active queue management infrastructure in\
    \ routers.\n   RED is assumed in most ECN discussions, because RED is already\n\
    \   identifying segments to drop, even before its buffer space is\n   exhausted.\
    \  ECN simply allows the delivery of \"marked\" segments while\n   still notifying\
    \ the end nodes that congestion is occurring along the\n   path.  ECN is safe\
    \ (from a congestion control perspective) for shared\n   networks, as it maintains\
    \ the same TCP congestion control principles\n   as are used when congestion is\
    \ detected via segment drops.\n"
- title: 3.3.3.4 Topology Considerations
  contents:
  - "3.3.3.4 Topology Considerations\n   It is expected that none of the environments\
    \ outlined in section 2\n   will present a bias towards or against ECN traffic.\n"
- title: 3.3.3.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.3.3.5 Possible Interaction and Relationships with Other Research\n   Note that\
    \ some form of active queueing is necessary to use ECN (e.g.,\n   RED queueing).\n"
- title: 3.3.4 Detecting Corruption Loss
  contents:
  - "3.3.4 Detecting Corruption Loss\n   Differentiating between congestion (loss\
    \ of segments due to router\n   buffer overflow or imminent buffer overflow) and\
    \ corruption (loss of\n   segments due to damaged bits) is a difficult problem\
    \ for TCP.  This\n   differentiation is particularly important because the action\
    \ that TCP\n   should take in the two cases is entirely different.  In the case\
    \ of\n   corruption, TCP should merely retransmit the damaged segment as soon\n\
    \   as its loss is detected; there is no need for TCP to adjust its\n   congestion\
    \ window.  On the other hand, as has been widely discussed\n   above, when the\
    \ TCP sender detects congestion, it should immediately\n   reduce its congestion\
    \ window to avoid making the congestion worse.\n   TCP's defined behavior, as\
    \ motivated by [Jac88,Jac90] and defined in\n   [Bra89,Ste97,APS99], is to assume\
    \ that all loss is due to congestion\n   and to trigger the congestion control\
    \ algorithms, as defined in\n   [Ste97,APS99].  The loss may be detected using\
    \ the fast retransmit\n   algorithm, or in the worst case is detected by the expiration\
    \ of\n   TCP's retransmission timer.\n   TCP's assumption that loss is due to\
    \ congestion rather than\n   corruption is a conservative mechanism that prevents\
    \ congestion\n   collapse [Jac88,FF98].  Over satellite networks, however, as\
    \ in many\n   wireless environments, loss due to corruption is more common than\
    \ on\n   terrestrial networks.  One common partial solution to this problem is\n\
    \   to add Forward Error Correction (FEC) to the data that's sent over\n   the\
    \ satellite/wireless link.  A more complete discussion of the\n   benefits of\
    \ FEC can be found in [AGS99].  However, given that FEC\n   does not always work\
    \ or cannot be universally applied, other\n   mechanisms have been studied to\
    \ attempt to make TCP able to\n   differentiate between congestion-based and corruption-based\
    \ loss.\n   TCP segments that have been corrupted are most often dropped by\n\
    \   intervening routers when link-level checksum mechanisms detect that\n   an\
    \ incoming frame has errors.  Occasionally, a TCP segment containing\n   an error\
    \ may survive without detection until it arrives at the TCP\n   receiving host,\
    \ at which point it will almost always either fail the\n   IP header checksum\
    \ or the TCP checksum and be discarded as in the\n   link-level error case.  Unfortunately,\
    \ in either of these cases, it's\n   not generally safe for the node detecting\
    \ the corruption to return\n   information about the corrupt packet to the TCP\
    \ sender because the\n   sending address itself might have been corrupted.\n"
- title: 3.3.4.1 Mitigation Description
  contents:
  - "3.3.4.1 Mitigation Description\n   Because the probability of link errors on\
    \ a satellite link is\n   relatively greater than on a hardwired link, it is particularly\n\
    \   important that the TCP sender retransmit these lost segments without\n   reducing\
    \ its congestion window.  Because corrupt segments do not\n   indicate congestion,\
    \ there is no need for the TCP sender to enter a\n   congestion avoidance phase,\
    \ which may waste available bandwidth.\n   Simulations performed in [SF98] show\
    \ a performance improvement when\n   TCP can properly differentiate between between\
    \ corruption and\n   congestion of wireless links.\n   Perhaps the greatest research\
    \ challenge in detecting corruption is\n   getting TCP (a transport-layer protocol)\
    \ to receive appropriate\n   information from either the network layer (IP) or\
    \ the link layer.\n   Much of the work done to date has involved link-layer mechanisms\
    \ that\n   retransmit damaged segments.  The challenge seems to be to get these\n\
    \   mechanisms to make repairs in such a way that TCP understands what\n   happened\
    \ and can respond appropriately.\n"
- title: 3.3.4.2 Research
  contents:
  - "3.3.4.2 Research\n   Research into corruption detection to date has focused primarily\
    \ on\n   making the link level detect errors and then perform link-level\n   retransmissions.\
    \  This work is summarized in [BKVP97,BPSK96].  One of\n   the problems with this\
    \ promising technique is that it causes an\n   effective reordering of the segments\
    \ from the TCP receiver's point of\n   view.  As a simple example, if segments\
    \ A B C D are sent across a\n   noisy link and segment B is corrupted, segments\
    \ C and D may have\n   already crossed the link before B can be retransmitted\
    \ at the link\n   level, causing them to arrive at the TCP receiver in the order\
    \ A C D\n   B.  This segment reordering would cause the TCP receiver to generate\n\
    \   duplicate ACKs upon the arrival of segments C and D.  If the\n   reordering\
    \ was bad enough, the sender would trigger the fast\n   retransmit algorithm in\
    \ the TCP sender, in response to the duplicate\n   ACKs.  Research presented in\
    \ [MV98] proposes the idea of suppressing\n   or delaying the duplicate ACKs in\
    \ the reverse direction to counteract\n   this behavior.  Alternatively, proposals\
    \ that make TCP more robust in\n   the face of re-ordered segment arrivals [Flo99]\
    \ may reduce the side\n   effects of the re-ordering caused by link-layer retransmissions.\n\
    \   A more high-level approach, outlined in the [DMT96], uses a new\n   \"corruption\
    \ experienced\" ICMP error message generated by routers that\n   detect corruption.\
    \  These messages are sent in the forward direction,\n   toward the packet's destination,\
    \ rather than in the reverse direction\n   as is done with ICMP Source Quench\
    \ messages.  Sending the error\n   messages in the forward direction allows this\
    \ feedback to work over\n   asymmetric paths.  As noted above, generating an error\
    \ message in\n   response to a damaged packet is problematic because the source\
    \ and\n   destination addresses may not be valid.  The mechanism outlined in\n\
    \   [DMT96] gets around this problem by having the routers maintain a\n   small\
    \ cache of recent packet destinations; when the router\n   experiences an error\
    \ rate above some threshold, it sends an ICMP\n   corruption-experienced message\
    \ to all of the destinations in its\n   cache.  Each TCP receiver then must return\
    \ this information to its\n   respective TCP sender (through a TCP option).  Upon\
    \ receiving an ACK\n   with this \"corruption-experienced\" option, the TCP sender\
    \ assumes\n   that packet loss is due to corruption rather than congestion for\
    \ two\n   round trip times (RTT) or until it receives additional link state\n\
    \   information (such as \"link down\", source quench, or additional\n   \"corruption\
    \ experienced\" messages).  Note that in shared networks,\n   ignoring segment\
    \ loss for 2 RTTs may aggravate congestion by making\n   TCP unresponsive.\n"
- title: 3.3.4.3 Implementation Issues
  contents:
  - "3.3.4.3 Implementation Issues\n   All of the techniques discussed above require\
    \ changes to at least the\n   TCP sending and receiving stacks, as well as intermediate\
    \ routers.\n   Due to the concerns over possibly ignoring congestion signals (i.e.,\n\
    \   segment drops), the above algorithm is not recommended for use in\n   shared\
    \ networks.\n"
- title: 3.3.4.4 Topology Considerations
  contents:
  - "3.3.4.4 Topology Considerations\n   It is expected that corruption detection,\
    \ in general would be\n   beneficial in all environments outlined in section 2.\
    \  It would be\n   particularly beneficial in the satellite/wireless environment\
    \ over\n   which these errors may be more prevalent.\n"
- title: 3.3.4.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.3.4.5 Possible Interaction and Relationships with Other Research\n   SACK-based\
    \ loss recovery algorithms (as described in 3.3.2) may\n   reduce the impact of\
    \ corrupted segments on mostly clean links because\n   recovery will be able to\
    \ happen more rapidly (and without relying on\n   the retransmission timer). \
    \ Note that while SACK-based loss recovery\n   helps, throughput will still suffer\
    \ in the face of non-congestion\n   related packet loss.\n"
- title: 3.4 Congestion Avoidance
  contents:
  - '3.4 Congestion Avoidance

    '
- title: 3.4.1  Mitigation Description
  contents:
  - "3.4.1  Mitigation Description\n   During congestion avoidance, in the absence\
    \ of loss, the TCP sender\n   adds approximately one segment to its congestion\
    \ window during each\n   RTT [Jac88,Ste97,APS99].  Several researchers have observed\
    \ that this\n   policy leads to unfair sharing of bandwidth when multiple connections\n\
    \   with different RTTs traverse the same bottleneck link, with the long\n   RTT\
    \ connections obtaining only a small fraction of their fair share\n   of the bandwidth.\n\
    \   One effective solution to this problem is to deploy fair queueing and\n  \
    \ TCP-friendly buffer management in network routers [Sut98].  However,\n   in\
    \ the absence of help from the network, other researchers have\n   investigated\
    \ changes to the congestion avoidance policy at the TCP\n   sender, as described\
    \ in [Flo91,HK98].\n"
- title: 3.4.2 Research
  contents:
  - "3.4.2 Research\n   The \"Constant-Rate\" increase policy has been studied in\
    \ [Flo91,HK98].\n   It attempts to equalize the rate at which TCP senders increase\
    \ their\n   sending rate during congestion avoidance.  Both [Flo91] and [HK98]\n\
    \   illustrate cases in which the \"Constant-Rate\" policy largely corrects\n\
    \   the bias against long RTT connections, although [HK98] presents some\n   evidence\
    \ that such a policy may be difficult to incrementally deploy\n   in an operational\
    \ network.  The proper selection of a constant (for\n   the constant rate of increase)\
    \ is an open issue.\n   The \"Increase-by-K\" policy can be selectively used by\
    \ long RTT\n   connections in a heterogeneous environment.  This policy simply\n\
    \   changes the slope of the linear increase, with connections over a\n   given\
    \ RTT threshold adding \"K\" segments to the congestion window\n   every RTT,\
    \ instead of one.  [HK98] presents evidence that this\n   policy, when used with\
    \ small values of \"K\", may be successful in\n   reducing the unfairness while\
    \ keeping the link utilization high, when\n   a small number of connections share\
    \ a bottleneck link.  The selection\n   of the constant \"K,\" the RTT threshold\
    \ to invoke this policy, and\n   performance under a large number of flows are\
    \ all open issues.\n"
- title: 3.4.3 Implementation Issues
  contents:
  - "3.4.3 Implementation Issues\n   Implementation of either the \"Constant-Rate\"\
    \ or \"Increase-by-K\"\n   policies requires a change to the congestion avoidance\
    \ mechanism at\n   the TCP sender.  In the case of \"Constant-Rate,\" such a change\
    \ must\n   be implemented globally.  Additionally, the TCP sender must have a\n\
    \   reasonably accurate estimate of the RTT of the connection.  The\n   algorithms\
    \ outlined above violate the congestion avoidance algorithm\n   as outlined in\
    \ RFC 2581 [APS99] and therefore should not be\n   implemented in shared networks\
    \ at this time.\n"
- title: 3.4.4 Topology Considerations
  contents:
  - "3.4.4 Topology Considerations\n   These solutions are applicable to all satellite\
    \ networks that are\n   integrated with a terrestrial network, in which satellite\
    \ connections\n   may be competing with terrestrial connections for the same bottleneck\n\
    \   link.\n"
- title: 3.4.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.4.5 Possible Interaction and Relationships with Other Research\n   As shown\
    \ in [PADHV99], increasing the congestion window by multiple\n   segments per\
    \ RTT can cause TCP to drop multiple segments and force a\n   retransmission timeout\
    \ in some versions of TCP.  Therefore, the above\n   changes to the congestion\
    \ avoidance algorithm may need to be\n   accompanied by a SACK-based loss recovery\
    \ algorithm that can quickly\n   repair multiple dropped segments.\n"
- title: 3.5 Multiple Data Connections
  contents:
  - '3.5 Multiple Data Connections

    '
- title: 3.5.1 Mitigation Description
  contents:
  - "3.5.1 Mitigation Description\n   One method that has been used to overcome TCP's\
    \ inefficiencies in the\n   satellite environment is to use multiple TCP flows\
    \ to transfer a\n   given file.  The use of N TCP connections makes the sender\
    \ N times\n   more aggressive and therefore can improve throughput in some\n \
    \  situations.  Using N multiple TCP connections can impact the transfer\n   and\
    \ the network in a number of ways, which are listed below.\n   1. The transfer\
    \ is able to start transmission using an effective\n      congestion window of\
    \ N segments, rather than a single segment as\n      one TCP flow uses.  This\
    \ allows the transfer to more quickly\n      increase the effective cwnd size\
    \ to an appropriate size for the\n      given network.  However, in some circumstances\
    \ an initial window\n      of N segments is inappropriate for the network conditions.\
    \  In\n      this case, a transfer utilizing more than one connection may\n  \
    \    aggravate congestion.\n   2. During the congestion avoidance phase, the transfer\
    \ increases the\n      effective cwnd by N segments per RTT, rather than the one\
    \ segment\n      per RTT increase that a single TCP connection provides.  Again,\n\
    \      this can aid the transfer by more rapidly increasing the effective\n  \
    \    cwnd to an appropriate point.  However, this rate of increase can\n     \
    \ also be too aggressive for the network conditions.  In this case,\n      the\
    \ use of multiple data connections can aggravate congestion in\n      the network.\n\
    \   3. Using multiple connections can provide a very large overall\n      congestion\
    \ window.  This can be an advantage for TCP\n      implementations that do not\
    \ support the TCP window scaling\n      extension [JBB92].  However, the aggregate\
    \ cwnd size across all N\n      connections is equivalent to using a TCP implementation\
    \ that\n      supports large windows.\n   4. The overall cwnd decrease in the\
    \ face of dropped segments is\n      reduced when using N parallel connections.\
    \  A single TCP\n      connection reduces the effective size of cwnd to half when\
    \ a\n      single segment loss is detected.  When utilizing N connections\n  \
    \    each using a window of W bytes, a single drop reduces the window\n      to:\n\
    \        (N * W) - (W / 2)\n   Clearly this is a less dramatic reduction in the\
    \ effective cwnd size\n   than when using a single TCP connection.  And, the amount\
    \ by which\n   the cwnd is decreased is further reduced by increasing N.\n   The\
    \ use of multiple data connections can increase the ability of\n   non-SACK TCP\
    \ implementations to quickly recover from multiple dropped\n   segments without\
    \ resorting to a timeout, assuming the dropped\n   segments cross connections.\n\
    \   The use of multiple parallel connections makes TCP overly aggressive\n   for\
    \ many environments and can contribute to congestive collapse in\n   shared networks\
    \ [FF99].  The advantages provided by using multiple\n   TCP connections are now\
    \ largely provided by TCP extensions (larger\n   windows, SACKs, etc.).  Therefore,\
    \ the use of a single TCP connection\n   is more \"network friendly\" than using\
    \ multiple parallel connections.\n   However, using multiple parallel TCP connections\
    \ may provide\n   performance improvement in private networks.\n"
- title: 3.5.2 Research
  contents:
  - "3.5.2 Research\n   Research on the use of multiple parallel TCP connections shows\n\
    \   improved performance [IL92,Hah94,AOK95,AKO96].  In addition, research\n  \
    \ has shown that multiple TCP connections can outperform a single\n   modern TCP\
    \ connection (with large windows and SACK) [AHKO97].\n   However, these studies\
    \ did not consider the impact of using multiple\n   TCP connections on competing\
    \ traffic.  [FF99] argues that using\n   multiple simultaneous connections to\
    \ transfer a given file may lead\n   to congestive collapse in shared networks.\n"
- title: 3.5.3 Implementation Issues
  contents:
  - "3.5.3 Implementation Issues\n   To utilize multiple parallel TCP connections\
    \ a client application and\n   the corresponding server must be customized.  As\
    \ outlined in [FF99]\n   using multiple parallel TCP connections is not safe (from\
    \ a\n   congestion control perspective) in shared networks and should not be\n\
    \   used.\n"
- title: 3.5.4 Topological Considerations
  contents:
  - "3.5.4 Topological Considerations\n   As stated above, [FF99] outlines that the\
    \ use of multiple parallel\n   connections in a shared network, such as the Internet,\
    \ may lead to\n   congestive collapse.  However, the use of multiple connections\
    \ may be\n   safe and beneficial in private networks.  The specific topology being\n\
    \   used will dictate the number of parallel connections required.  Some\n   work\
    \ has been done to determine the appropriate number of connections\n   on the\
    \ fly [AKO96], but such a mechanism is far from complete.\n"
- title: 3.5.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.5.5 Possible Interaction and Relationships with Other Research\n   Using multiple\
    \ concurrent TCP connections enables use of a large\n   congestion window, much\
    \ like the TCP window scaling option [JBB92].\n   In addition, a larger initial\
    \ congestion window is achieved, similar\n   to using [AFP98] or TCB sharing (see\
    \ section 3.8).\n"
- title: 3.6 Pacing TCP Segments
  contents:
  - '3.6 Pacing TCP Segments

    '
- title: 3.6.1 Mitigation Description
  contents:
  - "3.6.1 Mitigation Description\n   Slow-start takes several round trips to fully\
    \ open the TCP congestion\n   window over routes with high bandwidth-delay products.\
    \  For short TCP\n   connections (such as WWW traffic with HTTP/1.0), the slow-start\n\
    \   overhead can preclude effective use of the high-bandwidth satellite\n   links.\
    \  When senders implement slow-start restart after a TCP\n   connection goes idle\
    \ (suggested by Jacobson and Karels [JK92]),\n   performance is reduced in long-lived\
    \ (but bursty) connections (such\n   as HTTP/1.1, which uses persistent TCP connections\
    \ to transfer\n   multiple WWW page elements) [Hei97a].\n   Rate-based pacing\
    \ (RBP) is a technique, used in the absence of\n   incoming ACKs, where the data\
    \ sender temporarily paces TCP segments\n   at a given rate to restart the ACK\
    \ clock.  Upon receipt of the first\n   ACK, pacing is discontinued and normal\
    \ TCP ACK clocking resumes.  The\n   pacing rate may either be known from recent\
    \ traffic estimates (when\n   restarting an idle connection or from recent prior\
    \ connections), or\n   may be known through external means (perhaps in a point-to-point\
    \ or\n   point-to-multipoint satellite network where available bandwidth can\n\
    \   be assumed to be large).\n   In addition, pacing data during the first RTT\
    \ of a transfer may allow\n   TCP to make effective use of high bandwidth-delay\
    \ links even for\n   short transfers.  However, in order to pace segments during\
    \ the first\n   RTT a TCP will have to be using a non-standard initial congestion\n\
    \   window and a new mechanism to pace outgoing segments rather than send\n  \
    \ them back-to-back.  Determining an appropriate size for the initial\n   cwnd\
    \ is an open research question.  Pacing can also be used to reduce\n   bursts\
    \ in general (due to buggy TCPs or byte counting, see section\n   3.2.2 for a\
    \ discussion on byte counting).\n"
- title: 3.6.2 Research
  contents:
  - "3.6.2 Research\n   Simulation studies of rate-paced pacing for WWW-like traffic\
    \ have\n   shown reductions in router congestion and drop rates [VH97a].  In\n\
    \   this environment, RBP substantially improves performance compared to\n   slow-start-after-idle\
    \ for intermittent senders, and it slightly\n   improves performance over burst-full-cwnd-after-idle\
    \ (because of\n   drops) [VH98].  More recently, pacing has been suggested to\
    \ eliminate\n   burstiness in networks with ACK filtering [BPK97].\n"
- title: 3.6.3 Implementation Issues
  contents:
  - "3.6.3 Implementation Issues\n   RBP requires only sender-side changes to TCP.\
    \  Prototype\n   implementations of RBP are available [VH97b].  RBP requires an\n\
    \   additional sender timer for pacing.  The overhead of timer-driven\n   data\
    \ transfer is often considered too high for practical use.\n   Preliminary experiments\
    \ suggest that in RBP this overhead is minimal\n   because RBP only requires this\
    \ timer for one RTT of transmission\n   [VH98].  RBP is expected to make TCP more\
    \ conservative in sending\n   bursts of data after an idle period in hosts that\
    \ do not revert to\n   slow start after an idle period.  On the other hand, RBP\
    \ makes TCP\n   more aggressive if the sender uses the slow start algorithm to\
    \ start\n   the ACK clock after a long idle period.\n"
- title: 3.6.4  Topology Considerations
  contents:
  - "3.6.4  Topology Considerations\n   RBP could be used to restart idle TCP connections\
    \ for all topologies\n   in Section 2.  Use at the beginning of new connections\
    \ would be\n   restricted to topologies where available bandwidth can be estimated\n\
    \   out-of-band.\n"
- title: 3.6.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.6.5 Possible Interaction and Relationships with Other Research\n   Pacing segments\
    \ may benefit from sharing state amongst various flows\n   between two hosts,\
    \ due to the time required to determine the needed\n   information.  Additionally,\
    \ pacing segments, rather than sending\n   back-to-back segments, may make estimating\
    \ the available bandwidth\n   (as outlined in section 3.2.4) more difficult.\n"
- title: 3.7 TCP Header Compression
  contents:
  - "3.7 TCP Header Compression\n   The TCP and IP header information needed to reliably\
    \ deliver packets\n   to a remote site across the Internet can add significant\
    \ overhead,\n   especially for interactive applications.  Telnet packets, for\n\
    \   example, typically carry only a few bytes of data per packet, and\n   standard\
    \ IPv4/TCP headers add at least 40 bytes to this; IPv6/TCP\n   headers add at\
    \ least 60 bytes.  Much of this information remains\n   relatively constant over\
    \ the course of a session and so can be\n   replaced by a short session identifier.\n"
- title: 3.7.1 Mitigation Description
  contents:
  - "3.7.1 Mitigation Description\n   Many fields in the TCP and IP headers either\
    \ remain constant during\n   the course of a session, change very infrequently,\
    \ or can be inferred\n   from other sources.  For example, the source and destination\n\
    \   addresses, as well as the IP version, protocol, and port fields\n   generally\
    \ do not change during a session.  Packet length can be\n   deduced from the length\
    \ field of the underlying link layer protocol\n   provided that the link layer\
    \ packet is not padded.  Packet sequence\n   numbers in a forward data stream\
    \ generally change with every packet,\n   but increase in a predictable manner.\n\
    \   The TCP/IP header compression methods described in\n   [DNP99,DENP97,Jac90]\
    \ reduce the overhead of TCP sessions by replacing\n   the data in the TCP and\
    \ IP headers that remains constant, changes\n   slowly, or changes in a predictable\
    \ manner with a short \"connection\n   number\".  Using this method, the sender\
    \ first sends a full TCP/IP\n   header, including in it a connection number that\
    \ the sender will use\n   to reference the connection.  The receiver stores the\
    \ full header and\n   uses it as a template, filling in some fields from the limited\n\
    \   information contained in later, compressed headers.  This compression\n  \
    \ can reduce the size of an IPv4/TCP headers from 40 to as few as 3 to\n   5 bytes\
    \ (3 bytes for some common cases, 5 bytes in general).\n   Compression and decompression\
    \ generally happen below the IP layer, at\n   the end-points of a given physical\
    \ link (such as at two routers\n   connected by a serial line).  The hosts on\
    \ either side of the\n   physical link must maintain some state about the TCP\
    \ connections that\n   are using the link.\n   The decompresser must pass complete,\
    \ uncompressed packets to the IP\n   layer.  Thus header compression is transparent\
    \ to routing, for\n   example, since an incoming packet with compressed headers\
    \ is expanded\n   before being passed to the IP layer.\n   A variety of methods\
    \ can be used by the compressor/decompressor to\n   negotiate the use of header\
    \ compression.  For example, the PPP serial\n   line protocol allows for an option\
    \ exchange, during which time the\n   compressor/decompressor agree on whether\
    \ or not to use header\n   compression.  For older SLIP implementations, [Jac90]\
    \ describes a\n   mechanism that uses the first bit in the IP packet as a flag.\n\
    \   The reduction in overhead is especially useful when the link is\n   bandwidth-limited\
    \ such as terrestrial wireless and mobile satellite\n   links, where the overhead\
    \ associated with transmitting the header\n   bits is nontrivial.  Header compression\
    \ has the added advantage that\n   for the case of uniformly distributed bit errors,\
    \ compressing TCP/IP\n   headers can provide a better quality of service by decreasing\
    \ the\n   packet error probability.  The shorter, compressed packets are less\n\
    \   likely to be corrupted, and the reduction in errors increases the\n   connection's\
    \ throughput.\n   Extra space is saved by encoding changes in fields that change\n\
    \   relatively slowly by sending only their difference from their values\n   in\
    \ the previous packet instead of their absolute values.  In order to\n   decode\
    \ headers compressed this way, the receiver keeps a copy of each\n   full, reconstructed\
    \ TCP header after it is decoded, and applies the\n   delta values from the next\
    \ decoded compressed header to the\n   reconstructed full header template.\n \
    \  A disadvantage to using this delta encoding scheme where values are\n   encoded\
    \ as deltas from their values in the previous packet is that if\n   a single compressed\
    \ packet is lost, subsequent packets with\n   compressed headers can become garbled\
    \ if they contain fields which\n   depend on the lost packet.  Consider a forward\
    \ data stream of packets\n   with compressed headers and increasing sequence numbers.\
    \  If packet N\n   is lost, the full header of packet N+1 will be reconstructed\
    \ at the\n   receiver using packet N-1's full header as a template.  Thus the\n\
    \   sequence number, which should have been calculated from packet N's\n   header,\
    \ will be wrong, the checksum will fail, and the packet will be\n   discarded.\
    \  When the sending TCP times out and retransmits a packet\n   with a full header\
    \ is forwarded to re-synchronize the decompresser.\n   It is important to note\
    \ that the compressor does not maintain any\n   timers, nor does the decompresser\
    \ know when an error occurred (only\n   the receiving TCP knows this, when the\
    \ TCP checksum fails).  A single\n   bit error will cause the decompresser to\
    \ lose sync, and subsequent\n   packets with compressed headers will be dropped\
    \ by the receiving TCP,\n   since they will all fail the TCP checksum. When this\
    \ happens, no\n   duplicate acknowledgments will be generated, and the decompresser\
    \ can\n   only re-synchronize when it receives a packet with an uncompressed\n\
    \   header.  This means that when header compression is being used, both\n   fast\
    \ retransmit and selective acknowledgments will not be able\n   correct packets\
    \ lost on a compressed link.  The \"twice\" algorithm,\n   described below, may\
    \ be a partial solution to this problem.\n   [DNP99] and [DENP97] describe TCP/IPv4\
    \ and TCP/IPv6 compression\n   algorithms including compressing the various IPv6\
    \ extension headers\n   as well as methods for compressing non-TCP streams.  [DENP97]\
    \ also\n   augments TCP header compression by introducing the \"twice\" algorithm.\n\
    \   If a particular packet fails to decompress properly, the twice\n   algorithm\
    \ modifies its assumptions about the inferred fields in the\n   compressed header,\
    \ assuming that a packet identical to the current\n   one was dropped between\
    \ the last correctly decoded packet and the\n   current one.  Twice then tries\
    \ to decompress the received packet\n   under the new assumptions and, if the\
    \ checksum passes, the packet is\n   passed to IP and the decompresser state has\
    \ been re-synchronized.\n   This procedure can be extended to three or more decoding\
    \ attempts.\n   Additional robustness can be achieved by caching full copies of\n\
    \   packets which don't decompress properly in the hopes that later\n   arrivals\
    \ will fix the problem.  Finally, the performance improvement\n   if the decompresser\
    \ can explicitly request a full header is\n   discussed.  Simulation results show\
    \ that twice, in conjunction with\n   the full header request mechanism, can improve\
    \ throughput over\n   uncompressed streams.\n"
- title: 3.7.2 Research
  contents:
  - "3.7.2 Research\n   [Jac90] outlines a simple header compression scheme for TCP/IP.\n\
    \   In [DENP97] the authors present the results of simulations showing\n   that\
    \ header compression is advantageous for both low and medium\n   bandwidth links.\
    \  Simulations show that the twice algorithm, combined\n   with an explicit header\
    \ request mechanism, improved throughput by\n   10-15% over uncompressed sessions\
    \ across a wide range of bit error\n   rates.\n   Much of this improvement may\
    \ have been due to the twice algorithm\n   quickly re-synchronizing the decompresser\
    \ when a packet is lost.\n   This is because the twice algorithm, applied one\
    \ or two times when\n   the decompresser becomes unsynchronized, will re-sync\
    \ the\n   decompresser in between 83% and 99% of the cases examined.  This\n \
    \  means that packets received correctly after twice has resynchronized\n   the\
    \ decompresser will cause duplicate acknowledgments.  This re-\n   enables the\
    \ use of both fast retransmit and SACK in conjunction with\n   header compression.\n"
- title: 3.7.3 Implementation Issues
  contents:
  - "3.7.3 Implementation Issues\n   Implementing TCP/IP header compression requires\
    \ changes at both the\n   sending (compressor) and receiving (decompresser) ends\
    \ of each link\n   that uses compression.  The twice algorithm requires very little\n\
    \   extra machinery over and above header compression, while the explicit\n  \
    \ header request mechanism of [DENP97] requires more extensive\n   modifications\
    \ to the sending and receiving ends of each link that\n   employs header compression.\
    \  Header compression does not violate\n   TCP's congestion control mechanisms\
    \ and therefore can be safely\n   implemented in shared networks.\n"
- title: 3.7.4 Topology Considerations
  contents:
  - "3.7.4 Topology Considerations\n   TCP/IP header compression is applicable to\
    \ all of the environments\n   discussed in section 2, but will provide relatively\
    \ more improvement\n   in situations where packet sizes are small (i.e., overhead\
    \ is large)\n   and there is medium to low bandwidth and/or higher BER. When TCP's\n\
    \   congestion window size is large, implementing the explicit header\n   request\
    \ mechanism, the twice algorithm, and caching packets which\n   fail to decompress\
    \ properly becomes more critical.\n"
- title: 3.7.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.7.5 Possible Interaction and Relationships with Other Research\n   As discussed\
    \ above, losing synchronization between a sender and\n   receiver can cause many\
    \ packet drops.  The frequency of losing\n   synchronization and the effectiveness\
    \ of the twice algorithm may\n   point to using a SACK-based loss recovery algorithm\
    \ to reduce the\n   impact of multiple lost segments.  However, even very robust\
    \ SACK-\n   based algorithms may not work well if too many segments are lost.\n"
- title: 3.8 Sharing TCP State Among Similar Connections
  contents:
  - '3.8 Sharing TCP State Among Similar Connections

    '
- title: 3.8.1 Mitigation Description
  contents:
  - "3.8.1 Mitigation Description\n   Persistent TCP state information can be used\
    \ to overcome limitations\n   in the configuration of the initial state, and to\
    \ automatically tune\n   TCP to environments using satellite links and to coordinate\
    \ multiple\n   TCP connections sharing a satellite link.\n   TCP includes a variety\
    \ of parameters, many of which are set to\n   initial values which can severely\
    \ affect the performance of TCP\n   connections traversing satellite links, even\
    \ though most TCP\n   parameters are adjusted later after the connection is established.\n\
    \   These parameters include initial size of cwnd and initial MSS size.\n   Various\
    \ suggestions have been made to change these initial\n   conditions, to more effectively\
    \ support satellite links.  However, it\n   is difficult to select any single\
    \ set of parameters which is\n   effective for all environments.\n   An alternative\
    \ to attempting to select these parameters a-priori is\n   sharing state across\
    \ TCP connections and using this state when\n   initializing a new connection.\
    \  For example, if all connections to a\n   subnet result in extended congestion\
    \ windows of 1 megabyte, it is\n   probably more efficient to start new connections\
    \ with this value,\n   than to rediscover it by requiring the cwnd to increase\
    \ using slow\n   start over a period of dozens of round-trip times.\n"
- title: 3.8.2 Research
  contents:
  - "3.8.2 Research\n   Sharing state among connections brings up a number of questions\
    \ such\n   as what information to share, with whom to share, how to share it,\n\
    \   and how to age shared information.  First, what information is to be\n   shared\
    \ must be determined.  Some information may be appropriate to\n   share among\
    \ TCP connections, while some information sharing may be\n   inappropriate or\
    \ not useful.  Next, we need to determine with whom to\n   share information.\
    \  Sharing may be appropriate for TCP connections\n   sharing a common path to\
    \ a given host.  Information may be shared\n   among connections within a host,\
    \ or even among connections between\n   different hosts, such as hosts on the\
    \ same LAN.  However, sharing\n   information between connections not traversing\
    \ the same network may\n   not be appropriate.  Given the state to share and the\
    \ parties that\n   share it, a mechanism for the sharing is required.  Simple\
    \ state,\n   like MSS and RTT, is easy to share, but congestion window information\n\
    \   can be shared a variety of ways. The sharing mechanism determines\n   priorities\
    \ among the sharing connections, and a variety of fairness\n   criteria need to\
    \ be considered.  Also, the mechanisms by which\n   information is aged require\
    \ further study.  See RFC 2140 for a\n   discussion of the security issues in\
    \ both sharing state within a\n   single host and sharing state among hosts on\
    \ a subnet.  Finally, the\n   security concerns associated with sharing a piece\
    \ of information need\n   to be carefully considered before introducing such a\
    \ mechanism.  Many\n   of these open research questions must be answered before\
    \ state\n   sharing can be widely deployed.\n   The opportunity for such sharing,\
    \ both among a sequence of\n   connections, as well as among concurrent connections,\
    \ is described in\n   more detail in [Tou97].  The state management itself is\
    \ largely an\n   implementation issue, however what information should be shared\
    \ and\n   the specific ways in which the information should be shared is an\n\
    \   open question.\n   Sharing parts of the TCB state was originally documented\
    \ in T/TCP\n   [Bra92], and is used there to aggregate RTT values across connection\n\
    \   instances, to provide meaningful average RTTs, even though most\n   connections\
    \ are expected to persist for only one RTT.  T/TCP also\n   shares a connection\
    \ identifier, a sequence number separate from the\n   window number and address/port\
    \ pairs by which TCP connections are\n   typically distinguished. As a result\
    \ of this shared state, T/TCP\n   allows a receiver to pass data in the SYN segment\
    \ to the receiving\n   application, prior to the completion of the three-way handshake,\n\
    \   without compromising the integrity of the connection. In effect, this\n  \
    \ shared state caches a partial handshake from the previous connection,\n   which\
    \ is a variant of the more general issue of TCB sharing.\n   Sharing state among\
    \ connections (including transfers using non-TCP\n   protocols) is further investigated\
    \ in [BRS99].\n"
- title: 3.8.3 Implementation Issues
  contents:
  - "3.8.3 Implementation Issues\n   Sharing TCP state across connections requires\
    \ changes to the sender's\n   TCP stack, and possibly the receiver's TCP stack\
    \ (as in the case of\n   T/TCP, for example).  Sharing TCP state may make a particular\
    \ TCP\n   connection more aggressive.  However, the aggregate traffic should be\n\
    \   more conservative than a group of independent TCP connections.\n   Therefore,\
    \ sharing TCP state should be safe for use in shared\n   networks.  Note that\
    \ state sharing does not present any new security\n   problems within multiuser\
    \ hosts.  In such a situation, users can\n   steal network resources from one\
    \ another with or without state\n   sharing.\n"
- title: 3.8.4 Topology Considerations
  contents:
  - "3.8.4 Topology Considerations\n   It is expected that sharing state across TCP\
    \ connections may be\n   useful in all network environments presented in section\
    \ 2.\n"
- title: 3.8.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.8.5 Possible Interaction and Relationships with Other Research\n   The state\
    \ sharing outlined above is very similar to the Congestion\n   Manager proposal\
    \ [BRS99] that attempts to share congestion control\n   information among both\
    \ TCP and UDP flows between a pair of hosts.\n"
- title: 3.9 ACK Congestion Control
  contents:
  - "3.9 ACK Congestion Control\n   In highly asymmetric networks, a low-speed return\
    \ link can restrict\n   the performance of the data flow on a high-speed forward\
    \ link by\n   limiting the flow of acknowledgments returned to the data sender.\n\
    \   For example, if the data sender uses 1500 byte segments, and the\n   receiver\
    \ generates 40 byte acknowledgments (IPv4, TCP without\n   options), the reverse\
    \ link will congest with ACKs for asymmetries of\n   more than 75:1 if delayed\
    \ ACKs are used, and 37:1 if every segment is\n   acknowledged.  For a 1.5 Mb/second\
    \ data link, ACK congestion will\n   occur for reverse link speeds below 20 kilobits/sec.\
    \  These levels of\n   asymmetry will readily occur if the reverse link is shared\
    \ among\n   multiple satellite receivers, as is common in many VSAT satellite\n\
    \   networks.  If a terrestrial modem link is used as a reverse link, ACK\n  \
    \ congestion is also likely, especially as the speed of the forward\n   link is\
    \ increased.  Current congestion control mechanisms are aimed\n   at controlling\
    \ the flow of data segments, but do not affect the flow\n   of ACKs.\n   In [KVR98]\
    \ the authors point out that the flow of acknowledgments can\n   be restricted\
    \ on the low-speed link not only by the bandwidth of the\n   link, but also by\
    \ the queue length of the router.  The router may\n   limit its queue length by\
    \ counting packets, not bytes, and therefore\n   begin discarding ACKs even if\
    \ there is enough bandwidth to forward\n   them.\n"
- title: 3.9.1 Mitigation Description
  contents:
  - "3.9.1 Mitigation Description\n   ACK Congestion Control extends the concept of\
    \ flow control for data\n   segments to acknowledgment segments.  In the method\
    \ described in\n   [BPK97], any intermediate router can mark an acknowledgment\
    \ with an\n   Explicit Congestion Notification (ECN) bit once the queue occupancy\n\
    \   in the router exceeds a given threshold.  The data sender (which\n   receives\
    \ the acknowledgment) must \"echo\" the ECN bit back to the data\n   receiver\
    \ (see section 3.3.3 for a more detailed discussion of ECN).\n   The proposed\
    \ algorithm for marking ACK segments with an ECN bit is\n   Random Early Detection\
    \ (RED) [FJ93].  In response to the receipt of\n   ECN marked data segments, the\
    \ receiver will dynamically reduce the\n   rate of acknowledgments using a multiplicative\
    \ backoff.  Once\n   segments without ECN are received, the data receiver speeds\
    \ up\n   acknowledgments using a linear increase, up to a rate of either 1 (no\n\
    \   delayed ACKs) or 2 (normal delayed ACKs) data segments per ACK.  The\n   authors\
    \ suggest that an ACK be generated at least once per window,\n   and ideally a\
    \ few times per window.\n   As in the RED congestion control mechanism for data\
    \ flow, the\n   bottleneck gateway can randomly discard acknowledgments, rather\
    \ than\n   marking them with an ECN bit, once the queue fills beyond a given\n\
    \   threshold.\n"
- title: 3.9.2 Research
  contents:
  - "3.9.2 Research\n   [BPK97] analyze the effect of ACK Congestion Control (ACC)\
    \ on the\n   performance of an asymmetric network.  They note that the use of\
    \ ACC,\n   and indeed the use of any scheme which reduces the frequency of\n \
    \  acknowledgments, has potential unwanted side effects.  Since each ACK\n   will\
    \ acknowledge more than the usual one or two data segments, the\n   likelihood\
    \ of segment bursts from the data sender is increased.  In\n   addition, congestion\
    \ window growth may be impeded if the receiver\n   grows the window by counting\
    \ received ACKs, as mandated by\n   [Ste97,APS99].  The authors therefore combine\
    \ ACC with a series of\n   modifications to the data sender, referred to as TCP\
    \ Sender\n   Adaptation (SA).  SA combines a limit on the number of segments sent\n\
    \   in a burst, regardless of window size.  In addition, byte counting\n   (as\
    \ opposed to ACK counting) is employed for window growth.  Note\n   that byte\
    \ counting has been studied elsewhere and can introduce\n   side-effects, as well\
    \ [All98].\n   The results presented in [BPK97] indicate that using ACC and SA\
    \ will\n   reduce the bursts produced by ACK losses in unmodified (Reno) TCP.\n\
    \   In cases where these bursts would lead to data loss at an\n   intermediate\
    \ router, the ACC and SA modification significantly\n   improve the throughput\
    \ for a single data transfer.  The results\n   further suggest that the use of\
    \ ACC and SA significantly improve\n   fairness between two simultaneous transfers.\n\
    \   ACC is further reported to prevent the increase in round trip time\n   (RTT)\
    \ that occurs when an unmodified TCP fills the reverse router\n   queue with acknowledgments.\n\
    \   In networks where the forward direction is expected to suffer losses\n   in\
    \ one of the gateways, due to queue limitations, the authors report\n   at best\
    \ a very slight improvement in performance for ACC and SA,\n   compared to unmodified\
    \ Reno TCP.\n"
- title: 3.9.3 Implementation Issues
  contents:
  - "3.9.3 Implementation Issues\n   Both ACC and SA require modification of the sending\
    \ and receiving\n   hosts, as well as the bottleneck gateway.  The current research\n\
    \   suggests that implementing ACC without the SA modifications results\n   in\
    \ a data sender which generates potentially disruptive segment\n   bursts.  It\
    \ should be noted that ACC does require host modifications\n   if it is implemented\
    \ in the way proposed in [BPK97].  The authors\n   note that ACC can be implemented\
    \ by discarding ACKs (which requires\n   only a gateway modification, but no changes\
    \ in the hosts), as opposed\n   to marking them with ECN.  Such an implementation\
    \ may, however,\n   produce bursty data senders if it is not combined with a burst\n\
    \   mitigation technique.  ACC requires changes to the standard ACKing\n   behavior\
    \ of a receiving TCP and therefore is not recommended for use\n   in shared networks.\n"
- title: 3.9.4 Topology Considerations
  contents:
  - "3.9.4 Topology Considerations\n   Neither ACC nor SA require the storage of state\
    \ in the gateway.\n   These schemes should therefore be applicable for all topologies,\n\
    \   provided that the hosts using the satellite or hybrid network can be\n   modified.\
    \  However, these changes are expected to be especially\n   beneficial to networks\
    \ containing asymmetric satellite links.\n"
- title: 3.9.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.9.5 Possible Interaction and Relationships with Other Research\n   Note that\
    \ ECN is a pre-condition for using ACK congestion control.\n   Additionally, the\
    \ ACK Filtering algorithm discussed in the next\n   section attempts to solve\
    \ the same problem as ACC.  Choosing between\n   the two algorithms (or another\
    \ mechanism) is currently an open\n   research question.\n"
- title: 3.10 ACK Filtering
  contents:
  - "3.10 ACK Filtering\n   ACK Filtering (AF) is designed to address the same ACK\
    \ congestion\n   effects described in 3.9.  Contrary to ACC, however, AF is designed\n\
    \   to operate without host modifications.\n"
- title: 3.10.1 Mitigation Description
  contents:
  - "3.10.1 Mitigation Description\n   AF takes advantage of the cumulative acknowledgment\
    \ structure of TCP.\n   The bottleneck router in the reverse direction (the low\
    \ speed link)\n   must be modified to implement AF.  Upon receipt of a segment\
    \ which\n   represents a TCP acknowledgment, the router scans the queue for\n\
    \   redundant ACKs for the same connection, i.e. ACKs which acknowledge\n   portions\
    \ of the window which are included in the most recent ACK.\n   All of these \"\
    earlier\" ACKs are removed from the queue and discarded.\n   The router does not\
    \ store state information, but does need to\n   implement the additional processing\
    \ required to find and remove\n   segments from the queue upon receipt of an ACK.\n"
- title: 3.10.2  Research
  contents:
  - "3.10.2  Research\n   [BPK97] analyzes the effects of AF.  As is the case in ACC,\
    \ the use\n   of ACK filtering alone would produce significant sender bursts,\
    \ since\n   the ACKs will be acknowledging more previously-unacknowledged data.\n\
    \   The SA modifications described in 3.9.2 could be used to prevent\n   those\
    \ bursts, at the cost of requiring host modifications.  To\n   prevent the need\
    \ for modifications in the TCP stack, AF is more\n   likely to be paired with\
    \ the ACK Reconstruction (AR) technique, which\n   can be implemented at the router\
    \ where segments exit the slow reverse\n   link.\n   AR inspects ACKs exiting\
    \ the link, and if it detects large \"gaps\" in\n   the ACK sequence, it generates\
    \ additional ACKs to reconstruct an\n   acknowledgment flow which more closely\
    \ resembles what the data sender\n   would have seen had ACK Filtering not been\
    \ introduced.  AR requires\n   two parameters; one parameter is the desired ACK\
    \ frequency, while the\n   second controls the spacing, in time, between the release\
    \ of\n   consecutive reconstructed ACKs.\n   In [BPK97], the authors show the\
    \ combination of AF and AR to increase\n   throughput, in the networks studied,\
    \ over both unmodified TCP and the\n   ACC/SA modifications.  Their results also\
    \ strongly suggest that the\n   use of AF alone, in networks where congestion\
    \ losses are expected,\n   decreases performance (even below the level of unmodified\
    \ TCP Reno)\n   due to sender bursting.\n   AF delays acknowledgments from arriving\
    \ at the receiver by dropping\n   earlier ACKs in favor of later ACKs.  This process\
    \ can cause a slight\n   hiccup in the transmission of new data by the TCP sender.\n"
- title: 3.10.3 Implementation Issues
  contents:
  - "3.10.3 Implementation Issues\n   Both ACK Filtering and ACK Reconstruction require\
    \ only router\n   modification.  However, the implementation of AR requires some\n\
    \   storage of state information in the exit router.  While AF does not\n   require\
    \ storage of state information, its use without AR (or SA)\n   could produce undesired\
    \ side effects.  Furthermore, more research is\n   required regarding appropriate\
    \ ranges for the parameters needed in\n   AR.\n"
- title: 3.10.4 Topology Considerations
  contents:
  - "3.10.4 Topology Considerations\n   AF and AR appear applicable to all topologies,\
    \ assuming that the\n   storage of state information in AR does not prove to be\
    \ prohibitive\n   for routers which handle large numbers of flows.  The fact that\
    \ TCP\n   stack modifications are not required for AF/AR makes this approach\n\
    \   attractive for hybrid networks and networks with diverse types of\n   hosts.\
    \  These modifications, however, are expected to be most\n   beneficial in asymmetric\
    \ network paths.\n   On the other hand, the implementation of AF/AR requires the\
    \ routers\n   to examine the TCP header, which prohibits their use in secure\n\
    \   networks where IPSEC is deployed.  In such networks, AF/AR can be\n   effective\
    \ only inside the security perimeter of a private, or virtual\n   private network,\
    \ or in private networks where the satellite link is\n   protected only by link-layer\
    \ encryption (as opposed to IPSEC).  ACK\n   Filtering is safe to use in shared\
    \ networks (from a congestion\n   control point-of-view), as the number of ACKs\
    \ can only be reduced,\n   which makes TCP less aggressive.  However, note that\
    \ while TCP is\n   less aggressive, the delays that AF induces (outlined above)\
    \ can lead\n   to larger bursts than would otherwise occur.\n"
- title: 3.10.5 Possible Interaction and Relationships with Other Research
  contents:
  - "3.10.5 Possible Interaction and Relationships with Other Research\n   ACK Filtering\
    \ attempts to solve the same problem as ACK Congestion\n   Control (as outlined\
    \ in section 3.9).  Which of the two algorithms is\n   more appropriate is currently\
    \ an open research question.\n"
- title: 4   Conclusions
  contents:
  - "4   Conclusions\n   This document outlines TCP items that may be able to mitigate\
    \ the\n   performance problems associated with using TCP in networks containing\n\
    \   satellite links.  These mitigations are not IETF standards track\n   mechanisms\
    \ and require more study before being recommended by the\n   IETF.  The research\
    \ community is encouraged to examine the above\n   mitigations in an effort to\
    \ determine which are safe for use in\n   shared networks such as the Internet.\n"
- title: 5   Security Considerations
  contents:
  - "5   Security Considerations\n   Several of the above sections noted specific\
    \ security concerns which\n   a given mitigation aggravates.\n   Additionally,\
    \ any form of wireless communication link is more\n   susceptible to eavesdropping\
    \ security attacks than standard wire-\n   based links due to the relative ease\
    \ with which an attacker can watch\n   the network and the difficultly in finding\
    \ attackers monitoring the\n   network.\n"
- title: 6   Acknowledgments
  contents:
  - "6   Acknowledgments\n   Our thanks to Aaron Falk and Sally Floyd, who provided\
    \ very helpful\n   comments on drafts of this document.\n"
- title: 7   References
  contents:
  - "7   References\n   [AFP98]   Allman, M., Floyd, S. and C. Partridge, \"Increasing\
    \ TCP's\n             Initial Window\", RFC 2414, September 1998.\n   [AGS99]\
    \   Allman, M., Glover, D. and L. Sanchez, \"Enhancing TCP Over\n            \
    \ Satellite Channels using Standard Mechanisms\", BCP 28, RFC\n             2488,\
    \ January 1999.\n   [AHKO97]  Mark Allman, Chris Hayes, Hans Kruse, Shawn Ostermann.\
    \  TCP\n             Performance Over Satellite Links.  In Proceedings of the\n\
    \             5th International Conference on Telecommunication Systems,\n   \
    \          March 1997.\n   [AHO98]   Mark Allman, Chris Hayes, Shawn Ostermann.\
    \  An Evaluation\n             of TCP with Larger Initial Windows.  Computer Communication\n\
    \             Review, 28(3), July 1998.\n   [AKO96]   Mark Allman, Hans Kruse,\
    \ Shawn Ostermann.  An Application-\n             Level Solution to TCP's Satellite\
    \ Inefficiencies.  In\n             Proceedings of the First International Workshop\
    \ on\n             Satellite-based Information Services (WOSBIS), November\n \
    \            1996.\n   [All97a]  Mark Allman.  Improving TCP Performance Over\
    \ Satellite\n             Channels.  Master's thesis, Ohio University, June 1997.\n\
    \   [All97b]  Mark Allman.  Fixing Two BSD TCP Bugs.  Technical Report\n     \
    \        CR-204151, NASA Lewis Research Center, October 1997.\n   [All98]   Mark\
    \ Allman. On the Generation and Use of TCP\n             Acknowledgments.  ACM\
    \ Computer Communication Review, 28(5),\n             October 1998.\n   [AOK95]\
    \   Mark Allman, Shawn Ostermann, Hans Kruse.  Data Transfer\n             Efficiency\
    \ Over Satellite Circuits Using a Multi-Socket\n             Extension to the\
    \ File Transfer Protocol (FTP).  In\n             Proceedings of the ACTS Results\
    \ Conference, NASA Lewis\n             Research Center, September 1995.\n   [AP99]\
    \    Mark Allman, Vern Paxson.  On Estimating End-to-End Network\n           \
    \  Path Properties. ACM SIGCOMM, September 1999.\n   [APS99]   Allman, M., Paxson,\
    \ V. and W. Richard Stevens, \"TCP\n             Congestion Control\", RFC 2581,\
    \ April 1999.\n   [BCC+98]  Braden, B., Clark, D., Crowcroft, J., Davie, B., Deering,\n\
    \             S., Estrin, D., Floyd, S., Jacobson, V., Minshall, G.,\n       \
    \      Partridge, C., Peterson, L., Ramakrishnan, K., Shenker, S.,\n         \
    \    Wroclawski, J. and L. Zhang, \"Recommendations on Queue\n             Management\
    \ and Congestion Avoidance in the Internet\", RFC\n             2309, April 1998.\n\
    \   [BKVP97]  B. Bakshi and P. Krishna and N. Vaidya and D. Pradham,\n       \
    \      \"Improving Performance of TCP over Wireless Networks\", 17th\n       \
    \      International Conference on Distributed Computing Systems\n           \
    \  (ICDCS), May 1997.\n   [BPK97]   Hari Balakrishnan, Venkata N. Padmanabhan,\
    \ and Randy H.\n             Katz.  The Effects of Asymmetry on TCP Performance.\
    \  In\n             Proceedings of the ACM/IEEE Mobicom, Budapest, Hungary,\n\
    \             ACM.  September, 1997.\n   [BPK98]   Hari Balakrishnan, Venkata\
    \ Padmanabhan, Randy H. Katz.  The\n             Effects of Asymmetry on TCP Performance.\
    \  ACM Mobile\n             Networks and Applications (MONET), 1998 (to appear).\n\
    \   [BPSK96]  H. Balakrishnan and V. Padmanabhan and S. Sechan and R.\n      \
    \       Katz, \"A Comparison of Mechanisms for Improving TCP\n             Performance\
    \ over Wireless Links\", ACM SIGCOMM, August 1996.\n   [Bra89]   Braden, R., \"\
    Requirements for Internet Hosts --\n             Communication Layers\", STD 3,\
    \ RFC 1122, October 1989.\n   [Bra92]   Braden, R., \"Transaction TCP -- Concepts\"\
    , RFC 1379,\n             September 1992.\n   [Bra94]   Braden, R., \"T/TCP --\
    \ TCP Extensions for Transactions:\n             Functional Specification\", RFC\
    \ 1644, July 1994.\n   [BRS99]   Hari Balakrishnan, Hariharan Rahul, and Srinivasan\
    \ Seshan.\n             An Integrated Congestion Management Architecture for\n\
    \             Internet Hosts.  ACM SIGCOMM, September 1999.\n   [ddKI99]  M. deVivo,\
    \ G.O. deVivo, R. Koeneke, G. Isern.  Internet\n             Vulnerabilities Related\
    \ to TCP/IP and T/TCP.  Computer\n             Communication Review, 29(1), January\
    \ 1999.\n   [DENP97]  Mikael Degermark, Mathias Engan, Bjorn Nordgren, Stephen\n\
    \             Pink.  Low-Loss TCP/IP Header Compression for Wireless\n       \
    \      Networks.  ACM/Baltzer Journal on Wireless Networks, vol.3,\n         \
    \    no.5, p. 375-87.\n   [DMT96]   R. C. Durst and G. J. Miller and E. J. Travis,\
    \ \"TCP\n             Extensions for Space Communications\", Mobicom 96, ACM,\
    \ USA,\n             1996.\n   [DNP99]   Degermark, M., Nordgren, B. and S. Pink,\
    \ \"IP Header\n             Compression\", RFC 2507, February 1999.\n   [FF96]\
    \    Kevin Fall, Sally Floyd.  Simulation-based Comparisons of\n             Tahoe,\
    \ Reno, and SACK TCP.  Computer Communication Review,\n             V. 26 N. 3,\
    \ July 1996, pp. 5-21.\n   [FF99]    Sally Floyd, Kevin Fall.  Promoting the Use\
    \ of End-to-End\n             Congestion Control in the Internet, IEEE/ACM Transactions\n\
    \             on Networking, August 1999.\n   [FH99]    Floyd, S. and T. Henderson,\
    \ \"The NewReno Modification to\n             TCP's Fast Recovery Algorithm\"\
    , RFC 2582, April 1999.\n   [FJ93]    Sally Floyd and Van Jacobson.  Random Early\
    \ Detection\n             Gateways for Congestion Avoidance, IEEE/ACM Transactions\
    \ on\n             Networking, V. 1 N. 4, August 1993.\n   [Flo91]   Sally Floyd.\
    \  Connections with Multiple Congested Gateways\n             in Packet-Switched\
    \ Networks, Part 1: One-way Traffic.  ACM\n             Computer Communications\
    \ Review, V. 21, N. 5, October 1991.\n   [Flo94]   Sally Floyd.  TCP and Explicit\
    \ Congestion Notification, ACM\n             Computer Communication Review, V.\
    \ 24 N. 5, October 1994.\n   [Flo99]   Sally Floyd.  \"Re: TCP and out-of-order\
    \ delivery\", email to\n             end2end-interest mailing list, February,\
    \ 1999.\n   [Hah94]   Jonathan Hahn.  MFTP: Recent Enhancements and Performance\n\
    \             Measurements.  Technical Report RND-94-006, NASA Ames\n        \
    \     Research Center, June 1994.\n   [Hay97]   Chris Hayes.  Analyzing the Performance\
    \ of New TCP\n             Extensions Over Satellite Links.  Master's Thesis,\
    \ Ohio\n             University, August 1997.\n   [HK98]    Tom Henderson, Randy\
    \ Katz.  On Improving the Fairness of\n             TCP Congestion Avoidance.\
    \  Proceedings of IEEE Globecom `98\n             Conference, 1998.\n   [HK99]\
    \    Tim Henderson, Randy Katz.  Transport Protocols for\n             Internet-Compatible\
    \ Satellite Networks, IEEE Journal on\n             Selected Areas of Communications,\
    \ February, 1999.\n   [Hoe95]   J. Hoe, Startup Dynamics of TCP's Congestion Control\
    \ and\n             Avoidance Schemes. Master's Thesis, MIT, 1995.\n   [Hoe96]\
    \   Janey Hoe.  Improving the Startup Behavior of a Congestion\n             Control\
    \ Scheme for TCP.  In ACM SIGCOMM, August 1996.\n   [IL92]    David Iannucci and\
    \ John Lakashman.  MFTP: Virtual TCP\n             Window Scaling Using Multiple\
    \ Connections.  Technical\n             Report RND-92-002, NASA Ames Research\
    \ Center, January 1992.\n   [Jac88]   Van Jacobson.  Congestion Avoidance and\
    \ Control.  In\n             Proceedings of the SIGCOMM '88, ACM.  August, 1988.\n\
    \   [Jac90]   Jacobson, V., \"Compressing TCP/IP Headers\", RFC 1144,\n      \
    \       February 1990.\n   [JBB92]   Jacobson, V., Braden, R. and D. Borman, \"\
    TCP Extensions for\n             High Performance\", RFC 1323, May 1992.\n   [JK92]\
    \    Van Jacobson and Mike Karels.  Congestion Avoidance and\n             Control.\
    \  Originally appearing in the proceedings of\n             SIGCOMM '88 by Jacobson\
    \ only, this revised version includes\n             an additional appendix.  The\
    \ revised version is available\n             at ftp://ftp.ee.lbl.gov/papers/congavoid.ps.Z.\
    \  1992.\n   [Joh95]   Stacy Johnson.  Increasing TCP Throughput by Using an\n\
    \             Extended Acknowledgment Interval.  Master's Thesis, Ohio\n     \
    \        University, June 1995.\n   [KAGT98]  Hans Kruse, Mark Allman, Jim Griner,\
    \ Diepchi Tran.  HTTP\n             Page Transfer Rates Over Geo-Stationary Satellite\
    \ Links.\n             March 1998. Proceedings of the Sixth International\n  \
    \           Conference on Telecommunication Systems.\n   [Kes91]   Srinivasan\
    \ Keshav.  A Control Theoretic Approach to Flow\n             Control.  In ACM\
    \ SIGCOMM, September 1991.\n   [KM97]    S. Keshav, S. Morgan. SMART Retransmission:\
    \ Performance\n             with Overload and Random Losses. Proceeding of Infocom.\n\
    \             1997.\n   [KVR98]   Lampros Kalampoukas, Anujan Varma, and K. K.Ramakrishnan.\n\
    \             Improving TCP Throughput Over Two-Way Asymmetric Links:\n      \
    \       Analysis and Solutions.  Measurement and Modeling of\n             Computer\
    \ Systems, 1998, Pages 78-89.\n   [MM96a]   M. Mathis, J. Mahdavi, \"Forward Acknowledgment:\
    \ Refining\n             TCP Congestion Control,\" Proceedings of SIGCOMM'96,\
    \ August,\n             1996, Stanford, CA.  Available from\n             http://www.psc.edu/networking/papers/papers.html\n\
    \   [MM96b]   M. Mathis, J. Mahdavi, \"TCP Rate-Halving with Bounding\n      \
    \       Parameters\" Available from\n             http://www.psc.edu/networking/papers/FACKnotes/current.\n\
    \   [MMFR96]  Mathis, M., Mahdavi, J., Floyd, S. and A. Romanow, \"TCP\n     \
    \        Selective Acknowledgment Options\", RFC 2018, October 1996.\n   [MSMO97]\
    \  M. Mathis, J. Semke, J. Mahdavi, T. Ott, \"The Macroscopic\n             Behavior\
    \ of the TCP Congestion Avoidance\n             Algorithm\",Computer Communication\
    \ Review, volume 27,\n             number3, July 1997.  Available from\n     \
    \        http://www.psc.edu/networking/papers/papers.html\n   [MV98]    Miten\
    \ N. Mehta and Nitin H. Vaidya.  Delayed Duplicate-\n             Acknowledgments:\
    \ A Proposal to Improve Performance of TCP\n             on Wireless Links.  Technical\
    \ Report 98-006, Department of\n             Computer Science, Texas A&M University,\
    \ February 1998.\n   [Nic97]   Kathleen Nichols.  Improving Network Simulation\
    \ with\n             Feedback.  Com21, Inc. Technical Report.  Available from\n\
    \             http://www.com21.com/pages/papers/068.pdf.\n   [PADHV99] Paxson,\
    \ V., Allman, M., Dawson, S., Heavens, I. and B.\n             Volz, \"Known TCP\
    \ Implementation Problems\", RFC 2525, March\n             1999.\n   [Pax97] \
    \  Vern Paxson.  Automated Packet Trace Analysis of TCP\n             Implementations.\
    \  In Proceedings of ACM SIGCOMM, September\n             1997.\n   [PN98]   \
    \ Poduri, K. and K. Nichols, \"Simulation Studies of Increased\n             Initial\
    \ TCP Window Size\", RFC 2415, September 1998.\n   [Pos81]   Postel, J., \"Transmission\
    \ Control Protocol\", STD 7, RFC\n             793, September 1981.\n   [RF99]\
    \    Ramakrishnan, K. and S. Floyd, \"A Proposal to add Explicit\n           \
    \  Congestion Notification (ECN) to IP\", RFC 2481, January\n             1999.\n\
    \   [SF98]    Nihal K. G. Samaraweera and Godred Fairhurst,\n             \"Reinforcement\
    \ of TCP error Recovery for Wireless\n             Communication\", Computer Communication\
    \ Review, volume 28,\n             number 2, April 1998.\n   [SP98]    Shepard,\
    \ T. and C. Partridge, \"When TCP Starts Up With Four\n             Packets Into\
    \ Only Three Buffers\", RFC 2416, September 1998.\n   [Ste97]   Stevens, W., \"\
    TCP Slow Start, Congestion Avoidance, Fast\n             Retransmit, and Fast\
    \ Recovery Algorithms\", RFC 2001,\n             January 1997.\n   [Sut98]   B.\
    \ Suter, T. Lakshman, D. Stiliadis, and A. Choudhury.\n             Design Considerations\
    \ for Supporting TCP with Per-flow\n             Queueing.  Proceedings of IEEE\
    \ Infocom `98 Conference,\n             1998.\n   [Tou97]   Touch, J., \"TCP Control\
    \ Block Interdependence\", RFC 2140,\n             April 1997.\n   [VH97a]   Vikram\
    \ Visweswaraiah and John Heidemann.  Improving Restart\n             of Idle TCP\
    \ Connections.  Technical Report 97-661,\n             University of Southern\
    \ California, 1997.\n   [VH97b]   Vikram Visweswaraiah and John Heidemann.  Rate-based\
    \ pacing\n             Source Code Distribution, Web page:\n             http://www.isi.edu/lsam/publications/rate_based_pacing/README.html\n\
    \             November, 1997.\n   [VH98]    Vikram Visweswaraiah and John Heidemann.\
    \  Improving Restart\n             of Idle TCP Connections (revised).  Submitted\
    \ for\n             publication.\n"
- title: 8   Authors' Addresses
  contents:
  - "8   Authors' Addresses\n   Mark Allman\n   NASA Glenn Research Center/BBN Technologies\n\
    \   Lewis Field\n   21000 Brookpark Rd.  MS 54-2\n   Cleveland, OH  44135\n  \
    \ EMail: mallman@grc.nasa.gov\n   http://roland.grc.nasa.gov/~mallman\n   Spencer\
    \ Dawkins\n   Nortel\n   P.O.Box 833805\n   Richardson, TX 75083-3805\n   EMail:\
    \ Spencer.Dawkins.sdawkins@nt.com\n   Dan Glover\n   NASA Glenn Research Center\n\
    \   Lewis Field\n   21000 Brookpark Rd.  MS 3-6\n   Cleveland, OH  44135\n   EMail:\
    \ Daniel.R.Glover@grc.nasa.gov\n   http://roland.grc.nasa.gov/~dglover\n   Jim\
    \ Griner\n   NASA Glenn Research Center\n   Lewis Field\n   21000 Brookpark Rd.\
    \  MS 54-2\n   Cleveland, OH  44135\n   EMail: jgriner@grc.nasa.gov\n   http://roland.grc.nasa.gov/~jgriner\n\
    \   Diepchi Tran\n   NASA Glenn Research Center\n   Lewis Field\n   21000 Brookpark\
    \ Rd.  MS 54-2\n   Cleveland, OH  44135\n   EMail: dtran@grc.nasa.gov\n   Tom\
    \ Henderson\n   University of California at Berkeley\n   Phone: +1 (510) 642-8919\n\
    \   EMail: tomh@cs.berkeley.edu\n   URL: http://www.cs.berkeley.edu/~tomh/\n \
    \  John Heidemann\n   University of Southern California/Information Sciences Institute\n\
    \   4676 Admiralty Way\n   Marina del Rey, CA 90292-6695\n   EMail: johnh@isi.edu\n\
    \   Joe Touch\n   University of Southern California/Information Sciences Institute\n\
    \   4676 Admiralty Way\n   Marina del Rey, CA 90292-6601\n   USA\n   Phone: +1\
    \ 310-448-9151\n   Fax:   +1 310-823-6714\n   URL:   http://www.isi.edu/touch\n\
    \   EMail: touch@isi.edu\n   Hans Kruse\n   J. Warren McClure School of Communication\
    \ Systems Management\n   Ohio University\n   9 S. College Street\n   Athens, OH\
    \ 45701\n   Phone: 740-593-4891\n   Fax: 740-593-4889\n   EMail: hkruse1@ohiou.edu\n\
    \   http://www.csm.ohiou.edu/kruse\n   Shawn Ostermann\n   School of Electrical\
    \ Engineering and Computer Science\n   Ohio University\n   416 Morton Hall\n \
    \  Athens, OH  45701\n   Phone: (740) 593-1234\n   EMail: ostermann@cs.ohiou.edu\n\
    \   Keith Scott\n   The MITRE Corporation\n   M/S W650\n   1820 Dolley Madison\
    \ Blvd.\n   McLean VA 22102-3481\n   EMail: kscott@mitre.org\n   Jeffrey Semke\n\
    \   Pittsburgh Supercomputing Center\n   4400 Fifth Ave.\n   Pittsburgh, PA  15213\n\
    \   EMail: semke@psc.edu\n   http://www.psc.edu/~semke\n"
- title: 9  Full Copyright Statement
  contents:
  - "9  Full Copyright Statement\n   Copyright (C) The Internet Society (2000).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
