- title: __initial_text__
  contents:
  - '         Core Based Trees (CBT) Multicast Routing Architecture

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo defines an Experimental Protocol for the Internet\n\
    \   community.  This memo does not specify an Internet standard of any\n   kind.\
    \  Discussion and suggestions for improvement are requested.\n   Distribution\
    \ of this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   CBT is a multicast routing architecture that builds a single delivery\n\
    \   tree per group which is shared by all of the group's senders and\n   receivers.\
    \  Most multicast algorithms build one multicast tree per\n   sender (subnetwork),\
    \ the tree being rooted at the sender's\n   subnetwork.  The primary advantage\
    \ of the shared tree approach is\n   that it typically offers more favourable\
    \ scaling characteristics than\n   all other multicast algorithms.\n   The CBT\
    \ protocol [1] is a network layer multicast routing protocol\n   that builds and\
    \ maintains a shared delivery tree for a multicast\n   group.  The sending and\
    \ receiving of multicast data by hosts on a\n   subnetwork conforms to the traditional\
    \ IP multicast service model\n   [2].\n   CBT is progressing through the IDMR\
    \ working group of the IETF.  The\n   CBT protocol is described in an accompanying\
    \ document [1]. For this,\n   and all IDMR-related documents, see http://www.cs.ucl.ac.uk/ietf/idmr\n"
- title: TABLE OF CONTENTS
  contents:
  - "TABLE OF CONTENTS\n   1. Background...................................................\
    \  2\n   2. Introduction.................................................  2\n\
    \   3. Source Based Tree Algorithms.................................  3\n    \
    \  3.1 Distance-Vector Multicast Algorithm......................  4\n      3.2\
    \ Link State Multicast Algorithm...........................  5\n      3.3 The\
    \ Motivation for Shared Trees..........................  5\n   4. CBT - The New\
    \ Architecture...................................  7\n      4.1 Design Requirements......................................\
    \  7\n      4.2 Components & Functions...................................  8\n\
    \          4.2.1 CBT Control Message Retransmission Strategy........ 10\n    \
    \      4.2.2 Non-Member Sending................................. 11\n   5. Interoperability\
    \ with Other Multicast Routing Protocols ..... 11\n   6. Core Router Discovery........................................\
    \ 11\n      6.1 Bootstrap Mechanism Overview............................. 12\n\
    \   7. Summary ..................................................... 13\n   8.\
    \ Security Considerations...................................... 13\n   Acknowledgements\
    \ ............................................... 14\n   References .....................................................\
    \ 14\n   Author Information.............................................. 15\n"
- title: 1.  Background
  contents:
  - "1.  Background\n   Shared trees were first described by Wall in his investigation\
    \ into\n   low-delay approaches to broadcast and selective broadcast [3]. Wall\n\
    \   concluded that delay will not be minimal, as with shortest-path\n   trees,\
    \ but the delay can be kept within bounds that may be\n   acceptable.  Back then,\
    \ the benefits and uses of multicast were not\n   fully understood, and it wasn't\
    \ until much later that the IP\n   multicast address space was defined (class\
    \ D space [4]). Deering's\n   work [2] in the late 1980's was pioneering in that\
    \ he defined the IP\n   multicast service model, and invented algorithms which\
    \ allow hosts to\n   arbitrarily join and leave a multicast group. All of Deering's\n\
    \   multicast algorithms build source-rooted delivery trees, with one\n   delivery\
    \ tree per sender subnetwork. These algorithms are documented\n   in [2].\n  \
    \ After several years practical experience with multicast, we see a\n   diversity\
    \ of multicast applications and correspondingly, a wide\n   variety of multicast\
    \ application requirements.  For example,\n   distributed interactive simulation\
    \ (DIS) applications have strict\n   requirements in terms of join latency, group\
    \ membership dynamics,\n   group sender populations, far exceeding the requirements\
    \ of many\n   other multicast applications.\n   The multicast-capable part of\
    \ the Internet, the MBONE, continues to\n   expand rapidly.  The obvious popularity\
    \ and growth of multicast means\n   that the scaling aspects of wide-area multicasting\
    \ cannot be\n   overlooked; some predictions talk of thousands of groups being\n\
    \   present at any one time in the Internet.\n   We evaluate scalability in terms\
    \ of network state maintenance,\n   bandwidth efficiency, and protocol overhead.\
    \ Other factors that can\n   affect these parameters include sender set size,\
    \ and wide-area\n   distribution of group members.\n"
- title: 2.  Introduction
  contents:
  - "2.  Introduction\n   Multicasting on the local subnetwork does not require either\
    \ the\n   presence of a multicast router or the implementation of a multicast\n\
    \   routing algorithm; on most shared media (e.g. Ethernet), a host,\n   which\
    \ need not necessarily be a group member, simply sends a\n   multicast data packet,\
    \ which is received by any member hosts\n   connected to the same medium.\n  \
    \ For multicasts to extend beyond the scope of the local subnetwork,\n   the subnet\
    \ must have a multicast-capable router attached, which\n   itself is attached\
    \ (possibly \"virtually\") to another multicast-\n   capable router, and so on.\
    \ The collection of these (virtually)\n   connected multicast routers forms the\
    \ Internet's MBONE.\n   All multicast routing protocols make use of IGMP [5],\
    \ a protocol that\n   operates between hosts and multicast router(s) belonging\
    \ to the same\n   subnetwork. IGMP enables the subnet's multicast router(s) to\
    \ monitor\n   group membership presence on its directly attached links, so that\
    \ if\n   multicast data arrives, it knows over which of its links to send a\n\
    \   copy of the packet.\n   In our description of the MBONE so far, we have assumed\
    \ that all\n   multicast routers on the MBONE are running the same multicast routing\n\
    \   protocol. In reality, this is not the case; the MBONE is a collection\n  \
    \ of autonomously administered multicast regions, each region defined\n   by one\
    \ or more multicast-capable border routers. Each region\n   independently chooses\
    \ to run whichever multicast routing protocol\n   best suits its needs, and the\
    \ regions interconnect via the \"backbone\n   region\", which currently runs the\
    \ Distance Vector Multicast Routing\n   Protocol (DVMRP) [6]. Therefore, it follows\
    \ that a region's border\n   router(s) must interoperate with DVMRP.\n   Different\
    \ algorithms use different techniques for establishing a\n   distribution tree.\
    \ If we classify these algorithms into source-based\n   tree algorithms and shared\
    \ tree algorithms, we'll see that the\n   different classes have considerably\
    \ different scaling\n   characteristics, and the characteristics of the resulting\
    \ trees\n   differ too, for example, average delay. Let's look at source-based\n\
    \   tree algorithms first.\n"
- title: 3.  Source-Based Tree Algorithms
  contents:
  - "3.  Source-Based Tree Algorithms\n   The strategy we'll use for motivating (CBT)\
    \ shared tree multicast is\n   based, in part, in explaining the characteristics\
    \ of source-based\n   tree multicast, in particular its scalability.\n   Most\
    \ source-based tree multicast algorithms are often referred to as\n   \"dense-mode\"\
    \ algorithms; they assume that the receiver population\n   densely populates the\
    \ domain of operation, and therefore the\n   accompanying overhead (in terms of\
    \ state, bandwidth usage, and/or\n   processing costs) is justified.  Whilst this\
    \ might be the case in a\n   local environment, wide-area group membership tends\
    \ to be sparsely\n   distributed throughout the Internet.  There may be \"pockets\"\
    \ of\n   denseness, but if one views the global picture, wide-area groups tend\n\
    \   to be sparsely distributed.\n   Source-based multicast trees are either built\
    \ by a distance-vector\n   style algorithm, which may be implemented separately\
    \ from the unicast\n   routing algorithm (as is the case with DVMRP), or the multicast\
    \ tree\n   may be built using the information present in the underlying unicast\n\
    \   routing table (as is the case with PIM-DM [7]). The other algorithm\n   used\
    \ for building source-based trees is the link-state algorithm (a\n   protocol\
    \ instance being M-OSPF [8]).\n"
- title: 3.1.  Distance-Vector Multicast Algorithm
  contents:
  - "3.1.  Distance-Vector Multicast Algorithm\n   The distance-vector multicast algorithm\
    \ builds a multicast delivery\n   tree using a variant of the Reverse-Path Forwarding\
    \ technique [9].\n   The technique basically is as follows: when a multicast router\n\
    \   receives a multicast data packet, if the packet arrives on the\n   interface\
    \ used to reach the source of the packet, the packet is\n   forwarded over all\
    \ outgoing interfaces, except leaf subnets with no\n   members attached.  A \"\
    leaf\" subnet is one which no router would use\n   to reach the souce of a multicast\
    \ packet. If the data packet does not\n   arrive over the link that would be used\
    \ to reach the source, the\n   packet is discarded.\n   This constitutes a \"\
    broadcast & prune\" approach to multicast tree\n   construction; when a data packet\
    \ reaches a leaf router, if that\n   router has no membership registered on any\
    \ of its directly attached\n   subnetworks, the router sends a prune message one\
    \ hop back towards\n   the source. The receiving router then checks its leaf subnets\
    \ for\n   group membership, and checks whether it has received a prune from all\n\
    \   of its downstream routers (downstream with respect to the source).\n   If\
    \ so, the router itself can send a prune upstream over the interface\n   leading\
    \ to the source.\n   The sender and receiver of a prune message must cache the\
    \ <source,\n   group> pair being reported, for a \"lifetime\" which is at the\n\
    \   granularity of minutes. Unless a router's prune information is\n   refreshed\
    \ by the receipt of a new prune for <source, group> before\n   its \"lifetime\"\
    \ expires, that information is removed, allowing data to\n   flow over the branch\
    \ again. State that expires in this way is\n   referred to as \"soft state\".\n\
    \   Interestingly, routers that do not lead to group members are incurred\n  \
    \ the state overhead incurred by prune messages. For wide-area\n   multicasting,\
    \ which potentially has to support many thousands of\n   active groups, each of\
    \ which may be sparsely distributed, this\n   technique clearly does not scale.\n"
- title: 3.2.  Link-State Multicast Algorithm
  contents:
  - "3.2.  Link-State Multicast Algorithm\n   Routers implementing a link state algorithm\
    \ periodically collect\n   reachability information to their directly attached\
    \ neighbours, then\n   flood this throughout the routing domain in so-called link\
    \ state\n   update packets. Deering extended the link state algorithm for\n  \
    \ multicasting by having a router additionally detect group membership\n   changes\
    \ on its incident links before flooding this information in\n   link state packets.\n\
    \   Each router then, has a complete, up-to-date image of a domain's\n   topology\
    \ and group membership. On receiving a multicast data packet,\n   each router\
    \ uses its membership and topology information to calculate\n   a shortest-path\
    \ tree rooted at the sender subnetwork. Provided the\n   calculating router falls\
    \ within the computed tree, it forwards the\n   data packet over the interfaces\
    \ defined by its calculation. Hence,\n   multicast data packets only ever traverse\
    \ routers leading to members,\n   either directly attached, or further downstream.\
    \ That is, the\n   delivery tree is a true multicast tree right from the start.\n\
    \   However, the flooding (reliable broadcasting) of group membership\n   information\
    \ is the predominant factor preventing the link state\n   multicast algorithm\
    \ being applicable over the wide-area.  The other\n   limiting factor is the processing\
    \ cost of the Dijkstra calculation to\n   compute the shortest-path tree for each\
    \ active source.\n"
- title: 3.3.  The Motivation for Shared Trees
  contents:
  - "3.3.  The Motivation for Shared Trees\n   The algorithms described in the previous\
    \ sections clearly motivate\n   the need for a multicast algorithm(s) that is\
    \ more scalable. CBT was\n   designed primarily to address the topic of scalability;\
    \ a shared tree\n   architecture offers an improvement in scalability over source\
    \ tree\n   architectures by a factor of the number of active sources (where\n\
    \   source is usually a subnetwork aggregate).  Source trees scale O(S *\n   G),\
    \ since a distinct delivery tree is built per active source. Shared\n   trees\
    \ eliminate the source (S) scaling factor; all sources use the\n   same shared\
    \ tree, and hence a shared tree scales O(G).  The\n   implication of this is that\
    \ applications with many active senders,\n   such as distributed interactive simulation\
    \ applications, and\n   distributed video-gaming (where most receivers are also\
    \ senders),\n   have a significantly lesser impact on underlying multicast routing\
    \ if\n   shared trees are used.\n   In the \"back of the envelope\" table below\
    \ we compare the amount of\n   state required by CBT and DVMRP for different group\
    \ sizes with\n   different numbers of active sources:\n  |--------------|---------------------------------------------------|\n\
    \  |  Number of   |                |                |                 |\n  | \
    \   groups    |        10      |       100      |        1000     |\n  ====================================================================\n\
    \  |  Group size  |                |                |                 |\n  | (#\
    \ members)  |        20      |       40       |         60      |\n  -------------------------------------------------------------------|\n\
    \  | No. of srcs  |    |     |     |    |     |     |    |     |      |\n  | \
    \ per group   |10% | 50% |100% |10% | 50% |100% |10% | 50% | 100% |\n  --------------------------------------------------------------------\n\
    \  | No. of DVMRP |    |     |     |    |     |     |    |     |      |\n  | \
    \   router    |    |     |     |    |     |     |    |     |      |\n  |   entries\
    \    | 20 | 100 | 200 |400 | 2K  | 4K  | 6K | 30K | 60K  |\n  --------------------------------------------------------------------\n\
    \  | No. of CBT   |                |                |                 |\n  | \
    \ router      |                |                |                 |\n  |  entries\
    \     |       10       |       100      |       1000      |\n  |------------------------------------------------------------------|\n\
    \           Figure 1: Comparison of DVMRP and CBT Router State\n   Shared trees\
    \ also incur significant bandwidth and state savings\n   compared with source\
    \ trees; firstly, the tree only spans a group's\n   receivers (including links/routers\
    \ leading to receivers) -- there is\n   no cost to routers/links in other parts\
    \ of the network. Secondly,\n   routers between a non-member sender and the delivery\
    \ tree are not\n   incurred any cost pertaining to multicast, and indeed, these\
    \ routers\n   need not even be multicast-capable -- packets from non-member senders\n\
    \   are encapsulated and unicast to a core on the tree.\n   The figure below illustrates\
    \ a core based tree.\n           b      b     b-----b\n            \\     |  \
    \   |\n             \\    |     |\n              b---b     b------b\n        \
    \     /     \\  /                   KEY....\n            /       \\/\n       \
    \    b         X---b-----b          X = Core\n                    / \\       \
    \            b = on-tree router\n                   /   \\\n                 \
    \ /     \\\n                  b      b------b\n                 / \\     |\n \
    \               /   \\    |\n               b     b   b\n                    \
    \       Figure 2: CBT Tree\n"
- title: 4.  CBT - The New Architecture
  contents:
  - '4.  CBT - The New Architecture

    '
- title: 4.1.  Design Requirements
  contents:
  - "4.1.  Design Requirements\n   The CBT shared tree design was geared towards several\
    \ design\n   objectives:\n   o    scalability - the CBT designers decided not\
    \ to sacrifice CBT's\n        O(G) scaling characteric to optimize delay using\
    \ SPTs, as does\n        PIM.  This was an important design decision, and one,\
    \ we think,\n        was taken with foresight; once multicasting becomes ubiquitous,\n\
    \        router state maintenance will be a predominant scaling factor.\n    \
    \    It is possible in some circumstances to improve/optimize the\n        delay\
    \ of shared trees by other means. For example, a broadcast-\n        type lecture\
    \ with a single sender (or limited set of\n        infrequently changing senders)\
    \ could have its core placed in the\n        locality of the sender, allowing\
    \ the CBT to emulate a shortest-\n        path tree (SPT) whilst still maintaining\
    \ its O(G) scaling\n        characteristic. More generally, because CBT does not\
    \ incur\n        source-specific state, it is particularly suited to many sender\n\
    \        applications.\n   o    robustness - source-based tree algorithms are\
    \ clearly robust; a\n        sender simply sends its data, and intervening routers\
    \ \"conspire\"\n        to get the data where it needs to, creating state along\
    \ the way.\n        This is the so-called \"data driven\" approach -- there is\
    \ no\n        set-up protocol involved.\n        It is not as easy to achieve\
    \ the same degree of robustness in\n        shared tree algorithms; a shared tree's\
    \ core router maintains\n        connectivity between all group members, and is\
    \ thus a single\n        point of failure.  Protocol mechanisms must be present\
    \ that\n        ensure a core failure is detected quickly, and the tree\n    \
    \    reconnected quickly using a replacement core router.\n   o    simplicity\
    \ - the CBT protocol is relatively simple compared to\n        most other multicast\
    \ routing protocols. This simplicity can lead\n        to enhanced performance\
    \ compared to other protocols.\n   o    interoperability - from a multicast perspective,\
    \ the Internet is\n        a collection of heterogeneous multicast regions. The\
    \ protocol\n        interconnecting these multicast regions is currently DVMRP\
    \ [6];\n        any regions not running DVMRP connect to the DVMRP \"backbone\"\
    \ as\n        stub regions.  CBT has well-defined interoperability mechanisms\n\
    \        with DVMRP [15].\n"
- title: 4.2.  CBT Components & Functions
  contents:
  - "4.2.  CBT Components & Functions\n   The CBT protocol is designed to build and\
    \ maintain a shared multicast\n   distribution tree that spans only those networks\
    \ and links leading to\n   interested receivers.\n   To achieve this, a host first\
    \ expresses its interest in joining a\n   group by multicasting an IGMP host membership\
    \ report [5] across its\n   attached link. On receiving this report, a local CBT\
    \ aware router\n   invokes the tree joining process (unless it has already) by\n\
    \   generating a JOIN_REQUEST message, which is sent to the next hop on\n   the\
    \ path towards the group's core router (how the local router\n   discovers which\
    \ core to join is discussed in section 6). This join\n   message must be explicitly\
    \ acknowledged (JOIN_ACK) either by the core\n   router itself, or by another\
    \ router that is on the unicast path\n   between the sending router and the core,\
    \ which itself has already\n   successfully joined the tree.\n   The join message\
    \ sets up transient join state in the routers it\n   traverses, and this state\
    \ consists of <group, incoming interface,\n   outgoing interface>. \"Incoming\
    \ interface\" and \"outgoing interface\"\n   may be \"previous hop\" and \"next\
    \ hop\", respectively, if the\n   corresponding links do not support multicast\
    \ transmission. \"Previous\n   hop\" is taken from the incoming control packet's\
    \ IP source address,\n   and \"next hop\" is gleaned from the routing table -\
    \ the next hop to\n   the specified core address. This transient state eventually\
    \ times out\n   unless it is \"confirmed\" with a join acknowledgement (JOIN_ACK)\
    \ from\n   upstream. The JOIN_ACK traverses the reverse path of the\n   corresponding\
    \ join message, which is possible due to the presence of\n   the transient join\
    \ state.  Once the acknowledgement reaches the\n   router that originated the\
    \ join message, the new receiver can receive\n   traffic sent to the group.\n\
    \   Loops cannot be created in a CBT tree because a) there is only one\n   active\
    \ core per group, and b) tree building/maintenance scenarios\n   which may lead\
    \ to the creation of tree loops are avoided.  For\n   example, if a router's upstream\
    \ neighbour becomes unreachable, the\n   router immediately \"flushes\" all of\
    \ its downstream branches, allowing\n   them to individually rejoin if necessary.\
    \  Transient unicast loops do\n   not pose a threat because a new join message\
    \ that loops back on\n   itself will never get acknowledged, and thus eventually\
    \ times out.\n   The state created in routers by the sending or receiving of a\n\
    \   JOIN_ACK is bi-directional - data can flow either way along a tree\n   \"\
    branch\", and the state is group specific - it consists of the group\n   address\
    \ and a list of local interfaces over which join messages for\n   the group have\
    \ previously been acknowledged. There is no concept of\n   \"incoming\" or \"\
    outgoing\" interfaces, though it is necessary to be\n   able to distinguish the\
    \ upstream interface from any downstream\n   interfaces. In CBT, these interfaces\
    \ are known as the \"parent\" and\n   \"child\" interfaces, respectively.\n  \
    \ With regards to the information contained in the multicast forwarding\n   cache,\
    \ on link types not supporting native multicast transmission an\n   on-tree router\
    \ must store the address of a parent and any children.\n   On links supporting\
    \ multicast however, parent and any child\n   information is represented with\
    \ local interface addresses (or similar\n   identifying information, such as an\
    \ interface \"index\") over which the\n   parent or child is reachable.\n   When\
    \ a multicast data packet arrives at a router, the router uses the\n   group address\
    \ as an index into the multicast forwarding cache. A copy\n   of the incoming\
    \ multicast data packet is forwarded over each\n   interface (or to each address)\
    \ listed in the entry except the\n   incoming interface.\n   Each router that\
    \ comprises a CBT multicast tree, except the core\n   router, is responsible for\
    \ maintaining its upstream link, provided it\n   has interested downstream receivers,\
    \ i.e. the child interface list is\n   not NULL. A child interface is one over\
    \ which a member host is\n   directly attached, or one over which a downstream\
    \ on-tree router is\n   attached.  This \"tree maintenance\" is achieved by each\
    \ downstream\n   router periodically sending a \"keepalive\" message (ECHO_REQUEST)\
    \ to\n   its upstream neighbour, i.e. its parent router on the tree. One\n   keepalive\
    \ message is sent to represent entries with the same parent,\n   thereby improving\
    \ scalability on links which are shared by many\n   groups.  On multicast capable\
    \ links, a keepalive is multicast to the\n   \"all-cbt-routers\" group (IANA assigned\
    \ as 224.0.0.15); this has a\n   suppressing effect on any other router for which\
    \ the link is its\n   parent link.  If a parent link does not support multicast\n\
    \   transmission, keepalives are unicast.\n   The receipt of a keepalive message\
    \ over a valid child interface\n   immediately prompts a response (ECHO_REPLY),\
    \ which is either unicast\n   or multicast, as appropriate.\n   The ECHO_REQUEST\
    \ does not contain any group information; the\n   ECHO_REPLY does, but only periodically.\
    \ To maintain consistent\n   information between parent and child, the parent\
    \ periodically\n   reports, in a ECHO_REPLY, all groups for which it has state,\
    \ over\n   each of its child interfaces for those groups. This group-carrying\n\
    \   echo reply is not prompted explicitly by the receipt of an echo\n   request\
    \ message.  A child is notified of the time to expect the next\n   echo reply\
    \ message containing group information in an echo reply\n   prompted by a child's\
    \ echo request. The frequency of parent group\n   reporting is at the granularity\
    \ of minutes.\n   It cannot be assumed all of the routers on a multi-access link\
    \ have a\n   uniform view of unicast routing; this is particularly the case when\
    \ a\n   multi-access link spans two or more unicast routing domains. This\n  \
    \ could lead to multiple upstream tree branches being formed (an error\n   condition)\
    \ unless steps are taken to ensure all routers on the link\n   agree which is\
    \ the upstream router for a particular group. CBT\n   routers attached to a multi-access\
    \ link participate in an explicit\n   election mechanism that elects a single\
    \ router, the designated router\n   (DR), as the link's upstream router for all\
    \ groups. Since the DR\n   might not be the link's best next-hop for a particular\
    \ core router,\n   this may result in join messages being re-directed back across\
    \ a\n   multi-access link. If this happens, the re-directed join message is\n\
    \   unicast across the link by the DR to the best next-hop, thereby\n   preventing\
    \ a looping scenario.  This re-direction only ever applies\n   to join messages.\
    \  Whilst this is suboptimal for join messages, which\n   are generated infrequently,\
    \ multicast data never traverses a link\n   more than once (either natively, or\
    \ encapsulated).\n   In all but the exception case described above, all CBT control\n\
    \   messages are multicast over multicast supporting links to the \"all-\n   cbt-routers\"\
    \ group, with IP TTL 1. When a CBT control message is sent\n   over a non-multicast\
    \ supporting link, it is explicitly addressed to\n   the appropriate next hop.\n"
- title: 4.2.1.  CBT Control Message Retransmission Strategy
  contents:
  - "4.2.1.  CBT Control Message Retransmission Strategy\n   Certain CBT control messages\
    \ illicit a response of some sort. Lack of\n   response may be due to an upstream\
    \ router crashing, or the loss of\n   the original message, or its response. To\
    \ detect these events, CBT\n   retransmits those control messages for which it\
    \ expects a response,\n   if that response is not forthcoming within the retransmission-\n\
    \   interval, which varies depending on the type of message involved.\n   There\
    \ is an upper bound (typically 3) on the number of\n   retransmissions of the\
    \ original message before an exception condition\n   is raised.\n   For example,\
    \ the exception procedure for lack of response to an\n   ECHO_REQUEST is to send\
    \ a QUIT_NOTIFICATION upstream and a FLUSH_TREE\n   message downstream for the\
    \ group. If this is router has group members\n   attached, it restarts the joining\
    \ process to the group's core.\n"
- title: 4.2.2.  Non-Member Sending
  contents:
  - "4.2.2.  Non-Member Sending\n   If a non-member sender's local router is already\
    \ on-tree for the\n   group being sent to, the subnet's upstream router simply\
    \ forwards the\n   data packet over all outgoing interfaces corresponding to that\n\
    \   group's forwarding cache entry. This is in contrast to PIM-SM [18]\n   which\
    \ must encapsulate data from a non-member sender, irrespective of\n   whether\
    \ the local router has joined the tree. This is due to PIM's\n   uni-directional\
    \ state.\n   If the sender's subnet is not attached to the group tree, the local\n\
    \   DR must encapsulate the data packet and unicast it to the group's\n   core\
    \ router, where it is decapsulated and disseminated over all tree\n   interfaces,\
    \ as specified by the core's forwarding cache entry for the\n   group. The data\
    \ packet encapsulation method is IP-in-IP [14].\n   Routers in between a non-member\
    \ sender and the group's core need not\n   know anything about the multicast group,\
    \ and indeed may even be\n   multicast-unaware. This makes CBT particulary attractive\
    \ for\n   applications with non-member senders.\n"
- title: 5.  Interoperability with Other Multicast Routing Protocols
  contents:
  - "5.  Interoperability with Other Multicast Routing Protocols\n   See \"interoperability\"\
    \ in section 4.1.\n   The interoperability mechanisms for interfacing CBT with\
    \ DVMRP are\n   defined in [15].\n"
- title: 6.  Core Router Discovery
  contents:
  - "6.  Core Router Discovery\n   Core router discovery is by far the most controversial\
    \ and difficult\n   aspect of shared tree multicast architectures, particularly\
    \ in the\n   context of inter-domain multicast routing (IDMR).  There have been\n\
    \   many proposals over the past three years or so, including advertising\n  \
    \ core addresses in a multicast session directory like \"sdr\" [11],\n   manual\
    \ placement, and the HPIM [12] approach of strictly dividing up\n   the multicast\
    \ address space into many \"hierarchical scopes\" and using\n   explicit advertising\
    \ of core routers between scope levels.\n   There are currently two options for\
    \ CBTv2 [1] core discovery; the\n   \"bootstrap\" mechamism, and manual placement.\
    \ The bootstrap mechanisms\n   (as currently specified with the PIM sparse mode\
    \ protocol [18]) is\n   applicable only to intra-domain core discovery, and allows\
    \ for a\n   \"plug & play\" type operation with minimal configuration. The\n \
    \  disadvantage of the bootstrap mechanism is that it is much more\n   difficult\
    \ to affect the shape, and thus optimality, of the resulting\n   distribution\
    \ tree. Also, it must be implemented by all CBT routers\n   within a domain.\n\
    \   Manual configuration of leaf routers with <core, group> mappings is\n   the\
    \ other option (note: leaf routers only); this imposes a degree of\n   administrative\
    \ burden - the mapping for a particular group must be\n   coordinated across all\
    \ leaf routers to ensure consistency. Hence,\n   this method does not scale particularly\
    \ well. However, it is likely\n   that \"better\" trees will result from this\
    \ method, and it is also the\n   only available option for inter-domain core discovery\
    \ currently\n   available.\n"
- title: 6.1.  Bootstrap Mechanism Overview
  contents:
  - "6.1.  Bootstrap Mechanism Overview\n   It is unlikely at this stage that the\
    \ bootstrap mechanism will be\n   appended to a well-known network layer protocol,\
    \ such as IGMP [5] or\n   ICMP [13], though this would facilitate its ubiquitous\
    \ (intra-domain)\n   deployment.  Therefore, each multicast routing protocol requiring\
    \ the\n   bootstrap mechanism must implement it as part of the multicast\n   routing\
    \ protocol itself.\n   A summary of the operation of the bootstrap mechanism follows.\
    \ It is\n   assumed that all routers within the domain implement the \"bootstrap\"\
    \n   protocol, or at least forward bootstrap protocol messages.\n   A subset of\
    \ the domain's routers are configured to be CBT candidate\n   core routers. Each\
    \ candidate core router periodically (default every\n   60 secs) advertises itself\
    \ to the domain's Bootstrap Router (BSR),\n   using  \"Core Advertisement\" messages.\
    \  The BSR is itself elected\n   dynamically from all (or participating) routers\
    \ in the domain.  The\n   domain's elected BSR collects \"Core Advertisement\"\
    \ messages from\n   candidate core routers and periodically advertises a candidate\
    \ core\n   set (CC-set) to each other router in the domain, using traditional\n\
    \   hopby-hop unicast forwarding. The BSR uses \"Bootstrap Messages\" to\n   advertise\
    \ the CC-set. Together, \"Core Advertisements\" and \"Bootstrap\n   Messages\"\
    \ comprise the \"bootstrap\" protocol.\n   When a router receives an IGMP host\
    \ membership report from one of its\n   directly attached hosts, the local router\
    \ uses a hash function on the\n   reported group address, the result of which\
    \ is used as an index into\n   the CC-set. This is how local routers discover\
    \ which core to use for\n   a particular group.\n   Note the hash function is\
    \ specifically tailored such that a small\n   number of consecutive groups always\
    \ hash to the same core.\n   Furthermore, bootstrap messages can carry a \"group\
    \ mask\", potentially\n   limiting a CC-set to a particular range of groups. This\
    \ can help\n   reduce traffic concentration at the core.\n   If a BSR detects\
    \ a particular core as being unreachable (it has not\n   announced its availability\
    \ within some period), it deletes the\n   relevant core from the CC-set sent in\
    \ its next bootstrap message.\n   This is how a local router discovers a group's\
    \ core is unreachable;\n   the router must re-hash for each affected group and\
    \ join the new core\n   after removing the old state. The removal of the \"old\"\
    \ state follows\n   the sending of a QUIT_NOTIFICATION upstream, and a FLUSH_TREE\
    \ message\n   downstream.\n"
- title: 7.  Summary
  contents:
  - "7.  Summary\n   This document presents an architecture for intra- and inter-domain\n\
    \   multicast routing.  We motivated this architecture by describing how\n   an\
    \ inter-domain multicast routing algorithm must scale to large\n   numbers of\
    \ groups present in the internetwork, and discussed why most\n   other existing\
    \ algorithms are less suited to inter-domain multicast\n   routing.  We followed\
    \ by describing the features and components of\n   the architecture, illustrating\
    \ its simplicity and scalability.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   Security considerations are not addressed in\
    \ this memo.\n   Whilst multicast security is a topic of ongoing research, multicast\n\
    \   applications (users) nevertheless have the ability to take advantage\n   of\
    \ security services such as encryption or/and authentication\n   provided such\
    \ services are supported by the applications.\n   RFCs 1949 and 2093/2094 discuss\
    \ different ways of distributing\n   multicast key material, which can result\
    \ in the provision of network\n   layer access control to a multicast distribution\
    \ tree.\n   [19] offers a synopsis of multicast security threats and proposes\n\
    \   some possible counter measures.\n   Beyond these, little published work exists\
    \ on the topic of multicast\n   security.\n"
- title: Acknowledgements
  contents:
  - "Acknowledgements\n   Special thanks goes to Paul Francis, NTT Japan, for the\
    \ original\n   brainstorming sessions that brought about this work.\n   Clay Shields'\
    \ work on OCBT [17] identified various failure scenarios\n   with a multi-core\
    \ architecture, resulting in the specification of a\n   single core architecture.\n\
    \   Others that have contributed to the progress of CBT include Ken\n   Carlberg,\
    \ Eric Crawley, Jon Crowcroft, Mark Handley, Ahmed Helmy,\n   Nitin Jain, Alan\
    \ O'Neill, Steven Ostrowsksi, Radia Perlman, Scott\n   Reeve, Benny Rodrig, Martin\
    \ Tatham, Dave Thaler, Sue Thompson, Paul\n   White, and other participants of\
    \ the IETF IDMR working group.\n   Thanks also to 3Com Corporation and British\
    \ Telecom Plc for funding\n   this work.\n"
- title: References
  contents:
  - "References\n   [1] Ballardie, A., \"Core Based Trees (CBT version 2) Multicast\n\
    \   Routing: Protocol Specification\", RFC 2189, September 1997.\n   [2] Multicast\
    \ Routing in a Datagram Internetwork; S. Deering, PhD\n   Thesis, 1991; ftp://gregorio.stanford.edu/vmtp/sd-thesis.ps.\n\
    \   [3] Mechanisms for Broadcast and Selective Broadcast; D. Wall; PhD\n   thesis,\
    \ Stanford University, June 1980. Technical Report #90.\n   [4] Reynolds, J.,\
    \ and J. Postel, \"Assigned Numbers\", STD 2, RFC 1700,\n   October 1994.\n  \
    \ [5] Internet Group Management Protocol, version 2 (IGMPv2); W.\n   Fenner; Work\
    \ In Progress.\n   [6] Distance Vector Multicast Routing Protocol (DVMRP); T.\
    \ Pusateri;\n   Work In Progress.\n   [7] Protocol Independent Multicast (PIM)\
    \ Dense Mode Specification; D.\n   Estrin et al; ftp://netweb.usc.edu/pim, Work\
    \ In Progress.\n   [8] Moy, J., \"Multicast Extensions to OSPF\", RFC 1584, March\
    \ 1994.\n   [9] Reverse path forwarding of  broadcast packets; Y.K. Dalal and\n\
    \   R.M.  Metcalfe; Communications of the ACM, 21(12):1040--1048, 1978.\n   [10]\
    \ Some Issues for an Inter-Domain Multicast Routing Protocol; D.\n   Meyer;  Work\
    \ In Progress.\n   [11] SDP: Session Description Protocol; M. Handley and V. Jacobson;\n\
    \   Work In Progress.\n   [12] Hierarchical Protocol Independent Multicast; M.\
    \ Handley, J.\n   Crowcroft, I. Wakeman.  Available from:\n   http://www.cs.ucl.ac.uk/staff/M.Handley/hpim.ps\
    \  and\n   ftp://cs.ucl.ac.uk/darpa/IDMR/hpim.ps   Work done 1995.\n   [13] Postel,\
    \ J., \"Internet Control Message Protocol (ICMP)\", STD 5,\n   RFC 792, September\
    \ 1981.\n   [14] Perkins, C., \"IP Encapsulation within IP\", RFC 2003, October\n\
    \   1996.\n   [15] CBT - Dense Mode Multicast Interoperability; A. Ballardie;\
    \ Work\n   In Progress.\n   [16] Performance and Resource Cost Comparisons of\
    \ Multicast Routing\n   Algorithms for Distributed Interactive Simulation Applications;\
    \ T.\n   Billhartz, J. Bibb Cain, E.  Farrey-Goudreau, and D. Feig. Available\n\
    \   from: http://www.epm.ornl.gov/~sgb/pubs.html; July 1995.\n   [17] The Ordered\
    \ Core Based Tree Protocol; C. Shields and J.J.\n   Garcia- Luna-Aceves; In Proceedings\
    \ of IEEE Infocom'97, Kobe, Japan,\n   April 1997; http://www.cse.ucsc.edu/research/ccrg/publications/info-\n\
    \   comm97ocbt.ps.gz\n   [18] Estrin, D., et. al., \"Protocol Independent Multicast-Sparse\
    \ Mode\n   (PIM-SM): Protocol Specification\", RFC 2117, June 1997.\n   [19] Multicast-Specific\
    \ Security Threats and Counter-Measures; A.\n   Ballardie and J. Crowcroft; In\
    \ Proceedings \"Symposium on Network and\n   Distributed System Security\", February\
    \ 1995, pp.2-16.\n"
- title: Author Information
  contents:
  - "Author Information\n   Tony Ballardie,\n   Research Consultant\n   EMail: ABallardie@acm.org\n"
