- title: __initial_text__
  contents:
  - '                  Randomness Requirements for Security

    '
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document specifies an Internet Best Current Practices\
    \ for the\n   Internet Community, and requests discussion and suggestions for\n\
    \   improvements.  Distribution of this memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2005).\n"
- title: Abstract
  contents:
  - "Abstract\n   Security systems are built on strong cryptographic algorithms that\n\
    \   foil pattern analysis attempts.  However, the security of these\n   systems\
    \ is dependent on generating secret quantities for passwords,\n   cryptographic\
    \ keys, and similar quantities.  The use of pseudo-random\n   processes to generate\
    \ secret quantities can result in pseudo-\n   security.  A sophisticated attacker\
    \ may find it easier to reproduce\n   the environment that produced the secret\
    \ quantities and to search the\n   resulting small set of possibilities than to\
    \ locate the quantities in\n   the whole of the potential number space.\n   Choosing\
    \ random quantities to foil a resourceful and motivated\n   adversary is surprisingly\
    \ difficult.  This document points out many\n   pitfalls in using poor entropy\
    \ sources or traditional pseudo-random\n   number generation techniques for generating\
    \ such quantities.  It\n   recommends the use of truly random hardware techniques\
    \ and shows that\n   the existing hardware on many systems can be used for this\
    \ purpose.\n   It provides suggestions to ameliorate the problem when a hardware\n\
    \   solution is not available, and it gives examples of how large such\n   quantities\
    \ need to be for some applications.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction and Overview .......................................3\n\
    \   2. General Requirements ............................................4\n  \
    \ 3. Entropy Sources .................................................7\n    \
    \  3.1. Volume Required ............................................7\n      3.2.\
    \ Existing Hardware Can Be Used For Randomness ...............8\n           3.2.1.\
    \ Using Existing Sound/Video Input ....................8\n           3.2.2. Using\
    \ Existing Disk Drives ..........................8\n      3.3. Ring Oscillator\
    \ Sources ....................................9\n      3.4. Problems with Clocks\
    \ and Serial Numbers ...................10\n      3.5. Timing and Value of External\
    \ Events .......................11\n      3.6. Non-hardware Sources of Randomness\
    \ ........................12\n   4. De-skewing .....................................................12\n\
    \      4.1. Using Stream Parity to De-Skew ............................13\n  \
    \    4.2. Using Transition Mappings to De-Skew ......................14\n    \
    \  4.3. Using FFT to De-Skew ......................................15\n      4.4.\
    \ Using Compression to De-Skew ..............................15\n   5. Mixing\
    \ .........................................................16\n      5.1. A Trivial\
    \ Mixing Function .................................17\n      5.2. Stronger Mixing\
    \ Functions .................................18\n      5.3. Using S-Boxes for\
    \ Mixing ..................................19\n      5.4. Diffie-Hellman as a\
    \ Mixing Function .......................19\n      5.5. Using a Mixing Function\
    \ to Stretch Random Bits ............20\n      5.6. Other Factors in Choosing\
    \ a Mixing Function ...............20\n   6. Pseudo-random Number Generators ................................21\n\
    \      6.1. Some Bad Ideas ............................................21\n  \
    \         6.1.1. The Fallacy of Complex Manipulation ................21\n    \
    \       6.1.2. The Fallacy of Selection from a Large Database .....22\n      \
    \     6.1.3. Traditional Pseudo-random Sequences ................23\n      6.2.\
    \ Cryptographically Strong Sequences ........................24\n           6.2.1.\
    \ OFB and CTR Sequences ..............................25\n           6.2.2. The\
    \ Blum Blum Shub Sequence Generator ..............26\n      6.3. Entropy Pool\
    \ Techniques ...................................27\n   7. Randomness Generation\
    \ Examples and Standards ...................28\n      7.1. Complete Randomness\
    \ Generators ............................28\n           7.1.1. US DoD Recommendations\
    \ for Password Generation .....28\n           7.1.2. The /dev/random Device .............................29\n\
    \           7.1.3. Windows CryptGenRandom .............................30\n  \
    \    7.2. Generators Assuming a Source of Entropy ...................31\n    \
    \       7.2.1. X9.82 Pseudo-Random Number Generation ..............31\n      \
    \     7.2.2. X9.17 Key Generation ...............................33\n        \
    \   7.2.3. DSS Pseudo-random Number Generation ................34\n   8. Examples\
    \ of Randomness Required ................................34\n      8.1. Password\
    \ Generation .......................................35\n      8.2. A Very High\
    \ Security Cryptographic Key ....................36\n   9. Conclusion .....................................................38\n\
    \  10. Security Considerations ........................................38\n  11.\
    \ Acknowledgments ................................................39\n  Appendix\
    \ A: Changes from RFC 1750 ..................................40\n  Informative\
    \ References .............................................41\n"
- title: 1.  Introduction and Overview
  contents:
  - "1.  Introduction and Overview\n   Software cryptography is coming into wider\
    \ use, although there is a\n   long way to go until it becomes pervasive.  Systems\
    \ such as SSH,\n   IPSEC, TLS, S/MIME, PGP, DNSSEC, and Kerberos are maturing\
    \ and\n   becoming a part of the network landscape [SSH] [IPSEC] [TLS] [S/MIME]\n\
    \   [MAIL_PGP*] [DNSSEC*].  For comparison, when the previous version of\n   this\
    \ document [RFC1750] was issued in 1994, the only Internet\n   cryptographic security\
    \ specification in the IETF was the Privacy\n   Enhanced Mail protocol [MAIL_PEM*].\n\
    \   These systems provide substantial protection against snooping and\n   spoofing.\
    \  However, there is a potential flaw.  At the heart of all\n   cryptographic\
    \ systems is the generation of secret, unguessable (i.e.,\n   random) numbers.\n\
    \   The lack of generally available facilities for generating such random\n  \
    \ numbers (that is, the lack of general availability of truly\n   unpredictable\
    \ sources) forms an open wound in the design of\n   cryptographic software.  For\
    \ the software developer who wants to\n   build a key or password generation procedure\
    \ that runs on a wide\n   range of hardware, this is a very real problem.\n  \
    \ Note that the requirement is for data that an adversary has a very\n   low probability\
    \ of guessing or determining.  This can easily fail if\n   pseudo-random data\
    \ is used that meets only traditional statistical\n   tests for randomness, or\
    \ that is based on limited-range sources such\n   as clocks.  Sometimes such pseudo-random\
    \ quantities can be guessed by\n   an adversary searching through an embarrassingly\
    \ small space of\n   possibilities.\n   This Best Current Practice document describes\
    \ techniques for\n   producing random quantities that will be resistant to attack.\
    \  It\n   recommends that future systems include hardware random number\n   generation\
    \ or provide access to existing hardware that can be used\n   for this purpose.\
    \  It suggests methods for use if such hardware is\n   not available, and it gives\
    \ some estimates of the number of random\n   bits required for sample applications.\n"
- title: 2.  General Requirements
  contents:
  - "2.  General Requirements\n   Today, a commonly encountered randomness requirement\
    \ is to pick a\n   user password, usually a simple character string.  Obviously,\
    \ a\n   password that can be guessed does not provide security.  For re-\n   usable\
    \ passwords, it is desirable that users be able to remember the\n   password.\
    \  This may make it advisable to use pronounceable character\n   strings or phrases\
    \ composed of ordinary words.  But this affects only\n   the format of the password\
    \ information, not the requirement that the\n   password be very hard to guess.\n\
    \   Many other requirements come from the cryptographic arena.\n   Cryptographic\
    \ techniques can be used to provide a variety of\n   services, including confidentiality\
    \ and authentication.  Such\n   services are based on quantities, traditionally\
    \ called \"keys\", that\n   are unknown to and unguessable by an adversary.\n\
    \   There are even TCP/IP protocol uses for randomness in picking initial\n  \
    \ sequence numbers [RFC1948].\n   Generally speaking, the above examples also\
    \ illustrate two different\n   types of random quantities that may be wanted.\
    \  In the case of\n   human-usable passwords, the only important characteristic\
    \ is that\n   they be unguessable.  It is not important that they may be composed\n\
    \   of ASCII characters, so the top bit of every byte is zero, for\n   example.\
    \  On the other hand, for fixed length keys and the like, one\n   normally wants\
    \ quantities that appear to be truly random, that is,\n   quantities whose bits\
    \ will pass statistical randomness tests.\n   In some cases, such as the use of\
    \ symmetric encryption with the one-\n   time pads or an algorithm like the US\
    \ Advanced Encryption Standard\n   [AES], the parties who wish to communicate\
    \ confidentially and/or with\n   authentication must all know the same secret\
    \ key.  In other cases,\n   where asymmetric or \"public key\" cryptographic techniques\
    \ are used,\n   keys come in pairs.  One key of the pair is private and must be\
    \ kept\n   secret by one party; the other is public and can be published to the\n\
    \   world.  It is computationally infeasible to determine the private key\n  \
    \ from the public key, and knowledge of the public key is of no help to\n   an\
    \ adversary [ASYMMETRIC].  See general references [SCHNEIER,\n   FERGUSON, KAUFMAN].\n\
    \   The frequency and volume of the requirement for random quantities\n   differs\
    \ greatly for different cryptographic systems.  With pure RSA,\n   random quantities\
    \ are required only when a new key pair is generated;\n   thereafter, any number\
    \ of messages can be signed without a further\n   need for randomness.  The public\
    \ key Digital Signature Algorithm\n   devised by the US National Institute of\
    \ Standards and Technology\n   (NIST) requires good random numbers for each signature\
    \ [DSS].  And\n   encrypting with a one-time pad (in principle the strongest possible\n\
    \   encryption technique) requires randomness of equal volume to all the\n   messages\
    \ to be processed.  See general references [SCHNEIER,\n   FERGUSON, KAUFMAN].\n\
    \   In most of these cases, an adversary can try to determine the\n   \"secret\"\
    \ key by trial and error.  This is possible as long as the key\n   is enough smaller\
    \ than the message that the correct key can be\n   uniquely identified.  The probability\
    \ of an adversary succeeding at\n   this must be made acceptably low, depending\
    \ on the particular\n   application.  The size of the space the adversary must\
    \ search is\n   related to the amount of key \"information\" present, in an\n\
    \   information-theoretic sense [SHANNON].  This depends on the number of\n  \
    \ different secret values possible and the probability of each value,\n   as follows:\n\
    \                              -----\n                              \\\n     \
    \   Bits of information =  \\     - p   * log  ( p  )\n                      \
    \         /        i       2    i\n                              /\n         \
    \                     -----\n   where i counts from 1 to the number of possible\
    \ secret values and p\n   sub i is the probability of the value numbered i.  (Because\
    \ p sub i\n   is less than one, the log will be negative, so each term in the\
    \ sum\n   will be non-negative.)\n   If there are 2^n different values of equal\
    \ probability, then n bits\n   of information are present and an adversary would\
    \ have to try, on the\n   average, half of the values, or 2^(n-1), before guessing\
    \ the secret\n   quantity.  If the probability of different values is unequal,\
    \ then\n   there is less information present, and fewer guesses will, on\n   average,\
    \ be required by an adversary.  In particular, any values that\n   an adversary\
    \ can know to be impossible or of low probability can be\n   initially ignored\
    \ by the adversary, who will search through the more\n   probable values first.\n\
    \   For example, consider a cryptographic system that uses 128-bit keys.\n   If\
    \ these keys are derived using a fixed pseudo-random number\n   generator that\
    \ is seeded with an 8-bit seed, then an adversary needs\n   to search through\
    \ only 256 keys (by running the pseudo-random number\n   generator with every\
    \ possible seed), not 2^128 keys as may at first\n   appear to be the case.  Only\
    \ 8 bits of \"information\" are in these\n   128-bit keys.\n   While the above\
    \ analysis is correct on average, it can be misleading\n   in some cases for cryptographic\
    \ analysis where what is really\n   important is the work factor for an adversary.\
    \  For example, assume\n   that there is a pseudo-random number generator generating\
    \ 128-bit\n   keys, as in the previous paragraph, but that it generates zero half\n\
    \   of the time and a random selection from the remaining 2^128 - 1\n   values\
    \ the rest of the time.  The Shannon equation above says that\n   there are 64\
    \ bits of information in one of these key values, but an\n   adversary, simply\
    \ by trying the value zero, can break the security of\n   half of the uses, albeit\
    \ a random half.  Thus, for cryptographic\n   purposes, it is also useful to look\
    \ at other measures, such as min-\n   entropy, defined as\n        Min-entropy\
    \ =  - log  ( maximum ( p  ) )\n                                           i\n\
    \   where i is as above.  Using this equation, we get 1 bit of min-\n   entropy\
    \ for our new hypothetical distribution, as opposed to 64 bits\n   of classical\
    \ Shannon entropy.\n   A continuous spectrum of entropies, sometimes called Renyi\
    \ entropy,\n   has been defined, specified by the parameter r.  Here r = 1 is\n\
    \   Shannon entropy and r = infinity is min-entropy.  When r = zero, it\n   is\
    \ just log (n), where n is the number of non-zero probabilities.\n   Renyi entropy\
    \ is a non-increasing function of r, so min-entropy is\n   always the most conservative\
    \ measure of entropy and usually the best\n   to use for cryptographic evaluation\
    \ [LUBY].\n   Statistically tested randomness in the traditional sense is NOT\
    \ the\n   same as the unpredictability required for security use.\n   For example,\
    \ the use of a widely available constant sequence, such as\n   the random table\
    \ from the CRC Standard Mathematical Tables, is very\n   weak against an adversary.\
    \  An adversary who learns of or guesses it\n   can easily break all security,\
    \ future and past, based on the sequence\n   [CRC].  As another example, using\
    \ AES with a constant key to encrypt\n   successive integers such as 1, 2, 3,\
    \ ... will produce output that\n   also has excellent statistical randomness properties\
    \ but is\n   predictable.  On the other hand, taking successive rolls of a six-\n\
    \   sided die and encoding the resulting values in ASCII would produce\n   statistically\
    \ poor output with a substantial unpredictable component.\n   So note that passing\
    \ or failing statistical tests doesn't reveal\n   whether something is unpredictable\
    \ or predictable.\n"
- title: 3.  Entropy Sources
  contents:
  - "3.  Entropy Sources\n   Entropy sources tend to be very implementation dependent.\
    \  Once one\n   has gathered sufficient entropy, it can be used as the seed to\n\
    \   produce the required amount of cryptographically strong pseudo-\n   randomness,\
    \ as described in Sections 6 and 7, after being de-skewed\n   or mixed as necessary,\
    \ as described in Sections 4 and 5.\n   Is there any hope for true, strong, portable\
    \ randomness in the\n   future?  There might be.  All that's needed is a physical\
    \ source of\n   unpredictable numbers.\n   Thermal noise (sometimes called Johnson\
    \ noise in integrated circuits)\n   or a radioactive decay source and a fast,\
    \ free-running oscillator\n   would do the trick directly [GIFFORD].  This is\
    \ a trivial amount of\n   hardware, and it could easily be included as a standard\
    \ part of a\n   computer system's architecture.  Most audio (or video) input devices\n\
    \   are usable [TURBID].  Furthermore, any system with a spinning disk or\n  \
    \ ring oscillator and a stable (crystal) time source or the like has an\n   adequate\
    \ source of randomness ([DAVIS] and Section 3.3).  All that's\n   needed is the\
    \ common perception among computer vendors that this\n   small additional hardware\
    \ and the software to access it is necessary\n   and useful.\n   ANSI X9 is currently\
    \ developing a standard that includes a part\n   devoted to entropy sources. \
    \ See Part 2 of [X9.82].\n"
- title: 3.1.  Volume Required
  contents:
  - "3.1.  Volume Required\n   How much unpredictability is needed?  Is it possible\
    \ to quantify the\n   requirement in terms of, say, number of random bits per\
    \ second?\n   The answer is that not very much is needed.  For AES, the key can\
    \ be\n   128 bits, and, as we show in an example in Section 8, even the\n   highest\
    \ security system is unlikely to require strong keying material\n   of much over\
    \ 200 bits.  If a series of keys is needed, they can be\n   generated from a strong\
    \ random seed (starting value) using a\n   cryptographically strong sequence,\
    \ as explained in Section 6.2.  A\n   few hundred random bits generated at start-up\
    \ or once a day is enough\n   if such techniques are used.  Even if the random\
    \ bits are generated\n   as slowly as one per second and it is not possible to\
    \ overlap the\n   generation process, it should be tolerable in most high-security\n\
    \   applications to wait 200 seconds occasionally.\n   These numbers are trivial\
    \ to achieve.  It could be achieved by a\n   person repeatedly tossing a coin,\
    \ and almost any hardware based\n   process is likely to be much faster.\n"
- title: 3.2.  Existing Hardware Can Be Used For Randomness
  contents:
  - "3.2.  Existing Hardware Can Be Used For Randomness\n   As described below, many\
    \ computers come with hardware that can, with\n   care, be used to generate truly\
    \ random quantities.\n"
- title: 3.2.1.  Using Existing Sound/Video Input
  contents:
  - "3.2.1.  Using Existing Sound/Video Input\n   Many computers are built with inputs\
    \ that digitize some real-world\n   analog source, such as sound from a microphone\
    \ or video input from a\n   camera.  The \"input\" from a sound digitizer with\
    \ no source plugged in\n   or from a camera with the lens cap on is essentially\
    \ thermal noise.\n   If the system has enough gain to detect anything, such input\
    \ can\n   provide reasonably high quality random bits.  This method is\n   extremely\
    \ dependent on the hardware implementation.\n   For example, on some UNIX-based\
    \ systems, one can read from the\n   /dev/audio device with nothing plugged into\
    \ the microphone jack or\n   with the microphone receiving only low level background\
    \ noise.  Such\n   data is essentially random noise, although it should not be\
    \ trusted\n   without some checking, in case of hardware failure, and it will\
    \ have\n   to be de-skewed.\n   Combining this approach with compression to de-skew\
    \ (see Section 4),\n   one can generate a huge amount of medium-quality random\
    \ data with the\n   UNIX-style command line:\n        cat /dev/audio | compress\
    \ - >random-bits-file\n   A detailed examination of this type of randomness source\
    \ appears in\n   [TURBID].\n"
- title: 3.2.2.  Using Existing Disk Drives
  contents:
  - "3.2.2.  Using Existing Disk Drives\n   Disk drives have small random fluctuations\
    \ in their rotational speed\n   due to chaotic air turbulence [DAVIS, Jakobsson].\
    \  The addition of\n   low-level disk seek-time instrumentation produces a series\
    \ of\n   measurements that contain this randomness.  Such data is usually\n  \
    \ highly correlated, so significant processing is needed, as described\n   in\
    \ Section 5.2 below.  Nevertheless, experimentation a decade ago\n   showed that,\
    \ with such processing, even slow disk drives on the\n   slower computers of that\
    \ day could easily produce 100 bits a minute\n   or more of excellent random data.\n\
    \   Every increase in processor speed, which increases the resolution\n   with\
    \ which disk motion can be timed or increases the rate of disk\n   seeks, increases\
    \ the rate of random bit generation possible with this\n   technique.  At the\
    \ time of this paper and with modern hardware, a\n   more typical rate of random\
    \ bit production would be in excess of\n   10,000 bits a second.  This technique\
    \ is used in random number\n   generators included in many operating system libraries.\n\
    \   Note: the inclusion of cache memories in disk controllers has little\n   effect\
    \ on this technique if very short seek times, which represent\n   cache hits,\
    \ are simply ignored.\n"
- title: 3.3.  Ring Oscillator Sources
  contents:
  - "3.3.  Ring Oscillator Sources\n   If an integrated circuit is being designed\
    \ or field-programmed, an\n   odd number of gates can be connected in series to\
    \ produce a free-\n   running ring oscillator.  By sampling a point in the ring\
    \ at a fixed\n   frequency (for example, one determined by a stable crystal\n\
    \   oscillator), some amount of entropy can be extracted due to\n   variations\
    \ in the free-running oscillator timing.  It is possible to\n   increase the rate\
    \ of entropy by XOR'ing sampled values from a few\n   ring oscillators with relatively\
    \ prime lengths.  It is sometimes\n   recommended that an odd number of rings\
    \ be used so that, even if the\n   rings somehow become synchronously locked to\
    \ each other, there will\n   still be sampled bit transitions.  Another possible\
    \ source to sample\n   is the output of a noisy diode.\n   Sampled bits from such\
    \ sources will have to be heavily de-skewed, as\n   disk rotation timings must\
    \ be (see Section 4).  An engineering study\n   would be needed to determine the\
    \ amount of entropy being produced\n   depending on the particular design.  In\
    \ any case, these can be good\n   sources whose cost is a trivial amount of hardware\
    \ by modern\n   standards.\n   As an example, IEEE 802.11i suggests the circuit\
    \ below, with due\n   attention in the design to isolation of the rings from each\
    \ other and\n   from clocked circuits to avoid undesired synchronization, etc.,\
    \ and\n   with extensive post processing [IEEE_802.11i].\n             |\\   \
    \  |\\                |\\\n         +-->| >0-->| >0-- 19 total --| >0--+-------+\n\
    \         |   |/     |/                |/    |       |\n         |           \
    \                       |       |\n         +----------------------------------+\
    \       V\n                                                 +-----+\n        \
    \     |\\     |\\                |\\         |     | output\n         +-->| >0-->|\
    \ >0-- 23 total --| >0--+--->| XOR |------>\n         |   |/     |/          \
    \      |/    |    |     |\n         |                                  |    +-----+\n\
    \         +----------------------------------+      ^ ^\n                    \
    \                               | |\n             |\\     |\\                |\\\
    \           | |\n         +-->| >0-->| >0-- 29 total --| >0--+------+ |\n    \
    \     |   |/     |/                |/    |        |\n         |              \
    \                    |        |\n         +----------------------------------+\
    \        |\n                                                     |\n         \
    \    Other randomness, if available ---------+\n"
- title: 3.4.  Problems with Clocks and Serial Numbers
  contents:
  - "3.4.  Problems with Clocks and Serial Numbers\n   Computer clocks and similar\
    \ operating system or hardware values,\n   provide significantly fewer real bits\
    \ of unpredictability than might\n   appear from their specifications.\n   Tests\
    \ have been done on clocks on numerous systems, and it was found\n   that their\
    \ behavior can vary widely and in unexpected ways.  One\n   version of an operating\
    \ system running on one set of hardware may\n   actually provide, say, microsecond\
    \ resolution in a clock, while a\n   different configuration of the \"same\" system\
    \ may always provide the\n   same lower bits and only count in the upper bits\
    \ at much lower\n   resolution.  This means that successive reads of the clock\
    \ may\n   produce identical values even if enough time has passed that the\n \
    \  value \"should\" change based on the nominal clock resolution.  There\n   are\
    \ also cases where frequently reading a clock can produce\n   artificial sequential\
    \ values, because of extra code that checks for\n   the clock being unchanged\
    \ between two reads and increases it by one!\n   Designing portable application\
    \ code to generate unpredictable numbers\n   based on such system clocks is particularly\
    \ challenging because the\n   system designer does not always know the properties\
    \ of the system\n   clock.\n   Use of a hardware serial number (such as an Ethernet\
    \ MAC address) may\n   also provide fewer bits of uniqueness than one would guess.\
    \  Such\n   quantities are usually heavily structured, and subfields may have\n\
    \   only a limited range of possible values, or values may be easily\n   guessable\
    \ based on approximate date of manufacture or other data.\n   For example, it\
    \ is likely that a company that manufactures both\n   computers and Ethernet adapters\
    \ will, at least internally, use its\n   own adapters, which significantly limits\
    \ the range of built-in\n   addresses.\n   Problems such as those described above\
    \ make the production of code to\n   generate unpredictable quantities difficult\
    \ if the code is to be\n   ported across a variety of computer platforms and systems.\n"
- title: 3.5.  Timing and Value of External Events
  contents:
  - "3.5.  Timing and Value of External Events\n   It is possible to measure the timing\
    \ and content of mouse movement,\n   key strokes, and similar user events.  This\
    \ is a reasonable source of\n   unguessable data, with some qualifications.  On\
    \ some machines, input\n   such as key strokes is buffered.  Even though the user's\
    \ inter-\n   keystroke timing may have sufficient variation and unpredictability,\n\
    \   there might not be an easy way to access that variation.  Another\n   problem\
    \ is that no standard method exists for sampling timing\n   details.  This makes\
    \ it hard to use this technique to build standard\n   software intended for distribution\
    \ to a large range of machines.\n   The amount of mouse movement and the actual\
    \ key strokes are usually\n   easier to access than timings, but they may yield\
    \ less\n   unpredictability because the user may provide highly repetitive\n \
    \  input.\n   Other external events, such as network packet arrival times and\n\
    \   lengths, can also be used, but only with great care.  In particular,\n   the\
    \ possibility of manipulation of such network traffic measurements\n   by an adversary\
    \ and the lack of history at system start-up must be\n   carefully considered.\
    \  If this input is subject to manipulation, it\n   must not be trusted as a source\
    \ of entropy.\n   In principle, almost any external sensor, such as raw radio\
    \ reception\n   or temperature sensing in appropriately equipped computers, can\
    \ be\n   used.  But in each case, careful consideration must be given to how\n\
    \   much this data is subject to adversarial manipulation and to how much\n  \
    \ entropy it can actually provide.\n   The above techniques are quite powerful\
    \ against attackers that have\n   no access to the quantities being measured.\
    \  For example, these\n   techniques would be powerful against offline attackers\
    \ who had no\n   access to one's environment and who were trying to crack one's\
    \ random\n   seed after the fact.  In all cases, the more accurately one can\n\
    \   measure the timing or value of an external sensor, the more rapidly\n   one\
    \ can generate bits.\n"
- title: 3.6.  Non-hardware Sources of Randomness
  contents:
  - "3.6.  Non-hardware Sources of Randomness\n   The best source of input entropy\
    \ would be a hardware-based random\n   source such as ring oscillators, disk drive\
    \ timing, thermal noise, or\n   radioactive decay.  However, if none of these\
    \ is available, there are\n   other possibilities.  These include system clocks,\
    \ system or\n   input/output buffers, user/system/hardware/network serial numbers\
    \ or\n   addresses and timing, and user input.  Unfortunately, each of these\n\
    \   sources can produce very limited or predictable values under some\n   circumstances.\n\
    \   Some of the sources listed above would be quite strong on multi-user\n   systems,\
    \ where each user of the system is in essence a source of\n   randomness.  However,\
    \ on a small single-user or embedded system,\n   especially at start-up, it might\
    \ be possible for an adversary to\n   assemble a similar configuration.  This\
    \ could give the adversary\n   inputs to the mixing process that were well-enough\
    \ correlated to\n   those used originally to make exhaustive search practical.\n\
    \   The use of multiple random inputs with a strong mixing function is\n   recommended\
    \ and can overcome weakness in any particular input.  The\n   timing and content\
    \ of requested \"random\" user keystrokes can yield\n   hundreds of random bits,\
    \ but conservative assumptions need to be\n   made.  For example, one reasonably\
    \ conservative assumption would be\n   that an inter-keystroke interval provides\
    \ at most a few bits of\n   randomness, but only when the interval is unique in\
    \ the sequence of\n   intervals up to that point.  A similar assumption would\
    \ be that a key\n   code provides a few bits of randomness, but only when the\
    \ code is\n   unique in the sequence.  Thus, an interval or key code that\n  \
    \ duplicated a previous value would be assumed to provide no additional\n   randomness.\
    \  The results of mixing these timings with typed\n   characters could be further\
    \ combined with clock values and other\n   inputs.\n   This strategy may make\
    \ practical portable code for producing good\n   random numbers for security,\
    \ even if some of the inputs are very weak\n   on some of the target systems.\
    \  However, it may still fail against a\n   high-grade attack on small, single-user,\
    \ or embedded systems,\n   especially if the adversary has ever been able to observe\
    \ the\n   generation process in the past.  A hardware-based random source is\n\
    \   still preferable.\n"
- title: 4.  De-skewing
  contents:
  - "4.  De-skewing\n   Is there any specific requirement on the shape of the distribution\
    \ of\n   quantities gathered for the entropy to produce the random numbers?\n\
    \   The good news is that the distribution need not be uniform.  All that\n  \
    \ is needed to bound performance is a conservative estimate of how\n   non-uniform\
    \ it is.  Simple techniques to de-skew a bit stream are\n   given below, and stronger\
    \ cryptographic techniques are described in\n   Section 5.2.\n"
- title: 4.1.  Using Stream Parity to De-Skew
  contents:
  - "4.1.  Using Stream Parity to De-Skew\n   As a simple but not particularly practical\
    \ example, consider taking a\n   sufficiently long string of bits and mapping\
    \ the string to \"zero\" or\n   \"one\".  The mapping will not yield a perfectly\
    \ uniform distribution,\n   but it can be as close as desired.  One mapping that\
    \ serves the\n   purpose is to take the parity of the string.  This has the advantages\n\
    \   that it is robust across all degrees of skew up to the estimated\n   maximum\
    \ skew and that it is trivial to implement in hardware.\n   The following analysis\
    \ gives the number of bits that must be sampled:\n   Suppose that the ratio of\
    \ ones to zeros is ( 0.5 + E ) to\n   ( 0.5 - E ), where E is between 0 and 0.5\
    \ and is a measure of the\n   \"eccentricity\" of the distribution.  Consider\
    \ the distribution of the\n   parity function of N bit samples.  The respective\
    \ probabilities that\n   the parity will be one or zero will be the sum of the\
    \ odd or even\n   terms in the binomial expansion of (p + q)^N, where p = 0.5\
    \ + E, the\n   probability of a one, and q = 0.5 - E, the probability of a zero.\n\
    \   These sums can be computed easily as\n                         N         \
    \   N\n        1/2 * ( ( p + q )  + ( p - q )  )\n   and\n                   \
    \      N            N\n        1/2 * ( ( p + q )  - ( p - q )  ).\n   (Which formula\
    \ corresponds to the probability that the parity will be\n   1 depends on whether\
    \ N is odd or even.)\n   Since p + q = 1 and p - q = 2E, these expressions reduce\
    \ to\n                       N\n        1/2 * [1 + (2E)  ]\n   and\n         \
    \              N\n        1/2 * [1 - (2E)  ].\n   Neither of these will ever be\
    \ exactly 0.5 unless E is zero, but we\n   can bring them arbitrarily close to\
    \ 0.5.  If we want the\n   probabilities to be within some delta d of 0.5, e.g.,\
    \ then\n                            N\n        ( 0.5 + ( 0.5 * (2E)  ) )  <  0.5\
    \ + d.\n   Solving for N yields N > log(2d)/log(2E). (Note that 2E is less than\n\
    \   1, so its log is negative.  Division by a negative number reverses\n   the\
    \ sense of an inequality.)\n   The following table gives the length N of the string\
    \ that must be\n   sampled for various degrees of skew in order to come within\
    \ 0.001 of\n   a 50/50 distribution.\n                +---------+--------+-------+\n\
    \                | Prob(1) |    E   |    N  |\n                +---------+--------+-------+\n\
    \                |   0.5   |  0.00  |    1  |\n                |   0.6   |  0.10\
    \  |    4  |\n                |   0.7   |  0.20  |    7  |\n                |\
    \   0.8   |  0.30  |   13  |\n                |   0.9   |  0.40  |   28  |\n \
    \               |   0.95  |  0.45  |   59  |\n                |   0.99  |  0.49\
    \  |  308  |\n                +---------+--------+-------+\n   The last entry\
    \ shows that even if the distribution is skewed 99% in\n   favor of ones, the\
    \ parity of a string of 308 samples will be within\n   0.001 of a 50/50 distribution.\
    \  But, as we shall see in section 5.2,\n   there are much stronger techniques\
    \ that extract more of the available\n   entropy.\n"
- title: 4.2.  Using Transition Mappings to De-Skew
  contents:
  - "4.2.  Using Transition Mappings to De-Skew\n   Another technique, originally\
    \ due to von Neumann [VON_NEUMANN], is to\n   examine a bit stream as a sequence\
    \ of non-overlapping pairs.  One\n   could then discard any 00 or 11 pairs found,\
    \ interpret 01 as a 0 and\n   10 as a 1.  Assume that the probability of a 1 is\
    \ 0.5+E and that the\n   probability of a 0 is 0.5-E, where E is the eccentricity\
    \ of the\n   source as described in the previous section.  Then the probability\
    \ of\n   each pair is shown in the following table:\n            +------+-----------------------------------------+\n\
    \            | pair |            probability                  |\n            +------+-----------------------------------------+\n\
    \            |  00  | (0.5 - E)^2          =  0.25 - E + E^2  |\n            |\
    \  01  | (0.5 - E)*(0.5 + E)  =  0.25     - E^2  |\n            |  10  | (0.5\
    \ + E)*(0.5 - E)  =  0.25     - E^2  |\n            |  11  | (0.5 + E)^2     \
    \     =  0.25 + E + E^2  |\n            +------+-----------------------------------------+\n\
    \   This technique will completely eliminate any bias but requires an\n   indeterminate\
    \ number of input bits for any particular desired number\n   of output bits. \
    \ The probability of any particular pair being\n   discarded is 0.5 + 2E^2, so\
    \ the expected number of input bits to\n   produce X output bits is X/(0.25 -\
    \ E^2).\n   This technique assumes that the bits are from a stream where each\
    \ bit\n   has the same probability of being a 0 or 1 as any other bit in the\n\
    \   stream and that bits are uncorrelated, i.e., that the bits come from\n   identical\
    \ independent distributions.  If alternate bits are from two\n   correlated sources,\
    \ for example, the above analysis breaks down.\n   The above technique also provides\
    \ another illustration of how a\n   simple statistical analysis can mislead if\
    \ one is not always on the\n   lookout for patterns that could be exploited by\
    \ an adversary.  If the\n   algorithm were misread slightly so that overlapping\
    \ successive bits\n   pairs were used instead of non-overlapping pairs, the statistical\n\
    \   analysis given would be the same.  However, instead of providing an\n   unbiased,\
    \ uncorrelated series of random 1s and 0s, it would produce a\n   totally predictable\
    \ sequence of exactly alternating 1s and 0s.\n"
- title: 4.3.  Using FFT to De-Skew
  contents:
  - "4.3.  Using FFT to De-Skew\n   When real-world data consists of strongly correlated\
    \ bits, it may\n   still contain useful amounts of entropy.  This entropy can\
    \ be\n   extracted through various transforms, the most powerful of which are\n\
    \   described in section 5.2 below.\n   Using the Fourier transform of the data\
    \ or its optimized variant, the\n   FFT, is interesting primarily for theoretical\
    \ reasons.  It can be\n   shown that this technique will discard strong correlations.\
    \  If\n   adequate data is processed and if remaining correlations decay,\n  \
    \ spectral lines that approach statistical independence and normally\n   distributed\
    \ randomness can be produced [BRILLINGER].\n"
- title: 4.4.  Using Compression to De-Skew
  contents:
  - "4.4.  Using Compression to De-Skew\n   Reversible compression techniques also\
    \ provide a crude method of de-\n   skewing a skewed bit stream.  This follows\
    \ directly from the\n   definition of reversible compression and the formula in\
    \ Section 2 for\n   the amount of information in a sequence.  Since the compression\
    \ is\n   reversible, the same amount of information must be present in the\n \
    \  shorter output as was present in the longer input.  By the Shannon\n   information\
    \ equation, this is only possible if, on average, the\n   probabilities of the\
    \ different shorter sequences are more uniformly\n   distributed than were the\
    \ probabilities of the longer sequences.\n   Therefore, the shorter sequences\
    \ must be de-skewed relative to the\n   input.\n   However, many compression techniques\
    \ add a somewhat predictable\n   preface to their output stream and may insert\
    \ a similar sequence\n   periodically in their output or otherwise introduce subtle\
    \ patterns\n   of their own.  They should be considered only rough techniques\n\
    \   compared to those described in Section 5.2.  At a minimum, the\n   beginning\
    \ of the compressed sequence should be skipped and only later\n   bits should\
    \ used for applications requiring roughly-random bits.\n"
- title: 5.  Mixing
  contents:
  - "5.  Mixing\n   What is the best overall strategy for obtaining unguessable random\n\
    \   numbers in the absence of a strong, reliable hardware entropy source?\n  \
    \ It is to obtain input from a number of uncorrelated sources and to\n   mix them\
    \ with a strong mixing function.  Such a function will\n   preserve the entropy\
    \ present in any of the sources, even if other\n   quantities being combined happen\
    \ to be fixed or easily guessable (low\n   entropy).  This approach may be advisable\
    \ even with a good hardware\n   source, as hardware can also fail.  However, this\
    \ should be weighed\n   against a possible increase in the chance of overall failure\
    \ due to\n   added software complexity.\n   Once one has used good sources, such\
    \ as some of those listed in\n   Section 3, and mixed them as described in this\
    \ section, one has a\n   strong seed.  This can then be used to produce large\
    \ quantities of\n   cryptographically strong material as described in Sections\
    \ 6 and 7.\n   A strong mixing function is one that combines inputs and produces\
    \ an\n   output in which each output bit is a different complex non-linear\n \
    \  function of all the input bits.  On average, changing any input bit\n   will\
    \ change about half the output bits.  But because the relationship\n   is complex\
    \ and non-linear, no particular output bit is guaranteed to\n   change when any\
    \ particular input bit is changed.\n   Consider the problem of converting a stream\
    \ of bits that is skewed\n   towards 0 or 1 or which has a somewhat predictable\
    \ pattern to a\n   shorter stream which is more random, as discussed in Section\
    \ 4.  This\n   is simply another case where a strong mixing function is desired,\
    \ to\n   mix the input bits and produce a smaller number of output bits.  The\n\
    \   technique given in Section 4.1, using the parity of a number of bits,\n  \
    \ is simply the result of successively XORing them.  This is examined\n   as a\
    \ trivial mixing function, immediately below.  Use of stronger\n   mixing functions\
    \ to extract more of the randomness in a stream of\n   skewed bits is examined\
    \ in Section 5.2.  See also [NASLUND].\n"
- title: 5.1.  A Trivial Mixing Function
  contents:
  - "5.1.  A Trivial Mixing Function\n   For expository purposes we describe a trivial\
    \ example for single bit\n   inputs using the Exclusive Or (XOR) function.  This\
    \ function is\n   equivalent to addition without carry, as show in the table below.\n\
    \   This is a degenerate case in which the one output bit always changes\n   for\
    \ a change in either input bit.  But, despite its simplicity, it\n   provides\
    \ a useful illustration.\n                +-----------+-----------+----------+\n\
    \                |  input 1  |  input 2  |  output  |\n                +-----------+-----------+----------+\n\
    \                |     0     |     0     |     0    |\n                |     0\
    \     |     1     |     1    |\n                |     1     |     0     |    \
    \ 1    |\n                |     1     |     1     |     0    |\n             \
    \   +-----------+-----------+----------+\n   If inputs 1 and 2 are uncorrelated\
    \ and combined in this fashion, then\n   the output will be an even better (less\
    \ skewed) random bit than the\n   inputs are.  If we assume an \"eccentricity\"\
    \ E as defined in Section\n   4.1 above, then the output eccentricity relates\
    \ to the input\n   eccentricity as follows:\n        E       = 2 * E        *\
    \ E\n         output        input 1    input 2\n   Since E is never greater than\
    \ 1/2, the eccentricity is always\n   improved, except in the case in which at\
    \ least one input is a totally\n   skewed constant.  This is illustrated in the\
    \ following table, where\n   the top and left side values are the two input eccentricities\
    \ and the\n   entries are the output eccentricity:\n     +--------+--------+--------+--------+--------+--------+--------+\n\
    \     |    E   |  0.00  |  0.10  |  0.20  |  0.30  |  0.40  |  0.50  |\n     +--------+--------+--------+--------+--------+--------+--------+\n\
    \     |  0.00  |  0.00  |  0.00  |  0.00  |  0.00  |  0.00  |  0.00  |\n     |\
    \  0.10  |  0.00  |  0.02  |  0.04  |  0.06  |  0.08  |  0.10  |\n     |  0.20\
    \  |  0.00  |  0.04  |  0.08  |  0.12  |  0.16  |  0.20  |\n     |  0.30  |  0.00\
    \  |  0.06  |  0.12  |  0.18  |  0.24  |  0.30  |\n     |  0.40  |  0.00  |  0.08\
    \  |  0.16  |  0.24  |  0.32  |  0.40  |\n     |  0.50  |  0.00  |  0.10  |  0.20\
    \  |  0.30  |  0.40  |  0.50  |\n     +--------+--------+--------+--------+--------+--------+--------+\n\
    \   However, note that the above calculations assume that the inputs are\n   not\
    \ correlated.  If the inputs were, say, the parity of the number of\n   minutes\
    \ from midnight on two clocks accurate to a few seconds, then\n   each might appear\
    \ random if sampled at random intervals much longer\n   than a minute.  Yet if\
    \ they were both sampled and combined with XOR,\n   the result would be zero most\
    \ of the time.\n"
- title: 5.2.  Stronger Mixing Functions
  contents:
  - "5.2.  Stronger Mixing Functions\n   The US Government Advanced Encryption Standard\
    \ [AES] is an example of\n   a strong mixing function for multiple bit quantities.\
    \  It takes up to\n   384 bits of input (128 bits of \"data\" and 256 bits of\
    \ \"key\") and\n   produces 128 bits of output, each of which is dependent on\
    \ a complex\n   non-linear function of all input bits.  Other encryption functions\n\
    \   with this characteristic, such as [DES], can also be used by\n   considering\
    \ them to mix all of their key and data input bits.\n   Another good family of\
    \ mixing functions is the \"message digest\" or\n   hashing functions such as\
    \ the US Government Secure Hash Standards\n   [SHA*] and the MD4, MD5 [MD4, MD5]\
    \ series.  These functions all take\n   a practically unlimited amount of input\
    \ and produce a relatively\n   short fixed-length output mixing all the input\
    \ bits.  The MD* series\n   produces 128 bits of output, SHA-1 produces 160 bits,\
    \ and other SHA\n   functions produce up to 512 bits.\n   Although the message\
    \ digest functions are designed for variable\n   amounts of input, AES and other\
    \ encryption functions can also be used\n   to combine any number of inputs. \
    \ If 128 bits of output is adequate,\n   the inputs can be packed into a 128-bit\
    \ data quantity and successive\n   AES \"keys\", padding with zeros if needed;\
    \ the quantity is then\n   successively encrypted by the \"keys\" using AES in\
    \ Electronic Codebook\n   Mode.  Alternatively, the input could be packed into\
    \ one 128-bit key\n   and multiple data blocks and a CBC-MAC could be calculated\
    \ [MODES].\n   More complex mixing should be used if more than 128 bits of output\n\
    \   are needed and one wants to employ AES (but note that it is\n   absolutely\
    \ impossible to get more bits of \"randomness\" out than are\n   put in).  For\
    \ example, suppose that inputs are packed into three\n   quantities, A, B, and\
    \ C.  One may use AES to encrypt A with B and\n   then with C as keys to produce\
    \ the first part of the output, then\n   encrypt B with C and then A for more\
    \ output and, if necessary,\n   encrypt C with A and then B for yet more output.\
    \  Still more output\n   can be produced by reversing the order of the keys given\
    \ above.  The\n   same can be done with the hash functions, hashing various subsets\
    \ of\n   the input data or different copies of the input data with different\n\
    \   prefixes and/or suffixes to produce multiple outputs.\n   For an example of\
    \ using a strong mixing function, reconsider the case\n   of a string of 308 bits,\
    \ each of which is biased 99% toward zero.\n   The parity technique given in Section\
    \ 4.1 reduces this to one bit,\n   with only a 1/1000 deviance from being equally\
    \ likely a zero or one.\n   But, applying the equation for information given in\
    \ Section 2, this\n   308-bit skewed sequence contains over 5 bits of information.\
    \  Thus,\n   hashing it with SHA-1 and taking the bottom 5 bits of the result\n\
    \   would yield 5 unbiased random bits and not the single bit given by\n   calculating\
    \ the parity of the string.  Alternatively, for some\n   applications, you could\
    \ use the entire hash output to retain almost\n   all of the 5+ bits of entropy\
    \ in a 160-bit quantity.\n"
- title: 5.3.  Using S-Boxes for Mixing
  contents:
  - "5.3.  Using S-Boxes for Mixing\n   Many modern block encryption functions, including\
    \ DES and AES,\n   incorporate modules known as S-Boxes (substitution boxes).\
    \  These\n   produce a smaller number of outputs from a larger number of inputs\n\
    \   through a complex non-linear mixing function that has the effect of\n   concentrating\
    \ limited entropy from the inputs into the output.\n   S-Boxes sometimes incorporate\
    \ bent Boolean functions (functions of an\n   even number of bits producing one\
    \ output bit with maximum non-\n   linearity).  Looking at the output for all\
    \ input pairs differing in\n   any particular bit position, exactly half the outputs\
    \ are different.\n   An S-Box in which each output bit is produced by a bent function\
    \ such\n   that any linear combination of these functions is also a bent\n   function\
    \ is called a \"perfect S-Box\".\n   S-boxes and various repeated applications\
    \ or cascades of such boxes\n   can be used for mixing [SBOX1, SBOX2].\n"
- title: 5.4.  Diffie-Hellman as a Mixing Function
  contents:
  - "5.4.  Diffie-Hellman as a Mixing Function\n   Diffie-Hellman exponential key\
    \ exchange is a technique that yields a\n   shared secret between two parties.\
    \  It can be computationally\n   infeasible for a third party to determine this\
    \ secret even if they\n   can observe all the messages between the two communicating\
    \ parties.\n   This shared secret is a mixture of initial quantities generated\
    \ by\n   each of the parties [D-H].\n   If these initial quantities are random\
    \ and uncorrelated, then the\n   shared secret combines their entropy but, of\
    \ course, can not produce\n   more randomness than the size of the shared secret\
    \ generated.\n   Although this is true if the Diffie-Hellman computation is performed\n\
    \   privately, an adversary who can observe either of the public keys and\n  \
    \ knows the modulus being used need only search through the space of\n   the other\
    \ secret key in order to be able to calculate the shared\n   secret [D-H].  So,\
    \ conservatively, it would be best to consider\n   public Diffie-Hellman to produce\
    \ a quantity whose guessability\n   corresponds to the worse of the two inputs.\
    \  Because of this and the\n   fact that Diffie-Hellman is computationally intensive,\
    \ its use as a\n   mixing function is not recommended.\n"
- title: 5.5.  Using a Mixing Function to Stretch Random Bits
  contents:
  - "5.5.  Using a Mixing Function to Stretch Random Bits\n   Although it is not necessary\
    \ for a mixing function to produce the\n   same or fewer output bits than its\
    \ inputs, mixing bits cannot\n   \"stretch\" the amount of random unpredictability\
    \ present in the\n   inputs.  Thus, four inputs of 32 bits each, in which there\
    \ are 12\n   bits worth of unpredictability (such as 4,096 equally probable\n\
    \   values) in each input, cannot produce more than 48 bits worth of\n   unpredictable\
    \ output.  The output can be expanded to hundreds or\n   thousands of bits by,\
    \ for example, mixing with successive integers,\n   but the clever adversary's\
    \ search space is still 2^48 possibilities.\n   Furthermore, mixing to fewer bits\
    \ than are input will tend to\n   strengthen the randomness of the output.\n \
    \  The last table in Section 5.1 shows that mixing a random bit with a\n   constant\
    \ bit with Exclusive Or will produce a random bit.  While this\n   is true, it\
    \ does not provide a way to \"stretch\" one random bit into\n   more than one.\
    \  If, for example, a random bit is mixed with a 0 and\n   then with a 1, this\
    \ produces a two bit sequence but it will always be\n   either 01 or 10.  Since\
    \ there are only two possible values, there is\n   still only the one bit of original\
    \ randomness.\n"
- title: 5.6.  Other Factors in Choosing a Mixing Function
  contents:
  - "5.6.  Other Factors in Choosing a Mixing Function\n   For local use, AES has\
    \ the advantages that it has been widely tested\n   for flaws, is reasonably efficient\
    \ in software, and is widely\n   documented and implemented with hardware and\
    \ software implementations\n   available all over the world including open source\
    \ code.  The SHA*\n   family have had a little less study and tend to require\
    \ more CPU\n   cycles than AES but there is no reason to believe they are flawed.\n\
    \   Both SHA* and MD5 were derived from the earlier MD4 algorithm.  They\n   all\
    \ have source code available [SHA*, MD4, MD5].  Some signs of\n   weakness have\
    \ been found in MD4 and MD5.  In particular, MD4 has only\n   three rounds and\
    \ there are several independent breaks of the first\n   two or last two rounds.\
    \  And some collisions have been found in MD5\n   output.\n   AES was selected\
    \ by a robust, public, and international process.  It\n   and SHA* have been vouched\
    \ for by the US National Security Agency\n   (NSA) on the basis of criteria that\
    \ mostly remain secret, as was DES.\n   While this has been the cause of much\
    \ speculation and doubt,\n   investigation of DES over the years has indicated\
    \ that NSA\n   involvement in modifications to its design, which originated with\n\
    \   IBM, was primarily to strengthen it.  There has been no announcement\n   of\
    \ a concealed or special weakness being found in DES.  It is likely\n   that the\
    \ NSA modifications to MD4 to produce the SHA algorithms\n   similarly strengthened\
    \ these algorithms, possibly against threats not\n   yet known in the public cryptographic\
    \ community.\n   Where input lengths are unpredictable, hash algorithms are more\n\
    \   convenient to use than block encryption algorithms since they are\n   generally\
    \ designed to accept variable length inputs.  Block\n   encryption algorithms\
    \ generally require an additional padding\n   algorithm to accommodate inputs\
    \ that are not an even multiple of the\n   block size.\n   As of the time of this\
    \ document, the authors know of no patent claims\n   to the basic AES, DES, SHA*,\
    \ MD4, and MD5 algorithms other than\n   patents for which an irrevocable royalty\
    \ free license has been\n   granted to the world.  There may, of course, be essential\
    \ patents of\n   which the authors are unaware or patents on implementations or\
    \ uses\n   or other relevant patents issued or to be issued.\n"
- title: 6.  Pseudo-random Number Generators
  contents:
  - "6.  Pseudo-random Number Generators\n   When a seed has sufficient entropy, from\
    \ input as described in\n   Section 3 and possibly de-skewed and mixed as described\
    \ in Sections 4\n   and 5, one can algorithmically extend that seed to produce\
    \ a large\n   number of cryptographically-strong random quantities.  Such\n  \
    \ algorithms are platform independent and can operate in the same\n   fashion\
    \ on any computer.  For the algorithms to be secure, their\n   input and internal\
    \ workings must be protected from adversarial\n   observation.\n   The design\
    \ of such pseudo-random number generation algorithms, like\n   the design of symmetric\
    \ encryption algorithms, is not a task for\n   amateurs.  Section 6.1 below lists\
    \ a number of bad ideas that failed\n   algorithms have used.  To learn what works,\
    \ skip Section 6.1 and just\n   read the remainder of this section and Section\
    \ 7, which describes and\n   references some standard pseudo random number generation\
    \ algorithms.\n   See Section 7 and Part 3 of [X9.82].\n"
- title: 6.1.  Some Bad Ideas
  contents:
  - "6.1.  Some Bad Ideas\n   The subsections below describe a number of ideas that\
    \ might seem\n   reasonable but that lead to insecure pseudo-random number generation.\n"
- title: 6.1.1.  The Fallacy of Complex Manipulation
  contents:
  - "6.1.1.  The Fallacy of Complex Manipulation\n   One approach that may give a\
    \ misleading appearance of\n   unpredictability is to take a very complex algorithm\
    \ (or an excellent\n   traditional pseudo-random number generator with good statistical\n\
    \   properties) and to calculate a cryptographic key by starting with\n   limited\
    \ data such as the computer system clock value as the seed.\n   Adversaries who\
    \ knew roughly when the generator was started would\n   have a relatively small\
    \ number of seed values to test, as they would\n   know likely values of the system\
    \ clock.  Large numbers of pseudo-\n   random bits could be generated, but the\
    \ search space that an\n   adversary would need to check could be quite small.\n\
    \   Thus, very strong or complex manipulation of data will not help if\n   the\
    \ adversary can learn what the manipulation is and if there is not\n   enough\
    \ entropy in the starting seed value.  They can usually use the\n   limited number\
    \ of results stemming from a limited number of seed\n   values to defeat security.\n\
    \   Another serious strategic error is to assume that a very complex\n   pseudo-random\
    \ number generation algorithm will produce strong random\n   numbers, when there\
    \ has been no theory behind or analysis of the\n   algorithm.  There is a excellent\
    \ example of this fallacy near the\n   beginning of Chapter 3 in [KNUTH], where\
    \ the author describes a\n   complex algorithm.  It was intended that the machine\
    \ language program\n   corresponding to the algorithm would be so complicated\
    \ that a person\n   trying to read the code without comments wouldn't know what\
    \ the\n   program was doing.  Unfortunately, actual use of this algorithm\n  \
    \ showed that it almost immediately converged to a single repeated\n   value in\
    \ one case and a small cycle of values in another case.\n   Not only does complex\
    \ manipulation not help you if you have a limited\n   range of seeds, but blindly-chosen\
    \ complex manipulation can destroy\n   the entropy in a good seed!\n"
- title: 6.1.2.  The Fallacy of Selection from a Large Database
  contents:
  - "6.1.2.  The Fallacy of Selection from a Large Database\n   Another approach that\
    \ can give a misleading appearance of\n   unpredictability is to randomly select\
    \ a quantity from a database and\n   to assume that its strength is related to\
    \ the total number of bits in\n   the database.  For example, typical USENET servers\
    \ process many\n   megabytes of information per day [USENET_1, USENET_2].  Assume\
    \ that a\n   random quantity was selected by fetching 32 bytes of data from a\n\
    \   random starting point in this data.  This does not yield 32*8 = 256\n   bits\
    \ worth of unguessability.  Even if much of the data is human\n   language that\
    \ contains no more than 2 or 3 bits of information per\n   byte, it doesn't yield\
    \ 32*2 = 64 bits of unguessability.  For an\n   adversary with access to the same\
    \ Usenet database, the unguessability\n   rests only on the starting point of\
    \ the selection.  That is perhaps a\n   little over a couple of dozen bits of\
    \ unguessability.\n   The same argument applies to selecting sequences from the\
    \ data on a\n   publicly available CD/DVD recording or any other large public\n\
    \   database.  If the adversary has access to the same database, this\n   \"selection\
    \ from a large volume of data\" step buys little.  However,\n   if a selection\
    \ can be made from data to which the adversary has no\n   access, such as system\
    \ buffers on an active multi-user system, it may\n   be of help.\n"
- title: 6.1.3.  Traditional Pseudo-random Sequences
  contents:
  - "6.1.3.  Traditional Pseudo-random Sequences\n   This section talks about traditional\
    \ sources of deterministic or\n   \"pseudo-random\" numbers.  These typically\
    \ start with a \"seed\"\n   quantity and use simple numeric or logical operations\
    \ to produce a\n   sequence of values.  Note that none of the techniques discussed\
    \ in\n   this section is suitable for cryptographic use.  They are presented\n\
    \   for general information.\n   [KNUTH] has a classic exposition on pseudo-random\
    \ numbers.\n   Applications he mentions are simulations of natural phenomena,\n\
    \   sampling, numerical analysis, testing computer programs, decision\n   making,\
    \ and games.  None of these have the same characteristics as\n   the sorts of\
    \ security uses we are talking about.  Only in the last\n   two could there be\
    \ an adversary trying to find the random quantity.\n   However, in these cases,\
    \ the adversary normally has only a single\n   chance to use a guessed value.\
    \  In guessing passwords or attempting\n   to break an encryption scheme, the\
    \ adversary normally has many,\n   perhaps unlimited, chances at guessing the\
    \ correct value.  Sometimes\n   the adversary can store the message to be broken\
    \ and repeatedly\n   attack it.  Adversaries are also be assumed to be aided by\
    \ a\n   computer.\n   For testing the \"randomness\" of numbers, Knuth suggests\
    \ a variety of\n   measures, including statistical and spectral.  These tests\
    \ check\n   things like autocorrelation between different parts of a \"random\"\
    \n   sequence or distribution of its values.  But these tests could be met\n \
    \  by a constant stored random sequence, such as the \"random\" sequence\n   printed\
    \ in the CRC Standard Mathematical Tables [CRC].  Despite\n   meeting all the\
    \ tests suggested by Knuth, that sequence is unsuitable\n   for cryptographic\
    \ us, as adversaries must be assumed to have copies\n   of all commonly published\
    \ \"random\" sequences and to be able to spot\n   the source and predict future\
    \ values.\n   A typical pseudo-random number generation technique is the linear\n\
    \   congruence pseudo-random number generator.  This technique uses\n   modular\
    \ arithmetic, where the value numbered N+1 is calculated from\n   the value numbered\
    \ N by\n        V    = ( V  * a + b )(Mod c)\n         N+1      N\n   The above\
    \ technique has a strong relationship to linear shift\n   register pseudo-random\
    \ number generators, which are well understood\n   cryptographically [SHIFT*].\
    \  In such generators, bits are introduced\n   at one end of a shift register\
    \ as the Exclusive Or (binary sum\n   without carry) of bits from selected fixed\
    \ taps into the register.\n   For example, consider the following:\n      +----+\
    \     +----+     +----+                      +----+\n      | B  | <-- | B  | <--\
    \ | B  | <--  . . . . . . <-- | B  | <-+\n      |  0 |     |  1 |     |  2 | \
    \                     |  n |   |\n      +----+     +----+     +----+         \
    \             +----+   |\n        |                     |            |       \
    \              |\n        |                     |            V               \
    \   +-----+\n        |                     V            +----------------> | \
    \    |\n        V                     +-----------------------------> | XOR |\n\
    \        +---------------------------------------------------> |     |\n     \
    \                                                         +-----+\n       V  \
    \  = ( ( V  * 2 ) + B  XOR  B ... )(Mod 2^n)\n        N+1         N         0\
    \       2\n   The quality of traditional pseudo-random number generator algorithms\n\
    \   is measured by statistical tests on such sequences.  Carefully-chosen\n  \
    \ values a, b, c, and initial V or carefully-chosen placement of the\n   shift\
    \ register tap in the above simple process can produce excellent\n   statistics.\n\
    \   These sequences may be adequate in simulations (Monte Carlo\n   experiments)\
    \ as long as the sequence is orthogonal to the structure\n   of the space being\
    \ explored.  Even there, subtle patterns may cause\n   problems.  However, such\
    \ sequences are clearly bad for use in\n   security applications.  They are fully\
    \ predictable if the initial\n   state is known.  Depending on the form of the\
    \ pseudo-random number\n   generator, the sequence may be determinable from observation\
    \ of a\n   short portion of the sequence [SCHNEIER, STERN].  For example, with\n\
    \   the generators above, one can determine V(n+1) given knowledge of\n   V(n).\
    \  In fact, it has been shown that with these techniques, even if\n   only one\
    \ bit of the pseudo-random values are released, the seed can\n   be determined\
    \ from short sequences.\n   Not only have linear congruent generators been broken,\
    \ but techniques\n   are now known for breaking all polynomial congruent generators\n\
    \   [KRAWCZYK].\n"
- title: 6.2.  Cryptographically Strong Sequences
  contents:
  - "6.2.  Cryptographically Strong Sequences\n   In cases where a series of random\
    \ quantities must be generated, an\n   adversary may learn some values in the\
    \ sequence.  In general,\n   adversaries should not be able to predict other values\
    \ from the ones\n   that they know.\n   The correct technique is to start with\
    \ a strong random seed, to take\n   cryptographically strong steps from that seed\
    \ [FERGUSON, SCHNEIER],\n   and not to reveal the complete state of the generator\
    \ in the sequence\n   elements.  If each value in the sequence can be calculated\
    \ in a fixed\n   way from the previous value, then when any value is compromised,\
    \ all\n   future values can be determined.  This would be the case, for\n   example,\
    \ if each value were a constant function of the previously\n   used values, even\
    \ if the function were a very strong, non-invertible\n   message digest function.\n\
    \   (Note that if a technique for generating a sequence of key values is\n   fast\
    \ enough, it can trivially be used as the basis for a\n   confidentiality system.\
    \  If two parties use the same sequence\n   generation technique and start with\
    \ the same seed material, they will\n   generate identical sequences.  These could,\
    \ for example, be XOR'ed at\n   one end with data being sent to encrypt it, and\
    \ XOR'ed with this data\n   as received to decrypt it, due to the reversible properties\
    \ of the\n   XOR operation.  This is commonly referred to as a simple stream\n\
    \   cipher.)\n"
- title: 6.2.1.  OFB and CTR Sequences
  contents:
  - "6.2.1.  OFB and CTR Sequences\n   One way to produce a strong sequence is to\
    \ take a seed value and hash\n   the quantities produced by concatenating the\
    \ seed with successive\n   integers, or the like, and then to mask the values\
    \ obtained so as to\n   limit the amount of generator state available to the adversary.\n\
    \   It may also be possible to use an \"encryption\" algorithm with a\n   random\
    \ key and seed value to encrypt successive integers, as in\n   counter (CTR) mode\
    \ encryption.  Alternatively, one can feedback all\n   of the output value from\
    \ encryption into the value to be encrypted\n   for the next iteration.  This\
    \ is a particular example of output\n   feedback mode (OFB) [MODES].\n   An example\
    \ is shown below in which shifting and masking are used to\n   combine part of\
    \ the output feedback with part of the old input.  This\n   type of partial feedback\
    \ should be avoided for reasons described\n   below.\n            +---------------+\n\
    \            |       V       |\n            |  |     n      |--+\n           \
    \ +--+------------+  |\n                  |            |     +---------+\n   \
    \          shift|            +---> |         |      +-----+\n               +--+\
    \                  | Encrypt | <--- | Key |\n               |           +--------\
    \ |         |      +-----+\n               |           |         +---------+\n\
    \               V           V\n            +------------+--+\n            |  \
    \    V     |  |\n            |       n+1     |\n            +---------------+\n\
    \   Note that if a shift of one is used, this is the same as the shift\n   register\
    \ technique described in Section 6.1.3, but with the all-\n   important difference\
    \ that the feedback is determined by a complex\n   non-linear function of all\
    \ bits rather than by a simple linear or\n   polynomial combination of output\
    \ from a few bit position taps.\n   Donald W. Davies showed that this sort of\
    \ shifted partial output\n   feedback significantly weakens an algorithm, compared\
    \ to feeding all\n   the output bits back as input.  In particular, for DES, repeatedly\n\
    \   encrypting a full 64-bit quantity will give an expected repeat in\n   about\
    \ 2^63 iterations.  Feeding back anything less than 64 (and more\n   than 0) bits\
    \ will give an expected repeat in between 2^31 and 2^32\n   iterations!\n   To\
    \ predict values of a sequence from others when the sequence was\n   generated\
    \ by these techniques is equivalent to breaking the\n   cryptosystem or to inverting\
    \ the \"non-invertible\" hashing with only\n   partial information available.\
    \  The less information revealed in each\n   iteration, the harder it will be\
    \ for an adversary to predict the\n   sequence.  Thus it is best to use only one\
    \ bit from each value.  It\n   has been shown that in some cases this makes it\
    \ impossible to break a\n   system even when the cryptographic system is invertible\
    \ and could be\n   broken if all of each generated value were revealed.\n"
- title: 6.2.2.  The Blum Blum Shub Sequence Generator
  contents:
  - "6.2.2.  The Blum Blum Shub Sequence Generator\n   Currently the generator which\
    \ has the strongest public proof of\n   strength is called the Blum Blum Shub\
    \ generator, named after its\n   inventors [BBS].  It is also very simple and\
    \ is based on quadratic\n   residues.  Its only disadvantage is that it is computationally\n\
    \   intensive compared to the traditional techniques given in Section\n   6.1.3.\
    \  This is not a major drawback if it is used for moderately-\n   infrequent purposes,\
    \ such as generating session keys.\n   Simply choose two large prime numbers (say,\
    \ p and q) that each gives\n   a remainder of 3 when divided by 4.  Let n = p\
    \ * q.  Then choose a\n   random number, x, that is relatively prime to n.  The\
    \ initial seed\n   for the generator and the method for calculating subsequent\
    \ values\n   are then:\n                    2\n         s    =  ( x  )(Mod n)\n\
    \          0\n                    2\n         s    = ( s   )(Mod n)\n        \
    \  i+1      i\n   Be careful to use only a few bits from the bottom of each s.\
    \  It is\n   always safe to use only the lowest-order bit.  If one uses no more\n\
    \   than the:\n         log  ( log  ( s  ) )\n            2      2    i\n   low-order\
    \ bits, then predicting any additional bits from a sequence\n   generated in this\
    \ manner is provably as hard as factoring n.  As long\n   as the initial x is\
    \ secret, n can be made public if desired.\n   An interesting characteristic of\
    \ this generator is that any of the s\n   values can be directly calculated. \
    \ In particular,\n               ( (2^i) (Mod ((p-1)*(q-1)) ) )\n      s  = (\
    \ s                                )(Mod n)\n       i      0\n   This means that\
    \ in applications where many keys are generated in this\n   fashion, it is not\
    \ necessary to save them all.  Each key can be\n   effectively indexed and recovered\
    \ from that small index and the\n   initial s and n.\n"
- title: 6.3.  Entropy Pool Techniques
  contents:
  - "6.3.  Entropy Pool Techniques\n   Many modern pseudo-random number sources, such\
    \ as those described in\n   Sections 7.1.2 and 7.1.3 utilize the technique of\
    \ maintaining a\n   \"pool\" of bits and providing operations for strongly mixing\
    \ input\n   with some randomness into the pool and extracting pseudo-random bits\n\
    \   from the pool.  This is illustrated in the figure below.\n             +--------+\
    \    +------+    +---------+\n         --->| Mix In |--->| POOL |--->| Extract\
    \ |--->\n             |  Bits  |    |      |    |   Bits  |\n             +--------+\
    \    +------+    +---------+\n                               ^           V\n \
    \                              |           |\n                               +-----------+\n\
    \   Bits to be fed into the pool can come from any of the various\n   hardware,\
    \ environmental, or user input sources discussed above.  It\n   is also common\
    \ to save the state of the pool on system shutdown and\n   to restore it on re-starting,\
    \ when stable storage is available.\n   Care must be taken that enough entropy\
    \ has been added to the pool to\n   support particular output uses desired.  See\
    \ [RSA_BULL1] for similar\n   suggestions.\n"
- title: 7.  Randomness Generation Examples and Standards
  contents:
  - "7.  Randomness Generation Examples and Standards\n   Several public standards\
    \ and widely deployed examples are now in\n   place for the generation of keys\
    \ or other cryptographically random\n   quantities.  Some, in section 7.1, include\
    \ an entropy source.\n   Others, described in section 7.2, provide the pseudo-random\
    \ number\n   strong-sequence generator but assume the input of a random seed or\n\
    \   input from a source of entropy.\n"
- title: 7.1.  Complete Randomness Generators
  contents:
  - "7.1.  Complete Randomness Generators\n   Three standards are described below.\
    \  The two older standards use\n   DES, with its 64-bit block and key size limit,\
    \ but any equally strong\n   or stronger mixing function could be substituted\
    \ [DES].  The third is\n   a more modern and stronger standard based on SHA-1\
    \ [SHA*].  Lastly,\n   the widely deployed modern UNIX and Windows random number\
    \ generators\n   are described.\n"
- title: 7.1.1.  US DoD Recommendations for Password Generation
  contents:
  - "7.1.1.  US DoD Recommendations for Password Generation\n   The United States\
    \ Department of Defense has specific recommendations\n   for password generation\
    \ [DoD].  It suggests using the US Data\n   Encryption Standard [DES] in Output\
    \ Feedback Mode [MODES] as follows:\n         Use an initialization vector determined\
    \ from\n              the system clock,\n              system ID,\n          \
    \    user ID, and\n              date and time;\n         use a key determined\
    \ from\n              system interrupt registers,\n              system status\
    \ registers, and\n              system counters; and,\n         as plain text,\
    \ use an external randomly generated 64-bit\n         quantity such as the ASCII\
    \ bytes for 8 characters typed\n         in by a system administrator.\n   The\
    \ password can then be calculated from the 64 bit \"cipher text\"\n   generated\
    \ by DES in 64-bit Output Feedback Mode.  As many bits as are\n   needed can be\
    \ taken from these 64 bits and expanded into a\n   pronounceable word, phrase,\
    \ or other format if a human being needs to\n   remember the password.\n"
- title: 7.1.2.  The /dev/random Device
  contents:
  - "7.1.2.  The /dev/random Device\n   Several versions of the UNIX operating system\
    \ provide a kernel-\n   resident random number generator.  Some of these generators\
    \ use\n   events captured by the Kernel during normal system operation.\n   For\
    \ example, on some versions of Linux, the generator consists of a\n   random pool\
    \ of 512 bytes represented as 128 words of 4 bytes each.\n   When an event occurs,\
    \ such as a disk drive interrupt, the time of the\n   event is XOR'ed into the\
    \ pool, and the pool is stirred via a\n   primitive polynomial of degree 128.\
    \  The pool itself is treated as a\n   ring buffer, with new data being XOR'ed\
    \ (after stirring with the\n   polynomial) across the entire pool.\n   Each call\
    \ that adds entropy to the pool estimates the amount of\n   likely true entropy\
    \ the input contains.  The pool itself contains a\n   accumulator that estimates\
    \ the total over all entropy of the pool.\n   Input events come from several sources,\
    \ as listed below.\n   Unfortunately, for server machines without human operators,\
    \ the first\n   and third are not available, and entropy may be added slowly in\
    \ that\n   case.\n   1. Keyboard interrupts.  The time of the interrupt and the\
    \ scan code\n      are added to the pool.  This in effect adds entropy from the\
    \ human\n      operator by measuring inter-keystroke arrival times.\n   2. Disk\
    \ completion and other interrupts.  A system being used by a\n      person will\
    \ likely have a hard-to-predict pattern of disk\n      accesses.  (But not all\
    \ disk drivers support capturing this timing\n      information with sufficient\
    \ accuracy to be useful.)\n   3. Mouse motion.  The timing and mouse position\
    \ are added in.\n   When random bytes are required, the pool is hashed with SHA-1\
    \ [SHA*]\n   to yield the returned bytes of randomness.  If more bytes are\n \
    \  required than the output of SHA-1 (20 bytes), then the hashed output\n   is\
    \ stirred back into the pool and a new hash is performed to obtain\n   the next\
    \ 20 bytes.  As bytes are removed from the pool, the estimate\n   of entropy is\
    \ correspondingly decremented.\n   To ensure a reasonably random pool upon system\
    \ startup, the standard\n   startup and shutdown scripts save the pool to a disk\
    \ file at shutdown\n   and read this file at system startup.\n   There are two\
    \ user-exported interfaces. /dev/random returns bytes\n   from the pool but blocks\
    \ when the estimated entropy drops to zero.\n   As entropy is added to the pool\
    \ from events, more data becomes\n   available via /dev/random.  Random data obtained\
    \ from such a\n   /dev/random device is suitable for key generation for long term\
    \ keys,\n   if enough random bits are in the pool or are added in a reasonable\n\
    \   amount of time.\n   /dev/urandom works like /dev/random; however, it provides\
    \ data even\n   when the entropy estimate for the random pool drops to zero. \
    \ This\n   may be adequate for session keys or for other key generation tasks\n\
    \   for which blocking to await more random bits is not acceptable.  The\n   risk\
    \ of continuing to take data even when the pool's entropy estimate\n   is small\
    \ in that past output may be computable from current output,\n   provided that\
    \ an attacker can reverse SHA-1.  Given that SHA-1 is\n   designed to be non-invertible,\
    \ this is a reasonable risk.\n   To obtain random numbers under Linux, Solaris,\
    \ or other UNIX systems\n   equipped with code as described above, all an application\
    \ has to do\n   is open either /dev/random or /dev/urandom and read the desired\n\
    \   number of bytes.\n   (The Linux Random device was written by Theodore Ts'o.\
    \  It was based\n   loosely on the random number generator in PGP 2.X and PGP\
    \ 3.0 (aka\n   PGP 5.0).)\n"
- title: 7.1.3.  Windows CryptGenRandom
  contents:
  - "7.1.3.  Windows CryptGenRandom\n   Microsoft's recommendation to users of the\
    \ widely deployed Windows\n   operating system is generally to use the CryptGenRandom\
    \ pseudo-random\n   number generation call with the CryptAPI cryptographic service\n\
    \   provider.  This takes a handle to a cryptographic service provider\n   library,\
    \ a pointer to a buffer by which the caller can provide\n   entropy and into which\
    \ the generated pseudo-randomness is returned,\n   and an indication of how many\
    \ octets of randomness are desired.\n   The Windows CryptAPI cryptographic service\
    \ provider stores a seed\n   state variable with every user.  When CryptGenRandom\
    \ is called, this\n   is combined with any randomness provided in the call and\
    \ with various\n   system and user data such as the process ID, thread ID, system\
    \ clock,\n   system time, system counter, memory status, free disk clusters, and\n\
    \   hashed user environment block.  This data is all fed to SHA-1, and\n   the\
    \ output is used to seed an RC4 key stream.  That key stream is\n   used to produce\
    \ the pseudo-random data requested and to update the\n   user's seed state variable.\n\
    \   Users of Windows \".NET\" will probably find it easier to use the\n   RNGCryptoServiceProvider.GetBytes\
    \ method interface.\n   For further information, see [WSC].\n"
- title: 7.2.  Generators Assuming a Source of Entropy
  contents:
  - "7.2.  Generators Assuming a Source of Entropy\n   The pseudo-random number generators\
    \ described in the following three\n   sections all assume that a seed value with\
    \ sufficient entropy is\n   provided to them.  They then generate a strong sequence\
    \ (see Section\n   6.2) from that seed.\n"
- title: 7.2.1.  X9.82 Pseudo-Random Number Generation
  contents:
  - "7.2.1.  X9.82 Pseudo-Random Number Generation\n   The ANSI X9F1 committee is\
    \ in the final stages of creating a standard\n   for random number generation\
    \ covering both true randomness generators\n   and pseudo-random number generators.\
    \  It includes a number of\n   pseudo-random number generators based on hash functions,\
    \ one of which\n   will probably be based on HMAC SHA hash constructs [RFC2104].\
    \  The\n   draft version of this generator is described below, omitting a number\n\
    \   of optional features [X9.82].\n   In the subsections below, the HMAC hash\
    \ construct is simply referred\n   to as HMAC but, of course, a particular standard\
    \ SHA function must be\n   selected in an particular use.  Generally speaking,\
    \ if the strength\n   of the pseudo-random values to be generated is to be N bits,\
    \ the SHA\n   function chosen must generate N or more bits of output, and a source\n\
    \   of at least N bits of input entropy will be required.  The same hash\n   function\
    \ must be used throughout an instantiation of this generator.\n"
- title: 7.2.1.1.  Notation
  contents:
  - "7.2.1.1.  Notation\n   In the following sections, the notation give below is\
    \ used:\n      hash_length is the output size of the underlying hash function\
    \ in\n         use.\n      input_entropy is the input bit string that provides\
    \ entropy to the\n         generator.\n      K is a bit string of size hash_length\
    \ that is part of the state of\n         the generator and is updated at least\
    \ once each time random\n         bits are generated.\n      V is a bit string\
    \ of size hash_length and is part of the state of\n         the generator.  It\
    \ is updated each time hash_length bits of\n         output are generated.\n \
    \     \"|\" represents concatenation.\n"
- title: 7.2.1.2.  Initializing the Generator
  contents:
  - "7.2.1.2.  Initializing the Generator\n   Set V to all zero bytes, except the\
    \ low-order bit of each byte is set\n      to one.\n   Set K to all zero bytes,\
    \ then set:\n         K = HMAC ( K, V | 0x00 | input_entropy )\n         V = HMAC\
    \ ( K, V )\n         K = HMAC ( K, V | 0x01 | input_entropy )\n         V = HMAC\
    \ ( K, V )\n   Note: All SHA algorithms produce an integral number of bytes, so\
    \ the\n   lengths of K and V will be integral numbers of bytes.\n"
- title: 7.2.1.3.  Generating Random Bits
  contents:
  - "7.2.1.3.  Generating Random Bits\n   When output is called for, simply set:\n\
    \         V = HMAC ( K, V )\n   and use the leading bits from V.  If more bits\
    \ are needed than the\n   length of V, set \"temp\" to a null bit string and then\
    \ repeatedly\n   perform:\n         V = HMAC ( K, V )\n         temp = temp |\
    \ V\n   stopping as soon as temp is equal to or longer than the number of\n  \
    \ random bits requested.  Use the requested number of leading bits from\n   temp.\
    \  The definition of the algorithm prohibits requesting more than\n   2^35 bits.\n\
    \   After extracting and saving the pseudo-random output bits as\n   described\
    \ above, before returning you must also perform two more\n   HMACs as follows:\n\
    \         K = HMAC ( K, V | 0x00 )\n         V = HMAC ( K, V )\n"
- title: 7.2.2.  X9.17 Key Generation
  contents:
  - "7.2.2.  X9.17 Key Generation\n         The American National Standards Institute\
    \ has specified the\n         following method for generating a sequence of keys\
    \ [X9.17]:\n      s  is the initial 64 bit seed.\n       0\n      g  is the sequence\
    \ of generated 64-bit key quantities\n       n\n      k is a random key reserved\
    \ for generating this key sequence.\n      t is the time at which a key is generated,\
    \ to as fine a resolution\n         as is available (up to 64 bits).\n      DES\
    \ ( K, Q ) is the DES encryption of quantity Q with key K.\n   Then:\n       \
    \  g    = DES ( k, DES ( k, t ) XOR s  )\n          n                        \
    \        n\n         s    = DES ( k, DES ( k, t ) XOR  g  )\n          n+1   \
    \                            n\n   If g sub n is to be used as a DES key, then\
    \ every eighth bit should\n   be adjusted for parity for that use, but the entire\
    \ 64 bit unmodified\n   g should be used in calculating the next s.\n"
- title: 7.2.3.  DSS Pseudo-random Number Generation
  contents:
  - "7.2.3.  DSS Pseudo-random Number Generation\n   Appendix 3 of the NIST Digital\
    \ Signature Standard [DSS] provides a\n   method of producing a sequence of pseudo-random\
    \ 160 bit quantities\n   for use as private keys or the like.  This has been modified\
    \ by\n   Change Notice 1 [DSS_CN1] to produce the following algorithm for\n  \
    \ generating general-purpose pseudo-random numbers:\n         t = 0x 67452301\
    \ EFCDAB89 98BADCFE 10325476 C3D2E1F0\n         XKEY  = initial seed\n       \
    \      0\n         For j = 0 to ...\n             XVAL = ( XKEY  + optional user\
    \ input ) (Mod 2^512)\n                          j\n             X  = G( t, XVAL\
    \ )\n              j\n             XKEY   = ( 1 + XKEY  + X  ) (Mod 2^512)\n \
    \                j+1            j    j\n   The quantities X thus produced are\
    \ the pseudo-random sequence of\n   160-bit values.  Two functions can be used\
    \ for \"G\" above.  Each\n   produces a 160-bit value and takes two arguments,\
    \ a 160-bit value and\n   a 512 bit value.\n   The first is based on SHA-1 and\
    \ works by setting the 5 linking\n   variables, denoted H with subscripts in the\
    \ SHA-1 specification, to\n   the first argument divided into fifths.  Then steps\
    \ (a) through (e)\n   of section 7 of the NIST SHA-1 specification are run over\
    \ the second\n   argument as if it were a 512-bit data block.  The values of the\n\
    \   linking variable after those steps are then concatenated to produce\n   the\
    \ output of G [SHA*].\n   As an alternative method, NIST also defined an alternate\
    \ G function\n   based on multiple applications of the DES encryption function\
    \ [DSS].\n"
- title: 8.  Examples of Randomness Required
  contents:
  - "8.  Examples of Randomness Required\n   Below are two examples showing rough\
    \ calculations of randomness\n   needed for security.  The first is for moderate\
    \ security passwords,\n   while the second assumes a need for a very high-security\n\
    \   cryptographic key.\n   In addition, [ORMAN] and [RSA_BULL13] provide information\
    \ on the\n   public key lengths that should be used for exchanging symmetric keys.\n"
- title: 8.1.  Password Generation
  contents:
  - "8.1.  Password Generation\n   Assume that user passwords change once a year and\
    \ that it is desired\n   that the probability that an adversary could guess the\
    \ password for a\n   particular account be less than one in a thousand.  Further\
    \ assume\n   that sending a password to the system is the only way to try a\n\
    \   password.  Then the crucial question is how often an adversary can\n   try\
    \ possibilities.  Assume that delays have been introduced into a\n   system so\
    \ that an adversary can make at most one password try every\n   six seconds. \
    \ That's 600 per hour, or about 15,000 per day, or about\n   5,000,000 tries in\
    \ a year.  Assuming any sort of monitoring, it is\n   unlikely that someone could\
    \ actually try continuously for a year.\n   Even if log files are only checked\
    \ monthly, 500,000 tries is more\n   plausible before the attack is noticed and\
    \ steps are taken to change\n   passwords and make it harder to try more passwords.\n\
    \   To have a one-in-a-thousand chance of guessing the password in\n   500,000\
    \ tries implies a universe of at least 500,000,000 passwords,\n   or about 2^29.\
    \  Thus, 29 bits of randomness are needed.  This can\n   probably be achieved\
    \ by using the US DoD-recommended inputs for\n   password generation, as it has\
    \ 8 inputs that probably average over 5\n   bits of randomness each (see section\
    \ 7.1).  Using a list of 1,000\n   words, the password could be expressed as a\
    \ three-word phrase\n   (1,000,000,000 possibilities).  By using case-insensitive\
    \ letters and\n   digits, six characters would suffice ((26+10)^6 = 2,176,782,336\n\
    \   possibilities).\n   For a higher-security password, the number of bits required\
    \ goes up.\n   To decrease the probability by 1,000 requires increasing the universe\n\
    \   of passwords by the same factor, which adds about 10 bits.  Thus, to\n   have\
    \ only a one in a million chance of a password being guessed under\n   the above\
    \ scenario would require 39 bits of randomness and a password\n   that was a four-word\
    \ phrase from a 1,000 word list, or eight\n   letters/digits.  To go to a one-in-10^9\
    \ chance, 49 bits of randomness\n   are needed, implying a five-word phrase or\
    \ a ten-letter/digit\n   password.\n   In a real system, of course, there are\
    \ other factors.  For example,\n   the larger and harder to remember passwords\
    \ are, the more likely\n   users will bed to write them down, resulting in an\
    \ additional risk of\n   compromise.\n"
- title: 8.2.  A Very High Security Cryptographic Key
  contents:
  - "8.2.  A Very High Security Cryptographic Key\n   Assume that a very high security\
    \ key is needed for symmetric\n   encryption/decryption between two parties. \
    \ Assume also that an\n   adversary can observe communications and knows the algorithm\
    \ being\n   used.  Within the field of random possibilities, the adversary can\n\
    \   try key values in hopes of finding the one in use.  Assume further\n   that\
    \ brute force trial of keys is the best the adversary can do.\n"
- title: 8.2.1.  Effort per Key Trial
  contents:
  - "8.2.1.  Effort per Key Trial\n   How much effort will it take to try each key?\
    \  For very high-security\n   applications, it is best to assume a low value of\
    \ effort.  Even if it\n   would clearly take tens of thousands of computer cycles\
    \ or more to\n   try a single key, there may be some pattern that enables huge\
    \ blocks\n   of key values to be tested with much less effort per key.  Thus,\
    \ it\n   is probably best to assume no more than a couple of hundred cycles\n\
    \   per key.  (There is no clear lower bound on this, as computers\n   operate\
    \ in parallel on a number of bits and a poor encryption\n   algorithm could allow\
    \ many keys or even groups of keys to be tested\n   in parallel.  However, we\
    \ need to assume some value and can hope that\n   a reasonably strong algorithm\
    \ has been chosen for our hypothetical\n   high-security task.)\n   If the adversary\
    \ can command a highly parallel processor or a large\n   network of work stations,\
    \ 10^11 cycles per second is probably a\n   minimum assumption today.  Looking\
    \ forward a few years, there should\n   be at least an order of magnitude improvement.\
    \  Thus, it is\n   reasonable to assume that 10^10 keys could be checked per second,\
    \ or\n   3.6*10^12 per hour or 6*10^14 per week, or 2.4*10^15 per month.  This\n\
    \   implies a need for a minimum of 63 bits of randomness in keys, to be\n   sure\
    \ that they cannot be found in a month.  Even then it is possible\n   that, a\
    \ few years from now, a highly determined and resourceful\n   adversary could\
    \ break the key in 2 weeks; on average, they need try\n   only half the keys.\n\
    \   These questions are considered in detail in \"Minimal Key Lengths for\n  \
    \ Symmetric Ciphers to Provide Adequate Commercial Security: A Report\n   by an\
    \ Ad Hoc Group of Cryptographers and Computer Scientists\"\n   [KeyStudy] that\
    \ was sponsored by the Business Software Alliance.  It\n   concluded that a reasonable\
    \ key length in 1995 for very high security\n   is in the range of 75 to 90 bits\
    \ and, since the cost of cryptography\n   does not vary much with the key size,\
    \ it recommends 90 bits.  To\n   update these recommendations, just add 2/3 of\
    \ a bit per year for\n   Moore's law [MOORE].  This translates to a determination,\
    \ in the year\n   2004, a reasonable key length is in the 81- to 96-bit range.\
    \  In\n   fact, today, it is increasingly common to use keys longer than 96\n\
    \   bits, such as 128-bit (or longer) keys with AES and keys with\n   effective\
    \ lengths of 112-bits with triple-DES.\n"
- title: 8.2.2.  Meet-in-the-Middle Attacks
  contents:
  - "8.2.2.  Meet-in-the-Middle Attacks\n   If chosen or known plain text and the\
    \ resulting encrypted text are\n   available, a \"meet-in-the-middle\" attack\
    \ is possible if the structure\n   of the encryption algorithm allows it.  (In\
    \ a known plain text\n   attack, the adversary knows all or part (possibly some\
    \ standard\n   header or trailer fields) of the messages being encrypted.  In\
    \ a\n   chosen plain text attack, the adversary can force some chosen plain\n\
    \   text to be encrypted, possibly by \"leaking\" an exciting text that is\n \
    \  sent by the adversary over an encrypted channel because the text is\n   so\
    \ interesting.\n   The following is an oversimplified explanation of the meet-in-the-\n\
    \   middle attack:  the adversary can half-encrypt the known or chosen\n   plain\
    \ text with all possible first half-keys, sort the output, and\n   then half-decrypt\
    \ the encoded text with all the second half-keys.  If\n   a match is found, the\
    \ full key can be assembled from the halves and\n   used to decrypt other parts\
    \ of the message or other messages.  At its\n   best, this type of attack can\
    \ halve the exponent of the work required\n   by the adversary while adding a\
    \ very large but roughly constant\n   factor of effort.  Thus, if this attack\
    \ can be mounted, a doubling of\n   the amount of randomness in the very strong\
    \ key to a minimum of 192\n   bits (96*2) is required for the year 2004, based\
    \ on the [KeyStudy]\n   analysis.\n   This amount of randomness is well beyond\
    \ the limit of that in the\n   inputs recommended by the US DoD for password generation\
    \ and could\n   require user-typing timing, hardware random number generation,\
    \ or\n   other sources of randomness.\n   The meet-in-the-middle attack assumes\
    \ that the cryptographic\n   algorithm can be decomposed in this way.  Hopefully\
    \ no modern\n   algorithm has this weakness, but there may be cases where we are\
    \ not\n   sure of that or even of what algorithm a key will be used with.  Even\n\
    \   if a basic algorithm is not subject to a meet-in-the-middle attack,\n   an\
    \ attempt to produce a stronger algorithm by applying the basic\n   algorithm\
    \ twice (or two different algorithms sequentially) with\n   different keys will\
    \ gain less added security than would be expected.\n   Such a composite algorithm\
    \ would be subject to a meet-in-the-middle\n   attack.\n   Enormous resources\
    \ may be required to mount a meet-in-the-middle\n   attack, but they are probably\
    \ within the range of the national\n   security services of a major nation.  Essentially\
    \ all nations spy on\n   other nations' traffic.\n"
- title: 8.2.3.  Other Considerations
  contents:
  - "8.2.3.  Other Considerations\n   [KeyStudy] also considers the possibilities\
    \ of special-purpose code-\n   breaking hardware and having an adequate safety\
    \ margin.\n   Note that key length calculations such as those above are\n   controversial\
    \ and depend on various assumptions about the\n   cryptographic algorithms in\
    \ use.  In some cases, a professional with\n   a deep knowledge of algorithm-breaking\
    \ techniques and of the strength\n   of the algorithm in use could be satisfied\
    \ with less than half of the\n   192 bit key size derived above.\n   For further\
    \ examples of conservative design principles, see\n   [FERGUSON].\n"
- title: 9.  Conclusion
  contents:
  - "9.  Conclusion\n   Generation of unguessable \"random\" secret quantities for\
    \ security use\n   is an essential but difficult task.\n   Hardware techniques\
    \ for producing the needed entropy would be\n   relatively simple.  In particular,\
    \ the volume and quality would not\n   need to be high, and existing computer\
    \ hardware, such as audio input\n   or disk drives, can be used.\n   Widely-available\
    \ computational techniques can process low-quality\n   random quantities from\
    \ multiple sources, or a larger quantity of such\n   low-quality input from one\
    \ source, to produce a smaller quantity of\n   higher-quality keying material.\
    \  In the absence of hardware sources\n   of randomness, a variety of user and\
    \ software sources can frequently,\n   with care, be used instead.  However, most\
    \ modern systems already\n   have hardware, such as disk drives or audio input,\
    \ that could be used\n   to produce high-quality randomness.\n   Once a sufficient\
    \ quantity of high-quality seed key material (a\n   couple of hundred bits) is\
    \ available, computational techniques are\n   available to produce cryptographically-strong\
    \ sequences of\n   computationally-unpredictable quantities from this seed material.\n"
- title: 10.  Security Considerations
  contents:
  - "10.  Security Considerations\n   The entirety of this document concerns techniques\
    \ and recommendations\n   for generating unguessable \"random\" quantities for\
    \ use as passwords,\n   cryptographic keys, initialization vectors, sequence numbers,\
    \ and\n   similar security applications.\n"
- title: 11.  Acknowledgements
  contents:
  - "11.  Acknowledgements\n   Special thanks to Paul Hoffman and John Kelsey for\
    \ their extensive\n   comments and to Peter Gutmann, who has permitted the incorporation\
    \ of\n   material from his paper \"Software Generation of Practically Strong\n\
    \   Random Numbers\".\n   The following people (in alphabetic order) have contributed\n\
    \   substantially to this document:\n      Steve Bellovin, Daniel Brown, Don Davis,\
    \ Peter Gutmann, Tony\n      Hansen, Sandy Harris, Paul Hoffman, Scott Hollenback,\
    \ Russ\n      Housley, Christian Huitema, John Kelsey, Mats Naslund, and Damir\n\
    \      Rajnovic.\n   The following people (in alphabetic order) contributed to\
    \ RFC 1750,\n   the predecessor of this document:\n      David M.  Balenson, Don\
    \ T.  Davis, Carl Ellison, Marc Horowitz,\n      Christian Huitema, Charlie Kaufman,\
    \ Steve Kent, Hal Murray, Neil\n      Haller, Richard Pitkin, Tim Redmond, and\
    \ Doug Tygar.\n"
- title: 'Appendix A: Changes from RFC 1750'
  contents:
  - "Appendix A: Changes from RFC 1750\n   1. Additional acknowledgements have been\
    \ added.\n   2. Insertion of section 5.3 on mixing with S-boxes.\n   3. Addition\
    \ of section 3.3 on Ring Oscillator randomness sources.\n   4. Addition of AES\
    \ and the members of the SHA series producing more\n      than 160 bits.  Use\
    \ of AES has been emphasized and the use of DES\n      de-emphasized.\n   5. Addition\
    \ of section 6.3 on entropy pool techniques.\n   6. Addition of section 7.2.3\
    \ on the pseudo-random number generation\n      techniques given in FIPS 186-2\
    \ (with Change Notice 1), 7.2.1 on\n      those given in X9.82, section 7.1.2\
    \ on the random number\n      generation techniques of the /dev/random device\
    \ in Linux and other\n      UNIX systems, and section 7.1.3 on random number generation\n\
    \      techniques in the Windows operating system.\n   7. Addition of references\
    \ to the \"Minimal Key Lengths for Symmetric\n      Ciphers to Provide Adequate\
    \ Commercial Security\" study published\n      in January 1996 [KeyStudy] and\
    \ to [RFC1948].\n   8. Added caveats to using Diffie-Hellman as a mixing function\
    \ and,\n      because of those caveats and its computationally intensive nature,\n\
    \      recommend against its use.\n   9. Addition of references to the X9.82 effort\
    \ and the [TURBID] and\n      [NASLUND] papers.\n  10. Addition of discussion\
    \ of min-entropy and Renyi entropy and\n      references to the [LUBY] book.\n\
    \  11. Major restructuring, minor wording changes, and a variety of\n      reference\
    \ updates.\n"
- title: Informative References
  contents:
  - "Informative References\n   [AES]          \"Specification of the Advanced Encryption\
    \ Standard\n                   (AES)\", United States of America, US National\n\
    \                   Institute of Standards and Technology, FIPS 197,\n       \
    \            November 2001.\n   [ASYMMETRIC]    Simmons, G., Ed., \"Secure Communications\
    \ and\n                   Asymmetric Cryptosystems\", AAAS Selected Symposium\n\
    \                   69, ISBN 0-86531-338-5, Westview Press, 1982.\n   [BBS]  \
    \         Blum, L., Blum, M., and M. Shub, \"A Simple\n                   Unpredictable\
    \ Pseudo-Random Number Generator\", SIAM\n                   Journal on Computing,\
    \ v. 15, n. 2, 1986.\n   [BRILLINGER]    Brillinger, D., \"Time Series: Data Analysis\
    \ and\n                   Theory\", Holden-Day, 1981.\n   [CRC]           \"C.R.C.\
    \ Standard Mathematical Tables\", Chemical\n                   Rubber Publishing\
    \ Company.\n   [DAVIS]         Davis, D., Ihaka, R., and P. Fenstermacher,\n \
    \                  \"Cryptographic Randomness from Air Turbulence in Disk\n  \
    \                 Drives\", Advances in Cryptology - Crypto '94,\n           \
    \        Springer-Verlag Lecture Notes in Computer Science\n                 \
    \  #839, 1984.\n   [DES]           \"Data Encryption Standard\", US National Institute\
    \ of\n                   Standards and Technology, FIPS 46-3, October 1999.\n\
    \                   Also, \"Data Encryption Algorithm\", American National\n \
    \                  Standards Institute, ANSI X3.92-1981.  See also FIPS\n    \
    \               112, \"Password Usage\", which includes FORTRAN code\n       \
    \            for performing DES.\n   [D-H]           Rescorla, E., \"Diffie-Hellman\
    \ Key Agreement Method\",\n                   RFC 2631, June 1999.\n   [DNSSEC1]\
    \       Arends, R., Austein, R., Larson, M., Massey, D., and\n               \
    \    S. Rose, \"DNS Security Introduction and\n                   Requirements\"\
    , RFC 4033, March 2005.\n   [DNSSEC2]       Arends, R., Austein, R., Larson, M.,\
    \ Massey, D., and\n                   S. Rose, \"Resource Records for the DNS\
    \ Security\n                   Extensions\", RFC 4034, March 2005.\n   [DNSSEC3]\
    \       Arends, R., Austein, R., Larson, M., Massey, D., and\n               \
    \    S. Rose, \"Protocol Modifications for the DNS Security\n                \
    \   Extensions\", RFC 4035, March 2005.\n   [DoD]           \"Password Management\
    \ Guideline\", United States of\n                   America, Department of Defense,\
    \ Computer Security\n                   Center, CSC-STD-002-85, April 1885.\n\
    \                   (See also \"Password Usage\", FIPS 112, which\n          \
    \         incorporates CSC-STD-002-85 as one of its appendices.\n            \
    \       FIPS 112 is currently available at:\n                   http://www.idl.nist.gov/fipspubs/fip112.htm.)\n\
    \   [DSS]           \"Digital Signature Standard (DSS)\", US National\n      \
    \             Institute of Standards and Technology, FIPS 186-2,\n           \
    \        January 2000.\n   [DSS_CN1]       \"Digital Signature Standard Change\
    \ Notice 1\", US\n                   National Institute of Standards and Technology,\
    \ FIPS\n                   186-2 Change Notice 1, 5, October 2001.\n   [FERGUSON]\
    \      Ferguson, N. and B. Schneier, \"Practical\n                   Cryptography\"\
    ,  Wiley Publishing Inc., ISBN\n                   047122894X, April 2003.\n \
    \  [GIFFORD]       Gifford, D., \"Natural Random Number\", MIT/LCS/TM-371,\n \
    \                  September 1988.\n   [IEEE_802.11i]  \"Amendment to Standard\
    \ for Telecommunications and\n                   Information Exchange Between\
    \ Systems - LAN/MAN\n                   Specific Requirements - Part 11: Wireless\
    \ Medium\n                   Access Control (MAC) and physical layer (PHY)\n \
    \                  specifications: Medium Access Control (MAC) Security\n    \
    \               Enhancements\", IEEE, January 2004.\n   [IPSEC]         Kent,\
    \ S. and R. Atkinson, \"Security Architecture for\n                   the Internet\
    \ Protocol\", RFC 2401, November 1998.\n   [Jakobsson]     Jakobsson, M., Shriver,\
    \ E., Hillyer, B., and A.\n                   Juels, \"A practical secure random\
    \ bit generator\",\n                   Proceedings of the Fifth ACM Conference\
    \ on Computer\n                   and Communications Security, 1998.\n   [KAUFMAN]\
    \       Kaufman, C., Perlman, R., and M. Speciner, \"Network\n               \
    \    Security:  Private Communication in a Public World\",\n                 \
    \  Prentis Hall PTR, ISBN 0-13-046019-2, 2nd Edition\n                   2002.\n\
    \   [KeyStudy]      Blaze, M., Diffie, W., Riverst, R., Schneier, B.\n       \
    \            Shimomura, T., Thompson, E., and M.  Weiner, \"Minimal\n        \
    \           Key Lengths for Symmetric Ciphers to Provide Adequate\n          \
    \         Commercial Security: A Report by an Ad Hoc Group of\n              \
    \     Cryptographers and Computer Scientists\", January\n                   1996.\
    \  Currently available at:\n                   http://www.crypto.com/papers/keylength.txt\
    \ and\n                   http://www.securitydocs.com/library/441.\n   [KNUTH]\
    \         Knuth, D., \"The Art of Computer Programming\", Volume\n           \
    \        2:  Seminumerical Algorithms, Chapter 3: Random\n                   Numbers,\
    \ Addison-Wesley Publishing Company, 3rd\n                   Edition, November\
    \ 1997.\n   [KRAWCZYK]      Krawczyk, H., \"How to Predict Congruential\n    \
    \               Generators\", Journal of Algorithms, V. 13, N. 4,\n          \
    \         December 1992.\n   [LUBY]          Luby, M., \"Pseudorandomness and\
    \ Cryptographic\n                   Applications\", Princeton University Press,\
    \ ISBN\n                   0691025460, 8 January 1996.\n   [MAIL_PEM1]     Linn,\
    \ J., \"Privacy Enhancement for Internet\n                   Electronic Mail:\
    \ Part I: Message Encryption and\n                   Authentication Procedures\"\
    , RFC 1421, February 1993.\n   [MAIL_PEM2]     Kent, S., \"Privacy Enhancement\
    \ for Internet\n                   Electronic Mail: Part II: Certificate-Based\
    \ Key\n                   Management\", RFC 1422, February 1993.\n   [MAIL_PEM3]\
    \     Balenson, D., \"Privacy Enhancement for Internet\n                   Electronic\
    \ Mail: Part III: Algorithms, Modes, and\n                   Identifiers\", RFC\
    \ 1423, February 1993.\n   [MAIL_PEM4]     Kaliski, B., \"Privacy Enhancement\
    \ for Internet\n                   Electronic Mail: Part IV: Key Certification\
    \ and\n                   Related Services\", RFC 1424, February 1993.\n   [MAIL_PGP1]\
    \     Callas, J., Donnerhacke, L., Finney, H., and R.\n                   Thayer,\
    \ \"OpenPGP Message Format\", RFC 2440, November\n                   1998.\n \
    \  [MAIL_PGP2]     Elkins, M., Del Torto, D., Levien, R., and T.\n           \
    \        Roessler, \"MIME Security with OpenPGP\", RFC 3156,\n               \
    \    August 2001.\n   [S/MIME]        RFCs 2632 through 2634:\n              \
    \     Ramsdell, B., \"S/MIME Version 3 Certificate\n                   Handling\"\
    , RFC 2632, June 1999.\n                   Ramsdell, B., \"S/MIME Version 3 Message\n\
    \                   Specification\", RFC 2633, June 1999.\n                  \
    \ Hoffman, P., \"Enhanced Security Services for S/MIME\",\n                  \
    \ RFC 2634, June 1999.\n   [MD4]           Rivest, R., \"The MD4 Message-Digest\
    \ Algorithm\", RFC\n                   1320, April 1992.\n   [MD5]           Rivest,\
    \ R., \"The MD5 Message-Digest Algorithm \", RFC\n                   1321, April\
    \ 1992.\n   [MODES]         \"DES Modes of Operation\", US National Institute\
    \ of\n                   Standards and Technology, FIPS 81, December 1980.\n \
    \                  Also:  \"Data Encryption Algorithm - Modes of\n           \
    \        Operation\", American National Standards Institute,\n               \
    \    ANSI X3.106-1983.\n   [MOORE]         Moore's Law: the exponential increase\
    \ in the logic\n                   density of silicon circuits.  Originally formulated\n\
    \                   by Gordon Moore in 1964 as a doubling every year\n       \
    \            starting in 1962, in the late 1970s the rate fell to\n          \
    \         a doubling every 18 months and has remained there\n                \
    \   through the date of this document.  See \"The New\n                   Hacker's\
    \ Dictionary\", Third Edition, MIT Press, ISBN\n                   0-262-18178-9,\
    \ Eric S.  Raymond, 1996.\n   [NASLUND]       Naslund, M. and A. Russell, \"Extraction\
    \ of Optimally\n                   Unbiased Bits from a Biased Source\", IEEE\n\
    \                   Transactions on Information Theory. 46(3), May 2000.\n   [ORMAN]\
    \         Orman, H. and P. Hoffman, \"Determining Strengths For\n            \
    \       Public Keys Used For Exchanging Symmetric Keys\", BCP\n              \
    \     86, RFC 3766, April 2004.\n   [RFC1750]       Eastlake 3rd, D., Crocker,\
    \ S., and J. Schiller,\n                   \"Randomness Recommendations for Security\"\
    , RFC 1750,\n                   December 1994.\n   [RFC1948]       Bellovin, S.,\
    \ \"Defending Against Sequence Number\n                   Attacks\", RFC 1948,\
    \ May 1996.\n   [RFC2104]       Krawczyk, H., Bellare, M., and R. Canetti, \"\
    HMAC:\n                   Keyed-Hashing for Message Authentication\", RFC 2104,\n\
    \                   February 1997.\n   [RSA_BULL1]     \"Suggestions for Random\
    \ Number Generation in\n                   Software\", RSA Laboratories Bulletin\
    \ #1, January\n                   1996.\n   [RSA_BULL13]    Silverman, R., \"\
    A Cost-Based Security Analysis of\n                   Symmetric and Asymmetric\
    \ Key Lengths\", RSA\n                   Laboratories Bulletin #13, April 2000\
    \ (revised\n                   November 2001).\n   [SBOX1]         Mister, S.\
    \ and C. Adams, \"Practical S-box Design\",\n                   Selected Areas\
    \ in Cryptography, 1996.\n   [SBOX2]         Nyberg, K., \"Perfect Non-linear\
    \ S-boxes\", Advances in\n                   Cryptography, Eurocrypt '91 Proceedings,\
    \ Springer-\n                   Verland, 1991.\n   [SCHNEIER]      Schneier, B.,\
    \ \"Applied Cryptography: Protocols,\n                   Algorithms, and Source\
    \ Code in C\", 2nd Edition, John\n                   Wiley & Sons, 1996.\n   [SHANNON]\
    \       Shannon, C., \"The Mathematical Theory of\n                   Communication\"\
    , University of Illinois Press, 1963.\n                   Originally from:  Bell\
    \ System Technical Journal, July\n                   and October, 1948.\n   [SHIFT1]\
    \        Golub, S., \"Shift Register Sequences\", Aegean Park\n              \
    \     Press, Revised Edition, 1982.\n   [SHIFT2]        Barker, W., \"Cryptanalysis\
    \ of Shift-Register\n                   Generated Stream Cypher Systems\", Aegean\
    \ Park Press,\n                   1984.\n   [SHA]           \"Secure Hash Standard\"\
    , US National Institute of\n                   Science and Technology, FIPS 180-2,\
    \ 1 August 2002.\n   [SHA_RFC]       Eastlake 3rd, D. and P. Jones, \"US Secure\
    \ Hash\n                   Algorithm 1 (SHA1)\", RFC 3174, September 2001.\n \
    \  [SSH]           Products of the SECSH Working Group, Works in\n           \
    \        Progress, 2005.\n   [STERN]         Stern, J., \"Secret Linear Congruential\
    \ Generators are\n                   not Cryptographically Secure\", Proc. IEEE\
    \ STOC, 1987.\n   [TLS]           Dierks, T. and C. Allen, \"The TLS Protocol\
    \ Version\n                   1.0\", RFC 2246, January 1999.\n   [TURBID]    \
    \    Denker, J., \"High Entropy Symbol Generator\",\n                   <http://www.av8n.com/turbid/paper/turbid.htm>,\
    \ 2003.\n   [USENET_1]      Kantor, B. and P. Lapsley, \"Network News Transfer\n\
    \                   Protocol\", RFC 977, February 1986.\n   [USENET_2]      Barber,\
    \ S., \"Common NNTP Extensions\", RFC 2980,\n                   October 2000.\n\
    \   [VON_NEUMANN]   Von Nuemann, J., \"Various techniques used in\n          \
    \         connection with random digits\", Von Neumann's\n                   Collected\
    \ Works, Vol. 5, Pergamon Press, 1963.\n   [WSC]           Howard, M. and D. LeBlanc,\
    \ \"Writing Secure Code,\n                   Second Edition\", Microsoft Press,\
    \ ISBN 0735617228,\n                   December 2002.\n   [X9.17]         \"American\
    \ National Standard for Financial Institution\n                   Key Management\
    \ (Wholesale)\", American Bankers\n                   Association, 1985.\n   [X9.82]\
    \         \"Random Number Generation\", American National\n                  \
    \ Standards Institute, ANSI X9F1, Work in Progress.\n                      Part\
    \ 1 - Overview and General Principles.\n                      Part 2 - Non-Deterministic\
    \ Random Bit Generators\n                      Part 3 - Deterministic Random Bit\
    \ Generators\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Donald E. Eastlake 3rd\n   Motorola Laboratories\n   155\
    \ Beaver Street\n   Milford, MA 01757 USA\n   Phone: +1 508-786-7554 (w)\n   \
    \       +1 508-634-2066 (h)\n   EMail: Donald.Eastlake@motorola.com\n   Jeffrey\
    \ I. Schiller\n   MIT, Room E40-311\n   77 Massachusetts Avenue\n   Cambridge,\
    \ MA 02139-4307 USA\n   Phone: +1 617-253-0161\n   EMail: jis@mit.edu\n   Steve\
    \ Crocker\n   EMail: steve@stevecrocker.com\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2005).\n   This\
    \ document is subject to the rights, licenses and restrictions\n   contained in\
    \ BCP 78, and except as set forth therein, the authors\n   retain all their rights.\n\
    \   This document and the information contained herein are provided on an\n  \
    \ \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS\n  \
    \ OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET\n   ENGINEERING\
    \ TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED,\n   INCLUDING BUT NOT\
    \ LIMITED TO ANY WARRANTY THAT THE USE OF THE\n   INFORMATION HEREIN WILL NOT\
    \ INFRINGE ANY RIGHTS OR ANY IMPLIED\n   WARRANTIES OF MERCHANTABILITY OR FITNESS\
    \ FOR A PARTICULAR PURPOSE.\n"
- title: Intellectual Property
  contents:
  - "Intellectual Property\n   The IETF takes no position regarding the validity or\
    \ scope of any\n   Intellectual Property Rights or other rights that might be\
    \ claimed to\n   pertain to the implementation or use of the technology described\
    \ in\n   this document or the extent to which any license under such rights\n\
    \   might or might not be available; nor does it represent that it has\n   made\
    \ any independent effort to identify any such rights.  Information\n   on the\
    \ procedures with respect to rights in RFC documents can be\n   found in BCP 78\
    \ and BCP 79.\n   Copies of IPR disclosures made to the IETF Secretariat and any\n\
    \   assurances of licenses to be made available, or the result of an\n   attempt\
    \ made to obtain a general license or permission for the use of\n   such proprietary\
    \ rights by implementers or users of this\n   specification can be obtained from\
    \ the IETF on-line IPR repository at\n   http://www.ietf.org/ipr.\n   The IETF\
    \ invites any interested party to bring to its attention any\n   copyrights, patents\
    \ or patent applications, or other proprietary\n   rights that may cover technology\
    \ that may be required to implement\n   this standard.  Please address the information\
    \ to the IETF at ietf-\n   ipr@ietf.org.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
