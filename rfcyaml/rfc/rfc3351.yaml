- title: __initial_text__
  contents:
  - "      User Requirements for the Session Initiation Protocol (SIP)\n         \
    \         in Support of Deaf, Hard of Hearing\n                    and Speech-impaired\
    \ Individuals\n"
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  It does\n   not specify an Internet standard of any kind.  Distribution of\
    \ this\n   memo is unlimited.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (C) The Internet Society (2002).  All Rights Reserved.\n"
- title: Abstract
  contents:
  - "Abstract\n   This document presents a set of Session Initiation Protocol\n  \
    \ (SIP) user requirements that support communications for deaf, hard of\n   hearing\
    \ and speech-impaired individuals.  These user requirements\n   address the current\
    \ difficulties of deaf, hard of hearing and\n   speech-impaired individuals in\
    \ using communications facilities, while\n   acknowledging the multi-functional\
    \ potential of SIP-based\n   communications.\n   A number of issues related to\
    \ these user requirements are further\n   raised in this document.\n   Also included\
    \ are some real world scenarios and some technical\n   requirements to show the\
    \ robustness of these requirements on a\n   concept-level.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Terminology and Conventions Used in this Document................2\n\
    \   2. Introduction.....................................................3\n  \
    \ 3. Purpose and Scope................................................4\n   4.\
    \ Background.......................................................4\n   5. Deaf,\
    \ Hard of Hearing and Speech-impaired Requirements for SIP...5\n      5.1 Connection\
    \ without Difficulty................................5\n      5.2 User Profile.................................................6\n\
    \      5.3 Intelligent Gateways.........................................6\n  \
    \    5.4 Inclusive Design.............................................7\n    \
    \  5.5 Resource Management..........................................7\n      5.6\
    \ Confidentiality and Security.................................7\n   6. Some Real\
    \ World Scenarios........................................8\n      6.1 Transcoding\
    \ Service..........................................8\n      6.2 Media Service\
    \ Provider.......................................9\n      6.3 Sign Language Interface......................................9\n\
    \      6.4 Synthetic Lip-reading Support for Voice Calls...............10\n  \
    \    6.5 Voice-Activated Menu Systems................................10\n    \
    \  6.6 Conference Call.............................................11\n   7. Some\
    \ Suggestions for Service Providers and User Agent\n      Manufacturers...................................................13\n\
    \   8. Acknowledgements................................................14\n  \
    \    Security Considerations.........................................14\n    \
    \  Normative References............................................15\n      Informational\
    \ References........................................15\n      Author's Addresses..............................................15\n\
    \      Full Copyright Statement........................................17\n"
- title: 1. Terminology and Conventions Used in this Document
  contents:
  - "1. Terminology and Conventions Used in this Document\n   In this document, the\
    \ key words \"MUST\", \"MUST NOT\",\"REQUIRED\",\n   \"SHALL\", \"SHALL NOT\"\
    , \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\",\n   and \"OPTIONAL\" are\
    \ to be interpreted as described in BCP 14,\n   RFC2119[1] and indicate requirement\
    \ levels for compliant SIP\n   implementations.\n   For the purposes of this document,\
    \ the following terms are considered\n   to have these meanings:\n   Abilities:\
    \  A person's capacity for communicating which could include\n   a hearing or\
    \ speech impairment or not.  The terms Abilities and\n   Preferences apply to\
    \ both caller and call-recipient.\n   Preferences:  A person's choice of communication\
    \ mode.  This could\n   include any combination of media streams, e.g., text,\
    \ audio, video.\n   The terms Abilities and Preferences apply to both caller and\n\
    \   call-recipient.\n   Relay Service:  A third-party or intermediary that enables\n\
    \   communications between deaf, hard of hearing and speech-impaired\n   people,\
    \ and people without hearing or speech-impairment.  Relay\n   Services form a\
    \ subset of the activities of Transcoding Services (see\n   definition).\n   Transcoding\
    \ Services:  A human or automated third party acting as an\n   intermediary in\
    \ any session between two other User Agents (being a\n   User Agent itself), and\
    \ transcoding one stream into another (e.g.,\n   voice to text or vice versa).\n\
    \   Textphone:  Sometimes called a TTY (teletypewriter), TDD\n   (telecommunications\
    \ device for the deaf) or a minicom, a textphone\n   enables a deaf, hard of hearing\
    \ or speech-impaired person to place a\n   call to a telephone or another textphone.\
    \  Some textphones use the\n   V.18[3] protocol as a standard for communication\
    \ with other textphone\n   communication protocols world-wide.\n   User:  A deaf,\
    \ hard of hearing or speech-impaired individual.  A user\n   is otherwise referred\
    \ to as a person or individual, and users are\n   referred to as people.\n   Note:\
    \  For the purposes of this document, a deaf, hard of hearing, or\n   speech-impaired\
    \ person is an individual who chooses to use SIP\n   because it can minimize or\
    \ eliminate constraints in using common\n   communication devices.  As SIP promises\
    \ a total communication\n   solution for any kind of person, regardless of ability\
    \ and\n   preference, there is no attempt to specifically define deaf, hard of\n\
    \   hearing or speech-impaired in this document.\n"
- title: 2. Introduction
  contents:
  - "2. Introduction\n   The background for this document is the recent development\
    \ of SIP[2]\n   and SIP-based communications, and a growing awareness of deaf,\
    \ hard\n   of hearing and speech-impaired issues in the technical community.\n\
    \   The SIP capacity to simplify setting up, managing and tearing down\n   communication\
    \ sessions between all kinds of User Agents has specific\n   implications for\
    \ deaf, hard of hearing and speech-impaired\n   individuals.\n   As SIP enables\
    \ multiple sessions with translation between multiple\n   types of media, these\
    \ requirements aim to provide the standard for\n   recognizing and enabling these\
    \ interactions, and for a communications\n   model that includes any and all types\
    \ of SIP-networking abilities and\n   preferences.\n"
- title: 3. Purpose and Scope
  contents:
  - "3. Purpose and Scope\n   The scope of this document is firstly to present a current\
    \ set of\n   user requirements for deaf, hard of hearing and speech-impaired\n\
    \   individuals through SIP-enabled communications.  These are then\n   followed\
    \ by some real world scenarios in SIP-communications that\n   could be used in\
    \ a test environment, and some concepts of how these\n   requirements can be developed\
    \ by service providers and User Agent\n   manufacturers.\n   These recommendations\
    \ make explicit the needs of a currently often\n   disadvantaged user-group and\
    \ attempt to match them with the capacity\n   of SIP.  It is not the intention\
    \ here to prioritize the needs of\n   deaf, hard of hearing and speech-impaired\
    \ people in a way that would\n   penalize other individuals.\n   These requirements\
    \ aim to encourage developers and manufacturers\n   world-wide to consider the\
    \ specific needs of deaf, hard of hearing\n   and speech-impaired individuals.\
    \  This document presents a\n   world-vision where deafness, hard of hearing or\
    \ speech impairment are\n   no longer a barrier to communication.\n"
- title: 4. Background
  contents:
  - "4. Background\n   Deaf, hard of hearing and speech-impaired people are currently\n\
    \   often unable to use commonly available communication devices.\n   Although\
    \ this is documented[4], this does not mean that developers or\n   manufacturers\
    \ are always aware of this.  Communication devices for\n   deaf, hard of hearing\
    \ and speech-impaired people are\n   currently often primitive in design, expensive,\
    \ and non-compatible\n   with progressively designed, cheaper and more adaptable\
    \ communication\n   devices for other individuals.  For example, many models of\
    \ textphone\n   are unable to communicate with other models.\n   Additionally,\
    \ non-technical human communications, for example sign\n   languages or lip-reading,\
    \ are non-standard around the world.\n   There are intermediary or third-party\
    \ relay services (e.g.\n   transcoding services) that facilitate communications,\
    \ uni- or bi-\n   directional, for deaf, hard of hearing and speech-impaired people.\n\
    \   Currently relay services are mostly operator-assisted (manual),\n   although\
    \ methods of partial automation are being implemented in some\n   areas.  These\
    \ services enable full access to modern facilities and\n   conveniences for deaf,\
    \ hard of hearing and speech-impaired people.\n   Although these services are\
    \ somewhat limited, their value is\n   undeniable as compared to their previous\
    \ complete unavailability.\n   Yet communication methods in recent decades have\
    \ proliferated:\n   email, mobile phones, video streaming, etc.  These methods\
    \ are an\n   advance in the development of data transfer technologies between\n\
    \   devices.\n   Developers and advocates of SIP agree that it is a protocol that\
    \ not\n   only anticipates the growth in real-time communications between\n  \
    \ convergent networks, but also fulfills the potential of the Internet\n   as\
    \ a communications and information forum.  Further, they agree that\n   these\
    \ developments allow a standard of communication that can be\n   applied throughout\
    \ all networking communities, regardless of\n   abilities and preferences.\n"
- title: 5. Deaf, Hard of Hearing and Speech-impaired Requirements for SIP
  contents:
  - "5. Deaf, Hard of Hearing and Speech-impaired Requirements for SIP\n   Introduction\n\
    \   The user requirements in this section are provided for the benefit of\n  \
    \ service providers, User Agent manufacturers and any other interested\n   parties\
    \ in the development of products and services for deaf, hard of\n   hearing and\
    \ speech-impaired people.\n   The user requirements are as follows:\n"
- title: 5.1 Connection without Difficulty
  contents:
  - "5.1 Connection without Difficulty\n   This requirement states:\n   Whatever the\
    \ preferences and abilities of the user and User Agent,\n   there SHOULD be no\
    \ difficulty in setting up SIP sessions.  These\n   sessions could include multiple\
    \ proxies, call routing decisions,\n   transcoding services, e.g., the relay service\
    \ Typetalk[5] or other\n   media processing, and could include multiple simultaneous\
    \ or\n   alternative media streams.\n   This means that any User Agent in the\
    \ conversation (including\n   transcoding services) MUST be able to add or remove\
    \ a media stream\n   from the call without having to tear it down and re-establish\
    \ it.\n"
- title: 5.2 User Profile
  contents:
  - "5.2 User Profile\n   This requirement states:\n   Deaf, hard of hearing and speech-impaired\
    \ user abilities and\n   preferences (i.e., user profile) MUST be communicable\
    \ by SIP, and\n   these abilities and preferences MUST determine the handling\
    \ of the\n   session.\n   The User Profile for a deaf, hard of hearing or speech-impaired\n\
    \   person might include details about:\n   - How media streams are received and\
    \ transmitted (text, voice, video,\n     or any combination, uni- or bi-directional).\n\
    \   - Redirecting specific media streams through a transcoding service\n     (e.g.,\
    \ the relay service Typetalk)\n   - Roaming (e.g., a deaf person accessing their\
    \ User Profile from a\n     web-interface at an Internet cafe)\n   - Anonymity:\
    \ i.e., not revealing that a deaf person is calling, even\n     through a transcoding\
    \ service (e.g., some relay services inform the\n     call-recipient that there\
    \ is an incoming text call without saying\n     that a deaf person is calling).\n\
    \     Part of this requirement is to ensure that deaf, hard of hearing\n     and\
    \ speech-impaired people can keep their preferences and abilities\n     confidential\
    \ from others, to avoid possible discrimination or\n     prejudice, while still\
    \ being able to establish a SIP session.\n"
- title: 5.3 Intelligent Gateways
  contents:
  - "5.3 Intelligent Gateways\n   This requirement states:\n   SIP SHOULD support\
    \ a class of User Agents to perform as gateways for\n   legacy systems designed\
    \ for deaf, hard of hearing and speech-impaired\n   people.\n   For example, an\
    \ individual could have a SIP User Agent acting as a\n   gateway to a PSTN legacy\
    \ textphone.\n"
- title: 5.4 Inclusive Design
  contents:
  - "5.4 Inclusive Design\n   This requirement states:\n   Where applicable, design\
    \ concepts for communications (devices,\n   applications, etc.) MUST include the\
    \ abilities and preferences of\n   deaf, hard of hearing and speech-impaired people.\n\
    \   Transcoding services and User Agents MUST be able to connect with\n   each\
    \ other regardless of the provider or manufacturer.  This means\n   that new User\
    \ Agents MUST be able to support legacy protocols through\n   appropriate gateways.\n"
- title: 5.5 Resource Management
  contents:
  - "5.5 Resource Management\n   This requirement states:\n   User Agents SHOULD be\
    \ able to identify the content of a media stream\n   in order to obtain such information\
    \ as the cost of the media stream,\n   if a transcoding service can support it,\
    \ etc.\n   User Agents SHOULD be able to choose among transcoding services and\n\
    \   similar services based on their capabilities (e.g., whether a\n   transcoding\
    \ service carries a particular media stream), and any\n   policy constraints they\
    \ impose (e.g., charging for use).  It SHOULD\n   be possible for User Agents\
    \ to discover the availability of\n   alternative media streams and to choose\
    \ from them.\n"
- title: 5.6 Confidentiality and Security
  contents:
  - "5.6 Confidentiality and Security\n   This requirement states:\n   All third-party\
    \ or intermediaries (transcoding services) employed in\n   a session for deaf,\
    \ hard of hearing and speech-impaired people MUST\n   offer a confidentiality\
    \ policy.  All information exchanged in this\n   type of session SHOULD be secure,\
    \ that is, erased before\n   confidentiality is breached, unless otherwise required.\n\
    \   This means that transcoding services (e.g., interpretation,\n   translation)\
    \ MUST publish their confidentiality and security\n   policies.\n"
- title: 6. Some Real World Scenarios
  contents:
  - "6. Some Real World Scenarios\n   These scenarios are intended to show some of\
    \ the various types of\n   media streams that would be initiated, managed, directed,\
    \ and\n   terminated in a SIP-enabled network, and shows how some resources\n\
    \   might be managed between SIP-enabled networks, transcoding services\n   and\
    \ service providers.\n   To illustrate the communications dynamic of these kinds\
    \ of scenarios,\n   each one specifically mentions the kind of media streams transmitted,\n\
    \   and whether User Agents and Transcoding Services are involved.\n"
- title: 6.1 Transcoding Service
  contents:
  - "6.1 Transcoding Service\n   In this scenario, a hearing person calls the household\
    \ of a deaf\n   person and a hearing person.\n   1. A voice conversation is initiated\
    \ between the hearing\n      participants:\n      ( Person A) <-----Voice --->\
    \ ( Person B)\n   2. During the conversation, the hearing person asks to talk\
    \ with the\n      deaf person, while keeping the voice connection open so that\
    \ voice\n      to voice communications can continue if required.\n   3. A Relay\
    \ Service is invited into the conversation.\n   4. The Relay Service transcodes\
    \ the hearing person's words into text.\n   5. Text from the hearing person's\
    \ voice appears on the display of the\n      deaf person's User Agent.\n   6.\
    \ The deaf person types a response.\n   7. The Relay Service receives the text\
    \ and reads it to the hearing\n      person:\n      (         ) <------------------Voice---------------->\
    \ (         )\n      (Person A ) -----Voice---> ( Voice To Text  ) -Text-> (Person\
    \ B )\n      (         ) <----Voice---- (Service Provider) <-Text- (         )\n\
    \   8. The hearing person asks to talk with the hearing person in the\n      deaf\
    \ person's household.\n   9. The Relay Service withdraws from the call.\n"
- title: 6.2 Media Service Provider
  contents:
  - "6.2 Media Service Provider\n   In this scenario, a deaf person wishes to receive\
    \ the content of a\n   radio program through a text stream transcoded from the\
    \ program's\n   audio stream.\n   1. The deaf person attempts to establish a connection\
    \ to the radio\n      broadcast, with User Agent preferences set to receiving\
    \ audio\n      stream as text.\n   2. The User Agent of the deaf person queries\
    \ the radio station User\n      Agent on whether a text stream is available, other\
    \ than the audio\n      stream.\n   3. However, the radio station has no text\
    \ stream available for a deaf\n      listener, and responds in the negative.\n\
    \   4. As no text stream is available, the deaf person's User Agent\n      requests\
    \ a voice-to-text transcoding service (e.g., a real-time\n      captioning service)\
    \ to come into the conversation space.\n   5. The transcoding service User Agent\
    \ identifies the audio stream as\n      a radio broadcast.  However, the policy\
    \ of the transcoding service\n      is that it does not accept radio broadcasts\
    \ because it would\n      overload their resources far too quickly.\n   6. In\
    \ this case, the connection fails.\n   Alternatively, continuing from 2 above:\n\
    \   3. The radio station does provide text with their audio streams.\n   4. The\
    \ deaf person receives a text stream of the radio program.\n   Note:  To support\
    \ deaf, hard of hearing and speech-impaired people,\n   service providers are\
    \ encouraged to provide text with audio streams.\n"
- title: 6.3 Sign Language Interface
  contents:
  - "6.3 Sign Language Interface\n   In this scenario, a deaf person enables a signing\
    \ avatar (e.g.,\n   ViSiCAST[6]) by setting up a User Agent to receive audio streams\
    \ as\n   XML data that will operate an avatar for sign-language.  For outgoing\n\
    \   communications, the deaf person types text that is transcoded into an\n  \
    \ audio stream for the other conversation participant.\n"
- title: 'For example:'
  contents:
  - 'For example:

    '
- title: (         )-Voice->(Voice To Avatar Commands) ----XMLData-->(        )
  contents:
  - '(         )-Voice->(Voice To Avatar Commands) ----XMLData-->(        )

    '
- title: ( hearing )                                                 (deaf    )
  contents:
  - '( hearing )                                                 (deaf    )

    '
- title: ( Person A)<-Voice-( Text To Voice  ) <--------Text-------- (Person B)
  contents:
  - '( Person A)<-Voice-( Text To Voice  ) <--------Text-------- (Person B)

    '
- title: (         )        (Service Provider)                       (        )
  contents:
  - '(         )        (Service Provider)                       (        )

    '
- title: 6.4 Synthetic Lip-speaking Support for Voice Calls
  contents:
  - "6.4 Synthetic Lip-speaking Support for Voice Calls\n   In order to receive voice\
    \ calls, a hard of hearing person uses lip-\n   speaking avatar software (e.g.,\
    \ Synface[7]) on a PC.  The lip-\n   speaking software processes voice (audio)\
    \ stream data and displays a\n   synthetic animated face that a hard of hearing\
    \ person may be able to\n   lip-read.  During a conversation, the hard of hearing\
    \ person uses the\n   lip-speaking software as support for understanding the audio\
    \ stream.\n   For example:\n      (         ) <------------------Voice-------------->(\
    \         )\n      ( hearing )                    ( PC with     )     ( hard of\
    \ )\n      ( Person A) -------Voice-----> ( lip-speaking)---->( hearing )\n  \
    \    (         )                    ( software    )     ( Person B)\n"
- title: 6.5 Voice Activated Menu Systems
  contents:
  - "6.5 Voice Activated Menu Systems\n   In this scenario, a deaf person wishing\
    \ to book cinema tickets with a\n   credit card, uses a textphone to place the\
    \ call.  The cinema employs\n   a voice-activated menu system for film titles\
    \ and showing times.\n   1. The deaf person places a call to the cinema with a\
    \ textphone:\n         (Textphone) <-----Text ---> (Voice-activated System)\n\
    \   2. The cinema's voice-activated menu requests an auditory response to\n  \
    \    continue.\n   3. A Relay Service is invited into the conversation.\n   4.\
    \ The Relay Service transcodes the prompts of the voice-activated\n      menu\
    \ into text.\n   5. Text from the voice-activated menu appears on the display\
    \ of the\n      deaf person's textphone.\n   6. The deaf person types a response.\n\
    \   7. The Relay Service receives the text and reads it to the voice-\n      activated\
    \ system:\n   (           )         (Relay Service   )          (            \
    \   )\n   ( deaf      ) -Text-> (Provider        ) -Voice-> (Voice-Activated)\n\
    \   ( Person A  ) <-Text- (Text To Voice   ) <-Voice- (System         )\n   8.\
    \ The transaction is finalized with a confirmed booking time.\n   9. The Relay\
    \ Service withdraws from the call.\n"
- title: 6.6 Conference Call
  contents:
  - "6.6 Conference Call\n   A conference call is scheduled between five people:\n\
    \   - Person A listens and types text (hearing, no speech)\n   - Person B recognizes\
    \ sign language and signs back (deaf, no speech)\n   - Person C reads text and\
    \ speaks (deaf or hearing impaired)\n   - Person D listens and speaks\n   - Person\
    \ E recognizes sign language and reads text and signs\n   A conference call server\
    \ calls the five people and based on their\n   preferences sets up the different\
    \ transcoding services required.\n   Assuming English is the base language for\
    \ the call, the following\n   intermediate transcoding services are invoked:\n\
    \   - A transcoding service (English speech to English text)\n   - An English\
    \ text to sign language service\n   - A sign language to English text service\n\
    \   - An English text to English speech service\n   Note:  In order to translate\
    \ from English speech to sign language, a\n   chain of intermediate transcoding\
    \ services was used (transcoding and\n   English text to sign language) because\
    \ there was no speech-to-sign\n   language available for direct translation. \
    \ Accordingly, the same\n   applied for the translation from sign language to\
    \ English speech.\n"
- title: (Person A) ----- Text ----> (  Text-to-SL  ) --- Video ----> (Person B)
  contents:
  - "(Person A) ----- Text ----> (  Text-to-SL  ) --- Video ----> (Person B)\n   \
    \        ---------------------- Text --------------------> (Person C)\n      \
    \     ----- Text ----> (Text-to-Speech) --- Voice ----> (Person D)\n         \
    \  ---------------------- Text --------------------> (Person E)\n           -----\
    \ Text ----> (  Text-to-SL  ) --- Video ----> (Person E)\n"
- title: (Person B) -Video-> (SL-to-Text) -Text-> (Text-to-Speech) -> (Person A)
  contents:
  - "(Person B) -Video-> (SL-to-Text) -Text-> (Text-to-Speech) -> (Person A)\n   \
    \        ---- Video ----> (  SL-to-Text  ) ---- Text ----> (Person C)\n      \
    \     -Video-> (SL-to-Text) -Text-> (Text-to-Speech) -> (Person D)\n         \
    \  --------------------- Video --------------------> (Person E)\n           ----\
    \ Video ----> (  SL-to-Text  ) ---- Text ----> (Person E)\n"
- title: (Person C) --------------------- Voice --------------------> (Person A)
  contents:
  - "(Person C) --------------------- Voice --------------------> (Person A)\n   \
    \        Voice->(Speech-to-Text)-Text->(Text-to-SL)-Video->(Person B)\n      \
    \     --------------------- Voice --------------------> (Person D)\n         \
    \  ---- Voice ----> (Speech-to-Text) ---- Text ----> (Person E)\n           Voice->(Speech-to-Text)-Text->(Text-to-SL)-Video->(Person\
    \ E)\n"
- title: (Person D) --------------------- Voice --------------------> (Person A)
  contents:
  - "(Person D) --------------------- Voice --------------------> (Person A)\n   \
    \        Voice->(Speech-to-Text)-Text->(Text-to-SL)-Video->(Person B)\n      \
    \     ---- Voice ----> (Speech-to-Text) ---- Text ----> (Person C)\n         \
    \  ---- Voice ----> (Speech-to-Text) ---- Text ----> (Person E)\n           Voice->(Speech-to-Text)-Text->(Text-to-SL)-Video->(Person\
    \ E)\n"
- title: (Person E) -Video-> (SL-to-Text) -Text-> (Text-to-Speech) -> (Person A)
  contents:
  - "(Person E) -Video-> (SL-to-Text) -Text-> (Text-to-Speech) -> (Person A)\n   \
    \        --------------------- Video --------------------> (person B)\n      \
    \     ---- Video ----> (  SL-to-Text  ) ---- Text ----> (Person C)\n         \
    \  -Video-> (SL-to-Text) -Text-> (Text-to-Speech) -> (Person D)\n   Remarks: -\
    \ Some services might be shared by users and/or other\n              services.\n\
    \            - Person E uses two parallel streams (SL and English Text).\n   \
    \           The User Agent might perform time synchronisation when\n         \
    \     displaying the streams.  However, this would require\n              synchronisation\
    \ information to be present on the streams.\n            - The session protocols\
    \ might support optional buffering of\n              media streams, so that users\
    \ and/or intermediate services\n              could go back to previous content\
    \ or to invoke a\n              transcoding service for content they just missed.\n\
    \            - Hearing impaired users might still receive audio as well,\n   \
    \           which they will use to drive some visual indicators so\n         \
    \     that they can better see where, for instance, the pauses\n             \
    \ are in the conversation.\n"
- title: 7. Some Suggestions for Service Providers and User Agent Manufacturers
  contents:
  - "7. Some Suggestions for Service Providers and User Agent Manufacturers\n   This\
    \ section is included to encourage service providers and user\n   agent manufacturers\
    \ in developing products and services that can be\n   used by as wide a range\
    \ of individuals as possible, including deaf,\n   hard of hearing and speech-impaired\
    \ people.\n   - Service providers and User Agent manufacturers can offer to a\
    \ deaf,\n     hard of hearing and speech-impaired person the possibility of being\n\
    \     able to prevent their specific abilities and preferences from being\n  \
    \   made public in any transaction.\n   - If a User Agent performs auditory signalling,\
    \ for example a pager,\n     it could also provide another signalling method;\
    \ visual (e.g., a\n     flashing light) or tactile (e.g., vibration).\n   - Service\
    \ providers who allow the user to store specific abilities\n     and preferences\
    \ or settings (i.e., a user profile) might consider\n     storing these settings\
    \ in a central repository, accessible no\n     matter what the location of the\
    \ user and regardless of the User\n     Agent used at that time or location.\n\
    \   - If there are several transcoding services available, the User Agent\n  \
    \   can be set to select the most economical/highest quality service.\n   - The\
    \ service provider can show the cost per minute and any minimum\n     charge of\
    \ a transcoding service call before a session starts,\n     allowing the user\
    \ a choice of engaging in the service or not.\n   - Service providers are encouraged\
    \ to offer an alternative stream to\n     an audio stream, for example, text or\
    \ data streams that operate\n     avatars, etc.\n   - Service providers are encouraged\
    \ to provide a text alternative to\n     voice-activated menus, e.g., answering\
    \ and voice mail systems.\n   - Manufacturers of voice-activated software are\
    \ encouraged to provide\n     an alternative visual format for software prompts,\
    \ menus, messages,\n     and status information.\n   - Manufacturers of mobile\
    \ phones are encouraged to design equipment\n     that avoids electro-magnetic\
    \ interference with hearing aids.\n   - All services for interpreting, transliterating,\
    \ or facilitating\n     communications for deaf, hard of hearing and speech-impaired\
    \ people\n     are required to:\n     - Keep information exchanged during the\
    \ transaction strictly\n       confidential\n     - Enable information exchange\
    \ literally and simply, without\n       deviating and compromising the content\n\
    \     - Facilitate communication without bias, prejudice or opinion\n     - Match\
    \ skill-sets to the requirements of the users of the service\n     - Behave in\
    \ a professional and appropriate manner\n     - Be fair in pricing of services\n\
    \     - Strive to improve the skill-sets used for their services.\n   - Conference\
    \ call services might consider ways to allow users who\n     employ transcoding\
    \ services (which usually introduce a delay) to\n     have real-time information\
    \ sufficient to be able to identify gaps\n     in the conversation so they could\
    \ inject comments, as well as ways\n     to raise their hand, vote and carry out\
    \ other activities where\n     timing of their response relative to the real-time\
    \ conversation is\n     important.\n"
- title: 8. Acknowledgements
  contents:
  - "8. Acknowledgements\n   The authors would like to thank the following individuals\
    \ for their\n   contributions to this document:\n   David R. Oran, Cisco\n   Mark\
    \ Watson, Nortel Networks\n   Brian Grover, RNID\n   Anthony Rabin, RNID\n   Michael\
    \ Hammer, Cisco\n   Henry Sinnreich, Worldcom\n   Rohan Mahy, Cisco\n   Julian\
    \ Branston, Cedalion Hosting Services\n   Judy Harkins, Gallaudet University,\
    \ Washington, D.C.\n   Cary Barbin, Gallaudet University, Washington, D.C.\n \
    \  Gregg Vanderheiden, Trace R&D Center University of Wisconsin-Madison\n   Gottfried\
    \ Zimmerman, Trace R&D Center University of Wisconsin-Madison\n"
- title: Security Considerations
  contents:
  - "Security Considerations\n   This document presents some privacy and security\
    \ considerations.\n   They are treated in Section 5.6 Confidentiality and Security.\n"
- title: Normative References
  contents:
  - "Normative References\n   [1] Bradner, S., \"Key words for use in RFCs to Indicate\
    \ Requirement\n       Levels\", BCP 14, RFC 2119, March 1997.\n   [2] Rosenberg,\
    \ J., Schulzrinne, H., Camarillo, G., Johnston, A.,\n       Peterson, J., Sparks,\
    \ R., Handley, M. and E. Schooler, \"SIP:\n       Session Initiation Protocol\"\
    , RFC 3261, June 2002.\n"
- title: Informational References
  contents:
  - "Informational References\n   [3] International Telecommunication Union (ITU),\
    \ \"Operational and\n       interworking requirements for DCEs operating in the\
    \ text\n       telephone mode\". ITU-T Recommendation V.18, November 2000.\n \
    \  [4] Moore, Matthew, et al. \"For Hearing People Only: Answers to Some\n   \
    \    of the Most Commonly Asked Questions About the Deaf Community,\n       Its\
    \ Culture, and the Deaf Reality\". MSM Productions Ltd., 2nd\n       Edition,\
    \ September 1993.\n   [5] http://www.typetalk.org.\n   [6] http://www.visicast.co.uk.\n\
    \   [7] http://www.speech.kth.se/teleface.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Nathan Charlton\n   Millpark Limited\n   52 Coborn Road\n\
    \   London E3 2DG\n   Tel: +44-7050 803628\n   Fax: +44-7050 803628\n   EMail:\
    \ nathan@millpark.com\n   Mick Gasson\n   Koru Solutions\n   30 Howland Way\n\
    \   London SE16 6HN\n   Tel: +44-20 7237 3488\n   Fax: +44-20 7237 3488\n   EMail:\
    \ michael.gasson@korusolutions.com\n   Guido Gybels\n   RNID\n   19-23 Featherstone\
    \ Street\n   London EC1Y 8SL\n   Tel: +44-20 7296 8000\n   Textphone: +44-20 7296\
    \ 8001\n   Fax: +44-20 7296 8199\n   EMail: Guido.Gybels@rnid.org.uk\n   Mike\
    \ Spanner\n   RNID\n   19-23 Featherstone Street\n   London EC1Y 8SL\n   Tel:\
    \ +44-20 7296 8000\n   Textphone: +44-20 7296 8001\n   Fax: +44-20 7296 8199\n\
    \   EMail: mike.spanner@rnid.org.uk\n   Arnoud van Wijk\n   Ericsson EuroLab Netherlands\
    \ BV\n   P.O. Box 8\n   5120 AA Rijen\n   The Netherlands\n   Fax: +31-161-247569\n\
    \   EMail: Arnoud.van.Wijk@eln.ericsson.se\n   Comments can be sent to the SIPPING\
    \ mailing list.\n"
- title: Full Copyright Statement
  contents:
  - "Full Copyright Statement\n   Copyright (C) The Internet Society (2002).  All\
    \ Rights Reserved.\n   This document and translations of it may be copied and\
    \ furnished to\n   others, and derivative works that comment on or otherwise explain\
    \ it\n   or assist in its implementation may be prepared, copied, published\n\
    \   and distributed, in whole or in part, without restriction of any\n   kind,\
    \ provided that the above copyright notice and this paragraph are\n   included\
    \ on all such copies and derivative works.  However, this\n   document itself\
    \ may not be modified in any way, such as by removing\n   the copyright notice\
    \ or references to the Internet Society or other\n   Internet organizations, except\
    \ as needed for the purpose of\n   developing Internet standards in which case\
    \ the procedures for\n   copyrights defined in the Internet Standards process\
    \ must be\n   followed, or as required to translate it into languages other than\n\
    \   English.\n   The limited permissions granted above are perpetual and will\
    \ not be\n   revoked by the Internet Society or its successors or assigns.\n \
    \  This document and the information contained herein is provided on an\n   \"\
    AS IS\" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING\n   TASK FORCE\
    \ DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING\n   BUT NOT LIMITED\
    \ TO ANY WARRANTY THAT THE USE OF THE INFORMATION\n   HEREIN WILL NOT INFRINGE\
    \ ANY RIGHTS OR ANY IMPLIED WARRANTIES OF\n   MERCHANTABILITY OR FITNESS FOR A\
    \ PARTICULAR PURPOSE.\n"
- title: Acknowledgement
  contents:
  - "Acknowledgement\n   Funding for the RFC Editor function is currently provided\
    \ by the\n   Internet Society.\n"
