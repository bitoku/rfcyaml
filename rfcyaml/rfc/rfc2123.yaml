- title: __initial_text__
  contents:
  - '          Traffic Flow Measurement:  Experiences with NeTraMet

    '
- title: Status of this Memo
  contents:
  - "Status of this Memo\n   This memo provides information for the Internet community.\
    \  This memo\n   does not specify an Internet standard of any kind.  Distribution\
    \ of\n   this memo is unlimited.\n"
- title: Abstract
  contents:
  - "Abstract\n   This memo records experiences in implementing and using the Traffic\n\
    \   Flow Measurement Architecture and Meter MIB. It discusses the\n   implementation\
    \ of NeTraMet (a traffic meter) and NeMaC (a combined\n   manager and meter reader),\
    \ considers the writing of meter rule sets\n   and gives some guidance on setting\
    \ up a traffic flow measurement\n   system using NeTraMet.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n 1 Introduction                                          \
    \              2\n   1.1 NeTraMet structure and development . . . . . . . . .\
    \ . . . . .  3\n   1.2 Scope of this document . . . . . . . . . . . . . . . .\
    \ . . . .  4\n 2 Implementation                                              \
    \        4\n   2.1 Choice of meter platform . . . . . . . . . . . . . . . . .\
    \ . .  4\n   2.2 Programming support requirements . . . . . . . . . . . . . .\
    \ .  5\n     2.2.1 DOS environment  . . . . . . . . . . . . . . . . . . . . .\
    \  6\n     2.2.2 Unix environment . . . . . . . . . . . . . . . . . . . . .  7\n\
    \   2.3 Implementing the meter . . . . . . . . . . . . . . . . . . . .  7\n  \
    \   2.3.1 Data structures  . . . . . . . . . . . . . . . . . . . . .  7\n    \
    \ 2.3.2 Packet matching  . . . . . . . . . . . . . . . . . . . . .  8\n     2.3.3\
    \ Testing groups of rule addresses . . . . . . . . . . . . .  8\n     2.3.4 Compression\
    \ of address masks . . . . . . . . . . . . . . .  9\n     2.3.5 Ignoring unwanted\
    \ flow data  . . . . . . . . . . . . . . . 10\n     2.3.6 Observing meter reader\
    \ activity  . . . . . . . . . . . . . 11\n     2.3.7 Meter memory management \
    \ . . . . . . . . . . . . . . . . . 12\n   2.4 Data collection  . . . . . . .\
    \ . . . . . . . . . . . . . . . . 14\n   2.5 Restarting a meter . . . . . . .\
    \ . . . . . . . . . . . . . . . 15\n   2.6 Performance  . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . 16\n 3 Writing rule sets                       \
    \                           16\n   3.1 Rule set to observe all flows  . . . .\
    \ . . . . . . . . . . . . 17\n   3.2 Specifying flow direction, using computed\
    \ attributes . . . . . 18\n   3.3 Subroutines  . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . 21\n   3.4 More complicated rule sets . . . . . . . . . .\
    \ . . . . . . . . 23\n 4 Flow data files                                     \
    \               26\n   4.1 Sample flow data file  . . . . . . . . . . . . . .\
    \ . . . . . . 27\n   4.2 Flow data file features  . . . . . . . . . . . . . .\
    \ . . . . . 28\n   4.3 Terminating and restarting meter reading . . . . . . .\
    \ . . . . 29\n 5 Analysis applications                                       \
    \       30\n 6 Using NeTraMet in a measurement system                        \
    \     31\n   6.1 Examples of NeTraMet in production use . . . . . . . . . . .\
    \ . 31\n 7 Acknowledgments                                                   \
    \ 33\n 8 References                                                         33\n\
    \ 9 Security Considerations                                            34\n"
- title: 10 Author's Address                                                   34
  contents:
  - '10 Author''s Address                                                   34

    '
- title: 1 Introduction
  contents:
  - "1 Introduction\n   Early in 1992 my University needed to develop a system for\
    \ recovering\n   the costs of its Internet traffic.  In March of that year I attended\n\
    \   the Internet Accounting Working Group's session at the San Diego\n   IETF,\
    \ where I was delighted to find that the Group had produced a\n   detailed architecture\
    \ for measuring network traffic and were waiting\n   for someone to try implementing\
    \ it.\n   During 1992 I produced a prototype measurement system, using balanced\n\
    \   binary trees to store information about traffic flows.  This work was\n  \
    \ reported at the Washington IETF in November 1992.  The prototype\n   performed\
    \ well, but it made no attempt to recover memory from old\n   flows, and the overheads\
    \ in managing the balanced trees proved to be\n   unacceptably high.  I moved\
    \ on to develop a production-quality\n   system, this time using hash tables to\
    \ index the flow information.\n   This version was called NeTraMet (the Network\
    \ Traffic Meter), and was\n   released as free software in October 1993.  Since\
    \ then I have\n   continued working on NeTraMet, producing new releases two or\
    \ three\n   times each year.  NeTraMet is now in production use at many sites\n\
    \   around the world.  It is difficult to estimate the number of sites,\n   but\
    \ there is an active NeTraMet mailing list, which had about 130\n   subscribers\
    \ in March 1996.\n   Early in 1996 the Realtime Traffic Flow Measurement Working\
    \ Group\n   (RTFM) was chartered to move the Traffic Flow Measurement\n   Architecture\
    \ on to the IETF standards track.  This document records\n   traffic flow measurement\
    \ experience gained through three years\n   experience with NeTraMet.\n"
- title: 1.1 NeTraMet structure and development
  contents:
  - "1.1 NeTraMet structure and development\n   The Traffic Flow Architecture document\
    \ [1] describes four components:\n     - METERS, which are attached to the network\
    \ at the points where\n       it is desired to measure the traffic,\n     - METER\
    \ READERS, which read data from meters and store it for later\n       use,\n \
    \    - MANAGERS, which configure meters and control meter readers, and\n     -\
    \ ANALYSIS APPLICATIONS, which process the data from meter readers\n       so\
    \ as to produce whatever reports are required.\n   NeTraMet is a computer program\
    \ which implements the Traffic Meter,\n   stores the measured flow data in memory,\
    \ and provides an SNMP agent\n   so as to make it available to Meter Readers.\
    \  The NeTraMet\n   distribution files include NeMaC, which is a combined Manager\
    \ and\n   Meter Reader capable of managing an arbitrary number of meters, each\n\
    \   of which may be using its own rule set, and having its flow data\n   collected\
    \ at its own specified intervals.  The NeTraMet distribution\n   also includes\
    \ several rudimentary Analysis Applications, allowing\n   users to produce simple\
    \ plots from NeMaC's flow data files (fd_filter\n   and fd_extract) and to monitor\
    \ - in real time - the flows at a remote\n   meter (nm_rc and nifty).\n   Since\
    \ the first release the Traffic Meter MIB [2] has been both\n   improved and simplified.\
    \  Significant changes have included better\n   ways to specify traffic flows\
    \ (i.e. more actions and better control\n   structures for the Packet Matching\
    \ Engine), and computed attributes\n   (class and kind).  These changes have been\
    \ prompted by operational\n   requirements at sites using NeTraMet, and have been\
    \ tested\n   extensively in successive versions of NeTraMet.\n   NeTraMet is widely\
    \ used to collect usage data for Internet Service\n   Providers.  This is especially\
    \ so in Australia and New Zealand, but\n   there are also active users at sites\
    \ around the world, for example in\n   Canada, France, Germany and Poland.\n \
    \  NeTraMet is very useful as a tool for understanding exactly where\n   traffic\
    \ is flowing in large networks.  Since the Traffic Meters\n   perform considerable\
    \ data reduction (as specified by their rule sets)\n   they significantly reduce\
    \ the volume of data to be read by Meter\n   Readers.  This characteristic makes\
    \ NeTraMet particularly effective\n   for networks with many remote sites.  An\
    \ example of this (the\n   Kawaihiko network) is briefly described below.\n  \
    \ As well as providing data for post-observation analysis, NeTraMet can\n   be\
    \ used for real-time network monitoring and trouble-shooting.  The\n   NeTraMet\
    \ distribution includes 'nifty,' an X/Motif application which\n   monitors traffic\
    \ flows and attempts to highlight those which are\n   'interesting.'\n"
- title: 1.2 Scope of this document
  contents:
  - "1.2 Scope of this document\n   This document presents the experience gained from\
    \ three years work\n   with the Traffic Flow Measurement Architecture.  Its contents\
    \ are\n   grouped as follows\n     - Implementation issues for NeTraMet and NeMaC,\n\
    \     - How rule files work, and how to write them for particular\n       purposes,\
    \ and\n     - How to use NeTraMet and NeMaC for short-term and long-term flow\n\
    \       measurement.\n"
- title: 2 Implementation
  contents:
  - '2 Implementation

    '
- title: 2.1 Choice of meter platform
  contents:
  - "2.1 Choice of meter platform\n   As pointed out in the Architecture document\
    \ [1], the goal of the\n   Realtime Traffic Flow Measurement Working Group is\
    \ to develop a\n   standard for the Traffic Meter, with the goal of seeing it\n\
    \   implemented in network devices such as hubs, switches and routers.\n   Until\
    \ the Architecture is well enough developed to allow this, it has\n   sufficed\
    \ to implement the meter as a program running on a general-\n   purpose computer\
    \ system.\n   The choice of computer system for NeTraMet was driven by the need\
    \ to\n   choose one which would be widely available within the Internet\n   community.\
    \  One strong possibility was a Unix system, since these are\n   commonly used\
    \ for a variety of network support and management tasks.\n   For the initial implementation,\
    \ however, Unix would have had some\n   disadvantages:\n     - The wide variety\
    \ of different Unix systems can increase the\n       difficulties of software\
    \ support.\n     - The cost of a Unix system as a meter is too high to allow users\n\
    \       to run meters simultaneously at many points within their\n       networks.\n\
    \   Another factor in choosing the platform was system performance.  When\n  \
    \ I first started implementing NeTraMet it was impossible to predict\n   how much\
    \ processing workload was needed for a viable meter.\n   Similarly, I had no idea\
    \ how much memory would be required for code\n   or data.  I therefore chose to\
    \ implement NeTraMet on a DOS PC. This\n   was because:\n     - It is a minimum\
    \ system in all respects.  If the meter works\n       well on such a system, it\
    \ can be implemented on almost any\n       hardware (including routers, switches,\
    \ etc.)\n     - It is an inexpensive system.  Sites can easily afford to have\n\
    \       many meters around their networks.\n     - It is a simple system, and\
    \ one which I had complete control over.\n       This allowed me to implement\
    \ effective instrumentation to monitor\n       the meter's performance, and to\
    \ include a wide variety of\n       performance optimisations in the code.\n \
    \  Once the meter was running I needed a manager to download rule files\n   to\
    \ it.  Since a single manager and meter reader can effectively\n   support a large\
    \ number of meters, a Unix environment for NeMaC was a\n   natural choice.  There\
    \ are fewer software support problems for NeMaC\n   than for NeTraMet since NeMaC\
    \ has minimal support needs - it only\n   needs to open a UDP socket to the SNMP\
    \ port on each controlled meter.\n   Early NeTraMet distributions contained only\
    \ the PC meter and Unix\n   manager.  In later releases I ported NeTraMet (the\
    \ meter) to Unix,\n   and extended the control features of NeMaC (the combined\
    \ manager and\n   meter reader).  I have also experimented with porting NeMaC\
    \ to the\n   DOS system.  This is not difficult, but doesn't seem to be worth\n\
    \   pursuing.\n   The current version of NeTraMet is a production-quality traffic\n\
    \   measurement system which has been in continuous use at the University\n  \
    \ of Auckland for nearly two years.\n"
- title: 2.2 Programming support requirements
  contents:
  - "2.2 Programming support requirements\n   To implement the Traffic Flow Meter\
    \ I needed a programming\n   environment providing good support for the following:\n\
    \     - observation of packet headers on the network;\n     - system timer with\
    \ better than 10 ms resolution;\n     - IP (Internet Protocol), for communications\
    \ with manager and meter\n       reader;\n     - SNMP, for the agent implementing\
    \ the Meter MIB.\n"
- title: 2.2.1 DOS environment
  contents:
  - "2.2.1 DOS environment\n   For the PC I chose to use Ethernet as the physical\
    \ network medium.\n   This is simply an initial choice, being the medium used\
    \ within the\n   University of Auckland's data network.  Interfaces for other\
    \ media\n   could easily be added as they are needed.\n   In the PC environment\
    \ a variety of 'generalised' network interfaces\n   are available.  I considered\
    \ those available from companies such as\n   Novell, DEC and Microsoft and decided\
    \ against them, partly because\n   they are proprietary, and partly because they\
    \ did not appear to be\n   particularly easy to use.  Instead I chose the CRYNWR\
    \ Packet Drivers\n   [3] .  These are available for a wide variety of interface\
    \ cards and\n   are simple and clearly documented.  They support Ethernet's\n\
    \   promiscuous mode, allowing one to observe headers for every passing\n   packet\
    \ in a straightforward manner.  One disadvantage of the Packet\n   Drivers is\
    \ that it is harder to use them with newer user shells (such\n   as Microsoft\
    \ Windows), but this was irrelevant since I intended to\n   run the meter as the\
    \ only program on a dedicated machine.\n   Timing on the PC presented a challenge\
    \ since the BIOS timer routines\n   only provide a clock tick about 18 times each\
    \ second, which limits\n   the available time resolution.  Initially I made do\
    \ with a timing\n   resolution of one second for packets, since I believed that\
    \ most\n   flows existed for many seconds.  In recent years it has become\n  \
    \ apparent that many flows have lifetimes well under a second.  To\n   measure\
    \ them properly with the Traffic Flow Meter one needs times\n   resolved to 10\
    \ millisecond intervals, this being the size of\n   TimeTicks, the most common\
    \ time unit within SNMP [4].  Since all the\n   details of the original PC are\
    \ readily available [5], it was not\n   difficult to understand the underlying\
    \ hardware.  I have written PC\n   timer routines for NeTraMet which read the\
    \ hardware timer with 256\n   times the resolution of the DOS clock ticks, i.e.\
    \ about 5 ticks per\n   millisecond.\n   There are many TCP/IP implementations\
    \ available for DOS, but most of\n   them are commercial software.  Instead I\
    \ chose Waterloo TCP [6],\n   since this was available (including full source\
    \ code) as public\n   domain software.  This was necessary since I needed to modify\
    \ it to\n   allow me to save incoming packet headers at the same time as\n   forwarding\
    \ packets destined for the meter to the IP handler routines.\n   For SNMP I chose\
    \ CMU SNMP [7], since again this was available (with\n   full source code) as\
    \ public domain software.  This made it fairly\n   simple to port it from Unix\
    \ to the PC.\n   Finally, for the NeTraMet development I used Borland's Turbo\
    \ C and\n   Turbo Assembler.  Although many newer C programming environments are\n\
    \   now available, I have been perfectly happy with Turbo C version 2 for\n  \
    \ the NeTraMet project!\n"
- title: 2.2.2 Unix environment
  contents:
  - "2.2.2 Unix environment\n   In implementing the Unix meter, the one obvious problem\
    \ was 'how do I\n   get access to packet headers?'  Early versions of the Unix\
    \ meter were\n   implemented using various system-specific interfaces on a SunOS\
    \ 4.2\n   system.  Later versions use libpcap [8], which provides a portable\n\
    \   method of obtaining access to packet headers on a wide range of Unix\n   systems.\
    \  I have verified that this works very well for ethernet\n   interfaces on Solaris,\
    \ SunOS, Irix, DEC Unix and Linux, and for FDDI\n   interfaces on Solaris.  libpcap\
    \ provides timestamps for each packet\n   header with resolution determined by\
    \ the system clock, which is\n   certainly better than 10 ms!\n   All Unix systems\
    \ provide TCP/IP capabilities, so that was not an\n   issue.  For SNMP I used\
    \ CMU SNMP, exactly as on the PC.\n"
- title: 2.3 Implementing the meter
  contents:
  - "2.3 Implementing the meter\n   This section briefly discusses the data structures\
    \ used by the meter,\n   and the packet matching process.  One very strong concern\
    \ during the\n   evolution of NeTraMet has been the need for the highest possible\n\
    \   level of meter performance.  A variety of interesting optimisations\n   have\
    \ been developed to achieve this; as discussed below.  Another\n   particular\
    \ concern was the need for efficient and effective memory\n   managent; this is\
    \ discussed in detail below.\n"
- title: 2.3.1 Data structures
  contents:
  - "2.3.1 Data structures\n   All the programs in NeTraMet, NeMaC and their supporting\
    \ utility\n   programs are written in C, partly because C and its run-time\n \
    \  libraries provides good access to the underlying hardware, and partly\n   because\
    \ I have found it to be a highly portable language.\n   The data for each flow\
    \ is stored in a C structure.  The structure\n   includes all the flow's attribute\
    \ values (including packet and byte\n   counts), together with a link field which\
    \ can be used to link flows\n   into lists.  NeTraMet assumes that Adjacent addresses\
    \ are 802 MAC\n   Addresses, which are all six bytes long.  Similarly, Transport\n\
    \   addresses are assumes to be two bytes long, which is the case for\n   port\
    \ numbers in IP.  Peer addresses are normally four bytes or less\n   in length.\
    \  They may, however, be as long as 20 bytes (for CLNS). I\n   have chosen to\
    \ use a fixed Peer address size, defined at compile\n   time, so as to avoid the\
    \ complexity of having variable-sized flow\n   structures.\n   The flow table\
    \ itself is an array of pointers to flow data\n   structures, which allows indexed\
    \ access to flows via their flow\n   numbers.  There is also a single large hash\
    \ table, referred to in the\n   Architecture document [1] as the flow table's\
    \ 'search index'.  Each\n   hash value in the table points to a circular chain\
    \ of flows.  To find\n   a flow one computes its hash value then searches that\
    \ value's flow\n   chain.\n   The meter stores each rule in a C structure.  All\
    \ the rule components\n   have fixed sizes, but address fields must be wide enough\
    \ to hold any\n   type of address - Adjacent, Peer or Transport.  The rule address\n\
    \   width is defined at compile time, in the same way as flow Peer\n   addresses.\
    \  Each rule set is implemented as an array of pointers to\n   rule data structures,\
    \ and the rule table is an array of pointers to\n   the rule sets.  The size of\
    \ each rule set is specified by NeMaC\n   (before it begins downloading the rule\
    \ set), but the maximum number\n   of rule sets is defined at compile time.\n"
- title: 2.3.2 Packet matching
  contents:
  - "2.3.2 Packet matching\n   Packet matching is carried out in NeTraMet exactly\
    \ as described in\n   the Architecture document [1].  Each incoming packet header\
    \ is\n   analysed so as to determine its attribute values.  These values are\n\
    \   stored in a structure which is passed to the Packet Matching Engine.\n   To\
    \ facilitate matching with source and destination reversed this\n   structure\
    \ contains two substructures, one containing the source\n   Adjacent, Peer and\
    \ Transport address values, the other containing the\n   destination address values.\n"
- title: 2.3.3 Testing groups of rule addresses
  contents:
  - "2.3.3 Testing groups of rule addresses\n   As described in the Architecture [1]\
    \ each rule's address will usually\n   be tested, i.e. ANDed with the rule's mask\
    \ and compared with the\n   rule's value.  If the comparison fails, the next rule\
    \ in sequence is\n   executed.  This allows one to write rule sets which use a\
    \ group of\n   rules to test an incoming packet to see whether one of its addresses\n\
    \   - e.g. its SourcePeerAddress - is one of a set of specified IP\n   addresses.\
    \  Such groups of related rules can grow quite large,\n   containing hundreds\
    \ of rules.  It was clear that sequential execution\n   of such groups of rules\
    \ would be slow, and that something better was\n   essential.\n   The optimisation\
    \ implemented in NeTraMet is to find groups of rules\n   which test the same attribute\
    \ with the same mask, and convert them\n   into a single hashed search of their\
    \ values.  The overhead of setting\n   up hash tables (one for each group) is\
    \ incurred once, just before the\n   meter starts running a new rule set.  When\
    \ a 'group' test is to be\n   performed, the meter ANDs the incoming attribute\
    \ value, computes a\n   hash value from it, and uses this to search the group's\
    \ hash table.\n   Early tests showed that the rule hash chains were usually very\
    \ short,\n   usually having only one or two members.  The effect is to reduce\n\
    \   large sequences of tests to a hash computation and lookup, with a\n   very\
    \ small number of compares; in short this is an essential\n   optimisation for\
    \ any traffic meter!\n   There is, of course, overhead associated with performing\
    \ the hashed\n   compare.  NeTraMet handles this by having a minimum group size\n\
    \   defined at compile time.  If the group is too small it is not\n   combined\
    \ into a hashed group.\n   In early versions of NeTraMet I did not allow Gotos\
    \ into a hashed\n   group of rules, which proved to be an unnecessarily conservative\n\
    \   position.  NeTraMet stores each group's hash table in a separate\n   memory\
    \ area, and keeps a pointer to the hash table in the first rule\n   of the group.\
    \  (The rules data structure has an extra component to\n   hold this hash table\
    \ pointer).  Rules within the group don't have\n   hash table pointers; when they\
    \ are executed as the target of a Goto\n   rule they behave as ordinary rules,\
    \ i.e. their tests are performed\n   normally.\n"
- title: 2.3.4 Compression of address masks
  contents:
  - "2.3.4 Compression of address masks\n   When the Packet Matching Engine has decided\
    \ that an incoming packet\n   belongs to a flow which is to be measured, it searches\
    \ the flow table\n   to determine whether or not the flow is already present.\
    \  It does\n   this by computing a hash from the packet and using it for access\
    \ to\n   the flow table's search index.\n   When designing a hash table, one normally\
    \ assumes that the objects in\n   the table have a constant size.  For NeTraMet's\
    \ flow table this would\n   mean that each flow would contain a value for every\
    \ attribute.  This,\n   however, is not the case, since only those attribute values\
    \ 'pushed'\n   by rules during packet matching are stored for a flow.\n   To demonstrate\
    \ this problem , let us assume that every flow in the\n   table contains a value\
    \ for only one attribute, SourcePeerAddress, and\n   that the rule set decides\
    \ whether flows belong to a specified list of\n   IP networks, in which case only\
    \ their network numbers are pushed.\n   The rules perform this test using a variety\
    \ of masks, since the\n   network number allocations range from 16 to 24 bits\
    \ in width.  In\n   searching the flow table, the meter must distinguish between\
    \ zeroes\n   in the address and 'don't care' bits which had been ANDed out.  To\n\
    \   achieve this it must store SourcePeerMask values in the flow table as\n  \
    \ well as the ANDed SourcePeerAddress values.\n   In early versions of NeTraMet\
    \ this problem was side-stepped by using\n   multiple hash tables and relying\
    \ on the user to write rules which\n   used the same set of attributes and masks\
    \ for all the flows in each\n   table.  This was effective, but clumsy and difficult\
    \ to explain.\n   Later versions changed to using a single hash table, and storing\
    \ the\n   mask values for all the address attributes in each flow.\n   The current\
    \ version of the meter stores the address masks in\n   compressed form.  After\
    \ examining a large number of rule sets I\n   realised that although a rule set\
    \ may have many rules, it usually has\n   a very small number of address masks.\
    \  It is a simple matter to build\n   a table of address masks, and store an index\
    \ to this 'mask table'\n   instead of a complete mask.  NeTraMet's maximum number\
    \ of masks is\n   defined at compile time, up to a maximum of 256.  This allows\
    \ me to\n   use a single byte for each mask in the flow data structure,\n   significantly\
    \ reducing the structure's size.  As well as this size\n   reduction, two masks\
    \ can be compared by comparing their indices in\n   the mask table, i.e. it reduces\
    \ to a single-byte comparison.\n   Overall, using a mask table seems to provide\
    \ useful improvements in\n   storage efficiency and execution speed.\n"
- title: 2.3.5 Ignoring unwanted flow data
  contents:
  - "2.3.5 Ignoring unwanted flow data\n   As described in the Architecture document\
    \ [1], every incoming packet\n   is tested against the current rule set by the\
    \ Packet Matching Engine.\n   This section explains my efforts to improve NeTraMet\
    \ performance on\n   the PC by reducing the amount of processing required by each\
    \ incoming\n   packet.\n   On the PC each incoming packet causes an interrupt,\
    \ which NeTraMet\n   must process so as to collect information about the packet.\
    \  In early\n   versions I used a ring buffer with 512 slots for packet headers,\
    \ and\n   simply copied each packet's first 64 bytes into the next free slot.\n\
    \   The packet headers were later taken from the buffer, attribute values\n  \
    \ were extracted from them, and the resulting 'incoming attribute\n   values'\
    \ records were passed to the Packet Matching Engine.\n   I modified the interrupt\
    \ handling code to extract the attribute\n   values and store them in a 'buffer\
    \ slot.'  This reduced the amount of\n   storage required in each slot, allowing\
    \ more space for storing flows.\n   It did increase slightly the amount of processing\
    \ done for each\n   packet interrupt, but this has not caused any problems.\n\
    \   In later versions I realised that if one is only interested in\n   measuring\
    \ IP packets, there is no point in storing (and later\n   processing) Novell or\
    \ EtherTalk packets!  It is a simple matter for\n   the meter to inspect a rule\
    \ set and determine which Peer types are of\n   interest.  If there are PushRule\
    \ rules which test SourcePeerType (or\n   DestPeerType), they specify which types\
    \ are of interest.  If there\n   are no such rules, every packet type is of interest.\
    \  The PC NeTraMet\n   has a set of Boolean variables, one for each protocol it\
    \ can handle.\n   The values of these 'protocol' variables are determined when\
    \ the\n   meter begins running a new rule set.  For each incoming packet, the\n\
    \   interrupt handler determines the Peer type.  If the protocol is not\n   of\
    \ interest, no further processing is done - the packet is simply\n   ignored.\
    \  In a similar manner, if Adjacent addresses are never tested\n   there is no\
    \ point in copying them into the packet buffer slot.\n   The overall effect of\
    \ these optimisations is most noticeable for rule\n   files which measure IP flows\
    \ on a network segment which also carries\n   a lot of traffic for other network\
    \ protocols; this situation is\n   common on multiprotocol Local Area networks.\
    \  On the Unix version of\n   NeTraMet the Operating System does all the packet\
    \ interrupt\n   processing, and libpcap [8] delivers packet headers directly to\n\
    \   NeTraMet.  The 'protocol' and 'adjacent address' optimisations are\n   still\
    \ performed, at the point when NeTraMet receives the packet\n   headers from libpcap.\n"
- title: 2.3.6 Observing meter reader activity
  contents:
  - "2.3.6 Observing meter reader activity\n   The Architecture document [1] explains\
    \ that a flow data record must\n   be held in the meter until its data has been\
    \ read by a meter reader.\n   A meter must therefore have a reliable way of deciding\
    \ when flow data\n   has been read.  The problem is complicated by the fact that\
    \ there may\n   be more than one meter reader, and that meter readers collect\
    \ their\n   data asynchronously.\n   Early versions of NeTraMet solved this problem\
    \ by having a single MIB\n   variable which a meter reader could set to indicate\
    \ that it was\n   beginning a data collection.  In response to such an SNMP SET\n\
    \   request, NeTraMet would update its 'collectors' table.  This had an\n   entry\
    \ for each meter reader, and variables recording the start time\n   for the last\
    \ two collections.  The most recent collection might still\n   be in progress,\
    \ but its start time provides a safe estimate of the\n   time when the one before\
    \ it actually finished.  Space used for flows\n   which have been idle since the\
    \ penultimate collection started can be\n   recovered by the meter's garbage collector,\
    \ as described below.\n   The Meter MIB [2] specifies a more general table of\
    \ meter reader\n   information.  A meter reader wishing to collect data from a\
    \ meter\n   must inform the meter of its intention by creating a row in the\n\
    \   table, then setting a LastTime variable in that row to indicate the\n   start\
    \ of a collection.  The meter handles such a SET request exactly\n   as described\
    \ above.  If there are multiple meter readers the meter\n   can easily find the\
    \ earliest time any of them started its penultimate\n   collection, and may recover\
    \ flows idle since then.  Should a meter\n   reader fail, NeTraMet will eventually\
    \ time out its entry in the meter\n   reader info table, and delete it.  This\
    \ avoids a situation where the\n   meter can't recover flows until they have been\
    \ collected by several\n   meter readers, one of which has failed.\n"
- title: 2.3.7 Meter memory management
  contents:
  - "2.3.7 Meter memory management\n   In principle, the size of the flow table (i.e.\
    \ the maximum number of\n   flows) could be changed dynamically.  This would involve\
    \ allocating\n   space for the flow table's new pointer array and copying the\
    \ old\n   pointers into it.  NeTraMet does not implement this.  Instead the\n\
    \   maximum number of flows is set from the command line when it starts\n   execution.\
    \  If no maximum is specified, a compile-time default number\n   is used.\n  \
    \ Memory for flow data structures (i.e. 'flows') is allocated\n   dynamically.\
    \  NeTraMet requests the C run-time system for blocks of\n   several hundred flows,\
    \ and links them into a free list.  When a new\n   flow is needed NeTraMet gets\
    \ memory space from the free list, then\n   searches the flow table's pointer\
    \ array for an unused flow pointer.\n   In practice a 'last-allocated' index is\
    \ used to point to the flow\n   table, so a simple linear search suffices.  The\
    \ flow index is saved\n   in the flow's data record, and its other attribute values\
    \ are set to\n   zero.\n   To release a flow data record it must first be removed\
    \ from any hash\n   list it is part of - this is straightforward since those lists\
    \ are\n   circular.  The flow's entry in the flow table pointer array is then\n\
    \   set to zero (NULL pointer), and its space is returned to the free\n   list.\n\
    \   Once a flow data record is created it could continue to exist\n   indefinitely.\
    \  In time, however, the meter would run out of space.\n   To deal with this problem\
    \ NeTraMet uses an incremental garbage\n   collector to reclaim memory.\n   At\
    \ regular intervals specified by a 'GarbageCollectInterval' variable\n   the garbage\
    \ collector procedure is invoked.  This searches through\n   the flow table looking\
    \ for flows which might be recovered.  To\n   control the resources consumed by\
    \ garbage collection there are limits\n   on the number of in-use and idle flows\
    \ which the garbage collector\n   may inspect  these are set either when NeTraMet\
    \ is started (as\n   options on the command line) or dynamically by NeMaC (using\
    \ variables\n   in an Enterprise MIB for NeTraMet)\n   To decide whether a flow\
    \ can be recovered, the garbage collector\n   considers how long it has been idle\
    \ (no packets in either direction),\n   and when its data was last collected.\
    \  If it has been collected by\n   all known meter readers since its LastTime,\
    \ its memory may be\n   recovered.  This alogrithm is implemented using a variable\
    \ called\n   'GarbageCollectTime,' which normally contains the meter's UpTime\
    \ when\n   the penultimate collection (i.e. the one before last) was started.\n\
    \   See the section on observing meter reader activity (above) for more\n   details.\n\
    \   Should flows not be collected often enough the meter could run out of\n  \
    \ space.  NeTraMet attempts to prevent this by having a low-priority\n   background\
    \ process check the percentage of flows active and compare\n   it with the HighWaterMark\
    \ MIB variable.  If the percentage of active\n   flows is greater than the high-water\
    \ mark, 'GarbageCollectTime' is\n   incremented by the current value of the InactivityTimeout\
    \ MIB\n   variable.\n   The Meter MIB [2] specifies that a meter should switch\
    \ to using a\n   'standby' rule set if the percentage of active flows rises above\n\
    \   HighWaterMark.  In using NeTraMet to measure traffic flows to and\n   from\
    \ the University of Auckland it has not been difficult to create\n   standby rules\
    \ which are very similar to the 'production' rule file,\n   differing only in\
    \ that they push much less information about flows.\n   This has, on several occasions,\
    \ allowed the meter to continue running\n   for one or two days after the meter\
    \ reader failed.  When the meter\n   reader restarted, it was able to collect\
    \ all the accumulated flow\n   data!\n   The MIB also specifies that the meter\
    \ should take some action when\n   the active flow percentage rises above its\
    \ FloodMark value.  If this\n   were not done, the meter could spend a rapidly\
    \ increasing proportion\n   of its time garbage collecting, to the point where\
    \ its ability to\n   respond to requests from its manager would be compromised.\
    \  NeTraMet\n   switches to the default rule set when its FloodMark is reached.\n\
    \   A potentially large number of new flows may be created when the meter\n  \
    \ switches to a standby rule set.  It is important to set a\n   HighWaterMark\
    \ so as to allow enough flow table space for this.  In\n   practice, a HighWaterMark\
    \ of 65% and a FloodMark of 95% seem to work\n   well.\n"
- title: 2.4 Data collection
  contents:
  - "2.4 Data collection\n   As explained above, a meter reader wishing to collect\
    \ flows begins\n   each collection by setting the LastTime variable in its\n \
    \  ReaderInfoTable row, then works its way through the flow table\n   collecting\
    \ data.  A number of algorithms can be used to examine the\n   flow table; these\
    \ are presented below.\n   The simplest approach is a linear scan of the table,\
    \ reading the\n   LastTime variable for each row.  If the read fails the row is\n\
    \   inactive.  If it succeeds, it is of interest if its LastTime value is\n  \
    \ greater than the time of the last collection.  Although this method\n   is simple\
    \ it is also rather slow, requiring an SNMP GET request for\n   every possible\
    \ flow; this renders it impractical.\n   Early versions of NeTraMet used two 'windows'\
    \ into the flow table to\n   find flows which were of interest.  Both windows\
    \ were SNMP tables,\n   indexed by a variable which specified a time.  A succession\
    \ of\n   GETNEXT requests on one of these windows allowed NeMaC (the meter\n \
    \  reader) to find the flow indices for all flows which had been active\n   since\
    \ the specified time.  The two windows were the ActivityTime\n   window (which\
    \ located active flows), and the CreateTime window (which\n   located new flows).\
    \  Knowing the index of an active flow, the meter\n   reader can GET the values\
    \ for all the attributes of interest.  NeMaC\n   allows the user to specify which\
    \ these are, rather than simply read\n   all the attributes.\n   Having the two\
    \ windows allowed NeMaC to read attributes which remain\n   constant - such as\
    \ the flow's address attributes - when the flow is\n   created, but to only read\
    \ attributes which change with time - such as\n   its packet and byte counts -\
    \ during later collections.  Experience\n   has shown, however, that many flows\
    \ have rather short lifetimes; one\n   effect of this is that the improved efficiency\
    \ of using two windows\n   does not result in any worthwhile improvement in collection\n\
    \   performance.\n   The current version of the Meter MIB [2] uses a TimeFilter\
    \ variable\n   in the flow table entries.  This can be used with GETNEXT requests\
    \ to\n   find all flows which have been active since a specified time\n   directly,\
    \ without requiring the extra 'window' SNMP variables.  It\n   can be combined\
    \ with SNMPv2's GETBULK request to further reduce the\n   number of SNMP packets\
    \ needed for each collection; I have yet to\n   implement this in NeTraMet.\n\
    \   A disadvantage of using SNMP to collect data from the meter is that\n   SNMP\
    \ packets impose a high overhead.  For example, if we wish to read\n   an Integer32\
    \ variable (four bytes of data), it will be returned with\n   its object identifier,\
    \ type and length, i.e. at least ten bytes of\n   superfluous data.  One way to\
    \ reduce this overhead is to use an\n   Opaque object to return a collection of\
    \ data.  NeTraMet uses this\n   approach to retrieve 'column activity data' from\
    \ the meter, as\n   follows.\n   Each packet of column activity data contains\
    \ data values for a\n   specified attribute, and each value is preceded by its\
    \ flow number.\n   The flow table can be regarded as a two-dimensional array,\
    \ with a\n   column for each flow attribute.  Column activity data objects allow\n\
    \   the meter reader to read columns of the flow table, so as to collect\n   only\
    \ those attributes specified by the user.  The actual\n   implementation is complicated\
    \ by the fact that since the flow table\n   is read column by column, rows can\
    \ become active after the first\n   column has been read.  NeMaC reads the widest\
    \ columns (those with\n   greatest size in bytes, e.g. PeerAddress) first, and\
    \ ignores any rows\n   which appear in later columns.  Newly active rows will,\
    \ of course, be\n   read in the next collection.\n   Using Opaque objects in this\
    \ way dramatically reduces the number of\n   SNMP packets required to read a meter.\
    \  This has proved worthwhile in\n   situations where the number of flows is large\
    \ (for example on busy\n   LANs), and where the meter(s) are physically dispersed\
    \ over slow WAN\n   links.  It has the disadvantage that general-purpose MIB browsers\n\
    \   cannot understand the column activity variables, but this seems a\n   small\
    \ price to pay for the improved data collection performance.\n"
- title: 2.5 Restarting a meter
  contents:
  - "2.5 Restarting a meter\n   If a meter fails, for example because of a power failure,\
    \ it will\n   restart and begin running rule set 1, the default rule set which\
    \ is\n   built into the meter.  Its manager must recognise that this has\n   happened,\
    \ and respond with some suitable action.\n   NeMaC allows the user to specify\
    \ a 'keepalive' interval.  After every\n   such interval NeMaC reads the meter's\
    \ sysUptime and compares it with\n   the last sysUptime.  If the new sysUptime\
    \ is less than the last one,\n   NeMaC decides that the meter has restarted. \
    \ It downloads the meter's\n   backup rule set and production rule set, then requests\
    \ the meter to\n   start running the production rule set.  In normal use we use\
    \ a\n   keepalive interval of five minutes and a collection interval of 15\n \
    \  minutes.  If a meter restarts, we lose up to five minutes data before\n   the\
    \ rules sets are downloaded.\n   Having the meter run the default rule set on\
    \ startup is part of the\n   Traffic Flow Measurement Architecture [1], in keeping\
    \ with the notion\n   that meters are very simple devices which do not have disk\
    \ storage.\n   Since disks are now very cheap, it may be worth considering whether\n\
    \   the architecture should allow a meter to save its configuration\n   (including\
    \ rule sets) on disk.\n"
- title: 2.6 Performance
  contents:
  - "2.6 Performance\n   The PC version of the meter, NeTraMet, continually measures\
    \ how much\n   processor time is being used.  Whenever there is no incoming packet\n\
    \   data to process, 'dummy' packets are generated and placed in the\n   input\
    \ buffer.  These packets are processed normally by the Packet\n   Matching Engine;\
    \ they have a PeerType of 'dummy.'  The numbers of\n   dummy and normal packets\
    \ are counted by the meter; their ratio is\n   used as an estimate of the processor\
    \ time which is 'idle,' i.e. not\n   being used to process incoming packets. \
    \ The Unix version is intended\n   to run as a process in a multiprocessing system,\
    \ so it cannot busy-\n   wait in this way.\n   The meter also collects several\
    \ other performance measures; these can\n   be displayed on the meter console\
    \ in response to keyboard requests.\n   The PC meter can be used with a 10 MHz\
    \ 286 machine, on which it can\n   handle a steady load of about 750 packets per\
    \ second.  On a 25 MHz\n   386SX it will handle about 1250 packets per second.\
    \  Users have\n   reported that a 40 MHz 486 can handle peaks of about 3,000 packets\n\
    \   per second without packet loss.  The Unix meter has been tested\n   metering\
    \ traffic on a (lightly loaded) FDDI interface; it uses about\n   one percent\
    \ of the processor time on a SPARC 10 system running\n   Solaris.\n"
- title: 3 Writing rule sets
  contents:
  - "3 Writing rule sets\n   The Traffic Meter provides a versatile device for measuring\
    \ a user-\n   specified set of traffic flows, and performing useful data reduction\n\
    \   on them.  This data reduction capability not only minimises the\n   volume\
    \ of data to be collected by meter readers, but also simplifies\n   the later\
    \ processing of traffic flow data.\n   The flows of interest, and the processing\
    \ to be performed, are\n   specified in a 'rule set' which is downloaded to the\
    \ meter (NeTraMet)\n   by the manager (NeMaC). This section explains what is involved\
    \ in\n   writing rule sets.\n   NeTraMet is limited to metering packets observed\
    \ on a network\n   segment.  This means that for all the observed flows, Source\
    \ and Dest\n   Type attributes (e.g. SourcePeerType and DestPeerType) have the\
    \ same\n   value.\n   The NeTraMet implementation uses single variables in its\
    \ flow data\n   structure for AdjacentType, SourceType and TransType.  Nonetheless,\n\
    \   the rule sets discussed below push values for both Source and Dest\n   Type\
    \ attributes; this make sure that packet matching works properly\n   with the\
    \ directions reversed, even for a meter which allows Source\n   and Dest Type\
    \ values to be different.\n"
- title: 3.1 Rule set to observe all flows
  contents:
  - "3.1 Rule set to observe all flows\n   NeMaC reads rule sets from text files which\
    \ contain the rules, the\n   set number which the meter (and meter reader) will\
    \ identify them by,\n   and a 'format,' i.e. a list specifying which attributes\
    \ the meter\n   reader should collect and write to the flow data file.  The #\n\
    \   character indicates the start of a comment; NeMaC ignores the rest of\n  \
    \ the line.\n     SET 2\n     #\n     RULES\n     #\n       SourcePeerType & 255\
    \ = Dummy:   Ignore, 0;\n       Null & 0 = 0:  GotoAct, Next;\n     #\n      \
    \ SourcePeerType     & 255             = 0: PushPkttoAct, Next;\n       DestPeerType\
    \       & 255             = 0: PushPkttoAct, Next;\n       SourcePeerAddress \
    \ & 255.255.255.255 = 0: PushPkttoAct, Next;\n       DestPeerAddress    & 255.255.255.255\
    \ = 0: PushPkttoAct, Next;\n       SourceTransType    & 255             = 0: PushPkttoAct,\
    \ Next;\n       DestTransType      & 255             = 0: PushPkttoAct, Next;\n\
    \       SourceTransAddress & 255.255         = 0: PushPkttoAct, Next;\n      \
    \ DestTransAddress   & 255.255         = 0: CountPkt, 0;\n     #\n     FORMAT\
    \ FlowRuleSet FlowIndex FirstTime \"  \"\n        SourcePeerType SourcePeerAddress\
    \ DestPeerAddress \"  \"\n        SourceTransType SourceTransAddress DestTransAddress\
    \ \"  \"\n        ToPDUs FromPDUs \"  \" ToOctets FromOctets;\n   The first rule\
    \ tests the incoming packet's SourcePeerType to see\n   whether it is 'dummy.'\
    \  If it is, the packet is ignored, otherwise\n   the next rule is executed.\n\
    \   The second rule tests the Null attribute.  Such a test always\n   succeeds,\
    \ so the rule simply jumps to the action of the next rule.\n   (The keyword 'next'\
    \ is converted by NeMaC into the number of the\n   following rule.)\n   The third\
    \ rule pushes the packet's SourcePeerType value, then jumps\n   to the action\
    \ of the next rule.  The user does not know in advance\n   what the value of PushPkt\
    \ rules will be, which is why the value\n   appearing in them is always zero.\
    \  The user must take care not to\n   write rule sets which try to perform the\
    \ test in a PushPkt rule.\n   This is a very common error in a rule set, so NeMaC\
    \ tests for it and\n   displays an error message.\n   The following rules push\
    \ a series of attribute values from the\n   packet, and the last rule also Counts\
    \ the packet, i.e. it tells the\n   Packet Matching Engine (PME) that the packet\
    \ has been successfully\n   matched.  The PME responds by searching the flow table\
    \ to see whether\n   the flow is already current (i.e. in the table), creating\
    \ a new flow\n   data record for it should this be necessary, and incrementing\
    \ its\n   packet and byte counters.\n   Overall this rule set simply classifies\
    \ the packet (i.e. decides\n   whether or not it is to be counted), then pushes\
    \ all the Peer and\n   Transport attribute values for it.  It makes no attempt\
    \ to specify a\n   direction for the flow - this is left to the PME, as described\
    \ in\n   [1].  The resulting flow data file will have each flow's source and\n\
    \   destination addresses in the order of the first packet the meter\n   observed\
    \ for the flow.\n"
- title: 3.2 Specifying flow direction, using computed attributes
  contents:
  - "3.2 Specifying flow direction, using computed attributes\n   As indicated above,\
    \ the Packet Matching Engine will reliably\n   determine the flow, and the direction\
    \ within that flow, for every\n   packet seen by a meter.  If the rule set does\
    \ not specify a direction\n   for the flow, the PME simply assumes that the first\
    \ packet observed\n   for a flow is travelling forward, i.e. from source to destination.\n\
    \   In later analysis of the flow data, however, one is usually\n   interested\
    \ in traffic to or from a particular source.\n   One can achieve this in a simple\
    \ manner by writing a rule set to\n   specify the source for flows.  All that\
    \ is required is to have rules\n   which succeed if the packet is travelling in\
    \ the required direction,\n   and which execute a 'Fail' action otherwise.  This\
    \ is demonstrated in\n   the following two examples.\n   (Note that early versions\
    \ of NeMaC allowed 'Retry' as a synonym for\n   'Fail.'  The current version also\
    \ allows 'NoMatch,' which seems a\n   better way to imply \"fail, allowing PME\
    \ to try a second match with\n   directions reversed.\")\n     #  Count IP packets\
    \ from network 130.216.0.0\n     #\n     SourcePeerType & 255 = IP: Pushto, ip_pkt;\n\
    \     Null & 0 = 0: Ignore, 0;\n     #\n     ip_pkt:\n       SourcePeerAddress\
    \ & 255.255.0.0 = 130.216.0.0: Goto c_pkt;\n       Null & 0 = 0: NoMatch, 0;\n\
    \     #\n     c_pkt:\n       SourcePeerAddress & 255.255.255.255 = 0: PushPkttoAct,\
    \ Next;\n       DestPeerAddress & 255.255.255.255 = 0: CountPkt, 0;\n   The rule\
    \ labelled ip_pkt tests whether the packet came from network\n   130.216.  If\
    \ it did not, the test fails and the following rule\n   executes a NoMatch action,\
    \ causing the PME to retry the match with\n   the directions reversed.  If the\
    \ second match fails the packet did\n   not have 130.216 as an end-point, and\
    \ is ignored.\n   The next rule set meters IP traffic on a network segment which\n\
    \   connects two routers, g1 and g2.  It classifies flows into three\n   groups\
    \ - those travelling from g1 to g2, those whose source is g1 and\n   those whose\
    \ source is g2.\n     #  Count IP packets between two gateways\n     #\n     #\
    \     -------+-------------------+------------------+-------\n     #         \
    \   |                   |                  |\n     #       +----+-----+      \
    \  +----+-----+        +---+---+\n     #       |   g1     |        |    g2   \
    \ |        | meter |\n     #       +-+-+-+-+--+        +-+-+-+-+--+        +-------+\n\
    \     #\n     SourcePeerType & 255 = IP: Pushto, ip_pkt;\n     Null & 0 = 0: Ignore,\
    \ 0;\n     #\n     ip_pkt:\n       SourceAdjacentAddress & FF-FF-FF-FF-FF-FF =\
    \ 00-80-48-81-0E-7C:\n           Goto, s1;\n       Null & 0 = 0: Goto, s2;\n \
    \    s1:\n       DestAdjacentAddress & FF-FF-FF-FF-FF-FF = 02-07-01-04-ED-4A\n\
    \           GotoAct, g3;\n       Null & 0 = 0: GotoAct, g1;\n     s2:\n      \
    \ SourceAdjacentAddress & FF-FF-FF-FF-FF-FF = 02-07-01-04-ED-4A:\n           Goto,\
    \ s3;\n       Null & 0 = 0: NoMatch, 0;\n     s3:\n       DestAdjacentAddress\
    \ & FF-FF-FF-FF-FF-FF = 00-80-48-81-0E-7C:\n           NoMatch, 0;\n       Null\
    \ & 0 = 0: GotoAct, g2;\n     #\n     g1: FlowClass & 255 = 1:  PushtoAct, c_pkt;\
    \  # From g1\n     g2: FlowClass & 255 = 2:  PushtoAct, c_pkt;  # From g2\n  \
    \   g3: FlowClass & 255 = 3:  PushtoAct, c_pkt;  # g1 to g2\n     #\n     c_pkt:\n\
    \       SourceAdjacentAddress & FF-FF-FF-FF-FF-FF = 0:\n           PushPkttoAct,\
    \ Next;\n       DestAdjacentAddress & FF-FF-FF-FF-FF-FF = 0: PushPkttoAct, Next;\n\
    \       SourcePeerAddress & 255.255.255.255 = 0: PushPkttoAct, Next;\n       DestPeerAddress\
    \ & 255.255.255.255 = 0: PushPkttoAct, Next;\n       Null & 0 = 0:  Count, 0\n\
    \   The first two rules ignore non-IP packets.  The next two rules Goto\n   s1\
    \ if the packet's source was g1, or to s2 otherwise.  The rule\n   labelled s2\
    \ tests whether the packet's source was g2; if not a\n   NoMatch action is executed,\
    \ allowing the PME to try the match with\n   the packet's direction reversed.\
    \  If the match fails on the second\n   try the packet didn't come from (or go\
    \ to) g1 or g2, and is ignored.\n   Packets which come from g1 are tested by the\
    \ rule labelled s1, and\n   the PME will Goto either g3 or g1.\n   Packets which\
    \ came from g2 are tested by the rule labelled s3.  If\n   they are not going\
    \ to g1 the PME will Goto g2.  If they are going to\n   g1 a NoMatch action is\
    \ executed - we want them counted as backward-\n   travelling packets for the\
    \ g1-g2 flow.\n   The rules at g1, g2 and g3 push the value 1, 2 or 3 from their\
    \ rule\n   into the flow's FlowClass attribute.  This value can be used by an\n\
    \   Analysis Application to separate the flows into the three groups of\n   interest.\
    \  FlowClass is an example of a 'computed' attribute, i.e.\n   one whose value\
    \ is Pushed by the PME during rule matching.\n   The remaining rules Push the\
    \ values of other attributes required for\n   later analysis, then Count the flow.\n"
- title: 3.3 Subroutines
  contents:
  - "3.3 Subroutines\n   Subroutines are implemented in the PME in much the same way\
    \ as in\n   BASIC.  A subroutine body is just a sequence of statements, supported\n\
    \   by the GoSub and Return actions.  'GoSub' saves the PME's running\n   environment\
    \ and jumps to the first rule of the subroutine body.\n   Subroutine calls may\
    \ be nested as required - NeTraMet defines the\n   maximum nesting at compile\
    \ time.  'Return n' restores the environment\n   and jumps to the action part\
    \ of the nth rule after the Gosub, where n\n   is the index value from the Return\
    \ rule.\n   The Return action provides a way of influencing the flow of control\n\
    \   in a rule set, rather like a FORTRAN Computed Goto.  This is one way\n   in\
    \ which a subroutine can return a result.  The other way is by\n   Pushing a value\
    \ in either a computed attribute (as demonstrated in\n   the preceding section),\
    \ or in a flow attribute.\n   One common use for a subroutine is to test whether\
    \ a packet attribute\n   matches one of a set of values.  Such a subroutine becomes\
    \ much more\n   useful if it can be used to test one of several attributes.  The\
    \ PME\n   architecture provides for this by using 'meter variables' to hold the\n\
    \   names of the attributes to be tested.  The meter variables are called\n  \
    \ V1, V2, V3, V4 and V5, and the Assign action is provided to set their\n   values.\
    \  If, for example, we need a subroutine to test either\n   SourcePeerAddress\
    \ or DestPeerAddress, we write its rules to test V1\n   instead.  Before calling\
    \ the subroutine we Assign SourcePeerAddress\n   to V1; later tests of V1 are\
    \ converted by the PME into tests on\n   SourcePeerAddress.  Note that since meter\
    \ variables may be reassigned\n   in a subroutine, their values are part of the\
    \ environment which must\n   be saved by a Gosub action.\n   The following rule\
    \ set demonstrates the use of a subroutine ..\n     #  Rule specification file\
    \ to tally IP packets in three groups:\n     #     UA to AIT, UA to elsewhere,\
    \ AIT to elsewhere\n     #\n     #     -------+-------------------+-----------------+--------\n\
    \     #            |                   |                 |\n     #       +----+-----+\
    \        +----+-----+        +---+---+\n     #       |   UA     |        |   AIT\
    \    |        | meter |\n     #       +-+-+-+-+--+        +-+-+-+-+--+       \
    \ +-------+\n     #\n       SourcePeerType & 255 = IP:      PushtoAct, ip_pkt;\n\
    \       Null & 0 = 0:                   Ignore, 0;\n     #\n     ip_pkt:\n   \
    \    v1 & 0 = SourcePeerAddress:  AssignAct, Next;\n       Null & 0 = 0:  Gosub,\
    \ classify;\n         Null & 0 = 0:  GotoAct, from_ua;    # 1 ua\n         Null\
    \ & 0 = 0:  GotoAct, from_ait;   # 2 ait\n         Null & 0 = 0:  NoMatch, 0;\
    \          # 3 other\n     #\n     from_ua:\n       v1 & 0 = DestPeerAddress:\
    \  AssignAct, Next;\n       Null & 0 = 0:  Gosub, classify;\n         Null & 0\
    \ = 0:  Ignore, 0;            # 1 ua-ua\n         Null & 0 = 0:  GotoAct, ok_pkt;\
    \      # 2 ua-ait\n         Null & 0 = 0:  Gotoact, ok_pkt;      # 3 ua-other\n\
    \     #\n     from_ait:\n       v1 & 0 = DestPeerAddress:  AssignAct, Next;\n\
    \       Null & 0 = 0:  Gosub, classify;\n         Null & 0 = 0:  NoMatch, 0; \
    \          # 1 ait-ua\n         Null & 0 = 0:  Ignore, 0;            # 2 ait-ait\n\
    \         Null & 0 = 0:  GotoAct, ok_pkt;      # 3 ait-other\n     #\n     ok_pkt:\n\
    \       Null & 0 = 0:                   Count, 0;\n   The subroutine begins at\
    \ the rule labelled classify (shown below).\n   It returns to the first, second\
    \ or third rule after the invoking\n   Gosub rule, depending on whether the tested\
    \ PeerAddress is in the UA,\n   AIT, or 'other' group of networks.  In the listing\
    \ below only one\n   network is tested in each of the groups - it is trivial to\
    \ add more\n   rules (one per network) into either of the first two groups.  In\
    \ this\n   example the subroutine Pushes the network number from the packet into\n\
    \   the tested attribute before returning.\n   The first invocation of classify\
    \ (above) begins at the rule labelled\n   ip_pkt.  It Assigns SourcePeerAddress\
    \ to V1 then executes a Gosub\n   action.  Classify returns to one of the three\
    \ following rules.  They\n   will Goto from_ua or from_ait if the packet came\
    \ from the UA or AIT\n   groups, otherwise the PME will retry the match.  This\
    \ means that\n   matched flows will have a UA or AIT network as their source,\
    \ and\n   flows between other networks will be ignored.\n   The next two invocations\
    \ of 'classify' test the packet's\n   DestPeerAddress.  Packets from AIT to UA\
    \ are Retried, forcing them to\n   be counted as AU to AIT flows.  Packets from\
    \ UA to UA are ignored, as\n   are packets from AIT to AIT.\n     classify:\n\
    \       v1 & 255.255.0.0 = 130.216.0.0:  GotoAct, ua;   # ua\n       v1 & 255.255.0.0\
    \ = 156.62.0.0:   GotoAct, ait;  # ait\n       Null & 0 = 0:                 \
    \   Return, 3;     # other\n     ua:\n       v1 & 255.255.0.0 = 0:           \
    \ PushPkttoAct, Next;\n       Null & 0 = 0:                    Return, 1;\n  \
    \   ait:\n       v1 & 255.255.0.0 = 0:            PushPkttoAct, Next;\n      \
    \ Null & 0 = 0:                    Return, 2;\n"
- title: 3.4 More complicated rule sets
  contents:
  - "3.4 More complicated rule sets\n   The next example demonstrates a way of grouping\
    \ IP flows together\n   depending on their Transport Address, i.e. their IP port\
    \ number.\n   Simply Pushing every flow's SourceTransAddress and DestTransAddress\n\
    \   would produce a large number of flows, most of which differ only in\n   one\
    \ of their transport addresses (the one which is not a well-known\n   port).\n\
    \   Instead we Push the well-known port number into each flow's\n   SourceTransAddress;\
    \ its DestTransAddress will be zero by default.\n     SourcePeerType & 255 = dummy:\
    \      Ignore, 0;\n     SourcePeerType & 255 = IP:         Pushto, IP_pkt;\n \
    \    Null & 0 = 0:   GotoAct, Next;\n     SourcePeerType & 255 = 0:      PushPkttoAct,\
    \ Next;\n     Null & 0 = 0:  Count, 0;  # Count others by protocol type\n  #\n\
    \  IP_pkt:\n    SourceTransType & 255 = tcp:    Pushto, tcp_udp;\n    SourceTransType\
    \ & 255 = udp:    Pushto, tcp_udp;\n    SourceTransType & 255 = icmp:   CountPkt,\
    \ 0;\n    SourceTransType & 255 = ospf:   CountPkt, 0;\n    Null & 0 = 0:  GotoAct,\
    \ c_unknown;  #  Unknown transport type\n  #\n  tcp_udp:\n  s_domain:\n    SourceTransAddress\
    \ & 255.255 = domain:  PushtoAct, c_well_known;\n  s_ftp:\n    SourceTransAddress\
    \ & 255.255 = ftp:     PushtoAct, c_well_known;\n  s_imap:\n    SourceTransAddress\
    \ & 255.255 = 113:     PushtoAct, c_well_known;\n  s_nfs\n    SourceTransAddress\
    \ & 255.255 = 2049:    PushtoAct, c_well_known;\n  s_pop:\n    SourceTransAddress\
    \ & 255.255 = 110:     PushtoAct, c_well_known;\n  s_smtp:\n    SourceTransAddress\
    \ & 255.255 = smtp:    PushtoAct, c_well_known;\n  s_telnet:\n    SourceTransAddress\
    \ & 255.255 = telnet:  PushtoAct, c_well_known;\n  s_www:\n    SourceTransAddress\
    \ & 255.255 = www:     PushtoAct, c_well_known;\n  s_xwin\n    SourceTransAddress\
    \ & 255.255 = 6000:    PushtoAct, c_well_known;\n  #\n    DestTransAddress & 255.255\
    \ = domain:    GotoAct, s_domain;\n    DestTransAddress & 255.255 = ftp:     \
    \  GotoAct, s_ftp;\n    DestTransAddress & 255.255 = 113:       GotoAct, s_imap;\n\
    \    DestTransAddress & 255.255 = 2049:      GotoAct, s_nfs;\n    DestTransAddress\
    \ & 255.255 = 110:       GotoAct, s_pop;\n    DestTransAddress & 255.255 = smtp:\
    \      GotoAct, s_smtp;\n    DestTransAddress & 255.255 = telnet:    GotoAct,\
    \ s_telnet;\n    DestTransAddress & 255.255 = www:       GotoAct, s_www;\n   \
    \ DestTransAddress & 255.255 = 6000:      GotoAct, s_xwin;\n  #\n    Null & 0\
    \ = 0:  GotoAct, c_unknown;  #  'Unusual' port\n  #\n  c_unknown:\n    SourceTransType\
    \    & 255 = 0:     PushPkttoAct, Next;\n    DestTransType      & 255 = 0:   \
    \  PushPkttoAct, Next;\n    SourceTransAddress & 255.255 = 0: PushPkttoAct, Next;\n\
    \    DestTransAddress   & 255.255 = 0: CountPkt, 0;\n  #\n  c_well_known:\n  \
    \  Null & 0 = 0:  Count, 0\n  #\n   The first few rules ignore dummy packets,\
    \ select IP packets for\n   further processing, and count packets for other protocols\
    \ in a single\n   flow for each PeerType.  TCP and UDP packets cause the PME to\
    \ Push\n   their TransType and Goto tcp_udp.  ICMP and OSPF packets are counted\n\
    \   in flows which have only their TransType Pushed.\n   At tcp_udp the packets'\
    \ SourceTransAddress is tested to see whether\n   it is included in a set of 'interesting'\
    \ port numbers.  If it is, the\n   port number is pushed from the rule into the\
    \ SourceTransAddress\n   attribute, and the packet is counted at c_well_known.\
    \  (NeMaC accepts\n   Pushto as a synonym for PushRuleto).\n   This testing is\
    \ repeated for the packet's DestTransAddress; if one of\n   these tests succeeds\
    \ the PME Goes to the corresponding rule above and\n   Pushes the port number\
    \ into the flow's SourceTransAddress.  If these\n   tests fail the packet is counted\
    \ at c_unknown, where all the flow's\n   Trans attributes are pushed.  For production\
    \ use more well-known\n   ports would need to be included in the tests above -\
    \ c_unknown is\n   intended only for little-used exception flows!\n   Note that\
    \ these rules only Push a value into a flow's\n   SourceTransAddress, and they\
    \ don't contain any NoMatch actions.  They\n   therefore don't specify a packet's\
    \ direction, and they could be used\n   in other rule sets to group together flows\
    \ for well-known ports.\n   The last example (below) meters flows from a remote\
    \ router, and\n   demonstrates another approach to grouping well-known ports.\n\
    \    SourceAdjacentAddress & FF-FF-FF-FF-FF-FF =\n        00-60-3E-10-E0-A1: \
    \ Goto, gateway;  # tmkr2 router\n    DestAdjacentAddress & FF-FF-FF-FF-FF-FF\
    \ = 00-60-3E-10-E0-A1:\n        Goto, gateway;  # Source is tmkr2\n    Null &\
    \ 0 = 0:  Ignore, 0;\n  #\n  gateway:\n    SourcePeerType & 255 = IP:  GotoAct,\
    \ IP_pkt;\n    Null & 0 = 0:  GotoAct, Next;\n    SourcePeerType & 255 = 0:  CountPkt,\
    \ 0;\n  #\n  IP_pkt:\n    SourceTransType & 255 = tcp:    PushRuleto, tcp_udp;\n\
    \    SourceTransType & 255 = udp:    PushRuleto, tcp_udp;\n    Null & 0 = 0: \
    \ GotoAct, not_wkp;  #  Unknown transport type\n  #\n  tcp_udp:\n    SourceTransAddress\
    \ & FC-00 = 0:  GotoAct, well_known_port;\n    DestTransAddress & FC-00 = 0: \
    \ NoMatch, 0;\n    Null & 0 = 0:  GotoAct, not_wkp;\n  #\n  not_wkp:\n    DestTransAddress\
    \   & 255.255       = 0: PushPkttoAct, Next;\n  well_known_port:\n    SourcePeerType\
    \     & 255           = 0: PushPkttoAct, Next;\n    DestPeerType       & 255 \
    \          = 0: PushPkttoAct, Next;\n    SourcePeerAddress  & 255.255.255.0 =\
    \ 0: PushPkttoAct, Next;\n    DestPeerAddress    & 255.255.255.0 = 0: PushPkttoAct,\
    \ Next;\n    SourceTransType    & 255           = 0: PushPkttoAct, Next;\n   \
    \ DestTransType      & 255           = 0: PushPkttoAct, Next;\n    SourceTransAddress\
    \ & 255.255       = 0: CountPkt, 0;\n   The first group of rules test incoming\
    \ packet's AdjacentAddresses to\n   see whether they belong to a flow with an\
    \ end point at the specified\n   router.  Any which don't are ignored.  Non-IP\
    \ packets are counted in\n   flows which only have their PeerType Pushed; these\
    \ will produce one\n   flow for each non-IP protocol.  IP packets with TransTypes\
    \ other than\n   UDP and TCP are counted at not_wkp, where all their address\n\
    \   attributes are pushed.\n   The high-order six bits of SourceTransAddress for\
    \ UDP and TCP packets\n   are compared with zero.  If this succeeds their source\
    \ port number is\n   less than 1024, so they are from a well-known port.  The\
    \ port number\n   is pushed from the rule into the flow's SourceTransAddress attribute,\n\
    \   and the packet is counted at well_known_port.  If the test fails, it\n   is\
    \ repeated on the packet's DestTransAddress.  If the destination is\n   a well-known\
    \ port the match is Retried, and will succeed with the\n   well-known port as\
    \ the flow's source.\n   If later analysis were to show that a high proportion\
    \ of the observed\n   flows were from non-well-known ports, further pairs of rules\
    \ could be\n   added to perform a test in each direction for other heavily-used\n\
    \   ports.\n"
- title: 4 Flow data files
  contents:
  - "4 Flow data files\n   Although the Architecture document [1] specifies - in great\
    \ detail -\n   how the Traffic Flow Meter works, and how a meter reader should\n\
    \   collect flow data from a meter, it does not say anything about how\n   the\
    \ collected data should be stored.  NeMaC uses a simple, self-\n   documenting\
    \ file format, which has proved to be very effective in\n   use.\n   There are\
    \ two kinds of records in a flow data file:  flow records and\n   information\
    \ records.  Each flow record is simply a sequence of\n   attribute values with\
    \ separators (these can be specified in a NeMaC\n   rule file) or spaces between\
    \ them, terminated by a newline.\n   Information records all start with a cross-hatch.\
    \  The file's first\n   record begins with ##, and identifies the file as being\
    \ a file of\n   data from NeTraMet.  It records NeMaC's parameters and the time\
    \ this\n   collection was started.  The file's second record begins with\n   #Format:\
    \ and is a copy of the Format statement used by NeMaC to\n   collect the data.\n\
    \   The rest of the file is a sequence of collected data sets.  Each of\n   these\
    \ starts with a #Time:  record, giving the time-of-day the\n   collection was\
    \ started, the meter name, and the range of meter times\n   this collection represents.\
    \  These from and to times are meter\n   UpTimes, i.e. they are times in hundredths\
    \ of seconds since the meter\n   commenced operation.  Most analysis applications\
    \ have simply used the\n   collection start times (which are ASCII time-of-day\
    \ values), but the\n   from and to times could be used to convert Uptime values\
    \ to time-of-\n   day.  The flow records which comprise a data set follow the\
    \ #Time\n   record.\n"
- title: 4.1 Sample flow data file
  contents:
  - "4.1 Sample flow data file\n   A sample flow data file appears below.  Most of\
    \ the flow records have\n   been deleted, but lines of dots show where they were.\n\
    \  ##NeTraMet v3.2.  -c300 -r rules.lan -e rules.default\n    test_meter -i eth0\
    \  4000 flows  starting at 12:31:27 Wed 1 Feb 95\n  #Format: flowruleset flowindex\
    \ firsttime  sourcepeertype\n    sourcepeeraddress destpeeraddress  topdus frompdus\n\
    \    tooctets fromoctets\n  #Time: 12:31:27 Wed  1 Feb 95 130.216.14.251 Flows\n\
    \    from 1 to 3642\n  1 2 13  5 31.32.0.0 33.34.0.0  1138 0  121824 0\n  1 3\
    \ 13  2 11.12.0.0 13.14.0.0  4215 0  689711 0\n  1 4 13  7 41.42.0.0 43.34.0.0\
    \  1432 0  411712 0\n  1 5 13  6 21.22.0.0 23.24.0.0  8243 0  4338744 0\n  3 6\
    \ 3560  2 130.216.14.0 130.216.3.0  0 10  0 1053\n  3 7 3560  2 130.216.14.0 130.216.76.0\
    \  59 65  4286 3796\n  3 8 3560  7 0.0.255.0 1.144.200.0  0 4  0 222\n  3 9 3560\
    \  2 130.216.14.0 130.216.14.0  118 1  32060 60\n  3 10 3560  6 130.216.0.28 130.216.0.192\
    \  782 1  344620 66\n  3 11 3560  7 0.0.255.0 0.128.113.0  0 1  0 73\n  3 12 3560\
    \  5 59.3.13.0 4.1.152.0  1 1  60 60\n  3 13 3560  7 0.128.94.0 0.129.27.0  2\
    \ 2  120 158\n  3 14 3560  5 59.3.40.0 4.1.153.0  2 2  120 120\n  3 15 3560  5\
    \ 0.0.0.0 4.1.153.0  0 1  0 60\n  3 16 3560  5 4.1.152.0 59.2.189.0  2 2  120\
    \ 120\n       .  .  .  .  .  .  .  .  .\n  3 42 3560  7 0.128.42.0 0.129.34.0\
    \  0 1  0 60\n  3 43 3560  7 0.128.42.0 0.128.43.0  0 1  0 60\n  3 44 3560  7\
    \ 0.128.42.0 0.128.41.0  0 1  0 60\n  3 45 3560  7 0.128.42.0 0.129.2.0  0 1 \
    \ 0 60\n  3 46 3560  5 4.1.152.0 59.2.208.0  2 2  120 120\n  3 47 3560  5 59.3.46.0\
    \ 4.1.150.0  2 2  120 120\n  3 48 3560  5 4.1.152.0 59.2.198.0  2 2  120 120\n\
    \  3 49 3560  5 0.0.0.0 59.2.120.0  0 1  0 60\n  3 50 3664  5 4.1.152.0 59.2.214.0\
    \  0 1  0 60\n  3 51 3664  5 0.0.0.0 4.2.142.0  0 1  0 60\n  3 52 3664  5 4.1.153.0\
    \ 59.3.45.0  4 4  240 240\n  #Time: 12:36:25 Wed  1 Feb 95 130.216.14.251 Flows\n\
    \    from 3641 to 33420\n  3 6 3560  2 130.216.14.0 130.216.3.0  0 21  0 2378\n\
    \  3 7 3560  2 130.216.14.0 130.216.76.0  9586 7148  1111118 565274\n  3 8 3560\
    \  7 0.0.255.0 1.144.200.0  0 26  0 1983\n  3 9 3560  2 130.216.14.0 130.216.14.0\
    \  10596 1  2792846 60\n  3 10 3560  6 130.216.0.28 130.216.0.192  16589 1  7878902\
    \ 66\n  3 11 3560  7 0.0.255.0 0.128.113.0  0 87  0 16848\n  3 12 3560  5 59.3.13.0\
    \ 4.1.152.0  20 20  1200 1200\n  3 13 3560  7 0.128.94.0 0.129.27.0  15 14  900\
    \ 1144\n  3 14 3560  5 59.3.40.0 4.1.153.0  38 38  2280 2280\n  3 15 3560  5 0.0.0.0\
    \ 4.1.153.0  0 30  0 1800\n  3 16 3560  5 4.1.152.0 59.2.189.0  20 20  1200 1200\n\
    \  3 17 3560  5 0.0.0.0 59.2.141.0  0 11  0 660\n      .  .  .  .  .  .  .  .\
    \  .\n  3 476 26162  7 0.129.113.0 0.128.37.0  0 1  0 82\n  3 477 27628  7 0.128.41.0\
    \ 0.128.46.0  1 1  543 543\n  3 478 27732  7 0.128.211.0 0.128.46.0  1 1  543\
    \ 543\n  3 479 31048  7 0.128.47.0 2.38.221.0  1 1  60 60\n  3 480 32717  2 202.14.100.0\
    \ 130.216.76.0  0 4  0 240\n  3 481 32717  2 130.216.76.0 130.216.3.0  0 232 \
    \ 0 16240\n  #Time: 12:41:25 Wed  1 Feb 95 130.216.14.251 Flows\n    from 33419\
    \ to 63384\n  3 6 3560  2 130.216.14.0 130.216.3.0  51 180  3079 138195\n  3 7\
    \ 3560  2 130.216.14.0 130.216.76.0  21842 18428  2467693 1356570\n  3 8 3560\
    \  7 0.0.255.0 1.144.200.0  0 30  0 2282\n  3 9 3560  2 130.216.14.0 130.216.14.0\
    \  24980 1  5051834 60\n  3 10 3560  6 130.216.0.28 130.216.0.192  20087 1  8800070\
    \ 66\n  3 11 3560  7 0.0.255.0 0.128.113.0  0 164  0 32608\n  3 12 3560  5 59.3.13.0\
    \ 4.1.152.0  41 41  2460 2460\n  3 14 3560  5 59.3.40.0 4.1.153.0  82 82  4920\
    \ 4920\n  3 15 3560  5 0.0.0.0 4.1.153.0  0 60  0 3600\n      .  .  .  .  .  .\
    \  .  .  .\n"
- title: 4.2 Flow data file features
  contents:
  - "4.2 Flow data file features\n   Several features of NeMaC's flow data files (as\
    \ indicated above) are\n   worthy of note:\n  - Collection times overlap slightly\
    \ between samples.  This allows for\n    flows which were created after the collection\
    \ started, and makes\n    sure that flows are not missed from a collection.\n\
    \  - The rule set may change during a run.  The above shows flows from\n    rule\
    \ set 1 - the default set - in the first collection, followed by\n    the first\
    \ flows created by rule set 3 (which has just been\n    downloaded by NeMaC).\n\
    \  - FlowIndexes may be reused by the meter once their flows have been\n    recovered\
    \ by the garbage collector.  The combination of\n    FlowRuleSet, FlowIndex and\
    \ StartTime are needed to identify a flow\n    uniquely.\n  - Packet and Byte\
    \ counters are 32-bit unsigned integers, and are\n    never reset by the meter.\
    \  Computing the counts occurring within a\n    collection interval requires taking\
    \ the difference between the\n    collected count and its value when the flow\
    \ was last collected.\n    Note that counter wrap-around can be allowed for by\
    \ simply\n    performing an unsigned subtraction and ignoring any carry.\n  -\
    \ In the sample flow data file above I have used double spaces as\n    separators\
    \ between the flow identifiers, peer addresses, pdu counts\n    and packet counts.\n\
    \  - The format of addresses in the flow data file depends on the type\n    of\
    \ address.  NeMaC always displays Adjacent addresses as six hex\n    bytes separated\
    \ by hyphens, and Transport addresses as (16-bit)\n    integers.  The format of\
    \ a Peer address depends on its PeerType,\n    e.g. dotted decimal for IP. To\
    \ facilitate this NeMaC needs to know\n    the PeerType for each flow; the user\
    \ must request NeMaC to collect\n    it.\n"
- title: 4.3 Terminating and restarting meter reading
  contents:
  - "4.3 Terminating and restarting meter reading\n   When NeMaC first starts collecting\
    \ from a meter, it reads the flow\n   data for all active flows.  This provides\
    \ a starting point for\n   analysis applications to compute the counts between\
    \ successive\n   collections.\n   From time to time the user needs to terminate\
    \ a flow data file and\n   begin a new one.  For example, a user might need to\
    \ generate a\n   separate file for each day of metering.  NeMaC provides for this\
    \ by\n   closing the file after each collection, then opening it and appending\n\
    \   the data from the next collection.  To terminate a file the user\n   simply\
    \ renames it.  The Unix system will effect the name change\n   either immediately\
    \ (if the file was closed) or as soon as the current\n   collection is complete\
    \ (and the file is closed).\n   When NeMaC begins its next collection it observes\
    \ that the file has\n   disappeared, so it creates a new one and writes the #\
    \ header records\n   before writing the collected data.\n   There is one aspect\
    \ of the above which requires some care on the\n   user's part.  The last data\
    \ set in a file is not duplicated as the\n   first data set of the next file.\
    \  In other words, analysis\n   applications must either look ahead at the first\
    \ data set of the next\n   file, or begin by reading the last data set of the\
    \ previous file.  If\n   they fail to do this they will loose one collection's\
    \ worth of flow\n   data at each change of file.\n"
- title: 5 Analysis applications
  contents:
  - "5 Analysis applications\n   Most analysis applications will be unique, taking\
    \ data produced by a\n   locally-developed rule set and producing reports to satisfy\
    \ specific\n   local requirements.  The NeTraMet distribution files include three\n\
    \   applications which are of general use, as follows:\n  - fd_filter computes\
    \ data rates, i.e. the differences between\n    successive data sets in a flow\
    \ data file.  It also allows the user\n    to assign a 'tag' number to each flow;\
    \ these are 'computed'\n    attributes similar to FlowClass and FlowKind - the\
    \ only difference\n    is that they are computed from the collected data sets.\n\
    \  - fd_extract takes 'tagged' files from fd_filter and produces simple\n    'column\
    \ list' files for use by other programs.  One common use for\n    fd_extract is\
    \ to produce time-series data files which can be plotted\n    by utilities like\
    \ GNUPlot.\n  - nm_rc is a 'remote console' for a NeTraMet meter.  It is a slightly\n\
    \    simplified version of NeMaC combined with fd_filter.  It can be used\n  \
    \  to monitor any meter, and will display (as lines of text\n    characters) information\
    \ about the n busiest flows observed during\n    each collection interval.\n \
    \ - nifty is a traffic flow analyser, which (like nm_rc) displays data\n    from\
    \ a NeTraMet meter.  nifty is an X/Motif application, which\n    produces displays\
    \ like 'Packet rate (pps) vs Flow lifetime\n    (minutes),' so as to highlight\
    \ those flows which are 'interesting.'\n   These applications are useful in themselves,\
    \ and they provide a good\n   starting point for users who wish to write their\
    \ own analysis\n   applications.\n"
- title: 6 Using NeTraMet in a measurement system
  contents:
  - "6 Using NeTraMet in a measurement system\n   This section gives a brief summary\
    \ of the steps involved in setting\n   up a traffic measurement system using NeTraMet.\
    \  These are:\n  - Decide what is to be measured.  One good way to approach this\
    \ is to\n    specify exactly which flows are to be measured, and what reports\n\
    \    will be required.  Specifying the flows should make it obvious\n    where\
    \ meters will have to be placed so that the flows can be\n    observed, whether\
    \ PCs will be adequate for the task, etc..\n  - Install meters.  As well as actually\
    \ placing the meter hosts this\n    includes making sure that they are configured\
    \ correctly, with\n    appropriate IP addresses, SNMP community strings, etc.\n\
    \  - Develop the rule set (and a standby rule set).  The degree of\n    difficulty\
    \ here depends on how much is known in advance about the\n    traffic.  One possible\
    \ approach is to start with the meter default\n    rule set and measure how much\
    \ traffic there is for each PeerType.\n    (This is a good way to verify that\
    \ NeTraMet and NeMaC are working\n    properly).  You can now add rules so as\
    \ to increase the granularity\n    of the flows; this will of course increase\
    \ the number of flows to\n    be collected, and force the meter's garbage collector\
    \ to work\n    harder.  Another approach is to try a rule set with very fine\n\
    \    granularity (i.e. one which Pushes all the address attributes),\n    then\
    \ observing how many flows are collected every few minutes.\n  - Develop a strategy\
    \ for controlling meter reader.  This means\n    setting the meter's maximum number\
    \ of flows, the collection\n    interval, how breaks between flow data files will\
    \ be handled, how\n    often NeMaC should check that the meter is running, etc.\n\
    \  - Develop application(s) to process the collected flow data and\n    produce\
    \ the required files and reports.\n  - Test run.  Monitor the system, then refine\
    \ the rule sets and meter\n    reading strategy until the overall system performance\
    \ is\n    satisfactory.\n   This process can take quite a long time, but the overall\
    \ result is\n   well worth the effort.\n"
- title: 6.1 Examples of NeTraMet in production use
  contents:
  - "6.1 Examples of NeTraMet in production use\n   At the University of Auckland\
    \ we run two sets of meters.  One of\n   these measures the traffic entering and\
    \ leaving our University\n   network, and generates usage reports for all our\
    \ Internet users.\n   This has been in production since early 1994.\n   The other\
    \ set consists of meters which are distributed at\n   Universities throughout\
    \ New Zealand.  They provide continuous traffic\n   flow measurements at five-minute\
    \ intervals for all the links making\n   up the Universities' network (Kawaihiko);\
    \ this system has been in\n   production since January 1996, and has already proved\
    \ very useful in\n   planning the network's development.\n   The Kawaihiko Network\
    \ provides IP connectivity for the New Zealand\n   Universities.  They are linked\
    \ via a Frame Relay cloud, using a\n   partial mesh of permanent virtual circuits.\
    \  There is a NeTraMet\n   meter at each site, metering inward and outward traffic.\
    \  All the\n   meters are managed from Auckland, and they all run copies of the\
    \ same\n   rule set.\n   The rule set has about 650 rules, most of which are in\
    \ a single\n   subroutine which classifies PeerAddresses into three categories\
    \ -\n   'Kawaihiko network,' 'other New Zealand network' and 'non-New Zealand\n\
    \   network.'  Inside New Zealand IP addresses lie within six CIDR\n   blocks,\
    \ and there are about four hundred older networks which have\n   addresses outside\
    \ those blocks.  The rules are arranged in groups by\n   subnet size, i.e. all\
    \ the /24 networks are tested first, then the /23\n   networks, etc, finishing\
    \ with the /16 networks.  This means that\n   although there are about 600 networks,\
    \ any PeerAddress can be\n   classified with only nine tests.\n   The Kawaihiko\
    \ rule set classifies flows, using computed attributes to\n   indicate the network\
    \ 'kind' (Kawaihiko / New Zealand / international)\n   for each flow's SourcePeerAddress\
    \ and DestPeerAddress, and to\n   indicate whether the flow is a 'network news'\
    \ flow or not.\n   Flow data is collected from all of the meters every five minutes,\
    \ and\n   is used to produce weekly reports, as follows:\n  - Traffic Plots. \
    \ Plots of the 5-minute traffic rates for each site,\n    showing international\
    \ traffic in and out, news traffic in and out,\n    and total traffic in and out\
    \ of the site.\n  - Traffic Matrices.  Two of these are produced, one for news\
    \ traffic,\n    the other for total traffic.  They show the traffic rates from\n\
    \    every site (including 'other New Zealand' and 'international') to\n    every\
    \ other site.  The mean, third quartile and maximum are printed\n    for every\
    \ cell in the matrices.\n"
- title: 7 Acknowledgments
  contents:
  - "7 Acknowledgments\n   This memo documents the implementation work on traffic\
    \ flow\n   measurement here at the University of Auckland.  Many of my\n   University\
    \ colleagues have contributed significantly to this work,\n   especially Russell\
    \ Fulton (who developed the rules sets, Perl scripts\n   and Cron jobs which produce\
    \ our traffic usage reports automatically\n   week after week) and John White\
    \ (for his patient help in documenting\n   the project).\n"
- title: 8 References
  contents:
  - "8 References\n    [1] Brownlee, N., Mills, C., and G. Ruth, \"Traffic Flow\n\
    \    Measurement: Architecture\", RFC 2063, The University of Auckland,\n    Bolt\
    \ Beranek and Newman Inc., GTE Laboratories, Inc, January 1997.\n    [2] Brownlee,\
    \ N., \"Traffic Flow Measurement:  Meter MIB\",\n    RFC 2064, The University\
    \ of Auckland, January 1997.\n    [3] CRYNWR Packer Drivers distribution site:\n\
    \    http://www.crynwr.com/\n    [4] Case J., McCloghrie K., Rose M., and Waldbusser\
    \ S.,\n    \"Structure of Management Information for version 2 of the\n    Simple\
    \ Network Managemenet Protocol\", RFC 1902, SNMP Research\n    Inc., Hughes LAN\
    \ Systems, Dover Beach Consulting, Carnegie\n    Mellon University, April 1993.\n\
    \    [5] IBM Corporation, \"IBM PC Technical Reference Manual,\" 1984.\n    [6]\
    \ Waterloo TCP distribution site:\n    http://mvmpc9.ciw.uni-karlsruhe.de:80/d:/public/tcp_ip/wattcp\n\
    \    [7] CMU SNMP distribution site:\n    ftp://lancaster.andrew.cmu.edu/pub/snmp-dist\n\
    \    [8] libpcap distribution site:\n    ftp://ftp.ee.lbl.gov/libpcap-*.tar.gz\n"
- title: 9 Security Considerations
  contents:
  - "9 Security Considerations\n   Security issues are not discussed in detail in\
    \ this document.  The\n   meter's management and collection protocols are responsible\
    \ for\n   providing sufficient data integrity and confidentiality.\n"
- title: 10 Author's Address
  contents:
  - "10 Author's Address\n   Nevil Brownlee\n   The University of Auckland\n   Phone:\
    \ +64 9 373 7599 x8941\n   Email: n.brownlee@auckland.ac.nz\n"
