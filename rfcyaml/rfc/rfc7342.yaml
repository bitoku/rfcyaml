- title: __initial_text__
  contents:
  - ''
- title: Independent Submission                                         L. Dunbar
  contents:
  - "Independent Submission                                         L. Dunbar\n  \
    \         Practices for Scaling ARP and Neighbor Discovery (ND)\n            \
    \               in Large Data Centers\n"
- title: Abstract
  contents:
  - "Abstract\n   This memo documents some operational practices that allow ARP and\n\
    \   Neighbor Discovery (ND) to scale in data center environments.\n"
- title: Status of This Memo
  contents:
  - "Status of This Memo\n   This document is not an Internet Standards Track specification;\
    \ it is\n   published for informational purposes.\n   This is a contribution to\
    \ the RFC Series, independently of any other\n   RFC stream.  The RFC Editor has\
    \ chosen to publish this document at\n   its discretion and makes no statement\
    \ about its value for\n   implementation or deployment.  Documents approved for\
    \ publication by\n   the RFC Editor are not a candidate for any level of Internet\n\
    \   Standard; see Section 2 of RFC 5741.\n   Information about the current status\
    \ of this document, any errata,\n   and how to provide feedback on it may be obtained\
    \ at\n   http://www.rfc-editor.org/info/rfc7342.\n"
- title: Copyright Notice
  contents:
  - "Copyright Notice\n   Copyright (c) 2014 IETF Trust and the persons identified\
    \ as the\n   document authors.  All rights reserved.\n   This document is subject\
    \ to BCP 78 and the IETF Trust's Legal\n   Provisions Relating to IETF Documents\n\
    \   (http://trustee.ietf.org/license-info) in effect on the date of\n   publication\
    \ of this document.  Please review these documents\n   carefully, as they describe\
    \ your rights and restrictions with respect\n   to this document.\n"
- title: Table of Contents
  contents:
  - "Table of Contents\n   1. Introduction ....................................................2\n\
    \   2. Terminology .....................................................4\n  \
    \ 3. Common DC Network Designs .......................................4\n   4.\
    \ Layer 3 to Access Switches ......................................5\n   5. Layer\
    \ 2 Practices to Scale ARP/ND ...............................5\n      5.1. Practices\
    \ to Alleviate APR/ND Burden on L2/L3\n           Boundary Routers ...........................................5\n\
    \           5.1.1. Communicating with a Peer in a Different Subnet .....6\n  \
    \         5.1.2. L2/L3 Boundary Router Processing of Inbound\n               \
    \   Traffic .............................................7\n           5.1.3.\
    \ Inter-Subnet Communications .........................8\n      5.2. Static ARP/ND\
    \ Entries on Switches ..........................8\n      5.3. ARP/ND Proxy Approaches\
    \ ....................................9\n      5.4. Multicast Scaling Issues ...................................9\n\
    \   6. Practices to Scale ARP/ND in Overlay Models ....................10\n  \
    \ 7. Summary and Recommendations ....................................10\n   8.\
    \ Security Considerations ........................................11\n   9. Acknowledgements\
    \ ...............................................11\n   10. References ....................................................12\n\
    \      10.1. Normative References .....................................12\n  \
    \    10.2. Informative References ...................................13\n"
- title: 1.  Introduction
  contents:
  - "1.  Introduction\n   This memo documents some operational practices that allow\
    \ ARP/ND to\n   scale in data center environments.\n   As described in [RFC6820],\
    \ the increasing trend of rapid workload\n   shifting and server virtualization\
    \ in modern data centers requires\n   servers to be loaded (or reloaded) with\
    \ different Virtual Machines\n   (VMs) or applications at different times.  Different\
    \ VMs residing on\n   one physical server may have different IP addresses or may\
    \ even be in\n   different IP subnets.\n   In order to allow a physical server\
    \ to be loaded with VMs in\n   different subnets or allow VMs to be moved to different\
    \ server racks\n   without IP address reconfiguration, the networks need to enable\n\
    \   multiple broadcast domains (many VLANs) on the interfaces of L2/L3\n   boundary\
    \ routers and Top-of-Rack (ToR) switches and allow some\n   subnets to span multiple\
    \ router ports.\n   Note: L2/L3 boundary routers as discussed in this document\
    \ are\n   capable of forwarding IEEE 802.1 Ethernet frames (Layer 2) without a\n\
    \   Media Access Control (MAC) header change.  When subnets span multiple\n  \
    \ ports of those routers, they still fall under the category of\n   \"single-link\"\
    \ subnets, specifically the multi-access link model\n   recommended by [RFC4903].\
    \  They are different from the \"multi-link\"\n   subnets described in [Multi-Link]\
    \ and RFC 4903, which refer to\n   different physical media with the same prefix\
    \ connected to one\n   router.  Within the \"multi-link\" subnet described in\
    \ RFC 4903, Layer\n   2 frames from one port cannot be natively forwarded to another\
    \ port\n   without a header change.\n   Unfortunately, when the combined number\
    \ of VMs (or hosts) in all\n   those subnets is large, this can lead to address\
    \ resolution (i.e.,\n   IPv4 ARP and IPv6 ND) scaling issues.  There are three\
    \ major issues\n   associated with ARP/ND address resolution protocols when subnets\
    \ span\n   multiple L2/L3 boundary router ports:\n   1) The ARP/ND messages being\
    \ flooded to many physical link segments,\n      which can reduce bandwidth utilization\
    \ for user traffic.\n   2) The ARP/ND processing load impact on the L2/L3 boundary\
    \ routers.\n   3) In IPv4, every end station in a subnet receiving ARP broadcast\n\
    \      messages from all other end stations in the subnet.  IPv6 ND has\n    \
    \  eliminated this issue by using multicast.\n   Since the majority of data center\
    \ servers are moving towards 1G or\n   10G ports, the bandwidth taken by ARP/ND\
    \ messages, even when flooded\n   to all physical links, becomes negligible compared\
    \ to the link\n   bandwidth.  In addition, IGMP/MLD (Internet Group Management\
    \ Protocol\n   and Multicast Listener Discovery) snooping [RFC4541] can further\n\
    \   reduce the ND multicast traffic to some physical link segments.\n   As modern\
    \ servers' computing power increases, the processing taken by\n   a large amount\
    \ of ARP broadcast messages becomes less significant to\n   servers.  For example,\
    \ lab testing shows that 2000 ARP requests\n   per second only takes 2% of a single-core\
    \ CPU server.  Therefore, the\n   impact of ARP broadcasts to end stations is\
    \ not significant on\n   today's servers.\n   Statistics provided by Merit Network\
    \ [ARMD-Statistics] have shown\n   that the major impact of a large number of\
    \ mobile VMs in a data\n   center is on the L2/L3 boundary routers, i.e., issue\
    \ 2 above.\n   This memo documents some simple practices that can scale ARP/ND\
    \ in a\n   data center environment, especially in reducing processing loads to\n\
    \   L2/L3 boundary routers.\n"
- title: 2.  Terminology
  contents:
  - "2.  Terminology\n   This document reuses much of the terminology from [RFC6820].\
    \  Many of\n   the definitions are presented here to aid the reader.\n   ARP:\
    \ IPv4 Address Resolution Protocol [RFC826]\n   Aggregation Switch: A Layer 2\
    \ switch interconnecting ToR switches\n   Bridge: IEEE802.1Q-compliant device.\
    \  In this document, the term\n      \"Bridge\" is used interchangeably with \"\
    Layer 2 switch\"\n   DC: Data Center\n   DA: Destination Address\n   End Station:\
    \ VM or physical server, whose address is either the\n      destination or the\
    \ source of a data frame\n   EoR: End-of-Row switches in a data center\n   NA:\
    \ IPv6 Neighbor Advertisement\n   ND: IPv6 Neighbor Discovery [RFC4861]\n   NS:\
    \ IPv6 Neighbor Solicitation\n   SA: Source Address\n   ToR: Top-of-Rack Switch\
    \ (also known as access switch)\n   UNA: IPv6 Unsolicited Neighbor Advertisement\n\
    \   VM: Virtual Machine\n   Subnet: Refers to the multi-access link subnet referenced\
    \ by RFC 4903\n"
- title: 3.  Common DC Network Designs
  contents:
  - "3.  Common DC Network Designs\n   Some common network designs for a data center\
    \ include:\n   1) Layer 3 connectivity to the access switch,\n   2) Large Layer\
    \ 2, and\n   3) Overlay models.\n   There is no single network design that fits\
    \ all cases.  The following\n   sections document some of the common practices\
    \ to scale address\n   resolution under each network design.\n"
- title: 4.  Layer 3 to Access Switches
  contents:
  - "4.  Layer 3 to Access Switches\n   This network design configures Layer 3 to\
    \ the access switches,\n   effectively making the access switches the L2/L3 boundary\
    \ routers for\n   the attached VMs.\n   As described in [RFC6820], many data centers\
    \ are architected so that\n   ARP/ND broadcast/multicast messages are confined\
    \ to a few ports\n   (interfaces) of the access switches (i.e., ToR switches).\n\
    \   Another variant of the Layer 3 solution is a Layer 3 infrastructure\n   configured\
    \ all the way to servers (or even to the VMs), which\n   confines the ARP/ND broadcast/multicast\
    \ messages to the small number\n   of VMs within the server.\n   Advantage: Both\
    \ ARP and ND scale well.  There is no address\n      resolution issue in this\
    \ design.\n   Disadvantage: The main disadvantage of this network design occurs\n\
    \      during VM movement.  During VM movement, either VMs need an\n      address\
    \ change or switches/routers need a configuration change\n      when the VMs are\
    \ moved to different locations.\n   Summary: This solution is more suitable to\
    \ data centers that have a\n      static workload and/or network operators who\
    \ can reconfigure IP\n      addresses/subnets on switches before any workload\
    \ change.  No\n      protocol changes are suggested.\n"
- title: 5.  Layer 2 Practices to Scale ARP/ND
  contents:
  - '5.  Layer 2 Practices to Scale ARP/ND

    '
- title: 5.1.  Practices to Alleviate APR/ND Burden on L2/L3 Boundary Routers
  contents:
  - "5.1.  Practices to Alleviate APR/ND Burden on L2/L3 Boundary Routers\n   The\
    \ ARP/ND broadcast/multicast messages in a Layer 2 domain can\n   negatively affect\
    \ the L2/L3 boundary routers, especially with a large\n   number of VMs and subnets.\
    \  This section describes some commonly used\n   practices for reducing the ARP/ND\
    \ processing required on L2/L3\n   boundary routers.\n"
- title: 5.1.1.  Communicating with a Peer in a Different Subnet
  contents:
  - "5.1.1.  Communicating with a Peer in a Different Subnet\n   Scenario: When the\
    \ originating end station doesn't have its default\n      gateway MAC address\
    \ in its ARP/ND cache and needs to communicate\n      with a peer in a different\
    \ subnet, it needs to send ARP/ND\n      requests to its default gateway router\
    \ to resolve the router's MAC\n      address.  If there are many subnets on the\
    \ gateway router and a\n      large number of end stations in those subnets that\
    \ don't have the\n      gateway MAC address in their ARP/ND caches, the gateway\
    \ router has\n      to process a very large number of ARP/ND requests.  This is\
    \ often\n      CPU intensive, as ARP/ND messages are usually processed by the\
    \ CPU\n      (and not in hardware).\n   Note: Any centralized configuration that\
    \ preloads the default MAC\n      addresses is not included in this scenario.\n\
    \   Solution: For IPv4 networks, a practice to alleviate this problem is\n   \
    \   to have the L2/L3 boundary router send periodic gratuitous ARP\n      [GratuitousARP]\
    \ messages, so that all the connected end stations\n      can refresh their ARP\
    \ caches.  As a result, most (if not all) end\n      stations will not need to\
    \ send ARP requests for the gateway\n      routers when they need to communicate\
    \ with external peers.\n   For the above scenario, IPv6 end stations are still\
    \ required to send\n   unicast ND messages to their default gateway router (even\
    \ with those\n   routers periodically sending Unsolicited Neighbor Advertisements)\n\
    \   because IPv6 requires bidirectional path validation.\n   Advantage: This practice\
    \ results in a reduction of ARP requests to be\n      processed by the L2/L3 boundary\
    \ router for IPv4.\n   Disadvantage: This practice doesn't reduce ND processing\
    \ on the L2/L3\n      boundary router for IPv6 traffic.\n   Recommendation: If\
    \ the network is an IPv4-only network, then this\n      approach can be used.\
    \  For an IPv6 network, one needs to consider\n      the work described in [RFC7048].\
    \  Note: ND and Secure Neighbor\n      Discovery (SEND) [RFC3971] use the bidirectional\
    \ nature of queries\n      to detect and prevent security attacks.\n"
- title: 5.1.2.  L2/L3 Boundary Router Processing of Inbound Traffic
  contents:
  - "5.1.2.  L2/L3 Boundary Router Processing of Inbound Traffic\n   Scenario: When\
    \ an L2/L3 boundary router receives a data frame\n      destined for a local subnet\
    \ and the destination is not in the\n      router's ARP/ND cache, some routers\
    \ hold the packet and trigger an\n      ARP/ND request to resolve the L2 address.\
    \  The router may need to\n      send multiple ARP/ND requests until either a\
    \ timeout is reached or\n      an ARP/ND reply is received before forwarding the\
    \ data packets\n      towards the target's MAC address.  This process is not only\
    \ CPU\n      intensive but also buffer intensive.\n   Solution: To protect a router\
    \ from being overburdened by resolving\n      target MAC addresses, one solution\
    \ is for the router to limit the\n      rate of resolving target MAC addresses\
    \ for inbound traffic whose\n      target is not in the router's ARP/ND cache.\
    \  When the rate is\n      exceeded, the incoming traffic whose target is not\
    \ in the ARP/ND\n      cache is dropped.\n   For an IPv4 network, another common\
    \ practice to alleviate pain caused\n   by this problem is for the router to snoop\
    \ ARP messages between other\n   hosts, so that its ARP cache can be refreshed\
    \ with active addresses\n   in the L2 domain.  As a result, there is an increased\
    \ likelihood of\n   the router's ARP cache having the IP-MAC entry when it receives\
    \ data\n   frames from external peers.  [RFC6820] Section 7.1 provides a full\n\
    \   description of this problem.\n   For IPv6 end stations, routers are supposed\
    \ to send Router\n   Advertisements (RAs) unicast even if they have snooped UNAs/NSs/NAs\n\
    \   from those stations.  Therefore, this practice allows an L2/L3\n   boundary\
    \ to send unicast RAs to the target instead of multicasts.\n   [RFC6820] Section\
    \ 7.2 has a full description of this problem.\n   Advantage: This practice results\
    \ in a reduction of the number of ARP\n      requests that routers have to send\
    \ upon receiving IPv4 packets and\n      the number of IPv4 data frames from external\
    \ peers that routers\n      have to hold due to targets not being in the ARP cache.\n\
    \   Disadvantage: The amount of ND processing on routers for IPv6 traffic\n  \
    \    is not reduced.  IPv4 routers still need to hold data packets from\n    \
    \  external peers and trigger ARP requests if the targets of the data\n      packets\
    \ either don't exist or are not very active.  In this case,\n      IPv4 processing\
    \ or IPv4 buffers are not reduced.\n   Recommendation: If there is a higher chance\
    \ of routers receiving data\n      packets that are destined for nonexistent or\
    \ inactive targets,\n      alternative approaches should be considered.\n"
- title: 5.1.3.  Inter-Subnet Communications
  contents:
  - "5.1.3.  Inter-Subnet Communications\n   The router could be hit with ARP/ND requests\
    \ twice when the\n   originating and destination stations are in different subnets\n\
    \   attached to the same router and those hosts don't communicate with\n   external\
    \ peers often enough.  The first hit is when the originating\n   station in subnet-A\
    \ initiates an ARP/ND request to the L2/L3 boundary\n   router if the router's\
    \ MAC is not in the host's cache (Section 5.1.1\n   above), and the second hit\
    \ is when the L2/L3 boundary router\n   initiates ARP/ND requests to the target\
    \ in subnet-B if the target is\n   not in the router's ARP/ND cache (Section 5.1.2\
    \ above).\n   Again, practices described in Sections 5.1.1 and 5.1.2 can alleviate\n\
    \   some problems in some IPv4 networks.\n   For IPv6 traffic, the practices described\
    \ above don't reduce the ND\n   processing on L2/L3 boundary routers.\n   Recommendation:\
    \ Consider the recommended approaches described in\n      Sections 5.1.1 and 5.1.2.\
    \  However, any solutions that relax the\n      bidirectional requirement of IPv6\
    \ ND disable the security that the\n      two-way ND communication exchange provides.\n"
- title: 5.2.  Static ARP/ND Entries on Switches
  contents:
  - "5.2.  Static ARP/ND Entries on Switches\n   In a data center environment, the\
    \ placement of L2 and L3 addressing\n   may be orchestrated by Server (or VM)\
    \ Management System(s).\n   Therefore, it may be possible for static ARP/ND entries\
    \ to be\n   configured on routers and/or servers.\n   Advantage: This methodology\
    \ has been used to reduce ARP/ND\n      fluctuations in large-scale data center\
    \ networks.\n   Disadvantage: When some VMs are added, deleted, or moved, many\n\
    \      switches' static entries need to be updated.  In a data center\n      with\
    \ virtualized servers, those events can happen frequently.  For\n      example,\
    \ for an event of one VM being added to one server, if the\n      subnet of this\
    \ VM spans 15 access switches, all of them need to be\n      updated.  Network\
    \ management mechanisms (SNMP, the Network\n      Configuration Protocol (NETCONF),\
    \ or proprietary mechanisms) are\n      available to provide updates or incremental\
    \ updates.  However,\n      there is no well-defined approach for switches to\
    \ synchronize\n      their content with the management system for efficient incremental\n\
    \      updates.\n   Recommendation: Additional work may be needed within IETF\
    \ working\n      groups (e.g., NETCONF, NVO3, I2RS, etc.) to get prompt incremental\n\
    \      updates of static ARP/ND entries when changes occur.\n"
- title: 5.3.  ARP/ND Proxy Approaches
  contents:
  - "5.3.  ARP/ND Proxy Approaches\n   RFC 1027 [RFC1027] specifies one ARP Proxy\
    \ approach referred to as\n   \"Proxy ARP\".  However, RFC 1027 does not discuss\
    \ a scaling mechanism.\n   Since the publication of RFC 1027 in 1987, many variants\
    \ of Proxy ARP\n   have been deployed.  RFC 1027's Proxy ARP technique allows\
    \ a gateway\n   to return its own MAC address on behalf of the target station.\n\
    \   [ARP_Reduction] describes a type of \"ARP Proxy\" that allows a ToR\n   switch\
    \ to snoop ARP requests and return the target station's MAC if\n   the ToR has\
    \ the information in its cache.  However, [RFC4903] doesn't\n   recommend the\
    \ caching approach described in [ARP_Reduction] because\n   such a cache prevents\
    \ any type of fast mobility between Layer 2 ports\n   and breaks Secure Neighbor\
    \ Discovery [RFC3971].\n   IPv6 ND Proxy [RFC4389] specifies a proxy used between\
    \ an Ethernet\n   segment and other segments, such as wireless or PPP segments.\
    \  ND\n   Proxy [RFC4389] doesn't allow a proxy to send NA messages on behalf\n\
    \   of the target to ensure that the proxy does not interfere with hosts\n   moving\
    \ from one segment to another.  Therefore, the ND Proxy\n   [RFC4389] doesn't\
    \ reduce the number of ND messages to an L2/L3\n   boundary router.\n   Bottom\
    \ line, the term \"ARP/ND Proxy\" has different interpretations,\n   depending\
    \ on vendors and/or environments.\n   Recommendation: For IPv4, even though those\
    \ Proxy ARP variants (not\n      RFC 1076) have been used to reduce ARP traffic\
    \ in various\n      environments, there are many issues with caching.\n   The\
    \ IETF should consider making proxy recommendations for data center\n   environments\
    \ as a transition issue to help DC operators transitioning\n   to IPv6.  Section\
    \ 7 of [RFC4389] (\"Guidelines to Proxy Developers\")\n   should be considered\
    \ when developing any new proxy protocols to\n   scale ARP.\n"
- title: 5.4.  Multicast Scaling Issues
  contents:
  - "5.4.  Multicast Scaling Issues\n   Multicast snooping (IGMP/MLD) has different\
    \ implementations and\n   scaling issues.  [RFC4541] notes that multicast IGMPv2/v3\
    \ snooping\n   has trouble with subnets that include IGMPv2 and IGMPv3.  [RFC4541]\n\
    \   also notes that MLDv2 snooping requires the use of either destination\n  \
    \ MAC (DMAC) address filtering or deeper inspection of frames/packets\n   to allow\
    \ for scaling.\n   MLDv2 snooping needs to be re-examined for scaling within the\
    \ DC.\n   Efforts such as IGMP/MLD explicit tracking [IGMP-MLD-Tracking] for\n\
    \   downstream hosts need to provide better scaling than IGMP/MLDv2\n   snooping.\n"
- title: 6.  Practices to Scale ARP/ND in Overlay Models
  contents:
  - "6.  Practices to Scale ARP/ND in Overlay Models\n   There are several documents\
    \ on using overlay networks to scale large\n   Layer 2 networks (or avoid the\
    \ need for large L2 networks) and enable\n   mobility (e.g., [L3-VM-Mobility],\
    \ [VXLAN]).  Transparent\n   Interconnection of Lots of Links (TRILL) and IEEE\
    \ 802.1ah\n   (Mac-in-Mac) are other types of overlay networks that can scale\n\
    \   Layer 2.\n   Overlay networks hide the VMs' addresses from the interior switches\n\
    \   and routers, thereby greatly reducing the number of addresses exposed\n  \
    \ to the interior switches and router.  The overlay edge nodes that\n   perform\
    \ the network address encapsulation/decapsulation still handle\n   all remote\
    \ stations' addresses that communicate with the locally\n   attached end stations.\n\
    \   For a large data center with many applications, these applications'\n   IP\
    \ addresses need to be reachable by external peers.  Therefore, the\n   overlay\
    \ network may have a bottleneck at the gateway node(s) in\n   processing resolving\
    \ target stations' physical addresses (MAC or IP)\n   and the overlay edge address\
    \ within the data center.\n   Here are two approaches that can be used to minimize\
    \ this problem:\n   1. Use static mapping as described in Section 5.2.\n   2.\
    \ Have multiple L2/L3 boundary nodes (i.e., routers), with each\n      handling\
    \ a subset of stations' addresses that are visible to\n      external peers (e.g.,\
    \ Gateway #1 handles a set of prefixes,\n      Gateway #2 handles another subset\
    \ of prefixes, etc.).\n"
- title: 7.  Summary and Recommendations
  contents:
  - "7.  Summary and Recommendations\n   This memo describes some common practices\
    \ that can alleviate the\n   impact of address resolution on L2/L3 gateway routers.\n\
    \   In data centers, no single solution fits all deployments.  This memo\n   has\
    \ summarized some practices in various scenarios and the advantages\n   and disadvantages\
    \ of all of these practices.\n   In some of these scenarios, the common practices\
    \ could be improved by\n   creating and/or extending existing IETF protocols.\
    \  These protocol\n   change recommendations are:\n   o  Relax the bidirectional\
    \ requirement of IPv6 ND in some\n      environments.  However, other issues will\
    \ be introduced when the\n      bidirectional requirement of ND is relaxed.  Therefore,\
    \ it is\n      necessary to have performed a comprehensive study of possible\n\
    \      issues prior to making those changes.\n   o  Create an incremental \"update\"\
    \ scheme for efficient static ARP/ND\n      entries.\n   o  Develop IPv4 ARP/IPv6\
    \ ND Proxy standards for use in the data\n      center.  Section 7 of [RFC4389]\
    \ (\"Guidelines to Proxy Developers\")\n      should be considered when developing\
    \ any new proxy protocols to\n      scale ARP/ND.\n   o  Consider scaling issues\
    \ with IGMP/MLD snooping to determine\n      whether or not new alternatives can\
    \ provide better scaling.\n"
- title: 8.  Security Considerations
  contents:
  - "8.  Security Considerations\n   This memo documents existing solutions and proposes\
    \ additional work\n   that could be initiated to extend various IETF protocols\
    \ to better\n   scale ARP/ND for the data center environment.\n   Security is\
    \ a major issue for data center environments.  Therefore,\n   security should\
    \ be seriously considered when developing any future\n   protocol extensions.\n"
- title: 9.  Acknowledgements
  contents:
  - "9.  Acknowledgements\n   We want to acknowledge the ARMD WG and the following\
    \ people for their\n   valuable inputs to this document: Joel Jaeggli, Dave Thaler,\
    \ Susan\n   Hares, Benson Schliesser, T. Sridhar, Ron Bonica, Kireeti Kompella,\n\
    \   and K.K. Ramakrishnan.\n"
- title: 10.  References
  contents:
  - '10.  References

    '
- title: 10.1.  Normative References
  contents:
  - "10.1.  Normative References\n   [GratuitousARP]\n              Cheshire, S.,\
    \ \"IPv4 Address Conflict Detection\", RFC 5227,\n              July 2008.\n \
    \  [RFC826]   Plummer, D., \"Ethernet Address Resolution Protocol: Or\n      \
    \        Converting Network Protocol Addresses to 48.bit Ethernet\n          \
    \    Address for Transmission on Ethernet Hardware\", STD 37,\n              RFC\
    \ 826, November 1982.\n   [RFC1027]  Carl-Mitchell, S. and J. Quarterman, \"Using\
    \ ARP to\n              implement transparent subnet gateways\", RFC 1027,\n \
    \             October 1987.\n   [RFC3971]  Arkko, J., Ed., Kempf, J., Zill, B.,\
    \ and P. Nikander,\n              \"SEcure Neighbor Discovery (SEND)\", RFC 3971,\
    \ March 2005.\n   [RFC4389]  Thaler, D., Talwar, M., and C. Patel, \"Neighbor\
    \ Discovery\n              Proxies (ND Proxy)\", RFC 4389, April 2006.\n   [RFC4541]\
    \  Christensen, M., Kimball, K., and F. Solensky,\n              \"Considerations\
    \ for Internet Group Management Protocol\n              (IGMP) and Multicast Listener\
    \ Discovery (MLD) Snooping\n              Switches\", RFC 4541, May 2006.\n  \
    \ [RFC4861]  Narten, T., Nordmark, E., Simpson, W., and H. Soliman,\n        \
    \      \"Neighbor Discovery for IP version 6 (IPv6)\", RFC 4861,\n           \
    \   September 2007.\n   [RFC4903]  Thaler, D., \"Multi-Link Subnet Issues\", RFC\
    \ 4903,\n              June 2007.\n   [RFC6820]  Narten, T., Karir, M., and I.\
    \ Foo, \"Address Resolution\n              Problems in Large Data Center Networks\"\
    , RFC 6820,\n              January 2013.\n"
- title: 10.2.  Informative References
  contents:
  - "10.2.  Informative References\n   [ARMD-Statistics]\n              Karir, M.\
    \ and J. Rees, \"Address Resolution Statistics\",\n              Work in Progress,\
    \ July 2011.\n   [ARP_Reduction]\n              Shah, H., Ghanwani, A., and N.\
    \ Bitar, \"ARP Broadcast\n              Reduction for Large Data Centers\", Work\
    \ in Progress,\n              October 2011.\n   [IGMP-MLD-Tracking]\n        \
    \      Asaeda, H., \"IGMP/MLD-Based Explicit Membership Tracking\n           \
    \   Function for Multicast Routers\", Work in Progress,\n              December\
    \ 2013.\n   [L3-VM-Mobility]\n              Kumari, W. and J. Halpern, \"Virtual\
    \ Machine mobility in L3\n              Networks\", Work in Progress, August 2011.\n\
    \   [Multi-Link]\n              Thaler, D. and C. Huitema, \"Multi-link Subnet\
    \ Support in\n              IPv6\", Work in Progress, June 2002.\n   [RFC1076]\
    \  Trewitt, G. and C. Partridge, \"HEMS Monitoring and Control\n             \
    \ Language\", RFC 1076, November 1988.\n   [RFC7048]  Nordmark, E. and I. Gashinsky,\
    \ \"Neighbor Unreachability\n              Detection Is Too Impatient\", RFC 7048,\
    \ January 2014.\n   [VXLAN]    Mahalingam, M., Dutt, D., Duda, K., Agarwal, P.,\
    \ Kreeger,\n              L., Sridhar, T., Bursell, M., and C. Wright, \"VXLAN:\
    \ A\n              Framework for Overlaying Virtualized Layer 2 Networks over\n\
    \              Layer 3 Networks\", Work in Progress, April 2014.\n"
- title: Authors' Addresses
  contents:
  - "Authors' Addresses\n   Linda Dunbar\n   Huawei Technologies\n   5340 Legacy Drive,\
    \ Suite 175\n   Plano, TX  75024\n   USA\n   Phone: (469) 277 5840\n   EMail:\
    \ ldunbar@huawei.com\n   Warren Kumari\n   Google\n   1600 Amphitheatre Parkway\n\
    \   Mountain View, CA  94043\n   USA\n   EMail: warren@kumari.net\n   Igor Gashinsky\n\
    \   Yahoo\n   45 West 18th Street 6th floor\n   New York, NY  10011\n   USA\n\
    \   EMail: igor@yahoo-inc.com\n"
